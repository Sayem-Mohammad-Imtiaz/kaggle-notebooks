{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"##@title Importing Dependencies\n!pip install adam\n!pip install kwargs  \n!pip install cinit  \n#sys is used so as to access to some variables used or maintained by the interpreter and to functions that interact strongly with the interpreter \nimport sys,os#os for interaction with os but i doubt it will be useful here\n#import opencv-python #for computer vision and identification purposes\nimport tensorflow#for AI models, using data flow graphs to build models.\nimport numpy as np#for linear processing, for Scientific Computing.\nimport pandas as pd#For dealing with data analysis and manipulation\nimport keras# for developing and evaluating deep learning models\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\n#Sequential to build a model layer by layer..Each layer has weights that correspond to the layer the follows it..\nfrom keras.models import Sequential \n#dense layer:classic fully connected neural network layer:each input node is connected to each output node.\n#Dropout layer:similar except that when the layer is used, the activations are set to zero for some random nodes. This is a way to prevent overfitting.\n#activation functions help in reducing unneccessary noise\n#activation functions help the network use the important information and suppress the irrelevant data points.\n#flatten:didn't understand fully but i think it is used to convert matrix to single array\n#Flattening a tensor means to remove all of the dimensions except for one. This is exactly what the Flatten layer do.\nfrom keras.layers import Dense, Dropout, Activation, Flatten  \n#Conv2D for two dimensional convolutions network\n# Max pooling is a sample-based discretization process. \n# The objective is to down-sample an input representation\n#  (image, hidden-layer output matrix, etc.), reducing its\n#   dimensionality and allowing for assumptions to be made about features\n#   contained in the sub-regions binned.\n#Batch Normalization helps in accelearting the learning DNNs\n#Average Pooling2d:Bouncer\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n#categorical_crossentropy : don't know\nfrom keras.losses import categorical_crossentropy  \n#adam:replacement optimization algorithm for stochastic gradient descent for training deep learning models.#don't understand what it is \nfrom keras.optimizers import Adam  \n#l2:allows you to add a penalty for weight size to the loss function\nfrom keras.regularizers import l2 \n#np_utils:Numpy-related utilities. \nfrom keras.utils import np_utils  \n\n# why is it commented out??\n# pd.set_option('display.max_rows', 500)  \n# pd.set_option('display.max_columns', 500)  \n# pd.set_option('display.width', 1000)  \n\ndf=pd.read_csv('../input/fer2013/fer2013.csv')  \n\n# print(df.info())  \n# print(df[\"Usage\"].value_counts())  \n\n# print(df.head()) #tell about what is int he data frame \nX_train,train_y,X_test,test_y=[],[],[],[]  \n\nfor index, row in df.iterrows():  \n    val=row['pixels'].split(\" \")  \n    try:  \n        if 'Training' in row['Usage']:  \n           X_train.append(np.array(val,'float32'))  \n           train_y.append(row['emotion'])  \n        elif 'PublicTest' in row['Usage']:  \n           X_test.append(np.array(val,'float32'))  \n           test_y.append(row['emotion'])  \n    except:  \n        print(f\"error occured at index :{index} and row:{row}\")  \n\n\nnum_features = 64  \nnum_labels = 7  \nbatch_size = 64  \nepochs = 30  \nwidth, height = 48, 48  \n\n\nX_train = np.array(X_train,'float32')  \ntrain_y = np.array(train_y,'float32')  \nX_test = np.array(X_test,'float32')  \ntest_y = np.array(test_y,'float32')  \n\ntrain_y=np_utils.to_categorical(train_y, num_classes=num_labels)  \ntest_y=np_utils.to_categorical(test_y, num_classes=num_labels)  \n\n#cannot produce  \n#normalizing data between oand 1  \nX_train -= np.mean(X_train, axis=0)  \nX_train /= np.std(X_train, axis=0)  \n\nX_test -= np.mean(X_test, axis=0)  \nX_test /= np.std(X_test, axis=0)  \n\nX_train = X_train.reshape(X_train.shape[0], 48, 48, 1)  \n\nX_test = X_test.reshape(X_test.shape[0], 48, 48, 1)  \n\n# print(f\"shape:{X_train.shape}\")  \n##designing the cnn  \n#1st convolution layer  \nmodel = Sequential()  \n\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))  \nmodel.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))  \n# model.add(BatchNormalization())  \nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))  \nmodel.add(Dropout(0.5))  \n\n#2nd convolution layer  \nmodel.add(Conv2D(64, (3, 3), activation='relu'))  \nmodel.add(Conv2D(64, (3, 3), activation='relu'))  \n# model.add(BatchNormalization())  \nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))  \nmodel.add(Dropout(0.5))  \n\n#3rd convolution layer  \nmodel.add(Conv2D(128, (3, 3), activation='relu'))  \nmodel.add(Conv2D(128, (3, 3), activation='relu'))  \n# model.add(BatchNormalization())  \nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))  \n\nmodel.add(Flatten())  \n\n#fully connected neural networks  \nmodel.add(Dense(1024, activation='relu'))  \nmodel.add(Dropout(0.2))  \nmodel.add(Dense(1024, activation='relu'))  \nmodel.add(Dropout(0.2))  \n\nmodel.add(Dense(num_labels, activation='softmax'))  \n\n# model.summary()  \n\n#Compliling the model  \nmodel.compile(loss=categorical_crossentropy,  \n              optimizer=Adam(),  \n              metrics=['accuracy'])  \n\n#Training the model  \nmodel.fit(X_train, train_y,  \n          batch_size=batch_size,  \n          epochs=epochs,  \n          verbose=1,  \n          validation_data=(X_test, test_y),  \n          shuffle=True)  \n\n\n#Saving the  model to  use it later on  \nfer_json = model.to_json()  \nwith open(\"fer.json\", \"w\") as json_file:  \n    json_file.write(fer_json)  \nmodel.save_weights(\"fer.h5\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#videotesting file\nimport os  \nimport cv2  \nimport numpy as np  \nfrom keras.models import model_from_json  \nfrom keras.preprocessing import image  \n\n#load model  \nmodel = model_from_json(open(\"fer.json\", \"r\").read())  \n#load weights  \nmodel.load_weights('fer.h5')  \n\n\nface_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')  \n\n\ncap=cv2.VideoCapture(0)  \n\nwhile True:  \n    ret,test_img=cap.read()# captures frame and returns boolean value and captured image  \n    if not ret:  \n        continue  \n    gray_img= cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)  \n\n    faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)  \n\n\n    for (x,y,w,h) in faces_detected:  \n        cv2.rectangle(test_img,(x,y),(x+w,y+h),(255,0,0),thickness=7)  \n        roi_gray=gray_img[y:y+w,x:x+h]#cropping region of interest i.e. face area from  image  \n        roi_gray=cv2.resize(roi_gray,(48,48))  \n        img_pixels = image.img_to_array(roi_gray)  \n        img_pixels = np.expand_dims(img_pixels, axis = 0)  \n        img_pixels /= 255  \n\n        predictions = model.predict(img_pixels)  \n\n        #find max indexed array  \n        max_index = np.argmax(predictions[0])  \n\n        emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')  \n        predicted_emotion = emotions[max_index]  \n\n        cv2.putText(test_img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)  \n\n    resized_img = cv2.resize(test_img, (1000, 700))  \n    cv2.imshow('Facial emotion analysis ',resized_img)  \n\n\n\n    if cv2.waitKey(10) == ord('q'):#wait until 'q' key is pressed  \n        break  \n\ncap.release()  \ncv2.destroyAllWindows ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}