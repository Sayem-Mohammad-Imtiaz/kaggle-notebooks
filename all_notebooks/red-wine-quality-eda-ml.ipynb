{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# RED WINE QUALITY -DA & ML","metadata":{}},{"cell_type":"markdown","source":"### ABOUT DATASET","metadata":{}},{"cell_type":"markdown","source":"The Wine Quality dataset contains information about various physicochemical properties of wines.\ne are going to download and load the dataset into Python and perform an initial analysis to disclose what is inside it.\nAnd applying some Machine learning algorithms.","metadata":{}},{"cell_type":"markdown","source":"### FEATURES DESCRIPTION\n* Fixed acidity: It indicates the amount of tartaric acid in wine and is measured in g/dm3\n* Volatile acidity: It indicates the amount of acetic acid in the wine. It is measured in g/dm3.\n* Citric acid: It indicates the amount of citric acid in the wine. It is also measured in g/dm3\n* Residual sugar: It indicates the amount of sugar left in the wine after the fermentation process is done. It is also measured in g/dm3\n* Free sulfur dioxide: It measures the amount of sulfur dioxide (SO2) in free form. It is also measured in g/dm3\n* Total sulfur dioxide: It measures the total amount of SO2 in the wine. This chemical works as an antioxidant and antimicrobial agent.\n* Density: It indicates the density of the wine and is measured in g/dm3.\n* pH: It indicates the pH value of the wine. The range of value is between 0 to 14.0, which indicates very high acidity, and 14 indicates basic acidity.\n* Sulphates: It indicates the amount of potassium sulphate in the wine. It is also measured in g/dm3.\n* Alcohol: It indicates the alcohol content in the wine.\n* Quality: It indicates the quality of the wine, which is ranged from 1 to 10. Here, the higher the value is, the better the wine.\n","metadata":{}},{"cell_type":"markdown","source":"- - -","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load data file\nred_wine=pd.read_csv('../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\nred_wine.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"red_wine.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"red_wine.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"red_wine.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"red_wine.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observation:-\nIn red wine data set no missing values.","metadata":{}},{"cell_type":"code","source":"red_wine.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"red_wine.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10,7,))\ncorrMatrix=red_wine.corr()\nmask = np.triu(np.ones_like(corrMatrix, dtype = bool))\nsns.heatmap(corrMatrix,annot=True, fmt = '.2f', linewidths = 2)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observation:-\n* Alcohol is positively correlated with the quality of the red wine.\n* Alcohol has a weak positive correlation with the pH value.\n* Alcohol is negatively correlated with fixed acidity, volatile acidity,  chlorides, free sulfur dioxide ,total sulfur dioxide and density.\n* Citric acid and density have a strong positive correlation with fixed acidity\n* pH has a negative correlation with density, fixed acidity, citric acid, and sulfates.","metadata":{}},{"cell_type":"markdown","source":"- - - ","metadata":{}},{"cell_type":"markdown","source":"### * Red wine quality-wise analysis","metadata":{}},{"cell_type":"code","source":"#red wine quality value count\nquality_value_count=red_wine[\"quality\"].value_counts()\nquality_value_count","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(red_wine['quality'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"quality_value_count.plot.pie(autopct=\"%.1f%%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"red_wine.corr()['quality'].nlargest()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### * Red wine  alcohol-wise analysis","metadata":{}},{"cell_type":"code","source":"# Lets see how alcohol concentration is distributed with respect to the quality of the red wine.\nsns.distplot(red_wine['alcohol'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import skew\nskew(red_wine['alcohol'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The output verifies that alcohol is positively skewed.","metadata":{}},{"cell_type":"code","source":"#Dist plot of all features:\n# create dist plot\nfig, ax = plt.subplots(ncols=6, nrows=2, figsize=(20,10))\nindex = 0\nax = ax.flatten()\n\nfor col, value in red_wine.items():\n    sns.distplot(value, color='r', ax=ax[index])\n    index += 1\nplt.tight_layout(pad=0.5, w_pad=0.7, h_pad=5.0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above figures show the distribution of the features. Few of them are normally distributed where other are rightly skewed. The range of each feature is also not huge.","metadata":{}},{"cell_type":"markdown","source":"### Alcohol Vs Quality","metadata":{}},{"cell_type":"code","source":"sns.boxplot(x='quality', y='alcohol', data = red_wine)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above graph showing some dots outside of the graph. Those are outliers. outliers are around wine with quality 5 and 6. We can remove the outliers by passing an argument, showoutliers=False","metadata":{}},{"cell_type":"code","source":"sns.boxplot(x='quality', y='alcohol', data = red_wine, showfliers=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observation:-\nThe higher the alcohol concentration is, the higher the quality of the wine.","metadata":{}},{"cell_type":"markdown","source":"- - -","metadata":{}},{"cell_type":"code","source":"# red wine pH value wise count\nred_wine[\"pH\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(x='quality', y='pH', data = red_wine)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above graph showing some dots outside of the graph. Those are outliers. outliers are around wine with quality 4,5,6,7 AND 8. We can remove the outliers by passing an argument, showoutliers=False","metadata":{}},{"cell_type":"code","source":"sns.boxplot(x='quality', y='pH', data = red_wine, showfliers=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observation:- \n    For higher quality of red wine pH value lies between 3.0 to 3.6 range.","metadata":{}},{"cell_type":"markdown","source":"- - -","metadata":{}},{"cell_type":"markdown","source":"# Machine Learning Algorithm","metadata":{}},{"cell_type":"markdown","source":"# Linear Regression","metadata":{}},{"cell_type":"markdown","source":"Dependant variable:- quality\n    \nIndependant Variable:- fixed acidity\tvolatile acidity\tcitric acid\tresidual sugar\tchlorides\tfree sulfur dioxide\ttotal sulfur dioxide\tdensity\tpH\tsulphates\talcohol","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#droping data that we do not want to find corr\ndata=red_wine.drop(['quality'],axis=1)\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train,x_test, y_train, y_test=train_test_split(data,red_wine['quality'],test_size=0.20,random_state=8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=LinearRegression()\nmodel.fit(x_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy=model.score(x_test,y_test)\nprint(accuracy*100,'%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predicting the Test set result;  \ny_pred= model.predict(x_test)\ny_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Train Score: ', model.score(x_train, y_train))  \nprint('Test Score: ', model.score(x_test, y_test))  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#to see what coefficients our regression model has chose\ncoeff_df = pd.DataFrame(model.coef_,data.columns, columns=['Coefficient'])\ncoeff_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"red_wine_prediction = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\nred_wine_prediction","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Evaluating the Algorithm The final step is to evaluate the performance of algorithm. We'll do this by finding the values for MAE, MSE and RMSE. Execute the following script:","metadata":{}},{"cell_type":"code","source":"from sklearn import metrics\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observation:-\n* Accuracy of our red wine quality model by using linear regression is 35%.so here we observed that using linear regression algorithum is not good idea.\n\n* There is poor relation between Dependant variable(quality) and\nIndependant Variable(fixed acidity volatile acidity citric acid residual sugar chlorides free sulfur dioxide total sulfur dioxide density pH sulphates alcohol)  ","metadata":{}},{"cell_type":"markdown","source":"- - -","metadata":{}},{"cell_type":"markdown","source":"# Logistic Regression in Machine Learning","metadata":{}},{"cell_type":"markdown","source":"* Logistic regression predicts the output of a categorical dependent variable. \n\n* Dependant variable:- quality (as it is categorize in 5,6,7,4,8,3)\n    \n* Independant Variable:- fixed acidity volatile acidity citric acid residual sugar chlorides free sulfur dioxide total sulfur dioxide density pH sulphates alcohol","metadata":{}},{"cell_type":"code","source":"#Logistic regression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logistic_data=red_wine.drop(['quality'],axis=1)\nlogistic_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we will split the dataset into a training set and test set. Below is the code for it:","metadata":{}},{"cell_type":"code","source":"x_train,x_test, y_train, y_test=train_test_split(logistic_data,red_wine['quality'],test_size=0.20,random_state=8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In logistic regression, we will do feature scaling because we want accurate result of predictions. Here we will only scale the independent variable","metadata":{}},{"cell_type":"code","source":"#feature Scaling  \nfrom sklearn.preprocessing import StandardScaler    \nst_x= StandardScaler()    \nx_train= st_x.fit_transform(x_train)    \nx_test= st_x.transform(x_test)  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### * Fitting Logistic Regression to the Training set:\n\nWe have well prepared our dataset, and now we will train the dataset using the training set. For providing training or fitting the model to the training set, we will import the LogisticRegression class of the sklearn library.\n\nAfter importing the class, we will create a logmodel object and use it to fit the model to the logistic regression. Below is the code for it:","metadata":{}},{"cell_type":"code","source":"logmodel=LogisticRegression()\nlogmodel.fit(x_train,y_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### * Predicting the Test Result\n\nOur model is well trained on the training set, so we will now predict the result by using test set data. Below is the code for it:","metadata":{}},{"cell_type":"code","source":"predictions=logmodel.predict(x_test)\nx_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Accuracy of test data\naccuracy = logmodel.score(x_test, y_test)\nprint(\"Accuracy of Test set\",accuracy*100,'%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test,predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# accuracy score\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\nlr_acc = accuracy_score(y_test, logmodel.predict(x_test))\nprint(f\"Accuracy Score of Training Data is {accuracy_score(y_train, logmodel.predict(x_train))}\")\nprint(f\"Accuracy Score of Test Data is {lr_acc}\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- - -","metadata":{}},{"cell_type":"markdown","source":"# K-Nearest Neighbor (KNN)","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we are using same data i.e dependant variable is quality .And same training set and test set which we are created above (in linear regression)","metadata":{}},{"cell_type":"markdown","source":"we are fitting training set and test set to KNN  ","metadata":{}},{"cell_type":"code","source":"#feature Scaling  \nfrom sklearn.preprocessing import StandardScaler    \nst_x= StandardScaler()    \nx_train= st_x.fit_transform(x_train)    \nx_test= st_x.transform(x_test) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn = KNeighborsClassifier()\nknn.fit(x_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Accuracy of test data\n#accuracy = knn.score(x_test, y_test)\n#print(\"Accuracy score of Test set\",accuracy*100,'%')\nprint(f\"Accuracy score of Test Data is {(accuracy_score(y_test, knn.predict(x_test)))*100}\",'%')\nprint(f\"Accuracy score of Training Data is {(accuracy_score(y_train, knn.predict(x_train)))*100}\",'%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_knn = knn.predict(x_test)\npred_knn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, pred_knn))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix(y_test, pred_knn)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observation:- \n    Using KNN algorithm on red wine quality data where quality is dependant variable, accuracy of test data is 60%.","metadata":{}},{"cell_type":"markdown","source":"- - -","metadata":{}},{"cell_type":"markdown","source":"# SVC","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we are using same data i.e dependant variable is quality .And same training set and test set which we are created above (in linear regression)\n\nAfter scaling data we are fitting training set and test set to SVC \n","metadata":{}},{"cell_type":"code","source":"#SVM\nmodel_svc=SVC()\nmodel_svc.fit(x_train,y_train)\ny_train_pred=model_svc.predict(x_train)\ny_test_pred=model_svc.predict(x_test)\n\nprint(\"Train set Accuracy :\"+str(accuracy_score(y_train_pred,y_train)*100))\nprint(\"Test set Accuracy : \"+str(accuracy_score(y_test_pred,y_test)*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observation:- \n    Using SVC  algorithm on red wine quality data where quality is dependant variable, accuracy of test data is 61%.","metadata":{}},{"cell_type":"markdown","source":"- - -","metadata":{}},{"cell_type":"markdown","source":"# Decision Tree","metadata":{}},{"cell_type":"markdown","source":"Here we are using same data i.e dependant variable is quality .And same training set and test set which we are created above (in linear regression)\n\nAfter scaling data we are fitting training set and test set to SVC ","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(x_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" #accuracy score\nprint(f\"Accuracy score of Test Data is {(accuracy_score(y_test, decision_tree.predict(x_test)))*100}\",'%')\nprint(f\"Accuracy score of Training Data is {(accuracy_score(y_train, decision_tree.predict(x_train)))*100}\",'%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- - -","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}