{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Requirements\nBasic knowledge of Python is needed to follow this notebook. Check the subjects listed in these courses:\n- [Python course](https://www.kaggle.com/learn/python)\n- [Pandas course](https://www.kaggle.com/learn/pandas)\n- Check out [this notebook](https://www.kaggle.com/ponybiam/introduction-to-ifcopenshell-functions) to get familiar with the package `ifcopenshell`.","metadata":{}},{"cell_type":"markdown","source":"# About the environment\nThis Python 3 environment comes with many helpful analytics libraries installed. It is defined by the [kaggle/python Docker image](https://github.com/kaggle/docker-python). Input data files are available in the read-only `../input/` directory. For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory:","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2021-07-16T18:29:53.560904Z","iopub.execute_input":"2021-07-16T18:29:53.561417Z","iopub.status.idle":"2021-07-16T18:29:53.578217Z","shell.execute_reply.started":"2021-07-16T18:29:53.561384Z","shell.execute_reply":"2021-07-16T18:29:53.577113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can write up to 20GB to the current directory (`/kaggle/working/`) that gets preserved as output when you create a version using \"Save & Run All\". You can also write temporary files to `/kaggle/temp/`, but they won't be saved outside of the current session.","metadata":{}},{"cell_type":"markdown","source":"# Load packages\nFirst we are going to install the [`ifcopenshell`](http://ifcopenshell.org/) package. *IfcOpenShell* is an open source software library that helps users and software developers to work with the IFC file format. The IFC file format can be used to describe building and construction data. The format is commonly used for Building Information Modelling (BIM).<br>\n<br>\nRun the following code to install the package in the curren environment:","metadata":{}},{"cell_type":"code","source":"conda install -c conda-forge -c oce -c dlr-sc -c ifcopenshell ifcopenshell","metadata":{"execution":{"iopub.status.busy":"2021-07-16T18:29:53.5809Z","iopub.execute_input":"2021-07-16T18:29:53.581334Z","iopub.status.idle":"2021-07-16T18:31:39.462114Z","shell.execute_reply.started":"2021-07-16T18:29:53.581289Z","shell.execute_reply":"2021-07-16T18:31:39.461156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And now we import the packages we are going to use in this notebook:","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport ifcopenshell","metadata":{"execution":{"iopub.status.busy":"2021-07-16T18:31:39.463575Z","iopub.execute_input":"2021-07-16T18:31:39.46393Z","iopub.status.idle":"2021-07-16T18:31:39.644887Z","shell.execute_reply.started":"2021-07-16T18:31:39.463866Z","shell.execute_reply":"2021-07-16T18:31:39.643953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load dataset\nWe will be using the files:\n\n- `Grethes-hus-bok-2.ifc`\n- `11134_V_Motebello_Heistopp_Rev.ifc`\n- `11134_D_Motebello_Heistopp_Rev.ifc`\n\n Let's use our recently installed package to open them:","metadata":{}},{"cell_type":"code","source":"file1 = ifcopenshell.open(\"../input/example-ifc-file/Grethes-hus-bok-2.ifc\")\nfile2 =  ifcopenshell.open(\"../input/example-ifc-file/11134_V_Motebello_Heistopp_Rev.ifc\")","metadata":{"execution":{"iopub.status.busy":"2021-07-16T18:31:39.647429Z","iopub.execute_input":"2021-07-16T18:31:39.647759Z","iopub.status.idle":"2021-07-16T18:31:40.117929Z","shell.execute_reply.started":"2021-07-16T18:31:39.647728Z","shell.execute_reply":"2021-07-16T18:31:40.115924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Parse dataset\n## File 1: *Grethes-hus-bok-2.ifc*\nFirst, we are going to get all the elements of type [IfcBuildingElement](https://standards.buildingsmart.org/IFC/RELEASE/IFC4/ADD2_TC1/HTML/schema/ifcproductextension/lexical/ifcbuildingelement.htm) from `Grethes-hus-bok-2.ifc` file. We will use the method [by_type](https://blenderbim.org/docs/ifcopenshell-python/api-documentation.html#ifcopenshell.file.file.by_type) (from `ifcopenshell` package) to get a list with all the `IfcBuildingElement` entities:","metadata":{}},{"cell_type":"code","source":"elements = file1.by_type('IfcBuildingElement')\nlen(elements)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T18:31:40.120699Z","iopub.execute_input":"2021-07-16T18:31:40.121492Z","iopub.status.idle":"2021-07-16T18:31:40.134471Z","shell.execute_reply.started":"2021-07-16T18:31:40.121433Z","shell.execute_reply":"2021-07-16T18:31:40.132234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have 89 elements in our list. Let's see which information we have about the first of them. For this purporse we are using the method [get_info](https://blenderbim.org/docs/ifcopenshell-python/api-documentation.html#ifcopenshell.entity_instance.entity_instance.get_info) with the parameter `recursive=True`; this will parse the entity information as a dictionary and any IFC entity found inside will be parsed as a dictionnary too:","metadata":{}},{"cell_type":"code","source":"# We are selecting only the first element of our list \"elements\": elements[0]\nelement_info = elements[0].get_info(recursive=True)\nelement_info","metadata":{"execution":{"iopub.status.busy":"2021-07-16T18:31:40.136507Z","iopub.execute_input":"2021-07-16T18:31:40.137216Z","iopub.status.idle":"2021-07-16T18:31:40.411296Z","shell.execute_reply.started":"2021-07-16T18:31:40.137156Z","shell.execute_reply":"2021-07-16T18:31:40.410372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ok, we have a lot of information here! Let's choose some of them to build a dataset. We are getting the element id, the global id, the name and the description. Remember, this is a Python dictionary, you can acces any of the dictionary's key with:\n\n```\nmy_variable = my_dictionary[\"the_key_you_want_to_access\"]\n```","metadata":{}},{"cell_type":"code","source":"# We create the variables\nelement_type = element_info[\"type\"]\nelement_id = element_info[\"id\"]\nglobal_id = element_info[\"GlobalId\"]\nname = element_info[\"Name\"]\ndescription = element_info[\"Description\"]\n\n# And we print them\nprint(f\"This IfcBuildingElement is an {element_type} with the id {element_id}, the global id {global_id} and it's called {name}. Maybe we have a description? {description}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-16T18:33:24.631142Z","iopub.execute_input":"2021-07-16T18:33:24.631527Z","iopub.status.idle":"2021-07-16T18:33:24.638073Z","shell.execute_reply.started":"2021-07-16T18:33:24.631489Z","shell.execute_reply":"2021-07-16T18:33:24.637238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We don't have a description :( but that's not a problem, missing data is something we will encounter several times and we'll learn how to deal with it later.\n\nThese features we got are really easy to get, but what happens if we want a feature that is a little bit deeper in our dictionary? Let's try to find out the organization id. We have to check out the `OwnerHistory`:","metadata":{}},{"cell_type":"code","source":"element_info[\"OwnerHistory\"]","metadata":{"execution":{"iopub.status.busy":"2021-07-16T18:33:30.177705Z","iopub.execute_input":"2021-07-16T18:33:30.178211Z","iopub.status.idle":"2021-07-16T18:33:30.189918Z","shell.execute_reply.started":"2021-07-16T18:33:30.178166Z","shell.execute_reply":"2021-07-16T18:33:30.18871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Did you find it? We have to follow this path:\n\n```\nOwnerHistory > OwningUser > TheOrganization > id\n```\nLet's do it:","metadata":{}},{"cell_type":"code","source":"# Get the organization id\norganization_id = element_info[\"OwnerHistory\"][\"OwningUser\"][\"TheOrganization\"][\"id\"]\n# print it\nprint(f\"The organization id is {organization_id}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-16T18:33:38.793667Z","iopub.execute_input":"2021-07-16T18:33:38.794248Z","iopub.status.idle":"2021-07-16T18:33:38.800345Z","shell.execute_reply.started":"2021-07-16T18:33:38.794191Z","shell.execute_reply":"2021-07-16T18:33:38.799388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that we have all the features we wanted, we can create a Pandas DataFrame with them. One way to do it is from a dictionary, we should create one with the information we have:","metadata":{}},{"cell_type":"code","source":"# We create a dictionary\nelement_info_dictionary = {\"element_id\": element_id,\n                            \"global_id\": global_id,\n                            \"element_type\": element_type,\n                            \"name\": name,\n                            \"organization_id\": organization_id,\n                            \"description\": description}","metadata":{"execution":{"iopub.status.busy":"2021-07-16T18:34:02.173953Z","iopub.execute_input":"2021-07-16T18:34:02.17449Z","iopub.status.idle":"2021-07-16T18:34:02.180373Z","shell.execute_reply.started":"2021-07-16T18:34:02.174438Z","shell.execute_reply":"2021-07-16T18:34:02.179609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And now is super easy to create a pandas DataFrame:","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(element_info_dictionary, index=[0])","metadata":{"execution":{"iopub.status.busy":"2021-07-16T18:34:05.060858Z","iopub.execute_input":"2021-07-16T18:34:05.06142Z","iopub.status.idle":"2021-07-16T18:34:05.090811Z","shell.execute_reply.started":"2021-07-16T18:34:05.061358Z","shell.execute_reply":"2021-07-16T18:34:05.089722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Great! we have one row of our dataset! What if we want to add each of the 89 elements we obtained? We have to use a **for loop** that loops over our `elements` list and obtains each of the features we want. Sounds fancy, but is an easy task and a really useful tool. Make sure you read all the comment in the following code, it's explained step by step:","metadata":{}},{"cell_type":"code","source":"# Get all items of type \"IfcBuildingElement\"\nelements = file1.by_type('IfcBuildingElement')\n\n# Create an empty list to append each element\nelements_list = []\n\n# Loop over each of the elements in our list\nfor element in elements:\n    # get element info (this is a dictionary)\n    element_info = element.get_info(recursive=True)\n    \n    # Create desired variables, obtaining the value from the dictionary\n    element_id = element_info[\"id\"]\n    global_id = element_info[\"GlobalId\"]\n    element_type = element_info[\"type\"]\n    name = element_info[\"Name\"]\n    organization_id = element_info[\"OwnerHistory\"][\"OwningUser\"][\"TheOrganization\"][\"id\"]\n    description = element_info[\"Description\"]\n    \n    # Create dataframe (you can assign the index you want, we are going to ignore it later)\n    df = pd.DataFrame({\"element_id\": element_id,\n                        \"global_id\": global_id,\n                        \"element_type\": element_type,\n                        \"name\": name,\n                        \"organization_id\": organization_id,\n                        \"description\": description}, index=[0])\n    \n    # Append to the list created at the beginning of this code\n    elements_list.append(df)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T18:34:28.139107Z","iopub.execute_input":"2021-07-16T18:34:28.139691Z","iopub.status.idle":"2021-07-16T18:34:29.389296Z","shell.execute_reply.started":"2021-07-16T18:34:28.139637Z","shell.execute_reply":"2021-07-16T18:34:29.388517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And now is time to put it all togheter to create our dataset. We are going to use the Pandas method `concat`, you have to pass a list of dataframes as parameter (these are the dataframes you want to concat) and we are using `ignore_index=True` to reindex the final dataframe:","metadata":{}},{"cell_type":"code","source":"data1 = pd.concat(elements_list, ignore_index=True)\ndata1.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T18:34:30.122555Z","iopub.execute_input":"2021-07-16T18:34:30.123147Z","iopub.status.idle":"2021-07-16T18:34:30.18786Z","shell.execute_reply.started":"2021-07-16T18:34:30.123092Z","shell.execute_reply":"2021-07-16T18:34:30.186812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we have a dataset with all the `IfcBuildingElement`s present in file1! Would be nice to add some information about the building. Let's explore another ifc entity: ","metadata":{}},{"cell_type":"code","source":"buildings = file1.by_type(\"IfcBuilding\")\nbuildings","metadata":{"execution":{"iopub.status.busy":"2021-07-16T18:34:35.860425Z","iopub.execute_input":"2021-07-16T18:34:35.861023Z","iopub.status.idle":"2021-07-16T18:34:35.867197Z","shell.execute_reply.started":"2021-07-16T18:34:35.860985Z","shell.execute_reply":"2021-07-16T18:34:35.866243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have only one building described in this ifc file. Let's get the dictionary with all the information:","metadata":{}},{"cell_type":"code","source":"building_info = buildings[0].get_info(recursive=True)\nbuilding_info","metadata":{"execution":{"iopub.status.busy":"2021-07-16T18:34:37.839594Z","iopub.execute_input":"2021-07-16T18:34:37.840191Z","iopub.status.idle":"2021-07-16T18:34:37.852256Z","shell.execute_reply.started":"2021-07-16T18:34:37.840145Z","shell.execute_reply":"2021-07-16T18:34:37.851308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's add to our dataset the building name and id:","metadata":{}},{"cell_type":"code","source":"# First we get the variables we want\nbdg_name = building_info[\"Name\"]\nbdg_id = building_info[\"id\"]\n\n# And then we add them to our datatset\ndata1[\"bdg_name\"] = bdg_name\ndata1[\"bdg_id\"] = bdg_id\n\ndata1.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T18:34:41.233216Z","iopub.execute_input":"2021-07-16T18:34:41.233575Z","iopub.status.idle":"2021-07-16T18:34:41.253032Z","shell.execute_reply.started":"2021-07-16T18:34:41.233545Z","shell.execute_reply":"2021-07-16T18:34:41.25175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## File 2: *11134_V_Motebello_Heistopp_Rev.ifc*\nAnd now we want to perform the same process for file 2. Here we could copy and paste our previous code, but in cases like this when you want to perform the same process to different data, is really useful to write a function. We are going to create a function with the exact same code we used in the previous section all together in one function.","metadata":{}},{"cell_type":"code","source":"def create_IcfBuildingElement_dataframe(input_file):\n\n    elements = input_file.by_type('IfcBuildingElement')\n    building = input_file.by_type('IfcBuilding')[0] # here we are getting the first and only element of this list\n    \n    elements_list = []\n\n    for element in elements:\n        element_info = element.get_info(recursive=True)\n        building_info = building.get_info(recursive=True)\n\n        element_id = element_info[\"id\"]\n        global_id = element_info[\"GlobalId\"]\n        element_type = element_info[\"type\"]\n        name = element_info[\"Name\"]\n        organization_id = element_info[\"OwnerHistory\"][\"OwningUser\"][\"TheOrganization\"][\"id\"]\n        description = element_info[\"Description\"]\n        \n        bdg_id = building_info[\"id\"]\n        bdg_name = building_info[\"Name\"]\n\n        df = pd.DataFrame({\"element_id\": element_id,\n                            \"global_id\": global_id,\n                            \"element_type\": element_type,\n                            \"name\": name,\n                            \"organization_id\": organization_id,\n                            \"description\": description,\n                            \"bdg_id\": bdg_id,\n                            \"bdg_name\": bdg_name}, index=[0])\n\n        elements_list.append(df)\n    \n    data = pd.concat(elements_list, ignore_index=True)\n    \n    return data","metadata":{"execution":{"iopub.status.busy":"2021-07-16T18:34:54.679399Z","iopub.execute_input":"2021-07-16T18:34:54.679755Z","iopub.status.idle":"2021-07-16T18:34:54.691425Z","shell.execute_reply.started":"2021-07-16T18:34:54.679725Z","shell.execute_reply":"2021-07-16T18:34:54.690331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data2 = create_IcfBuildingElement_dataframe(file2)\ndata2.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T18:34:56.053426Z","iopub.execute_input":"2021-07-16T18:34:56.05394Z","iopub.status.idle":"2021-07-16T18:34:56.193088Z","shell.execute_reply.started":"2021-07-16T18:34:56.053905Z","shell.execute_reply":"2021-07-16T18:34:56.191729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Export dataset\nLast step is to concat the two datasets we recently created and export it.","metadata":{}},{"cell_type":"code","source":"ifc_parsed_data = pd.concat([data1, data2], ignore_index=True)\nifc_parsed_data","metadata":{"execution":{"iopub.status.busy":"2021-07-16T18:35:02.890392Z","iopub.execute_input":"2021-07-16T18:35:02.890957Z","iopub.status.idle":"2021-07-16T18:35:02.925386Z","shell.execute_reply.started":"2021-07-16T18:35:02.890905Z","shell.execute_reply":"2021-07-16T18:35:02.924104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And we export it with the pandas methos `to_csv`. We use the parameter `index=False` to omit the index column when saving. This will save the file in the directory `/kaggle/working/`.","metadata":{}},{"cell_type":"code","source":"ifc_parsed_data.to_csv(\"ifc_parsed_data.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T18:35:06.006185Z","iopub.execute_input":"2021-07-16T18:35:06.006549Z","iopub.status.idle":"2021-07-16T18:35:06.552773Z","shell.execute_reply.started":"2021-07-16T18:35:06.006518Z","shell.execute_reply":"2021-07-16T18:35:06.551789Z"},"trusted":true},"execution_count":null,"outputs":[]}]}