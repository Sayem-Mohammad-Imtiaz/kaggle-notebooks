{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Importing the relevant libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load the CSV data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"raw_csv_data = pd.read_csv('/kaggle/input/employee-absenteeism-prediction/Absenteeism-data.csv')\nraw_csv_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Preprocessing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Copying the content of initial dataframe to a new one","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = raw_csv_data.copy()\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Following code is for displaying all the rows and columns in the dataframe, despite of how large they are","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_columns=None\npd.options.display.max_rows=None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Getting the information about the dataframe","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop ID column from the dataframe as it is of no use for prediction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['ID'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Displaying the head of the dataframe","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exploration of Reason for Absence column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Maximum value in 'Reason for Absence' column\ndf['Reason for Absence'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Minimum value in 'Reason for Absence' column\ndf['Reason for Absence'].min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Unique values in 'Reason for Absence' column\ndf['Reason for Absence'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# length of unique values in 'Reason for Absence' column\nlen(df['Reason for Absence'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"However wait didn't we already find out that minimum value contained in this column is zero while the\nlargest one is 28. This makes up to 29 different values while using the len function instead we just obtained twenty eight.This has to say one thing and one thing only a number between 0 and 28 is missing.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted(df['Reason for Absence'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can spot that the value we lack is number 20.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"But wait which are the twenty eight reasons we have substituted with numbers. In other words reason one stands for a certain reason for absence as much as reason to stands for another. You may know from statistics that these variables are categorical nominal nominal because instead of using the numbers from 0 to 28 we could have had names disease dentist pregnancy etc..However using numbers is the convention for working with categorical nominal data ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Converting to dummies","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create dummy for 'Reason for Absence' column\nreason_columns = pd.get_dummies(df['Reason for Absence'], drop_first=True)\nreason_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check whether any missing value is there or not\nreason_columns['check'] = reason_columns.sum(axis=1)\nreason_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reason_columns['check'].sum(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Which is the length of dataframe, so there is no missing values in 'Reason for Absence' column\n\nAnd thus, the validity of reason columns has been checked and we are satisfied with its state.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# So, we'll be dropping the check column from reason_columns\nreason_columns = reason_columns.drop(['check'], axis=1)\nreason_columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Group the Reason for Absence column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reason_columns.columns.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop 'Reason for Absence' column to avoid multi-collinearity\ndf = df.drop(['Reason for Absence'], axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Group the variables from 'Reason for Absence' column\nreason_type_1 = reason_columns.iloc[:, 1:14].max(axis=1)\nreason_type_2 = reason_columns.iloc[:, 15:17].max(axis=1)\nreason_type_3 = reason_columns.iloc[:, 18:21].max(axis=1)\nreason_type_4 = reason_columns.iloc[:, 22:].max(axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Concatenate column values from reason_columns to df","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([df, reason_type_1, reason_type_2, reason_type_3, reason_type_4], axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Rename the above four concatenated columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"column_names = ['Date', 'Transportation Expense', 'Distance to Work', 'Age',\n       'Daily Work Load Average', 'Body Mass Index', 'Education',\n       'Children', 'Pets', 'Absenteeism Time in Hours', 'Reason_1', 'Reason_2', 'Reason_3', 'Reason_4']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns = column_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reorder columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"column_names_reordered = ['Reason_1', 'Reason_2', 'Reason_3', 'Reason_4', 'Date', 'Transportation Expense', 'Distance to Work', 'Age',\n       'Daily Work Load Average', 'Body Mass Index', 'Education',\n       'Children', 'Pets', 'Absenteeism Time in Hours']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[column_names_reordered]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create a Checkpoint (Creating checkpoint refers to storing the current version of once code)\n\n(Create a copy of the current state of your dataframe)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reason_mod = df.copy()\ndf_reason_mod.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exploration of 'Date' column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"type(df_reason_mod['Date'][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting the Date column to timestamp format\ndf_reason_mod['Date'] = pd.to_datetime(df_reason_mod['Date'], format='%d/%m/%Y')\ndf_reason_mod['Date'].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Extract the Month value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reason_mod['Date'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reason_mod['Date'][0].month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_months = []\nlist_months","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_reason_mod)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reason_mod.loc[:, 'Date'][0].month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range (len(df_reason_mod)):\n    list_months.append(df_reason_mod.loc[:, 'Date'][i].month)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_months","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(list_months)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reason_mod['Month Value'] = list_months\ndf_reason_mod.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Extract the Day of the Week","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reason_mod.loc[:, 'Date'][0].weekday()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_days = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def date_to_weekday(date_value):\n    return (date_value.weekday())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reason_mod['Day of the Week'] = df_reason_mod['Date'].apply(date_to_weekday)\ndf_reason_mod.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping Date column from dataframe to avoid multicollinearity\ndf_reason_mod = df_reason_mod.drop(['Date'], axis=1)\ndf_reason_mod.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reorder the columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reason_mod.columns.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"column_names_reordered = ['Reason_1', 'Reason_2', 'Reason_3', 'Reason_4',\n                          'Month Value', 'Day of the Week',\n                           'Transportation Expense', 'Distance to Work', 'Age',\n                           'Daily Work Load Average', 'Body Mass Index', 'Education',\n                           'Children', 'Pets', 'Absenteeism Time in Hours']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reason_mod = df_reason_mod[column_names_reordered]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reason_mod.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create a Checkpoint","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reason_date_mod = df_reason_mod.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reason_date_mod.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exploring other variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"type(df_reason_date_mod['Transportation Expense'][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(df_reason_date_mod['Distance to Work'][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(df_reason_date_mod['Age'][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(df_reason_date_mod['Daily Work Load Average'][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(df_reason_date_mod['Body Mass Index'][0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exploring 'Education', 'Children', 'Pets' columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reason_date_mod['Education'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reason_date_mod['Education'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reason_date_mod['Education'] = df_reason_date_mod['Education'].map({1:0, 2:1, 3:1, 4:1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reason_date_mod['Education'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reason_date_mod['Education'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Final Checkpoint","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preprocessed = df_reason_date_mod.copy()\ndf_preprocessed.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Saving the preprocessed CSV file\ndf_preprocessed.to_csv('Absenteeism_preprocessed.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Create a logistic regression model to predict Absenteeism","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Load the preprocessed data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_preprocessed = pd.read_csv('Absenteeism_preprocessed.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_preprocessed.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create the targets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_preprocessed['Absenteeism Time in Hours'].median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targets = np.where(data_preprocessed['Absenteeism Time in Hours'] > \n                   data_preprocessed['Absenteeism Time in Hours'].median(),\n                   1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_preprocessed['Excessive Absenteeism'] = targets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_preprocessed.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A comment on the targets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"targets.sum() / targets.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop 'Absenteeism Time in Hours' column\ndata_with_targets = data_preprocessed.drop(['Absenteeism Time in Hours', \n                                            'Daily Work Load Average', \n                                            'Education', \n                                            'Reason_4', \n                                            'Distance to Work'], \n                                             axis=1)\ndata_with_targets.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking whether the following two dataframes are same or different\ndata_with_targets is data_preprocessed","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Select the inputs for the regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_with_targets.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_with_targets.iloc[:, :14]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_with_targets.iloc[:, :-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unscaled_inputs = data_with_targets.iloc[:, :-1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Standardize the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.preprocessing import StandardScaler\n# absenteeism_scaler = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import the libraries needed to create the Custom Scaler\n# note that all of them are a part of the sklearn package\n# moreover, one of them is actually the StandardScaler module, \n# so you can imagine that the Custom Scaler is build on it\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import StandardScaler\n\n# create the Custom Scaler class\n\nclass CustomScaler(BaseEstimator,TransformerMixin): \n    \n    # init or what information we need to declare a CustomScaler object\n    # and what is calculated/declared as we do\n    \n    def __init__(self,columns,copy=True,with_mean=True,with_std=True):\n        \n        # scaler is nothing but a Standard Scaler object\n        self.scaler = StandardScaler(copy,with_mean,with_std)\n        # with some columns 'twist'\n        self.columns = columns\n        self.mean_ = None\n        self.var_ = None\n        \n    \n    # the fit method, which, again based on StandardScale\n    \n    def fit(self, X, y=None):\n        self.scaler.fit(X[self.columns], y)\n        self.mean_ = np.mean(X[self.columns])\n        self.var_ = np.var(X[self.columns])\n        return self\n    \n    # the transform method which does the actual scaling\n\n    def transform(self, X, y=None, copy=None):\n        \n        # record the initial order of the columns\n        init_col_order = X.columns\n        \n        # scale all features that you chose when creating the instance of the class\n        X_scaled = pd.DataFrame(self.scaler.transform(X[self.columns]), columns=self.columns)\n        \n        # declare a variable containing all information that was not scaled\n        X_not_scaled = X.loc[:,~X.columns.isin(self.columns)]\n        \n        # return a data frame which contains all scaled features and all 'not scaled' features\n        # use the original order (that you recorded in the beginning)\n        return pd.concat([X_not_scaled, X_scaled], axis=1)[init_col_order]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unscaled_inputs.columns.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# columns_to_scale = ['Month Value','Day of the Week', 'Transportation Expense', \n#                     'Distance to Work','Age', 'Daily Work Load Average', 'Body Mass Index', \n#                     'Children', 'Pets']\n\ncolumns_to_omit = ['Reason_1', 'Reason_2', 'Reason_3', 'Reason_4', 'Education']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_to_scale = [x for x in unscaled_inputs.columns.values if x not in columns_to_omit]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"absenteeism_scaler = CustomScaler(columns_to_scale)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"absenteeism_scaler.fit(unscaled_inputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_inputs = absenteeism_scaler.transform(unscaled_inputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_inputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_inputs.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split the data into train and test and shuffle","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split\nx_train, x_test, y_train, y_test = train_test_split(scaled_inputs, targets, train_size=0.8, random_state=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train.shape, y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_test.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logistic Regression with Sklearn","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"reg = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg.score(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Manually check the accuracy","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_outputs = reg.predict(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_outputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sum(model_outputs == y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_outputs.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sum(model_outputs == y_train) / model_outputs.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Finding the intercept and coefficients","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding the intercept\nreg.intercept_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding the coefficient\nreg.coef_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding the column names in unscaled dataframe\nunscaled_inputs.columns.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_name = unscaled_inputs.columns.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating summary table to store different attributes and their corresponding values\nsummary_table = pd.DataFrame(columns=['Feature Name'], data=feature_name)\nsummary_table['Coefficients'] = np.transpose(reg.coef_)\nsummary_table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inserting the value of intercept in the summary table\nsummary_table.index = summary_table.index + 1\nsummary_table.loc[0] = ['Intercept', reg.intercept_[0]]\nsummary_table = summary_table.sort_index()\nsummary_table","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Interpreting the coefficients","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"summary_table['Odds_Ratio'] = np.exp(summary_table['Coefficients'])\nsummary_table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summary_table.sort_values('Odds_Ratio', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Testing the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"reg.score(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_proba = reg.predict_proba(x_test)\npredicted_proba","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_proba[:, 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Save the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pickle the model file\nwith open('model', 'wb') as file:\n    pickle.dump(reg, file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pickle the scaler file\nwith open('scaler', 'wb') as file:\n    pickle.dump(absenteeism_scaler, file)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}