{"cells":[{"metadata":{},"cell_type":"markdown","source":"Hello there! In this notebook we are going to build a Decision Tree Classifier and see what criteria are important to get victorious in a League of Legends ranked match!\n\nWhat will we do?:\n\n* Build a Decision Tree Classifier to predict match result according to some criterias\n* Try to understand how important is this criterias to win a ranked match.\n\nSo, here we go! Enjoy!\n\n# The Firsts\n\nOur dataset has some columns informating \"the firts\": FirstBlood, FirstTower, firstInhibitor, firstBaron, firstDragon, firstRiftHerald. I'm curious about this data and I want to see if it is possible predict a match result and how accurate are the prediction using this set of informations.\nI will use the files: match_winner_data_version1.csv and match_loser_data_version1.csv to perform the analysis.\nLet's code!\n\n**First things first: Importing some modules and loading the data**\n\nPlease, note the function clean_data(). We will use it to delete rows with NaN/null values in the next steps.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn import tree\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport graphviz\nimport numpy as np\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nwinner_data = pd.read_csv(\"../input/league-of-legendslol-ranked-games-2020-ver1/match_winner_data_version1.csv\")\nloser_data = pd.read_csv(\"../input/league-of-legendslol-ranked-games-2020-ver1/match_loser_data_version1.csv\")\n\ndef clean_data(data):\n    #Eliminating rows with NaN and null values\n    if data.isnull().values.any():\n        data.dropna(subset = [\"win\", \"firstBlood\", \"firstTower\", \"firstInhibitor\",\n        \"firstBaron\", \"firstDragon\", \"firstRiftHerald\"], inplace=True)    \n    return data\n\nif (winner_data.empty or loser_data.empty):\n    print(\"Problem reading files! Please check files path!\")\nelse:\n    print(\"Files read successfully!\")\n    print(\"Winner dataset shape: \", winner_data.shape)\n    print(\"Loser dataset shape: \", loser_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"So, we loaded the data! Now it's time to make some preparing and cleaning.\n\nFirst I will replace the win and fail values with True and False in \"win\" column and after I will take just the columns I have interest: The firsts columns and the win column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Replace \"Win\" and \"Fail\" with True and False\nwinner_data[\"win\"].replace({\"Win\": True}, inplace=True)\nloser_data[\"win\"].replace({\"Fail\": False}, inplace=True)\n\n#Separate training set\nwinner_training_data = winner_data.iloc[0:50000, 2:9] #I'm taking just a part of dataset to train our model\nloser_training_data = loser_data.iloc[0:50000, 2:9]\n\n#Separate test dataset\nwinner_test_data = winner_data.iloc[50000:108828, 2:9]\nloser_test_data = loser_data.iloc[50000:108828, 2:9]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now it's time to clean! I will remove all rows that has NaN/null values. For this, I created a function and you already know that function! It's time to use clean_data().","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Clean training data\nwinner_training_data = clean_data( winner_training_data)\nloser_training_data = clean_data(loser_training_data)\n\n#Clean test set\nwinner_test_data = clean_data(winner_test_data)\nloser_test_data = clean_data(loser_test_data)\n\n#Make sure the loser dataset column win is bool\nloser_training_data['win'] = loser_training_data['win'].astype('bool')\nloser_test_data['win'] = loser_test_data['win'].astype('bool')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's prepare the test data and the variables to run fit() method. First we need to concatenate winner and loser training and test datasets.\n\nWe want to predict the match result (Victory or Defeat) through a decision tree classifier. Thus, \"win\" column is the dependent variable and the other columns are the independent variables.\n\nY => \"win\" column\n\nX => FirstBlood, FirstTower, firstInhibitor, firstBaron, firstDragon and firstRiftHerald columns.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#preparing test data\ntest_data = pd.concat([winner_test_data.iloc[:, 1:7], loser_test_data.iloc[:, 1:7]], ignore_index=True)\ntest_set_labels = pd.concat([winner_test_data[\"win\"], loser_test_data[\"win\"]], ignore_index=True)\n\n#Preparing training data and define the dependent and independent variables\n#Defining dependent variable\nY = pd.concat([winner_training_data[\"win\"], loser_training_data[\"win\"]], ignore_index=True)\n\n#Defining independent variable\nX = pd.concat([winner_training_data.iloc[:, 1:7], loser_training_data.iloc[:, 1:7]], ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now it's time to fit our model and calculate the accuracy the our decision tree can achieve:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = tree.DecisionTreeClassifier(criterion=\"entropy\")\nclf = clf.fit(X, Y)\n\nnew_matches_test = clf.predict(test_data)\nacc = accuracy_score(test_set_labels, new_matches_test)\n\nprint('Accuracy Score: ', acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy score calculated means that our model has predicted 84,36% correctly. I can say that this is a \"ok\" model accuracy.\n\nOne of the biggest advantages of decision trees is that we can visualize them! And for that, just use the export_graphviz method","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"my_tree = tree.export_graphviz(clf, out_file=None, \n                              feature_names= [\"firstBlood\", \"firstTower\", \"firstInhibitor\",\n                                              \"firstBaron\", \"firstDragon\", \"firstRiftHerald\"],  \n                              class_names=[\"Win\", \"Lose\"],  \n                              filled=True, rounded=True,  \n                              special_characters=True)\n\ngraph = graphviz.Source(my_tree)\ngraph.render(\"LoLDecisionTree\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The next step is to make an analysis of the tree to make sure it make sense! I'll let this for next notebooks!\n\nIf this notebook was somehow helpful to you, upvote!\n\nFeel free to tell me if I made a mistake or where I can improve this little job!\n\nTill next notebook!","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}