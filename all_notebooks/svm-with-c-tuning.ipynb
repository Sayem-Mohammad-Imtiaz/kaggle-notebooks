{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#importing libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing the dataset\n\ndf = pd.read_csv(\"../input/pima-indians-diabetes-database/diabetes.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Knowing my dataset**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Analysis**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training & testing\n\n**We will be using SVM and will tune C parameter as much as possible.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(['Outcome'], axis=1)\ny = df['Outcome']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train test split\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,\n                                               test_size=0.31,random_state=30)\n\nprint('train size is %i'%y_train.shape[0])\nprint('test size is %i'%y_test.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#getting the accuracy rate initially\n\nsvm = SVC()\nsvm.fit(X_train,y_train)\n\n\ny_pred1=svm.predict(X_test)\naccuracy_score(y_pred1,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Initially we are getting 79.5% accuracy on my testing data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Testing Classification Report: \\n\", classification_report(y_test,y_pred1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let us better tune our hyper-parameters to get a better accuracy**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"*With rbf kernel and C tuning*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train=[]\ntest=[]\n\nfor i in np.arange(1.0,20.0,0.3):\n    svm=SVC(kernel='rbf',C=i)\n    svm.fit(X_train,y_train)\n    y_pred1=svm.predict(X_train)\n    y_pred2=svm.predict(X_test)\n    train.append(accuracy_score(y_pred1,y_train))\n    test.append(accuracy_score(y_pred2,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#getting the C value where the accuracy is max\n\nprint(\"Maximum accuracy is at :\",max(test)*100,\"% where c value is = \",np.argmax(test))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We are getting an accuracy of 80% with rbf kernel with C tuned at 15**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"*With poly kernel and C tuning*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train=[]\ntest=[]\n\nfor i in np.arange(1.0,20.0,0.3):\n    svm=SVC(kernel='poly',C=i)\n    svm.fit(X_train,y_train)\n    y_pred1=svm.predict(X_train)\n    y_pred2=svm.predict(X_test)\n    train.append(accuracy_score(y_pred1,y_train))\n    test.append(accuracy_score(y_pred2,y_test))\n    \n#getting the C value where the accuracy is max\n\nprint(\"Maximum accuracy is at :\",max(test)*100,\"% where c value is = \",np.argmax(test))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**With poly kernel we are getting an accuracy of 83% with C tuned at 4**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"*With sigmoid kernel and C tuning*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train=[]\ntest=[]\n\nfor i in np.arange(1.0,20.0,0.3):\n    svm=SVC(kernel='sigmoid',C=i)\n    svm.fit(X_train,y_train)\n    y_pred1=svm.predict(X_train)\n    y_pred2=svm.predict(X_test)\n    train.append(accuracy_score(y_pred1,y_train))\n    test.append(accuracy_score(y_pred2,y_test))\n    \n#getting the C value where the accuracy is max\n\nprint(\"Maximum accuracy is at :\",max(test)*100,\"% where c value is = \",np.argmax(test))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Getting a very poor accuracy with sigmoid kernel**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**For getting a better accuracy we can also tune hyper-parameters with grid search / random search/k folds.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Thus to conclude, we got the best accuracy of 83% while using \"**POLY**\" kernel when the C parameter is working at 4.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}