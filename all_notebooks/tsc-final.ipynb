{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sb\n\n%matplotlib inline\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# Loading the data"},{"metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"trusted":true,"_uuid":"8df2fac6c363e4813999dea7cf9aaed6ebc6a4fb"},"cell_type":"code","source":"data = pd.read_csv('../input/AirQualityUCI_req.csv')\ndata.index = pd.DatetimeIndex(data.Date, dayfirst=True).strftime('%Y-%m-%d')\ndata = data.drop(['Date' ], 1)\ncols = data.columns\ndata = data[data[cols] > 0]\ndata = data.fillna(method='ffill')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c9b37e7c36247c689b909184a953edcd70b9bd7"},"cell_type":"markdown","source":"# Getting the temperature values."},{"metadata":{"_kg_hide-output":true,"trusted":true,"_uuid":"d1e2e7e04e8549e04f65911d65e1e2bbf30489c0"},"cell_type":"code","source":"temperature = data[['T']]\ntemperature_by_day = temperature.groupby(temperature.index).mean()\nt_values = temperature_by_day.values\nt_values = t_values.reshape(-1)\nlen(t_values)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0934f4e3b4045d4e3ffefede9c1db4d26afbe6be"},"cell_type":"markdown","source":"> **Coining Time series problem as a classification problem**\n\n- We try to predict the trend of the data based on the values. We only predict the direction of temperature based on the history of data points.\n- We convert the dataset to classes as 1 for upward trend and 0 for downward trend.\n- We can select the window of the data that is chosen. Tuning the window size changes the length of history that is considered as features."},{"metadata":{"trusted":true,"_uuid":"5512659197d4968c0489dddad529dda643fc9fd8"},"cell_type":"code","source":"def make_data(data_array, window=7):\n    col = ['t'+str(i) for i in range(window)]\n    col.append('Class')\n    dict_data = {}\n    count = 0\n    inc_count = 0\n    dec_count = 0\n    for i in range(len(data_array)-window):\n        if data_array[i+window] >= data_array[i+window-1]:\n            temp_class = int(1)\n            inc_count += 1\n        else:\n            temp_class = int(0)\n            dec_count += 1\n        #print(temp_class)\n        count = count + 1\n        temp_data = data_array[i:i+window]\n        temp_row = np.concatenate((temp_data, temp_class), axis=None)\n        dict_data[i] = temp_row\n    #print(data)\n    print(count, inc_count, dec_count)\n    dataframe = pd.DataFrame.from_dict(dict_data,orient='index', columns=col)\n    return dataframe, col[:len(col)-1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ebd5e1b8d837c2d6fc66e023c6d6d6f1273bba98"},"cell_type":"code","source":"transformed_data, feature_cols = make_data(t_values)\ntransformed_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"62a8c534308650026de9f15f48bb3db54dc52831"},"cell_type":"markdown","source":"> ** Using this dataframe to create features and classes.**"},{"metadata":{"trusted":true,"_uuid":"7ebeb8bb284ece36dd1d3f36628b74fedebd92fe"},"cell_type":"code","source":"features = transformed_data[feature_cols].values\nclasses = transformed_data[['Class']].values\nprint(features.shape, classes.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"839f6b7fdca03bb22d3f7d28fc4e0f22b4cc3a2f"},"cell_type":"markdown","source":"> This notebook approaches the problem in two ways :\n- Without Dimensionality Reduction\n- With Dimensionality Reduction\n\nWe compare different classifiers in each approach."},{"metadata":{"_uuid":"586d9bfffb4a0be5f31624b15522b7e03d36abee"},"cell_type":"markdown","source":"**Wihtout Dimensionality Reduction**"},{"metadata":{"trusted":true,"_uuid":"5a07db8365ce3eec754fa057dbd314e429f6ef8f"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport itertools","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"_uuid":"b633256fe9ae187309318b4bbf46572770d63187"},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(features,classes, test_size=0.33, random_state=42)\nY_train = Y_train.reshape(-1)\nY_test = Y_test.reshape(-1)\nprint(X_train.shape, Y_train.shape)\nprint(X_test.shape, Y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"762fe9b960e2e1e2be083e9cb80a9c3e0cb0006f"},"cell_type":"markdown","source":"> Logistic Regression"},{"metadata":{"trusted":true,"_uuid":"8912ecd64f1fe5234f6351bc096a141b9a6766a0"},"cell_type":"code","source":"model = LogisticRegression(solver='liblinear')\nmodel.fit(X_train, Y_train)\n\ny_pred = model.predict(X_test)\ncm_lr = confusion_matrix(Y_test, y_pred)\nacc_lr = accuracy_score(Y_test, y_pred)\nprint(\"Accuracy of classification : {0} %\".format(acc_lr*100))\nprint(cm_lr)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"81ad02ac35990496605e7301e4900302fcc2eb06"},"cell_type":"markdown","source":">  Multi Layer Perceptron"},{"metadata":{"trusted":true,"_uuid":"d5ab54424611e4928c882a9b42108d4c43d9ff7d"},"cell_type":"code","source":"model = MLPClassifier(hidden_layer_sizes=(90), learning_rate='constant')\nmodel.fit(X_train, Y_train)\n\ny_pred = model.predict(X_test)\ncm_mlp = confusion_matrix(Y_test, y_pred)\nacc_mlp = accuracy_score(Y_test, y_pred)\nprint(\"Accuracy of classification : {0} %\".format(acc_mlp*100))\nprint(cm_mlp)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff74bd056b25630b0cfe20761c99ca9e6b984851"},"cell_type":"markdown","source":"> Naive Bayes Classifier"},{"metadata":{"trusted":true,"_uuid":"6e4e9857febe2bff706853b3934260f0344ab638"},"cell_type":"code","source":"NB_model = GaussianNB()\nNB_model.fit(X_train, Y_train)\n\ny_pred = NB_model.predict(X_test)\nacc_nb = accuracy_score(Y_test, y_pred)\ncm_nb = confusion_matrix(Y_test, y_pred)\nprint(\"Accuracy of classification : {0} %\".format(acc_nb*100))\nprint(cm_nb)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4f27058f439c1a61e2d89f34fb52f3de394563e2"},"cell_type":"markdown","source":"> Decision Tree Classifier"},{"metadata":{"trusted":true,"_uuid":"2031387ee2a7a16da493bf9de4d0d21f3e6a7943"},"cell_type":"code","source":"DT_model = DecisionTreeClassifier()\nDT_model.fit(X_train,Y_train)\n\ny_pred = DT_model.predict(X_test)\nacc_dt = accuracy_score(Y_test, y_pred)\ncm_dt = confusion_matrix(Y_test, y_pred)\nprint(\"Accuracy of classification : {0} %\".format(acc_dt*100))\nprint(cm_dt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad024de2d73414cc4a9dd06b14c4be4a228a9b0b"},"cell_type":"code","source":"sb.barplot(x=[acc_lr,acc_mlp,acc_nb,acc_nb],y=['Logistic Regression', 'MLP', 'Naive Bayes', 'Decision Tree'])\nplt.title('Without Dimensionality Reduction')\nplt.xlabel('Accuracy in %')\nplt.ylabel('Classifiers')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"13ac5d653991f7c4c7daecc2853acd9843c32ff2"},"cell_type":"markdown","source":"**With Dimensionality Reduction**"},{"metadata":{"_uuid":"221c29cf36bd434132d09b3729b06133db1ca5b5"},"cell_type":"markdown","source":"> We can use two types of Embedding techniques:\n-  t-SNE\n- Multi Dimensional Spacing"},{"metadata":{"trusted":true,"_uuid":"29b0cf3c21f3bb6a3847a10dc3b8538b0815ed1b"},"cell_type":"code","source":"from sklearn.manifold import TSNE, MDS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e8fa5fab838090f9c4da0e4436c71586456a5aba"},"cell_type":"code","source":"features_embedded_tsne = TSNE(n_components=2).fit_transform(features)\nplt.scatter(features_embedded_tsne[:,0], features_embedded_tsne[:,1],c=classes.reshape(-1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2fa157bc669dcc3f153e12043af45d659ab7fdfd"},"cell_type":"code","source":"features_embedded_mds = MDS(n_components=2).fit_transform(features)\nplt.scatter(features_embedded_mds[:,0], features_embedded_mds[:,1],c=classes.reshape(-1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"be005f9c54b1e0cb8bfd7b7eefd39b959334e747"},"cell_type":"markdown","source":"We will use MDS embedding for classification due to the distribution of the data across x and y axes."},{"metadata":{"trusted":true,"_uuid":"39bfd2e6f208693906f682ec49d38934dc55d39f"},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(features_embedded_mds,classes, test_size=0.33, random_state=42)\nY_train = Y_train.reshape(-1)\nY_test = Y_test.reshape(-1)\nprint(X_train.shape, Y_train.shape)\nprint(X_test.shape, Y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a05728e392a408282d87ec6ac29f8e6dc1551620"},"cell_type":"markdown","source":"> Logistic Regression"},{"metadata":{"trusted":true,"_uuid":"c4631035cf214d4ce3e2631d6780412c23899255"},"cell_type":"code","source":"LRmodel = LogisticRegression(solver='liblinear')\nLRmodel.fit(X_train,Y_train)\ny_pred = LRmodel.predict(X_test)\ncm_lr1 = confusion_matrix(Y_test, y_pred)\nacc_lr1 = accuracy_score(Y_test, y_pred)\nprint(\"Accuracy of classification : {0} %\".format(acc_lr1*100))\nprint(cm_lr1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8ce5a5248d41ea8a364d7ad11a6d9d072b1b535b"},"cell_type":"markdown","source":"> Multi Layer Perceptron"},{"metadata":{"trusted":true,"_uuid":"9509c791104e4836c34872faeb8c86ebd7c524e2"},"cell_type":"code","source":"MLPmodel = MLPClassifier(hidden_layer_sizes=(90), learning_rate='constant')\nMLPmodel.fit(X_train, Y_train)\ny_pred = MLPmodel.predict(X_test)\ncm_mlp1 = confusion_matrix(Y_test, y_pred)\nacc_mlp1 = accuracy_score(Y_test, y_pred)\nprint(\"Accuracy of classification : {0} %\".format(acc_mlp1*100))\nprint(cm_mlp1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ad00c3ce2b5dbee16fff39dc933f7dc885525f0"},"cell_type":"markdown","source":"> Naive Bayes Classifier"},{"metadata":{"trusted":true,"_uuid":"14bc32fcff720c63e59db50227d9f87fe9ddc38e"},"cell_type":"code","source":"NB_model = GaussianNB()\nNB_model.fit(X_train, Y_train)\n\ny_pred = NB_model.predict(X_test)\nacc_nb1 = accuracy_score(Y_test, y_pred)\ncm_nb1 = confusion_matrix(Y_test, y_pred)\nprint(\"Accuracy of classification : {0} %\".format(acc_nb1*100))\nprint(cm_nb1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d05807546ed7bd766925793d5135c9202262952b"},"cell_type":"markdown","source":"> Decision Tree Classifier"},{"metadata":{"trusted":true,"_uuid":"a72af12948d2f754f477703d869e293be6ec8d6b"},"cell_type":"code","source":"DT_model = DecisionTreeClassifier()\nDT_model.fit(X_train,Y_train)\n\ny_pred = DT_model.predict(X_test)\nacc_dt1 = accuracy_score(Y_test, y_pred)\ncm_dt1 = confusion_matrix(Y_test, y_pred)\nprint(\"Accuracy of classification : {0} %\".format(acc_dt1*100))\nprint(cm_dt1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b60d2591c1f9e5be38e5bb579a57454a5b0b5146"},"cell_type":"markdown","source":"> Comparing the models "},{"metadata":{"trusted":true,"_uuid":"35d655350b343731454e3b50a5acd343b2f544a0"},"cell_type":"code","source":"sb.barplot(x=[acc_lr1,acc_mlp1, acc_nb1, acc_nb1], y= ['Logistic Regression', 'MLP', 'Naive Bayes', 'Decision Tree'])\nplt.title('With Dimensionality Reduction')\nplt.xlabel('Accuracy in %')\nplt.ylabel('Classifiers')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c9af63a10eac665f361e94088eb452a796aab5a"},"cell_type":"markdown","source":"> Comapring each model with and without Dimensionality reduction"},{"metadata":{"trusted":true,"_uuid":"bed389f53b0648092c4e17664c621a4a3d90027e"},"cell_type":"code","source":"plt.figure(figsize=(20,5))\nplt.subplot(1,5,1)\nsb.barplot(x=['With MDS', 'Without MDS'], y = [acc_lr1,acc_lr])\nplt.title('Logistic Regression')\n\nplt.subplot(1,5,2)\nsb.barplot(x=['With MDS', 'Without MDS'], y = [acc_mlp1,acc_mlp])\nplt.title('MLP')\n\nplt.subplot(1,5,3)\nsb.barplot(x=['With MDS', 'Without MDS'], y = [acc_nb1,acc_nb])\nplt.title('Naive Bayes')\n\nplt.subplot(1,5,4)\nsb.barplot(x=['With MDS', 'Without MDS'], y = [acc_dt1, acc_dt])\nplt.title('Decision Tree')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61bc1c187a6bb5576016202672fc9076d91deda1"},"cell_type":"markdown","source":"> From the above plots, it is clear that the dimensionality reduction has very little impact on the classification.\n- Moreover, the classifiers are performing worse than a random guess of the trend. This is becuase of the availability of limited data.\n- Further, this approach can be tested with more amount of the data to get better results."},{"metadata":{"_uuid":"7314cea81d04203d267fa369f5091909230fc30f"},"cell_type":"markdown","source":"*All values in the plots provided are averaged over various runs of the classifiers.*"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}