{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-25T09:36:31.756746Z","iopub.execute_input":"2021-05-25T09:36:31.757432Z","iopub.status.idle":"2021-05-25T09:36:31.810794Z","shell.execute_reply.started":"2021-05-25T09:36:31.757387Z","shell.execute_reply":"2021-05-25T09:36:31.809962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport time\nimport gc\nfrom pathlib import Path\n\nimport os\nimport os.path\nimport glob\nimport cv2\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras import Sequential, Input, initializers, optimizers, callbacks\nfrom tensorflow.keras.layers import BatchNormalization, Dense, Dropout, Flatten, ReLU, PReLU\nfrom tensorflow.keras.metrics import AUC\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.utils import to_categorical\n\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D,Flatten, GlobalAveragePooling2D, Activation\nfrom tensorflow.keras.layers import AveragePooling2D, GlobalMaxPooling2D, Lambda\nfrom tensorflow.keras.optimizers import Nadam, Adam\n\nseed = 47","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:36:31.812353Z","iopub.execute_input":"2021-05-25T09:36:31.812686Z","iopub.status.idle":"2021-05-25T09:36:31.820909Z","shell.execute_reply.started":"2021-05-25T09:36:31.812648Z","shell.execute_reply":"2021-05-25T09:36:31.819882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\n\ndata = pd.read_csv('/kaggle/input/clothing-dataset-full/images.csv')\ndata.loc[data['label']=='Not sure','label'] = 'Not_sure'\n#data['image'] = data['image'] + '.jpg'\n\nlabels=data['label']\nfeatures=data.drop('label',1)\n\nlabels_values=labels.value_counts()\nprint(labels_values)\n\n# data['label_cat'] = data['label'] + ' ' + data['kids'].astype(str)\n# proc_data=data[['image', 'label_cat']]\n# print(type(proc_data))\n\np= sns.countplot(data=data['image'], x=data['label'])","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:36:31.823298Z","iopub.execute_input":"2021-05-25T09:36:31.82385Z","iopub.status.idle":"2021-05-25T09:36:32.06709Z","shell.execute_reply.started":"2021-05-25T09:36:31.823746Z","shell.execute_reply":"2021-05-25T09:36:32.066304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_y=data.label\nlabels_num1=labels_y[:1000]\nlabels_num1","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:36:32.068814Z","iopub.execute_input":"2021-05-25T09:36:32.069164Z","iopub.status.idle":"2021-05-25T09:36:32.077001Z","shell.execute_reply.started":"2021-05-25T09:36:32.069112Z","shell.execute_reply":"2021-05-25T09:36:32.075967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_unique=labels_num1.unique()\nprint(labels_unique.shape)\n# data.loc[(data.label) & (data.image == '4285fab0-751a-4b74-8e9b-43af05deee22')]","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:36:32.078553Z","iopub.execute_input":"2021-05-25T09:36:32.07894Z","iopub.status.idle":"2021-05-25T09:36:32.087121Z","shell.execute_reply.started":"2021-05-25T09:36:32.078902Z","shell.execute_reply":"2021-05-25T09:36:32.08621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# foods = list(os.walk('../input/food41/images/'))[0][1]\nnr_foods = 20\nlabels_values=list(labels_values)\n\nidx_to_name = {i:x for (i,x) in enumerate(labels_unique[:nr_foods])}\nname_to_idx = {x:i for (i,x) in enumerate(labels_unique[:nr_foods])}\n\nidx_to_name","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:36:32.08875Z","iopub.execute_input":"2021-05-25T09:36:32.089115Z","iopub.status.idle":"2021-05-25T09:36:32.098298Z","shell.execute_reply.started":"2021-05-25T09:36:32.089078Z","shell.execute_reply":"2021-05-25T09:36:32.097247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nfrom PIL import Image\nfrom tqdm import tqdm \n\ndata_l = []\nimg_size = (64, 64)\n\nfor img in tqdm(data['image'][:1000]):\n    imgs = [cv2.resize(cv2.imread(f'/kaggle/input/clothing-dataset-full/images_original/{img}.jpg'), img_size, interpolation=cv2.INTER_AREA)]\n    for i in imgs:\n        data_l.append(i)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:36:32.099855Z","iopub.execute_input":"2021-05-25T09:36:32.100275Z","iopub.status.idle":"2021-05-25T09:38:29.706349Z","shell.execute_reply.started":"2021-05-25T09:36:32.100239Z","shell.execute_reply":"2021-05-25T09:38:29.705492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_y=[]\n\nimport numpy as np\nfor i in labels_num1:\n    labels_y.append(name_to_idx[i])\nlen(labels_y)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:38:29.707763Z","iopub.execute_input":"2021-05-25T09:38:29.708357Z","iopub.status.idle":"2021-05-25T09:38:29.716686Z","shell.execute_reply.started":"2021-05-25T09:38:29.708318Z","shell.execute_reply":"2021-05-25T09:38:29.715839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_y_s=pd.Series(labels_y)\ntype(labels_y_s)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:38:29.719937Z","iopub.execute_input":"2021-05-25T09:38:29.720315Z","iopub.status.idle":"2021-05-25T09:38:29.730044Z","shell.execute_reply.started":"2021-05-25T09:38:29.720273Z","shell.execute_reply":"2021-05-25T09:38:29.729228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.preprocessing import OneHotEncoder\n\n\nenc = OneHotEncoder()\nenc.fit(labels_y_s.values.reshape(-1, 1))\n\ny_transformed = enc.transform(labels_y_s.values.reshape(-1, 1))\n\nimport scipy\ny_one_hot=scipy.sparse.csr_matrix.toarray(y_transformed)\n\ny_one_hot.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:38:29.732183Z","iopub.execute_input":"2021-05-25T09:38:29.732596Z","iopub.status.idle":"2021-05-25T09:38:29.74395Z","shell.execute_reply.started":"2021-05-25T09:38:29.73256Z","shell.execute_reply":"2021-05-25T09:38:29.742923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = np.array(data_l)\ndata = data / 255.0\ndata = data.astype('float32')","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:38:29.745608Z","iopub.execute_input":"2021-05-25T09:38:29.745984Z","iopub.status.idle":"2021-05-25T09:38:29.799273Z","shell.execute_reply.started":"2021-05-25T09:38:29.745938Z","shell.execute_reply":"2021-05-25T09:38:29.798249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_y_s[:1000].mean()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:38:29.800525Z","iopub.execute_input":"2021-05-25T09:38:29.800904Z","iopub.status.idle":"2021-05-25T09:38:29.807403Z","shell.execute_reply.started":"2021-05-25T09:38:29.800862Z","shell.execute_reply":"2021-05-25T09:38:29.806393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = data[:500]\nX_test = data[500:]\n\ny_train = labels_y[:500]\ny_test = labels_y[500:]","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:38:29.808983Z","iopub.execute_input":"2021-05-25T09:38:29.809474Z","iopub.status.idle":"2021-05-25T09:38:29.818768Z","shell.execute_reply.started":"2021-05-25T09:38:29.809438Z","shell.execute_reply":"2021-05-25T09:38:29.817778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n# X_train, X_test, y_train, y_test = train_test_split(data_l_3, y_one_hot,\n#                                                     test_size=0.2,\n#                                                     random_state=1,\n#                                                     shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:38:29.819881Z","iopub.execute_input":"2021-05-25T09:38:29.820359Z","iopub.status.idle":"2021-05-25T09:38:29.830119Z","shell.execute_reply.started":"2021-05-25T09:38:29.820319Z","shell.execute_reply":"2021-05-25T09:38:29.829306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\nclass Sampling(layers.Layer):\n\n    def call(self, inputs):\n        z_mean, z_log_var = inputs\n        batch = tf.shape(z_mean)[0]\n        dim = tf.shape(z_mean)[1]\n        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n        return z_mean + tf.exp(0.5 * z_log_var) * epsilon","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:38:29.83129Z","iopub.execute_input":"2021-05-25T09:38:29.831834Z","iopub.status.idle":"2021-05-25T09:38:29.840847Z","shell.execute_reply.started":"2021-05-25T09:38:29.831774Z","shell.execute_reply":"2021-05-25T09:38:29.840049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"latent_dim = 512\n\nencoder_inputs = keras.Input(shape=(64, 64, 3))\nx = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\ntf.keras.layers.Dropout(0.2)\nx = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\ntf.keras.layers.Dropout(0.2)\n# x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\nx = layers.Flatten()(x)\n# x = layers.Dense(512, activation=\"relu\")(x)\nz_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\nz_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\nz = Sampling()([z_mean, z_log_var])\nencoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\nencoder.summary()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:38:29.842162Z","iopub.execute_input":"2021-05-25T09:38:29.842557Z","iopub.status.idle":"2021-05-25T09:38:29.904599Z","shell.execute_reply.started":"2021-05-25T09:38:29.842484Z","shell.execute_reply":"2021-05-25T09:38:29.90357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"latent_inputs = keras.Input(shape=(latent_dim,))\nx = layers.Dense(16 * 16 * 64, activation=\"relu\")(latent_inputs)\nx = layers.Reshape((16, 16, 64))(x)\nx = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\nx = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\ndecoder_outputs = layers.Conv2DTranspose(3, 3, activation=\"sigmoid\", padding=\"same\")(x)\ndecoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\ndecoder.summary()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:38:29.905987Z","iopub.execute_input":"2021-05-25T09:38:29.906358Z","iopub.status.idle":"2021-05-25T09:38:29.969701Z","shell.execute_reply.started":"2021-05-25T09:38:29.90632Z","shell.execute_reply":"2021-05-25T09:38:29.968726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VAE(keras.Model):\n    def __init__(self, encoder, decoder, **kwargs):\n        super(VAE, self).__init__(**kwargs)\n        self.encoder = encoder\n        self.decoder = decoder\n        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n        self.reconstruction_loss_tracker = keras.metrics.Mean(\n            name=\"reconstruction_loss\"\n        )\n        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n\n    @property\n    def metrics(self):\n        return [\n            self.total_loss_tracker,\n            self.reconstruction_loss_tracker,\n            self.kl_loss_tracker,\n        ]\n\n    def train_step(self, data):\n        with tf.GradientTape() as tape:\n            z_mean, z_log_var, z = self.encoder(data)\n            reconstruction = self.decoder(z)\n            reconstruction_loss = tf.reduce_mean(\n                tf.reduce_sum(\n                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n                )\n            )\n            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n            total_loss = (reconstruction_loss + kl_loss)/2000\n        grads = tape.gradient(total_loss, self.trainable_weights)\n        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n        self.total_loss_tracker.update_state(total_loss)\n        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n        self.kl_loss_tracker.update_state(kl_loss)\n        return {\n            \"loss\": self.total_loss_tracker.result(),\n            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n            \"kl_loss\": self.kl_loss_tracker.result(),\n        }","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:38:29.971165Z","iopub.execute_input":"2021-05-25T09:38:29.971509Z","iopub.status.idle":"2021-05-25T09:38:29.983398Z","shell.execute_reply.started":"2021-05-25T09:38:29.97147Z","shell.execute_reply":"2021-05-25T09:38:29.982387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vae = VAE(encoder, decoder)\nvae.compile(optimizer=keras.optimizers.Adam())\nhistory = vae.fit(X_train, epochs=15, batch_size=32, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:38:29.984858Z","iopub.execute_input":"2021-05-25T09:38:29.985224Z","iopub.status.idle":"2021-05-25T09:38:33.982129Z","shell.execute_reply.started":"2021-05-25T09:38:29.985186Z","shell.execute_reply":"2021-05-25T09:38:33.98136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2386 2333 2299 2290 2.34\npreds_enc = vae.encoder.predict(X_train)\npreds_enc[0].shape","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:38:33.983573Z","iopub.execute_input":"2021-05-25T09:38:33.983914Z","iopub.status.idle":"2021-05-25T09:38:34.126924Z","shell.execute_reply.started":"2021-05-25T09:38:33.983878Z","shell.execute_reply":"2021-05-25T09:38:34.123748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_dec = vae.decoder.predict(preds_enc[2])\npreds_dec.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:38:34.128874Z","iopub.execute_input":"2021-05-25T09:38:34.12937Z","iopub.status.idle":"2021-05-25T09:38:34.35997Z","shell.execute_reply.started":"2021-05-25T09:38:34.129329Z","shell.execute_reply":"2021-05-25T09:38:34.35886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(history.history.keys())\nplt.plot(history.history['loss'])","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:38:34.364118Z","iopub.execute_input":"2021-05-25T09:38:34.364492Z","iopub.status.idle":"2021-05-25T09:38:34.578633Z","shell.execute_reply.started":"2021-05-25T09:38:34.364448Z","shell.execute_reply":"2021-05-25T09:38:34.5777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num = 499\nfig, ax = plt.subplots(1,2)\nax[0].imshow(X_train[num])\nax[1].imshow(preds_dec[num])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:38:34.582379Z","iopub.execute_input":"2021-05-25T09:38:34.584534Z","iopub.status.idle":"2021-05-25T09:38:34.849236Z","shell.execute_reply.started":"2021-05-25T09:38:34.58449Z","shell.execute_reply":"2021-05-25T09:38:34.84843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_sample = np.mean(preds_enc[2],axis=0)\ntest_sample = np.random.normal(size=512)\n\ntest_pred = vae.decoder.predict(test_sample.reshape(1,512))\nplt.imshow(test_pred[0])","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:38:34.85061Z","iopub.execute_input":"2021-05-25T09:38:34.850954Z","iopub.status.idle":"2021-05-25T09:38:35.012239Z","shell.execute_reply.started":"2021-05-25T09:38:34.850916Z","shell.execute_reply":"2021-05-25T09:38:35.011437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vae_test = VAE(encoder, decoder)\nvae_test.compile(optimizer=keras.optimizers.Adam())\nhistory = vae_test.fit(X_test, epochs=15, batch_size=32, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:38:35.013495Z","iopub.execute_input":"2021-05-25T09:38:35.013814Z","iopub.status.idle":"2021-05-25T09:38:38.733547Z","shell.execute_reply.started":"2021-05-25T09:38:35.013786Z","shell.execute_reply":"2021-05-25T09:38:38.7327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_enc_test = vae_test.encoder.predict(X_test)\n# preds_enc[0].shape\npreds_dec_test = vae_test.decoder.predict(preds_enc_test[2])\n# preds_dec.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:38:38.7349Z","iopub.execute_input":"2021-05-25T09:38:38.735194Z","iopub.status.idle":"2021-05-25T09:38:38.894729Z","shell.execute_reply.started":"2021-05-25T09:38:38.735167Z","shell.execute_reply":"2021-05-25T09:38:38.89383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num = 30\nfig, ax = plt.subplots(1,2)\nax[0].imshow(X_test[num])\nax[1].imshow(preds_dec_test[num])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:39:09.285288Z","iopub.execute_input":"2021-05-25T09:39:09.285645Z","iopub.status.idle":"2021-05-25T09:39:09.52143Z","shell.execute_reply.started":"2021-05-25T09:39:09.285612Z","shell.execute_reply":"2021-05-25T09:39:09.520412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_sample = np.mean(preds_enc_test[2],axis=0)\n\ntest_sample = np.random.normal(size=512)\ntest_pred = vae_test.decoder.predict(test_sample.reshape(1,512))\nplt.imshow(test_pred[0])","metadata":{"execution":{"iopub.status.busy":"2021-05-25T09:39:13.744845Z","iopub.execute_input":"2021-05-25T09:39:13.745195Z","iopub.status.idle":"2021-05-25T09:39:13.900601Z","shell.execute_reply.started":"2021-05-25T09:39:13.745144Z","shell.execute_reply":"2021-05-25T09:39:13.89978Z"},"trusted":true},"execution_count":null,"outputs":[]}]}