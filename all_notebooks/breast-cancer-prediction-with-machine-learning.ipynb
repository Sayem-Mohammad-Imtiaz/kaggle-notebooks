{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Breast Cancer Prediction with Machine Learning\n","metadata":{}},{"cell_type":"markdown","source":"### 1. Introducció ","metadata":{}},{"cell_type":"markdown","source":"El càncer més comú entre les dones és el de mama. L'objectiu d'aquesta pràctica, és predir si un tumor és beginge o maligne. Per fer-ho disposem d'una base de diferents mostres. Per calcular les característiques de cada mostra, es fa a partir d’una imatge digitalitzada d’un aspirat d’agulla fina (FNA) d’una massa mamària. Descriuen les característiques dels nuclis cel·lulars presents a la imatge. D'entre aquestes característiques, tenim les següents:\n- ID number\n- diagnosis (M si és maligne i B si és benigne)\n- radius: mitjana de les distàncies des del centre fins a al punt del perímetre\n- texture: desviació estàndard dels valors a escala de grisos\n- perimeter: perímetre\n- area: àrea\n- smothness: variació local de longituds del radi\n- compactness: perímetre ^ 2 / àrea - 1,0\n- concativy: gravetat de les porcions còncaves del contorn\n- concave points: nombre de porcions còncaves del contorn\n- simmetry: simetra\n- dimensió fractal: aproximació del contorn\n\nLa mitjana, error estàndard i \"pitjor\" d'aquestes funcions es van calcular per a cada imatge, donant lloc a 30 funcions.","metadata":{}},{"cell_type":"markdown","source":"### 2. Com són les dades?","metadata":{}},{"cell_type":"markdown","source":"#### Importem les llibreries i carreguem  les dades","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import make_regression\nimport numpy as np\nimport pandas as pd\n%matplotlib notebook\nimport scipy.stats\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfrom matplotlib import pyplot\nfrom sklearn.metrics import f1_score, confusion_matrix\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import LeaveOneOut\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.linear_model import LogisticRegression","metadata":{"execution":{"iopub.status.busy":"2021-07-12T16:01:02.529923Z","iopub.execute_input":"2021-07-12T16:01:02.530673Z","iopub.status.idle":"2021-07-12T16:01:04.108063Z","shell.execute_reply.started":"2021-07-12T16:01:02.530577Z","shell.execute_reply":"2021-07-12T16:01:04.106951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualitzarem només 3 decimals per mostra\npd.set_option('display.float_format', lambda x: '%.3f' % x)\n\n# Funcio per a llegir dades en format csv\ndef load_dataset(path):\n    dataset = pd.read_csv(path, header=0, delimiter=',')\n    return dataset\n\n# Carreguem el dataset\ndataset = pd.read_csv(\"../input/breast-cancer-wisconsin-data/data.csv\")\n\nprint(\"La dimensionalitat de la nostre BBDD (mostres, característiques):\", dataset.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T16:01:12.028604Z","iopub.execute_input":"2021-07-12T16:01:12.028984Z","iopub.status.idle":"2021-07-12T16:01:12.060683Z","shell.execute_reply.started":"2021-07-12T16:01:12.028953Z","shell.execute_reply":"2021-07-12T16:01:12.059504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Per visualitzar les primeres 5 mostres de la BBDD:\")\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-12T16:01:19.014027Z","iopub.execute_input":"2021-07-12T16:01:19.014677Z","iopub.status.idle":"2021-07-12T16:01:19.058427Z","shell.execute_reply.started":"2021-07-12T16:01:19.014636Z","shell.execute_reply":"2021-07-12T16:01:19.057602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Mirem els atribut amb valors no existents:\")\nprint(dataset.isnull().sum())","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-12T16:01:24.159269Z","iopub.execute_input":"2021-07-12T16:01:24.159845Z","iopub.status.idle":"2021-07-12T16:01:24.167822Z","shell.execute_reply.started":"2021-07-12T16:01:24.159807Z","shell.execute_reply":"2021-07-12T16:01:24.167099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tots els atributs són numèrics menys \"diagnosis\" que és categòric, concretament està en format string. Convertim M en un 1 i B en un 0","metadata":{}},{"cell_type":"code","source":"dataset['diagnosis'] = dataset['diagnosis'].map({'M':1 ,'B':0}) \ndataset['diagnosis'].astype('int')","metadata":{"execution":{"iopub.status.busy":"2021-07-12T16:01:30.457668Z","iopub.execute_input":"2021-07-12T16:01:30.45823Z","iopub.status.idle":"2021-07-12T16:01:30.470745Z","shell.execute_reply.started":"2021-07-12T16:01:30.458196Z","shell.execute_reply":"2021-07-12T16:01:30.46991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"El nostre atribut objectiu serà 'diagnostic', per tant, ens interesa que les proporció de malignes i benignes sigui semblant:\")\nsns.countplot(dataset['diagnosis'])\ndataset['diagnosis'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-12T16:01:33.303251Z","iopub.execute_input":"2021-07-12T16:01:33.303658Z","iopub.status.idle":"2021-07-12T16:01:33.374026Z","shell.execute_reply.started":"2021-07-12T16:01:33.303622Z","shell.execute_reply":"2021-07-12T16:01:33.373147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Un 62% de les dades són de tumors benignes, mentre un 38% són de malignes.","metadata":{}},{"cell_type":"code","source":"# Mirem la correlació entre els atributs d'entrada\ncorrelacio = dataset.iloc[:,1:32].corr()\npyplot.figure(figsize=(20,20))\nax = sns.heatmap(correlacio, annot=True, linewidths=.5, fmt='.0%')","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Preparació de dades","metadata":{}},{"cell_type":"markdown","source":"Per fer el model, escollirem els atributs amb una correlació major de 0.7:","metadata":{}},{"cell_type":"code","source":"(correlacio['diagnosis'])[correlacio['diagnosis']>0.7]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Per l'atribut y tindrem l'objectiu\n#Per l'atribut x escollim els atributs amb major correlació\ndata = dataset.values\ny = data[:, 1]\nx = data[:, [2, 4, 5, 9, 22, 24, 25, 29 ]] \n#x[radius_mean, perimeter_mean, area_mean, concave points_mean, radius_worst, perimeter_worst, area_worst, concave points_worst]es. Para ello, se dispone de p características (X1, X2 … Xp","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Primera prova amb els models","metadata":{}},{"cell_type":"markdown","source":"Separem les dades que tenim en un 80% validació i un 20% test","metadata":{}},{"cell_type":"code","source":"x_t, x_v, y_t, y_v = train_test_split(x, y, train_size=0.8)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculem una regressió logística:\nlogireg = LogisticRegression(C=2.0, fit_intercept=True, penalty='l2', tol=0.001)\nlogireg.fit(x_t, y_t)\nprobs = logireg.predict_proba(x_v)\nprint (\"Correct classification Logistic \", logireg.score(x_v, y_v))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculem una svm:\nsvc = svm.SVC(C=10.0, kernel='rbf', gamma=0.9, probability=True)\nsvc.fit(x_t, y_t)\nprobs = svc.predict_proba(x_v)\nprint (\"Correct classification SVM  \", svc.score(x_v, y_v))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"En la primera prova, al regressió logística és millor que SVM","metadata":{}},{"cell_type":"markdown","source":"#### Normalització","metadata":{}},{"cell_type":"code","source":"#Podem provar d'estandaritzar algunes dades per comorobar si funciona millor.\ndef standarize(x):\n    mean = x.mean(0)\n    std = x.std(0)\n    x_t = x - np.array(mean)\n    x_t /= np.array(std)\n    return x_t\n\nx_s=standarize(x)\n#Per tant en x tindrem les dades sense modificar i en x_s les dades normalitzades.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Separem les dades que tenim en un 80% validació i un 20% test","metadata":{}},{"cell_type":"code","source":"x_t, x_v, y_t, y_v = train_test_split(x_s, y, train_size=0.8)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculem una regressió logística:\nlogireg = LogisticRegression(C=2.0, fit_intercept=True, penalty='l2', tol=0.001)\nlogireg.fit(x_t, y_t)\nprobs = logireg.predict_proba(x_v)\nprint (\"Correct classification Logistic \", logireg.score(x_v, y_v))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculem una svm:\nsvc = svm.SVC(C=10.0, kernel='rbf', gamma=0.9, probability=True)\nsvc.fit(x_t, y_t)\nprobs = svc.predict_proba(x_v)\nprint (\"Correct classification SVM  \", svc.score(x_v, y_v))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Els dos classificadors han millorat en comparació a l'anterior. Per aquest motiu, utilitzarem les dades estandaritzades per les proves següents. De nou, el regressor logístic té un millor accuracy.","metadata":{}},{"cell_type":"markdown","source":"#### PCA","metadata":{}},{"cell_type":"markdown","source":"Probarem de fer un PCA per reduir-ho a dos dimensions.","metadata":{}},{"cell_type":"code","source":"pca = PCA(n_components=2)\nx2=x_s\nelem = pca.fit_transform(x2)\ndf=pd.DataFrame(data=elem, columns=['1','2'])\nfinal_df=pd.concat([df, dataset['diagnosis']], axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = pyplot.figure(figsize = (8,8))\nax = fig.add_subplot(1,1,1) \nax.set_xlabel('Principal Component 1', fontsize = 15)\nax.set_ylabel('Principal Component 2', fontsize = 15)\nax.set_title('2 component PCA', fontsize = 20)\ntargets = [0, 1]\ncolors = ['orange', 'b']\nfor target, color in zip(targets,colors):\n    indicesToKeep = final_df['diagnosis'] == target\n    ax.scatter(final_df.loc[indicesToKeep, '1']\n               , final_df.loc[indicesToKeep, '2']\n               , c = color\n               , s = 50)\nax.legend(targets)\nax.grid()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podem obervar que les dades es veuen bastant separades.","metadata":{}},{"cell_type":"markdown","source":"#### Transformació polinomial","metadata":{}},{"cell_type":"markdown","source":"Fem una transformació polinomial de grau 3:","metadata":{}},{"cell_type":"code","source":"# perform a polynomial features transform of the dataset\ntrans = PolynomialFeatures(degree=3)\nX_polynomial = trans.fit_transform(x_s)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_t, x_v, y_t, y_v = train_test_split(X_polynomial, y, train_size=0.8)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logireg = LogisticRegression(C=2.0, fit_intercept=True, penalty='l2', tol=0.001)\nlogireg.fit(x_t, y_t)\nprobs = logireg.predict_proba(x_v)\nprint (\"Correct classification Logistic \", logireg.score(x_v, y_v))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svc = svm.SVC(C=10.0, kernel='rbf', gamma=0.9, probability=True)\nsvc.fit(x_t, y_t)\nprobs = svc.predict_proba(x_v)\nprint (\"Correct classification SVM  \", svc.score(x_v, y_v))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Cap dels dos classificadors a millorat, per tant, la transformació polinomial no ñes acertada per les nostres dades.","metadata":{}},{"cell_type":"markdown","source":"### 4. Crossvalidation","metadata":{}},{"cell_type":"markdown","source":"Utilitzaem la crossvalidació per avaluar els resultats dels models. Per aquest apartat, utilitzarem tres models diferents: regressió logística, SVM i el KNN. Ho farem per k igual a 3, 5 i 10.","metadata":{}},{"cell_type":"code","source":"for k in [3,5,10]:\n    cv = KFold(n_splits=k, shuffle=True) \n    logireg = LogisticRegression(C=2.0, fit_intercept=True, penalty='l2', tol=0.001)\n    svc = svm.SVC(C=10.0, kernel='rbf', gamma=0.9)\n    classifier= KNeighborsClassifier()\n    # evaluate model\n    scores = cross_val_score(logireg, x_s, y, scoring='accuracy', cv=cv, n_jobs=-1)\n    scores2 = cross_val_score(svc, x_s, y, scoring='accuracy', cv=cv, n_jobs=-1)\n    scores3 = cross_val_score(classifier, x_s, y, scoring='accuracy', cv=cv, n_jobs=-1)\n    # report performance\n    print('K =',k)\n    print('Regressió Logística --> Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))\n    print('SVM --> Accuracy: %.3f (%.3f)' % (np.mean(scores2), np.std(scores2)))\n    print('KNN --> Accuracy: %.3f (%.3f)' % (np.mean(scores3), np.std(scores3)))\ncv = LeaveOneOut()\nlogireg = LogisticRegression(C=2.0, fit_intercept=True, penalty='l2', tol=0.001)\nsvc = svm.SVC(C=10.0, kernel='rbf', gamma=0.9)\nclassifier= KNeighborsClassifier()\n# evaluate model\nscores = cross_val_score(logireg, x_s, y, scoring='accuracy', cv=cv, n_jobs=-1)\nscores2 = cross_val_score(svc, x_s, y, scoring='accuracy', cv=cv, n_jobs=-1)\nscores3 = cross_val_score(classifier, x_s, y, scoring='accuracy', cv=cv, n_jobs=-1)\n# report performance\nprint('LeaveOneOut')\nprint('Regressió Logística --> Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))\nprint('SVM --> Accuracy: %.3f (%.3f)' % (np.mean(scores2), np.std(scores2)))\nprint('KNN --> Accuracy: %.3f (%.3f)' % (np.mean(scores3), np.std(scores3)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Veiem que per k=10 tenim els millors resultats per la regressió logística i SVM. Pel cas del KNN no canvia.  Un cop hem fet Leave One Out, només milloren els resultats de KNN.","metadata":{}},{"cell_type":"markdown","source":"### 5. Mètriques de classificació","metadata":{}},{"cell_type":"markdown","source":"En aquest apartat ens centrarem en les mètriques de classificació. Les que utilitzarem seran  `accuracy_score`, `f1_score` i `average_precision_score`","metadata":{}},{"cell_type":"code","source":"for acc in ['accuracy','f1','average_precision']:\n    cv = KFold(n_splits=5, shuffle=True) \n    logireg = LogisticRegression(C=2.0, fit_intercept=True, penalty='l2', tol=0.001)\n    svc = svm.SVC(C=10.0, kernel='rbf', gamma=0.9)\n    classifier= KNeighborsClassifier()\n    # evaluate model\n    scores = cross_val_score(logireg, x_s, y, scoring=acc, cv=cv, n_jobs=-1)\n    scores2 = cross_val_score(svc, x_s, y, scoring=acc, cv=cv, n_jobs=-1)\n    scores3 = cross_val_score(classifier, x_s, y, scoring=acc, cv=cv, n_jobs=-1)\n    # report performance\n    print(acc)\n    print('Regressió Logística --> Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))\n    print('SVM --> Accuracy: %.3f (%.3f)' % (np.mean(scores2), np.std(scores2)))\n    print('KNN --> Accuracy: %.3f (%.3f)' % (np.mean(scores3), np.std(scores3)))\n    print('\\n')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podem observar que la millor mètrica per accuracy i f1 és la regressió logística mentre que per average_precision és KNN","metadata":{}},{"cell_type":"markdown","source":"Ara veurem la classificació de scikit-learn:","metadata":{}},{"cell_type":"code","source":"for idx_train, idx_test in cv.split(x_s):\n    x_t, y_t = x_s[idx_train], y[idx_train]\n    x_test, y_test = x_s[idx_test], y[idx_test]\nlogireg = LogisticRegression(C=2.0, fit_intercept=True, penalty='l2', tol=0.001)\nlogireg.fit(x_t, y_t)\ny_pred_log = logireg.predict(x_s)\ny_true_log = y","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\ntarget_names = ['Benigne', 'Maligne']\nprint(classification_report(y_true_log, y_pred_log, target_names=target_names))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Veiem els seus significats:\n- precision seran els elements que es classifiquen correctament entre aquesta classe.\n- recall ens proporciona intuitivament la capacitat del classificador per trobar les mostres de la classe.\n- f1-score és la mitjana harmònica entre precisió i record.\n- support és el nombre d’ocurrències de la classe donada al nostre conjunt de dades.","metadata":{}},{"cell_type":"markdown","source":"Podem observar que els tumors benignes tenen millors resultats de predicció que els malignes.","metadata":{}},{"cell_type":"markdown","source":"### 6. Resultats","metadata":{}},{"cell_type":"markdown","source":"Mostrem la matriu de confussió i el gràfic ROC pel model logístic ja que ha resultat ser el que millor s'adapta a la base de dades:","metadata":{}},{"cell_type":"code","source":"cm_log = confusion_matrix(y_true_log,y_pred_log)    \npyplot.subplots(figsize=(10, 6))\ncm_log_m = pd.DataFrame(cm_log, index = ['B','M'], columns = ['B','M'])\nsns.heatmap(cm_log_m, annot = True, fmt = 'd', cbar=False)\npyplot.xlabel(\"Predicted\")\npyplot.ylabel(\"Actual\")\npyplot.title(\"Confusion Matrix Logistic Regresion\")\npyplot.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Els valors de la diagonal són els casos estimats de forma correcte pel model. L'altre diagonal són els valors dels casos que s'ha equivocat:\n- 13 dels valors que són malignes, els ha predit com a benignes\n- 7 dels valors que són benignes, els ha predit com a malignes","metadata":{}},{"cell_type":"code","source":"# roc curve and auc\nmodel = logireg\n# generate a no skill prediction (majority class)\nns_probs = [0 for i in range(len(y_t))]\n# predict probabilities\nlr_probs = model.predict_proba(x_t)\n# keep probabilities for the positive outcome only\nlr_probs = lr_probs[:, 1]\n# calculate scores\nns_auc = roc_auc_score(y_t, ns_probs)\nlr_auc = roc_auc_score(y_t, lr_probs)\n# summarize scores\nprint('No Skill: ROC AUC=%.3f' % (ns_auc))\nprint('Logistic: ROC AUC=%.3f' % (lr_auc))\n# calculate roc curves\nns_fpr, ns_tpr, _ = roc_curve(y_t, ns_probs)\nlr_fpr, lr_tpr, _ = roc_curve(y_t, lr_probs)\n# plot the roc curve for the model\npyplot.figure(figsize=(7,5))\npyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\npyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n# axis labels\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\n# show the legend\npyplot.legend()\n# show the plot\npyplot.show()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Les corbes ROC ens proporcionan informació de quan de bo és el nostre predictor. El model ideal seria trobar un AUC d'1. Qualsevol model que es trobés per sota de la lína d'AUC 0.5 no seria eficient. La nostre corba ROC és molt elevada i la probabilitat de que el nostre model faci una predicció correcte és del 98.8%, per tant podem concloure que el nostre model és eficient.","metadata":{}},{"cell_type":"markdown","source":"### 7. Conclusions ","metadata":{}},{"cell_type":"markdown","source":"- El classificador que millor s'adapta a les nostres dades és el Regressor Logístic.\n- Molts dels atributs que se'ns proporcionen son irrelevants, ja que la correlació amb la variable objectiu és molt baixa i tenirlos en compte podria empitjorar el nostre model.\n- A partir de les proves que hem fet, hem pogut veure que els tumors benignes es prediuen millor que els malignes, això pot ser degut a que les proporcions de l'atribut objectius són desiguals. \n- També podem veure, a partir de la matriu de confusió, que hi ha més tumors malignes predits com a benignes tal pel motiu que hem comentat anteriorment.","metadata":{}},{"cell_type":"markdown","source":"----------- Natalia López ","metadata":{}}]}