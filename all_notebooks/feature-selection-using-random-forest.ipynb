{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom math import sqrt\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error,accuracy_score,r2_score,mean_absolute_error\nfrom sklearn.model_selection import TimeSeriesSplit\n\n# Setting seed for reproducibility\nnp.random.seed(1234)  \nPYTHONHASHSEED = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##################################\n# Data Preprocessing\n# Validation method considering that the degradation occurs at a certain moment onwards. Based on: https://ieeexplore.ieee.org/abstract/document/7998311/\n\n##################################\nMAXLIFE = 15\n\ndef Piecewise(cycle_list, max_cycle):\n    '''\n    Piecewise linear function with zero gradient and unit gradient\n            ^\n            |\n    MAXLIFE |-----------\n            |            \\\n            |             \\\n            |              \\\n            |               \\\n            |                \\\n            |----------------------->\n    '''\n    #print(max(cycle_list))\n    knee_point = max_cycle - MAXLIFE\n    Piecewise_RUL = []\n    stable_life = MAXLIFE\n    for i in range(0, len(cycle_list)):\n        if i < knee_point:\n            Piecewise_RUL.append(MAXLIFE)\n        else:\n            tmp = Piecewise_RUL[i - 1] - (stable_life / (max_cycle - knee_point))\n            Piecewise_RUL.append(tmp)\n\n    return Piecewise_RUL\n\ndef Apply_Piecewise(lf_dataset):    \n    lf_piecewise = []        \n    for id in lf_dataset['machineID'].unique():\n        for i in lf_dataset.loc[(lf_dataset['machineID']==id)\n                              & (lf_dataset['failed'] == 1)].index:\n            tam = int(lf_dataset[lf_dataset.index==i]['RUL'])\n            i_ini = i - tam + 1\n            lf_piecewise.extend(Piecewise(lf_dataset.loc[(lf_dataset.index>=i_ini)&(lf_dataset.index<=i)]['RUL'].values,tam))\n    return lf_piecewise  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/predictive-useful-life-based-into-telemetry/ALLtrainMescla5D.csv')\ndata_test = pd.read_csv('/kaggle/input/predictive-useful-life-based-into-telemetry/ALLtestMescla5D.csv')\n#######\n# TRAIN\n#######\nmapping = {'model1': 1, 'model2': 2, 'model3': 3, 'model4': 4}\ndata = data.replace({'model': mapping})\nmapping = {'none': 0, 'comp1': 1, 'comp2': 2, 'comp3': 3, 'comp4': 4}\ndata = data.replace({'failure': mapping})\ndata = data.drop('datetime',axis=1)\n\ndata['time_in_cycles'] = data['RUL'] \ndata['RULWise'] = Apply_Piecewise(data)\ndata = data.astype(np.float)\n\nn_features = 31\nn_target = 35\ntarget = 'RUL_I'\n\nfeature_list = [data.columns[i] for i in range(0,n_features)]\n\nX_train = data.iloc[:, 0:n_features].values.astype(np.float)\n# generate labels\nY_train = data.iloc[:, n_target-1:n_target].values.astype(np.float).ravel()\n\n#######\n# TEST\n#######\nmapping = {'model1': 1, 'model2': 2, 'model3': 3, 'model4': 4}\ndata_test = data_test.replace({'model': mapping})\nmapping = {'none': 0, 'comp1': 1, 'comp2': 2, 'comp3': 3, 'comp4': 4}\ndata_test = data_test.replace({'failure': mapping})\ndata_test = data_test.drop('datetime',axis=1)\ndata_test['time_in_cycles'] = data_test['RUL'] #* -1\ndata_test['RULWise'] = Apply_Piecewise(data_test)\ndata_test = data_test.astype(np.float)\n\nX_test = data_test.iloc[:, 0:n_features].values.astype(np.float)\n# generate labels\nY_test = data_test.iloc[:, n_target-1:n_target].values.astype(np.float).ravel()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##################################\n# MODELING\n##################################\nrf = RandomForestRegressor(n_estimators= 50, criterion = 'mse', random_state=42, verbose = 1)#random_state=42,warm_start=True\n\n# Train the model on training data\nrf.fit(X_train, Y_train);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##################################\n# TEST DATA\n##################################\nscore = rf.score(X_test, Y_test)\n    \n# Use the forest's predict method on the test data\nY_pred = rf.predict(X_test).round()\n\n#KPIs\n#Number of features\nk = X_test.shape[1]\n#No. of data samples\nn = len(X_test)\n\nerrors = abs(Y_pred - Y_test)\nACC = accuracy_score(Y_test, Y_pred)\nRMSE = float(format(np.sqrt(mean_squared_error(Y_test, Y_pred)), '.3f'))\nMSE = mean_squared_error(Y_test, Y_pred)\nMAE = mean_absolute_error(Y_test, Y_pred)\nR2 = r2_score(Y_test, Y_pred, multioutput='variance_weighted')\nadjR2 = 1- ((1-R2)*(n-1))/(n-k-1)\n\nprint('\\nAccuracy: ',ACC,'%')\nprint('Average absolute error:', round(np.mean(errors), 2))\nprint(\"Root Mean Squared Error (RMSE): \", RMSE)\nprint(\"Mean Squared Error (MSE): \", MSE)\nprint(\"Mean Absolute Error (MAE): \", MAE)\nprint(\"R2_Score: \", R2)\nprint(\"Adjusted R2: \", adjR2)\nprint('Score: ',score.round(2))\n\n# Plot in blue color the predicted data and in green color the\n# actual data to verify visually the accuracy of the model.\nplt_title = 'Predict RF Acurracy '+str(ACC)+'%. R^2 '+str(round(R2,2))\nfig_verify = plt.figure(figsize=(20, 10))\nplt.plot(Y_pred, color=\"red\")\nplt.plot(Y_test, color=\"green\")\nplt.title('prediction')\nplt.ylabel('RUL in cycles')\nplt.xlabel('machineID')\nplt.legend(['predicted', 'actual data'], loc='upper left')\nplt.title(plt_title)\nplt.show()\n#fig_verify.savefig(\"Output/model_regression_verifyRF_test.png\")\n\nfig_verify = plt.figure(figsize=(20, 10))\nplt.plot(Y_pred, color=\"red\")\nplt.title('prediction')\nplt.ylabel('RUL in cycles')\nplt.xlabel('machineID')\nplt.legend(['predicted'], loc='upper left')\nplt.show()\n#fig_verify.savefig(\"Output/model_regression_verifyRF_pred.png\")\n\nfig_verify = plt.figure(figsize=(20, 10))\nplt.plot(Y_test, color=\"green\")\nplt.title('true data')\nplt.ylabel('RUL in cycles')\nplt.xlabel('machineID')\nplt.legend(['actual data'], loc='upper left')\nplt.show()\n#fig_verify.savefig(\"Output/model_regression_verifyRF_true.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##################################\n# FETURES IMPORTANCES\n##################################\n\n# Get numerical feature importances\nimportances = list(rf.feature_importances_)\n# List of tuples with variable and importance\nfeature_importances = [(feature, round(importance, 4)) for feature, importance in zip(feature_list, importances)]\n# Sort the feature importances by most important first\nfeature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n# Print out the feature and importances \n[print('Feature: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];\n\n# Set the style\nplt.style.use('fivethirtyeight')\n# list of x locations for plotting\nx_values = list(range(len(importances)))\n# Make a bar chart\nplt.bar(x_values, importances, orientation = 'vertical')\n# Tick labels for x axis\nplt.xticks(x_values, feature_list, rotation='vertical')\n# Axis labels and title\nplt.ylabel('Importance'); plt.xlabel('Feature'); plt.title('Feature Importances');","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}