{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"cell_type":"markdown","source":"**Synthetic Features and Outliers**\n\n- create a synthetic feature which is a ratio of two other features\n- use this new feature as an input to a linear regression model\n- improve the effectiveness of the model by identifying and clipping (removing) outliers out of the input data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import math\nfrom IPython import display\nfrom matplotlib import cm\nfrom matplotlib import gridspec\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport sklearn.metrics as metrics\nimport tensorflow as tf\nfrom tensorflow.python.data import Dataset\n\ntf.logging.set_verbosity(tf.logging.ERROR)\npd.options.display.max_rows = 10\npd.options.display.float_format = '{:.1f}'.format\n\ncalifornia_housing_dataframe = pd.read_csv('../input/california_housing_train.csv', sep=',')\n\ncalifornia_housing_dataframe = california_housing_dataframe.reindex(np.random.permutation(california_housing_dataframe.index))\ncalifornia_housing_dataframe['median_house_value'] /= 1000.0\ncalifornia_housing_dataframe","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"94eb5dbe-27f4-417a-85fc-e19f6ba61533","collapsed":true,"_uuid":"9131e512bc554ceef76613b45b3b0f8373b72438","trusted":true},"cell_type":"code","source":"# setup input function and define function for model training\n\ndef my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n    \"\"\"Trains a linear regression model of one feature.\n    \n    Args:\n        features: pandas DataFrame of feature\n        targets: pandas DataFrame of targets\n        batch_size: size of btaches to be passed to the model\n        shuffle: True or False. Whether to shuffle the data\n        num_epochs: Number of epochs for which data should be repeated. None=repeat indefinitely\n    Returns:\n        Tuple of (features, labels) for next data batch\n    \"\"\"\n    \n    # convert pandas data into a dict of np.arrays\n    features = {key: np.array(value) for key, value in dict(features).items()}\n    \n    # construct a dataset, and configure batching/repeating\n    ds = Dataset.from_tensor_slices((features, targets)) # beware of the limits\n    ds = ds.batch(batch_size).repeat(num_epochs)\n    \n    # shuffle the data, if specified\n    if shuffle:\n        ds = ds.shuffle(buffer_size=10000)\n        \n    # return the next batch of data\n    features, labels = ds.make_one_shot_iterator().get_next()\n    return features, labels","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"e7aab912-c87b-4480-9f11-052a0e9dfc36","collapsed":true,"_uuid":"0baf6ea6dfafb2cf2d4a750913e7f6a6b6c67515","trusted":true},"cell_type":"code","source":"def train_model(learning_rate, steps, batch_size, input_feature):\n    \"\"\"Trains a linear regression model.\n    \n    Args:\n        learning_rate: A `float`, the learning rate\n        steps: A non-zero `int`, the total number of training steps. A training step consists of a forward and backward pass using a single batch\n        batch_size: A non-zero `int`, the batch size\n        input_feature: A `string` specifying a column from `california_housing_dataframe` to use as input feature\n        \n    Returns:\n        A pandas `DataFrame` containing a targets and the corresponding predictions done after training the model\n    \"\"\"\n    \n    periods = 10\n    steps_per_period = steps / periods\n    \n    my_feature = input_feature\n    my_feature_data = california_housing_dataframe[[my_feature]].astype('float32')\n    my_label = 'median_house_value'\n    targets = california_housing_dataframe[my_label].astype('float32')\n    \n    # create input functions\n    training_input_fn = lambda: my_input_fn(my_feature_data, targets, batch_size=batch_size)\n    predict_training_input_fn = lambda: my_input_fn(my_feature_data, targets, num_epochs=1, shuffle=False)\n    \n    # create feature columns\n    feature_columns = [tf.feature_column.numeric_column(my_feature)]\n    \n    # create a linear regressor object\n    my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n    my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n    linear_regressor = tf.estimator.LinearRegressor(\n        feature_columns=feature_columns,\n        optimizer=my_optimizer\n    )\n    \n    # set up to plot the state of our model's line each period\n    plt.figure(figsize=(15, 6))\n    plt.subplot(1, 2, 1)\n    plt.title('Learned line by period')\n    plt.ylabel(my_label)\n    plt.xlabel(my_feature)\n    sample = california_housing_dataframe.sample(n=300)\n    plt.scatter(sample[my_feature], sample[my_label])\n    colors = [cm.coolwarm(x) for x in np.linspace(-1, 1, periods)]\n    \n    # train the model, but do it in a loop so that we can periodicaly asses loss metrics\n    print('Training model...')\n    print('RMSE (on training data):')\n    root_mean_squared_errors = []\n    for period in range(0, periods):\n        # train the model, starting from prior state\n        linear_regressor.train(\n            input_fn=training_input_fn,\n            steps=steps_per_period\n        )\n        \n        # take a break and compute predictions\n        predictions = linear_regressor.predict(input_fn=predict_training_input_fn)\n        predictions = np.array([item['predictions'][0] for item in predictions])\n        \n        # compute loss\n        root_mean_squared_error = math.sqrt(metrics.mean_squared_error(predictions, targets))\n        \n        # occasionally print the current loss\n        print(' period %02d: %0.2f' % (period, root_mean_squared_error))\n        \n        # add the loss metrics from this period to our list\n        root_mean_squared_errors.append(root_mean_squared_error)\n        \n        # finally, track the weights and biases over time\n        # apply some math to ensure that the data and line are plotted neatly\n        y_extents = np.array([0, sample[my_label].max()])\n        \n        weight = linear_regressor.get_variable_value('linear/linear_model/%s/weights' % input_feature)[0]\n        bias = linear_regressor.get_variable_value('linear/linear_model/bias_weights')\n        \n        x_extents = (y_extents - bias) / weight\n        x_extents = np.maximum(np.minimum(x_extents, sample[my_feature].max()), sample[my_feature].min())\n        y_extents = weight * x_extents + bias\n        plt.plot(x_extents, y_extents, color=colors[period])\n        \n    print('Model training finished')\n    \n    # output a graph of loss metrics over periods\n    plt.subplot(1, 2, 2)\n    plt.ylabel('RMSE')\n    plt.xlabel('Periods')\n    plt.title('Root mean squared erros vs periods')\n    plt.tight_layout()\n    plt.plot(root_mean_squared_errors)\n    \n    # create a table with calibration data\n    calibration_data = pd.DataFrame()\n    calibration_data['predictions'] = pd.Series(predictions)\n    calibration_data['targets'] = pd.Series(targets)\n    display.display(calibration_data.describe())\n    \n    print('Final RMSE (on training data): %0.2f' % root_mean_squared_error)\n    \n    return calibration_data","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"0e30d9b4-f2bc-4036-b747-3a4efc54aaee","collapsed":true,"_uuid":"09d6da4cd0d7f33eddb0f8aa90bb9138d603e2c0"},"cell_type":"markdown","source":"**Try a synthetic feature**\n\n`total_room` and `population` features count totals for a given city block. What if one city block was more densely populated that another? Let's create a synthetic feature `rooms_per_person` which is a ratio of `total_rooms` and `population` use that as `input_feature` to `train_model()`. What's the best performance you can get with this single feature by tweaking the learning rate?"},{"metadata":{"_cell_guid":"5e3f560e-5086-4822-92ef-2e7103552b0c","_uuid":"e63818aad48b36df9e4114ee4aa4565acc766084","trusted":true},"cell_type":"code","source":"california_housing_dataframe['rooms_per_person'] = california_housing_dataframe['total_rooms'] / california_housing_dataframe['population']\ncalifornia_housing_dataframe['rooms_per_person'].describe()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"28840dba-6dc0-41ab-a949-1c8116d10b99","collapsed":true,"_uuid":"7d076915d48af5ad4f3d40beda8bc967e3fd05d8","trusted":true},"cell_type":"code","source":"calibration_data = train_model(\n    learning_rate=0.00005,\n    steps=500,\n    batch_size=5,\n    input_feature='rooms_per_person'\n)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f6ce4bdd-140f-4878-92ac-87ccca10f722","collapsed":true,"_uuid":"63b1011fc0aa60bd2a18683c5ec3de37897f45e5","trusted":true},"cell_type":"code","source":"calibration_data = train_model(\n    learning_rate=0.0005,\n    steps=500,\n    batch_size=5,\n    input_feature='rooms_per_person'\n)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4abb14f8-a16d-4a30-baa5-e5547f24b7a4","collapsed":true,"_uuid":"1c1fdc0f51077cc9dbf6bbdbb2bbbb61be82f636","trusted":true},"cell_type":"code","source":"calibration_data = train_model(\n    learning_rate=0.005,\n    steps=500,\n    batch_size=5,\n    input_feature='rooms_per_person'\n)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c23351e2-2aec-47c7-8c54-ec4a26f9b93d","collapsed":true,"_uuid":"4113c813a4e187a0e395fea4ec8a892731efe1b3","trusted":true},"cell_type":"code","source":"calibration_data = train_model(\n    learning_rate=0.08,\n    steps=500,\n    batch_size=5,\n    input_feature='rooms_per_person'\n)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"70ba3adf-5aa7-40db-956e-df7da860ddff","collapsed":true,"_uuid":"b5b79205c0ab91b664def078d2da0430e4641d9e","trusted":true},"cell_type":"code","source":"calibration_data = train_model(\n    learning_rate=0.05,\n    steps=500,\n    batch_size=5,\n    input_feature=\"rooms_per_person\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3733587c-bf32-4116-b107-189591dd114c","_uuid":"9877abf27c741dec8011f433a8d94a53d3744bad","_kg_hide-output":false},"cell_type":"markdown","source":"**Idenitify outliers**\n\nUse scatter plot of predictions vs targets to find any oddities."},{"metadata":{"_cell_guid":"edaad3c2-9ac2-4c9e-a590-02fa40c72b32","collapsed":true,"_uuid":"7a8d524d105239a29baa89ed0d1556d39239c520","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 6))\nplt.subplot(1, 2, 1)\nplt.scatter(calibration_data['predictions'], calibration_data['targets'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"913ee8a5-6239-4dd4-a7e8-4fa0d5da268d","collapsed":true,"_uuid":"c0157bd55e4b6386115e72453a3a848ebfb34a63","trusted":true},"cell_type":"code","source":"# most of the predictions seem to be on the left side of the plot, let's confirm this with our input data as well\nplt.subplot(1, 2, 2)\n_ = california_housing_dataframe['rooms_per_person'].hist()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c1a9d779-371e-4681-867e-4d8995feff81","_uuid":"a4bfaee0f95b6645d01138eb621ea8fa4ea43428"},"cell_type":"markdown","source":"**Clip Outliers**\n\nCan we improve the model's accuracy by setting the outlier values of `room_per_person` to some reasonable min and max."},{"metadata":{"_cell_guid":"90a5c396-5b77-401c-8bbc-151985f90ad7","collapsed":true,"_uuid":"3d64bc6232f8890fee0d84a1c19fc219dad76e5c","trusted":true},"cell_type":"code","source":"# since most of input values are less than 5, let's clip at 5 and confirm with histogram plot\ncalifornia_housing_dataframe['clipped_rooms_per_person'] = (california_housing_dataframe['rooms_per_person']).apply(lambda x: min(x, 5))\n_ = california_housing_dataframe['clipped_rooms_per_person'].hist()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f74c49a8-791e-4c69-afee-53d3e0fc7611","collapsed":true,"_uuid":"e6d9e76543cc2c9fbb3c1480c41c82f3cace28e4","trusted":true},"cell_type":"code","source":"# to check if clipping had any effect, let's retry training\ncalibration_data = train_model(\n    learning_rate=0.05,\n    steps=500,\n    batch_size=5,\n    input_feature='clipped_rooms_per_person'\n)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ec71721a-a02a-4ec7-ac49-ba35176a6e81","collapsed":true,"_uuid":"e09b77f6bba95b4f4c43436817954a9b070219a4","trusted":true},"cell_type":"code","source":"_ = plt.scatter(calibration_data['predictions'], calibration_data['targets'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"122ef64f-9457-4cbd-bc4e-6e5cd3ca8a44","collapsed":true,"_uuid":"fea2ce2b91a3fead005c0d38672536e7dc8f1d97","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}