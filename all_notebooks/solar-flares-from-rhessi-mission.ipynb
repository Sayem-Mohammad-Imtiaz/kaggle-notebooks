{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"e3b72ec7-ca75-36f2-2b47-3010d7c8fd6f"},"source":" - Flare\t\t- An ID number, ymmddnn, e.g., 2042101 is the first flare found for 21-Apr-2002. These numbers are not time ordered.\n - Date\t\t- The date when the flare occurred\n - Start\t\t- Flare start time\n - Peak\t\t- Flare peak time\n - End\t\t- Flare end time\n - Dur[s]\t\t- Duration of flare in seconds\n - Peak[c/s]\t- Peak count rate in corrected counts, peak counts/second\n - Total Counts\t- Total of counts in corrected counts, counts in energy range \n - Energy [keV]\t- The highest energy band in which the flare was observed.\n - X pos [asec]\t- Flare position in arcsec from sun center \n - Y pos [asec]\t- Flare position in arcsec from sun center \n - Radial [asec]\t- Radial distance in arcsec from sun center \n - \n - Flags\t\t- Quality Codes\n\n - Flare Flag Codes: \n  \n\n - List item\n\n  * a0 - In attenuator state 0 (None) sometime during flare\n  * a1 - In attenuator state 1 (Thin) sometime during flare\n  * a2 - In attenuator state 2 (Thick) sometime during flare\n  * a3 - In attenuator state 3 (Both) sometime during flare\n  * An - Attenuator state (0=None, 1=Thin, 2=Thick, 3=Both) at peak of flare\n  * DF - Front segment counts were decimated sometime during flare\n  * DR - Rear segment counts were decimated sometime during flare\n  * ED - Spacecraft eclipse (night) sometime during flare\n  * EE - Flare ended in spacecraft eclipse (night)\n  * ES - Flare started in spacecraft eclipse (night)\n  * FE - Flare ongoing at end of file\n  * FR - In Fast Rate Mode\n  * FS - Flare ongoing at start of file\n  * GD - Data gap during flare\n  * GE - Flare ended in data gap\n  * GS - Flare started in data gap\n  * MR - Spacecraft in high-latitude zone during flare\n  * NS - Non-solar event\n  * PE - Particle event: Particles are present\n  * PS - Possible Solar Flare; in front detectors, but no position\n  * Pn - Position Quality: P0 = Position is NOT valid, P1 = Position is valid\n  * Qn - Data Quality: Q0 = Highest Quality, Q11 = Lowest Quality\n  * SD - Spacecraft was in SAA sometime during flare\n  * SE - Flare ended when spacecraft was in SAA\n  * SS - Flare started when spacecraft was in SAA"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"eb345f31-3a4f-1393-d314-fd276f97b85e"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\nimport os\nfrom datetime import datetime\nimport copy"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"92606df3-ccb3-5df7-a879-4ffcc9f0463c"},"outputs":[],"source":"\"\"\" PARAMETERS \"\"\"\nfolder_input = '../input'\nfile_input = 'hessi.solar.flare.2002to2016.csv'"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fbf7c185-4335-2953-a320-3d1f08e8ab93"},"outputs":[],"source":"\"\"\" FUNCTIONS \"\"\"\n\n## review variables of data\ndef review_data(DATA):\n    ## Dates data\n    print('Data between %s and %s'%(np.min(DATA['dt.start'].tolist()),np.max(DATA['dt.end'].tolist())))\n\n    ## categorical data\n    print('\\nCATEGORICAL DATA:')\n    # list of categorical variables\n    lcat = ['energy.kev','flag.1','flag.2','flag.3','flag.4','flag.5']\n    # possible values\n    for icat in lcat:\n        # filter nan values\n        values = DATA[icat].values\n        values = list(values[pd.notnull(values)])\n        print('VARIABLE %s: \\n%s\\n'%(icat,sorted(list(set(values)), reverse=False)))\n\n    ## non categorical data\n    print('NON CATEGORICAL DATA:')\n    # list of categorical variables\n    lnoncat = ['duration.s','peak.c/s','total.counts','x.pos.asec','y.pos.asec','active.region.ar','radial']\n    # describe\n    print(DATA[lnoncat].describe())\n\n    ## NAN data\n    print('\\nNULL DATA:')\n    print(DATA.isnull().sum())\n    \n    return None\n\n## filtering data\ndef filtering(DATA,lwrong):\n    ## filter 1: 3-16 kev\n    lenght1 = len(DATA)\n    DATA = DATA[DATA['energy.kev']!='3-6']\n    lenght2 = len(DATA)\n    if lenght1!=lenght2: print('filtering 3-6 kev',lenght1,lenght2)\n\n    ## filter 2: radial\n    radial = DATA['radial'].values\n    lenght1 = len(DATA)\n    DATA = DATA[DATA['radial']<=np.percentile(radial,99)]\n    lenght2 = len(DATA)\n    if lenght1!=lenght2: print('filtering radial',lenght1,lenght2)\n\n    # filter possible wrong values or without solar event\n    #lwrong = ['NS','SD','SS','DF','DR','ED','ES','FE','FR','FS','GD','GE','GS','MR','P0','PS','PE']\n    for icod in lwrong: \n        ## filter\n        lenght1 = len(DATA)\n        DATA = DATA[DATA['flag.1']!=icod]\n        lenght2 = len(DATA)\n        if lenght1!=lenght2: print('filtering %s'%icod,lenght1,lenght2)\n\n        lenght1 = len(DATA)\n        DATA = DATA[DATA['flag.2']!=icod]\n        lenght2 = len(DATA)\n        if lenght1!=lenght2: print('filtering %s'%icod,lenght1,lenght2)\n\n        lenght1 = len(DATA)\n        DATA = DATA[DATA['flag.3']!=icod]\n        lenght2 = len(DATA)\n        if lenght1!=lenght2: print('filtering %s'%icod,lenght1,lenght2)\n\n        lenght1 = len(DATA)\n        DATA = DATA[DATA['flag.4']!=icod]\n        lenght2 = len(DATA)\n        if lenght1!=lenght2: print('filtering %s'%icod,lenght1,lenght2)\n\n        lenght1 = len(DATA)\n        values = DATA['flag.5'].values\n        lfilter = [i for i in list(values[pd.notnull(values)]) if icod in i]\n        DATA = DATA[~DATA['flag.5'].isin(lfilter)]\n        lenght2 = len(DATA)\n        if lenght1!=lenght2: print('filtering %s'%icod,lenght1,lenght2)\n            \n    return DATA"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8be213cb-0ceb-46b6-ef7f-79723efd1958"},"outputs":[],"source":"\"\"\" DATA \"\"\"\n\n# read data\npath_input = os.path.join(folder_input,file_input)\nDATA = pd.read_csv(path_input,sep=\",\",index_col=0)\n# process date / time columns\ndef parse_dt(sdatex,stimex):\n    datex = datetime.strptime(sdatex, '%Y-%m-%d')\n    timex = datetime.strptime(stimex, '%H:%M:%S')\n    return datetime(datex.year,datex.month,datex.day,timex.hour,timex.minute,timex.second)\nDATA['dt.start'] = DATA[['start.date','start.time']].apply(lambda x: parse_dt(x[0],x[1]), axis=1)\nDATA['dt.peak'] = DATA[['start.date','peak']].apply(lambda x: parse_dt(x[0],x[1]), axis=1)\nDATA['dt.end'] = DATA[['start.date','end']].apply(lambda x: parse_dt(x[0],x[1]), axis=1)\n# clean columns\nDATA.drop(['start.date','start.time','peak','end'], axis=1, inplace=True)\n# add new columns\nDATA['year'] = DATA['dt.start'].apply(lambda col: col.year)\nDATA['month'] = DATA['dt.start'].apply(lambda col: col.month)\nDATA['day'] = DATA['dt.start'].apply(lambda col: col.day)\n\n# filtering basic\nlwrong = ['NS','SD']\nDATA1 = filtering(copy.deepcopy(DATA),lwrong)\n\n# include energy bounday ranges\nDATA1['energy.kev.i'] = DATA1['energy.kev'].apply(lambda col: int(col.split('-')[0]))\nDATA1['energy.kev.f'] = DATA1['energy.kev'].apply(lambda col: int(col.split('-')[1]))\nCENERGY = DATA1[['energy.kev','energy.kev.i','energy.kev.f']].drop_duplicates(inplace=False).sort(['energy.kev.i'], ascending=[1], inplace=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"36bce216-be3f-d21d-8248-629020e29671"},"outputs":[],"source":"## REVIEW OF DATA\nreview_data(DATA1)"},{"cell_type":"markdown","metadata":{"_cell_guid":"3bcdf810-0252-d3ba-802e-9b0b8c9b7d36"},"source":"## SUN SPOTS"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"104f3b24-4207-2369-3096-59029aafd2c0"},"outputs":[],"source":"## PLOT SUNSPOTS per Energy\nimport matplotlib.pyplot as plt\n\n# get colors\ncolors = plt.cm.jet(np.linspace(0,1,len(CENERGY['energy.kev.i'].values)))\n\n# build figure object\nfig, ax = plt.subplots(figsize=(10,10))\n# loop of energy ranges\nfor i,irange in enumerate(CENERGY['energy.kev'].values):\n    # collect data\n    AUX = DATA1[DATA1['energy.kev']==irange][['x.pos.asec','y.pos.asec']]\n    # scatter plot\n    plt.scatter(AUX['x.pos.asec'].values,AUX['y.pos.asec'].values,color=colors[i],label='%s Kev'%irange)\n    ax.legend(loc='best',fontsize=9,shadow=True)\n    # clean\n    del(AUX)\n# set title\nplt.title('SUNSPOTS per Energy')\n# plot\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"afcb216b-db69-e529-db0d-70548244d0d3"},"outputs":[],"source":"## Y DISTRIBUTION\nimport matplotlib.pyplot as plt\n# create objects\nfig, ax = plt.subplots(figsize=(10,2))\n# hist\ny = DATA1['y.pos.asec'].values\nplt.hist(y, bins=np.linspace(np.min(y),np.max(y),100),normed=True,label=\"label var y\")\n# set limits\nax.set_xlim([np.min(y),np.max(y)])\n# title\nplt.title('Y Distribution')\n# plot\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"cb5f43cc-3741-b2c2-697f-a3d6ba7973a1"},"source":"Sunspots specially distributed around the equator."},{"cell_type":"markdown","metadata":{"_cell_guid":"c422b839-7fd7-11e4-f042-69635aead8db"},"source":"## YEARLY ANALYSIS"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"27b516c2-a45f-760b-6017-8c2bd3d2886b"},"outputs":[],"source":"\"\"\" number of events per year \"\"\"\n\nimport matplotlib.pyplot as plt\nDATA1.groupby(['year'])['total.counts'].count().plot(kind='bar',figsize=(10,2),title='YEARLY NUMBER OF EVENTS')\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9792b9ec-a95b-3531-14e2-8b615e847fa2"},"outputs":[],"source":"\"\"\" number of events per year and intensity ranges \"\"\"\n\n# calculate limits of intensity ranges\nintensity = DATA1['peak.c/s'].values\np10 = np.percentile(intensity,10)\np50 = np.percentile(intensity,50)\np90 = np.percentile(intensity,90)\n\n# plot average of events intensity per year\nPI0 = DATA1[(DATA1['peak.c/s']<=p10)].groupby(['year'])['peak.c/s'].count()\nPI1 = DATA1[(DATA1['peak.c/s']>p10) & (DATA1['peak.c/s']<=p50)].groupby(['year'])['peak.c/s'].count()\nPI2 = DATA1[(DATA1['peak.c/s']>p50) & (DATA1['peak.c/s']<=p90)].groupby(['year'])['peak.c/s'].count()\nPI3 = DATA1[(DATA1['peak.c/s']>p90)].groupby(['year'])['peak.c/s'].count()\nPI = pd.DataFrame({'year':PI0.index.values,'very low':PI0.values,'low':PI1.values,'high':PI2.values,'very high':PI3.values})\n\nimport matplotlib.patches as mpatches\nimport matplotlib.pyplot as plt\n# build figure object\nfig, ax = plt.subplots(figsize=(10,5))\n\n# collect data\nind = PI0.index.values\ny0 = PI0.values\ny1 = PI1.values\ny2 = PI2.values\ny3 = PI3.values\n# plot\nax.stackplot(ind,y0, y1, y2, y3,colors=['blue','green','orange','red'])\n# set limits\nax.set_xlim([ind[0]-1,ind[-1]+1])\n# set legend\nax.legend([mpatches.Patch(color='blue'),  \n            mpatches.Patch(color='green'),\n            mpatches.Patch(color='orange'),\n            mpatches.Patch(color='red')], \n           ['very low','low','high','very high'])\n\n# set label\nax.set_xlabel('Years')\n# set title\nax.set_title('YEARLY NUMBER OF EVETNS per INTENSITY (c/s)\\n (Limits Classification = %s c/s, %s c/s, %s c/s)'%(p10,p50,p90))\n# plot\nplt.show()"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}