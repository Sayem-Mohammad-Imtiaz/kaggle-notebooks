{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#导入包\n\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import backend, models, layers, optimizers, regularizers\nfrom tensorflow.keras.utils import to_categorical\nimport numpy as np\nfrom numpy import expand_dims \nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nfrom IPython.display import display \nfrom PIL import Image \nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array \nfrom keras.preprocessing.image import array_to_img\nfrom keras.applications.vgg19 import preprocess_input\nfrom keras.applications.inception_v3 import InceptionV3 \nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import optimizers,regularizers\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import Input\nfrom keras.layers import Dense,Flatten,Dropout\nfrom keras.layers import Input\nfrom tensorflow.keras import optimizers,regularizers\nfrom tensorflow.python.keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.utils import np_utils\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator \nimport os, shutil, datetime\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input \nfrom keras.layers import Conv2D \nfrom keras.layers import MaxPooling2D \nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.layers import Dense \nfrom keras.layers import Flatten \nfrom keras.layers import Dropout \nfrom keras.optimizers import SGD, Adam\nimport pandas as pd\nfrom IPython.core.display import display, HTML\n\nimport os\nfrom statistics import mean, median\nfrom numpy.random import seed\n\nfrom statistics import mean, median\nfrom IPython.display import display, HTML\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport math\nfrom sklearn.metrics import classification_report\nfrom keras.models import load_model\nfrom tensorflow.keras.utils import  plot_model     \n\ndisplay(HTML(\"<style>.container { width:100% !important; }</style>\"))","metadata":{"id":"AEYa2SQ8W2BI","outputId":"67445bb7-ee4b-46e0-ba36-65f24e9c8862","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#参数设置\n\nseed(1234)\nbase       = '../input/birdafter-1/'\ntrain_dir  = 'train_1/'\ntest_dir   = 'test_1/'\nvalid_dir  = 'val_1/'\nDIR_TEST =  base + test_dir\nDIR_TRAIN = base + train_dir\nDIR_VALID = base + valid_dir\n\nb_epochs = 30\nb_size = 32\nb_lr=0.0001\n\nimg_width =  224\nimg_height = 224\n\n\ncallbacks_list = [\n  EarlyStopping(\n        monitor = 'accuracy', \n        patience = 8, \n        mode = 'max',\n        restore_best_weights=True),\n  ReduceLROnPlateau( \n      monitor='accuracy',\n      factor=0.1, \n      patience=1)\n]","metadata":{"id":"Gp0rGQeTW2Bv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 数据统计\ndef cntSamples(directory):\n    specs = []\n    for root, dirs, files in os.walk(directory, topdown=True):\n        dirs.sort()\n        for name in dirs:\n            if name not in specs:\n                specs.append(name)\n\n    # file counts for each species \n    nums = []\n    for b in specs:\n        path = os.path.join(directory,b)\n        num_files = len(os.listdir(path))\n        nums.append(num_files)\n \n    # Create Dictionary\n    adict = {specs[i]:nums[i] for i in range(len(specs))}\n    return adict\ntestDict =  cntSamples(DIR_TEST)\ntrainDict = cntSamples(DIR_TRAIN)\nvalidDict = cntSamples(DIR_VALID)\nnum_classes = len(trainDict)\n\n\n# Count labels in train, valid and test\n\n\ntrain_tbl = pd.DataFrame.from_dict(trainDict, \n                orient='index', dtype=None, columns=['Images'])\n\nnum_classes = len(trainDict)\nlabel_index = list(range(num_classes))\n#print(num_classes)\ntrain_tbl.insert(0,'Label Index',label_index, True)\n\n# Creates pandas DataFrame. \ndata = {'样本数': [sum(trainDict.values()), \n                   sum(testDict.values()), \n                   sum(validDict.values())],\n        \n        '样本种类': [len(trainDict.values()), \n                    len(testDict.values()), \n                    len(validDict.values())],\n        \n        '最小样本量': [min(trainDict.values()), \n                    min(testDict.values()), \n                    min(validDict.values())],\n        \n        '最大样本量': [max(trainDict.values()), \n                    max(testDict.values()), \n                    max(validDict.values())],\n        \n        '平均样本量': [int(median(trainDict.values())), \n                   int(median(testDict.values())), \n                   int(median(validDict.values()))]}\nlblSummary = pd.DataFrame(data, index =['Train', 'Test', 'Valid']) \ndisplay(HTML(lblSummary.to_html()))\n\nnum_train=sum(trainDict.values())\nnum_val=sum(testDict.values())\n\n'''\ndef tuple_count(file_path, dataset):\n    bird_count = []\n    for file in os.listdir(file_path):\n        bird_count.append((file, len(os.listdir(file_path + file)), dataset))\n    return bird_count\n\nconsolidated = tuple_count(DIR_TEST, '测试集样本量') + tuple_count(DIR_VALID, '验证集样本量') + tuple_count(DIR_TRAIN, '训练集样本量')\ncount_df = pd.DataFrame.from_records(consolidated, columns =['种类名称', '样本量', '数据集划分']) \n\nfig = px.bar(count_df, x='种类名称', y='样本量', color='数据集划分')\nfig.update_xaxes(visible=False)\nfig.show()\n'''","metadata":{"id":"b9LDld6KW2CG","outputId":"3edc13d5-60b5-41c5-bd81-40a32a3a84ae","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n# 查看图像\ndef getKeybyValue(LabelDict, value):\n    listItems = LabelDict.items()\n    for item in listItems:\n        if item[1] == value:\n            return item[0]\n    \n    return None\n\nseed(1234)\n\ndef pltImages(dir):\n    datagen2 = ImageDataGenerator()\n    it2 = datagen2.flow_from_directory(\n            dir,\n            target_size=(224, 224),\n            batch_size=4,\n            class_mode='binary')\n\n    labDict = it2.class_indices\n    batchX, batchy = it2.next() \n    num_img = batchX.shape[0]\n    imgs = [array_to_img(batchX[i]) for i in range(num_img)]\n    indx = [int(batchy[i]) for i in range(len(batchy))]\n    labs = [getKeybyValue(labDict, i) for i in indx]\n   \n    # settings\n    h, w = 5, 5        \n    nrows, ncols = 1, 4  \n    figsize = [25,4]     \n\n    # create figure (fig), and array of axes (ax)\n    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize, dpi = 80)\n\n    # plot image on each sub-plot\n    for i, axi in enumerate(ax.flat):\n        # i runs from 0 to (nrows*ncols-1)\n        # axi is equivalent with ax[rowid][colid]\n        axi.imshow(imgs[i], aspect = 'auto')\n\n        # write Label as title\n        axi.set_title(labs[i])\n\n    plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=0.2, wspace=0.2)\n    plt.show()\n    return\n\nfor d in [train_dir,test_dir,valid_dir]:\n    print('\\n\\n样本示例： ', d)\n    pltImages(base + d)\n'''","metadata":{"id":"8S4eDMjLW2CL","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''# 搭建InceptionV3模型\n\nif K.image_data_format() == 'channels_first':\n    input_shape = (3,img_width, img_height)\nelse:\n    input_shape = (img_width, img_height,3)\n    \n    \nb_epochs = 30\nb_size = 32\nb_lr=0.0001\n\n\n# create a data generator \n\ndatagen=ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n)\n\n# Train Generator for InceptionV3\ntrain_generator = datagen.flow_from_directory(\n    base + train_dir , \n    target_size = (img_width, img_height),\n    class_mode='categorical', \n    batch_size=b_size) \n\n# Validation Generator \nvalidation_generator = datagen.flow_from_directory(\n    base + valid_dir, \n    target_size = (img_width, img_height),\n    class_mode='categorical', \n    batch_size=b_size) \n\n# Test Generator \ntest_generator = datagen.flow_from_directory(\n    base + test_dir, \n    target_size = (img_width, img_height),\n    class_mode='categorical',\n    shuffle = False,\n    batch_size=b_size) \n\nbackend.clear_session()\ninput_shape = (img_width, img_height, 3)\n\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.layers import Input\n\n# Input Tensor\ninput_tensor = Input(shape=input_shape)  \n\nbase_model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n\nflat_1 = Flatten()(base_model.output)\nx = Dense(512, activation='relu')(flat_1)\nx = Dense(512, activation='relu')(x)\npredictions = Dense(num_classes, activation='softmax')(x)\n\n# Model\nmodel = Model(inputs=base_model.input, outputs=predictions)\nprint(\"layers in model: \", len(model.layers))\n\nmodel.compile(optimizer=Adam(lr=b_lr), \n              loss='categorical_crossentropy', metrics = ['accuracy'])\nstart = datetime.datetime.now()\n# Train\nhistory = model.fit_generator(train_generator, \n                            steps_per_epoch=num_train//b_size, \n                            validation_data=validation_generator, \n                            validation_steps=num_val//b_size, \n                            epochs=b_epochs, \n                            verbose=1)\n\nend = datetime.datetime.now()\nelapsed = end - start\nprint ('Inception模型训练完成. 用时: ', elapsed)\n#model.save(\"./inception_e50_b32_lr0.0015_sgd_nodrop.h5\")\nimport pickle\nwith open('./51_inception_e30_b32_lr0001_adam_nodrop_hist', 'wb') as file_pi:\n        pickle.dump(history.history, file_pi)\n'''","metadata":{"id":"ZX1vQudYW2CW","outputId":"b50cfdd1-45ad-4f3b-9577-c99570393e52","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nfrom tensorflow.keras.layers import Input\nfrom tensorflow import keras\nimport seaborn as sns\nfrom tensorflow.compat.v1 import ConfigProto\nfrom tensorflow.keras.models import Model\nconfig = ConfigProto()\nconfig.gpu_options.allow_growth = True\nfrom keras.preprocessing import image\n# 搭建densenet模型\n\nif K.image_data_format() == 'channels_first':\n    input_shape = (3,img_width, img_height)\nelse:\n    input_shape = (img_width, img_height,3)\n\n\nb_epochs = 30\nb_size = 32\nb_lr=0.0001\n\n\n    \n# create a data generator \n\ndatagen=ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n)\n\n# Train Generator for InceptionV3\ntrain_generator = datagen.flow_from_directory(\n    base + train_dir , \n    target_size = (img_width, img_height),\n    class_mode='categorical', \n    batch_size=b_size) \n\n# Validation Generator \nvalidation_generator = datagen.flow_from_directory(\n    base + valid_dir, \n    target_size = (img_width, img_height),\n    class_mode='categorical', \n    batch_size=b_size) \n\n# Test Generator \ntest_generator = datagen.flow_from_directory(\n    base + test_dir, \n    target_size = (img_width, img_height),\n    class_mode='categorical',\n    shuffle = False,\n    batch_size=b_size) \n\nbackend.clear_session()\ninput_shape = (img_width, img_height, 3)\n\n\n\n# Input Tensor\ninput_tensor = Input(shape=input_shape)  \n\nbase_model_2 = tf.keras.applications.DenseNet201(include_top=False, weights='imagenet', input_shape=(224,224,3))\ndef densenet(input_shape=(224, 224, 3)):\n    inputs=Input(shape=input_shape)\n    x=base_model_2(inputs)\n    x=tf.keras.layers.Conv2D(256,4,2,padding='same',activation='relu')(x)\n    x=tf.keras.layers.Conv2D(512, 4, 2, padding='same', activation='relu')(x)\n    #x=tf.keras.layers.Dropout(0.35)(x)\n    s = Model(inputs=base_model_2.input, outputs=base_model_2.get_layer('conv2_block6_2_conv').output)\n    s1 = Model(inputs=base_model_2.input, outputs=base_model_2.get_layer('conv3_block2_1_conv').output)\n    s=s(inputs)\n    s1=s1(inputs)\n    x=tf.keras.layers.Conv2D(256,4,2,padding='same',activation='relu')(x)\n    x1=tf.keras.layers.GlobalAveragePooling2D()(x)\n    x2 = tf.keras.layers.GlobalAveragePooling2D()(s)\n    x3 = tf.keras.layers.GlobalAveragePooling2D()(s1)\n    x=tf.keras.layers.Concatenate()([x1,x2,x3])\n    output_layer=tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n    return Model(inputs=inputs, outputs=output_layer)\nmodel=densenet((224, 224, 3))\nmodel.summary()\n\n#tf.keras.utils.plot_model(model, to_file='model4.png', show_shapes=True, show_layer_names=True,rankdir='TB', dpi=900, expand_nested=True)\nfrom keras.optimizers import SGD\nmodel.compile(optimizer=SGD(lr=0.0015, momentum=0.8), \n              loss='categorical_crossentropy', metrics = ['accuracy'])\nstart = datetime.datetime.now()\n# Train\nhistory = model.fit_generator(train_generator, \n                            steps_per_epoch=num_train//b_size, \n                            validation_data=validation_generator, \n                            validation_steps=num_val//b_size, \n                            epochs=b_epochs, \n                            verbose=1)\n\nend = datetime.datetime.now()\nelapsed = end - start\nprint ('Densenet模型训练完成. 用时: ', elapsed)\n#model.save(\"./51_densenet_e50_b32_lr0001_adam_drop.h5\")\nimport pickle\nwith open('./51_densenet201_e30_b32_lr0015_sgd_nodrop_hist', 'wb') as file_pi:\n        pickle.dump(history.history, file_pi)\n        \n'''","metadata":{"id":"ZX1vQudYW2CW","outputId":"b50cfdd1-45ad-4f3b-9577-c99570393e52","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 搭建densenet模型\nfrom tensorflow.keras import optimizers,regularizers\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Model\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nif K.image_data_format() == 'channels_first':\n    input_shape = (3,img_width, img_height)\nelse:\n    input_shape = (img_width, img_height,3)\n\n\nb_epochs = 30\nb_size = 32\nb_lr=0.00005\n\n\n    \n# create a data generator \n\ndatagen=ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n)\n\n# Train Generator for InceptionV3\ntrain_generator = datagen.flow_from_directory(\n    base + train_dir , \n    target_size = (img_width, img_height),\n    class_mode='categorical', \n    batch_size=b_size) \n\n# Validation Generator \nvalidation_generator = datagen.flow_from_directory(\n    base + valid_dir, \n    target_size = (img_width, img_height),\n    class_mode='categorical', \n    batch_size=b_size) \n\n# Test Generator \ntest_generator = datagen.flow_from_directory(\n    base + test_dir, \n    target_size = (img_width, img_height),\n    class_mode='categorical',\n    shuffle = False,\n    batch_size=b_size) \n\n\ninput_shape = (img_width, img_height, 3)\n\n\n\n# Input Tensor\ninput_tensor = Input(shape=input_shape)  \n\nbase_model_2 = tf.keras.applications.DenseNet201(include_top=False, weights='imagenet', input_shape=(224,224,3))\ndef densenet(input_shape=(224, 224, 3)):\n    inputs=Input(shape=input_shape)\n    x=base_model_2(inputs)\n    x=tf.keras.layers.Conv2D(256,4,2,padding='same',activation='relu')(x)\n    x=tf.keras.layers.Conv2D(512, 4, 2, padding='same', activation='relu')(x)\n    x=tf.keras.layers.Dropout(0.35)(x)\n    s = Model(inputs=base_model_2.input, outputs=base_model_2.get_layer('conv2_block6_2_conv').output)\n    s1 = Model(inputs=base_model_2.input, outputs=base_model_2.get_layer('conv3_block2_1_conv').output)\n    s=s(inputs)\n    s1=s1(inputs)\n    x=tf.keras.layers.Conv2D(256,4,2,padding='same',activation='relu')(x)\n    x1=tf.keras.layers.GlobalAveragePooling2D()(x)\n    x2 = tf.keras.layers.GlobalAveragePooling2D()(s)\n    x3 = tf.keras.layers.GlobalAveragePooling2D()(s1)\n    x=tf.keras.layers.Concatenate()([x1,x2,x3])\n    output_layer=tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n    return Model(inputs=inputs, outputs=output_layer)\nmodel=densenet((224, 224, 3))\n\n\ntf.keras.utils.plot_model(model, to_file='model4.png', show_shapes=True, show_layer_names=True,rankdir='TB', dpi=900, expand_nested=True)\nmodel.compile(optimizer=optimizers.Adam(lr=b_lr), \n              loss='categorical_crossentropy', metrics = ['accuracy'])\nstart = datetime.datetime.now()\n# Train\nhistory = model.fit_generator(train_generator, \n                            steps_per_epoch=num_train//b_size, \n                            validation_data=validation_generator, \n                            validation_steps=num_val//b_size, \n                            epochs=b_epochs, \n                            verbose=1)\n\nend = datetime.datetime.now()\nelapsed = end - start\nprint ('Densenet模型训练完成. 用时: ', elapsed)\n#model.save(\"./densenet_e50_b32_lr0.0001_adam_drop.h5\")\nimport pickle\nwith open('./6_densenet201_e30_b32_lr00005_adam_35drop_hist', 'wb') as file_pi:\n        pickle.dump(history.history, file_pi)\n        ","metadata":{"id":"ZX1vQudYW2CW","outputId":"b50cfdd1-45ad-4f3b-9577-c99570393e52","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nfrom keras.applications import ResNet50V2\nfrom tensorflow.python.keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.utils import np_utils\n# 搭建resnet50模型\n\nb_epochs = 30\nb_size = 32\nb_lr=0.0001\n\n\nif K.image_data_format() == 'channels_first':\n    input_shape = (3,img_width, img_height)\nelse:\n    input_shape = (img_width, img_height,3)\n    \n# create a data generator \n\ndatagen=ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n)\n\n# Train Generator for InceptionV3\ntrain_generator = datagen.flow_from_directory(\n    base + train_dir , \n    target_size = (img_width, img_height),\n    class_mode='categorical', \n    batch_size=b_size) \n\n# Validation Generator \nvalidation_generator = datagen.flow_from_directory(\n    base + valid_dir, \n    target_size = (img_width, img_height),\n    class_mode='categorical', \n    batch_size=b_size) \n\n# Test Generator \ntest_generator = datagen.flow_from_directory(\n    base + test_dir, \n    target_size = (img_width, img_height),\n    class_mode='categorical',\n    shuffle = False,\n    batch_size=b_size) \n\nbackend.clear_session()\n\n\nbase_model = tf.keras.applications.ResNet50V2(include_top=False, weights='imagenet', input_shape=(224,224,3))\nfor layer in base_model.layers:\n    layer.trainable=False\nplot_model(base_model)\n\nmodel=Sequential()\nmodel.add(base_model)\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(2048,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1024,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes,activation='softmax',kernel_initializer='glorot_uniform'))\nprint(model.summary())\n\n#model.summary()\n#tf.keras.utils.plot_model(model, to_file='model3.png', show_shapes=True, show_layer_names=True,rankdir='TB', dpi=900, expand_nested=True)\nmodel.compile(optimizer=optimizers.Adam(lr=b_lr), \n              loss='categorical_crossentropy', metrics = ['accuracy'])\nstart = datetime.datetime.now()\n# Train\nhistory = model.fit_generator(train_generator, \n                            steps_per_epoch=num_train//b_size, \n                            validation_data=validation_generator, \n                            validation_steps=num_val//b_size, \n                            epochs=b_epochs, \n                            verbose=1)\n\nend = datetime.datetime.now()\nelapsed = end - start\nprint ('/Resnet50模型训练完成. 用时: ', elapsed)\nmodel.save(\"./resnet50_e50_b8_lr0001_adam_drop.h5\")\nimport pickle\nwith open('./resnet50_e50_b8_lr0001_adam_drop_hist', 'wb') as file_pi:\n        pickle.dump(history.history, file_pi)\n'''","metadata":{"id":"ZX1vQudYW2CW","outputId":"b50cfdd1-45ad-4f3b-9577-c99570393e52","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n#vgg16\n#import libraries\nimport keras\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import preprocess_input\n\n\nb_epochs = 30\nb_size = 32\nb_lr=0.0001\n\n\n# create a data generator \n\ndatagen=ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n)\n\n# Train Generator for InceptionV3\ntrain_generator = datagen.flow_from_directory(\n    base + train_dir , \n    target_size = (img_width, img_height),\n    class_mode='categorical', \n    batch_size=b_size) \n\n# Validation Generator \nvalidation_generator = datagen.flow_from_directory(\n    base + valid_dir, \n    target_size = (img_width, img_height),\n    class_mode='categorical', \n    batch_size=b_size) \n\n# Test Generator \ntest_generator = datagen.flow_from_directory(\n    base + test_dir, \n    target_size = (img_width, img_height),\n    class_mode='categorical',\n    shuffle = False,\n    batch_size=b_size) \n\nbackend.clear_session()\n\n#加载迁移学习的预训练权重\nbase_model=keras.applications.VGG16(\n    include_top=False,\n    weights=\"imagenet\",\n    input_shape=(224,224,3))\n#方法一：冻结预测层之前的所有的权重参数\nbase_model.trainable = False\n\n#Create new model on top\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Flatten,Dropout\nmodel=Sequential()\nmodel.add(base_model)\nmodel.add(Flatten())\nmodel.add(Dense(2048,activation='relu',kernel_initializer='he_normal'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2048,activation='relu',kernel_initializer='he_normal'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(200,activation='softmax',kernel_initializer='glorot_normal'))\nmodel.summary()\n#tf.keras.utils.plot_model(model, to_file='vgg16model.png', show_shapes=True, show_layer_names=True,rankdir='TB', dpi=900, expand_nested=True)\nprint(\"layers in model: \", len(model.layers))\n\nmodel.compile(optimizer=Adam(lr=b_lr), \n              loss='categorical_crossentropy', metrics = ['accuracy'])\nstart = datetime.datetime.now()\n\n\nhistory = model.fit_generator(train_generator, \n                            steps_per_epoch=num_train//b_size, \n                            validation_data=validation_generator, \n                            validation_steps=num_val//b_size, \n                            epochs=b_epochs, \n                            verbose=1)\n\n\nend = datetime.datetime.now()\nelapsed = end - start\nprint ('/Vgg16模型训练完成. 用时: ', elapsed)\n#model.save(\"./51_vgg16v1_e30_b32_lr0001_adam_nodrop.h5\")\nimport pickle\nwith open('./2_vgg16v1_e30_b32_lr0001_adam_50drop_hist', 'wb') as file_pi:\n        pickle.dump(history.history, file_pi)\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n#mydensenet\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Conv2D,BatchNormalization,Dense,Flatten,Dropout,MaxPooling2D,Input,Concatenate\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport  matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.compat.v1 import ConfigProto\nfrom tensorflow.compat.v1 import InteractiveSession\n\nconfig = ConfigProto()\nconfig.gpu_options.allow_growth = True\nsession = InteractiveSession(config=config)\n\nb_size=32\nb_epochs=30\nb_lr=0.00015\n\nclass BottleNeck(tf.keras.layers.Layer):\n    def __init__(self, growth_rate, drop_rate):\n        super(BottleNeck, self).__init__()\n        self.bn1 = tf.keras.layers.BatchNormalization()\n        self.conv1 = tf.keras.layers.Conv2D(filters=4 * growth_rate,\n                                            kernel_size=(1, 1),\n                                            strides=1,\n                                            padding=\"same\")\n        self.bn2 = tf.keras.layers.BatchNormalization()\n        self.conv2 = tf.keras.layers.Conv2D(filters=growth_rate,\n                                            kernel_size=(3, 3),\n                                            strides=1,\n                                            padding=\"same\")\n        self.dropout = tf.keras.layers.Dropout(rate=drop_rate)\n\n    def call(self, inputs, training=None, **kwargs):\n        x = self.bn1(inputs, training=training)\n        x = tf.nn.relu(x)\n        x = self.conv1(x)\n        x = self.bn2(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.conv2(x)\n        x = self.dropout(x, training=training)\n        return x\n\n\nclass DenseBlock(tf.keras.layers.Layer):\n    def __init__(self, num_layers, growth_rate, drop_rate):\n        super(DenseBlock, self).__init__()\n        self.num_layers = num_layers\n        self.growth_rate = growth_rate\n        self.drop_rate = drop_rate\n        self.features_list = []\n        self.bottle_necks = []\n        for i in range(self.num_layers):\n            self.bottle_necks.append(BottleNeck(growth_rate=self.growth_rate, drop_rate=self.drop_rate))\n\n    def call(self, inputs, training=None, **kwargs):\n        self.features_list.append(inputs)\n        x = inputs\n        for i in range(self.num_layers):\n            y = self.bottle_necks[i](x, training=training)\n            self.features_list.append(y)\n            x = tf.concat(self.features_list, axis=-1)\n        self.features_list.clear()\n        return x\n\n\nclass TransitionLayer(tf.keras.layers.Layer):\n    def __init__(self, out_channels):\n        super(TransitionLayer, self).__init__()\n        self.bn = tf.keras.layers.BatchNormalization()\n        self.conv = tf.keras.layers.Conv2D(filters=out_channels,\n                                           kernel_size=(1, 1),\n                                           strides=1,\n                                           padding=\"same\")\n        self.pool = tf.keras.layers.MaxPool2D(pool_size=(2, 2),\n                                              strides=2,\n                                              padding=\"same\")\n\n    def call(self, inputs, training=None, **kwargs):\n        x = self.bn(inputs, training=training)\n        x = tf.nn.relu(x)\n        x = self.conv(x)\n        x = self.pool(x)\n        return x\n\n\nclass DenseNet(tf.keras.Model):\n    def __init__(self, num_init_features, growth_rate, block_layers, compression_rate, drop_rate):\n        super(DenseNet, self).__init__()\n        self.conv = tf.keras.layers.Conv2D(filters=num_init_features,\n                                           kernel_size=(7, 7),\n                                           strides=2,\n                                           padding=\"same\")\n        self.bn = tf.keras.layers.BatchNormalization()\n        self.pool = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n                                              strides=2,\n                                              padding=\"same\")\n        self.num_channels = num_init_features\n        self.dense_block_1 = DenseBlock(num_layers=block_layers[0], growth_rate=growth_rate, drop_rate=drop_rate)\n        self.num_channels += growth_rate * block_layers[0]\n        self.num_channels = compression_rate * self.num_channels\n        self.transition_1 = TransitionLayer(out_channels=int(self.num_channels))\n        self.dense_block_2 = DenseBlock(num_layers=block_layers[1], growth_rate=growth_rate, drop_rate=drop_rate)\n        self.num_channels += growth_rate * block_layers[1]\n        self.num_channels = compression_rate * self.num_channels\n        self.transition_2 = TransitionLayer(out_channels=int(self.num_channels))\n        self.dense_block_3 = DenseBlock(num_layers=block_layers[2], growth_rate=growth_rate, drop_rate=drop_rate)\n        self.num_channels += growth_rate * block_layers[2]\n        self.num_channels = compression_rate * self.num_channels\n        self.transition_3 = TransitionLayer(out_channels=int(self.num_channels))\n        self.dense_block_4 = DenseBlock(num_layers=block_layers[3], growth_rate=growth_rate, drop_rate=drop_rate)\n\n        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n        self.fc = tf.keras.layers.Dense(units=200,activation=tf.keras.activations.softmax)\n\n    def call(self, inputs, training=None, mask=None):\n        x = self.conv(inputs)\n        x = self.bn(x, training=training)\n        x = tf.nn.relu(x)\n        x = self.pool(x)\n\n        x = self.dense_block_1(x, training=training)\n        x = self.transition_1(x, training=training)\n        x = self.dense_block_2(x, training=training)\n        x = self.transition_2(x, training=training)\n        x = self.dense_block_3(x, training=training)\n        x = self.transition_3(x, training=training)\n        x = self.dense_block_4(x, training=training)\n\n        x = self.avgpool(x)\n        x = self.fc(x)\n\n        return x\n\n\ndef densenet_121():\n    return DenseNet(num_init_features=64, growth_rate=32, block_layers=[1, 1, 1, 5], compression_rate=0.35, drop_rate=0.2)\n\n\ndef densenet_169():\n    return DenseNet(num_init_features=64, growth_rate=32, block_layers=[6, 12, 32, 32], compression_rate=0.35, drop_rate=0.2)\n\n\ndef densenet_201():\n    return DenseNet(num_init_features=64, growth_rate=32, block_layers=[6, 12, 48, 32], compression_rate=0.35, drop_rate=0.2)\n\n\n#model_1=densenet_121()\nmodel_1=densenet_169()\ntf.keras.utils.plot_model(model_1, to_file='model.png', show_shapes=True, show_layer_names=True,rankdir='TB', dpi=900, expand_nested=True)\nmodel = tf.keras.Sequential([model_1])\nfrom tensorflow.keras.utils import  plot_model \nmodel.build(input_shape=(None, 224, 224, 3))\n\ndatagen=ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n)\n\n# Train Generator for InceptionV3\ntrain_generator = datagen.flow_from_directory(\n    base + train_dir , \n    target_size = (img_width, img_height),\n    class_mode='categorical', \n    batch_size=b_size) \n\n# Validation Generator \nvalidation_generator = datagen.flow_from_directory(\n    base + valid_dir, \n    target_size = (img_width, img_height),\n    class_mode='categorical', \n    batch_size=b_size) \n\n# Test Generator \ntest_generator = datagen.flow_from_directory(\n    base + test_dir, \n    target_size = (img_width, img_height),\n    class_mode='categorical',\n    shuffle = False,\n    batch_size=b_size) \nmodel.summary()\n\nmodel.compile(optimizer=optimizers.Adam(lr=b_lr), \n              loss='categorical_crossentropy', metrics = ['accuracy'])\nstart = datetime.datetime.now()\n# Train\n#callback=[tf.keras.callbacks.ModelCheckpoint(filepath='./model-ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',save_weights_only=True,monitor='val_loss',verbose=0)]\nhistory = model.fit_generator(train_generator, \n                            steps_per_epoch=num_train//b_size, \n                            validation_data=validation_generator, \n                            validation_steps=num_val//b_size, \n                            epochs=b_epochs, \n                            #callbacks = callback,\n                            verbose=1)\n\nend = datetime.datetime.now()\nelapsed = end - start\nprint ('/mydensenet模型训练完成. 用时: ', elapsed)\nimport pickle\nwith open('./51_mydensenet169_e30_b32_lr00015_adam_hist', 'wb') as file_pi:\n        pickle.dump(history.history, file_pi)\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_eval(Model, hist):\n    import matplotlib.pyplot as plt\n    \n    loss = hist['loss']\n    val_loss = hist['val_loss']\n    epochs = range(1, len(loss) + 1)\n    \n    f = plt.figure(figsize=(12,6))\n    ax1 = f.add_subplot(121)\n    ax2 = f.add_subplot(122)\n    \n    plt.clf()   # clear figure\n    plt.subplot(121)\n    plt.plot(epochs, loss, color = 'blue', label='loss')\n    plt.plot(epochs, val_loss, color = 'orange', label='val loss')\n    plt.title('Loss')\n    plt.xlabel('epochs')\n    plt.ylabel('loss')\n    plt.legend()\n    acc = hist['accuracy']\n    val_acc = hist['val_accuracy']\n    plt.subplot(122)\n    plt.plot(epochs, acc, color = 'blue', label='acc')\n    plt.plot(epochs, val_acc, color = 'orange', label='val acc')\n    plt.title('Acc')\n    plt.xlabel('epochs')\n    plt.ylabel('acc')\n    plt.legend()\n    plt.show()\n    \n    acc = hist['accuracy']\n    xs = list(range(len(acc)))\n    val_acc = hist['val_accuracy']\n    loss = hist['loss']\n    val_loss = hist['val_loss']\n    fig = go.Figure()\n    fig.add_trace(go.Scatter(x=xs, y=acc, mode='lines+markers', name='训练集准确值'))\n    fig.add_trace(go.Scatter(x=xs, y=val_acc, mode='lines+markers', name='验证集准确值'))\n    fig.add_trace(go.Scatter(x=xs, y=loss, mode='lines+markers', name='训练集损失值'))\n    fig.add_trace(go.Scatter(x=xs, y=val_loss, mode='lines+markers', name='验证集损失值'))\n    fig.show()\n    \nloss, accuracy = model.evaluate_generator(test_generator) \n \n# Report\nhist = pd.DataFrame(history.history)\ne_exe = hist.shape[0]\n\nprint(\"\\n\\n模型训练与测试\\n\\n\")\nprint(\"  迭代轮数: \", e_exe)\nprint(\"  初始学习率: \", b_lr)\nprint(\"  样本批次量: \", b_size)\nprint(\"  损失值: {0:.4f}\".format(loss))\nprint(\"  准确率: {0:.4f} % \".format(accuracy * 100.0))\nprint(\"  训练用时:\",elapsed)\nplot_eval(\"Model\", hist)","metadata":{"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n#测试集报告\npred_generator = datagen.flow_from_directory(\n    base + test_dir, \n    target_size = (img_width, img_height),\n    class_mode='categorical',\n    shuffle = False,\n    batch_size=b_size) \n\npred = model.predict_generator(pred_generator, steps= math.ceil(num_val/b_size))\npred_generator.reset\nspecies = list(train_tbl.index)\n\npred_labs = np.argmax(pred,axis=1)\n\n#print(\"测试集预测结果表：\\n\",pred_labs)\n#test_generator.reset()\npred_generator.reset\nrepDict = classification_report(pred_generator.labels, pred_labs, target_names=species, output_dict = True)\nreport = classification_report(pred_generator.labels, pred_labs, target_names=species)\nprint(\"测试集预测结果分析：\\n\",report)\n\npred_generator.reset\nerrors = np.where(pred_labs != pred_generator.classes)[0]\nprint(\"预测错误的图像有%d张\"%int(len(errors)))\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nimport pickle\nimport matplotlib.pyplot as plt\nwith open('../input/inception-sgd-adam-hist/inception_e50_b32_lr0001_adam_nodrop_hist', 'rb') as f:\n    hist_sgd = pickle.load(f)\n    \nwith open('../input/inception-sgd-adam-hist/inception_e50_b32_lr0015_sgd_nodrop_hist', 'rb') as f:\n    hist_adam = pickle.load(f)\n\nplt.figure(figsize=(10,8))\nplt.plot(hist_sgd[\"loss\"],linewidth=3.0,color=\"blue\",label=\"Adam Loss\")\nplt.plot(hist_adam[\"loss\"],linewidth=3.0,color=\"red\",label=\"Sgd Loss\")\nplt.plot(hist_sgd[\"val_loss\"],linewidth=2.0,color=\"blue\",linestyle='--',label=\"Adam val_Loss\")\nplt.plot(hist_adam[\"val_loss\"],linewidth=2.0,color=\"red\",linestyle='--',label=\"Sgd val_Loss\")\nplt.legend()\nplt.title(\"Loss Plot\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss Values\")\nplt.grid()\nplt.savefig(\"3.png\")\nplt.show()\n\n\nplt.figure(figsize=(10,8))\nplt.plot(hist_sgd[\"accuracy\"],color=\"blue\",linewidth=3.0,label=\"Adam accuracy\")\nplt.plot(hist_adam[\"accuracy\"],color=\"red\",linewidth=3.0,label=\"Sgd accuracy\")\nplt.plot(hist_sgd[\"val_accuracy\"],linewidth=2.0,color=\"blue\",linestyle='--',label=\"Adam val_accuracy\")\nplt.plot(hist_adam[\"val_accuracy\"],linewidth=2.0,color=\"red\",linestyle='--',label=\"Sgd val_accuracy\")\nplt.legend()\nplt.title(\"Accuracy Plot\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Accuracy Values\")\nplt.savefig(\"4.png\")\nplt.grid()\nplt.show()\n''''''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nimport pickle\nimport matplotlib.pyplot as plt\nwith open('../input/5cnn-hist/ResNet101V2_e30_b32_lr0001_adam_drop_hist', 'rb') as f:\n    hist_res101 = pickle.load(f)\n    \nwith open('../input/5cnn-hist/inception_e30_b32_lr0001_adam_nodrop_hist', 'rb') as f:\n    hist_ince = pickle.load(f)\n\nwith open('../input/5cnn-hist/resnet50_e30_b32_lr0001_adam_drop_hist', 'rb') as f:\n    hist_res50 = pickle.load(f)\n     \nwith open('../input/5cnn-hist/vgg16_e30_b32_lr0001_adam_nodrop_hist', 'rb') as f:\n    hist_vgg16v1 = pickle.load(f)\n    \nwith open('../input/5cnn-hist/vgg16v2_e30_b32_lr0001_adam_nodrop_hist', 'rb') as f:\n    hist_vgg16v2 = pickle.load(f)\n    \nplt.figure(figsize=(10,8))\nplt.plot(hist_vgg16v1[\"accuracy\"],color=\"black\",linewidth=3.0,label=\"Vgg16v1 accuracy\")\nplt.plot(hist_vgg16v2[\"accuracy\"],color=\"blue\",linewidth=3.0,label=\"Vgg16v2 accuracy\")\nplt.plot(hist_res50[\"accuracy\"],color=\"red\",linewidth=3.0,label=\"ResNet50 accuracy\")\nplt.plot(hist_res101[\"accuracy\"],color=\"orange\",linewidth=3.0,label=\"ResNet101 accuracy\")\nplt.plot(hist_ince[\"accuracy\"],color=\"green\",linewidth=3.0,label=\"Inception accuracy\")\nplt.plot(hist_vgg16v1[\"val_accuracy\"],color=\"black\",linewidth=1.5,linestyle='--',label=\"Vgg16v1 val_accuracy\")\nplt.plot(hist_vgg16v2[\"val_accuracy\"],color=\"blue\",linewidth=1.5,linestyle='--',label=\"Vgg16v2 val_accuracy\")\nplt.plot(hist_res50[\"val_accuracy\"],color=\"red\",linewidth=1.5,linestyle='--',label=\"ResNet50 val_accuracy\")\nplt.plot(hist_res101[\"val_accuracy\"],color=\"orange\",linewidth=1.5,linestyle='--',label=\"ResNet101 val_accuracy\")\nplt.plot(hist_ince[\"val_accuracy\"],color=\"green\",linewidth=1.5,linestyle='--',label=\"Inception val_accuracy\")\nplt.legend()\nplt.title(\"Accuracy Plot\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Accuracy Values\")\nplt.grid()\nplt.savefig(\"5.png\")\nplt.show()\n\nplt.figure(figsize=(10,8))\nplt.plot(hist_vgg16v1[\"loss\"],color=\"black\",linewidth=3.0,label=\"Vgg16v1 loss\")\nplt.plot(hist_vgg16v2[\"loss\"],color=\"blue\",linewidth=3.0,label=\"Vgg16v2 loss\")\nplt.plot(hist_res50[\"loss\"],color=\"red\",linewidth=3.0,label=\"ResNet50 loss\")\nplt.plot(hist_res101[\"loss\"],color=\"orange\",linewidth=3.0,label=\"ResNet101 loss\")\nplt.plot(hist_ince[\"loss\"],color=\"green\",linewidth=3.0,label=\"Inception loss\")\nplt.plot(hist_vgg16v1[\"val_loss\"],color=\"black\",linewidth=1.5,linestyle='--',label=\"Vgg16v1 val_loss\")\nplt.plot(hist_vgg16v2[\"val_loss\"],color=\"blue\",linewidth=1.5,linestyle='--',label=\"Vgg16v2 val_loss\")\nplt.plot(hist_res50[\"val_loss\"],color=\"red\",linewidth=1.5,linestyle='--',label=\"ResNet50 val_loss\")\nplt.plot(hist_res101[\"val_loss\"],color=\"orange\",linewidth=1.5,linestyle='--',label=\"ResNet101 val_loss\")\nplt.plot(hist_ince[\"val_loss\"],color=\"green\",linewidth=1.5,linestyle='--',label=\"Inception val_loss\")\nplt.legend()\nplt.title(\"Loss Plot\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss Values\")\nplt.grid()\nplt.savefig(\"6.png\")\nplt.show()\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nimport pickle\nimport matplotlib.pyplot as plt\nwith open('../input/densenet121-e30-diff-drop-hist/densenet121_e30_b32_lr0001_adam_05drop_hist', 'rb') as f:\n    hist_1 = pickle.load(f)\n    \nwith open('../input/densenet121-e30-diff-drop-hist/densenet_e30_b32_lr0001_adam_drop_hist', 'rb') as f:\n    hist_2 = pickle.load(f)\n\nplt.figure(figsize=(10,8))\n\nplt.plot(hist_1[\"accuracy\"],color=\"blue\",linewidth=3.0,label=\"drop0.5 accuracy\")\nplt.plot(hist_2[\"accuracy\"],color=\"red\",linewidth=3.0,label=\"drop0.35 accuracy\")\n\n\nplt.plot(hist_1[\"val_accuracy\"],color=\"blue\",linewidth=1.5,linestyle='--',label=\"drop0.5 val_accuracy\")\nplt.plot(hist_2[\"val_accuracy\"],color=\"red\",linewidth=1.5,linestyle='--',label=\"drop0.35 val_accuracy\")\n\nplt.legend()\nplt.title(\"Accuracy Plot\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Accuracy Values\")\nplt.grid()\nplt.savefig(\"7.png\")\nplt.show()\n\nplt.figure(figsize=(10,8))\n\nplt.plot(hist_1[\"loss\"],color=\"blue\",linewidth=3.0,label=\"drop0.5 loss\")\nplt.plot(hist_2[\"loss\"],color=\"red\",linewidth=3.0,label=\"drop0.35 loss\")\n\n\nplt.plot(hist_1[\"val_loss\"],color=\"blue\",linewidth=1.5,linestyle='--',label=\"drop0.5 val_loss\")\nplt.plot(hist_2[\"val_loss\"],color=\"red\",linewidth=1.5,linestyle='--',label=\"drop0.35 val_loss\")\n\nplt.legend()\nplt.title(\"Loss Plot\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss Values\")\nplt.grid()\nplt.savefig(\"8.png\")\nplt.show()\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nimport pickle\nimport matplotlib.pyplot as plt\nwith open('../input/densenet121-e30-diff-drop-hist/densenet121_e30_b32_lr0001_adam_05drop_hist', 'rb') as f:\n    hist_05 = pickle.load(f)\n    \nwith open('../input/densenet121-e30-diff-drop-hist/densenet_e30_b32_lr0001_adam_drop_hist', 'rb') as f:\n    hist_035 = pickle.load(f)\n\n\n    \nplt.figure(figsize=(10,8))\n\nplt.plot(hist_05[\"accuracy\"],color=\"blue\",linewidth=3.0,label=\"drop0.5 accuracy\")\nplt.plot(hist_035[\"accuracy\"],color=\"red\",linewidth=3.0,label=\"drop0.35 accuracy\")\n\n\nplt.plot(hist_05[\"val_accuracy\"],color=\"blue\",linewidth=1.5,linestyle='--',label=\"drop0.5 val_accuracy\")\nplt.plot(hist_r035[\"val_accuracy\"],color=\"red\",linewidth=1.5,linestyle='--',label=\"drop0.35 val_accuracy\")\n\nplt.legend()\nplt.title(\"Accuracy Plot\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Accuracy Values\")\nplt.grid()\nplt.savefig(\"7.png\")\nplt.show()\n\nplt.figure(figsize=(10,8))\n\nplt.plot(hist_05[\"loss\"],color=\"blue\",linewidth=3.0,label=\"drop0.5 loss\")\nplt.plot(hist_035[\"loss\"],color=\"red\",linewidth=3.0,label=\"drop0.35 loss\")\n\n\nplt.plot(hist_05[\"val_loss\"],color=\"blue\",linewidth=1.5,linestyle='--',label=\"drop0.5 val_loss\")\nplt.plot(hist_035[\"val_loss\"],color=\"red\",linewidth=1.5,linestyle='--',label=\"drop0.35 val_loss\")\n\nplt.legend()\nplt.title(\"Loss Plot\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss Values\")\nplt.grid()\nplt.savefig(\"8.png\")\nplt.show()\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nimport pickle\nimport matplotlib.pyplot as plt\nwith open('../input/densenet-e100-200-hist/densenet_e200_b8_lr0.0001_adam_drop_hist', 'rb') as f:\n    hist_densenet_e200 = pickle.load(f)\nwith open('../input/densenet-e100-200-hist/densenet_e100_b8_lr0.0001_adam_drop_hist', 'rb') as f:\n    hist_densenet_e100 = pickle.load(f)\n    \nplt.figure(figsize=(8,6))\nplt.plot(hist_densenet_e200[\"accuracy\"],color=\"black\",linewidth=3.0,label=\"lr001 accuracy\")\nplt.plot(hist_densenet_e100[\"accuracy\"],color=\"blue\",linewidth=3.0,label=\"lr0005 accuracy\")\nplt.legend()\nplt.title(\"Accuracy Plot\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Accuracy Values\")\nplt.grid()\nplt.show()\n\nplt.figure(figsize=(8,6))\nplt.plot(hist_densenet_e200[\"loss\"],color=\"black\",linewidth=3.0,label=\"lr001 loss\")\nplt.plot(hist_densenet_e100[\"loss\"],color=\"blue\",linewidth=3.0,label=\"lr0005 loss\")\nplt.legend()\nplt.title(\"Loss Plot\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss Values\")\nplt.grid()\nplt.show()\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n#加载和测试训练好的模型\nmodel = tf.keras.models.load_model('../input/densenet-e30-b32-lr0001-adam-drop/densenet_e30_b32_lr0001_adam_drop.h5')\n#print(model.summary())\ndatagen=ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n)\npred_generator = datagen.flow_from_directory(\n    base + test_dir, \n    target_size = (img_width, img_height),\n    class_mode='categorical',\n    shuffle = False,\n    batch_size=b_size) \nscores = model.evaluate(pred_generator,use_multiprocessing=True,workers=10)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nfrom keras.preprocessing import image \n\nspecies = list(train_tbl.index)\ndef predict(dir):\n    img=image.load_img(dir,target_size=(224,224))\n    img1=image.img_to_array(img)\n    img1=img1/255\n    img1=np.expand_dims(img1,[0])\n    plt.imshow(img)\n    predict = model.predict(img1)\n    predict=np.argmax(predict,axis=1)\n    result = np.squeeze(model.predict(img1))\n    print('\\n图中鸟类预测结果为:', species[predict[0]])\n    print('\\n置信度:', max(result))\npredict('../input/bird200/test/CALIFORNIA QUAIL/5.jpg')\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}