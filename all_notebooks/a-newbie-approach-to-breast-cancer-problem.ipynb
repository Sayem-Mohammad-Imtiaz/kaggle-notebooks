{"cells":[{"metadata":{},"cell_type":"raw","source":"This is my first attempt in machine learning and data science fields. I tried to apply what i learned in books and courses. So if there's an anomaly or somethink i was wrong on , please let me now. So let's jump to our problem.  \n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt \nimport pandas as pd \nimport numpy as np \nimport seaborn as sns \nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load data and take a quick look","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\nprint(df.head)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.info()) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The last column is totaly empty so let's drop it.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"copied_data = df.dropna(axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we have 31 feature to analyse .I don't think that it's wise to analyse them one by one. So my approach is to define the most correlated features with our target(diagnosis) and then visualise them. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# One hot encode the diagnosis \n\nI will encode the diagnosis feature into a binary one : 1 for malignant 0 for benign in order to determine the most correlated features. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelBinarizer \n\n\nencoder = LabelBinarizer()\nfeature = copied_data['diagnosis']\nencoded_feature = encoder.fit_transform(feature)\ncopied_data['diagnosis'] = encoded_feature\nmost_correlated = copied_data.corr().abs()['diagnosis'].sort_values(ascending=False)\n\n#We will chose top 10 most correlated features\nmost_correlated = most_correlated[:10]\ntraining_set = copied_data.loc[:, most_correlated.index]\nprint(most_correlated)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizing ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x=\"diagnosis\", y=\"radius_mean\", data=training_set)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Okay so it's obvious that the larger the radius is the higher the possibility of the tumor to be malignant\nDon't forget malignant is encoded to 1 !","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"for feature in training_set.columns.values:\n    sns.catplot(x='diagnosis', y=feature, data=training_set)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nsns.heatmap(training_set.corr(), annot=True, fmt='.0%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see all the selected features are positively correlated to our target. Now we will check negatively correlated features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = copied_data.corr()\nprint(corr_matrix['diagnosis'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hummmm. As you can see there isn't interesting correlations here. Let's move to the next step. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing the training set\n\nWe will apply feature scalling and split our data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler \nfrom sklearn.model_selection import train_test_split\n\nlabels = training_set['diagnosis']\nnew_training_set = training_set.drop('diagnosis', axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(new_training_set, labels, test_size=0.2, random_state=0)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.fit_transform(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression \nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.model_selection import cross_val_score\n\nmodels = {'Logistic':LogisticRegression(), 'forest':RandomForestClassifier(n_estimators=10, criterion='gini', random_state=0),\n         'tree':DecisionTreeClassifier(criterion='gini', random_state=0)}\n\ntrained_models = list()\n\nfor value in models.values():\n    model = value\n    model.fit(X_train, y_train)\n    acc = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=10)\n    print(acc.mean())\n    trained_models.append(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Okay so based on the results, i will choose the logistic regression model.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Accuracy on test set\n\nWill choose the confusion matrics to calculate the accuracy on test data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix \n\npredictions = trained_models[0].predict(X_test)\nconf_matrix = confusion_matrix(y_test, predictions)\n\ndataframe = pd.DataFrame(conf_matrix)\nsns.heatmap(dataframe, annot=True, cbar=None, cmap=\"Reds\")\nplt.title(\"Confusion Matrix\"), plt.tight_layout()\nplt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hum.. Nice! Our classifier is doing pretty well on data it has never seen! \nLet's calculate the accuracy using the formula:\naccuracy = (True Positive + True Negative) / (True Positive + True Negative + False Positive + False Negative)\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = (dataframe[0][0] + dataframe[1][1]) / (dataframe[0][1] + dataframe[1][0]+ dataframe[0][0] + dataframe[1][1]) \nprint('Test accuracy:', accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}