{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Práctica 1: Análisis exploratorio de datos, preprocesamiento y validación de modelos de clasificación\n\n### Minería de Datos: Curso académico 2020-2021\n\n### Alumnos:\n\n* José Luis Bernáldez Morales\n* Guillermo López Bermejo\n\nEntregado el día 08/11/2020"},{"metadata":{},"cell_type":"markdown","source":"# Introducción"},{"metadata":{},"cell_type":"markdown","source":"En esta práctica trabajaremos los siguientes aspectos explicados en clase:\n\n* Almacenamiento y carga de datos\n* Análisis exploratorio de datos\n* Preprocesamiento de datos\n* Validación de modelos de clasificación\n\nA diferencia de la libreta de ejemplo, aquí trabajaremos con las bases de datos *pima_diabetes* y *wisconsin*, las cuales cargaremos cada una en su respectivo apartado. Aunque el proceso de análisis, preprocesamiento y validación los realizaremos cada uno de acuerdo a su base de datos, tanto los imports necesarios y la semilla los estableceremos ahora, puesto que nos servirán a ambos en el desarrollo de la práctica.\n"},{"metadata":{},"cell_type":"markdown","source":"Primero, incluiremos los imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.compose import make_column_transformer, make_column_selector \nfrom sklearn.impute import SimpleImputer\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport plotly.express as px\nimport miner_a_de_datos_an_lisis_exploratorio_utilidad as utils","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Antes de comenzar con la carga de datos, uno de los aspectos fundamentales de esta práctica es la posibilidad de reproducir los experimentos las veces que hagan falta para saber si el tratamiento de los datos es el correcto o no. Para ello, en aquellos momentos donde la aleatoriedad sea un factor que nos afecte, puesto que los experimentos deben darse en igualdad de condiciones para que nos sirva su comparatoria, vamos a establecer la semilla de aleatoriedad que vamos a usar durante toda la práctica. Su valor no es importante, pero el hecho de que usemos siempre el mismo, sí que lo es."},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 27912 # La misma que en la libreta de ejemplo","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pima Diabetes"},{"metadata":{},"cell_type":"markdown","source":"# 1. Almacenamiento y carga de datos"},{"metadata":{},"cell_type":"markdown","source":"La primera base de datos que vamos a analizar es la de Pima Diabetes, cuyo objetivo es diagnosticar si un paciente tiene diabetes basándose en una serie de mediciones diagnósticas.\n\n\nComenzamos cargando el conjunto de datos diabetes:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\nfilepath = \"../input/pima-indians-diabetes-database/diabetes.csv\"\n\ntarget = \"Outcome\"\n\ndata = pd.read_csv('../input/pima-indians-diabetes-database/diabetes.csv')\ndata[target] = data[target].astype(\"category\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obtenemos una muestra representativa aleatorizada del conjunto de datos:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dividimos el conjunto en variables predictoras (X) y variable objetivo (y):"},{"metadata":{"trusted":true},"cell_type":"code","source":"(X, y) = utils.divide_dataset(data, target=\"Outcome\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comprobamos que el conjunto de datos se ha dividido correctamente mediante dos muestras representativas aleatorizadas:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dividimos el conjunto de datos en una muestra de entrenamiento (70%) y otra de pruebas (30%):\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = 0.7\n\n(X_train, X_test, y_train, y_test) = train_test_split(X, y,\n                                                      stratify=y,\n                                                      random_state=seed,\n                                                      train_size=train_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"La muestra de datos debe aleatorizarse antes de la división (shuffle=True por defecto) para evitar la eliminación de todas las instancias de una o varias clases en caso de que el conjunto de datos esté ordenado en base a los valores de la variable clase.\n\nTambién debemos establecer la semilla para que los datos sean reproducibles (random_state=seed), e indicamos que el holdout sea estratificado (stratify=y) para preservar la porción de ejemplos de cada clase en cada uno de los conjuntos resultantes de la división."},{"metadata":{},"cell_type":"markdown","source":"Volvemos a comprobar que la división se ha realizado correctamente mediante una muestra aleatoria:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Antes de comenzar el análisis exploratorio de datos, volvemos a unir las variables predictoras con la variable clase:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = utils.join_dataset(X_train, y_train)\ndata_test = utils.join_dataset(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comprobamos si la unión se ha realizado correctamente:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Análisis exploratorio de datos"},{"metadata":{},"cell_type":"markdown","source":"Para obtener el número de casos y variables utilizamos el atributo shape:"},{"metadata":{"trusted":true},"cell_type":"code","source":"tamaño = data_train.shape\ntamaño","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos observar, tenemos 537 casos y 9 variables (8 predictoras y 1 variable clase).\n\nAhora para obtener el tipo de cada una de las variables utilizamos el método info:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.info(memory_usage=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos observar, del conjunto de variables predictoras, las variables *Glucose*, *BloodPressure*, *SkinThickness*, *Insulin* y *Age* son numéricas enteras, y las variables *BMI* y *DiabetesPedigreeFunction* son numéricas decimales (float).\n\nEn cuanto a la variable clase (Outcome), es una variable categórica."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.cat.categories","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos observar, esta variable categórica Outcome únicamente contiene 2 estados, 1 y 0, que según podemos deducir de la información de la base de datos, indica si el paciente tiene o no diabetes."},{"metadata":{},"cell_type":"markdown","source":"### Visualización de las variables"},{"metadata":{},"cell_type":"markdown","source":"En primer lugar mostramos el histograma que muestra la densidad de ejemplos para cada uno de los valores:"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_histogram(data_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A primera vista podemos observar una anomalía, algunas variables como *Glucose*, *BloodPressure*, *SkinThickness*, *Insulin* y *BMI* presentan una gran cantidad de ejemplos en el primer intervalo (0-x), vamos a comprobar si existen registros con el valor 0 para estas variables y calcular la porción de la base de datos que representan:"},{"metadata":{"trusted":true},"cell_type":"code","source":"nfilas = tamaño[0]\nperdidos = {}\nGlucose = np.asarray(data_train[[\"Glucose\"]])\nperdidos[\"Glucose\"] = (np.sum(Glucose == 0)/nfilas) * 100\nperdidos[\"Glucose\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BloodPressure = np.asarray(data_train[[\"BloodPressure\"]])\nperdidos[\"BloodPressure\"] = (np.sum(BloodPressure == 0)/nfilas) * 100\nperdidos[\"BloodPressure\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SkinThickness = np.asarray(data_train[[\"SkinThickness\"]])\nperdidos[\"SkinThickness\"] = (np.sum(SkinThickness == 0)/nfilas) * 100\nperdidos[\"SkinThickness\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Insulin = np.asarray(data_train[[\"Insulin\"]])\nperdidos[\"Insulin\"] = (np.sum(Insulin == 0)/nfilas) * 100\nperdidos[\"Insulin\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BMI = np.asarray(data_train[[\"BMI\"]])\nperdidos[\"BMI\"] = (np.sum(BMI == 0)/nfilas) * 100\nperdidos[\"BMI\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos observar, efectivamente tenemos registros con el valor 0 para variables en las que no tendría sentido (es imposible tener una presión sanguínea o un nivel de insulina de 0), por lo que los consideraremos valores perdidos.\n\nVamos a visualizar los valores perdidos de cada atributo de manera gráfica:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(data=perdidos, index = ['Perdidos'])\ndf = df.transpose()\ndf.columns = ['Perdidos']\ndf.index.names = ['Variables']\ndf['Variables'] = df.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.CustomBarplot(df, 'Variables', 'Perdidos')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos destacar el 48,6% de valores perdidos de la variable *Insulin* (prácticamente la mitad de los registros), y el 29% de valores perdidos de la variable *SkinThickness*.\n\nA primera vista esto hace que estas dos variables sean susceptibles de ser eliminadas."},{"metadata":{},"cell_type":"markdown","source":"Ahora vamos a mostrar una tabla resumen con información relevante como la media, la mediana, la desviación estándar, etc. de cada una de las variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.describe(include=\"number\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A primera vista podemos observar una gran desviación estándar en la variable *Insulin*, entre otras variables, lo que podría indicar una gran cantidad de outliers en estas variables.\n\nVamos a tratar de visualizar estos posibles outliers con un diagrama de caja y bigotes:"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.BoxWhisker(data_train, (3,3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos observar, las variables *Insulin* y *DiabetesPedigreeFunction* presentan un número considerable de outliers, por lo que son susceptibles de ser eliminadas.\n\nEn cuanto al resto de variables, la mayoría también presentan outliers, por lo que a la hora de imputar los valores perdidos, debemos sustituirlos por la mediana y no por la media, ya que esta se ve mucho más afectada por los outliers.\n\nAhora vamos a visualizar las variables categóricas del problema:"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_barplot(data_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos observar hay aproximadamente un 65,17% de casos con el valor 0, y un 34,82% de casos con el valor 1, esto nos da a entender que el conjunto de datos no está balanceado y por tanto, dado que hemos indicado que se trata de un holdout estratificado al realizar las particiones, esta proporción deberá mantenerse prácticamente igual en el conjunto de datos de test:"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_barplot(data_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos observar, hay aproximadamente una frecuencia del 64,93% de casos para el valor 0, y del 35,06% para el valor 1, valores casi idénticos a los obtenidos para la distribución de entrenamiento.\n\nEste análisis univariado nos permite identificar problemas como ruido y outliers, así como distribuciones carentes de información. Para obtener información algo más relevante, debemos realizar un análisis multivariado que contraste el conjunto de variables para determinar la potencia discriminativa de los atributos en base a la información que aportan sobre la variable clase.\n\nEn primer lugar vamos a estudiar las relaciones entre pares de variables mediante gráficos de nube de puntos organizados en una matriz en los que cada punto corresponde a un caso coloreado según la variable clase a la que pertenezca y en cada eje se representa un atributo."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_pairplot(data_train, target=\"Outcome\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A primera vista no se observa ninguna variable con un poder discriminativo destacable.\n\nAhora vamos a visualizar las posibles correlaciones entre variables mediante un mapa de calor:"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.HeatMap(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No se observa ninguna correlación que aporte información relevante de cara al preprocesamiento, aunque resulta interesante observar que si que existe una mínima correlación con un valor de 0.56 sobre 1 entre las variables *Age* y *Pregnancies*, ya que a más edad, más probabilidad de haber tenido hijos."},{"metadata":{},"cell_type":"markdown","source":"# 3. Preprocesamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"### Imputación de valores perdidos y selección de variables"},{"metadata":{},"cell_type":"markdown","source":"Para llevar a cabo la imputación vamos a sustituir los valores perdidos de las variables *Glucose*, *BloodPressure*, *SkinThickness*, *BMI* y *DiabetesPedigreeFunction* por la mediana de cada uno de los atributos, ya que, como comentamos en el análisis exploratorio, es el parámetro más adecuado para variables con outliers.\n\nPara ello crearemos un imputador utilizando la función SimpleImputer de sklearn para facilitarnos su inclusión en el pipeline:"},{"metadata":{"trusted":true},"cell_type":"code","source":"impute = make_pipeline(SimpleImputer(strategy=\"median\", missing_values=0))\n\ncolumns = 'Glucose|BloodPressure|SkinThickness|BMI|DiabetesPedigreeFunction'\nnon = 'Pregnancies'\n\nimputer = make_column_transformer(\n    (impute, make_column_selector(pattern=columns)),\n    ('passthrough', make_column_selector(pattern=non))\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En cuanto a la selección de variables, se ha optado por eliminar la variable *Insulin* por tres motivos principales:\n\n* La gran cantidad de valores perdidos (casi la mitad de los registros para esta variable son valores perdidos, siendo esta la que más tiene).\n* El elevado número de outliers.\n* La ausencia de poder predictivo observada en el análisis exploratorio.\n\nEsta eliminación de la variable *Insulin* se ha realizado de manera implícita al no incluirla en la lista columns a la hora de crear el imputador.\n\nEsta sería una muestra del array obtenido tras aplicar la imputación. Como se puede observar, la columna correspondiente a los registros de la variable Insulin ha sido eliminada, y los valores perdidos (registros con un 0) han sido sustituidos por la mediana de la variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"imputer.fit_transform(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En cuanto a la discretización, dado que tras el análisis exploratorio no hemos obtenido ninguna información relevante que nos induzca a pensar que una discretización por igual anchura o frecuencia sea lo mejor, vamos a optar por utilizar un método de discretización no supervisada algo más complejo, llamado discretización por k-medias con dos secciones."},{"metadata":{"trusted":true},"cell_type":"code","source":"discretizer = KBinsDiscretizer(n_bins=2, strategy=\"kmeans\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Algoritmos de clasificación"},{"metadata":{},"cell_type":"markdown","source":"### Algoritmo Zero-R\n\nEste es el algoritmo que utilizaremos como baseline para evaluar la complejidad del conjunto de datos y la efectividad de los clasificadores, considerando éste como el peor clasificador posible."},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_r_model = DummyClassifier(strategy=\"most_frequent\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Algoritmo CART\nAhora probamos con un algoritmo algo más elaborado tal como un árbol de decisión:"},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_model = DecisionTreeClassifier(random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pipeline\nDefinimos el pipeline con la secuencia de preprocesamiento que queremos aplicar antes del aprendizaje del árbol de decisión mediante make_pipeline, compuesto por el imputador/selector de variables y el discretizador:"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline = make_pipeline(imputer,discretizer,tree_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Evaluación de modelos"},{"metadata":{},"cell_type":"markdown","source":"Ahora pasamos a entrenar y validar los modelos mediante matrices de confusión, la tasa de acierto y otras métricas.\n\nComenzamos con el algoritmo Zero-R:"},{"metadata":{},"cell_type":"markdown","source":"### Evaluar algoritmo *Zero-R*"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(zero_r_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.metrics(zero_r_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos observar, obtenemos un accuracy de 0,64935, que es precisamente el porcentaje de casos de la clase mayoritaria (valor 0) en la base de datos, por lo que a pesar de que está por encima del 50% de accuracy podemos considerarlo como un mal resultado.\n\nEsto se confirma al observar que, como era de esperar, los valores tanto de precision como de recall para el valor 1 son de 0."},{"metadata":{},"cell_type":"markdown","source":"### Evaluar algoritmo *CART*"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(tree_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos observar, hemos obtenido un accuracy ligeramente superior al obtenido con el algoritmo Zero-R, pero seguimos sin poder considerarlo como un buen resultado."},{"metadata":{},"cell_type":"markdown","source":"De cara a su comparación con el algoritmo aplicando el pipeline vamos a mostrar otras métricas como el recall o la precisión."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.metrics(tree_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Por último vamos a evaluar el árbol de decisión obtenido aplicando un preprocesamiento que incluiría una selección de variables, la imputación de valores y la discretización por k-medias:"},{"metadata":{},"cell_type":"markdown","source":"### Evaluar clasificador con el Pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(pipeline,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.metrics(pipeline,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos observar un pequeño incremento del accuracy o tasa de acierto (de 0,65 a 0,69).\n\nEn cuanto a otras métricas, podemos observar una disminución del recall, esto implica una reducción de la fracción de casos positivos detectados."},{"metadata":{},"cell_type":"markdown","source":"# 5. Conclusiones"},{"metadata":{},"cell_type":"markdown","source":"En conclusión, tras aplicar el preprocesamiento formado por una selección de variables, una imputación de valores y una discretización por k-medias hemos obtenido un mejor resultado en cuanto a la tasa de acierto a cambio de una reducción del recall, por lo que este preprocesamiento podría no ser adecuado a la hora de utilizar este modelo para el diagnóstico de la diabetes, ya que habrá un mayor número de casos positivos que no serán detectados como tal."},{"metadata":{},"cell_type":"markdown","source":"# Breast Cancer Wisconsin"},{"metadata":{},"cell_type":"markdown","source":"# 1. Almacenamiento y carga de datos"},{"metadata":{},"cell_type":"markdown","source":"La segunda base de datos con la que vamos a trabajar es *Breast Cancer Wisconsin data*, que es un dataset de 569 muestras en el que se trata de clasificar si un cáncer de mama es benigno o maligno. Para ello, y como ya hemos puesto en la carga de datos, la variable objetivo de la que nos encargaremos de clasificar será el diagnóstico, variable discreta cuyos valores serán **Benigno**/**Maligno**, y para identificar cada una de las instancias, utilizaremos una variable de tipo entero que servirá de identificador."},{"metadata":{},"cell_type":"markdown","source":"En cuanto a las variables predictoras, en nuestro caso, tendremos 10:\n* Radius: media de las distancias del centro al perímetro\n* Texture: desviación estandar de valores en escala de grises\n* Perimeter\n* Area\n* Smoothness: variación local en la longitud de los radio\n* Compactness: perímetro^2 / area - 1\n* Concavity: severidad de las porciones cóncavas del contorno\n* Symmetry\n* Fractal dimension: \"coastline approximation\" - 1\n"},{"metadata":{},"cell_type":"markdown","source":"Ahora, cargaremos las bases de datos e imprimimos 5 instancias aleatorias para ver que está todo correcto."},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath = \"../input/breast-cancer-wisconsin-data/data.csv\"\n\nindex = \"id\"\ntarget = \"diagnosis\"   # Nuestra variable objetivo\n\ndata = utils.load_data(filepath, index, target)\ndata.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Antes de nada, y analizando esta pequeña tabla, podemos ver que la última variable de todas, *Unnamed*, muestra valores null, es decir, que no aporta valor para nuestro problema. Para ver si tenemos que eliminar estos valores, vamos a comprobar que no estén vacíos todos los registros:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info(memory_usage=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De esta manera, podemos ver que esa variable no nos aporta información, por lo que vamos a eliminar estos valores. Además, la variable id tampoco nos va a servir para la clasificación, porque no es una variable predictora.\n\nEsta tarea es parte del preprocesamiento de datos, pero no tiene sentido seguir arrastrando este error, por lo que hemos decidido quitar la variable de en medio."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop('Unnamed: 32', axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dividamos ahora el nuestro dataset:"},{"metadata":{"trusted":true},"cell_type":"code","source":"(X, y) = utils.divide_dataset(data, target=\"diagnosis\")\n\nX.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ahora que ya tenemos los datos, tenemos que asegurarnos de que el trabajo que vamos a realizar lo hacemos de manera correcta. Para ello, vamos a aplicar un holdout, el cual consiste en dividir nuestra base de datos en dos muestras diferentes, una para el entrenamiento del modelo y otra para la validación de los datos (la distribución será 70% - 30%).\n\nEl primer conjunto lo utilizaremos para entrenar y así crear la estimación del modelo, pero no podremos usar el 30% restante para entrenar, sino que únicamente los utilizaremos una vez para comprobar que el model funciona como esperamos. De esta manera, evitamos el sobreajuste, puesto que si los datos de validación se utilizaran para aprender el modelo, no estaríamos probando nuestro modelo en datos nuevos, y la estimación de acierto sería optimista e incorrecta. Es decir, estaríamos sobreajustando el modelo a los datos que vamos a usar para validarlo, y lo que queremos es un clasificador que generalice y nos sirva para datos nuevos.\n\nEs muy importante que en el proceso de creación de dichas carpetas, aleatoricemos sus registros de manera que la muestra no esté sesgada. Para ello, la siguiente función tiene por defecto un parámetro, llamado shuffle, que se encuentra a True por defecto, por lo que no tendremos que hacerlo a mano. Del mismo modo, aún no sabemos cómo está distribuida la muestra que nos han dado, es decir, no sabemos si está o no balanceada, por lo que vamos a estratificar, es decir, preservar la distribución original de la variable clase en cada uno de los conjuntos que vamos a crear."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = 0.7\n\n(X_train, X_test, y_train, y_test) = train_test_split(X, y,\n                                                      stratify=y,\n                                                      random_state=seed,\n                                                      train_size=train_size)\nX_train.sample(5, random_state=seed)\n# X_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.sample(5, random_state=seed)\n# y_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Estas variables serán las que utilicemos para entrenar nuestros modelos, pero para la visualización de los datos, vamos a volver a unirlos, ya que nos serán más útiles que por separado. Importante no unir el conjunto de datos con el conjunto de test para evitar una fuga de datos."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = utils.join_dataset(X_train, y_train)\n# data_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Puesto que las variables predictoras son 10, pero están divididas en valor medio, error y peor valor, vamos a separarlos para que más adelante podamos comparar dichas variables con mayor facilidad."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creamos listas para eliminar las columnas que necesitemos\nvariables_mean = ['radius_mean', 'texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave points_mean','symmetry_mean','fractal_dimension_mean']\nvariables_se = ['radius_se', 'texture_se','perimeter_se','area_se','smoothness_se','compactness_se','concavity_se','concave points_se','symmetry_se','fractal_dimension_se']\nvariables_worse = ['radius_worst', 'texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst']\nvariables = variables_mean + variables_se + variables_worse\n\nmeanList = ['radius_se', 'texture_se','perimeter_se','area_se','smoothness_se','compactness_se','concavity_se','concave points_se','symmetry_se','fractal_dimension_se','radius_worst', 'texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst']\nseList = ['radius_mean', 'texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave points_mean','symmetry_mean','fractal_dimension_mean','radius_worst', 'texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst']\nworstList = ['radius_mean', 'texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave points_mean','symmetry_mean','fractal_dimension_mean','radius_se', 'texture_se','perimeter_se','area_se','smoothness_se','compactness_se','concavity_se','concave points_se','symmetry_se','fractal_dimension_se']\n\nmean = X_train.drop(meanList, axis=1)\nse = X_train.drop(seList, axis=1)\nworst = X_train.drop(worstList, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Análisis exploratorio de los datos"},{"metadata":{},"cell_type":"markdown","source":"### Descripción del conjunto de datos"},{"metadata":{},"cell_type":"markdown","source":"Esta es la parte de la práctica donde comenzaremos a analizar las variables de manera que podamos obtener información sobre ellas. Vamos a empezar analizando el tamaño del problema:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver que el tamaño de la muestra, como ya sabíamos, es de 569 instancias, las cuales tienen 30 varaibles cada una, además de contar con la variable clase y el id. "},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.info(memory_usage=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nuestro conjunto de entrenamiento se compone de 398 instancias, con 30 variables predictoras cada una. De todas estas variables, podemos ver que son todas numéricas, concretamente decimales, a excepción de la variable clase, que es categórica. Ahora vamos a comprobar si tenemos valores perdidos."},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values = data_train.isnull().sum()\nmissing_values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Veamos la variable clase:"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.cat.categories","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sus valores son benigno (B) y maligno (M). Veamos ahora su distribución."},{"metadata":{},"cell_type":"markdown","source":"### Visualización de las variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_barplot(data_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aquí podemos ver que la muestra no está balanceada, ya que hay más casos benignos que malignos. De aquí la importancia de que hayamos realizado un holdout estratificado, para que la proporción de casos benignos y malignos se mantenga y no perdamos información."},{"metadata":{},"cell_type":"markdown","source":"Realicemos ahora un análisis univariado, en el que podamos ver como se distribuyen los valores de cada una de las variables predictoras. Utilizaremos histogramas para visualizar los datos y obtendremos también las tablas para ver los valores. Puesto que tenemos 30 variables predictoras, resultará más interesante realizar varios histogramas, para que podamos compara los valores de las variables que corresponden al mismo tipo de dato (media, error, peor caso):"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_histogram(mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Prácticamente todas tienen una distribución normal o casi normal. Otras, como *concavity_mean* o *concave points_mean* son exponenciales."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_histogram(se)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"se.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En el caso del error, la tendencia cambia, puesto que podemos ver que algunas de las variables, como *radius_se* y *perimeter_se* pasan de ser normales a exponenciales, mientras que *concave points_se* es normal en vez de exponencial."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_histogram(worst)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"worst.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Por último, los valores en los peores casos son, en su mayoría, distribuciones normales o mixturas. De estas gráficas podemos observar algo interesante, y es que la mayoría de variables parecen tener outliers, por lo que conocer sus distribuciones nos ayudará a imputar de la mejor manera dichos valores si fuera necesario. Para comprobarlo, utilizaremos diagramas de cajas:"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.BoxWhisker(data_train, (6,6))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Efectivamente podemos comprobar que nuestras variables tienen outliers o ruido, por lo que consideraremos estos valores como erróneos."},{"metadata":{},"cell_type":"markdown","source":"También resulta interesante comprobar si las variables están correlacionadas entre sí. Para ello, crearemos una matriz de gráficos, y en vez de crear 1 de los datos en general, utilizaremos las particiones donde tenemos las variables predictoras agrupadas para realizar el análisis multivariado."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Introducimos el valor de la variable clase en nuestras tablas para poder visualizar los datos mejor\nmean = data_train.drop(meanList, axis=1)\nse = data_train.drop(seList, axis=1)\nworst = data_train.drop(worstList, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_pairplot(mean, target='diagnosis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_pairplot(se, target='diagnosis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_pairplot(worst, target='diagnosis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" El problema de tener tantas variables, es que no podemos sacar conclusiones de manera sencilla, puesto que las gráficas no son muy grandes y es probable que cometamos errores. No obstante, no está mal tenerlas para al menos descartar algunas teorías y quizá formular otras. Por ejemplo, a simple vista, se puede ver que la variable *radius_mean* muy probablemente estará correlacionada con las variables *perimeter_mean* y *area_mean*, aunque esto no debería sorprendernos porque son elementos que ya están relacionados en otros ámbitos matemáticos. Esto se aplica también en los valores *se* y *worst*.\n\nOtras variables, como el *fractal_dimension* o el *texture_mean* ya las podemos ir descartando porque no parece que vayan a ofrecernos una gran cantidad de información relevante para nuestro problema. También podemos observar que las variables de las medias son valores más razonables a la hora de utilizarlas en un posible clasificador, mientras que con el error y el peor caso, cometeríamos un error mayor y presentan un mayor número de outliers, por lo que si no fueramos a ocuparnos de ellos, los podríamos descartar.\n \nPara ver mejor las posibles correlaciones, vamos a analizar los mapas de calor."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.HeatMap(mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Efectivamente, el radio está correlacionado con el perímetro y el área. Además, podemos ver que la variable *concave points_mean* también tiene una fuerte correlación con estas 3 variables, así como con *concavity mean* y *compactness_mean*."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.HeatMap(se)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"se.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.HeatMap(worst)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"worst.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De los otros dos mapas de calor, a parte de las relaciones ya establecidas, podemos ver que tampoco encontramos correlaciones negativas en ninguna de las variables, que las variables que representan valores medios parecen más interesantes y que hay 2 variables más que nos pueden ser útiles, que son *concavity* y *concave_points*, tanto en sus valores medios como en el peor.\n\nPor tanto, de los mapas de calor y las gráficas previamente creadas, las variables que a priori parecen importantes y que afectan a la distribución son el radio, el perímetro y el área. Otras variables como la concavidad nos pueden ser útiles también. Es importante conocer estos valores de manera que podamos evitar utilizar más variables de las necesarias, facilitándonos el proceso.\n\nAhora, vamos a utilizar dichas variables para ver como afectan a la variable clase y así, probablemente, reducir el número de variables que utilizará nuestro predictor."},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in variables:\n    fig = px.histogram(X_train, x=i, color=y_train, )\n    fig.update_traces(opacity=0.7)\n    fig.update_layout(barmode='overlay') # Así vemos como se superponen\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De aquí podemos observar qué variables, como *radius_mean*, *perimeter_mean*, etc., discriminan mejor la variable clase."},{"metadata":{},"cell_type":"markdown","source":"# 3. Preprocesamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"En este apartado vamos a trabajar sobre las operaciones que vamos a realizar sobre nuestros datos crudos. Estas operaciones van a ser las siguientes:\n* Limpieza de datos: eliminaríamos la variable *Unnamed: 32*, puesto que no aporta ningún valor, aunque ya lo hemos hecho.\n* Reducción de datos: seleccionaremos qué variables vamos a utilizar para discriminar la variable clase y realizaremos una discretización de los mismos.\n* Por último, cambiaremos los valores de la variable objetivo por ceros y unos de manera que podamos comparar los modelos utilizando la gráfica ROC.\n\nEmpecemos con la selección de variables."},{"metadata":{},"cell_type":"markdown","source":"Para comenzar, puesto que las variables *radius*, *perimeter* y *area* están claramente correlacionadas, podemos eliminar 2 de ellas. En nuestro caso, nos quedaremos con el radio.\n\nLas variables *concavity* y *concave points* también lo están, por lo que nos quedaremos con la concavidad.\n\nEl resto de variables las vamos a omitir."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Estas son todas las variables a eliminar\nvariables_mean_drop = ['perimeter_mean','area_mean','concave points_mean']\nvariables_se_drop = ['perimeter_se','area_se','concave points_se']\nvariables_worse_drop = ['perimeter_worst','area_worst','concave points_worst']\n\nreduccion_datos = variables_mean_drop + variables_se_drop + variables_worse_drop","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"elim_var = make_column_transformer((\"drop\", reduccion_datos), remainder=\"passthrough\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ahora transformaremos la variable clase en numérica."},{"metadata":{"trusted":true},"cell_type":"code","source":"data['diagnosis']=data['diagnosis'].map({'M':1,'B':0})\n(X, y) = utils.divide_dataset(data, target=\"diagnosis\")\n(X_train, X_test, y_train, y_test) = train_test_split(X, y,\n                                                      stratify=y,\n                                                      random_state=seed,\n                                                      train_size=train_size)\n\n# Como estamos utilizando la misma semilla, la división se realizará de la misma manera, por lo que \n# los datos visualizados y estos serán exactamente iguales","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Por último, discretizaremos las variables mediante k-medias, utilizando 4 secciones, puesto que no podemos dividir exactamente las variables ya que tendríamos resultados incorrectos."},{"metadata":{"trusted":true},"cell_type":"code","source":"discretizer = KBinsDiscretizer(n_bins=4, strategy=\"kmeans\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para poder aplicar todas estas transformaciones, haremos unos de un *pipeline*, el cual aplicará automáticamente las transformaciones implementadas en este apartado a cualquier conjunto de datos que le pasemos."},{"metadata":{},"cell_type":"markdown","source":"# 4. Algoritmos de clasificación y evaluación de modelos"},{"metadata":{},"cell_type":"markdown","source":"Vamos a implementar ahora los algoritmos y procederemos con el modelado. Una vez se hayan entrenado los algoritmos, procederemos a validar y evaluar los modelos, y escogeremos el mejor."},{"metadata":{},"cell_type":"markdown","source":"Para implementar el *Zero-R*, es necesario que definamos el hiperparámetro de la estrategia como *most_frequent*, de manera que el clasificador clasifique todas las instancias como la clase mayoritaria. \n\nEn cuanto al árbol de decisión, será necesario indicar la semilla que estamos utilizando en el hiperparámetro del *random_state*, puesto que en caso de empate entre diferentes variables, siempre elija las mismas con el objetivo de que los resultados de esta práctica sean reproducibles."},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_r_model = DummyClassifier(strategy=\"most_frequent\")\ntree_model = DecisionTreeClassifier(random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline = make_pipeline(elim_var, discretizer, tree_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluar algoritmo *Zero-R*"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(zero_r_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.metrics(zero_r_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"El resultado es el esperable, puesto que al utilizar la clase mayoritaria, que en este caso es la clase benigno, ha clasificado los 64 de la otra clase de manera incorrecta. Este clasificador no nos sirve para nada más que como un baseline, es decir, un punto de partida desde el cual los clasificadores que creemos nosotros tienen que mejorar su resultado."},{"metadata":{},"cell_type":"markdown","source":"### Evaluar algoritmo CART"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(tree_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.metrics(tree_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"El resultado es lógicamente superior, y podemos ver lo sencillo que es realizar un clasificador relativamente bueno para un problema tan complejo. No obstante, aún podemos mejorarlo más si le aplicamos el pipeline que hemos definido previamente."},{"metadata":{},"cell_type":"markdown","source":"### Evaluar clasificador con el Pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline = make_pipeline(elim_var, discretizer, tree_model)\n\nutils.evaluate(pipeline,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.metrics(pipeline,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Una vez aplicado el pipeline, nuestras clasificaciones son mucho más precisas. Realicemos ahora una evaluaciónde los modelos.\n\nPara elegir el mejor modelo, nos vamos a apoyar en el análisis ROC (*Reciever Operating Characteristics*), en el cual normalizamos la matriz de confusión por columnas. Tal y como vamos a observar en los gráficos, el peor clasificador posible, en este caso el *Zero-R*, se verá representado como una recta ascendente (la representaremos como una línea discontinua). Cuanto más esté nuestra gráfica por encima del baseline, mejor será nuestro modelo."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.ROC(tree_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.ROC(pipeline,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver que gracias al uso del pipeline hemos maximizado el área bajo la curva. Además, como la subida es tán rápida, podemos concluir de la propia gráfica lo que ya habíamos visto en los datos, y es que nuestro clasificador tiene una sensibilidad alta (tasa de verdaderos positivos) y una especifidad baja (tasa de falsos negativos)."},{"metadata":{},"cell_type":"markdown","source":"# 5. Conclusiones"},{"metadata":{},"cell_type":"markdown","source":"Gracias al estudio de este dataset hemos comprendido la importancia del preprocesamiento de datos y del uso del pipeline. Utilizando un árbol de decisión hemos obtenido un clasificador bastante bueno sin necesidad de trabajar sobre los datos, pero si analizamos el problema, nuestro cometido es clasificar los máximos casos malignos que podamos, pues si nuestro clasificador los pasa por alto, estaríamos poniendo vidas en juego. \n\nMediante las transformaciones que hemos definido en nuestro preprocesamiento de datos hemos tratado de aumentar el recall al máximo posible para que se nos escapen los mínimos casos malignos posibles, es decir, buscamos clasificar correctamente para evitar el mayor número de falsos negativos, por lo que, en definitiva, gracias al correcto tratamiento de los datos hemos aumentado la eficacia de nuestro clasificador para el cometido que se esperaba."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}