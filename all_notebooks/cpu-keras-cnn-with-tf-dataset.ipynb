{"cells":[{"metadata":{},"cell_type":"markdown","source":"# CPU Keras CNN with TF dataset solution\n\nWe import the datast via the [tensorflow dataset API ](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) and provide a CNN solution in Keras that runs in a reasonable ammount of time on the CPU (and very fast on a GPU). The solution uses 1/5th the paramters of the GPU solution that can be found [here](https://www.kaggle.com/gpreda/tensorflow-keras-gpu-for-chinese-mnist-prediction)"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nfrom pathlib import Path\n\nimport tensorflow as tf\n\n\nos.listdir(\"../input/chinese-mnist\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Constants"},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\n\nIMG_HEIGHT = 32\nIMG_WIDTH = 32\nCHANNELS = 1\n\nBATCH_SIZE = 32","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataset Generation"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = Path('../input/chinese-mnist/data/data')\nlist_ds = tf.data.Dataset.list_files(str(data_dir / '*.jpg'), shuffle=False)\nimage_count = len(list_ds)\nlist_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check if list_ds is populated\nfor f in list_ds.take(5):\n    print(f.numpy())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train val test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = int(image_count * 0.75)\nval_size = int(image_count * 0.15)\ntest_size = int(image_count * 0.1)\n\ntrain_ds = list_ds.take(train_size)\ntest_ds = list_ds.skip(train_size)\nval_ds = test_ds.take(val_size)\ntest_ds = test_ds.skip(val_size)\n\nprint(tf.data.experimental.cardinality(train_ds).numpy())\nprint(tf.data.experimental.cardinality(val_ds).numpy())\nprint(tf.data.experimental.cardinality(test_ds).numpy())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compose dataset from filenames. Generate labels and decode image."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_label(file_path):\n    # Get the class\n    label_str = tf.strings.split(tf.strings.split(file_path, \"_\")[3], \".\")[0]\n    # Start at 0\n    label_number = tf.strings.to_number(label_str, out_type=tf.dtypes.int32, name=None) - 1\n    return label_number\n\ndef decode_img(img):\n    # convert the compressed string to a 1D uint8 tensor\n    img = tf.image.decode_jpeg(img, channels=CHANNELS)\n    # resize the image to the desired size\n    return tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])\n\ndef process_path(file_path):\n    label = get_label(file_path)\n    # load the raw data from the file as a string\n    img = tf.io.read_file(file_path)\n    img = decode_img(img)\n    return img, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\nval_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)\ntest_ds = test_ds.map(process_path, num_parallel_calls=AUTOTUNE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for image, label in train_ds.take(1):\n    print(\"Image shape: \", image.numpy().shape)\n    print(\"Label: \", label.numpy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def configure_for_performance(ds):\n    ds = ds.cache()\n    ds = ds.shuffle(buffer_size=1000)\n    ds = ds.batch(BATCH_SIZE)\n    ds = ds.prefetch(buffer_size=AUTOTUNE)\n    return ds\n\ntrain_ds = configure_for_performance(train_ds)\nval_ds = configure_for_performance(val_ds)\ntest_ds = configure_for_performance(test_ds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataset Visual"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nimage_batch, label_batch = next(iter(test_ds))\n\nplt.figure(figsize=(10, 10))\nfor i in range(16):\n    ax = plt.subplot(4, 4, i + 1)\n    plt.imshow(image_batch[i,:,:,0].numpy().astype(\"uint8\"))\n    label = label_batch[i]\n    plt.title(str(label.numpy()))\n    plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Keras Model Creation\n\nCreating a simple CNN model with a callback for early stopping."},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras import layers\nfrom tensorflow.keras import Input\n\nnum_classes = 15\n\nmodel = tf.keras.Sequential([\n    layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS)),\n    # Preprocessing\n    layers.experimental.preprocessing.Rescaling(1./255),\n    \n    # Augmentation\n    #layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n    layers.experimental.preprocessing.RandomRotation(0.05),\n    \n    # Conv Maxpool model\n    layers.Conv2D(64, 3, activation='relu'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n    layers.Conv2D(32, 3, activation='relu'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n    layers.Conv2D(32, 3, activation='relu'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n    layers.Flatten(),\n    \n    # Regularization\n    layers.Dropout(0.25),\n    \n    layers.Dense(128, activation='relu'),\n    layers.Dense(num_classes, activation='softmax')\n])\n\nmodel.compile(\n  optimizer='adam',\n  loss=\"sparse_categorical_crossentropy\",\n  metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\ncheckpoint_filepath = '/tmp/checkpoint'\ncb_checkpoint = ModelCheckpoint(checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_ds, epochs=40, validation_data=val_ds, batch_size=32, callbacks=[cb_checkpoint])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_model = model\n_ = best_model.load_weights(checkpoint_filepath)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"best_model.evaluate(test_ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\neval_lists = []\n# Predict in batches\nfor images, labels in test_ds.take(-1):  # only take first element of dataset\n    y_pred = best_model.predict(images)\n    y_pred_bool = np.argmax(y_pred, axis=1)\n    eval_lists.append(list(zip(y_pred_bool, labels.numpy())))\n\n# Place in format we can use\nimport itertools\neval_list = list(itertools.chain.from_iterable(eval_lists))\neval_t = list(zip(*eval_list))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\n\nprint(classification_report(*eval_t))\nprint(confusion_matrix(*eval_t, labels=range(15)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}