{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pandas as pd\nimport re\nimport os\n# General libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport time\nimport seaborn as sns\n\n# Libraries for data cleaning\n\nimport re\nimport string\nimport plotly.offline as py\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode\ninit_notebook_mode(connected=False)\n\nimport spacy\nfrom spacy.lang.en.stop_words import STOP_WORDS\nfrom spacy.lang.en import English\npunctuations = string.punctuation\n\n#nlp = spacy.load('en')\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner'])\nparser = English()\n\n\nfrom geopy.geocoders import Nominatim\nfrom folium.plugins import HeatMap\nimport folium\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/real-or-fake-fake-jobposting-prediction/fake_job_postings.csv\")\nlocation = pd.read_csv(\"../input/location-fakevsreal/location.csv\")\n\ndf.head(2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Location \ndf['location'] = df['location'].astype(str)\ndf['Loc_1'] = df['location'].str.split(',').str[0]\ndf['Loc_2'] = df['location'].str.split(',').str[1]\ndf['Loc_3'] = df['location'].str.split(',').str[2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"## Target Distribution\nfig, axes = plt.subplots(ncols=2, figsize=(17, 5), dpi=100)\nplt.tight_layout()\n\ndf[\"fraudulent\"].value_counts().plot(kind='pie', ax=axes[0], labels=['Real Post (17014)', 'Fake Post (866)'])\ntemp = df[\"fraudulent\"].value_counts()\nsns.barplot(temp.index, temp, ax=axes[1],color='#E1396C')\n\naxes[0].set_ylabel(' ')\naxes[1].set_ylabel(' ')\naxes[1].set_xticklabels([\"Real Post (17014) [0]\", \"Fake Post (866) [1]\"])\n\naxes[0].set_title('Dataset - Distribution', fontsize=13)\naxes[1].set_title('Target Count in Dataset', fontsize=13)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f1, axes = plt.subplots(2, 2, figsize=(16,15))\naxes = axes.flatten()\nf1.subplots_adjust(hspace=0.2, wspace=0.4)\n\nax1 = sns.barplot(y=df['location'].value_counts()[:20].index,x=df['location'].value_counts()[:20],\n            orient='h', ax=axes[0],palette='Blues_d')\nax1.set_title(\"Top 20 Location\")\n\nax2 = sns.barplot(y=df['department'].value_counts()[:20].index,x=df['department'].value_counts()[:20],\n            orient='h', ax=axes[1],palette='Blues_d')\nax2.set_title(\"Top 20 Department\")\n\n\nax3 = sns.barplot(y=df['industry'].value_counts()[:20].index,x=df['industry'].value_counts()[:20],\n            orient='h', ax=axes[2],palette='Blues_d')\nax3.set_title(\"Top 20 Industry\")\n\n\nax4 = sns.barplot(y=df['function'].value_counts()[:20].index,x=df['function'].value_counts()[:20],\n            orient='h', ax=axes[3],palette='Blues_d')\nax4.set_title(\"Top 20 Functions\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\ntemp = df[\"Loc_3\"].value_counts()\nsns.barplot(temp.index, temp, ax=axes[1])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def custom_preprocessor(text):\n    '''\n    Make text lowercase, remove text in square brackets,remove links,remove special characters\n    and remove words containing numbers.\n    '''\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub(\"\\\\W\",\" \",text) # remove special chars\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    \n    return text\n\ndf['description'] = df['description'].astype(str)\ndf['requirements'] = df['requirements'].astype(str)\ndf['benefits'] = df['benefits'].astype(str)\ndf['company_profile'] = df['company_profile'].astype(str)\ndf['description'] = df['description'].apply(custom_preprocessor)    \ndf['requirements'] = df['requirements'].apply(custom_preprocessor)    \ndf['benefits'] = df['benefits'].apply(custom_preprocessor)    \ndf['company_profile'] = df['company_profile'].apply(custom_preprocessor)    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"%time\n### Spacy Lemma # Own Stop words\nspacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\ndef spacy_lemma_text(text):\n    doc = nlp(text)\n    tokens = [tok.lemma_.lower().strip() for tok in doc if tok.lemma_ != '-PRON-']\n    tokens = [tok for tok in tokens if tok not in spacy_stopwords and tok not in punctuations]\n    tokens = ' '.join(tokens)\n    return tokens\n\ndf['description'] = df['description'].apply(spacy_lemma_text)    \ndf['requirements'] = df['requirements'].apply(spacy_lemma_text)    \ndf['benefits'] = df['benefits'].apply(spacy_lemma_text)  \ndf['company_profile'] = df['company_profile'].apply(spacy_lemma_text)  \ndf['combined_text'] = df['company_profile'] + \" \" + df['description'] + \" \" + df['requirements'] + \" \" + df['benefits']\ndf['combined_text'] = df['combined_text'].astype(str)\ndf['combined_text'] = df['combined_text'].apply(custom_preprocessor)    \ndf['combined_text'] = df['combined_text'].apply(spacy_lemma_text)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def length(text):    \n    '''a function which returns the length of text'''\n    return len(text)\n\ndf['Com_length'] = df['combined_text'].apply(length)\nplt.rcParams['figure.figsize'] = (10.0, 6.0)\nbins = 100\nplt.hist(df[df['fraudulent'] == 0]['Com_length'], alpha = 0.6, bins=bins, label='Fake Job')\nplt.hist(df[df['fraudulent'] == 1]['Com_length'], alpha = 0.8, bins=bins, label='Real Job')\nplt.xlabel('Distribution of tokens')\nplt.ylabel('numbers')\nplt.legend(loc='upper right')\nplt.xlim(0,150)\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Geo location ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"location.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pytextrank\nimport spacy\nimport pytextrank\nnlp = spacy.load('en_core_web_sm')\ntr = pytextrank.TextRank()\nnlp.add_pipe(tr.PipelineComponent, name='textrank', last=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Extracting Keywords Using PageRank Alogrithm"},{"metadata":{"trusted":true},"cell_type":"code","source":"#pytext_key = []\n\n#for text in df['combined_text']:\n#    text = nlp(text)\n#    t = text._.phrases\n#    pytext_key.append(t)\n    \n#df['Pytextrank_keyword'] = pytext_key        \n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is a popular unsupervised learning method utilized in model building and machine learning algorithms."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\nimport tensorflow_hub as hub\nembed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def prepare_similarity(vectors):\n    similarity=cosine_similarity(vectors)\n    return similarity\n\ndef get_top_similar(sentence, sentence_list, similarity_matrix, topN):\n    # find the index of sentence in list\n    index = sentence_list.index(sentence)\n    # get the corresponding row in similarity matrix\n    similarity_row = np.array(similarity_matrix[index, :])\n    # get the indices of top similar\n    indices = similarity_row.argsort()[-topN:][::-1]\n    return [sentence_list[i] for i in indices]\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Find similar job descriptions"},{"metadata":{"trusted":true},"cell_type":"code","source":"titles=df['description'].fillna(\"Unknown\")\nembed_vectors=embed(titles.values).numpy()\nsentence_list=titles.values.tolist()\nsentence=titles.iloc[1]\nprint(\"Find similar research papers for :\")\nprint(sentence)\n\nsimilarity_matrix=prepare_similarity(embed_vectors)\nsimilar=get_top_similar(sentence,sentence_list,similarity_matrix,6)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for sentence in similar:\n    print(sentence)\n    print(\"\\n\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Find similar job requirements (Combined)"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def prepare_similarity(vectors):\n    similarity=cosine_similarity(vectors)\n    return similarity\n\ndef get_top_similar(sentence, sentence_list, similarity_matrix, topN):\n    # find the index of sentence in list\n    index = sentence_list.index(sentence)\n    # get the corresponding row in similarity matrix\n    similarity_row = np.array(similarity_matrix[index, :])\n    # get the indices of top similar\n    indices = similarity_row.argsort()[-topN:][::-1]\n    return [sentence_list[i] for i in indices]\n\n\n\ncom=df['combined_text'].fillna(\"Unknown\")\nembed_vectors=embed(com.values).numpy()\nsentence_list=com.values.tolist()\nsentence=com.iloc[5]\nprint(\"Find similar requirements in the job post\")\nprint(sentence)\nsimilarity_matrix=prepare_similarity(embed_vectors)\nsimilar=get_top_similar(sentence,sentence_list,similarity_matrix,10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for sentence in similar:\n    print(sentence)\n    print(\"\\n\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}