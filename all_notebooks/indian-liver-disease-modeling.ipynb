{"metadata":{"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"nbconvert_exporter":"python","file_extension":".py","version":"3.6.1","name":"python","pygments_lexer":"ipython3","mimetype":"text/x-python"},"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"}},"nbformat_minor":1,"cells":[{"metadata":{"_uuid":"c36ae967084875d3354ac47cd4f20eba9150e8d8","_cell_guid":"87ecb2d7-4902-4928-b8e9-c76aba954697"},"cell_type":"markdown","source":"# Liver Disease Prediction <a class=\"anchor\" id=\"top\"></a>\n\n**Background** \n\n> Patients with Liver disease have been continuously increasing because of excessive consumption of alcohol, inhale of harmful gases, intake of contaminated food, pickles and drugs. This dataset was used to evaluate prediction algorithms in an effort to reduce burden on doctors.\n\nThis notebook will explore the provided data and use these data to build the predictive model, which will hopefully help the doctor or any individual to diagnose the liver disease.\n\nThe notebook will be divided into outlined section.\n\n### Table of Contents:\n* [1. Read the data](#read-data)\n* [2. Exploratory Analysis](#eda)\n* [3. Predictive Modeling](#model)\n\n"},{"metadata":{"_uuid":"99dd7882cdbe11d00fb46f206a990499fb26ab11","_cell_guid":"068c6902-f18a-48fb-8122-d570386449cb"},"outputs":[],"cell_type":"code","source":"from IPython.display import HTML\n\nHTML('''<script>\ncode_show=true; \nfunction code_toggle() {\n if (code_show){\n $('div.input').hide();\n } else {\n $('div.input').show();\n }\n code_show = !code_show\n} \n$( document ).ready(code_toggle);\n</script>\n<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Toggle on/off the raw code.\"></form>''')","execution_count":82},{"metadata":{"_uuid":"4506f17c046b7dade3bb6a66bca2c9be2589920a","_cell_guid":"6f2f9bc3-27dc-41fb-ade3-c4823f62aaf3"},"outputs":[],"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\n%matplotlib inline\n\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.graph_objs as go\n\nimport seaborn as sns\nsns.set(style=\"white\", palette=\"muted\", color_codes=True)\n\ninit_notebook_mode()","execution_count":83},{"metadata":{"_uuid":"0960e52c27d0095fe4e0e224d14a6257300cd339","_cell_guid":"58f57ee8-7b2e-4249-82ef-5c29d5038718"},"cell_type":"markdown","source":"## 1. Read the data <a class=\"anchor\" id=\"read-data\"></a>\n\nIn this section, data is being read in and quickly looking at the top 2 rows of the data."},{"metadata":{"_uuid":"fe1bb092cb00ad314170ef07111223a79cd303e0","_cell_guid":"29780c29-0374-4918-9710-7f7994f98694"},"outputs":[],"cell_type":"code","source":"data = pd.read_csv(\"../input/indian_liver_patient.csv\", low_memory=False)\ndata.head(2)","execution_count":84},{"metadata":{"_uuid":"a05f090c0cc4ff8db416554786434e90ce8334fd","_cell_guid":"bcfa54d3-cc4d-4282-9e74-62fb8f260730"},"cell_type":"markdown","source":"How clean is the data, is there any missing values?"},{"metadata":{"_uuid":"875f10c4485af6f8aff768b3f49c7f772f98e93c","_cell_guid":"d3110013-1d8f-4e00-bd58-7a9872772221"},"outputs":[],"cell_type":"code","source":"def missing_values_table(df): \n    mis_val = df.isnull().sum()\n    mis_val_percent = 100 * df.isnull().sum()/len(df)\n    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n    mis_val_table_ren_columns = mis_val_table.rename(columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n    return mis_val_table_ren_columns \n    \nmissing_values_table(data)","execution_count":85},{"metadata":{"_uuid":"f55a1063a92576728f96abe2fba6e1b24eeca146","_cell_guid":"ab0c79f5-b7ab-475b-afb8-939bcad66a8b"},"cell_type":"markdown","source":"There are only 4 rows of data with missing values in **Albumin_and_Globulin_Ratio** column. \nLet's quickly see those records."},{"metadata":{"_uuid":"707412d810bdb39009847389ba3c6871a434fdf2","_cell_guid":"d93aee01-7073-4e59-83c4-821ca38d4ca2"},"outputs":[],"cell_type":"code","source":"data.loc[data['Albumin_and_Globulin_Ratio'].isnull()]","execution_count":86},{"metadata":{"_uuid":"bacc7e8102675d857bfa4476fb0bb05eefc82f6d","_cell_guid":"9a11a883-cb46-4bb3-8a0f-2222d3354be2"},"cell_type":"markdown","source":"The quick statistic data of the each column."},{"metadata":{"_uuid":"77de5debf8ffd5cb680514595417f02bce14b449","_cell_guid":"c1a31685-74b7-4bff-b6e7-24a92ad434be"},"outputs":[],"cell_type":"code","source":"data.describe()","execution_count":87},{"metadata":{"_uuid":"f295c653602315eec9fbfd980f1c7038a3f288a8","_cell_guid":"ba904bcd-dae0-4a1a-b176-847e30e90861"},"cell_type":"markdown","source":"From the data description, we know that there are 416 liver patient records and 167 non liver patient records collected from North East of Andhra Pradesh, India. We will check which values are representing the target and non-target label."},{"metadata":{"_uuid":"78162a6e78e1d051d0bf1f50d6bc46e57f1ef6a5","_cell_guid":"8ce5651b-aa7f-41da-a24c-b906fa7e7b69"},"outputs":[],"cell_type":"code","source":"sizing = data.groupby(['Dataset']).size().reset_index(name='Counts')\nsizing['Percent'] = sizing['Counts']/sum(sizing['Counts']) * 100\nsizing","execution_count":88},{"metadata":{"_uuid":"6a544d37aa492c861df699917251e55c8b079dc9","_cell_guid":"9026cfde-0375-480b-bf05-66f8997d7a0f"},"cell_type":"markdown","source":"### [Go to top](#top)\n\n## 2. Exploratory Analysis <a class=\"anchor\" id=\"eda\"></a>\n\nIn this section, I will look deeper onto the data and provide any visualization to help understanding of each variable and its relationship."},{"metadata":{"_uuid":"f455bf71c27cafa8f7bef9245d2ec78198cbbbd7","collapsed":true,"_cell_guid":"00f07867-3478-4acb-b16e-26f6b9ee44b4"},"outputs":[],"cell_type":"code","source":"gender_sizing = data.groupby(['Gender']).size().reset_index(name='Counts')\ngender_sizing['Percent'] = gender_sizing['Counts']/sum(gender_sizing['Counts']) * 100\ngender_sizing['Text'] = gender_sizing['Gender'] + \": \" + round(gender_sizing['Percent'], 1).astype(str) + \"%\"","execution_count":89},{"metadata":{"_uuid":"4664d5d7062f0d9cf85863941e15c711423f3b3f","_cell_guid":"de67c82a-27d2-4de3-82d6-b7f192828d43"},"outputs":[],"cell_type":"code","source":"import plotly.tools as tls\n\nfig = tls.make_subplots(rows=5, cols=2)\nfig.append_trace({'y': data['Age'], \n                  'type': 'box', \n                  'name': 'Total Age'}, 1, 1)\nfig.append_trace({'x': gender_sizing['Gender'], 'y': gender_sizing['Counts'], \n                  'type': 'bar', 'text': gender_sizing['Text'],\n                  'name': 'Gender', 'marker': dict(color=['red', 'blue'])}, 1, 2)\nfig.append_trace({'y': data['Total_Bilirubin'], \n                  'type': 'box', 'name': 'Total Bilirubin'}, 2, 1)\nfig.append_trace({'y': data['Direct_Bilirubin'], \n                  'type': 'box', 'name': 'Direct Bilirubin'}, 2, 2)\nfig.append_trace({'y': data['Alkaline_Phosphotase'], \n                  'type': 'box', 'name': 'Alkaline Phosphotase'}, 3, 1)\nfig.append_trace({'y': data['Alamine_Aminotransferase'], \n                  'type': 'box', 'name': 'Alamine Aminotransferase'}, 3, 2)\nfig.append_trace({'y': data['Aspartate_Aminotransferase'], \n                  'type': 'box', 'name': 'Aspartate Aminotransferase'}, 4, 1)\nfig.append_trace({'y': data['Total_Protiens'], \n                  'type': 'box', 'name': 'Total Proteins'}, 4, 2)\nfig.append_trace({'y': data['Albumin'], \n                  'type': 'box', 'name': 'Albumin'}, 5, 1)\nfig.append_trace({'y': data['Albumin_and_Globulin_Ratio'], \n                  'type': 'box', 'name': 'Ratio of Albumin & Globulin'}, 5, 2)\n    \nfig['layout'].update(height=800, width=700, title='All features Visualizations')\niplot(fig, filename='all-features-visualization')    ","execution_count":90},{"metadata":{"_uuid":"7d9f904154fb0b5e58898d2008ac5d59a8291e44","_cell_guid":"519ebdf7-24c0-4645-b9d6-3a1a92c7e11f"},"cell_type":"markdown","source":"The correlation of all variables (without any transformation)."},{"metadata":{"_uuid":"7f25e83f455a8773918ed7987743cd4d9bdee0c5","collapsed":true,"_cell_guid":"a75db6b2-27be-435c-beb9-f13c0eee1ffd"},"outputs":[],"cell_type":"code","source":"corr = data[data.columns].corr()","execution_count":91},{"metadata":{"_uuid":"7569e2540d132150a8d3ad9ba0608a9dec22dff3","_cell_guid":"2cfc9848-1c76-41e5-b674-711398343704"},"outputs":[],"cell_type":"code","source":"sns.heatmap(corr, annot = True)","execution_count":92},{"metadata":{},"cell_type":"markdown","source":"### [Go to top](#top)"},{"metadata":{},"cell_type":"markdown","source":"## 3. Predictive Modeling <a class=\"anchor\" id=\"model\"></a>\n\n#### Data Preparation\n\nAs per initial analysis, there are 4 missing values, I will fix the missing values with the median value of that column."},{"metadata":{},"outputs":[],"cell_type":"code","source":"data = data.where(pd.notnull(data), data.median(), axis='columns')\ndata.isnull().sum()","execution_count":93},{"metadata":{},"cell_type":"markdown","source":"Next, I will standardize the data, except the Age and Gender variables, using min / max scaler. \n\nI will also encode the Gender variables."},{"metadata":{},"outputs":[],"cell_type":"code","source":"from sklearn import preprocessing\ncol_name = data.iloc[:, 2:len(data.columns)-1].columns.tolist()\nmin_max_scaler = preprocessing.MinMaxScaler()\nnp_scaled = min_max_scaler.fit_transform(data.iloc[:, 2:len(data.columns)-1])\ndf_normalized = pd.DataFrame(np_scaled)\ndf_normalized.columns = col_name\n\n# One hot encoding and drop the first column to prevent dummy trap variable\ngender_df = data.iloc[:,1]\ngender_df = pd.get_dummies(gender_df, prefix='Gender', drop_first=True)","execution_count":94},{"metadata":{},"cell_type":"markdown","source":"Combine all dataframes (age, gender and normalized features) to one and visualize them."},{"metadata":{"scrolled":true},"outputs":[],"cell_type":"code","source":"my_df = pd.concat([gender_df, data.iloc[:, 0], df_normalized, data.iloc[:, len(data.columns)-1]], axis = 1)","execution_count":95},{"metadata":{},"outputs":[],"cell_type":"code","source":"fig = tls.make_subplots(rows=5, cols=2)\nfig.append_trace({'y': my_df['Age'], \n                  'type': 'box', \n                  'name': 'Total Age'}, 1, 1)\nfig.append_trace({'x': my_df['Gender_Male'],  \n                  'type': 'histogram', \n                  'name': 'Gender', 'marker': dict(color=['red', 'blue'])}, 1, 2)\nfig.append_trace({'y': my_df['Total_Bilirubin'], \n                  'type': 'box', 'name': 'Total Bilirubin'}, 2, 1)\nfig.append_trace({'y': my_df['Direct_Bilirubin'], \n                  'type': 'box', 'name': 'Direct Bilirubin'}, 2, 2)\nfig.append_trace({'y': my_df['Alkaline_Phosphotase'], \n                  'type': 'box', 'name': 'Alkaline Phosphotase'}, 3, 1)\nfig.append_trace({'y': my_df['Alamine_Aminotransferase'], \n                  'type': 'box', 'name': 'Alamine Aminotransferase'}, 3, 2)\nfig.append_trace({'y': my_df['Aspartate_Aminotransferase'], \n                  'type': 'box', 'name': 'Aspartate Aminotransferase'}, 4, 1)\nfig.append_trace({'y': my_df['Total_Protiens'], \n                  'type': 'box', 'name': 'Total Proteins'}, 4, 2)\nfig.append_trace({'y': my_df['Albumin'], \n                  'type': 'box', 'name': 'Albumin'}, 5, 1)\nfig.append_trace({'y': my_df['Albumin_and_Globulin_Ratio'], \n                  'type': 'box', 'name': 'Ratio of Albumin & Globulin'}, 5, 2)\n    \nfig['layout'].update(height=800, width=700, title='All features Visualizations after normalization')\niplot(fig, filename='all-norm-features-visualization')  ","execution_count":96},{"metadata":{},"cell_type":"markdown","source":"How does the final dataframe look?"},{"metadata":{},"outputs":[],"cell_type":"code","source":"my_df.head(2)","execution_count":100},{"metadata":{},"cell_type":"markdown","source":"Correlation matrix (removing the target label)."},{"metadata":{},"outputs":[],"cell_type":"code","source":"sns.heatmap(my_df[my_df.columns[:len(my_df.columns)-1]].corr(),annot=True,cmap='RdYlGn')\nfig=plt.gcf()\nfig.set_size_inches(10,8)\nplt.show();","execution_count":118},{"metadata":{},"cell_type":"markdown","source":"#### Machine Learning\n\nIn this section, let's predict the target labels (liver disease) using various machine learning algorithm and see if we can find the best one.\n"},{"metadata":{},"outputs":[],"cell_type":"code","source":"from sklearn.model_selection import train_test_split, KFold\nfrom sklearn import svm\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics","execution_count":106},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","source":"train, test = train_test_split(my_df,\n                            test_size = 0.3,\n                            random_state = 0,\n                            stratify = my_df['Dataset'])\ntrain_X = train[train.columns[:len(train.columns)-1]]\ntest_X = test[test.columns[:len(test.columns)-1]]\ntrain_Y = train['Dataset']\ntest_Y = test['Dataset'] ","execution_count":109},{"metadata":{},"outputs":[],"cell_type":"code","source":"types=['rbf','linear', 'sigmoid']\nfor i in types:\n    model = svm.SVC(kernel=i, random_state=0)\n    model.fit(train_X,train_Y)\n    prediction = model.predict(test_X)\n    print('Accuracy for SVM kernel =',i,'is',metrics.accuracy_score(prediction,test_Y))\n    print('F1 score for SVM kernel =', i, ' is ', metrics.f1_score(prediction, test_Y))","execution_count":113},{"metadata":{},"outputs":[],"cell_type":"code","source":"model = LogisticRegression()\nmodel.fit(train_X,train_Y)\nprediction=model.predict(test_X)\nprint('The accuracy of the Logistic Regression is',metrics.accuracy_score(prediction,test_Y))\nprint('The F1 score of the Logistic Regression is',metrics.f1_score(prediction,test_Y))","execution_count":114},{"metadata":{},"outputs":[],"cell_type":"code","source":"model=DecisionTreeClassifier()\nmodel.fit(train_X,train_Y)\nprediction=model.predict(test_X)\nprint('The accuracy of the Decision Tree is',metrics.accuracy_score(prediction,test_Y))\nprint('The F1 score of the Decision Tree is',metrics.f1_score(prediction,test_Y))","execution_count":115},{"metadata":{},"outputs":[],"cell_type":"code","source":"model = RandomForestClassifier(n_estimators=100,random_state=0)\nmodel.fit(train_X, train_Y)\nprediction = model.predict(test_X)\nprint('The accuracy of the Random Forest is',metrics.accuracy_score(prediction,test_Y))\nprint('The F1 score of the Random Forest is',metrics.f1_score(prediction,test_Y))\n\nprint(pd.Series(model.feature_importances_,index=train_X.columns).sort_values(ascending=False))","execution_count":124},{"metadata":{"_uuid":"7241ea1e9fd53a8200c0b2c6f18e8fc127a13116","_cell_guid":"cdbda61d-bd2a-4960-80ec-958a6db8d3ca"},"cell_type":"markdown","source":"### TBC"},{"metadata":{},"cell_type":"markdown","source":""}],"nbformat":4}