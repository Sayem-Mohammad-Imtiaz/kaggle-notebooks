{"cells":[{"metadata":{"_uuid":"a92c8f141999550c2331d2dd30b3cf783001f370"},"cell_type":"markdown","source":"# Gensim NLP Seq2Seq with Attention\n### Overview\nThis kernel works on Ubuntu Dialogues Dataset and we shall compare the words preprocessing algorithms:\n1. Dictionary Token 2 Index\n2. Word2Vec Word Embeddings\n3. FastText Word Embeddings ( Skip Gram )\nThen train Sequence to Sequence model with Attention on the preprocessed dataset.\n\nReference for Concepts & Theories:\n* https://machinelearningmastery.com/encoder-decoder-attention-sequence-to-sequence-prediction-keras/\n* https://towardsdatascience.com/word-embedding-with-word2vec-and-fasttext-a209c1d3e12c"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"## Load DataSet"},{"metadata":{"trusted":true,"_uuid":"ca8d7db665580f6d8377e477a6f8eb89f6816b0f"},"cell_type":"markdown","source":"The Dataset: Ubuntu Dialogue Corpus\n26 million turns from natural two-person dialogues <a href=\"https://www.kaggle.com/rtatman/ubuntu-dialogue-corpus\" target=\"_blank\">view details</a>"},{"metadata":{"trusted":true,"_uuid":"7d00ce07bfb945c4e8eb8d7f7ef90e047d1ac9e3"},"cell_type":"code","source":"# Inspect data directory\nprint(os.listdir(\"../input/Ubuntu-dialogue-corpus\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c92895f488aa639b92b8d5f083c49fae3958d065"},"cell_type":"code","source":"# Inspect file structure\npd.read_csv(\"../input/toc.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6aa310e393b18a281cdbeee73dec27d70ab5368e"},"cell_type":"code","source":"# inspect dialogue text\ndf = pd.read_csv(\"../input/Ubuntu-dialogue-corpus/dialogueText.csv\", encoding='utf-8')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61cb4d71333405c29fa0dc8fca22fc1fb9bdf433"},"cell_type":"code","source":"# inspect single dialogue\ndf.loc[df.dialogueID == '65545.tsv']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0f7bac1f78eb94478e2485a5af78477d0a8ca63d"},"cell_type":"markdown","source":"## Install Gensim"},{"metadata":{"trusted":true,"_uuid":"7f1a6496bdf801c837021ad7a1748abb811465df"},"cell_type":"code","source":"!pip install gensim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"736e261a04614698182be3f1c4b40f8e92074736"},"cell_type":"code","source":"# import gensim modules\nfrom gensim import corpora\nfrom gensim import utils","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"57886eec01eba09673a5e096f2cdb3a36b001187"},"cell_type":"markdown","source":"## Create Vocabulary"},{"metadata":{"trusted":true,"_uuid":"aee16fafbc053d7f5aea4769d23232e4ed3b78e7"},"cell_type":"code","source":"# Convert to lower case, ensure string conversion, exract tokens, & build dictionary\ndf.text = df.text.str.lower()\nlines = [str(l) for l in df.text.values]\ntokens = [list(utils.tokenize(t)) for t in lines]\nvocabs = corpora.Dictionary(tokens)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac2468baadd9932ec9edbfc3c89ec4d08d6870a4"},"cell_type":"markdown","source":"## Verify Tokens to Index ( # of features = 1 )"},{"metadata":{"trusted":true,"_uuid":"e1801346023389f224ce90f42de9dd524d0ab858"},"cell_type":"code","source":"vocabs.token2id[\"channel\"]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"621c3ad1f24e942599ef1e0830679c17b9105aed"},"cell_type":"markdown","source":"## Extract Word Embeddings ( # of features = 100 )"},{"metadata":{"trusted":true,"_uuid":"9be760fcb20ebb935c7b4a74da68e0132868ee2e"},"cell_type":"code","source":"from gensim.models import Word2Vec","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0af9f44c7392cf2f1f070828250c74bfe1f3c16"},"cell_type":"code","source":"model = Word2Vec(tokens, size=100, window=5, min_count=1, workers=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"675912211fc49561fa86dfa898b4b8c438f83e20"},"cell_type":"code","source":"model.wv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c08cd4e8b79436e93fb54c4871f5d7b1598f20a1"},"cell_type":"code","source":"model.corpus_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec90f6a0f759aab746760680fd9fa9168df36166"},"cell_type":"code","source":"model.corpus_total_words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a12c13f9af64cf1d6c3233c872b8dd1e11023cc"},"cell_type":"code","source":"model.vocabulary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"727d4d0c18415b8c9f2a16a63dca654bb0b45810"},"cell_type":"code","source":"model.wv.vectors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f6a7b0900de19fcedf4c048208327e6496d31112"},"cell_type":"code","source":"model.wv.vectors.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"58e10cd8c2f4364707c756882817aa32deb5b508"},"cell_type":"code","source":"model.wv['hello']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5824a7438c021e2c5ad49fb740b6e6730815eaa4"},"cell_type":"markdown","source":"## FastText ( # of Features = 100 )"},{"metadata":{"trusted":true,"_uuid":"bf085b041fbaea1adfc3d16a1e94685163a12737"},"cell_type":"code","source":"from gensim.models import FastText","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"55d9ac58de45addc03964bfec8dd091b6ed9ad5b"},"cell_type":"code","source":"model = FastText(tokens, size=100, window=5, min_count=1, iter=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d374b4a239541c149a4b6a8319d85dbfe7dae4d"},"cell_type":"code","source":"model.wv[\"channel\"]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b50ef6efe4f596d4dc07d3d52c2ff8df75b717d"},"cell_type":"markdown","source":"## Preprocess Dataset\n* sort dataset by date and dialogue id\n* concat several sentences in row from same person, for example if A says xxx and then says yyyy before B replies, then concat [xxxx yyyy]\n* roll questions as inputs and answers as outputs in columns\n* mark end of sentences EOS\n* pad all inputs and outputs of fixed length, and mark paddings as PAD"},{"metadata":{"_uuid":"c781dcf89e549cf053f427e6d444ecdbd640da78"},"cell_type":"markdown","source":"### Sorting"},{"metadata":{"trusted":true,"_uuid":"f2adc044bb66f78674121d5435b8480fe4c48b54"},"cell_type":"code","source":"df.head() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8635d8456739bab59f93d74bc06aff67a7cbf172"},"cell_type":"code","source":"df = df.sort_values(['dialogueID', 'date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"593ecace78a75f138a1a47dcb399d8cae90256c3"},"cell_type":"code","source":"df.head() ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e4f40381257fc062acfb20aed2c04300094c933d"},"cell_type":"markdown","source":"### Concatenation"},{"metadata":{"trusted":true,"_uuid":"970f21a22ceb73fd155d00e81aa5ac22cfe2800a"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"346c0035fc4e5298beecfc6be922e21b7765d5e1"},"cell_type":"markdown","source":"#### What should be concatenated?"},{"metadata":{"trusted":true,"_uuid":"cf752fbac1f3a34cc97574e016df3d9da7fba585"},"cell_type":"code","source":"from_step = df[\"from\"].values\nfrom_step[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0142e8e24e05099eb89b7387f9a7fcf36dfaf1e"},"cell_type":"code","source":"from_next = df[\"from\"].shift(-1).values\nfrom_next[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01ca595cce34b40537a3daac80d0188ba34338b7"},"cell_type":"code","source":"indices_prev = df.index.values\nindices_next = [ix + 1 for ix in df.index.values]\nfrom_step = df[\"from\"].values\nfrom_next = df[\"from\"].shift(-1).values\n\nindices_to_concat = []\nprint_five = 5\nfor idx_prev, idx_next, rec_prev, rec_next in zip(indices_prev, indices_next, from_step, from_next):\n    if rec_prev == rec_next:\n        indices_to_concat.append((idx_prev, idx_next))\n        if print_five > 0:\n            print(idx_prev, rec_prev, idx_next, rec_next)\n            print_five -= 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e8b8629cbc1829dac6da72e0a39e07654e0481eb"},"cell_type":"markdown","source":"#### Let's concatenate!"},{"metadata":{"trusted":true,"_uuid":"79a0cc67c5eb1694c7d498e1f7089928b1ce394c"},"cell_type":"code","source":"# Verify assumption\nfor x, y in indices_to_concat:\n    assert df.iloc[x]['from'] == df.iloc[y]['from'], \"Sender Mismatch Error {} & {} @ Index: {} & {}\".format(df.iloc[x]['from'], df.iloc[y]['from'], x, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3cd4d48d5b685d3a4bd849cbb8e2fb95c809a08"},"cell_type":"code","source":"df.index.isin(indices_to_concat)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"866e1bfbc5e45aeb82cbeb77805beec0c4c58067"},"cell_type":"markdown","source":"### Rolling Questions & Answers"},{"metadata":{"trusted":true,"_uuid":"a9b50e64e54c3a8be3d95c6ac4863142ba60ee3f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9ce324a6c736e4ce588993499396eb52c80b2dce"},"cell_type":"markdown","source":"## Version (1):  Prepare Dataset ( Dictionary Word2ID ) \n"},{"metadata":{"_uuid":"504eab9bfa0000e0ed210e13ce1c2ae9028d77f3"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"d05d6d3a2eea39f46e117571d08ffdb161b9e824"},"cell_type":"markdown","source":"## Version (2):  Prepare Dataset ( Embeddings Word2Vec ) "},{"metadata":{"_uuid":"018fac17c007dc3406d85bc1d55972e76f41896d"},"cell_type":"markdown","source":"## Version (3):  Prepare Dataset ( Embeddings FastText ) "},{"metadata":{"_uuid":"5e3d1f958885302b10b81732699505ffed86461d"},"cell_type":"markdown","source":"## Attention Model Implementation\n### Reference: https://machinelearningmastery.com/encoder-decoder-attention-sequence-to-sequence-prediction-keras/"},{"metadata":{"trusted":true,"_uuid":"49f0bb5368b9a2e8ad55f8425970dc089b8c3374"},"cell_type":"code","source":"from random import randint\nfrom numpy import array\nfrom numpy import argmax\nfrom numpy import array_equal\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\nfrom keras.layers import TimeDistributed\nfrom keras.layers import RepeatVector\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras import regularizers, constraints, initializers, activations\nfrom keras.layers.recurrent import Recurrent\nfrom keras.engine import InputSpec\n\n\ndef _time_distributed_dense(x, w, b=None, dropout=None,\n                           input_dim=None, output_dim=None, timesteps=None):\n    '''Apply y.w + b for every temporal slice y of x.\n    '''\n    if not input_dim:\n        # won't work with TensorFlow\n        input_dim = K.shape(x)[2]\n    if not timesteps:\n        # won't work with TensorFlow\n        timesteps = K.shape(x)[1]\n    if not output_dim:\n        # won't work with TensorFlow\n        output_dim = K.shape(w)[1]\n\n    if dropout:\n        # apply the same dropout pattern at every timestep\n        ones = K.ones_like(K.reshape(x[:, 0, :], (-1, input_dim)))\n        dropout_matrix = K.dropout(ones, dropout)\n        expanded_dropout_matrix = K.repeat(dropout_matrix, timesteps)\n        x *= expanded_dropout_matrix\n\n    # collapse time dimension and batch dimension together\n    x = K.reshape(x, (-1, input_dim))\n\n    x = K.dot(x, w)\n    if b:\n        x = x + b\n    # reshape to 3D tensor\n    x = K.reshape(x, (-1, timesteps, output_dim))\n    return x\n\n\ntfPrint = lambda d, T: tf.Print(input_=T, data=[T, tf.shape(T)], message=d)\n\nclass AttentionDecoder(Recurrent):\n\n    def __init__(self, units, output_dim,\n                 activation='tanh',\n                 return_probabilities=False,\n                 name='AttentionDecoder',\n                 kernel_initializer='glorot_uniform',\n                 recurrent_initializer='orthogonal',\n                 bias_initializer='zeros',\n                 kernel_regularizer=None,\n                 bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None,\n                 bias_constraint=None,\n                 **kwargs):\n        \"\"\"\n        Implements an AttentionDecoder that takes in a sequence encoded by an\n        encoder and outputs the decoded states\n        :param units: dimension of the hidden state and the attention matrices\n        :param output_dim: the number of labels in the output space\n\n        references:\n            Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio.\n            \"Neural machine translation by jointly learning to align and translate.\"\n            arXiv preprint arXiv:1409.0473 (2014).\n        \"\"\"\n        self.units = units\n        self.output_dim = output_dim\n        self.return_probabilities = return_probabilities\n        self.activation = activations.get(activation)\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.recurrent_initializer = initializers.get(recurrent_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.recurrent_regularizer = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.recurrent_constraint = constraints.get(kernel_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n\n        super(AttentionDecoder, self).__init__(**kwargs)\n        self.name = name\n        self.return_sequences = True  # must return sequences\n\n    def build(self, input_shape):\n        \"\"\"\n          See Appendix 2 of Bahdanau 2014, arXiv:1409.0473\n          for model details that correspond to the matrices here.\n        \"\"\"\n\n        self.batch_size, self.timesteps, self.input_dim = input_shape\n\n        if self.stateful:\n            super(AttentionDecoder, self).reset_states()\n\n        self.states = [None, None]  # y, s\n\n        \"\"\"\n            Matrices for creating the context vector\n        \"\"\"\n\n        self.V_a = self.add_weight(shape=(self.units,),\n                                   name='V_a',\n                                   initializer=self.kernel_initializer,\n                                   regularizer=self.kernel_regularizer,\n                                   constraint=self.kernel_constraint)\n        self.W_a = self.add_weight(shape=(self.units, self.units),\n                                   name='W_a',\n                                   initializer=self.kernel_initializer,\n                                   regularizer=self.kernel_regularizer,\n                                   constraint=self.kernel_constraint)\n        self.U_a = self.add_weight(shape=(self.input_dim, self.units),\n                                   name='U_a',\n                                   initializer=self.kernel_initializer,\n                                   regularizer=self.kernel_regularizer,\n                                   constraint=self.kernel_constraint)\n        self.b_a = self.add_weight(shape=(self.units,),\n                                   name='b_a',\n                                   initializer=self.bias_initializer,\n                                   regularizer=self.bias_regularizer,\n                                   constraint=self.bias_constraint)\n        \"\"\"\n            Matrices for the r (reset) gate\n        \"\"\"\n        self.C_r = self.add_weight(shape=(self.input_dim, self.units),\n                                   name='C_r',\n                                   initializer=self.recurrent_initializer,\n                                   regularizer=self.recurrent_regularizer,\n                                   constraint=self.recurrent_constraint)\n        self.U_r = self.add_weight(shape=(self.units, self.units),\n                                   name='U_r',\n                                   initializer=self.recurrent_initializer,\n                                   regularizer=self.recurrent_regularizer,\n                                   constraint=self.recurrent_constraint)\n        self.W_r = self.add_weight(shape=(self.output_dim, self.units),\n                                   name='W_r',\n                                   initializer=self.recurrent_initializer,\n                                   regularizer=self.recurrent_regularizer,\n                                   constraint=self.recurrent_constraint)\n        self.b_r = self.add_weight(shape=(self.units, ),\n                                   name='b_r',\n                                   initializer=self.bias_initializer,\n                                   regularizer=self.bias_regularizer,\n                                   constraint=self.bias_constraint)\n\n        \"\"\"\n            Matrices for the z (update) gate\n        \"\"\"\n        self.C_z = self.add_weight(shape=(self.input_dim, self.units),\n                                   name='C_z',\n                                   initializer=self.recurrent_initializer,\n                                   regularizer=self.recurrent_regularizer,\n                                   constraint=self.recurrent_constraint)\n        self.U_z = self.add_weight(shape=(self.units, self.units),\n                                   name='U_z',\n                                   initializer=self.recurrent_initializer,\n                                   regularizer=self.recurrent_regularizer,\n                                   constraint=self.recurrent_constraint)\n        self.W_z = self.add_weight(shape=(self.output_dim, self.units),\n                                   name='W_z',\n                                   initializer=self.recurrent_initializer,\n                                   regularizer=self.recurrent_regularizer,\n                                   constraint=self.recurrent_constraint)\n        self.b_z = self.add_weight(shape=(self.units, ),\n                                   name='b_z',\n                                   initializer=self.bias_initializer,\n                                   regularizer=self.bias_regularizer,\n                                   constraint=self.bias_constraint)\n        \"\"\"\n            Matrices for the proposal\n        \"\"\"\n        self.C_p = self.add_weight(shape=(self.input_dim, self.units),\n                                   name='C_p',\n                                   initializer=self.recurrent_initializer,\n                                   regularizer=self.recurrent_regularizer,\n                                   constraint=self.recurrent_constraint)\n        self.U_p = self.add_weight(shape=(self.units, self.units),\n                                   name='U_p',\n                                   initializer=self.recurrent_initializer,\n                                   regularizer=self.recurrent_regularizer,\n                                   constraint=self.recurrent_constraint)\n        self.W_p = self.add_weight(shape=(self.output_dim, self.units),\n                                   name='W_p',\n                                   initializer=self.recurrent_initializer,\n                                   regularizer=self.recurrent_regularizer,\n                                   constraint=self.recurrent_constraint)\n        self.b_p = self.add_weight(shape=(self.units, ),\n                                   name='b_p',\n                                   initializer=self.bias_initializer,\n                                   regularizer=self.bias_regularizer,\n                                   constraint=self.bias_constraint)\n        \"\"\"\n            Matrices for making the final prediction vector\n        \"\"\"\n        self.C_o = self.add_weight(shape=(self.input_dim, self.output_dim),\n                                   name='C_o',\n                                   initializer=self.recurrent_initializer,\n                                   regularizer=self.recurrent_regularizer,\n                                   constraint=self.recurrent_constraint)\n        self.U_o = self.add_weight(shape=(self.units, self.output_dim),\n                                   name='U_o',\n                                   initializer=self.recurrent_initializer,\n                                   regularizer=self.recurrent_regularizer,\n                                   constraint=self.recurrent_constraint)\n        self.W_o = self.add_weight(shape=(self.output_dim, self.output_dim),\n                                   name='W_o',\n                                   initializer=self.recurrent_initializer,\n                                   regularizer=self.recurrent_regularizer,\n                                   constraint=self.recurrent_constraint)\n        self.b_o = self.add_weight(shape=(self.output_dim, ),\n                                   name='b_o',\n                                   initializer=self.bias_initializer,\n                                   regularizer=self.bias_regularizer,\n                                   constraint=self.bias_constraint)\n\n        # For creating the initial state:\n        self.W_s = self.add_weight(shape=(self.input_dim, self.units),\n                                   name='W_s',\n                                   initializer=self.recurrent_initializer,\n                                   regularizer=self.recurrent_regularizer,\n                                   constraint=self.recurrent_constraint)\n\n        self.input_spec = [\n            InputSpec(shape=(self.batch_size, self.timesteps, self.input_dim))]\n        self.built = True\n\n    def call(self, x):\n        # store the whole sequence so we can \"attend\" to it at each timestep\n        self.x_seq = x\n\n        # apply the a dense layer over the time dimension of the sequence\n        # do it here because it doesn't depend on any previous steps\n        # thefore we can save computation time:\n        self._uxpb = _time_distributed_dense(self.x_seq, self.U_a, b=self.b_a,\n                                             input_dim=self.input_dim,\n                                             timesteps=self.timesteps,\n                                             output_dim=self.units)\n\n        return super(AttentionDecoder, self).call(x)\n\n    def get_initial_state(self, inputs):\n        # apply the matrix on the first time step to get the initial s0.\n        s0 = activations.tanh(K.dot(inputs[:, 0], self.W_s))\n\n        # from keras.layers.recurrent to initialize a vector of (batchsize,\n        # output_dim)\n        y0 = K.zeros_like(inputs)  # (samples, timesteps, input_dims)\n        y0 = K.sum(y0, axis=(1, 2))  # (samples, )\n        y0 = K.expand_dims(y0)  # (samples, 1)\n        y0 = K.tile(y0, [1, self.output_dim])\n\n        return [y0, s0]\n\n    def step(self, x, states):\n\n        ytm, stm = states\n\n        # repeat the hidden state to the length of the sequence\n        _stm = K.repeat(stm, self.timesteps)\n\n        # now multiplty the weight matrix with the repeated hidden state\n        _Wxstm = K.dot(_stm, self.W_a)\n\n        # calculate the attention probabilities\n        # this relates how much other timesteps contributed to this one.\n        et = K.dot(activations.tanh(_Wxstm + self._uxpb),\n                   K.expand_dims(self.V_a))\n        at = K.exp(et)\n        at_sum = K.sum(at, axis=1)\n        at_sum_repeated = K.repeat(at_sum, self.timesteps)\n        at /= at_sum_repeated  # vector of size (batchsize, timesteps, 1)\n\n        # calculate the context vector\n        context = K.squeeze(K.batch_dot(at, self.x_seq, axes=1), axis=1)\n        # ~~~> calculate new hidden state\n        # first calculate the \"r\" gate:\n\n        rt = activations.sigmoid(\n            K.dot(ytm, self.W_r)\n            + K.dot(stm, self.U_r)\n            + K.dot(context, self.C_r)\n            + self.b_r)\n\n        # now calculate the \"z\" gate\n        zt = activations.sigmoid(\n            K.dot(ytm, self.W_z)\n            + K.dot(stm, self.U_z)\n            + K.dot(context, self.C_z)\n            + self.b_z)\n\n        # calculate the proposal hidden state:\n        s_tp = activations.tanh(\n            K.dot(ytm, self.W_p)\n            + K.dot((rt * stm), self.U_p)\n            + K.dot(context, self.C_p)\n            + self.b_p)\n\n        # new hidden state:\n        st = (1-zt)*stm + zt * s_tp\n\n        yt = activations.softmax(\n            K.dot(ytm, self.W_o)\n            + K.dot(stm, self.U_o)\n            + K.dot(context, self.C_o)\n            + self.b_o)\n\n        if self.return_probabilities:\n            return at, [yt, st]\n        else:\n            return yt, [yt, st]\n\n    def compute_output_shape(self, input_shape):\n        \"\"\"\n            For Keras internal compatability checking\n        \"\"\"\n        if self.return_probabilities:\n            return (None, self.timesteps, self.timesteps)\n        else:\n            return (None, self.timesteps, self.output_dim)\n\n    def get_config(self):\n        \"\"\"\n            For rebuilding models on load time.\n        \"\"\"\n        config = {\n            'output_dim': self.output_dim,\n            'units': self.units,\n            'return_probabilities': self.return_probabilities\n        }\n        base_config = super(AttentionDecoder, self).get_config()\n        return dict(list(base_config.items())) + list(config.items())\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"623de04b8d5ee0ccae3d06534a1ee0915ed89382"},"cell_type":"markdown","source":"## Attention Model Design"},{"metadata":{"trusted":true,"_uuid":"cc5003519d4815408012db451799b858b63e1c52"},"cell_type":"code","source":"# define the encoder-decoder with attention model\ndef attention_model(n_timesteps_in, n_features, o_features):\n    model = Sequential()\n    model.add(LSTM(150, input_shape=(n_timesteps_in, n_features), return_sequences=True))\n    model.add(AttentionDecoder(150, o_features))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f388b3885d177199e0df0d0800e762ca3d18d222"},"cell_type":"markdown","source":"## Version (1): Train Model with Dictionary"},{"metadata":{"trusted":true,"_uuid":"71316a85d5ad75ac520b2113fbe27222d82909f6"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0fada7eeefaf649a4949bd6f9a0b656ae985a0ab"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42c922690b40b984182cdbd11cf1656d6e87c202"},"cell_type":"markdown","source":"## Version (2): Train Model with Word2Vec Embeddings"},{"metadata":{"trusted":true,"_uuid":"6a72bfd70910df3766bdd27eaf1ffc6e1bc5de0e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8abccd47213af60edb8f313d70a39e5c027db65"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d88ab851be8e8a1e1f2d8c5d79dd9e9c35fb85f"},"cell_type":"markdown","source":"## Version (3): Train Model with FastText Embeddings"},{"metadata":{"trusted":true,"_uuid":"f97e83854c42a574e0612c75b13b3d2dd94cf2c6"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9429e522290514396e8282f78107de483987ce73"},"cell_type":"markdown","source":"## Compare Dictionary vs Word2Vec vs FastText Performance"},{"metadata":{"trusted":true,"_uuid":"3aa696fbbd7b9ff0a6c22ea9eef20a410dc8bcd1"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}