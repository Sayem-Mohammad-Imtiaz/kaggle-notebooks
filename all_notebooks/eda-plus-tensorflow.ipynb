{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\ndirect = \"\"\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        direct = os.path.join(dirname, filename)\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Gender: 0 - male; 1 - female\n\nEthnicity: 0 - white; 1 - afro-american; 2 - asian; 3 - indian (brown); 4 - unkown for me :D","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom PIL import Image\nfrom sklearn.metrics import confusion_matrix, plot_confusion_matrix\nfrom IPython.display import Image\nfrom skimage.transform import resize\nfrom skimage.io import imread, imshow","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(direct)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA for the data\n\nThis part is necessary for every project. You should know your data and the way of dependency of its features.  ","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize = (18, 8))\nfig.suptitle(\"Count for each label\")\n\nsns.countplot(ax = axes[0], x = df.ethnicity)\naxes[0].set_title(\"Ethnicity\")\n\nsns.countplot(ax = axes[1], x = df.gender)\naxes[1].set_title(\"Gender\")\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(18,8))\nsns.histplot(df.age, kde=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(18,8))\nsns.kdeplot(x=df.ethnicity)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We saw for the Ethnicity we have kinda unbalanced data but for gender prediction will not be a problem. \nBoth of those problems are classification ones but for age prediction we have rregression.\nFirst of all I saw really old people here but are they really that old or dataset mistake?\nShould i take them for training ?","metadata":{}},{"cell_type":"code","source":"df.age.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pixel_reshape(column):\n    column = np.array([x for x in column.str.split()], dtype =\"float32\")\n    column = np.reshape(column, (-1,48,48,1))\n    return np.array(column)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"old_people = df[df.age > 95]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oldImgs = pixel_reshape(old_people.pixels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oldImgs.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(1, 15):\n    plt.imshow(oldImgs[i], cmap = \"gray\")\n    plt.show()  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So for now we can see that they are actually old people but we have very few of them. We can se duplicated as well. Ether out regression model is going to be good on predicting the age are we are going to need data augmentation for those years.... ","metadata":{}},{"cell_type":"markdown","source":"#### Scale Data","metadata":{}},{"cell_type":"markdown","source":"### Age classification\ntrain, val, test split the data based on Gender","metadata":{}},{"cell_type":"code","source":"TRAIN_PCT = 0.8\nVAL_PCT = 0.1\nTEST_PCT = 0.1\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_stratify_split_by(df, category):\n    train_data = pd.DataFrame()\n    val_data = pd.DataFrame()\n    test_data = pd.DataFrame()\n    \n    for (label, group_img) in df.groupby(category):\n        group_img = group_img.sample(len(group_img), random_state=24)\n\n        train_data_end_index = int(len(group_img) * TRAIN_PCT)\n        val_data_end_index = train_data_end_index + int(len(group_img) * VAL_PCT)\n\n\n        train_data_in_group = group_img[:train_data_end_index]\n        val_data_in_group = group_img[train_data_end_index:val_data_end_index]\n        test_data_in_group = group_img[val_data_end_index :]\n\n        print(len(train_data_in_group), len(val_data_in_group), len(test_data_in_group))\n\n        train_data = train_data.append(train_data_in_group)\n        val_data = val_data.append(val_data_in_group)\n        test_data = test_data.append(test_data_in_group)\n    return train_data, val_data, test_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data, val_data, test_data = get_stratify_split_by(df, \"gender\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.ethnicity.value_counts(), val_data.ethnicity.value_counts(), test_data.ethnicity.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.shape, val_data.shape, test_data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = (pixel_reshape(train_data.pixels)) / 255\nX_val = (pixel_reshape(val_data.pixels)) / 255\nX_test = (pixel_reshape(test_data.pixels)) / 255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_one = Sequential([\n    Conv2D(16, padding=\"same\", kernel_size=(2, 2), input_shape=((48,48,1))),\n    MaxPool2D((2, 2)),\n    Conv2D(32, kernel_size=(3, 3), padding=\"same\"),\n    MaxPool2D((2, 2)),\n    Conv2D(64, kernel_size=(3, 3), padding=\"valid\"),\n    Flatten(),\n    Dense(64, activation=\"relu\"),\n    Dropout(0.2),\n    Dense(1, activation=\"sigmoid\")\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_one.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_one.compile(optimizer=Adam(learning_rate=0.001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_one_hist = model_one.fit(X_train, train_data.gender, batch_size=64, epochs=8, validation_data=(X_val, val_data.gender))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(model_one_hist.history['loss'])\nplt.plot(model_one_hist.history['val_loss'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(model_one_hist.history['accuracy'])\nplt.plot(model_one_hist.history['val_accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_one.evaluate(X_test, test_data.gender)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = [np.round(i, 0) for i in model_one.predict(X_test)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(confusion_matrix(test_data.gender, preds), annot=True, fmt=\"d\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(6):\n    pic = X_test[i] * 255\n    plt.title(f\"True label: {test_data.gender.iloc[i]}, Predicted label: {preds[i]}\")\n    plt.imshow(pic)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ethnicity","metadata":{}},{"cell_type":"code","source":"model_two = Model(inputs=model_one.input, outputs=model_one.layers[-2].output)\nmodel_two = Sequential([\n    model_two,\n    Dense(len(set(train_data.ethnicity)), activation =  \"softmax\")\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_two.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_two.compile(optimizer=Adam(), loss = \"sparse_categorical_crossentropy\", metrics = ['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_two_hist = model_two.fit(X_train, train_data.ethnicity,\n                               batch_size=64, epochs=16,\n                               validation_data=(X_val, val_data.ethnicity),\n                               callbacks=[EarlyStopping(patience=2, restore_best_weights=True, monitor=\"val_accuracy\")])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(model_two_hist.history['loss'])\nplt.plot(model_two_hist.history['val_loss'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(model_two_hist.history['accuracy'])\nplt.plot(model_two_hist.history['val_accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_two.evaluate(X_test, test_data.ethnicity)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = [np.argmax(i) for i in model_two.predict(X_test)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(confusion_matrix(test_data.ethnicity, preds), annot=True, fmt=\"d\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For now we saw that the most common class is the most reconised by the model and we have 0 correct prediction of the 4th one. ","metadata":{}},{"cell_type":"markdown","source":"### AGE PREDICTION","metadata":{}},{"cell_type":"code","source":"age_prediciton_model = Sequential([\n    Conv2D(16, padding=\"same\", kernel_size=(2, 2), input_shape=((48,48,1))),\n    MaxPool2D((2, 2)),\n    Conv2D(32, kernel_size=(3, 3), padding=\"same\"),\n    Conv2D(32, kernel_size=(3, 3), padding=\"same\"),\n    MaxPool2D((2, 2)),\n    Conv2D(64, kernel_size=(3, 3), padding=\"valid\"),\n    Conv2D(64, kernel_size=(3, 3), padding=\"valid\"),\n    BatchNormalization(),\n    Flatten(),\n    Dense(64, activation=\"relu\"),\n    Dropout(0.2),\n    Dense(256, activation=\"relu\"),\n    Dropout(0.5),\n    Dense(1, activation=\"linear\")\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"age_prediciton_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"age_prediciton_model.compile(optimizer=Adam(), loss=\"mean_absolute_error\", metrics=['mean_absolute_error'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"age_prediciton_model.fit(X_train, train_data.age,\n                               batch_size=120, epochs=12,\n                               validation_data=(X_val, val_data.age))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"age_prediciton_model.evaluate(X_test, test_data.age)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = age_prediciton_model.predict(X_test)\n\nfor i in range(20):\n    print(f\"True age: {test_data.age.iloc[i]} vs Predicted_age: {int(preds[i])}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the end we saw how to create classification and regression models.\nGender model accuracy is nearly 89% and the age prediction with 7 MAE.\n\nThe thing is that those pictures were zoomed and most of them missed the hair factor. If we had pics with hair maby our models would be better at predicting (or worse if whe have High bias for women with long hair).\n\nThe ethnicity didn't do as well as I would like, but maby some Image augmentation would do a little bit better.\nI will continue to edit this notebook with more text... (to be continue.. :) )","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}