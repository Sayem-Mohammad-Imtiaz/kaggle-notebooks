{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n# Standard machine learning models\nfrom sklearn.linear_model import LogisticRegressionCV\n\n# Scikit-learn utilities\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, confusion_matrix, roc_auc_score, roc_curve\n# PyMC3 for Bayesian Inference\nimport pymc3 as pm\nprint(pm.__version__)\nimport arviz\n\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\nplt.style.use('seaborn-darkgrid')\nfrom IPython.core.pylabtools import figsize\nimport matplotlib.lines as mlines\n\nimport seaborn as sns\nimport itertools\n\npd.options.mode.chained_assignment = None\n\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom IPython.display import set_matplotlib_formats\nset_matplotlib_formats('retina')\nimport seaborn as sns\nsns.set(palette='viridis_r',context='notebook',\n        font='ubuntu', style='white')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-27T11:51:44.366823Z","iopub.execute_input":"2021-05-27T11:51:44.367305Z","iopub.status.idle":"2021-05-27T11:51:55.991675Z","shell.execute_reply.started":"2021-05-27T11:51:44.367269Z","shell.execute_reply":"2021-05-27T11:51:55.990764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"telcom = pd.read_csv(\"/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n#first few rows\ntelcom.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:52:55.065047Z","iopub.execute_input":"2021-05-27T11:52:55.065617Z","iopub.status.idle":"2021-05-27T11:52:55.176738Z","shell.execute_reply.started":"2021-05-27T11:52:55.065585Z","shell.execute_reply":"2021-05-27T11:52:55.175854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"telcom.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:53:26.062041Z","iopub.execute_input":"2021-05-27T11:53:26.062592Z","iopub.status.idle":"2021-05-27T11:53:26.09737Z","shell.execute_reply.started":"2021-05-27T11:53:26.062558Z","shell.execute_reply":"2021-05-27T11:53:26.096526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for column in telcom.drop(['tenure','MonthlyCharges','TotalCharges'], axis=1).columns:\n    print(column,'-',telcom[column].unique())","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:53:37.735476Z","iopub.execute_input":"2021-05-27T11:53:37.735826Z","iopub.status.idle":"2021-05-27T11:53:37.767767Z","shell.execute_reply.started":"2021-05-27T11:53:37.735798Z","shell.execute_reply":"2021-05-27T11:53:37.766694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"telcom.describe(include='object').T","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:53:48.564474Z","iopub.execute_input":"2021-05-27T11:53:48.564887Z","iopub.status.idle":"2021-05-27T11:53:48.678499Z","shell.execute_reply.started":"2021-05-27T11:53:48.564854Z","shell.execute_reply":"2021-05-27T11:53:48.677153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"telcom.TotalCharges = telcom.TotalCharges.apply(pd.to_numeric, errors='coerce')\ntelcom.TotalCharges = telcom.TotalCharges.fillna(telcom.TotalCharges.median())","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:54:11.042539Z","iopub.execute_input":"2021-05-27T11:54:11.042896Z","iopub.status.idle":"2021-05-27T11:54:11.074616Z","shell.execute_reply.started":"2021-05-27T11:54:11.042866Z","shell.execute_reply":"2021-05-27T11:54:11.073746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(2,6))\nsns.countplot(x=telcom.Churn, edgecolor='darkgray', \n              alpha=.95)\nsns.despine()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:54:20.485129Z","iopub.execute_input":"2021-05-27T11:54:20.485725Z","iopub.status.idle":"2021-05-27T11:54:20.666335Z","shell.execute_reply.started":"2021-05-27T11:54:20.485676Z","shell.execute_reply":"2021-05-27T11:54:20.665238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"telcom.TotalCharges = telcom.TotalCharges.apply(pd.to_numeric, errors='coerce')\ntelcom.TotalCharges = telcom.TotalCharges.fillna(telcom.TotalCharges.median())","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:54:32.992457Z","iopub.execute_input":"2021-05-27T11:54:32.992819Z","iopub.status.idle":"2021-05-27T11:54:33.024321Z","shell.execute_reply.started":"2021-05-27T11:54:32.992789Z","shell.execute_reply":"2021-05-27T11:54:33.023068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(telcom, hue='Churn', markers='x')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:54:47.349604Z","iopub.execute_input":"2021-05-27T11:54:47.349968Z","iopub.status.idle":"2021-05-27T11:54:54.316023Z","shell.execute_reply.started":"2021-05-27T11:54:47.349937Z","shell.execute_reply":"2021-05-27T11:54:54.315247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(ncols=3, figsize=(8,3))\n\nsample = telcom[['tenure','MonthlyCharges','TotalCharges']]\n\nfor ax, column in zip(axes.ravel(),sample):\n    sns.boxplot(x=telcom.Churn,\n          y=sample[column], ax=ax)\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:55:01.12545Z","iopub.execute_input":"2021-05-27T11:55:01.126054Z","iopub.status.idle":"2021-05-27T11:55:01.709014Z","shell.execute_reply.started":"2021-05-27T11:55:01.126005Z","shell.execute_reply":"2021-05-27T11:55:01.708169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nmelted = pd.melt(telcom, id_vars=['Churn'], value_vars = ['gender', 'SeniorCitizen',\n        'Contract','PhoneService','MultipleLines','TechSupport'])\nmelted = melted.sort_values(['value','variable']).rename(\n                            columns={'variable':'var.'})\n\ng = sns.FacetGrid(melted, col='Churn', row='var.', aspect=1.15,\n                  hue = 'Churn',sharex=False)\ng.map(sns.countplot, 'value')\n\ng.set_xticklabels(rotation=25)\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:55:12.08627Z","iopub.execute_input":"2021-05-27T11:55:12.086828Z","iopub.status.idle":"2021-05-27T11:55:15.380013Z","shell.execute_reply.started":"2021-05-27T11:55:12.086776Z","shell.execute_reply":"2021-05-27T11:55:15.37924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\ntrain2 = telcom.copy()\n\nlec = LabelEncoder()\n\ntrain2.loc[:,'gender':'Dependents']=train2.loc[:,'gender':'Dependents'].transform(lec.fit_transform)\ntrain2.loc[:,'PhoneService':'PaymentMethod']=train2.loc[:,'PhoneService':'PaymentMethod'].\\\ntransform(lec.fit_transform)\ntrain2['Churn'] = lec.fit_transform(train2['Churn'])\n\nmms = MinMaxScaler()\ntrain2[['tenure','MonthlyCharges','TotalCharges']] =\\\nmms.fit_transform(train2[['tenure','MonthlyCharges','TotalCharges']])","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:55:41.475394Z","iopub.execute_input":"2021-05-27T11:55:41.475801Z","iopub.status.idle":"2021-05-27T11:55:41.553908Z","shell.execute_reply.started":"2021-05-27T11:55:41.475766Z","shell.execute_reply":"2021-05-27T11:55:41.553009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = train2.loc[:,'gender':'TotalCharges']\ntarget = train2['Churn']\n\nfig = plt.figure(figsize=(24,12))\nax = sns.heatmap(train2.corr(), cmap='viridis_r',\n      linecolor='black', lw=.65,annot=True, alpha=.95)\n\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:55:59.494671Z","iopub.execute_input":"2021-05-27T11:55:59.495273Z","iopub.status.idle":"2021-05-27T11:56:02.260388Z","shell.execute_reply.started":"2021-05-27T11:55:59.495218Z","shell.execute_reply":"2021-05-27T11:56:02.25927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (\"Rows     : \" ,telcom.shape[0])\nprint (\"Columns  : \" ,telcom.shape[1])\nprint (\"\\nFeatures : \\n\" ,telcom.columns.tolist())\nprint (\"\\nMissing values :  \", telcom.isnull().sum().values.sum())\nprint (\"\\nUnique values :  \\n\",telcom.nunique())","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:56:13.847927Z","iopub.execute_input":"2021-05-27T11:56:13.848294Z","iopub.status.idle":"2021-05-27T11:56:13.899565Z","shell.execute_reply.started":"2021-05-27T11:56:13.848264Z","shell.execute_reply":"2021-05-27T11:56:13.898644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in telcom.columns:\n    if len(telcom[i].unique())<10:\n        print(\"Column:{},Unique values:{}\".format(i,telcom[i].unique()))\n    else:\n        print(\"Column:{}Unique values:{}\".format(i,len(telcom[i].unique())))","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:56:31.849958Z","iopub.execute_input":"2021-05-27T11:56:31.850545Z","iopub.status.idle":"2021-05-27T11:56:31.889686Z","shell.execute_reply.started":"2021-05-27T11:56:31.850495Z","shell.execute_reply":"2021-05-27T11:56:31.888583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"telcom_dummies=pd.DataFrame()\nprint(\"Total number of rows before starting copying:{}\".format(len(telcom_dummies)))\n# len(telcom_dummies[telcom_dummies['TotalCharges'] == \" \"])\ntelcom_dummies = pd.get_dummies(telcom[['gender','PaymentMethod','Contract']], columns=['gender','PaymentMethod','Contract'])\ntelcom_dummies['SeniorCitizen'] =telcom['SeniorCitizen']\ntelcom_dummies['Partner'] = telcom['Partner'].map(lambda s :1  if s =='Yes' else 0)\ntelcom_dummies['Dependents'] = telcom['Dependents'].map(lambda s :1  if s =='Yes' else 0)\ntelcom_dummies['tenure']=telcom['tenure']\ntelcom_dummies['PhoneService'] = telcom['PhoneService'].map(lambda s :1  if s =='Yes' else 0)\ntelcom_dummies['MultipleLines'] = telcom['MultipleLines'].map(lambda s :1  if s =='Yes' else 0)\ntelcom_dummies['Has_InternetService'] = telcom['InternetService'].map(lambda s :0  if s =='No' else 1)\ntelcom_dummies['Fiber_optic'] = telcom['InternetService'].map(lambda s :1  if s =='Fiber optic' else 0)\ntelcom_dummies['DSL'] = telcom['InternetService'].map(lambda s :1  if s =='DSL' else 0)\ntelcom_dummies['OnlineSecurity'] = telcom['OnlineSecurity'].map(lambda s :1  if s =='Yes' else 0)\ntelcom_dummies['OnlineBackup'] = telcom['OnlineBackup'].map(lambda s :1  if s =='Yes' else 0)\ntelcom_dummies['DeviceProtection'] = telcom['DeviceProtection'].map(lambda s :1  if s =='Yes' else 0)\ntelcom_dummies['TechSupport'] = telcom['TechSupport'].map(lambda s :1  if s =='Yes' else 0)\ntelcom_dummies['StreamingTV'] = telcom['StreamingTV'].map(lambda s :1  if s =='Yes' else 0)\ntelcom_dummies['StreamingMovies'] = telcom['StreamingMovies'].map(lambda s :1  if s =='Yes' else 0)\ntelcom_dummies['PaperlessBilling'] = telcom['PaperlessBilling'].map(lambda s :1  if s =='Yes' else 0)\ntelcom_dummies['MonthlyCharges']=telcom['MonthlyCharges']\ntelcom_dummies['TotalCharges'] = pd.to_numeric(telcom['TotalCharges'],errors='coerce')\nprint(\"Total number of rows after  copying:{}\".format(len(telcom_dummies)))\n      #Counting number of na\nprint(\"Number of NA\")\nprint(len(telcom_dummies) - telcom_dummies.count())\ntelcom_dummies.dropna(axis=0,inplace=True)\nprint(\"Total number of rows after removing NA:{}\".format(len(telcom_dummies)))\ntelcom_dummies['Churn']=telcom['Churn'].map(lambda s :1  if s =='Yes' else 0)\ntelcom_dummies.rename(columns={\"PaymentMethod_Bank transfer (automatic)\" :\"paymnt_mthd_bank_auto\",\n\"PaymentMethod_Credit card (automatic)\"  : \"paymnt_mthd_cc_auto\",\n\"PaymentMethod_Electronic check\"   :\"paymnt_mthd_elc_check\",\n\"PaymentMethod_Mailed check\"       :\"paymnt_mthd_mailed_check\",         \n\"Contract_Month-to-month\":\"cont_mnth_to_mnth\",                    \n\"Contract_One year\"  :\"cont_1_yr\",                       \n\"Contract_Two year\"    :\"cont_2_yr\" },inplace=True)\ntelcom_dummies.columns","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Checking if columns are ready to apply ML algorithm\")\nfor i in telcom_dummies.columns:\n    if len(telcom_dummies[i].unique())<10:\n        print(\"Column:{},Unique values:{},Type:{}\".format(i,telcom_dummies[i].unique(),telcom_dummies[i].dtypes))\n    else:\n        print(\"Column:{}Unique values:{},Type:{}\".format(i,len(telcom_dummies[i].unique()),telcom_dummies[i].dtypes))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = telcom_dummies['Churn'].values\nX = telcom_dummies.loc[:, telcom_dummies.columns != 'Churn']\nfrom sklearn.preprocessing import MinMaxScaler\nfeatures = X.columns.values\nscaler = MinMaxScaler(feature_range = (0,1))\nscaler.fit(X)\nX = pd.DataFrame(scaler.transform(X))\nX.columns = features\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the accuracy and f1 score of a model\ndef calc_metrics(predictions, y_test):\n    accuracy = np.mean(predictions == y_test)\n    f1_metric = f1_score(y_test, predictions)\n\n    print('Accuracy of Model: {:.2f}%'.format(100 * accuracy))\n    print('F1 Score of Model: {:.4f}'.format(f1_metric))\nbaseline_pred = [0 for _ in range(len(y_test))]\ncalc_metrics(baseline_pred, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = LogisticRegressionCV(Cs= 20, cv = 3, scoring = 'f1', \n                          penalty = 'l2', random_state = 42)\nlr.fit(X_test, y_test)\n\n# Make predictions and evaluate\nlr_pred = lr.predict(X_test)\ncalc_metrics(lr_pred, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build up a formula\nformula = [' %s + ' % variable for variable in X_test.columns]\nformula.insert(0, 'y ~ ')\nformula = ' '.join(''.join(formula).split(' ')[:-2])\nformula","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Intercept: {:0.4f}'.format(lr.intercept_[0]))\nfor feature, weight in zip(X_test.columns, lr.coef_[0]):\n    print('Feature: {:30} Weight: {:0.4f}'.format(feature, weight))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_with_labels = X_train.copy()\nX_with_labels['y'] = y_train\nwith pm.Model() as logistic_model:\n    priors=dict()\n    \n    for variable in X_test.columns:\n        priors[variable]=pm.Uniform.dist(0,1)\n    priors['Intercept']=pm.Normal.dist(mu=0., sigma=100.)\n    priors['MonthlyCharges']=pm.Normal.dist(mu=0., sigma=100.)\n    priors['TotalCharges'] = pm.Normal.dist(mu=0., sigma=100.)\n    # Build the model using the formula and specify the data likelihood \n    pm.GLM.from_formula(formula, data = X_with_labels, family = pm.glm.families.Binomial(),priors=priors)\n    \n    # Using the no-uturn sampler\n    sampler = pm.NUTS()\n    \n    # Sample from the posterior using NUTS\n    trace_log = pm.sample(draws=2000, step = sampler, chains=1, tune=1000, random_seed=100,init='adapt_diag')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nfileObject = open(\"all_parameters.pickle\",'wb')  \npickle.dump(trace_log, fileObject)\nfileObject.close()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trace_log_from_file= pickle.load(open(\"all_parameters.pickle\",'rb')  )\n#trace_log=trace_log_from_file   #Uncomment this line if we don't want to run model again","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figsize(10, 12)\npm.forestplot(trace_log);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pm.plot_posterior(trace_log);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pm.summary(trace_log)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_trace(trace, data, print_model = False):\n    means_dict = {}\n    std_dict = {}\n    \n    for var in trace.varnames:\n        means_dict[var] = np.mean(trace[var])\n        std_dict[var] = np.std(trace[var])\n    \n    model = 'logit = %0.4f + ' % np.mean(means_dict['Intercept'])\n    \n    for var in data.columns:\n        model += '%0.4f * %s + ' % (means_dict[var], var)\n    \n    model = ' '.join(model.split(' ')[:-2])\n    if print_model:\n        print('Final Equation: \\n{}'.format(model))\n    \n    return means_dict, std_dict","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"means_dict, std_dict = evaluate_trace(trace_log, X_train, print_model=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find a single probabilty estimate using the mean value of variables in a trace\ndef find_probs(trace, data):\n    \n    # Find the means and std of the variables\n    means_dict1, std_dict = evaluate_trace(trace, data)\n          \n    probs = []\n       \n    \n    # Need an intercept term in the data\n    data['Intercept'] = 1\n    l_means_dict=dict()\n    for c in data.columns:\n        \n        l_means_dict[c]=means_dict1[c]\n    \n    data = data[list(l_means_dict.keys())]\n    mean_array = np.array(list(l_means_dict.values()))\n    # Calculate the probability for each observation in the data\n    for _, row in data.iterrows():\n        # First the log odds\n        logit = np.dot(row, mean_array)\n        # Convert the log odds to a probability\n        probability = 1 / (1 + np.exp(-logit))\n        probs.append(probability)\n        \n    return probs","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"blr_probs = find_probs(trace_log, X_test.copy())\n\n# Threshold the values at 0.5\npredictions = (np.array(blr_probs) > 0.5)\ncalc_metrics(predictions, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test2=X_test[X_test.columns.difference(['MonthlyCharges', 'paymnt_mthd_cc_auto', 'cont_1_yr', 'cont_2_yr', 'Partner', 'Dependents', 'Tenure', 'PhoneService', 'DSL', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport'])]\n# Build up a formula\nformula1 = [' %s + ' % variable for variable in X_test2.columns]\nformula1.insert(0, 'y ~ ')\nformula1 = ' '.join(''.join(formula1).split(' ')[:-2])\nformula1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with pm.Model() as logistic_model1:\n    \n    # Build the model using the formula and specify the data likelihood \n    priors=dict()\n    for variable in X_test2.columns:\n        priors[variable]=pm.Uniform.dist(0,1)\n    priors['Intercept']=pm.Normal.dist(mu=0., sigma=100.)\n    priors['MonthlyCharges']=pm.Normal.dist(mu=0., sigma=100.)\n    priors['TotalCharges'] = pm.Normal.dist(mu=0., sigma=100.)\n              \n    pm.GLM.from_formula(formula1, data = X_with_labels, family = pm.glm.families.Binomial(),priors=priors)\n    \n    # Using the no-uturn sampler\n    sampler = pm.NUTS()\n    \n    # Sample from the posterior using NUTS\n    trace_log1 = pm.sample(draws=2000, step = sampler, chains=1, tune=1000, random_seed=100,init='adapt_diag')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pm.plot_posterior(trace_log);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pm.summary(trace_log1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fileObject = open(\"sign_parameters.pickle\",'wb')  \npickle.dump(trace_log1, fileObject)\nfileObject.close()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trace_log1_frm_file= pickle.load(open(\"sign_parameters.pickle\",'rb')  )\n#trace_log1=trace_log1_frm_file #Uncomment this line if we want to load the model from static file","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"means_dict_sign, std_dict_sign = evaluate_trace(trace_log1, X_test2, print_model=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"blr1_probs = find_probs(trace_log1, X_test2)\n\n# Threshold the values at 0.5\npredictions = (np.array(blr1_probs) > 0.5)\ncalc_metrics(predictions, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logistic_model.name='all_parm'\nlogistic_model1.name='sign_parm'\nmodel_trace_dict = {'all_parm':trace_log,\n                   'sign_parm':trace_log1}\ndfwaic = pm.compare(model_trace_dict)\npm.compareplot(dfwaic);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfwaicloo = pm.compare(model_trace_dict, ic='LOO')\npm.compareplot(dfwaicloo);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dfwaic)\nprint(dfwaicloo)","metadata":{},"execution_count":null,"outputs":[]}]}