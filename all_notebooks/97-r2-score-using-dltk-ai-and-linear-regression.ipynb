{"cells":[{"metadata":{"id":"XPMGwt8SzPZU"},"cell_type":"markdown","source":"# <font color=darkblue> Importing Packages"},{"metadata":{"id":"569nJ6spzPZq","outputId":"05b79e62-5cca-4e5e-e82c-b8850b6cd0dc","trusted":true,"collapsed":true},"cell_type":"code","source":"!pip install dltk_ai","execution_count":null,"outputs":[]},{"metadata":{"id":"BIJFneqLzPZs","trusted":true},"cell_type":"code","source":"import os #file handling\nimport dltk_ai\nfrom dltk_ai.dataset_types import Dataset     #importing datasets\nfrom dltk_ai import visualization as vs #importing visualizations\nfrom dltk_ai import preprocessor       #importing preprocessor\nimport json\nfrom sklearn import datasets #Machine Learning \nimport numpy as np #Numerical\nimport seaborn as sns #plot\nimport matplotlib.pyplot as plt #plot\nfrom sklearn.model_selection import train_test_split #ML","execution_count":null,"outputs":[]},{"metadata":{"id":"gJiJKPc1zPZt"},"cell_type":"markdown","source":"# <font color=darkblue> Data"},{"metadata":{"id":"8M5frBDP9RAt"},"cell_type":"markdown","source":"Loading the dataset and splitting it into 2 parts, train and test"},{"metadata":{"id":"XfmbOTPlzPZt","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\ndf =  pd.read_csv('../input/life-expectancy-who/Life Expectancy Data.csv')\ndata, test_data = train_test_split(df, test_size=0.2,random_state = 42) \ntest_data.dropna(inplace = True)\ntest_data.to_csv('Life Expectancy Data test.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"id":"tGen1mrezPZv"},"cell_type":"markdown","source":"# <font color=darkblue> Sneak Peak at Dataset"},{"metadata":{"id":"mh_RKUde9bnB"},"cell_type":"markdown","source":"Lets see what our data looks like"},{"metadata":{"id":"OMExXw_qfhMl","outputId":"ad1da542-b33d-4d36-af00-62f0af4c7097","trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"R5y2HIlyzPZw","outputId":"1bc2a3be-71af-4afe-d7c4-770d50b4bd91","trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"4YfEv5zS9h3f"},"cell_type":"markdown","source":"We can see that the data is not following normal distribution and, we also have nulls"},{"metadata":{"id":"o5KIaV0MzPZy","outputId":"1b980615-d043-4894-8287-10fe56a4f7cf","trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"id":"QRHkb0wizPZy","outputId":"aee37b04-4790-4893-c87d-06658f710eb5","trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"id":"M5SLwl3K9vB4"},"cell_type":"markdown","source":"Since we have a lot of nulls, we cannot simply drop them"},{"metadata":{"id":"UN0kmButzPZz","outputId":"0cef2292-2cc8-4c8f-e5f3-300fffadbb11","trusted":true},"cell_type":"code","source":"print(data.columns)\nprint(data.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"O8MjxOgVzPZ0"},"cell_type":"markdown","source":"# <font color = 'darkblue'> Data preprocessing and Feature anlysis"},{"metadata":{"id":"jh-nx2j7zPZ0"},"cell_type":"markdown","source":"## <font color = green> Correlation Analysis"},{"metadata":{"id":"POmrPyD1-VXF"},"cell_type":"markdown","source":"Heatmap lets us see how different values are correlated, in a visual manner."},{"metadata":{"id":"O-3HiuIvzPZ1","outputId":"dd0b2389-a546-45b0-ad71-19700c471f90","trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize = (20,15))\nsns.heatmap(data.corr(),annot = True)","execution_count":null,"outputs":[]},{"metadata":{"id":"-Msbv-2JzPZ1"},"cell_type":"markdown","source":"## <font color = green> Handling Outliers and missing values"},{"metadata":{"id":"mY95lJWOzPZ2"},"cell_type":"markdown","source":"To fill the null values, imputation, grouped mean and dropping were used"},{"metadata":{"id":"N13rwU2x_BXf"},"cell_type":"markdown","source":"Dropping the nulls which are very few in number"},{"metadata":{"id":"FS3Xv3-OzPZ2","trusted":true},"cell_type":"code","source":"# removing null value of 'Adult Morality' and 'Life expectancy ' columns\ndata['Adult Mortality']=data['Adult Mortality'].fillna(value=data['Adult Mortality'].mean())\ndata['Life expectancy ']=data['Life expectancy '].fillna(value=data['Life expectancy '].mean())","execution_count":null,"outputs":[]},{"metadata":{"id":"3gpjn4p2_J5t"},"cell_type":"markdown","source":"For imputation, first, the correlation was seen,. for example, column X is highly correlated to column Y.  Now, if column X has null values and column Y is filled fully, then column X can be filled using column Y \n\nIf we see the scatter plot of X and Y we can see where majority of points fall and what is the relation"},{"metadata":{"id":"NQ7UGXTTzPZ3","outputId":"7d9b7940-43f2-4562-a2ce-e8ffdc8dd8d1","trusted":true},"cell_type":"code","source":"sns.scatterplot(data=data,x='Life expectancy ',y='Schooling')","execution_count":null,"outputs":[]},{"metadata":{"id":"kwdIGdfWzPZ3","trusted":true},"cell_type":"code","source":"# Imputing missing values of 'Schooling' column \ndef impute_schooling(c):\n    s=c[0]\n    l=c[1]\n    if pd.isnull(s):\n        if l<= 40:\n            return 8.0\n        elif 40<l<=44:\n            return 7.5\n        elif 44<l<50:\n            return 8.1\n        elif 50<l<=60:\n            return 8.2\n        elif 60<l<=70:\n            return 10.5\n        elif 70<l<=80:\n            return 13.4\n        elif l>80:\n            return 16.5\n    else:\n        return s\n    \ndata['Schooling']=data[['Schooling','Life expectancy ']].apply(impute_schooling,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"gXnYXF-rzPZ4","outputId":"cb22b005-cce7-47f4-c32f-29c69fae052f","trusted":true},"cell_type":"code","source":"sns.scatterplot(data=data,x='Alcohol',y='Schooling')","execution_count":null,"outputs":[]},{"metadata":{"id":"3Pq982lwzPZ4","trusted":true},"cell_type":"code","source":"# Imputing missing values of 'Alcohol' column \ndef impute_Alcohol(cols):\n    al=cols[0]\n    sc=cols[1]\n    if pd.isnull(al):\n        if sc<=2.5:\n            return 4.0\n        elif 2.5<sc<=5.0:\n            return 1.5\n        elif 5.0<sc<=7.5:\n            return 2.5\n        elif 7.5<sc<=10.0:\n            return 3.0\n        elif 10.0<sc<=15:\n            return 4.0\n        elif sc>15:\n            return 10.0\n    else:\n        return al\n    \ndata['Alcohol']=data[['Alcohol','Schooling']].apply(impute_Alcohol,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"7rmtKbVszPZ4","outputId":"144731f2-d79e-42b0-ae09-ce5b4bd989b6","trusted":true},"cell_type":"code","source":"sns.scatterplot(data=data,x='Income composition of resources',y='Life expectancy ')","execution_count":null,"outputs":[]},{"metadata":{"id":"stHr5pH1zPZ5","trusted":true},"cell_type":"code","source":"# Imputing missing values of ''Income composition of resources'' column \ndef impute_Income(c):\n    i=c[0]\n    l=c[1]\n    if pd.isnull(i):\n        if l<=40:\n            return 0.4\n        elif 40<l<=50:\n            return 0.42\n        elif 50<l<=60:\n            return 0.402\n        elif 60<l<=70:\n            return 0.54\n        elif 70<l<=80:\n            return 0.71\n        elif l>80:\n            return 0.88\n    else:\n        return i\n        \ndata['Income composition of resources']=data[['Income composition of resources','Life expectancy ']].apply(impute_Income,axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"SH2jquMbzPZ5","outputId":"3cf18c2e-a16c-4503-81af-19419070405d","trusted":true},"cell_type":"code","source":"sns.scatterplot(data=data,x=' BMI ',y='Life expectancy ')","execution_count":null,"outputs":[]},{"metadata":{"id":"Aee4dBTu_d-I"},"cell_type":"markdown","source":"Creating a function for hadling outliers in certain columns.The function will calculate the z score of all the values in the passed column, if the zscore is greater than the threshold we replace it with the group(country) mean."},{"metadata":{"id":"bkwTrWx7zPZ5","trusted":true},"cell_type":"code","source":"def outlier_replace(col):\n    for i in countries:\n        for j in groups.get_group(i)[col]:\n            threshold = 3\n            mean = np.mean(groups.get_group(i)[col])\n            std = np.std(groups.get_group(i)[col])\n            if std != 0:                     \n                z_score = (j - mean) / std\n                if np.abs(z_score) > threshold:\n                    j = data[col][data['Country'] == i].mean()","execution_count":null,"outputs":[]},{"metadata":{"id":"pOpn7qWeAa_Q"},"cell_type":"markdown","source":"The other columns, wer replaced by group mean.\n\nIf the number of null was less than 10 then the mean of the column was taken, or else, the mean of that value belonging to that country were taken."},{"metadata":{"id":"RdUr6mIwzPZ5","trusted":true},"cell_type":"code","source":"data.dropna(subset=['Life expectancy '],inplace = True) \ncountries = data['Country'].unique()\n\n# we are creating groups of countries \n\ngroups = data.groupby('Country')\n\n# from the avialble data we know that values depends on country , \n# so we are going to handle the missing values and outliers of some columns  with respect to the country\n\n\n# creating a new list contains gdp null values greater than 10.. this simply means that we cannot update the null with \n# the respective country mean .. \ngdpnull_c = []\nfor i in countries:\n    if groups.get_group(i)['GDP'].isna().sum() >10:\n        gdpnull_c.append(i)\n        \n        \n        \n# for countries with less gdp null then fill it with mean of gdp  values with respect to each country\nfor i in countries:\n    if i not in gdpnull_c:\n        for j in groups.get_group(i)['GDP']:\n            data['GDP'][data['Country'] == i]= groups.get_group(i)['GDP'].fillna(groups.get_group(i)['GDP'].mean()) \n            \n# for those countries null values more than 10 fill it with  mean of 'GDP'  of entire dataframe\nfor i in gdpnull_c:\n    data['GDP'][data['Country'] == i]=groups.get_group(i)['GDP'].fillna(data['GDP'].mean())\n    \n# replacing outlier with mean of the rest values in the respective country:\n\noutlier_replace('GDP')\n\n# there are some countries for which we dont have the 15 years data.. so eventhough we did above steps, we may not replace\n# null values of such coutries... \n\n# so , we are droping rest na values ( 5 rows)\ndata.dropna(subset=['GDP'],inplace = True) ","execution_count":null,"outputs":[]},{"metadata":{"id":"B0UP4qxHzPZ6","trusted":true},"cell_type":"code","source":"# hepatities     outlier  and null analysis\n\n# same process in the case of gdp data handling ( refer )\ncountries = data['Country'].unique()\ngroups = data.groupby('Country')\ngnull_c = []\nfor i in countries:\n    if groups.get_group(i)['Hepatitis B'].isna().sum() >10:\n        gnull_c.append(i)","execution_count":null,"outputs":[]},{"metadata":{"id":"Z8B9GjNqzPZ7","trusted":true},"cell_type":"code","source":"# treating outlier 'Hepatitis B'values among countries which contain less number of nulls\noutlier_replace('Hepatitis B') \n\n# we replace all null values by mean 'Hepatities B' of the corresponding countries ( countries not in gnull_c)    \nfor i in countries:\n    if i not in gnull_c:\n        for j in groups.get_group(i)['Hepatitis B']:\n            data['Hepatitis B'][data['Country'] == i]= groups.get_group(i)['Hepatitis B'].fillna(groups.get_group(i)['Hepatitis B'].mean()) \n# for those countries in gnull_c we replace it with mean of 'Hepatitis B'  in the entire dataframe\nfor i in gnull_c:   \n    data['Hepatitis B'][data['Country'] == i]=groups.get_group(i)['Hepatitis B'].fillna(data['Hepatitis B'].mean())\n\n# same processing ( refer gdp data handling process)   \ndata.dropna(subset=['Hepatitis B'],inplace = True) ","execution_count":null,"outputs":[]},{"metadata":{"id":"dkQb1KFfzPZ8","trusted":true},"cell_type":"code","source":"\n\ngnull_c = []\nfor i in countries:\n    if groups.get_group(i)['Total expenditure'].isna().sum() >10:\n        gnull_c.append(i)\n\n        \noutlier_replace('Total expenditure') \n\n\nfor i in countries:\n    if i not in gnull_c:\n        for j in groups.get_group(i)['Total expenditure']:\n            data['Total expenditure'][data['Country'] == i]= groups.get_group(i)['Total expenditure'].fillna(groups.get_group(i)['Total expenditure'].mean()) \n\nfor i in gnull_c:   \n    data['Total expenditure'][data['Country'] == i]=groups.get_group(i)['Total expenditure'].fillna(data['Total expenditure'].mean())\n\ndata.dropna(subset=['Total expenditure'],inplace = True) ","execution_count":null,"outputs":[]},{"metadata":{"id":"IccMzsAkzPZ8"},"cell_type":"markdown","source":"## Further outlier removal and missing values"},{"metadata":{"id":"wF6kgH86A1LE","outputId":"6e0db808-7721-4330-c4f3-1b926bdfae40","trusted":true},"cell_type":"code","source":"sns.scatterplot(x=' BMI ',y=' thinness  1-19 years',data=data)","execution_count":null,"outputs":[]},{"metadata":{"id":"XSQUqrgkzPZ8","trusted":true},"cell_type":"code","source":"# Another imputation technique\n\ndata = data.drop(' thinness 5-9 years',axis = 1)\ndef impute_BMI(c):\n    b=c[0]\n    l=c[1]\n    if pd.isnull(b):\n        if l<=50:\n            return 25.0\n        elif 50<l<=60:\n            return 25.0\n        elif 60<l<=70:\n            return 32.0\n        elif 70<l<=80:\n            return 46.8\n        elif 80<l<=100:\n            return 60.0\n    else:\n        return b\n    \ndata[' BMI ']=data[[' BMI ','Life expectancy ']].apply(impute_BMI,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"vzu21tCTBLRf","outputId":"ee2a5ee6-4a14-4670-eddb-64af09084fa3","trusted":true},"cell_type":"code","source":"sns.scatterplot(x='Population',y='infant deaths',data=data)","execution_count":null,"outputs":[]},{"metadata":{"id":"wgxJxxegzPZ8","trusted":true},"cell_type":"code","source":"def impute_population(c):\n    p=c[0]\n    i=c[1]\n    if pd.isnull(p):\n        if i<=100:\n            return 0.19*((10)**9)\n        elif 100<i<=250:\n            return 0.18*((10)**9)\n        elif 250<i<=350:\n            return 0.02*((10)**9)\n        elif 350<i<=900:\n            return 0.1*((10)**9)\n        elif 900<i<=1100:\n            return 0.18*((10)**9)\n        elif 1100<i<=1250:\n            return 0.05*((10)**9)\n        elif 1250<i<=1500:\n            return 0.19*((10)**9)\n        elif 1500<i<=1750:\n            return 0.05*((10)**9)\n        elif i>1750:\n            return 0.1*((10)**9)\n    else:\n        return p\ndata['Population']=data[['Population','infant deaths']].apply(impute_population,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"blag4HXTzPZ9","outputId":"2dba6c9f-4750-452f-9e53-a8ad4b1eadbd","trusted":true},"cell_type":"code","source":"sns.scatterplot(data=data,x=' thinness  1-19 years',y=' BMI ')","execution_count":null,"outputs":[]},{"metadata":{"id":"-Tmgoo3izPZ9","trusted":true},"cell_type":"code","source":"def impute_Thin_1(c):\n    t=c[0]\n    b=c[1]\n    if pd.isnull(t):\n        if b<=10:\n            return 5.0\n        elif 10<b<=20:\n            return 10.0\n        elif 20<b<=30:\n            return 8.0\n        elif 30<b<=40:\n            return 6.0\n        elif 40<b<=50:\n            return 3.0\n        elif 50<b<=70:\n            return 4.0\n        elif b>70:\n            return 1.0\n    else:\n        return t\n    \ndata[' thinness  1-19 years']=data[[' thinness  1-19 years',' BMI ']].apply(impute_Thin_1,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"er6kTT1XzPZ-","trusted":true},"cell_type":"code","source":"\ncountries = data['Country'].unique()\ngroups = data.groupby('Country')\ngnull_c = []\nfor i in countries:\n    if groups.get_group(i)['Polio'].isna().sum() >10:\n        gnull_c.append(i)\n\noutlier_replace('Polio') \n\nfor i in countries:\n    if i not in gnull_c:\n        for j in groups.get_group(i)['Polio']:\n            data['Polio'][data['Country'] == i]= groups.get_group(i)['Polio'].fillna(groups.get_group(i)['Polio'].mean()) \nfor i in gnull_c:   \n    data['Polio'][data['Country'] == i]=groups.get_group(i)['Polio'].fillna(data['Polio'].mean())\ndata.dropna(subset=['Polio'],inplace = True) ","execution_count":null,"outputs":[]},{"metadata":{"id":"hqx-mtmyzPaD","trusted":true},"cell_type":"code","source":"\ncountries = data['Country'].unique()\ngroups = data.groupby('Country')\ngnull_c = []\nfor i in countries:\n    if groups.get_group(i)['Diphtheria '].isna().sum() >10:\n        gnull_c.append(i)\n\noutlier_replace('Diphtheria ') \n\nfor i in countries:\n    if i not in gnull_c:\n        for j in groups.get_group(i)['Diphtheria ']:\n            data['Diphtheria '][data['Country'] == i]= groups.get_group(i)['Diphtheria '].fillna(groups.get_group(i)['Diphtheria '].mean())\n            \n            \nfor i in gnull_c:   \n    data['Diphtheria '][data['Country'] == i]=groups.get_group(i)['Diphtheria '].fillna(data['Diphtheria '].mean())\ndata.dropna(subset=['Diphtheria '],inplace = True) ","execution_count":null,"outputs":[]},{"metadata":{"id":"__oOGYBIzPaE","trusted":true},"cell_type":"code","source":"life = data['Life expectancy ']","execution_count":null,"outputs":[]},{"metadata":{"id":"bG08yLXazPaF"},"cell_type":"markdown","source":"## More Exploration "},{"metadata":{"id":"6ewYFkVkBgrh"},"cell_type":"markdown","source":"Creating a dummy dataframe, so that the original dataframe doesnt get destroyed"},{"metadata":{"id":"3RXVvjBAzPaF","trusted":false},"cell_type":"code","source":"dataplt = data\ndataplt = dataplt.drop(['Status'],axis=1)\ndataplt = dataplt.drop(['Country'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"lfAEf8i-BoxX"},"cell_type":"markdown","source":"Dropping the categorical data"},{"metadata":{"id":"Jqab9bJiBsNh"},"cell_type":"markdown","source":"A pairplot, helps in understanding all the feature correlation in one single frame, which is useful for feature analysis."},{"metadata":{"id":"VAcGYDRyzPaG","trusted":false},"cell_type":"code","source":"#sns.pairplot(dataplt,palette='flare')","execution_count":null,"outputs":[]},{"metadata":{"id":"KZLGWBmeB4UF"},"cell_type":"markdown","source":"Boxplots are helpful in understanding outliers and central tendency"},{"metadata":{"id":"aLUS-uthzPaG","outputId":"0b9240f5-ca2d-49a1-e90d-c27cf0379998","trusted":false},"cell_type":"code","source":"fig, axs = plt.subplots(ncols=3, nrows=7, figsize=(30, 30))\nindex = 0\naxs = axs.flatten()\nfor k,v in dataplt.items():\n    sns.boxplot(y=k, data=dataplt, ax=axs[index],color = '#7c4780')\n    index += 1","execution_count":null,"outputs":[]},{"metadata":{"id":"vl8uegDkCBIc"},"cell_type":"markdown","source":"We can see that there are many outliers, but since we have already done outlier detection, we can say these are true values, and dropping them can mess with data."},{"metadata":{"id":"cjUMs73zCOK9"},"cell_type":"markdown","source":"A distribution plot is helpful for analysing the distribution that a certain attribute holds.\n\nHere we are looping through all the columns and making their distplot."},{"metadata":{"scrolled":false,"id":"6lOie2kszPaH","outputId":"a51e9b4b-0cb2-4bdf-c591-7817977f97b4","trusted":false},"cell_type":"code","source":"for cols in dataplt:\n    sns.displot(dataplt[cols],color= '#7c4780')\n    plt.title('Distribution Plot of '+cols)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"QSdY0Ty2CksX"},"cell_type":"markdown","source":"Plotting highly correlarted data"},{"metadata":{"id":"VY3gvf56DVve"},"cell_type":"markdown","source":"Income Composition and schooling"},{"metadata":{"id":"WqZbRNHvzPaH","outputId":"a7e17f28-a6a9-4a85-cbec-bf110ff30a75","trusted":false},"cell_type":"code","source":"sns.set_style(\"whitegrid\")\n\ncmap = sns.cubehelix_palette(rot=-.2, as_cmap=True)\ng = sns.relplot(\n    data=dataplt,\n    color= '#7c4780',\n    x=\"Schooling\", y=\"Income composition of resources\",\n    hue=\"Year\", size=\"Life expectancy \",\n    palette=cmap, sizes=(10, 200),\n)\n\ng.ax.xaxis.grid(True, \"minor\", linewidth=.25)\ng.ax.yaxis.grid(True, \"minor\", linewidth=.25)\ng.despine(left=True, bottom=True) ","execution_count":null,"outputs":[]},{"metadata":{"id":"h41sW0fsDYXc"},"cell_type":"markdown","source":"We can see a nice relation between both"},{"metadata":{"id":"L3XIMnQuDdbP"},"cell_type":"markdown","source":"Schooling and Life Expectancy:\n\nThis also follows a beautiful relationship, it can be thought that, since schooling increases awareness and hence awareness about health also increases, and hence the results"},{"metadata":{"id":"EJwguxkHzPaI","outputId":"826af0ab-2d27-48f1-9c06-38df32512122","trusted":false},"cell_type":"code","source":"sns.set_style(\"darkgrid\")\n\ng = sns.jointplot(y=\"Schooling\", x=\"Life expectancy \", data=dataplt,\n                  kind=\"reg\", truncate=False,\n                  color=\"#7c4780\", height=7)","execution_count":null,"outputs":[]},{"metadata":{"id":"yGLKsYKCDyzM"},"cell_type":"markdown","source":"Income Composition and Life expectancy\n\nThe linear relationship can be because, the with increasing in income, health facility become better and hence better life expectancy."},{"metadata":{"id":"EncvynPyzPaI","outputId":"543b20e0-dd29-445b-f598-5d8f67926457","trusted":false},"cell_type":"code","source":"\ng = sns.jointplot(y=\"Income composition of resources\", x=\"Life expectancy \", data=dataplt,\n                  kind=\"reg\", truncate=False,\n                  color=\"#7c4780\", height=7)","execution_count":null,"outputs":[]},{"metadata":{"id":"LfLOX4MY3YyM"},"cell_type":"markdown","source":"# Pre Model Data Processing"},{"metadata":{"id":"x0Rr1XN3EsOR"},"cell_type":"markdown","source":"Dropping the categorical data.\n\nAnd since dltk_ai can take upto 20 parameters, it is better to drop this column"},{"metadata":{"id":"pPewjYS-zPaJ","trusted":false},"cell_type":"code","source":"## Applying scalar transformation \ndata = data.drop('Country',axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"id":"FFuWwybVE4P3"},"cell_type":"markdown","source":"Dropping catergorical variable and target variable"},{"metadata":{"id":"_bytlFINzPaJ","trusted":false},"cell_type":"code","source":"I = data\nfrom sklearn.preprocessing import MinMaxScaler\nI = I.drop(['Status','Life expectancy '],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"id":"ZGBqYtDwE_lN"},"cell_type":"markdown","source":"Using MinMax scaler to scale down the data to a normalized form\n\n$x_i-min(x)/(max(x)-min(x)) $ "},{"metadata":{"scrolled":false,"id":"400jr6ZFzPaK","trusted":false},"cell_type":"code","source":"scaler=MinMaxScaler()\nscaler.fit(I)\nscaled_data=scaler.transform(I)\nscaled_data = pd.DataFrame(scaled_data)\nlife = np.array(data['Life expectancy '])[:,np.newaxis]\nscaled_data['target'] = life\nscaled_data.columns = ['Year','Adult Mortality',\n       'infant deaths', 'Alcohol', 'percentage expenditure', 'Hepatitis B',\n       'Measles ', ' BMI ', 'under-five deaths ', 'Polio', 'Total expenditure',\n       'Diphtheria ', ' HIV/AIDS', 'GDP', 'Population',\n       ' thinness  1-19 years', 'Income composition of resources','Schooling','Life expectancy ']\ndata= scaled_data.copy()\ndata.to_csv('processed.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"-KmKMcwwzPaK"},"cell_type":"markdown","source":"<font color=blue> API key setup\n\nWe need to provide APIkey to connect to DLTK"},{"metadata":{"id":"uorIBYSGzPaL","trusted":false},"cell_type":"code","source":"# initialize dltk client with API key\nclient = dltk_ai.DltkAiClient('7dbbe2f4-3fb4-4a2a-95d3-1454bb6bc09e')","execution_count":null,"outputs":[]},{"metadata":{"id":"bMG7RXHEzPaL"},"cell_type":"markdown","source":"<font color=blue> Uploading training data"},{"metadata":{"id":"FbtpMx4lzPaL","outputId":"b8672730-f55b-4c98-854b-7a9618a010c4","trusted":false},"cell_type":"code","source":"train_data_store_response = client.store('processed.csv', Dataset.TRAIN_DATA)\nprint(train_data_store_response)\ntrain_data = train_data_store_response['fileUrl']","execution_count":null,"outputs":[]},{"metadata":{"id":"_51nVejpzPaL"},"cell_type":"markdown","source":"Next step after uploading the dataset is to train a model using Train Dataset."},{"metadata":{"id":"3UoN0Y8AOrJA"},"cell_type":"markdown","source":"# <font color=red> Model One"},{"metadata":{"id":"08g2dfYS1QC0"},"cell_type":"markdown","source":"## Creating Model"},{"metadata":{"id":"hnwNLSPSOr3U","outputId":"f257a975-c223-4424-c9e5-a82142e152b5","trusted":false},"cell_type":"code","source":"# Create ML Model\n# Its a regression problem, where we need to predict  \"Life Expectancy\" which is a continous value\ntask = \"regression\"\n\n# Library to use (scikit, weka, h2o)\nlibrary = 'weka'\nalgorithm = \"LinearRegression\"\n\nremoved_features =  ['Measles ', 'percentage expenditure',\n                     'infant deaths','Diphtheria ', 'Total expenditure',\n                     'Population'\n                     'Hepatitis B']\nnp.random.seed(24)\n# features to be used for training\nfeature = ['Adult Mortality',\n       'Alcohol', ' BMI ',\n       'under-five deaths ', 'Polio',\n       ' HIV/AIDS', ' thinness  1-19 years', 'Schooling','Income composition of resources']  \n# Label to predict\nlabel = 'Life expectancy '\n# Train-test split percentage\ntrain_percentage = 90\n\n# Save model \nsave_model = 'true'\ntrain_response = client.train(task,\n                              algorithm,\n                              train_data,\n                              label,\n                              feature,\n                              \"Life Expectancy Prediction Model\",\n                              library,\n                              train_percentage,\n                              save_model)\nprint(train_response)","execution_count":null,"outputs":[]},{"metadata":{"id":"5ehngDWz1SaH"},"cell_type":"markdown","source":"## Training"},{"metadata":{"id":"28sqXb5wO2Np","outputId":"b8b73ebc-e8ab-452e-c52a-25edb105e1aa","trusted":false},"cell_type":"code","source":"train_job_status_response = client.job_status(train_response['data']['jobId'])\nprint(train_job_status_response)\nprint(json.dumps(train_job_status_response, indent=2))","execution_count":null,"outputs":[]},{"metadata":{"id":"_a22AFKRO6R1","outputId":"08aea2f5-330d-415e-fdb4-b5fba0c45b46","trusted":false},"cell_type":"code","source":"# Model Evaluation Metrics\ntrain_job_output_response = client.job_output(train_response['data']['jobId'])\ntrain_job_output_response ","execution_count":null,"outputs":[]},{"metadata":{"id":"dPpdITVmO-uG","outputId":"c5eb3450-eac8-4e7b-e349-dc3c1a7d5829","trusted":false},"cell_type":"code","source":"# Error rate if predictions are given based in mean of the target variable\nprint(data[label].mean())\nprint(data[label].std())\n\n# here label is the target variable ","execution_count":null,"outputs":[]},{"metadata":{"id":"PQBjSOEyPEIZ","trusted":false},"cell_type":"code","source":"# load the predictions data set and preprocess it as per training\nlife_exp_predictions = preprocessor.read_csv('Life Expectancy Data test.csv',usecols= feature)\nj = preprocessor.read_csv('Life Expectancy Data test.csv')\nactual = j['Life expectancy ']\n\n# further processing of predictions_data set  \nscaler.fit(life_exp_predictions)\nscaled_data_t=scaler.transform(life_exp_predictions)\nlife_exp_predictions= pd.DataFrame(scaled_data_t, columns = life_exp_predictions.columns)\nlife_exp_predictions.to_csv('life_exp_predictions.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"_p7tydqqPKXe","outputId":"3d109987-496f-44e7-f132-a408522c6350","trusted":false},"cell_type":"code","source":"test_file_store_response = client.store('life_exp_predictions.csv', Dataset.TEST_DATA)\nprint(test_file_store_response)\ntest_data = test_file_store_response['fileUrl']","execution_count":null,"outputs":[]},{"metadata":{"id":"ZYP0ShoJGiGY"},"cell_type":"markdown","source":"## Testing"},{"metadata":{"id":"kwenFRPUPOZo","outputId":"dc772a7d-5164-4560-af1e-e0029e00a44b","trusted":false},"cell_type":"code","source":"# load the model built\nmodel = train_job_output_response['output']['modelUrl']\nmodel","execution_count":null,"outputs":[]},{"metadata":{"id":"XVrnxifBPTUa","outputId":"16339c1c-1fe6-4bd2-ee43-cc4952e44f80","trusted":false},"cell_type":"code","source":"# Predict using created ML Model\npredict_response = client.predict(task, test_data, model, library,features=feature)\npredict_response","execution_count":null,"outputs":[]},{"metadata":{"id":"ZXhWdU1PPW9O","outputId":"33bc3b14-1e43-4a0c-8b3e-a1b36dce9885","trusted":false},"cell_type":"code","source":"predict_job_status_response = client.job_status(predict_response['data']['jobId'])\npredict_job_status_response","execution_count":null,"outputs":[]},{"metadata":{"id":"9WFE_JIfPcWy","outputId":"800ef8a0-8cce-4548-8d1d-f72814b20598","trusted":false},"cell_type":"code","source":"predict_job_output_response = client.job_output(predict_response['data']['jobId'])\npredict_job_output_response","execution_count":null,"outputs":[]},{"metadata":{"id":"A6KPce88Wh8z","trusted":false},"cell_type":"code","source":"pred_file = predict_job_output_response['output']['predFileUrl']\nresponse = client.download(pred_file)","execution_count":null,"outputs":[]},{"metadata":{"id":"9FMxWSUNWkVT","outputId":"4a3ec7f1-35e4-415c-b251-e3f71c83c4a6","trusted":false},"cell_type":"code","source":"from io import StringIO\nimport pandas as pd\npred_data = StringIO(response.text)\ndf = pd.read_csv(pred_data, sep=\",\")\ndf","execution_count":null,"outputs":[]},{"metadata":{"id":"WI0_YMw5WmYU","outputId":"d887f3ce-4dad-46c8-acbd-8fb426d51398","trusted":false},"cell_type":"code","source":"# creating a dataframe for comparing model predictions and actual value\nactual_predicted = pd.DataFrame(df['Life expectancy '])\nactual_predicted['actual'] = actual\nactual_predicted.columns = ['model_prediction', 'actual']\nactual_predicted","execution_count":null,"outputs":[]},{"metadata":{"id":"fateNCqlWodC","outputId":"20bc7aae-692e-4f65-837a-fed3e646e1b2","trusted":false},"cell_type":"code","source":"# for regression problems we use R^2 metric \n# using sklearn packagge for calculating r^2 value\nfrom sklearn.metrics import r2_score \nr2_score(actual,df['_score'])","execution_count":null,"outputs":[]},{"metadata":{"id":"5Nqd4Qe2ot0o","outputId":"1f0b4d23-0707-41ce-fc05-e8c9c9b5a222","trusted":false},"cell_type":"code","source":"sns.regplot(x=actual,y=df['_score'])","execution_count":null,"outputs":[]},{"metadata":{"id":"za4Bcw4mzPaN"},"cell_type":"markdown","source":"# <font color=red> Model Two "},{"metadata":{"id":"Eq_Nwxl1GpTP"},"cell_type":"markdown","source":"## Creating Model"},{"metadata":{"id":"tsZNsq3jzPaN","outputId":"a3230713-e12e-434a-bb9a-8ca14a23d05b","trusted":false},"cell_type":"code","source":"# Create ML Model\n# Its a regression problem, where we need to predict  \"Life Expectancy\" which is a continous value\ntask = \"regression\"\n\n# Library to use (scikit, weka, h2o)\nlibrary = 'weka'\nalgorithm = \"RandomForest\"\n\nremoved_features =  ['percentage expenditure',\n                     \n                     'Population','Hepatitis B'\n                    ]\nnp.random.seed(42)\n# features to be used for training\nfeatures = ['Adult Mortality',\n       'Alcohol', ' BMI ',\n       'under-five deaths ', 'Polio',\n       ' HIV/AIDS', ' thinness  1-19 years', 'infant deaths','Schooling','Total expenditure','Measles ','Diphtheria ','Income composition of resources']  \n# Label to predict\nlabel = 'Life expectancy '\n# Train-test split percentage\ntrain_percentage = 80\n\n# Save model \nsave_model = 'true'\ntrain_response = client.train(task,\n                              algorithm,\n                              train_data,\n                              label,\n                              features,\n                              \"Life Expectancy Prediction Model\",\n                              library,\n                              train_percentage,\n                              save_model)\nprint(train_response)","execution_count":null,"outputs":[]},{"metadata":{"id":"uXkXep2mGstZ"},"cell_type":"markdown","source":"## Training"},{"metadata":{"id":"LdJVhzs2zPaN"},"cell_type":"markdown","source":"<font color=blue>Checking training status</font>\n\nAs training a model might take lot of time depending on size of dataset, we can check current status of model training using below functions"},{"metadata":{"id":"KEJVGYUszPaO","outputId":"cc2b99ee-379a-4da0-f341-cc1515bb2a69","trusted":false},"cell_type":"code","source":"train_job_status_response = client.job_status(train_response['data']['jobId'])\nprint(train_job_status_response)\nprint(json.dumps(train_job_status_response, indent=2))","execution_count":null,"outputs":[]},{"metadata":{"id":"yRGEn-ELzPaO","outputId":"9a8bb65d-189f-4af6-c1ff-a240c678e6f3","trusted":false},"cell_type":"code","source":"# Model Evaluation Metrics\ntrain_job_output_response = client.job_output(train_response['data']['jobId'])\ntrain_job_output_response","execution_count":null,"outputs":[]},{"metadata":{"id":"nh-yM8lnzPaO","outputId":"b4a6f641-80cb-4a9b-9968-db49e09c23be","trusted":false},"cell_type":"code","source":"# Error rate if predictions are given based in mean of the target variable\nprint(data[label].mean())\nprint(data[label].std())\n\n# here label is the target variable ","execution_count":null,"outputs":[]},{"metadata":{"id":"VIwzfGwUzPaP","trusted":false},"cell_type":"code","source":"# load the predictions data set and preprocess it as per training\nlife_exp_predictions = preprocessor.read_csv('Life Expectancy Data test.csv',usecols= features)\nj = preprocessor.read_csv('Life Expectancy Data test.csv')\nactual = j['Life expectancy ']","execution_count":null,"outputs":[]},{"metadata":{"id":"u41C0MuAzPaP","trusted":false},"cell_type":"code","source":"# further processing of predictions_data set  ","execution_count":null,"outputs":[]},{"metadata":{"id":"EX9741xczPaP","trusted":false},"cell_type":"code","source":"scaler.fit(life_exp_predictions)\nscaled_data_t=scaler.transform(life_exp_predictions)\nlife_exp_predictions= pd.DataFrame(scaled_data_t, columns = life_exp_predictions.columns)\nlife_exp_predictions.to_csv('life_exp_predictions.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"uJk2tqGizPaR","outputId":"9de6ed84-75af-4110-d46d-a2d42f4421d1","trusted":false},"cell_type":"code","source":"life_exp_predictions.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"cT9T3PQ2zPaS","outputId":"0cf77ec0-a386-4e06-86c7-4e68072e9cc5","trusted":false},"cell_type":"code","source":"# Upload test dataset\ntest_file_store_response = client.store('life_exp_predictions.csv', Dataset.TEST_DATA)\nprint(test_file_store_response)\ntest_data = test_file_store_response['fileUrl']","execution_count":null,"outputs":[]},{"metadata":{"id":"yJhaLZGJzPaS"},"cell_type":"markdown","source":"## Testing"},{"metadata":{"id":"PADHqjX-zPaT","outputId":"bbf27dd0-f9e3-4a8c-c664-18813172238b","trusted":false},"cell_type":"code","source":"# load the model built\nmodel = train_job_output_response['output']['modelUrl']\nmodel","execution_count":null,"outputs":[]},{"metadata":{"id":"tnMD3XVdzPaT","outputId":"3e8f8e4b-cc86-4f65-8c41-d51fc94b8ddb","trusted":false},"cell_type":"code","source":"# Predict using created ML Model\npredict_response = client.predict(task, test_data, model, library)\npredict_response","execution_count":null,"outputs":[]},{"metadata":{"id":"rat5tYCizPaU","outputId":"f8733d76-357c-42f0-e390-cd87fbd1bba3","trusted":false},"cell_type":"code","source":"predict_job_status_response = client.job_status(predict_response['data']['jobId'])\npredict_job_status_response","execution_count":null,"outputs":[]},{"metadata":{"id":"RYBBZ7kyzPaU","outputId":"09cd4866-812a-4c4e-8512-5567671e16d8","trusted":false},"cell_type":"code","source":"predict_job_output_response = client.job_output(predict_response['data']['jobId'])\npredict_job_output_response","execution_count":null,"outputs":[]},{"metadata":{"id":"Roq45iCjzPaV","trusted":false},"cell_type":"code","source":"pred_file = predict_job_output_response['output']['predFileUrl']\nresponse = client.download(pred_file)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"id":"h3x1BAXlzPaV","outputId":"e5868e4a-0431-41fc-e735-b33b84644955","trusted":false},"cell_type":"code","source":"from io import StringIO\nimport pandas as pd\npred_data = StringIO(response.text)\ndf = pd.read_csv(pred_data, sep=\",\")\ndf","execution_count":null,"outputs":[]},{"metadata":{"id":"0d_dep_MzPaW","outputId":"30fd5a12-0809-4108-fa41-7fe26e4217d5","trusted":false},"cell_type":"code","source":"# creating a dataframe for comparing model predictions and actual value\nactual_predicted = pd.DataFrame(df['Life expectancy '])\nactual_predicted['actual'] = actual\nactual_predicted.columns = ['model_prediction', 'actual']\nactual_predicted","execution_count":null,"outputs":[]},{"metadata":{"id":"uLaiFB3FzPaW","outputId":"f31e39f9-baaa-40ba-b7c3-3bd69f34e426","trusted":false},"cell_type":"code","source":"# for regression problems we use R^2 metric \n# using sklearn packagge for calculating r^2 value\nfrom sklearn.metrics import r2_score \nr2_score(actual,df['_score']) ","execution_count":null,"outputs":[]},{"metadata":{"id":"PD5ceuacqvq2","outputId":"4bba3d78-335a-4320-8956-e5146b886a7e","trusted":false},"cell_type":"code","source":"sns.regplot(x=actual,y=df['_score'])","execution_count":null,"outputs":[]},{"metadata":{"id":"ugtE36h87xso"},"cell_type":"markdown","source":"\n\n# <font color=red> Model Three"},{"metadata":{"id":"p8inIrfIG4Ce"},"cell_type":"markdown","source":"## Creating Model"},{"metadata":{"id":"QGlFOeys8E_D","outputId":"d01a3f18-e986-46aa-8620-a871fad02560","trusted":false},"cell_type":"code","source":"# Create ML Model\n# Its a regression problem, where we need to predict  \"Life Expectancy\" which is a continous value\ntask = \"regression\"\n\n# Library to use (scikit, weka, h2o)\nlibrary = 'weka'\nalgorithm = \"RandomForest\"\n\nremoved_features =  ['Measles ', 'percentage expenditure',\n                     'infant deaths','Diphtheria ', 'Total expenditure',\n                     'Population'\n                     'Hepatitis B']\nnp.random.seed(42)\n# features to be used for training\nfeatures = ['Income composition of resources', \n            'Schooling',\n            ' thinness  1-19 years',\n            ' HIV/AIDS',\n            'Adult Mortality']  \n# Label to predict\nlabel = 'Life expectancy '\n# Train-test split percentage\ntrain_percentage = 95\n\n# Save model \nsave_model = True\ntrain_response = client.train(task,\n                              algorithm,\n                              train_data,\n                              label,\n                              features,\n                              \"Life Expectancy Prediction Model\",\n                              library,\n                              train_percentage,\n                              save_model)\nprint(train_response)","execution_count":null,"outputs":[]},{"metadata":{"id":"Cbr6g_rOG77V"},"cell_type":"markdown","source":"## Training"},{"metadata":{"id":"1Z_Ldz_s8uCk","outputId":"b6850622-68b2-49b6-b384-84bc4ae07503","trusted":false},"cell_type":"code","source":"train_job_status_response = client.job_status(train_response['data']['jobId'])\nprint(train_job_status_response)\nprint(json.dumps(train_job_status_response, indent=2))","execution_count":null,"outputs":[]},{"metadata":{"id":"6rsOr_1A-k3F","outputId":"00fdfd66-ede8-49b1-f9a8-a3b8e87e5c98","trusted":false},"cell_type":"code","source":"# Model Evaluation Metrics\ntrain_job_output_response = client.job_output(train_response['data']['jobId'])\ntrain_job_output_response","execution_count":null,"outputs":[]},{"metadata":{"id":"vbcbgKm9-pRN","outputId":"4291c46e-fed1-4250-e7a7-8005fd1f2d83","trusted":false},"cell_type":"code","source":"# Error rate if predictions are given based in mean of the target variable\nprint(data[label].mean())\nprint(data[label].std())\n\n# here label is the target variable ","execution_count":null,"outputs":[]},{"metadata":{"id":"WUq-WoWUNt4G","trusted":false},"cell_type":"code","source":"# load the predictions data set and preprocess it as per training\nlife_exp_predictions = preprocessor.read_csv('Life Expectancy Data test.csv',usecols= features)\nj = preprocessor.read_csv('Life Expectancy Data test.csv')\nactual = j['Life expectancy ']\n\n# further processing of predictions_data set  \nscaler.fit(life_exp_predictions)\nscaled_data_t=scaler.transform(life_exp_predictions)\nlife_exp_predictions= pd.DataFrame(scaled_data_t, columns = life_exp_predictions.columns)\nlife_exp_predictions.to_csv('life_exp_predictions.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"cJUcbBcuNuiR","outputId":"7fa0dae6-5288-40bb-dfab-0ab532dfe2b7","trusted":false},"cell_type":"code","source":"# Upload test dataset\ntest_file_store_response = client.store('life_exp_predictions.csv', Dataset.TEST_DATA)\nprint(test_file_store_response)\ntest_data = test_file_store_response['fileUrl']","execution_count":null,"outputs":[]},{"metadata":{"id":"6JB9iMtIHIDf"},"cell_type":"markdown","source":"## Testing"},{"metadata":{"id":"sYOiAY3eN2fM","outputId":"fe06ac67-6e1e-46a1-fb50-cf9f1aa85d30","trusted":false},"cell_type":"code","source":"# load the model built\nmodel = train_job_output_response['output']['modelUrl']\nmodel","execution_count":null,"outputs":[]},{"metadata":{"id":"sJm9pm-4N54z","outputId":"961715aa-c4cb-41c1-cbd5-82cda75daaee","trusted":false},"cell_type":"code","source":"# Predict using created ML Model\npredict_response = client.predict(task, test_data, model, library)\npredict_response","execution_count":null,"outputs":[]},{"metadata":{"id":"XddvTGjtN-Qx","outputId":"45431d64-d8a5-4be0-c872-68428dacba4d","trusted":false},"cell_type":"code","source":"predict_job_status_response = client.job_status(predict_response['data']['jobId'])\npredict_job_status_response","execution_count":null,"outputs":[]},{"metadata":{"id":"9cLOjU9pOE9P","outputId":"a578d04c-1a5d-4b7d-fd29-45d49b4fd765","trusted":false},"cell_type":"code","source":"predict_job_output_response = client.job_output(predict_response['data']['jobId'])\npredict_job_output_response","execution_count":null,"outputs":[]},{"metadata":{"id":"6VXAJFhO-ux7","trusted":false},"cell_type":"code","source":"pred_file = predict_job_output_response['output']['predFileUrl']\nresponse = client.download(pred_file)","execution_count":null,"outputs":[]},{"metadata":{"id":"HUaRoBqZ-yt6","outputId":"18bc2b6e-cce5-4aab-af83-43b15fd99c6e","trusted":false},"cell_type":"code","source":"from io import StringIO\nimport pandas as pd\npred_data = StringIO(response.text)\ndf = pd.read_csv(pred_data, sep=\",\")\ndf","execution_count":null,"outputs":[]},{"metadata":{"id":"Gex3hRjm-3O5","outputId":"d35731cb-d818-4774-8b4b-1ca4ef6dff69","trusted":false},"cell_type":"code","source":"# creating a dataframe for comparing model predictions and actual value\nactual_predicted = pd.DataFrame(df['Life expectancy '])\nactual_predicted['actual'] = actual\nactual_predicted.columns = ['model_prediction', 'actual']\nactual_predicted","execution_count":null,"outputs":[]},{"metadata":{"id":"gGRN6KmZ-7zD","outputId":"8e746bdc-4e66-4daf-ad1d-3444688c081e","trusted":false},"cell_type":"code","source":"# for regression problems we use R^2 metric \n# using sklearn packagge for calculating r^2 value\nfrom sklearn.metrics import r2_score \nr2_score(actual,df['_score']) ","execution_count":null,"outputs":[]},{"metadata":{"id":"j45QFPtACsaO","outputId":"5855694a-ba5e-49a7-9a57-725985d3ce1e","trusted":false},"cell_type":"code","source":"actual_predicted.columns","execution_count":null,"outputs":[]},{"metadata":{"id":"ykbenr3eGVQR","outputId":"0447f5f5-e3e5-43fb-e677-f23b23c67c5b","trusted":false},"cell_type":"code","source":"sns.regplot(x=actual,y=df['_score'])","execution_count":null,"outputs":[]},{"metadata":{"id":"EkDDYDTAzPaL"},"cell_type":"markdown","source":"# <font color=red> Model Four"},{"metadata":{"id":"x233F0ZWHOTF"},"cell_type":"markdown","source":"## Creating Model"},{"metadata":{"id":"4xxeNaqSzPaM","outputId":"f4168c5b-897d-4919-a351-4b030e15e8b2","trusted":false},"cell_type":"code","source":"# Create ML Model\n# Its a regression problem, where we need to predict  \"Life Expectancy\" which is a continous value\ntask = \"regression\"\n\n# Library to use (scikit, weka, h2o)\nlibrary = 'weka'\nalgorithm = \"RandomForest\"\n\nremoved_features =  ['Measles ', \n                     'percentage expenditure',\n                     'infant deaths',\n                     'Diphtheria ', \n                     'Total expenditure',\n                     'Population',\n                     ' HIV/AIDS', \n                     'Schooling',\n                     'Hepatitis B']\nnp.random.seed(42)\n# features to be used for training\nfeatures = ['Adult Mortality',\n       'Alcohol', ' BMI ',\n       'under-five deaths ', 'Polio',\n        ' thinness  1-19 years','Income composition of resources']  \n# Label to predict\nlabel = 'Life expectancy '\n# Train-test split percentage\ntrain_percentage = 80\n\n# Save model \nsave_model = True\ntrain_response = client.train(task,\n                              algorithm,\n                              train_data,\n                              label,\n                              features,\n                              \"Life Expectancy Prediction Model1\",\n                              library,\n                              train_percentage,\n                              save_model)\nprint(train_response)","execution_count":null,"outputs":[]},{"metadata":{"id":"w4v551DiHRkH"},"cell_type":"markdown","source":"## Training"},{"metadata":{"id":"hM5PVhrlzPaM"},"cell_type":"markdown","source":"<font color=blue>Checking training status</font>"},{"metadata":{"id":"nlF75xJwzPaM","outputId":"b554d544-76c9-45c2-b8b1-c4372d321f4c","trusted":false},"cell_type":"code","source":"train_job_status_response = client.job_status(train_response['data']['jobId'])\nprint(train_job_status_response)\nprint(json.dumps(train_job_status_response, indent=2))","execution_count":null,"outputs":[]},{"metadata":{"id":"vTpnnyvNzPaM","outputId":"05ed7a96-3ca5-403b-f46c-cdb991f40958","trusted":false},"cell_type":"code","source":"# Model Evaluation Metrics\ntrain_job_output_response = client.job_output(train_response['data']['jobId'])\ntrain_job_output_response ","execution_count":null,"outputs":[]},{"metadata":{"id":"OH5zKdkNzPaN","outputId":"c5b39332-8283-46fa-cfa6-c35fc65544be","trusted":false},"cell_type":"code","source":"# Error rate if predictions are given based in mean of the target variable\nprint(data[label].mean())\nprint(data[label].std())\n\n# here label is the target variable ","execution_count":null,"outputs":[]},{"metadata":{"id":"DqyJI2r8LCuz","trusted":false},"cell_type":"code","source":"# load the predictions data set and preprocess it as per training\nlife_exp_predictions = preprocessor.read_csv('Life Expectancy Data test.csv',usecols= features)\nj = preprocessor.read_csv('Life Expectancy Data test.csv')\nactual = j['Life expectancy ']\n\n# further processing of predictions_data set  \nscaler.fit(life_exp_predictions)\nscaled_data_t=scaler.transform(life_exp_predictions)\nlife_exp_predictions= pd.DataFrame(scaled_data_t, columns = life_exp_predictions.columns)\nlife_exp_predictions.to_csv('life_exp_predictions.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"S4A6Bi7NK_YZ","outputId":"44ae5fc7-494c-42ac-beca-7527f02611f1","trusted":false},"cell_type":"code","source":"test_file_store_response = client.store('life_exp_predictions.csv', Dataset.TEST_DATA)\nprint(test_file_store_response)\ntest_data = test_file_store_response['fileUrl']","execution_count":null,"outputs":[]},{"metadata":{"id":"-zV9oUBNHTsU"},"cell_type":"markdown","source":"## Testing"},{"metadata":{"id":"3v-aohwkLPcr","outputId":"3f3fb9b9-2311-4f3b-8e1b-e49acc9062f0","trusted":false},"cell_type":"code","source":"# load the model built\nmodel = train_job_output_response['output']['modelUrl']\nmodel","execution_count":null,"outputs":[]},{"metadata":{"id":"IJiQG6lwLVhC","outputId":"5c97f768-a380-4e1c-c0aa-3b32ffeb63ca","trusted":false},"cell_type":"code","source":"# Predict using created ML Model\npredict_response = client.predict(task, test_data, model, library,features=features)\npredict_response","execution_count":null,"outputs":[]},{"metadata":{"id":"rtW2_LsjLZkZ","outputId":"28ec6647-d348-4bd3-bdbb-c47fdddcc2ff","trusted":false},"cell_type":"code","source":"predict_job_status_response = client.job_status(predict_response['data']['jobId'])\npredict_job_status_response","execution_count":null,"outputs":[]},{"metadata":{"id":"PTapC2bwzPaN","outputId":"d032b781-826d-4577-b684-1c37e2dca141","trusted":false},"cell_type":"code","source":"predict_job_output_response = client.job_output(predict_response['data']['jobId'])\npredict_job_output_response","execution_count":null,"outputs":[]},{"metadata":{"id":"oyswQVNKMOR2","trusted":false},"cell_type":"code","source":"pred_file = predict_job_output_response['output']['predFileUrl']\nresponse = client.download(pred_file)","execution_count":null,"outputs":[]},{"metadata":{"id":"OocHBT-gMSKQ","outputId":"c1ec251b-0a4e-43e2-eb48-30699fbb8194","trusted":false},"cell_type":"code","source":"from io import StringIO\nimport pandas as pd\npred_data = StringIO(response.text)\ndf = pd.read_csv(pred_data, sep=\",\")\ndf","execution_count":null,"outputs":[]},{"metadata":{"id":"fusKAuTnMUnI","outputId":"f09e120d-51c4-446d-c2d1-a18914d232af","trusted":false},"cell_type":"code","source":"# creating a dataframe for comparing model predictions and actual value\nactual_predicted = pd.DataFrame(df['Life expectancy '])\nactual_predicted['actual'] = actual\nactual_predicted.columns = ['model_prediction', 'actual']\nactual_predicted","execution_count":null,"outputs":[]},{"metadata":{"id":"UnK2vYxrMXXC","outputId":"1415b126-9745-41e2-84f9-c779cdff362a","trusted":false},"cell_type":"code","source":"# for regression problems we use R^2 metric \n# using sklearn packagge for calculating r^2 value\nfrom sklearn.metrics import r2_score \nr2_score(actual,df['_score'])","execution_count":null,"outputs":[]},{"metadata":{"id":"lGJHnU5iq3KJ","outputId":"26de7158-1d9b-41f8-90f9-c353dc180d5d","trusted":false},"cell_type":"code","source":"sns.regplot(x=actual,y=df['_score'])","execution_count":null,"outputs":[]},{"metadata":{"id":"4nqQ-k0UraWH"},"cell_type":"markdown","source":"# <font color=red> Model Five"},{"metadata":{"id":"MiR331bzHW5z"},"cell_type":"markdown","source":"## Creating Model"},{"metadata":{"id":"jJLJefjHrdlK","outputId":"5f00c717-7697-483a-cc4b-24f5b9f11d6c","trusted":false},"cell_type":"code","source":"# Create ML Model\n# Its a regression problem, where we need to predict  \"Life Expectancy\" which is a continous value\ntask = \"regression\"\n\n# Library to use (scikit, weka, h2o)\nlibrary = 'weka'\nalgorithm = \"RandomForest\"\n\nremoved_features =  [ \n                   'Total expenditure','Schooling','under-five deaths ', ' BMI ', 'Polio', 'Measles ' \n                   , 'Population', 'percentage expenditure'\n                     ]\nnp.random.seed(24)\n# features to be used for training\n\n\nfeatures = ['Adult Mortality','Hepatitis B',' thinness  1-19 years',\n            ' HIV/AIDS','Diphtheria ','Income composition of resources','infant deaths'\n       , 'Alcohol'] \n\n\n# Label to predict\nlabel = 'Life expectancy '\n# Train-test split percentage\ntrain_percentage = 90\n\n# Save model \nsave_model = 'true'\ntrain_response = client.train(task,\n                              algorithm,\n                              train_data,\n                              label,\n                              features,\n                              \"Life Expectancy Prediction Model\",\n                              library,\n                              train_percentage,\n                              save_model)\nprint(train_response)","execution_count":null,"outputs":[]},{"metadata":{"id":"JWueCeShHZB8"},"cell_type":"markdown","source":"## Training"},{"metadata":{"id":"vsEANJwWsOwf","outputId":"15200396-6c9d-45b7-c5e7-d073affd1445","trusted":false},"cell_type":"code","source":"train_job_status_response = client.job_status(train_response['data']['jobId'])\nprint(train_job_status_response)\nprint(json.dumps(train_job_status_response, indent=2))","execution_count":null,"outputs":[]},{"metadata":{"id":"H9bupwr5sT8A","outputId":"28621afa-2728-4930-a5ab-dfccffd9dd62","trusted":false},"cell_type":"code","source":"# Model Evaluation Metrics\ntrain_job_output_response = client.job_output(train_response['data']['jobId'])\ntrain_job_output_response ","execution_count":null,"outputs":[]},{"metadata":{"id":"9OJk7nk1sZPw","outputId":"c37342c5-1a3d-4fbf-89a9-a5991d89ad96","trusted":false},"cell_type":"code","source":"# Error rate if predictions are given based in mean of the target variable\nprint(data[label].mean())\nprint(data[label].std())\n\n# here label is the target variable ","execution_count":null,"outputs":[]},{"metadata":{"id":"M0cIhTpasdSm","trusted":false},"cell_type":"code","source":"# load the predictions data set and preprocess it as per training\nlife_exp_predictions = preprocessor.read_csv('Life Expectancy Data test.csv',usecols= features)\nj = preprocessor.read_csv('Life Expectancy Data test.csv')\nactual = j['Life expectancy ']\n\n# further processing of predictions_data set  \nscaler.fit(life_exp_predictions)\nscaled_data_t=scaler.transform(life_exp_predictions)\nlife_exp_predictions= pd.DataFrame(scaled_data_t, columns = life_exp_predictions.columns)\nlife_exp_predictions.to_csv('life_exp_predictions.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"p8m84It9shT3","outputId":"5dcc3f3e-eda5-4e15-c775-7aaf7a764f5c","trusted":false},"cell_type":"code","source":"test_file_store_response = client.store('life_exp_predictions.csv', Dataset.TEST_DATA)\nprint(test_file_store_response)\ntest_data = test_file_store_response['fileUrl']","execution_count":null,"outputs":[]},{"metadata":{"id":"25EC32GXHbCN"},"cell_type":"markdown","source":"## Testing"},{"metadata":{"id":"C2MT0a3rsk9m","outputId":"aa43af32-d0c0-4de0-a2e1-cac28ae78547","trusted":false},"cell_type":"code","source":"# load the model built\nmodel = train_job_output_response['output']['modelUrl']\nmodel","execution_count":null,"outputs":[]},{"metadata":{"id":"TVkWFIaesoh7","outputId":"74d3bcd1-8e78-4e4d-d597-7a2b92edc93d","trusted":false},"cell_type":"code","source":"# Predict using created ML Model\npredict_response = client.predict(task, test_data, model, library,features=features)\npredict_response","execution_count":null,"outputs":[]},{"metadata":{"id":"7GxYOXOZswr1","outputId":"4635fc42-bfea-4d60-89ef-5d449be964b3","trusted":false},"cell_type":"code","source":"predict_job_status_response = client.job_status(predict_response['data']['jobId'])\npredict_job_status_response","execution_count":null,"outputs":[]},{"metadata":{"id":"VjDfNx9CsxVw","outputId":"0854ec5d-216a-45d6-c7d5-3ff2f65908f2","trusted":false},"cell_type":"code","source":"predict_job_output_response = client.job_output(predict_response['data']['jobId'])\npredict_job_output_response","execution_count":null,"outputs":[]},{"metadata":{"id":"tGflZ9-as1Eq","trusted":false},"cell_type":"code","source":"pred_file = predict_job_output_response['output']['predFileUrl']\nresponse = client.download(pred_file)","execution_count":null,"outputs":[]},{"metadata":{"id":"EBIPNxa1s8we","outputId":"24fc8a7f-548d-4826-b6b7-287e2c294ddd","trusted":false},"cell_type":"code","source":"from io import StringIO\nimport pandas as pd\npred_data = StringIO(response.text)\ndf = pd.read_csv(pred_data, sep=\",\")\ndf","execution_count":null,"outputs":[]},{"metadata":{"id":"nrvva0BttAff","outputId":"bf05b9b8-a32b-4f90-85c0-2502385a8d7c","trusted":false},"cell_type":"code","source":"# creating a dataframe for comparing model predictions and actual value\nactual_predicted = pd.DataFrame(df['Life expectancy '])\nactual_predicted['actual'] = actual\nactual_predicted.columns = ['model_prediction', 'actual']\nactual_predicted","execution_count":null,"outputs":[]},{"metadata":{"id":"AXMAwFngtEVG","outputId":"cae13354-d406-4b1c-e2d3-624518dd0678","trusted":false},"cell_type":"code","source":"# for regression problems we use R^2 metric \n# using sklearn packagge for calculating r^2 value\nfrom sklearn.metrics import r2_score \nr2_score(actual,df['_score'])","execution_count":null,"outputs":[]},{"metadata":{"id":"sB9mFYHUtHhq","outputId":"c41e3a56-3dd0-4820-b70b-433a21e3246a","trusted":false},"cell_type":"code","source":"sns.regplot(x=actual,y=df['_score'])","execution_count":null,"outputs":[]},{"metadata":{"id":"3y8AxpxJ03sv"},"cell_type":"markdown","source":"# <font color=red> Model Six"},{"metadata":{"id":"xZtvHKL9HeNF"},"cell_type":"markdown","source":"## Creating Model"},{"metadata":{"id":"7ICF86yw03s1","outputId":"0cbb335c-1c7d-4d09-ee7e-09bf56739de5","trusted":false},"cell_type":"code","source":"# Create ML Model\n# Its a regression problem, where we need to predict  \"Life Expectancy\" which is a continous value\ntask = \"regression\"\n\n# Library to use (scikit, weka, h2o)\nlibrary = 'weka'\nalgorithm = \"RandomForest\"\n\nremoved_features =  [ \n                   'Total expenditure','Schooling','under-five deaths ', ' BMI ', 'Measles ' \n                   ,  'percentage expenditure','Population'\n                     ]\nnp.random.seed(24)\n# features to be used for training\n\n\nfeatures = ['Adult Mortality','Hepatitis B',' thinness  1-19 years','Year','under-five deaths ','Polio',\n            ' HIV/AIDS','Diphtheria ','Income composition of resources','infant deaths', 'Alcohol'] \n\n\n# Label to predict\nlabel = 'Life expectancy '\n# Train-test split percentage\ntrain_percentage = 90\n\n# Save model \nsave_model = 'true'\ntrain_response = client.train(task,\n                              algorithm,\n                              train_data,\n                              label,\n                              features,\n                              \"Life Expectancy Prediction Model\",\n                              library,\n                              train_percentage,\n                              save_model)\nprint(train_response)","execution_count":null,"outputs":[]},{"metadata":{"id":"4_bl2D_wHhNd"},"cell_type":"markdown","source":"## Training"},{"metadata":{"id":"NE6m-DDR03s3","outputId":"d4bee38f-e06a-41cd-aa41-e08c5941d3f5","trusted":false},"cell_type":"code","source":"train_job_status_response = client.job_status(train_response['data']['jobId'])\nprint(train_job_status_response)\nprint(json.dumps(train_job_status_response, indent=2))","execution_count":null,"outputs":[]},{"metadata":{"id":"kpTaYzL303s4","outputId":"a9f088ec-5776-4cc7-d9f3-1f340c4908c0","trusted":false},"cell_type":"code","source":"# Model Evaluation Metrics\ntrain_job_output_response = client.job_output(train_response['data']['jobId'])\ntrain_job_output_response ","execution_count":null,"outputs":[]},{"metadata":{"id":"klzflcn-03s5","outputId":"17f29156-3646-480b-c479-4d6532984121","trusted":false},"cell_type":"code","source":"# Error rate if predictions are given based in mean of the target variable\nprint(data[label].mean())\nprint(data[label].std())\n\n# here label is the target variable ","execution_count":null,"outputs":[]},{"metadata":{"id":"DE3wlXZN03s6","trusted":false},"cell_type":"code","source":"# load the predictions data set and preprocess it as per training\nlife_exp_predictions = preprocessor.read_csv('Life Expectancy Data test.csv',usecols= features)\nj = preprocessor.read_csv('Life Expectancy Data test.csv')\nactual = j['Life expectancy ']\n\n# further processing of predictions_data set  \nscaler.fit(life_exp_predictions)\nscaled_data_t=scaler.transform(life_exp_predictions)\nlife_exp_predictions= pd.DataFrame(scaled_data_t, columns = life_exp_predictions.columns)\nlife_exp_predictions.to_csv('life_exp_predictions.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"3idg8dqq03s7","outputId":"9fa0e13e-c5ce-470b-8fc2-39a89a1da901","trusted":false},"cell_type":"code","source":"test_file_store_response = client.store('life_exp_predictions.csv', Dataset.TEST_DATA)\nprint(test_file_store_response)\ntest_data = test_file_store_response['fileUrl']","execution_count":null,"outputs":[]},{"metadata":{"id":"j-DwuyltHkwC"},"cell_type":"markdown","source":"## Testing"},{"metadata":{"id":"03v9CcZB03s8","outputId":"9b8c0d05-3aee-4d48-ec5e-163248e89634","trusted":false},"cell_type":"code","source":"# load the model built\nmodel = train_job_output_response['output']['modelUrl']\nmodel","execution_count":null,"outputs":[]},{"metadata":{"id":"wqe6RPjk03s8","outputId":"55419da3-60bf-42c8-a16d-967b0c2030c1","trusted":false},"cell_type":"code","source":"# Predict using created ML Model\npredict_response = client.predict(task, test_data, model, library,features=features)\npredict_response","execution_count":null,"outputs":[]},{"metadata":{"id":"pb9QWryZ03s8","outputId":"ad887677-e16e-41d9-e921-173890a3ee84","trusted":false},"cell_type":"code","source":"predict_job_status_response = client.job_status(predict_response['data']['jobId'])\npredict_job_status_response","execution_count":null,"outputs":[]},{"metadata":{"id":"tm5m8ZnW03s9","outputId":"0b07aab0-4458-42db-e66a-8d74cf6b2d4d","trusted":false},"cell_type":"code","source":"predict_job_output_response = client.job_output(predict_response['data']['jobId'])\npredict_job_output_response","execution_count":null,"outputs":[]},{"metadata":{"id":"VvTaQP0L03s9","trusted":false},"cell_type":"code","source":"pred_file = predict_job_output_response['output']['predFileUrl']\nresponse = client.download(pred_file)","execution_count":null,"outputs":[]},{"metadata":{"id":"qf8Nmipx03s9","outputId":"8a152835-1373-42ac-a0ec-e238dbd6f280","trusted":false},"cell_type":"code","source":"from io import StringIO\nimport pandas as pd\npred_data = StringIO(response.text)\ndf = pd.read_csv(pred_data, sep=\",\")\ndf","execution_count":null,"outputs":[]},{"metadata":{"id":"9QLSObCI03s-","outputId":"95607edd-43ae-4304-d687-a335c3044c2c","trusted":false},"cell_type":"code","source":"# creating a dataframe for comparing model predictions and actual value\nactual_predicted = pd.DataFrame(df['Life expectancy '])\nactual_predicted['actual'] = actual\nactual_predicted.columns = ['model_prediction', 'actual']\nactual_predicted","execution_count":null,"outputs":[]},{"metadata":{"id":"63tG-TUJ03s-","outputId":"db7e2a73-ab1e-415c-e25b-e1fa21213f41","trusted":false},"cell_type":"code","source":"# for regression problems we use R^2 metric \n# using sklearn packagge for calculating r^2 value\nfrom sklearn.metrics import r2_score \nr2_score(actual,df['_score'])","execution_count":null,"outputs":[]},{"metadata":{"id":"3o3IUOyC03s-","outputId":"0a394429-8ac7-44f6-edc0-92cf629ee501","trusted":false},"cell_type":"code","source":"sns.regplot(x=actual,y=df['_score'])","execution_count":null,"outputs":[]},{"metadata":{"id":"Jt_5CLGd2lPx"},"cell_type":"markdown","source":"# Summary"},{"metadata":{"id":"zYAZl6kb2ou1"},"cell_type":"markdown","source":"First, the dataset was cleaned and scaled. For scaling min-max scaler was used.\n\nAll the outliers were removed, using three different techniques, imputation, grouped mean and dropping.\nSpecific attributes were found to be highly correlated to the target variable, which was 'Life Expectancy'. \n\nModels were built by tweaking the parameters, to receive the highest accuracy.\nThe highest accuracy reached was 97.02% on test data.\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}