{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing libraries and data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Libraries for data analysis\nimport numpy as np\nimport pandas as pd\n\n# Libraries for Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/911-calls/911.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding out which column has missing data and how much ?\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What are the top 5 Zipcodes in the data set ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['zip'].value_counts().head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What are the top 5 township in the dataset ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['twp'].value_counts().head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How many unique title codes are there in the dataset ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['title'].nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** In the titles column there are \"Reasons/Departments\" specified before the title code. These are EMS, Fire, and Traffic. Use .apply() with a custom lambda expression to create a new column called \"Reason\" that contains this string value.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Reason'] = df['title'].apply(lambda title: title.split(':')[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What is the most common Reason for a 911 call based off of this new column?"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Reason'].value_counts()[:1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"seaborn to create a countplot of 911 calls by Reason."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style('whitegrid')\nsns.countplot(x='Reason', data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What is the data type of the objects in the timeStamp column?"},{"metadata":{"trusted":true},"cell_type":"code","source":"type(df['timeStamp'].iloc[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"pd.to_datetime to convert the column from strings to DateTime objects."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['timeStamp'] = pd.to_datetime(df['timeStamp'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Now that the timestamp column are actually DateTime objects, .apply() to create 3 new columns called Hour, Month, and Day of Week. You will create these columns based off of the timeStamp column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Hour'] = df['timeStamp'].apply(lambda time: time.hour)\ndf['Month'] = df['timeStamp'].apply(lambda time: time.month)\ndf['Day of Week'] = df['timeStamp'].apply(lambda time: time.dayofweek)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Notice how the Day of Week is an integer 0-6. Use the .map() with this dictionary to map the actual string names to the day of the week: **\n\ndmap = {0:'Mon',1:'Tue',2:'Wed',3:'Thu',4:'Fri',5:'Sat',6:'Sun'}"},{"metadata":{"trusted":true},"cell_type":"code","source":"dmap = {0:'Mon',1:'Tue',2:'Wed',3:'Thu',4:'Fri',5:'Sat',6:'Sun'}\n\ndf['Day of Week'] = df['Day of Week'].map(dmap)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seaborn to create a countplot of the Day of Week column with the hue based off of the Reason column."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Day of Week', data=df, hue='Reason')\nplt.legend(loc='best', bbox_to_anchor=(1.25,0.5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now same for Month:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Month', data=df, hue='Reason')\nplt.legend(bbox_to_anchor=(1.25,0.5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Simple line plot that fills in the missing months, in order to do this, we'll need to do some work with pandas...**\n\n** creating a gropuby object called byMonth, where you group the DataFrame by the month column and use the count() method for aggregation.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"byMonth = df.groupby('Month').count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"byMonth","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Creating a simple plot off of the dataframe indicating the count of calls per month. **"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Could be any column\nbyMonth['twp'].plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Seaborn's lmplot() to create a linear fit on the number of calls per month. Resetting the index to a column. **"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lmplot(x='Month', y='twp', data=byMonth.reset_index())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Creating a new column called 'Date' that contains the date from the timeStamp column. Using apply along with the .date() method. *"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Date'] = df['timeStamp'].apply(lambda time: time.date())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** groupby this Date column with the count() aggregate and create a plot of counts of 911 calls.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\ndf.groupby('Date').count()['twp'].plot()\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Recreating this plot but create 3 separate plots with each plot representing a Reason for the 911 call**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(nrows=3, figsize=(10,6))\n\ndf[df['Reason']=='EMS'].groupby('Date')['twp'].count().plot(ax=axs[0])\naxs[0].set_title('EMS',fontsize=15)\ndf[df['Reason']=='Traffic'].groupby('Date')['twp'].count().plot(ax=axs[1])\naxs[1].set_title('Traffic',fontsize=15)\ndf[df['Reason']=='Fire'].groupby('Date')['twp'].count().plot(ax=axs[2])\naxs[2].set_title('Fire',fontsize=15)\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Creating heatmaps with seaborn and our data.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dayHour = df.groupby(by=['Day of Week','Hour']).count()['Reason'].unstack()\ndayHour","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.heatmap(dayHour,cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Now create a clustermap using this DataFrame. **"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.clustermap(dayHour, cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** For a DataFrame that shows the Month as the column. **"},{"metadata":{"trusted":true},"cell_type":"code","source":"dayMonth = df.groupby(by=['Day of Week','Month']).count()['Reason'].unstack()\ndayMonth","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.heatmap(dayMonth, cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.clustermap(dayMonth, cmap='viridis')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}