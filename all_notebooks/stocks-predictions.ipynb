{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Time series prediction \n\nThe particular network architecture we will employ for our RNN is known as  [Long Term Short Memory (LTSM)](https://en.wikipedia.org/wiki/Long_short-term_memory), which helps significantly avoid technical problems with optimization of RNNs.  "},{"metadata":{},"cell_type":"markdown","source":"## 1.1 Getting started\n\nFirst we must load in our time series - a history of around 140 days of Apple's stock price.  Then we need to perform a number of pre-processing steps to prepare it for use with an RNN model.  First off, it is good practice to normalize time series - by normalizing its range.  This helps us avoid serious numerical issues associated how common activation functions (like tanh) transform very large (positive or negative) numbers, as well as helping us to avoid related issues when computing derivatives.\n\nHere we normalize the series to lie in the range [0,1] [using this scikit function](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html), but it is also commonplace to normalize by a series standard deviation."},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndataset = np.loadtxt('/kaggle/input/mydatasets/apple_prices.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets take a quick look at the time series we'll be performing predictions on."},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets take a look at our time series\nplt.plot(dataset)\nplt.xlabel('time period')\nplt.ylabel('series value')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### TODO: Normalize time series and plot it again"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ndataset = scaler.fit_transform(dataset.reshape(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets take a look at our time series\nplt.plot(dataset)\nplt.xlabel('time period')\nplt.ylabel('normalized series value')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.2  Cutting our time series into sequences\n\nRemember, our time series is a sequence of numbers that we can represent in general mathematically as \n\n$$s_{0},s_{1},s_{2},...,s_{P}$$\n\nwhere $s_{p}$ is the numerical value of the time series at time period $p$ and where $P$ is the total length of the series.  In order to apply our RNN we treat the time series prediction problem as a regression problem, and so need to use a sliding window to construct a set of associated input/output pairs to regress on.  This process is animated in the gif below."},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image\nImage(filename=\"../input/images/timeseries_windowing_training.gif\", width= 600, height=600)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For example - using a window of size T = 5 (as illustrated in the gif above) we produce a set of input/output pairs like the one shown in the table below\n\n$$\\begin{array}{c|c}\n\\text{Input} & \\text{Output}\\\\\n\\hline \\color{CornflowerBlue} {\\langle s_{1},s_{2},s_{3},s_{4},s_{5}\\rangle} & \\color{Goldenrod}{ s_{6}} \\\\\n\\ \\color{CornflowerBlue} {\\langle s_{2},s_{3},s_{4},s_{5},s_{6} \\rangle } & \\color{Goldenrod} {s_{7} } \\\\\n\\color{CornflowerBlue}  {\\vdots} & \\color{Goldenrod} {\\vdots}\\\\\n\\color{CornflowerBlue} { \\langle s_{P-5},s_{P-4},s_{P-3},s_{P-2},s_{P-1} \\rangle } & \\color{Goldenrod} {s_{P}}\n\\end{array}$$\n\nNotice here that each input is a sequence (or vector) of length 4 (and in general has length equal to the window size T) while each corresponding output is a scalar value.  Notice also how given a time series of length P and window size T = 5 as shown above, we created P - 5  input/output pairs.  More generally, for a window size T we create P - T such pairs."},{"metadata":{},"cell_type":"markdown","source":"Now its time for you to window the input time series as described above!  \n\n<a id='TODO_1'></a>\n\n**TODO:** Fill in the function below - called **window_transform_series** - that runs a sliding window along the input series and creates associated input/output pairs.    Note that this function should input a) the series and b) the window length, and return the input/output subsequences.  Make sure to format returned input/output as generally shown in table above (where window_size = 5), and make sure your returned input is a numpy array.\n\n-----"},{"metadata":{"trusted":true},"cell_type":"code","source":"### TODO: fill out the function below that transforms the input series and window-size into a set of input/output pairs for use with our RNN model\ndef window_transform_series(series, window_size):\n    X = []\n    y = []\n    for batch_start in range(len(series) - window_size):\n        batch = []\n        for batch_ind in range(0, window_size):\n            batch.append(series[batch_start + batch_ind])\n        X.append(batch)\n        y.append(series[batch_start + window_size])\n    \n    return np.array(X), np.array(y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can test your function on the list of odd numbers given below"},{"metadata":{"trusted":true},"cell_type":"code","source":"odd_nums = np.array([1,3,5,7,9,11,13])\n\n# run a window of size 2 over the odd number sequence and display the results\nwindow_size = 2\nX,y = window_transform_series(odd_nums,window_size)\n\n# print out input/output pairs --> here input = X, corresponding output = y\nprint ('--- the input X will look like ----')\nprint (X)\n\nprint ('--- the associated output y will look like ----')\nprint (y)\n\nprint ('the shape of X is ' + str(np.shape(X)))\nprint ('the shape of y is ' + str(np.shape(y)))\nprint('the type of X is ' + str(type(X)))\nprint('the type of y is ' + str(type(y)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With this function in place apply it to the series in the Python cell below.  We use a window_size = 7 for these experiments."},{"metadata":{"trusted":true},"cell_type":"code","source":"# window the data using your windowing function\nwindow_size = 7\nX,y = window_transform_series(series = dataset,window_size = window_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.3  Splitting into training and testing sets\n\nIn order to perform proper testing on our dataset we will lop off the last 1/3 of it for validation (or testing).  This is that once we train our model we have something to test it on (like any regression problem!).  This splitting into training/testing sets is done in the cell below.\n\nNote how here we are **not** splitting the dataset *randomly* as one typically would do when validating a regression model.  This is because our input/output pairs *are related temporally*.   We don't want to validate our model by training on a random subset of the series and then testing on another random subset, as this simulates the scenario that we receive new points *within the timeframe of our training set*.  \n\nWe want to train on one solid chunk of the series (in our case, the first full 2/3 of it), and validate on a later chunk (the last 1/3) as this simulates how we would predict *future* values of a time series."},{"metadata":{"trusted":true},"cell_type":"code","source":"# TODO: split our dataset into training / testing sets\ntrain_test_split = 2*len(dataset) // 3   # set the split point\n\n# partition the training set\nX_train = X[:train_test_split,:]\ny_train = y[:train_test_split]\n\n# keep the last chunk for testing\nX_test = X[train_test_split:,:]\ny_test = y[train_test_split:]\n\n# NOTE: to use keras's RNN LSTM module our input must be reshaped to [samples, window size, stepsize] \nX_train = np.asarray(np.reshape(X_train, (X_train.shape[0], window_size, 1)))\nX_test = np.asarray(np.reshape(X_test, (X_test.shape[0], window_size, 1)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='TODO_2'></a>\n\n## 1.4  Build and run an RNN regression model\n\nHaving created input/output pairs out of our time series and cut this into training/testing sets, we can now begin setting up our RNN.  We use Keras to quickly build a two hidden layer RNN of the following specifications\n\n- layer 1 uses an LSTM module with 5 hidden units (note here the input_shape = (window_size,1))\n- layer 2 uses a fully connected module with one unit\n- the 'mean_squared_error' loss should be used (remember: we are performing regression here)\n\nThis can be constructed using just a few lines - see e.g., the [general Keras documentation](https://keras.io/getting-started/sequential-model-guide/) and the [LTSM documentation in particular](https://keras.io/layers/recurrent/) for examples of how to quickly use Keras to build neural network models.  Make sure you are initializing your optimizer given the [keras-recommended approach for RNNs](https://keras.io/optimizers/) "},{"metadata":{"trusted":true},"cell_type":"code","source":"### TODO: build model\nfrom keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Input, LSTM, Dense, Flatten\nprint('Build model...')\nmodel = Sequential()\nmodel.add(Input(shape = (window_size,1)))\nmodel.add(LSTM(30, dropout=0.2, recurrent_dropout=0.2, return_sequences=False))\nmodel.add(Dense(1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train...')\nbatch_size = 32\nmodel.fit(X_train, y_train,\n          batch_size=batch_size,\n          epochs=100,\n          validation_data=(X_test, y_test))\nscore, acc = model.evaluate(X_test, y_test,\n                            batch_size=batch_size)\nprint('Test score:', score)\nprint('Test accuracy:', acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.5  Checking model performance\n\nWith your model fit we can now make predictions on both our training and testing sets."},{"metadata":{"trusted":true},"cell_type":"code","source":"# generate predictions for training\ntrain_predict = model.predict(X_train)\ntest_predict = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the next cell we compute training and testing errors using our trained model - you should be able to achieve at least\n\n*training_error* < 0.02\n\nand \n\n*testing_error* < 0.02\n\nwith your fully trained model.  \n\nIf either or both of your accuracies are larger than 0.02 re-train your model - increasing the number of epochs you take (a maximum of around 1,000 should do the job) and/or adjusting your batch_size."},{"metadata":{"trusted":true},"cell_type":"code","source":"# print out training and testing errors\ntraining_error = model.evaluate(X_train, y_train, verbose=0)\nprint('training error = ' + str(training_error))\n\ntesting_error = model.evaluate(X_test, y_test, verbose=0)\nprint('testing error = ' + str(testing_error))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Activating the next cell plots the original data, as well as both predictions on the training and testing sets. "},{"metadata":{"trusted":true},"cell_type":"code","source":"### Plot everything - the original series as well as predictions on training and testing sets\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# plot original series\nplt.plot(dataset,color = 'k')\n\n# plot training set prediction\nsplit_pt = train_test_split + window_size \nplt.plot(np.arange(window_size,split_pt,1),train_predict,color = 'b')\n\n# plot testing set prediction\nplt.plot(np.arange(split_pt,split_pt + len(test_predict),1),test_predict,color = 'r')\n\n# pretty up graph\nplt.xlabel('day')\nplt.ylabel('(normalized) price of Apple stock')\nplt.legend(['original series','training fit','testing fit'],loc='center left', bbox_to_anchor=(1, 0.5))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Note:** you can try out any time series for this exercise!  If you would like to try another see e.g., [this site containing thousands of time series](https://datamarket.com/data/list/?q=provider%3Atsdl) and pick another one!"},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}