{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Usual imports"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport pprint as pp\nimport re","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Getting an idea of the data"},{"metadata":{},"cell_type":"markdown","source":"### **Report**\n\n- 41157 tweets labeled\n\n - *Positive*              11422 (0.27)\n - *Negative*              9917 (0.24)\n - *Neutral*               7713 (0.18)\n - *Extremely Positive*    6624 (0.16)\n - *Extremely Negative*    5481 (0.13)\n\n \n- *'UserName'and 'ScreenName'* columns are just coded values to preserve anonymity. We can drop them."},{"metadata":{},"cell_type":"markdown","source":"### First hypothesis (H0)\n\n- Tweets mentions don't help to classify sentiment\n- Tweets hashtags don't help to classify sentiment"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"scrolled":true},"cell_type":"code","source":"trainset = pd.read_csv('/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_train.csv', encoding='latin-1')\ntestset = pd.read_csv('/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_test.csv', encoding='latin-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"trainset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"trainset.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Percentage of each Sentiment label in the train set"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"trainset['Sentiment'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"sns.barplot(trainset.Sentiment.unique(), trainset.Sentiment.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Top 25 values for the 'Location' column\n\n - As we can see, certain locations are repeated. We could maybe use NER to group locations"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"trainset['Location'].value_counts()[:25]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating new features on the dataset : mentions, hashtags, urls (and their count) / Dropping of the 'UserName' and 'ScreenName' columns"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"hashtag_regex = re.compile('(#[A-Z]\\w+)')\ntest = '#Covid#Iran and #Trump'\ngroup = hashtag_regex.findall(test)\nfor elt in group:\n    print(elt)\n    \nmention_regex = re.compile('(@[A-Z]\\w+)')\ntest = \"@Trump's etc @ABC@Obama\"\nmention_regex.findall(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"mention_regex = re.compile('(@[A-Z]\\w+)')\nhashtag_regex = re.compile('(#[A-Z]\\w+)')\n\neda_data = trainset.drop(['UserName', 'ScreenName'], axis=1)\neda_data['TweetAt'] = pd.to_datetime(eda_data['TweetAt'])\n# eda_data['mentions'] = pd.Series([[word for word in tweet.split() if word.startswith('@')] for tweet in eda_data['OriginalTweet'].values])\n# eda_data['hashtags'] = pd.Series([[hashtag_regex.search(word).group() for word in tweet.split() if word.startswith('#')] for tweet in eda_data['OriginalTweet'].values])\neda_data['mentions'] = pd.Series(mention_regex.findall(tweet) for tweet in eda_data['OriginalTweet'].values)\neda_data['hashtags'] = pd.Series(hashtag_regex.findall(tweet) for tweet in eda_data['OriginalTweet'].values)\neda_data['urls'] = pd.Series([[url for url in tweet.split() if 'http' in url] for tweet in eda_data['OriginalTweet'].values])\neda_data['hashtags_count'] = pd.Series([float(len(_)) for _ in eda_data['hashtags']])\neda_data['mentions_count'] = pd.Series([float(len(_)) for _ in eda_data['mentions']])\neda_data['urls_count'] = pd.Series([float(len(_)) for _ in eda_data['urls']])\neda_data['cleaned_tweet'] = pd.Series([tweet.replace('\\r', '').replace('\\n', '') for tweet in eda_data['OriginalTweet'].values])\neda_data['tweet_length'] = pd.Series([len(tweet) for tweet in eda_data['cleaned_tweet'].values])\neda_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"pos = eda_data[eda_data['Sentiment'] == 'Positive']\nex_pos = eda_data[eda_data['Sentiment'] == 'Extremely Positive']\nneg = eda_data[eda_data['Sentiment'] == 'Negative']\nex_neg = eda_data[eda_data['Sentiment'] == 'Extremely Negative']\nneutral = eda_data[eda_data['Sentiment'] == 'Neutral']\ndfs = [pos,ex_pos, neg, ex_neg, neutral]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"for col in ['mentions_count', 'hashtags_count', 'urls_count']:\n    plt.figure()\n    sns.barplot(eda_data['Sentiment'], eda_data[col])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Note** : Extremely negative sentiment tweets systematicaly has less mentions / hashtags / urls"},{"metadata":{"trusted":true},"cell_type":"code","source":"dict = {}\nfor df in dfs:\n    sent = df['Sentiment'].values[0]\n    dict[sent] = {}\n    for col in ['mentions', 'hashtags']:\n        dict[sent][col] = {}\n        for values in df[col]:\n            for value in values:\n                dict[sent][col][value] = dict[sent][col].get(value, 0) + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for sent in dict.keys():\n    for col in dict[sent].keys():\n        dict[sent][col] = sorted(dict[sent][col].items(), key=lambda x: x[1], reverse=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for sent in dict.keys():\n    for col in dict[sent].keys():\n       print('Top 10', col, 'for ', sent, ':', dict[sent][col][:10], '\\n')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}