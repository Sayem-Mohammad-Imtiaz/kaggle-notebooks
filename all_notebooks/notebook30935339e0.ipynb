{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd '../input/pccnethajj/PCC-Net'","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:52:45.822945Z","iopub.execute_input":"2021-06-09T07:52:45.82331Z","iopub.status.idle":"2021-06-09T07:52:45.831931Z","shell.execute_reply.started":"2021-06-09T07:52:45.823232Z","shell.execute_reply":"2021-06-09T07:52:45.830776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install easydict\n","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:52:50.056769Z","iopub.execute_input":"2021-06-09T07:52:50.057087Z","iopub.status.idle":"2021-06-09T07:52:58.758465Z","shell.execute_reply.started":"2021-06-09T07:52:50.057058Z","shell.execute_reply":"2021-06-09T07:52:58.757674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorboardX import SummaryWriter\nimport os\nimport random\nimport cv2\nimport torch\nfrom torch import optim\nfrom torch.autograd import Variable\nfrom torch.nn import NLLLoss2d\nfrom torch.optim.lr_scheduler import StepLR\nimport torchvision.transforms as standard_transforms\nimport torchvision.utils as vutils\nfrom models.CC import CrowdCounter\nfrom config import cfg\nfrom loading_data import loading_data\nfrom misc.utils import *\nfrom misc.timer import Timer\nimport pdb\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix, plot_confusion_matrix,multilabel_confusion_matrix,roc_curve,roc_auc_score\nimport seaborn as sn\n\n\ndef miou(im1, im2):\n    im1 = np.asarray(im1).astype(np.bool)\n    im2 = np.asarray(im2).astype(np.bool)\n\n    if im1.shape != im2.shape:\n        raise ValueError(\"Shape mismatch\")\n\n    intersection = np.logical_and(im1, im2)\n    union = np.logical_or(im1, im2)\n\n    return intersection.sum() / union.sum()\n\ndef dice(im1, im2):\n    im1 = np.asarray(im1).astype(np.bool)\n    im2 = np.asarray(im2).astype(np.bool)\n\n    if im1.shape != im2.shape:\n        raise ValueError(\"Shape mismatch\")\n\n    intersection = np.logical_and(im1, im2)\n\n    return 2. * intersection.sum() / (im1.sum() + im2.sum())\n\n    \ntrain_set, train_loader, val_set, val_loader, restore_transform = loading_data()\n\n_t = {'iter time' : Timer(),'train time' : Timer(),'val time' : Timer()} \n\nrand_seed = cfg.TRAIN.SEED    \nif rand_seed is not None:\n    np.random.seed(rand_seed)\n    torch.manual_seed(rand_seed)\n    torch.cuda.manual_seed(rand_seed)\n\ndef main():\n\n    cfg_file = open('./config.py',\"r\")  \n    cfg_lines = cfg_file.readlines()\n    \n    torch.cuda.set_device(cfg.TRAIN.GPU_ID[0])\n    torch.backends.cudnn.benchmark = True\n\n    net = CrowdCounter(ce_weights=train_set.wts,modelname='vgg_backbone')\n\n    net.train()\n    \n    i_tb = 0\n    epoch = 1\n    model_path = './exp/all_ep_299.pth'\n    _t['val time'].tic()\n    validate(val_loader, model_path, epoch, restore_transform)\n    _t['val time'].toc(average=False)\n    print( 'val time of one epoch: {:.2f}s'.format(_t['val time'].diff))\n\n\ndef validate(val_loader, model_path, epoch, restore):\n    net = CrowdCounter(ce_weights=train_set.wts)\n    net.load_state_dict(torch.load(model_path))\n    net.cuda()\n    net.eval()\n    print( '='*50 )\n    val_loss_mse = []\n    val_loss_cls = []\n    val_loss_seg = []\n    val_loss = []\n    mae = 0.0\n    mse = 0.0\n    count = 0\n    accuracy_total = 0\n    precision_total = 0\n    recall_total = 0\n    f1_total = 0\n    total_dice = 0\n    total_miou = 0\n    confusion_matrix_total = None\n    for vi, data in enumerate(val_loader, 0):\n        img, gt_map, gt_cnt, roi, gt_roi, gt_seg = data\n        with torch.no_grad():\n            count+=1\n            img = Variable(img).cuda()\n            gt_map = Variable(gt_map).cuda()\n            gt_seg = Variable(gt_seg).cuda()\n\n            roi = Variable(roi[0]).cuda().float()\n            gt_roi = Variable(gt_roi[0]).cuda()\n\n            pred_map,pred_cls,pred_seg = net(img, gt_map, roi, gt_roi, gt_seg)\n            cloned_pred = pred_seg.clone().detach().cpu().numpy()\n            cloned_gt = gt_seg.clone().detach().cpu().numpy()\n            \n            loss1,loss2,loss3 = net.f_loss()\n            val_loss_mse.append(loss1.item())\n            val_loss_cls.append(loss2.item())\n            val_loss_seg.append(loss3.item())\n            val_loss.append(net.loss.item())\n            # class_id = np.argmax(pred_cls)\n            pred_map = pred_map.data.cpu().numpy()/cfg.DATA.DEN_ENLARGE\n            gt_map = gt_map.data.cpu().numpy()/cfg.DATA.DEN_ENLARGE\n            #print(pred_seg.shape)\n            pred_seg = pred_seg.cpu().max(1)[1].squeeze_(1).data.numpy()\n            gt_seg = gt_seg.data.cpu().numpy()\n            gt_count = np.sum(gt_map)\n            pred_cnt = np.sum(pred_map)\n            total_dice = dice(gt_seg.flatten(), pred_seg.flatten())+total_dice\n            total_miou = miou(gt_seg.flatten(), pred_seg.flatten())+total_miou\n            # print(gt_seg.flatten().shape, pred_seg.flatten().shape)\n\n            color = (255, 0, 0)\n  \n            # Line thickness of 2 px\n            thickness = 2\n            image = img.cpu()[0,:,:,:].permute(1, 2, 0).numpy()\n            maxi = np.max(image)\n            mini = np.min(image)\n            image = (image-mini)*255/(maxi-mini)\n            image = np.array(image, np.uint8)\n            predicted_class=pred_cls\n            pred_cls = pred_cls.cpu().numpy().tolist()\n            roi = roi.cpu().numpy().tolist()\n            gt_roi=gt_roi.cpu().numpy()\n            \n            predicted_class = predicted_class.cpu().numpy()\n            ####\n            predicted_class_score = np.zeros_like(predicted_class)\n            predicted_class_score[np.arange(len(predicted_class)), predicted_class.argmax(1)] = 1    \n            #######\n            #print(gt_roi.flatten().tolist())\n            #print(predicted_class_score.flatten().tolist())\n            if count==1:\n                confusion_matrix_total = confusion_matrix(gt_roi.flatten().tolist(), predicted_class_score.flatten().tolist())\n            else:\n                confusion_matrix_total += confusion_matrix(gt_roi.flatten().tolist(), predicted_class_score.flatten().tolist())\n            #print(confusion_matrix_total.shape)\n            for i in range(len(roi)):\n              # start_point = (int(r[2]), int(r[1]))\n              # end_point = (int(r[4]), int(r[3]))\n              xmin = int(roi[i][1])\n              ymin = int(roi[i][2])\n              xmax = int(roi[i][3])\n              ymax = int(roi[i][4])\n              start_point = (xmin, ymin)\n              end_point = (xmax, ymax)\n              # print(start_point, end_point) \n              \n              image=image.copy()\n              image = cv2.rectangle(image,start_point, end_point, color, thickness)\n              cls = np.argmax(pred_cls[i])\n              cv2.putText(image,str(cls),(xmin,ymin),cv2.FONT_HERSHEY_COMPLEX,0.5,(0,255,0),1)\n            # print(type(image))\n            plt.imshow((image))\n           # plt.show()\n            # cv2.imshow(image)\n            # cv2.imwrite('image.png', image)\n            # plt.imshow(img[0,:,:,:].cpu().permute(1,2,0))\n            # plt.show()\n            # plt.imshow(gt_seg[0,:,:])\n            # plt.show()\n            # plt.imshow(gt_seg[0,:,:])\n            # plt.show()\n            #change the gt_seg --> gt_roi and pred_seg --> pred_cls\n\n\n            #print(calculate_lane_metrics(pred_cls,gt_roi.cpu().numpy().tolist(), 10))\n            #print(type(gt_seg))\n            #print(type(pred_seg))\n            #print(type(pred_cls))\n            \n\n           # fpr, tpr, thresholds = roc_curve(gt_roi.flatten(), predicted_class_score.flatten())\n           # auc = roc_auc_score(gt_roi.flatten(), predicted_class_score.flatten())\n           # print('AUC: %.3f' % auc)\n            accuracy = accuracy_score(gt_roi.flatten(), predicted_class_score.flatten())\n            precision = precision_score(gt_roi.flatten(), predicted_class_score.flatten()) \n            f1 = f1_score(gt_roi.flatten(), predicted_class_score.flatten())\n            recall = recall_score(gt_roi.flatten(), predicted_class_score.flatten())\n            pred_dummy = np.array(pred_seg>0.5, np.float32)\n            accuracy_total = accuracy+accuracy_total\n            recall_total=recall+recall_total\n            precision_total=precision+precision_total\n            f1_total=f1+f1_total\n            mae += abs(gt_count-pred_cnt)\n            mse += ((gt_count-pred_cnt)*(gt_count-pred_cnt))\n            \n            \n    fpr, tpr, thresholds = roc_curve(gt_roi.flatten(), predicted_class_score.flatten())\n    auc = roc_auc_score(gt_roi.flatten(), predicted_class_score.flatten())\n    plt.plot(fpr, tpr, linestyle='--', label='ROC')\n    print('AUC: %.3f' % auc)\n    plt.figure()\n    confusion = confusion_matrix_total\n    sn.heatmap(confusion, annot=True, annot_kws={\"size\": 16})\n    plt.imshow(image)\n    plt.show()\n    mean_iou = total_miou/count*100\n    mean_dice = total_dice/count*100\n    mean_accuracy = accuracy_total/count*100\n    mean_f1 = f1_total/count*100\n    mean_recall = recall_total/count*100\n    mean_precision = precision_total/count*100\n    mae = mae/val_set.get_num_samples()\n    mse = np.sqrt(mse/val_set.get_num_samples())\n    loss1 = np.mean(val_loss_mse)\n    loss2 = np.mean(val_loss_cls)\n    loss3 = np.mean(val_loss_seg)\n    loss = np.mean(val_loss)\n    \n   # fpr=[]\n   # tpr=[]\n   # for i in range(10):\n    #    fpr[i], tpr[i],_ =roc_curve(gt_roi[:,i], predicted_class_score[:,i])\n        #gt[:,i]=\n ###############################################################################   \n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    for i in range(10):\n        print(f\"class:= {i+1}\")\n        fpr[i], tpr[i], _ = roc_curve(gt_roi[:, i], predicted_class_score[:, i])\n        plt.figure()\n        plt.plot(fpr[i], tpr[i], linestyle='--', label='ROC')\n        plt.title(\"class \"+ str(i+1))\n        try:\n            auc=roc_auc_score(gt_roi[:, i], predicted_class_score[:, i])\n            print(f\"accuracy:= {auc}\")\n        except:\n            print(\"No positive prediction found so auc can't be compputed\")\n####################################################################################   \n    #print(gt_roi)\n    #print( predicted_class_score)\n    #print(gt_roi.shape)\n    #print(gt_roi[:,1])\n   # fpr, tpr, thresholds =roc_curve(gt_roi.flatten(), predicted_class_score.flatten())\n    print( '='*50 )\n    print( '    '+ '-'*20 )\n    print( '    [mae %.1f mse %.1f], [val loss %.8f %.8f %.4f %.4f]' % (mae, mse, loss, loss1, loss2, loss3) )        \n    print( '    '+ '-'*20 )\n    print(f\"accuracy:{mean_accuracy}\\nprecision:{mean_precision}\\nrecall:{mean_recall}\\nf1_score:{mean_f1}\")\n    print(f\"Confusicon_matrix:{confusion}\")\n    print(f'MIOU:{mean_iou}\\nDice Score:{mean_dice}')\n    print( '='*50 )\n\n\nif __name__ == '__main__':\n    main()\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-09T07:59:03.899306Z","iopub.execute_input":"2021-06-09T07:59:03.899682Z","iopub.status.idle":"2021-06-09T07:59:13.698654Z","shell.execute_reply.started":"2021-06-09T07:59:03.899651Z","shell.execute_reply":"2021-06-09T07:59:13.697921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}