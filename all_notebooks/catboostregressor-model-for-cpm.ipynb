{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics\nfrom sklearn.linear_model import LinearRegression\nfrom catboost import CatBoostRegressor  \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport json\nfrom datetime import datetime\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/real-time-advertisers-auction/Dataset.csv')\ndata.head().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data descriptive analysis and Preprocessing"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"def data_stats_table(data, data_example=True, nlargest_num=1, stats_describe=True):\n    data_stats = pd.DataFrame()\n\n    if data_example:  \n        data_stats['data[0]'] = data.loc[0, :].T\n\n    data_stats['dtypes'] = data.dtypes  \n    data_stats.loc['rows_count', 'dtypes'] = len(data.dtypes)\n    data_stats['dupl'] = int(data.duplicated().sum())\n\n    data_stats['NaNs'] = data.isnull().sum()  \n    data_stats.loc['rows_count', 'NaNs'] = (\n        data.isnull().sum(axis=1) != 0).sum()\n    data_stats['NaNs'] = data_stats['NaNs'].astype('int')\n\n    for name in data.columns:\n        data_stats.loc[name, 'unique'] = data[name].nunique()\n        top_freq = round(data[name].value_counts(\n            normalize=True).nlargest(nlargest_num), 2)\n        data_stats.loc[name, 'top_freq'] = json.dumps(list(top_freq))\n        data_stats.loc[name, 'top_freq_value'] = json.dumps(\n            list(top_freq.index))\n\n    if stats_describe:  \n        df_des = round(data.describe().T.drop(columns=['count']), 2)\n        data_stats = pd.concat([data_stats, df_des], axis=1, sort=False)\n    data_stats.fillna(\"\", inplace=True)\n    return data_stats\n\ndata_stats_table(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def weird_division(n, d):\n    return n / d if d else 0\n\ndata['CPM'] = data.apply(lambda x: 1000*weird_division(x['total_revenue']*100, x['measurable_impressions']), axis=1)\ndata = data[data['CPM'] >= 0]\n\ndata.drop(columns = ['integration_type_id' , 'revenue_share_percent', 'total_revenue'], inplace=True)\ndata_cols = data.columns\n\ndata['date'] = pd.to_datetime(data['date'])\ndata[\"sample\"] = (data['date'] < pd.to_datetime('22.06.2019')).astype(\"int\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(font_scale=1)\nplt.subplots(figsize=(17, 10))\nsns.heatmap(data.corr(), square=True, annot=True, fmt=\".2f\", cmap=\"coolwarm\", vmin=-1, vmax=1, center=0, \n           linewidths=1, linecolor='white',  mask = np.tril(data.corr()));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_train_test_hist(data_, col_names, col_number=2, figsize_=(18, 8), bins_=10):\n    fig, axes_ = plt.subplots(-(-len(col_names)//col_number),\n                              col_number, figsize=figsize_)\n\n    for counter_ in range(len(col_names)):\n        pic_row_ = counter_//col_number\n        pic_col_ = counter_ % col_number\n        axes_[pic_row_, pic_col_].hist(data_[col_names[counter_]], rwidth=0.95,\n                                       alpha=0, color='green', bins=bins_, density = True)\n        \n        axes_[pic_row_, pic_col_].hist(data_[data_['sample'] == 1][col_names[counter_]], rwidth=0.95,\n                                       alpha=0.65, label='learn_data', color='red', bins=bins_, density = True)\n\n        axes_[pic_row_, pic_col_].hist(data_[data_['sample'] == 0][col_names[counter_]], rwidth=0.95,\n                                       alpha=0.65, label='predict_data', color='blue', bins=bins_, density = True)\n\n        axes_[pic_row_, pic_col_].set_title(col_names[counter_])\n        axes_[pic_row_, pic_col_].legend(loc=1)\n\nplot_train_test_hist(data, data_cols, col_number=4, figsize_=(16, 16), bins_=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Taking the logarithm of features and CPM"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_logs = [\"total_impressions\", \"viewable_impressions\", \"measurable_impressions\", \"CPM\"]\nfor item in num_logs:\n    data[item] = data[item].apply(lambda x: np.log(x+1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(font_scale=1)\nplt.subplots(figsize=(17, 10))\nsns.heatmap(data.corr(), square=True, annot=True, fmt=\".2f\", cmap=\"coolwarm\", vmin=-1, vmax=1, center=0, \n           linewidths=1, linecolor='white',  mask = np.tril(data.corr()));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_train_test_hist(data, data_cols, col_number=4, figsize_=(16, 16), bins_=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train/test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = data[data['date'] < pd.to_datetime('22.06.2019')]\ndata_train = data_train[data_train[\"CPM\"] < data_train[\"CPM\"].quantile(0.95)]\ndata_train = data_train.drop_duplicates()\n\ndata_test = data[data['date'] >= pd.to_datetime('22.06.2019')]\ndata_test = data_test[data_test[\"CPM\"] < data_test[\"CPM\"].quantile(0.95)]\n\n\ntrain_cols = ['site_id', 'ad_type_id', 'geo_id', 'device_category_id', 'advertiser_id', 'order_id', \n              'line_item_type_id', 'os_id', 'monetization_channel_id', 'ad_unit_id', \n              'total_impressions', 'viewable_impressions', 'measurable_impressions']\n\nX_train = data_train[train_cols]\ny_train = data_train[\"CPM\"]\n\nX_test = data_test[train_cols]\ny_test = data_test[\"CPM\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CatBoostRegressor Model for CPM"},{"metadata":{"trusted":true},"cell_type":"code","source":"def log_y_mse_metrics(y, y_pred):\n    return metrics.mean_squared_error(np.exp(y) - 1, np.exp(y_pred) - 1)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"%%time\ncatb_params = {\n    'random_seed': 0, \n    'learning_rate': 0.5,\n    'iterations': 1000, \n    'depth': 6, \n    'l2_leaf_reg': 10, \n    'subsample' : 0.75, \n    'random_strength': 0.06, \n    'od_type': \"Iter\", \n    'od_wait': 100, \n    'verbose': False, \n}\ncat_features = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\nctb_model = CatBoostRegressor(**catb_params)\nctb_model.fit(X_train, y_train, cat_features = cat_features) \n\ny_pred_test = ctb_model.predict(X_test)\nprint(log_y_mse_metrics(y_test, y_pred_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}