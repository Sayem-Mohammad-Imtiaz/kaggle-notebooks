{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns  #Plotting Lib","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_columns = None\nintrain = pd.read_csv('/kaggle/input/mobile-price-classification/train.csv')\nintrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(intrain.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Bar Plot\ndata = intrain['price_range'].value_counts() \npoints = data.index \nfrequency = data.values \nplt.bar(points, frequency, width = 0.4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From Above graphs it is clear that the output(Target) column have below value\n\n*  0 - low cost\n*  1 - medium cost\n*  2 - high cost\n*  3 - very high cost\n \nAnd all the above catergory are almost equally distributed\n "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Relation between the Price and Ram\nsns.boxplot(intrain['price_range'],intrain['ram'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Relation between the Price and Ram\nsns.boxplot(intrain['touch_screen'],intrain['price_range'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"intrain.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr=intrain.corr()\nfig = plt.figure(figsize=(12,10))\nr = sns.heatmap(corr, cmap='Blues')\nr.set_title(\"Correlation \")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see **our target price range has highly positive correlation between RAM**.\nAlso\n1. 3G and 4G\n2. pc(Primary Camera mega pixels) and fc(Front Camera mega pixels)\n3. px_weight(Pixel Resolution Width) and px_height(Pixel Resolution Height)\n4. sc_w(Screen Width of mobile in cm) and sc_h(Screen Height of mobile in cm)\nfeatures have highly positive correlation. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check the missing values in each column\nintrain.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = intrain.iloc[:, :-1].values  # All input variable \ny = intrain.iloc[:,20].values    #Output Variable\nprint(intrain.columns)\nprint(y)\n#Split the Data into Train and Test Sets\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the Decision Tree model using our X_Train Dataset\nfrom sklearn import tree\nclf = tree.DecisionTreeClassifier()\nclf = clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualize the Decision Tree which is created\nclf1 = tree.DecisionTreeClassifier(max_depth=2) #Limiting the Depth to 2 for better visualization of Tree\nclf1 = clf1.fit(X_train, y_train)\nfrom sklearn.tree import export_graphviz\nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\n# Export as dot file\nexport_graphviz(clf1, out_file='tree.dot', \n                feature_names = ['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n       'touch_screen', 'wifi'],\n                class_names = ['0','1','2','3'],\n                rounded = True, proportion = False, \n                precision = 2, filled = True)\n\n# Convert to png\nfrom subprocess import call\ncall(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n\n# Display in python\nimport matplotlib.pyplot as plt\nplt.figure(figsize = (14, 18))\nplt.imshow(plt.imread('tree.png'))\nplt.axis('off');\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test the model on X_test data\ny_pred_test = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_test, y_pred_test))\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now Lets read the test dataset provide us and try to predict the values for it\nintest = pd.read_csv('/kaggle/input/mobile-price-classification/test.csv')\nXtest = intest.iloc[:, 1:].values\nPred= clf.predict(Xtest)\nintest['Pred'] = Pred\nintest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Random Forest**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Build the Random Forest Model for same data\nfrom sklearn.ensemble import RandomForestClassifier\nrfclf = RandomForestClassifier(n_estimators=100)\nrfclf.fit(X_train, y_train) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using feature importance find the most important features which decide the price ranges\nfig = plt.figure(figsize=(8,6))\npoints = intrain.columns[0:20] \nfrequency = rfclf.feature_importances_ \nplt.barh(points, frequency)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above plot it is clear that RAM is most important feature and plays and important rile in deciding \nthe price of the mobile\nThe few other columns which are important(apart from RAM) are :-\n*     Battery Power\n*     Pixel Width and Height\n*     Mobile weight"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test the model on X_test data\ny_predrf_test = rfclf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_test, y_predrf_test))\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test,y_predrf_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}