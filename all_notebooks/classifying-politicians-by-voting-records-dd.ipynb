{"cells":[{"metadata":{},"cell_type":"markdown","source":"## CONHEÇA NOSSO BLOG: https://www.dadosedecisao.com/blog\n\nEste notebook foi desenvolvido para trazer em termos práticos o conhecimento sobre regressão logística mostrado no artigo: Regressão Logística: o essencial.\nThis notebook was developed to show in pratical terms the knowledge about logistic regression at paper: Logistic Regression: the essential."},{"metadata":{},"cell_type":"markdown","source":"Importando a base de dados online\nImporting the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for k_value in range(1,30):\n    import numpy as np\n    import pandas as pd\n    votos = pd.read_csv('/kaggle/input/congressional-voting-records/house-votes-84.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Verificando os 10 primeiros valores da base de dados\nThe 10 first value"},{"metadata":{"trusted":true},"cell_type":"code","source":"votos.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Substituindo os valores y,n,? por 1,0,NaN (missing)\nCriando a variável Republican\nSubstituindo os valores de da variável Class Name (republican e democrat) por (1 e 0);\n\nChanging y,n,? values for 1,0,NaN\nInput a new column: Republican\nChanging class name values for 1,0"},{"metadata":{"trusted":true},"cell_type":"code","source":"ynmap = {'y':1,'n':0,'?':np.nan}\npartymap = {'republican':0,'democrat':1}\nvotos['republican'] = votos['Class Name'].map(partymap)\nvotos.drop('Class Name',axis=1,inplace=True)\nfor column in votos.columns.drop('republican'):\n    votos[column+'1'] = votos[column].map(ynmap)\n    votos.drop(column,axis=1,inplace=True)\npartymap = {'republican':1,'democrat':0}\ndata_col = votos.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Verificando o tamanho da base de dados (quantidade de linhas totais)\nThe length of dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(votos)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tratamento de missing\n\nMissing data treatment "},{"metadata":{},"cell_type":"markdown","source":"Nesta primeira tentativa, vamos construir um modelo eliminando todos os missing da amostra.\n\nThis model will exlude all missing data."},{"metadata":{},"cell_type":"markdown","source":"Verificando a quantidade de missing por variável\n\nMissing data by column"},{"metadata":{"trusted":true},"cell_type":"code","source":"votos.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Temos um total de 203 linhas sem dados perdidos (47%), o que significa dizer que 53% da nossa amostra possui dados perdidos nas observações. Além disso, 100% das variáveis possui dados perdidos. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# identificando o detalhe de cada observação e retornando true para dado perdido e false para dado completo num array\nvotos.isnull().values.ravel()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#contagem do total de dados perdidos em toda a tabela (levando em conta observaçõe + variáveis = extensão total dos dados perdidos)\nvotos.isnull().values.ravel().sum()\n\n# obs: a diferença entre esta linha e a soma, é que a soma retorna o número de dados perdidos por variável","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# eliminando os dados missing\nvotos = votos.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(votos)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vemos que tivemos uma redução considerável no número de observações em nossa tabela. A representatividade perdida, após a tratativa de missing excluindo todos os dados perdidos, é de 53%. Para bases de dados com tamanha extensão de dados perdidos, o ideal é realizar uma análise mais profunda acerca dos padrões aleatórios ou não aleatórios dos dados perdidos. Para os intuitos introdutórios desse kernel, vamos optar pela eliminação total dos dados missing.\n\nWe using that form to treated missing data because the intention of this notebook is just only show how a logistic regression model works. We know wich the best way to treat missing data is MCAR or CAR analysis when we have a lot of missing values. "},{"metadata":{},"cell_type":"markdown","source":"# Análise exploratória de dados\n\nExploratory analysis"},{"metadata":{},"cell_type":"markdown","source":"Importando a biblioteca pandas profiling para construir as visualizações gráficas mais comuns em análise exploratória (histogramas, tabelas de correlação, dentre outros). \nA análise exploratória é um dos passos mais importantes de qualquer modelo. Uma análise exploratória mal feita pode enviesar os dados, geralmente, resultando em performance reduzida do modelo."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas_profiling","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"relatorio_votos = pandas_profiling.ProfileReport(votos)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"relatorio_votos.to_file('relatorio_votos.html')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"relatorio_votos","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Divisão em treino e teste"},{"metadata":{},"cell_type":"markdown","source":"We using train and test division to make our model."},{"metadata":{},"cell_type":"markdown","source":"Aqui chegamos no momento de separar nossas bases. O método de divisão de bases em treino e teste é o mais utilizado na comunidade de data science. Geralmente, 70% dos dados vão para a base de treino e 30% ficam na base de teste. O motivo dessa divisão é simples: 1) a base de treino serve para que o modelo execute previsões com os dados brutos. Ele faz isso a partir de tentativa e erro, reduzindo o erro a cada tentativa. No treino ele pode chegar ao overfiting (previsão perfeita) de tanto treinar. Já a 2) base de teste é a mais fundamental, pois nos revelará como o modelo se comporta ao receber novos dados. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# devinindo x e y\n#  x assumira todas as linhas [:] e as colunas de [a:17]\n# y assumira a variável republican\nX = votos.iloc[:,1:17]\ny = votos.republican\n\n# aqui, defino os nomes das bases de treino e teste e o tamanho desta última\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Verificando o tamanho da base de treino e base de teste.\nBase de treino tem 162 linhas e 16 colunas\nbase de teste tem 70 linhas e 16 colunas"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Rodando modelos"},{"metadata":{},"cell_type":"markdown","source":"Regressão logística"},{"metadata":{},"cell_type":"markdown","source":"Carregando a biblioteca"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Configurando a biblioteca"},{"metadata":{"trusted":true},"cell_type":"code","source":"#criando a variavel votos_logistic que receberá o método de regressão logística\nvotos_logistic = LogisticRegression(C=10)\n#.fit é o que aplica o modelo nas bases de treino inicialmente, geraldo as estatísticas iniciais\nvotos_logistic.fit(X_train, y_train)\n#.predict aplica o aprendido no treino na base de teste\nvotos_logistic_predictions = votos_logistic.predict(X_test)\n# criando a métrica de acurácia\nfrom sklearn.metrics import accuracy_score\nacc_votos_logistic = accuracy_score(y_test, votos_logistic_predictions)\nprint(\"accuracy_score: %4f\" % acc_votos_logistic)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"É comum utilizarmos nós \"tunarmos\" nosso modelo em busca dos melhores parametros. Faço isso abaixo. Esta parte é opcional."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tuned_parameters_votos_logistic = [{'C': [0.1,1,10]}]\nclf_votos_logistic = GridSearchCV(LogisticRegression (), tuned_parameters_votos_logistic, cv=3, scoring='accuracy')\nclf_votos_logistic.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"Melhores parametros encontrados:\")\nprint()\nprint(clf_votos_logistic)\nprint()\nprint(\"Grid scores:\")\nprint()\nmeans = clf_votos_logistic.cv_results_['mean_test_score']\nstds = clf_votos_logistic.cv_results_['std_test_score']\nfor mean, std, params in zip (means, stds, clf_votos_logistic.cv_results_['params']):\n    print(\"%0.3f (+/-%0.03f) for %r\"\n        % (mean, std * 2, params))\nprint()\nprint(\"Detailed classification report:\")\nprint()\nprint(\"The model is trained on the full development set.\")\nprint(\"The scores are computed on the full evaluation set.\")\nprint()\nfrom sklearn.metrics import accuracy_score\nacc_votos_logistic = accuracy_score(y_test, votos_logistic_predictions)\nprint(\"accuracy_score: %4f\" % acc_votos_logistic)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cálculo do indicador da area under the curve (área sob a curva) que mostra a qualidade da nossa previsão. Tivemos um excelente desempenho, acertando 0,9913. \nObs: o fato de ter eliminado os missing e reduzido a extensão da base tem impacto direto."},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn.metrics as metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probs_votos_logistic = votos_logistic.predict_proba(X_test)\nfrom sklearn.metrics import roc_auc_score\nauc_votos_logistic = roc_auc_score(y_test, probs_votos_logistic[:,1])\nprint(\"AUC: %.4f\" % auc_votos_logistic)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Criando a tabela com os detalhes estatísticos (coeficientes, desvio padrão, normalização, p-valor, percentil) e outras métricas como pseudo R, Razão e desigualdades, logit, dentre outros."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nlogit_model=sm.Logit(y, X)\nresult=logit_model.fit(method='bfgs', full_output='bool')\nprint (result.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# VISUALIZAÇÃO GRÁFICA DA QUALIDADE DO MODELO"},{"metadata":{},"cell_type":"markdown","source":"Nesta última etapa, construímos a matriz de confusão (gráfico 1), distribuição de probabilidades (gráfico 2) e Curva ROC (gráfico3).\nEm resumo, verificamos na matriz de confusão como o modelo performou nas previsões. O verdadeiro negativo e o verdadeiro positivo são os mais importantes, pois representam as previsões corretas.\nA distribuição de probabilidades mostra se nossas previsões estão claramente bem distribuídas (no nosso caso, beirou a perfeição). \nE a curva ROC é a representação gráfica da área sob a curva.\nNoutro momento, explicarei em detalhes sobre cada um deles em nosso blog."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import roc_curve, confusion_matrix, auc\nfrom sklearn import linear_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evalBinaryClassifierRL (model, x, y_test, labels=['Positives', 'Negatives']):\n\n# model predicts probabilities of positive class\n\n    p= votos_logistic.predict_proba(X_test)\n    if len(votos_logistic.classes_)!=2:\n        raise ValueError('A binary class problem is required')\n    if model.classes_[1] == 1:\n        pos_p = p[:,1]\n    elif model.classes_[0] == 1:\n        pos_p = p[:,0]\n        \n    #Figure\n    plt.figure(figsize=[15,4])\n    \n    \n    # 1 - Confusion matrix\n    cm_rl = confusion_matrix(y_test, votos_logistic_predictions)\n    plt.subplot(131)\n    ax = sns.heatmap(cm_rl, annot=True, cmap='Blues', cbar=False,\n                    annot_kws={\"size\": 14}, fmt='g')\n    cmlabels = ['Verdadeiros negativos', 'Falso Positivos', 'Falso Negativos', 'Verdadeiros Positivos']\n    \n    for i, t in enumerate(ax.texts):\n        t.set_text(t.get_text() + \"\\n\" + cmlabels[i])\n    plt.title('Matrix de confusão', size =15)\n    plt.xlabel('Valores previstos', size = 13)\n    plt.ylabel('Valores verdadeiros', size=13)\n    \n    #2 - Distribuiçãode probabilidades para ambas as classes\n    df = pd.DataFrame({'probPos':pos_p, 'target':y_test})\n    plt.subplot(132)\n    plt.hist(df[df.target==1].probPos, density=True,\n            alpha=.5, color='blue', label=labels[0])\n    plt.hist(df[df.target==0].probPos, density=True,\n            alpha=.5, color='purple', label=labels[1])\n    plt.axvline(.5, color='red', linestyle=':', label='Boundary')\n    plt.xlim([0,1])\n    plt.title('Distribuição das previsões', size=15)\n    plt.xlabel('Probabilidade positiva (previsto)', size=13)\n    plt.ylabel('Samples(escala normalizada)', size=13)\n    plt.legend(loc=\"upper right\")\n\n    #3 - Curva ROC\n    fp_rates, tp_rates, _ = roc_curve(y_test, p[:,1])\n    roc_auc = auc(fp_rates, tp_rates)\n    plt.subplot(133)\n    plt.plot(fp_rates, tp_rates, color = 'purple',\n             lw=1, label='Roc curve (area = %0.2f)'%roc_auc)\n    plt.plot([0,1], [0,1], lw=1, linestyle='--', color='red')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.xlabel('Falso positivo', size=13)\n    plt.ylabel('Verdadeiro positivo', size=13)\n    plt.title('Curva ROC', size=15)\n    plt.legend(loc='lower right')\n    plt.subplots_adjust(wspace=.3)\n    plt.show()\n    \n    # Mostrar e retornar o f1 score\n    tn, fp, fn, tp = [i for i in cm_rl.ravel()]\n    precision = tp/(tp+fp)\n    recall = tp/(tp+fn)\n    F1 = 2*(precision*recall)/(precision+recall)\n    printout=(\n        f'Precision: {round(precision,2)} | '\n        f'Recall: {round(recall,2)} | '\n        f'F1 Score: {round(F1,2)} | '\n    )\n    print(printout)\n    return F1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"F1= evalBinaryClassifierRL(votos_logistic, X_test, y_test)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":4}