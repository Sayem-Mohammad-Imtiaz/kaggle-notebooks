{"cells":[{"metadata":{"_uuid":"9cf6c761b432b7aa3816181a097a760de1017c22"},"cell_type":"markdown","source":"The purpose of this notebook is to take information that is provided in the datasets and deep dive into them in order to get more insights - features - that characterize the different loans and different people who obtained a loan. In particular will be looking at:\n\nNew derived features ::\n1. Defining the number of borrowers and the sex ratio given a string column\n2. Binarize the repayment interval\n3. Binarize the different sectors of the \"sector\" of the loan\n4. Vectorize the \"use\" of the loans \n5. Calculate the distances between the places where the loans are provided - using the longitude/latitude\n\nFrom there we will be able to::\n1.  See how many people together apply for a loan - and thus a proxy of the community spirit in the different areas\n2. Depict a wordCloud of the different uses of the loans\n"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\n\n# endoder for the categorical columns\nfrom sklearn.preprocessing import LabelBinarizer\nfrom math import sin, cos, sqrt, atan2, radians\n\n#word cloud\nfrom os import path\nfrom scipy.misc import imread\nfrom wordcloud import WordCloud, STOPWORDS\nimport random\nimport scipy.stats as st\n\n# for doc2vec - use of loan\nimport gensim\nfrom nltk import RegexpTokenizer\nfrom nltk.corpus import stopwords\nfrom os import listdir\nfrom os.path import isfile, join\n\n#plotting\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\npd.options.mode.chained_assignment = None\npd.options.display.max_columns = 999\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n%matplotlib inline\n# Any results you write to the current directory are saved as output.","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"7889cac3-b822-4212-affb-6fa46e7f2e23","_uuid":"67387dea0a9f89fa802c0e735d66df596f29c9ed"},"cell_type":"markdown","source":"**Read in tables**"},{"metadata":{"_cell_guid":"026c5ce8-52ab-462d-a55f-19e7d9739a37","_uuid":"0401296bed328a24b3c06847ec630ab9de850822","trusted":true,"collapsed":true},"cell_type":"code","source":"kiva_mpi_locations_df = pd.read_csv(\"../input/kiva_mpi_region_locations.csv\")\nloan_theme_ids_df = pd.read_csv(\"../input/loan_theme_ids.csv\")\nkiva_loans_df = pd.read_csv(\"../input/kiva_loans.csv\")\n#loan_theme_ids_df.head()\n#kiva_mpi_locations_df.head()\n#kiva_loans_df.head()","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"45509283-cf49-40c2-8e18-b1b9c6f111cd","_uuid":"a49d461f9baa13995a0af8ab4bc5becccd30fb37"},"cell_type":"markdown","source":"**FUNCTIONS**"},{"metadata":{"_cell_guid":"90a9e114-e114-46e6-9210-3886239ae160","_uuid":"b4dd7d18b9f7354e8cb380ac0500bbded13f988d"},"cell_type":"markdown","source":" >  ** Create features from raw columns**"},{"metadata":{"_cell_guid":"4b810b30-34db-4a6f-a93e-7752fa567aeb","_uuid":"66eb39afcd4c42a9704b90051ce429f6b1b28c6c","collapsed":true,"trusted":true},"cell_type":"code","source":"def number_of_borrowers(x):\n    if type(x['borrower_genders']) in [float]:\n        return 0\n    else:\n        y= x['borrower_genders'].split(',')\n        return len(y)\n\ndef number_of_fem_borrowers(x):\n    if type(x['borrower_genders']) in [float]:\n        return 0\n    else:\n        y = x['borrower_genders'].split(',')\n        y = [str(n.strip()) for n in y]\n        return y.count('female')\n    \n\ndef distance(x1,x2,y1,y2):\n    # approximate radius of earth in km\n    R = 6373.0\n\n    lat1 = radians(x1)\n    lon1 = radians(x2)\n    lat2 = radians(y1)\n    lon2 = radians(y2)\n\n    dlon = lon2 - lon1\n    dlat = lat2 - lat1\n\n    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n\n    distance = R * c\n    \n    return distance","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"0aebf3fa-7db1-4205-a8ec-65a8b1572c99","_uuid":"7b50a1721f9d96207d589ec739b2dbfa321a4d63"},"cell_type":"markdown","source":"> **Functions for the doc2vec**"},{"metadata":{"_cell_guid":"166046f3-b332-4e67-ac98-e2cd842bb281","_uuid":"03ab5020993ba9ff8b28be3b19b70cfd9939bbf8","collapsed":true,"trusted":true},"cell_type":"code","source":"tokenizer = RegexpTokenizer('\\w+')\nstopword_set = set(stopwords.words(\"english\"))\n#This function does all cleaning of data using two objects above\ndef nlp_clean(data):\n   new_data = []\n   for d in data:\n      new_str = d.lower()\n      dlist = tokenizer.tokenize(new_str)\n      dlist = list(set(dlist).difference(stopword_set))\n      new_data.append(dlist)\n   return new_data\n\nclass LabeledLineSentence(object):\n    def __init__(self, doc_list, labels_list):\n        self.labels_list = labels_list\n        self.doc_list = doc_list\n    def __iter__(self):\n        for idx, doc in enumerate(self.doc_list):\n              yield gensim.models.doc2vec.TaggedDocument(doc,[self.labels_list[idx]])","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"4a6ae64d-495b-4df3-83f1-265f397ee357","_uuid":"a3587a7544ca029ee6285a97c309d103eeb41f7e"},"cell_type":"markdown","source":"> **Plotting**\n"},{"metadata":{"_cell_guid":"37617b7a-f459-445c-882e-d5983d6c7f2f","_uuid":"2690f3627241263e4d5c479fc928c9bb6202a426","collapsed":true,"trusted":true},"cell_type":"code","source":"def plot_num_borrowers():\n    '''understanding the sense of community in each place is an important factor to understand how best to allocate loans, \n    we look here which countries create cooperatives and if there is any relationship with the loan funded'''\n    cnt_srs = kiva_loans_df1.groupby('country')[\"number_of_borrowers\"].mean().sort_values(ascending=False).head(20)\n    trace = go.Bar(\n        y=cnt_srs.index[::-1],\n        x=cnt_srs.values[::-1],\n        orientation = 'h',\n        marker=dict(\n            color=cnt_srs.values[::-1],\n            colorscale = 'Viridis',\n            reversescale = True\n        ),\n    )\n\n    layout = go.Layout(\n        title='Mean number of borrowers per loan',\n        width=700,\n        height=1000,\n        )\n    data = [trace]\n    fig = go.Figure(data=data, layout=layout)\n    py.iplot(fig, filename=\"CountryLoan\")\n    \ndef scatter():\n    r = random.sample(range(1, kiva_loans_df1.shape[0]), 10000)\n    x = kiva_loans_df1['number_of_borrowers'][r]\n    y = np.log(kiva_loans_df1['loan_amount'][r])\n    s = np.random.rand(*x.shape) * 0.2 + 50\n\n    plt.scatter(x, y, s, c=\"g\", alpha=0.5)\n    plt.xlabel(\"Number of borrowers\")\n    plt.ylabel(\"log of Loan amount\")\n    plt.legend(loc=2)\n    plt.show()\n    \ndef word_cloud():\n        # Simple WordCloud\n    plt.figure(figsize=(20,10))\n    r = random.sample(range(1, df2.shape[0]), 15000)\n    text = ' '.join(str(m) for m in df2['use'][r])\n\n    wordcloud = WordCloud(\n                          relative_scaling = 1.0,\n                          stopwords = {'when','they','his','her','to', 'of','in','their','for','my','more','and','the','such','as'} # set or space-separated string\n                          ).generate(text)\n    plt.imshow(wordcloud)\n    plt.axis(\"off\")\n    plt.show()","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"e096612e-ec22-403e-8159-9c605faa30e5","_uuid":"258bd0843e2373372e62a7959f7a1b4adf2aebe2"},"cell_type":"markdown","source":"**Looking into the text data**\n"},{"metadata":{"_cell_guid":"2641a477-c86c-4583-b585-35fa4bc9d5b5","_uuid":"717be572f429e8c736d35d7ecc637d8250df934d","trusted":true,"collapsed":true},"cell_type":"code","source":"#BINARISE SECTOR\nlb_style = LabelBinarizer()\n\nlb_results1 = lb_style.fit_transform(kiva_loans_df[\"sector\"])\nX1=pd.DataFrame(lb_results1,columns=lb_style.classes_)\n\n#BINARISE REPAYMENT INTERVAL\nlb_results2 = lb_style.fit_transform(kiva_loans_df[\"repayment_interval\"])\nX2=pd.DataFrame(lb_results2,columns=lb_style.classes_)\n\n# PERCENTAGE OF LOAN FUNDED by KIVA\nkiva_loans_df[\"Perc_loan_funded\"] = kiva_loans_df[\"funded_amount\"]/kiva_loans_df[\"loan_amount\"]*100.0\n\n# BORROWERS GENDER AND NUMBER\nkiva_loans_df['number_of_borrowers'] = kiva_loans_df.apply(number_of_borrowers,axis=1)\nkiva_loans_df['number_of_fem_borrowers'] = kiva_loans_df.apply(number_of_fem_borrowers,axis=1)\n\nXX = pd.concat([X1,X2],axis=1,join=\"inner\")\nkiva_loans_df1 = pd.concat([kiva_loans_df.drop([\"sector\",\"repayment_interval\",\"borrower_genders\"],axis=1),XX],axis=1,join=\"inner\")\n# join the loans with the purpose of the loan\n\ndf10 = pd.merge(kiva_loans_df1,loan_theme_ids_df,on=\"id\",how=\"left\")\ndf11 = pd.merge(df10,kiva_mpi_locations_df,on=\"country\",how=\"left\")\n\n","execution_count":7,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"bf6feedb7d63aa3bcfb7d801a0e545048db0f887"},"cell_type":"code","source":"#BINARIZE WORLD REGIONS\ndf11[\"world_region\"] = df11.world_region.replace(np.NaN, \"other\")\nlb_results3 = lb_style.fit_transform(df11[\"world_region\"])\nX3=pd.DataFrame(lb_results3,columns=lb_style.classes_)\n\ndf2 = pd.concat([df11.drop(\"world_region\",axis=1),X3],axis=1)","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"be3f6cad-1262-4e49-ae80-c36d4c0197f7","_uuid":"20fc4183993597aba20f6225cc95e14eb8001b8a","trusted":true},"cell_type":"code","source":"st.pearsonr(np.log(kiva_loans_df1['loan_amount']),kiva_loans_df1['number_of_borrowers'])","execution_count":9,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc71ec8d348fbb8beb3697b322b486c3a4001dcd"},"cell_type":"code","source":"df2.head()","execution_count":10,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"962f11358598e5ce77b5ed9b25233d1f014938bd"},"cell_type":"code","source":"from numpy import genfromtxt,array,linalg,zeros,apply_along_axis\n\ndata = df2.drop([\"id\",\"activity\",\"use\",\"country_code\",\"country\",\"region_x\",\"currency\",\"partner_id\",\"posted_time\",\"disbursed_time\",\"funded_time\",\"tags\",\\\n                 \"date\",\"Loan Theme ID\",\"Loan Theme Type\",\"Partner ID\",\"LocationName\",\"ISO\",\"region_y\",\"geo\"],axis=1)\n# normalization to unity of each pattern in the data\ndata = apply_along_axis(lambda x: x/linalg.norm(x),1,data)","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"3136c4e5-8501-4c7c-9303-7167f8ba8dda","_uuid":"5b10cbdd990b94ecbb1aecfcebc527b03c7355a2","collapsed":true},"cell_type":"markdown","source":"sentiment analysis on loan purpose "},{"metadata":{"_cell_guid":"6db7fc46-7a15-438c-8d91-fe46535a7dbb","_uuid":"bf81b1534a67b1949d33af5dc5775a39122385fb","collapsed":true,"trusted":true},"cell_type":"code","source":"data = ''.join(str(m) for m in df2['use'])\ndata = data.split(\".\")\ndocLabels = []\ndocLabels = [str(f) for f in range(0,len(data))]","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"b6867213-ac1b-4169-af40-7b20f1fe910a","_uuid":"85fbafc1f63b79664b22c0925ffcd3c1007ed7dc","collapsed":true,"trusted":true},"cell_type":"code","source":"data = nlp_clean(data)\nit = LabeledLineSentence(data, docLabels)","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"4cf3e89a-3fa4-430f-b987-6dc31d80552c","_uuid":"a73c24a139659d058797eca27dece721c0415423","collapsed":true,"trusted":true},"cell_type":"code","source":"#model = gensim.models.Doc2Vec(vector_size=20, min_count=5, alpha=0.025, min_alpha=0.025)\n#model.build_vocab(it)\n#training of model\n#for epoch in range(1):\n# print(\"iteration \" + str(epoch+1))\n# model.train(it,total_examples=model.corpus_count,epochs=model.epochs)\n#    #saving the created model\n# model.save(\"doc2vec.model\")\n#print(\"model saved\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}