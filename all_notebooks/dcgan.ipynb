{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nfrom random import randint\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa\nimport matplotlib.pyplot as plt\nimport glob\nimport imageio\nimport matplotlib.pyplot as plt\nimport PIL\nimport time\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom IPython import display\n\ninput = '../input/pokemon-images-and-types/'\noutput = '/kaggle/working/'\n\nstrategy = tf.distribute.get_strategy()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-12T10:06:16.658521Z","iopub.execute_input":"2021-06-12T10:06:16.658829Z","iopub.status.idle":"2021-06-12T10:06:16.665806Z","shell.execute_reply.started":"2021-06-12T10:06:16.6588Z","shell.execute_reply":"2021-06-12T10:06:16.664822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nEPOCHS = 1400\nBUFFER_SIZE = 60000\nBATCH_SIZE = 120\nIMAGE_SIZE = [120,120] #all images are in the same size\nCHANNELS = 3 #R,G,B\nNOISE_DIM = 100\nNUM_EXAMPLES_TO_GEN = 16","metadata":{"execution":{"iopub.status.busy":"2021-06-12T10:06:16.667619Z","iopub.execute_input":"2021-06-12T10:06:16.667994Z","iopub.status.idle":"2021-06-12T10:06:16.678286Z","shell.execute_reply.started":"2021-06-12T10:06:16.667958Z","shell.execute_reply":"2021-06-12T10:06:16.677435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_image(image):\n    image = tf.io.read_file(image)\n    image = tf.image.decode_jpeg(image, channels=CHANNELS)\n    image = (tf.cast(image, tf.float32) / 127.5) - 1 #rescale them to [-1,1]\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image","metadata":{"execution":{"iopub.status.busy":"2021-06-12T10:06:16.680314Z","iopub.execute_input":"2021-06-12T10:06:16.680846Z","iopub.status.idle":"2021-06-12T10:06:16.688276Z","shell.execute_reply.started":"2021-06-12T10:06:16.680803Z","shell.execute_reply":"2021-06-12T10:06:16.687445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DCGan(keras.Model):\n    def __init__(\n        self,\n        pokemon_generator,\n        pokemon_discriminator\n    ):\n        super(DCGan, self).__init__()\n        self.p_gen = pokemon_generator\n        self.p_disc = pokemon_discriminator\n        self.seed = tf.random.normal([NUM_EXAMPLES_TO_GEN, NOISE_DIM])\n        \n    def compile(\n        self,\n        p_gen_optimizer,\n        p_disc_optimizer,\n        gen_loss_fn,\n        disc_loss_fn\n    ):\n        super(DCGan, self).compile()\n        self.p_gen_optimizer = p_gen_optimizer\n        self.p_disc_optimizer = p_disc_optimizer\n        self.gen_loss_fn = gen_loss_fn\n        self.disc_loss_fn = disc_loss_fn\n        \n    @tf.function\n    def train_step(self, images):\n        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n\n        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n            generated_images = self.p_gen(noise, training=True)\n\n            real_output = self.p_disc(images, training=True)\n            fake_output = self.p_disc(generated_images, training=True)\n\n            gen_loss = self.gen_loss_fn(fake_output)\n            disc_loss = self.disc_loss_fn(real_output, fake_output)\n\n        gradients_of_generator = gen_tape.gradient(gen_loss, self.p_gen.trainable_variables)\n        gradients_of_discriminator = disc_tape.gradient(disc_loss, self.p_disc.trainable_variables)\n\n        generator_optimizer.apply_gradients(zip(gradients_of_generator, self.p_gen.trainable_variables))\n        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, self.p_disc.trainable_variables))\n        \n        return {\n            \"pokemon_gen_loss\": gen_loss ,\n            \"pokemon_disc_loss\": disc_loss,\n        }\n    \n    def train(self,dataset,epochs):\n        history = []\n        for epoch in range(epochs):\n            start = time.time()\n\n            for i, image_batch in enumerate(dataset):\n                loss = self.train_step(image_batch)\n\n            print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n    \n        display.clear_output(wait=True)\n        self.save_images(epochs)\n        \n        return history\n\n    def save_images(self, epoch):\n        predictions = self.p_gen(self.seed, training=False)\n        fig = plt.figure(figsize=(4, 4))\n        for i in range(predictions.shape[0]):\n            plt.subplot(4, 4, i+1)\n            plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n            plt.axis('off')\n\n        plt.savefig(output + 'image_at_epoch_{:04d}.png'.format(epoch))","metadata":{"execution":{"iopub.status.busy":"2021-06-12T10:06:16.68989Z","iopub.execute_input":"2021-06-12T10:06:16.69044Z","iopub.status.idle":"2021-06-12T10:06:16.706445Z","shell.execute_reply.started":"2021-06-12T10:06:16.690365Z","shell.execute_reply":"2021-06-12T10:06:16.705609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename_dataset = tf.data.Dataset.list_files(str(input + 'images/images/*.png'))\nimg_ds = filename_dataset.map(lambda x: decode_image(x),num_parallel_calls=AUTOTUNE)\nds = img_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).prefetch(AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T10:06:16.707939Z","iopub.execute_input":"2021-06-12T10:06:16.708509Z","iopub.status.idle":"2021-06-12T10:06:16.791089Z","shell.execute_reply.started":"2021-06-12T10:06:16.70847Z","shell.execute_reply":"2021-06-12T10:06:16.790254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_generator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Dense(30*30*256, use_bias=False, input_shape=(100,)))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Reshape((30, 30, 256)))\n    assert model.output_shape == (None, 30, 30, 256)  # None is the batch size\n\n    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n    assert model.output_shape == (None, 30, 30, 128)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    assert model.output_shape == (None, 60, 60, 64)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(CHANNELS, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n\n    assert model.output_shape == (None, 120, 120, CHANNELS)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-12T10:06:16.792412Z","iopub.execute_input":"2021-06-12T10:06:16.792942Z","iopub.status.idle":"2021-06-12T10:06:16.803115Z","shell.execute_reply.started":"2021-06-12T10:06:16.792893Z","shell.execute_reply":"2021-06-12T10:06:16.802299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_discriminator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[120, 120, CHANNELS])) #120 is image size\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1))\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-12T10:06:16.805689Z","iopub.execute_input":"2021-06-12T10:06:16.806055Z","iopub.status.idle":"2021-06-12T10:06:16.81408Z","shell.execute_reply.started":"2021-06-12T10:06:16.806019Z","shell.execute_reply":"2021-06-12T10:06:16.8133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = build_generator_model()\n\nnoise = tf.random.normal([1, 100])\ngenerated_image = generator(noise, training=False)\n\nplt.imshow(generated_image[0, :, :, 0], cmap='gray')","metadata":{"execution":{"iopub.status.busy":"2021-06-12T10:06:16.815739Z","iopub.execute_input":"2021-06-12T10:06:16.816151Z","iopub.status.idle":"2021-06-12T10:06:17.037813Z","shell.execute_reply.started":"2021-06-12T10:06:16.816116Z","shell.execute_reply":"2021-06-12T10:06:17.036849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator = build_discriminator_model()\ndecision = discriminator(generated_image)\nprint (decision)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T10:06:17.039236Z","iopub.execute_input":"2021-06-12T10:06:17.039574Z","iopub.status.idle":"2021-06-12T10:06:17.085578Z","shell.execute_reply.started":"2021-06-12T10:06:17.03954Z","shell.execute_reply":"2021-06-12T10:06:17.084717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\ngenerator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T10:06:17.086831Z","iopub.execute_input":"2021-06-12T10:06:17.087196Z","iopub.status.idle":"2021-06-12T10:06:17.092415Z","shell.execute_reply.started":"2021-06-12T10:06:17.087159Z","shell.execute_reply":"2021-06-12T10:06:17.091413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    def generator_loss(generated):\n        return loss(tf.ones_like(generated), generated)\n    \n    def discriminator_loss(real, generated):\n        real_loss = loss(tf.ones_like(real), real)\n\n        generated_loss = loss(tf.zeros_like(generated), generated)\n\n        return (real_loss + generated_loss) * 0.5","metadata":{"execution":{"iopub.status.busy":"2021-06-12T10:06:17.093927Z","iopub.execute_input":"2021-06-12T10:06:17.094345Z","iopub.status.idle":"2021-06-12T10:06:17.10166Z","shell.execute_reply.started":"2021-06-12T10:06:17.094305Z","shell.execute_reply":"2021-06-12T10:06:17.100489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DCGAN = DCGan(generator,discriminator)\nDCGAN.compile(\n    generator_optimizer,\n    discriminator_optimizer,\n    generator_loss,\n    discriminator_loss\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T10:06:17.103088Z","iopub.execute_input":"2021-06-12T10:06:17.10343Z","iopub.status.idle":"2021-06-12T10:06:17.119852Z","shell.execute_reply.started":"2021-06-12T10:06:17.103393Z","shell.execute_reply":"2021-06-12T10:06:17.119114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DCGAN.train(ds, EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T10:06:17.121072Z","iopub.execute_input":"2021-06-12T10:06:17.121396Z","iopub.status.idle":"2021-06-12T10:34:50.586877Z","shell.execute_reply.started":"2021-06-12T10:06:17.121363Z","shell.execute_reply":"2021-06-12T10:34:50.586036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"noise = tf.random.normal([1, 100])\ngenerated_image = generator(noise, training=False)\n\nplt.imshow(generated_image[0, :, :, 0], cmap='gray')","metadata":{"execution":{"iopub.status.busy":"2021-06-12T10:39:23.889614Z","iopub.execute_input":"2021-06-12T10:39:23.889965Z","iopub.status.idle":"2021-06-12T10:39:24.02Z","shell.execute_reply.started":"2021-06-12T10:39:23.88993Z","shell.execute_reply":"2021-06-12T10:39:24.018984Z"},"trusted":true},"execution_count":null,"outputs":[]}]}