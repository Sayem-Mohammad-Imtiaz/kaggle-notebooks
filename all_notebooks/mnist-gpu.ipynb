{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import cv2\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport os\nimport math\nimport time\n\n#pytorch utility imports\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision.utils import make_grid\n\n#neural net imports\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('../input/mnist-in-csv/mnist_test.csv')\ntrain_df = pd.read_csv('../input/mnist-in-csv/mnist_train.csv')\ntrain_labels = train_df['label'].values # converting to numpy also\ntest_labels=test_df['label'].values\ntrain_images = (train_df.iloc[:,1:].values).astype('float32')\ntest_images = (test_df.iloc[:,1:].values).astype('float32')\ntrain_images = train_images[0:20000]\ntrain_labels = train_labels[0:20000]\nprint(\"train images shape\",train_images.shape)\nprint(\"train labels shape\",train_labels.shape)\nprint(\"test images shape\",test_images.shape)\nprint(\"test labels shape\",test_labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images = train_images.reshape(train_images.shape[0], 28, 28)\ntest_images = test_images.reshape(test_images.shape[0], 28, 28)\nprint(train_images.shape)\nprint(test_images.shape)\n\n#train samples\nfor i in range(6, 9):\n    plt.subplot(330 + (i+1))\n    plt.imshow(train_images[i].squeeze(), cmap=plt.get_cmap('gray'))\n    plt.title(train_labels[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test samples\nfor j in range(3, 9):\n    plt.subplot(330 + (j+1))\n    plt.imshow(test_images[j].squeeze(), cmap=plt.get_cmap('gray'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images_tensor = torch.tensor(train_images)/255.0 #default torch.FloatTensor\ntrain_labels_tensor = torch.tensor(train_labels)\ntrain_tensor = TensorDataset(train_images_tensor, train_labels_tensor)\n\ntest_images_tensor = torch.tensor(test_images)/255.0\ntest_labels_tensor = torch.tensor(test_labels)\ntest_tensor = TensorDataset(test_images_tensor, test_labels_tensor)\ntrain_loader = DataLoader(train_tensor, batch_size=16, num_workers=2, shuffle=True)\ntest_loader = DataLoader(test_images_tensor, batch_size=16, num_workers=2, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        \n        self.fc1 = nn.Linear(784, 548)\n        self.bn1 = nn.BatchNorm1d(548)\n        \n        self.fc2 = nn.Linear(548, 252)\n        self.bn2 = nn.BatchNorm1d(252)\n        \n        self.fc3 = nn.Linear(252, 10)\n        \n        \n    def forward(self, x):\n        x = x.view((-1, 784))\n        h = self.fc1(x)\n        h = self.bn1(h)\n        h = F.relu(h)\n        h = F.dropout(h, p=0.5, training=self.training)\n        \n        h = self.fc2(h)\n        h = self.bn2(h)\n        h = F.relu(h)\n        h = F.dropout(h, p=0.2, training=self.training)\n        \n        h = self.fc3(h)\n        out = F.log_softmax(h,dim=1)\n        return out\n\nmodel = Model()\nprint(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\nif (device.type=='cuda'):\n    model.cuda() # convert model to cuda model\n\n    \noptimizer = optim.Adam(model.parameters(), lr=0.001) #adam optimizer from optim module","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.train()\n\n\nlosses = []\nfor epoch in range(5):\n    for batch_idx, (data, target) in enumerate(train_loader):\n        # Get Samples\n        if (device.type=='cuda'):\n            data, target = Variable(data.cuda()), Variable(target.cuda())\n        else:\n            data, target = Variable(data), Variable(target) # making group of 16\n            \n        \n        # Init\n        optimizer.zero_grad() #making gradient zero for new mini-batch. \n\n        # Predict\n        y_pred = model(data) \n         \n        \n        # Calculate loss\n        loss = F.cross_entropy(y_pred, target)\n        losses.append(loss.data)\n        \n        # Backpropagation\n        loss.backward()  #It computes gradient of loss w.r.t all the parameters and store them in (parameter.grad) attribute.\n        optimizer.step() #optimizer.step() updates all the parameters based on (parameter.grad)\n        \n        \n        # Display\n        #if batch_idx % 100 == 1:\n        print('\\r Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format( epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data), end='')\n            \n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if (device.type=='cuda'):\n    evaluate_x=test_images_tensor.cuda()\n    evaluate_y=test_labels_tensor.cuda()\nelse:\n    evaluate_x=test_images_tensor\n    evaluate_y=test_labels_tensor\n    \n\noutput = model(evaluate_x)\n\npred = output.data.max(1)[1]\nd = pred.eq(evaluate_y.data).cpu()\na=(d.sum().data.cpu().numpy())\nb=d.size()\nb=torch.tensor(b)\nb=(b.sum().data.cpu().numpy())\naccuracy = a/b\n\nprint('Accuracy:', accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(evaluate_y[3: 9])\nprint(pred[3: 9])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}