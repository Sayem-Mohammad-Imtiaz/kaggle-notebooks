{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predicting insurance costs given the set of attributes in this data set using an extra-trees regressor model."},{"metadata":{},"cell_type":"markdown","source":"#### Features (Data Dictionary):\n- age: age of primary beneficiary\n- sex: insurance contractor gender, female, male\n- bmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\n- children: Number of children covered by health insurance / Number of dependents\n- smoker: Smoking\n- region: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n\n#### Target:\n- charges: Individual medical costs billed by health insurance\n\n#### We will use an \"extra-trees regressor\" in this project.\n- This class implements a meta estimator that fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting."},{"metadata":{},"cell_type":"markdown","source":"#### Import necessary tools."},{"metadata":{"trusted":true},"cell_type":"code","source":"# data preparation\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# visualizations\nimport seaborn as sns\nfrom itertools import cycle, islice\n\n# modeling\nfrom sklearn.ensemble import ExtraTreesRegressor\nimport sklearn.metrics\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Load and peek at the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/insurance/insurance.csv')\ndf.head().append(df.tail())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Check for null values."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### No nulls!"},{"metadata":{},"cell_type":"markdown","source":"#### Let's print some general descriptors of the data in each feature."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's look at the unique values in each column."},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in df:\n    print(col)\n    print(df[col].unique())\n    print()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### And let's peek at the correlations between each of the features."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Now let's visualize those correlations in a heatmap."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style=\"white\")\n\n# Compute the correlation matrix\ncorr = df.corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(5, 5))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(240, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5},\n            annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### All of the features have acceptably small correlations with each other.\n#### Age and BMI have by far the highest correlations with our target variable, charges.\n\n#### First, we need to convert the bmi to integer values."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['bmi_int'] = df['bmi'].apply(lambda x: int(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's look at the distribution of the data now."},{"metadata":{"trusted":true},"cell_type":"code","source":"variables = ['sex','smoker','region','age','bmi_int','children']\n\nprint('Data distribution analysis')\nfor v in variables:\n    # Create a list of colors to cycle through in the visualizations.\n    my_colors = list(islice(cycle(['b', 'r', 'g', 'y', 'k']), None, len(df[v])))\n    # Set the figure size.\n    plt.figure(figsize=(20,5))\n    # Now sort the values in each column.\n    df = df.sort_values(by=[v])\n    # Finally, plot bar graphs of each column's values.\n    df[v].value_counts()\\\n        .plot(kind = 'bar',\n              color=my_colors)\n    plt.title(v)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We sorted the values, so let's peek at the head and tail of the dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head().append(df.tail())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### And at a sample..."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Now let's look at the average cost per feature value."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mean cost analysis:')\nfor v in variables:\n    group_df = df.groupby(pd.Grouper(key=v)).mean()\n    group_df = group_df.sort_index()\n    group_df.plot(y = ['charges'],kind = 'bar', figsize=(20,5))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Men average a little bit higher charges than women.\n- Smokers average a lot more than non-smokers.\n- Regions don't really vary.\n- Charges trend up with age.\n- Need to look more carefully at bmi. Charges sort of trend up as bmi increases, but then the last four markers are really odd.\n- Not much difference between numbers of children except five is significantly less."},{"metadata":{},"cell_type":"markdown","source":"#### Let's look at a pairs plot. It will allow us to see both the distribution of single variables as well as the relationships between two variables. Pair plots are a great method to identify trends for follow-up analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Variables pairplot:')\nvariables = ['sex','smoker','region','age','bmi_int','children','charges']\nsns_plot = sns.pairplot(df[variables])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Age shows three distinct tiers of linear relationships with charges.\n- Charges are pretty similar for 0-3 children, but drop off for 4 and especially 5.\n- Max bmi drops as the number of children increases until 5 children."},{"metadata":{},"cell_type":"markdown","source":"#### We need to transform the categorical data and then store it back in the df dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"le_sex = LabelEncoder()\nle_smoker = LabelEncoder()\nle_region = LabelEncoder()\n\ndf['sex'] = le_sex.fit_transform(df['sex'])\ndf['smoker'] = le_smoker.fit_transform(df['smoker'])\ndf['region'] = le_region.fit_transform(df['region'])\n\ndf.head().append(df.tail())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Now let's split the data into train and test sets and run our regressor model."},{"metadata":{"trusted":true},"cell_type":"code","source":"variables = ['sex','smoker','region','age','bmi','children']\n\nX = df[variables]\n# scale the data\nsc = StandardScaler()\nX = sc.fit_transform(X) \nY = df['charges']\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's train our model and evaluate it. We will use an \"extra-trees regressor.\"\n\n#### This class implements a meta estimator that fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting."},{"metadata":{"trusted":true},"cell_type":"code","source":"# create model\nregressor = ExtraTreesRegressor(n_estimators = 200)\n# fit model\nregressor.fit(X_train,y_train)\n\n# use model to obtain predictions and then evaluate the predictions\ny_train_pred = regressor.predict(X_train)\ny_test_pred = regressor.predict(X_test)\n\nprint('ExtraTreesRegressor evaluating result:')\nprint()\nprint(\"The mean of the train:\", y_train.mean())\nprint(\"The median of the train:\", y_train.median())\nprint(\"Train MAE: \", sklearn.metrics.mean_absolute_error(y_train, y_train_pred))\nprint(\"Train RMSE: \", np.sqrt(sklearn.metrics.mean_squared_error(y_train, y_train_pred)))\nprint(\"mean/RMSE:\", y_train.mean()/np.sqrt(sklearn.metrics.mean_squared_error(y_train, y_train_pred)))\n\nprint()\nprint(\"The mean of the test:\", y_test.mean())\nprint(\"The median of the test:\", y_test.median())\nprint(\"Test MAE: \", sklearn.metrics.mean_absolute_error(y_test, y_test_pred))\nprint(\"Test RMSE: \", np.sqrt(sklearn.metrics.mean_squared_error(y_test, y_test_pred)))\nprint(\"mean/RMSE:\", y_test.mean()/np.sqrt(sklearn.metrics.mean_squared_error(y_test, y_test_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Now let's rank the importance of each feature using regressor.feature_importances."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Feature importance ranking\\n\\n')\nimportances = regressor.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in regressor.estimators_],axis=0)\nindices = np.argsort(importances)[::-1]\n\nimportance_list = []\nfor f in range(X.shape[1]):\n    variable = variables[indices[f]]\n    importance_list.append(variable)\n    print(\"%d.%s(%f)\" % (f + 1, variable, importances[indices[f]]))\n\n# Plot the feature importances of the forest\nplt.figure()\nplt.title(\"Feature importances\")\nplt.bar(importance_list, importances[indices],\n       color=\"r\", yerr=std[indices], align=\"center\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### So whether a person smoked or not is by far the most important feature in predicting the insurance rates.\n#### BMI drops off in importance, but is second.\n#### And age is third.\n\n#### Let's show some examples of predicting insurance rates on fictitious characters. Recall the ranges in values for each feature (note they have been encoded)."},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in df:\n    print(col)\n    print(df[col].min(), ' - ', df[col].max())\n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Predicting insurance rates on new fictitious characters:\\n\\n')\n\n# Recall that the order of our variables is \n# ['sex','smoker','region','age','bmi','children']\n\n# Create a character named Rock.\nRock = ['male','yes','southwest',25,30.5,2]\nprint('Rock - ')\nprint('\\tsex:', Rock[0])\nprint('\\tsmoker:', Rock[1])\nprint('\\tregion:', Rock[2])\nprint('\\tage:', Rock[3])\nprint('\\tbmi:', Rock[4])\nprint('\\tchildren:', Rock[5])\nprint()\n\n# Transform the string data into numeric.\nRock[0] = le_sex.transform([Rock[0]])[0] \nRock[1] = le_smoker.transform([Rock[1]])[0] \nRock[2] = le_region.transform([Rock[2]])[0] \n\n# Scale the data using the StandardScaler() we previously created.\nX = sc.transform([Rock])\n\n# Predict the cost for Rock using the extra trees regressor we previously created.\ncost_for_Rock = regressor.predict(X)[0]\nprint('Cost for Rock = $',cost_for_Rock,'\\n\\n')\n\n\nRockette = ['female','no','southeast',45,19,0]\nprint('Rockette - ')\nprint('\\tsex:', Rockette[0])\nprint('\\tsmoker:', Rockette[1])\nprint('\\tregion:', Rockette[2])\nprint('\\tage:', Rockette[3])\nprint('\\tbmi:', Rockette[4])\nprint('\\tchildren:', Rockette[5])\nprint()\n\n# Transform the string data into numeric.\nRockette[0] = le_sex.transform([Rockette[0]])[0] \nRockette[1] = le_smoker.transform([Rockette[1]])[0] \nRockette[2] = le_region.transform([Rockette[2]])[0] \n\n# Scale the data using the StandardScaler() we previously created.\nX = sc.transform([Rockette])\n\n# Predict the cost for Rock using the extra trees regressor we previously created.\ncost_for_Rockette = regressor.predict(X)[0]\nprint('Cost for Rockette = $',cost_for_Rockette, '\\n\\n')\n\n\nFertileRockette = ['female','no','southeast',45,19,5]\nprint('FertileRockette - ')\nprint('\\tsex:', FertileRockette[0])\nprint('\\tsmoker:', FertileRockette[1])\nprint('\\tregion:', FertileRockette[2])\nprint('\\tage:', FertileRockette[3])\nprint('\\tbmi:', FertileRockette[4])\nprint('\\tchildren:', FertileRockette[5])\nprint()\n\n# Transform the string data into numeric.\nFertileRockette[0] = le_sex.transform([FertileRockette[0]])[0] \nFertileRockette[1] = le_smoker.transform([FertileRockette[1]])[0] \nFertileRockette[2] = le_region.transform([FertileRockette[2]])[0] \n\n# Scale the data using the StandardScaler() we previously created.\nX = sc.transform([FertileRockette])\n\n# Predict the cost for Rock using the extra trees regressor we previously created.\ncost_for_FertileRockette = regressor.predict(X)[0]\nprint('Cost for FertileRockette = $',cost_for_FertileRockette)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thank you to the following tutorial:\nhttps://www.kaggle.com/flagma/health-care-cost-analysys-prediction-python/data"},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}