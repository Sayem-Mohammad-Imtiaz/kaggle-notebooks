{"nbformat":4,"cells":[{"cell_type":"markdown","metadata":{},"source":"# Is it a mushroom or is it a toadstool?"},{"cell_type":"code","metadata":{"_uuid":"f3a1930729d54aa81ce7dffb1e199a7e99f05066","_cell_guid":"de3c92f7-93b4-49a7-b919-9066057fa4d4"},"execution_count":null,"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy\nimport pandas\nimport collections\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","outputs":[]},{"cell_type":"markdown","metadata":{},"source":"To classify fungi as edible (mushrooms) or poisonous (toadstools), I use a Bayesian Belief Network with one hidden variable, on which each of the observables is dependent. This is inferred by clustering the samples as follows.\nA cluster is characterised by a probability distribution P(Xi|C) for each variable. For each observation, the average of P(Xi|Cj) is calculated for each existing cluster Cj, and the most similar cluster is found. If the probability of the observation belonging to the most similar cluster is greater than 0.5, the observation is added to that cluster. If not, a new cluster is created, starting with that cluster."},{"cell_type":"code","metadata":{"collapsed":true},"execution_count":null,"source":"class FungusClassifier(object):\n    \"\"\"Infers a hidden variable and uses Bayesian classification to predict whether a fungus is \n    edible or poisonous\"\"\"\n    def __init__(self,filename):\n        data=pandas.read_csv(filename,index_col=False)\n        clusters=[]\n        for (i,row) in data.iterrows():\n            best=-1\n            sim=0.5\n            for (j,cluster) in enumerate(clusters):\n                x=sum(cluster[key][value]/sum(cluster[key].values())\n                      for (key,value) in row.iteritems())/(data.shape[1])\n                if x>sim:\n                    best=j\n                    sim=x\n            if best==-1:\n                clusters.append(collections.defaultdict(lambda: collections.defaultdict(float)))\n                print(i+1,'rows analysed',len(clusters),'clusters found')\n            for (key,value) in row.iteritems():\n                clusters[best][key][value]+=1.0\n        index=[]\n        for column in data.columns:\n            index.extend([(column,value) for value in data[column].unique()])\n        self.probabilities=pandas.DataFrame({(key,value):[cluster[key][value]+1.0 for cluster in clusters]\n                                            for (key,value) in index}).T\n        self.prior=self.probabilities.sum(axis=0)\n        self.prior/=self.prior.sum()\n        self.edibility_prior=self.probabilities.loc['class'].sum(axis=1)\n        self.edibility_prior/=self.edibility_prior.sum()\n        def normalize(group):\n            return group.div(group.sum(axis=0),axis='columns')\n        self.probabilities=self.probabilities.groupby(axis=0,level=0).apply(normalize)\n        \n    def __call__(self,**kwargs):\n        \"Estimates the probability that a fungus is edible given the features in kwargs\"\n        category=self.prior.copy()\n        for (key,value) in kwargs.items():\n            category*=self.probabilities.loc[(key,value)]\n            category/=category.sum()\n        result=self.edibility_prior*((self.probabilities.loc['class']*category).sum(axis=1))\n        return result/result.sum()\n    \n    def test(self,filename):\n        \"\"\"Produces KDE plots of the estimated probability\"\"\"\n        data=pandas.read_csv(filename,index_col=False)\n        observables=[column for column in data.columns if column!='class']\n        results=pandas.DataFrame([self(**row) for (i,row) in data[observables].iterrows()])\n        results.loc[:,'class']=data['class']\n        return results","outputs":[]},{"cell_type":"markdown","metadata":{},"source":"This creates 11 clusters"},{"cell_type":"code","metadata":{},"execution_count":null,"source":"BBN=FungusClassifier('../input/mushrooms.csv')","outputs":[]},{"cell_type":"markdown","metadata":{},"source":"Here is the prior probability of a fungus being edible."},{"cell_type":"code","metadata":{},"execution_count":null,"source":"BBN.edibility_prior.plot.bar()","outputs":[]},{"cell_type":"markdown","metadata":{},"source":"Here is the prior probability of each cluster."},{"cell_type":"code","metadata":{},"execution_count":null,"source":"BBN.prior.plot.bar()","outputs":[]},{"cell_type":"markdown","metadata":{},"source":"Here is the probability of edibility given each cluster. Most clusters discriminate very strongly between mushrooms and toadstools."},{"cell_type":"code","metadata":{},"execution_count":null,"source":"BBN.probabilities.loc['class'].T.plot.bar()","outputs":[]},{"cell_type":"markdown","metadata":{},"source":"Here is a KDE plot of the posterior probability of edibility over the entire sample."},{"cell_type":"code","metadata":{},"execution_count":null,"source":"result=BBN.test('../input/mushrooms.csv')\nresult['e'].plot.kde()","outputs":[]},{"cell_type":"markdown","metadata":{},"source":"All edible fungi are classified as edible with a high degree of confidence."},{"cell_type":"code","metadata":{},"execution_count":null,"source":"result[result['class']=='e']['e'].plot.kde()","outputs":[]},{"cell_type":"markdown","metadata":{},"source":"Poisonous fungi are mostly classified a poisonous with a high degree of confidence. There are however a few that are misclassified (these probably belong to cluster 0)."},{"cell_type":"code","metadata":{},"execution_count":null,"source":"result[result['class']=='p']['e'].plot.kde()","outputs":[]},{"cell_type":"markdown","metadata":{},"source":"Fungi identified as edible with >50% confidence are 90% likely to be correctly classified."},{"cell_type":"code","metadata":{},"execution_count":null,"source":"result[result['e']>0.5]['class'].value_counts(normalize=True).plot.bar()","outputs":[]},{"cell_type":"markdown","metadata":{},"source":"With a confidence threshold of 90%, correct classification is close to 99%"},{"cell_type":"code","metadata":{},"execution_count":null,"source":"result[result['e']>0.9]['class'].value_counts(normalize=True).plot.bar()","outputs":[]},{"cell_type":"markdown","metadata":{},"source":"This is a pretty good classifier, but given the safety-critical nature of the problem, I'd like to do better."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"file_extension":".py","mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","version":"3.6.1","codemirror_mode":{"version":3,"name":"ipython"},"nbconvert_exporter":"python"}},"nbformat_minor":1}