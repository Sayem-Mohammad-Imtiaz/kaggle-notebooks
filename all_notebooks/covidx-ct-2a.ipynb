{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport time\nimport copy\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport torch,torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets,models,transforms\nimport torch.optim as optim\n# from torchsummary import summary\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:39:04.434381Z","iopub.execute_input":"2021-06-19T09:39:04.434758Z","iopub.status.idle":"2021-06-19T09:39:06.695862Z","shell.execute_reply.started":"2021-06-19T09:39:04.434726Z","shell.execute_reply":"2021-06-19T09:39:06.694742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:54:20.038791Z","iopub.execute_input":"2021-06-09T01:54:20.039235Z","iopub.status.idle":"2021-06-09T01:54:20.042791Z","shell.execute_reply.started":"2021-06-09T01:54:20.039203Z","shell.execute_reply":"2021-06-09T01:54:20.042041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 读取train.txt\ntrain_df = pd.read_csv('../input/covidxct/train_COVIDx_CT-2A.txt', sep=\" \", header=None)\ntrain_df.columns=['filename', 'label', 'xmin','ymin','xmax','ymax']\ntrain_df=train_df.drop(['xmin', 'ymin','xmax', 'ymax'], axis=1 )\n# 读取test.txt\nval_df = pd.read_csv('../input/covidxct/val_COVIDx_CT-2A.txt', sep=\" \", header=None)\nval_df.columns=['filename', 'label', 'xmin','ymin','xmax','ymax']\nval_df=val_df.drop(['xmin', 'ymin','xmax', 'ymax'], axis=1 )\n\ntest_df = pd.read_csv('../input/covidxct/test_COVIDx_CT-2A.txt', sep=\" \", header=None)\ntest_df.columns=['filename', 'label', 'xmin','ymin','xmax','ymax']\ntest_df=test_df.drop(['xmin', 'ymin','xmax', 'ymax'], axis=1 )","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:39:09.781991Z","iopub.execute_input":"2021-06-19T09:39:09.782379Z","iopub.status.idle":"2021-06-19T09:39:10.209855Z","shell.execute_reply.started":"2021-06-19T09:39:09.782346Z","shell.execute_reply":"2021-06-19T09:39:10.208955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# labels={0:'Normal',1:'Pneumonia',2:'COVID-19'}\ntrain_df.head()\ntrain_df.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:39:13.210769Z","iopub.execute_input":"2021-06-19T09:39:13.211189Z","iopub.status.idle":"2021-06-19T09:39:13.220649Z","shell.execute_reply.started":"2021-06-19T09:39:13.211152Z","shell.execute_reply":"2021-06-19T09:39:13.219656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path = '../input/covidxct/2A_images/'  #directory path\ntrain_df['filename'] = image_path+train_df['filename']\nval_df['filename'] = image_path+val_df['filename']\ntest_df['filename'] = image_path + test_df['filename']\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:39:14.670353Z","iopub.execute_input":"2021-06-19T09:39:14.670766Z","iopub.status.idle":"2021-06-19T09:39:14.745245Z","shell.execute_reply.started":"2021-06-19T09:39:14.670729Z","shell.execute_reply":"2021-06-19T09:39:14.744279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = shuffle(train_df) # 打乱顺序\nval_df = shuffle(val_df)\ntest_df = shuffle(test_df)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:39:16.777328Z","iopub.execute_input":"2021-06-19T09:39:16.777731Z","iopub.status.idle":"2021-06-19T09:39:16.816932Z","shell.execute_reply.started":"2021-06-19T09:39:16.777696Z","shell.execute_reply":"2021-06-19T09:39:16.815965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels={0:'Normal',1:'Pneumonia',2:'COVID-19'}\nclass_names=['Normal','Pneumonia','COVID-19']\n\ntrain_df['label_n']=[labels[b] for b in train_df['label']]\nval_df['label_n']=[labels[b] for b in val_df['label']]\ntest_df['label_n']=[labels[b] for b in test_df['label']]\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:39:18.385395Z","iopub.execute_input":"2021-06-19T09:39:18.385776Z","iopub.status.idle":"2021-06-19T09:39:18.45038Z","shell.execute_reply.started":"2021-06-19T09:39:18.385745Z","shell.execute_reply":"2021-06-19T09:39:18.449275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Negative and positive values of train: \\n{train_df['label_n'].value_counts()}\")\nprint(f\"Negative and positive values of validation: \\n{val_df['label_n'].value_counts()}\")\nprint(f\"Negative and positive values of test: \\n{test_df['label_n'].value_counts()}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:39:20.494987Z","iopub.execute_input":"2021-06-19T09:39:20.495471Z","iopub.status.idle":"2021-06-19T09:39:20.546381Z","shell.execute_reply.started":"2021-06-19T09:39:20.495437Z","shell.execute_reply":"2021-06-19T09:39:20.545423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df=train_df.reset_index()\nval_df=val_df.reset_index()\ntest_df=test_df.reset_index()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:39:22.435241Z","iopub.execute_input":"2021-06-19T09:39:22.435617Z","iopub.status.idle":"2021-06-19T09:39:22.4504Z","shell.execute_reply.started":"2021-06-19T09:39:22.435581Z","shell.execute_reply":"2021-06-19T09:39:22.449465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CovidDataset(Dataset):\n    def __init__(self, dataset_df, transform=None):\n        self.dataset_df = dataset_df\n        self.transform = transform\n        \n    def __len__(self):\n        return self.dataset_df.shape[0]\n    \n    def __getitem__(self, idx):\n        image_name = self.dataset_df['filename'][idx]\n        img = Image.open(image_name)\n        label = self.dataset_df['label'][idx]\n        \n        if self.transform:\n            img = self.transform(img)\n        return img, label","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:39:23.961227Z","iopub.execute_input":"2021-06-19T09:39:23.961772Z","iopub.status.idle":"2021-06-19T09:39:23.969274Z","shell.execute_reply.started":"2021-06-19T09:39:23.961713Z","shell.execute_reply":"2021-06-19T09:39:23.968409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\ninput_channel = 3\ninput_size = (224,224)\ncrop_size=(320,350)\nnum_classes=3\nnum_epochs = 20","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:39:25.426469Z","iopub.execute_input":"2021-06-19T09:39:25.426902Z","iopub.status.idle":"2021-06-19T09:39:25.432306Z","shell.execute_reply.started":"2021-06-19T09:39:25.42687Z","shell.execute_reply":"2021-06-19T09:39:25.430953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transform = {\n#     'train':transforms.Compose([\n#         transforms.CenterCrop(crop_size),\n#         transforms.Resize(input_size),\n#         transforms.RandomHorizontalFlip(p=0.5),\n#         transforms.RandomVerticalFlip(p=0.5),\n#         transforms.Grayscale(input_channel),\n#         transforms.ToTensor(),\n#         transforms.Normalize([0.6349431,0.6349431,0.6349431],[0.32605055,0.32605055,0.32605055])\n#     ]),\n#     'test':transforms.Compose([\n#         transforms.CenterCrop(crop_size),\n#         transforms.Resize(input_size),\n#         transforms.Grayscale(input_channel),\n#         transforms.ToTensor(),\n#         transforms.Normalize([0.63507175,0.63507175,0.63507175],[0.3278614,0.3278614,0.3278614])\n#     ])\n# }\ntransform = {\n    'train':transforms.Compose([\n        transforms.CenterCrop(crop_size),\n        transforms.Resize(input_size),\n#         transforms.RandomHorizontalFlip(p=0.5),\n#         transforms.RandomVerticalFlip(p=0.5),\n        transforms.Grayscale(input_channel),\n        transforms.ToTensor(),\n#         transforms.Normalize([0.6349431,0.6349431,0.6349431],[0.32605055,0.32605055,0.32605055])\n    ]),\n    'test':transforms.Compose([\n        transforms.CenterCrop(crop_size),\n        transforms.Resize(input_size),\n        transforms.Grayscale(input_channel),\n        transforms.ToTensor(),\n#         transforms.Normalize([0.63507175,0.63507175,0.63507175],[0.3278614,0.3278614,0.3278614])\n    ])\n}","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:40:56.208754Z","iopub.execute_input":"2021-06-19T09:40:56.209163Z","iopub.status.idle":"2021-06-19T09:40:56.215094Z","shell.execute_reply.started":"2021-06-19T09:40:56.209122Z","shell.execute_reply":"2021-06-19T09:40:56.214366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_names=['train','val','test']\nimage_transforms = {'train':transform['train'], 'val':transform['test'],'test':transform['test']}\n\ntrain_dataset = CovidDataset(train_df, transform=image_transforms['train'])\nval_dataset = CovidDataset(val_df, transform=image_transforms['val'])\ntest_dataset = CovidDataset(test_df, transform=image_transforms['test'])\n\nimage_dataset = {'train':train_dataset, 'val':val_dataset,'test':test_dataset}\n\ndataloaders = {x:DataLoader(image_dataset[x],batch_size=batch_size,shuffle=True,num_workers=4) for x in dataset_names}\n\ndataset_sizes = {x:len(image_dataset[x]) for x in dataset_names}\n\n# class_names = {}\n# print(dataset_sizes)\n# print(class_names)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:40:58.322148Z","iopub.execute_input":"2021-06-19T09:40:58.322645Z","iopub.status.idle":"2021-06-19T09:40:58.329642Z","shell.execute_reply.started":"2021-06-19T09:40:58.322612Z","shell.execute_reply":"2021-06-19T09:40:58.328528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a=image_dataset['train'][2][0]\na=transforms.ToPILImage()(a)\n# a.show()\nplt.imshow(a)\n# len(a)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:41:34.075146Z","iopub.execute_input":"2021-06-19T09:41:34.075688Z","iopub.status.idle":"2021-06-19T09:41:34.295606Z","shell.execute_reply.started":"2021-06-19T09:41:34.075643Z","shell.execute_reply":"2021-06-19T09:41:34.294514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2 as cv\nfrom skimage import feature as skif\nimport numpy as np\n\n#获取图像的lbp特征\ndef get_lbp_data(img, lbp_radius=1, lbp_point=8):\n    # img = utils.change_image_rgb(image_path)\n#     img = cv.imread(image_path)\n    img=transforms.Grayscale(1)(img)\n    img=transforms.ToPILImage()(img)\n#     image = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n    # 使用LBP方法提取图像的纹理特征.\n    #lbp_point：选取中心像素周围的像素点的个数；lbp_radius：选取的区域的半径\n    #以下为5种不同的方法提取的lbp特征，相应的提取到的特征维度也不一样\n    #'default': original local binary pattern which is gray scale but notrotation invariant\n    #'ror': extension of default implementation which is gray scale androtation invariant\n    #'uniform': improved rotation invariance with uniform patterns andfiner quantization of the angular space which is gray scale and rotation invariant.\n    #'nri_uniform': non rotation-invariant uniform patterns variantwhich is only gray scale invariant\n    #'var': rotation invariant variance measures of the contrast of localimage texture which is rotation but not gray scale invariant\n    lbp = skif.local_binary_pattern(img, lbp_point, lbp_radius, 'default')\n    # 统计图像的直方图\n    max_bins = int(lbp.max() + 1)\n    #print(max_bins)\n    # hist size:256\n    hist, _ = np.histogram(lbp, density=True, bins=max_bins, range=(0, max_bins))\n    return hist,lbp\n\nplt.figure(figsize=(10,10))\nfor i in range(10,19):\n    img,lab=image_dataset['train'][i]\n    feature,lbp = get_lbp_data(img)  #调用函数\n    plt.subplot(3,3,i-9),plt.title(lab)\n    plt.imshow(lbp,plt.cm.gray),plt.axis('off')\nprint(feature) ","metadata":{"execution":{"iopub.status.busy":"2021-06-19T09:46:00.981194Z","iopub.execute_input":"2021-06-19T09:46:00.981858Z","iopub.status.idle":"2021-06-19T09:46:03.008223Z","shell.execute_reply.started":"2021-06-19T09:46:00.981765Z","shell.execute_reply":"2021-06-19T09:46:03.005987Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom PIL import Image\ndef show_tensor_img(tensor_img):\n    to_pil = transforms.ToPILImage()\n    img = tensor_img.cpu().clone()\n    img = to_pil(img)\n    plt.figure()\n    plt.imshow(img)\n    plt.show()\n\ndef show_img(idx):\n  show_tensor_img(train_dataset[idx][0])\nfor i in range(4):\n    show_img(i)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T03:20:13.554725Z","iopub.execute_input":"2021-06-09T03:20:13.555045Z","iopub.status.idle":"2021-06-09T03:20:14.231394Z","shell.execute_reply.started":"2021-06-09T03:20:13.555016Z","shell.execute_reply":"2021-06-09T03:20:14.230693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def get_mean_std(dataset, ratio=0.01): # 计算样本的均值与方差\n#     \"\"\"Get mean and std by sample ratio\n#     \"\"\"\n#     dataloader = torch.utils.data.DataLoader(dataset, batch_size=int(len(dataset)*ratio),shuffle=True, num_workers=2)\n#     train = iter(dataloader).next()[0]   # 一个batch的数据\n# #     print(train)\n#     mean = np.mean(train.numpy(), axis=(0,2,3))\n#     std = np.std(train.numpy(), axis=(0,2,3))\n#     return mean, std\n# train_mean, train_std = get_mean_std(train_dataset)\n# val_mean, val_std = get_mean_std(val_dataset)\n# test_mean, test_std = get_mean_std(test_dataset)\n\n# print(train_mean, train_std)\n# print(val_mean, val_std)\n# print(test_mean,test_std)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:54:21.344582Z","iopub.execute_input":"2021-06-09T01:54:21.344881Z","iopub.status.idle":"2021-06-09T01:54:21.34903Z","shell.execute_reply.started":"2021-06-09T01:54:21.344852Z","shell.execute_reply":"2021-06-09T01:54:21.348026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\n# 绘制混淆矩阵\ndef plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    Input\n    - cm : 计算出的混淆矩阵的值\n    - classes : 混淆矩阵中每一行每一列对应的列\n    - normalize : True:显示百分比, False:显示个数\n    \"\"\"\n    cm=cm.numpy()\n    if normalize:\n      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n      print(\"Normalized confusion matrix\")\n    else:\n      cm=cm.astype('int')\n      print('Confusion matrix, without normalization')\n    print(cm)\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    fmt = '{:.2f}' if normalize else '{}'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n      plt.text(i, j, fmt.format(cm[i, j]),horizontalalignment=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n\n# 生成混淆矩阵\ndef confusion_matrix(preds, labels, conf_matrix):\n    preds = torch.argmax(preds, 1)\n    for p, t in zip(preds, labels):\n        conf_matrix[t, p] += 1\n    return conf_matrix\n\ndef calculate_all_prediction(conf_matrix):\n    '''\n    计算总精度：对角线上所有值除以总数\n    '''\n    total_sum = conf_matrix.sum()\n    correct_sum = (np.diag(conf_matrix)).sum()\n    prediction = round(100*float(correct_sum)/float(total_sum),2)\n    return prediction\n \ndef calculate_label_prediction(conf_matrix,labelidx):\n    '''\n    计算某一个类标预测精度：该类被预测正确的数除以该类的总数\n    '''\n    label_total_sum = conf_matrix.sum(axis=0)[labelidx]\n    label_correct_sum = conf_matrix[labelidx][labelidx]\n    prediction = 0\n    if label_total_sum != 0:\n        prediction = round(100*float(label_correct_sum)/float(label_total_sum),2)\n    return prediction\n \ndef calculate_label_recall(conf_matrix,labelidx):\n    '''\n    计算某一个类标的召回率：\n    '''\n    label_total_sum = conf_matrix.sum(axis=1)[labelidx]\n    label_correct_sum = conf_matrix[labelidx][labelidx]\n    recall = 0\n    if label_total_sum != 0:\n        recall = round(100*float(label_correct_sum)/float(label_total_sum),2)\n    return recall\n \ndef calculate_f1(prediction,recall):\n    if (prediction+recall)==0:\n        return 0\n    return round(2*prediction*recall/(prediction+recall),2)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-09T03:20:26.334718Z","iopub.execute_input":"2021-06-09T03:20:26.335133Z","iopub.status.idle":"2021-06-09T03:20:26.350251Z","shell.execute_reply.started":"2021-06-09T03:20:26.335092Z","shell.execute_reply":"2021-06-09T03:20:26.349365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n# path='./vgg16/vgg16_0.pth'\n# model=torch.load(path)\n# model=model_all[0]\n# model=model.to(device)\n\nmodel=models.vgg16(pretrained=True)\n# 将所有参数都设置为不计算梯度\nfor param in model.parameters():\n    param.requires_grad=False\nnum_ftrs=model.classifier[6].in_features # feature_map 的大小\nmodel.classifier[6]=nn.Linear(num_ftrs,num_classes) #重新设计全连接层\nmodel=model.to(device)\n\ncriterion=nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr=0.0001,betas=(0.9, 0.999)) #优化函数","metadata":{"execution":{"iopub.status.busy":"2021-06-09T03:21:16.245237Z","iopub.execute_input":"2021-06-09T03:21:16.245577Z","iopub.status.idle":"2021-06-09T03:21:17.654669Z","shell.execute_reply.started":"2021-06-09T03:21:16.245542Z","shell.execute_reply":"2021-06-09T03:21:17.652551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model,epoch,num_epochs,criterion,optimizer):\n  model.train()\n  print('-' * 100)\n  print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n  running_loss = 0.0\n  running_corrects = 0\n  for idx, (inputs, labels) in enumerate(dataloaders['train']):# 对dataloader进行遍历，dataloader时包含数据及标签的元组\n    inputs,labels=inputs.to(device),labels.to(device)\n    outputs = model(inputs) # output接受结果\n    _, preds = torch.max(outputs, 1)\n    loss = criterion(outputs, labels)  # 默认平均，计算损失值\n\n    #反向传播及更新\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    if idx % 10 == 0:\n        print('train iteration:{},loss:{},acc:{}%'.format( idx, loss.item(),torch.sum(preds == labels.data)/batch_size*100))\n    running_loss += loss.item() * inputs.size(0)\n    running_corrects += torch.sum(preds == labels.data)\n\n  epoch_loss = running_loss / dataset_sizes['train']\n  epoch_acc = running_corrects.double() / dataset_sizes['train']\n  print('train_total Loss: {:.4f} Acc: {:.4f}%'.format( epoch_loss, epoch_acc*100))","metadata":{"execution":{"iopub.status.busy":"2021-06-09T03:20:51.53859Z","iopub.execute_input":"2021-06-09T03:20:51.538912Z","iopub.status.idle":"2021-06-09T03:20:51.547735Z","shell.execute_reply.started":"2021-06-09T03:20:51.53888Z","shell.execute_reply":"2021-06-09T03:20:51.546547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(model,epoch,num_epochs,criterion,optimizer,best_acc):\n  model.eval()\n  running_loss = 0.0\n  running_corrects = 0\n  best_acc=best_acc\n  best_model_wts=copy.deepcopy(model.state_dict())\n  conf_matrix = torch.zeros(num_classes, num_classes) # 混淆矩阵初始化\n  with torch.no_grad():\n    for idx, (inputs, labels) in enumerate(dataloaders['val']):\n      inputs, labels = inputs.to(device), labels.to(device)\n      outputs = model(inputs)\n      _, preds = torch.max(outputs, 1)\n      loss = criterion(outputs, labels)\n      conf_matrix = confusion_matrix(outputs, labels, conf_matrix) # 生成混淆矩阵\n\n      running_loss += loss.item() * inputs.size(0)\n      running_corrects += torch.sum(preds == labels.data)\n\n    plot_confusion_matrix(conf_matrix, classes=class_names, normalize=False, title='Normalized confusion matrix') # 混淆矩阵的可视化\n    \n  epoch_loss = running_loss / dataset_sizes['test'] \n  epoch_acc = running_corrects.double() / dataset_sizes['test']\n  print('test_total Loss: {:.4f} Acc: {:.4f}%'.format( epoch_loss, epoch_acc*100))\n\n  all_prediction = calculate_all_prediction(conf_matrix) # 总精度=准确率\n  print('all_prediction:{}'.format(all_prediction))\n  label_prediction = [] # 存放每个类的精确率\n  label_recall = [] # 存放每个类的召回率\n  for i in range(num_classes):\n    label_prediction.append(calculate_label_prediction(conf_matrix,i))\n    label_recall.append(calculate_label_recall(conf_matrix,i))\n\n  keys=class_names\n  values=list(range(num_classes))\n  dictionary = dict(zip(keys, values))\n  for ei,i in enumerate(dictionary):\n    print(ei,'\\t',i,'\\t','prediction=',label_prediction[ei],'%,\\trecall=',label_recall[ei],'%,\\tf1=',calculate_f1(label_prediction[ei],label_recall[ei])) # 输出每个类的，精确率，召回率，F1\n  p = round(np.array(label_prediction).sum()/len(label_prediction),2) # 总精确率\n  r = round(np.array(label_recall).sum()/len(label_prediction),2) # 总召回率\n  print('MACRO-averaged:\\nprediction=',p,'%,recall=',r,'%,f1=',calculate_f1(p,r)) #输出总精确率和召回率\n\n  if epoch_acc > best_acc:# 获取最好的模型和准确率\n    best_acc=epoch_acc\n    best_model_wts=copy.deepcopy(model.state_dict())\n  model.load_state_dict(best_model_wts)\n\n  return best_model_wts,best_acc,epoch_acc","metadata":{"execution":{"iopub.status.busy":"2021-06-09T03:20:53.6137Z","iopub.execute_input":"2021-06-09T03:20:53.614032Z","iopub.status.idle":"2021-06-09T03:20:53.628251Z","shell.execute_reply.started":"2021-06-09T03:20:53.613999Z","shell.execute_reply":"2021-06-09T03:20:53.627202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n  # best_model_wts = copy.deepcopy(model.state_dict())\n  best_acc = 0.0\n  acc=[]\n  for epoch in range(num_epochs):\n    train(model,epoch,num_epochs,criterion,optimizer)\n    best_model_wts,best_acc,epoch_acc=test(model,epoch,num_epochs,criterion,optimizer,best_acc)\n    acc.append(epoch_acc)\n  print(best_acc)\n  # torch.save(best_model_wts, 'covid_net_model_best_acc.pt')","metadata":{"execution":{"iopub.status.busy":"2021-06-09T03:20:54.283865Z","iopub.execute_input":"2021-06-09T03:20:54.284167Z","iopub.status.idle":"2021-06-09T03:20:59.169797Z","shell.execute_reply.started":"2021-06-09T03:20:54.284136Z","shell.execute_reply":"2021-06-09T03:20:59.167429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections.abc import Iterable\n\ndef set_freeze_by_idxs(model, idxs, freeze=True): #默认freeze=True是冻结层\n    if not isinstance(idxs, Iterable):\n        idxs = [idxs]\n    num_child = len(list(model.children()))\n    idxs = tuple(map(lambda idx: num_child + idx if idx < 0 else idx, idxs))\n    for idx, child in enumerate(model.children()):\n        if idx not in idxs:\n            continue\n        for param in child.parameters():\n            param.requires_grad = not freeze\n    return model\n            \ndef freeze_by_idxs(model, idxs):\n    return set_freeze_by_idxs(model, idxs, True)\n\ndef unfreeze_by_idxs(model, idxs):\n    return set_freeze_by_idxs(model, idxs, False)\ndef set_parameter_requires_grad(model):#冻结特征提取层\n    for param in model.parameters():\n        param.requires_grad=False\n    return model\n\ndef initialize_model(model_name,num_classes,use_pretrained,unfreeze_num):\n    if model_name=='vgg16':\n        model_pre=models.vgg16(pretrained=use_pretrained) # True：torchversion 已经预训练好的模型，False：随机初始化的模型\n#         for i in model_pre.named_children():\n#             print(i)\n        model_pre=set_parameter_requires_grad(model_pre) # 冻结全部层\n        num_ftrs=model_pre.classifier[6].in_features # feature_map 的大小\n        model_pre.classifier[6]=nn.Linear(num_ftrs,num_classes) #重新设计全连接层\n        if unfreeze_num==1:\n            unfreeze=[-1]\n        elif unfreeze_num==2:\n            unfreeze=[-1,-3]\n        elif unfreeze_num==3:\n            unfreeze=[-1,-3,-5]\n        else:\n            unfreeze=[-1,-3,-5,-7]\n        model_pre.features=unfreeze_by_idxs(model_pre.features,unfreeze)\n        for param in model_pre.classifier.parameters():\n            param.requires_grad=True\n        input_size=224\n    elif model_name=='vgg19':\n        model_pre=models.vgg19(pretrained=use_pretrained) # True：torchversion 已经预训练好的模型，False：随机初始化的模型\n\n        model_pre=set_parameter_requires_grad(model_pre) # 冻结全部层\n        num_ftrs=model_pre.classifier[6].in_features # feature_map 的大小\n        model_pre.classifier[6]=nn.Linear(num_ftrs,num_classes) #重新设计全连接层\n        if unfreeze_num==1:\n            unfreeze=[-1]\n        elif unfreeze_num==2:\n            unfreeze=[-1,-3]\n        elif unfreeze_num==3:\n            unfreeze=[-1,-3,-5]\n        else:\n            unfreeze=[-1,-3,-5,-7]\n        model_pre.features=unfreeze_by_idxs(model_pre.features,unfreeze)\n        for param in model_pre.classifier.parameters():\n            param.requires_grad=True\n        input_size=224\n    elif model_name=='resnet101':\n        model_pre=models.resnet101(pretrained=use_pretrained) # True：torchversion 已经预训练好的模型，False：随机初始化的模型\n        \n        model_pre=set_parameter_requires_grad(model_pre)\n        num_ftrs=model_pre.fc.in_features # feature_map 的大小\n        model_pre.fc=nn.Linear(num_ftrs,num_classes)\n        \n        for i in range(unfreeze_num):\n            model_pre.layer4=unfreeze_by_idxs(model_pre.layer4,-i)\n        for param in model_pre.fc.parameters():\n            param.requires_grad=True\n        input_size=224\n    elif model_name=='resnet152':\n        model_pre=models.resnet152(pretrained=use_pretrained) #True：torchversion 已经预训练好的模型，False：随机初始化的模型\n        \n        model_pre=set_parameter_requires_grad(model_pre)\n        num_ftrs=model_pre.fc.in_features #feature_map 的大小\n        model_pre.fc=nn.Linear(num_ftrs,num_classes)\n\n        for i in range(unfreeze_num):\n            model_pre.layer4=unfreeze_by_idxs(model_pre.layer4,-i)\n        for param in model_pre.fc.parameters():\n            param.requires_grad=True\n        input_size=224\n    elif model_name=='densenet161':\n        model_pre=models.densenet161(pretrained=use_pretrained) #True：torchversion 已经预训练好的模型，False：随机初始化的模型\n        \n        model_pre=set_parameter_requires_grad(model_pre)\n        num_ftrs=model_pre.classifier.in_features #feature_map 的大小\n        model_pre.classifier=nn.Linear(num_ftrs,num_classes)\n        \n        for i in range(unfreeze_num):\n            model_pre.features.denseblock4=unfreeze_by_idxs(model_pre.features.denseblock4,-i)\n        for param in model_pre.classifier.parameters():\n            param.requires_grad=True\n        input_size=224\n    elif model_name=='densenet201':\n        model_pre=models.densenet201(pretrained=use_pretrained) #True：torchversion 已经预训练好的模型，False：随机初始化的模型\n        \n        model_pre=set_parameter_requires_grad(model_pre)\n        num_ftrs=model_pre.classifier.in_features #feature_map 的大小\n        model_pre.classifier=nn.Linear(num_ftrs,num_classes)\n        \n        for i in range(unfreeze_num):\n            model_pre.features.denseblock4=unfreeze_by_idxs(model_pre.features.denseblock4,-i)\n        for param in model_pre.classifier.parameters():\n            param.requires_grad=True\n        input_size=224\n    else:\n        print('model not implemented')\n        return None,None\n    return model_pre,input_size","metadata":{"execution":{"iopub.status.busy":"2021-06-09T03:19:33.840806Z","iopub.execute_input":"2021-06-09T03:19:33.841129Z","iopub.status.idle":"2021-06-09T03:19:33.862047Z","shell.execute_reply.started":"2021-06-09T03:19:33.8411Z","shell.execute_reply":"2021-06-09T03:19:33.861265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\nmodel_all=[]\ndir='.'\ndef auto_net(model_name,num_classes,use_pretrained,unfreeze_num):\n    \n    for k in range(unfreeze_num):\n        model,input_size=initialize_model(model_name,num_classes,use_pretrained,k+1)\n        my_path=Path(dir+'/{}'.format(model_name))\n        if not my_path.is_dir():    # 若指定的目录不存在，创建文件夹\n            os.mkdir(my_path)\n        torch.save(model,dir+'/{}/{}_{}.pth'.format(model_name,model_name,k)) # 0 1 2 3\n            \n        model_all.append(model)\n#         print('------------------------删除{}层,添加{}层,倒数{}层求梯度------------------------'.format(i+1,j+1,k+1))\n#         for m in model.named_children():\n#             print(m)\n#         print('----------------')\n#         for n in model.named_parameters():\n#             print(n)\n    return model_all\nmodel_name=['vgg16','vgg19','resnet101','resnet152','densenet161','densenet201'] # 'inception_v3','resnext101'\n# for name in model_name:\n#     model_all=auto_net(name,num_classes=2,use_pretrained=True,unfreeze_num=4)\nmodel_all=auto_net(model_name[0],num_classes=2,use_pretrained=True,unfreeze_num=4)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T03:19:35.351676Z","iopub.execute_input":"2021-06-09T03:19:35.352005Z","iopub.status.idle":"2021-06-09T03:19:49.007134Z","shell.execute_reply.started":"2021-06-09T03:19:35.351969Z","shell.execute_reply":"2021-06-09T03:19:49.006284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}