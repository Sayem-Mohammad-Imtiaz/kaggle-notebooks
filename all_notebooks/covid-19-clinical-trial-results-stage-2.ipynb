{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Summary\nThis notebook is an entry in the COVID-19 Open Research Dataset Challenge task: What do we know about vaccines and therapeutics?\n\nAbout 50 therapeutics have been identified in the literature. Numberous trials and studies are reported. Methodologies are not standard and sample sizes are small. Evidence is contradictory and with the danger of both false positives and false negative ever present. An analysis is presented [here](#therapeuics) and details of some interesting papers can be found [here](#therapypapers) including the study level and number of patients involved where applicable.\n\nVaccine development is at a much earlier stage of development. Papers have been identified which propose [candidates](#11).\n\nIn addition there were 11 questions associated with this task. Links to relevant papers can be found [here](#questions).\n\nIf you found this notebook useful please give it a vote or better still please leave a comment at the [end of the notebook](#vote). Any comments would be much appreciated but ideas on improvement would be great.\n\n## Therapeutics<a id='therapeuics'></a>\n\nThe WHO has initiated a large trial that should provide welcome certainty about the efficacy of four therapies: Remdesivir, Chloroquine/Hydroxychloroquine, Lopinavir/Ritonavir and Lopinavir/Ritonavir and interferon-beta.\n\nIn this analysis, evidence has been found that the following therapies also merit further investigation:\n\n* baricitinib\n* danoprevir\n* dipyridamole\n* Hydroxycytidine\n* indomethacin\n* interferon\n* ivermectin\n* LMW Heparin\n* mefloquine hydrochloride\n* meplazumab\n* methylprednisolone\n* Nitric Oxide\n* prazosin\n* saquinavir\n* selamectin\n* Stem Cell therapy\n* tocilizumab\n\n\nIn some cases the evidence is flimsy and may well be the result of a false positive.\n\nIn addition, theoretical studies have shown that the following could be effective. As a first step they should be tested for effectiveness against the virus in vitro:\n\n* acetazolamide\n* alafenamide\n* alovudine\n* amantadine\n* atazanavir\n* dactinomycin\n* deoxythymidine\n* dolutegravir\n* emodin\n* emtricitabine\n* enofovir alafenamide\n* ledipasvir\n* mercaptopurine\n* metronidazole\n* nelfinavir\n* nifedipine\n* saquinavir\n* sirolimus\n* Sofosbuvir\n* teicoplanin\n* tenofovir\n* theaflavin\n* tilorone\n* velpatasvir\n\n\n\n\nOver 50 therapeutics have been identified in the search on the 10th April literature set :\n\n[['chloroquine', 123], ['lopinavir', 75], ['ritonavir', 70], ['remdesivir', 59], ['hydroxychloroquine', 54], ['steroid', 52], ['interferon', 35], ['arbidol', 22], ['ribavirin', 18], ['favipiravir', 15], ['sofosbuvir', 14], ['azithromycin', 14], ['methylprednisolone', 14], ['stem cell', 13], ['darunavir', 11], ['heparin', 10], ['meplazumab', 10], ['lopinavir–ritonavir', 9], ['theaflavin', 9], ['tocilizumab', 9], ['danoprevir', 7], ['teicoplanin', 7], ['cas13', 7], ['tenofovir', 6], ['amantadine', 6], ['velpatasvir', 6], ['nelfinavir', 6], ['sirolimus', 5], ['alovudine', 5], ['ledipasvir', 4], ['moxifloxacin', 4], ['deoxythymidine', 4], ['nitric oxide', 4], ['mercaptopurine', 4], ['umifenovir', 3], ['prazosin', 3], ['acetazolamide', 3], ['heparan', 3], ['atazanavir', 3], ['tilorone', 3], ['metronidazole', 3], ['hydroxycytidine', 3], ['indomethacin', 3], ['emetine', 3], ['emtricitabine', 2], ['dactinomycin', 2], ['selamectin', 2], ['saquinavir', 2], ['alafenamide', 2], ['ganciclovir', 2], ['baricitinib', 2], ['emodin', 2], ['nifedipine', 2], ['siltuximab', 2], ['tenofovir alafenamide', 2], ['dipyridamole', 2], ['linezolid', 2], ['ivermectin', 2], ['mefloquine hydrochloride', 2], ['mycophenolate', 2], ['dolutegravir', 2]]\n\n\nClick [here](#therapies) to find details of the 400+ papers that mention these therapies.\n\nClinical trials or reports on these therapies are mentioned in over 200 papers \nlisted [here](#therapytrials).\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Theraputics Data Analysis\n\nThe following summary of therapy effectiveness has been produced by inspection of the highlighted literature. \n\n### WHO Trial\n\nThe World Health Organisation has  [launched](https://www.sciencemag.org/news/2020/03/who-launches-global-megatrial-four-most-promising-coronavirus-treatments) a global megatrial of the four most promising coronavirus treatments:\n\n#### Remdesivir\n\nRemdesivir [inhibits](https://www.sciencedirect.com/science/article/pii/S016635422030200X) the replication of SARS-CoV-2 in vitro which is a good start. [Animal trials](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7104368/) have also been successful. [This Paper](https://www.sciencedirect.com/science/article/pii/S1477893920301162?via%3Dihub) discusses the use of the drug on the 1st American patient as well as the mechanism by which the drug could be effective. Clinical trials are underway and currently  there is no reliable evidence of the efficacy of the drug.\n\nSynergy between remdesivir and emetine was observed [here](https://www.sciencedirect.com/science/article/pii/S016635422030200X)\n\n#### Chloroquine and hydroxychloroquine\n\nThese therapies are mentioned extensively in the literature. Most trials show beneficial outcomes however the sample sizes are small and there are references that question the value of the therapy.\n\nFor instance [this trial](https://doi.org/10.1016/j.ijantimicag.2020.105949) concluded:\n\n'Despite its small sample size our survey shows that hydroxychloroquine treatment is significantly associated with viral load reduction/disappearance in COVID-19 patients and its effect is reinforced by azithromycin.'\n\nHowever further analysis [here](https://doi.org/10.1101/2020.03.31.20048777) and [here](https://doi.org/10.1101/2020.03.22.20040949) quesitoned the conclusion although a mixure of HCQ and azithromycin showed promise.\n\n#### Lopinavir/Ritonavir\n\nLopinavir [inhibits](https://www.sciencedirect.com/science/article/pii/S016635422030200X)  the replication of SARS-CoV-2 in vitro but Ritonavir does not.\n\nThe combination has been used extensively in China. Trial results [indicate no benefit]( \thttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC7121492/) and adverse reactions are reported. Some trials advocate a combination of Lopinavir/ritonavir with [arbidol](https://doi.org/10.1016/j.jinf.2020.03.002) <a id='LRA'></a>but others indicate [no benefit](https://doi.org/10.1101/2020.03.19.20038984).\n\n#### Lopinavir/Ritonavir and interferon-beta\n\n\n[This trial](https://doi.org/10.1016/j.eng.2020.03.007) of 80 patients compared Favipiravir (35 patients) with Lopinavir/Ritonavir(45 patients). Some of each group were also treated with alpha interferon. Favipiravir showed significantly better treatment effects.\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"\n### Other Options\n\nThis is where I can do more work to identify any new or useful unpopular therapies. What about stem cell therapy for instance.\n\n#### Stem Cell therapy\n\nTwo interesting trails have been reported:\n\n[One trail](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7069465/) of seven patients found: \"the intravenous transplantation of  Mesenchymal stem cells (MSCs) was safe and effective for treatment in patients with COVID-19 pneumonia, especially for the patients in critically severe condition.\"\n\n[In another trial](https://doi.org/10.1016/j.eng.2020.02.006) of 61 patients with H7N9-induced ARDS, 17 patients acted as an experimental group with MSCs. Mortality rate was significatnyl reduced in the experimental group and it was concluded that MSC-based therapy could be a possible alternative for treating COVID-19.\n\n\n#### Interferon\n\n[Abstract Type 1 interferons have a broad antiviral activity in vitro](https://doi.org/10.1016/j.antiviral.2020.104791).\n\n[This paper](https://doi.org/10.1016/s1473-3099(20)30198-5) details the use of Interferon alpha with 36 children infected with severe acute respiratory syndrome coronavirus 2. All recovered.\n\n\n\n#### Umifenovir/Arbidol/Abidol\n\n[Umifenovir (brand name Arbidol)](https://en.wikipedia.org/wiki/Umifenovir) is an antiviral treatment for influenza infection used in Russia and China.\n\nCross ref [here](#LRA) and [here](#Favi)\n\n\n#### Ribavirin\n\nRibavirin showed  [no apparent anti-viral effect](https://www.sciencedirect.com/science/article/pii/S016635422030200X)  against SARS-CoV-2 in vitro \n\n#### Favipiravir\n\nFavipiravir showed  [no apparent anti-viral effect](https://www.sciencedirect.com/science/article/pii/S016635422030200X)  against SARS-CoV-2 in vitro. However a [trial including 240 patients](https://doi.org/10.1101/2020.03.17.20037432) showed that Favipiravir was more significantly more effective than Arbidol<a id='Favi'></a>. Also Favipiravir was more effective than Lopinavir/Ritonavir [is this trial](https://doi.org/10.1016/j.eng.2020.03.007)\n\n\n#### Azithromycin\n\n[Azithromycine presents antiviral potency](https://doi.org/10.1101/2020.04.03.023846)\n\n\nAzithromycin is often used along with Chloroquine and hydroxychloroquine.\n\n\n#### Darunavir\n\nDarunavir [showed no activity](https://doi.org/10.1101/2020.04.03.20052548) against SARS-CoV-2 at clinically relevant concentrations (EC50 >100 μM). Remdesivir, used as a positive control, showed potent antiviral activity (EC50 = 0.38 μM).\n\n#### Heparin\n\nIn a trial of 42 patients (21 in control), [low molecular weight heparin (LMWH)](https://doi.org/10.1101/2020.03.28.20046144) was found to be beneficial.\n\n#### Meplazumab\n\nCompared to control group  [meplazumab treatment significantly](https://doi.org/10.1101/2020.03.21.20040691) improved the discharged (p=0.006) and case severity (p=0.021) in critical and severe patients for a group of 17 patients.\n\nMeplazumab [inhibits](https://doi.org/10.1101/2020.03.14.988345)  SARS-CoV-2 from invading host cells in vitro\n\n#### Tilorone\n\nTilorone: a Broad-Spectrum [Antiviral](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7100484/) Invented in the USA and Commercialized in Russia and beyond\n\n#### Methlyprednisolone\n\nOne trail of [26 patients](https://doi.org/10.1101/2020.03.06.20032342)  shows beneficial response with a dosage of 1-2mg/kg/d whereas another with 72 patients shows no benefit(dosage 0.75-1.5mg/kg/d). There was a difference in dosage though with the beneficial trail administrating a higher dosage.\n\nIn another [retrospective study](https://doi.org/10.1001/jamainternmed.2020.0994) it was found that among patients with ARDS, treatment with methylprednisolone decreased the risk of death. This quesitoned [here](https://www.journalofinfection.com/article/S0163-4453(20)30113-4/pdf).\n\n#### Nitric Oxide\n\nNitric Oxide [therapy in adult ICUs](https://www.ncbi.nlm.nih.gov/pubmed/9470075) is used in the UK. [Trials are underway in China](https://clinicaltrials.gov/ct2/show/record/NCT04290871) to determine whether the perceived anti-viral effect of the gas is effective against Covid at higher concentrations. Also reported [here](https://doi.org/10.1101/2020.03.09.20033530).\n\n#### Tocilizumab \n\n\n[A single non-randomized, single-arm study](https://doi.org/10.1101/2020.03.30.20048058) assessed tocilizumab in patients with severe COVID-19, demonstrating decreased oxygen requirements, resolution of radiographic abnormalities, and clinical improvement\n\n#### Danoprevir\n\nAfter 4 to 12-day treatment of [Danoprevir](https://doi.org/10.1101/2020.03.22.20034041) boosted by Ritonavir, all eleven patients enrolled were discharged from the hospital. \n\n#### Moxifloxacin\n\nMoxifloxacin is an anti-biotic.\n\n#### Indomethacin\n\n[In canine coronavirus-infected dogs](https://doi.org/10.1101/2020.04.01.017624), recovery occurred significantly sooner with symptomatic treatment + oral indomethacin (1 mg/kg body weight) daily treatments than with symptomatic treatment + ribavirin (10-15 mg/kg body weight) daily treatments (P =0.0031), but was not significantly different from that with symptomatic treatment + anti-canine coronavirus serum + canine hemoglobin + canine blood immunoglobulin + interferon treatments (P =0.7784).\n\n#### Hydroxycytidine\n\nIn mice infected with SARS-CoV or MERS-CoV, [both prophylactic and therapeutic administration](https://doi.org/10.1101/2020.03.19.997890) of EIDD-2801, an orally bioavailable NHC-prodrug (b-D-N4-hydroxycytidine-5‚Äô-isopropyl ester), improved pulmonary function, and reduced virus titer and body weight loss. \n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Specific Questions<a id='questions'></a>\n\nThe organisers want to know what the literature reports about the following topics. Click on the topic to go a list of relevant literature. The text for the questions can be found in the following code cell:\n\n* [Question 1](#0)\n* [Question 2](#1)\n* [Question 3](#2)\n* [Question 4](#3)\n* [Question 5](#4)\n* [Question 6](#5)\n* [Question 7](#6)\n* [Question 8](#7)\n* [Question 9](#8)\n* [Question 10](#9)\n* [Question 11](#10)\n\nFor some of the questions, the papers retrieved do not appear to be relevant. This likely indicates that the question is not yet covered by the literature. A threshold of similarity is available to be introduced if thought necessary.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n#The following organiser questions have been modified and extended to improve the search\n\n# df_queries = pd.DataFrame({'question': [\\\n# 'Effectiveness of drugs being developed and tried to treat COVID-19 patients',\\\n# 'Clinical and bench trials to investigate less common viral inhibitors against COVID-19 such as naproxen, clarithromycin, and minocycline that that may exert effects on viral replication',\\\n# 'Methods evaluating potential complication of Antibody-Dependent Enhancement (ADE) in vaccine recipients',\\\n# 'Exploration of use of best animal models and their predictive value for a human vaccine',\\\n# 'Capabilities to discover a therapeutic (not vaccine) for the disease, and clinical effectiveness studies to discover therapeutics, to include antiviral agents',\\\n# 'Alternative models to aid decision makers in determining how to prioritize and distribute scarce, newly proven therapeutics as production ramps up. This could include identifying approaches for expanding production capacity to ensure equitable and timely distribution to populations in need',\\\n# 'Efforts targeted at developing options for a universal coronavirus vaccine',\\\n# 'Efforts to develop animal models and standardize challenge studies',\\\n# 'Efforts to develop prophylaxis clinical studies and prioritize in healthcare workers',\\\n# 'Approaches to evaluate risk for enhanced disease after vaccination',\\\n# 'Assays to evaluate vaccine immune response and process development for vaccines, alongside suitable animal models [in conjunction with therapeutics]',\\\n# 'Developing candidates for a vaccine',\\\n# 'Clinical trials with patients and controlled groups'\n\n# ]})\n#This is an updated list aimed at responding to the round 2 challenge\n\ndf_queries = pd.DataFrame({'question': [\\\n'Effectiveness of drugs being developed and tried to treat COVID-19 patients',\\\n'Clinical and bench trials to investigate less common viral inhibitors against COVID-19',\\\n'Capabilities to discover a therapeutic for the disease, and clinical effectiveness studies to discover therapeutics, to include antiviral agents',\\\n'Efforts to develop prophylaxis clinical studies and prioritize in healthcare workers',\\\n'Clinical trials with patients and controlled groups',\\\n'Capabilities to discover interventions for the disease, and clinical effectiveness studies to discover interventions',\\\n'What is the best method to combat the hypercoagulable state seen in COVID-19',\\\n'Results and conclusions of clinical trials with patients and controlled groups',\\\n'Clinical trials with patients and controlled groups',\\\n'Clinical trials with patients and controlled groups',\\\n'Clinical trials with patients and controlled groups',\\\n'Clinical trials with patients and controlled groups',\\\n'Clinical trials with patients and controlled groups'\\\n\n\n]})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Finding Relevant Papers \n\nI started by trying the methods that were successful in my entry(https://www.kaggle.com/rdhnw1/triage-recommender-with-cold-start) into last year's Kaggle CareerVillage competion. The method consisted of answering career related questions by comparing a new question with previously asked questions.\n\nA number of methods were tried including tfidf, word2vec, Fasttext, Global Vectors and the Universal Sentence encoder (USE).\n\nFasttext and USE seemed to produce the best performance. However for this challenge only USE has produced useful results. I think that this is because the other methods rely on a simple averaging technique to move from word to sentence embedding. This works well when the phrases being compared are similar in length but fails in this challenge where there is a huge mismatch between the length of the query and the literature. USE copes much better.\n\n\"Google’s Universal Sentence Encoder encodes text into high dimensional vectors. The model is trained and optimized for greater-than-word length text, such as sentences, phrases or short paragraphs.\n\nThe input is variable length English text and the output is a 512 dimensional vector.\"\n\nMore details can be found here: https://tfhub.dev/google/universal-sentence-encoder/2\n\nI found this blog useful: https://medium.com/@gaurav5430/universal-sentence-encoding-7d440fd3c7c7\n\nThe encoder provides a matrix defining the similarity between a set of questions.\n\n### Method Details\n\nHere are the details of the method:\n\n### Preparation\n\nLoad in the data and print out size and compare with a previous set. This alerts us to changes in the data set\n\nRemove duplicates and compare with a previous set. This method does not remove all duplicates but it is good enough\n\nPrepare list of queries on the literature. This is the list of questions set by the organisers. Some fine tuning on the questions can improve the results.\n\nClean Text. The text is moved to lower case and is lemmatized. Stop words are removed but punctation is left\n\nReduce literature set to include those mentioning Covid 19 or its synonyms. This is acheived using the method supplied in covid19-tools provided by Andy White. Thank you!\n\nSplit Abstracts into sentences. The literature source consists of a number of fields for each piece of research. Fields include the title and an summary of the research called an abstract. The title is too general to be useful and trying to compare a query with the abstract also produces confusing results. By comparing at the sentence level, it is possible to find interesting and relevant pieces of research.\n\n## Therapy identification\n\nThree methods are used to identify potential therapies:\n\n* Using Spacy as identified in  medalCORD-19: Explore Drugs Being Developedby Maria and Gtteixeira (https://www.kaggle.com/maria17/cord-19-explore-drugs-being-developed). Thank you. \n* by identifying drugs by their ending as defined in Wikipedia (https://en.wikipedia.org/wiki/Drug_nomenclature).\n* by referring to the FDA's drug directory (https://www.fda.gov/drugs/drug-approvals-and-databases/national-drug-code-directory)\n\n\n\n### Trials\nTwo stages are required:\n\nFirst, for each therapy, identify all papers that mention the therapy\nThen, for each therapy rank the papers in order of similarity to the phrase: \"Clinical trials with patients and controlled groups\"\n\n### Organisers specific questions\n\nA bag of sentences is prepared by combining the queries and the abstract sentences. The USE algorithm is then used to provide a vector for each query and abstract sentence. For each query, the top ten matches with the research literature are found and displayed \n\n\n## Pros and Cons on Therapy Discovery\n\nIdentifying potential therapies by the ending of their name is very quick but does not produce a complete list. The Spacy method can fill some of the gaps but I did identify a few problems. When I set it up to identify word bigrams, it sometimes produced long chains of unrelated words. Perhaps I was doing something wrong, anyway I decided to use the method on a single word basis. Bigrams are handled by exception which is not ideal. For instance stem cell is converted to stem-cell.\n\nEach method contributes to the list of drugs found in the literature. Although the FDA's directory is comprehensive it does not always name drugs in the same way as done in the literature. Also some anti-virals are not currently listed.\n\n","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# df_queries = pd.DataFrame({'question': [\\\n# 'Effectiveness of drugs being developed and tried to treat COVID-19 patients',\\\n# 'Clinical and bench trials to investigate less common viral inhibitors against COVID-19 such as naproxen, clarithromycin, and minocycline that that may exert effects on viral replication',\\\n# 'Methods evaluating potential complication of Antibody-Dependent Enhancement (ADE) in vaccine recipients',\\\n# 'Exploration of use of best animal models and their predictive value for a human vaccine',\\\n# 'Capabilities to discover a therapeutic (not vaccine) for the disease, and clinical effectiveness studies to discover therapeutics, to include antiviral agents',\\\n# 'Alternative models to aid decision makers in determining how to prioritize and distribute scarce, newly proven therapeutics as production ramps up. This could include identifying approaches for expanding production capacity to ensure equitable and timely distribution to populations in need',\\\n# 'Efforts targeted at a universal coronavirus vaccine',\\\n# 'Efforts to develop animal models and standardize challenge studies',\\\n# 'Efforts to develop prophylaxis clinical studies and prioritize in healthcare workers',\\\n# 'Approaches to evaluated risk for enhanced disease after vaccination',\\\n# 'Assays to evaluate vaccine immune response and process development for vaccines, alongside suitable animal models [in conjunction with therapeutics]',\\\n\n# ]})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pdb\nimport os\nimport nltk, string\nfrom nltk.corpus import stopwords \nfrom nltk.stem import WordNetLemmatizer\n\nimport covid19_tools as cvt\n\nfrom sklearn.feature_extraction.text import CountVectorizer \nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nw_tokenizer = nltk.tokenize.WhitespaceTokenizer()\nlemmatizer = nltk.stem.WordNetLemmatizer()\n\nstop_words = set(stopwords.words('english'))\n\n'''remove punctuation, lowercase, stem'''\nremove_punctuation_map = dict((ord(char), ' ') for char in string.punctuation)    \ndef normalize(text):\n    return nltk.word_tokenize(text.lower().translate(remove_punctuation_map))\n\ndef clean_text(text):\n    text = text.lower().translate(remove_punctuation_map)\n    \n    return ' '.join(lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text))\n\n#From Andy White utility script. Thank you!\n\ndef abstract_title_filter(df, search_string):\n    return (df.Abstract.str.lower().str.replace('-', ' ')\n            .str.contains(search_string, na=False) |\n            df.Title.str.lower().str.replace('-', ' ')\n            .str.contains(search_string, na=False))\n\n\ncovid19_synonyms = ['covid',\n                    'coronavirus disease 19',\n                    'sars cov 2', # Note that search function replaces '-' with ' '\n                    '2019 ncov',\n                    '2019ncov',\n                    r'2019 n cov\\b',\n                    r'2019n cov\\b',\n                    'ncov 2019',\n                    r'\\bn cov 2019',\n                    'coronavirus 2019',\n                    'wuhan pneumonia',\n                    'wuhan virus',\n                    'wuhan coronavirus',\n                    r'coronavirus 2\\b']\n\ndef count_and_tag(df: pd.DataFrame,\n                  synonym_list: list,\n                  tag_suffix: str) -> (pd.DataFrame, pd.Series):\n    counts = {}\n    df[f'tag_{tag_suffix}'] = False\n    for s in synonym_list:\n        synonym_filter = abstract_title_filter(df, s)\n        counts[s] = sum(synonym_filter)\n        df.loc[synonym_filter, f'tag_{tag_suffix}'] = True\n    print(f'Added tag_{tag_suffix} to DataFrame')\n    return df, pd.Series(counts)\n#ends\n\ndf=pd.read_csv('/kaggle/input/CORD-19-research-challenge/metadata.csv')\nprint ('Size of literature Set on 10th April 51078,18')\nprint ('Size of literature Set', df.shape)\n ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf = df.sort_values(by='publish_time',ascending=True)\n#to include only the most recent papers\ndf = df.loc[df['publish_time'] > '2020']\ndf.shape\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Interesting Therapeutic Papers<a id='therapypapers'></a>","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# %%HTML\n# <style type=\"text/css\">\n# table.dataframe td, table.dataframe th {\n#     border: 1px  black solid !important;\n#   color: black !important;\n# }\n# </style>\n\ndf_return=pd.read_csv('/kaggle/input/handedit/therapiesbytrails15sorted.csv')\ndf_return = df_return.rename(columns={'______________Abstract________________':'____________________________Abstract______________________________'})\ndfStyler = df_return.style.set_properties(**{'text-align': 'left',\"font-size\": \"120%\",\"border\": \"1px  black solid\",})\ndfStyler.set_table_styles([dict(selector='th', props=[(\"font-size\", \"150%\"),('text-align', 'center')])])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import pandas as pd\n\n# df = pd.DataFrame([{'a': 'text1', 'b': 15, 'c': 5}, {'a':'text2', 'b': 10, 'c': 7}, {'a':'text', 'b': 30, 'c': 9}])\n\n# df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df['end'] = 'end'\n# df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dftest['text2'] = dftest['text'].apply(lambda texta: [sent for sent in sent_tokenize(text)\n#                                        if any(True for w in word_tokenize(sent) \n#                                                if w.lower() in searched_words)])\n\n# dftest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test code\n# import nltk\n# from nltk.tokenize import sent_tokenize, word_tokenize\n# from nltk.stem import PorterStemmer\n# stemmer = PorterStemmer()\n\n\n# searched_words=['conclusion', 'outcome']\n# df_covid19_t = df[:60]\n\n# #abstract = 'ective To assess the incidence of asymptomatic unruptured renal artery pseudoaneurysm (RAP) on contrast-enhanced computed tomography (CE-CT) after robot-assisted partial nephrectomy (RAPN) without parenchymal renorrhaphy. Methods From May 2016 to December 2017, 78 patients underwent RAPN for renal tumors. Inner suture was performed in the opened collecting system or renal sinus, whereas parenchymal renorrhaphy was not. For hemostasis, the soft coagulation system was used, and absorbable hemostats were placed on the resection bed. CE-CT was carried out within 7 days after surgery. Data on these patients were prospectively collected. A single radiologist determined the diagnosis of RAP. Results Median (range) data were as follows: Patient age, 65 (19-82) years; radiographic tumor size, 30 (12-95) mm; operating time, 166 (102-294) min; warm ischemic time, 16 (7-67) min; and blood loss, 15 (0-4450) mL. One patient (1.6%) required a perioperative blood transfusion. No patient required conversion to open surgery or nephrectomy. CE-CT was carried out at median 6 (3-7) days after surgery. CE-CT showed no RAP development in all 61 patients. Urinary leakage was not observed. One patient had acute cholecystitis, a postoperative complication classified as Clavien-Dindo grade higher than 3, which was treated with cholecystectomy. Positive surgical margin was identified in four patients (6.6%). Conclusion RAPN using soft coagulation and absorbable hemostats without renorrhaphy appears to be feasible and safe. Our technique could eliminate the risk of RAP.'\n\n# df_covid19_t['abstract']=df_covid19_t['abstract'].apply(str)\n# df_covid19_t['Conclusion'] = df_covid19_t['abstract'].apply(lambda texta: [sent for sent in sent_tokenize(texta)\n#                                        if any(True for w in word_tokenize(sent) \n#                                                if w.lower() in searched_words)])\n\n# df_covid19_t['Endpoint'] = 'none'\n\n# #df_covid19_t = df_covid19_t.assign(EndPoint=lambda df_covid19_t: df_covid19_t.abstract +\"test\")\n\n# df_covid19_t = df_covid19_t.assign(EndPoint=lambda df_covid19_t: [sent for sent in sent_tokenize(df_covid19_t.abstract)\n#                                                                     if any(True for w in word_tokenize(sent) \n#                                                                           if stemmer.stem(w.lower()) in searched_words)])\n    \n    \n#     lambda text: [sent for sent in sent_tokenize(text)\n#                            if any(True for w in word_tokenize(sent) \n#                                      if stemmer.stem(w.lower()) in searched_words)])\n\n\n# df_covid19_t['Endpoint']= df_covid19_t['Abstract'].apply(lambda text: [sent for sent in sent_tokenize(text)\n#                            if any(True for w in word_tokenize(sent) \n#                                      if stemmer.stem(w.lower()) in searched_words)])\n\n\n                                  \n                                  \n# dfStyler = df_covid19_t.style.set_properties(**{'text-align': 'left',\"font-size\": \"120%\"})\n# dfStyler.set_table_styles([dict(selector='th', props=[(\"font-size\", \"150%\"),('text-align', 'center')])])\n   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# searched_words=['Conclusion','conclusion']\n\n\n# print(df_covid19_t['abstract'].apply(lambda text: [sent for sent in sent_tokenize(text)\n#                            if any(True for w in word_tokenize(sent) \n#                                      if stemmer.stem(w.lower()) in searched_words)]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df = df.rename(columns={'source_x': 'Source', 'title': 'Title', 'abstract': 'Abstract', 'publish_time': 'Publish_Date', 'authors': 'Authors', 'journal': 'Journal', 'url': 'Ref URL'})\n#drop duplicate abstracts\ndf = df.drop_duplicates(subset='Abstract', keep=\"first\")\n\nprint ('Size of literature Set after removing duplicates on 10th April 41952,18')\nprint ('Size after removing duplicates', df.shape)\n#4/3/20 38667,18","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\nGroup 7 - Therapeutics, Interventions, and Clinical Studies\n\nDate\n\nStudy \n\nStudy Link\n\nJournal \n\nStudy Type\n\nTherapeutic method(s) utilized/assessed \n\nSample Severity of Symptoms \n\nGeneral Outcome/Conclusion Excerpt \n\nPrimary Endpoint(s) of Study\n\nClinical Improvement (Y/N) \n\nAdded on DOI\n\nCORD_UID\n\n# For mapping from David Mezzetti's Study Design metadata\nDESIGNS = [\n    'Other',\n    'Systematic review',\n    'Randomized control trial',\n    'Non-randomized trial',\n    'Prospective observational',\n    'Time-to-event analysis',\n    'Retrospective observational',\n    'Cross-sectional',\n    'Case series',\n    'Modeling'\n]\n    words=['prospective cohort','retrospective cohort', 'systematic review',' meta ','randomized',' search ','case control','case series,','time series','cross-sectional','observational cohort', 'retrospective clinical','virological analysis','prevalence study','literature']\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Clean the text\ndf_queries['query_bow'] = df_queries.question.apply(clean_text)\ndf_queries['query_bow'] = df_queries['query_bow'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n\n#Only include papers that reference covid-19\ndf_a, covid19_counts = count_and_tag(df, covid19_synonyms, 'disease_covid19')\ndf_covid19 = df[df['tag_disease_covid19'] == True ]\ndf_covid19 = df_covid19.reset_index()\ndf_covid19 = df_covid19.drop(['index'], axis=1)\n\n#limit Abstract to 3500 words\ndf_covid19[\"Abstract\"] = df_covid19[\"Abstract\"].str[:3500]\n\n#Split the abstract into sentences\ndf_covid19['org_abstract'] = df_covid19['Abstract']\ndf_covid19_by_sentence = df_covid19.set_index(df_covid19.columns.drop('org_abstract',1).tolist())\\\n.org_abstract.str.split('\\. ', expand=True).stack().reset_index()\\\n.rename(columns={0:'Sent Abstract'})\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_by_sentence = df_covid19_by_sentence.copy()\n#df_covid19_bow_full ['bow_raw'] = df_covid19_bow_full ['title'] + \" \" + df_covid19_bow_full ['abstract']\ndf_by_sentence ['bow_raw'] = df_by_sentence ['Sent Abstract']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_by_sentence['bow'] = df_by_sentence.bow_raw.apply(clean_text)\ndf_by_sentence['bow'] = df_by_sentence['bow'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n#df_by_sentence.head(5)\n\n\n#Only consider sentences > 20 chars\n\ndf_covid19_bow_f = df_by_sentence[df_by_sentence['Abstract'].map(len) > 20]\ndf_covid19_bow = df_covid19_bow_f.reset_index()\n#Subset for testing\n# df_covid19_bow_fs = df_covid19_bow_f.loc[1218:1230].copy()\n# df_covid19_bow = df_covid19_bow_fs.reset_index(\n\n#force search for some compound terms\n#df_covid19_bow.replace({'stem cell': 'stem-cell'}, regex=True)\n#df_covid19_bow.replace({'nitric oxide': 'nitric-oxide'}, regex=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_covid19_bow = df_covid19_bow[['Title','Sent Abstract','Abstract','bow', 'cord_uid', 'Journal', 'Authors','Publish_Date', 'Source', 'Ref URL']]\n\n#produce a bag of words for queries and sentence of papers\ntotal_bow = [\"\".join(x) for x in (df_queries['query_bow'])]\ntotal_bow += [\"\".join(x) for x in (df_covid19_bow['bow'])]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Discover chemicals in the papers ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"#Use the Spacy model\n!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_ner_bc5cdr_md-0.2.4.tar.gz\n\nimport spacy\nimport en_ner_bc5cdr_md\nfrom spacy import displacy\n\nnlp = en_ner_bc5cdr_md.load()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#'full_text_file', 'has_pdf_parse', 'has_pmc_xml_parse', 'WHO #Covidence', 'Microsoft Academic Paper ID'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# abstract split into sentence\ndf_covid19_bow = df_covid19_bow[['Title','Sent Abstract','Abstract','bow', 'cord_uid', 'Journal', 'Authors','Publish_Date', 'Source', 'Ref URL']]\n\n#abstract complete\ndf_covid19['therapies'] = np.nan\ndf_covid19 = df_covid19[['therapies','cord_uid', 'sha', 'Source', 'Title', 'doi', 'pmcid', 'pubmed_id',\n       'license', 'Abstract', 'Publish_Date', 'Authors', 'Journal',\n         'Ref URL', 'tag_disease_covid19','org_abstract']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Previous final version\n# df_covid19['therapies'] = np.nan\n# df_covid19 = df_covid19[['therapies','cord_uid', 'sha', 'Source', 'Title', 'doi', 'pmcid', 'pubmed_id',\n#        'license', 'Abstract', 'Publish_Date', 'Authors', 'Journal',\n#        'Microsoft Academic Paper ID', 'WHO #Covidence', 'has_pdf_parse',\n#        'has_pmc_xml_parse', 'full_text_file', 'Ref URL', 'tag_disease_covid19','org_abstract']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#get a list of strings. each string is an abstract\nabstract_sent_list = [\"\".join(x) for x in (df_covid19_bow['bow'])]\n\n#convert the list of strings to one long string\nabstract_bow_full = ' '.join(abstract_sent_list)\n\n#Scapy cannot handle the full text and so repeats are removed on a single word basis\n#bigram chemicals are missed and so known ones are handled here\n#force search for some compound terms\n# abstract_bow_full = abstract_bow_full.replace('stem cell','stem-cell')\n# abstract_bow_full = abstract_bow_full.replace('nitric oxide','nitric-oxide')\n\n\n\n#split the string into a list of single word strings\nabstract_bow_full_list = abstract_bow_full.split()\n#removes repeats because of the Scapy memory limitation \nabstract_bow = ' '.join(set(abstract_bow_full.split()))\n#abstract_bow = abstract_bow_full","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import re\n\n#Prep before running Spacy Model and search to find therapies\n\n\n#remove any number\nabstract_bow = re.sub(r'\\d+', '',abstract_bow )\n\n#remove single char words\nabstract_bow = re.sub(r'(?:^| ).(?:$| )', ' ', abstract_bow)\n#remove 2 char words\nabstract_bow = re.sub(r'(?:^| )..(?:$| )', ' ', abstract_bow)\n#remove 3 char words\nabstract_bow = re.sub(r'(?:^| )...(?:$| )', ' ', abstract_bow)\n\n#Then produce a list of unique words\n\nabstract_bow_list = abstract_bow.split() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# all_therapies_list = []\n# all_chemicals_str = ''\n\n# for word in abstract_bow_list:\n#     if len(word) > 5 and len(word) <30:\n#         wordspace = ' '+word+' '\n#         doc = nlp(wordspace)\n#         entry = doc.ents\n#         if entry:\n#             if entry[0].label_ == 'CHEMICAL':          \n#                 all_chemicals_str += ' ' + word\n#                 all_therapies_list.append(word)\n#                 if word == 'concentri':\n#                     print ('word, nlp(word)',word, nlp(word).ents)  \n#                     pdb.set_trace()\n   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#abstract_bow_list = abstract_bow.split() \nall_therapies_list = []\nall_chemicals_str = ''\nfor word in abstract_bow_list:\n    if len(word) > 5 and len(word) <30:\n        wordspace = word+' '\n        doc = nlp(wordspace)\n        entry = doc.ents\n        if entry:\n            #print ('word, entry[0].label_',word,entry[0].label_)\n            if entry[0].label_ == 'CHEMICAL':\n                #print ('word, nlp(word)',word, nlp(word).ents)            \n                all_chemicals_str += ' ' + word\n                all_therapies_list.append(word)\n                #pdb.set_trace()\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print (abstract_bow_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print (all_chemicals_str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (len(all_therapies_list))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load and Prep Drug List","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_druglist=pd.read_csv('/kaggle/input/fdadrugs/druglist.csv')\ndf_druglist=pd.read_csv('/kaggle/input/fdasubsubstance/substancename.csv')\ndf_druglist = df_druglist.drop_duplicates(subset='SUBSTANCENAME', keep=\"first\")\ndf_druglist = df_druglist[df_druglist['SUBSTANCENAME'].notna()]\n\n#Split the names: one name per line\ndf_druglist['org_SUBSTANCENAME'] = df_druglist['SUBSTANCENAME']\ndf_druglist = df_druglist.set_index(df_druglist.columns.drop('SUBSTANCENAME',1).tolist())\\\n.SUBSTANCENAME.str.split('\\; ', expand=True).stack().reset_index()\\\n.rename(columns={0:'SUBSTANCENAME'})\ndf_druglist = df_druglist.drop_duplicates(subset='SUBSTANCENAME', keep=\"first\")\n\n#convert to list and go to lower case\ndrug_list = df_druglist['SUBSTANCENAME'].tolist()\ndrug_list = [element.lower() for element in drug_list] ; \n#drug_list = drug_list.tolower()\n#print (drug_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Add drugs from FDA list","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add FDA drug list\n\n\ndrugs_str = ''\n\nfor drug in drug_list:\n    #print (drug)\n    drugspace = ' '+drug+' '\n    if abstract_bow_full.find(drugspace) > -1:\n        #print (drug)\n        if drugs_str == '':\n            drugs_str = drug\n        else:\n            drugs_str = drugs_str + \", \" + drug\n        all_therapies_list.append(drug)\n        \n\n#Add therapies, interventions and issues mentioned in the literature        \nall_therapies_list.append(\"stem cell\")\nall_therapies_list.append(\"interferon\")\nall_therapies_list.append(\"cas13\")\nall_therapies_list.append(\"cepharanthine\")\nall_therapies_list.append(\"selamectin\")\nall_therapies_list.append(\"camostat mesylate\")\nall_therapies_list.append(\"nafamostat mesylate\")\nall_therapies_list.append(\"fusan\")\nall_therapies_list.append(\"hyperbaric oxygen therapy\")\nall_therapies_list.append(\"hypercoagulable\")\nall_therapies_list.append(\"conclusion\")\n\n\n# all_therapies = ','.join(drugs_str)\n# all_therapies_list = drugs_str.split() \n# all_therapies_list = ['interferon', 'remdesivir', 'stem cell', 'nitric oxide']            \n#print(all_therapies_list, drugs_str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Add drugs from Wikipedia list\n#Add drugs mentioned in literature or task\n\ndrugs_str = ''\nfor word in abstract_bow_list:\n    ending = re.findall(r'(?:.*?(\\w{3})\\b)', word)\n    if ((ending == ['vir']) or (ending == ['mab']) or (ending == ['dol'])or (ending == ['axine'])or (ending == ['oxacin'])\\\n        or (ending == ['tinib']) or (ending == ['lisib'])\n        or word.find('interferon') > -1\\\n        or word.find('naproxen') > -1\\\n        or word.find('clarithromycin') > -1\\\n        or word.find('minocycline') > -1\\\n        or word.find('homoharringtonine') > -1):\n            #drugs_str = drugs_str + \" \" + word\n            all_therapies_list.append(word)\n\n# #drugs_unique = ' '.join(set(drugs_str.split()))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\n# #Combine results from two methods\n\n# all_therapies = all_chemicals_str + drugs_str\n# all_therapies = ' '.join(set(all_therapies.split()))\n# all_therapies_list = all_therapies.split() \n# #print (all_therapies_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stopwords = ['air','lead','oxygen','hydrogen','urea',\\\n'diamond', 'creatinine','gold','nitrogen',\\\n'alanine','water',\\\n'creatine','alcohol',\\\n'silicon', 'lactic acid','sodium''phosphorus','egg',\\\n'zinc', 'influenza b virus','hydrogen peroxide',\\\n'hepatitis c virus', 'garlic','glycine',\\\n'thyroid', 'leucine','sodium hypochlorite',\\\n'potassium','squash', 'efavirenz',\\\n'sulbactam sodium','nifedipine,'\\\n'uric acid', 'legionella pneumophila'\\\n'hama','chine','acid','mechan','extract','iran','icacy','guan','isse','ester',\\\n'betacoronavirus', 'hydrogen','methyl', 'provincia','greg','virol', 'urea',\\\n'lombardy','phosphate','pakistan','sarbecovirus', 'hcovs', 'crrt', 'acei',\\\n'hunan', 'ecmo', 'statin','henan', 'daegu', 'biomed','jinyintan','aspartate','hama',\\\n'virus','hopkins','ncovs','tryptanthrin','oseltamivir', 'hpdi','macau','ethanol',\\\n'youtube','fcov','xiao','aedt','enac','philippine', 'york', 'repatriate',\\\n'phosphorus','alcohol','hebei', 'chloride', '‐ncov', 'thiol', 'yokohama', 'paul','stein', \\\n'saharan', 'zinc','indigodole','ncapp','glucose','methanol','phys',\\\n'oxygen','angiotensin','amino','ncip','nucleotide','lactate','tongji',\\\n'separ', 'tianjin','creatinine', 'nitrogen', 'cochrane','qpcr','dpcr','alanine','trypsin','purine','sichuan',\\\n'triphosphate','virus’','ptsd', 'ddpcr','melatonin', 'sodium','emergencia',\\\n'creatine', 'tibetan', 'ciclesonide','sulfate','brote', 'cuidado', 'jama', 'tmax','proline', 'sirolimus,'\n'youan','quench','ccov','chicago', 'sudan','abstractan''espii','ncov”', 'intensivos',\\\n'gompertz', 'iraq', 'berlin','nucleoside', 'virales','taiyuan','quencher','coronavirus’',\\\n'cxcr','cpet','nucleal','brigham', 'niclosamide', 'nettree','冠状病毒（', 'hcov–host',\\\n'covd','pbmcs','gyeongsangbuk','hydrochloride', 'iata', 'belgium', 'scovs', 'gyeongbuk',\\\n'abstractin','abstractan','espii','bscs','mercado','youan','fubar','leucine','bilirubin','mab','tcr',\\\n'hypochlorite','contexte', 'τtrans',\"we’ve\",'dado','cardiovasculaire','particulière',\\\n'mographic','fema','primari','indonesia', 'hepg','infectado','denominada','ganglioside','fatty', 'fetp',\\\n'carbon', 'palo', 'mhla','zeit','qiaamp','tacrolimus','sanitarium', 'begg','contingencia','bolivia','calmette','vitamin','mape','ncov’',\\\n'glycine', 'comorbidités', 'asif','ishr','existencia','dioxide','sanitizer', 'tracker','línea','™','unsaturated',\\\n'silver', 'chlorine', 'cholesterol', 'cobalt', 'formaldehyde', 'escherichia coli',\\\n'morphine','benzalkonium chloride','serine','papain',\\\n'catecholamine','confirmado','metformin','torovirus','minipcr', 'propone','℃','nab','oxide','—','\\u200b','enc','∞',\\\n 'prednisolone','angiotensin ii','nitric', 'ibuprofen','abidol', 'hek',\\\n 'monoxide','formoterol','contiene','carbohydrate',\\\n 'bast','dlco','volatile','instrucciones','isopropyl',\\\n 'ferroprotein','avis', 'oral–fecal',\\\n 'calcium','shankar', 'ccaa', 'lactobacillus','hydroxychloroquine sulfate', 'jingmen','pescado', 'speared',\\\n 'profesionales', 'wikipedia','bioline','tamil','anthony','bifidobacterium',\\\n '−recovered','lebanon','legionella pneumophila','territorio', 'yeast',\\\n 'appetite','simplot','nfκb', 'francisco', 'hower', 'dcps','toremifene', 'liées', 'carol',\\\n 'ziff', 'l’origine', 'urgencia', 'viele', 'adecuadas','spectacle', 'ámbito', 'revu',\\\n 'grossesse','ethylene', 'mayoría', 'colorado','tehran','identificado','τend',\\\n 'aldehyde','engen','spine', 'scct',\\\n 'veroe','huoshenshan', 'uric acid','infectées', 'evag', 'cipomo','soporte', 'leishenshan','ukraine',\\\n 'xiaobo', 'allyl', 'choloroquine','infecciones','hurst', 'equipos',\\\n 'tcga','normokalemia', 'number—the','guerin', 'canadian',\\\n 'podría','penta','新型冠状病毒肺炎（covid', 'horsham',\\\n'≈','chloroquine phosphate','humboldt', 'eyedrop',\\\n'adenosine','adenosyl','thymosin','herramienta','coordenado','benzalkonium','estuvieron','disulfiram',\\\n'digluconate','collectrin','guanosine','provocan','methionine','guanine','garantice','thiazide',\\\n'sospechosos','chlorhexidine','rituximab','cefoperazone','sulbactam','mefloquine','cobicistat',\\\n'tin', 'irat','trat','treatmen', 'char','includi', 'pea','trib','contin', 'ques','inflamm', 'xpress', 'asymp', '1309'\\\n'ether','chloro', 'pregnan','quip','iron','amine','perte','clare','ather','uncer',\\\n'pathol', 'sage', 'fran', 'studie','virtu','mace','elm','maine', 'ipal','toch','merci','taco'\\\n'chas', 'breas', 'trus','huan','itus', 'viol', 'tibio', 'tenu','lora', 'coco',\\\n'sanita', 'xact','covide', 'decontaminat', 'mansfield','thea','proteo', 'gamm', 'nonin',\\\n'foca', 'laryngology','cooper', 'turkey', 'quot','spri', 'hemos','spice','lama', 'haled','quid',\\\n'scad','irvine', 'ilam','biotec', 'disinfectan', 'telle', 'ozone', 'transporte', 'rabbit',\\\n'incrementa', 'progrip', 'dice', 'apple','brescia', 'erythemato', 'louis', 'cas13','nicotine',\\\n'hfabp','eppi', 'ð½ðµ','lamb', '新型冠状病毒（''capitulate', 'kinin','bean', 'accru',\\\n'testosterone','angii', 'frontlines', 'huangshi','ephrology','tambi', 'germicidal', 'sace',\\\n'chicken', 'carbon dioxide', 'silc', 'carmen', 'calu', 'btcov', 'essai', 'cannabis',\\\n'–angiotensin', 'disembark', 'david', 'trevo', 'human milk', 'puesta', 'bata','conjugate',\\\n'paco', 'barré','qiao','parietex™', 'iodine', 'harte','zenker', 'conjugated', 'incheon', 'kegg','briggs',\\\n'ipom', 'imid', 'acetyl','contagios', 'ltcfs', 'crso', 'chla', 'titanium', 'dmts', 'utah','georgia',\\\n'nama', 'nitrous','kurdistan','hads','infodemiology', 'dornase alfa','covids','ð¸ñ…', 'hyde', 'methylene',\\\n'sbrt','urethane','gypsum','glycol', 'utla', 'staphylococcus aureus', 'sanitarios', 'nord',\\\n'orange', 'benefice', 'bis®','devra', 'wisconsin', 'nont', 'zhao','ltch', 'tyrosine',\\\n'sras','cortisone','codogno','seiqrd', 'aaga', 'liquorice', 'scandinavia', 'guérin', '焦虑症状', 'gia™','arabic', 'polyphenol', 'russian','quebec', 'habe', 'ldrt','psychotropes',\\\n'hrsace', 'fast™', 'hepatitis b virus''chws', 'assistdem', 'précautions', 'conoce','mcgrath', \\\n'cuadro', 'microsoft', 'mycoplasma pneumoniae', 'butyrate', 'sitr', 'cvir', 'methadone', 'arksey', 'sprayshield™', \\\n'alteplase','hydrocortisone','langone','aspirin', 'hdrt', 'austrian', 'philadelphia','naproxen', 'doacs','nicht', 'istanbul',\\\n'sysf','chlorogenic', 'saho','assut','prendre', 'yemen', 'ffpe', 'vnrs', 'ceap', 'qfpdt','polyethylene', 'digestifs','ifnl', 'panama', 'escenarios', 'ammonium',\\\n'honey', 'gbind', 'puis', 'hpsc', 'suramin','rhine', 'ccbs', 'según', 'chad', 'sniffin','nagpaul', 'yolo','polysorb', 'mead','connaissances','zahl', 'alovudine',\\\n'médecin', 'bridgepoint', 'dane', 'opium', 'connu', 'considerar', 'zinc sulfate','gelpoint', 'verlauf',\\\n'gps™','chuv', 'mvaova', 'hslam', 'certaines', 'dinucleotides', 'saccharin', 'civid', 'geben', 'phenolic', \\\n'picovacc', 'stella', 'flavonoid'\\\n'folic acid', 'bengal','chup', 'ð°ð¼','multidisciplinario', 'ölüm', 'slnb', 'cscs', 'twinsuk', 'enfin',\\\n'antihistamine', 'biologiques',  'oestrogen','methotrexate', 'sinophobic', 'â\\x80¯±â\\x80¯','sulphate',\\\n'ñ€ðµñ\\x81ð¿ð¸ñ€ð°ñ‚ð¾ñ€ð½ð¾ð³ð¾', 'â\\x80¯ms', 'tropospheric','scfv', 'violencia','qualité','amies',\\\n'tiotropium', 'xpert®','butyl', 'folic','courte','wssci', 'shcs', 'carbonate', 'cardiff',\\\n'caffeic','wifi','hoffmann','ciaad','hospitalarios', 'ionized', 'glucoside', 'hospitalière'\\\n'auteur', 'copper', 'resnetv', 'folgen', 'higgins', 'calhr','amlodipine','jensenone', 'florian',\\\n'cov及', 'poliovirus','paraffin', 'novid', 'dynamesh®', 'dlnms', 'pyruvate', 'sdel', 'qifen',\\\n'cin','ether',\\\n'новой', 'hydroxybutyrate', 'erences', 'chelators', 'klebsiella pneumoniae','tdd‐ncp','trendstm',\\\n'indium', 'propio', 'macaflavanone', 'ppab', 'evicel', 'hypothèse', 'tiantan', 'niran', 'progrip™',\\\n'glucan', 'vodan', 'chiffon', 'kaplan–meier', 'instituciones', 'alveolo', 'atlanta','antidepressant',\\\n'monophosphate', 'mycophenolic', 'hazelwood', 'amcs', 'flavone', 'eswabs', 'autacoid', 'ascorbic acid',\\\n'aichi', 'chemai', 'moroccan', 'grecco','permitan','cuimc', 'benzene', 'supone', 'ambarl', 'desarrolladas',\\\n'effectivene','steroid','nemen', 'taco','chas','immunol', 'nterleukin', 'hejia','к', 'sterol',\\\n'luminal','新型冠状病毒（', 'tcid', 'capitulate','resveratrol',\\\n'biliar','poblaci','tonavir','calcitonin','aldosterone',\\\n'cli', 'tri', 'gly','pandemonium','auteur',\\\n'lithuania', 'swissadme','constituye','preperiod','santiago', 'parsimony','magnesium',\\\n'cirugías', 'diesem', 'rtv–ifn','servir', 'verteporfin', 'inflamatorio', 'hungarian', 'sildenafil', 'prácticas',\\\n'quirúrgicas', 'cell·μl', 'catharina', 'miglustat', 'gargle', 'manhattan','équipes','human‐to‐human'\\\n'condado', 'atovaquone', 'dihydrotestosterone','conformité','stopcovid','lysosomotropic','matthew']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#'esfuerzos','desmopressin', 3], ['palestinian', 3], ['selenite', 3], ['kynurenine', 3], ['human papillomavirus', 3], ['clarithromycin', 3], ['doxorubicin', 3], ['parcours', 3], ['presentaban', 3], ['farnesol', 3], ['l’afero', 3], ['herausforderungen', 3], ['tenofovir alafenamide', 3], ['calmette–guérin', 3], ['ciprofloxacin', 3], ['consecuencia', 3], ['zeigen', 3], ['palestine', 3], ['fièvre', 3], ['glycyrrhizic', 3], ['favilavir', 3], ['clopidogrel', 3], ['pasakoy', 3], ['tetralone', 3], ['fentanyl', 3], ['anestesiología', 3], ['telepsychology', 3], ['resolvins', 3], ['fracaso', 3], ['situaciones', 3], ['digitoxin', 3], ['vapreotide', 3], ['secukinumab', 3], ['unopposed', 3], ['protocole', 3], ['carboxamide', 3], ['uracil', 3], ['natalizumab', 3], ['apixaban', 3], ['chirurgicales', 3], ['persian', 3], ['semaine', 3], ['ipilimumab', 3], ['alamandine', 3], ['meropenem', 3], ['necesarios', 3], ['antimetabolite', 3], ['médecins', 3], ['homocysteine', 3], ['diphosphate', 3], ['rajshahi', 3], ['cuestionario', 3], ['bleomycin', 3], ['covidnlp', 3], ['ledipasvir', 3], ['maastriccht', 3], ['personnelle', 3], ['favorisées', 3], ['clostridium difficile', 3], ['niacin', 3], ['epinephrine', 3], ['nelfinavir mesylate', 3], ['radioiodine', 3], ['beneficios', 3], ['résécables', 3], ['varicelliform', 3], ['civile', 3], ['emodin', 3], ['macrolide', 3], ['valsartan', 3], ['coxcomb', 3], ['fragen', 3], ['covidence™', 3], ['mycophenolic acid', 3], ['biblioteca', 3], ['estaban', 3], ['fondazione', 3], ['synthèse', 3], ['proposons', 3], ['incluyeron', 3], ['huangqin', 3], ['cyclosporine', ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"       \n        \n            \n            \n #'～','youan', 4], ['espii', 4], ['moxifloxacin', 4], ['abstractin', 4], ['deoxythymidine', 4], ['intensivos', 4], ['sudan', 4], ['ncov”', 4], ['quench', 4], ['chicago', 4], ['mercado', 4], ['bscs', 4], ['mercaptopurine', 4], ['alovudine', 4], ['ccov', 4], ['abstractan', 4], ['heparin', 4], ['nucleoside', 3], ['brigham', 3], ['taiyuan', 3], ['fubar', 3], ['contexte', 3], ['leucine', 3], ['scovs', 3], ['hypochlorite', 3], ['tilorone', 3], ['hydroxycytidine', 3], ['cpet', 3], ['quencher', 3], ['belgium', 3], ['冠状病毒（', 3], ['virales', 3], ['iraq', 3], ['cxcr', 3], ['torovirus', 3], ['gyeongsangbuk', 3], ['iata', 3], ['glycine', 3], ['nucleal', 3], ['acetazolamide', 3], ['niclosamide', 3], ['tenofovir', 3], ['nettree', 3], ['gyeongbuk', 3], ['hydrochloride', 3], ['covd', 3], ['heparan', 3], ['pbmcs', 3], ['τtrans', 3], ['nitric', 3], ['coronavirus’', 3], ['ibuprofen', 3], ['berlin', 3], ['hcov–host', 3], ['we’ve', 3], ['denominada', 2], ['ncov’', 2], ['speared', 2], ['normokalemia', 2], ['ferroprotein', 2], ['oral–fecal', 2], ['eyedrop', 2], ['humboldt', 2], ['disulfiram', 2], ['dactinomycin', 2], ['lebanon', 2], ['grossesse', 2], ['coordenado', 2], ['sanitarium', 2], ['tcga', 2], ['leishenshan', 2], ['dlco', 2], ['begg', 2], ['benzalkonium', 2], ['digluconate', 2], ['guanosine', 2], ['territorio', 2], ['chlorhexidine', 2], ['adecuadas', 2], ['choloroquine', 2], ['scct', 2], ['dipyridamole', 2], ['新型冠状病毒肺炎（covid', 2], ['lactobacillus', 2], ['thiazide', 2], ['revu', 2], ['mefloquine', 2], ['collectrin', 2], ['efavirenz', 2], ['bioline', 2], ['thymosin', 2], ['anthony', 2], ['soporte', 2], ['veroe', 2], ['number—the', 2], ['huoshenshan', 2], ['formoterol', 2], ['linezolid', 2], ['τend', 2], ['pescado', 2], ['infectées', 2], ['instrucciones', 2], ['morphine', 2], ['identificado', 2], ['cholesterol', 2], ['dolutegravir', 2], ['hower', 2], ['hurst', 2], ['adenosine', 2], ['emodin', 2], ['methionine', 2], ['aldehyde', 2], ['calcium', 2], ['xiaobo', 2], ['carbohydrate', 2], ['cefoperazone', 2], ['provocan', 2], ['sulbactam', 2], ['toremifene', 2], ['jingmen', 2], ['infecciones', 2], ['adenosyl', 2], ['bifidobacterium', 2], ['potassium', 2], ['atazanavir', 2], ['guanine', 2], ['confirmado', 2], ['ámbito', 2], ['ccaa', 2], ['ganciclovir', 2], ['horsham', 2], ['shankar', 2], ['estuvieron', 2], ['sanitizer', 2], ['nelfinavir', 2], ['l’origine', 2], ['qiaamp', 2], ['carbon', 2], ['carol', 2], ['dcps', 2], ['nifedipine', 2], ['ukraine', 2], ['simplot', 2], ['engen', 2], ['sospechosos', 2], ['avis', 2], ['contiene', 2], ['zhao', 1], ['cytosine', 1], ['digoxin', 1], ['siie', 1], ['tacrolimus', 1], ['l’aquila', 1], ['you’ve', 1], ['formaldehyde', 1], ['changde', 1], ['namen', 1], ['hads', 1], ['greta', 1], ['saquinavir', 1], ['在新冠肺炎的筛查和诊断体系中', 1], ['conformité', 1], ['dropx', 1], ['）主要通过呼吸道飞沫传播及密切接触传播。肺功能检查可增加医务人员和受检者发生covid', 1], ['随着新型冠状病毒肺炎（covid', 1], ['summarynovel', 1], ['phosphoramide', 1], ['human‐to‐human', 1], ['saccharin', 1], ['mesylate', 1], ['highlightswe', 1], ['bioingine', 1], ['ciprofloxacin', 1], ['hexamethylene', 1], ['aportaciones', 1], ['perpetúe', 1], ['lipopolysaccharide', 1], ['nagpaul', 1], ['priorités', 1], ['parsimony', 1], ['–ace', 1], ['silver', 1], ['francisco', 1], ['macroareas', 1], ['isopropyl', 1], ['ferramenta', 1], ['i’ve', 1], ['tengyue', 1], ['digestifs', 1], ['prendre', 1], ['address—education', 1\n\n\n\n\n#all_therapies_list = drugs_str.split() \nall_therapies_list  = [word for word in all_therapies_list if word not in stopwords]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Count occurrences of therapies in the full bag of words\npotentials =[[x,abstract_bow_full.count(\" \"+x+\" \") ]for x in set(all_therapies_list)]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Count occurrences of therapies in the full bag of words\n#potentials =[[x,abstract_bow_full.count(x) ]for x in set(all_therapies_list)]\n\n#sort list\nfrom operator import itemgetter\nall_drugs = sorted (potentials, key=itemgetter(1), reverse  = True)\n#therapies = all_drugs\n#remove noise\ntherapies = []\nfor sublist in all_drugs:\n    if sublist[1] >3:\n        #print (sublist)\n        therapies.append(sublist)\n\n# #there is still noise and so exclude items mentioned twice or less\n# therapies_f = []\n# for sublist in all_drugs:\n#     if sublist[1] >2:\n#         print (sublist)\n#         therapies_f.append(sublist)\n\n# #Remove subwords found\n# #eg prednisolone and chloroquine\n# #as a by product ritonavir is also removed which is unfortuate but not a problem\n        \n# therapies = []\n# for therapy in therapies_f:\n#     subword = False\n#     for therapy_t in therapies_f:\n#         #print ('therapy, therapy_t',therapy, therapy_t)\n#         if (therapy_t[0].find(therapy[0])) >0:\n#             subword = True\n#     if subword == False:\n#         therapies.append(therapy)\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (all_drugs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print (therapies)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nwith open('therapyfile.txt','w') as f:\n    json.dump(therapies, f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_covid19.to_csv('df_covid19.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Find Therapies","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_covid19 = pd.read_csv('df_covid19.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_covid19.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nwith open('therapyfile.txt') as f:\n    therapies = json.load(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(therapies)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def abstract_title_filter(df, search_string):\n    return (df.Abstract.str.lower().str.replace('-', ' ')\n            .str.contains(search_string, na=False) |\n            df.Title.str.lower().str.replace('-', ' ')\n            .str.contains(search_string, na=False))\n\n# def abstract_title_filter(df, search_string):\n#     return (df.Abstract.str.lower()\n#             .str.contains(search_string, na=False) |\n#             df.Title.str.lower()\n#             .str.contains(search_string, na=False))\n\ndef tag_therapy(df, synonym_list: list,\n                  tag_suffix: str) -> (pd.DataFrame, pd.Series):\n    counts = {}\n    df[f'tag_{tag_suffix}'] = False\n    for s in synonym_list:\n        synonym_filter = abstract_title_filter(df, s)\n        \n        df.loc[synonym_filter, f'tag_{tag_suffix}'] = True\n    print(f'Added tag_{tag_suffix} to DataFrame')\n    return df\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"pd.options.mode.chained_assignment = None  # default='warn'\n\n#set a flag for occurrence of a therapy in abstract\nfor therapy in therapies:\n    s = therapy[0]\n    df_covid19[f'tag_{s}'] = False\n    therapy_filter = abstract_title_filter(df_covid19, s.replace('-', ' '))\n    df_covid19.loc[therapy_filter, f'tag_{s}'] = True\n\n#set a flag for occurrence of an endpoint in abstract or title\ns= 'endpoint'\ndf_covid19['endp'] = False\nendpoint_filter = abstract_title_filter(df_covid19, s.replace('-', ' '))\ndf_covid19.loc[endpoint_filter, 'endp'] = True\n\n#set a flag for occurrence of a conclusion in abstract or title\ns= 'conclusion'\ndf_covid19['conc'] = False\nendpoint_filter = abstract_title_filter(df_covid19, s.replace('-', ' '))\ndf_covid19.loc[endpoint_filter, 'conc'] = True\n\n#set a flag for occurrence of a review in abstract or title\ns= 'review'\ndf_covid19['rev'] = False\nendpoint_filter = abstract_title_filter(df_covid19, s.replace('-', ' '))\ndf_covid19.loc[endpoint_filter, 'rev'] = True\n\n#set a flag for occurrence of a review in abstract or title\ns= 'molecular modeling'\ndf_covid19['mmod'] = False\nendpoint_filter = abstract_title_filter(df_covid19, s.replace('-', ' '))\ndf_covid19.loc[endpoint_filter, 'mmod'] = True\n\n #set a flag for occurrence of a review in abstract or title\ns= 'homology modeling'\ndf_covid19['hmod'] = False\nendpoint_filter = abstract_title_filter(df_covid19, s.replace('-', ' '))\ndf_covid19.loc[endpoint_filter, 'hmod'] = True\n   \n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pd.set_option('display.max_columns', 500)\n# df_covid19_bow","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def therapy_prep_abstract (df,s):\n\n    df_covid19_t = df[df[f'tag_{s}'] == True ]\n    df_covid19_t = df_covid19_t.reset_index()\n    df_covid19_t = df_covid19_t.drop(['index'], axis=1)\n    \n    df_covid19_t['Therapy'] = s\n\n    df_covid19_display = df_covid19_t[['Therapy','Publish_Date','Title','Abstract', 'Journal', 'Authors', 'Source', 'Ref URL']]\n#sort by date, earliest first\n    df_covid19_display['Publish_Date'] = pd.to_datetime(df_covid19_display.Publish_Date)\n    df_covid19_display['Publish_Date'] = df_covid19_display['Publish_Date'].dt.date\n    df_covid19_display.sort_values(by=['Publish_Date'], inplace=True, ascending=False)\n    df_covid19_display = df_covid19_display.reset_index()\n    df_covid19_display = df_covid19_display.drop(['index'], axis=1)\n    df_covid19_display = df_covid19_display.rename(columns={'Abstract': '___________________Abstract___________________'})\n    return (df_covid19_display)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# w = 'conclusion'\n# print (stemmer.stem(w.lower()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# dfStyler = df_covid19.style.set_properties(**{'text-align': 'left',\"font-size\": \"120%\"})\n# dfStyler.set_table_styles([dict(selector='th', props=[(\"font-size\", \"150%\"),('text-align', 'center')])])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = 'the  not very good at all in fact very poor and awful continuation of the lord of the rings trilogy is so belittling  einffective that a column of words cannot adequately describe co-writer/director peter jackson' \n\nfrom textblob import TextBlob\n\npos_count = 0\npos_correct = 0\n\n\n   \nanalysis = TextBlob(test)\nprint (analysis.sentiment.polarity)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.stem import PorterStemmer\nstemmer = PorterStemmer()\n\nimport nltk\ndef therapy_prep_abstract_enhanced (df,s):\n\n    df_covid19_t = df[df[f'tag_{s}'] == True ]\n    df_covid19_t = df_covid19_t[df_covid19_t['conc'] == True ]\n    \n    df_covid19_t = df_covid19_t[df_covid19_t['rev'] == False ]\n    df_covid19_t = df_covid19_t[df_covid19_t['mmod'] == False ]\n    df_covid19_t = df_covid19_t[df_covid19_t['hmod'] == False ]\n    \n    df_covid19_t = df_covid19_t.reset_index()\n    df_covid19_t = df_covid19_t.drop(['index'], axis=1)\n    \n    df_covid19_t['Therapy'] = s\n\n#     searched_words=['endpoint']\n#     df_covid19_t['Endpoint']= df_covid19_t['Abstract'].apply(lambda text: [sent for sent in sent_tokenize(text)\n#                            if any(True for w in word_tokenize(sent) \n#                                      if stemmer.stem(w.lower()) in searched_words)])\n\n\n    searched_words=['conclus', 'conclude']\n\n#    df_covid19_t['abstract']=df_covid19_t['Abstract'].apply(str)\n\n    df_covid19_t['Abstract'].apply(str)\n#    df_covid19_t = df_covid19_t.assign(Abstract=lambda df_covid19_t: df_covid19_t.Abstract +\" a conclusion and result Ends.\")\n\n    df_covid19_t['Conclusion'] = df_covid19_t['Abstract'].apply(lambda texta: [sent for sent in sent_tokenize(texta)\n                                       if any(True for w in word_tokenize(sent) \n                                               if stemmer.stem(w.lower()) in searched_words)])\n\n    searched_words=['endpoint', 'outcome']\n\n    df_covid19_t['Endpoint(s) of Study'] = df_covid19_t['Abstract'].apply(lambda texta: [sent for sent in sent_tokenize(texta)\n                                       if any(True for w in word_tokenize(sent) \n                                               if stemmer.stem(w.lower()) in searched_words)])\n\n\n    df_covid19_display = df_covid19_t[['Publish_Date','Title','Ref URL','Journal','Therapy','Conclusion','Endpoint(s) of Study','Abstract',  'Authors', 'Source', 'doi','cord_uid']]\n    df_covid19_display = df_covid19_display.rename(columns={'Publish_Date': 'Date', 'Title':'Study', 'doi':'DOI', 'cord_uid':'CORD_UID','Ref URL':'Study Link',\\\n                                                           'Therapy':'Therapeutic method(s) utilized/assessed','Conclusion':'General Outcome/Conclusion'\\\n                                                           })\n\n    #    df_covid19_display = df_covid19_t[['Therapy','Endpoint','Publish_Date','Title','Abstract', 'Journal', 'Authors', 'Source', 'Ref URL','endp']]\n#sort by date, earliest first\n    df_covid19_display['Date'] = pd.to_datetime(df_covid19_display.Date)\n    df_covid19_display['Date'] = df_covid19_display['Date'].dt.date\n    df_covid19_display.sort_values(by=['Date'], inplace=True, ascending=False)\n    df_covid19_display = df_covid19_display.reset_index()\n    df_covid19_display = df_covid19_display.drop(['index'], axis=1)\n    df_covid19_display = df_covid19_display.rename(columns={'Abstract': '___________________Abstract___________________'})\n    return (df_covid19_display)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def therapy_prep (df,s):\n\n    df_covid19_t = df[df[f'tag_{s}'] == True ]\n    df_covid19_t = df_covid19_t.reset_index()\n    df_covid19_t = df_covid19_t.drop(['index'], axis=1)\n    \n    df_covid19_t['Therapy'] = s\n\n    df_covid19_display = df_covid19_t[['Therapy','Sent Abstract','Publish_Date','Title','Abstract', 'Journal', 'Authors', 'Source', 'Ref URL','bow']]\n    df_covid19_display['Publish_Date'] = pd.to_datetime(df_covid19_display.Publish_Date)\n    df_covid19_display['Publish_Date'] = df_covid19_display['Publish_Date'].dt.date\n    df_covid19_display.sort_values(by=['Publish_Date'], inplace=True, ascending=False)\n    df_covid19_display = df_covid19_display.reset_index()\n    df_covid19_display = df_covid19_display.drop(['index'], axis=1)\n    #df_covid19_display = df_covid19_display.rename(columns={'Abstract': '___________________Abstract___________________'})\n    return (df_covid19_display)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Literature mentioning therapies filtered by:\n\nmention of endpoint","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#therapies by abstract\ni = 0\n\n\n\nfor therapy in therapies:\n    s = therapy[0]\n    df_covid19_display = therapy_prep_abstract_enhanced (df_covid19,s)\n#    df_covid19_display = therapy_prep_abstract (df_covid19,s)\n    if i ==0:\n        df_covid19_display_full = df_covid19_display\n    else:\n        df_covid19_display_full = pd.concat([df_covid19_display_full, df_covid19_display], ignore_index=True)\n    i = i + 1\n\n\ndfStyler = df_covid19_display_full.style.set_properties(**{'text-align': 'left',\"font-size\": \"120%\"})\ndfStyler.set_table_styles([dict(selector='th', props=[(\"font-size\", \"150%\"),('text-align', 'center')])])\n   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_covid19.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(df_covid19['Abstract'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftest = pd.DataFrame({'State': ['California', 'Florida','New York'], 'Text': ['This is a beutiful day# Its too hard I am get...', 'Can somebody please help me; I am new to python','But I am stuck with code How should I solve th.']})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftest.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(dftest['Text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftest['Text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_covid19['Abstract']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftest[['polarity', 'subjectivity']] = dftest['Text'].apply(lambda Text: pd.Series(TextBlob(Text).sentiment))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_covid19 = df_covid19.replace(np.nan, '', regex=True)\ndf_covid19['Sentiment'] =df_covid19['Abstract'].apply(lambda Abstract:pd.Series(TextBlob(Abstract).sentiment.polarity))\n\n#df[['polarity', 'subjectivity']] = df['Text'].apply(lambda Text: pd.Series(TextBlob(Text).sentiment))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df[['polarity', 'subjectivity']] = df['Text'].apply(lambda Text: pd.Series(TextBlob(Text).sentiment))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_covid19 = df_covid19.assign(Sentiment= lambda x: TextBlob(df_covid19['Abstract'].str) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_covid19.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_covid19['Sentiment'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_covid19['Sentiment'].min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_covid19['sentiment'] = TextBlob(df_covid19['Abstract'].str)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# # Literature mentioning therapies<a id='therapies'></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_covid19_display = therapy_prep_abstract (df_covid19,'nitric-oxide')\n# df_covid19_display\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#therapies by abstract\ni = 0\nfor therapy in therapies:\n    s = therapy[0]\n    df_covid19_display = therapy_prep_abstract (df_covid19,s)\n    if i ==0:\n        df_covid19_display_full = df_covid19_display\n    else:\n        df_covid19_display_full = pd.concat([df_covid19_display_full, df_covid19_display], ignore_index=True)\n    i = i + 1\ndfStyler = df_covid19_display_full.style.set_properties(**{'text-align': 'left',\"font-size\": \"120%\"})\ndfStyler.set_table_styles([dict(selector='th', props=[(\"font-size\", \"150%\"),('text-align', 'center')])])\n   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_covid19_display_full.to_csv('therapiesbyabstract.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using the universal Sentence encoder to find relevant papers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#set a flag for occurrence of a therapy in abstract split into sentence \n#remove - first so that bigrams are found\nfor therapy in therapies:\n    s = therapy[0]\n    df_covid19_bow[f'tag_{s}'] = False\n    therapy_filter = abstract_title_filter(df_covid19_bow, s.replace('-', ' '))\n    df_covid19_bow.loc[therapy_filter, f'tag_{s}'] = True\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub\n#model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")\n\nmodule_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/4\", \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"]\nmodel = hub.load(module_url)\nprint (\"module %s loaded\" % module_url)\ndef embed(input):\n  return model(input)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def Find_therapies (index,sim_array,answer_sentence,query, display_no = 10, threshold = 0.3):\n#df_covid19_display = df_covid19_t[['Therapy','Sent Abstract','Publish_Date','Title','Abstract', 'Journal', 'Authors', 'Source', 'Ref URL','bow']]\n    \n    \n    \n    query_len = len(query)\n    \n    #df_sim_q = pd.DataFrame({'Cosine':sim_array[query_len:,index],  'Question':query.iloc[index]['question'],'Title':answer_sentence['title'], 'Abstract Sentence':answer_sentence['abstract'],'Journal':answer_sentence['journal'],'Published':answer_sentence['publish_time'],'URL':answer_sentence['url']})\n    #df_sim_q = pd.DataFrame({'Cosine':sim_array[query_len:,index],  'Abstract Snippet':answer_sentence['abstract'],'Published':answer_sentence['publish_time'],'Title':answer_sentence['title'], 'Journal':answer_sentence['journal'],'Source':answer_sentence['source_x'],'Abstract                                                                                                                                                                                                      p':answer_sentence['org abstract'],'URL':answer_sentence['url']})\n\n    df_sim_q = pd.DataFrame({'Cosine':sim_array[query_len:,index],\\\n                             'Therapy':answer_sentence['Therapy'],\\\n                             'Abstract_Snippet':answer_sentence['Sent Abstract'],\\\n                             'Journal':answer_sentence['Journal'],\\\n                             'Authors':answer_sentence['Authors'],\\\n                             'Published':answer_sentence['Publish_Date'],\\\n                             'Title             ':answer_sentence['Title'],\\\n                             '______________Abstract________________':answer_sentence['Abstract'],\\\n                             'Source':answer_sentence['Source'],\\\n                             'URL to full text':answer_sentence['Ref URL']})\n\n    \n    df_sim_q_sorted = df_sim_q.sort_values('Cosine',ascending = False )\n    df_sim_q_sample = df_sim_q_sorted.loc[df_sim_q_sorted['Cosine'] > threshold]\n    df_sim_q_sample = df_sim_q_sample.drop_duplicates('______________Abstract________________')\n    #df_sim_q_sample = df_sim_q_sorted[:display_no]\n\n    df_sim_q_sample = df_sim_q_sample.reset_index()\n    df_sim_q_sample = df_sim_q_sample.drop(['index'], axis=1)\n    df_sim_q_sample = df_sim_q_sample.drop(['Cosine'], axis=1)\n\n#     df_sim_q_sample['___________________________________________Abstract________________'] =\\\n#     df_sim_q_sample['___________________________________________Abstract________________'].str[:1000]\n    df_sim_q_sample[\"Authors\"] = df_sim_q_sample[\"Authors\"].str[:100]\n    \n    return ( df_sim_q_sample)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def Find_articles (index,sim_array,answer_sentence,query, display_no = 10, threshold = 0.0):\n\n    query_len = len(query)\n    \n    #df_sim_q = pd.DataFrame({'Cosine':sim_array[query_len:,index],  'Question':query.iloc[index]['question'],'Title':answer_sentence['title'], 'Abstract Sentence':answer_sentence['abstract'],'Journal':answer_sentence['journal'],'Published':answer_sentence['publish_time'],'URL':answer_sentence['url']})\n    #df_sim_q = pd.DataFrame({'Cosine':sim_array[query_len:,index],  'Abstract Snippet':answer_sentence['abstract'],'Published':answer_sentence['publish_time'],'Title':answer_sentence['title'], 'Journal':answer_sentence['journal'],'Source':answer_sentence['source_x'],'Abstract                                                                                                                                                                                                      p':answer_sentence['org abstract'],'URL':answer_sentence['url']})\n\n    df_sim_q = pd.DataFrame({'Cosine':sim_array[query_len:,index],  'Abstract_Snippet':answer_sentence['Sent Abstract'],\\\n                             'Published':answer_sentence['Publish_Date'],'Title             ':answer_sentence['Title'], 'Journal':answer_sentence['Journal'],\\\n                             'Source':answer_sentence['Source'],\\\n                             'Authors':answer_sentence['Authors'],\\\n                             'Abstract truncted at 1000 characters                                                                                                                           ':answer_sentence['Abstract'],\\\n                             'URL to full text':answer_sentence['Ref URL']})\n\n    \n    df_sim_q_sorted = df_sim_q.sort_values('Cosine',ascending = False )\n    df_sim_q_sorted = df_sim_q_sorted.loc[df_sim_q_sorted['Cosine'] > threshold]\n\n    df_sim_q_sample = df_sim_q_sorted[:display_no]\n\n    df_sim_q_sample = df_sim_q_sample.reset_index()\n    df_sim_q_sample = df_sim_q_sample.drop(['index'], axis=1)\n    df_sim_q_sample = df_sim_q_sample.drop(['Cosine'], axis=1)\n\n    #df_sim_q_sample = df_sim_q_sample.apply(lambda x: x.str.slice(0, 1000))\n    df_sim_q_sample[\"Authors\"] = df_sim_q_sample[\"Authors\"].str[:100]\n    \n    return ( df_sim_q_sample)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Finding therapies Trials<a id='therapytrials'></a>\n<a id='therapies'></a>","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#therapies by sentence\n\ni = 0\nfor therapy in therapies:\n    s = therapy[0]\n    df_covid19_therapy = therapy_prep (df_covid19_bow,s)\n\n    therapy_bow = [\"\".join(x) for x in (df_queries['query_bow'])]\n    therapy_bow += [\"\".join(x) for x in (df_covid19_therapy['bow'])]\n    message_embeddings_therapy_ = embed(therapy_bow)\n    therapy_corr = np.inner(message_embeddings_therapy_, message_embeddings_therapy_)\n    results = Find_therapies (6,therapy_corr,df_covid19_therapy,df_queries)\n    \n    if i ==0:\n        df_covid19_display_full = results\n    else:\n        df_covid19_display_full = pd.concat([df_covid19_display_full, results], ignore_index=True)\n    i = i + 1\ndfStyler = df_covid19_display_full.style.set_properties(**{'text-align': 'left',\"font-size\": \"120%\"})\ndfStyler.set_table_styles([dict(selector='th', props=[(\"font-size\", \"150%\"),('text-align', 'center')])])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"USeful reference\n\nhttps://www.jwatch.org/na51172/2020/03/24/lopinavir-ritonavir-was-not-effective-covid-19","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_covid19_display_full.to_csv('therapiesbytrails.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#del therapy_corr\n#del message_embeddings_therapy_\n#del df_covid19_display_full\nimport gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"message_embeddings_ = embed(total_bow)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del total_bow\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_queries_len = len(df_queries)\nprint(df_queries_len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = np.inner(message_embeddings_, message_embeddings_[:df_queries_len])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Question 1<a id='0'></a>","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print (df_queries.iloc[0]['question'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"results = Find_articles (0,corr,df_covid19_bow,df_queries)\ndfStyler = results.style.set_properties(**{'text-align': 'left'})\ndfStyler.set_table_styles([dict(selector='th', props=[(\"font-size\", \"150%\"),('text-align', 'left')])])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Question 2<a id='1'></a>","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print (df_queries.iloc[1]['question'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"results = Find_articles (1,corr,df_covid19_bow,df_queries)\ndfStyler = results.style.set_properties(**{'text-align': 'left'})\ndfStyler.set_table_styles([dict(selector='th', props=[('text-align', 'left')])])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Question 3<a id='2'></a>\n    ","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print (df_queries.iloc[2]['question'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"results = Find_articles (2,corr,df_covid19_bow,df_queries)\ndfStyler = results.style.set_properties(**{'text-align': 'left'})\ndfStyler.set_table_styles([dict(selector='th', props=[('text-align', 'left')])])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Question 4<a id='3'></a>\n    ","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print (df_queries.iloc[3]['question'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"results = Find_articles (3,corr,df_covid19_bow,df_queries)\ndfStyler = results.style.set_properties(**{'text-align': 'left'})\ndfStyler.set_table_styles([dict(selector='th', props=[('text-align', 'left')])])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#  Question 5<a id='4'></a>\n ","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print (df_queries.iloc[4]['question'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"results = Find_articles (4,corr,df_covid19_bow,df_queries)\ndfStyler = results.style.set_properties(**{'text-align': 'left'})\ndfStyler.set_table_styles([dict(selector='th', props=[('text-align', 'left')])])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Question 6<a id='5'></a>\n  ","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print (df_queries.iloc[5]['question'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"results = Find_articles (5,corr,df_covid19_bow,df_queries)\ndfStyler = results.style.set_properties(**{'text-align': 'left'})\ndfStyler.set_table_styles([dict(selector='th', props=[('text-align', 'left')])])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Question 7<a id='6'></a>","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print (df_queries.iloc[6]['question'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"results = Find_articles (6,corr,df_covid19_bow,df_queries)\n\ndfStyler = results.style.set_properties(**{'text-align': 'left',\"font-size\": \"120%\"})\ndfStyler.set_table_styles([dict(selector='th', props=[(\"font-size\", \"150%\"),('text-align', 'center')])])\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Question 8<a id='7'></a>\n    ","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print (df_queries.iloc[7]['question'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"results = Find_articles (7,corr,df_covid19_bow,df_queries)\ndfStyler = results.style.set_properties(**{'text-align': 'left'})\ndfStyler.set_table_styles([dict(selector='th', props=[('text-align', 'left')])])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Question 9<a id='8'></a>\n  ","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print (df_queries.iloc[8]['question'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"results = Find_articles (8,corr,df_covid19_bow,df_queries)\ndfStyler = results.style.set_properties(**{'text-align': 'left'})\ndfStyler.set_table_styles([dict(selector='th', props=[('text-align', 'left')])])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Question 10<a id='9'></a>\n ","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print (df_queries.iloc[9]['question'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"results = Find_articles (9,corr,df_covid19_bow,df_queries)\ndfStyler = results.style.set_properties(**{'text-align': 'left'})\ndfStyler.set_table_styles([dict(selector='th', props=[('text-align', 'left')])])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Question 11<a id='10'></a>","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print (df_queries.iloc[10]['question'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"results = Find_articles (10,corr,df_covid19_bow,df_queries)\ndfStyler = results.style.set_properties(**{'text-align': 'left'})\ndfStyler.set_table_styles([dict(selector='th', props=[('text-align', 'left')])])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Developing a Vaccine<a id='11'></a>\n   ","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print (df_queries.iloc[11]['question'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"results = Find_articles (11,corr,df_covid19_bow,df_queries,threshold = 0.43, display_no = 50 )\ndfStyler = results.style.set_properties(**{'text-align': 'left'})\ndfStyler.set_table_styles([dict(selector='th', props=[('text-align', 'left')])])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ## Clincal Trials<a id='12'></a>\n","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print (df_queries.iloc[12]['question'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"results = Find_articles (12,corr,df_covid19_bow,df_queries, display_no = 20)\n#dfStyler = results.style.set_properties(**{('text-align': 'left',\"font-size\": \"120%\"})\ndfStyler = results.style.set_properties(**{'text-align': 'left',\"font-size\": \"120%\"})\ndfStyler.set_table_styles([dict(selector='th', props=[(\"font-size\", \"150%\"),('text-align', 'center')])])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### EndOfFile<a id='vote'></a>","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}