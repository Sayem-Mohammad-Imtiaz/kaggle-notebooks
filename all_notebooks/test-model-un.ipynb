{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 数据准备","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nfrom sklearn.utils import shuffle\nimport pandas as pd\nimport pickle\nfrom matplotlib.pyplot import MultipleLocator","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(r'../input/fortrainvalidation/Train_Merge_Data.csv')\nvalidation_data = pd.read_csv(r'../input/fortrainvalidation/Validation_Merge_Data.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_data = shuffle(train_data)\n# validation_data = shuffle(validation_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_label_Sbp = train_data.iloc[:,635]\ntrain_label_Sbp = train_label_Sbp.values\n\ntrain_label_Dbp = train_data.iloc[:,636]\ntrain_label_Dbp = train_label_Dbp.values\n\ntrain_data = train_data.iloc[:,:625]\ntrain_data = train_data.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_label_Sbp = validation_data.iloc[:,635]\nvalidation_label_Sbp = validation_label_Sbp.values\n\nvalidation_label_Dbp = validation_data.iloc[:,636]\nvalidation_label_Dbp = validation_label_Dbp.values\n\nvalidation_data = validation_data.iloc[:,:625]\nvalidation_data = validation_data.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"train_data_information:\")\nprint(train_data.shape)\nprint(train_label_Sbp.shape)\nprint(train_label_Dbp.shape)\nprint(\"validation_data_information:\")\nprint(validation_data.shape)\nprint(validation_label_Sbp.shape)\nprint(validation_label_Dbp.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 模型","metadata":{}},{"cell_type":"code","source":"inputs = keras.Input(shape=(625,1))\n\nx=32","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv1 = layers.Conv1D(x,3,padding='same')(inputs)\nconv1 = layers.BatchNormalization()(conv1)\nconv1 = layers.Activation(tf.nn.relu)(conv1)\n\nconv1 = layers.Conv1D(x,3,padding='same')(conv1)\nconv1 = layers.BatchNormalization()(conv1)\nconv1 = layers.Activation(tf.nn.relu)(conv1)\n\npool1 = layers.MaxPooling1D(pool_size=2)(conv1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv2 = layers.Conv1D(x*2,3,padding='same')(pool1)\nconv2 = layers.BatchNormalization()(conv2)\nconv2 = layers.Activation(tf.nn.relu)(conv2)\n\nconv2 = layers.Conv1D(x*2,3,padding='same')(conv2)\nconv2 = layers.BatchNormalization()(conv2)\nconv2 = layers.Activation(tf.nn.relu)(conv2)\n\npool2 = layers.MaxPooling1D(pool_size=2)(conv2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv3 = layers.Conv1D(x*4,3,padding='same')(pool2)\nconv3 = layers.BatchNormalization()(conv3)\nconv3 = layers.Activation(tf.nn.relu)(conv3)\n\nconv3 = layers.Conv1D(x*4,3,padding='same')(conv3)\nconv3 = layers.BatchNormalization()(conv3)\nconv3 = layers.Activation(tf.nn.relu)(conv3)\n\npool3 = layers.MaxPooling1D(pool_size=2)(conv3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv4 = layers.Conv1D(x*8,3,padding='same')(pool3)\nconv4 = layers.BatchNormalization()(conv4)\nconv4 = layers.Activation(tf.nn.relu)(conv4)\n\nconv4 = layers.Conv1D(x*8,3,padding='same')(conv4)\nconv4 = layers.BatchNormalization()(conv4)\nconv4 = layers.Activation(tf.nn.relu)(conv4)\n\npool4 = layers.MaxPooling1D(pool_size=2)(conv4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv5 = layers.Conv1D(x*16,3,padding='same')(pool4)\nconv5 = layers.BatchNormalization()(conv5)\nconv5 = layers.Activation(tf.nn.relu)(conv5)\n\nconv5 = layers.Conv1D(x*16,3,padding='same')(conv5)\nconv5 = layers.BatchNormalization()(conv5)\nconv5 = layers.Activation(tf.nn.relu)(conv5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"up6 = layers.Concatenate(axis=2)([layers.UpSampling1D(size=2)(conv5),conv4])\n\nconv6 = layers.Conv1D(x*8,3,padding='same')(up6)\nconv6 = layers.BatchNormalization()(conv6)\nconv6 = layers.Activation(tf.nn.relu)(conv6)\n\nconv6 = layers.Conv1D(x*8,3,padding='same')(conv6)\nconv6 = layers.BatchNormalization()(conv6)\nconv6 = layers.Activation(tf.nn.relu)(conv6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"up7 = layers.Concatenate(axis=2)([layers.UpSampling1D(size=2)(conv6),conv3])\n\nconv7 = layers.Conv1D(x*4,3,padding='same')(up7)\nconv7 = layers.BatchNormalization()(conv7)\nconv7 = layers.Activation(tf.nn.relu)(conv7)\n\nconv7 = layers.Conv1D(x*4,3,padding='same')(conv7)\nconv7 = layers.BatchNormalization()(conv7)\nconv7 = layers.Activation(tf.nn.relu)(conv7)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"up8 = layers.Concatenate(axis=2)([layers.UpSampling1D(size=2)(conv7),conv2])\n\nconv8 = layers.Conv1D(x*2,3,padding='same')(up8)\nconv8 = layers.BatchNormalization()(conv8)\nconv8 = layers.Activation(tf.nn.relu)(conv8)\n\nconv8 = layers.Conv1D(x*2,3,padding='same')(conv8)\nconv8 = layers.BatchNormalization()(conv8)\nconv8 = layers.Activation(tf.nn.relu)(conv8)\nconv8 = layers.UpSampling1D(size=2)(conv8)\n\nconv8 = layers.ZeroPadding1D((0,1))(conv8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"up9 = layers.Concatenate(axis=2)([conv8,conv1])\n\nconv9 = layers.Conv1D(x,3,padding='same')(up9)\nconv9 = layers.BatchNormalization()(conv9)\nconv9 = layers.Activation(tf.nn.relu)(conv9)\n\nconv9 = layers.Conv1D(x,3,padding='same')(conv9)\nconv9 = layers.BatchNormalization()(conv9)\nconv9 = layers.Activation(tf.nn.relu)(conv9)\n\n\nconv10 = layers.Conv1D(1,1)(conv9)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conv10 =layers.Flatten()(conv10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"com_layer = layers.Dense(32,activation='relu')(conv10)\n\ncom_layer = layers.Dense(32,activation='relu')(com_layer)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputs_sbp = layers.Dense(1,name='Sbp')(com_layer)\noutputs_dbp = layers.Dense(1,name='Dbp')(com_layer)\n\nmodel = keras.Model(inputs=inputs,outputs=[outputs_sbp,outputs_dbp])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, to_file='./model_show.png', show_shapes=True, show_layer_names=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 基础参数设置","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 128","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 训练自定义模块","metadata":{}},{"cell_type":"code","source":"def standard_deviation(y_true, y_pred):\n    u = keras.backend.mean(y_pred-y_true)\n    return keras.backend.sqrt(keras.backend.mean(keras.backend.square((y_pred-y_true) - u)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_filepath = r'./Model_UN_01.h5'\nSave_epochs = 5 #迭代多少层保存一次模型\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    # save_weights_only=True,\n    monitor='val_Sbp_loss',\n    mode='min',\n    save_best_only=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001,decay=0.0001)\nthe_optimizer = keras.optimizers.Adam(lr=0.0001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 编译模型","metadata":{}},{"cell_type":"code","source":"# model.compile(loss=keras.losses.mse, optimizer=the_optimizer,metrics=[tf.keras.metrics.MeanAbsoluteError(),standard_deviation])\nmodel.compile(loss={'Sbp':\"mae\",'Dbp':\"mae\"}, optimizer=the_optimizer,metrics=[standard_deviation])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 训练模型","metadata":{}},{"cell_type":"code","source":"history = model.fit(train_data,{'Sbp':train_label_Sbp,'Dbp':train_label_Dbp},\n                    batch_size=BATCH_SIZE,\n                    epochs=5,\n                    callbacks=model_checkpoint_callback,\n                    validation_data=(validation_data,{'Sbp':validation_label_Sbp,'Dbp':validation_label_Dbp})\n                    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(r'./Last_Model_01.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 加载模型","metadata":{}},{"cell_type":"code","source":"def Conv1d_layer(inputs,Filters,Kernel_size,Padding='same',Strides=1):\n    com_layer = layers.Conv1D(filters=Filters,kernel_size=Kernel_size,padding=Padding,strides=Strides)(inputs)\n    com_layer = layers.BatchNormalization()(com_layer)\n    com_layer = layers.Activation(tf.nn.relu)(com_layer)\n    return com_layer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#短序列-目前初始输入维度为（-1,125，1）\ndef Resnet_Model_S(inputs):\n    #卷积块1\n    com_layer = Conv1d_layer(inputs,Filters=64,Kernel_size=8,Padding='same',Strides=1)\n    #卷积块2\n    com_layer = Conv1d_layer(com_layer,Filters=128,Kernel_size=5,Padding='same',Strides=1)\n    #卷积块3\n    com_layer = layers.Conv1D(filters=128,kernel_size=3,padding='same',strides=1)(com_layer)\n    #批标准化\n    com_layer = layers.BatchNormalization()(com_layer)\n    add_layer = layers.BatchNormalization()(inputs)\n    #信息叠加\n    com_layer = layers.add([add_layer,com_layer])\n    \n    return com_layer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#长序列-目前初始输入维度为（625，1）\ndef Resnet_Model_L(inputs):\n    #卷积块1\n    com_layer = Conv1d_layer(inputs,Filters=64,Kernel_size=8,Padding='same',Strides=1)\n    #卷积块2\n    com_layer = Conv1d_layer(com_layer,Filters=128,Kernel_size=5,Padding='same',Strides=1)\n    #卷积块3\n    com_layer = layers.Conv1D(filters=128,kernel_size=3,padding='same',strides=1)(com_layer)\n    #批标准化\n    com_layer = layers.BatchNormalization()(com_layer)\n    add_layer = layers.BatchNormalization()(inputs)\n    #信息叠加\n    com_layer = layers.add([add_layer,com_layer])\n    \n    return com_layer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Separate_Data(inputs,num_of_cycle):\n    per_input = inputs[:,125*(num_of_cycle-1):125*num_of_cycle]\n    return per_input","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Separate_Data_For_Conv1d(per_input):\n    per_input = tf.reshape(per_input,(-1,125,1))\n    return per_input","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def standard_deviation(y_true, y_pred):\n    u = keras.backend.mean(y_pred-y_true)\n    return keras.backend.sqrt(keras.backend.mean(keras.backend.square((y_pred-y_true) - u)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = keras.models.load_model(r'../input/model-res-gru-650/Model_ls_650_03.h5',           \n                                    custom_objects={\n                                    'Conv1d_layer':Conv1d_layer,\n                                    'Separate_Data':Separate_Data,\n                                    'Separate_Data_For_Conv1d':Separate_Data_For_Conv1d,\n                                    'Resnet_Model_L':Resnet_Model_L,\n                                    'Resnet_Model_S':Resnet_Model_S,\n                                    \n                                    \n                                    'standard_deviation':standard_deviation\n                                    \n                                    }\n                               )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = keras.models.load_model(r'./Last_Model_01.h5',           \n                                    custom_objects={\n    \n                                    \n                                    'standard_deviation':standard_deviation,\n                                    }\n                               )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv(r'../input/fortrainvalidation/Validation_Merge_Data.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_label_Sbp = test_data.iloc[:,635]\ntest_label_Sbp = test_label_Sbp.values\n\ntest_label_Dbp = test_data.iloc[:,636]\ntest_label_Dbp = test_label_Dbp.values\n\ntest_data = test_data.iloc[:,:625]\ntest_data = test_data.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sbp_pre_0,dbp_pre_0 = model.predict(test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.mean(abs(dbp_pre_0-test_label_Dbp))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.mean(abs(sbp_pre_0-test_label_Sbp))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sbp_true = test_label_Sbp\ndbp_true = test_label_Dbp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sbp_pre= sbp_pre_0\ndbp_pre= dbp_pre_0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,10))\nplt.plot(sbp_pre,'r.-',label='SBP_pred')\n\nplt.plot(sbp_true,'b.-',label='SBP_true')\nplt.plot(dbp_pre,'g.-',label='DBP_pred')\n\nplt.plot(dbp_true,'y.-',label='DBP_true')\nplt.title('Predict Display',fontsize=16)\nplt.xlabel('Numbers',fontsize=14)\nx_major_locator=MultipleLocator(10)\ny_major_locator=MultipleLocator(5)\nax=plt.gca()\nax.xaxis.set_major_locator(x_major_locator)\nax.yaxis.set_major_locator(y_major_locator)\n\nplt.tick_params(labelsize=10)\n\nplt.ylim(25,220)\nplt.ylabel('mmHg',fontsize=14)\nplt.legend(fontsize=8)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}