{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npd.options.display.max_columns = 200\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom catboost import CatBoostRegressor, Pool, cv\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/real-time-advertisers-auction/Dataset.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making label\n\ndef weird_division(n, d):\n    return n / d if d else 0\n\ndf['CPM'] = df.apply(lambda x: weird_division(((x['total_revenue']*100)),\n                                              x['measurable_impressions'])*1000 , axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's drop columns that are used in CPM formula and useless ones\n\ndf.drop(['total_revenue', 'measurable_impressions', 'integration_type_id', 'revenue_share_percent'], \\\n        axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['date'] = pd.to_datetime(df.date)\ndf = df.sort_values('date')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[df.CPM < df.CPM.quantile(.95)]\ndf = df[df.CPM >= 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.CPM.hist();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = df.corr()\ncorr.style.background_gradient(cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make some features\n\ndf['weekday'] = df.date.apply(lambda x: x.weekday())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dates = df.date.sort_values().unique()\ndate_df = pd.DataFrame({'date': dates, 'date_num': np.arange(len(dates)).astype(float)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.merge(date_df, left_on='date', right_on='date', how='inner')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['total_impressions', 'viewable_impressions']] = df[['total_impressions', 'viewable_impressions']].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making two datasets to compare how big 'order_id' and 'line_item_type_id' improve score (they may contain leaks)\n\ndata1 = pd.get_dummies(df[[col for col in df.columns if col not in ['order_id' , 'line_item_type_id']]])\ndata2 = pd.get_dummies(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = data1[data1.date <= pd.Timestamp(2019,6,21)]\ny_train = train.pop('CPM')\ntest = data1[data1.date > pd.Timestamp(2019,6,21)]\ny_test = test.pop('CPM')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train['date']\ndel test['date']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(train, y_train, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"cat_feat = np.where(X_train.dtypes != np.float)[0]\nparams = {\n    'iterations': 300,\n    #'logging_level': 'Silent',\n    'loss_function': 'RMSE',\n    'use_best_model': True,\n}\ntrain_pool = Pool(X_train, y_train, cat_features=cat_feat)\nvalidate_pool = Pool(X_val, y_val, cat_features=cat_feat)\n\nmodel = CatBoostRegressor(**params, cat_features=cat_feat)\nmodel.fit(train_pool, eval_set=validate_pool)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.get_feature_importance(data=None,\n                       #type=EFstrType.FeatureImportance,\n                       prettified=True,\n                       thread_count=-1,\n                       verbose=False).head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Turning negative CPM values to zeros\n\ny_pred = pd.Series(model.predict(test)).apply(lambda x: 0 if x < 0 else x).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'MSE = {mean_squared_error(y_pred, y_test)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking second dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = data2[data2.date <= pd.Timestamp(2019,6,21)]\ny_train = train.pop('CPM')\ntest = data2[data2.date > pd.Timestamp(2019,6,21)]\ny_test = test.pop('CPM')\n\ndel train['date']\ndel test['date']\n\nX_train, X_val, y_train, y_val = train_test_split(train, y_train, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"cat_feat = np.where(X_train.dtypes != np.float)[0]\nparams = {\n    #'iterations': 300,\n    #'logging_level': 'Silent',\n    'loss_function': 'RMSE',\n    'use_best_model': True,\n}\ntrain_pool = Pool(X_train, y_train, cat_features=cat_feat)\nvalidate_pool = Pool(X_val, y_val, cat_features=cat_feat)\n\nmodel = CatBoostRegressor(**params, cat_features=cat_feat)\nmodel.fit(train_pool, eval_set=validate_pool)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.get_feature_importance(data=None,\n                       #type=EFstrType.FeatureImportance,\n                       prettified=True,\n                       thread_count=-1,\n                       verbose=False).head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = pd.Series(model.predict(test)).apply(lambda x: 0 if x < 0 else x).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'MSE = {mean_squared_error(y_pred, y_test)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We see, that in the second case considered features influence the model much better than others, so they can contain leak info\n\n#### But stil we have obtain acceptable MSE under 4850 in both methods"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}