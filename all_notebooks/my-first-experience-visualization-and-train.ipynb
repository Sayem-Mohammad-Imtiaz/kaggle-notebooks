{"cells":[{"metadata":{"_uuid":"1769451cb9f721522ab107a5905e22a78c055eb7","colab_type":"text","id":"xQfGug1uMRMm"},"cell_type":"markdown","source":"<br>\n<center> <b> ******Data Visualization****** </b> </center>\n<br>"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":false,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","colab":{},"colab_type":"code","id":"s49BoY-JMRMq","trusted":true},"cell_type":"code","source":"# Module import\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport os\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","colab":{"base_uri":"https://localhost:8080/","height":204},"colab_type":"code","executionInfo":{"elapsed":682,"status":"ok","timestamp":1554816126858,"user":{"displayName":"Daniel Kindischew","photoUrl":"https://lh5.googleusercontent.com/-TF6NGgM75H0/AAAAAAAAAAI/AAAAAAAAABk/PEX1UCOgi54/s64/photo.jpg","userId":"17008209418971916367"},"user_tz":-120},"id":"zMN3QixfMRM2","outputId":"a148a6c4-2f6f-4928-caa5-8d0b7c9a0f52","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/heart.csv')\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"HNW8uul0R45t"},"cell_type":"markdown","source":"## Dataset Columns (Features)\n"},{"metadata":{"colab_type":"text","id":"9Xn3R2xJSSeq"},"cell_type":"markdown","source":"- Age (age in years)\n- Sex (1 = male; 0 = female)\n- CP (chest pain type)\n- TRESTBPS (resting blood pressure (in mm Hg on admission to the hospital))\n- CHOL (serum cholestoral in mg/dl)\n- FPS (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n- RESTECH (resting electrocardiographic results)\n- THALACH (maximum heart rate achieved)\n- EXANG (exercise induced angina (1 = yes; 0 = no))\n- OLDPEAK (ST depression induced by exercise relative to rest)\n- SLOPE (the slope of the peak exercise ST segment)\n- CA (number of major vessels (0-3) colored by flourosopy)\n- THAL (3 = normal; 6 = fixed defect; 7 = reversable defect)\n- TARGET (1 or 0)"},{"metadata":{"colab_type":"text","id":"JMEA3C3-Uca_"},"cell_type":"markdown","source":"### Concise summary of a Data"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":340},"colab_type":"code","executionInfo":{"elapsed":1077,"status":"ok","timestamp":1554817107439,"user":{"displayName":"Daniel Kindischew","photoUrl":"https://lh5.googleusercontent.com/-TF6NGgM75H0/AAAAAAAAAAI/AAAAAAAAABk/PEX1UCOgi54/s64/photo.jpg","userId":"17008209418971916367"},"user_tz":-120},"id":"zpGnrTZRUghb","outputId":"5256a85b-b9a8-4521-e2d9-20fce254c335","trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"nY8iFEiWWMww"},"cell_type":"markdown","source":"### Missing values detection"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":272},"colab_type":"code","executionInfo":{"elapsed":895,"status":"ok","timestamp":1554817579028,"user":{"displayName":"Daniel Kindischew","photoUrl":"https://lh5.googleusercontent.com/-TF6NGgM75H0/AAAAAAAAAAI/AAAAAAAAABk/PEX1UCOgi54/s64/photo.jpg","userId":"17008209418971916367"},"user_tz":-120},"id":"J8ugZGBsWPkV","outputId":"6e1a413d-67fe-45b8-90ca-8804e9cca42f","trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"tPT6JsehVjg7"},"cell_type":"markdown","source":"<br>\n## <center>  <b> **Visualization** </b> </center>\n<br>"},{"metadata":{"colab_type":"text","id":"EBE3VfajX0mT"},"cell_type":"markdown","source":"**Age**"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":310},"colab_type":"code","executionInfo":{"elapsed":1023,"status":"ok","timestamp":1554818084356,"user":{"displayName":"Daniel Kindischew","photoUrl":"https://lh5.googleusercontent.com/-TF6NGgM75H0/AAAAAAAAAAI/AAAAAAAAABk/PEX1UCOgi54/s64/photo.jpg","userId":"17008209418971916367"},"user_tz":-120},"id":"Qp7mA2d1X2q2","outputId":"f9dd6bca-153f-455d-d8da-ce8b91415e78","trusted":true},"cell_type":"code","source":"plot = data[data.target == 1].age.value_counts().sort_index().plot(kind = \"bar\", figsize=(15,4), fontsize = 15)\nplot.set_title(\"Age distribution\", fontsize = 20)","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"m_XnfIbLXnKh"},"cell_type":"markdown","source":"**Sex**"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":248},"colab_type":"code","executionInfo":{"elapsed":753,"status":"ok","timestamp":1554817925246,"user":{"displayName":"Daniel Kindischew","photoUrl":"https://lh5.googleusercontent.com/-TF6NGgM75H0/AAAAAAAAAAI/AAAAAAAAABk/PEX1UCOgi54/s64/photo.jpg","userId":"17008209418971916367"},"user_tz":-120},"id":"85jprgmCXpgJ","outputId":"790ae0a8-1637-482e-f10b-ce32d6aa7da0","trusted":true},"cell_type":"code","source":"male = len(data[data.sex == 1])\nfemale = len(data[data.sex == 0])\nplt.pie(x=[male, female], explode=(0, 0), labels=['Male', 'Female'], autopct='%1.2f%%', shadow=True, startangle=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"eKxmEOEhYqkd"},"cell_type":"markdown","source":"**CP (chest pain type)**"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":248},"colab_type":"code","executionInfo":{"elapsed":831,"status":"ok","timestamp":1554818289040,"user":{"displayName":"Daniel Kindischew","photoUrl":"https://lh5.googleusercontent.com/-TF6NGgM75H0/AAAAAAAAAAI/AAAAAAAAABk/PEX1UCOgi54/s64/photo.jpg","userId":"17008209418971916367"},"user_tz":-120},"id":"-SAdX5ryY7vl","outputId":"f85619d1-1a01-45c1-ba03-a99cc0445908","trusted":true},"cell_type":"code","source":"x = [len(data[data['cp'] == 0]),len(data[data['cp'] == 1]), len(data[data['cp'] == 2]), len(data[data['cp'] == 3])]\nplt.pie(x, data=data, labels=['CP(1) typical angina', 'CP(2) atypical angina', 'CP(3) non-anginal pain', 'CP(4) asymptomatic'], autopct='%1.2f%%', shadow=True,startangle=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"UeA4SmLwiYFf"},"cell_type":"markdown","source":"**TRESTBPS (resting blood pressure (in mm Hg on admission to the hospital))**"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":319},"colab_type":"code","executionInfo":{"elapsed":1475,"status":"ok","timestamp":1554820886048,"user":{"displayName":"Daniel Kindischew","photoUrl":"https://lh5.googleusercontent.com/-TF6NGgM75H0/AAAAAAAAAAI/AAAAAAAAABk/PEX1UCOgi54/s64/photo.jpg","userId":"17008209418971916367"},"user_tz":-120},"id":"zQv5ZvB7iaso","outputId":"c6fd3ec2-6657-4fb1-9083-f6e5e46e477f","trusted":true},"cell_type":"code","source":"plot = data[data.target == 1].trestbps.value_counts().sort_index().plot(kind = \"bar\", figsize=(15,4), fontsize = 15)\nplot.set_title(\"Resting blood pressure\", fontsize = 20)","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"8NoQr6gRdvB-"},"cell_type":"markdown","source":"**Chol (serum cholestoral in mg/dl)**"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"colab_type":"code","executionInfo":{"elapsed":920,"status":"ok","timestamp":1554819716022,"user":{"displayName":"Daniel Kindischew","photoUrl":"https://lh5.googleusercontent.com/-TF6NGgM75H0/AAAAAAAAAAI/AAAAAAAAABk/PEX1UCOgi54/s64/photo.jpg","userId":"17008209418971916367"},"user_tz":-120},"id":"7P8ueDPEdzDW","outputId":"db46a9af-f97b-4fc3-d5bc-6c7dfd1e1ff5","trusted":true},"cell_type":"code","source":"plt.hist([data.chol[data.target==0], data.chol[data.target==1]], bins=20,color=['blue', 'red'], stacked=True)\nplt.legend([\"Haven't Disease\", \"Have Disease\"])\nplt.title('Heart Disease Frequency for cholestoral ')\nplt.ylabel('Frequency')\nplt.xlabel('Chol in mg/dl')\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"iKrYbhQ8hoTB"},"cell_type":"markdown","source":"**FPS (fasting blood sugar > 120 mg/dl)**"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":248},"colab_type":"code","executionInfo":{"elapsed":928,"status":"ok","timestamp":1554820552158,"user":{"displayName":"Daniel Kindischew","photoUrl":"https://lh5.googleusercontent.com/-TF6NGgM75H0/AAAAAAAAAAI/AAAAAAAAABk/PEX1UCOgi54/s64/photo.jpg","userId":"17008209418971916367"},"user_tz":-120},"id":"zVcNiylAhlri","outputId":"ee4dda9e-604f-420d-eb3b-ed23c15ba7a2","trusted":true},"cell_type":"code","source":"sizes = [len(data[data.fbs == 0]), len(data[data.fbs==1])]\nlabels = ['No', 'Yes']\nplt.pie(x=sizes, labels=labels, explode=(0.1, 0), autopct=\"%1.2f%%\", startangle=90,shadow=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"GxkjCpk2hLcG"},"cell_type":"markdown","source":"**Restecg (resting electrocardiographic results)**"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":248},"colab_type":"code","executionInfo":{"elapsed":922,"status":"ok","timestamp":1554820444086,"user":{"displayName":"Daniel Kindischew","photoUrl":"https://lh5.googleusercontent.com/-TF6NGgM75H0/AAAAAAAAAAI/AAAAAAAAABk/PEX1UCOgi54/s64/photo.jpg","userId":"17008209418971916367"},"user_tz":-120},"id":"TvCsOjHJhQWK","outputId":"395f2d6a-a921-4b93-a836-c5d35bc045ce","trusted":true},"cell_type":"code","source":"sizes = [len(data[data.restecg == 0]), len(data[data.restecg==1]), len(data[data.restecg==2])]\nlabels = ['Normal', 'ST-T wave abnormality', 'definite left ventricular hypertrophy by Estes criteria']\nplt.pie(x=sizes, labels=labels, explode=(0, 0, 0), autopct=\"%1.2f%%\", startangle=90,shadow=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"z4Y-Z69WezjP"},"cell_type":"markdown","source":"**THALACH (maximum heart rate achieved)**"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"colab_type":"code","executionInfo":{"elapsed":944,"status":"ok","timestamp":1554819972910,"user":{"displayName":"Daniel Kindischew","photoUrl":"https://lh5.googleusercontent.com/-TF6NGgM75H0/AAAAAAAAAAI/AAAAAAAAABk/PEX1UCOgi54/s64/photo.jpg","userId":"17008209418971916367"},"user_tz":-120},"id":"0jHTgp3pe15s","outputId":"2193d155-2a52-41d7-ad16-1472c50c0900","trusted":true},"cell_type":"code","source":"plt.hist([data.thalach[data.target==0], data.thalach[data.target==1]], bins=20,color=['blue', 'red'], stacked=True)\nplt.legend([\"Haven't Disease\", \"Have Disease\"])\nplt.title('Heart Disease Frequency for maximum heart rate achieved')\nplt.ylabel('Frequency')\nplt.xlabel('Heart rate')\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"PhskPLYcdG8P"},"cell_type":"markdown","source":"**Exang**"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":248},"colab_type":"code","executionInfo":{"elapsed":1545,"status":"ok","timestamp":1554819365696,"user":{"displayName":"Daniel Kindischew","photoUrl":"https://lh5.googleusercontent.com/-TF6NGgM75H0/AAAAAAAAAAI/AAAAAAAAABk/PEX1UCOgi54/s64/photo.jpg","userId":"17008209418971916367"},"user_tz":-120},"id":"Fpjg3HNndKkR","outputId":"8483601a-38b9-4a39-cea1-ca9c669b8bd5","trusted":true},"cell_type":"code","source":"sizes = [len(data[data.exang == 0]), len(data[data.exang==1])]\nlabels = ['No', 'Yes']\nplt.pie(x=sizes, labels=labels, explode=(0.1, 0), autopct=\"%1.2f%%\", startangle=90,shadow=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"BQdRc4ZwdR6U"},"cell_type":"markdown","source":"**Slope**"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":248},"colab_type":"code","executionInfo":{"elapsed":1418,"status":"ok","timestamp":1554819406103,"user":{"displayName":"Daniel Kindischew","photoUrl":"https://lh5.googleusercontent.com/-TF6NGgM75H0/AAAAAAAAAAI/AAAAAAAAABk/PEX1UCOgi54/s64/photo.jpg","userId":"17008209418971916367"},"user_tz":-120},"id":"tp606VsOdUii","outputId":"b0f4456f-a795-4b19-bc18-67af8c8c32f1","trusted":true},"cell_type":"code","source":"sizes = [len(data[data.slope == 0]), len(data[data.slope==1]), len(data[data.slope==2])]\nlabels = ['Upsloping', 'Flat', 'Downssloping']\nplt.pie(x=sizes, labels=labels, explode=(0, 0, 0), autopct=\"%1.2f%%\", startangle=90,shadow=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"VoSbcZBTgS8D"},"cell_type":"markdown","source":"**Thal (thalassemia)**"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"colab_type":"code","executionInfo":{"elapsed":1808,"status":"ok","timestamp":1554821373576,"user":{"displayName":"Daniel Kindischew","photoUrl":"https://lh5.googleusercontent.com/-TF6NGgM75H0/AAAAAAAAAAI/AAAAAAAAABk/PEX1UCOgi54/s64/photo.jpg","userId":"17008209418971916367"},"user_tz":-120},"id":"HPUa0XLHkvnZ","outputId":"588f958e-8902-4d92-99f7-028437bc598d","trusted":true},"cell_type":"code","source":"sns.countplot('thal', data=data)\nplt.title('Frequency for thal')\nplt.ylabel('Frequency')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Preprocessing**\n\n'cp', 'thal' and 'slope' are categorical variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"cp = pd.get_dummies(data['cp'], prefix = \"cp\", drop_first=True)\nthal = pd.get_dummies(data['thal'], prefix = \"thal\" , drop_first=True)\nslope = pd.get_dummies(data['slope'], prefix = \"slope\", drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Removing the first level."},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data = pd.concat([data, cp, thal, slope], axis=1)\nnew_data.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We don't need 'cp', 'thal', 'slope' columns so we will drop them"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data.drop(['cp', 'thal', 'slope'], axis=1, inplace=True)\nnew_data.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"removing target columns from dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = new_data.drop(['target'], axis=1)\ny = new_data.target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Normalize the data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = (X - X.min())/(X.max()-X.min())\nX.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split our Data. 80% - train, 20% - test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br>\n## <center>  <b> **Train** </b> </center>\n<br>"},{"metadata":{},"cell_type":"markdown","source":"**Logistic Regression**"},{"metadata":{},"cell_type":"markdown","source":"In statistics, the logistic model (or logit model) is a widely used statistical model that, in its basic form, uses a logistic function to model a binary dependent variable; many more complex extensions exist. In regression analysis, logistic regression (or logit regression) is estimating the parameters of a logistic model; it is a form of binomial regression. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(X_train, y_train)\nlr.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Setting parameters for GridSearchCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'penalty':['l1','l2'],\n         'C':[0.01,0.1,1,10,100],\n         'class_weight':['balanced',None]}\nlr_model = GridSearchCV(lr,param_grid=params,cv=10)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"lr_model.fit(X_train,y_train)\nlr_model.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(C=1, penalty='l2')\nlr.fit(X_train, y_train)\nlr.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, lr.predict(X_test))\nsns.heatmap(cm, annot=True)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Result (Logistic Regression) - 0.9016393442622951.\n\nOur model (Logistic Regression) is giving good result."},{"metadata":{},"cell_type":"markdown","source":"**K Nearest Neighbor**"},{"metadata":{},"cell_type":"markdown","source":"In pattern recognition, the k-nearest neighbors algorithm (k-NN) is a non-parametric method used for classification and regression. In both cases, the input consists of the k closest training examples in the feature space. The output depends on whether k-NN is used for classification or regression:\n\n* In k-NN classification, the output is a class membership. An object is classified by a plurality vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). If k = 1, then the object is simply assigned to the class of that single nearest neighbor.\n* In k-NN regression, the output is the property value for the object. This value is the average of the values of k nearest neighbors.\n\nk-NN is a type of instance-based learning, or lazy learning, where the function is only approximated locally and all computation is deferred until classification. The k-NN algorithm is among the simplest of all machine learning algorithms."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\nknn.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(1,11):\n    knn = KNeighborsClassifier()\n    knn.fit(X_train, y_train)\n    print(\"k : \",i ,\"score : \",knn.score(X_test, y_test), end=\"\\n\" )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion Matrix\ncm = confusion_matrix(y_test, knn.predict(X_test))\nsns.heatmap(cm, annot=True)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Result (K Nearest Neighbor) - 0.8688524590163934."},{"metadata":{},"cell_type":"markdown","source":"**Decision Tree Classifier**"},{"metadata":{},"cell_type":"markdown","source":"In computer science, Decision tree learning uses a decision tree (as a predictive model) to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). It is one of the predictive modeling approaches used in statistics, data mining and machine learning. Tree models where the target variable can take a discrete set of values are called classification trees; in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier(random_state=1)\ndt.fit(X_train, y_train)\ndt.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion Matrix\ncm = confusion_matrix(y_test, dt.predict(X_test))\nsns.heatmap(cm, annot=True)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Result (Decision Tree Classifier) - 0.8032786885245902."},{"metadata":{},"cell_type":"markdown","source":"**Gradient Boosting Classifier**"},{"metadata":{},"cell_type":"markdown","source":"Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees. It builds the model in a stage-wise fashion like other boosting methods do, and it generalizes them by allowing optimization of an arbitrary differentiable loss function."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\ngbc = GradientBoostingClassifier()\ngbc.fit(X_train, y_train)\ngbc.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion Matrix\ncm = confusion_matrix(y_test, gbc.predict(X_test))\nsns.heatmap(cm, annot=True)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Gaussian NB**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(X_train, y_train)\nnb.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion Matrix\ncm = confusion_matrix(y_test, nb.predict(X_test))\nsns.heatmap(cm, annot=True)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Random Forest Classifier**"},{"metadata":{},"cell_type":"markdown","source":"Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random decision forests correct for decision trees' habit of overfitting to their training set"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfor i in range(1, 20):\n    rfc = RandomForestClassifier(n_estimators=i)\n    rfc.fit(X_train, y_train)\n    print('estimators : ', i, \"score : \", rfc.score(X_test, y_test), end=\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(1, 10):\n    rfc = RandomForestClassifier(n_estimators=100, max_depth=i)\n    rfc.fit(X_train, y_train)\n    print('max_depth : ', i, \"score : \", rfc.score(X_test, y_test), end=\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier(n_estimators=100)\nrfc.fit(X_train, y_train)\nrfc.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion Matrix\ncm = confusion_matrix(y_test, rfc.predict(X_test))\nsns.heatmap(cm, annot=True)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Support Vector Machine**"},{"metadata":{},"cell_type":"markdown","source":"In machine learning, support-vector machines (SVMs, also support-vector networks) are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis. Given a set of training examples, each marked as belonging to one or the other of two categories, an SVM training algorithm builds a model that assigns new examples to one category or the other, making it a non-probabilistic binary linear classifier (although methods such as Platt scaling exist to use SVM in a probabilistic classification setting). A SVM model is a representation of the examples as points in space, mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible. New examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvc = SVC(kernel='linear')\nsvc.fit(X_train, y_train)\nsvc.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion Matrix\ncm = confusion_matrix(y_test, svc.predict(X_test))\nsns.heatmap(cm, annot=True)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**All Score**"},{"metadata":{},"cell_type":"markdown","source":"* Logistic Regression - 0.9016393442622951\n* K Nearest Neighbor - 0.8688524590163934\n* Decision Tree Classifier - 0.8032786885245902\n* Gradient Boosting Classifies - 0.8852459016393442\n* Gaussian NB - 0.9344262295081968\n* Random Forest Classifier - 0.9180327868852459\n* Support Vector Machine - 0.9016393442622951\n\nThe best option shows the Gaussian NB model"}],"metadata":{"colab":{"name":"cookbook-for-data-visualization.ipynb","provenance":[],"version":"0.3.2"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}