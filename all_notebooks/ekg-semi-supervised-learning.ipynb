{"cells":[{"metadata":{},"cell_type":"markdown","source":"<div>\n    <img src=\"https://storage.googleapis.com/kaggle-datasets-images/29414/37484/9a4417b65ea46ec36477358cbbf4bdd2/dataset-cover.jpg?t=2018-05-31-18-56-03\"/>\n</div>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from numpy import concatenate\nfrom numpy import hstack\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns; \nsns.set_theme()\nsns.set(rc={'figure.figsize':(11.7,8.27)})\n\nfrom sklearn.utils import shuffle\nfrom abc import abstractmethod\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.semi_supervised import LabelSpreading, LabelPropagation\n\nfrom warnings import simplefilter\nfrom sklearn.exceptions import ConvergenceWarning\nsimplefilter(\"ignore\", category=ConvergenceWarning)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:black; background:white; border:0.5 black dotted;\" role=\"tab\" aria-controls=\"home\"><center>Prepare Data</center></h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/heartbeat/'\n\ndf_abnormal = pd.read_csv(path + 'ptbdb_abnormal.csv', header=None)\ndf_normal = pd.read_csv(path + 'ptbdb_normal.csv', header=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"class HeartbeatDataset():\n    def __init__(self, path):\n        self.df_abnormal = pd.read_csv(path + 'ptbdb_abnormal.csv', header=None)\n        categories = list([1] * len(self.df_abnormal))\n        self.df_normal = pd.read_csv(path + 'ptbdb_normal.csv', header=None)\n        categories.extend(list([0] * len(self.df_normal)))\n        self.df = pd.concat([df_abnormal, df_normal])\n        self.df['labels'] = categories\n        self.df = shuffle(self.df)\n        \n    def get_features_labels(self, end):\n        features = self.df.values[:,:end]\n        labels = self.df.values[:,-1]\n        return features, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/heartbeat/'\n\nhds = HeartbeatDataset(path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Filter data using correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"correlations = hds.df[list(hds.df.columns)[:-1]].corr()\n\nsns.heatmap(correlations);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# select only the columns from 0 to 95 for highest correlation\ncorrelations = hds.df[list(hds.df.columns)[:95]].corr()\n\nsns.heatmap(correlations);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features, labels = hds.get_features_labels(95)\n\nX_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.25, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style=\"color:black; background:white; border:0.5 black dotted;\" role=\"tab\" aria-controls=\"home\"><center>Semi Supervised Learning</center></h2>"},{"metadata":{},"cell_type":"markdown","source":"## Definitions\n\n<b>Label propagation</b> : assigns labels to previously unlabeled data points. At the start of the algorithm, a (generally small) subset of the data points have labels (or classifications). These labels are propagated to the unlabeled points throughout the course of the algorithm.\n\n<b>LabelSpreading</b> : this model is similar to the basic Label Propagation algorithm, but uses affinity matrix based on the normalized graph Laplacian and soft clamping across the labels.\n"},{"metadata":{},"cell_type":"markdown","source":"## Train each model"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = list()\nmodels.append((\"LabelSpreading\", LabelSpreading(max_iter=100)))\nmodels.append((\"LabelPropagation\", LabelPropagation(max_iter=100)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for model in models:\n    model[1].fit(X_train, y_train)\n    yhat = model[1].predict(X_test)\n    accuracy = accuracy_score(y_test, yhat)\n    print('{:16s} Accuracy: {:.3f}'.format(model[0], accuracy))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Combine model using logistic regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_meta(models, X):\n    meta = list()\n    for model in models:\n        yhat = model[1].predict_proba(X)\n        meta.append(yhat)\n    return hstack(meta)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_train = get_meta(models, X_train)\nmeta_test = get_meta(models, X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_model = LogisticRegression(solver='liblinear')\nmeta_model.fit(meta_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yhat = meta_model.predict(meta_test)\naccuracy = accuracy_score(y_test, yhat)\nprint('Combined Accuracy: {:.3f}'.format(accuracy))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}