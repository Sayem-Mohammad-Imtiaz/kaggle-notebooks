{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\n\nimage_path = '/kaggle/input/kermany2018/oct2017/OCT2017 '\noct_csv_path = '/kaggle/input/oct-csv/'\noct_singan_path = '/kaggle/input/octsingan/'\ntrain_dir = image_path + \"/train/\"\nvalid_dir = image_path + \"/val/\"\ntest_dir = image_path + \"/test/\"","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:32:03.67782Z","iopub.execute_input":"2021-09-11T16:32:03.678294Z","iopub.status.idle":"2021-09-11T16:32:03.690441Z","shell.execute_reply.started":"2021-09-11T16:32:03.678187Z","shell.execute_reply":"2021-09-11T16:32:03.689628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = ['CNV', 'DME', 'DRUSEN', 'NORMAL']\ncols = [x.upper() for x in classes]\ndirs = [train_dir, valid_dir, test_dir]\nlabel = {0: 'CNV', 1: 'DME', 2: 'DRUSEN', 3: 'NORMAL'}\nIMG_SIZE = 224\n\n# if we should read the directory structre, if False then use the CSV files already saved\n# Once you generate the csv files you should probably download them and re-upload into kaggle and set this to FALSE\nREGEN = False ","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:32:03.692311Z","iopub.execute_input":"2021-09-11T16:32:03.693082Z","iopub.status.idle":"2021-09-11T16:32:03.699717Z","shell.execute_reply.started":"2021-09-11T16:32:03.693044Z","shell.execute_reply":"2021-09-11T16:32:03.698905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_df (path, classes=classes):\n  df = pd.DataFrame(columns=['FILENAME', 'CNV', 'DME', 'DRUSEN', 'NORMAL'])\n  for sub_dir in classes:\n    condition = {'NORMAL': 0, 'CNV': 0, 'DME':0, 'DRUSEN': 0}\n    files = os.listdir(path + sub_dir)\n    if (sub_dir== 'NORMAL'):\n      condition['NORMAL'] = 1\n    elif (sub_dir == 'CNV'):\n      condition['CNV'] = 1\n    elif (sub_dir == 'DME'):\n      condition['DME'] = 1\n    else:\n      condition['DRUSEN']= 1\n    for f in files:\n      df = df.append({'FILENAME': path +  sub_dir  + \"/\" + f, \n                      'NORMAL': condition['NORMAL'], \n                      'CNV': condition['CNV'],\n                      'DME': condition['DME'],\n                      'DRUSEN': condition['DRUSEN']}, ignore_index=True)\n  return df","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:32:03.701868Z","iopub.execute_input":"2021-09-11T16:32:03.702444Z","iopub.status.idle":"2021-09-11T16:32:03.71056Z","shell.execute_reply.started":"2021-09-11T16:32:03.702399Z","shell.execute_reply":"2021-09-11T16:32:03.709354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generting the DataFrames of the filenames\n# this is primarily used so we can sub-sample files easier for the different training strategies\nif (REGEN):\n  train_df = create_df(train_dir)\n  valid_df = create_df(valid_dir)\n  test_df = create_df(test_dir)\n  singan_df = create_df(oct_singan_path)\n  train_df.to_csv(\"train_data.csv\")\n  valid_df.to_csv(\"valid_data.csv\")\n  test_df.to_csv(\"test_data.csv\")\n  singan_df.to_csv(\"singan_data.csv\")\nelse:\n  train_df = pd.read_csv(oct_csv_path + \"train_data.csv\")\n  valid_df = pd.read_csv(oct_csv_path + \"valid_data.csv\")\n  test_df = pd.read_csv(oct_csv_path + \"test_data.csv\")\n  singan_df = pd.read_csv(oct_csv_path + \"singan_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:32:03.71245Z","iopub.execute_input":"2021-09-11T16:32:03.712825Z","iopub.status.idle":"2021-09-11T16:32:04.032738Z","shell.execute_reply.started":"2021-09-11T16:32:03.71279Z","shell.execute_reply":"2021-09-11T16:32:04.031831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (\"Training Data: \", train_df.shape)\nprint (\"Validation Data: \", valid_df.shape)\nprint (\"Test Data: \", test_df.shape)\nprint (\"SinGAN Data: \", singan_df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:32:04.034139Z","iopub.execute_input":"2021-09-11T16:32:04.034493Z","iopub.status.idle":"2021-09-11T16:32:04.043547Z","shell.execute_reply.started":"2021-09-11T16:32:04.034458Z","shell.execute_reply":"2021-09-11T16:32:04.041861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Printing out the # of samples for each subsample percentage \nprint (\"Trainig Data percentages:\")\nprint (\" 1% ==> \", int(.01 * train_df.shape[0]))\nprint (\" 5% ==> \", int(.05 * train_df.shape[0]))\nprint (\"10% ==> \", int(.1  * train_df.shape[0]))\nprint (\"25% ==> \", int(.25 * train_df.shape[0]))\nprint (\"50% ==> \", int(.5  * train_df.shape[0]))\nprint (\"75% ==> \", int(.75 * train_df.shape[0]))\nprint (\"90% ==> \", int(.9  * train_df.shape[0]))\nprint (\"98% ==> \", int(.98 * train_df.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:32:04.044916Z","iopub.execute_input":"2021-09-11T16:32:04.045544Z","iopub.status.idle":"2021-09-11T16:32:04.057996Z","shell.execute_reply.started":"2021-09-11T16:32:04.045506Z","shell.execute_reply":"2021-09-11T16:32:04.057019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"singan_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:32:04.05962Z","iopub.execute_input":"2021-09-11T16:32:04.06066Z","iopub.status.idle":"2021-09-11T16:32:04.084524Z","shell.execute_reply.started":"2021-09-11T16:32:04.060621Z","shell.execute_reply":"2021-09-11T16:32:04.083777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sampling 50% of the data\nsample = train_df.sample(frac=0.1, random_state=10, axis=0)\nsample = sample.append(singan_df, ignore_index=False)\nsample = sample.sample(frac=1, random_state=10, axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:32:04.086988Z","iopub.execute_input":"2021-09-11T16:32:04.087331Z","iopub.status.idle":"2021-09-11T16:32:04.100873Z","shell.execute_reply.started":"2021-09-11T16:32:04.087298Z","shell.execute_reply":"2021-09-11T16:32:04.10016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# determine class weights to feed into neural network during training\ndef get_classweight(df):\n  total = df.shape[0]\n  num_norm = df['NORMAL'].sum()\n  num_cnv = df['CNV'].sum()\n  num_dme = df['DME'].sum()\n  num_drusen = df['DRUSEN'].sum()\n  norm_weight = (1/num_norm) * (total/4)\n  cnv_weight = (1/num_cnv) * (total/4)\n  dme_weight = (1/num_dme) * (total/4)\n  drusen_weight = (1/num_drusen) * (total/4)\n  class_weight = {0 : cnv_weight, 1: dme_weight,\n                  2 : drusen_weight, 3: norm_weight}\n  return class_weight","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:32:04.103558Z","iopub.execute_input":"2021-09-11T16:32:04.10379Z","iopub.status.idle":"2021-09-11T16:32:04.11095Z","shell.execute_reply.started":"2021-09-11T16:32:04.103768Z","shell.execute_reply":"2021-09-11T16:32:04.110195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_weight = get_classweight(sample)\nclass_weight","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:32:04.11242Z","iopub.execute_input":"2021-09-11T16:32:04.112802Z","iopub.status.idle":"2021-09-11T16:32:04.126491Z","shell.execute_reply.started":"2021-09-11T16:32:04.112752Z","shell.execute_reply":"2021-09-11T16:32:04.125624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow_addons as tfa\nimport tensorflow.keras.applications as app\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:32:04.129483Z","iopub.execute_input":"2021-09-11T16:32:04.129751Z","iopub.status.idle":"2021-09-11T16:32:08.795848Z","shell.execute_reply.started":"2021-09-11T16:32:04.129728Z","shell.execute_reply":"2021-09-11T16:32:08.795027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_image_datagen = ImageDataGenerator(rotation_range=90, width_shift_range=[-.1,.1], height_shift_range=[-.1,.1],\n                                         shear_range=0.25, zoom_range=0.3, horizontal_flip=True,\n                                         vertical_flip=True, rescale = 1./255., validation_split=0.1)\n\n# Setting the imgages to come from the dataframe where we specify the filenames and columns to use for \"labels\"\ntrain_imgs = train_image_datagen.flow_from_dataframe(sample, directory=None, x_col='FILENAME', y_col=cols, subset=\"training\",\n                                        class_mode=\"raw\", target_size=(IMG_SIZE,IMG_SIZE), batch_size=32, seed=10)\nvalid_imgs = train_image_datagen.flow_from_dataframe(sample, directory=None, x_col='FILENAME', y_col=cols, subset=\"validation\",\n                                        class_mode=\"raw\", target_size=(IMG_SIZE,IMG_SIZE), batch_size=32, seed=10)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:32:08.799071Z","iopub.execute_input":"2021-09-11T16:32:08.799347Z","iopub.status.idle":"2021-09-11T16:33:01.148558Z","shell.execute_reply.started":"2021-09-11T16:32:08.799322Z","shell.execute_reply":"2021-09-11T16:33:01.147156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating the model based on Xception Network\ninput_layer = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\nbase_model = app.xception.Xception(include_top=False, weights=\"imagenet\", input_shape=(IMG_SIZE,IMG_SIZE,3))\nbase_model.trainable = True\n\nx = base_model(input_layer)\nx = keras.layers.GlobalAveragePooling2D()(x)\noutput = keras.layers.Dense(4, activation=\"softmax\")(x)\n\nmodel = keras.Model(inputs=input_layer, outputs=output)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:33:01.149877Z","iopub.execute_input":"2021-09-11T16:33:01.150226Z","iopub.status.idle":"2021-09-11T16:33:05.29269Z","shell.execute_reply.started":"2021-09-11T16:33:01.150188Z","shell.execute_reply":"2021-09-11T16:33:05.291855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This code did not work, it caused I/O Error 5:\n# model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics='accuracy')\nmodel.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:33:05.293908Z","iopub.execute_input":"2021-09-11T16:33:05.294236Z","iopub.status.idle":"2021-09-11T16:33:05.312396Z","shell.execute_reply.started":"2021-09-11T16:33:05.294207Z","shell.execute_reply":"2021-09-11T16:33:05.311593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a checkpoint to save the best model so that we can reload it once training is complete\ncheckpoint_cb = keras.callbacks.ModelCheckpoint(\"oct_singan.h5\", save_best_only=True)\n# Adding an an early stop callback to avoid overfitting in case the model is not improving after 5 consescutive epochs\nearlystop_cb = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:33:05.313687Z","iopub.execute_input":"2021-09-11T16:33:05.314031Z","iopub.status.idle":"2021-09-11T16:33:05.319279Z","shell.execute_reply.started":"2021-09-11T16:33:05.313996Z","shell.execute_reply":"2021-09-11T16:33:05.318343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_imgs,  epochs=30, verbose=1, validation_data=valid_imgs, \n                    class_weight=class_weight, callbacks=[checkpoint_cb, earlystop_cb])","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:41:20.135218Z","iopub.execute_input":"2021-09-11T16:41:20.135547Z","iopub.status.idle":"2021-09-11T18:33:53.393508Z","shell.execute_reply.started":"2021-09-11T16:41:20.135516Z","shell.execute_reply":"2021-09-11T18:33:53.392558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image_datagen = ImageDataGenerator( rescale = 1./255.)\n\ntest_imgs = test_image_datagen.flow_from_dataframe(test_df, directory=None, x_col='FILENAME', y_col=cols, validate_filenames=True,\n                                        class_mode=\"raw\", target_size=(224,224), batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T18:33:53.394884Z","iopub.execute_input":"2021-09-11T18:33:53.395232Z","iopub.status.idle":"2021-09-11T18:33:53.773977Z","shell.execute_reply.started":"2021-09-11T18:33:53.395195Z","shell.execute_reply":"2021-09-11T18:33:53.773046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights(\"oct_singan.h5\")\nmodel.evaluate(test_imgs)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T18:33:53.788068Z","iopub.execute_input":"2021-09-11T18:33:53.78843Z","iopub.status.idle":"2021-09-11T18:34:03.761741Z","shell.execute_reply.started":"2021-09-11T18:33:53.788394Z","shell.execute_reply":"2021-09-11T18:34:03.760968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plotiting training results\nplt.figure(figsize=(32,12))\nplt.subplot(1,3,1)\nplt.plot(range(len(history.history[\"loss\"])), history.history['loss'], label=\"loss\")\nplt.plot(range(len(history.history[\"loss\"])), history.history['val_loss'], label=\"val_loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.subplot(1,3,2)\nplt.plot(range(len(history.history[\"loss\"])), history.history[\"accuracy\"], label=\"accuracy\")\nplt.plot(range(len(history.history[\"loss\"])), history.history[\"val_accuracy\"], label=\"val_accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.subplot(1,3,3)\nplt.plot(range(len(history.history[\"loss\"])), history.history['f1_score'], label=\"loss\")\nplt.plot(range(len(history.history[\"loss\"])), history.history['val_f1_score'], label=\"val_loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T16:40:34.183148Z","iopub.status.idle":"2021-09-11T16:40:34.183926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.saved_model.save(model, 'XceptionSinGANOCT')\n\n# Intialize the TFLite converter to load the SavedModel\nconverter = tf.lite.TFLiteConverter.from_saved_model('XceptionSinGANOCT')# YOUR CODE HERE\n\n# Set the optimization strategy for 'size' in the converter \nconverter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE] # YOUR CODE HERE]\n\n# Use the tool to finally convert the model\ntflite_model = converter.convert()\n\ntflite_model_file = 'XceptionSinGANOCT.tflite'\n\nwith open(tflite_model_file, \"wb\") as f:\n    f.write(tflite_model)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T18:34:16.293532Z","iopub.execute_input":"2021-09-11T18:34:16.293876Z","iopub.status.idle":"2021-09-11T18:34:49.541693Z","shell.execute_reply.started":"2021-09-11T18:34:16.293845Z","shell.execute_reply":"2021-09-11T18:34:49.540752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}