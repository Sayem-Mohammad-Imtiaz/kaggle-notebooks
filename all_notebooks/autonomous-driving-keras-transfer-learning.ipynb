{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import Dependencies"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from __future__ import division\nimport random,pickle,csv,cv2,os,scipy,pickle,warnings,matplotlib\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nfrom scipy.stats import norm,skew\nfrom itertools import islice\n\nimport keras.backend as K\nfrom keras.callbacks import History\nfrom keras.layers import Dense,Flatten,Dropout,Concatenate,GlobalAveragePooling2D,Lambda,ZeroPadding2D,GlobalMaxPooling2D\nfrom keras.layers import SeparableConv2D,BatchNormalization,MaxPooling2D,Conv2D\nfrom keras.applications.mobilenet_v2 import MobileNetV2\nfrom keras.utils import print_summary\nfrom keras.models import Sequential\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,CSVLogger,ReduceLROnPlateau,LearningRateScheduler\nfrom keras.optimizers import Adam,SGD\nfrom keras import applications\nfrom keras.utils.vis_utils import plot_model\n\nprint(os.listdir('../input/self driving car training data/data'))\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Helper Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_final_history(history):\n    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n    ax[0].set_title('loss')\n    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n    ax[1].set_title('acc')\n    ax[1].plot(history.epoch, history.history[\"acc\"], label=\"Train acc\")\n    ax[1].plot(history.epoch, history.history[\"val_acc\"], label=\"Validation acc\")\n    ax[0].legend()\n    ax[1].legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def image_preprocessing(img):\n    resized_image = cv2.resize((cv2.cvtColor(img,cv2.COLOR_RGB2HSV))[:,:,1],(40,40))\n    return resized_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_training(delta):\n    logs = []\n    features = []\n    labels = []\n    with open(labels_file,'rt') as f:\n        reader = csv.reader(f)\n        for line in reader:\n            logs.append(line)\n        log_labels = logs.pop(0)\n        \n    for i in range(len(logs)):\n        for j in range(3):\n            img_path = logs[i][j]\n            img_path = features_directory + 'IMG' + (img_path.split('IMG')[1]).strip()\n            img = plt.imread(img_path)\n            features.append(image_preprocessing(img))\n            \n            if j == 0:\n                labels.append(float(logs[i][3]))\n            elif j == 1:\n                labels.append(float(logs[i][3]) + delta)\n            else:\n                labels.append(float(logs[i][3]) - delta)\n    return features,labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def loadFromPickle():\n    with open('features','rb') as f:\n        features = np.array(pickle.load(f))\n    with open('labels','rb') as f:\n        labels = np.array(pickle.load(f))\n    return features,labels\n\ndef augmentData(features,labels):\n    features = np.append(features,features[:,:,::-1],axis=0)\n    labels = np.append(labels,-labels,axis=0)\n    return features,labels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load in the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"features_directory = '../input/self driving car training data/data/'\nlabels_file = '../input/self driving car training data/data/driving_log.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"delta = 0.2\nfeatures,labels = load_training(delta)\n\nfeatures = np.array(features).astype('float32')\nlabels = np.array(labels).astype('float32')\n\nwith open('features','wb') as f:\n    pickle.dump(features,f,protocol=4)\nwith open('labels','wb') as f:\n    pickle.dump(labels,f,protocol=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pan = pd.Panel(features)\ndf = pan.swapaxes(1,2).to_frame()\ndf.index = df.index.droplevel('major')\ndf.index = df.index+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features,labels = loadFromPickle()\nfeatures,labels = shuffle(features,labels)\n\nx_train,x_val,y_train,y_val = train_test_split(features,labels,random_state=42,test_size=0.2)\n\nx_train = x_train.reshape(x_train.shape[0],40,40,1)\nx_val = x_val.reshape(x_val.shape[0],40,40,1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create The Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = MobileNetV2(include_top=False,weights=None,input_shape=(40,40,1))\n\nfor layer in base_model.layers:\n    layer.trainable = False\n    \nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.summary()\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Callbacks"},{"metadata":{"trusted":true},"cell_type":"code","source":"#-------Callbacks-------------#\nbest_model_weights = './base.model'\ncheckpoint = ModelCheckpoint(\n    best_model_weights,\n    monitor='val_loss',\n    verbose=1,\n    save_best_only=True,\n    mode='min',\n    save_weights_only=False,\n    period=1\n)\nearlystop = EarlyStopping(\n    monitor='val_loss',\n    min_delta=0.001,\n    patience=10,\n    verbose=1,\n    mode='auto'\n)\ntensorboard = TensorBoard(\n    log_dir = './logs',\n    histogram_freq=0,\n    batch_size=16,\n    write_graph=True,\n    write_grads=True,\n    write_images=False,\n)\n\ncsvlogger = CSVLogger(\n    filename= \"training_csv.log\",\n    separator = \",\",\n    append = False\n)\n\n#lrsched = LearningRateScheduler(step_decay,verbose=1)\n\nreduce = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience=10,\n    verbose=1, \n    mode='auto',\n    cooldown=1 \n)\n\ncallbacks = [checkpoint,tensorboard,csvlogger,reduce]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Now we train the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = SGD(lr=1e-4,momentum=0.99)\nopt1 = Adam(lr=1e-3)\n\nmodel.compile(\n    loss='binary_crossentropy',\n    optimizer='rmsprop',\n    metrics=['accuracy']\n)\n    \nhistory = model.fit(\n    x_train,\n    y_train,\n    validation_data=(x_val,y_val),\n    epochs = 50, \n    verbose = 1,\n    callbacks=callbacks,\n    batch_size = 256\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualize the training and save the weights and json file"},{"metadata":{"trusted":true},"cell_type":"code","source":"show_final_history(history)\nmodel.load_weights(best_model_weights)\n\nmodel_json = model.to_json()\nwith open(\"model.json\",\"w\") as json_file:\n    json_file.write(model_json)\n    \nmodel.save(\"model.h5\")\nprint(\"Weights Saved\")\nprint(\"JSON Saved\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TensorBoard"},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n!unzip ngrok-stable-linux-amd64.zip\nLOG_DIR = './logs' # Here you have to put your log directory\nget_ipython().system_raw(\n    'tensorboard --logdir {} --host 0.0.0.0 --port 8080 &'\n    .format(LOG_DIR)\n)\nget_ipython().system_raw('./ngrok http 8080 &')\n! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}