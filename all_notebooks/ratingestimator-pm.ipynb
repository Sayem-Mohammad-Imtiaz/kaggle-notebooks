{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h3>REVIEWS RATING ESTIMATOR</h3>"},{"metadata":{},"cell_type":"markdown","source":"<p> This is a project that estimates ratings based on customer reviews.The purpose of such an application is to help identify ratings for reviews where the user ratings are missing. This rating could be used to further analyze the success rate of your product.</p><br>\n<p>The dataset used for this project is a boardgamegeek review dataset available at Kaggle here: \n    <a href=\"https://www.kaggle.com/jvanelteren/boardgamegeek-reviews\">Dataset</a> This model will also work for other kinds of dataset for e.g. Movie review dataset for IMDB, Restaurant review dataset etc. The various steps involved in the creation of the model are described in detail over the ipynb.</p>"},{"metadata":{},"cell_type":"markdown","source":"<h3> Reading the data </h3>\n<p>The first step is to read the data and convert it to a pandas dataframe</p>"},{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('D:/UTA/Fall-2020/DM/TermProject/archive/bgg-15m-reviews.csv')\ndel df['Unnamed: 0']\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>Dropping rows that have missing comments(NaN)</h4>\n\n<p>This step is essential because we have to get a dataset that contains reviews in order to train our model. So removal of ratings without review is executed.</p>"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Dropping rows with missing reviews \ntemp_dataset = df.dropna().reset_index(drop=True)\ntemp_dataset\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>Use the 'Reviews' and the corresponding 'Rating' columns as the dataset</p>"},{"metadata":{"trusted":false},"cell_type":"code","source":"dataset = temp_dataset[['comment', 'rating']].copy()\ndataset.columns = ['Reviews','Rating']\ndataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3> PREPROCESSING </h3>\n\n<p>For preprocessing and cleaning the data in the reviews column, NLTK libraries are used for removing punctuations, stopwords, numbers and lemmatization of the filtered reviews.</p>"},{"metadata":{"trusted":false},"cell_type":"code","source":"import nltk\nimport re\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.corpus import stopwords\n\ndef sentence_tokenize(text):\n    sentences = nltk.sent_tokenize(text)\n    return sentences\n    \n\ndef remove_html_tags(text):\n    pattern = re.compile('<.*?>')\n    new_text = re.sub(pattern, '', text)\n    return new_text\n\ndef remove_numbers(text):\n    text = re.sub('\\w*\\d\\w*', \"\",text)\n    return text\n\ndef word_tokenize(text):\n    #remove punctuations\n    tokeniser = nltk.tokenize.RegexpTokenizer(r'\\w+')\n    tokens = (tokeniser.tokenize(text))\n    return tokens\n    \ndef lemmatization(text):\n    lemmatiser = WordNetLemmatizer()\n    lemmas = [lemmatiser.lemmatize(token, pos='v') for token in text]\n    return lemmas\n    \ndef remove_stopwords(text):\n    stopwords = nltk.corpus.stopwords.words('english')\n    new_text = [word for word in text if word not in stopwords]\n    return new_text\n\ndef list_to_string(str2):  \n    str1 = \" \"   \n    return (str1.join(str2)) \n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>At this step changing the words in the reviews to lowercase, removing of certain patterns and numbers is performed</h4>"},{"metadata":{"trusted":false},"cell_type":"code","source":"lower_case_dataset = pd.DataFrame(dataset.Reviews.apply(lambda x: x.lower()))\nreviews_without_htmltags_df =  pd.DataFrame(lower_case_dataset.Reviews.apply(lambda x: remove_html_tags(x)))\nreviews_without_htmltags_df =  pd.DataFrame(reviews_without_htmltags_df.Reviews.apply(lambda x: remove_numbers(x)))\nreviews_without_htmltags_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>Here sentence tokenization,word tokenization and removal of stop words is performed</h4>"},{"metadata":{"trusted":false},"cell_type":"code","source":"reviews_without_htmltags_df['Reviews_sentence_tokenized'] = reviews_without_htmltags_df['Reviews']\nreviews_without_htmltags_df['Reviews_sentence_tokenized'] = reviews_without_htmltags_df['Reviews'].apply(lambda x: sentence_tokenize(x))\n\n#word tokenizing\nreviews_without_htmltags_df['Reviews_word_tokenized'] = reviews_without_htmltags_df['Reviews']\nreviews_without_htmltags_df['Reviews_word_tokenized'] = reviews_without_htmltags_df['Reviews'].apply(lambda x: word_tokenize(x))\n\n#removing stop words\nreviews_without_htmltags_df['Reviews_without_stopwords'] = reviews_without_htmltags_df['Reviews_word_tokenized'].apply(lambda x: remove_stopwords(x))\nreviews_without_htmltags_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>Lemmatization</h4>\n<p>Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma . If confronted with the token saw, stemming might return just s, whereas lemmatization would attempt to return either see or saw depending on whether the use of the token was as a verb or a noun. The two may also differ in that stemming most commonly collapses derivationally related words, whereas lemmatization commonly only collapses the different inflectional forms of a lemma. </p>"},{"metadata":{"trusted":false},"cell_type":"code","source":"#performing lemmatization as a preprocessing step\nreviews_lemmatized = pd.DataFrame(reviews_without_htmltags_df['Reviews_without_stopwords'].apply(lambda x: lemmatization(x)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"reviews_lemmatized.columns = ['Reviews']\nreviews_lemmatized","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dataset['Reviews'] = reviews_lemmatized['Reviews'].apply(lambda x: list_to_string(x))\n#dataset['Reviews'] = reviews_lemmatized","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>Processed Dataset</h4>\n<p>The ratings are rounded to the nearest integer to get a rating in the scale of 1-10. This cleaned and pre-processed dataset is then used for training and testing our algorithm</p>"},{"metadata":{"trusted":false},"cell_type":"code","source":"import numpy as np\n#Round the ratings to the nearest integer\nnewdf = dataset['Rating'].astype(np.int64)\ndataset['Rating'] = newdf\n#final dataset with pre-processed reviews\ndataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3> Splitting dataset into train and test </h3>\n<p>We split the dataset in the ratio 4:1 to get the training and the test dataset respectively</p>"},{"metadata":{"trusted":false},"cell_type":"code","source":"import numpy as np\n\ntrain_df,test_df = np.split(dataset, [int(.8*len(dataset))])\nprint(\"training: \",train_df.shape)\nprint(\"test: \",test_df.shape)\nY_train = train_df['Rating'].tolist() #ratings for the train dataset\nY_test = test_df['Rating'].tolist() # ratings for the test dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# from sklearn.feature_extraction.text import TfidfVectorizer\n# corpus = train_df['Reviews'].tolist()\n# vectorizer = TfidfVectorizer(analyzer = 'word',use_idf = True)\n# X = vectorizer.fit_transform(corpus)\n# print(vectorizer.get_feature_names())\n# print(X.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>CREATING DOCUMENT MATRIX</h3>\n<p>In order to get a vocabulary of words with their frequencies we need to utilize sklearn's <a href = \"https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">CountVectorizer</a>. This gives us a dictionary of words with their corresponding frequencies in each document in vector form. We need the output in a matrix form in order to pass it as an input to our models. </p>\n<p>Here the max_features is set to 5000 to get a better accuracy and ignore the less frequent words</p>\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n# Create an instance of CountfVectorizer\nvectoriser = CountVectorizer(max_features=5000) # max features is set to 5000 for better accuracy\n# Fit to the data and transform to feature matrix\nX_train = vectoriser.fit_transform(train_df['Reviews'])\nX_test = vectoriser.transform(test_df['Reviews'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>This is the input of our model in matrix form.</h4>"},{"metadata":{"trusted":false},"cell_type":"code","source":"print(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3> NAIVE BAYES MODEL IMPLEMENTATION</h3>\n<p>This classifier has two probabilities: P(class) which is the probability an input will produce a certain class, and P(input_condition|class) is the probability an input feature has a certain value, given the class. Otherwise, default probability is 0. Multinomial Na√Øve bayes implements the naive Bayes algorithm for multinomially distributed data, and is one of the two classic naive Bayes variants used in text classification (where the data are typically represented as word vector counts</p>\n<p>The <a href = \"https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\"> multinomial naive bayes model</a> provided by sklearn is implemented here. At first the model was executed with default alpha= 1. After performing hyperparameter tuning the alpha is updated to get the best accuracy 27.3%.</p>"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nclf = MultinomialNB(alpha = 1.0e-10)\nclf.fit(X_train, Y_train)\n\nY_pred = clf.predict(X_test)#testing the predictions for test dataset once model has been trained\ntest_df['Predictions'] = Y_pred\nprint(test_df)\naccuracy = clf.score(X_test, np.array(Y_test))\nprint(\"Accuracy of test data predictions: \",accuracy*100,\"%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>PERFORMANCE EVALUATION </h3>\n<p>For evaluation of the algorithm: accuracy and mean squared error is used as performance measure. Since this is a classification for 10 different classes, the accuracy can be low. So the mean squared error will give us idea how close to the original rating was our predicted rating.</p>"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import accuracy_score\nimport numpy as np\nY_true = np.array(Y_test)\nmse = mean_squared_error(Y_true, Y_pred)\nprint(\"Accuracy:\",accuracy_score(Y_true, Y_pred)*100,\"%\")\nprint(\"Mean Squared error:\",mse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3> HYPERPARAMETER TUNING </h3>\n<p>Hyperparameter tuning is done on the smoothing parameter alpha for Multinomial Naive Bayes. The best accuracy obtained against the best alpha value is then used in training the final model.5 fold cross validation is performed and the best accuracy obtained can be seen as 30.9% for this model.For this process sklearn GridSearchCV method is used.</p>\n<p>Best results are obtained for alpha=0.0 but recommended alpha value is 1.0e-10 so that is used for training the algorithm</p>"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nparams = {'alpha': np.array(np.linspace(0,1,100))}\nmultinomial_nb_grid = GridSearchCV(MultinomialNB(), param_grid=params, n_jobs=3, cv=5, verbose=5,scoring='accuracy')\nmultinomial_nb_grid.fit(X_train, Y_train)\nprint('Train Accuracy : %.3f'%multinomial_nb_grid.best_estimator_.score(X_train, Y_train))\nprint('Test Accuracy : %.3f'%multinomial_nb_grid.best_estimator_.score(X_test, Y_true))\nprint('Best Accuracy Through Grid Search : %.3f'%multinomial_nb_grid.best_score_)\nprint('Best Parameters : ',multinomial_nb_grid.best_params_)\nresults_NB = pd.DataFrame(multinomial_nb_grid.cv_results_['params'])\nresults_NB['test_score'] = multinomial_nb_grid.cv_results_['mean_test_score']\nresults_NB","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>Hyperparameter tuning plot</h4>"},{"metadata":{"trusted":false},"cell_type":"code","source":"#ind = params['alpha'].index(multinomial_nb_grid.best_params_['alpha'])\nind = np.where(params['alpha'] == multinomial_nb_grid.best_params_['alpha'])\nprint(ind)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nplt.rcParams[\"figure.figsize\"] = (15,7)\n\nfig, ax = plt.subplots(1) \nax.plot(results_NB['alpha'], results_NB['test_score'],'ro-')\nax.set_title('Hyperparameter Tuning')\nax.set(xlabel='Alpha', ylabel='Accuracy')\nax.set_xticks(ind)\nax.set_xticklabels([\"Min\"])\nplt.legend(loc=\"upper right\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# from sklearn import svm\n# clf = svm.SVC()\n# clf.fit(X_train, train_df['Rating'])\n# accuracy = clf.score(X_test, y)\n# print(accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Rating estimation for a sample review</h3>"},{"metadata":{"trusted":false},"cell_type":"code","source":"review = input(\"Enter a review:\")\nX_test = vectoriser.transform([review])\npred = clf.predict(X_test)\nprint(\"The estimated rating is: \", str(pred[0]))\nprint(clf.predict_proba(vectoriser.transform([review])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Training with the complete dataset</h3>\n<p>Now that we have a hyper parameter to get the best results the entire dataset is used to train the model to estimate ratings in the application for best results</p>"},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train_final = vectoriser.fit_transform(dataset['Reviews'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"clf = MultinomialNB(alpha = 1.0e-10)\nclf.fit(X_train_final, dataset['Rating'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Exporting vectorizer and model to use in deployment server</h3>\n<p>Pickle is used to save our model to be used externally. The mentioned files are used in pythonanywhere along with the deployed application.</p>"},{"metadata":{"trusted":false},"cell_type":"code","source":"import pickle\npickle.dump(clf, open('D:/UTA/Fall-2020/DM/TermProject/NaiveBayesClassifier', 'wb'))\nwith open('D:/UTA/Fall-2020/DM/TermProject/Vectorizer', 'wb') as fin:\n        pickle.dump(vectoriser, fin)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Challenges faced</h3>\n\n - Due to large dataset model execution time was very high so could not implement SVM for the entire dataset. \n - Dataset had missing values, reduced the dataset size by removing rows with NaN reviews.\n - The pre-processing step was removed after it was observed that the accuracy is improved by 1% without pre-processing like lemmatization and stop words removal."},{"metadata":{},"cell_type":"markdown","source":"<h3>References</h3>\n\n - Sklearn documentation: [https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n - [https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)\n - [https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/](https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/)\n\n<p>I did not use any references for the model implementation. Just followed official documentation above and process followed in assignment 3.</p>"},{"metadata":{},"cell_type":"markdown","source":"<h3>Links</h3>\n\n - Blog post : https://pxm5568.uta.cloud/img/Maitreyee_02.html \n - Working model is deployed at: [http://pragnyam.pythonanywhere.com/](http://pragnyam.pythonanywhere.com/ )\n - GitHub link : [https://github.com/Pragnyashree/RatingEstimator](https://github.com/Pragnyashree/RatingEstimator)\n  "},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}