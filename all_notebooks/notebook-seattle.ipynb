{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#usefulcols=['OSEBuildingID','BuildingType','PrimaryPropertyType','PropertyName','YearBuilt','ENERGYSTARScore','SiteEnergyUse(kBtu)','TotalGHGEmissions']\ndata2016= pd.read_csv('/kaggle/input/sea-building-energy-benchmarking/2016-building-energy-benchmarking.csv')\ndata2016","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#usefulcols_=['OSEBuildingID','BuildingType','PrimaryPropertyType','PropertyName','YearBuilt','ENERGYSTARScore','SiteEnergyUse(kBtu)','GHGEmissions(MetricTonsCO2e)']\ndata2015= pd.read_csv('/kaggle/input/sea-building-energy-benchmarking/2015-building-energy-benchmarking.csv')\ndata2015","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cleaning Data**\n\nFirst let us find unique columns. Then we will rename columns in both 2015 and 2016 datasets, so all columns match. Unnecessary or empty columns will be removed."},{"metadata":{"trusted":true},"cell_type":"code","source":"data2015.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2016.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"column_2015= set(data2015.columns)\ncolumn_2016=set(data2016.columns)\ncommon_columns= column_2015.intersection(column_2016)\nunique_2015= column_2015.difference(common_columns)\nunique_2015","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_2016= column_2016.difference(common_columns)\nunique_2016","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique2015df= data2015[list(unique_2015)]\nunique2015df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique2016df= data2016[list(unique_2016)]\nunique2016df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique2015df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique2016df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique2016df['Comments'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique2015df['Comment'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop comments columns in both datasets as it is not useful in our analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_2015_updated=data2015.copy()\ndata_2015_updated.drop('Comment', axis=1,inplace=True)\n\ndata_2016_updated=data2016.copy()\ndata_2016_updated.drop('Comments', axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_2015_updated.rename({'Zip Codes': 'ZipCode'}, axis=1, inplace=True)\ndata_2015_updated['ZipCode']=data_2015_updated['ZipCode'].astype('object')\ndata_2016_updated['ZipCode']=data_2016_updated['ZipCode'].astype('object')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import ast\n\nl=[]\nfor row in data_2015_updated['Location']:\n    a=ast.literal_eval(row)\n    l.append(a['latitude'])\n\ndata_2015_updated['Latitude']=l\n\nl1=[]\nfor row in data_2015_updated['Location']:\n    a=ast.literal_eval(row)\n    l1.append(a['longitude'])\n\ndata_2015_updated['Longitude']=l1\n\ndata_2015_updated.drop('Location', axis=1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Extract latitude, longitude, address.\nRemove other columns which are nt useful for our case."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_2015_updated.drop(['OtherFuelUse(kBtu)','2010 Census Tracts','SPD Beats','City Council Districts','Seattle Police Department Micro Community Policing Plan Areas'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_2016_updated.drop(['City','Address','State'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#make the CHGEmissions column name same in both dataframes\ndata_2015_updated.rename({'GHGEmissions(MetricTonsCO2e)':'TotalGHGEmissions', 'GHGEmissionsIntensity(kgCO2e/ft2)': 'GHGEmissionsIntensity'}, axis=1, inplace=True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"column_2015_updated= set(data_2015_updated.columns)\ncolumn_2016_updated=set(data_2016_updated.columns)\ncommon_columns= column_2015_updated.intersection(column_2016_updated)\nunique_2015_updated= column_2015_updated.difference(common_columns)\nunique_2015_updated","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_2016_updated= column_2016_updated.difference(common_columns)\nunique_2016_updated","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No unique columns remain in the datasets. Now we can combine them"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_2015_updated.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_2016_updated.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Making datatypes same in both datasets for correct combination"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_2015_updated[['Latitude', 'Longitude', 'NumberofBuildings']].astype(float)\ndata_2016_updated['NumberofFloors'].astype(float)\ndata_2015_updated.drop('DefaultData', axis=1, inplace=True)\ndata_2016_updated.drop('DefaultData', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bldg_data=pd.concat([data_2015_updated, data_2016_updated], ignore_index=True)\nbldg_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can work with one dataset bldg_data"},{"metadata":{"trusted":true},"cell_type":"code","source":"bldg_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets find number of nan values in each column\nwith pd.option_context('display.max_rows', None, 'display.max_columns', None):  # display full series\n    print(bldg_data.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#There are a few columns which have a large number of missing values (>1000). Let us drop them \n\nbldg_data.dropna(axis=1, thresh=5000, inplace=True)                             #require atleast 5000 non NaN values\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # display full series\n    print(bldg_data.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Univariate Analysis**\nSimple univariate analysis will help us fill missing items in the dataset and also give us basic information about various columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_theme()\nsns.displot(bldg_data, x='ENERGYSTARScore', binwidth=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsns.displot(bldg_data, x='ENERGYSTARScore', hue='BuildingType', element=\"step\", palette='bright', height=6, aspect=1.5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.displot(bldg_data, x='BuildingType', aspect=3.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can observe that distribution of EnergyStar Score varies according to building type. So we can fill NaN values using building type as a parameter. "},{"metadata":{"trusted":true},"cell_type":"code","source":"bldg_data['BuildingType'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#columns will be filled with mean values for NaN locations\n\nbldg_data.fillna({'ENERGYSTARScore': bldg_data.groupby('BuildingType')['ENERGYSTARScore'].transform('mean')},\n                inplace=True)\nbldg_data['ENERGYSTARScore'].fillna(method='ffill', inplace=True)\nbldg_data.fillna({'TotalGHGEmissions': bldg_data.groupby('BuildingType')['TotalGHGEmissions'].transform('mean')},\n                inplace=True)\n\nbldg_data.fillna({'Electricity(kWh)': bldg_data.groupby('BuildingType')['Electricity(kWh)'].transform('mean')},\n                inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observing distribution of other important factors-"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.displot(bldg_data, x='Electricity(kWh)', aspect=4)\nplt.xlim(0,10000000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that most buildings have electricity consumption under 2X10^6 kWh."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.displot(bldg_data, x='GHGEmissionsIntensity')\nplt.xlim(0,10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(bldg_data['ENERGYSTARScore'], bldg_data['Electricity(kWh)'], 'go')\nplt.ylim(0, 50000000)\nplt.title('Energystar vs Electricity consumption')\nplt.xlabel('Energystar score')\nplt.ylabel('Electricity consumption in kWh')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(y='Electricity(kBtu)' ,x='ENERGYSTARScore',  data=bldg_data, line_kws={'color':'red'})\nplt.ylim(0,50000000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bldg_data=bldg_data[bldg_data['Electricity(kWh)']<50000000]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(x='ENERGYSTARScore' ,y='TotalGHGEmissions',  data=bldg_data, line_kws={'color':'red'})\nplt.ylim(0,2500)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nOn increasing electricity consumption or GHG Emissions, Energystar score decreases\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(y='Electricity(kWh)' ,x='TotalGHGEmissions',  data=bldg_data, line_kws={'color':'red'})\nplt.xlim(0, 4000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Power consumption clearly increases on inreasing GHG Emissions."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(x='NumberofFloors', y='Electricity(kWh)', data=bldg_data)\nplt.title('No. of floors vs Electricity consumption')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(x='NumberofFloors', y='TotalGHGEmissions', data=bldg_data)\nplt.title('No. of floors vs GHG Emissions')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Both emissions and electricity consumption increase with an increase in number of floors in buildings. Thus this factor can be used in prediction of electricity and emission."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Since neighborhood names were in uppercase in 2015 dataset and lowercase in 2016 one, we will make all neigborhood names uppercase\nbldg_data.replace({'Central':'CENTRAL',\n                  'North': 'NORTH',\n                  'Delridge':'DELRIDGE',\n                  'Northwest': 'NORTHWEST'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nax=sns.countplot(data=bldg_data, x='Neighborhood')\nax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\nplt.tight_layout()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='Neighborhood', y='Electricity(kBtu)', data=bldg_data, height=10, aspect=3, kind='box')\n\nplt.ylim(0,20000000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='Neighborhood', y='TotalGHGEmissions', data=bldg_data, height=10, aspect=3, kind='box')\nplt.ylim(0,500)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above graph, we can observe that- the neighborhood of Downtown has the highest median electricity consumption, followed by Lake Union. Such areas have a higher probability of high electricity consumption as compared to other areas. \nThis parameter can be suitable for prediction of electricity consumption.\n\nSimilarly, Downtown, East and Lake Union neighborhoods have highest median GHG emisions. Thus, neighborhood can be useful in prediciton of GHG emissions as well. "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='BuildingType', y='TotalGHGEmissions', data=bldg_data, height=10, aspect=3, kind='box')\nplt.ylim(0,1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='BuildingType', y='Electricity(kBtu)', data=bldg_data, height=10, aspect=3, kind='box')\nplt.ylim(0,50000000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Above boxplots depict that Campuses have much higher electricity consumption and GHG emission out of all building types, followed by multifamily HR.\nBuilding type can be a helpful parameter in our predicitons."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(x='YearBuilt' ,y='GHGEmissionsIntensity',  data=bldg_data, line_kws={'color':'red'})\nplt.ylim(0,10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that Emissions are negatively correlated to year built, with older buildings having higher GHG emissions. \nThus this variable can be used in emission prediction."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(x='PropertyGFATotal' ,y='GHGEmissionsIntensity',  data=bldg_data, line_kws={'color':'red'})\nplt.xlim(0,2000000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(x='PropertyGFATotal' ,y='Electricity(kBtu)',  data=bldg_data, line_kws={'color':'red'})\nplt.xlim(0,2000000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And as we can already guess, electricity consumption is proportional to the Gross Floor Area (GFA) of the property."},{"metadata":{"trusted":true},"cell_type":"code","source":"# let us take a subset of bldg_data dataset- of columns which can help us predict energy consumption\n\nbldg_x= bldg_data[['BuildingType','Neighborhood','ENERGYSTARScore','TotalGHGEmissions','YearBuilt','PropertyGFATotal']]\nbldg_y= bldg_data[['Electricity(kWh)']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bldg_x.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bldg_x.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bldg_x['BuildingTypeRep']=bldg_x['BuildingType'].replace({'NonResidential': 0, 'Nonresidential COS': 1, \n                                'Multifamily MR (5-9)':2,'SPS-District K-12':3, \n                                'Multifamily LR (1-4)':4, 'Campus':5,\n                                'Multifamily HR (10+)':6, 'Nonresidential WA':7})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bldg_x['Neighborhood'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bldg_x['NeighborhoodRep']= bldg_x['Neighborhood'].replace({'DOWNTOWN':0, 'SOUTHEAST':1, 'NORTHEAST':2, 'EAST':3,\n                                                           'CENTRAL':4, 'NORTH':5,'MAGNOLIA / QUEEN ANNE':6, 'LAKE UNION':7, \n                                                           'GREATER DUWAMISH':8,'BALLARD':9, 'NORTHWEST':10, 'SOUTHWEST':11, \n                                                           'DELRIDGE':12, 'Ballard':13,'DELRIDGE NEIGHBORHOODS':14})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bldg_pred_x= bldg_x.drop(['BuildingType', 'Neighborhood'], axis=1)\nbldg_pred_x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us begin with simple linear regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"#train test split \nfrom sklearn.model_selection import train_test_split\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test=train_test_split(bldg_pred_x, bldg_y, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import linear_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg1= linear_model.LinearRegression()\nreg1train_x= np.asanyarray(x_train[['PropertyGFATotal']])\nreg1train_y= np.asanyarray(y_train)\n\nprint(reg1train_x.shape)\nprint(reg1train_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg1.fit (reg1train_x, reg1train_y)\n# The coefficients\nprint ('Coefficients: ', reg1.coef_)\nprint ('Intercept: ',reg1.intercept_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg1test_x= np.asanyarray(x_test[['PropertyGFATotal']])\nreg1test_y= np.asanyarray(y_test)\nreg1_yhat= reg1.predict(y_test)\n\nprint('r^2 score is ', r2_score(reg1test_y, reg1_yhat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(reg1test_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg1_yhat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}