{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"raw_data = pd.read_csv(\"/kaggle/input/malware-detection/Malware dataset.csv\")\nraw_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the characteristics of the observations, the dataset was created in a Unix / Lunix-based\nvirtual machine for classification purposes, which are harmless with malware software for Android\ndevices. The data set consists of 100,000 observation data and 35 features. Below is a table of\nspecifications and descriptions."},{"metadata":{},"cell_type":"markdown","source":"| Features Description \t| Properties                                                      \t|\n|----------------------\t|-----------------------------------------------------------------\t|\n| hash APK/ SHA256     \t| file name                                                       \t|\n| milisecond           \t| time                                                            \t|\n| classification       \t| malware/beign                                                   \t|\n| state                \t| flag of unrunable/runnable/stopped tasks                        \t|\n| usage_counter        \t| task structure usage counter                                    \t|\n| prio                 \t| keeps the dynamic priority of a process                         \t|\n| static_prio          \t| static priority of a process                                    \t|\n| normal_prio          \t| priority without taking RT-inheritance into account             \t|\n| policy               \t| planning policy of the process                                  \t|\n| vm_pgoff             \t| the offset of the area in the file, in pages.                   \t|\n| vm_truncate_count    \t| used to mark a vma as now dealt with                            \t|\n| task_size            \t| size of current task.                                           \t|\n| cached_hole_size     \t| size of free address space hole.                                \t|\n| free_area_cache      \t| first address space hole                                        \t|\n| mm_users             \t| address space users                                             \t|\n| map_count            \t| number of memory areas                                          \t|\n| hiwater_rss          \t| peak of resident set size                                       \t|\n| total_vm             \t| total number of pages                                           \t|\n| shared_vm            \t| number of shared pages.                                         \t|\n| exec_vm              \t| number of executable pages.                                     \t|\n| reserved_vm          \t| number of reserved pages.                                       \t|\n| nr_ptes              \t| number of page table entries                                    \t|\n| end_data             \t| end address of code component                                   \t|\n| last_interval        \t| last interval time before thrashing                             \t|\n| nvcsw                \t| number of volunteer context switches.                           \t|\n| nivcsw               \t| number of in-volunteer context switches                         \t|\n| min_flt              \t| minör page faults                                               \t|\n| maj_flt              \t| majör page faults                                               \t|\n| fs_excl_counter      \t| ıt holds file system exclusive resources.                       \t|\n| lock                 \t| the read-write synchronization lock used for file system access \t|\n| utime                \t| user time                                                       \t|\n| stime                \t| system time                                                     \t|\n| gtime                \t| guest time                                                      \t|\n| cgtime               \t| cumulative group time. Cumulative resource counter              \t|\n| signal_nvcsw         \t| used as cumulative resource counter.                            \t|\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# read some statistics of the dataset\nraw_data.describe(include=\"all\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the DataType of our dataset\nraw_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data is already clean."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Start Processing\ndata = raw_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"classification\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['classification'] = data.classification.map({'benign':0, 'malware':1})\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shuffle data\ndata = data.sample(frac=1).reset_index(drop=True)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import drawing tools\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data[\"classification\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrMatrix = data.corr()\nsns.heatmap(corrMatrix, annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.drop([\"hash\",\"classification\",'vm_truncate_count','shared_vm','exec_vm','nvcsw','maj_flt','utime'],axis=1)\nY = data[\"classification\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before we feed to a NN, we need to normalize the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data normalization\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Number of attributes\ninput_size = 27 \n\n#Number of Outputs\noutput_size = 2 \n\n# Use same hidden layer size for both hidden layers. Not a necessity.\nhidden_layer_size = 50\n    \n# define how the model will look like\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(hidden_layer_size, input_shape=(input_size,), activation='relu'), # 1st hidden layer\n    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n    tf.keras.layers.Dense(output_size, activation='softmax') # output layer\n])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n#from keras.optimizers import SGD\n#opt = SGD(lr=0.01)\n#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n#model.compile(optimizer = sgd, loss = \"sparse_categorical_crossentropy\", metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set the batch size\nbatch_size = 100\n\n# set a maximum number of training epochs\nmax_epochs = 20\n\n# set an early stopping mechanism\n# let's set patience=2, to be a bit tolerant against random validation loss increases\nearly_stopping = tf.keras.callbacks.EarlyStopping(patience=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = model.fit(x=x_train,\n                   y=y_train,\n                   batch_size=batch_size,\n                   epochs=max_epochs,\n                   verbose=1,\n                   #callbacks=[early_stopping],\n                   validation_split=0.2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize the result\nacc = result.history['accuracy']\nval_acc = result.history['val_accuracy']\nloss = result.history['loss']\nval_loss = result.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\nsns.set_style(\"white\")\nplt.suptitle('Train history', size = 15)\n\nax1.plot(epochs, acc, \"bo\", label = \"Training acc\")\nax1.plot(epochs, val_acc, \"b\", label = \"Validation acc\")\nax1.set_title(\"Training and validation acc\")\nax1.legend()\n\nax2.plot(epochs, loss, \"bo\", label = \"Training loss\", color = 'red')\nax2.plot(epochs, val_loss, \"b\", label = \"Validation loss\", color = 'red')\nax2.set_title(\"Training and validation loss\")\nax2.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(x_test, y_test)\n\nprint('\\nTest loss: {0:.6f}. Test accuracy: {1:.6f}%'.format(test_loss, test_accuracy*100.))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Further train the model using SGD with lr=0.001"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import SGD\nsgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(optimizer = sgd, loss = \"sparse_categorical_crossentropy\", metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = model.fit(x=x_train,\n                   y=y_train,\n                   batch_size=batch_size,\n                   epochs=30,\n                   verbose=1,\n                   initial_epoch=10, #start from epoch 11\n                   callbacks=[early_stopping], #prevent overfitting\n                   validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(x_test, y_test)\n\nprint('\\nTest loss: {0:.6f}. Test accuracy: {1:.6f}%'.format(test_loss, test_accuracy*100.))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}