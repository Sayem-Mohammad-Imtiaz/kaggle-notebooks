{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"25b3bc6f-585b-2a9b-53fb-e9106697257b"},"source":"# This is my first shot at data analysis with Python and ML.\n# Comments and critique are welcome."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f1942f32-004c-aaa2-37d5-dc4c2e368147"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.cross_validation import train_test_split"},{"cell_type":"markdown","metadata":{"_cell_guid":"d4f7286a-3163-44c2-2f93-ce194abd8c44"},"source":"<h2>We have one giant csv to work with. Let's look at it further.</h2>"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b43d69f8-5e97-6c8b-b41d-313d9121e814"},"outputs":[],"source":"data = pd.read_csv(\"../input/diabetes.csv\")\n\ndata.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4c0c4a07-d25c-aab8-2a1e-8c28e4e98105"},"outputs":[],"source":"data.describe()"},{"cell_type":"markdown","metadata":{"_cell_guid":"1c8c8811-10dd-559c-92c4-e1b7fccb0da4"},"source":"<h1>Data Exploration</h1>\n<p>We only have numerical features (int and float).  Let's band our features (except pregnancy). \nLuckliy, we don't have any NaN values, but some measurements are simply 0. Let's find how many 0's.</p>"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"31d46e1e-a80d-aeac-b921-b440f73a431f"},"outputs":[],"source":"# convert all 0's to Boolean values\n# sum the Trues along the columns\n(data == 0).sum(axis=0)"},{"cell_type":"markdown","metadata":{"_cell_guid":"53bd9c36-2a2c-3fa0-113f-9d64353411fd"},"source":"<h3>Wow. Almost half of Insulin values are 0 and a significant number of zeros for other features. We will have to replace them with something.</h3>\n\nBut before we do that, let's see how the data is correlated, just for fun."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9571afcb-7341-79c0-c676-7722990ab646"},"outputs":[],"source":"corr = data.corr() # compute pairwise correlation of columns\n_, ax = plt.subplots(figsize=(12, 10)) # returns a pyploy figure object and array of axes\ncmap = sns.diverging_palette( 255, 10, as_cmap=True ) # return matplot lib colormap \n_ = sns.heatmap(\n    corr, # use computed correlations\n    cmap = cmap, # use our colormap\n    square=True, # set axes to be same size\n    cbar_kws={ 'shrink' : .9 }, # shrink color bar by 9/10ths\n   # ax=ax, # axes in which to draw the plot\n    annot = True, # put the correlation values in the plot\n    annot_kws = { 'fontsize' : 14 } # 12 point font\n)"},{"cell_type":"markdown","metadata":{"_cell_guid":"1056a4ef-283d-a79a-43e1-b82dc8a84693"},"source":"## We will replace the zeros with the median value from that column."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7ba6e611-828a-8429-9e49-3e2d11968db2"},"outputs":[],"source":"# replace zeros of each column with their column's median\nfor col in data.columns[1:6]:\n    data[col] = data[col].replace(0, data[col].median())\ndata.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"68a3978d-4cd6-07b1-4054-c79efa52dc53"},"source":"Now we will band the features and replace the ordinals with their membership in a band\n------------------------------------------------------------------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ff71d49f-b8d1-5251-f5f3-4b1ec022627d"},"outputs":[],"source":"# from Glucose to BMI, create 20 bins for the range of data\nfor col in data.columns[1:8]:\n    data[col + \"Band\"] = pd.cut(data[col], 20)\ndata.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1eb6a999-2ec4-0102-d33d-78c26cc41269"},"outputs":[],"source":"from operator import itemgetter \n\nfor col in data.columns[1:8]: # Glucose to Age\n\n    # turn the unique values of each band into a list\n    # of lists of floats\n    band_range = list()\n    for band in data[col + \"Band\"].unique(): \n        band = band.strip('(] ').replace(' ', '').split(',')\n        band = list(map(float,band))\n        band_range.append(band)\n        \n    # sort the list of lists based on the first member of each list\n    band_range = sorted(band_range, key=itemgetter(0))\n    \n    # find where our data points fall into a certain band\n    # and assign them the band's respective index\n    for i, b in enumerate(band_range):\n        data.loc[(data[col] > b[0]) & (data[col] <= b[1]), col] = i\ndata.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"92233396-a9fd-e21a-47ea-bc136f6b0cc6"},"outputs":[],"source":"# get rid of bands\nfor col in data.columns[9:]:\n    data = data.drop(str(col), axis=1)\ndata.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"ed1e5e34-1b62-68d0-1126-ff874115259d"},"source":"Time for the machine learning\n-----------------------------\n\nFirst to segment our data into training and testing sets"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b14fd49f-e194-6d4d-1107-b9b69b78b863"},"outputs":[],"source":"target = data.Outcome\ndata = data.drop('Outcome', axis=1)\ndata.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"326c7e97-0bba-9b48-f0e7-1f713bb0733d"},"outputs":[],"source":"X_train, X_test, Y_train, Y_test = train_test_split( data, target , train_size = .7 )\n\nprint(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"},{"cell_type":"markdown","metadata":{"_cell_guid":"c93b5da3-d6e6-620b-1cc6-44d899c1ccb2"},"source":"Now to  try several models"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9032f5be-7c11-5249-fda8-defc423c3e12"},"outputs":[],"source":"# Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nY_pred = logreg.predict(X_test)\nprint(accuracy_score(Y_test, Y_pred))\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3bdb07ef-bf1f-8c30-c1cb-350c1893b4ce"},"outputs":[],"source":"# Support Vector Machines\n\nsvc = SVC()\nsvc.fit(X_train, Y_train)\nY_pred = svc.predict(X_test)\nprint(accuracy_score(Y_test, Y_pred))\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e65dc0af-bd4c-85ef-08bc-7d041e368eb6"},"outputs":[],"source":"# K-nearest Neighbors\n\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nprint(accuracy_score(Y_test, Y_pred))\n\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ea2640a6-128c-f51c-c200-6485984fb229"},"outputs":[],"source":"# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nY_pred = gaussian.predict(X_test)\nprint(accuracy_score(Y_test, Y_pred))\n\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7f5fc9d1-086e-05a2-28ae-d65871e99351"},"outputs":[],"source":"# Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(X_train, Y_train)\nY_pred = perceptron.predict(X_test)\nprint(accuracy_score(Y_test, Y_pred))\n\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"84f381e7-f18d-a4bc-3089-c54996fff6e2"},"outputs":[],"source":"# Linear SVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\nY_pred = linear_svc.predict(X_test)\nprint(accuracy_score(Y_test, Y_pred))\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9cc7ca8d-9782-3ab7-fdde-58fae3586650"},"outputs":[],"source":"# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nY_pred = sgd.predict(X_test)\nprint(accuracy_score(Y_test, Y_pred))\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e39e7f2d-4cf9-69d7-2a1a-eb7231ab1da1"},"outputs":[],"source":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nprint(accuracy_score(Y_test, Y_pred))\n\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b9d41e58-dd3f-1c94-2adb-ec833c8a6694"},"outputs":[],"source":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nprint(accuracy_score(Y_test, Y_pred))\n\n\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"6b1ad2a0-8bc3-3518-2209-ee3a5d8a87b5"},"source":"##Linear Support Vector Machine worked the best with 78.35% accuracy. \n\n##Since you made it this far, thanks and I hope to read your comments."}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}