{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt \nimport os \nimport cv2\nimport random\nimport scipy.signal as sg\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from keras.models import Model\n# from keras.layers import Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n# from keras.layers import BatchNormalization, Activation, Dropout, Flatten, Dense\n# from keras import backend as K\n# from keras import optimizers\n# from imgaug import augmenters as iaa","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datadir = \"../input/asldataset/train/train\"\ncategories = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\",\"del\",\"nothing\",\"space\"]\nfor category in categories:\n\tpath = os.path.join(datadir,category)\n\tfor img in os.listdir(path):\n\t\timg_array = cv2.imread(os.path.join(path,img))\n# \t\tAbo,Ago,Aro = cv2.split(img_array)\n\t\tplt.imshow(img_array)\n\t\tplt.show()\n\t\tbreak\n\tbreak","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_size = 100\nnew_array = cv2.resize(img_array,(img_size,img_size))\nplt.imshow(new_array,cmap = \"gray\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data = []\ndef create_training_data():\n    for category in categories:\n        path = os.path.join(datadir,category)\n        class_num = categories.index(category)\n        for img in os.listdir(path):\n            try:\n#                 img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n                img_array = cv2.imread(os.path.join(path,img),0)\n#                 clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n                new_array = cv2.resize(img_array,(img_size,img_size))\n                # create a CLAHE object (Arguments are optional).\n#                 clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n#                 cl1 = clahe.apply(new_array)\n#                 equ = cv2.equalizeHist(new_array)\n#                 Abo,Ago,Aro = cv2.split(new_array)\n#                 equ = cv2.equalizeHist(new_array)\n#                 cl1 = clahe.apply(new_array)\n                training_data.append([new_array,class_num])\n            except Exception as e:\n                pass\ncreate_training_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(training_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random.shuffle(training_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = []\ny = []\nfor features,label in training_data:\n\tx.append(features)\n\ty.append(label)\nx = np.array(x).reshape(-1,img_size,img_size,1) #use 1 for grey and 3 for colorful image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# np.save('featuresX.npy',x)\n# np.save('featuresY.npy',y) #saving","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = x/255.0\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\ny = to_categorical(y)\nnp.shape(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# img_width, img_height = 256, 256\n# input_shape = (img_size, img_size, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# input = Input(shape=input_shape)\n\n# block1 = BatchNormalization(name='norm_0')(input)\n\n# # Block 1\n# block1 = Conv2D(8, (3,3), name='conv_11', activation='relu')(block1)\n# block1 = Conv2D(16, (3,3), name='conv_12', activation='relu')(block1)\n# block1 = Conv2D(32, (3,3), name='conv_13', activation='relu')(block1)\n# block1 = Conv2D(64, (3,3), name='conv_14', activation='relu')(block1)\n# block1 = MaxPooling2D(pool_size=(2, 2))(block1)\n# block1 = BatchNormalization(name='norm_1')(block1)\n\n# block1 = Conv2D(16, 1)(block1)\n\n# # Block 2\n# block2 = Conv2D(32, (3,3), name='conv_21', activation='relu')(block1)\n# block2 = Conv2D(64, (3,3), name='conv_22', activation='relu')(block2)\n# block2 = Conv2D(64, (3,3), name='conv_23', activation='relu')(block2)\n# block2 = Conv2D(128, (3,3), name='conv_24', activation='relu')(block2)\n# block2 = MaxPooling2D(pool_size=(2, 2))(block2)\n# block2 = BatchNormalization(name='norm_2')(block2)\n\n# block2 = Conv2D(64, 1)(block2)\n\n# # Block 3\n# block3 = Conv2D(64, (3,3), name='conv_31', activation='relu')(block2)\n# block3 = Conv2D(128, (3,3), name='conv_32', activation='relu')(block3)\n# block3 = Conv2D(128, (3,3), name='conv_33', activation='relu')(block3)\n# block3 = Conv2D(64, (3,3), name='conv_34', activation='relu')(block3)\n# block3 = MaxPooling2D(pool_size=(2, 2))(block3)\n# block3 = BatchNormalization(name='norm_3')(block3)\n\n# # Block 4\n# block4 = Conv2D(64, (3,3), name='conv_41', activation='relu')(block3)\n# block4 = Conv2D(32, (3,3), name='conv_42', activation='relu')(block4)\n# block4 = Conv2D(16, (3,3), name='conv_43', activation='relu')(block4)\n# block4 = Conv2D(8, (2,2), name='conv_44', activation='relu')(block4)\n# block4 = MaxPooling2D(pool_size=(2, 2))(block4)\n# block4 = BatchNormalization(name='norm_4')(block4)\n\n# block4 = Conv2D(2, 1)(block4)\n\n# block5 = GlobalAveragePooling2D()(block4)\n# output = Activation('softmax')(block5)\n\n# model = Model(inputs=[input], outputs=[output])\n# model.summary()\n# model.compile(loss=\"binary_crossentropy\", optimizer=optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), metrics=[\"accuracy\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(256, (3, 3), input_shape=x.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(256, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n\nmodel.add(Dense(64))\n\nmodel.add(Dense(29))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = tf.keras.callbacks.ModelCheckpoint(\"checkpoint.pkl\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=0, mode='auto', cooldown=0, min_lr=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x, y,batch_size = 64,epochs=20,verbose = 1,callbacks = [checkpoint, reduce_lr], validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# history = model.fit(x, y,batch_size = 16,epochs=30,verbose = 1,callbacks = None, validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n#Train and validation accuracy\nplt.plot(epochs, acc, 'b', label='Training accurarcy')\nplt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\nplt.title('Training and Validation accurarcy')\nplt.legend()\n\nplt.figure()\n#Train and validation loss\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('model_30_epochs.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}