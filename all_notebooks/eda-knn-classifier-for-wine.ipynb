{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Table of Contents\n\n### Libraries & Environment Setup\n### Data Loading & Formatting\n### Missing Values\n### Target Variable Binarization\n### Exploratory Data Analysis\n    1. Distribution of the target variable (Original vs Binary)   \n    2. How do our variables interact with one another? (Correlation Matrix)\n    3. How does one of the strongest relationship fair between wine types?\n    4. How do the different type of acidity vary between good and bad wines?\n    5. What are predictors of pH of any type of wine?\n### Modeling \n    1. Target Variable Comparison\n        a. MultiClass Using the Original Target Variable  \n        b. Binary Using the newly created column \n    2. Find best sample Split\n    3. Find best k\n    4. Hyperparameter Tuning\n    5. Check for overfitting","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# Libraries & Environment Setup","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \n\nimport utils_clf_models as clf\nimport utils_data_prepping as udp\nimport utils_eda as eda\n\n%matplotlib inline\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nsns.set(rc={'figure.figsize':(12, 10)})\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the data","metadata":{}},{"cell_type":"code","source":"df = udp.loading('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['quality'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking for any missing values","metadata":{}},{"cell_type":"code","source":"udp.missing_values(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modifying the target variable","metadata":{}},{"cell_type":"code","source":"df['quality_binary'] = np.where(df['quality'] >= 6, 'good', 'bad')\ndf['quality_binary_num'] = np.where(df['quality'] >= 6, 1, 0)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d =  { 3 : 0,  4 : 0, \n       5 : 1,  6 : 1,\n       7 : 2,  8 : 2,}\n\nd1 =  { 3 : 'bad',  4 : 'bad', \n       5 : 'good',  6 : 'good',\n       7 : 'very good',  8 : 'very good',}\n\ndf['quality_tri_num'] = df['quality'].map(d)\ndf['quality_tri'] = df['quality'].map(d1)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"## 1. Distribution of the target variable (Original vs Binary)","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(16, 12))\ngs = fig.add_gridspec(1, 3, hspace=0.1, wspace=0.1)\n(ax1, ax2, ax3) = gs.subplots(sharex=False, sharey=True)\nfig.suptitle('Histograms for Target Variable (Original vs Binary)')\n\nsns.histplot(ax=ax1, data=df, x='quality')\nsns.histplot(ax=ax2, data=df, x='quality_binary')\nsns.histplot(ax=ax3, data=df, x='quality_tri')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. How do our variables interact with one another? (Correlation Matrix)","metadata":{}},{"cell_type":"code","source":"eda.corr_matrix(df)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. How does one of the strongest relationship fair between wine types?","metadata":{}},{"cell_type":"code","source":"sns.scatterplot(data=df, x='alcohol', y='density', hue='quality_binary')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.scatterplot(data=df, x='alcohol', y='density', hue='quality_tri')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. How do the different type of acidity vary between good and bad wines?","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(16, 12))\ngs = fig.add_gridspec(2, 2, hspace=0.2, wspace=0.2)\n(ax1, ax2), (ax3, ax4) = gs.subplots(sharex=False, sharey=True)\nfig.suptitle('Histograms for Target Variable (Original vs Binary)')\n\nsns.scatterplot(ax=ax1, data=df, x='fixed acidity',  y='citric acid', hue='quality_binary')\nsns.scatterplot(ax=ax2, data=df, x='volatile acidity', y='citric acid', hue='quality_binary')\n\nsns.scatterplot(ax=ax3, data=df, x='fixed acidity',  y='citric acid', hue='quality_tri')\nsns.scatterplot(ax=ax4, data=df, x='volatile acidity', y='citric acid', hue='quality_tri')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. What are predictors of pH of any type of wine?","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(16, 12))\ngs = fig.add_gridspec(2, 2, hspace=0.2, wspace=0.2)\n(ax1, ax2), (ax3, ax4)  = gs.subplots(sharex=False, sharey=True)\nfig.suptitle('Histograms for Target Variable (Original vs Binary)')\n\nsns.scatterplot(ax=ax1, data=df, x='fixed acidity',  y='pH', hue='quality_binary')\nsns.scatterplot(ax=ax2, data=df, x='citric acid', y='pH', hue='quality_binary')\n\nsns.scatterplot(ax=ax3, data=df, x='fixed acidity',  y='pH', hue='quality_tri')\nsns.scatterplot(ax=ax4, data=df, x='citric acid', y='pH', hue='quality_tri')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling ","metadata":{}},{"cell_type":"markdown","source":"## 1. Target Variable Comparison ","metadata":{}},{"cell_type":"markdown","source":"### a. MultiClass Using the Original Target Variable","metadata":{}},{"cell_type":"code","source":"df1 = df.drop(['quality_binary', 'quality_binary_num', \n               'quality_tri', 'quality_tri_num'], axis=1)\nX, y = udp.pre_processing(df1, 'quality')\nknn = clf.Classifier(X, y, 'knn')\nknn.preprocess_split(size=0.2, state=12)\nknn.fit_predict()\nmulti = knn.metrics().ev['Accuracy']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### b. Binary Using the newly created column","metadata":{}},{"cell_type":"code","source":"df2 = df.drop(['quality_binary', 'quality', \n               'quality_tri', 'quality_tri_num'], axis=1)\nX, y = udp.pre_processing(df2, 'quality_binary_num')\nknn = clf.Classifier(X, y, 'knn')\nknn.preprocess_split(size=0.2, state=12)\nknn.fit_predict()\nbinary = knn.metrics().ev['Accuracy']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### c. Three classes using the newly created column","metadata":{}},{"cell_type":"code","source":"df3 = df.drop(['quality_binary', 'quality', \n               'quality_tri', 'quality_binary_num'], axis=1)\nX, y = udp.pre_processing(df3, 'quality_tri_num')\nknn = clf.Classifier(X, y, 'knn')\nknn.preprocess_split(size=0.2, state=12)\nknn.fit_predict()\ntrio = knn.metrics().ev['Accuracy']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame({'multi':pd.Series(multi),'binary':pd.Series(binary), 'trio':pd.Series(trio)})\nmet = pd.DataFrame([multi,binary, trio]).T\nmet.rename(index= {0:'Accuracy'}, columns={0: \"multi_class\", 1: \"binary_class\", 2: \"three_classes\"})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### After multiple attempts, it appears that splitting the target variable in three sets works better. We will proceed in finding the best k to maximize accuracy","metadata":{}},{"cell_type":"markdown","source":"# Modeling Phase 2: Find best sample Split","metadata":{}},{"cell_type":"code","source":"# Works using utils_clf_models (See Documentation)\ndef search_best_split(clf, iters):\n    sizes = [round(i, 2) for i in np.arange(0.2, 0.45, 0.05)]\n    states = list(range(0, iters+1))\n    scores = {}\n    for i in sizes:\n        for j in states:\n            clf.preprocess_split(size=i, state=j)\n            clf.fit_predict()\n            scores[(i, j)]  = clf.metrics().ev['Accuracy']\n    \n    best_split = max(scores, key=scores.get)\n    return best_split\ndata = df.drop(['quality_binary', 'quality', \n               'quality_tri', 'quality_binary_num'], axis=1)\nX, y = udp.pre_processing(data, 'quality_tri_num')\nknn = clf.Classifier(X, y, 'knn')\ns, t = search_best_split(knn, 500)\n\n# Rerunning it with the following sampling parameters\ndata = df.drop(['quality_binary', 'quality', \n               'quality_tri', 'quality_binary_num'], axis=1)\nX, y = udp.pre_processing(data, 'quality_tri_num')\nknn = clf.Classifier(X, y, 'knn')\nknn.preprocess_split(size=s, state=t)\nknn.fit_predict()\ntrio = knn.metrics().ev['Accuracy']\ntrio","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### From the following loop, we obtain the sampling paramater as the size and state respectively.","metadata":{}},{"cell_type":"markdown","source":"# Modeling Phase 3: Find best k","metadata":{}},{"cell_type":"code","source":"def elbow_method(clf, iters):\n    scores = {}    \n    for k in range(2, iters+1):\n        clf.fit_predict({'n_neighbors':k})\n        clf.metrics().ev['Accuracy']\n        scores[k]  = clf.metrics().ev['Accuracy']\n    k_best = max(scores, key=scores.get)\n    return k_best\n\ndata = df.drop(['quality_binary', 'quality', \n               'quality_tri', 'quality_binary_num'], axis=1)\nX, y = udp.pre_processing(data, 'quality_tri_num')\nknn = clf.Classifier(X, y, 'knn')\nknn.preprocess_split(s, t)\nk_best = elbow_method(knn, 30)\n\n# Rerunning it with the following sampling parameters\ndata = df.drop(['quality_binary', 'quality', \n               'quality_tri', 'quality_binary_num'], axis=1)\nX, y = udp.pre_processing(data, 'quality_tri_num')\nknn = clf.Classifier(X, y, 'knn')\nknn.preprocess_split(size=s, state=t)\nknn.fit_predict({'n_neighbors': k_best})\ntrio = knn.metrics().ev['Accuracy']\ntrio","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling Phase 4: Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"#Using Grid Search (Exhaustive) with cross validation\nfrom sklearn.neighbors import KNeighborsClassifier as knn\nfrom sklearn.model_selection import GridSearchCV\n\ndata = df.drop(['quality_binary', 'quality', \n               'quality_tri', 'quality_binary_num'], axis=1)\nX, y = udp.pre_processing(data, 'quality_tri_num')\n\nparameters = {'weights':('uniform', 'distance'), \n              'algorithm':('auto', 'ball_tree', 'kd_tree', 'brute'),\n             'leaf_size': [0, 300], 'p': [0, 300],'n_jobs':(-1, 1)}\nsvc = knn(n_neighbors=2)\nsearch = GridSearchCV(svc, parameters)\nsearch.fit(X, y)\nres = pd.DataFrame(search.cv_results_)\nbest = res[(res['rank_test_score'] == 1)]\nbest.sort_values(by=['std_score_time'], ascending=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Given that we have now our parameters set, we will check for overfitting before proceeding to an overfit check","metadata":{}},{"cell_type":"code","source":"# Reruning the model using the given parameters \ndata = df.drop(['quality_binary', 'quality', \n               'quality_tri', 'quality_binary_num'], axis=1)\nX, y = udp.pre_processing(data, 'quality_tri_num')\nknn = clf.Classifier(X, y, 'knn')\nknn.preprocess_split(size=s, state=t)\nknn_params = {'n_neighbors': k_best, 'weights':'uniform', \n              'algorithm': 'kd_tree', 'leaf_size': 300, \n              'p': 300,'n_jobs':1,}\nknn.fit_predict(knn_params)\ntrio = knn.metrics().ev['Accuracy']\ntrio","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling Phase 4: Check for Overfitting","metadata":{}}]}