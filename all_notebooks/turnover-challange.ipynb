{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Challenge Data Science - Genomawork**\n\n*Nombre: Víctor Estrada*\n\nEl cliente Stark Industries se ha planteado el objetivo de mejorar sus contrataciones. Dentro de sus principales problemas, este identifica la rotación de personal, es decir, los colaboradores que abandonan la compañia. Para ello, se ha recolectado datos de esta empresa, para poder analizar tal fenómeno.\n\n*   **Objetivo principal** : \n    * Hacer uso de técnicas de ciencias de datos para resolver problemas de la vida.\n\n* **Objectivos segundarios**: \n    * Manejo de datos (leer archivos .csv, filtrarlos, etc).\n    * Enfoque científico (planteamiento de hipótesis y validación o refutación de datos).\n    * Uso de estadística en problemas reales.\n    * Uso de herramienta de visualización de datos.\n    * Técnicas de elección y entrenamiento de modelos simples de machine learning.\n    * Capacidad de sintetizar los principales resultados.\n\n\n---\n\n\n\n","metadata":{"id":"5VAm1gh2NFtY"}},{"cell_type":"markdown","source":"# **Glosario de la data**\n\n* Stag        : Experiencia (tiempo).\n* Event       : Deserción de trabajo (1: Abandona, 0: Se queda).\n*    Gender      : Feminino(f), Másculino(m).\n*    Age         : Edad del empleado (años).\n*    Industry    : Industria del empleado.\n*    Profession  : Profesión del empleado.\n*    Traffic     : Si el empleado vino por recomendación, paginas, etc.\n*    Coach       : Presencia de un entrenador en el periodo de prueba (No,Yes,My head).\n*    Head gender : Sexo del supervisor.\n*    greywage    : White(salario mínimo) /Gray (pequeña cantidad por encima del mínimo).\n*    Way         : Tranporte para ir a trabajar.\n*    Parametros de medición de salud: extraversion, selfcontrol, etc.\n---","metadata":{"id":"ljL3h0-qNHmU"}},{"cell_type":"markdown","source":"# Librerias importadas\n","metadata":{"id":"sXss_1xUVjWU"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"id":"FmeD0hWpAY3U","execution":{"iopub.status.busy":"2021-06-17T22:20:40.751284Z","iopub.execute_input":"2021-06-17T22:20:40.751848Z","iopub.status.idle":"2021-06-17T22:20:40.755077Z","shell.execute_reply.started":"2021-06-17T22:20:40.751811Z","shell.execute_reply":"2021-06-17T22:20:40.754381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# I. Carga y visualización de los datos\n","metadata":{"id":"lc--A9Anae6a"}},{"cell_type":"markdown","source":"---\nPrimero que todo se importa la data (ya sea desde el computador, o en este caso, *google drive*; para luego hacer lectura de esta y visualizarla.","metadata":{"id":"YUb2s47cl4Mp"}},{"cell_type":"code","source":"# Just to read from google colab\n#from google.colab import files\n\n#uploaded = files.upload()","metadata":{"id":"DtpGp64jBE1w","outputId":"ecc5f136-d506-463a-95ad-246401faa636","execution":{"iopub.status.busy":"2021-06-17T22:20:40.756211Z","iopub.execute_input":"2021-06-17T22:20:40.756592Z","iopub.status.idle":"2021-06-17T22:20:40.768853Z","shell.execute_reply.started":"2021-06-17T22:20:40.756566Z","shell.execute_reply":"2021-06-17T22:20:40.767575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lectura de data (archivo .csv) y visualización\n\nfile = pd.read_csv('../input/employee-turnover/turnover.csv',encoding='ISO-8859-1')\ndf = pd.DataFrame(file)\ndf.head()","metadata":{"id":"dE2rIKbvBRMx","outputId":"95fdc210-0d50-48ef-f520-136c5ac8e651","execution":{"iopub.status.busy":"2021-06-17T22:20:40.771019Z","iopub.execute_input":"2021-06-17T22:20:40.771466Z","iopub.status.idle":"2021-06-17T22:20:40.80722Z","shell.execute_reply.started":"2021-06-17T22:20:40.771405Z","shell.execute_reply":"2021-06-17T22:20:40.806375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# II. Análisis estadístico","metadata":{"id":"-kcbS5XXbqMJ"}},{"cell_type":"markdown","source":"**Información general**\n\n---\n\n","metadata":{"id":"Tb-0ykXpklg0"}},{"cell_type":"code","source":"#Informacion principal;\ndf.info()","metadata":{"id":"BLmFaovdBenu","outputId":"3037ac56-1dab-45c1-f1b4-e9a14102e35c","execution":{"iopub.status.busy":"2021-06-17T22:20:40.808827Z","iopub.execute_input":"2021-06-17T22:20:40.809114Z","iopub.status.idle":"2021-06-17T22:20:40.831967Z","shell.execute_reply.started":"2021-06-17T22:20:40.809087Z","shell.execute_reply":"2021-06-17T22:20:40.831064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Con la función ***.info()*** se puede obtener información general acercas de los *features* (columnas), tamaño de la muestra 1129x16,datos nulos (en este caso, no existen datos nulos), y además, el tipo de variable que representa, en este caso, se pueden encontrar: *float64, int64 y object*, lo que se traduce a que existen variables númericas y categóricas.","metadata":{"id":"moK9YMVfc_gO"}},{"cell_type":"code","source":"#Información acerca de datos nulos\ndf.isnull().any()","metadata":{"id":"3W8qAs--cj9w","outputId":"898169c0-d4a2-4a9f-b554-6e1ffd9282fd","execution":{"iopub.status.busy":"2021-06-17T22:20:40.833362Z","iopub.execute_input":"2021-06-17T22:20:40.833658Z","iopub.status.idle":"2021-06-17T22:20:40.8425Z","shell.execute_reply.started":"2021-06-17T22:20:40.833631Z","shell.execute_reply":"2021-06-17T22:20:40.841519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* ***isnull().any()*** Nos ayuda a corrobar la verificación de datos nulos.","metadata":{"id":"FeWWdONmh1kK"}},{"cell_type":"markdown","source":"**Muestro de varibles categóricas/númericas**\n\n---\n\n","metadata":{"id":"NDZnD5Xakpvi"}},{"cell_type":"code","source":"# Identificamos las variables categoricas\n\ndf_objects = df.select_dtypes(include=['object']).copy() # La guardamos como variable para su posterior uso.\nprint(df_objects.columns.values,'\\n')","metadata":{"id":"DArWkAZSBgf7","outputId":"a7521865-cf90-4470-87b1-c3d59c3974d7","execution":{"iopub.status.busy":"2021-06-17T22:20:40.843672Z","iopub.execute_input":"2021-06-17T22:20:40.844072Z","iopub.status.idle":"2021-06-17T22:20:40.857679Z","shell.execute_reply.started":"2021-06-17T22:20:40.844043Z","shell.execute_reply":"2021-06-17T22:20:40.85671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Luego vemos los valores únicos de tales variables\n\nfor i in df_objects.columns.values:\n    print(i,':', df[i].unique(),'\\n')","metadata":{"id":"ymzV0EmnBjeE","outputId":"b25486e5-7ee6-4b71-89e5-184257307703","execution":{"iopub.status.busy":"2021-06-17T22:20:40.859997Z","iopub.execute_input":"2021-06-17T22:20:40.860471Z","iopub.status.idle":"2021-06-17T22:20:40.875099Z","shell.execute_reply.started":"2021-06-17T22:20:40.860439Z","shell.execute_reply":"2021-06-17T22:20:40.873857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"El objetivo de analizar los valores únicos es intentar reducir las categorias para un mejor modelado.","metadata":{"id":"rBbTYBiAjUQW"}},{"cell_type":"code","source":"# Identificamos las variables numéricas\n\ndf_numerical = df.select_dtypes(exclude=['object']).copy()\nprint(df_numerical.columns.values,'\\n')","metadata":{"id":"Ci0zFpTlBmIX","outputId":"b53b4bf5-75c1-4c8d-ad97-d8e2c028cd5b","execution":{"iopub.status.busy":"2021-06-17T22:20:40.876831Z","iopub.execute_input":"2021-06-17T22:20:40.877208Z","iopub.status.idle":"2021-06-17T22:20:40.886695Z","shell.execute_reply.started":"2021-06-17T22:20:40.877174Z","shell.execute_reply":"2021-06-17T22:20:40.885961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Estadísticas**\n\n---\n\n","metadata":{"id":"lMX19Ap9k1Id"}},{"cell_type":"code","source":"# Rotación de empleados\n\nevent = df['event'].value_counts()\nporcentaje = [round(i*100/event.sum(),1) for i in df['event'].value_counts()]\nprint(event,'\\n')\nprint('Trabajadores que renuncian : %',porcentaje[0])\nprint('Trabajadores que se quendan : %',porcentaje[1])","metadata":{"id":"5cayESFjBv-v","outputId":"bfe560f0-4e3a-4cc2-bb44-781460f39fad","execution":{"iopub.status.busy":"2021-06-17T22:20:40.887846Z","iopub.execute_input":"2021-06-17T22:20:40.890531Z","iopub.status.idle":"2021-06-17T22:20:40.901353Z","shell.execute_reply.started":"2021-06-17T22:20:40.890484Z","shell.execute_reply":"2021-06-17T22:20:40.900207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Se observa que de los datos observados existe una mayoria de personas que renuncian a sus trabajos, siendo este del % 50.6.","metadata":{"id":"V9IY6VlmlbK3"}},{"cell_type":"code","source":"# Promedios de valos númericos en función de la variable 'event'\ndf.groupby('event').mean()","metadata":{"id":"CI1qsNvWlQQg","outputId":"c596ddfc-8a24-4d33-9696-21a974cae27b","execution":{"iopub.status.busy":"2021-06-17T22:20:40.902603Z","iopub.execute_input":"2021-06-17T22:20:40.903119Z","iopub.status.idle":"2021-06-17T22:20:40.924286Z","shell.execute_reply.started":"2021-06-17T22:20:40.903079Z","shell.execute_reply":"2021-06-17T22:20:40.923491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observaciones generales**\n(Repecto a la tabla anterior)\n* Las personas con menor tiempo en sus trabajos tienden a irse de ellos.\n* Los trabajadores más extrovertidos, independientes, novatos y con menos autocntrol tienden a renuciar.\n* La edad igual parece ser influente en la estadía de trabajo, mostrándose que las personas de mayor edad tienden a la estabilidad.\n\n\n\n\n\n\n","metadata":{"id":"cJb0tkvvp-Tf"}},{"cell_type":"markdown","source":"**Visualización de datos**\n\n---\n\n","metadata":{"id":"AGeZQ0ykr1PG"}},{"cell_type":"markdown","source":"A continuacíon se hace una visualización de las variables categoricas en función de la variable objetivo 'event'","metadata":{"id":"iWXccPhd1C5u"}},{"cell_type":"code","source":"rows    = 3\ncolumns = 3\nc       = 1 # Inicializar plot counter\n\n# Histograma categorical variables\nfig = plt.figure(figsize=(20,20))\nfor i in df_objects.columns.values:\n\n    ax = plt.subplot(rows,columns,c)\n    pd.crosstab(df[i],df.event).plot(kind='bar',ax=ax)\n    plt.title('Frecuencia de rotación por {}'.format(i))\n    plt.ylabel('Frecuencia de rotación')\n    plt.xlabel('{}'.format(i))\n    plt.tight_layout(pad=4.0)\n    c = c + 1","metadata":{"id":"oV5QaujuBytL","outputId":"4f6e45d0-1eb4-459c-c44b-271e1d454b79","execution":{"iopub.status.busy":"2021-06-17T22:20:40.925391Z","iopub.execute_input":"2021-06-17T22:20:40.92577Z","iopub.status.idle":"2021-06-17T22:20:43.992843Z","shell.execute_reply.started":"2021-06-17T22:20:40.925742Z","shell.execute_reply":"2021-06-17T22:20:43.991732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"De la gráfica anterior se puede observar lo siguiente:\n* Las mújeres son más probables de abandonar su lugar de trabajo\n* Es claro que la frecuencia de rotación depende en gran parte de la profesión e industria, por lo que pueden ser buenas variables para el modelo predictor.","metadata":{"id":"N7vc11pTsNoN"}},{"cell_type":"markdown","source":"Por último, es bueno representar las variables númericas en gráficos de histogramas.","metadata":{"id":"U9kJ8eCu1JEb"}},{"cell_type":"code","source":"num_bins = 10\nhistograma = df.hist(bins=num_bins, figsize=(20,20))","metadata":{"id":"jjP88-AoB38f","outputId":"767514b6-77a7-4cfc-e4e6-b7be8bf76b71","execution":{"iopub.status.busy":"2021-06-17T22:20:43.9944Z","iopub.execute_input":"2021-06-17T22:20:43.994794Z","iopub.status.idle":"2021-06-17T22:20:45.187333Z","shell.execute_reply.started":"2021-06-17T22:20:43.994748Z","shell.execute_reply":"2021-06-17T22:20:45.186288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# III. Aplicación a Machine Learning\n\n","metadata":{"id":"Pq-cRW3O2YKp"}},{"cell_type":"markdown","source":"**Importación de librerias utilizadas**\n\n---\n\n","metadata":{"id":"tmve9HjC310e"}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.feature_selection import RFE, RFECV\nfrom sklearn import metrics, preprocessing, model_selection\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.svm import SVC\n\nfrom sklearn.model_selection import StratifiedKFold, train_test_split,cross_val_score,ShuffleSplit\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"id":"2Iv8rV8EB9IP","execution":{"iopub.status.busy":"2021-06-17T22:20:45.189315Z","iopub.execute_input":"2021-06-17T22:20:45.189647Z","iopub.status.idle":"2021-06-17T22:20:45.557098Z","shell.execute_reply.started":"2021-06-17T22:20:45.189615Z","shell.execute_reply":"2021-06-17T22:20:45.556277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Conversión de variables**\n\n---\n\n\n\nPara poder iniciar el análisis de datos mediante machine learning, debemos tener una matriz solo de variables númericas; por lo que debe transformarse las variables categóricas en \"*dummy variables*\".\n\n\n","metadata":{"id":"9OSPmQPR4Wns"}},{"cell_type":"code","source":"# Agreamos 1/0 para las variables categóricas\n\nfor i in df_objects.columns.values:\n    object_list = 'var'+' '+ i\n    object_list = pd.get_dummies(df[i],prefix = i)\n    df_1 = df.join(object_list)\n    df = df_1","metadata":{"id":"fUzLh_2PCGls","execution":{"iopub.status.busy":"2021-06-17T22:20:45.558317Z","iopub.execute_input":"2021-06-17T22:20:45.558615Z","iopub.status.idle":"2021-06-17T22:20:45.58383Z","shell.execute_reply.started":"2021-06-17T22:20:45.558589Z","shell.execute_reply":"2021-06-17T22:20:45.582899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A continuación eliminamos las variables categóricas\ndf = df.drop(df_objects,axis=1)","metadata":{"id":"twnWPIKw5kni","execution":{"iopub.status.busy":"2021-06-17T22:20:45.585324Z","iopub.execute_input":"2021-06-17T22:20:45.585748Z","iopub.status.idle":"2021-06-17T22:20:45.59315Z","shell.execute_reply.started":"2021-06-17T22:20:45.585703Z","shell.execute_reply":"2021-06-17T22:20:45.592128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A continuación configuramos las variables para poder ingresarlas a los modelos de predicción.","metadata":{"id":"QQkJtvlF7D-M"}},{"cell_type":"code","source":"df_1 = df.drop('event', axis=1)  # Se elimina la variable objetivo ('event')\nX = df_1.values                  # Se define la matriz X\nY = df['event'].values           # Se define el vector Y","metadata":{"id":"tjiXr4fjCL4K","execution":{"iopub.status.busy":"2021-06-17T22:20:45.594725Z","iopub.execute_input":"2021-06-17T22:20:45.595188Z","iopub.status.idle":"2021-06-17T22:20:45.607309Z","shell.execute_reply.started":"2021-06-17T22:20:45.595119Z","shell.execute_reply":"2021-06-17T22:20:45.606223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Normalización de variables mediante**\n\n\n---\n\n\nSe normalizan los valores mediante *Mean Normalization* para evitar diferencias de ordenes de magnitud.","metadata":{"id":"nzeR3w9aNhFs"}},{"cell_type":"code","source":"scaler = preprocessing.StandardScaler()\nX2 = scaler.fit_transform(X)   ### Con este me quedo (MEAN NORMALIZATION)","metadata":{"id":"06C2g409COQv","execution":{"iopub.status.busy":"2021-06-17T22:20:45.609038Z","iopub.execute_input":"2021-06-17T22:20:45.609631Z","iopub.status.idle":"2021-06-17T22:20:45.618192Z","shell.execute_reply.started":"2021-06-17T22:20:45.609581Z","shell.execute_reply":"2021-06-17T22:20:45.617415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Recursive Feature Elimination (RFE)**\n\n---\n\n\n\nSe utiliza este método para escoger la cantidad de features más relevantes en el modelo predictivo.","metadata":{"id":"3K10gCd6OUb7"}},{"cell_type":"code","source":"# PRIORIZANDO ACCURACY\n\nrfc = RandomForestClassifier()\nrfecv = RFECV(estimator= rfc, step= 1, cv=StratifiedKFold(10), scoring='accuracy')\nrfecv.fit(X2,Y)\n","metadata":{"id":"nkIgSZPdW_on","outputId":"ddbab86e-ba88-43fe-89d0-2d488f4f319f","execution":{"iopub.status.busy":"2021-06-17T22:20:45.619747Z","iopub.execute_input":"2021-06-17T22:20:45.620111Z","iopub.status.idle":"2021-06-17T22:23:43.793296Z","shell.execute_reply.started":"2021-06-17T22:20:45.620076Z","shell.execute_reply":"2021-06-17T22:23:43.792332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Número óptimo de features: {}'.format(rfecv.n_features_))\n\nplt.figure(figsize=(16, 9))\nplt.title('Recursive Feature Elimination with Cross-Validation', fontsize=18, fontweight='bold', pad=20)\nplt.xlabel('Number of features selected', fontsize=14, labelpad=20)\nplt.ylabel('% Correct Classification', fontsize=14, labelpad=20)\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_, color='#303F9F', linewidth=3)\n\nplt.show()","metadata":{"id":"r6hGJwmaPmlv","outputId":"d534b18c-a3d2-4a23-a5c7-f990ab85ad9b","execution":{"iopub.status.busy":"2021-06-17T22:23:43.797216Z","iopub.execute_input":"2021-06-17T22:23:43.797531Z","iopub.status.idle":"2021-06-17T22:23:44.012612Z","shell.execute_reply.started":"2021-06-17T22:23:43.797495Z","shell.execute_reply":"2021-06-17T22:23:44.011364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ahora seleccionamos y eliminamos las variables menos importantes.","metadata":{"id":"DpSPmjKCQmiu"}},{"cell_type":"code","source":"df_2 = df_1 # Se crea una variable auxiliar\ndf_2.drop(df_2.columns[np.where(rfecv.support_ == False)[0]], axis=1, inplace=True)","metadata":{"id":"WqVBhEv-XQOX","execution":{"iopub.status.busy":"2021-06-17T22:23:44.014052Z","iopub.execute_input":"2021-06-17T22:23:44.014359Z","iopub.status.idle":"2021-06-17T22:23:44.023217Z","shell.execute_reply.started":"2021-06-17T22:23:44.01433Z","shell.execute_reply":"2021-06-17T22:23:44.022306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualización de variables más importantes.","metadata":{"id":"nWAF-5S1RpoJ"}},{"cell_type":"code","source":"dset = pd.DataFrame()\ndset['attr'] = df_2.columns\ndset['importance'] = rfecv.estimator_.feature_importances_\n\ndset = dset.sort_values(by='importance', ascending=False)\n\n\nplt.figure(figsize=(16, 14))\nplt.barh(y=dset['attr'], width=dset['importance'], color='#1976D2')\nplt.title('RFECV - Feature importantes', fontsize=20, fontweight='bold', pad=20)\nplt.xlabel('Importancia', fontsize=14, labelpad=20)\nplt.show()","metadata":{"id":"3m-BDaGbRwtr","outputId":"01b55d23-ae98-4a13-c542-ccf6df69136d","execution":{"iopub.status.busy":"2021-06-17T22:23:44.026169Z","iopub.execute_input":"2021-06-17T22:23:44.02654Z","iopub.status.idle":"2021-06-17T22:23:44.64462Z","shell.execute_reply.started":"2021-06-17T22:23:44.026506Z","shell.execute_reply":"2021-06-17T22:23:44.643616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Aplicación a modelos predictivos**\n\n---\n\n\n\nSe utilizaron 3 modelos de predicción: Logistic Regression, Random Forest y Support Vector Machine (SVM).\n\nPrimero que todo, se debe dividir los datos para alcanzar la máxima precisión.","metadata":{"id":"bE44Z93KOlgE"}},{"cell_type":"code","source":"test_size = 0.3\nrandom_state = 42\n\nX_train, X_test, Y_train, Y_test = train_test_split(X2, Y, test_size= test_size, random_state= random_state)\n\nprint('Training Features Shape:', X_train.shape)\nprint('Training Labels Shape:', Y_train.shape)\nprint('Testing Features Shape:', X_test.shape)\nprint('Testing Labels Shape:', Y_test.shape)","metadata":{"id":"Vl1vVkEbCPm1","outputId":"de2003bb-f516-44da-cdc4-982fb4ed85dc","execution":{"iopub.status.busy":"2021-06-17T22:23:44.645813Z","iopub.execute_input":"2021-06-17T22:23:44.64609Z","iopub.status.idle":"2021-06-17T22:23:44.655564Z","shell.execute_reply.started":"2021-06-17T22:23:44.646063Z","shell.execute_reply":"2021-06-17T22:23:44.654325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Logistic Regression\n","metadata":{"id":"u2MG1ScDT1WO"}},{"cell_type":"code","source":"model_logreg = LogisticRegression(max_iter=100, C= 10)\nmodel_logreg.fit(X_train, Y_train)\n\nprint('Precisión Logistic Regression: {:.3f}'.format(accuracy_score(Y_test, model_logreg.predict(X_test))))","metadata":{"id":"A7dxBFTvCS6y","outputId":"8ac02d46-111f-4adb-d81e-9ea90dcff25b","execution":{"iopub.status.busy":"2021-06-17T22:23:44.656962Z","iopub.execute_input":"2021-06-17T22:23:44.657375Z","iopub.status.idle":"2021-06-17T22:23:44.696581Z","shell.execute_reply.started":"2021-06-17T22:23:44.657332Z","shell.execute_reply":"2021-06-17T22:23:44.695504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Random Forest","metadata":{"id":"B9q9JrBBUSng"}},{"cell_type":"code","source":"model_rf = RandomForestClassifier(n_estimators= 100, random_state=10, max_depth=13)\nmodel_rf.fit(X_train,Y_train)\n\nprint('Precisión Random Forest: {:.3f}'.format(accuracy_score(Y_test, model_rf.predict(X_test))))","metadata":{"id":"8P2Xs5jnCW33","outputId":"e8606cd4-4b0d-4b39-e4e6-c141e077a1bf","execution":{"iopub.status.busy":"2021-06-17T22:23:44.698437Z","iopub.execute_input":"2021-06-17T22:23:44.699222Z","iopub.status.idle":"2021-06-17T22:23:45.016686Z","shell.execute_reply.started":"2021-06-17T22:23:44.69917Z","shell.execute_reply":"2021-06-17T22:23:45.015888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SVM","metadata":{"id":"rM1jlkiSUXk9"}},{"cell_type":"code","source":"model_svc = SVC(C=1)\nmodel_svc.fit(X_train,Y_train)\n\nprint('Precisión Support vector machine: {:.3f}'.format(accuracy_score(Y_test, model_svc.predict(X_test))))","metadata":{"id":"HUKOptAuCZQ8","outputId":"234b2123-de86-48eb-edf8-37a9e39244ae","execution":{"iopub.status.busy":"2021-06-17T22:23:45.018006Z","iopub.execute_input":"2021-06-17T22:23:45.018582Z","iopub.status.idle":"2021-06-17T22:23:45.101047Z","shell.execute_reply.started":"2021-06-17T22:23:45.018543Z","shell.execute_reply":"2021-06-17T22:23:45.100023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Luego de calcular la precisión de los modelos, se hace uso de *Cross Validation* para poder generalizar el modelo y confirmar que está bien adaptado.","metadata":{"id":"dy9laKywUo9S"}},{"cell_type":"code","source":"kfold = model_selection.KFold(n_splits=20)\nmodelCV = RandomForestClassifier()\nscoring = 'accuracy'\nresults = model_selection.cross_val_score(modelCV, X_train, Y_train, cv=kfold, scoring=scoring)\nprint(\"Precisión promedio 10-fold cross validation: %.3f\" % (results.mean()))","metadata":{"id":"vwhffim1Ccja","outputId":"d736abc4-8c70-499b-d55d-1d468f0a250e","execution":{"iopub.status.busy":"2021-06-17T22:23:45.102238Z","iopub.execute_input":"2021-06-17T22:23:45.102617Z","iopub.status.idle":"2021-06-17T22:23:50.358375Z","shell.execute_reply.started":"2021-06-17T22:23:45.102584Z","shell.execute_reply":"2021-06-17T22:23:50.357379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Como la precisión promedio resultó ser bastante cercana a la predicción del modelo, se puede decir que este está bien adaptado.","metadata":{"id":"IyEFXM7lVTgu"}},{"cell_type":"markdown","source":"**Precision/Recall/F1 score**\n\n---\n\n\n\nEstas variables nos ayudan a corrobar la calidad de las predicciones de los modelos establecidos.\n\n\n","metadata":{"id":"7Qf_ZSJ5VkNT"}},{"cell_type":"markdown","source":"Logistic Regression","metadata":{"id":"YpTlE-9fWzqh"}},{"cell_type":"code","source":"print(classification_report(Y_test, model_logreg.predict(X_test)))","metadata":{"id":"2oZRNlZpW2Ia","outputId":"54163a37-84f0-46dd-db21-c03771125cd1","execution":{"iopub.status.busy":"2021-06-17T22:23:50.359471Z","iopub.execute_input":"2021-06-17T22:23:50.359771Z","iopub.status.idle":"2021-06-17T22:23:50.375009Z","shell.execute_reply.started":"2021-06-17T22:23:50.359713Z","shell.execute_reply":"2021-06-17T22:23:50.373451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Random Forest","metadata":{"id":"qNvRrUMxcEjB"}},{"cell_type":"code","source":"print(classification_report(Y_test, model_rf.predict(X_test)))","metadata":{"id":"eu6AL1C9cIYI","outputId":"acb30eee-a8e6-4845-80ce-fc96fa82278e","execution":{"iopub.status.busy":"2021-06-17T22:23:50.37712Z","iopub.execute_input":"2021-06-17T22:23:50.377704Z","iopub.status.idle":"2021-06-17T22:23:50.420976Z","shell.execute_reply.started":"2021-06-17T22:23:50.377652Z","shell.execute_reply":"2021-06-17T22:23:50.41986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SVM","metadata":{"id":"bv96klplcLBX"}},{"cell_type":"code","source":"print(classification_report(Y_test, model_svc.predict(X_test)))","metadata":{"id":"a6sXdiOUCfaM","outputId":"124aba11-9bba-4ac0-8f34-1828c555129a","execution":{"iopub.status.busy":"2021-06-17T22:23:50.422597Z","iopub.execute_input":"2021-06-17T22:23:50.423212Z","iopub.status.idle":"2021-06-17T22:23:50.487074Z","shell.execute_reply.started":"2021-06-17T22:23:50.423165Z","shell.execute_reply":"2021-06-17T22:23:50.486348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"De los modelos estudiados, Random Forest es el que tiene un mayor precision, lo que indica que al momento de predecir la rotación de un trabajador, este realmente abandona su trabajo. Por otro lado Loggistic regression presentó el menor valor. Lo mismo pasa con la variable Recall, que indica cuando un trabajador abandona, cuan a menudo el modelo lo predice correctamente.","metadata":{"id":"drG66BE0hgUR"}},{"cell_type":"markdown","source":"**Curva ROC**\n\n---\n\nEsta curva muestra la tasa de verdaderos positivos en función de falsos positivos para distintos umbrales de clasificación.\n\n","metadata":{"id":"rgUxdyYKkBPZ"}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\n\nlogit_roc_auc = roc_auc_score(Y_test, model_logreg.predict(X_test))\nfpr, tpr, thresholds = roc_curve(Y_test, model_logreg.predict_proba(X_test)[:,1])\n\nrf_roc_auc = roc_auc_score(Y_test, model_rf.predict(X_test))\nrf_fpr, rf_tpr, rf_thresholds = roc_curve(Y_test, model_rf.predict_proba(X_test)[:,1])\n\n\nplt.figure()\nplt.figure(figsize=(10, 10))\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\nplt.plot(rf_fpr, rf_tpr, label='Random Forest (area = %0.2f)' % rf_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('Tasa False Positive')\nplt.ylabel('Tasa True Positive')\nplt.title('ROC')\nplt.legend(loc=\"lower right\")\nplt.savefig('ROC')","metadata":{"id":"sWkmlMkVCkYO","outputId":"c9aa47d2-a416-49db-9e41-03bd62a8aae2","execution":{"iopub.status.busy":"2021-06-17T22:23:50.488097Z","iopub.execute_input":"2021-06-17T22:23:50.48838Z","iopub.status.idle":"2021-06-17T22:23:50.853012Z","shell.execute_reply.started":"2021-06-17T22:23:50.488354Z","shell.execute_reply":"2021-06-17T22:23:50.851976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"En la gráfica reciente se muestran dos modelos de predicción, los cuales están alejados de la curva roja (representa una curva pura aleatoria). Mientrás más alejados de esta, mayor precision y recall presentará el modelo.","metadata":{"id":"_HSUdgU5mXDI"}},{"cell_type":"markdown","source":"#IV. Evaluación de un algoritmo de aprendizaje\n\n\n\n\n","metadata":{"id":"u0QtGuB0nXo0"}},{"cell_type":"markdown","source":"---\n**Learning Curves**","metadata":{"id":"F4axYNCItXTS"}},{"cell_type":"code","source":"##### EVALUATING A LEARNING ALGORITHM\n## VALIDATION CURVES -> En función de algún \"hyperparameters\"\nfrom sklearn.model_selection import validation_curve, learning_curve\nfrom sklearn.naive_bayes import GaussianNB\n\ndef plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n    \"\"\"\n    Generate 3 plots: the test and training learning curve, the training\n    samples vs fit times curve, the fit times vs score curve.\n\n    Parameters\n    ----------\n    estimator : estimator instance\n        An estimator instance implementing `fit` and `predict` methods which\n        will be cloned for each validation.\n\n    title : str\n        Title for the chart.\n\n    X : array-like of shape (n_samples, n_features)\n        Training vector, where ``n_samples`` is the number of samples and\n        ``n_features`` is the number of features.\n\n    y : array-like of shape (n_samples) or (n_samples, n_features)\n        Target relative to ``X`` for classification or regression;\n        None for unsupervised learning.\n\n    axes : array-like of shape (3,), default=None\n        Axes to use for plotting the curves.\n\n    ylim : tuple of shape (2,), default=None\n        Defines minimum and maximum y-values plotted, e.g. (ymin, ymax).\n\n    cv : int, cross-validation generator or an iterable, default=None\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n\n          - None, to use the default 5-fold cross-validation,\n          - integer, to specify the number of folds.\n          - :term:`CV splitter`,\n          - An iterable yielding (train, test) splits as arrays of indices.\n\n        For integer/None inputs, if ``y`` is binary or multiclass,\n        :class:`StratifiedKFold` used. If the estimator is not a classifier\n        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validators that can be used here.\n\n    n_jobs : int or None, default=None\n        Number of jobs to run in parallel.\n        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n        for more details.\n\n    train_sizes : array-like of shape (n_ticks,)\n        Relative or absolute numbers of training examples that will be used to\n        generate the learning curve. If the ``dtype`` is float, it is regarded\n        as a fraction of the maximum size of the training set (that is\n        determined by the selected validation method), i.e. it has to be within\n        (0, 1]. Otherwise it is interpreted as absolute sizes of the training\n        sets. Note that for classification the number of samples usually have\n        to be big enough to contain at least one sample from each class.\n        (default: np.linspace(0.1, 1.0, 5))\n    \"\"\"\n    if axes is None:\n        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n\n    axes[0].set_title(title)\n    if ylim is not None:\n        axes[0].set_ylim(*ylim)\n    axes[0].set_xlabel(\"Training examples\")\n    axes[0].set_ylabel(\"Score\")\n\n    train_sizes, train_scores, test_scores, fit_times, _ = \\\n        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n                       train_sizes=train_sizes,\n                       return_times=True)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    fit_times_mean = np.mean(fit_times, axis=1)\n    fit_times_std = np.std(fit_times, axis=1)\n\n    # Plot learning curve\n    axes[0].grid()\n    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n                         train_scores_mean + train_scores_std, alpha=0.1,\n                         color=\"r\")\n    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n                         test_scores_mean + test_scores_std, alpha=0.1,\n                         color=\"g\")\n    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n                 label=\"Training score\")\n    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n                 label=\"Cross-validation score\")\n    axes[0].legend(loc=\"best\")\n\n    # Plot n_samples vs fit_times\n    axes[1].grid()\n    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n                         fit_times_mean + fit_times_std, alpha=0.1)\n    axes[1].set_xlabel(\"Training examples\")\n    axes[1].set_ylabel(\"fit_times\")\n    axes[1].set_title(\"Scalability of the model\")\n\n    # Plot fit_time vs score\n    axes[2].grid()\n    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n                         test_scores_mean + test_scores_std, alpha=0.1)\n    axes[2].set_xlabel(\"fit_times\")\n    axes[2].set_ylabel(\"Score\")\n    axes[2].set_title(\"Performance of the model\")\n\n    return plt\n\n\nfig, axes = plt.subplots(3, 2, figsize=(10, 15))\n\ntitle = \"Learning Curves (Naive Bayes)\"\n# Cross validation with 100 iterations to get smoother mean test and train\n# score curves, each time with 20% data randomly selected as a validation set.\ncv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n\nestimator = GaussianNB()\nplot_learning_curve(estimator, title, X2, Y, axes=axes[:, 0], ylim=(0.0, 1.01),\n                    cv=cv, n_jobs=4)\n\ntitle = r\"Learning Curves (SVM, RBF kernel, $\\gamma=0.001$)\"\n# SVC is more expensive so we do a lower number of CV iterations:\ncv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\nestimator = SVC(gamma=0.001)\nplot_learning_curve(estimator, title, X2, Y, axes=axes[:, 1], ylim=(0.0, 1.01),\n                    cv=cv, n_jobs=4)\n\nplt.show()\n\n","metadata":{"id":"oTjwYs5a0nlL","outputId":"ddde8c4c-8e34-483d-d800-8249367af1b1","execution":{"iopub.status.busy":"2021-06-17T22:23:50.854601Z","iopub.execute_input":"2021-06-17T22:23:50.855Z","iopub.status.idle":"2021-06-17T22:23:56.857803Z","shell.execute_reply.started":"2021-06-17T22:23:50.854956Z","shell.execute_reply":"2021-06-17T22:23:56.85665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Observaciones\n\n\n\n\n\n","metadata":{"id":"7o-cKabldLgH"}},{"cell_type":"markdown","source":"---\n* El análisis estadístico como los histogramas, nos brindan importantes observaciones a analizar a prior al modelo de predicción; dándonos una idea de que variables \"podrian\" tener mayor impacto en la rotación de trabajadores. Para este caso se observa que las variables, tales como, **gender, industry y profession**, tienen patrones muy marcados en la rotación. Además, los histogramas nos dan información acerca de que tan sesgada es la data recolectada, lo cual no siempre es beneficioso para el modelo de predicción.\n\n* Con respecto a Machine learning los modelos arrojaron los siguientes resultados: Logistic regression 63.7%, Random Forest 69% y SVM 67%, con Random Forest como el modelo que más se ajusta la data. La elección de estos fue debido a su bajo coste computacional (tiempo de ejecución) y además porque soy ampliamente utilizados. Si bien soy diferentes entre si, se infiere que pudieron adaptarse de manera simil a los datos entregados. Cabe destacar, que existen otros modelos más precisos y complejos, como Neural Network, pero computacionalmente es más costoso. \n\n  Volviendo a los resultados arrojados por los modelos de predicción, se observa que son bastante bajos (entre 60-70%), por lo que se debe analizar el desempeño de estos con lo siguiente:\n\n* Evaluar tu algoritmo de aprendizaje\n    * Iniciando con la evaluación de tu hipótesis; que tu modelo tenga bajo error, no significa que es necesariamente una buen hipótesis (ejemplo: overfitting). Para ello se utiliza la separación de data (la cual se utilizó en este análisis).\n    * En segunda instancia, aumentar el grado de tu selección de modelo y escoger la que tenga menor error.\n\n* Análisis de Bias vs Variance\n    * Para minimizar el error de un modelo (ya sea, under/over fitting), se diagnóstica como varía el error de tu modelo en función de parametros, tales como, grado, regularización y cantidad de ejemplos.\n    * Si necesito ajustar la varianza, puedo agregar más datos o incrementar el parametro de regularización. Por otro lado, para arreglar el bias, es posible obtener más características.\n\n  Con lo nombrado anteriormente, es posible disminuir el error y por ende aumentar la calidad del modelo. Lo ideal es encontrar un equilibrio entre bias y variance.  Si con estos análisis de modelos, no se logra un aumento significativo, cabe la opción es que los modelos seleccionados no se ajustan bien a la data (recordar que en esta existen variables númericas y categóricas) o tambíen cabe la posibilidad que los datos recolectados no tengan un correlación con la tasa de rotación.\n\n* Ahora, para evaluar el desempeño de los modelos predictivos se utilizan los parámetros Precision/Recall y F1 score. De los resultados entregados se observa que Random Forest obtuvo los mayores resultados (73%/65%  Precision/Recall, respectivamente. Y 69% F1 score), y Logistic regression lo más bajos (68%, 57% y 64%).\n\n  Cabe recordar que los parámetros Precision/Recall funcionan como un trade-off (como se muestra en el gráfico de ROC). Por lo que si quiero mejorar la precision del modelo (en este caso, predecir un empleado con riesgo de rotación) debo sacrificar el recall (a modo general). Esto significa que se debe restringir las predicciones positivas a aquellas con mayor certeza en el modelo, lo que se traduce en predecir menos resultados positivos (con esto se refiere a que, si el modelo predice una cierta cantidad de rotaciones, lo más probable es que sea conrrectas). Lo que además significa, que al tener un menor recall tendré menos aciertos de la realidad (no podré identificar a las personas con alto riesgo de rotación antes de contratarla).\n\n* Por último se encontraron que las variables más relacionadas con la rotación son: Los parametros de medición de salud (anxiety, extraversion, selfcontrol, novator, independ), age, stage, industry retail y profession_HR, los cuales tiene un rango de importancia entre 2 y 14%.","metadata":{"id":"omVlkwKoQhsj"}},{"cell_type":"markdown","source":"# Conclusiones\n\n\n","metadata":{"id":"D_qWO6IsQVO_"}},{"cell_type":"markdown","source":"---\n\nEl objetivo principal fue estudiar la tasas de rotación mediante Machine learning dada una cierta base de datos con datos números y no númericos. Para ello se utilizaron distintos modelos de predicción los cuales dieron como resultado una exactitud entre 64-70%, lo cual parece bastante bajo; una de las posibilidades es que los modelos no se ajustan bien a este tipo de datos (datos cuantitativos y cualitativos) o bien los datos no tienen correlación alguna con la rotación de trabajadores. Una observación importante a destacar es el sesgo de los datos; lo más óptimo es distribuir de manera equitativa, a modo de ejemplo, se tiene la profesión HR, la cual tiene la mayoria de los datos.\n\nPara poder mejorar la predicción de los modelos se debe tener en consideración lo anteriormente mencionado, y además, lo ideal es obtener datos más influyentes en la toma decisión de rotación de los empleados; a modo de sugerencia se pueden examinar las siguientes característics: Salario (bajo-medio-alto), Promoción (aumento de sueldo/cargo) y lejanía (distancia hogar-trabajo).","metadata":{"id":"DmtsZN5mluef"}}]}