{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# General\nimport os\nimport time\nfrom random import shuffle\n\n# Math\nimport numpy as np \n# Data management\nimport pandas as pd\n# Data Visualizatoin\nimport matplotlib.pyplot as plt\n# %matplotlib inline\n\n# Machine Learning\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n\n\nimport wavio\nimport librosa\nimport librosa.display\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data_dir = '../input/respiratory_sound_database'\n\ndemogr_fname = '../input/respiratory-sound-database/demographic_info.txt'\ndemogrCol_strLst = ['Patient number', 'Age', 'Sex' , 'Adult BMI (kg/m2)', 'Child Weight (kg)' , 'Child Height (cm)']\ndemogr_df = pd.read_csv(\n    demogr_fname, \n    names = demogrCol_strLst,\n    delimiter = ' ',\n)\n\ndemogr_fname = '../input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/patient_diagnosis.csv'\ndiagnosisCol_strLst = ['Patient number', 'Diagnosis']\ndiagnosis_df = pd.read_csv(\n    demogr_fname,\n    names = diagnosisCol_strLst,\n)\n\ndata_dname = '../input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/'\nrecords_idLst = [s.split('.')[0] for s in os.listdir(path = data_dname) if '.txt' in s]\n\nprint(\"# Of recordings: %d\"%(len(records_idLst)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def loadData(record_id, dry = False):\n    \n    data_fname = record_id + '.wav'\n    annotation_fname = record_id + '.txt'\n    \n    if not dry:\n        wave_data = wavio.read(data_dname+'/'+data_fname)\n        waveform_np = wave_data.data.astype(float).flatten()\n        waveWidth_int= wave_data.sampwidth\n\n        # Get the info of the wavefile\n        fs = wave_data.rate # Sampling frequency\n        N = waveform_np.shape[0]\n        \n    else:\n        waveform_np = None\n        fs = float('nan')\n        N = float('nan')\n    Ts = 1.0 / fs;\n    AT = Ts * N    \n\n    tokens_strLst = record_id.split('_') + [fs, N, AT, Ts]\n    \n    infoLabels_strLst = ['Patient number', 'Recording index', 'Chest location','Acquisition mode','Recording equipment', 'fs', 'N', 'AT', 'Ts']\n    recordInfo_dict = dict(zip(infoLabels_strLst,tokens_strLst))\n    \n    dataCols_strLst = ['Start', 'End', 'Crackles', 'Wheezes']\n    recAnnotations_df = pd.read_csv(\n        os.path.join(data_dname, annotation_fname), \n        names = dataCols_strLst,\n        delimiter= '\\t'\n    )\n    \n    return (waveform_np, recordInfo_dict, recAnnotations_df)\n\n(waveform_np, recordInfo_dict, recAnnotations_df) = loadData(records_idLst[0], 0)\n_, recordInfo_dict, recAnnotations_df = loadData(records_idLst[0], 1)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Class to time the execution blocks\nclass Timer():\n    # Static variable for verbosity\n    quiet = False\n    \n    # Init the class\n    def __init__(self, str): \n        # print('init method called') \n        self.str = str\n        \n    # Enter the context\n    def __enter__(self):\n        # print('enter method called') \n        self.tick = time.time()\n        return self\n    \n    # Leave the context\n    def __exit__(self, exc_type, exc_value, exc_traceback): \n        if not Timer.quiet:\n            print(\"%s: \\t%.3f s\"%(self.str, time.time() - self.tick))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of respiratory cycle lengths\n\nrespDuration_ser = pd.Series([],dtype='float64')\nfor record_id in records_idLst:\n    _, recordInfo_dict, recAnnotations_df = loadData(record_id, dry = True)\n    respDuration_ser = respDuration_ser.append(recAnnotations_df['End'] - recAnnotations_df['Start'])\n\nplt.figure(figsize=(16,16))\nrespDuration_ser.hist(bins=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature extraction\n\n# Parameters\nframeLength_int = 2**13\nframeHop_int = 2**11\n\n# Derivative values\nframeOvelap_int = frameLength_int - frameHop_int\n\ndef extractFeatures(waveform_np, recordInfo_dict, dry=False):\n    \n    if dry:\n        # Extract the spectrum from the waveform\n        spectrum_np = librosa.core.stft(\n           waveform_np, \n           n_fft=frameLength_int, \n           hop_length=frameHop_int, \n           win_length=frameLength_int, \n        )\n        spectrumMag_np = np.abs(spectrum_np)\n        spectrumN_int = spectrumMag_np.shape[1]\n        spectrumTime_np = np.linspace(0,recordInfo_dict['AT'],spectrumN_int)\n    else:\n        # Chroma Frequencies\n        chroma_np = librosa.feature.chroma_stft(\n            waveform_np, \n            sr=recordInfo_dict['fs'],\n            n_fft=frameLength_int, \n            hop_length=frameHop_int, \n            win_length=frameLength_int, \n        )\n\n        # Spectral Centroid\n        spectralCentroid_np = librosa.feature.spectral_centroid(\n            waveform_np,\n            sr=recordInfo_dict['fs'],\n            n_fft=frameLength_int, \n            hop_length=frameHop_int, \n            win_length=frameLength_int, \n        )\n\n        # Spectral Bandwidth\n        spectralBandwidth_np = librosa.feature.spectral_bandwidth(\n            waveform_np, \n            sr=recordInfo_dict['fs'],\n            n_fft=frameLength_int, \n            hop_length=frameHop_int, \n            win_length=frameLength_int, \n        )\n\n        # Spectral Roll-off\n        spectralRolloff_np = librosa.feature.spectral_rolloff(\n            waveform_np,\n            sr=recordInfo_dict['fs'],\n            n_fft=frameLength_int, \n            hop_length=frameHop_int, \n            win_length=frameLength_int, \n        )\n\n        # Zero Crossing Rate\n        spectralZeroCrossing_zp = librosa.feature.zero_crossing_rate(\n            waveform_np,\n            hop_length=frameHop_int, \n            frame_length=frameLength_int, \n        )\n\n        # Mel Cepstral Coeffs (MFCC)\n        mfcc_np = librosa.feature.mfcc(\n            waveform_np,\n            sr=recordInfo_dict['fs'],\n            n_fft=frameLength_int, \n            hop_length=frameHop_int, \n            win_length=frameLength_int, \n        )\n\n    features_np = np.concatenate((\n#        spectrumMag_np,\n        spectralCentroid_np,\n        spectralBandwidth_np,\n        spectralRolloff_np,\n        spectralZeroCrossing_zp,\n#        chroma_np,\n        mfcc_np,\n    )).T\n    \n    \n    \n    scaler = preprocessing.StandardScaler()\n    #scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n    features_np = scaler.fit_transform(features_np)\n        \n    return features_np\n\n\n(waveform_np, recordInfo_dict, recAnnotations_df) = loadData(records_idLst[0])\nfeatures_np = extractFeatures(waveform_np, recordInfo_dict)\n\nplt.figure(figsize=(16,16))\nlibrosa.display.specshow(\n    #   librosa.amplitude_to_db(features_np, ref=np.max),\n    features_np,\n    #   x_coords=spectrumTime_np,\n    #y_axis='time',\n    #x_axis='log',\n    cmap = 'seismic'\n)\n\nprint(features_np.shape)\nprint(features_np.min(axis=0))\nprint(features_np.mean(axis=0))\nprint(features_np.max(axis=0))\nprint(features_np.std(axis=0))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"M = features_np.shape[1]\nrows = np.ceil(np.sqrt(M))\ncols = np.ceil(np.sqrt(M))\nplt.figure(figsize=(16,16))\n\n\nfor i in range(M):\n    plt.subplot(rows,cols,i+1)\n    #plt.plot(t_np,features_np[:,i])\n    plt.hist(features_np[:,i], bins=50)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display a representative spectrum\n\nspectrum_np = librosa.core.stft(\n   waveform_np, \n   n_fft=frameLength_int, \n   hop_length=frameHop_int, \n   win_length=frameLength_int, \n)\nspectrumMagLog_np = np.log(np.abs(spectrum_np))\nspectrumN_int = spectrumMagLog_np.shape[1]\nspectrumTime_np = np.linspace(0,recordInfo_dict['AT'],spectrumN_int)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert the annotations to a usable Y vector\n# TODO: Perhaps we can use a complex periodic signal i.e. 2 output vectors\n\ndef annotations2Y(recAnnotations_df, recordInfo_dict):\n\n    # Variables\n    t = spectrumTime_np\n    Y = np.zeros(t.shape[0])\n    lag_f = 0\n    \n    for row in recAnnotations_df.itertuples():\n        start_f = row.Start\n        stop_f = row.End\n        duration_f = stop_f - start_f\n        mask_b = np.logical_and(t >= start_f, t < stop_f)\n        x = 0.5 - np.cos(2*np.pi*(t-stop_f)/duration_f)/2\n        \n        Y[mask_b] = x[mask_b]\n        \n    return t,Y\n\nt_np, Y_np = annotations2Y(recAnnotations_df, recordInfo_dict)\n\nplt.figure(figsize=(24,8))\nlibrosa.display.specshow(\n    spectrumMagLog_np,\n    x_coords=spectrumTime_np,\n    y_axis='log',\n    x_axis='time',\n)\n# Draw the Y over the spectrogram\nplt.plot(t_np,Y_np*8000)\nplt.colorbar()\n\nprint(spectrumMagLog_np.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Temp, this code block is for testing purposes\n# Ignore\n\nspectrum_np = librosa.core.stft(\n    waveform_np, \n    n_fft=frameLength_int, \n    hop_length=frameHop_int, \n    win_length=frameLength_int, \n)\nspectrumMag_np = np.abs(spectrum_np)\nspectrumN_int = spectrumMag_np.shape[1]\nspectrumTime_np = np.linspace(0,recordInfo_dict['AT'],spectrumN_int)\n\n#plt.figure(figsize=(16,16))\n#librosa.display.specshow(\n#    librosa.amplitude_to_db(spectrumMag_np, ref=np.max),\n#    #spectrumMag_np,\n#    x_coords=spectrumTime_np,\n#    x_axis='time',\n#    y_axis='log',\n#    cmap = 'seismic'\n#)\n\n\n\nplt.figure(figsize=(16,16))\nlibrosa.display.specshow(\n    #librosa.amplitude_to_db(spectrumMag_np, ref=np.max),\n    features_np.T,\n    x_coords=spectrumTime_np,\n    x_axis='time',\n#    y_axis='log',\n    y_axis='hz',\n#    cmap = 'seismic'\n)\nplt.plot(t_np,Y_np*8000,'g*')\nprint(features_np.shape)\nprint(spectrumTime_np.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Concatenate the files into a big dataset\n\ndef generateDataset(records_idLst):\n    \n    records_cnt = len(records_idLst)\n    \n    # This function takes time so lets do some reporting\n    print(\"Generating a dataset of %d records\"%(records_cnt))\n    \n    datasetX_np = None\n    datasetY_np = None\n    for index_int, record_id in enumerate(records_idLst):\n        \n        # Load the file\n        (waveform_np, recordInfo_dict, recAnnotations_df) = loadData(records_idLst[0])\n\n        # Extract the features\n        features_np = extractFeatures(waveform_np, recordInfo_dict, )\n\n        # Extract the target\n        t_np, Y_np = annotations2Y(recAnnotations_df, recordInfo_dict)\n\n        if datasetX_np is None:\n            datasetX_np = features_np\n            datasetY_np = Y_np\n        else:\n            datasetX_np = np.append(datasetX_np, features_np, axis=0)\n            datasetY_np = np.append(datasetY_np, Y_np)\n        print(\"Loading: %5.2f%%\\t%s\"%(100.0 * (index_int + 1) / records_cnt, record_id), end=\"\\r\")\n        \n    print(\"\")\n    print(datasetX_np.shape)\n    print(datasetY_np.shape)\n    return datasetX_np, datasetY_np\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Parameters\ntestN_cnt = 10\n\n# Randomize the dataset order\nshuffle(records_idLst)\n# Split the training and test datasets\ntrainRecords_idLst = records_idLst[testN_cnt:]\ntestRecords_idLst = records_idLst[:testN_cnt]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate and visualize the model results\n\ndef evaluateModel(model):\n    \n    trainR2_f = model.score(trainX_np, trainY_np)\n    testR2_f = model.score(testX_np, testY_np)\n    print(\"Train R2: %8.5f\\t Test R2: %8.5f\\t (%5.2f)\"%(trainR2_f,testR2_f,testR2_f/trainR2_f))\n\n    trainResult_np = model.predict(trainX_np)\n    testResult_np = model.predict(testX_np)\n    visualResult_np = model.predict(visualX_np)\n\n    trainMAE_f = metrics.mean_absolute_error(trainY_np, trainResult_np)\n    testMAE_f = metrics.mean_absolute_error(testY_np, testResult_np)\n    print(\"Train MAE: %8.5f\\t Test MAE: %8.5f\\t (%5.2f)\"%(trainMAE_f,testMAE_f,testMAE_f/trainMAE_f))\n\n    # Visualize the test performance\n    visualX_np, visualY_np\n\n    plt.figure(figsize=(24,10))\n    \n    plt.subplot(211)\n    plt.plot(trainY_np[:visualN_cnt],'g')\n    plt.plot(trainResult_np[:visualN_cnt],'b.')\n    plt.title('Training Set fit')\n    \n    plt.subplot(212)\n    plt.plot(visualY_np,'g')\n    plt.plot(visualResult_np,'b.')\n    plt.title('Test Set fit')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the training dataset\n\nwith Timer(\"Training set generation:\"):\n    trainX_np, trainY_np = generateDataset(trainRecords_idLst)\nprint(\"Training dataset consists of %d records\"%(len(trainRecords_idLst)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the test set\n\ntestX_np, testY_np = generateDataset(testRecords_idLst)\n\nprint(\"Test dataset consists of %d records\"%(len(testRecords_idLst)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pick a record from the validation set to do the visualization\n\nrecords_idLst = [testRecords_idLst[0]]\n#records_idLst = [trainRecords_idLst[0]]\n\nvisualX_np, visualY_np = generateDataset(records_idLst)\nvisualN_cnt = visualX_np.shape[0]\n\n(waveform_np, recordInfo_dict, recAnnotations_df) = loadData(records_idLst[0], False)\n\nprint(\"N:\",recordInfo_dict['N'])\nprint(\"AT:\",recordInfo_dict['AT'])\n\nplt.figure(figsize=(24,10))\nplt.subplot(211)\nplt.plot(trainY_np[:visualN_cnt],'g')\nplt.subplot(212)\nplt.plot(visualY_np,'g')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Try Linear Regression\n\nmodel = LinearRegression()\n\nwith Timer(\"Training Linear Regression:\"):\n    model.fit(trainX_np,trainY_np)\n\nevaluateModel(model)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Try Decision Tree Regression\n\nfrom sklearn.tree import DecisionTreeRegressor\n\nmodel = DecisionTreeRegressor(\n    criterion = 'mse',\n#    max_depth = 15,\n)\n\nwith Timer(\"Training Decision Tree Regression:\"):\n    model.fit(trainX_np,trainY_np)\n\n\nevaluateModel(model)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Try Random Forest Regression\n\nfrom sklearn.ensemble import RandomForestRegressor \n\nmodel = RandomForestRegressor(\n    n_estimators = 30,\n#    max_depth = 10,\n#    min_samples_split = 100,   \n#    random_state = 0,\n) \n\nwith Timer(\"Training Random Forest Regression:\"):\n    model.fit(trainX_np,trainY_np)\n\nevaluateModel(model)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Try AdaBoost Regression\n\nfrom sklearn.ensemble import AdaBoostRegressor\n\nmodel = AdaBoostRegressor(\n#    n_estimators = 25,\n    learning_rate = 0.10,\n    loss = ['linear', 'square', 'exponential'][2],\n) \n\nwith Timer(\"Training AdaBoost Regression:\"):\n    model.fit(trainX_np,trainY_np)\n\nevaluateModel(model)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Try Gradient Boost Regression\n\nfrom sklearn.ensemble import GradientBoostingRegressor\n\nmodel = GradientBoostingRegressor(\n#    n_estimators = 25,\n    learning_rate = 0.10,\n    loss = ['ls', 'lad', 'huber', 'quantile'][1],\n) \n\nwith Timer(\"Training Gradient Boost Regression:\"):\n    model.fit(trainX_np,trainY_np)\n\nevaluateModel(model)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Try out a Multilayer Neural Network\n\nfrom keras import models\nfrom keras.optimizers import Adam \nfrom keras.layers import Dense\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# Parameters\nbatch_cnt = 1000\nlRate_float = 0.01\nvalidationFraction_f = 0.1\nlossFunction_str = \"sparse_categorical_crossentropy\"\nlossFunction_str = 'mean_squared_logarithmic_error'\nlossFunction_str = \"mean_squared_error\"\nlossFunction_str = 'mean_absolute_error'\nmetric_strList=['accuracy', 'mean_absolute_error']\n\n# Derived\ninput_cnt = trainX_np.shape[1]\nmodel = models.Sequential()\n\nmodel.add(Dense(\n    input_shape=[input_cnt],\n#    units=int(input_cnt**(1.0/2)),\n    units=input_cnt,\n    activation='sigmoid',\n))\n\nmodel.add(Dense(\n    input_shape=[input_cnt],\n    units=int(input_cnt**(1.0/2)),\n    activation='sigmoid',\n))\n\nmodel.add(Dense(\n    units = 1,\n    activation = 'sigmoid',\n))\n\nearly_stopping = EarlyStopping(\n    min_delta=1e-3, # minimium amount of change to count as an improvement\n    patience=5, # how many epochs to wait before stopping\n    restore_best_weights=True,\n)\n\nmodel.compile(\n    Adam(lr=lRate_float), \n    loss=lossFunction_str,\n    metrics=metric_strList,\n)\n\n# Derived\n\nperm = np.random.permutation(trainX_np.shape[0])\n\nwith Timer(\"Training Neural Network Regression:\"):\n    model.fit(\n        trainX_np[perm],\n        trainY_np[perm],\n        batch_size=batch_cnt,\n        epochs=100,\n        validation_split = validationFraction_f,\n#        validation_data=(\n#            validX_np, \n#            validY_np,\n#        ),\n        callbacks=[early_stopping],\n        verbose=False,\n    )\n\n#testResult_np = neuralNet_model.predict(testX_np)\n#score = neuralNet_model.score(testX_np, testY_np)\n#score = neuralNet_model.evaluate(testX_np, testY_np)\n#model.fit(trainX_np,trainY_np)\n\n\naccuracy_idx = model.metrics_names.index('accuracy')\ntrainAcc_f = model.evaluate(trainX_np, trainY_np,verbose=False,)[accuracy_idx]\ntestAcc_f = model.evaluate(testX_np, testY_np,verbose=False,)[accuracy_idx]\nprint(\"Train Acc: %8.5f\\t Test Acc: %8.5f\\t (%5.2f)\"%(trainAcc_f,testAcc_f,testAcc_f/trainAcc_f))\n\nmae_idx = model.metrics_names.index('mean_absolute_error')\ntrainMAE_f = model.evaluate(trainX_np, trainY_np,verbose=False,)[mae_idx]\ntestMAE_f = model.evaluate(testX_np, testY_np,verbose=False,)[mae_idx]\nprint(\"Train MAE: %8.5f\\t Test MAE: %8.5f\\t (%5.2f)\"%(trainMAE_f,testMAE_f,testMAE_f/trainMAE_f))\n\n# Visualize the test performance\ntrainResult_np = model.predict(trainX_np)\nvisualResult_np = model.predict(visualX_np)\n\nplt.figure(figsize=(24,10))\n\nplt.subplot(211)\nplt.plot(trainY_np[:visualN_cnt],'g')\nplt.plot(trainResult_np[:visualN_cnt],'b.')\nplt.title('Training Set fit')\n\nplt.subplot(212)\nplt.plot(visualY_np,'g')\nplt.plot(visualResult_np,'b.')\nplt.title('Test Set fit')\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}