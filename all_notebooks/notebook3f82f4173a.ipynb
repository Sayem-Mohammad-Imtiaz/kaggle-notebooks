{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport json\nfrom PIL import Image\nimport os\n\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import lr_scheduler\nimport cv2\nfrom scipy.special import softmax\n\nhyperparams = {\n    \"BATCH\": 32,\n    \"EPOCHS\": 32,\n    \"LR\": 0.0001,\n    \"model_name\": 'resnext50_32x4d'\n}\nIM_SIZE = 512\nDEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nTRAIN_DIR = '../input/cassava-leaf-disease-classification/train_images/'\nTEST_DIR = '../input/cassava-leaf-disease-classification/test_images/'\nprint(DEVICE)\n\nlabels = json.load(open(\"../input/cassava-leaf-disease-classification/label_num_to_disease_map.json\"))\ntrain = pd.read_csv('../input/cassava-leaf-disease-classification/train.csv')\n\nX_Train, Y_Train = train['image_id'].values, train['label'].values\nX_Test = [name for name in (os.listdir(TEST_DIR))]\n\nclass GetData(Dataset):\n    def __init__(self, Dir, FNames, Labels, Transform):\n        self.dir = Dir\n        self.fnames = FNames\n        self.transform = Transform\n        self.lbs = Labels\n        \n    def __len__(self):\n        return len(self.fnames)\n    \n    def __getitem__(self, index):\n        image = Image.open(os.path.join(self.dir, self.fnames[index]))\n        if \"train\" in self.dir:\n            return self.transform(image), self.lbs[index]\n        elif \"test\" in self.dir:\n            return self.transform(image), self.fnames[index]\n\nTransform = transforms.Compose(\n    [transforms.RandomResizedCrop(224),\n    transforms.Resize((IM_SIZE, IM_SIZE)),\n    transforms.RandomRotation(90),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]\n)\n\nclass CustomResnet(nn.Module):\n    def __init__(self, model_name = 'skresnext50_32x4d', pretrained = False):\n        super().__init__()\n        self.model = timm.create_model(model_name = model_name, pretrained = pretrained)\n        n_features = self.model.fc.in_features\n        self.model.fc == nn.Linear(n_features, 5, bias = True)\n    def forward(self, x):\n        return self.model(x)\n\nclass enet_v2(nn.Module):\n    def __init__(self, backbone = 'efficientnet_b3a', outdim = 5, pretrained=False):\n        super(enet_v2, self).__init__()\n        self.enet = timm.create_model(backbone, pretrained = pretrained)\n        in_ch = self.enet.classifier.in_features\n        self.myfc = nn.Linear(in_ch, outdim)\n        self.enet.classifier = nn.Identity()\n        \n    def forward(self, x):\n        x = self.enet(x)\n        x = self.myfc(x)\n        return x\n\nmodel = CustomResnet(pretrained = False)\nmodel = model.to(DEVICE)\nloss_func = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr = hyperparams[\"LR\"])\nlearning_rate_scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n\ndef finetune(model, trainloader, optimizer, learning_rate_scheduler, model_name):\n    model.train()\n    train_loss = 0.0\n    for i, (images, labels) in enumerate(tqdm(trainloader)):\n        images = images.to(DEVICE)\n        labels = labels.to(DEVICE)\n        train_result = model(images)\n        loss = loss_func(train_result, labels)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.detach().item()\n        del labels\n        del images\n        torch.cuda.empty_cache()\n    learning_rate_scheduler.step()\n    if(model_name==\"res\"):\n        torch.save(model.state_dict(), './checkpoints/'+'res.pt')\n    else:\n        torch.save(model.state_dict(), './checkpoints/'+'eff.pt')\n    print('Train Loss: %.4f'%train_loss)\n\nmodel2 = enet_v2(pretrained = False)\nmodel2 = model2.to(DEVICE)\noptimizer2 = torch.optim.Adam(model2.parameters(), lr = hyperparams[\"LR\"])\nlearning_rate_scheduler = lr_scheduler.ExponentialLR(optimizer2, gamma=0.99)\n\ndef train_res(pretrained = True):\n    trainset = GetData(TRAIN_DIR, X_Train, Y_Train, Transform)\n    trainloader = DataLoader(trainset, batch_size = hyperparams[\"BATCH\"], shuffle=True, num_workers=4)\n    os.makedirs('./checkpoints', exist_ok = True)\n    for epoch in range(hyperparams[\"EPOCHS\"]):\n        print('******* EPOCH %d / %d ********' % (epoch+1, hyperparams['EPOCHS']))\n        finetune(model, trainloader, optimizer, learning_rate_scheduler, \"res\")\n\n    print(\"resnet train finished\")\n\ndef train_eff():\n    trainset = GetData(TRAIN_DIR, X_Train, Y_Train, Transform)\n    trainloader = DataLoader(trainset, batch_size = hyperparams[\"BATCH\"], shuffle=True, num_workers=4)\n    os.makedirs('./checkpoints', exist_ok = True)\n    for epoch in range(hyperparams[\"EPOCHS\"]):\n         print('******* EPOCH %d / %d ********' % (epoch+1, hyperparams['EPOCHS']))\n         finetune(model2, trainloader, optimizer2, learning_rate_scheduler, \"eff\")\n\n    print(\"effnet train finished\")\n\n# train_res()\n# train_eff()\n\n######################infer########################\n\ndef infer():\n    testset = GetData(TEST_DIR, X_Test, None, Transform)\n    testloader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)\n    res_preds = []\n    eff_preds = []\n    model.load_state_dict(torch.load('../input/checkpoint5/res.pt', map_location = DEVICE))\n    model2.load_state_dict(torch.load('../input/checkpoint6/eff.pt', map_location = DEVICE))\n    model.eval()\n\n    files = []\n\n    with torch.no_grad():\n        for image, fname in tqdm(testloader):\n            image = image.to(DEVICE)\n            logits = model(image)\n            ps = torch.exp(logits)\n            res_preds += [torch.softmax(logits, 1).detach().cpu()]\n            files.append(fname[0])\n        res_preds = torch.cat(res_preds).cpu().numpy()\n    model2.eval()\n    with torch.no_grad():\n        for image, fname in tqdm(testloader):\n            x = image.to(DEVICE)\n            x = torch.stack([x,x.flip(-1),x.flip(-2),x.flip(-1,-2),\n            x.transpose(-1,-2),x.transpose(-1,-2).flip(-1),\n            x.transpose(-1,-2).flip(-2),x.transpose(-1,-2).flip(-1,-2)],0)\n            x = x.view(-1, 3, IM_SIZE, IM_SIZE)\n            logits = model(x)\n            logits = logits.view(1, 8, -1).mean(1)\n            eff_preds += [torch.softmax(logits, 1).detach().cpu()]\n\n        eff_preds = torch.cat(eff_preds).cpu().numpy()\n    pred = 0.5*res_preds + 0.5 *eff_preds\n    \n    return pred, files\n\nfin_pred, files = infer()\ns_ls = []\nfin = softmax(fin_pred).argmax(1)\n\nfor i in range(len(fin_pred)):\n    s_ls.append([files[i], fin[i]])\n\nsub = pd.DataFrame.from_records(s_ls, columns=['image_id', 'label'])\nsub.to_csv(\"submission.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}