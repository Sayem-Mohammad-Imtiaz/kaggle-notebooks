{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-11T22:41:24.154564Z","iopub.execute_input":"2021-07-11T22:41:24.154951Z","iopub.status.idle":"2021-07-11T22:41:24.167388Z","shell.execute_reply.started":"2021-07-11T22:41:24.154914Z","shell.execute_reply":"2021-07-11T22:41:24.166326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Project WeRateDogs Twitter Data: Wrangle and Analyze Data","metadata":{}},{"cell_type":"markdown","source":"# importing libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport datetime\nimport json\n#import tweepy\nimport os\nimport re\nimport requests","metadata":{"execution":{"iopub.status.busy":"2021-07-11T22:42:06.764872Z","iopub.execute_input":"2021-07-11T22:42:06.765357Z","iopub.status.idle":"2021-07-11T22:42:06.771549Z","shell.execute_reply.started":"2021-07-11T22:42:06.765326Z","shell.execute_reply":"2021-07-11T22:42:06.770635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Gathering data","metadata":{}},{"cell_type":"code","source":"#I will gather data from a variety of sources and in a variety of formats:\n\n#from :\n\n#1- Download this file manually: \n#This file (twitter_archive_enhanced.csv)\n#The WeRateDogs Twitter archive,\n\n#2- Downloaded programmatically using the requests library and the following \n#URL: https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv  \n#This file (image_predictions.tsv)\n#The tweet image predictions, i.e., what breed of dog (or other object, animal, etc.)\n# is present in each tweet according to a neural network is hosted on Udacity's servers\n\n#3- Query the Twitter API :\n#for each tweet's JSON data using Python's Tweepy library and store each tweet's entire set of JSON data\n#in a file called tweet_json.txt file.\n#This file (tweet_json.txt)\n#Each tweet's JSON data should be written to its own line.\n#Then \n#Reading this file line by line into a pandas DataFrame with  tweet ID, retweet count, and favorite count. ","metadata":{"execution":{"iopub.status.busy":"2021-07-11T22:42:14.70021Z","iopub.execute_input":"2021-07-11T22:42:14.70058Z","iopub.status.idle":"2021-07-11T22:42:14.705366Z","shell.execute_reply.started":"2021-07-11T22:42:14.70054Z","shell.execute_reply":"2021-07-11T22:42:14.704666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" # 1- Download this file manually: This file (twitter_archive_enhanced.csv)","metadata":{}},{"cell_type":"code","source":"df_twt = pd.read_csv('../input/weratedogs/twitter-archive-enhanced.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-11T22:42:22.106196Z","iopub.execute_input":"2021-07-11T22:42:22.10657Z","iopub.status.idle":"2021-07-11T22:42:22.137382Z","shell.execute_reply.started":"2021-07-11T22:42:22.106534Z","shell.execute_reply":"2021-07-11T22:42:22.136272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_twt.sample(3)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T22:42:31.007874Z","iopub.execute_input":"2021-07-11T22:42:31.008248Z","iopub.status.idle":"2021-07-11T22:42:31.029186Z","shell.execute_reply.started":"2021-07-11T22:42:31.008215Z","shell.execute_reply":"2021-07-11T22:42:31.028402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2- Downloaded manually: This file (image_predictions.tsv)","metadata":{}},{"cell_type":"code","source":"df_img = pd.read_csv('../input/image-predictions/image_predictions.tsv', sep = '\\t')","metadata":{"execution":{"iopub.status.busy":"2021-07-11T22:52:14.724661Z","iopub.execute_input":"2021-07-11T22:52:14.72503Z","iopub.status.idle":"2021-07-11T22:52:14.753959Z","shell.execute_reply.started":"2021-07-11T22:52:14.724997Z","shell.execute_reply":"2021-07-11T22:52:14.752903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_img.sample(1)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T22:52:42.053631Z","iopub.execute_input":"2021-07-11T22:52:42.05397Z","iopub.status.idle":"2021-07-11T22:52:42.071468Z","shell.execute_reply.started":"2021-07-11T22:52:42.053941Z","shell.execute_reply":"2021-07-11T22:52:42.070542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3- Additional Data via the Twitter API: This file ( tweet_json.txt)Â¶\n# Accessing Project Data Without a Twitter Account\n# I can't set up a Twitter developer account so i instead follow the directions below by udacity to access the data necessary for the project.","metadata":{}},{"cell_type":"code","source":"# Reading the json file\nid_twt = []\nnum_fav = []\nnum_ret = []\nwith open('../input/tweet-json/tweet_json.txt', mode = 'r') as f:\n     for line in f.readlines():\n            tweet_data = json.loads(line)\n            id_twt.append(tweet_data['id'])\n            num_fav.append(tweet_data['favorite_count'])\n            num_ret.append(tweet_data['retweet_count'])\n            \ndf_json = pd.DataFrame({'tweet_id':id_twt, 'favorite_count':num_fav, 'retweet_count':num_ret})","metadata":{"execution":{"iopub.status.busy":"2021-07-11T22:56:25.743841Z","iopub.execute_input":"2021-07-11T22:56:25.744178Z","iopub.status.idle":"2021-07-11T22:56:26.020894Z","shell.execute_reply.started":"2021-07-11T22:56:25.74415Z","shell.execute_reply":"2021-07-11T22:56:26.019856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_json.sample(1)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T22:56:56.219418Z","iopub.execute_input":"2021-07-11T22:56:56.21979Z","iopub.status.idle":"2021-07-11T22:56:56.22942Z","shell.execute_reply.started":"2021-07-11T22:56:56.219751Z","shell.execute_reply":"2021-07-11T22:56:56.228665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_json.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T22:58:15.558975Z","iopub.execute_input":"2021-07-11T22:58:15.559324Z","iopub.status.idle":"2021-07-11T22:58:15.579278Z","shell.execute_reply.started":"2021-07-11T22:58:15.559294Z","shell.execute_reply":"2021-07-11T22:58:15.578478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_twt.tail(1)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T22:58:52.222964Z","iopub.execute_input":"2021-07-11T22:58:52.223508Z","iopub.status.idle":"2021-07-11T22:58:52.244477Z","shell.execute_reply.started":"2021-07-11T22:58:52.223475Z","shell.execute_reply":"2021-07-11T22:58:52.243518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_img.tail(1)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T22:59:26.633498Z","iopub.execute_input":"2021-07-11T22:59:26.63387Z","iopub.status.idle":"2021-07-11T22:59:26.649134Z","shell.execute_reply.started":"2021-07-11T22:59:26.633835Z","shell.execute_reply":"2021-07-11T22:59:26.648122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_json.tail(1)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T22:59:52.870129Z","iopub.execute_input":"2021-07-11T22:59:52.870474Z","iopub.status.idle":"2021-07-11T22:59:52.879885Z","shell.execute_reply.started":"2021-07-11T22:59:52.870443Z","shell.execute_reply":"2021-07-11T22:59:52.878599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **#NOW I have 3 dataframes\n# #df_twt = 0 - 2355 = 2356 rows\n# #df_img = 0 - 2074 = 2075 rows\n# #df_json = 0 - 2353 = 2354 rows\n\n# #for sure**","metadata":{}},{"cell_type":"code","source":"df_twt.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:02:32.193182Z","iopub.execute_input":"2021-07-11T23:02:32.193546Z","iopub.status.idle":"2021-07-11T23:02:32.200418Z","shell.execute_reply.started":"2021-07-11T23:02:32.193501Z","shell.execute_reply":"2021-07-11T23:02:32.199355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_img.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:02:51.497516Z","iopub.execute_input":"2021-07-11T23:02:51.497878Z","iopub.status.idle":"2021-07-11T23:02:51.503166Z","shell.execute_reply.started":"2021-07-11T23:02:51.497847Z","shell.execute_reply":"2021-07-11T23:02:51.502301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_json.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:03:11.968101Z","iopub.execute_input":"2021-07-11T23:03:11.968623Z","iopub.status.idle":"2021-07-11T23:03:11.973577Z","shell.execute_reply.started":"2021-07-11T23:03:11.968589Z","shell.execute_reply":"2021-07-11T23:03:11.972828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Assessing data","metadata":{}},{"cell_type":"code","source":"#Assess its quality and tidiness\n#visually and programmatically\n#I will document at least eight (8) quality issues and two (2) tidiness issues\n# such as requested.\n#I created a Python function that includes the required functions for assess\n#from what I learned in this course for easy and speed in performance","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:04:29.907295Z","iopub.execute_input":"2021-07-11T23:04:29.907826Z","iopub.status.idle":"2021-07-11T23:04:29.911807Z","shell.execute_reply.started":"2021-07-11T23:04:29.907776Z","shell.execute_reply":"2021-07-11T23:04:29.91067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def assess_data(topic, source_df, df):\n    print('Use pandas to explore and assess {} datasets  {}  in terms of quality \\\n    and tidness \\n by display data details:'.format(topic, source_df))\n    print('----------------------------------------------------------------')\n    print('Number of columns and rows :')\n    print(df.shape)\n    print('---------------------------')\n    print('The first 5 lines of the data frame :')\n    print(df.head())\n    print('----------------------------------------------------------------')\n    print('The last 5 lines of the data frame :')\n    print(df.tail())\n    print('----------------------------------------------------------------')\n    print('The sample 7 lines of the data frame :')\n    print(df.sample(7))\n    print('----------------------------------------------------------------')\n    print('Duplicate rows in the {} {} dataset'.format(topic, source_df))\n    print(df.duplicated().sum())\n    print('----------------------------------------------------------------')\n    print('Datatype of column in the {} {} dataset'.format(topic, source_df))\n    print(df.info())\n    print('----------------------------------------------------------------')\n    print('Features with missing values in the {} {} dataset'.format(topic, source_df))\n    print(df.isnull().sum())\n    print('----------------------------------------------------------------')\n    print('Number of unique values for quality in the {} {} dataset'.format(topic, source_df))\n    print(df.nunique())\n    print('----------------------------------------------------------------')\n    print('Number of rows with missing values in the {} {} dataset'.format(topic, source_df))\n    print(df.isnull().any(axis=1).sum())\n    print('----------------------------------------------------------------')","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:05:09.623823Z","iopub.execute_input":"2021-07-11T23:05:09.62415Z","iopub.status.idle":"2021-07-11T23:05:09.632623Z","shell.execute_reply.started":"2021-07-11T23:05:09.624122Z","shell.execute_reply":"2021-07-11T23:05:09.631623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#assess\n## run : def\nif __name__ == '__main__':\n    t = 'We_Rate_Dogs'\n    s1 = 'from Twitter archive file'\n    s2 = 'from Tweet Image Prediction'\n    s3 = 'from Twitter API and JSON'\n\n    print('--------------------------------------------------------------')\n    print('1 - Inspect to Assess dataframe of Twitter archive file = df_twt :')\n    assess_data(t, s1, df_twt)\n    print('--------------------------------------------------------------')\n    print('2- Inspect to Assess dataframe of Tweet Image Prediction = df_img :')\n    assess_data(t, s2, df_img)\n    print('--------------------------------------------------------------')\n    print('3- Inspect to Assess dataframe of Twitter API and JSON = df_json :')\n    assess_data(t, s3, df_json)\n    print('--------------------------------------------------------------') ","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:05:55.407304Z","iopub.execute_input":"2021-07-11T23:05:55.407664Z","iopub.status.idle":"2021-07-11T23:05:55.555543Z","shell.execute_reply.started":"2021-07-11T23:05:55.407633Z","shell.execute_reply":"2021-07-11T23:05:55.554528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Document at least eight (8) quality issues and two (2) tidiness issues","metadata":{}},{"cell_type":"code","source":"#Tidiness issue 2 : MessyÂ data, also known asÂ untidyÂ data. Untidy data hasÂ structural issues.\n#1- all data frames must be integrated into one frame with a common factor, tweet_id, to be easy to clean\n#2- each dog must have one stage, so we will create one column for the stage and ignore the null values\n\n##Quality Issues 8 : DirtyÂ data, also known asÂ low qualityÂ data. Low quality data hasÂ content issues.\n#1- I will drop the columns for the 4 stages as they become unnecessary or duplicate\n#2-  I will drop the columns :  'retweeted_status_id', 'retweeted_status_user_id' and 'retweeted_status_timestamp'\n    #I will keep only those rows in  archieve table that are original tweets and not retweets\n#3-  I will convert tweet_id to str\n#4- I will convert timestamp to datetime to be suitable\n#5- I will remove columns that are not needed for analysis\n#6- I will drop duplicate jpg_url  2075 - 2009 = 66\n  #To remove duplicates on specific column(s), use subset, to remove duplicates and keep last occurences, use keep\n#7- I will put a space in place of the underscore for both p1,p2 and p3\n#8- I will convert rating_numerator, rating_denominator to float to be suitable","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:07:45.116624Z","iopub.execute_input":"2021-07-11T23:07:45.11697Z","iopub.status.idle":"2021-07-11T23:07:45.121668Z","shell.execute_reply.started":"2021-07-11T23:07:45.116943Z","shell.execute_reply":"2021-07-11T23:07:45.120327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cleaning data","metadata":{}},{"cell_type":"code","source":"#clean\n#I will clean each of the issues documented while assessing.\n\n#The result will be a high quality and tidy master pandas DataFrame.\n\n# Copies of original dataframes to clean. \n\ntwt_clean = df_twt.copy()\njson_clean = df_json.copy()\nimg_clean = df_img.copy()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:08:36.294928Z","iopub.execute_input":"2021-07-11T23:08:36.295334Z","iopub.status.idle":"2021-07-11T23:08:36.301159Z","shell.execute_reply.started":"2021-07-11T23:08:36.295302Z","shell.execute_reply":"2021-07-11T23:08:36.300206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Tidiness issue 2","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:09:06.901573Z","iopub.execute_input":"2021-07-11T23:09:06.902104Z","iopub.status.idle":"2021-07-11T23:09:06.906437Z","shell.execute_reply.started":"2021-07-11T23:09:06.90206Z","shell.execute_reply":"2021-07-11T23:09:06.905487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tidiness(1) : Merge 3 dataframes in one dataframe :\n\n#Define:\n#First, all data frames must be integrated into one frame with a common factor, tweet_id, to be easy to clean\n\n#Code:\ntwt_clean = pd.merge(twt_clean, json_clean, on = ['tweet_id'], how = 'inner')\ntwt_clean = pd.merge(twt_clean, img_clean, on ='tweet_id', how = 'inner')\n\n#Test:\ntwt_clean.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:09:35.247394Z","iopub.execute_input":"2021-07-11T23:09:35.248023Z","iopub.status.idle":"2021-07-11T23:09:35.287451Z","shell.execute_reply.started":"2021-07-11T23:09:35.247989Z","shell.execute_reply":"2021-07-11T23:09:35.286667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tidiness(2) : Merge ['doggo', 'floofer', 'pupper', 'puppo'] in one Column :\n\n#Define:\n#Second, each dog must have one stage, so we will create one column for the stage and ignore the null values \n\n\n#Code:\ntwt_clean['stage'] = twt_clean[['doggo', 'floofer', 'pupper', 'puppo']].max(axis=1)\n\n#Test:\ntwt_clean.stage.value_counts().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:10:13.751987Z","iopub.execute_input":"2021-07-11T23:10:13.752463Z","iopub.status.idle":"2021-07-11T23:10:13.766841Z","shell.execute_reply.started":"2021-07-11T23:10:13.752432Z","shell.execute_reply":"2021-07-11T23:10:13.765742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"twt_clean.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:10:44.078635Z","iopub.execute_input":"2021-07-11T23:10:44.078982Z","iopub.status.idle":"2021-07-11T23:10:44.098831Z","shell.execute_reply.started":"2021-07-11T23:10:44.078954Z","shell.execute_reply":"2021-07-11T23:10:44.097768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#become 15 object","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:14:17.695616Z","iopub.execute_input":"2021-07-11T23:14:17.69594Z","iopub.status.idle":"2021-07-11T23:14:17.699908Z","shell.execute_reply.started":"2021-07-11T23:14:17.695911Z","shell.execute_reply":"2021-07-11T23:14:17.698885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Quality Issues 8 :","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:14:25.759028Z","iopub.execute_input":"2021-07-11T23:14:25.759367Z","iopub.status.idle":"2021-07-11T23:14:25.763093Z","shell.execute_reply.started":"2021-07-11T23:14:25.759338Z","shell.execute_reply":"2021-07-11T23:14:25.762117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Quality(1) \n\n#Define:\n# I will drop the columns for the 4 stages as they become unnecessary or duplicate \n\n#Code:\ntwt_clean.drop(['doggo', 'floofer', 'pupper', 'puppo'], axis=1, inplace=True)\n\n#Test:\ntwt_clean.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:15:03.369661Z","iopub.execute_input":"2021-07-11T23:15:03.370027Z","iopub.status.idle":"2021-07-11T23:15:03.391099Z","shell.execute_reply.started":"2021-07-11T23:15:03.369994Z","shell.execute_reply":"2021-07-11T23:15:03.39011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Quality(2) \n\n#Define:\n# I will drop the columns :  'retweeted_status_id', 'retweeted_status_user_id' and 'retweeted_status_timestamp'\n#I will keep only those rows in  archieve table that are original tweets and not retweets\n\n#Code:\ntwt_clean = twt_clean.drop(['retweeted_status_id', 'retweeted_status_user_id', 'retweeted_status_timestamp'], axis=1)\n\n#Test:\ntwt_clean.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:15:37.613972Z","iopub.execute_input":"2021-07-11T23:15:37.614307Z","iopub.status.idle":"2021-07-11T23:15:37.633791Z","shell.execute_reply.started":"2021-07-11T23:15:37.614277Z","shell.execute_reply":"2021-07-11T23:15:37.63264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Quality(3) \n\n#Define:\n# I will convert tweet_id to str\n\n#Code:\ntwt_clean['tweet_id'] = twt_clean['tweet_id'].astype(str)\n\n#Test:\ntwt_clean.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:16:20.040659Z","iopub.execute_input":"2021-07-11T23:16:20.040986Z","iopub.status.idle":"2021-07-11T23:16:20.06095Z","shell.execute_reply.started":"2021-07-11T23:16:20.040958Z","shell.execute_reply":"2021-07-11T23:16:20.059916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Quality(4) \n\n#Define:\n# I will convert timestamp to datetime to be suitable\n\n#Code:\ntwt_clean.timestamp = pd.to_datetime(twt_clean.timestamp)\n\n#Test:\ntwt_clean.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:17:20.420479Z","iopub.execute_input":"2021-07-11T23:17:20.420866Z","iopub.status.idle":"2021-07-11T23:17:20.444329Z","shell.execute_reply.started":"2021-07-11T23:17:20.420833Z","shell.execute_reply":"2021-07-11T23:17:20.443315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Quality(5) \n\n#Define:\n# I will remove columns that are not needed for analysis\n\n#Code:\ntwt_clean.drop(['in_reply_to_status_id', 'in_reply_to_user_id'], axis=1, inplace= True)\n\n#Test:\ntwt_clean.columns","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:18:35.770292Z","iopub.execute_input":"2021-07-11T23:18:35.770676Z","iopub.status.idle":"2021-07-11T23:18:35.781332Z","shell.execute_reply.started":"2021-07-11T23:18:35.770645Z","shell.execute_reply":"2021-07-11T23:18:35.780276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Quality(6) \n\n#Define:\n# I will drop duplicate jpg_url  2075 - 2009 = 66\n#To remove duplicates on specific column(s), use subset, to remove duplicates and keep last occurences, use keep\n\n#Code:\ntwt_clean = twt_clean.drop_duplicates(subset=['jpg_url'], keep='last')\n\n#Test:\nsum(twt_clean['jpg_url'].duplicated())","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:18:57.932199Z","iopub.execute_input":"2021-07-11T23:18:57.932552Z","iopub.status.idle":"2021-07-11T23:18:57.944982Z","shell.execute_reply.started":"2021-07-11T23:18:57.932508Z","shell.execute_reply":"2021-07-11T23:18:57.943983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Quality(7) \n\n#Define:\n#I will put a space in place of the underscore for both p1,p2 and p3\n\n#Code:\ntwt_clean['p1'] = twt_clean['p1'].str.replace('_', ' ')\ntwt_clean['p2'] = twt_clean['p2'].str.replace('_', ' ')\ntwt_clean['p3'] = twt_clean['p3'].str.replace('_', ' ')\n\n#Test:\ntwt_clean.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:19:19.781023Z","iopub.execute_input":"2021-07-11T23:19:19.781494Z","iopub.status.idle":"2021-07-11T23:19:19.822258Z","shell.execute_reply.started":"2021-07-11T23:19:19.78146Z","shell.execute_reply":"2021-07-11T23:19:19.821185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Quality(8) \n\n#Define:\n# I will convert rating_numerator, rating_denominator to float to be suitable\n\n#Code:\ntwt_clean['rating_numerator'] = twt_clean['rating_numerator'].astype(float)\ntwt_clean['rating_denominator'] = twt_clean['rating_denominator'].astype(float)\n\n#Test:\ntwt_clean.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:20:04.564581Z","iopub.execute_input":"2021-07-11T23:20:04.564953Z","iopub.status.idle":"2021-07-11T23:20:04.584183Z","shell.execute_reply.started":"2021-07-11T23:20:04.564921Z","shell.execute_reply":"2021-07-11T23:20:04.583448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Storing data","metadata":{}},{"cell_type":"code","source":"twt_master = twt_clean.copy()\n# I will save twt_master dataframe to a CSV file\ntwt_master.to_csv('twitter_archive_master.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:27:00.068726Z","iopub.execute_input":"2021-07-11T23:27:00.069115Z","iopub.status.idle":"2021-07-11T23:27:00.123446Z","shell.execute_reply.started":"2021-07-11T23:27:00.069049Z","shell.execute_reply":"2021-07-11T23:27:00.122635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analyzing and Visualizing","metadata":{}},{"cell_type":"code","source":"#statistics \ntwt_master.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:27:48.102989Z","iopub.execute_input":"2021-07-11T23:27:48.103715Z","iopub.status.idle":"2021-07-11T23:27:48.14923Z","shell.execute_reply.started":"2021-07-11T23:27:48.103666Z","shell.execute_reply":"2021-07-11T23:27:48.148184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"twt_master.p1.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:28:21.697879Z","iopub.execute_input":"2021-07-11T23:28:21.698264Z","iopub.status.idle":"2021-07-11T23:28:21.708418Z","shell.execute_reply.started":"2021-07-11T23:28:21.698231Z","shell.execute_reply":"2021-07-11T23:28:21.7073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"twt_master.p2.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:28:38.408422Z","iopub.execute_input":"2021-07-11T23:28:38.408783Z","iopub.status.idle":"2021-07-11T23:28:38.417864Z","shell.execute_reply.started":"2021-07-11T23:28:38.408754Z","shell.execute_reply":"2021-07-11T23:28:38.416916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"twt_master.p3.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:29:03.72862Z","iopub.execute_input":"2021-07-11T23:29:03.728955Z","iopub.status.idle":"2021-07-11T23:29:03.739039Z","shell.execute_reply.started":"2021-07-11T23:29:03.728927Z","shell.execute_reply":"2021-07-11T23:29:03.738124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This indicates that the most prediction is to golden retriever and Labrador retriever","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:29:27.298082Z","iopub.execute_input":"2021-07-11T23:29:27.298629Z","iopub.status.idle":"2021-07-11T23:29:27.30268Z","shell.execute_reply.started":"2021-07-11T23:29:27.298582Z","shell.execute_reply":"2021-07-11T23:29:27.301602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"twt_master['rating_denominator'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:29:45.276163Z","iopub.execute_input":"2021-07-11T23:29:45.276561Z","iopub.status.idle":"2021-07-11T23:29:45.286146Z","shell.execute_reply.started":"2021-07-11T23:29:45.276502Z","shell.execute_reply":"2021-07-11T23:29:45.28528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"twt_master['rating_denominator'].value_counts().plot(kind='bar');","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:30:03.354888Z","iopub.execute_input":"2021-07-11T23:30:03.355594Z","iopub.status.idle":"2021-07-11T23:30:03.614911Z","shell.execute_reply.started":"2021-07-11T23:30:03.355553Z","shell.execute_reply":"2021-07-11T23:30:03.613863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This indicates that the most rating_denominator is 10 to fact dog","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:30:27.339144Z","iopub.execute_input":"2021-07-11T23:30:27.339852Z","iopub.status.idle":"2021-07-11T23:30:27.344945Z","shell.execute_reply.started":"2021-07-11T23:30:27.339805Z","shell.execute_reply":"2021-07-11T23:30:27.343589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#to display favorite_count vs stage\nplt.scatter(twt_master['favorite_count'], twt_master['stage'])\nplt.xlabel('favorite_count')\nplt.ylabel('stage')\nplt.title('stages and favorites by Scatter plot')","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:31:05.329063Z","iopub.execute_input":"2021-07-11T23:31:05.329573Z","iopub.status.idle":"2021-07-11T23:31:05.502686Z","shell.execute_reply.started":"2021-07-11T23:31:05.329542Z","shell.execute_reply":"2021-07-11T23:31:05.501972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This indicates that the most favorites stage is pupper","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:31:30.666518Z","iopub.execute_input":"2021-07-11T23:31:30.666925Z","iopub.status.idle":"2021-07-11T23:31:30.670468Z","shell.execute_reply.started":"2021-07-11T23:31:30.666888Z","shell.execute_reply":"2021-07-11T23:31:30.669629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#to display favorite_count vs retweet_count\nplt.scatter(twt_master['favorite_count'], twt_master['retweet_count'])\nplt.xlabel('favorite_count')\nplt.ylabel('retweet_count')\nplt.title('Retweets and favorites by Scatter plot')","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:31:54.094926Z","iopub.execute_input":"2021-07-11T23:31:54.095437Z","iopub.status.idle":"2021-07-11T23:31:54.291832Z","shell.execute_reply.started":"2021-07-11T23:31:54.095392Z","shell.execute_reply":"2021-07-11T23:31:54.291149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#to display p_conf is how confident the algorithm is in its prediction\n#for p1,p2 and p3","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:32:17.829245Z","iopub.execute_input":"2021-07-11T23:32:17.829821Z","iopub.status.idle":"2021-07-11T23:32:17.833404Z","shell.execute_reply.started":"2021-07-11T23:32:17.829771Z","shell.execute_reply":"2021-07-11T23:32:17.832473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(x = twt_master.p1_conf, bins = 80)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:32:39.012136Z","iopub.execute_input":"2021-07-11T23:32:39.012489Z","iopub.status.idle":"2021-07-11T23:32:39.263504Z","shell.execute_reply.started":"2021-07-11T23:32:39.012455Z","shell.execute_reply":"2021-07-11T23:32:39.262761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(x = twt_master.p2_conf, bins = 80)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:32:59.243385Z","iopub.execute_input":"2021-07-11T23:32:59.243761Z","iopub.status.idle":"2021-07-11T23:32:59.617705Z","shell.execute_reply.started":"2021-07-11T23:32:59.24373Z","shell.execute_reply":"2021-07-11T23:32:59.616681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(x = twt_master.p3_conf, bins = 80)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:33:19.908939Z","iopub.execute_input":"2021-07-11T23:33:19.909301Z","iopub.status.idle":"2021-07-11T23:33:20.141467Z","shell.execute_reply.started":"2021-07-11T23:33:19.90927Z","shell.execute_reply":"2021-07-11T23:33:20.14064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot stage of dog\ntwt_master['stage'].hist();","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:33:46.531307Z","iopub.execute_input":"2021-07-11T23:33:46.531817Z","iopub.status.idle":"2021-07-11T23:33:46.683407Z","shell.execute_reply.started":"2021-07-11T23:33:46.531783Z","shell.execute_reply":"2021-07-11T23:33:46.682778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This indicates that the most fact stages is pupper ","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:34:24.740021Z","iopub.execute_input":"2021-07-11T23:34:24.740363Z","iopub.status.idle":"2021-07-11T23:34:24.744095Z","shell.execute_reply.started":"2021-07-11T23:34:24.740335Z","shell.execute_reply":"2021-07-11T23:34:24.743327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"twt_master['stage'].describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:34:43.463457Z","iopub.execute_input":"2021-07-11T23:34:43.464149Z","iopub.status.idle":"2021-07-11T23:34:43.499319Z","shell.execute_reply.started":"2021-07-11T23:34:43.464103Z","shell.execute_reply":"2021-07-11T23:34:43.498257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# #visualizations  with alot of details and Transparency and clarity \n# #by using seaborn","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nsns.set_style('darkgrid')","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:37:06.975549Z","iopub.execute_input":"2021-07-11T23:37:06.975919Z","iopub.status.idle":"2021-07-11T23:37:06.980685Z","shell.execute_reply.started":"2021-07-11T23:37:06.975885Z","shell.execute_reply":"2021-07-11T23:37:06.979567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('twitter_archive_master.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:37:51.670833Z","iopub.execute_input":"2021-07-11T23:37:51.671175Z","iopub.status.idle":"2021-07-11T23:37:51.702385Z","shell.execute_reply.started":"2021-07-11T23:37:51.671143Z","shell.execute_reply":"2021-07-11T23:37:51.701257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:38:07.255014Z","iopub.execute_input":"2021-07-11T23:38:07.25535Z","iopub.status.idle":"2021-07-11T23:38:07.288441Z","shell.execute_reply.started":"2021-07-11T23:38:07.25532Z","shell.execute_reply":"2021-07-11T23:38:07.287412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:38:41.37345Z","iopub.execute_input":"2021-07-11T23:38:41.373832Z","iopub.status.idle":"2021-07-11T23:38:41.392876Z","shell.execute_reply.started":"2021-07-11T23:38:41.373795Z","shell.execute_reply":"2021-07-11T23:38:41.391596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Report (1)\n# 2008 rows\n# 23 columns\n# there values by null but it no display because none","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:39:17.363937Z","iopub.execute_input":"2021-07-11T23:39:17.364417Z","iopub.status.idle":"2021-07-11T23:39:17.367371Z","shell.execute_reply.started":"2021-07-11T23:39:17.364385Z","shell.execute_reply":"2021-07-11T23:39:17.366731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['rating_denominator'].value_counts().plot(kind='bar');","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:39:35.388048Z","iopub.execute_input":"2021-07-11T23:39:35.390781Z","iopub.status.idle":"2021-07-11T23:39:35.655153Z","shell.execute_reply.started":"2021-07-11T23:39:35.39073Z","shell.execute_reply":"2021-07-11T23:39:35.654518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This indicates that the most rating_denominator is 10 to fact dog","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:39:58.701103Z","iopub.execute_input":"2021-07-11T23:39:58.701443Z","iopub.status.idle":"2021-07-11T23:39:58.705255Z","shell.execute_reply.started":"2021-07-11T23:39:58.701415Z","shell.execute_reply":"2021-07-11T23:39:58.704356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#to display favorite_count vs stage\nplt.scatter(df['favorite_count'], df['stage'])\nplt.xlabel('favorite_count')\nplt.ylabel('stage')\nplt.title('stages and favorites by Scatter plot')","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:40:17.12079Z","iopub.execute_input":"2021-07-11T23:40:17.121162Z","iopub.status.idle":"2021-07-11T23:40:17.333339Z","shell.execute_reply.started":"2021-07-11T23:40:17.121129Z","shell.execute_reply":"2021-07-11T23:40:17.332439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This indicates that the most favorites stage is pupper","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:40:34.840716Z","iopub.execute_input":"2021-07-11T23:40:34.841124Z","iopub.status.idle":"2021-07-11T23:40:34.84548Z","shell.execute_reply.started":"2021-07-11T23:40:34.84109Z","shell.execute_reply":"2021-07-11T23:40:34.844156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#to display favorite_count vs retweet_count\nplt.scatter(df['favorite_count'], df['retweet_count'])\nplt.xlabel('favorite_count')\nplt.ylabel('retweet_count')\nplt.title('Retweets and favorites by Scatter plot')","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:40:51.918398Z","iopub.execute_input":"2021-07-11T23:40:51.918779Z","iopub.status.idle":"2021-07-11T23:40:52.165707Z","shell.execute_reply.started":"2021-07-11T23:40:51.918746Z","shell.execute_reply":"2021-07-11T23:40:52.164714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#to display p_conf is how confident the algorithm is in its prediction\n#for p1,p2 and p3","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:41:11.371511Z","iopub.execute_input":"2021-07-11T23:41:11.371918Z","iopub.status.idle":"2021-07-11T23:41:11.376383Z","shell.execute_reply.started":"2021-07-11T23:41:11.371886Z","shell.execute_reply":"2021-07-11T23:41:11.375198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(x = df.p1_conf, bins = 80)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:41:26.785862Z","iopub.execute_input":"2021-07-11T23:41:26.786202Z","iopub.status.idle":"2021-07-11T23:41:27.067103Z","shell.execute_reply.started":"2021-07-11T23:41:26.786172Z","shell.execute_reply":"2021-07-11T23:41:27.066428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(x = df.p2_conf, bins = 80)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:41:45.249346Z","iopub.execute_input":"2021-07-11T23:41:45.249866Z","iopub.status.idle":"2021-07-11T23:41:45.543415Z","shell.execute_reply.started":"2021-07-11T23:41:45.249831Z","shell.execute_reply":"2021-07-11T23:41:45.542621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(x = df.p3_conf, bins = 80)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:42:03.714789Z","iopub.execute_input":"2021-07-11T23:42:03.715331Z","iopub.status.idle":"2021-07-11T23:42:03.990046Z","shell.execute_reply.started":"2021-07-11T23:42:03.715298Z","shell.execute_reply":"2021-07-11T23:42:03.989179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot stage of dog\ndf['stage'].hist();","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:42:21.994075Z","iopub.execute_input":"2021-07-11T23:42:21.994429Z","iopub.status.idle":"2021-07-11T23:42:22.174588Z","shell.execute_reply.started":"2021-07-11T23:42:21.994397Z","shell.execute_reply":"2021-07-11T23:42:22.17333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This indicates that the most fact stages is pupper ","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:42:37.780562Z","iopub.execute_input":"2021-07-11T23:42:37.780932Z","iopub.status.idle":"2021-07-11T23:42:37.784326Z","shell.execute_reply.started":"2021-07-11T23:42:37.780901Z","shell.execute_reply":"2021-07-11T23:42:37.783632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['img_num'].value_counts().plot(kind='bar');","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:42:52.315449Z","iopub.execute_input":"2021-07-11T23:42:52.315949Z","iopub.status.idle":"2021-07-11T23:42:52.476565Z","shell.execute_reply.started":"2021-07-11T23:42:52.315919Z","shell.execute_reply":"2021-07-11T23:42:52.475636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['img_num'].value_counts().plot(kind='pie');","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:43:22.06725Z","iopub.execute_input":"2021-07-11T23:43:22.067625Z","iopub.status.idle":"2021-07-11T23:43:22.167515Z","shell.execute_reply.started":"2021-07-11T23:43:22.06759Z","shell.execute_reply":"2021-07-11T23:43:22.166587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['stage'].value_counts().plot(kind='pie');","metadata":{"execution":{"iopub.status.busy":"2021-07-11T23:43:41.977588Z","iopub.execute_input":"2021-07-11T23:43:41.977925Z","iopub.status.idle":"2021-07-11T23:43:42.09473Z","shell.execute_reply.started":"2021-07-11T23:43:41.977898Z","shell.execute_reply":"2021-07-11T23:43:42.093609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# #This indicates also that the most fact stages is pupper ","metadata":{}},{"cell_type":"markdown","source":"# # job great with udacity  by Hedra Atia","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}