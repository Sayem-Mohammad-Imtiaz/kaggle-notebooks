{"cells":[{"metadata":{},"cell_type":"markdown","source":"#### Idea\nWe are interested in exploring text summarization and, in particular, headline generation, here is a first baseline, we just take first 30 words of each text as a hypothesis for a title. \n\n#### Data\n[Kaggle Dataset](https://www.kaggle.com/kashnitsky/news-about-major-cryptocurrencies-20132018-40k) with ~40k articles sharing news on major cryptocurrencies. \n\n#### Task\nAll articles have `title` and `text`, the task is to generate a title given the text. The chosen metric is an avarage of ROUGE-1, ROUGE-2, and ROUGE-L, see [this report](http://www.dialog-21.ru/media/4661/camerareadysubmission-157.pdf) describing the metric, page 3.\n\n#### Results\n\nROUGE scores (F1 variant):\n- ROUGE-1 – 18.4%\n- ROUGE-2 – 5.3%\n- ROUGE-L – 16.9%\n- Average - 13.5%\n\nPretty mediocre. Hope ML models will do a better job"},{"metadata":{},"cell_type":"markdown","source":"#### Installing the Rouge package and playing around with the metric "},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://pypi.org/project/rouge/\n!pip install rouge > /dev/null","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Example of Rouge calculation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from rouge import Rouge \n\nhypothesis = \"Some London Underground stations should be closed, as the city is trying to reduce the impact of a coronavirus outbreak.\".lower()\n\nreference = \"Up to 40 stations on the London Underground network are to be shut as the city attempts to reduce the effect of the coronavirus outbreak.\".lower()\n\nrouge = Rouge()\nscores = rouge.get_scores(hypothesis, reference)\nscores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Reading and briefly exploring data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom tqdm import tqdm\ntqdm.pandas()\nfrom pathlib import Path\n\nfrom matplotlib import pyplot as plt\n%config InlineBackend.figure_format = 'retina'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH_TO_CRYPTO_NEWS = Path('../input/news-about-major-cryptocurrencies-20132018-40k/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(PATH_TO_CRYPTO_NEWS / 'crypto_news_parsed_2013-2017_train.csv')\nvalid_df = pd.read_csv(PATH_TO_CRYPTO_NEWS / 'crypto_news_parsed_2018_validation.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# readling empty strings is a bit different locally and here, but not a big deal \ntrain_df['text'].fillna(' ', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**URL**\n\nIt is an id of a news article"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['url'].nunique() == len(train_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can take a look at some of the actual articles on the Web"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.loc[:5, 'url']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"https://www.ccn.com/paris-hiltons-hotel-mogul-father-to-sell-38-million-mansion-for-cryptocurrency/\n\n<img src=\"https://habrastorage.org/webt/4c/3n/eg/4c3neg5owcdohooydlz4dbdwzdo.png\" width=70% />"},{"metadata":{},"cell_type":"markdown","source":"**Title**\n\nThese are on avearge pretty short, the median is just 9 words"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['title'].apply(lambda s: len(s.split())).describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dunno if wordclouds have ever been useful but let's build one"},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\n\nwordcloud = WordCloud(background_color='black', stopwords = STOPWORDS,\n                max_words = 200, max_font_size = 100, \n                random_state = 17, width=800, height=400)\n\nplt.figure(figsize=(16, 12))\nwordcloud.generate(str(train_df['title']))\nplt.imshow(wordcloud);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Text**\n\nText are pretty long, of normal length for a news online, the median is around 400 words"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['text'].apply(lambda s: len(s.split())).describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's extract first sentences of each text in a dumb way simply splitting by the dot (it's far from perfect!).\n\nFirst sentences are longer than titles, the median is 21 words, max. 232. So also makes sense to try just a part of a first sentence as a hypothesis for a title."},{"metadata":{"trusted":true},"cell_type":"code","source":"first_sentences_dumb = train_df['text'].apply(lambda s: s.split('.')[0])\nfirst_sentences_dumb.apply(lambda s: len(s.split())).describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's perform a sanity check – whether texts actually start as normal articles and don't have any placeholders in the beggining (like timestamp), this we check simply by taking first 10 words (10 is an arbitrary choice) of each sentence and checking the number of unique values. "},{"metadata":{"trusted":true},"cell_type":"code","source":"first_ten_words_dumb = first_sentences_dumb.apply(lambda s: \" \".join(s.split()[:10]))\nfirst_ten_words_dumb.value_counts().head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Indeed, we see some problems with taking everything before the first dot as a first sentence. \n\nPicularities of the 1st sentence:\n\n - Splitting on a dot is imperfect, thus it splits some phrases like \"Dr. Brown\"\n - Looks like there're duplicates of some news (plagiarism?), published in different sources (\"Noelle Acheson is a 10-year veteran of company analysis\" over 40 times)\n - Already fixed some commom welcome messages (\"The views and opinions expressed here are solely those of \")"},{"metadata":{},"cell_type":"markdown","source":"#### So let's try to use `sent_tokenize` to better extract first sentence"},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.tokenize import sent_tokenize","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_first_sent(text):\n    \n    sent_tok = sent_tokenize(text)\n    \n    return sent_tok[0].strip() if sent_tok else ''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we see that first sentences are on average twice longer that those dumb ones"},{"metadata":{"trusted":true},"cell_type":"code","source":"first_sentences = train_df['text'].progress_apply(extract_first_sent)\nfirst_sentences.apply(lambda s: len(s.split())).describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"first_ten_words = first_sentences.apply(lambda s: \" \".join(s.split()[:10]))\nfirst_ten_words.value_counts().head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Now it's a bit better, though still not perfect\n"},{"metadata":{},"cell_type":"markdown","source":"**Year**"},{"metadata":{},"cell_type":"markdown","source":"The train-validation split is done based on year."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['year'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_df['year'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Author**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['author'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['author'].value_counts().head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Source**\n\nThese is a feature of the actual scraping, some articles come from websites having tags in metadata (no more information on that)."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['source'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['source'].value_counts().head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That's it for the analysis, let's now create a first headline generation baseline. We saw that titles are short, up to 30 words, so we'll just use first 30 words as a hypothesis for a title."},{"metadata":{},"cell_type":"markdown","source":"#### Now calculating ROUGE scores for the validation part with first 30 words as hypotheses."},{"metadata":{"trusted":true},"cell_type":"code","source":"true_val_titles = valid_df['title'].str.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"first_sentences_val = valid_df['text'].progress_apply(extract_first_sent)\nfirst_thirty_words_val = first_sentences_val.loc[valid_df.index].apply(lambda s: \" \".join(s.split()[:30]).lower())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nrouge = Rouge()\nscores = rouge.get_scores(hyps=first_thirty_words_val, refs=true_val_titles, avg=True, ignore_empty=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Average between ROUGE-1, ROUGE-2, and ROUGE-L (the metric of interest)"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_metric = (scores['rouge-1']['f'] + scores['rouge-2']['f'] + scores['rouge-l']['f']) / 3\nfinal_metric","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":4}