{"cells":[{"metadata":{},"cell_type":"markdown","source":"A heart attack occurs when the flow of blood to the heart is blocked. The blockage is most often a buildup of fat, cholesterol and other substances, which form a plaque in the arteries that feed the heart (coronary arteries).\n\nThe plaque eventually breaks away and forms a clot. The interrupted blood flow can damage or destroy part of the heart muscle.\n\nA heart attack, also called a myocardial infarction, can be fatal, but treatment has improved dramatically over the years, however the diagnosis for heart diseases are expensive and complex. \n\nThe tests you'll need to diagnose your heart disease depend on what condition your doctor thinks you might have. No matter what type of heart disease you have, your doctor will likely perform a physical exam and ask about your personal and family medical history before doing any tests. Besides blood tests and a chest X-ray, tests to diagnose heart disease can include[1]:\n\nElectrocardiogram (ECG).\nHolter monitoring. \nEchocardiogram. \nStress test. \nCardiac catheterization.\nCardiac computerized tomography (CT) scan. \nCardiac magnetic resonance imaging (MRI).\n\n[1]https://www.mayoclinic.org/diseases-conditions/heart-disease/diagnosis-treatment/drc-20353124\n\nLets see how Machine Learning Models are used in predicting Heart Attack in human.\n\nContext\nThis database contains 76 attributes, but all published experiments refer to using a subset of 14 of them. In particular, the Cleveland database is the only one that has been used by ML researchers to this date. The \"goal\" field refers to the presence of heart disease in the patient. It is integer valued from 0 (no presence) to 4.\n\nContent\n\nAttribute Information: \n*  age \n* sex \n* chest pain type (4 values) \n* resting blood pressure \n* serum cholestoral in mg/dl \n* fasting blood sugar > 120 mg/dl\n* resting electrocardiographic results (values 0,1,2)\n* maximum heart rate achieved \n* exercise induced angina \n* oldpeak = ST depression induced by exercise relative to rest \n* the slope of the peak exercise ST segment \n* number of major vessels (0-3) colored by flourosopy \n* thal: 3 = normal; 6 = fixed defect; 7 = reversable defect"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sb\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.ensemble import ExtraTreesClassifier\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n\n\n# Any results you write to the current directory are saved as output.\ndataset = pd.read_csv(\"../input/heart.csv\")\ndataset.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* we need to check if there is any Null values in the dataset. \n* If there are any Null then we need to impute the values."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"dataset.isnull().values.any()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Check the datatypes to see if we need to perform encoding categorical data"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Feature selection is one of the most important step in machine learning.\n* Irrelevant Parameters will lower the performance of the model.\n* lets try out the first method, correlation heat map."},{"metadata":{"trusted":true},"cell_type":"code","source":"Corr = dataset.corr()\nCorr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* plotting heatmap to analyze the correlation of all the parameters."},{"metadata":{"trusted":true},"cell_type":"code","source":"sb.heatmap(Corr,vmin=0, vmax=1, center=0,\n            square=True, linewidths=1, cbar_kws={\"shrink\": .5})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* second method of feature selction\n* Univariate Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dataset.iloc[:,0:13]  \ny = dataset.iloc[:,-1]\n#apply SelectKBest class to extract best features\nparameters = SelectKBest(score_func=chi2, k=13)\nfit = parameters.fit(X,y)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X.columns)\n#concat two dataframes for better visualization \nfeatureScores = pd.concat([dfcolumns,dfscores],axis=1)\nfeatureScores.columns = ['Specs','Score']  #naming the dataframe columns\nprint(featureScores.nlargest(13,'Score'))  #print 10 best features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Third Method of feature selection \n* Feature Importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ExtraTreesClassifier()\nmodel.fit(X,y)\nprint(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n#plot graph of feature importances for better visualization\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(13).plot(kind='barh')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Now let us build our model\n* we have already seperated x and y dataset\n* lets choose test and training set."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"lets scale the features\n\nFeature Scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Fitting SVM to the Training set"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nclassifier = SVC(kernel = 'linear', random_state = 0)\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* lets see how many corrct and in incorrect predictions through confusion matrix\n* Making the Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\ncm\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* our model is making 65 correct predictions and 11 incorrect prediction"},{"metadata":{},"cell_type":"markdown","source":"* Lets find out the Recall and Specifity "},{"metadata":{"trusted":true},"cell_type":"code","source":"Recall = cm[0,0]/(cm[0,0]+cm[1,0])\nprint('Recall : ', Recall )\n\nSp = cm[1,1]/(cm[1,1]+cm[0,1])\nprint('Specifity : ', Sp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Our Model is making good prediction with SVM linear kernel method"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}