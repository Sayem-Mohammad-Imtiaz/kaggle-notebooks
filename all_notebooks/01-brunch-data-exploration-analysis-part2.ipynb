{"cells":[{"metadata":{},"cell_type":"markdown","source":"## 데이터 탐색의 목적\n1. 데이터가 어떤 식으로 구성된지 확인하고 분석의 방향을 결정 \n2. 사용자와 아이템의 특성을 파악하고 좋은 피쳐와 아이디어를 발굴 ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nimport pandas as pd\nimport numpy as np\nimport os, sys, gc \nfrom plotnine import *\nimport plotnine\n\nfrom tqdm import tqdm_notebook\nimport seaborn as sns\nimport warnings\nimport matplotlib.pyplot as plt\nimport matplotlib.font_manager as fm\nimport matplotlib as mpl\nfrom matplotlib import rc\nimport re\nfrom matplotlib.ticker import PercentFormatter\nimport datetime\nfrom math import log # IDF 계산을 위해","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%config InlineBackend.figure_format = 'retina'\nmpl.font_manager._rebuild()\n\nfontpath = '../input/t-academy-recommendation/NanumBarunGothic.ttf'\nfont = fm.FontProperties(fname=fontpath, size=9).get_name()\n\nmpl.pyplot.rc('font', family=font)\nplt.rc('font', family=font)\nplt.rcParams['font.family'] = font","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"warnings.filterwarnings(action='ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 데이터 로드","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"../input/t-academy-recommendation/\"\nprint(os.listdir(path))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"데이터의 종류는 크게 5가지로 분류가 가능합니다. 하지만, 메타 데이터의 magazine_id와 Magazine데이터의 id와 매핑되는 등 컬럼명이 조금 다른 점을 볼 수 있습니다. 해당 사항에 유의하면서 각 파일별로 어떠한 특성을 가지고 있는 지 살펴보겠습니다. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 하나의 리스트로 반환하는 코드 \ndef chainer(s):\n    return list(itertools.chain.from_iterable(s))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pd.read_json : json 형태의 파일을 dataframe 형태로 불러오는 코드 \nmagazine = pd.read_json(path + 'magazine.json', lines=True) # lines = True : Read the file as a json object per line.\nmetadata = pd.read_json(path + 'metadata.json', lines=True)\nusers = pd.read_json(path + 'users.json', lines=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"json 파일의 경우는 pd.read_json을 이용해서 쉽게 불러왔습니다. 하지만, read의 데이터는 파일명이 \"시작일_종료일\" 형태로 제공되었고 파일의 갯수도 3600개로 많습니다. 그렇기에 경로내에 있는 파일을 한번에 불러와서 하나의 파일로 합치는 작업이 필요합니다. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import itertools\nfrom itertools import chain\nimport glob\nimport os ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"read_rowwise = pd.read_csv(path + \"read_rowwise.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time \n# article_id가 없는 경우 삭제 \nread_rowwise = read_rowwise[read_rowwise['article_id'] != ''].reset_index(drop=True)\n\n# 읽은날짜와 시간 추출 \nread_rowwise['dt'] = read_rowwise['from'].astype(str).apply(lambda x: x[0:8]).astype(int)\nread_rowwise['hr'] = read_rowwise['from'].astype(str).apply(lambda x: x[8:10]).astype(int)\nread_rowwise['read_dt'] = pd.to_datetime(read_rowwise['dt'].astype(str).apply(lambda x: x[0:4] + '-' + x[4:6] + '-' + x[6:8]))\n\nread_rowwise['author_id'] = read_rowwise['article_id'].apply(lambda x: str(x).split('_')[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"read_rowwise[read_rowwise['user_id'] == '#0000d1188f75d0b0ea7a8e23a2b760e5']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"read_rowwise[read_rowwise['user_id'] == '#0000eea6d339abfd02ed590bc451fc63']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"두번째로 발견한 이유는 시간이 흐름에 따라서 사용자의 선호가 바뀔 수 있습니다. 아래의 사용자를 보면 초기에 구독했던 작가들은 많으나 시간이 지나면서 읽지 않고 가장 최근 한달에는 구독하지 않은 작가들의 글을 더 많이 읽는 모습을 볼 수 있습니다. (구독하는 작가의 이름만 표시했습니다. )","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"following_cnt_by_user = users['following_list'].map(len)\nfollowing_rowwise = pd.DataFrame({'user_id': np.repeat(users['id'], following_cnt_by_user),\n                             'author_id': chainer(users['following_list'])})\n\nfollowing_rowwise.reset_index(drop=True, inplace=True)\n\n# 구독하는 작가의 글을 읽는 비율 vs 그렇지 않은 작가의 글을 읽는 비율 \nfollowing_rowwise['is_following'] = 1\nread_rowwise = pd.merge(read_rowwise, following_rowwise, how='left', on=['user_id', 'author_id'])\n\ndel following_rowwise\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"user_id = '#a87e970972364bb14a542f57b0933db9'\nread_user = read_rowwise[read_rowwise['user_id'] == user_id]\nread_user = read_user.groupby(['read_dt', 'is_following', 'author_id'])['author_id'].agg({'count'}).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from mizani.breaks import date_breaks\nfrom mizani.formatters import date_format\n\n(ggplot(data=read_user)\n    + geom_point(aes(x='read_dt', y='count', color='author_id', size='count'), alpha = 0.5, show_legend=False)\n    + geom_text(aes(x='read_dt', y='count', label='author_id'), color='grey', \n               data = read_user[read_user['is_following'] == 1], size=7)\n    + scale_x_datetime(breaks=date_breaks('1 month'), labels=date_format('%Y%m'))\n    + theme_minimal()\n    + ggtitle(\"일별 읽은 작가의 글의 빈도\")\n    + labs(x=\"년도\", y=\"읽은 작가의 글의 빈도\") \n    + theme(text = element_text(fontproperties=fm.FontProperties(fname=fontpath, size=9)),\n         axis_text_x = element_text(angle=60, color='black'),\n         axis_text_y = element_text(color='black'),\n         axis_line=element_line(color=\"black\"),\n         axis_ticks=element_line(color = \"grey\"),\n         figure_size=(12,6))\n )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"위를 통해 판단할 수 있는 정보는 **추천시에 해당 정보들을 토대로 시간에 따라서 사용자의 선호가 바뀐 것은 아닌지, 구독한 작가만의 글을 읽는 게 신뢰할 만한지에 대해 정확히 따져봐야 합니다.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 데이터 탐색 - metadata","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"metadata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime \nmetadata['reg_datetime'] = metadata['reg_ts'].apply(lambda x : datetime.fromtimestamp(x/1000.0))\nmetadata.loc[metadata['reg_datetime'] == metadata['reg_datetime'].min(), 'reg_datetime'] = datetime(2090, 12, 31)\nmetadata['reg_dt'] = metadata['reg_datetime'].dt.date\nmetadata['type'] = metadata['magazine_id'].apply(lambda x : '개인' if x == 0.0 else '매거진')\nmetadata['reg_dt'] = pd.to_datetime(metadata['reg_dt'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"read_cnt_by_reg_dt = pd.DataFrame(metadata.groupby('reg_dt')['article_id'].count()).reset_index()\nread_cnt_by_reg_dt = read_cnt_by_reg_dt.iloc[:-1]\n\n(ggplot(data=read_cnt_by_reg_dt)\n    + geom_line(aes(x='reg_dt', y='article_id'), colour = '#49beb7')\n    + theme_minimal()\n    + ggtitle(\"등록일자별 글 수\")\n    + labs(x=\"등록일자\", y=\"글 수\") \n    + theme(text = element_text(fontproperties=fm.FontProperties(fname=fontpath, size=9)),\n         axis_text_x = element_text(angle=60, color='black'),\n         axis_line=element_line(color=\"black\"),\n         axis_ticks=element_line(color = \"grey\"),\n         figure_size=(12,6))\n )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"등록일자별 글의 수를 보면 2015년도 7월 1일을 기점으로 증가하는 추세이고, 주기적으로 증가했다가 감소하는 모습을 볼 수 있습니다. 그리고 1년을 주기로 1번정도 피크를 보이는 모습을 보입니다. 특히, 2019년도 1월 근방에는 엄청나게 뛰는데 해당 이유를 한번 살펴보겠습니다. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"https://brunch.co.kr/brunchbookproject/7 먼저, 해당 이유는 브런치북 출판 프로젝트의 결과입니다. 브런치에서는 단순 글만 쓰는게 아니라 매거진, 위클리 연재등의 다양한 형태의 글이 존재합니다. 해당 날짜는 브런치북 출판 프로젝트의 마감날로서 사람들이 많이 신청한 것으로 판단됩니다. \n\n이번에는 2019년도 3월의 데이터만을 뽑아서 주기별로 어떤 특성을 보이는 지 살펴보겠습니다. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"read_cnt_by_reg_dt_ = read_cnt_by_reg_dt[read_cnt_by_reg_dt['reg_dt'] >= '2019-03-01']\n\n(ggplot(data=read_cnt_by_reg_dt_)\n    + geom_line(aes(x='reg_dt', y='article_id'), colour = '#49beb7')\n    + theme_minimal()\n    + ggtitle(\"3월의 등록일자별 글 수\")\n    + labs(x=\"등록일자\", y=\"글 수\") \n    + theme(text = element_text(fontproperties=fm.FontProperties(fname=fontpath, size=9)),\n         axis_text_x = element_text(angle=60, color='black'),\n         axis_line=element_line(color=\"black\"),\n         axis_ticks=element_line(color = \"grey\"),\n         figure_size=(12,6))\n )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3월의 등록일자별 글 수를 살펴보면 1주일을 주기로 어떤 패턴을 보이는 것 같습니다. 이런 모습을 보이는 이유는 위클리 매거진에 있는데 매주 동일한 날짜에 \"브런치에서 선정한 작가가 글을 주기적으로 올리는 매거진\"이기 때문입니다. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# metadata[metadata['magazine_id'] == 34075]\nread_cnt_by_reg_dt = read_rowwise[read_rowwise['author_id'] == '@merryseo'].groupby(['read_dt','article_id'])['article_id'].agg({'count'}).reset_index()\nread_cnt_by_reg_dt = read_cnt_by_reg_dt.sort_values(by='read_dt', ascending=False)\n\n(ggplot(data=read_cnt_by_reg_dt)\n    + geom_line(aes(x='read_dt', y='count',group='article_id', colour='article_id'), show_legend=False)\n    + theme_minimal()\n    + ggtitle(\"위클리 매거진 Magazine(34075)\")\n    + labs(x=\"등록일자\", y=\"글 소비수\") \n    + theme(text = element_text(fontproperties=fm.FontProperties(fname=fontpath, size=9)),\n         axis_text_x = element_text(angle=60, color='black'),\n         axis_line=element_line(color=\"black\"),\n         axis_ticks=element_line(color = \"grey\"),\n         figure_size=(12,6))\n    + scale_color_hue(l=0.5)\n )","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# metadata[metadata['magazine_id'] == 34075]\nread_cnt_by_reg_dt = read_rowwise[read_rowwise['author_id'] == '@basenell'].groupby(['read_dt','article_id'])['article_id'].agg({'count'}).reset_index()\nmetadata_ = metadata[['id', 'reg_dt']].rename(columns={'id':'article_id'})\nread_cnt_by_reg_dt = pd.merge(read_cnt_by_reg_dt, metadata_[['article_id', 'reg_dt']], how='left', on='article_id')\nread_cnt_by_reg_dt = read_cnt_by_reg_dt[read_cnt_by_reg_dt['reg_dt'] >= '2019-01-15']\n\n(ggplot(data=read_cnt_by_reg_dt)\n    + geom_line(aes(x='read_dt', y='count',group='article_id', colour='article_id'), show_legend=False)\n    + theme_minimal()\n    + ggtitle(\"위클리 매거진 Magazine(40511)\")\n    + labs(x=\"등록일자\", y=\"글 소비수\") \n    + theme(text = element_text(fontproperties=fm.FontProperties(fname=fontpath, size=9)),\n         axis_text_x = element_text(angle=60, color='black'),\n         axis_line=element_line(color=\"black\"),\n         axis_ticks=element_line(color = \"grey\"),\n         figure_size=(12,6))\n    + scale_color_hue(l=0.5)\n )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"위클리 매거진에 따른 글 소비수를 **발행과 동시에 엄청난 소비수**를 보이는 것을 알 수 있습니다. 그리고 자세히보면, 일주일 이후에 다시 솟아오르는 모습 또한 볼 수 있는데, 다음편을 보기전에 이전편을 보는 모습을 확인할 수 있습니다. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 등록일에 따른 글 소비수의 변화 \nread_rowwise = pd.merge(read_rowwise, metadata_, how='left', on='article_id')\nread_rowwise['diff_dt'] = (read_rowwise['read_dt'] - read_rowwise['reg_dt']).dt.days\noff_day = read_rowwise.groupby(['diff_dt'])['diff_dt'].agg({'count'}).reset_index()\n\n# 메타데이터에 날짜가 잘못 매핑되어서 음수값이 나오는 값 제거 \n# 200이하로 뽑은 이유는 날짜가 너무 큰 데이터가 있어서 제거했음 \noff_day = off_day[(off_day['diff_dt'] >= 0) & (off_day['diff_dt'] <= 200)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(ggplot(data=off_day)\n    + geom_line(aes(x='diff_dt', y='count'), color='#49beb7')\n    + theme_minimal()\n    + ggtitle(\"경과일에 따른 글 소비수 변화\")\n    + labs(x=\"경과일\", y=\"평균 글 소비수\") \n    + theme(text = element_text(fontproperties=fm.FontProperties(fname=fontpath, size=9)),\n         axis_text_x = element_text(angle=60, color='black'),\n         axis_line=element_line(color=\"black\"),\n         axis_ticks=element_line(color = \"grey\"),\n         figure_size=(12,6))\n    + scale_color_hue(l=0.5)\n )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metadata['keyword_list'].values[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keyword_dict = {}\nfor i in tqdm_notebook(metadata[metadata['keyword_list'].apply(lambda x: len(x)) != 0]['keyword_list'].values):\n    for j in range(0, len(i)):\n        word = i[j]\n        cnt = 1\n        try:\n            keyword_dict[word] += cnt\n        except:\n            keyword_dict[word] = cnt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# wordcloud에 대한 자세한 정보는 lovit님의 블로그 https://lovit.github.io/nlp/2018/04/17/word_cloud/를 참고하시기 바랍니다. \nfrom wordcloud import WordCloud\nfrom PIL import Image\n\nwordcloud = WordCloud(\n    font_path = fontpath,\n    width = 800,\n    height = 800,\n    background_color=\"white\",\n    mask= np.array(Image.open(path + \"/figure/RS-KR.png\"))\n\n)\nwordcloud = wordcloud.generate_from_frequencies(keyword_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12, 8))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.show()\nfig.savefig('wordcloud2.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"참고자료 \n- 브런치 데이터의 탐색과 시각화 : https://brunch.co.kr/@kakao-it/332\n- Kakao Arena 2회 대회 : 브런치 사용자를 위한 글 추천 대회 : https://arena.kakao.com/forum/topics/10","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}