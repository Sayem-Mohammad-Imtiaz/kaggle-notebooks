{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-01T00:21:08.983688Z","iopub.execute_input":"2021-08-01T00:21:08.984178Z","iopub.status.idle":"2021-08-01T00:21:08.99363Z","shell.execute_reply.started":"2021-08-01T00:21:08.984144Z","shell.execute_reply":"2021-08-01T00:21:08.99278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading the data\nraw_data = pd.read_csv('/kaggle/input/credit-card-customers/BankChurners.csv')\nraw_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T00:21:08.995695Z","iopub.execute_input":"2021-08-01T00:21:08.996088Z","iopub.status.idle":"2021-08-01T00:21:09.053329Z","shell.execute_reply.started":"2021-08-01T00:21:08.996048Z","shell.execute_reply":"2021-08-01T00:21:09.05262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The dataset\n\n## What the owner of the dataset says\n\n* **CLIENTNUM**: Client number. Unique identifier for the customer holding the account\n* **Attrition_Flag**: Internal event (customer activity) variable - if the account is closed then 1 else 0 (**Target**)\n* **Customer_Age**: Demographic variable - Customer's Age in Years\n* **Gender**: Demographic variable - M=Male, F=Female\n* **Dependent_count**: Demographic variable - Number of dependents\n* **Education_Level**: Demographic variable - Educational Qualification of the account holder (example: high school, college graduate, etc.)\n* **Marital_Status**: Demographic variable - Married, Single, Divorced, Unknown\n* **Income_Category**: Demographic variable - Annual Income Category of the account holder (< $40K, $40K - 60K, $60K - $80K, $80K-$120K, > $120K, Unknown)\n* **Card_Category**: Product Variable - Type of Card (Blue, Silver, Gold, Platinum)\n* **Months_on_book**: Period of relationship with bank\n* **Total_relationship_count**: Total no. of products held by the customer\n* **Months_Inactive_12_mon**: No. of months inactive in the last 12 months\n* **Contacts_Count_12_mon**: No. of Contacts in the last 12 months\n* **Credit_Limit**: Credit Limit on the Credit Card\n* **Total_Revolving_Bal**: Total Revolving Balance on the Credit Card\n* **Avg_Open_To_Buy**: Open to Buy Credit Line (Average of last 12 months)\n* **Total_Amt_Chng_Q4_Q1**: Change in Transaction Amount (Q4 over Q1)\n* **Total_Trans_Amt**: Total Transaction Amount (Last 12 months)\n* **Total_Trans_Ct**: Total Transaction Count (Last 12 months)\n* **Total_Ct_Chng_Q4_Q1**: Change in Transaction Count (Q4 over Q1)\n* **Avg_Utilization_Ratio**: Average Card Utilization Ratio\n\nAnd then the owner advises not to use the last 2 columns.\n\n## Data preprocessing\n\n* Drop the CLIENTNUM and the last 2 columns, as it makes no sense using it in the model\n* Let's see the describe method and check for NaN and/or strange values\n* Map the Attrition_Flag to 1: churned, 0: active; Gender to 0: male, 1: female (Let's do this before the get_dummies method, so it's not necessary to create dummies for them)\n* One-hot encoding for the Education_Level, Marital_Status, Income_Category and Card_Category columns","metadata":{}},{"cell_type":"code","source":"# Creating a new data frame and dropping the columns we won't use\ndf = raw_data.copy().drop([raw_data.columns[0], raw_data.columns[-2], raw_data.columns[-1]], axis=1)\n# Dataset statistics\ndf.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2021-08-01T00:21:09.054432Z","iopub.execute_input":"2021-08-01T00:21:09.05479Z","iopub.status.idle":"2021-08-01T00:21:09.131241Z","shell.execute_reply.started":"2021-08-01T00:21:09.054762Z","shell.execute_reply":"2021-08-01T00:21:09.130333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the NaN count\ndf.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T00:21:09.288871Z","iopub.execute_input":"2021-08-01T00:21:09.289229Z","iopub.status.idle":"2021-08-01T00:21:09.301562Z","shell.execute_reply.started":"2021-08-01T00:21:09.289184Z","shell.execute_reply":"2021-08-01T00:21:09.300602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mapping the Attrition_Flag and Gender columns\ndf['Attrition_Flag'] = df['Attrition_Flag'].map({'Existing Customer': 0, 'Attrited Customer': 1})\ndf['Gender'] = df['Gender'].map({'M': 0, 'F': 1})\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T00:21:09.303278Z","iopub.execute_input":"2021-08-01T00:21:09.303676Z","iopub.status.idle":"2021-08-01T00:21:09.330367Z","shell.execute_reply.started":"2021-08-01T00:21:09.303637Z","shell.execute_reply":"2021-08-01T00:21:09.329372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the amount of \"unknown\" values on the education level, marital status and income columns\ned_level_unknown = df['Education_Level'].value_counts()['Unknown'] / df['Education_Level'].count()\nmarital_unknown = df['Marital_Status'].value_counts()['Unknown'] / df['Marital_Status'].count()\nincome_unknown = df['Marital_Status'].value_counts()['Unknown'] / df['Income_Category'].count()\n\nprint('Education Level % of unknown values: ', ed_level_unknown)\nprint('Marital Status % of unknown values: ', marital_unknown)\nprint('Income Category % of unknown values: ', income_unknown)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T00:21:09.332375Z","iopub.execute_input":"2021-08-01T00:21:09.332758Z","iopub.status.idle":"2021-08-01T00:21:09.347389Z","shell.execute_reply.started":"2021-08-01T00:21:09.332718Z","shell.execute_reply":"2021-08-01T00:21:09.346187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's check the distribution of values on those categories\nfig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharey=True, figsize=(12, 18))\nax1.hist(df['Income_Category'])\nax1.set_title('Income Category')\nax2.hist(df['Marital_Status'])\nax2.set_title('Marital Status')\nax3.hist(df['Education_Level'])\nax3.set_title('Education Level')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T00:21:09.348629Z","iopub.execute_input":"2021-08-01T00:21:09.348869Z","iopub.status.idle":"2021-08-01T00:21:09.852415Z","shell.execute_reply.started":"2021-08-01T00:21:09.348845Z","shell.execute_reply":"2021-08-01T00:21:09.851417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding the 'unknown' observations to the mode value\ndf['Education_Level'] = df['Education_Level'].replace('Unknown', df['Education_Level'].mode()[0])\ndf['Marital_Status'] = df['Marital_Status'].replace('Unknown', df['Marital_Status'].mode()[0])\ndf['Income_Category'] = df['Income_Category'].replace('Unknown', df['Income_Category'].mode()[0])","metadata":{"execution":{"iopub.status.busy":"2021-08-01T00:21:09.854396Z","iopub.execute_input":"2021-08-01T00:21:09.854809Z","iopub.status.idle":"2021-08-01T00:21:09.867537Z","shell.execute_reply.started":"2021-08-01T00:21:09.854767Z","shell.execute_reply":"2021-08-01T00:21:09.866533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting dummies for the categorical columns: Education_Level, Marital_Status, Income_Category and Card_Category\ndf = pd.get_dummies(df)\nprint(df.columns)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-01T00:21:09.868618Z","iopub.execute_input":"2021-08-01T00:21:09.868853Z","iopub.status.idle":"2021-08-01T00:21:09.903453Z","shell.execute_reply.started":"2021-08-01T00:21:09.86883Z","shell.execute_reply":"2021-08-01T00:21:09.902499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The dummies are good!\n\nAll the columns we wanted to get dummies are now one-hot encoded. But there's one problem: There are \"unknown\" categories for education level, marital status and income. I wonder how that's going to impact the model. Speaking of it, let's create it!","metadata":{}},{"cell_type":"code","source":"# Creating the train and test sets\ntrain_dataset = df.sample(frac=0.8, random_state=0)\ntest_dataset = df.drop(train_dataset.index) # Excluding all observations from the train set\n\n# Let's compare the distributions of the train and test datasets\nprint(train_dataset.describe().transpose()[['mean', 'std']])\nprint(test_dataset.describe().transpose()[['mean', 'std']])","metadata":{"execution":{"iopub.status.busy":"2021-08-01T00:21:09.904533Z","iopub.execute_input":"2021-08-01T00:21:09.904787Z","iopub.status.idle":"2021-08-01T00:21:10.054522Z","shell.execute_reply.started":"2021-08-01T00:21:09.904753Z","shell.execute_reply":"2021-08-01T00:21:10.053571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the features from the labels\ntrain_features = train_dataset.copy()\ntest_features = test_dataset.copy()\n\ntrain_labels = train_features.pop('Attrition_Flag')\ntest_labels = test_features.pop('Attrition_Flag')","metadata":{"execution":{"iopub.status.busy":"2021-08-01T00:21:10.0563Z","iopub.execute_input":"2021-08-01T00:21:10.056583Z","iopub.status.idle":"2021-08-01T00:21:10.062764Z","shell.execute_reply.started":"2021-08-01T00:21:10.056556Z","shell.execute_reply":"2021-08-01T00:21:10.061795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data normalization\nnormalizer = preprocessing.Normalization()\nnormalizer.adapt(np.array(train_features))","metadata":{"execution":{"iopub.status.busy":"2021-08-01T00:21:10.064118Z","iopub.execute_input":"2021-08-01T00:21:10.064444Z","iopub.status.idle":"2021-08-01T00:21:10.090995Z","shell.execute_reply.started":"2021-08-01T00:21:10.064416Z","shell.execute_reply":"2021-08-01T00:21:10.090147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model\nwidth = 5\n\nmodel = keras.models.Sequential([\n    normalizer,\n    layers.Dense(units = width, activation='softplus'),\n    layers.Dense(units = width, activation='softplus'),\n    layers.Dense(units = 1)\n])\n\nmodel.summary()\n\n# Compiling and Fitting\n\nlearning_rate = 0.005\nepochs = 50\nbatch_size = 100\n\nloss = keras.losses.MeanSquaredError()\noptimizer = keras.optimizers.Adam(lr = learning_rate)\n\nmodel.compile(\n    optimizer = optimizer,\n    loss = loss,\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    train_features,\n    train_labels,\n    validation_split = 0.2,\n    verbose = 2,\n    epochs = epochs,\n    batch_size = batch_size\n)\n\nplt.plot(history.history['loss'], label='loss')\nplt.plot(history.history['val_loss'], label='val_loss')\nplt.xlabel('Epoch')\nplt.ylabel('Error [Attrition_Flag]')\nplt.legend()\nplt.grid(True)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T00:21:55.700102Z","iopub.execute_input":"2021-08-01T00:21:55.700466Z","iopub.status.idle":"2021-08-01T00:22:02.313469Z","shell.execute_reply.started":"2021-08-01T00:21:55.700436Z","shell.execute_reply":"2021-08-01T00:22:02.31257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's evaluate\nmodel.evaluate(\n    test_features,\n    test_labels,\n    verbose = 2\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-01T00:29:05.034152Z","iopub.execute_input":"2021-08-01T00:29:05.034559Z","iopub.status.idle":"2021-08-01T00:29:05.135954Z","shell.execute_reply.started":"2021-08-01T00:29:05.034523Z","shell.execute_reply":"2021-08-01T00:29:05.135273Z"},"trusted":true},"execution_count":null,"outputs":[]}]}