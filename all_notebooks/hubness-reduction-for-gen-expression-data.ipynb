{"cells":[{"metadata":{},"cell_type":"markdown","source":"# What is about ?\n\n\nLook at modularity of KNN graphs for single cell data with Hubness reduction and without , also testing other transforms.\n\nV25 - same as 24, but for mouse \n\nV24 - human - analysis of pca-reduction to many different values \n\nV23 - same as 22 , but for mouse \n\nV22 same, but  transforms : None and log  (again as before). Also new aggregated statistics output added \n\nV21 human - all with more than 200 cells, fixed: transform = log \n\nV20 - skip \n\nV19 - human again , datasets with 200 - 1000 cells\n\nV18 same as v17 but datasets 200-500 cells \n\nV17 same as V16 but datasets with 500-1000 cells \n\nV16 same as V15 but for MOUSE (not human) data - 38 datasets \n\nV15 same as V14 but PCA 50 and 200 (not only 50 as in V14). \n\nV14 analyse several datasets  from collection:  ARCHS4/human/ cell number: more than 1000 - 27 datasets \n(see info in https://www.kaggle.com/alexandervc/multiple-single-cell-rna-expressions-archs4 )\n\nV13 cancelled - more than 8 hours  dataset = 'GSE95753_v5_scrna_10x_6000_19585_Mouse_Brain_DentateGyrus_invivo_fromCytotrace'\n\nV12 dataset = 'Torus1000x10000'\n\nV11 dataset = 'Sphere1000x10000'\n\nV10 dataset = 'Uniform1000x10000'\n\nV8,9 Gaussian 1000x10_000\n\nV7 - dataset = 'Dexter300from_scikit_hubness'\n\nV6 - dataset = 'openml1146OVA_Prostate'\n\nV5 - dataset = 'GSE67123_v6_scrna_10x_143_23548_Mouse_Embryo_HSCs_invivo_fromCytotrace'\n\nV4 - dataset = 'GSE90047_Mouse_Liver_Hepatoblast_invivo'\n\nV3 - dataset = 'single-cell-rna-seq-from-stoeckius-et-al-2017/GSE100866_CD8_merged-RNA_umi'\n\nV2: extend by transforms by PCA, extend statistics\n\nV1: Data - 'human_liver_ARCHS4' Conclusion - best modularity - mutual_proximity minkowski log 0.908534"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import h5py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt \nimport seaborn as sns\nimport time\n\n_t00 = time.time() # script start time ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Open file"},{"metadata":{"trusted":true},"cell_type":"code","source":"#filename = '/kaggle/input/multiple-single-cell-rna-expressions-archs4/human_matrix.h5'\nfilename = '/kaggle/input/multiple-single-cell-rna-expressions-archs4/mouse_matrix.h5'\n\nf = h5py.File(filename,'r')#, mode)\nfor key in f.keys():\n    print(key) #Names of the groups in HDF5 file.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Access full expression data  "},{"metadata":{"trusted":true},"cell_type":"code","source":"key = 'data'\nkey2 = 'expression'\nX_full = f[key][key2]\nprint(X_full.shape)\nX_full","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_full[:5,:8]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Look at different GSE present in data\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract GSE and look how many unique we have:\nkey = 'meta'\ngroup = f[key]\nd = group['Sample_series_id']\nprint(  len(np.unique(d) ) )\nseries_GSE_for_each_row = pd.Series(d)\nv = series_GSE_for_each_row.value_counts()\nprint( (v > 2000).sum(), (v > 1000).sum(),  (v > 500).sum(),(v > 100).sum(), (v<=10).sum(), (v==1).sum(), )\nv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Some statistics on number of cells corresponding to different GSE:\nseries_GSE_and_cell_count = series_GSE_for_each_row.value_counts()\nseries_GSE_and_cell_count.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Generate statistics for datasets with more than 1000 cells"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install scikit-hubness\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skhubness.neighbors import NearestNeighbors\nfrom sklearn.neighbors import NearestNeighbors as NearestNeighbors_sklearn\nfrom sklearn.decomposition import PCA\n\nimport igraph","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"verbose = 0 \n\n#mm = (1500 < series_GSE_and_cell_count ) &  ( series_GSE_and_cell_count < 2000 )\nmm = (301 < series_GSE_and_cell_count ) &  ( series_GSE_and_cell_count <= 500000 )\n\nn_neighbors = 10\n\nt00 = time.time()\n\nprint( mm.sum() )\n#print( series_GSE_and_cell_count[mm] )\n\nkey = 'meta'\nkey2 = 'gene_name'\ngene_names = f[key][key2]\n\nlist_results = []\ndf_stat = pd.DataFrame()\nix4df_stat = 0\nfor GSE in series_GSE_and_cell_count[mm].index:\n    print()\n    print(GSE)\n    t0 = time.time()\n    mask = GSE == series_GSE_for_each_row\n    mask = mask.values\n    X = X_full[mask,:]\n    print(X.shape, 'count totally zero genes',  (X.sum(axis = 0) == 0 ).sum() ) \n    m = X.sum(axis = 0) != 0 \n    X = X[:,m]\n\n    \n    for dim_reduction in [None, 50, 100, 150,200, 250, 300]: #None, , 200 10, 50, 100, 500]:\n        for transform_type in [ 'log']: # '',\n            for metric in ['cosine'  ]: # 'minkowski', ,   'minkowski'\n                for mode in ['Standard KNN graph' ,  'mutual_proximity']:# ,   ,  \"local_scaling\" \"local_scaling\", \"dis_sim_local\" ] : # 'KNN graph with hubness = mutual_proximity' ]: # range(2):\n                    if verbose >= 10:\n                        print()\n                    str_info = str(GSE) + ' ' +mode + ' ' +  metric + ' ' + transform_type \n                    if dim_reduction is not None: str_info += 'PCA'+str(dim_reduction)\n                    if str_info[-1]==' ': str_info = str_info[:-1] \n                    \n                    df_stat.loc[ ix4df_stat, 'GSE'] = GSE\n\n                    t0 = time.time()\n\n                    X2 = X.copy()\n\n                    if transform_type == 'log':\n                        X2 = np.log(1+np.abs(X2) ) \n\n                    if dim_reduction is not None:\n                        pca = PCA(n_components=dim_reduction)\n                        pca.fit(X2)\n                        X2 = pca.transform(X2)\n\n                    if mode == 'Standard KNN graph':\n                        nbrs = NearestNeighbors_sklearn(n_neighbors=n_neighbors, metric = metric).fit(X2) #  algorithm='ball_tree' #  {‘mutual_proximity’, ‘local_scaling’, ‘dis_sim_local’, None},\n                    else:    \n                        nbrs = NearestNeighbors(n_neighbors=n_neighbors,hubness = mode, metric = metric ).fit(X2) #  algorithm='ball_tree' #  {‘mutual_proximity’, ‘local_scaling’, ‘dis_sim_local’, None}, \n                    \n                    if verbose >= 10:\n                        print(str_info,  np.round(time.time()-t0,2),'secs passed')\n\n                    distances, indices = nbrs.kneighbors(X2)\n                    edges = np.zeros( (0,2), dtype= int ) \n                    for i in range(1,5):\n                        ed = indices[:,[0,i]]\n                        edges = np.concatenate( (edges,ed), axis = 0 )\n\n                    g = igraph.Graph( directed = True )\n                    g.add_vertices(range(len(X)))\n                    g.add_edges(edges )\n\n                    g.to_undirected(mode = 'collapse')\n                    louvain_partition = g.community_multilevel()# weights=graph.es['weight'], return_levels=False)\n                    modularity1 = g.modularity( louvain_partition )#, we    \n\n                    if verbose >= 10:\n                        print(\"The modularity for Louvain partition is {}\".format(modularity1))\n                        print(np.round(time.time()-t0,2),'secs passed')\n\n                    list_results.append( (str_info, g) )\n\n                    df_stat.loc[ix4df_stat,'Info'] = str_info\n                    df_stat.loc[ix4df_stat,'Louvain modularity'] = modularity1\n                    df_stat.loc[ix4df_stat,'Mode'] = mode\n                    df_stat.loc[ix4df_stat,'Metric'] =  metric\n                    if transform_type == '':\n                        df_stat.loc[ix4df_stat,'Transform'] =  'None'\n                    else:\n                        df_stat.loc[ix4df_stat,'Transform'] = transform_type\n                    if dim_reduction is not None:\n                        df_stat.loc[ix4df_stat,'PCA'] = str(dim_reduction )\n                    else:\n                        df_stat.loc[ix4df_stat,'PCA'] = 'None' \n\n                    ix4df_stat += 1\n\n                    \nprint(np.round(time.time()-t00,1), np.round( (time.time()-t00)/60,1),  np.round( (time.time()-t00)/3600,1), 'seconds minutes hours total passed')\n    \ndf_stat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_stat.to_csv('df_stat')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_stat.groupby([ 'Mode',]).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_stat.groupby(['PCA', 'Mode']).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('ggplot')\nf1 = 'PCA'\nf2 = 'Mode'\nfor val1 in df_stat[f1].unique():\n    fig=plt.figure(figsize=(10,4))\n    l = []\n    for val2 in ['mutual_proximity', 'Standard KNN graph'   ]: # df_stat[f2].unique():\n        mask = (df_stat[f1] == val1) & ( df_stat[f2] == val2)\n        v = df_stat['Louvain modularity'][mask]\n        l.append(v)\n    d = pd.DataFrame(data = (l[0].values,l[1].values )) \n    d = d.transpose()\n    d = d.sort_values(0)\n    plt.plot(d[0].values, label = 'mutual proximity' )\n    plt.plot(d[1].values, label = 'Standard KNN graph' )\n    plt.title(f1 + ' ' +str(val1)  )\n    plt.ylabel('Louvain modularity' )\n    plt.ylabel('dataset' )\n    plt.show()\n    \n    from scipy.stats import wilcoxon\n    w, p = wilcoxon(l[0].values , l[1].values )\n    #w, p\n    print(f1, val1, 'wilcoxon p-value', p)\n    \n        \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_stat.sort_values( 'Louvain modularity', ascending = False ).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_stat.groupby(['Transform']).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_stat.groupby(['Transform', 'Mode',]).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_stat.groupby([ 'Transform','Metric',  'Mode',]).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_stat.groupby([ 'Transform', 'PCA', 'Metric',  'Mode',]).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_stat.groupby([  'Transform','Metric',  'Mode',]).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_stat.groupby([  'Transform','PCA',  'Mode',]).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_stat.groupby([  'PCA', 'Transform',  'Mode',]).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_stat.groupby(['Metric']).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_stat.groupby(['Metric', 'Mode',]).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_stat.groupby([ 'PCA','Metric',  'Mode',]).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_stat.groupby([ 'PCA', 'Mode',]).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_stat.groupby([ 'Mode',]).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_stat.to_csv('df_stat.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.round(time.time() - _t00,1),np.round((time.time() - _t00)/60,1),np.round((time.time() - _t00)/3600,1),'total seconds,minutes/hours passed' ) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}