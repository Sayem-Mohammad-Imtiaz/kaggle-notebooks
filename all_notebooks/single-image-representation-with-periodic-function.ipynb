{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Implicit Neural Representations with Periodic Activation Functions\n[https://arxiv.org/pdf/2006.09661.pdf](https://arxiv.org/pdf/2006.09661.pdf)","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%%capture\n!git clone https://gist.github.com/belkhir-nacim/5230ccfcab05f30c35abb03444f6a216 dataset_util\n!pip install pytorch-lightning==0.7.6\n!pip install git+https://github.com/belkhir-nacim/generative_model_toolbox\n!pip install fastai2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import functools\nfrom enum import IntEnum\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.utils as utils\nimport argparse\nfrom dataset_util.kaggle_textile_texuture_dataset import TextureDataset\nimport os\nimport torchvision.transforms as transforms\nfrom torchvision.utils import make_grid\nfrom torch import optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom functools import partial\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from generative_models_toolbox.utils.device import Cudafy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cudafy = Cudafy(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai2.vision.all import *\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Optional dependency to visualize image gradient\nimport kornia\nfrom typing import List\nimport math\nfrom torch.nn.init import _calculate_correct_fan\n\n\nlaplace_filter = partial(kornia.filters.laplacian, kernel_size=3)\ngradient_filter = kornia.filters.sobel\n\ndef visualize_filter(image, filter_func, ax=None,title=None):\n    filt = filter_func(image.unsqueeze(0))\n    # Normalizing to [0, 1] range\n    filt -= filt.min()\n    filt /= filt.max()\n    img = kornia.tensor_to_image(filt[0])\n    if ax is None:\n        fig = plt.figure()\n        ax = fig.gca()\n    ax.imshow(img,cmap='gray')\n    if title is not None: ax.set_title(title)\n    return ax\n\n#Helper function\ndef decode_prediction(learner, inp):\n    y_hat = learn.model(cudafy(inp))\n    return TensorImage(y_hat.transpose(0, 1).reshape(1, 256, 256))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom typing import List\nimport math\n\n\ndef siren_init(tensor, use_this_fan_in=None):\n    \"\"\"\n        Siren initalization of a tensor. To initialize a nn.Module use 'apply_siren_init'. \n        It's equivalent to torch.nn.init.kaiming_uniform_ with mode = 'fan_in'\n        and the same gain as the 'ReLU' nonlinearity\n    \"\"\"\n    if use_this_fan_in is not None:\n        fan_in = use_this_fan_in\n    else:\n        fan_in = nn.init._calculate_correct_fan(tensor, \"fan_in\")\n    bound = math.sqrt(6.0 / fan_in)\n    with torch.no_grad():\n        return tensor.uniform_(-bound, bound)\n\n\ndef apply_siren_init(layer: nn.Module):\n    \"\"\"\n        Applies siren initialization to a layer\n    \"\"\"\n    siren_init(layer.weight)\n    if layer.bias is not None:\n        fan_in = nn.init._calculate_correct_fan(layer.weight, \"fan_in\")\n        siren_init(layer.bias, use_this_fan_in=fan_in)\n\n\nclass Siren(nn.Module):\n    \"\"\"\n        Siren activation\n        https://arxiv.org/abs/2006.09661\n    \"\"\"\n\n    def __init__(self, w0=1):\n        \"\"\"\n            w0 comes from the end of section 3\n            it should be 30 for the first layer\n            and 1 for the rest\n        \"\"\"\n        super().__init__()\n        self.w0 = torch.tensor(w0)\n\n    def forward(self, x):\n        return torch.sin(self.w0 * x)\n\n    def extra_repr(self):\n        return \"w0={}\".format(self.w0)\n\n\ndef siren_layer(in_features, out_features, bias=True, w0=1):\n    \"\"\"\n        Siren Layer - it's a modified linear layer with sine activation\n    \"\"\"\n    layer = nn.Sequential(nn.Linear(in_features, out_features, bias), Siren(w0))\n    apply_siren_init(layer[0])\n    return layer\n\n\ndef siren_model(dimensions: List[int]):\n    \"\"\"\n        Siren model as presented in the paper. It's a sequence of linear layers followed by the Siren activation\n    \"\"\"\n    first_layer = siren_layer(dimensions[0], dimensions[1], w0=30)\n    other_layers = []\n    for dim0, dim1 in zip(dimensions[1:-1], dimensions[2:]):\n        other_layers.append(siren_layer(dim0, dim1))\n    return nn.Sequential(first_layer, *other_layers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_xp_trial():\n\n    dl = DataLoader(TextureDataset('/kaggle/input/textiledefectdetection',train=True, patch_size= 64, keep_angles=False,  keep_defects=False, sub_sample=2),shuffle=True, batch_size=1)\n    img_ground_truth,_,_ = next(iter(dl))\n    img_ground_original = img_ground_truth.squeeze(0)\n    img_ground_truth = img_ground_truth.squeeze(0).permute(1,2,0)\n    \n    pipe = Pipeline([transforms.ToPILImage(), transforms.Resize(256), transforms.ToTensor()])\n    image = pipe(img_ground_original)\n    print(image.shape)\n    fig, axes = plt.subplots(1,3,figsize=(15,8))\n    visualize_filter(image, lambda x:x,ax=axes[0],title='original' )\n    visualize_filter(image, gradient_filter,ax=axes[1],title='gradient')\n    visualize_filter(image, laplace_filter,ax=axes[2],title='laplacian')\n    \n    y = image.reshape(1, -1).transpose(0, 1)\n    g0, g1 = torch.meshgrid([torch.arange(-1, 1, step=2/256), torch.arange(-1, 1, step=2/256)])\n    x = torch.cat([g0.flatten().unsqueeze(1), g1.flatten().unsqueeze(1)], dim=1)\n    x = x.float()\n    for coord, pixel_value in zip(x, y):\n        c = ( 128 * (1 + coord)).long()\n        assert (image[:, c[0], c[1]] == pixel_value).all(), \"Pixel values do not match\"\n    from torch.utils.data import TensorDataset, random_split\n    dset = TensorDataset(cudafy(x), cudafy(y))\n    val_pct = 0.2\n    val_len = int(len(dset)*val_pct)\n    lengths = [len(dset)-val_len, val_len]\n    train_dset, val_dset = random_split(dset, lengths)\n    dls = DataLoaders(DataLoader(train_dset, bs=256), DataLoader(val_dset, bs=4096))\n    learn = Learner(dls,  cudafy(siren_model([2, 256, 128, 64, 32, 1])),  loss_func=MSELossFlat(),opt_func=ranger)\n    print(learn.model)\n    learn.fit_flat_cos(5, lr=1e-3)\n    \n    fig, axes = plt.subplots(1,2,figsize=(15,8))\n    visualize_filter(image, lambda x:x,ax=axes[0],title='original' )\n    visualize_filter(decode_prediction(cudafy(learn), cudafy(x)), lambda x:x,ax=axes[1], title='decoded')\n\n    fig, axes = plt.subplots(1,3,figsize=(15,8))\n    visualize_filter(image, laplace_filter,ax=axes[0],title='original laplacian' )\n    visualize_filter(decode_prediction(cudafy(learn), cudafy(x)), laplace_filter,ax=axes[1], title='decoded laplacian')\n    tmp = laplace_filter(image.unsqueeze(0))  - laplace_filter(decode_prediction(cudafy(learn), cudafy(x)).unsqueeze(0) )\n    visualize_filter(tmp , lambda x :x,ax=axes[2], title='diff')\n\n\n    fig, axes = plt.subplots(1,3,figsize=(15,8))\n    visualize_filter(image, gradient_filter,ax=axes[0],title='original gradient' )\n    visualize_filter(decode_prediction(cudafy(learn), cudafy(x)), gradient_filter,ax=axes[1], title='decoded gradient')\n    tmp = gradient_filter(image.unsqueeze(0))  - gradient_filter(decode_prediction(cudafy(learn), cudafy(x)).unsqueeze(0) )\n    visualize_filter(tmp , lambda x :x,ax=axes[2], title='diff')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dl = DataLoader(TextureDataset('/kaggle/input/textiledefectdetection',train=False, patch_size= 64, keep_angles=False,  keep_defects=True, sub_sample=10),shuffle=True, batch_size=1)\n\nimg_ground_truth = None\nfor data,angle,label in dl:\n    if label[0].item()==3:\n        img_ground_truth = data\n    else:\n        pass\n# img_ground_truth,_,_ = next(iter(dl)) if train == True\nimg_ground_original = img_ground_truth.squeeze(0)\nimg_ground_truth = img_ground_truth.squeeze(0).permute(1,2,0)\npipe = Pipeline([transforms.ToPILImage(), transforms.Resize(256), transforms.ToTensor()])\nimage = pipe(img_ground_original)\nprint(image.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1,3,figsize=(15,8))\nvisualize_filter(image, lambda x:x,ax=axes[0],title='original' )\nvisualize_filter(image, gradient_filter,ax=axes[1],title='gradient')\nvisualize_filter(image, laplace_filter,ax=axes[2],title='laplacian')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = image.reshape(1, -1).transpose(0, 1)\ny.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g0, g1 = torch.meshgrid([torch.arange(-1, 1, step=2/256), torch.arange(-1, 1, step=2/256)])\nx = torch.cat([g0.flatten().unsqueeze(1), g1.flatten().unsqueeze(1)], dim=1)\nx = x.float()\nx.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for coord, pixel_value in zip(x, y):\n    c = ( 128 * (1 + coord)).long()\n    assert (image[:, c[0], c[1]] == pixel_value).all(), \"Pixel values do not match\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import TensorDataset, random_split\ndset = TensorDataset(cudafy(x), cudafy(y))\nval_pct = 0.005\nval_len = int(len(dset)*val_pct)\nlengths = [len(dset)-val_len, val_len]\ntrain_dset, val_dset = random_split(dset, lengths)\ndls = DataLoaders(DataLoader(train_dset, bs=256), DataLoader(val_dset, bs=4096))\nlearn = Learner(dls,  cudafy(siren_model([2, 256, 128, 64, 32, 1])),  loss_func=MSELossFlat(),opt_func=ranger)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_flat_cos(150, lr=1e-3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1,2,figsize=(15,8))\nvisualize_filter(image, lambda x:x,ax=axes[0],title='original' )\nvisualize_filter(decode_prediction(learn, cudafy(x)), lambda x:x,ax=axes[1], title='decoded')\n\nfig, axes = plt.subplots(1,3,figsize=(15,8))\nvisualize_filter(image, laplace_filter,ax=axes[0],title='original laplacian' )\nvisualize_filter(decode_prediction(learn, cudafy(x)), laplace_filter,ax=axes[1], title='decoded laplacian')\ntmp = cudafy(laplace_filter(image.unsqueeze(0)))  - laplace_filter(decode_prediction(learn, cudafy(x)).unsqueeze(0) )\nvisualize_filter(tmp , lambda x :x,ax=axes[2], title='diff')\n\n\nfig, axes = plt.subplots(1,3,figsize=(15,8))\nvisualize_filter(image, gradient_filter,ax=axes[0],title='original gradient' )\nvisualize_filter(decode_prediction(learn, cudafy(x)), gradient_filter,ax=axes[1], title='decoded gradient')\ntmp = cudafy(gradient_filter(image.unsqueeze(0)))  - gradient_filter(decode_prediction(learn, cudafy(x)).unsqueeze(0) )\nvisualize_filter(tmp , lambda x :x,ax=axes[2], title='diff')\n\n# fig, axes = plt.subplots(1,2,figsize=(15,8))\n# visualize_filter(image, lambda x:x,ax=axes[0],title='original' )\n# visualize_filter(decode_prediction(cudafy(learn), cudafy(x)), lambda x:x,ax=axes[1], title='decoded')\n\n# fig, axes = plt.subplots(1,3,figsize=(15,8))\n# visualize_filter(image, laplace_filter,ax=axes[0],title='original laplacian' )\n# visualize_filter(decode_prediction(cudafy(learn), cudafy(x)), laplace_filter,ax=axes[1], title='decoded laplacian')\n# tmp = laplace_filter(image.unsqueeze(0))  - laplace_filter(decode_prediction(cudafy(learn), cudafy(x)).unsqueeze(0) )\n# visualize_filter(tmp , lambda x :x,ax=axes[2], title='diff')\n\n\n# fig, axes = plt.subplots(1,3,figsize=(15,8))\n# visualize_filter(image, gradient_filter,ax=axes[0],title='original gradient' )\n# visualize_filter(decode_prediction(cudafy(learn), cudafy(x)), gradient_filter,ax=axes[1], title='decoded gradient')\n# tmp = gradient_filter(image.unsqueeze(0))  - gradient_filter(decode_prediction(cudafy(learn), cudafy(x)).unsqueeze(0) )\n# visualize_filter(tmp , lambda x :x,ax=axes[2], title='diff')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of pixels on the image\n256*256*3\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of parameters on the model\nprint('Number of parameters of the model {}'.format(sum([p.numel() for p in learn.model.parameters()])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training with ReLU","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from typing import List\ndef relu_model(dimensions: List[int]):\n    \"\"\"\n        Sequence of linear layers followed by ReLU\n    \"\"\"\n    layers = []\n    for dim0, dim1 in zip(dimensions[:-1], dimensions[1:]):\n        layers.append(nn.Linear(dim0, dim1))\n        layers.append(nn.ReLU())\n    return nn.Sequential(*layers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = Learner(dls,  cudafy(relu_model([2, 256, 128, 64, 32, 1])),  loss_func=MSELossFlat(), opt_func=ranger )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_flat_cos(150, lr=1e-3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1,2,figsize=(15,8))\nvisualize_filter(image, lambda x:x,ax=axes[0],title='original' )\nvisualize_filter(decode_prediction(learn, cudafy(x)), lambda x:x,ax=axes[1], title='decoded')\n\nfig, axes = plt.subplots(1,3,figsize=(15,8))\nvisualize_filter(image, laplace_filter,ax=axes[0],title='original laplacian' )\nvisualize_filter(decode_prediction(learn, cudafy(x)), laplace_filter,ax=axes[1], title='decoded laplacian')\ntmp = cudafy(laplace_filter(image.unsqueeze(0)))  - laplace_filter(decode_prediction(learn, cudafy(x)).unsqueeze(0) )\nvisualize_filter(tmp , lambda x :x,ax=axes[2], title='diff')\n\n\nfig, axes = plt.subplots(1,3,figsize=(15,8))\nvisualize_filter(image, gradient_filter,ax=axes[0],title='original gradient' )\nvisualize_filter(decode_prediction(learn, cudafy(x)), gradient_filter,ax=axes[1], title='decoded gradient')\ntmp = cudafy(gradient_filter(image.unsqueeze(0)))  - gradient_filter(decode_prediction(learn, cudafy(x)).unsqueeze(0) )\nvisualize_filter(tmp , lambda x :x,ax=axes[2], title='diff')\n\n# fig, axes = plt.subplots(1,2,figsize=(15,8))\n# visualize_filter(image, lambda x:x,ax=axes[0],title='original' )\n# visualize_filter(decode_prediction(cudafy(learn), cudafy(x)), lambda x:x,ax=axes[1], title='decoded')\n\n# fig, axes = plt.subplots(1,3,figsize=(15,8))\n# visualize_filter(image, laplace_filter,ax=axes[0],title='original laplacian' )\n# visualize_filter(decode_prediction(cudafy(learn), cudafy(x)), laplace_filter,ax=axes[1], title='decoded laplacian')\n# tmp = laplace_filter(image.unsqueeze(0))  - laplace_filter(decode_prediction(cudafy(learn), cudafy(x)).unsqueeze(0) )\n# visualize_filter(tmp , lambda x :x,ax=axes[2], title='diff')\n\n\n# fig, axes = plt.subplots(1,3,figsize=(15,8))\n# visualize_filter(image, gradient_filter,ax=axes[0],title='original gradient' )\n# visualize_filter(decode_prediction(cudafy(learn), cudafy(x)), gradient_filter,ax=axes[1], title='decoded gradient')\n# tmp = gradient_filter(image.unsqueeze(0))  - gradient_filter(decode_prediction(cudafy(learn), cudafy(x)).unsqueeze(0) )\n# visualize_filter(tmp , lambda x :x,ax=axes[2], title='diff')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}