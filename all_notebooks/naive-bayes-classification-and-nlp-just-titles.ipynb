{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport seaborn as sns # used to plot interactive graph.\nfrom sklearn.metrics import f1_score, confusion_matrix  # evaluate models\n\n# tokenize\nfrom nltk.tag import pos_tag\nfrom nltk.stem.wordnet import WordNetLemmatizer\nimport re, string\n\n# NLP\nimport nltk\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/question-classification-android-or-ios/test.csv')\ndf_train = pd.read_csv('/kaggle/input/question-classification-android-or-ios/train.csv')\ndf_valid = pd.read_csv('/kaggle/input/question-classification-android-or-ios/valid.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.shape)\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ***Very* Basic Data Viz**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_valid.shape)\ndf_valid.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_test.shape)\ndf_test.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.groupby(['LabelNum']).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Using NLTK to perform NLP** (on just the titles)"},{"metadata":{},"cell_type":"markdown","source":"### **Tokenize**"},{"metadata":{"trusted":true},"cell_type":"code","source":"nltk.download('punkt')                # this is a tokenizer\nnltk.download('wordnet')                    # lexical database (determine base word)\nnltk.download('averaged_perceptron_tagger'); # context of a word\nnltk.download('stopwords'); # stopwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndef remove_noise(tweet_tokens, stop_words = ()):\n\n    cleaned_tokens = []\n\n    for token, tag in pos_tag(tweet_tokens):\n        token = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\\\n                       '(?:%[0-9a-fA-F][0-9a-fA-F]))+','', token)\n        token = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", token) # remove tagging of users\n        token = re.sub(\"(<\\/?\\w*>)\", \"\", token) # remove html\n\n        if tag.startswith(\"NN\"):\n            pos = 'n'\n        elif tag.startswith('VB'):\n            pos = 'v'\n        else:\n            pos = 'a'\n\n        lemmatizer = WordNetLemmatizer()\n        token = lemmatizer.lemmatize(token, pos)\n\n        if len(token) > 0 and token not in string.punctuation and token.lower() not in stop_words:\n            cleaned_tokens.append(token.lower())\n    return cleaned_tokens","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# stopwords to be parsed into function `remove_noise` defined above \nfrom nltk.corpus import stopwords\nstop_words = stopwords.words('english')\n\nall_tokens = df_train.apply(lambda row: nltk.word_tokenize(row['Title']), axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_tokens = list()\nfor tokens in all_tokens:\n    cleaned_tokens.append(remove_noise(tokens, stop_words))\n    \ndf_train['cleaned_tokenized_titles'] = cleaned_tokens","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets look at our tokens"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.cleaned_tokenized_titles[df_train.LabelNum == 0]\n\ndef get_all_words(cleaned_tokens_list):\n    for tokens in cleaned_tokens_list:\n        for token in tokens:\n            yield token\n            \nfrom nltk import FreqDist\n\nfreq_dist_apple = FreqDist(get_all_words(df_train.cleaned_tokenized_titles[df_train.LabelNum == 1].values))\nfreq_dist_android = FreqDist(get_all_words(df_train.cleaned_tokenized_titles[df_train.LabelNum == 0].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_dist_apple.most_common(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_dist_android.most_common(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Naive Bayes Classification Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport random\n\ndef prep_tokens_for_model(cleaned_tokens_list):\n    for tokens in cleaned_tokens_list:\n        yield dict([token, True] for token in tokens)\n\n\n# NLTK requires the data in this format:\nandroid_data = [(title, 'Android') for title in prep_tokens_for_model(df_train.cleaned_tokenized_titles.values[df_train.LabelNum == 0])]\napple_data = [(title, 'Apple') for title in prep_tokens_for_model(df_train.cleaned_tokenized_titles[df_train.LabelNum == 1])]\n\nX_train = android_data + apple_data\nrandom.shuffle(X_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk import classify\nfrom nltk import NaiveBayesClassifier\n\nclf = NaiveBayesClassifier.train(X_train)\n\nprint(clf.show_most_informative_features(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testing = [i[0] for i in X_train] # removing y_test, the correct label\ny_test = [i[1] for i in X_train]  # saving y_test to evaluate the classifications\n\n# making predictions\ny_preds = list()\nfor test in testing:\n    y_preds.append(clf.classify(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"y_preds length\", len(y_preds))\nprint(y_preds[:2])\nprint(\"y_test length\", len(y_test))\nprint(y_test[:2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# evaluating by f1_score\n\nf1_score(y_test, y_preds, labels=['Android', 'Apple'], pos_label='Apple')\nconfusion_matrix(y_test, y_preds, labels=['Android', 'Apple'], normalize='true')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(\"Accuracy is: \", classify.accuracy(clf, X_train))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Evaluating Model on `test.csv`:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def prep_for_model(df):\n    \n    apple = df_test.Title[df_test.LabelNum == 1].copy()\n    android = df_test.Title[df_test.LabelNum == 0].copy()\n    \n    apple_tokens = [nltk.word_tokenize(app) for app in apple.values]\n    android_tokens = [nltk.word_tokenize(andr) for andr in android.values]\n    \n    apple_cleaned_tokens = list()\n    android_cleaned_tokens = list()\n    \n    for tokens in apple_tokens:\n        apple_cleaned_tokens.append(remove_noise(tokens, stop_words))\n        \n    for tokens in android_tokens:\n        android_cleaned_tokens.append(remove_noise(tokens, stop_words))\n    \n    apple_tokens_for_model = prep_tokens_for_model(apple_cleaned_tokens)\n    android_tokens_for_model = prep_tokens_for_model(android_cleaned_tokens)\n    \n    data_android = [(title, \"Android\")\n                         for title in android_tokens_for_model]\n\n    data_apple = [(title, \"Apple\")\n                         for title in apple_tokens_for_model]\n    \n    X = data_android + data_apple\n    \n    random.shuffle(X)\n    \n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = prep_for_model(df_test)\n\nX_test = [i[0] for i in X] # removing y_test, the correct label\ny_test = [i[1] for i in X]  # saving y_test to evaluate the classifications\n\n# making predictions\ny_preds = list()\nfor test in X_test:\n    y_preds.append(clf.classify(test))\n    \n\nprint(\"F1 score is: \", f1_score(y_test, y_preds, labels=['Android', 'Apple'], pos_label='Apple'))\nprint(confusion_matrix(y_test, y_preds, labels=['Android', 'Apple'], normalize='true'))\n\nprint(\"Accuracy is: \", classify.accuracy(clf, X))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}