{"cells":[{"metadata":{"_cell_guid":"e4cf7a3c-3ca4-4859-ac1f-c834ddc4f927","_uuid":"dbff6a6cfe68c7f582e31968f78d2efe3613c26b"},"cell_type":"markdown","source":"# Breast Cancer"},{"metadata":{"_cell_guid":"7b2dff74-8732-4e2f-82a5-f0621ab483e6","_uuid":"170e0561c702396111a6f5ddf2c450b9274dd5f1"},"cell_type":"markdown","source":"## A. Problem Understanding"},{"metadata":{"_cell_guid":"7a1cd875-c364-4d88-9b84-3d048c81c42d","_uuid":"02ef6f27048d28f437a955ee3c6b08a8a26a4da4"},"cell_type":"markdown","source":"Despite a great deal of public awareness and scientific research, breast cancer continues to be the most common cancer and the second largest cause of cancer deaths among women. Approximately 12% of U.S. women will be diagnosed with breast cancer, and 3.5% will die of it. The annual mortality rate of approximately 28 deaths per 100,000 women has remained nearly constant over the past 20 years. A breast cancer victim’s chances for long-term survival are improved by early detection of the disease, and early detection is in turn enhanced by an accurate diagnosis. After the diagnosis, for each patient with breast cancer, we classify the severity of cancers as malignant or benign in order to give them special treatments."},{"metadata":{"_cell_guid":"c07653db-6b97-4681-8ed4-5eadf0e5a3bf","_uuid":"c6e35862fee41fd8746c6c02468f9d6efd6a447a"},"cell_type":"markdown","source":"## B. Data Understanding"},{"metadata":{"_cell_guid":"8c3c7cb1-861f-4d71-b15c-30173380f401","_uuid":"d8b0af64788cb80b553ddf556a2ef54dce2795f6"},"cell_type":"markdown","source":"First, a sample of fluid is taken from the patient’s breast. This outpatient procedure involves using a small-\ngauge needle to take the fluid, known as a fine needle aspirate (FNA), directly from a breast lump or mass, the\nlump having been previously detected by self-examination and/or mammoaphy. The fluid from the FNA is placed\non a glass slide and stained to highlight the nuclei of the constituent cells. An image from the FNA is transferred\nto a workstation by a video camera mounted on a microscope.\n\nXcyt uses a curve-fitting program to determine the exact boundaries of the nuclei. The boundaries are initialized by an operator using a mouse pointer. For a typical image containing between 10 and 40 nuclei, the image analysis process takes approximately two to five minutes. Ten features are computed for each nucleus: area, radius, perimeter, symmetry, number and size of concavities, fractal dimension (of the boundary), compactness, smootimess (local variation of radial seg ments), and texture (variance of gray levels inside the boundary). The mean value, extreme value (i.e., largest or worst value: biggest size, most irregular shape) and standard error of each of these cellular features are com puted for each image, resulting in a total of 30 real-valued features."},{"metadata":{"_cell_guid":"68d7ba30-4f34-4478-a5b0-9d5516009f38","_uuid":"53c740d857d90f09102bdbe6bf97a82148ea9309"},"cell_type":"markdown","source":"#### 1. Data Description"},{"metadata":{"_cell_guid":"ff7630d6-ed0c-4a12-a4a4-645887c930bd","_uuid":"de73d232e9d41a62fad07274a25c8e0893012f15"},"cell_type":"markdown","source":"**data.csv**\n\n1. ID number\n2. Diagnosis (M = malignant, B = benign)\n3. Ten real-valued features are computed for each cell nucleus:\n\n\n- radius (mean of distances from center to points on the perimeter) \n- texture (standard deviation of gray-scale values) \n- perimeter \n- area \n- smoothness (local variation in radius lengths) \n- compactness (perimeter^2 / area - 1.0) \n- concavity (severity of concave portions of the contour) \n- concave points (number of concave portions of the contour) \n- symmetry \n- fractal dimension (\"coastline approximation\" - 1)\n\nNote: Mean, Etandard Error (SE) and Worst (mean of the three largest values) of these features are obtained from each image, resulting in 30 features. For example, the third column is Mean Radius, column 13 is Radius SE, column 23 is Worst Radius. All feature values are stored with four significant numbers."},{"metadata":{"_cell_guid":"61d32940-ee41-4510-8818-bc855ec2559b","_uuid":"a893bce4b14575ab3db810d4a9fcf2e964e84b59"},"cell_type":"markdown","source":"#### 2. Load The Data"},{"metadata":{"_cell_guid":"802a8435-47b8-4700-a28d-25d42617e897","_uuid":"79fe0eb710b2858059013a60945fd5f362307585","trusted":true},"cell_type":"code","source":"#import library\nimport pandas as pd\nimport pandas_profiling\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set_style('whitegrid')\n#import data\ndata = pd.read_csv('../input/breast-cancer.csv')","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"d7501cdc-91c6-43ff-945b-ee5095abc8eb","_uuid":"f53e5dddec52f9405e609ba3ace360cae0fa5697","trusted":true},"cell_type":"code","source":"data","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"53bf9a8b-a958-4add-b848-fa05183e7aae","_uuid":"743ead0690221338d06c5baf81d20e40c5fdf88d","trusted":true},"cell_type":"code","source":"#Check the null data\ndata.isnull().sum()","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"47d003b9-148a-4f69-8aac-69d3456d88c6","_uuid":"09b63879dcef87adc3716f970b35c53ded3f56c9"},"cell_type":"markdown","source":"#### 3. Data Types"},{"metadata":{"_cell_guid":"2f140025-1617-427f-bb3d-dfc4cff76f4f","_uuid":"03992fe483fef873490259571086410c063f6c0f","trusted":false,"collapsed":true},"cell_type":"code","source":"#Check data types and memory usage\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0a386d0e-9dd9-4b56-afba-6807ef8feb9c","_uuid":"c87c05ba47efdc200f2a29e24c5a4e9759366ece"},"cell_type":"markdown","source":"# C. Data Exploration"},{"metadata":{"_cell_guid":"24991815-2cff-4bf1-b041-b21be0dd7618","_uuid":"e4998d9898b60a091762a52a5a0eccf688879851"},"cell_type":"markdown","source":"On the data exploration, we will see the distribution of each variable using a histogram. In the histogram, the horizontal axis is the data of the feature while the vertical axis is the frequency of occurrence. The correlation test is used to evaluate the relationship between two numerical variables. If two variables have a correlation coefficient, then the two variables are numerical variables, while the remainder are categorical variables."},{"metadata":{"_cell_guid":"120ebc26-3dcd-4b6e-bfbe-efa801925f6c","_uuid":"3b449a9b70aae1ab37d2306ac59fb2de714c564e"},"cell_type":"markdown","source":"Before go to correlation test, we need to change the target of classification in the column of diagnosis to be numerical. So, we can also include the target to the correlation test, because the correlation test can process only numerical data. It is also important to binarized our target because it is need to convert to 0 and 1 to calculate F1 score of our model evaluation."},{"metadata":{"collapsed":true,"_cell_guid":"780a5ed7-76fc-4b7c-9755-e18434df4286","_uuid":"8c0c5adefeca9bd5565251c7f7c3ae6bcb24431a","trusted":false},"cell_type":"code","source":"# Change diagnosis to numerical data M --> 1; B--> 0\nfrom sklearn import preprocessing\nlb = preprocessing.LabelBinarizer()\ndata['diagnosis'] = lb.fit_transform(data['diagnosis'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7e62bf3c-8fff-4208-a6fc-2c86d60f905b","_uuid":"0351d94471df10f71661439500d8f6848274dc23"},"cell_type":"markdown","source":"We also consider to remove unnecessary data that is clearly not required. For example, the patient ID and other blank features. This is helpful to speed up our correlation test."},{"metadata":{"collapsed":true,"_cell_guid":"1e65a00f-8aaf-4a5b-92fc-288b67ff154e","_uuid":"7450c5b9777ae361ba64d4b7ca1d9ebb62d06986","trusted":false},"cell_type":"code","source":"# Delete unnecessary features\ndel data['Unnamed: 32']\ndel data['id']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"63417f46-9b0d-4099-af8f-591917e2e7d1","_uuid":"e4bc1839701bbf781e6ec4d455575715d7545da7","trusted":false,"collapsed":true},"cell_type":"code","source":"# Check data shape after removal\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"81524017-e9cf-4b30-bd70-ec53b616e9ca","_uuid":"21879e4b29315a67e8e12d11da4ff8daa481443b"},"cell_type":"markdown","source":"There are 31 features now (including the target)"},{"metadata":{"_cell_guid":"d0397798-4cb7-4105-8f5e-62b33c91cc9c","_uuid":"b6418e80075895e9bc7135c3db790cfaa75b6d8f"},"cell_type":"markdown","source":"Next, let's explore all variables using Pandas Proiling Report. From the histograms, below we can see the distributions are normal."},{"metadata":{"scrolled":false,"_cell_guid":"95e02004-c25a-42ae-88ed-b2df838f2784","_uuid":"8b862fb36e26991ede6eb1767118bf5a45ded23c","trusted":false,"collapsed":true},"cell_type":"code","source":"pandas_profiling.ProfileReport(data)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d2f5c634-cf7a-47ce-b12d-48b7faf23f38","_uuid":"104f8b1c987eb483a90ea0e2f4f9d64a83ed3a7e"},"cell_type":"markdown","source":"# D. Data Preprocessing"},{"metadata":{"_cell_guid":"3f937915-653a-4bf4-b2bf-2f66af318bc6","_uuid":"7fb94b5404960ce0be5f5cf4a9147513ccb842d0"},"cell_type":"markdown","source":"#### 1. Data Selection"},{"metadata":{"_cell_guid":"c65cc466-9c72-4473-8b54-3600532a1d0b","_uuid":"37ee52a9b2cd2867f39c9b058bc615a2ae141d1f"},"cell_type":"markdown","source":"Now, we need to select the data based on the question that we want to address, which is classification of the cancer. Even though, the available data are seems to be relevant, we need to conduct the correlation test to make sure we used the features that are must be included. The available data can includes independent variables and dependent variables. What we need is to ensure the inputs include all independent varibales, and each feature doesn't make a high correlation with the target or with other input(s), we can identify them by evaluating through correlation test. If the data are highly correlated, we then exlude it.\n\nFrom the Pandas Profiling, thare are 14 warnings, 4 are due to zero values. In this case, because the data are obtained using real image, we assume zero values are possible and not human error, so we can't exclude that.\n\nFrom the above warning, we can see that there are 10 warning regarding the correlation of the features, we can group them as 2 groups of correlation test\n\n**Group 1 (Features in Radius, Perimeter, and Area)**\n\nTake a look at the pandas profile report\n* area_mean is highly correlated with perimeter_mean (ρ = 0.98651) Rejected\n* area_se is highly correlated with perimeter_se (ρ = 0.93766) Rejected\n* area_worst is highly correlated with perimeter_worst (ρ = 0.97758) Rejected\n* perimeter_mean is highly correlated with radius_mean (ρ = 0.99786) Rejected\n* perimeter_se is highly correlated with radius_se (ρ = 0.97279) Rejected\n* perimeter_worst is highly correlated with radius_worst (ρ = 0.99371) Rejected\n* radius_worst is highly correlated with area_mean (ρ = 0.96275) Rejected\n"},{"metadata":{"_cell_guid":"b43a70e4-f75c-40e3-a3d1-705e60997483","_uuid":"14ff31e69dffea9dec5cd438063510927fa9743c","trusted":false,"collapsed":true},"cell_type":"code","source":"# Correlation test of group 1\ngroup_1 = data.loc[:, [\"radius_mean\", \"perimeter_mean\",\"area_mean\",\"radius_se\",\"perimeter_se\", \"area_se\",\n\"radius_worst\",\"perimeter_worst\", \"area_worst\"]].copy()\nsns.heatmap(group_1.corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"03f7d06c-6464-4863-b104-5dfd8c61fc40","_uuid":"5e8e48ae726e84dc8cd178c9c7217454d3fe25db"},"cell_type":"markdown","source":"First, we will choose one out of three variables that are higly correlated\n* From \"radius_mean\", \"perimeter_mean\", and \"area_mean\", we choose \"radius_mean\"\n* From \"radius_se\",\"perimeter_se\", and  \"area_se\", we choose \"radius_se\"\n* From \"radius_worst\",\"perimeter_worst\", and  \"area_worst\", we choose \"radius_worst\"\n\nSecond, due to the high correlation of the radius features (\"radius_mean\" and \"radius_worst\"), we need to choose one, let's take the \"radius_mean\"\n\nAt this step, we keep 2 variables **\"radius_mean\"** and **\"radius_se\"** and will exclude 7 other variables in group_1 (\"perimeter_mean\",\"area_mean\",\"perimeter_se\", \"area_se\",\n\"radius_worst\",\"perimeter_worst\", \"area_worst\")"},{"metadata":{"_cell_guid":"a5f403d7-5cde-4222-a3fc-239daee93152","_uuid":"48653d262d2fb30e6ad63ab65a4b49c453fda22f"},"cell_type":"markdown","source":"**Group 2 (Features in concave points, texture, and concavity)**\n\n Look at the pandas profile report, we can witness\n* concave points_mean is highly correlated with concavity_mean (ρ = 0.92139) Rejected\n* concave points_worst is highly correlated with concave points_mean (ρ = 0.91016) Rejected\n* texture_worst is highly correlated with texture_mean (ρ = 0.91204) Rejected"},{"metadata":{"_cell_guid":"f788a449-5c73-478a-a531-2948cce744b2","_uuid":"f2b933921250079f28d9949fbbf6078000970ecb","trusted":false,"collapsed":true},"cell_type":"code","source":"# Correlation test of group 1\ngroup_2 = data.loc[:, [\"concave points_mean\", \"concavity_mean\",\"texture_mean\",\"concave points_se\",\"concavity_se\", \"texture_se\",\n\"concave points_worst\",\"concavity_worst\", \"texture_worst\"]].copy()\nsns.heatmap(group_2.corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f3e65510-ff14-4454-80da-eac39108aae2","_uuid":"8a976859a0d62d31bcaa25d2e5705524a0e91a59"},"cell_type":"markdown","source":"As on the previous test, we need to keep some features and remove the other features that are unnecessary.\n* From \"concave points_mean\", \"concavity_mean\", and \"concave points_worst\", we choose \"concave points_mean\"\n* From \"texture_mean\", and  \"texture_worse\", we choose \"texture_mean\"\n\nAt this step, we keep variables **\"concave points_mean\"** and **\"texture_mean\"** and will exclude 3 other variables in group_2 (\"concavity_mean\", \"concave points_worst\", and \"texture_worse\")"},{"metadata":{"_cell_guid":"20d6684b-075f-4020-a293-8aa32053a69b","_uuid":"393e67e3e8c664611994bede2613886354c93e0a"},"cell_type":"markdown","source":"#### 2. Preprocess Data"},{"metadata":{"_cell_guid":"55511ec8-109d-46f5-828e-a156ab41655e","_uuid":"db5fb6a30664236543d22c507a831ae612ae10e7"},"cell_type":"markdown","source":"After we know what features to be excluded, let's make the sample data for analysis or the data that we want to work with."},{"metadata":{"collapsed":true,"_cell_guid":"1889a45a-1560-4f08-9bd2-6658e93d86ba","_uuid":"e6ac6ef5039d7943ee23f489370bed2db6fbb1ea","trusted":false},"cell_type":"code","source":"data = data.drop(['perimeter_mean','area_mean','perimeter_se','area_se','radius_worst','perimeter_worst', 'area_worst',\n                 'concavity_mean','concave points_worst','texture_worst'],1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"35a7d3aa-f7ba-42df-af82-c8da6f22cf6b","_uuid":"e4ceb9c6fab542163ab76a805388d6f1b46b8cba","trusted":false,"collapsed":true},"cell_type":"code","source":"# See the correlation again after removing unwanted features\ndata.corr()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"00a80db0-77e9-4af2-9c7d-780a0ee269dc","_uuid":"48d4b498e8ea2008d8e2894728cce4f35754dfb7","trusted":false,"collapsed":true},"cell_type":"code","source":"#Check the current features\ndata.columns","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c1f28483-087a-4d94-8c89-22730be78529","_uuid":"16d8b262a6672f3eb9c23b12e173c97d1ea4ec6e"},"cell_type":"markdown","source":"#### 3. Data Transformation"},{"metadata":{"_cell_guid":"59667702-ffa6-4aff-9083-45c78c87ddcf","_uuid":"c1c58287de0fdc637cd74017f52b67bc820f2e21"},"cell_type":"markdown","source":"We need to check the boundaries (minimum and maximum values) of each features."},{"metadata":{"_cell_guid":"289954a4-f8b4-4b34-ab83-7befc1017a28","_uuid":"3b7d2988048104dd01c3800512996345fa4a7a29","trusted":false,"collapsed":true},"cell_type":"code","source":"# Check summary statistics\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"959880c4-1d9b-40f3-a729-0e414bbdfd56","_uuid":"99e58cedc18bab27d96131b6687b8b6c871c06f2"},"cell_type":"markdown","source":"It is better to scale the numeric data because every feature has different scale."},{"metadata":{"collapsed":true,"_cell_guid":"2c7704c7-596c-449f-bd2c-4f6b550c6418","_uuid":"0d4f2f23b98de1e1a03c8e10c87cbb88669234d4","trusted":false},"cell_type":"code","source":"# Data transformation using Standard Scaler\nfrom sklearn.preprocessing import StandardScaler\nnumeric_data = data.iloc[:,1:22]\nsc = StandardScaler()\ninput = pd.DataFrame(sc.fit_transform(numeric_data))\ninput.columns = ['radius_mean', 'texture_mean', 'smoothness_mean',\n       'compactness_mean', 'concave points_mean', 'symmetry_mean',\n       'fractal_dimension_mean', 'radius_se', 'texture_se', 'smoothness_se',\n       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n       'fractal_dimension_se', 'smoothness_worst', 'compactness_worst',\n       'concavity_worst', 'symmetry_worst', 'fractal_dimension_worst']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a541ec88-db5f-4968-a27c-447aab5915fc","_uuid":"25eca0aa7457357a984c2983e88b655483e37893","trusted":false,"collapsed":true},"cell_type":"code","source":"# Preview the result of transformation\ninput","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5f3a212c-9ad0-4d83-a489-f2927a85108e","_uuid":"cfa7cc1a4ca5eba812865b29e1a5d59d40614529"},"cell_type":"markdown","source":"# E. Data Modelling"},{"metadata":{"_cell_guid":"007df145-985f-4c30-911d-04918edf1d86","_uuid":"2329e0dc12a807cdb09f35132ce9d2d2feb6f824"},"cell_type":"markdown","source":"Let's prapare our input and output using tran test split before we create models."},{"metadata":{"collapsed":true,"_cell_guid":"35116d9b-3d14-44c8-9eba-ac5fcf278667","_uuid":"0c42ee47459ebe0455309b3896d539f5788702ee","trusted":false},"cell_type":"code","source":"# Train test split\nfrom sklearn.model_selection import train_test_split\nX = input\ny = data['diagnosis']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5dfa76f6-d970-4917-b340-a21a111248a4","_uuid":"51c67019b878be462b376ef4f9e5870450b29f16"},"cell_type":"markdown","source":"We create 3 basic models and then optimze each models using Hyperparameter Search technique. The model we used are:\n1. Random Forest\n2. K Nearest Neighbours\n3. Support Vector Machine (SVM)"},{"metadata":{"_cell_guid":"95e463c9-864a-48a5-b0ee-552720cc2700","_uuid":"eaeb7a17af86ebedc669c27a4bc9707dd19d21a4"},"cell_type":"markdown","source":"#### 1. Random Forest"},{"metadata":{"collapsed":true,"_cell_guid":"0aa649e0-939f-486c-904e-e92076b3a418","_uuid":"efc22cf4826da5e38069e959abdc6fdbe2f9ec25","trusted":false},"cell_type":"code","source":"#Import random forest calassifier\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"d6239bbb-4294-4c0c-a7d8-42982aadb33a","_uuid":"72a702647dda19773bf4dd31ae39d2f440ce3c85","trusted":false},"cell_type":"code","source":"# Create random forest model \nrf_model = RandomForestClassifier(random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c7c26ae6-fac0-484d-9e90-acde39452a19","_uuid":"c010a105e55e533762f473630ee93fa0f65f7d34","trusted":false,"collapsed":true},"cell_type":"code","source":"# Apply the model\nrf_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"ac05e505-eec8-4eca-9bf9-8608e8813006","_uuid":"86f01021d14c2189cbaee8f188538b71a889658d","trusted":false},"cell_type":"code","source":"# Predicted value\ny_pred1 = rf_model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"81e409e0-79ec-40f6-ae61-a85da9bb8524","_uuid":"5c2c7856710a874c1410401446adfa6a018b5a7a","trusted":false},"cell_type":"code","source":"#Create model evaluation function\ndef evaluate(model, test_features, test_labels):\n    from sklearn.metrics import f1_score\n    predictions = model.predict(test_features)\n    F1 = np.mean(f1_score(test_labels, predictions))\n    print('Model Performance')\n    print('F1 score = %.3f' % F1)\n    \n    return f1_score","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4daf0f5c-913f-4302-a279-e61e8f4fb860","_uuid":"d6ea5ccbe73c4ad22e426baf35ef49cac401b5cb","trusted":false,"collapsed":true},"cell_type":"code","source":"#f1 score before optimization\nf1_before_rf= evaluate(rf_model, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3ad18400-714d-411b-b2b8-6715d15a5b53","_uuid":"03cfab0c9ec7a55d82751419097d06aa5dc898cc","trusted":false,"collapsed":true},"cell_type":"code","source":"#confusion matrix before optimization\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test, y_pred1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"93ea12c4-542e-4b7b-b78f-7e094d8712ea","_uuid":"aabc3434dd01e1754b96e43c00cc2725f50217f0","trusted":false,"collapsed":true},"cell_type":"code","source":"# Random forest optimization parameters\nfrom sklearn.model_selection import RandomizedSearchCV\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 778, stop = 784, num = 7)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt',5,6,7,8]\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(start = 8, stop = 14, num = 7)]\n# Minimum number of samples required to split a node\nmin_samples_split = [int(x) for x in np.linspace(start = 10, stop = 14, num = 5)]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [int(x) for x in np.linspace(start = 1, stop = 6, num = 5)]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Method of selecting xriterion\ncriterion = ['gini', 'entropy']\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap,\n               'criterion':criterion}\nprint(random_grid)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"9a911b5f-cead-405b-8739-9106b7dda44f","_uuid":"6eaa9c62ebc3698fb46b728d94e198735cb7d494","trusted":false},"cell_type":"code","source":"#Create new model using the parameters\nrf_random = RandomizedSearchCV(estimator = rf_model, param_distributions = random_grid, n_iter = 15,\n                               cv = 5, verbose=2, random_state=0, n_jobs = -1)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"_cell_guid":"16d99bd2-6ab7-43a7-b097-9199c51de3d9","_uuid":"6ee1aa895bc727242ea9293aa49a77a48d6d1127","trusted":false,"collapsed":true},"cell_type":"code","source":"#Apply the model\nrf_random.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c5165254-ba09-4d9b-bfe3-628d361c36bb","_uuid":"6b8f55450e9badf1bb3ab889aff35913bb0dbcf3","trusted":false,"collapsed":true},"cell_type":"code","source":"#View the best parameters\nrf_random.best_params_","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"1439115c-1ca9-4dc6-b6d1-41ccc9064eeb","_uuid":"14e85e47fd2f8fab46d60b5544b1fcb2b4427a46","trusted":false},"cell_type":"code","source":"# Predicted value\ny_pred1_ = rf_random.best_estimator_.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3272fcd1-7e8c-4ad8-b0cd-ea884dbf0d0c","_uuid":"9e03360230540c59514605a48db84b71779a00e5","trusted":false,"collapsed":true},"cell_type":"code","source":"#f1 score after optimization\nbest_random = rf_random.best_estimator_\nf1_after_rf= evaluate(best_random, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5b90b398-1794-43a4-9d55-231a3e2c2418","_uuid":"d0aafe017aacb818359b775277731af5667a56ae","trusted":false,"collapsed":true},"cell_type":"code","source":"#confusion matrix after optimization\nconfusion_matrix(y_test, y_pred1_)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4c6b0d2e-ff4e-4d73-b722-d5790e6dd25a","_uuid":"da1b91a9fbec27a1dfed52dff9df1ac0f8f3fb5c"},"cell_type":"markdown","source":"#### 2. KNN"},{"metadata":{"collapsed":true,"_cell_guid":"8997ddd0-9d0b-4c07-b103-5de19453eb7c","_uuid":"90a085c0016438d5efa8fb0eba6d9d2b381c6f44","trusted":false},"cell_type":"code","source":"#Import KNN calassifier\nfrom sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"1ac94e38-12b2-447e-b491-a45bb4554b7d","_uuid":"039adcc388429fc7b230b4ca378b82fffde4a2b8","trusted":false},"cell_type":"code","source":"# Create KNN model\nkn_model = KNeighborsClassifier(n_neighbors=5)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e2ba90be-e161-4d39-a6f6-39fbe89d0734","_uuid":"041696de1089fddfe2a0a7e94e7af40ea48da074","trusted":false,"collapsed":true},"cell_type":"code","source":"# Apply the model\nkn_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"01a2ceb9-9717-4d24-a791-202157d49886","_uuid":"41ec975f5cbd01c021884f16c4c079842966932b","trusted":false},"cell_type":"code","source":"# Predicted value\ny_pred2 = kn_model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"01d14ccf-1e44-44cd-93c7-f380837f6b63","_uuid":"de8a558ece72bb59b780f8148265f588749e9740","trusted":false,"collapsed":true},"cell_type":"code","source":"#f1 score before optimization\nf1_before_kn= evaluate(kn_model, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e1f452a0-3b86-421c-957a-295469f2987a","_uuid":"bdd961584bb6b2280e70b541d0def72d081cbbf6","trusted":false,"collapsed":true},"cell_type":"code","source":"#confusion matrix before optimization\nconfusion_matrix(y_test, y_pred2)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c778bcf7-de65-4b5a-86de-e4319cdb00df","_uuid":"33de75ebf3c4976aa11e1fceee7c8175fa34aaff","trusted":false,"collapsed":true},"cell_type":"code","source":"# KNN optimization parameters\nn_neighbors = [5,6,7,8,9,10]\nleaf_size = [1,2,3,5]\nweights = ['uniform', 'distance']\nalgorithm = ['auto', 'ball_tree','kd_tree','brute']\n\nrandom_grid_kn = {'n_neighbors':n_neighbors,\n                  'leaf_size':leaf_size,\n                  'weights':weights,\n                  'algorithm':algorithm}\nprint(random_grid_kn)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"2969dd72-cd57-4ae1-9db6-52131e9e492c","_uuid":"145a5605adf7cc11e3b415a9eecd968aa5465436","trusted":false},"cell_type":"code","source":"#Create new model using the parameters\nkn_random = RandomizedSearchCV(estimator = kn_model, param_distributions = random_grid_kn, n_iter = 15,\n                           cv = 5, verbose=2, random_state=123, n_jobs = -1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"39f0bc02-c6b2-4168-94c4-5432ce7e3771","_uuid":"53cb50f49534887dfa2e2fa6c7636e92b4aeda6a","trusted":false,"collapsed":true},"cell_type":"code","source":"#Apply the model\nkn_random.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e7b79a6a-3466-42f5-b43b-f08631bed43c","_uuid":"34d3ce8384fc0bf2fc83b9722128dd240d2cb111","trusted":false,"collapsed":true},"cell_type":"code","source":"#View the best parameters\nkn_random.best_params_","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"546c1bda-1746-40ac-866e-aae0840b5d15","_uuid":"db992af13320e53daaaceaefadbfac526e94a128","trusted":false},"cell_type":"code","source":"# Predicted value\ny_pred2_ = kn_random.best_estimator_.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"44933fdd-42b6-4524-9658-42e0760ceb94","_uuid":"9cea7c0db4dca5494074b5c6dad4518a0509c959","trusted":false,"collapsed":true},"cell_type":"code","source":"#f1 score after optimization\nbest_random_kn = kn_random.best_estimator_\nf1_after_kn= evaluate(best_random_kn, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0d5d80e1-1ac2-4c63-bc20-f11ab549a897","_uuid":"148d4fd28b6174070ce91909d278db078db43ace","trusted":false,"collapsed":true},"cell_type":"code","source":"#confusion matrix after optimization\nconfusion_matrix(y_test, y_pred2_)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"47100f9d-2924-414b-ae2d-6f9f4f1a3b04","_uuid":"f0836c6a592a3eb586746242e9743ffbe7c10e45"},"cell_type":"markdown","source":"#### 3. SVM"},{"metadata":{"collapsed":true,"_cell_guid":"91715e3c-fff6-45c1-a686-3ef88a9b86bd","_uuid":"967a1610eae249c3d0db9ddeec30263c24b44506","trusted":false},"cell_type":"code","source":"#Import SVM calassifier\nfrom sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"ebbd719b-cf06-4efd-8d55-cf2be182bdf5","_uuid":"ea99e1cd21bb261874eaf6ef73757788664ba129","trusted":false},"cell_type":"code","source":"# Create SVM model\nsvc_model = SVC(random_state=123)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"dfbc2304-154c-4df8-8d02-8431694863f0","_uuid":"f7e4577af0c82a9f9a57edac2cc8ff66d56a8e20","trusted":false,"collapsed":true},"cell_type":"code","source":"# Apply the model\nsvc_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"35368d3a-884f-4b57-9811-2380d5a5bca4","_uuid":"e42dc4c67de8d5402e5b7a1fd725ec75872d1daa","trusted":false},"cell_type":"code","source":"# Predicted value\ny_pred3 = svc_model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e0ee9c62-e137-4068-887a-d93a40e0d02b","_uuid":"5fd0af08f91060adb49b751f4faf0d3182bfebdb","trusted":false,"collapsed":true},"cell_type":"code","source":"#f1 score before optimization\nf1_before_svc= evaluate(svc_model, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"94b05018-3c8a-4fa0-986d-8433ae892892","_uuid":"d92f898faa70350f5e6e9f2bbcb74430175c3e6c","trusted":false,"collapsed":true},"cell_type":"code","source":"#confusion matrix score optimization\nconfusion_matrix(y_test, y_pred3)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5a723dfb-913a-4cee-86b6-af8ea307f37d","_uuid":"59fe3cdc5e7d83c399ecf90ffc4025133b7a7a45","trusted":false,"collapsed":true},"cell_type":"code","source":"# SVM optimization parameters\nC= [0.123,0.124, 0.125, 0.126, 0.127]\nkernel = ['linear','rbf','poly']\ngamma = [0, 0.0000000000001, 0.000000000001, 0.00000000001]\n\nrandom_grid_svm = {'C': C,\n                   'kernel': kernel,\n                   'gamma': gamma}\nprint(random_grid_svm)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"57444b8c-7718-45a1-b296-7df2173faa52","_uuid":"02c1395d9d51b5b3c7aab7dcee7e6941f363d644","trusted":false},"cell_type":"code","source":"#Create new model using the parameters\nsvc_random = RandomizedSearchCV(estimator = svc_model, param_distributions = random_grid_svm, n_iter = 15,\n                           cv = 5, verbose=2, random_state=123, n_jobs = -1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3b9c8416-7068-438f-9c56-b1b4ebb2c9b2","_uuid":"9fd4fd5ed7855c3f5d666523f84232f618cd870f","trusted":false,"collapsed":true},"cell_type":"code","source":"#Apply the model\nsvc_random.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7557065b-9293-4739-bd14-f200473fe6e5","_uuid":"feb721b3995cd747089e095264bc25f1f6f4e8c9","trusted":false,"collapsed":true},"cell_type":"code","source":"#View the best parameters\nsvc_random.best_params_","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"c4b5fa11-50ef-44de-bfb2-b312e70f82a4","_uuid":"506f751d7267b02b9c0d3525aa7e3cccccb2e49c","trusted":false},"cell_type":"code","source":"# Predicted value\ny_pred3_ = svc_random.best_estimator_.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"78e7a847-1caf-4b01-a048-deed2cb00c84","_uuid":"6ba318568233b2f78e6ea9d2958265a6398bb059","trusted":false,"collapsed":true},"cell_type":"code","source":"#f1 score after optimization\nbest_random_svc = svc_random.best_estimator_\nf1_after_svc= evaluate(best_random_svc, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"56ebb349-bc23-4748-b073-b6a45b64a0bb","_uuid":"45f3babe04c98f40388ebf6fe2d15d3dbde7af9a","trusted":false,"collapsed":true},"cell_type":"code","source":"#confusion matrix after optimization\nconfusion_matrix(y_test, y_pred3_)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"036ec8f3-062a-4d01-a5da-9f6455ca2238","_uuid":"f9040b98e38f6ba2b3bc676697e8837235bd1a41"},"cell_type":"markdown","source":"For the above confusion matrix, we can see that the false positive = 0 and the false negative = 1.\nLet me remind you what does it mean.\n* False positives (FP): We predicted yes, but they don't actually have the malignant cancer.\n* False negatives (FN): We predicted no, but they actually do have the malignant cancer.\n\nFP is the most important indicator. To illustrate, if there is a value in FP, it means that the patient with benign cancer predicted as malignant cancer. It is very dangerous, because the patient will have the serious treatment, consume a high-dose drug category, or have a serious surgery that is actually not appropriate for such patient. If the cancer is identified as malignant, there is a sort amount of time or even no time to re-evaluate the patient, and the wrong treatment will be taken by the doctor and make the patient in danger.\n\nIn contrast, a value in FN is the number of malignant patient, who are predicted as benign. There is a time to re-assess the patient in order to provide better treatment. Clearly, this not severe as the opposite situation.\n\nBecause the FP is zero and NP is very small (1). The predictive model using SVM does very well."},{"metadata":{"collapsed":true,"_cell_guid":"2a3b10c5-6999-49cc-bc01-a5f41ed42f34","_uuid":"c15758aefc0bae2b4fb7413bc25565fe9a3f2ba1"},"cell_type":"markdown","source":"# F. Evaluation"},{"metadata":{"_cell_guid":"10cea308-9ae5-406f-bbdf-8df76c5b829c","_uuid":"823785e1f9952fb8774c089e9e0bbccd64656ea9"},"cell_type":"markdown","source":"Overall, the model perform well to predict the class of cancer with F1 score > 94% even not using hyperparameter optimization\n\n* F1 score of **Random Forest** model = 94.7%\n* F1 score of **KNN** model = 97.0%\n* F1 score of **SVM** model = 99.3%\n\nTo increase the F1 score, we have applied hyperparameter tuning using RandomizedSearch and obtain\n* F1 score of **Optmized Random Forest** model = 94.9%\n* F1 score of **Optmized KNN** model = 97.7%\n* F1 score of **Optmized SVM** model = 99.3%\n\nWe can conclude that SVM is the best model to classify the breast cancer with the optimum F1 score of 99.3%"},{"metadata":{"collapsed":true,"_cell_guid":"554ad323-0d10-487a-9d70-50a2e4362fcc","_uuid":"f74d559a628e3406eca840452d829ac938283481","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}