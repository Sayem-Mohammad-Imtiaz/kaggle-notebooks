{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#message = [line.rstrip() for line in open('../input/SMSSpamCollection')]\nmessage = [line.rstrip() for line in open('../input/smsspamcollection/SMSSpamCollection')]\nprint(len(message))\nfor message_no,message in enumerate(message[:10]):\n    print(message_no,message)\n    print('\\n')\nimport pandas as pd\nmessage=pd.read_csv('../input/smsspamcollection/SMSSpamCollection',sep='\\t',names=[\"labels\",\"message\"])\nmessage.head()\nmessage.describe()\nmessage.groupby('labels').describe()\nmessage['length']=message['message'].apply(len)\nmessage.head()\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nmessage['length'].plot(bins=50,kind='hist')\nmessage.length.describe()\nWoah! 910 characters, let's use masking to find this message:\n\nmessage[message['length']==910]['message'].iloc[0]\nimport string\nmess = 'my sample message!...'\nnopunc=[char for char in mess if char not in string.punctuation]\nnopunc=''.join(nopunc)\nprint(nopunc)\nfrom nltk.corpus import stopwords\nstopwords.words('english')[0:10]\nnopunc.split()\nclean_mess=[word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\nclean_mess\ndef text_process(mess):\n    nopunc =[char for char in mess if char not in string.punctuation]\n    nopunc=''.join(nopunc)\n    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\nmessage.head()\nmessage['message'].head(5).apply(text_process)\nmessage.head()\nfrom sklearn.feature_extraction.text import CountVectorizer\nbow_transformer = CountVectorizer(analyzer=text_process).fit(message['message'])\nprint(len(bow_transformer.vocabulary_))\nmessage4=message['message'][3]\nprint(message4)\nbow4=bow_transformer.transform([message4])\nprint(bow4)\nprint(bow4.shape)\nprint(bow_transformer.get_feature_names()[4068])\nprint(bow_transformer.get_feature_names()[9554])\nmessages_bow = bow_transformer.transform(message['message'])\nprint('Shape of Sparse Matrix: ',messages_bow.shape)\nprint('Amount of non-zero occurences:',messages_bow.nnz)\nfrom PIL import Image\nsparsity =(100.0 * messages_bow.nnz/(messages_bow.shape[0]*messages_bow.shape[1]))\nprint('sparsity:{}'.format(round(sparsity)))\nimg_array = np.array(Image.open('../input/explanation/Capture.JPG'))\nplt.figure(figsize=(16,10))\nplt.imshow(img_array)\nfrom sklearn.feature_extraction.text import TfidfTransformer\ntfidf_transformer=TfidfTransformer().fit(messages_bow)\ntfidf4 = tfidf_transformer.transform(bow4)\nprint(tfidf4)\nprint(tfidf_transformer.idf_[bow_transformer.vocabulary_['u']])\nprint(tfidf_transformer.idf_[bow_transformer.vocabulary_['university']])\nmessages_tfidf=tfidf_transformer.transform(messages_bow)\nprint(messages_tfidf.shape)\n\nfrom sklearn.naive_bayes import MultinomialNB\nspam_detect_model = MultinomialNB().fit(messages_tfidf,message['labels'])\nprint('predicted:',spam_detect_model.predict(tfidf4)[0])\nprint('expected:',message.labels[3])\nall_predictions = spam_detect_model.predict(messages_tfidf)\nprint(all_predictions)\nfrom sklearn.metrics import classification_report,confusion_matrix\nprint(classification_report(message['labels'],all_predictions))\nprint(confusion_matrix(message['labels'],all_predictions))\nfrom sklearn.model_selection import train_test_split\nmsg_train,msg_test,label_train,label_test = train_test_split(message['message'],message['labels'],test_size=0.2)\nprint(len(msg_train),len(msg_test),len(label_train),len(label_test))\nfrom sklearn.pipeline import Pipeline\npipeline = Pipeline([\n   ( 'bow',CountVectorizer(analyzer=text_process)),\n    ('tfidf',TfidfTransformer()),\n    ('classifier',MultinomialNB()),\n])\npipeline.fit(msg_train,label_train)\npredictions = pipeline.predict(msg_test)\nprint(classification_report(predictions,label_test))\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}