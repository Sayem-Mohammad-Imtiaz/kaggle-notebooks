{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Time series\n\nA time series is simply a series of data points ordered in time. As continuous monitoring and data collection become more common, the need for competent time series analysis with both statistical and machine learning techniques will increase.\n\nNow, datasets where only one variable is observed at each time is called ‘Univariate Time Series’ and if two or more variables are observed at each time is called ‘Multivariate Time Series’.\n\nIn this notebook, we will focus on the univariate time series for forecasting the sales with Facebook Prophet and Auto ARIMA functionality in python","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# load libraries \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pandas_profiling\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import show\nimport plotly.express as px\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load and combine the data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# combine and create single dataframe\nchicago_df_1 = pd.read_csv('/kaggle/input/crimes-in-chicago/Chicago_Crimes_2001_to_2004.csv', error_bad_lines=False)\nchicago_df_2 = pd.read_csv('/kaggle/input/crimes-in-chicago/Chicago_Crimes_2005_to_2007.csv', error_bad_lines=False)\nchicago_df_3 = pd.read_csv('/kaggle/input/crimes-in-chicago/Chicago_Crimes_2008_to_2011.csv', error_bad_lines=False)\nchicago_df_4 = pd.read_csv('/kaggle/input/crimes-in-chicago/Chicago_Crimes_2012_to_2017.csv', error_bad_lines=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# combining the datasets\ndf = pd.concat([chicago_df_1,chicago_df_2,chicago_df_3,chicago_df_4],ignore_index=False,axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exploring the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's view the head of the training dataset\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# select only the necessary columns\ndf = df[['ID','Date','Primary Type','Location Description','Arrest','Domestic']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change the column date dtype from object to date\ndf.Date = pd.to_datetime(df.Date, format='%m/%d/%Y %I:%M:%S %p')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# setting the index to be the date \ndf.index = pd.DatetimeIndex(df.Date)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# verify the change\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the summary\nprint (\"Rows     : \" ,df.shape[0])\nprint (\"Columns  : \" ,df.shape[1])\nprint (\"\\nFeatures : \\n\\n\" ,df.columns.tolist())\nprint (\"\\nMissing values : \\n\\n\", df.isnull().any())\nprint (\"\\nUnique values :  \\n\\n\",df.nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Examine the null records of Location Description\ndf[df[\"Location Description\"].isnull()]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop these records\ndf = df.dropna()\n# print the count of Null records in each column\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Analysis & Visualization","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Plot the top 10 primary types","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# set figure size\nplt.figure(figsize = (15, 10))\n\n# plot the records\nax=sns.countplot(x= 'Primary Type', data = df, order = df['Primary Type'].value_counts().iloc[:10].index, palette = 'RdBu_r')\n\n# set individual bar lables using above list\nfor i in ax.patches:\n    # get_x pulls left or right; get_height pushes up or down\n    ax.text(i.get_x(), i.get_height(),\n            str(i.get_height()), fontsize=15,\ncolor='dimgrey')\nshow()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot the top 10 Location descriptions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# set the figure size\nplt.figure(figsize = (15, 10))\n\n# plot the values\nax = sns.countplot(y= 'Location Description', data = df, order = df['Location Description'].value_counts().iloc[:15].index,palette = 'RdBu_r')\n\n# set individual bar lables using above list\nfor i in ax.patches:\n    # get_width pulls left or right; get_y pushes up or down\n    ax.text(i.get_width()+.3, i.get_y()+.5, \n            str(i.get_width()), fontsize=15,\ncolor='dimgrey')\nshow()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Resample is a Convenience method for frequency conversion and resampling of time series.\n\n# resample into Years\n\nplt.plot(df.resample('Y').size())\nplt.title('Crimes Count Per Year')\nplt.xlabel('Years')\nplt.ylabel('Number of Crimes')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# resample into Months\n\nplt.plot(df.resample('M').size())\nplt.title('Crimes Count Per Month')\nplt.xlabel('Months')\nplt.ylabel('Number of Crimes')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preparing the data for the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# aggregating the number of cases per month for all years\nts_df = pd.DataFrame(df.resample('M').size().reset_index())\nts_df.columns = ['Date', 'Crime Count'] # renaming the columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot interactive slider chart\nfig = px.line(ts_df, x='Date',y='Crime Count', title= 'Crime count')\n\nfig.update_xaxes(\nrangeslider_visible =True,\nrangeselector=dict(\n        buttons=list([\n                dict(count=1,label=\"1y\",step=\"year\",stepmode=\"backward\"),\n                dict(count=2,label=\"3y\",step=\"year\",stepmode=\"backward\"),\n                dict(count=3,label=\"5y\",step=\"year\",stepmode=\"backward\"),\n                dict(step=\"all\")\n                    ])\n                )\n                )\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_df = ts_df.set_index('Date')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split into train and test datasets to build the model on the training dataset and forecast using the test dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting into train and test set\ntrain = ts_df[:181]\ntest = ts_df[181:]\nprint(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train)\nplt.plot(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build Fb prophet model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Prophet is open source software released by Facebook’s Core Data Science team.\n\nProphet is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects.\n\nProphet works best with time series that have strong seasonal effects and several seasons of historical data.\n\nFor more information, please check this out: https://research.fb.com/prophet-forecasting-at-scale/ https://facebook.github.io/prophet/docs/quick_start.html#python-api","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet import Prophet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating the dataframe\nprophet_df = train.reset_index()\nprophet_df .head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Rename the columns as ds and y for the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"prophet_df = prophet_df.rename(columns= {'Date':'ds','Crime Count':'y'})\nprophet_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = Prophet()\nm.fit(prophet_df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Forcasting into the future\nfuture = m.make_future_dataframe(periods=12, freq='M')\nforecast = m.predict(future)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figure = m.plot(forecast, xlabel='Date', ylabel='Crime Rate')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot = m.plot_components(forecast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast_df = pd.DataFrame(forecast)\nforecast_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preparing the dataframe with date and forecast\nforecast_df=forecast_df[['ds','yhat']]\nforecast_df=forecast_df.set_index('ds')\nforecast_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the predictions\nplt.figure(figsize=(20,10))\nplt.plot(train, label ='Train')\nplt.plot(test, label='Test')\nplt.plot(forecast_df, label='Forecast')\nplt.xlabel('Year')\nplt.ylabel('Count')\nplt.title('Plotting Train vs Test vs Predicted Crime rate')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Crime Count']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast_df['yhat'][181:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate error\ntest['fbprophet_error'] = test['Crime Count'] - forecast_df['yhat'][181:]\n\nrmse = np.sqrt(np.mean(test.fbprophet_error**2)).round(2)\nmape = np.round(np.mean(np.abs(100*(test.fbprophet_error/test['Crime Count'])), 0))\n\nprint('RMSE = $', rmse)\nprint('MAPE =', mape, '%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build Auto Arima Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"ARIMA is an acronym for Auto Regressive (AR) Integrated (I) Moving Average (MA) which indicates that an ARIMA model has three components to it.","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!pip install pmdarima","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pmdarima as pm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas.plotting import autocorrelation_plot\nautocorrelation_plot(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.graphics.tsaplots import plot_pacf\nplot_pacf(train,lags=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we are trying with the p, d, q values ranging from 0 to 5 to get better optimal values from the model. There are many other parameters in this model and to know more about the functionality, visit this link [[here]](https://alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.auto_arima.html)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![](https://miro.medium.com/max/1148/1*64ZOjhR_jsZ9D-E51MKvBQ.png)\n* Auto-Regressive (p) -> Number of autoregressive terms.\n* Integrated (d) -> Number of nonseasonal differences needed for stationarity.\n* Moving Average (q) -> Number of lagged forecast errors in the prediction equation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = pm.auto_arima(train,m=12,start_p=0,start_q=3, max_order=5, \n                      error_action='ignore',test='adf',seasonal=True,\n                      trace=True,stepwise=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The output above shows that the final model fitted was an ARIMA(0,1,3) estimator, where the values of the parameters p, d, and q were zero, one, and three, respectively. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a dataframe with test date index\nprediction = pd.DataFrame(model.predict(n_periods=12),index = test.index,columns =['Predicted Crime Count'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print predictions\nprediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the predictions\nplt.plot(train, label ='Train')\nplt.plot(test['Crime Count'], label='Test')\nplt.plot(prediction, label='Prediction')\nplt.xlabel('Year')\nplt.ylabel('Count')\nplt.title('Plotting Train vs Test vs Predicted Crime rate')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate error\ntest['arima_error'] = test['Crime Count'] - prediction['Predicted Crime Count']\n\nrmse = np.sqrt(np.mean(test.arima_error**2)).round(2)\nmape = np.round(np.mean(np.abs(100*(test.arima_error/test['Crime Count'])), 0))\n\nprint('RMSE = $', rmse)\nprint('MAPE =', mape, '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out = model.plot_diagnostics()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Hello! I Hope you are well, if you find this notebook helpful please upvote and support my work.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}