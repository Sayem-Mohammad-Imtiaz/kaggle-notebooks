{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:  \n        print(os.path.join(dirname, filename))  ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"创建绘图","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport json\n\n\n# 训练日志绘图类\nclass HistoryGraph:\n    def __init__(self, history, epochs, title, file_path):\n        # 训练日志\n        self.history = history\n        # 训练趟数\n        self.epochs = epochs\n        # 图标题\n        self.title = title\n        # 图像存盘文件路径名\n        self.file_path = file_path\n\n    def draw(self):\n        figure, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n        figure.suptitle(self.title, fontsize=12)\n        figure.subplots_adjust(top=0.85, wspace=0.3)\n\n        epoch_list = list(range(1, self.epochs + 1))\n        ax1.plot(epoch_list,\n                 self.history.history['accuracy'],\n                 label='Train Accuracy')\n        ax1.plot(epoch_list,\n                 self.history.history['val_accuracy'],\n                 label='Validation Accuracy')\n        ax1.set_xticks(np.arange(0, self.epochs + 1, 5))\n        ax1.set_ylabel('Accuracy Value')\n        ax1.set_xlabel('Epoch #')\n        ax1.set_title('Accuracy')\n        ax1.legend(loc=\"best\")\n\n        ax2.plot(epoch_list, self.history.history['loss'], label='Train Loss')\n        ax2.plot(epoch_list,\n                 self.history.history['val_loss'],\n                 label='Validation Loss')\n        ax2.set_xticks(np.arange(0, self.epochs + 1, 5))\n        ax2.set_ylabel('Loss Value')\n        ax2.set_xlabel('Epoch #')\n        ax2.set_title('Loss')\n        ax2.legend(loc=\"best\")\n        figure.savefig(self.file_path)\n        figure.show()\n        plt.close()\n\n    def draw_from_json(self, json_path):\n        history = json.loads(open(json_path).read())\n        epochs = len(history[\"loss\"])\n        figure, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n        figure.suptitle(self.title, fontsize=12)\n        figure.subplots_adjust(top=0.85, wspace=0.3)\n\n        epoch_list = list(range(1, epochs + 1))\n        ax1.plot(epoch_list,\n                 history['accuracy'],\n                 label='Train Accuracy')\n        ax1.plot(epoch_list,\n                 history['val_accuracy'],\n                 label='Validation Accuracy')\n        ax1.set_xticks(np.arange(0, epochs + 1, 5))\n        ax1.set_ylabel('Accuracy Value')\n        ax1.set_xlabel('Epoch #')\n        ax1.set_title('Accuracy')\n        ax1.legend(loc=\"best\")\n\n        ax2.plot(epoch_list, history['loss'], label='Train Loss')\n        ax2.plot(epoch_list,\n                 history['val_loss'],\n                 label='Validation Loss')\n        ax2.set_xticks(np.arange(0, epochs + 1, 5))\n        ax2.set_ylabel('Loss Value')\n        ax2.set_xlabel('Epoch #')\n        ax2.set_title('Loss')\n        ax2.legend(loc=\"best\")\n        figure.savefig(self.file_path)\n        plt.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"处理csv文件","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nsample_df = pd.read_csv('/kaggle/input/facial-expression-recognition-challenge/icml_face_data.csv/icml_face_data.csv')\nprint(sample_df)\nemotions = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n\n# 修改列名称：emotion→label，pixels→image\nsample_df.columns = ['label', 'Usage', 'image']\n\n# 删除Usage列\nsample_df = sample_df.drop(columns=['Usage'])\nprint(sample_df)\n\n# 添加emotion列及对应的内容\nsample_df['emotion'] = sample_df['label'].apply(lambda x: emotions[int(x)])\nprint(sample_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"统计样本分布","metadata":{}},{"cell_type":"code","source":"sample_distribution_df = sample_df.groupby('emotion').count()\nprint(sample_distribution_df)\n\nsample_df = sample_df[sample_df['emotion']!='Disgust']\nsample_distribution_df = sample_df.groupby('emotion').count()\nprint(sample_distribution_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"采样前后数量","metadata":{}},{"cell_type":"code","source":"m = sample_df.groupby('label').count().mean().values[0]\nprint(\"各类表情样本平均数量: \" + str(m))\n\nemotions = ['Angry', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n\noversampled = pd.DataFrame()\nfor emotion in emotions:\n    print('\\n' + emotion)\n    l = len(sample_df[sample_df.emotion==emotion])\n    print('采样前: ' + str(l))\n    \n    if (l>=m):\n        dft = sample_df[sample_df.emotion==emotion].sample(int(m))\n        oversampled = oversampled.append(dft)\n        print('采样后: ' + str(len(dft)))\n    else:\n        frac = int(m/l)\n        dft = pd.DataFrame()\n        for i in range(frac+1):\n            dft = dft.append(sample_df[sample_df.emotion==emotion])\n        dft = dft[dft.emotion==emotion].sample(int(m))\n        oversampled = oversampled.append(dft)\n        print('采样后: ' + str(len(dft)))\n        \noversampled = oversampled.sample(frac=1).reset_index().drop(columns=['index'])\nprint(oversampled)\nsample_distribution_df = oversampled.groupby('emotion').count()\nprint(sample_distribution_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"分割训练集、测试集","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# 删除emotion列\n# oversampled = oversampled.drop(columns=['emotion'])\n\n# 随机混洗DataFrame的行 \noversampled = oversampled.sample(frac = 1) \n\ntrain_sample, test_sample = train_test_split(oversampled, test_size=0.1)\nprint(train_sample)\nprint(test_sample)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"MiniVGG11模型","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.regularizers import l1, l2, l1_l2\nfrom tensorflow.keras import backend\n\n\n# 定义 MiniVGG11类\nclass MiniVGG11:\n    @staticmethod\n    def build(width, height, channel, classes, reg=0.0002):\n        \"\"\"\n        根据输入样本的维度（width、height、channel），分类数量，正则化因子创建MiniVGG11网络模型\n        Args:\n            width:   输入样本的宽度\n            height:  输入样本的高度\n            channel: 输入样本的通道\n            classes: 分类数量\n            reg:     正则化因子\n\n        Returns:\n            MiniVGG11网络模型对象\n\n        \"\"\"\n\n        model = Sequential(name=\"MiniVGG11\")\n\n        # 缺省输入格式为通道后置（\"channels_last\"）\n        shape = (height, width, channel)\n        channel_dimension = -1\n\n        # 如果输入格式为通道前置\n        # 重新设置输入格式和通道位置指示\n        if backend.image_data_format() == \"channels_first\":\n            shape = (channel, height, width)\n            channel_dimension = 1\n\n        # 第一卷积块\n        model.add(Conv2D(64, (3, 3), input_shape=shape, padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n        # 第二卷积块\n        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n        # 第三卷积块\n        model.add(Conv2D(256, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n\n        model.add(Conv2D(256, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n        # 第四卷积块\n        model.add(Conv2D(512, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        \n        model.add(Conv2D(512, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n        # 第五卷积块\n        model.add(Conv2D(512, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Dropout(0.5))\n\n        model.add(Conv2D(512, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Dropout(0.5))\n        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\", strides=(1, 1)))\n\n        # 第一全连接层\n        model.add(Flatten())\n        model.add(Dense(32, kernel_regularizer=l2(reg)))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Dropout(0.5))\n        \n        # 第二全连接层\n        model.add(Dense(32, kernel_regularizer=l2(reg)))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Dropout(0.5))\n\n        # 第三全连接层\n        model.add(Dense(classes, kernel_regularizer=l2(reg)))\n        model.add(Activation(\"softmax\"))\n\n        return model\n\n\n# 测试MiniVGG11类实例化并输出MiniVGG11模型的概要信息\nif __name__ == \"__main__\":\n    model = MiniVGG11.build(width=48, height=48, channel=1, classes=7, reg=0.0002)\n    print(model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"更新学习率","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n\nclass StepDecay:\n    def __init__(self, init_alpha=0.256, factor=0.97, drop_every=2.4):\n        # 保存初始学习速率、递减因子、递减周期\n        self.initAlpha = init_alpha\n        self.factor = factor\n        self.dropEvery = drop_every\n\n    def __call__(self, epoch):\n        # 为当前训练趟就是新的学习速率\n        exp = np.floor((1 + epoch) / self.dropEvery)\n        alpha = self.initAlpha * (self.factor ** exp)\n        # 返回新的学习速率\n        return float(alpha)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"模型训练","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Nadam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import to_categorical\nimport numpy as np\nfrom tensorflow.keras.callbacks import LearningRateScheduler\n\n\nEPOCHS = 100\nBATCH_SIZE = 512\nNUM_CLASSES = 7\nMODEL_FILE = \"MiniVGG11_model.h5\"\n\nreg = 1e-4\nlearning_rate = 5e-4\nopt = Nadam(learning_rate=learning_rate)\n\nschedule = StepDecay(init_alpha=learning_rate, factor=0.5, drop_every=10)\n\nlrs = LearningRateScheduler(schedule, verbose=1)\n\nmodel = MiniVGG11.build(width=48, height=48, channel=1, classes=NUM_CLASSES, reg=reg)\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n\n# 训练网络\nimages = train_sample['image'].tolist()\nX = []\nfor image in images:\n    image = np.array(image.split(\" \"), dtype=\"float32\")\n    # image = image / 255.0\n    image = image.reshape((48, 48, 1))\n    X.append(image)\n\nX = np.array(X)\n\n\nlabels = train_sample.loc[:,'label']\nY = to_categorical(labels)\nhistory = model.fit(x=X,\n                    y=Y, \n                    epochs=EPOCHS, \n                    batch_size=BATCH_SIZE, \n                    shuffle=True,\n                    validation_split=0.2, \n                    validation_batch_size=BATCH_SIZE, \n                    callbacks=[lrs,])\n\n# 将训练得到的模型保存到文件\nprint(\"[信息] 保存模型...\")\nmodel.save(MODEL_FILE, overwrite=True)\n\n# 绘制并保存训练性能图\ntitle = \"VGG11 Fer2013 Dataset Training Performance 320203313\"\ngraph_file = \"VGG11_Fer2013_Dataset_Training_Performance.pdf\"\nHistoryGraph(history, EPOCHS, title, graph_file).draw()\n\n# 保存训练历史数据\njson_path = \"VGG11_Fer2013_Dataset_Training.json\"\nf = open(json_path, \"w\")\nf.write(json.dumps(str(history.history), skipkeys=True))\nf.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"模型评估","metadata":{}},{"cell_type":"code","source":"from keras.utils import to_categorical\nimport numpy as np\nfrom tensorflow.keras.models import load_model\n# 训练网络\nimages = test_sample['image'].tolist()\nX = []\nfor image in images:\n    image = np.array(image.split(\" \"), dtype=\"float32\")\n    # image = image / 255.0\n    image = image.reshape((48, 48, 1))\n    X.append(image)\n\nX = np.array(X)\n\n\nlabels = test_sample.loc[:,'label']\nY = to_categorical(labels)\n\n# 加载前面训练好的网络\nprint(\"[信息] 加载网络模型...\")\nmodel = load_model(\"../input/vgg11model/MiniVGG11_model.h5\")\n\n(loss, acc) = model.evaluate(x=X, y=Y)\nprint(\"[信息] 测试集准确率：{:.2f}%\".format(acc * 100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}