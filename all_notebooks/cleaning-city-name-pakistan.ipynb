{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\nfrom fuzzywuzzy import process, fuzz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset=pd.read_csv('../input/gufhtugu-publications-dataset-challenge/GP Orders - 5.csv')\ncitiesdb=pd.read_csv('../input/pakistan-cities-and-postal-codes/Pakistan Cities and Zip Codes.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.City.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.City=dataset.City.astype('str')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lowering the text\ndataset.City=dataset.City.apply(lambda x:x.lower() )\n\ndataset.City.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.City=dataset.City.str.split(':',expand=True)\ndataset.City=dataset.City.str.split(',',expand=True)\ndataset.City=dataset.City.str.split('/',expand=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.City.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.City","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"token=nltk.tokenize.RegexpTokenizer(r'\\w+')\n#applying token\ndataset.City=dataset.City.apply(lambda x:token.tokenize(x))\n\n#view\ndisplay(dataset.City.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#removing stop words\ndataset.City=dataset.City.apply(lambda x:[w for w in x if w not in stopwords.words('english')])\n\n#view\ndataset.City.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.City=dataset.City.apply(lambda x:\" \".join(x))\n#View\ndataset.City.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.City.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_city = dataset['City'].unique().tolist()\nunique_city[4:10] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"process.extract('islamabad', unique_city, scorer=fuzz.token_sort_ratio)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"process.extract('rajanpur', unique_city, scorer=fuzz.token_sort_ratio)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_sort = [(x,) + i\n             for x in citiesdb.Area_Name \n             for i in process.extract(x, unique_city,     scorer=fuzz.token_sort_ratio)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"similarity_sort = pd.DataFrame(score_sort, columns=['City_sort','match_sort','score_sort'])\nsimilarity_sort.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"similarity_sort['sorted_City_sort'] = np.minimum(similarity_sort['City_sort'], similarity_sort['match_sort'])\nsimilarity_sort.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"high_score_sort = similarity_sort[(similarity_sort['score_sort'] >= 95) &\n                (similarity_sort['City_sort'] !=  similarity_sort['match_sort']) &\n                (similarity_sort['sorted_City_sort'] != similarity_sort['match_sort'])]\nhigh_score_sort = high_score_sort.drop('sorted_City_sort',axis=1).copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"high_score_sort","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"high_score_sort.groupby(['City_sort','score_sort']).agg(\n                        {'match_sort': ', '.join}).sort_values(\n                        ['score_sort'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in range(len(high_score_sort.City_sort)):\n    dataset.City= dataset.City.replace([high_score_sort.match_sort.iloc[x]],[high_score_sort.City_sort.iloc[x]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.City=dataset.City.str.title()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.City.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"original=pd.read_csv('../input/gufhtugu-publications-dataset-challenge/GP Orders - 5.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"original['Diff']=(original['City'].str.len())-(dataset['City']).str.len()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"original.loc[original['Diff'] != 0, 'Changed?'] = True \noriginal.loc[original['Diff'] == 0, 'Changed?'] = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(original['Changed?'].sum(),\"Changes were made\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.to_csv('clean_city.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# I have improved ðŸ¤— the data but there is alot more work to be done to get only names. In this Notebook I have use fuzzywuzzy and nltk for extracting and then improving overall cities name. If you like my work do Upvote ðŸ‘†"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}