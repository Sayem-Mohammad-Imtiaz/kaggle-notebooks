{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Capstone Project\n\n## Problem statement: \n\n### A house value is simply more than location and square footage. Like the features that make up a person, an educated party would want to know all aspects that give a house its value. For example, you want to sell a house and you don’t know the price which you can take — it can’t be too low or too high. To find house price you usually try to find similar properties in your neighbourhood and based on gathered data you will try to assess your house price. \n\n\n## Objective:\n\n### Take advantage of all of the feature variables available below, use it to analyse and predict house prices. \n\n1.\tcid: a notation for a house\n\n2.\tdayhours: Date house was sold\n\n3.\tprice: Price is prediction target\n\n4.\troom_bed: Number of Bedrooms/House\n\n5.\troom_bath: Number of bathrooms/bedrooms\n\n6.\tliving_measure: square footage of the home\n\n7.\tlot_measure: quare footage of the lot\n\n8.\tceil: Total floors (levels) in house\n\n9.\tcoast: House which has a view to a waterfront\n\n10.\tsight: Has been viewed\n\n11.\tcondition: How good the condition is (Overall)\n\n12.\tquality: grade given to the housing unit, based on grading system\n\n13.\tceil_measure: square footage of house apart from basement\n\n14.\tbasement_measure: square footage of the basement\n\n15.\tyr_built: Built Year\n\n16.\tyr_renovated: Year when house was renovated\n\n17.\tzipcode: zip\n\n18.\tlat: Latitude coordinate\n\n19.\tlong: Longitude coordinate\n\n20.\tliving_measure15: Living room area in 2015(implies-- some renovations) This might or might not have affected the lotsize area\n\n21.\tlot_measure15: lotSize area in 2015(implies-- some renovations)\n\n22.\tfurnished: Based on the quality of room \n\n23. total_area: Measure of both living and lot"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style='whitegrid')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"city= pd.read_csv(\"../input/innercity/innercity.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def details(df):\n    b = pd.DataFrame()\n    b['Null Values'] = df.isnull().sum()\n    b['Data Type'] = df.dtypes\n    b['No. of Unique Values'] = df.nunique()\n    return b","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"details(city)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city.corr()['price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,20))\nsns.heatmap(city.corr(),annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city['dayhours']= [x.strip().replace('T000000','') for x in city.dayhours]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city['dayhours'] = pd.to_datetime(city.dayhours)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city['year_sold'] = city.dayhours.dt.year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city_1 = city.drop(columns = 'dayhours')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city_1[city_1['room_bed'] == 33].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city_1['room_bed']=city_1['room_bed'].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city_1.drop(columns = 'cid',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city_1.drop(index=750,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city_1 = city_1.reset_index()\ncity_1.drop(columns='index',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city_1['room_bath']=city_1['room_bath'].astype('category')\ncity_1['ceil']=city_1['ceil'].astype('category')\ncity_1['coast']=city_1['coast'].astype('category')\ncity_1['sight']=city_1['sight'].astype('category')\ncity_1['condition']=city_1['condition'].astype('category')\ncity_1['quality']=city_1['quality'].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city_1['have_basement'] = city_1['basement'].apply(lambda x: 0 if x==0 else 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city_1['Is_renovated'] = city_1['yr_renovated'].apply(lambda x: 0 if x==0 else 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city_1['Age_of_house'] = city_1['year_sold'] - city_1['yr_built']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lst = []\nfor i in city_1.lat:\n    if i<47.255900:\n        lst.append('ES')\n    elif i>47.255900 and i<47.405900:\n        lst.append('MS')\n    elif i>47.405900 and i<47.555900:\n        lst.append('MN')\n    else:\n        lst.append('EN')\ncity_1['SN_region'] = lst\ncity_1['SN_region'] = city_1['SN_region'].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lst = []\nfor i in abs(city_1.long):\n    if i<122.105000:\n        lst.append('EE')\n    elif i>122.105000 and i<122.205000:\n        lst.append('ME')\n    elif i>122.205000 and i<122.328000:\n        lst.append('MW')\n    else:\n        lst.append('EW')\ncity_1['EW_region'] = lst\ncity_1['EW_region'] = city_1['EW_region'].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"delete_index = city_1[city_1['Age_of_house']== -1]['year_sold'].index\ncity_1.drop(index=delete_index,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city.hist(figsize=(25,20))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list1 = ['dayhours','cid','price','room_bed', 'room_bath',\n        'ceil', 'coast', 'sight', 'condition', 'quality',\n        'furnished','zipcode']\ncity_def = city.drop(columns=list1)\ndef trend():\n    for i in city_def.columns:\n        city[[i,'price']].groupby([i]).sum().plot(figsize=(15,5))\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trend() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list1 = ['dayhours','cid','price','room_bed', 'room_bath',\n        'ceil', 'coast', 'sight', 'condition', 'quality',\n        'furnished','zipcode','year_sold','yr_renovated','lat','long']\ncity_def = city.drop(columns=list1)\ndef scatterr():\n    for i in city_def.columns:\n        plt.figure(figsize=(15,5))\n        sns.regplot(x='price',y=i, data=city, color='#79d13e')\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scatterr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city_1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city_1.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"details(city_1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"drop columns : \n\nbasement : as the data is already in ceil measure and living measure\n\nyr_built : data is in age of house\n\nyr_renovated : is renovated new column\n\ntotal_area : ambiguous column\n\nlat, long : made catogorical columns\n\nyear_sold : data in age of house"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = city_1.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummy_data = pd.get_dummies(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummy_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in dummy_data.columns:\n    print(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_list = ['lat','long','zipcode','yr_built','year_sold','yr_renovated','basement','total_area',\n'room_bed_33']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummy_data.drop(columns=drop_list,inplace =True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummy_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummy_data.corr()['price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"details(dummy_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = dummy_data.drop(columns='price')\ny = dummy_data.price","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state = 100) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nX_train=sm.add_constant(x_train)# Add constant X\nX_test = sm.add_constant(x_test)\nols_model=sm.OLS(y_train,X_train).fit()\nresiduals = ols_model.resid\nols_model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As the smallest eigenvalue is 4.7e-20, and most of the features are categorical, therefore ignoring the multicollinearity warning of the OLS model. "},{"metadata":{},"cell_type":"markdown","source":"After Stepwise Selection of features having p value < 0.05"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = dummy_data[['SN_region_MS', 'living_measure', 'sight_4', 'SN_region_EN', 'furnished', 'quality_9', 'quality_10', 'Age_of_house', 'coast_1', 'quality_13', 'sight_0', 'quality_12', 'quality_8', 'room_bath_7.75', 'EW_region_EE', 'condition_5', 'Is_renovated', 'condition_4', 'room_bath_6.0', 'EW_region_MW', 'living_measure15', 'EW_region_EW', 'room_bath_4.75', 'room_bath_8.0', 'ceil_2.5', 'quality_7', 'room_bath_4.25', 'room_bath_3.25', 'room_bath_5.5', 'room_bath_3.75', 'room_bath_5.25', 'room_bath_5.0', 'room_bath_4.5', 'room_bath_4.0', 'quality_11', 'sight_2', 'lot_measure15', 'room_bath_3.5', 'room_bed_4', 'room_bed_6', 'ceil_1.0', 'room_bed_7', 'room_bath_5.75', 'room_bed_5', 'SN_region_ES', 'room_bath_3.0', 'lot_measure', 'room_bath_6.25', 'room_bath_2.25', 'ceil_measure', 'room_bath_6.75']]\nx = x.drop(columns='ceil_1.0')\ny = dummy_data.price","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state = 100) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nX_train=sm.add_constant(x_train)# Add constant X\nX_test = sm.add_constant(x_test)\nols_model=sm.OLS(y_train,X_train).fit()\nresiduals = ols_model.resid\nols_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlm=LinearRegression()\nlm.fit(x_train,y_train)\ncoefficients = pd.concat([pd.DataFrame(x_train.columns),pd.DataFrame(np.transpose(lm.coef_))], axis = 1)\nprint(coefficients)\nprint(lm.intercept_)\nli_y_pred=lm.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\ny_test = pd.to_numeric(y_test, errors='coerce')\nRSS = np.sum((li_y_pred - y_test)**2)\ny_mean = np.mean(y_test)\nTSS = np.sum((y_test - y_mean)**2)\nR2 = 1 - RSS/TSS\nprint('R Squared',R2)\n\nn=X_test.shape[0]\np=X_test.shape[1] - 1\n\nadj_rsquared = 1 - (1 - R2) * ((n - 1)/(n-p-1))\nprint('Adjusted R squared',adj_rsquared)\nprint(\" Root Mean Squared Error: %.4f\"\n      % np.sqrt(np.mean((li_y_pred - y_test) ** 2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nss=StandardScaler()\nx_train_scaled = ss.fit_transform(x_train)\nx_test_scaled = ss.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\n#Fitting the PCA algorithm with our Data\npca = PCA()\nmodel_pca = pca.fit(x_train_scaled)\n#Plotting the Cumulative Summation of the Explained Variance\nplt.figure()\nplt.plot(np.cumsum(model_pca.explained_variance_ratio_))\nplt.xlabel('Number of Components')\nplt.ylabel('Variance (%)') #for each component\nplt.title('Popularity Dataset Explained Variance')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_pca = PCA(n_components=46,svd_solver='full')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train = model_pca.fit_transform(x_train_scaled)\nnew_test  = model_pca.transform(x_test_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport pylab as pl\nfrom sklearn.decomposition import PCA\n\n# Dump components relations with features:\npd.DataFrame(model_pca.components_,columns=x_train.columns,index = ['PC-1','PC-2','PC-3','PC-4','PC-5','PC-6','PC-7','PC-8','PC-9','PC-10',\n                                                                   'PC-11','PC-12','PC-13','PC-14','PC-15','PC-16','PC-17','PC-18','PC-19','PC-20',\n                                                                   'PC-21','PC-22','PC-23','PC-24','PC-25','PC-26','PC-27','PC-28','PC-29','PC-30',\n                                                                   'PC-31','PC-32','PC-33','PC-34','PC-35','PC-36','PC-37','PC-38','PC-39','PC-40',\n                                                                   'PC-41','PC-42','PC-43','PC-44','PC-45','PC-46'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlm=LinearRegression()\nlm.fit(new_train,y_train)\ncoefficients = pd.concat([pd.DataFrame(x_train.columns),pd.DataFrame(np.transpose(lm.coef_))], axis = 1)\nprint(coefficients)\nprint(lm.intercept_)\nli_y_pred=lm.predict(new_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\ny_test = pd.to_numeric(y_test, errors='coerce')\nRSS = np.sum((li_y_pred - y_test)**2)\ny_mean = np.mean(y_test)\nTSS = np.sum((y_test - y_mean)**2)\nR2 = 1 - RSS/TSS\nprint('R Squared',R2)\n\nn=new_test.shape[0]\np=new_test.shape[1] - 1\n\n\n\nadj_rsquared = 1 - (1 - R2) * ((n - 1)/(n-p-1))\nprint('Adjusted R squared',adj_rsquared)\nlin_rmse =  np.sqrt(np.mean((li_y_pred - y_test) ** 2))\nprint(\" Root Mean Squared Error: %.4f\"\n      % np.sqrt(np.mean((li_y_pred - y_test) ** 2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error,r2_score\nfrom sklearn.linear_model import Lasso\nlas = Lasso(alpha=1.0, fit_intercept=True, normalize=False, precompute=False, copy_X=True, max_iter=1000, \n            tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')\nlas.fit(new_train,y_train)\nlas_predict_pca = las.predict(new_test)\n\n# Accuracy Score on test dataset\nlas_rmse_test_pca = mean_squared_error(y_test,las_predict_pca)**(0.5)\nprint('\\nRMSE on test dataset : ', las_rmse_test_pca)\n\nlas_r2 = r2_score(y_test,las_predict_pca)\nprint('R square on test dataset is %1.3f' %r2_score(y_test,las_predict_pca))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coefficients = pd.concat([pd.DataFrame(x_train.columns),pd.DataFrame(np.transpose(las.coef_))], axis = 1)\nprint(coefficients)\nprint(las.intercept_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge\nrid = Ridge(alpha=2.0, fit_intercept=True,normalize=False, copy_X=True, max_iter=None, tol=0.001, \n solver='auto', random_state=None)\nrid.fit(new_train,y_train)\nrid_predict_pca = rid.predict(new_test)\n\n# Accuracy Score on test dataset\nrid_rmse_test_pca = mean_squared_error(y_test,rid_predict_pca)**(0.5)\nprint('\\nRMSE on test dataset : ', rid_rmse_test_pca)\n\nrid_r2 =r2_score(y_test,rid_predict_pca)\nprint('R square on test dataset is %1.3f' %r2_score(y_test,rid_predict_pca))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coefficients = pd.concat([pd.DataFrame(x_train.columns),pd.DataFrame(np.transpose(rid.coef_))], axis = 1)\nprint(coefficients)\nprint(rid.intercept_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing decision tree classifier from sklearn library\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_squared_error,r2_score\n# Fitting the decision tree with default hyperparameters, apart from\n# max_depth which is 5 so that we can plot and read the tree.\ndtree = DecisionTreeRegressor(max_depth=5)\ndtree.fit(new_train,y_train)\n\n\n# predict the target on the new train dataset\ndtree_pca_train_pred = dtree.predict(new_train)\n\n# predict the target on the new test dataset\ndtree_predict_test_pca = dtree.predict(new_test)\n\n# Accuracy Score on test dataset\ndtree_rmse_test_pca = mean_squared_error(y_test,dtree_predict_test_pca)**(0.5)\nprint('\\nRMSE on test dataset : ', dtree_rmse_test_pca)\n\ndtree_r2 =r2_score(y_test,dtree_predict_test_pca)\nprint('R square on test dataset is %1.3f' %r2_score(y_test,dtree_predict_test_pca))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coefficients = pd.concat([pd.DataFrame(x_train.columns),pd.DataFrame(np.transpose(dtree.feature_importances_))], axis = 1)\nprint(coefficients)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrf_reg = RandomForestRegressor(n_estimators=200, n_jobs=-1)\nrf_reg.fit(new_train,y_train)\n\n\n# predict the target on the new test dataset\nrf_reg_predict_test_pca = rf_reg.predict(new_test)\n\n# Accuracy Score on test dataset\nrf_reg_rmse_test_pca = mean_squared_error(y_test,rf_reg_predict_test_pca)**(0.5)\nprint('RMSE on test dataset : ', rf_reg_rmse_test_pca)\n\nrf_reg_r2 = r2_score(y_test,rf_reg_predict_test_pca)\nprint('R square on test dataset is %1.3f' % r2_score(y_test,rf_reg_predict_test_pca))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coefficients = pd.concat([pd.DataFrame(x_train.columns),pd.DataFrame(np.transpose(rf_reg.feature_importances_))], axis = 1)\nprint(coefficients)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\ngbr = GradientBoostingRegressor(n_estimators=6000,\n                                                    learning_rate=0.01,\n                                                    max_depth=4,\n                                                    max_features='sqrt',\n                                                    min_samples_leaf=15,\n                                                    min_samples_split=10,\n                                                    loss='huber',\n                                                    random_state=100\n                   )\n\ngbr.fit(new_train,y_train)\n\n\n\n# predict the target on the new test dataset\ngbr_predict_test_pca = gbr.predict(new_test)\n\n# Accuracy Score on test dataset\ngbr_rmse_test_pca = mean_squared_error(y_test,gbr_predict_test_pca)**(0.5)\nprint('\\nRMSE on new test dataset : ', gbr_rmse_test_pca)\n\ngbr_r2 = r2_score(y_test, gbr_predict_test_pca)\nprint('R square is %1.3f' % r2_score(y_test, gbr_predict_test_pca))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coefficients = pd.concat([pd.DataFrame(x_train.columns),pd.DataFrame(np.transpose(gbr.feature_importances_))], axis = 1)\nprint(coefficients)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Light Gradient Boosting Regressor\nfrom lightgbm import LGBMRegressor\n\nlightgbm = LGBMRegressor(n_jobs=-1)\n\nlightgbm.fit(new_train,y_train)\n\n\n\n# predict the target on the new test dataset\nlgbm_predict_test_pca = lightgbm.predict(new_test)\n\n# Accuracy Score on test dataset\nlgbm_rmse_test_pca = mean_squared_error(y_test,lgbm_predict_test_pca)**(0.5)\nprint('\\nRMSE on new test dataset : ', lgbm_rmse_test_pca)\n\nlgbm_r2 =r2_score(y_test, lgbm_predict_test_pca)\nprint('R square is %1.3f' % r2_score(y_test, lgbm_predict_test_pca))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coefficients = pd.concat([pd.DataFrame(x_train.columns),pd.DataFrame(np.transpose(lightgbm.feature_importances_))], axis = 1)\nprint(coefficients)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# XGBoost Regressor\nfrom xgboost import XGBRegressor\nxgboost = XGBRegressor(learning_rate=0.01,\n                                            n_estimators=6000,\n                                            max_depth=4,\n                                            min_child_weight=0,\n                                            gamma=0.6,\n                                            subsample=0.7,\n                                            colsample_bytree=0.7,\n                                            objective='reg:linear',\n                                            nthread=-1,\n                                            scale_pos_weight=1,\n                                            seed=27,\n                                            reg_alpha=0.00006,\n                                            random_state=42,\n                      n_jobs=-1)\n\nxgboost.fit(new_train,y_train)\n\n\n# predict the target on the new test dataset\nxgb_predict_test_pca = xgboost.predict(new_test)\n\n# Accuracy Score on test dataset\nxgb_rmse_test_pca = mean_squared_error(y_test,xgb_predict_test_pca)**(0.5)\nprint('\\nRMSE on new test dataset : ', xgb_rmse_test_pca)\n\nxgb_r2 = r2_score(y_test, xgb_predict_test_pca)\nprint('R square is %1.3f' % r2_score(y_test, xgb_predict_test_pca))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coefficients = pd.concat([pd.DataFrame(x_train.columns),pd.DataFrame(np.transpose(xgboost.feature_importances_))], axis = 1)\nprint(coefficients)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Run all\noutput = pd.DataFrame({'Regressors With PCA':['Linear Regression','LASSO','Ridge','Decision Tree Regressor','Random Forest Regressor','Gradient Boosting Regressor','Light GBM Regressor', 'XGB Regressor'],\n                      'Root Mean Squared Error': [lin_rmse,las_rmse_test_pca,rid_rmse_test_pca,dtree_rmse_test_pca,rf_reg_rmse_test_pca,gbr_rmse_test_pca,lgbm_rmse_test_pca,xgb_rmse_test_pca],\n                      'R2 Score':[R2,las_r2,rid_r2,dtree_r2,rf_reg_r2,gbr_r2,lgbm_r2,xgb_r2]\n                      })\noutput","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can see the XGB Regressor works best with accuracy of 0.8184 and RMSE of 151468.31 "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}