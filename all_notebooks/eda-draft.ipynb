{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir('../input/')\nos.listdir()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"hotel-booking-demand/hotel_bookings.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We should first make train-validation-test split, but given this is an EDA practice we are not going to do that."},{"metadata":{},"cell_type":"markdown","source":"**Since there are only 32 variables with very nice feature documentation, before we dive into any EDA we should first look at each feature along with its' descriptions and some sample data in order to save some unnecessary effort and list some potential problems and things that need to pay attention to.**\n\n**In the next section, we will first list all features along with their dtype in the orginal dataset. Then a few rows from the df as a sample. Finally examine them one by one.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum(df.duplicated())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop_duplicates(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame({'feature':list(df.columns),'Datatype':[df[x].dtype for x in df.columns]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **'hotel':not much to pay attention to. This is a categorical variable indicating type of hotel(or just two particular hotels)**\n\n* **'is_canceled': a binary variable indicating whether this booking is canceled or not. Probably the target we want to predict.**\n\n* **'lead_time': the original description \"Number of days that elapsed between the entering date and the arrival date\" is not very accurate since we can observe some canceled booking has values other than 0. This suggest that lead_time is actually the interval between the book entering date and the planned arrival date.**\n\n* **'arrival_date_year','arrival_date_month', 'arrival_date_week_number','arrival_date_day_of_month': Arrival time. Again for those canceled booking, this means the planned arrival date. Here the 'arrival_date_day_of_month' seems uniformly distributed across the month. Intuitively, it may not very useful. But what about when it conditioning on other factors? Probably worth to find out.**\n\n* **'stays_in_weekend_nights','stays_in_week_nights': nights stayed. from a rough scan of the dataset we can find some entries have 0 in both columns while the is_canceled feature says it is not canceled. What does that mean? Is that just an error? Or it just means the guest check in check out during the same day in the daytime?**\n\n* **'adults', 'children', 'babies': # of guests. children,babies are highly concentrate at 0. Probably not very important.**\n\n* **'meal': categorical. Undefined/SC,BB,HB,FB**\n\n* **'country':categorical. Country of origin**\n\n* **'market_segment', 'distribution_channel': the second one could be just a simplified feature of the first one. Need further check.** \n       \n* **'is_repeated_guest', 'previous_cancellations','previous_bookings_not_canceled': a customer could be divided into 1)who never booked before,2)who has booked before. Those who has booked before can be further divided into 3)who booked before but all canceled,4)who booked before but arrived at least once. Then we can see the latter two features already have the information of the first. ''**\n\n* **'reserved_room_type','assigned_room_type': two categorical. could combine these two features, but very likely to lose some important info** \n\n* **'booking_changes': if canceled is that count as a 'change'? seems no. need further check**\n\n* **'deposit_type': categorical,No Deposit,Non Refund,Refundable. Could be an important feature.**\n\n* **'agent': ID of the travel agency that made the booking. There are null values in this column. Is it due to missing value or just because guests book the room directly without a travel agency? Need further check. It should be transformed into categorical.**\n\n* **'company': company id. probably not very useful since it's a very imbalanced feature even if we transform it into a binary feature.**\n\n* **'days_in_waiting_list':**\n\n* **'customer_type':**\n\n* **'adr':**\n\n* **'required_car_parking_spaces', 'total_of_special_requests':**\n\n* **'reservation_status': basically is covered by 'is_canceled'**\n\n* **'reservation_status_date': potentially useful to construct other features such as the time gap between date canceled and anticipated arrival date.**"},{"metadata":{},"cell_type":"markdown","source":"**Next we do a quick data cleaning. Handle all missing values and do some datatype transformation.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import missingno as msno\nmsno.matrix(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First we take care of 'company'"},{"metadata":{"trusted":true},"cell_type":"code","source":"(df.company.isna().sum())/len(df.company)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.market_segment.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.distribution_channel.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df.company)-df.company.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df[(df.market_segment=='Corporate') & (df.distribution_channel=='Corporate') & (df.company != 'NaN')])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that there are 5259 non-na values in the 'company' column, while around 4k-5k values are labeled 'corporate' in both market_segment and distribution_channel columns, which very likely to suggest that 'company' information is already included in the latter two columns. In the other hand, there are only 6% rows have a valid value in the company column, which is not very helpful for identifying different companies not even to say finding a general pattern. So I believe it's safe to drop the company column.\n\nFurthermore, in order to avoid having too many features when we encode all categorical variables, I believe we should only choose one between 'market_segment' and 'distribution_channel' in the future study since they pretty much give the same infomation."},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_df =df.drop('company',axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then we move on to 'agent'. The missing values in agent column could because of guest directly book the hotel without any agency. Let's look at all rows of market_segment and distribution_channel where the agent value is missing."},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = df[df.agent.isna()].loc[:,['market_segment','distribution_channel']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp.market_segment.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp.distribution_channel.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.agent.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What we can do here is to fill a value in the agent column where the corresponding distribution_channel column has the value 'Direct' or 'Corporate'. But before doing that, one thing we need to keep in mind is we have to tranform the agent column into a categorical feature in the end. According to the above cell, we know that agent column has 333 distinct values which will cost us too much to directly transform it into a categorcal feature. Thus, we basically have two choices: 1) convert it into a binary feature indicating there is an agency or not. 2) discard it since we don't really need to identify different agency, also because 'market_segment' and 'distribution_channel' already have the information about whether an agency is involved or not.\n\nMy choice here is to discard agent feature.\n\nIn the future study, I believe we should only keep one out of these three closely related features."},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_df.drop('agent',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, 'country' and 'children' both have a few missing values compare to the size of the dataset. We just delete those rows."},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_df.dropna(axis=0,how='any',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So far, we have taken care of missing values."},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we want to further lightweight our dataset, put some features aside and check some potential problems mentioned in the beginning.\nHere is the list of things we want to do next:\n* arrival_date_year: check if we should keep it or not(done)\n* arrival_date_month,arrival_date_week_number,arrival_date_day_of_month: check if we should just keep week_number(done)\n* stays_in_weekend_nights, stays_in_week_nights: examine the cases have 0 in both columns(done)\n* country: check if we should keep it or not, at least we won't use this feature in the prediction of cancellation(leave it for EDA)\n* is_repeated_guest: we want to discard this value since previous_not_canceled feature already cover the same information, but double check it.(done)\n* reserved_room_type, assigned_room_type: we could try to combine these two together and construct features like 'is_different', but for now just keep them for EDA(leave it for EDA)\n* revervation_status: we want to discard this value, even if in the future we have some new data with values other than 'check-out','canceled'. It won't help much to predict cancellation.(done)\n* reservation_date: we can construct new feature like 'time interval between booking enter date and cancellation date' or 'time interval between cancellation date and planned arrival date' which could be very helpful, but for now we don't need it.(done)"},{"metadata":{},"cell_type":"markdown","source":"We starts with 'arrival_date_year'. The reason I want to discard this feature is because we only have data from 2015 to 2017. We can't and don't want to capture how year affect cancellation with only 3 years' data. Even if we do, we'll need data from more different years and need to encode the year data in another form. Although, we could still make some plots against year in EDA, but that won't help much."},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_df.arrival_date_year.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the below plots, it seems arrival_date_month and arrival_date_week_number resemble the same trend but the latter one contains more detialed information. We can consider just keep arrival_date_week_number."},{"metadata":{"trusted":true},"cell_type":"code","source":"city = cleaned_df[cleaned_df.hotel=='City Hotel']\nresort = cleaned_df[cleaned_df.hotel== 'Resort Hotel']\nf, axes = plt.subplots(1, 3, figsize=(30, 7))\naxes[0].hist([city['arrival_date_month'], resort['arrival_date_month']], color=['r','b'], alpha=0.5,bins=12)\naxes[1].hist([city['arrival_date_week_number'], resort['arrival_date_week_number']], color=['r','b'], alpha=0.5)\naxes[2].hist([city['arrival_date_day_of_month'], resort['arrival_date_day_of_month']], color=['r','b'], alpha=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"arrival_date_day_of_month\", hue=\"is_canceled\", data=cleaned_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems there is no clear pattern between cancellation and arrival_date_day_of_month except that there is a drop in count numbers in 31 which is due to the fact not every month has 31th day. Together with the histogram, we probably could exclude arrival_date_day_of_month out."},{"metadata":{},"cell_type":"markdown","source":"For stays_in_weekend_nights and stays_in_week_nights, we mentioned in the beginning that we can observe some cases where both columns equal to 0 while the booking is not canceled. "},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_df[(cleaned_df.stays_in_week_nights ==0)&(cleaned_df.stays_in_weekend_nights ==0)].is_canceled.hist(bins=[0,0.5,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(cleaned_df[(cleaned_df.stays_in_week_nights ==0)&(cleaned_df.stays_in_weekend_nights ==0)])/len(cleaned_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see there are around 600 cases in total which only count for 0.7% of the whole dataset. Still, we can't say for sure how those cases comes from, but it won't harm much in our study, we can just leave them there and consider them as errors."},{"metadata":{},"cell_type":"markdown","source":"I believe is_repeated_guest is just where previous_bookings_not_canceled >= 1. Let's check that."},{"metadata":{"trusted":true},"cell_type":"code","source":"((cleaned_df.is_repeated_guest ==1) == (cleaned_df.previous_bookings_not_canceled >=1)).value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most cases are like what we believed. The rest is very likely to be data errors."},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_df.reservation_status.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Given the information in the above section. We will drop features below:\n* arrival_date_year\n* arrival_date_month\n* arrival_date_day_of_month\n* country\n* is_repeated_guest\n* reservation_status\n* reservation_status_date"},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_df = cleaned_df.drop(['arrival_date_year','arrival_date_month','arrival_date_day_of_month','country','is_repeated_guest','reservation_status','reservation_status_date'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have 23 columns left. They all in the correct dtype except 'is_canceled' which already being encoded into a binary feature."},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above infomation, there are a few need further investigate.\n* children\n* babies\n* previous_cancellations\n* previous_bookings_not_canceled\n* required_car_parking_spaces"},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_df[['children','babies',\n'previous_cancellations',\n'previous_bookings_not_canceled',\n'required_car_parking_spaces']].hist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"They are highly skewed. probably can be converted into binary features."},{"metadata":{},"cell_type":"markdown","source":"Correlation matrix of numerical features from the whole data.(Check if any linear relationship)"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = eda_df.corr()\nax = sns.heatmap(\n    corr, \n    vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200),\n    square=True\n)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=45,\n    horizontalalignment='right'\n);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Correlation between is_canceled and the rest from whole data"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr['is_canceled'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Do the above again just for City Hotels"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr1 = eda_df[eda_df.hotel=='City Hotel'].corr()\nax = sns.heatmap(\n    corr1, \n    vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200),\n    square=True\n)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=45,\n    horizontalalignment='right'\n);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr1['is_canceled'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again just for Resort Hotels"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr2 = eda_df[eda_df.hotel=='Resort Hotel'].corr()\nax = sns.heatmap(\n    corr2, \n    vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200),\n    square=True\n)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=45,\n    horizontalalignment='right'\n);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr2['is_canceled'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr3 = pd.DataFrame({'Whole data':corr['is_canceled'],'CityHotel':corr1['is_canceled'],'ResortHotel':corr2['is_canceled']})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.heatmap(\n    corr3, \n    vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200),\n    square=True\n)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=45,\n    horizontalalignment='right'\n);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no clear linear relation among features or between 'is_canceled' and the rest."},{"metadata":{},"cell_type":"markdown","source":"Next, for categorical features. We first select all columns with dtype 'object', then convert 'is_canceled' into categorical. After having all these columns we form contingency tables between 'is_canceled' and all the rest categorical features then conduct the chi-square test for independence."},{"metadata":{"trusted":true},"cell_type":"code","source":"cate = []\nfor i in eda_df.columns:\n    cate.append((eda_df[i].dtype == 'object'))\ncat_features = eda_df[eda_df.columns[cate]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_label = eda_df.is_canceled.map({1:'canceled',0:'not canceled'})\ncat_df = pd.concat([cat_label,cat_features],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy\npvalue={}\n#pvalues = pd.DataFrame(data = np.zeros((9,9)),index=list(cat_df.columns),columns=list(cat_df.columns))\n#for i in cat_df.columns:\nfor j in cat_features.columns:\n    tab = pd.crosstab(cat_label,cat_features[j], margins = False)\n    chi2, p, dof, ex = scipy.stats.chi2_contingency(tab)\n    pvalue[j] = p","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pvalue","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All p-values are extremely small, which indicate these categorical features are not independent with is_canceled."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}