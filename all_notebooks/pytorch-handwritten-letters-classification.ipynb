{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torchvision\nfrom torchvision import models, datasets, transforms\nimport torch.optim as optim\nfrom tqdm import tqdm\nimport os\nimport cv2\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nimport scipy\n\nimport matplotlib.pylab as plt\nfrom matplotlib import cm\n%matplotlib inline\n\nfrom tensorflow.keras.preprocessing import image\n\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\nfrom albumentations.pytorch import ToTensorV2\nimport albumentations as albu\nimport shutil\n\nfrom torchvision import transforms","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"disk_folder = '/kaggle/working/'\ndata_folder = '/kaggle/input/classification-of-handwritten-letters/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Merger dataframes\n\ndef ohe_letter(label):\n    result = np.zeros(len(letters))\n    index = letters.index(label)\n    result[index] = 1\n    return result\n\nmain_df = pd.read_csv(data_folder + 'letters.csv')\nmain_df.drop('background', axis=1, inplace=True)\n\nfor i in range(len(main_df)):\n    main_df['file'][i] = os.path.join('letters', main_df['file'][i])\n\nfor root in ['letters2', 'letters3']:\n    tmp_df = pd.read_csv(data_folder + root + '.csv')\n    tmp_df.drop('background', axis=1, inplace=True)\n    for i in range(len(tmp_df)):\n        tmp_df['file'][i] = os.path.join(root, tmp_df['file'][i])\n    main_df = main_df.merge(tmp_df, how='outer')\n    \nmain_df = shuffle(main_df)\nmain_df.head(), main_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"letters = ''\nname_of_letters = ['filename']\nfor letter in main_df.letter.unique():\n    letters += letter\n    name_of_letters.append(letter)\n    \nlabels = main_df.label\n\nclassnames = [i for i in letters]\n\ninputs = main_df['letter'].apply(ohe_letter)\na = []\nfor i in range(len(inputs)):\n    t = [main_df.file.values[i]]\n    for q in inputs[i]:\n        t.append(q)\n    a.append(t)\na\n\nmain_df = shuffle(pd.DataFrame(a, columns = name_of_letters))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for Class in classnames:\n    for phase in ['train', 'valid']:\n        os.makedirs(os.path.join(disk_folder, phase, Class))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df, valid_df = train_test_split(main_df,\n                               test_size=0.15,\n                               random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for index, row in train_df.iterrows():\n    for bukv in classnames:\n        if row[bukv]:\n            shutil.copy(os.path.join(data_folder, row['filename']), os.path.join(disk_folder, 'train', bukv))\n\nfor index, row in valid_df.iterrows():\n    for bukv in classnames:\n        if row[bukv]:\n            shutil.copy(os.path.join(data_folder, row['filename']), os.path.join(disk_folder, 'valid', bukv))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_transforms = {\n    'train':\n    transforms.Compose([\n        transforms.Resize((32, 32)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n    ]),\n    'valid':\n    transforms.Compose([\n        transforms.Resize((32, 32)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n    ]),\n}\n\nimage_datasets = {\n    'train':\n    datasets.ImageFolder(os.path.join(disk_folder, 'train'), data_transforms['train']),\n    \n    'valid':\n    datasets.ImageFolder(os.path.join(disk_folder, 'valid'), data_transforms['valid'])\n}\n\ndataloaders = {\n    'train':\n    DataLoader(image_datasets['train'],\n              batch_size=16,\n              shuffle=True,\n              num_workers=0),\n    \n    'valid':\n    DataLoader(image_datasets['valid'],\n              batch_size=16,\n              shuffle=True,\n              num_workers=0)\n}\n\n\"Data Preprocessing COMPLETED\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n\nmodel = models.resnet18(pretrained=False).to(device)\n\nmodel.fc = nn.Linear(model.fc.in_features, 33).to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.fc.parameters())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, criterion, optimizer, num_epochs=3):\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n        print('-' * 10)\n\n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n\n                if phase == 'train':\n                    optimizer.zero_grad()\n                    loss.backward()\n                    optimizer.step()\n\n                _, preds = torch.max(outputs, 1)\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / len(dataloaders[phase])\n            epoch_acc = running_corrects.double() / len(dataloaders[phase])\n\n            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n                                                        epoch_loss,\n                                                        epoch_acc))\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trained_model = train_model(model, criterion, optimizer, num_epochs=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}