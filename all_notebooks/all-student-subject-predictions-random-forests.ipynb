{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/students-performance-in-exams/StudentsPerformance.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,10))\nsns.countplot(df['gender'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Around an even distribution between Male and Female Students"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\nsns.countplot(df['race/ethnicity'], hue = df['gender'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Around an even distribution of male and females for every gender."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['lunch'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\nsns.countplot(df['lunch'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Getting a free/reduced lunch vs standard lunch may play a part in overall test scores"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['test preparation course'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\nsns.countplot(df['test preparation course'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"More students didn't prepare for their tests than did "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\nsns.countplot(df['race/ethnicity'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Group C and D seem to be the top two most common races in the data set"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\nsns.countplot(df['race/ethnicity'], hue=df['lunch'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\nsns.countplot(df['race/ethnicity'], hue=df['test preparation course'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\nsns.heatmap(df.corr(), annot = True, cmap = 'viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As expected there is a high correlation between reading and writing scores, both being subsets of the language category"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\nsns.pairplot(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Manipulation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating numerical values for categorical data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a list of all the object dtypes\nobjects = list(df.dtypes[df.dtypes == \"object\"].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One Hot Encoding Categorical data\ndf = pd.get_dummies(data = df, columns = objects, drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets create a copy of the df because we will be predicting for all of the different subject scores \n\nmath_df = df.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Model (Math Score Prediction)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = math_df.drop('math score', axis = 1).values\ny = math_df['math score']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting Data into Training and Test Sets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scaling Data\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating Random Forest Model\nrf = RandomForestRegressor(n_estimators=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training Model\nrf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions\npredictions = rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluating Model\n\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('MAE: ', mean_absolute_error(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('MSE: ', mean_squared_error(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('RMSE: ', np.sqrt(mean_squared_error(y_test, predictions)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\nsns.distplot((y_test-predictions), bins = 50, color='gray')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Approximately a normal curve of the residuals which means it was a good model"},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Model (Reading Score Prediction) "},{"metadata":{"trusted":true},"cell_type":"code","source":"reading_df = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = reading_df.drop(\"reading score\", axis = 1).values\ny = reading_df[\"reading score\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scale Data with StandardScaler\n\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating Model\nrf = RandomForestRegressor(n_estimators=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training model\nrf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predictions\n\npredictions = rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluating Model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('MAE: ', mean_absolute_error(y_test, predictions))\nprint('MSE: ', mean_squared_error(y_test, predictions))\nprint('RMSE: ', np.sqrt(mean_squared_error(y_test, predictions)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\nsns.distplot((y_test-predictions), bins = 50, color='gray')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model's residuals is once again a normal curve meaning the model was a good fit. "},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Model (Writing Score Prediction)"},{"metadata":{},"cell_type":"raw","source":"writing_df = df.copy()"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = reading_df.drop(\"writing score\", axis = 1).values\ny = reading_df[\"writing score\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scale Data with StandardScaler\n\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating Model\nrf = RandomForestRegressor(n_estimators=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training model\nrf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predictions\n\npredictions = rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluating the Model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('MAE: ', mean_absolute_error(y_test, predictions))\nprint('MSE: ', mean_squared_error(y_test, predictions))\nprint('RMSE: ', np.sqrt(mean_squared_error(y_test, predictions)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\nsns.distplot((y_test-predictions), bins = 50, color='gray')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Residuals are a normal curve meaning model was a good fit."},{"metadata":{},"cell_type":"markdown","source":"# Conclusion"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Math min score was: {} \".format(df['math score'].min()))\nprint(\"Math max score was: {} \".format(df['math score'].max()))\nprint(\"Reading min score was: {} \".format(df['reading score'].min()))\nprint(\"Reading max score was: {} \".format(df['reading score'].max()))\nprint(\"Writing min score was: {} \".format(df['writing score'].min()))\nprint(\"Writing max score was: {} \".format(df['writing score'].max()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Random Forest Model predicted quite accurately for the Math, Reading, and Writing Scores. The Writing Scores were predicted the most accurately followed by the Reading Scores, and lastly the Math Scores. Considering the large range between scores, the model predicted quite accurately having an error average of around 4 - 6% for all of the subject scores."},{"metadata":{},"cell_type":"markdown","source":"# Please let me know what you think!"},{"metadata":{},"cell_type":"markdown","source":"# Thank You!!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}