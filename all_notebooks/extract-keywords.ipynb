{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## What is Keyword Exctraction?\n\nKeyword extraction is defined as the task that automatically identifies a set of the terms that best describe the subject of document. This is an important method in information retrieval (IR) systems: keywords simplify and speed up the search. Keyword extraction can be used to reduce the dimensionality of text for further text analysis (text classification ot topic modeling). [S.Art et al.](https://onlinelibrary.wiley.com/doi/abs/10.1002/smj.2699), for example, extracted keywords to measure patent similarity. Using keyword extraction, you can automatically index data, summarize a text, or generate tag clouds with the most representative keywords.\n\n## How to extract the keywords?\n\nAll keyword extraction algorithms include the following steps:\n\n- *Candidate generation*. Detection of possible candidate keywords from the text.\n- *Property calculation*. Computation of properties and statistics required for ranking.\n- *Ranking*. Computation of a score for each candidate keyword and sorting in descending order of all candidates. The top n candidates are finally selected as the n keywords representing the text.\n\n## Automatic Keyword extraction algorithms\n\n- Rapid Automatic Keyword Extraction (RAKE). Python implementations: [one](https://github.com/csurfer/rake-nltk), [two](https://github.com/zelandiya/RAKE-tutorial), [three](https://github.com/aneesha/RAKE)\n- TextRank. Python implementations [number one](https://pypi.org/project/summa/) and [number two](https://radimrehurek.com/gensim/summarization/keywords.html)\n- [Yet Another Keyword Extractor (Yake)](https://github.com/LIAAD/yake)\n\n\n## If you want to know more...\n- [Slobodan Beliga.](https://pdfs.semanticscholar.org/bdbf/25f3dcf63d38cdb527a9ffca269fa0b8046b.pdf) Keyword extraction: a review of methods and approache\n- [Kamil Bennani-Smires et al.](https://arxiv.org/pdf/1801.04470.pdf) Simple Unsupervised Keyphrase Extraction using Sentence Embeddings\n- [YanYing et al.](https://www.sciencedirect.com/science/article/pii/S1877050917303629) A Graph-based Approach of Automatic Keyphrase Extraction\n- [Martin Dostal and Karel Jezek](http://ceur-ws.org/Vol-706/poster13.pdf) Automatic Keyphrase Extraction based on NLP and Statistical Methods","metadata":{}},{"cell_type":"markdown","source":"# REQUIRED PART OF THE WORK  \"EXTRACT TOP WORDS\" ","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-02T14:44:18.874939Z","iopub.execute_input":"2021-06-02T14:44:18.875242Z","iopub.status.idle":"2021-06-02T14:44:18.883933Z","shell.execute_reply.started":"2021-06-02T14:44:18.875191Z","shell.execute_reply":"2021-06-02T14:44:18.883006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the dataset\ndf = pd.read_excel('../input/invisalign-modif/invisalign modif.xlsx')\ndf.head()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-06-02T14:44:18.890819Z","iopub.execute_input":"2021-06-02T14:44:18.891373Z","iopub.status.idle":"2021-06-02T14:44:21.635303Z","shell.execute_reply.started":"2021-06-02T14:44:18.891321Z","shell.execute_reply":"2021-06-02T14:44:21.634285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport string\nimport nltk\n\nimport pandas as pd\n\nfrom collections import Counter\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\n\nnltk.download('punkt')\nnltk.download('stopwords')\n\nSTOP_WORDS = stopwords.words()\n\n# removing the emojies\n# https://www.kaggle.com/alankritamishra/covid-19-tweet-sentiment-analysis#Sentiment-analysis\nEMOJI_PATTERN = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n\n\ndef cleaning(text):\n    \"\"\"\n    Convert to lowercase.\n    Rremove URL links, special characters and punctuation.\n    Tokenize and remove stop words.\n    \"\"\"\n    text = text.lower()\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('[’“”…]', '', text)\n\n    text = EMOJI_PATTERN.sub(r'', text)\n\n    # removing the stop-words\n    text_tokens = word_tokenize(text)\n    tokens_without_sw = [\n        word for word in text_tokens if not word in STOP_WORDS]\n    filtered_sentence = (\" \").join(tokens_without_sw)\n    text = filtered_sentence\n\n    return text\n\n\ndt = df['Tweet Text'].apply(cleaning)\n\nword_count_10 = Counter(\" \".join(dt).split()).most_common(10)\nword_count_100 = Counter(\" \".join(dt).split()).most_common(100)\nword_frequency_10 = pd.DataFrame(word_count_10, columns = ['Word', 'Frequency'])\nword_frequency_100 = pd.DataFrame(word_count_100, columns = ['Word', 'Frequency'])\nprint(word_frequency_10)\nprint(word_frequency_100)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T14:47:52.431319Z","iopub.execute_input":"2021-06-02T14:47:52.431649Z","iopub.status.idle":"2021-06-02T14:48:54.551268Z","shell.execute_reply.started":"2021-06-02T14:47:52.431588Z","shell.execute_reply":"2021-06-02T14:48:54.550502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_frequency_10.to_excel(\"./TOP 10.xlsx\")\nword_frequency_100.to_excel(\"./TOP 100.xlsx\")","metadata":{"execution":{"iopub.status.busy":"2021-06-02T14:45:23.632942Z","iopub.execute_input":"2021-06-02T14:45:23.633378Z","iopub.status.idle":"2021-06-02T14:45:23.664718Z","shell.execute_reply.started":"2021-06-02T14:45:23.63333Z","shell.execute_reply":"2021-06-02T14:45:23.664104Z"},"trusted":true},"execution_count":null,"outputs":[]}]}