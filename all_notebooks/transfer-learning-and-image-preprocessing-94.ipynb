{"cells":[{"metadata":{"collapsed":true,"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nfrom pandas import HDFStore, DataFrame\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport h5py # library for processing h5 file\nfrom keras.utils import to_categorical  \nfrom sklearn.model_selection import train_test_split\n\nnp.random.seed(105208) # for reproducibility\n# import basic Keras function  \nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization\nfrom keras.layers import Conv2D, MaxPool2D\nfrom keras.optimizers import Adam\nfrom keras.initializers import Initializer\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator  #Easy to use api for generate images on the run\nfrom keras.applications.xception import Xception  # Pre trained model\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4198a915-7fd2-4b19-af36-c62a03efb8ef","_uuid":"e493be66d03781695a805e9ba47eeecb9195c437"},"cell_type":"markdown","source":"# Overview \n**In this notebook I'm trying to predict from where traditional decoration products are. Database contains photos sorted by countries and pattern types with names of famous traditional decor styles.  <br>\n**\n<br>\n**Main dataset contains only 485 color images (150 x 150 x 3) of traditional decoration patterns and products** <br> \n**Some examples : ** <br> \n![](https://image.ibb.co/k5BYDn/02_07_2_007.png)\n![](https://image.ibb.co/bxatDn/02_07_1_005.png)\n![](https://image.ibb.co/ggJDDn/02_07_2_032.png)\n<br> \n<br>\n\n# At first load and explore data "},{"metadata":{"collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"# read and look on head of images\ndf = pd.read_csv(\"../input/traditional-decor-patterns/decor.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"0a3f761b-7c44-4621-970e-4a199493b599","_uuid":"ad286e7179068f5dec96a24d772d768aa85e1df9","trusted":false},"cell_type":"code","source":"# create new column with Country-pattern it can by useful for recogintion task\ndf['country_decor'] = df[['country', 'decor']].apply(lambda x: '-'.join(x), axis=1)\ndf['type_country_decor'] = pd.factorize(df.country_decor)[0]\n\ncountry = df.country.unique()\ndecor = df.decor.unique()\ntypeOf = df.type.unique()\nproductDf = df[df['type'] == 'product']\ncoutryDecor = df.country_decor.unique()\n\ndef lookAt(data):\n    return \", \".join(str(x) for x in data)\n        \n\nprint(\"Country: \" + lookAt(country))\nprint(\"Decor: \" + lookAt(decor))\nprint(\"Type: \" + lookAt(typeOf))\nprint(\"Decor with Country: \" + \", \".join(str(x) for x in coutryDecor))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"0104602c-fcd5-4248-ad13-5e212180646b","_uuid":"056759724685ffa1284f98d32c1cdf54fe1cdfe0","trusted":false},"cell_type":"code","source":"def createHist(data, xlabel = None, ylabel = None, title = None, grid = True, size = (5, 5)):\n    plt.figure(figsize=size)\n    plt.hist(data)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.title(title)\n    plt.grid(True)\n    plt.show()\n    \ncreateHist(df.country, xlabel = 'Country', ylabel = \"Count\", title = \"Country Distribution\", grid = True)\ncreateHist(df.decor, xlabel = 'Decor', ylabel = \"Count\", title = \"Decor Distribution\", grid = True, size = (12, 10))\ncreateHist(df.country_decor, xlabel = 'Country with decor', ylabel = \"Count\", title = \"Decor grouped by coutry\", grid = True, size = (20, 10))\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"641f9863-e132-44f9-8ea4-d2da14200d7c","_uuid":"bc9ec576051ceeebdb0ae3adb8d2af7449383249","trusted":false},"cell_type":"code","source":"# read h5 file \nf = h5py.File('../input/traditional-decor-patterns/DecorColorImages.h5', 'r')\nkeys = list(f.keys())\nkeys","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"836a160a-b248-484a-b318-e8f1cfc9a795","_uuid":"f89971c4e0486a042a4d437dd83d708ac2413819","trusted":false},"cell_type":"code","source":"images = np.array(f[keys[2]])\n\nfig = plt.figure(figsize=(10, 10))\nfor idx in range(25):\n    num = 100\n    if(idx % 5 == 0):\n        num += 50\n    plt.subplot(5,5, idx + 1)\n    plt.imshow(images[num + idx])\n    \nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"91d062ea-76a9-470c-9ed8-bce4a59c7993","_uuid":"321b339fb2777e894e076d60c3c21ffeabd82cbe"},"cell_type":"markdown","source":"## Processing data for train model\n\nWe don't have many images for specific type of decor. The largest are decors from Russia +250 images. <br> \nWe use all of products / patterns images becouse it can be usefull for prediction. <br>\nPatern is the same on product as on image of pattern. so we can use it. <br> \n"},{"metadata":{"collapsed":true,"_cell_guid":"653a999d-31e6-4113-a894-400acc25c0bc","_uuid":"5cbf40f8368c9cdf00ea57e2f557f0f810cd52f6","trusted":false},"cell_type":"code","source":"# Create tensors and targets\ncountries = np.array(f[keys[0]])\ndecors = np.array(f[keys[1]])\ntypes = np.array(f[keys[3]])\n\nprint ('Country shape:', countries.shape)\nprint ('Decor shape', decors.shape)\nprint ('Image shape:', images.shape)\nprint ('Type shape', types.shape)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"9ee03318-94c5-40d5-8b55-01cd4ebf2846","_uuid":"215d38d48598ddf33debdbf2e63a0187481c831e","trusted":false},"cell_type":"code","source":"# Normalize the images\nimages = images.astype('float32') / 255\ncat_countries = to_categorical(np.array(countries-1), 4)\ncat_decors = to_categorical(np.array(decors-1), 7)\ntargets = np.concatenate((cat_countries, cat_decors), axis=1)\nconcatTargets = np.concatenate((countries, decors))\n\ncat_countries.shape, cat_decors.shape, targets.shape","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"4188713f-83ca-4a41-9c19-1c5bdef0fdca","_uuid":"7e325ebb04ddbc94c0937a7d1144c48bb42ba261","trusted":false},"cell_type":"code","source":"img_rows, img_cols = 150, 150\nX_train, X_test, y_train, y_test = train_test_split(images, cat_countries, test_size=0.2, random_state=42)\ninput_shape = (img_rows, img_cols, 3)\nnum_classes = y_test.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"de23a822-84b2-4132-ad5c-04d86a879fe1","_uuid":"1aab9f6c7fedf1861910571c6ee99bf6626e8522"},"cell_type":"markdown","source":"# Create predict models \n\nNow we will create some models to check which could be best for our data.  We have only **485** images so keep in mind that. <br> \nAs we'll see Keras Api for images augmentation  and Transfer Learning comes with help and avoid **over/under fitting**.\n#### This is our plan : \n* [Create simply CNN network with existing data](#section2)\n* [Simply CNN with Keras Image Generator API](#section3)\n* [Xception model with frozen all layers](#section4)\n* [Xception model with unfrozen last 10 layers](#section5)\n* [Model predict function](#section6)"},{"metadata":{"collapsed":true,"_cell_guid":"9b5822b2-0db0-4d40-951f-af53f507dd44","_uuid":"4ff04bf6fdbe9739b2e4c4314ed5e723a5633dbd","trusted":false},"cell_type":"code","source":"# draw learing curve to avoid overfitting\ndef draw_learning_curve(history, key='acc', ylim=(0, 1.01)):\n    plt.figure(figsize=(15,15))\n    plt.plot(history.history[key])\n    plt.plot(history.history['val_' + key])\n    plt.title('Learning Curve')\n    plt.ylabel(key.title())\n    plt.xlabel('Epoch')\n    plt.ylim(ylim)\n    plt.legend(['train', 'test'], loc='best')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"208610d8-b3b6-4d52-9532-a5036f226c81","_uuid":"edf836f9315b0605fc25960b966162fa0e663cac"},"cell_type":"markdown","source":"<a id='section2'></a>"},{"metadata":{"collapsed":true,"_cell_guid":"34f8c548-1d38-4d5e-afab-f09e4d1f7553","_uuid":"f8eae4e53dbdba827649fae1c08d3f9b4c3b4cf8","trusted":false},"cell_type":"code","source":"# create CNN model and first check only on our data\ndef get_simple_cnn():\n    return Sequential([\n        Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n        MaxPool2D(pool_size=(2, 2)),\n      \n        Conv2D(64, kernel_size=(3, 3), activation='relu', kernel_initializer = 'glorot_normal'),\n        MaxPool2D(pool_size=(2, 2)),\n        Dropout(0.5),\n        \n        Conv2D(128, kernel_size=(3, 3), activation='relu', kernel_initializer = 'glorot_normal'),\n        MaxPool2D(pool_size=(2, 2)),\n        Dropout(0.5),\n        \n        Flatten(), #<= bridge between conv layers and full connected layers\n        \n        Dense(128, activation='relu', kernel_initializer = 'glorot_normal'),\n        Dropout(0.25),\n        Dense(num_classes, activation='softmax')\n    ])\n\nget_simple_cnn().summary()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"18f35d54-113e-4951-afcb-41cc82cf2341","_uuid":"083aa26295a17221003659ac3bf194fba990889c","trusted":false},"cell_type":"code","source":"def trainModel(model, X_train, y_train, X_test, y_test, batch_size, epochs, optimizer = 'Adam'):\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    history = model.fit(X_train, y_train,\n              batch_size=batch_size,\n              epochs=epochs,\n              verbose=1,\n              validation_data=(X_test, y_test))\n    score = model.evaluate(X_test, y_test, verbose=0)\n    print('Test loss:', score[0])\n    print('Test accuracy:', score[1])\n    print(\"Network Error: %.2f%%\" % (100-score[1]*100))\n    draw_learning_curve(history, 'acc')\n    return history","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"c5185c36-187f-4a08-9136-8f74f5f4a0eb","_uuid":"89682055c2f623f49b7414b83f466d16036ebd05","trusted":false},"cell_type":"code","source":"trainModel(get_simple_cnn(), X_train, y_train, X_test, y_test, 32, 50, optimizer = 'Adam')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"375544e5-01f0-47e8-82b9-68ce4759d93e","_uuid":"cc5a3dc1c0468e585fdd09f2024388e9ab46e5ac"},"cell_type":"markdown","source":"<a id='section3'></a>"},{"metadata":{"collapsed":true,"scrolled":true,"_cell_guid":"e45a3add-9443-41f0-bcfc-2ef93d541ef0","_uuid":"6b3f746d481f1df21876d370530813d40e86a9aa","trusted":false},"cell_type":"code","source":"# Make more data with Image Generator api from Keras. \n# Images generate on the run so we don't have to save any of them.\ndatagen = ImageDataGenerator(\n        featurewise_center=False,\n        rotation_range=60,\n        horizontal_flip=True,\n        vertical_flip=True,\n        width_shift_range=0.2, \n        height_shift_range=0.2)\n\ndef modelWithGenData(model, datagen, X_train, y_train, X_test, y_test, batch_size = 32, steps_per_epoch = len(X_train), epochs = 20):\n\n    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n\n    # create more data on the run\n    datagen.fit(X_train)\n    model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n                        steps_per_epoch=steps_per_epoch,\n                        epochs=epochs,\n                        validation_data=(X_test, y_test))\n    model.save('CNN_model.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"6e076059-a072-4e4a-9d70-07f5a60d959d","_uuid":"4f76a018cff76dfd222df601e5eb989b85d67128","trusted":false},"cell_type":"code","source":"modelWithGenData(get_simple_cnn(), datagen, X_train, y_train, X_test, y_test, batch_size = 32, epochs = 50)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"95178dc8-0224-42c4-acc8-af46cc4d4405","_uuid":"8d95e246e82d2a4e1c9919360a4f5652d5f8bf65","trusted":false},"cell_type":"code","source":"# reshape images from (150 x 150 x 3) to (197 x 197 x 3) \ntransferImage = np.zeros((485, 197, 197, 3))\ntransferImage[:images.shape[0], :images.shape[1], :images.shape[2], :images.shape[3]] = images","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"a9ca92df-d145-4275-89a8-b579fc7b848b","_uuid":"e2cb4495857dd1e927bd5583bf4eb4f9dd8a8d35","trusted":false},"cell_type":"code","source":"#Generate new X, y test / train set\nX_train, X_test, y_train, y_test = train_test_split(transferImage, targets, test_size=0.25, random_state=42)\nnum_classes = y_test.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"592e74da-383c-4375-a235-6ee5a88f44c5","_uuid":"a755b8f3ed7ce7065298debfc11de64220a74e82"},"cell_type":"markdown","source":"<a id='section4'></a>"},{"metadata":{"_cell_guid":"8c2364bc-612e-47fb-9638-e858819cf0e5","_uuid":"d1f4b1067c911685ed1bf48826ec67aac9faf03f"},"cell_type":"markdown","source":"### Load pretrained Xception model \n  \n**Model architecture : **\n![](https://image.ibb.co/gNzjM7/Xceptionmodel.jpg)  \nFor more information about this model check :  \n**[Xception: Deep Learning with Depthwise Separable Convolutions](https://arxiv.org/pdf/1610.02357.pdf)**  \n  \n**[An Intuitive Guide to Deep Network Architectures](https://www.kdnuggets.com/2017/08/intuitive-guide-deep-network-architectures.html/2)**  "},{"metadata":{"collapsed":true,"_cell_guid":"abc1917b-9e5b-4e23-a57b-6310b3df3213","_uuid":"169bff1b5932cb8b6ffe976d09003e18ee522779","trusted":false},"cell_type":"code","source":"# Base model with Transfer Learning \nbaseModel = Xception(weights=\"../input/keras-pretrained-models/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\", \n                        include_top=False,\n                       input_shape = (197, 197, 3))\nfor layer in baseModel.layers:\n    layer.trainable = False\n\ntransferModel = Sequential([\n    baseModel,\n    \n    Flatten(), #<= bridge between conv layers and full connected layers\n        \n    Dense(128, activation='relu'),\n    Dropout(0.7),\n    Dense(num_classes, activation='sigmoid')\n    \n])\n\noptimizer = Adam(0.0005, decay=0.0005)\ntransferModel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n\nhistory = transferModel.fit(X_train, y_train,\n          batch_size=8,\n          epochs=5,\n          verbose=1,\n          validation_data=(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"c6434c8d-3660-48a3-ab3d-45afe37a0f47","_uuid":"889b79b1847674f927bc85bb09a3dc7bd3764ac9","trusted":false},"cell_type":"code","source":"#unFreeze 10 layers \nfor layer in baseModel.layers[-10:]:\n    layer.trainable = True\n\nfor it, layer in enumerate(baseModel.layers):\n    print(it, layer.name, layer.trainable)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"13025247-7e80-436c-ab79-73557e685324","_uuid":"a3507ed8a3f1b4ab465cc0ddbb04f03a37ff7122"},"cell_type":"markdown","source":"<a id='section5'></a>"},{"metadata":{"collapsed":true,"_cell_guid":"5ed6a89e-25ff-4e35-8962-8897ac6a563e","_uuid":"39abb7ea1f14e3c296772a43d640610f01975d13","trusted":false},"cell_type":"code","source":"# Images generate on the run so we don't have to save any of them.\ndatagen = ImageDataGenerator(\n        featurewise_center=False,\n        rotation_range=60,\n        horizontal_flip=True,\n        vertical_flip=True,\n        width_shift_range=0.2, \n        height_shift_range=0.2)\n\ndatagen.fit(X_train)\n\ntransferModel = Sequential([\n    baseModel,\n    \n    Flatten(), #<= bridge between conv layers and full connected layers\n        \n    Dense(128, activation='relu'),\n    Dropout(0.25),\n    Dense(64, activation='relu'),\n    Dropout(0.25),\n    Dense(num_classes, activation='sigmoid')\n    \n])\n\noptimizer = Adam(0.00001, decay=0.00001, amsgrad=True)\ntransferModel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n\nhistory = transferModel.fit_generator(datagen.flow(X_train, y_train, batch_size=64),\n                        steps_per_epoch=len(X_train),\n                        epochs=15,\n                        validation_data=(X_test, y_test))\n\ntransferModel.save('general_weights.h5')","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"a54adf50-bde2-4322-a511-cec4eeb723da","_uuid":"30dc1fced1daf7969bdbdbe2f7fd456c2eb62af7","trusted":false},"cell_type":"code","source":"draw_learning_curve(history)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"26614b78-aac1-44f7-87c5-767b260ee0dc","_uuid":"4301af299372fe0b427c488f9f3056b2e75243a3"},"cell_type":"markdown","source":"| Algorithm | Epochs | Batch Size | Optimizer | Image Augmentation | Score |\n| --- | --- | --- | --- | --- |\n| CNN **(country only )** | 50 | 32 | Adam | No | **76.29 %** |\n| CNN **(country only )** | 50 | 32 | Adam | Yes | **92.78 %** |\n| Xception **(Frozen layers)** | 5 | 8 | Adam | No | **83.08 %** |\n| Xception **(Unfrozen layers)** | 15 | 64 | Adam | Yes | **93.37 %** |"},{"metadata":{"_cell_guid":"d02b2e07-651f-4665-9030-d1290c6928b6","_uuid":"88c18ea4ac3f84858ef3d3cef86687e776974146"},"cell_type":"markdown","source":"<a id='section6'></a> <br>\n\n### If You use Images from this dataset please compile everything before Create predict models section."},{"metadata":{"_cell_guid":"1c5dcede-bbd9-4a73-8eeb-ae8e3735f53c","_uuid":"d70791929b129149dfc4db12b364e1155eb721ae","trusted":false,"collapsed":true},"cell_type":"code","source":"#load pretrained weights\nfrom keras.models import load_model\n\nnew_model = load_model('general_weights.h5')","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"779a965f-bdd3-4038-a6fe-df3fbef707de","_uuid":"81175bf364af75d57705bd82b338af55c3dd8110","trusted":false},"cell_type":"code","source":"def predictImage(imagePath, fromData = True):\n    # split path for image\n    data = df[df.file == imagePath.split(\"/\")[-1]]\n    index = int(data.index[0])\n    img = images[index]\n    plt.imshow(img)\n    # reshape images from (150 x 150 x 3) to (197 x 197 x 3) \n    reshapeImage = np.zeros((197, 197, 3))\n    reshapeImage[:img.shape[0], :img.shape[1], :img.shape[2]] = img\n    reshapeImage = np.reshape(reshapeImage, (1, 197, 197, 3))\n    #predict Value for specyfic Image\n    predict = new_model.predict(reshapeImage)\n    predictIndex = predict.argsort()[0][-2:]\n    #print answer\n    print(\"Predict Country: \" + country[min(predictIndex)] + \", predict decor: \" + decor[max(predictIndex) - 4])\n    print(\"Real Country: \" + data.country.to_string(index = False) + \", real decor: \" + data.decor.to_string(index = False))\n    print(\"Type of Image: \" + data.type.to_string(index = False))\n    countryTrue = data.country.to_string(index = False) == country[min(predictIndex)]\n    decorTrue = decor[max(predictIndex) - 4] == data.decor.to_string(index = False)\n    print(\"Predict of country: \" + str(countryTrue) + '. Predict of decor: ' + str(decorTrue))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"47d2fbc2-f6ce-46b2-b063-751d5fcc74f2","_uuid":"1958c20d0c8d29abae2b875a1ed5bbb6eb5a8c93","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"d51db324-fa58-411f-87c8-bdbc3ee3596c","_uuid":"56e9272a7feaf647af87260cb6b1ef1063a14f5d","trusted":false},"cell_type":"code","source":"#check our model\npath = '../input/traditional-decor-patterns/decor/01_01_2_041.png'","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"5252bade-8cec-48ed-b0fc-9082e133a6e1","_uuid":"39175bb8577bace89b68e6c0d2e27c23ff4e4612","trusted":false},"cell_type":"code","source":"predictImage(path)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"54370746-5b1e-4af4-9b45-2c749639d754","_uuid":"319b4bdeeffc59ad495a0a0a20c2f898bf185d95","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}