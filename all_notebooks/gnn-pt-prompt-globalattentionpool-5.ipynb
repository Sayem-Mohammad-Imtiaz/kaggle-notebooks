{"cells":[{"metadata":{},"cell_type":"markdown","source":"v1 - complete-3MPL-attention_pool-FCNN-0.79(86/73)-0.98<br>\nv3 - complete-2MPL-attention_pool-2MPL-attention_pool-concat_attention-FCNN-0.50(85/36)-0.96<br>\nv4 - complete-2MPL-attention_pool-2MPL-attention_pool-2MPL-attention_pool-concat_attention-FCNN-0.80(87/73)-0.98<br>\nv5 - adjacent-3MPL-attention_pool-FCNN-0.54(88/39)-0.97<br>\nv6 - adjacent-2MPL-attention_pool-2MPL-attention_pool-concat_attention-FCNN-0.83(89/77)-0.98<br>\nv7 - adjacent-2MPL-attention_pool-2MPL-attention_pool-2MPL-attention_pool-concat_attention-FCNN-0.83(89/78)-0.98<br>\nv10 - adjacent-2TAGConv-attention_pool-2TAGConv-attention_pool-2TAGConv-attention_pool-concat_attention-FCNN<br>\nv10 - 6167-0.53(87/38)-0.97<br>\nv11 - adjacent-2SGConv-attention_pool-2SGConv-attention_pool-2SGConv-attention_pool-concat_attention-FCNN<br>\nv11 - 8166-0.05(89/02)-0.95<br>\nv12 - adjacent-2RGCNConv-attention_pool-2RGCNConv-attention_pool-2RGCNConv-attention_pool-concat_attention-FCNN<br>\nv12 - 8002-0.14(75/07)-0.95<br>\nv13 - adjacent-2MFConv-attention_pool-2MFConv-attention_pool-2MFConv-attention_pool-concat_attention-FCNN<br>\nv13 - 6142-0.54(87/40)-0.97<br>\nv14 - adjacent-2LEConv-attention_pool-2LEConv-attention_pool-2LEConv-attention_pool-concat_attention-FCNN<br>\nv14 - 2874-0.83(89/79)-0.98<br>\nv15 - adjacent-2HypergraphConv-attention_pool-2HypergraphConv-attention_pool-2HypergraphConv-attention_pool-concat_attention-FCNN<br>\nv15 - 6249-0.54(78/41)-0.96<br>\nv16 - adjacent-2HypergraphConv(att)-attention_pool-2HypergraphConv(att)-attention_pool-2HypergraphConv(att)-attention_pool-concat_attention-FCNN<br>\nv16 - 5949-0.51(87/36)-0.96<br>\nv17 - adjacent-2GravNetConv-attention_pool-2GravNetConv-attention_pool-2GravNetConv-attention_pool-concat_attention-FCNN<br>\nv17 - 4282-0.71(84/62)-0.97<br>\nv18 - adjacent-2GraphConv-attention_pool-2GraphConv-attention_pool-2GraphConv-attention_pool-concat_attention-FCNN<br>\nv18 - 3352-0.79(88/73)-0.98<br>\nv19 - adjacent-2Sageconv-attention_pool-2Sageconv-attention_pool-2Sageconv-attention_pool-concat_attention-FCNN<br>\nv19 - 2882-0.83(89/78)-0.98<br>\nv20 - adjacent-2GatedGraphConv-attention_pool-2GatedGraphConv-attention_pool-2GatedGraphConv-attention_pool-concat_attention-FCNN<br>\nv20 - 8995-0-0.95<br>\nv21 - adjacent-2GINConv-attention_pool-2GINConv-attention_pool-2GINConv-attention_pool-concat_attention-FCNN<br>\nv21 - 8942-0-0.95<br>\nv22 - adjacent-2GCNConv-attention_pool-2GCNConv-attention_pool-2GCNConv-attention_pool-concat_attention-FCNN<br>\nv22 - 7009-0.20(86/11)-0.95<br>\nv23 - adjacent-2GATConv-attention_pool-2GATConv-attention_pool-2GATConv-attention_pool-concat_attention-FCNN<br>\nv23 - 7079-0.34(84/21)-0.96<br>\nv24 - adjacent-2EdgeConv-attention_pool-2EdgeConv-attention_pool-2EdgeConv-attention_pool-concat_attention-FCNN<br>\nv24 - 2747-0.84(89/79)-0.98<br>\nv25 - adjacent-2FeaStConv-attention_pool-2FeaStConv-attention_pool-2FeaStConv-attention_pool-concat_attention-FCNN<br>\nv25 - 7686-0.20(88/11)-0.95<br>\nv26 - adjacent-2DynamicEdgeConv-attention_pool-2DynamicEdgeConv-attention_pool-2DynamicEdgeConv-attention_pool-concat_attention-FCNN<br>\nv27 - adjacent-2ClusterGCNConv-attention_pool-2ClusterGCNConv-attention_pool-2ClusterGCNConv-attention_pool-concat_attention-FCNN<br>\nv27 - 2985-0.83(87/78)-0.98<br>\nv28 - adjacent-2ChebConv-attention_pool-2ChebConv-attention_pool-2ChebConv-attention_pool-concat_attention-FCNN<br>\nv28 - 2975-0.82(89/77)-0.98<br>\nv29 - adjacent-2CGConv-attention_pool-2CGConv-attention_pool-2CGConv-attention_pool-concat_attention-FCNN<br>\nv29 - 2995-0.83(88/79)-0.98<br>\nv30 - adjacent-2ARMAConv-attention_pool-2ARMAConv-attention_pool-2ARMAConv-attention_pool-concat_attention-FCNN<br>\nv30 - 2855-0.83(89/79)-0.98<br>\nv33 - adjacent-2AGNNConv-attention_pool-2AGNNConv-attention_pool-2AGNNConv-attention_pool-concat_attention-FCNN<br>\nv33 - 7188-0.33(86/20)-0.96<br>\nv34 - adjacent-2APPNP-attention_pool-2APPNP-attention_pool-2APPNP-attention_pool-concat_attention-FCNN<br>\nv34 - 6376-0.51(83/37)-0.96<br>\nv37 - EdgeConv only - No Fully Connected Layers<br>\nv38 - EdgeConv only II - No Fully Connected Layers<br>\nv39 - ARMAConv only - No Fully Connected Layers<br>\nv40 - ARMAConv only II - No Fully Connected Layers<br>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!python -c \"import torch; print(torch.__version__)\"\n!python -c \"import torch; print(torch.version.cuda)\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip -qq install torch==1.5.1+cpu torchvision==0.6.1+cpu -f https://download.pytorch.org/whl/torch_stable.html\n! pip -qq install torch-scatter==latest+cpu -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n! pip -qq install torch-sparse==latest+cpu -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n! pip -qq install torch-cluster==latest+cpu -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n! pip -qq install torch-spline-conv==latest+cpu -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n! pip -qq install torch-geometric","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ! pip -qq install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n# ! pip -qq install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n# ! pip -qq install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n# ! pip -qq install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n# ! pip -qq install torch-geometric","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import os\nimport time\nimport random\nfrom tqdm.notebook import tqdm\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom joblib import Parallel, delayed\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nimport torch\nimport torch.nn.functional as F\nimport torch_geometric.nn as gnn\nfrom torch_geometric.nn import MessagePassing\nfrom torch_geometric.data import Dataset, Data, DataLoader\nfrom torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/cmsnewsamples/new-smaples.csv').drop(columns = 'Unnamed: 0')\ndf = df.drop(columns = [i for i in df.columns if '_1' in i])\ndf['non_hits'] = df[[i for i in df.columns if 'mask' in i]].sum(axis=1)\ndf = df[df['non_hits']==0].reset_index(drop=True)\n\ndf['1/pT'] = df['q/pt'].abs()\ndef label(a):\n    if a<=10:\n        return 0\n    if a>10 and a<=30:\n        return 1\n    if a>30 and a<=100:\n        return 2\n    if a>100:\n        return 3\n\ndf['pT'] = 1/df['1/pT']\n    \ndf['pT_classes'] = df['pT'].apply(label)\n\nfeatures = ['emtf_phi_'+str(i) for i in [0,2,3,4]] + ['emtf_theta_'+str(i) for i in [0,2,3,4]] + ['fr_'+str(i) for i in [0,2,3,4]] + ['old_emtf_phi_'+str(i) for i in [0,2,3,4]]\nlabels_1 = ['pT']\nlabels_2 = ['pT_classes']\nlabels_3 = ['vx']\n\nscaler_1 = StandardScaler()\ndf[features] = scaler_1.fit_transform(df[features])\n\nscaler_3 = MinMaxScaler()\ndf[labels_3] = scaler_3.fit_transform(df[labels_3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shuffled_list = list(range(len(df)))\nrandom.Random(242).shuffle(shuffled_list)\nshuffled_list = np.array_split(np.array(shuffled_list), 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"edge_index = torch.tensor([(0,1),(1,2),(2,3),(3,2),(2,1),(1,0)], dtype=torch.long).T\nX_data = df[features].to_numpy()\nY_data = df[labels_1].to_numpy()\ndef process_data(i):\n  graph = X_data[i].reshape(-1,4).T\n  y = Y_data[i]\n  data = Data(x=torch.tensor(graph, dtype=torch.float), y=torch.tensor(y, dtype=torch.float), edge_index=edge_index)\n  return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TriggerDataset(Dataset):\n    def __init__(self, root, indexes=list(range(len(df))), transform=None, pre_transform=None):\n        super(TriggerDataset, self).__init__(root, transform, pre_transform)\n        self.indexes = indexes\n        self.length = len(self.indexes)\n\n    @property\n    def raw_file_names(self):\n        return ['vgc']\n\n    @property\n    def processed_file_names(self):\n        return ['vghv']\n\n    def download(self):\n        return None\n\n    def process(self):\n        return None\n\n    def len(self):\n        return self.length\n\n    def get(self, idx):\n        return process_data(self.indexes[idx])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MPL(MessagePassing):\n    def __init__(self, in_channels, out_channels):\n        super(MPL, self).__init__(aggr='max') #  \"Max\" aggregation.\n        self.mlp = torch.nn.Linear(in_channels*2, out_channels)\n\n    def forward(self, x, edge_index):\n        return self.propagate(edge_index, x=x)\n\n    def message(self, x_i, x_j):\n        msg = F.relu(self.mlp(torch.cat([x_i, x_j], dim=1)))\n        return msg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MPNN(torch.nn.Module):\n    def __init__(self):\n      super(MPNN, self).__init__()\n      self.conv1 = gnn.ARMAConv(4,128 )\n      self.conv2 = gnn.ARMAConv(128,32)\n      self.conv3 = gnn.ARMAConv(32,64 )\n      self.conv4 = gnn.ARMAConv(64,32 )\n      self.conv5 = gnn.ARMAConv(32,32 )\n      self.conv6 = gnn.ARMAConv(32,32 )\n      self.conv7 = gnn.ARMAConv(32,32 )\n      self.conv8 = gnn.ARMAConv(32,32 )\n      self.conv9 = gnn.ARMAConv(32,32 )\n      self.conv10 = gnn.ARMAConv(32,32 )\n      self.lin1 = torch.nn.Linear(160, 1)\n      self.global_att_pool1 = gnn.GlobalAttention(torch.nn.Sequential(torch.nn.Linear(32, 1)))\n      self.global_att_pool2 = gnn.GlobalAttention(torch.nn.Sequential(torch.nn.Linear(32, 1)))\n      self.global_att_pool3 = gnn.GlobalAttention(torch.nn.Sequential(torch.nn.Linear(32, 1)))\n      self.global_att_pool4 = gnn.GlobalAttention(torch.nn.Sequential(torch.nn.Linear(32, 1)))\n      self.global_att_pool5 = gnn.GlobalAttention(torch.nn.Sequential(torch.nn.Linear(32, 1)))\n\n    def forward(self, data):\n      x, edge_index, batch = data.x, data.edge_index, data.batch\n      x = F.relu(self.conv1(x, edge_index))\n      x = F.relu(self.conv2(x, edge_index))\n      x1 = self.global_att_pool1(x, batch)\n      x = F.relu(self.conv3(x, edge_index))\n      x = F.relu(self.conv4(x, edge_index))\n      x2 = self.global_att_pool2(x, batch)\n      x = F.relu(self.conv5(x, edge_index))\n      x = F.relu(self.conv6(x, edge_index))\n      x3 = self.global_att_pool3(x, batch)\n      x = F.relu(self.conv7(x, edge_index))\n      x = F.relu(self.conv8(x, edge_index))\n      x4 = self.global_att_pool4(x, batch)\n      x = F.relu(self.conv9(x, edge_index))\n      x = F.relu(self.conv10(x, edge_index))\n      x5 = self.global_att_pool5(x, batch)\n      x = torch.cat([x1, x2, x3, x4, x5], dim=1)\n      x = self.lin1(x).squeeze(1)\n\n      return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 512\nepochs = 50","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mse(outputs, labels):\n    weights = torch.tensor(labels<80, dtype=torch.float).to(device)*labels + torch.tensor(labels>=80, dtype=torch.float).to(device)*torch.tensor(labels<160, dtype=torch.float).to(device)*labels*2.4 + torch.tensor(labels>=160, dtype=torch.float).to(device)*10\n    error = weights*(((outputs-labels)/labels)**2)\n    return torch.mean(error)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndef train_fn(val_batch=1, test_batch=2):\n\n    train_loader = DataLoader(TriggerDataset('./',np.concatenate([shuffled_list[j] for j in range(10) if j not in (val_batch, test_batch)])), batch_size=batch_size, shuffle=True, num_workers = 4) \n    val_loader = DataLoader(TriggerDataset('./',shuffled_list[val_batch]), batch_size=batch_size) \n    test_loader = DataLoader(TriggerDataset('./',shuffled_list[test_batch]), batch_size=batch_size)\n\n    model = MPNN().to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=1, factor=0.5)\n    \n    m_train_loss = []\n    m_val_loss = []\n    m_test_loss = []\n    min_val_loss = float('inf')\n    for epoch in range(epochs):\n      train_loss = 0\n      val_loss = 0\n      pbar = tqdm(train_loader)\n      for data in pbar:\n        data = data.to(device)\n        optimizer.zero_grad()\n        outputs = model(data)\n        labels = data.y\n        loss = mse(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        pbar.set_description('MSELoss: '+str(loss.cpu().detach().numpy()))\n        train_loss += loss.cpu().detach()/len(train_loader)\n\n      for data in val_loader:\n        data = data.to(device)\n        optimizer.zero_grad()\n        outputs = model(data)\n        labels = data.y\n        loss = mse(outputs, labels)\n        val_loss += loss.cpu().detach()/len(val_loader)\n      if val_loss.detach().numpy()<min_val_loss:\n        min_val_loss = val_loss.cpu().detach().numpy()\n        torch.save(model.state_dict(), 'model.pth')\n      lr_scheduler.step(val_loss)\n      print('Epoch: ', str(epoch+1)+'/'+str(epochs),'| Training MSELoss: ', train_loss.numpy(), '| Validation MSELoss: ', val_loss.numpy())\n      m_train_loss.append(train_loss.numpy())\n      m_val_loss.append(val_loss.numpy())\n      if epoch>10 and min(m_val_loss[-7:])>min_val_loss:\n        break\n        \n    model = MPNN().to(device)\n    model.load_state_dict(torch.load('model.pth'))\n    test_loss = 0\n    true = []\n    preds = []\n    for data in test_loader:\n      data = data.to(device)\n      optimizer.zero_grad()\n      outputs = model(data)\n      labels = data.y\n      true += list(labels.detach().numpy())\n      preds += list(outputs.detach().numpy())\n      loss = mse(outputs, labels)\n      test_loss += loss/len(test_loader)\n    print('Test MSELoss: ', test_loss.detach().numpy())\n    OOF_preds = pd.DataFrame()\n    OOF_preds['true_value'] = true\n    OOF_preds['preds'] = preds\n    OOF_preds['row'] = shuffled_list[test_batch]\n    OOF_preds.to_csv('OOF_preds_'+str(val_batch)+'.csv')\n    return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(6,10):\n    train_fn(val_batch=i, test_batch=(i+1)%10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files = os.listdir('/kaggle/working')\ndf = pd.concat([pd.read_csv('/kaggle/working/'+i).drop(columns = ['Unnamed: 0']) for i in files if 'OOF_preds_' in i])\ndf.to_csv('OOF_preds.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('OOF_preds.csv').drop(columns = ['Unnamed: 0'])\ndf = df.sort_values(by = 'row').reset_index(drop = True)\ndf['True_pT'] = df['true_value']\ndf['Predicted_pT'] = df['preds']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.metrics import mean_absolute_error as mae\n\nMAE1 = []\ndx = 0.5\nfor i in tqdm(range(int(2/dx),int(150/dx))):\n    P = df[(df['True_pT']>=(i-1)*dx)&(df['True_pT']<=(i+1)*dx)]\n    try:\n        p = mae(P['True_pT'],P['Predicted_pT'])\n    except:\n        p=0\n    MAE1.append(p)\nMAE1 = MAE1[:196]\nplt.plot([i*dx for i in range(4,200)],MAE1,label = 'FCNN')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(sum(MAE1[:196]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pT_classes(x):\n    if x>=25:\n        return 'Above 25 GeV'\n    else:\n        return 'Below 25 GeV'\n\nprint(classification_report(df['True_pT'].apply(pT_classes), df['Predicted_pT'].apply(pT_classes)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}