{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-27T12:04:04.982703Z","iopub.execute_input":"2021-07-27T12:04:04.983058Z","iopub.status.idle":"2021-07-27T12:04:04.989267Z","shell.execute_reply.started":"2021-07-27T12:04:04.98303Z","shell.execute_reply":"2021-07-27T12:04:04.988587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n \n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-07-27T12:04:04.990598Z","iopub.execute_input":"2021-07-27T12:04:04.991013Z","iopub.status.idle":"2021-07-27T12:04:05.011815Z","shell.execute_reply.started":"2021-07-27T12:04:04.990979Z","shell.execute_reply":"2021-07-27T12:04:05.010569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"../input/flight-take-off-data-jfk-airport/M1_final.csv\"\ndf = pd.read_csv(path)\npd.set_option('display.max_columns', None)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T12:04:05.013462Z","iopub.execute_input":"2021-07-27T12:04:05.013774Z","iopub.status.idle":"2021-07-27T12:04:05.093307Z","shell.execute_reply.started":"2021-07-27T12:04:05.013744Z","shell.execute_reply":"2021-07-27T12:04:05.092104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(['DAY_OF_MONTH','DAY_OF_WEEK','MONTH','TAIL_NUM'], axis=1)\ndf = df.dropna()\ndf.info()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-27T12:04:05.094307Z","iopub.execute_input":"2021-07-27T12:04:05.094534Z","iopub.status.idle":"2021-07-27T12:04:05.12519Z","shell.execute_reply.started":"2021-07-27T12:04:05.094512Z","shell.execute_reply":"2021-07-27T12:04:05.124721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['TAXI_OUT'].unique()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T12:04:05.126011Z","iopub.execute_input":"2021-07-27T12:04:05.126296Z","iopub.status.idle":"2021-07-27T12:04:05.131228Z","shell.execute_reply.started":"2021-07-27T12:04:05.126274Z","shell.execute_reply":"2021-07-27T12:04:05.130528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pre-Processing dew point column","metadata":{"execution":{"iopub.status.busy":"2021-07-27T12:03:29.749157Z","iopub.execute_input":"2021-07-27T12:03:29.749435Z","iopub.status.idle":"2021-07-27T12:03:29.76768Z","shell.execute_reply.started":"2021-07-27T12:03:29.749411Z","shell.execute_reply":"2021-07-27T12:03:29.765342Z"}}},{"cell_type":"code","source":"df['Dew Point'] = df['Dew Point'].astype('int')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T12:04:05.13277Z","iopub.execute_input":"2021-07-27T12:04:05.133068Z","iopub.status.idle":"2021-07-27T12:04:05.149282Z","shell.execute_reply.started":"2021-07-27T12:04:05.133046Z","shell.execute_reply":"2021-07-27T12:04:05.148528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Dew Point'].unique()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T12:04:05.150635Z","iopub.execute_input":"2021-07-27T12:04:05.150927Z","iopub.status.idle":"2021-07-27T12:04:05.167387Z","shell.execute_reply.started":"2021-07-27T12:04:05.150896Z","shell.execute_reply":"2021-07-27T12:04:05.166796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train Test Split","metadata":{"execution":{"iopub.status.busy":"2021-07-27T12:03:29.772169Z","iopub.status.idle":"2021-07-27T12:03:29.772678Z"}}},{"cell_type":"code","source":"X= df.drop(['TAXI_OUT'], axis=1).values\ny = df['TAXI_OUT'].values\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,random_state=101)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T12:04:05.16834Z","iopub.execute_input":"2021-07-27T12:04:05.168691Z","iopub.status.idle":"2021-07-27T12:04:05.209901Z","shell.execute_reply.started":"2021-07-27T12:04:05.16866Z","shell.execute_reply":"2021-07-27T12:04:05.209005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Regression using One_hot_encoder","metadata":{"execution":{"iopub.status.busy":"2021-07-27T12:03:29.774816Z","iopub.status.idle":"2021-07-27T12:03:29.775218Z"}}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n\ndef get_pipeline(machine_learning_model, one_hot_cols):\n    #One hot encoder\n    one_hotter = ColumnTransformer([\n        ('onehot_cols',\n        OneHotEncoder(sparse=False, categories='auto', handle_unknown='ignore'),\n        one_hot_cols)\n    ], remainder = 'passthrough')\n    \n    #Min max scaler\n    min_maxer = MinMaxScaler()\n    #regression step\n    regressor = machine_learning_model\n    \n    pipeline = Pipeline([\n        ('one_hot', one_hotter),\n        #('min_maxer', min_maxer),\n        ('regressor', regressor)\n    ])\n    return pipeline\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-27T12:04:05.211165Z","iopub.execute_input":"2021-07-27T12:04:05.211426Z","iopub.status.idle":"2021-07-27T12:04:05.218852Z","shell.execute_reply.started":"2021-07-27T12:04:05.211398Z","shell.execute_reply":"2021-07-27T12:04:05.217633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import BayesianRidge\nfrom sklearn.ensemble import RandomForestRegressor\nfrom lightgbm import LGBMRegressor\n\n\ndef evaluate1(regressors, datasets, verbose=True):\n    results = {'Dataset':[], 'Regressor':[], 'RMSE':[]}\n    for data in datasets:\n        dataset_label = data['label']\n        print(f'For {data[\"label\"]}:')\n        for regressor in regressors:\n            results['Dataset'].append(dataset_label)\n            pipeline = get_pipeline(regressor, data['1h'])\n            pipeline.fit(X_train, y_train)\n            \n            regressor_name = str(regressor).split('(')[0]\n            results['Regressor'].append(regressor_name)\n            rmse = np.sqrt(mean_squared_error(y_test, pipeline.predict(X_test)))\n            \n            if verbose:\n                print(f'Done {dataset_label} using {regressor_name}: {rmse}')\n            results['RMSE'].append(rmse)\n        \n        \n    evaluate1.df_one_hot_encoder = pd.DataFrame(results)\n    plt.figure(figsize=(10,10))\n    sns.barplot(x='RMSE', y='Regressor', data=evaluate1.df_one_hot_encoder)\n\n    \nevaluate1([\n    LinearRegression(),\n    Ridge(),\n    Lasso(),\n    KNeighborsRegressor(n_neighbors=3),\n    SVR(),\n    BayesianRidge(),\n    RandomForestRegressor(),\n    LGBMRegressor()\n],\n[\n    {'label':'Taxi time', 'df':df , '1h':[0,1,11,15]}\n])","metadata":{"execution":{"iopub.status.busy":"2021-07-27T12:04:05.220237Z","iopub.execute_input":"2021-07-27T12:04:05.220656Z","iopub.status.idle":"2021-07-27T12:07:28.284208Z","shell.execute_reply.started":"2021-07-27T12:04:05.220629Z","shell.execute_reply":"2021-07-27T12:07:28.282853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Regression using label encoder","metadata":{}},{"cell_type":"code","source":"y = df['TAXI_OUT']\nX = df.drop(['TAXI_OUT'],axis = 1)\n\nX[\"Dew Point\"] = X[\"Dew Point\"].astype(int)\n\nobj_cols = list(X.select_dtypes(include = 'object').columns) #object columns\nnum_cols = list(set(X.columns) - set(obj_cols)) #numerical columns","metadata":{"execution":{"iopub.status.busy":"2021-07-27T12:08:51.517871Z","iopub.execute_input":"2021-07-27T12:08:51.518251Z","iopub.status.idle":"2021-07-27T12:08:51.531433Z","shell.execute_reply.started":"2021-07-27T12:08:51.518228Z","shell.execute_reply":"2021-07-27T12:08:51.530655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\nlabelencoder = LabelEncoder()\n\nfor col in obj_cols:\n    X[col] = labelencoder.fit_transform(X[col].astype(str))\n    \nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.1, random_state =101)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T12:08:52.044244Z","iopub.execute_input":"2021-07-27T12:08:52.044524Z","iopub.status.idle":"2021-07-27T12:08:52.112026Z","shell.execute_reply.started":"2021-07-27T12:08:52.044481Z","shell.execute_reply":"2021-07-27T12:08:52.11117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n\ndef get_pipeline(machine_learning_model, one_hot_cols):\n    #One hot encoder\n    one_hotter = ColumnTransformer([\n        ('onehot_cols',\n        OneHotEncoder(sparse=False, categories='auto', handle_unknown='ignore'),\n        one_hot_cols)\n    ], remainder = 'passthrough')\n    \n    #Min max scaler\n    min_maxer = MinMaxScaler()\n    #regression step\n    regressor = machine_learning_model\n    \n    pipeline = Pipeline([\n        ('one_hot', one_hotter),\n        #('min_maxer', min_maxer),\n        ('regressor', regressor)\n    ])\n    return pipeline\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-27T12:09:07.125363Z","iopub.execute_input":"2021-07-27T12:09:07.125735Z","iopub.status.idle":"2021-07-27T12:09:07.13282Z","shell.execute_reply.started":"2021-07-27T12:09:07.125704Z","shell.execute_reply":"2021-07-27T12:09:07.131986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import BayesianRidge\nfrom sklearn.ensemble import RandomForestRegressor\nfrom lightgbm import LGBMRegressor\n\n\ndef evaluate2(regressors, datasets, verbose=True):\n    results = {'Dataset':[], 'Regressor':[], 'RMSE':[]}\n    for data in datasets:\n        dataset_label = data['label']\n        print(f'For {data[\"label\"]}:')\n        for regressor in regressors:\n            results['Dataset'].append(dataset_label)\n            pipeline = get_pipeline(regressor, data['1h'])\n            pipeline.fit(X_train, y_train)\n            \n            regressor_name = str(regressor).split('(')[0]\n            results['Regressor'].append(regressor_name)\n            rmse = np.sqrt(mean_squared_error(y_test, pipeline.predict(X_test)))\n            \n            if verbose:\n                print(f'Done {dataset_label} using {regressor_name}: {rmse}')\n            results['RMSE'].append(rmse)\n        \n        \n    evaluate2.df_label_encoder = pd.DataFrame(results)\n    plt.figure(figsize=(10,10))\n    sns.barplot(x='RMSE', y='Regressor', data=evaluate2.df_label_encoder)\n\n    \nevaluate2([\n    LinearRegression(),\n    Ridge(),\n    Lasso(),\n    KNeighborsRegressor(n_neighbors=3),\n    SVR(),\n    BayesianRidge(),\n    RandomForestRegressor(),\n    LGBMRegressor()\n],\n[\n    {'label':'Taxi time', 'df':df , '1h':[]}\n])","metadata":{"execution":{"iopub.status.busy":"2021-07-27T12:09:23.529254Z","iopub.execute_input":"2021-07-27T12:09:23.529551Z","iopub.status.idle":"2021-07-27T12:10:30.682089Z","shell.execute_reply.started":"2021-07-27T12:09:23.529528Z","shell.execute_reply":"2021-07-27T12:10:30.681597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"array1 = np.array(evaluate2.df_label_encoder['RMSE'])\narray2 = np.array(evaluate1.df_one_hot_encoder['RMSE'])\nplt.figure(figsize=(12,10))\nmodel_names =['Linear', 'Ridge','Lasso','KNN','SVM', 'Naive Bayes','Random Forest', 'LGBM']\nplt.plot(model_names, array1)\nplt.plot(model_names, array2)\n\nplt.legend(['Label Encoder', 'One Hot Encoder'])\n\nplt.xlabel('Models')\nplt.ylabel('RMSE')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T12:10:30.683092Z","iopub.execute_input":"2021-07-27T12:10:30.683404Z","iopub.status.idle":"2021-07-27T12:10:30.86005Z","shell.execute_reply.started":"2021-07-27T12:10:30.683368Z","shell.execute_reply":"2021-07-27T12:10:30.859303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}