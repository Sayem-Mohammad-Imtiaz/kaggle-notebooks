{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 6. DEEP LEARNING USING ARTIFICIAL NEURAL NETWORK","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* In this notebook, i will create an ANN model: Multi-layer NN using KerasClassifier.\n* I did also EDA, Visualisation and Machine Learning study for same topic in my notebook linked below.\n* You can have a look and vote if you enjoy.\n\n\n  https://www.kaggle.com/ozkanozturk/ml-model-with-86-7-accuracy","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The story: A bank is investigating a very high rate of customer leaving the bank. Here is a 10.000 records dataset to investigate and predict which of the customers are more likely to leave the bank soon","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"[6.1. Data Preparation](#6.1) <br>\n>[6.1.1. Loading Libraries](#6.1.1) <br>\n>[6.1.2. Reading Data](#6.1.2) <br>\n>[6.1.3. Dropping unnecessary columns](#6.1.3) <br>\n>[6.1.4. Normalizig/Rescaling Data](#6.1.4) <br>\n>[6.1.5. Converting data types to Categorical](#6.1.5) <br>\n>[6.1.6. Converting columns to Categorical](#6.1.6) <br>\n\n[6.2. Multi-Layer Neural Network with Keras](#6.2) <br>\n>[6.2.1. Creating X_train, y_train](#6.2.1) <br>\n>[6.2.2. Train-Test split](#6.2.2) <br>\n>[6.2.3. Feature Scaling with StandardScaler](#6.2.3) <br>\n>[6.2.4. Modelling Using KerasClassifier](#6.2.4) <br>\n>>[6.2.4.1. Defining a function to pass by `build_fn` argument](#6.2.4.1) <br>\n>>[6.2.4.2. Creating Model with default `batch_size`](#6.2.4.2) <br>\n>>[6.2.4.3. Fiting Model](#6.2.4.3) <br>\n>>[6.2.4.4. Creating Model with a decreased `batch_size`](#6.2.4.4) <br>\n>>[6.2.4.5. Evaluating model with `cross_val_score` and `StratifiedKFold`](#6.2.4.5) <br>\n>>[6.2.4.6 Deep Learning with Grid Search](#6.2.4.6) <br>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6.1\"></a>\n# 6.1. DATA PREPARATION","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6.1.1\"></a>\n## 6.1.1. Loading Libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6.1.2\"></a>\n## 6.1.2. Reading Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/deep-learning-az-ann/Churn_Modelling.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6.1.3\"></a>\n## 6.1.3. Dropping unnecessary columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop([\"RowNumber\",\"CustomerId\",\"Surname\"], axis=1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6.1.4\"></a>\n## 6.1.4. Normalizing (Rescaling) data ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* Rescaling data to have values between 0 and 1. \n* This is usually called feature scaling. One possible formula to achieve this is:\n![image.png](attachment:image.png)","attachments":{"image.png":{"image/png":"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"}},"execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# CreditScore, Age, Tenure, Balance, EstimatedSalary to be rescaled:\n\nfor each in [\"CreditScore\", \"Age\",\"Tenure\", \"Balance\", \"EstimatedSalary\"]:\n    data[each] = (data[each] - np.min(data[each])) / (np.max(data[each])-np.min(data[each]))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6.1.5\"></a>\n## 6.1.5. Converting data types to categorical","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# looking at current types:\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* From above info, although there are some categorical columns (such as Gender:Male-Female); data types are not categorical.\n* They are object (as in Gender), integer (as in HasCrCard and Exited)\n* So, i need to convert data types to categorical.\n* Thus we prevent model to get 1 and 0 as weights of features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting type of some features to category\nfor each in [\"Geography\",\"Gender\",\"NumOfProducts\",\"HasCrCard\",\"IsActiveMember\",\"Exited\"]:\n    data[each] = data[each].astype(\"category\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# types after conversion\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6.1.6\"></a>\n## 6.1.6. Converting some columns to categoricals(Numericals)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* Geography ---> Geography_France / Geography_Spain / Geography_Germany\n* Gender ---> Gender_Female / Gender_Male\n* NumOfProducts ---> NumOfProducts_1 / NumOfProducts_2 / NumOfProducts_3 / NumOfProducts_4 ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.get_dummies(data, columns = [\"Geography\",\"Gender\", \"NumOfProducts\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6.2\"></a>\n# 6.2 MULTI LAYER NEURAL NETWORK WITH KERAS","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6.2.1\"></a>\n## 6.2.1. Creating X_train and y_train","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = data.drop(columns = [\"Exited\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = data[\"Exited\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6.2.2\"></a>\n## 6.2.2. Train - Test split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X_train, \n    y_train,\n    test_size = 0.33,\n    random_state = 42\n)\n\nprint(\"Length of X_train: \",len(X_train))\nprint(\"Length of X_test: \",len(X_test))\nprint(\"Length of y_train: \",len(y_train))\nprint(\"Length of y_test: \",len(y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\n    \"Shape of X_train: \",np.shape(X_train),\n    \"\\nShape of y_train: \",np.shape(y_train)\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6.2.3\"></a>\n## 6.2.3. Feature Scaling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc_x = StandardScaler()\nX_train = pd.DataFrame(sc_x.fit_transform(X_train), columns=X_train.columns.values)\nX_test = pd.DataFrame(sc_x.transform(X_test), columns=X_test.columns.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6.2.4\"></a>\n## 6.2.4. Modelling Using KerasClassifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom keras.models import Sequential     # Neural network library\nfrom keras.layers import Dense          # layer library\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6.2.4.1\"></a>\n### 6.2.4.1. Defining a function to pass by build_fn argument","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* KerasClassifier class in Keras takes an argument `build_fn` which is the name of the function to call to get your model.\n* We must define a function that defines our model, compiles it and returns it.\n* Defining function named as `create_model` :","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    \n    # create model\n    model = Sequential()\n    \n    # adding input layer\n    model.add(Dense(units = 12, kernel_initializer = \"uniform\", activation = \"relu\", input_dim = 16))\n    \n    # adding layer\n    model.add(Dense(units = 8, kernel_initializer = \"uniform\", activation = \"relu\"))\n    \n    # adding layer\n    model.add(Dense(units = 4, kernel_initializer = \"uniform\", activation = \"relu\"))\n        \n    # adding output layer\n    model.add(Dense(units = 1, kernel_initializer = \"uniform\", activation = \"sigmoid\"))\n    \n    # compile model\n    model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n    \n    return model    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We will pass this funtion `create_model`  to the KerasClassifier class by `build_fn` argument. \n* We also pass additional argument of `epochs=15`. \n* We also pass additional argument of `batch_size=10`.\n* There is also argument of `batch_size`; it is 32 as default.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6.2.4.2\"></a>\n### 6.2.4.2. Creating model with default `batch_size`","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* `epochs`: generally defined as \"one pass over the entire dataset\", used to separate training into distinct phases, which is useful for logging and periodic evaluation.\n* We have 6700 samples in our train data; in one epoch, one forward and backward propogation to be passed for all 6700 samples and one accuracy to be calculated.\n* When we get **epochs** as 10; it means that 10 forward-backward to be passed and 10 accuracies to be calculated.\n* `batch_size`: Number of samples per gradient update. If unspecified, batch_size will bedefault to 32.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = KerasClassifier(build_fn = create_model, epochs=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6.2.4.3\"></a>\n### 6.2.4.3. Fitting model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"history1 = model1.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* From above output:\n* We saw that 15 epochs and 210 iterations for each epoch.\n* Because the default batch size is 32; we had 6700 samples / 32 = 210 batches for each epoch.\n* Parameters (weights and bias) were updated and accuracy re-calculated after each batch in each epoch.\n* For example: in 1st epoch, parameters and accuracy calculated (with 32 samples) after 1st batch (1/210).\n* Then parameters and accuracy re-calculated (with 32 samples) after 2nd batch (2/210).\n* Then parameters and accuracy re-calculated (with 32 samples) after 3rd batch (3/210); so on and so on.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6.2.4.4\"></a>\n### 6.2.4.4. Creating model with a decreased `batch_size`","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = KerasClassifier(build_fn = create_model, epochs=15, batch_size = 10)\nhistory2 = model2.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Decreasing batch size will increase the iteration number as well as computation time and cpu usage.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize = (10,6))\nplt.plot(history1.history[\"accuracy\"], label = \"Batch size = 32\")\nplt.plot(history2.history[\"accuracy\"], label = \"Batch size = 10\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Accuracies\")\nplt.title(\"Affects of batch size on accuracy on ANN\")\nplt.grid(axis = \"both\")\n\nplt.legend()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6.2.4.5\"></a>\n### 6.2.4.5. Evaluating model with `cross_val_score` and `StratifiedKFold`","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Evaluating using 15-fold cross validation:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = KerasClassifier(build_fn = create_model, epochs=15, batch_size = 10)\nkfold = StratifiedKFold(n_splits = 15, shuffle = True, random_state = 42)\naccuracies = cross_val_score(estimator = model, X = X_train, y = y_train, cv = kfold)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize = (10,6))\nplt.plot(accuracies)\nplt.xlabel(\"K-fold values of Cross Validation Score\")\nplt.ylabel(\"Accuracies\")\nplt.title(\"Cross Validation Accuracies vs K-Folds of ANN\")\nplt.grid(axis = \"both\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best accuracy : {} @ k-fold value of {}\".format(round(accuracies.max()*100,2),accuracies.argmax()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6.2.4.6\"></a>\n### 6.2.4.6. Deep learning with Grid Search","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* We will use a grid search to evaluate different configurations for our neural network model.\n* And we will report the combination that provides the best-estimated performance.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\ndef create_model1(optimizer=\"rmsprop\", init=\"glorot_uniform\"):\n        \n    # create model\n    model = Sequential()\n    \n    # adding input layer\n    model.add(Dense(units = 12, kernel_initializer = init, activation = \"relu\", input_dim = 16))\n    \n    # adding layer\n    model.add(Dense(units = 8, kernel_initializer = init, activation = \"relu\"))\n    \n    # adding layer\n    model.add(Dense(units = 4, kernel_initializer = init, activation = \"relu\"))\n        \n    # adding output layer\n    model.add(Dense(units = 1, kernel_initializer = init, activation = \"sigmoid\"))\n    \n    # compile model\n    model.compile(loss = \"binary_crossentropy\", optimizer = optimizer, metrics = [\"accuracy\"])\n    \n    return model  \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create model\nmodel_new = KerasClassifier(build_fn = create_model1, epochs = 15, batch_size = 32)\n\n# grid search epochs, batch size and optimizer\noptimizers = ['rmsprop', 'adam']\ninit = ['glorot_uniform', 'uniform']\n\nparam_grid = dict(optimizer = optimizers, init = init)\ngrid = GridSearchCV(estimator = model_new, param_grid = param_grid)\n\nresult = grid.fit(X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize results\nprint(\"Best: %f using %s\" % (result.best_score_, result.best_params_))\nmeans = result.cv_results_['mean_test_score']\nstds = result.cv_results_['std_test_score']\nparams = result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}