{"cells":[{"metadata":{"_uuid":"360438aaf7ccc46a31414c2fefeb663c81486761","_cell_guid":"170dad24-043e-49c1-be86-2e030e4db750"},"cell_type":"markdown","source":"# ‚úíÔ∏è Code Modules, Links and Helpful Functions\n#### [üìë GitHub Repository](https://github.com/OlgaBelitskaya/deep_learning_projects/tree/master/DL_PP2) & [üìë Colaboratory](https://colab.research.google.com/drive/1Z9Fz0OOi6bpWvH-H2OhExC9CkGPWBYZz)\n#### [üìë Full Version - Python](https://olgabelitskaya.github.io/kaggle_letters.html) & [üìë Full Version - R](https://olgabelitskaya.github.io/kaggle_letters_R.html) \n#### [üìë Deep Learning. P2: Multi-Label Classification. Letter Recognition](https://olgabelitskaya.github.io/DL_PP2_Solutions_SMC.html)"},{"metadata":{"_uuid":"34a51fcfca0c0056b1607859047b229ed9ce80fb","_cell_guid":"6edff160-dd66-48f8-a6d2-53947586cacf","trusted":true},"cell_type":"code","source":"import warnings; warnings.filterwarnings('ignore')\nimport numpy as np,pandas as pd,pylab as pl,h5py\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom IPython import display\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping\nfrom keras.metrics import top_k_categorical_accuracy,categorical_accuracy\nfrom keras.models import Sequential,load_model,Model\nfrom keras.layers import Dense,LSTM,GlobalAveragePooling1D,GlobalAveragePooling2D\nfrom keras.layers.advanced_activations import PReLU,LeakyReLU\nfrom keras.layers import Input,Activation,Flatten,Dropout,BatchNormalization\nfrom keras.layers import Conv2D,MaxPooling2D,GlobalMaxPooling2D\nfw='weights.best.letters.hdf5'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1dfb0ff0bdb9df9f74656088e60d642d6318d18c","_cell_guid":"ebbd3db4-f1f0-4849-9b36-75d23c410f9e","trusted":true},"cell_type":"code","source":"# plotting of fitting histories for neural networks\ndef history_plot(fit_history):\n    pl.figure(figsize=(12,10)); pl.subplot(211)\n    keys=list(fit_history.history.keys())[0:4]\n    pl.plot(fit_history.history[keys[0]],\n            color='slategray',label='train')\n    pl.plot(fit_history.history[keys[2]],\n            color='#4876ff',label='valid')\n    pl.xlabel(\"Epochs\"); pl.ylabel(\"Loss\")\n    pl.legend(); pl.grid()\n    pl.title('Loss Function')     \n    pl.subplot(212)\n    pl.plot(fit_history.history[keys[1]],\n            color='slategray',label='train')\n    pl.plot(fit_history.history[keys[3]],\n            color='#4876ff',label='valid')\n    pl.xlabel(\"Epochs\"); pl.ylabel(\"Accuracy\")    \n    pl.legend(); pl.grid()\n    pl.title('Accuracy'); pl.show()\n# preprocessing functions \ndef ohe(x): \n    return OneHotEncoder(categories='auto')\\\n           .fit(x.reshape(-1,1)).transform(x.reshape(-1,1))\\\n           .toarray().astype('int64')\ndef tts(X,y): \n    x_train,x_test,y_train,y_test=\\\n    train_test_split(X,y,test_size=.2,random_state=1)\n    n=int(len(x_test)/2)\n    x_valid,y_valid=x_test[:n],y_test[:n]\n    x_test,y_test=x_test[n:],y_test[n:]\n    return x_train,x_valid,x_test,y_train,y_valid,y_test","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f121bb211d481cad0b50afba397005afda387cd3","_cell_guid":"29895737-f8d1-4207-afb6-d30e4e6e29f4"},"cell_type":"markdown","source":"# ‚úíÔ∏è Loading and Preprocessing the Data"},{"metadata":{"_uuid":"2ae459d8a7ea97ad505990de83814d710e516366","_cell_guid":"f8f6dc29-65ef-4020-9a5b-9058380c461c","trusted":true},"cell_type":"code","source":"f=h5py.File('../input/LetterColorImages_123.h5','r')\nkeys=list(f.keys()); keys ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dff5dd08420d0bd50e963bcb175070e40c72e1d6","_cell_guid":"5d7d011f-02be-47ec-b0e0-884198113546","trusted":true},"cell_type":"code","source":"# creating image arrays and targets\nletters=u'–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è'\nbackgrounds=np.array(f[keys[0]])\nlabels=np.array(f[keys[2]])\n# normalization of image arrays\nimages=np.array(f[keys[1]])/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gray_images=np.dot(images[...,:3],[.299,.587,.114])\nrn=np.random.randint(10000); pl.figure(figsize=(2,3))\npl.title('Label: %s \\n'%letters[labels[rn]-1]+\\\n         'Background: %s'%backgrounds[rn],\n         fontsize=18)\npl.imshow(gray_images[rn],cmap=pl.cm.bone)\npl.xticks([]); pl.yticks([]); pl.show()\ngray_images=gray_images.reshape(-1,32,32,1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b792f2af8e730f86b2c5280dedb2bb01b5272a68","_cell_guid":"980a3e6c-40d9-4361-b14b-c594b28fe145","trusted":true},"cell_type":"code","source":"# one-hot encoding\ncbackgrounds,clabels=ohe(backgrounds),ohe(labels)\nctargets=np.concatenate((clabels,cbackgrounds),axis=1)\ndisplay.display(pd.DataFrame([labels[97:103],clabels[97:103]]).T)\npd.DataFrame([clabels.shape,cbackgrounds.shape,ctargets.shape])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a5c8c47bb2e9ae1a65071860b0d4a56fae535200","_cell_guid":"374ef5ec-554c-4957-8ab2-af926e77a959","trusted":true},"cell_type":"code","source":"# splitting the data\nx_train1,x_valid1,x_test1,\\\ny_train1,y_valid1,y_test1=tts(gray_images,clabels)\nx_train2,x_valid2,x_test2,\\\ny_train2,y_valid2,y_test2=tts(gray_images,ctargets)\ny_train2_list=[y_train2[:,:33],y_train2[:,33:]]\ny_test2_list=[y_test2[:,:33],y_test2[:,33:]]\ny_valid2_list=[y_valid2[:,:33],y_valid2[:,33:]]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bf1a1512728978569831b2df91a4e1cc94f89e6d","_cell_guid":"c05d40a2-dda4-4254-8f24-56ad286996c1"},"cell_type":"markdown","source":"# ‚úíÔ∏è Defining a Classification Model"},{"metadata":{"_uuid":"33cf0ea82c6f01309049f70011413c7583c1d594","_cell_guid":"a5ef1f92-3ed3-4e1b-b4e8-6752e07f6013","trusted":true},"cell_type":"code","source":"def top_3_categorical_accuracy(y_true,y_pred):\n    return top_k_categorical_accuracy(y_true,y_pred,k=3)\ndef gray_model():\n    model = Sequential()    \n    model.add(Conv2D(32,(5,5),padding='same',\n                     input_shape=x_train1.shape[1:]))\n    model.add(LeakyReLU(alpha=.02))    \n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(.25))\n    model.add(Conv2D(128,(5,5)))\n    model.add(LeakyReLU(alpha=.02))    \n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(.25))   \n    model.add(GlobalMaxPooling2D())  \n    model.add(Dense(1024))\n    model.add(LeakyReLU(alpha=.02)) \n    model.add(Dropout(.25))  \n    model.add(Dense(128))\n    model.add(LeakyReLU(alpha=.02)) \n    model.add(Dropout(.25))    \n    model.add(Dense(33))\n    model.add(Activation('softmax'))\n    model.compile(loss='categorical_crossentropy',optimizer='rmsprop',\n                  metrics=[categorical_accuracy,top_3_categorical_accuracy])\n    return model\ngray_model=gray_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69ecbffc0d2dc51f95b3e8d59dfc660cdca088db","_kg_hide-output":true},"cell_type":"code","source":"checkpointer=ModelCheckpoint(filepath=fw,verbose=2,save_best_only=True)\nlr_reduction=ReduceLROnPlateau(monitor='val_loss', \n                               patience=10,verbose=2,factor=.5)\nestopping=EarlyStopping(monitor='val_loss',patience=20,verbose=2)\nhistory=gray_model.fit(x_train1,y_train1, \n                       epochs=200,batch_size=64,verbose=2,\n                       validation_data=(x_valid1,y_valid1),\n                       callbacks=[checkpointer,lr_reduction,estopping])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce4f900d58243a7c51ce7bb470dc82d53b0e02da","_cell_guid":"f7abcba5-70a8-4683-beca-b325b9bfdbac","trusted":true},"cell_type":"code","source":"history_plot(history)\n# loading the model weights with the best validation accuracy\ngray_model.load_weights(fw)\n# calculation classification accuracy on the testing set\ngray_model.evaluate(x_test1,y_test1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"steps,epochs=1000,10\nigen=ImageDataGenerator(zoom_range=.3,shear_range=.3,rotation_range=30)\ngenerator=\\\ngray_model.fit_generator(igen.flow(x_train1,y_train1,batch_size=64),\n                         steps_per_epoch=steps,epochs=epochs,verbose=2,\n                         validation_data=(x_valid1,y_valid1), \n                         callbacks=[checkpointer,lr_reduction])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_plot(generator)\ngray_model.load_weights(fw)\ngray_model.evaluate(x_test1,y_test1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1bc29810f5131e191a09cc0ab0c95cec3d96f6b"},"cell_type":"markdown","source":"# ‚úíÔ∏è Displaying Predictions"},{"metadata":{"trusted":true,"_uuid":"d0ed0e4a5f531822175b62dc58c7f1551caf959c"},"cell_type":"code","source":"py_test1=gray_model.predict_classes(x_test1)\nfig=pl.figure(figsize=(12,12))\nfor i,idx in enumerate(np.random.choice(x_test1.shape[0],\n                                        size=16,replace=False)):\n    ax=fig.add_subplot(4,4,i+1,xticks=[],yticks=[])\n    ax.imshow(np.squeeze(x_test1[idx]),cmap=pl.cm.bone)\n    pred_idx=py_test1[idx]\n    true_idx=np.argmax(y_test1[idx])\n    ax.set_title(\"{} ({})\".format(letters[pred_idx],letters[true_idx]),\n                 color=(\"darkblue\" if pred_idx==true_idx else \"darkred\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ‚úíÔ∏è Comparing with Multi-Label Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"def gray_multi_model():    \n    model_input=Input(shape=(32,32,1))\n    x=BatchNormalization()(model_input)\n    x=Conv2D(32,(5,5),padding='same')(model_input)\n    x=LeakyReLU(alpha=.02)(x)\n    x=MaxPooling2D(pool_size=(2,2))(x)    \n    x=Dropout(.25)(x)   \n    x=Conv2D(256,(5,5),padding='same')(x) \n    x=LeakyReLU(alpha=.02)(x)\n    x=MaxPooling2D(pool_size=(2,2))(x)    \n    x=Dropout(.25)(x)             \n    x=GlobalMaxPooling2D()(x)    \n    x=Dense(1024)(x) \n    x=LeakyReLU(alpha=.02)(x)\n    x=Dropout(.25)(x)   \n    x=Dense(256)(x) \n    x=LeakyReLU(alpha=.02)(x)\n    x=Dropout(.025)(x)   \n    y1=Dense(33,activation='softmax')(x)\n    y2=Dense(4,activation='softmax')(x)      \n    model=Model(inputs=model_input,outputs=[y1,y2])\n    model.compile(loss='categorical_crossentropy',optimizer='rmsprop',\n                  metrics=[categorical_accuracy,top_3_categorical_accuracy])      \n    return model\ngray_multi_model=gray_multi_model()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"checkpointer=ModelCheckpoint(filepath=fw,verbose=2,save_best_only=True)\nlr_reduction=ReduceLROnPlateau(monitor='val_loss',patience=5,verbose=2,factor=.75)\nestopping=EarlyStopping(monitor='val_loss',patience=20,verbose=2)\nhistory=gray_multi_model.fit(x_train2,y_train2_list,\n                             epochs=200,batch_size=128,verbose=2,\n                             validation_data=(x_valid2,y_valid2_list),\n                             callbacks=[checkpointer,lr_reduction,estopping])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gray_multi_model.evaluate(x_test2,y_test2_list)","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":4}