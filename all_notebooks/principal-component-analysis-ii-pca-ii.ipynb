{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing Libaries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/hr-comma-sepcsv/HR_comma_sep.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_names=df.columns.tolist()\nprint(\"Columns names:\")\nprint(columns_names)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Principal Component Analysis****"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_drop=df.drop(labels=['sales','salary'],axis=1)\ndf_drop.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"df.drop() is the method to drop the columns in our dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = df_drop.columns.tolist()\ncols","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we are converting columns of the data frame to list so it would be easier for us to reshuffle the columns.We are going to use column insert method"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols.insert(0, cols.pop(cols.index('left')))\ncols","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Converting list to columns again**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_drop = df_drop.reindex(columns=cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_drop.iloc[:,1:8].values\ny = df_drop.iloc[:,0].values\nX\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.shape(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus X is now matrix with 14999 rows and 7 columns"},{"metadata":{},"cell_type":"markdown","source":" ** Data Standardisation **"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nX_std = StandardScaler().fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Computing Eigenvectors and Eigenvalues **\nFirst we need to calculate covariance matrix.\n   \n"},{"metadata":{},"cell_type":"markdown","source":"** Covariance matrix **"},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_vec = np.mean(X_std, axis=0)\ncov_mat = (X_std - mean_vec).T.dot((X_std - mean_vec)) / (X_std.shape[0]-1)\nprint('Covariance matrix \\n%s' %cov_mat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('NumPy covariance matrix:\\n%s' %np.cov(X_std.T))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nsns.heatmap(cov_mat, vmax=1, square=True,annot=True,cmap='cubehelix')\nplt.title('Correlation between different features')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Eigen Decomposition of the covariance matrix **"},{"metadata":{"trusted":true},"cell_type":"code","source":"eig_vals, eig_vecs = np.linalg.eig(cov_mat)\nprint('Eigenvectors \\n%s' %eig_vecs)\nprint('\\nEigenvalues \\n%s' %eig_vals)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Selecting Principal Components**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make a list of(eigenvalue, eigenvector) tuples\neig_pairs = [(np.abs(eig_vals[i]),eig_vecs[:,i]) for i in range(len(eig_vals))]\n\n# sort the (eigenvalue, eigenvector) tuples from high to low\neig_pairs.sort(key=lambda x:x[0],reverse=True)\n\n# Visually confirm that the list is correctly sorted by decreasing eigenvalues\n\nprint('Eigenvalues in decreasing order:')\nfor i in eig_pairs:\n    print(i[0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tot = sum(eig_vals)\nvar_exp = [(i /tot)*100 for i in sorted(eig_vals, reverse=True)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with plt.style.context('dark_background'):\n    plt.figure(figsize=(6, 4))\n    \n    plt.bar(range(7), var_exp, alpha=0.5, align='center',\n            label='individual explained variance')\n    plt.ylabel('Explained variance ratio')\n    plt.xlabel('Principal components')\n    plt.legend(loc='best')\n    plt.tight_layouut()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Projection Matrix**"},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix_w = np.hstack((eig_pairs[0][1].reshape(7,1),\n                     eig_pairs[1][1].reshape(7,1)\n                     ))\nprint('Matrix W:\\n', matrix_w)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y=X_std.dot(matrix_w)\nY","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** PCA in scikit-learn**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA().fit(X_std)\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlim(0,7,1)\nplt.xlabel('Number of components')\nplt.ylabel('Cumulative explained variance')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above graph shows almost 90% variace by the first 6 components .Therefore we can drop 7th component"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\nsklearn_pca = PCA(n_components=6)\nY_sklearn = sklearn_pca.fit_transform(X_std)\nprint(X_std)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_sklearn.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus principal component Analysis is used to remove the redundant features from the datasets withouut losing much information.These features are less dimensional in nature.The first component has the highest variance followed by second,third and so on.PCA works better on dataset havingthree or higher dimensions. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}