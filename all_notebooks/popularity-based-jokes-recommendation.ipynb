{"cells":[{"metadata":{},"cell_type":"markdown","source":"## What is Recommendation System ?\n\nRecommender/recommendation system is a subclass of information filtering system that seeks to predict the rating/ preference a user would give to an item.\n\nThey are primarily used in applications where a person/ entity is involved with a product/ service. To further improve their experience with this product, we try to personalize it to their needs. For this we have to look up at their past interactions with this product.\n\n*In one line* -> **Specialized content for everyone.**\n\n*For further info, [Wiki](https://en.wikipedia.org/wiki/Recommender_system#:~:text=A%20recommender%20system%2C%20or%20a,would%20give%20to%20an%20item.)*\n\n## Types of Recommender System\n\n* 1). Popularity Based\n* 2). Classification Based\n* 3). Content Based\n* 4). Collaborative Based\n* 5). Hybrid Based (Content + Collaborative)\n* 6). Association Based Rule Mining\n\n## Popularity based recommender system\nAs the name suggests it recommends based on what is currently popular. This is particularly useful when you don't have past data as a reference to recommend product to the user. \n\n# Import packages and dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndata = pd.read_csv('../input/jester-online-joke-recommender/jesterfinal151cols.csv')\nprint(data.shape)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#There are NaN values, we need to drop or impute them in data preprocessing step.\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing\n\nDataset contains no column headers. The first column is user id and subsequent columns are Joke ratings for 150 jokes. Also there are NaN values towards the end of the data\n\n**Things to do:**\n* Add column headers\n* All other Joke rating columns would be renamed to 1-150\n* 0th column would be user_id\n* Some rows contain NaN values, replace them as 0\n* Many ratings are 99.0 such jokes were not rated by user, replace them as 0","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert all 151 columns into a range of 0-150\ndata.columns = range(data.shape[1]) #shape of column\nprint(data.columns) #Start 0, Stop 151, Step 1\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#0th column would be renamed to user_id\ndata.rename(columns = {0: 'user_id'}, inplace = True)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Replace all NaN values as 0\ndata = data.fillna(0)\ndata.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Replace all 99.0 ratings as 0\ndata = data.replace(99.0, 0)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some these ratings are as high as 6.9 while some are -9.68. Lets normalize only ratings columns using **Standard Scalar**, the idea behind this is to transform your data such that it's distribution will have mean of 0 and standard deviation of 1. Standard scaler aligns it into a Gaussian or Normal disctribution.\n\n*For further info on [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)*\n\n**Things to do:**\n* Extract ratings\n* Fit Standard Scaler into Ratings","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Extract only ratings columns\nratings = data.iloc[:, 1:]\nratings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fit StandardScaler into ratings\nfrom sklearn.preprocessing import StandardScaler\nratings_ss = StandardScaler().fit_transform(ratings)\nratings_ss","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Recommend Popular Jokes\nRecommend the top n most popular jokes using mean ratings.\n\n**Things to do:**\n* Find mean rating for all the jokes\n* Mean rating is an array that needs to be converted into Dataframe for sort into descending order\n* Recommend top n popular jokes","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# Find the mean rating for all the jokes\nmean_ratings = ratings_ss.mean(axis = 0) #axis of 0 for it to calculate mean across all rows \nprint(mean_ratings.shape) #(150,) clearly indicates mean scores for all 150 jokes\nmean_ratings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert array into Dataframe and rename column name for better readability\nmean_ratings = pd.DataFrame(mean_ratings)\nmean_ratings.rename(columns = {0: 'mean_joke_ratings'}, inplace = True) \nmean_ratings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Recommend the top n most popular jokes\nn = 10\n#mean_ratings.iloc[:,0].argsort()[:-(n+1):-1] #outputs only Joke ids\nmean_ratings.sort_values(ascending = False, by = 'mean_joke_ratings')[:n] #outputs Joke ids and their mean ratings","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Recommender system recommends the top 10 most popular jokes based on their mean ratings.**","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}