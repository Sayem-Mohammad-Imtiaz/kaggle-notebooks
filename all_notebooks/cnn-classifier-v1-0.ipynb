{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nnp.random.seed(69)\nimport pandas as pd\nimport random\nimport pickle as pkl\nimport matplotlib.pyplot as plt\nimport matplotlib.image as img\nimport seaborn as sns\nimport tensorflow as tf\nfrom tqdm.notebook import tqdm\nfrom tensorflow.keras.utils import to_categorical, plot_model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,concatenate, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, ZeroPadding2D, LeakyReLU, ReLU, AveragePooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.models import load_model\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n# import kerastuner as kt\n# from kerastuner import HyperModel\nimport time\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/sdss-project-v10/SDSS_Query_v1.0_DF.csv\",index_col=0)\n\nregressor = load_model(\"../input/sdss-project-v10/DNNRegressor.h5\")\nphotodf = df.loc[:,['dered_u', 'deVRad_u', 'psffwhm_u', 'extinction_u',\n       'dered_g', 'deVRad_g', 'psffwhm_g', 'extinction_g', 'dered_r',\n       'deVRad_r', 'psffwhm_r', 'extinction_r', 'dered_i', 'deVRad_i',\n       'psffwhm_i', 'extinction_i', 'dered_z', 'deVRad_z', 'psffwhm_z',\n       'extinction_z', 'u_g', 'g_r', 'r_i', 'i_z']]\n\nphotodf.loc[:,\"redshift\"] = regressor.predict(photodf.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.load(\"../input/sdss-project-v10/X_v1.0.npy\")\ny = np.load(\"../input/sdss-project-v10/y_v1.0.npy\")\nobjlist = np.load(\"../input/sdss-project-v10/objlist_v1.0.npy\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y, label_strings = pd.factorize(y)\ny = to_categorical(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newinpsdf = df.loc[:,[\"extinction_u\",\"extinction_g\",\"extinction_r\",\"extinction_i\",\"extinction_z\"]]\n# newinpsdf.loc[:,\"redshift\"] = photodf.loc[:,\"redshift\"]\n\nnewinps = []\nfor i,objnum in tqdm(enumerate(objlist),total=len(objlist)):\n    newinps.append(newinpsdf.loc[objnum].values)\nnewinps=np.array(newinps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zipX = list(zip(X, newinps))\n\nzipX_train, zipX_test, y_train, y_test = train_test_split(zipX, y, test_size = 0.2,random_state=69)\nzipX_train, zipX_val, y_train, y_val = train_test_split(zipX_train, y_train, test_size = 0.25, random_state=69)\n\nX_train, newinps_train = zip(*zipX_train)\nX_val, newinps_val = zip(*zipX_val)\nX_test, newinps_test = zip(*zipX_test)\n\nX_train = np.array(X_train)\nX_val = np.array(X_val)\nX_test = np.array(X_test)\n\nnewinps_train = np.array(newinps_train)\nnewinps_val = np.array(newinps_val)\nnewinps_test = np.array(newinps_test)\n\ndel(zipX,zipX_test,zipX_train,zipX_val, X, newinps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_metrics(y_pred, y_test, labels, to_print=True):\n    correct_labels = np.where(y_pred==y_test)[0]\n    accuracy = metrics.accuracy_score(y_test, y_pred)\n    precision = metrics.precision_score(y_test, y_pred,average='macro')\n    recall = metrics.recall_score(y_test, y_pred,average='macro')\n    f1score = metrics.f1_score(y_test, y_pred,average='macro')\n    # rocscore = metrics.roc_auc_score(y_test, y_pred,average='micro',multi_class=\"ovo\")\n    confusion_matrix = metrics.confusion_matrix(y_test, y_pred)  \n    classification_report = metrics.classification_report(y_test, y_pred)\n\n    if to_print:\n        print(\"Identified {} correct labels out of {} labels\".format(len(correct_labels), y_test.shape[0]))\n        print(\"Accuracy:\",accuracy)\n        print(\"Precision:\",precision)\n        print(\"Recall:\",recall)\n        print(\"F1 Score:\",f1score)\n        # print(\"ROC AUC Score:\",rocscore)\n        print(f\"Labels are: {labels}\")\n        print(\"Confusion Matrix:\\n\", confusion_matrix)\n        print(\"Classification_Report:\\n\", classification_report)\n\n    return (correct_labels, accuracy, precision, recall, confusion_matrix, classification_report)\n\ndef plot_model_change(history):\n    # summarize history for accuracy\n    plt.plot(history.history['accuracy'],label=\"Training Acc\")\n    plt.plot(history.history['val_accuracy'],label=\"Val Acc\")\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend()\n    plt.show()\n    # summarize history for loss\n    plt.plot(history.history['loss'],label=\"Training Loss\")\n    plt.plot(history.history['val_loss'],label=\"Val Loss\")\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inp_layer = tf.keras.Input(shape=(32, 32, 5))\n\nmod = Conv2D(filters=64, kernel_size=(5,5), padding='same')(inp_layer)\nmod = ReLU()(mod)\n\n\n# mod = AveragePooling2D(pool_size=(2, 2), strides=2)(mod)\n\nc1 = Conv2D(filters=48, kernel_size=(1,1), padding='same')(mod)\nc1 = ReLU()(c1)\nc2 = Conv2D(filters=48, kernel_size=(1,1), padding='same')(mod)\nc2 = ReLU()(c2)\nc3 = Conv2D(filters=48, kernel_size=(1,1), padding='same')(mod)\nc3 = ReLU()(c3)\nc4 = Conv2D(filters=64, kernel_size=(1,1), padding='same')(c1)\nc4 = ReLU()(c4)\nc5 = Conv2D(filters=64, kernel_size=(3,3), padding='same')(c1)\nc5 = ReLU()(c5)\nc6 = Conv2D(filters=64, kernel_size=(5,5), padding='same')(c2)\nc6 = ReLU()(c6)\np1 = AveragePooling2D(pool_size=(1, 1))(c3)\nmod = concatenate([c4,c5,c6,p1])\n\nc7 = Conv2D(filters=64, kernel_size=(1,1), padding='same')(mod)\nc7 = ReLU()(c7)\nc8 = Conv2D(filters=64, kernel_size=(1,1), padding='same')(mod)\nc8 = ReLU()(c8)\nc9 = Conv2D(filters=64, kernel_size=(1,1), padding='same')(mod)\nc9 = ReLU()(c9)\nc10 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(c7)\nc10 = ReLU()(c10)\nc11 = Conv2D(filters=92, kernel_size=(3,3), padding='same')(c7)\nc11 = ReLU()(c11)\nc12 = Conv2D(filters=92, kernel_size=(5,5), padding='same')(c8)\nc12 = ReLU()(c12)\np2 = AveragePooling2D(pool_size=(1, 1))(c9)\nmod = concatenate([c10,c11,c12,p2])\nmod = AveragePooling2D(pool_size=(2, 2))(mod)\n\nc13 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(mod)\nc13 = ReLU()(c13)\nc14 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(mod)\nc14 = ReLU()(c14)\nc15 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(mod)\nc15 = ReLU()(c15)\nc16 = Conv2D(filters=128, kernel_size=(1,1), padding='same')(c13)\nc16 = ReLU()(c16)\nc17 = Conv2D(filters=128, kernel_size=(3,3), padding='same')(c13)\nc17 = ReLU()(c17)\nc18 = Conv2D(filters=128, kernel_size=(5,5), padding='same')(c14)\nc18 = ReLU()(c18)\np3 = AveragePooling2D(pool_size=(1, 1))(c15)\nmod = concatenate([c16,c17,c18,p3])\n\nc19 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(mod)\nc19 = ReLU()(c19)\nc20 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(mod)\nc20 = ReLU()(c20)\nc21 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(mod)\nc21 = ReLU()(c21)\nc22 = Conv2D(filters=128, kernel_size=(1,1), padding='same')(c19)\nc22 = ReLU()(c22)\nc23 = Conv2D(filters=128, kernel_size=(3,3), padding='same')(c19)\nc23 = ReLU()(c23)\nc24 = Conv2D(filters=128, kernel_size=(5,5), padding='same')(c20)\nc24 = ReLU()(c24)\np4 = AveragePooling2D(pool_size=(1, 1))(c21)\nmod = concatenate([c22,c23,c24,p4])\nmod = AveragePooling2D(pool_size=(2, 2))(mod)\n\nc25 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(mod)\nc25 = ReLU()(c25)\nc26 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(mod)\nc26 = ReLU()(c26)\nc27 = Conv2D(filters=128, kernel_size=(1,1), padding='same')(mod)\nc27 = ReLU()(c27)\nc28 = Conv2D(filters=128, kernel_size=(3,3), padding='same')(c25)\nc28 = ReLU()(c28)\np5 = AveragePooling2D(pool_size=(1, 1))(c26)\nmod = concatenate([c27,c28,p5])\nmod = Flatten()(mod)    #Check\nnewinputs = tf.keras.Input(shape=(newinps_train.shape[1]))\nmod = concatenate([mod,newinputs])\nmod = Dense(1024)(mod)\nmod = Dense(1024)(mod)\nout_layer = Dense(3, activation=\"softmax\") (mod)\nmodel = tf.keras.Model(inputs=[inp_layer,newinputs], outputs=out_layer)\n\nmodel.compile(optimizer = 'adam' , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True)\ndatagen.fit(X_train)\n\n\nes = EarlyStopping(monitor='val_loss', verbose=1, patience=30, restore_best_weights=True)\n\ncb = [es]\n\nhistory = model.fit(datagen.flow([X_train,newinps_train],y_train, batch_size=512),\n                              epochs = 300, validation_data = ([X_val,newinps_val],y_val),\n                              callbacks = cb,\n                              verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"Newinps1CNNClassifier.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model_change(history)\n\npreds_test = model.predict([X_test,newinps_test],batch_size=1024, verbose = 0)\nprint(get_metrics(preds_test.argmax(axis=1), y_test.argmax(axis=1),label_strings))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}