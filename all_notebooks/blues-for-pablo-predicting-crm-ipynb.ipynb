{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Here is the notebook that has finished with the MSE score 4626.235**"},{"metadata":{},"cell_type":"markdown","source":"**IMPORTS**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\n\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor\nfrom sklearn.metrics import mean_absolute_error, make_scorer\nfrom sklearn.feature_selection import VarianceThreshold, RFE\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import mutual_info_regression, f_regression\nfrom sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.neighbors import KNeighborsRegressor, RadiusNeighborsRegressor\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold, RepeatedStratifiedKFold\nfrom sklearn.metrics import mean_squared_error as mse\n \nimport matplotlib.pyplot as plt\nfrom matplotlib import pyplot\nimport matplotlib.style as style\nimport seaborn as sns\n\nimport folium\nfrom folium.plugins import FloatImage\n\nfrom lightgbm import LGBMRegressor\n\nimport warnings\n%matplotlib inline\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns', 100)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DATA PREPROCESSING AND ANALISYS**"},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = \"../input/real-time-advertisers-auction\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(f'{PATH}/Dataset.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sample(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['date'] = pd.to_datetime(df['date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Formula to calculate CPM. Imported from the orginal notebook\ndef weird_division(n, d):\n    return n / d if d else 0\n\ndf['CPM'] = df.apply(lambda x: weird_division(((x['total_revenue'] * 100)),\n                                                x['measurable_impressions']) * 1000,\n                                                axis=1)\ndf = df[df['CPM'] >= 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separating the train and test dataframes\n\ntrain = df[df['date'] <= \"2019-06-21\"]\ntest = df[df['date'] > \"2019-06-21\"]\n\n# Now we drop target columns, columns linked to them and the quantile\ntest = test[test['CPM'] < test['CPM'].quantile(0.95)]\ntrain = train[train['CPM'] < train['CPM'].quantile(0.95)]\n\n# We set our target ('CPM' from test dataframe, also further we act as though we didn't have it)\n# and y_train ('CPM' from train dataframe)\ntarget = test['CPM']\ny = train['CPM']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train.corr()\nplt.figure(figsize=(14,10))\nsns.heatmap(data=corr,vmin=0, vmax=1, cmap=\"YlGnBu\",  square=True, annot= True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We drop the values that have been used to calculate our target\ntrain = train.drop(['total_revenue', 'CPM'], axis=1)\ntest = test.drop(['total_revenue', 'CPM'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we can remove values which are not correlated with the 'CPM'\ntrain.drop(['integration_type_id' , 'revenue_share_percent'], axis = 1, inplace=True)\ntest.drop(['integration_type_id' , 'revenue_share_percent'], axis = 1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We try to fetch some information by precisely looking at our features**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.os_id.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.site_id.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.ad_type_id.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.ad_unit_id.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.geo_id.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.order_id.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.monetization_channel_id.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We fill the empty cells using diiferent variants.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.fillna(0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**First let's try to make using only those features that are numeric though could be easily represented as the categoical\nFor that purpose the one-hot encoding with dummies would be used**"},{"metadata":{},"cell_type":"markdown","source":"**We select columns for further work. We consider the least diverse features as categorical.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We get rid of some values to show a little bit of fair play (of course because the model still beats the target)\ncat_columns = ['site_id', 'ad_type_id', 'device_category_id', 'advertiser_id',\n               'order_id', 'line_item_type_id', 'os_id', 'monetization_channel_id']\n\n# We can further use other features so let's include and comment them in our case\nnum_columns = ['geo_id', 'ad_unit_id']#, 'total_impressions', 'viewable_impressions']\n\n\n# And then our first-guess df looks like this\nfg_df = train[cat_columns + num_columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fg_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def transform_data(df, num_cols, cat_cols):\n    transformed_df = df.copy()\n    \n    for col in cat_cols:\n        transformed_df[col] = transformed_df[col].astype('category')\n        transformed_df = pd.concat([transformed_df.drop(col, axis=1),\n                                    pd.get_dummies(transformed_df[col], prefix=col)], axis=1)\n        \n    transformed_df[num_cols] = transformed_df[num_cols].apply(\n        lambda x: np.log(x+1))\n    \n    scaler = MinMaxScaler()\n    transformed_df[num_cols] = scaler.fit_transform(transformed_df[num_cols])\n\n    return transformed_df\ntransformed_df = transform_data(fg_df, num_columns, cat_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transformed_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_and_test(df, y, model, test_size=0.2):\n    target = y\n    features = df\n\n    X_train, X_test, y_train, y_test = train_test_split(\n        features, target, test_size=test_size, random_state=42)\n\n    model.fit(X_train, y_train)  \n    y_pred = model.predict(X_test) \n    print('MSE test: %.3f' % (mse(y_test, y_pred)))\n    pred = np.round((y_pred) + 1, 1)\n    actual = np.round((y_test) + 1, 1)\n    plt.scatter(actual.to_numpy(), pred)\n    plt.title('Predicted vs. Actual', fontsize=18, fontweight='bold')\n    plt.xlabel('Actual')\n    plt.ylabel('Predicted')\n    plt.show()\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We use the LGBMRegressor as a model. For this particular case we can do it \"from the box\".\n# Anyway we leave some room for manoeuvre and comment possible attributes to be added\n\n# n = 10\nmodel = LGBMRegressor()# boosting_type=\"dart\", n_estimators=60, learning_rate=0.2, max_depth=n, num_leaves=2 ** n)\ntrained_model_LGBMR = train_and_test(transformed_df, y, model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here we get the most important features for some further analytics (maybe for RnD department)\nfeat_imp = pd.Series(trained_model_LGBMR.feature_importances_,\n                     index=transformed_df.columns)\nfeat_imp.nlargest(30).plot(kind='barh', figsize=(10, 6))\nplt.xlabel('Relative Importance')\nplt.title(\"Feature importances\", fontsize=18, fontweight='bold')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transformed_test = transform_data(test, num_columns, cat_columns)\ntrain_cols = transformed_df.columns.tolist()\ntest_cols = transformed_test.columns.tolist()\nintersection = []\nfor col in train_cols:\n    if col in test_cols:\n        intersection.append(col)\ntransformed_test = transform_data(test, num_columns, cat_columns)\ntransformed_test = transformed_test[intersection]\ntransformed_df = transformed_df[intersection]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cross-validation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# To be sure we use cross-validation mechanism\nfeatures = transformed_df.copy()\n    \nX_train, X_test, y_train, y_test = train_test_split(\n        features, y, test_size=0.1, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scorer = make_scorer(mse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = cross_val_score(trained_model_LGBMR, X_train, y_train, scoring=scorer, cv=5)\nscores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**As we can see the results respond our expactations so we proceed**"},{"metadata":{},"cell_type":"markdown","source":"**Final train on the whole dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LGBMRegressor()# boosting_type=\"dart\", n_estimators=60, learning_rate=0.2, max_depth=n, num_leaves=2 ** n)\ntrained_model_LGBMR = train_and_test(transformed_df, y, model, 0.99)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Still not bad**"},{"metadata":{},"cell_type":"markdown","source":"**And now we get down to business**"},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = trained_model_LGBMR.predict(transformed_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('MSE test: %.3f' % (mse(target, prediction)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I want a credit for the auction theory.\n# Thank you in advance!","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}