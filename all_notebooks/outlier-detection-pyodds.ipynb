{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-24T18:23:15.601451Z","iopub.execute_input":"2021-05-24T18:23:15.601837Z","iopub.status.idle":"2021-05-24T18:23:15.643087Z","shell.execute_reply.started":"2021-05-24T18:23:15.601805Z","shell.execute_reply":"2021-05-24T18:23:15.641641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To use PyODDS we have to install the required dependencies. These are the following:\n- pandas>=0.25.0\n- taos==1.4.15\n- tensorflow==2.0.0b1\n- numpy>=1.16.4\n- seaborn>=0.9.0\n- torch>=1.1.0\n- luminol==0.4\n- tqdm>=4.35.0\n- matplotlib>=3.1.1\n- scikit_learn>=0.21.3","metadata":{}},{"cell_type":"code","source":"# Required dependencies for PyODDS\n\n# pandas >= 0.25.0\n# taos == 1.4.15\n!pip install taos\n# tensorflow == 2.0.0b1\n!pip install tensorflow==2.0.0b1\n# numpy >= 1.16.4\nnp.version.version\n# seaborn >= 0.9.0\nimport seaborn as sns\nsns.__version__\n# torch >= 1.1.0\nimport torch\ntorch.__version__\n# luminol == 0.4\n!pip install luminol==0.4\n# tqdm >= 4.35.0\nimport tqdm\ntqdm.__version__\n# matplotlib >=3.1.1\nimport matplotlib\nmatplotlib.__version__\n# scikit_learn >= 0.21.3\n!pip install scikit_learn==0.21.3","metadata":{"execution":{"iopub.status.busy":"2021-05-24T18:23:15.644863Z","iopub.execute_input":"2021-05-24T18:23:15.645339Z","iopub.status.idle":"2021-05-24T18:23:42.096095Z","shell.execute_reply.started":"2021-05-24T18:23:15.645286Z","shell.execute_reply":"2021-05-24T18:23:42.094881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then we install PyODDS.","metadata":{}},{"cell_type":"code","source":"# We will use PyODDs. For this we have to install PyODDS and its required dependencies.\n!pip install pyodds\nimport pyodds as pyodds","metadata":{"execution":{"iopub.status.busy":"2021-05-24T18:23:42.099176Z","iopub.execute_input":"2021-05-24T18:23:42.099684Z","iopub.status.idle":"2021-05-24T18:23:48.798091Z","shell.execute_reply.started":"2021-05-24T18:23:42.099603Z","shell.execute_reply":"2021-05-24T18:23:48.796841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The datasets are from the NAB corpus. Two datasets are used:\n- an artificially generated dataset with anomaly (df1)\n- a real traffic dataset (df2)","metadata":{}},{"cell_type":"code","source":"# The datasets are from the NAB corpus. \n# The first is an artificial dataset with anomaly.\ndf1 = pd.read_csv('../input/nab/artificialWithAnomaly/artificialWithAnomaly/art_daily_flatmiddle.csv')\nprint('ARTIFICIAL DATASET\\n')\nprint(df1.info())\nprint(df1['timestamp'].head(10))\n\ndf1.plot(x='timestamp', y='value')\n\n\n# The second is a real traffic occupancy dataset.\ndf2 = pd.read_csv('../input/nab/realTraffic/realTraffic/occupancy_t4013.csv')\nprint('\\n\\n\\nREAL DATASET\\n')\nprint(df2.info())\nprint(df2['timestamp'].head(10))\n\ndf2.plot(x='timestamp', y='value')\n","metadata":{"execution":{"iopub.status.busy":"2021-05-24T18:23:48.800009Z","iopub.execute_input":"2021-05-24T18:23:48.800377Z","iopub.status.idle":"2021-05-24T18:23:49.257554Z","shell.execute_reply.started":"2021-05-24T18:23:48.800339Z","shell.execute_reply":"2021-05-24T18:23:49.256671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting timestamp object into float\ndf1['timestamp'] = pd.to_datetime(df1['timestamp'])\ndf1['timestamp'] = [d.timestamp() for d in df1['timestamp']]\n\ndf2['timestamp'] = pd.to_datetime(df2['timestamp'])\ndf2['timestamp'] = [d.timestamp() for d in df2['timestamp']]","metadata":{"execution":{"iopub.status.busy":"2021-05-24T18:23:49.258786Z","iopub.execute_input":"2021-05-24T18:23:49.259056Z","iopub.status.idle":"2021-05-24T18:23:49.286405Z","shell.execute_reply.started":"2021-05-24T18:23:49.259029Z","shell.execute_reply":"2021-05-24T18:23:49.285344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the datasets to train and test sets. Approximately 70% of the data is used to train, and the remaining 30% to test.\ndf1_train = df1[:2822]\ndf1_test = df1[2822:]\n\n\ndf2_train = df2[:1750]\ndf2_test = df2[1750:]","metadata":{"execution":{"iopub.status.busy":"2021-05-24T18:23:49.287846Z","iopub.execute_input":"2021-05-24T18:23:49.288199Z","iopub.status.idle":"2021-05-24T18:23:49.302593Z","shell.execute_reply.started":"2021-05-24T18:23:49.288165Z","shell.execute_reply":"2021-05-24T18:23:49.301538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pyodds.utils.importAlgorithm import algorithm_selection\nfrom pyodds.utils.plotUtils import visualize_outlierscore,visualize_distribution, visualize_distribution_static, visualize_distribution_time_serie\nfrom pyodds.utils.utilities import output_performance\nimport matplotlib.pyplot as plt\n\n# selecting the knn algorithm\nclf_knn = algorithm_selection('knn', random_state=9, contamination=0.1)\n\n\n\n# on the first dataset\nclf_knn.fit(df1_train)\n\n# get outlier result and scores\nprediction_result = clf_knn.predict(df1_test)\noutlierness_score = clf_knn.decision_function(df1_test)\n\n# visualize the prediction_result\nvisualize_distribution(df1_test,prediction_result,outlierness_score)\nvisualize_distribution_static(df1_test,prediction_result,outlierness_score)\n\n\n\n\n# on the second dataset\nclf_knn.fit(df2_train)\n\n# get outlier result and scores\nprediction_result = clf_knn.predict(df2_test)\noutlierness_score = clf_knn.decision_function(df2_test)\n\n# visualize the prediction_result\nvisualize_distribution(df2_test,prediction_result,outlierness_score)\nvisualize_distribution_static(df2_test,prediction_result,outlierness_score)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-24T18:44:34.295242Z","iopub.execute_input":"2021-05-24T18:44:34.29562Z","iopub.status.idle":"2021-05-24T18:44:55.949105Z","shell.execute_reply.started":"2021-05-24T18:44:34.295585Z","shell.execute_reply":"2021-05-24T18:44:55.948072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# selecting the iforest algorithm\nclf_if = algorithm_selection('iforest', random_state=9, contamination=0.1)\n\n\n\n# on the first dataset\nclf_if.fit(df1_train)\n\n# get outlier result and scores\nprediction_result = clf_if.predict(df1_test)\noutlierness_score = clf_if.decision_function(df1_test)\n\n# visualize the prediction_result\nvisualize_distribution(df1_test,prediction_result,outlierness_score)\nvisualize_distribution_static(df1_test,prediction_result,outlierness_score)\n\n\n\n\n# on the second dataset\nclf_if.fit(df2_train)\n\n# get outlier result and scores\nprediction_result = clf_if.predict(df2_test)\noutlierness_score = clf_if.decision_function(df2_test)\n\n# visualize the prediction_result\nvisualize_distribution(df2_test,prediction_result,outlierness_score)\nvisualize_distribution_static(df2_test,prediction_result,outlierness_score)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-24T18:48:41.664396Z","iopub.execute_input":"2021-05-24T18:48:41.664811Z","iopub.status.idle":"2021-05-24T18:49:03.701247Z","shell.execute_reply.started":"2021-05-24T18:48:41.664771Z","shell.execute_reply":"2021-05-24T18:49:03.700094Z"},"trusted":true},"execution_count":null,"outputs":[]}]}