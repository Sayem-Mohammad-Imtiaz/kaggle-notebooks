{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nfrom sklearn.model_selection import KFold","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-11T09:57:09.770602Z","iopub.execute_input":"2021-08-11T09:57:09.770971Z","iopub.status.idle":"2021-08-11T09:57:09.775038Z","shell.execute_reply.started":"2021-08-11T09:57:09.770887Z","shell.execute_reply":"2021-08-11T09:57:09.774326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def batch_generator(batch_size, gen_x): \n    batch_features = np.zeros((batch_size,256,256,3))\n    batch_labels = np.zeros((batch_size,256,256,3)) \n    while True:\n        for i in range(batch_size):\n            batch_features[i] , batch_labels[i] = next(gen_x)\n        yield batch_features, batch_labels","metadata":{"execution":{"iopub.status.busy":"2021-08-11T09:57:11.187829Z","iopub.execute_input":"2021-08-11T09:57:11.188147Z","iopub.status.idle":"2021-08-11T09:57:11.196385Z","shell.execute_reply.started":"2021-08-11T09:57:11.188097Z","shell.execute_reply":"2021-08-11T09:57:11.195562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_data(filelist, img_path, mask_path, gen_type = \"train\"):\n    while True:\n        for i in filelist:\n            X_train = cv2.imread(img_path + i, cv2.IMREAD_COLOR )\n            X_train = cv2.resize(X_train, (256,256), interpolation= cv2.INTER_LINEAR )\n            if gen_type == \"train\":\n                X_train = X_train * np.random.choice([1,1,1,np.random.rand(256, 256,3)])\n            y_mask = cv2.imread(mask_path + i, cv2.IMREAD_COLOR)\n            y_mask = cv2.resize(y_mask, (256,256), interpolation= cv2.IMREAD_GRAYSCALE)\n            _,y_mask = cv2.threshold(y_mask, 127, 255, cv2.THRESH_BINARY)\n            y_mask = (y_mask/255).astype(int)\n            yield X_train, y_mask","metadata":{"execution":{"iopub.status.busy":"2021-08-11T09:57:11.962326Z","iopub.execute_input":"2021-08-11T09:57:11.962629Z","iopub.status.idle":"2021-08-11T09:57:11.972033Z","shell.execute_reply.started":"2021-08-11T09:57:11.962578Z","shell.execute_reply":"2021-08-11T09:57:11.971137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_data_pred(filelist, img_path, mask_path, gen_type = \"train\"):\n    while True:\n        for i in filelist:\n            original_img = cv2.imread(img_path + i, cv2.IMREAD_COLOR )\n            X_train = cv2.resize(original_img, (256,256), interpolation= cv2.INTER_LINEAR )\n            if gen_type == \"train\":\n                X_train = X_train * np.random.choice([1,1,1,np.random.rand(256, 256,3)])\n            original_mask = cv2.imread(mask_path + i, cv2.IMREAD_COLOR)\n            y_mask = cv2.resize(original_mask, (256,256), interpolation= cv2.IMREAD_GRAYSCALE)\n            _,y_mask = cv2.threshold(y_mask, 127, 255, cv2.THRESH_BINARY)\n            y_mask = (y_mask/255).astype(int)\n            yield original_img, original_mask, X_train, y_mask","metadata":{"execution":{"iopub.status.busy":"2021-08-11T09:57:12.626724Z","iopub.execute_input":"2021-08-11T09:57:12.627031Z","iopub.status.idle":"2021-08-11T09:57:12.635128Z","shell.execute_reply.started":"2021-08-11T09:57:12.626979Z","shell.execute_reply":"2021-08-11T09:57:12.634313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dice_score(mask_gt, mask_pred):\n    \"\"\"Computes soerensen-dice coefficient.\n\n    compute the soerensen-dice coefficient between the ground truth mask `mask_gt`\n    and the predicted mask `mask_pred`.\n\n    Args:\n    mask_gt: 3-dim Numpy array of type bool. The ground truth mask.\n    mask_pred: 3-dim Numpy array of type bool. The predicted mask.\n\n    Returns:\n    the dice coeffcient as float. If both masks are empty, the result is NaN.\n    \"\"\"\n    volume_sum = mask_gt.sum() + mask_pred.sum()\n    if volume_sum == 0:\n        return np.NaN\n    volume_intersect = (mask_gt & mask_pred).sum()\n    return 2*volume_intersect / volume_sum ","metadata":{"execution":{"iopub.status.busy":"2021-08-11T09:57:13.090364Z","iopub.execute_input":"2021-08-11T09:57:13.09067Z","iopub.status.idle":"2021-08-11T09:57:13.097834Z","shell.execute_reply.started":"2021-08-11T09:57:13.090621Z","shell.execute_reply":"2021-08-11T09:57:13.096988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import backend as K\n# From: https://gist.github.com/wassname/7793e2058c5c9dacb5212c0ac0b18a8a\ndef dice_coef(y_true, y_pred, smooth=1):\n    \"\"\"\n    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n    \"\"\"\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    return (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1-dice_coef(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T09:57:13.793652Z","iopub.execute_input":"2021-08-11T09:57:13.793984Z","iopub.status.idle":"2021-08-11T09:57:15.317278Z","shell.execute_reply.started":"2021-08-11T09:57:13.793928Z","shell.execute_reply":"2021-08-11T09:57:15.31649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def jacard_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n\n\ndef jacard_coef_loss(y_true, y_pred):\n    return 1-jacard_coef(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T09:57:15.319607Z","iopub.execute_input":"2021-08-11T09:57:15.320125Z","iopub.status.idle":"2021-08-11T09:57:15.327286Z","shell.execute_reply.started":"2021-08-11T09:57:15.31988Z","shell.execute_reply":"2021-08-11T09:57:15.326361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import layers\nimport tensorflow as tf\n\n\ndef get_model(img_size, num_classes):\n\n    inputs = tf.keras.Input(shape=img_size + (3,))\n    #inputs = tf.keras.Input(shape=(256,256,3))\n    #inputs = tf.keras.Input(shape=img_size + (1,))\n    ### [First half of the network: downsampling inputs] ###\n\n    # Entry block\n    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    previous_block_activation = x  # Set aside residual\n\n    # Blocks 1, 2, 3 are identical apart from the feature depth.\n    for filters in [64, 128, 256]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n\n        # Project residual\n        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n            previous_block_activation\n        )\n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    ### [Second half of the network: upsampling inputs] ###\n\n    for filters in [256, 128, 64, 32]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation(\"relu\")(x)\n        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.UpSampling2D(2)(x)\n\n        # Project residual\n        residual = layers.UpSampling2D(2)(previous_block_activation)\n        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    # Add a per-pixel classification layer\n    outputs = layers.Conv2D(num_classes, 3, activation=\"sigmoid\", padding=\"same\")(x)\n\n    # Define the model\n    model = tf.keras.Model(inputs, outputs)\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=jacard_coef_loss, metrics = [jacard_coef, dice_coef])\n    return model\n\n\n# Free up RAM in case the model definition cells were run multiple times\ntf.keras.backend.clear_session()\n\n# Build model\n#model = get_model(img_size, num_classes)\n\n#model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-11T09:57:15.328734Z","iopub.execute_input":"2021-08-11T09:57:15.32918Z","iopub.status.idle":"2021-08-11T09:57:15.377838Z","shell.execute_reply.started":"2021-08-11T09:57:15.329028Z","shell.execute_reply":"2021-08-11T09:57:15.377272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss', factor=0.1, patience=3, verbose=1, mode='min',\n    min_delta=0.0001, cooldown=5, min_lr=0\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-11T09:57:15.419644Z","iopub.execute_input":"2021-08-11T09:57:15.419881Z","iopub.status.idle":"2021-08-11T09:57:15.424315Z","shell.execute_reply.started":"2021-08-11T09:57:15.419836Z","shell.execute_reply":"2021-08-11T09:57:15.423602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install segmentation-models==1.0.1","metadata":{"execution":{"iopub.status.busy":"2021-08-11T09:57:21.165598Z","iopub.execute_input":"2021-08-11T09:57:21.165893Z","iopub.status.idle":"2021-08-11T09:57:30.093462Z","shell.execute_reply.started":"2021-08-11T09:57:21.165844Z","shell.execute_reply":"2021-08-11T09:57:30.092569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import segmentation_models as sm","metadata":{"execution":{"iopub.status.busy":"2021-08-11T09:57:30.095283Z","iopub.execute_input":"2021-08-11T09:57:30.095587Z","iopub.status.idle":"2021-08-11T09:57:31.971138Z","shell.execute_reply.started":"2021-08-11T09:57:30.095541Z","shell.execute_reply":"2021-08-11T09:57:31.970479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install neptune-client","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import neptune.new as neptune\nfrom sklearn.metrics import jaccard_score\nimport time","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_list = np.asarray(os.listdir(\"../input/hyperkvasiraugustversion/Kvasir-SEG/images\"))\nimage_path = \"../input/hyperkvasiraugustversion/Kvasir-SEG/images/\" \nmask_path = \"../input/hyperkvasiraugustversion/Kvasir-SEG/masks/\"\n\nrun = neptune.init(project='SSCP/HyperKvasir',\n                   api_token='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIzMGUyN2Q2ZS05MjVkLTRlMzItODYwZS0yODQ3ZWU3ZTdmMmEifQ==') # your credentials\n\n\nbatchsize = 10\ndata_size = len(file_list)\nnum_epoch = 25\nsplits = 10\nkf = KFold(n_splits=splits)\nvalsize = data_size // splits\ntrainsize = data_size - valsize\n\ndata_num = np.arange(data_size)\n\nimg_size = (256, 256)\nnum_classes = 3\n\nrun[\"Dataset\"] = \"Polyp\"\nrun[\"Model\"] = \"inceptionv3\"\nrun[\"CV-folds\"] = splits\nrun[\"Epochs\"] = num_epoch\nrun[\"Batch size\"] = batchsize\nrun[\"pretrained\"] = \"Imagenet\"\n\nvalidation_dice_original = np.zeros([valsize,splits])\nvalidation_dice_resized = np.zeros([valsize,splits])\n#validation_jaccard_original = np.zeros([valsize,splits])\n#validation_jaccard_resized = np.zeros([valsize,splits])\n\ncv_count = 0\n\nfor train_index, val_index in kf.split(data_num):\n    #model = get_model(img_size, num_classes)\n    model = sm.Unet('inceptionv3', encoder_weights='imagenet', input_shape=( 256,256, 3), classes=3, activation='sigmoid')\n    model.compile(optimizer='Adam', loss=jacard_coef_loss, metrics = [jacard_coef, dice_coef])\n    model.fit(x=batch_generator(batchsize, generate_data(file_list[train_index], image_path, mask_path, gen_type = \"train\")), epochs=num_epoch, \n                            steps_per_epoch=(trainsize/batchsize), \n                            validation_steps=(valsize/batchsize),\n                            validation_data=batch_generator(batchsize, generate_data(file_list[val_index], image_path, mask_path, gen_type = \"val\")), \n                            validation_freq=1, \n                            verbose = 1, \n                            callbacks=[reduce_lr],\n                            )\n    val_gen  = generate_data_pred(file_list[val_index], image_path, mask_path, gen_type = \"val\")\n    for i in range(valsize):\n        time_start = time.time()\n        original_img, original_mask, X, y_true = next(val_gen)\n        original_shape = original_img.shape\n        y_pred = model.predict(np.expand_dims(X,0))\n        _,y_pred_thr = cv2.threshold(y_pred[0,:,:,0]*255, 127, 255, cv2.THRESH_BINARY)\n        y_pred = (y_pred_thr/255).astype(int)\n        dice_resized = dice_score(y_true[:,:,0],y_pred)\n        #jaccard_resized = jaccard_score(y_true[:,:,0],y_pred, average=\"macro\")\n        \n        y_pred_original = cv2.resize(y_pred.astype(float), (original_shape[1],original_shape[0]), interpolation= cv2.INTER_LINEAR)\n        dice_original = dice_score(original_mask[:,:,0],y_pred_original.astype(int)*255)\n        #jaccard_original = jaccard_score(original_mask[:,:,0],y_pred_original.astype(int)*255, average=\"macro\")\n        \n        validation_dice_original[i,cv_count] = dice_original\n        validation_dice_resized[i,cv_count] = dice_resized\n        #validation_jaccard_original[i,cv_count] = jaccard_original\n        #validation_jaccard_resized[i,cv_count] = jaccard_resized\n        \n        if i < 5:\n            plt.figure(figsize=(20,10))\n            plt.subplot(1,2,1)\n            plt.imshow(original_img, 'gray', interpolation='none')\n            plt.imshow(original_mask/255.0, 'jet', interpolation='none', alpha=0.4)\n            plt.subplot(1,2,2)\n            plt.imshow(original_img, 'gray', interpolation='none')\n            plt.imshow(y_pred_original, 'jet', interpolation='none', alpha=0.4)\n            plt.show()\n        \n    dice_resized_mean = validation_dice_resized[:,cv_count].mean()\n    dice_original_mean = validation_dice_original[:,cv_count].mean()\n    #jaccard_resized_mean = validation_jaccard_resized[:,cv_count].mean()\n    #jaccard_original_mean = validation_jaccard_original[:,cv_count].mean()\n        \n    print(\"--------------------------------------\")\n    print(\"Mean validation DICE (on resized data):\", dice_resized_mean) \n    print(\"Mean validation DICE (on original data):\", dice_original_mean)\n    print(\"--------------------------------------\")\n    #print(\"Mean validation Jaccard (on resized data):\", jaccard_resized_mean) \n    #print(\"Mean validation Jaccard (on original data):\", jaccard_original_mean)\n    #print(\"--------------------------------------\")\n    run[\"Dice Resized\"].log(dice_resized_mean)\n    run[\"Dice Original\"].log(dice_original_mean)\n    #run[\"Jaccard Resized\"].log(jaccard_resized_mean)\n    #run[\"Jaccard Original\"].log(jaccard_original_mean)\n    runtime = time.time() - time_start \n    print('Runtime: {} sec'.format(runtime))\n    run[\"Runtime\"] = runtime\n    cv_count +=1\nrun.stop()","metadata":{"execution":{"iopub.status.busy":"2021-08-11T10:12:22.938867Z","iopub.execute_input":"2021-08-11T10:12:22.939254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}