{"cells":[{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"The aim is to predict success rate (%) in reaching the Mount Rainier peak given (1) the route and (2) the weather condition.","execution_count":null},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"# Import Libraries","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"# Load libraries\nimport sys\nimport scipy\nimport numpy as np\nimport pandas as pd\nfrom pandas import read_csv\nfrom pandas.plotting import scatter_matrix\nfrom math import sqrt\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold, GridSearchCV\nfrom sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, accuracy_score, mean_squared_error, r2_score, mean_absolute_error\nfrom sklearn.linear_model import LogisticRegression, Ridge, LinearRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC, SVR\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nimport pickle","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"# get working directory\n! pwd","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"# Load dataset","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"# load data\nclimbing_data = pd.read_csv('/kaggle/input/mount-rainier-weather-and-climbing-data/climbing_statistics.csv')\nweather_data = pd.read_csv('/kaggle/input/mount-rainier-weather-and-climbing-data/Rainier_Weather.csv')","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"## Preliminary exploration","execution_count":null},{"metadata":{"Collapsed":"false","trusted":true},"cell_type":"code","source":"climbing_data.info()\nweather_data.info()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"Merge the climbing and weather datasets into 1 dataset.","execution_count":null},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"# Preprocess Data (1)","execution_count":null},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"**Ways data can be preprocessed:**\n* Remove missing values\n* Remove outliers\n* Remove duplicates\n* Feature selection\n* Feature engineering\n* Feature scaling\n    * **Numerical** data = standardize or normalize\n    * **Categorical** data = one-hot encoding or dummify\n* Group data into clusters\n    * Cluster by an attribute (e.g. age, price)\n    * Cluster using k-means","execution_count":null},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# Merge 2 datasets\njoined_data = pd.merge(climbing_data, weather_data, how=\"left\", on=[\"Date\"])\njoined_data.head()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# Remove missing values\njoined_data.isna().sum()\njoined_data = joined_data.dropna()\njoined_data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# Remove rows where success percentage > 1.00\njoined_data = joined_data[joined_data['Success Percentage'] <= 1]  \njoined_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# Feature selection\ndata = joined_data.drop(columns=[\"Date\", \"Attempted\",\"Succeeded\", \"Battery Voltage AVG\"])\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# dummify \"Route\"\ndummy_Route = pd.get_dummies(data['Route'])\ndummify_data = pd.concat([data, dummy_Route], axis = 1)\ndata = dummify_data.drop(columns=[\"Route\"])\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":false},"cell_type":"code","source":"# Alternative to dummify, is to code \"Route\"\n\n# Change route into codes\ndata[\"Route\"] = data[\"Route\"].astype(\"category\")\ndata[\"Route_code\"] = data[\"Route\"].cat.codes\ndata[\"Route_code\"].describe() # if min is -1, then there is NA\n\n# double check there are same no of unique Route names and Route codes\ndata[\"Route\"].describe() == data[\"Route\"].cat.codes.astype(\"category\").describe()\n\n# View Route code dictionary\ncode = data[\"Route\"].astype('category')\ncode_dictionary = dict(enumerate(code.cat.categories))\nprint(code_dictionary)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"# Exploratory Data Analysis (EDA)","execution_count":null},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"## Understand data with descriptive statistics","execution_count":null},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# describe\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# head\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# shape\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# data types\ndata.dtypes","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# attributes\nattributes = data.dtypes.index\nprint(attributes)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# Correlation Coefficient Matrix Heatmap\ncorrelation = data.corr()\nplt.figure(figsize=(15, 10))\nsns.heatmap(correlation, xticklabels=correlation.columns.values, yticklabels=correlation.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# Covariance Coefficient Matrix Heatmap\ncovariance = data.cov()\nplt.figure(figsize=(15, 10))\nsns.heatmap(covariance, xticklabels=covariance.columns.values, yticklabels=covariance.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"## Understand data with visualization","execution_count":null},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"### Univariate plots to understand each individual attribute","execution_count":null},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# Dependent variable -- 'Success Percentage'\nsns.countplot(data['Success Percentage'])","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# Distribution of attribute -- \"Success Percentage\"\nf = plt.figure(figsize=(20,4))\nf.add_subplot(1,2,1)\nsns.distplot(data['Success Percentage'])\nf.add_subplot(1,2,2)\nsns.boxplot(data['Success Percentage'])","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# histogram of all attributes\ndata.hist(figsize=(10,6), bins = 10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"#box plot\nplt.figure(figsize=(20,6))\nsns.boxplot(data = data)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# Line plot\nplt.plot(data['Temperature AVG'])\nplt.title('Line plot: Temperature AVG')\nplt.ylabel('Temperature AVG')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"### Multivariate plots to understand relationship between attributes","execution_count":null},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# Visualize succeeded vs attempted climbs per route\ndata.loc[joined_data[\"Succeeded\"]==1]\n\n# create succeeded climbs dataset\nsucceded_data = joined_data[[\"Route\",\"Succeeded\"]].groupby(\"Route\").sum().reset_index()\nsucceded_data.columns = [\"Route\", \"Succeeded\"]\n#succeded_data.head()\n\n# create attempted climbs dataset\nattempts_data = joined_data[[\"Route\",\"Attempted\"]].groupby(\"Route\").sum().reset_index()\nattempts_data.columns=[\"Route\", \"Attempted\"]\n#attempts_data.head()\n\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n\nSuccessAttempt_data = [go.Bar(x=attempts_data.Route,\n               y=attempts_data.Attempted, name = \"Attempted climb\"),\n        go.Bar(x=succeded_data.Route,\n               y=succeded_data.Succeeded, name = 'Successful climb'),]\n\nlayout = go.Layout(barmode='stack', title = 'Sucesssful vs Attempted climbs')\n\nfig = go.Figure(data=SuccessAttempt_data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# Visualize % succeess rate per route\nsuccess_rate_data = pd.merge(attempts_data, succeded_data, how=\"left\", on=[\"Route\"])\nsuccess_rate_data[\"Success Percentage\"] = (success_rate_data.Succeeded / success_rate_data.Attempted * 100)\n#success_rate_data.head(10)\n\nimport plotly.express as px\nfig = px.bar(success_rate_data, x = \"Route\", y = \"Success Percentage\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# scatter plot of 2 features\nscatter_x = data['Success Percentage']\nscatter_y = data['Temperature AVG']\nplt.scatter(scatter_x, scatter_y)\nplt.title('Relationship between climb success and temperature')\nplt.xlabel('% successful climbs')\nplt.ylabel('Average temperature')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# scatter plot matrix\nscatter_matrix(data, figsize=(10, 10))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"---","execution_count":null},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"# Modeling","execution_count":null},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"**5 Levels of ML Model Iteration:**\n1. Fitting Parameters\n2. Tuning Hyperparameters\n3. Feature Engineering\n\n---","execution_count":null},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"**Model Types**\n\n**- Linear models:**\n* Logistic Regression (LR)\n* Linear Discriminant Analysis (LDA)\n\n**- Nonlinear models:**\n* K-Nearest Neighbors (KNN)\n* Classification and Regression Trees (CART)\n* Gaussian Naive Bayes (NB)\n* Support Vector Machines (SVM)\n* Ridge Regression (RR)\n\n**- Bagging ensemble models:**\n* Random Forest (RF)\n\n---","execution_count":null},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"Split dataset into train/test set:","execution_count":null},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# Create x (independent, input) + y (dependent, output) variables\nx = data.drop(columns=['Success Percentage'])\ny = data['Success Percentage']\n\n# Split train/validation datasets (80-20%)\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=7)\n\n# dimensions of train/test set\nprint(x_train.shape, y_train.shape)\nprint(x_test.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","toc-hr-collapsed":true,"toc-nb-collapsed":true},"cell_type":"markdown","source":"## Iteration (1)","execution_count":null},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# Prepare models\nmodels = []\n\n# classification\n#models.append(('KNN', KNeighborsClassifier()))\n#models.append(('CART', DecisionTreeClassifier()))\n#models.append(('SVM', SVC(gamma='auto')))\n#models.append(('RF', RandomForestClassifier(n_estimators=100, max_features=3)))\n#models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n#models.append(('LDA', LinearDiscriminantAnalysis()))\n#models.append(('NB', GaussianNB()))\n\n# regression\nmodels.append(('RFregressor', RandomForestRegressor()))\nmodels.append(('SVR', SVR()))\nmodels.append(('KNNregressor', KNeighborsRegressor()))\nmodels.append(('LinearR', LinearRegression()))","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"### Optimize Models by Fitting Parameters (1)\n\nTrain models on train set to find the best parameters with cross validation & get the first performance measures on the validation set\n\nFind different model performance metrics part of *scikit learn* here: https://scikit-learn.org/stable/modules/model_evaluation.html","execution_count":null},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# Evaluate each model's accuracy on the validation set\nprint('Cross Validation Score: RMSE & SD')\nresults = []\nnames = []\nfor name, model in models:\n\tkfold = KFold(n_splits=10, random_state=7, shuffle=True)\n\tcv_results = cross_val_score(model, x_train, y_train, cv=kfold, scoring='neg_root_mean_squared_error')\n\tresults.append(cv_results)\n\tnames.append(name)\n\tprint('%s: %.3f (%.3f)' % (name, -cv_results.mean(), cv_results.std()))\n    \n# Visualize model comparison\nplt.boxplot(results, labels=names)\nplt.title('Model Comparison: Cross Validation Score (RMSE)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"### Evaluate Model Performance (1)","execution_count":null},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"Performance metrics on ***train set***:","execution_count":null},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"print('Train Set Performance Metrics: RMSE & MAE')\nfor name, model in models:\n    trained_model = model.fit(x_train, y_train)\n    y_train_pred = trained_model.predict(x_train)\n    print('%s: %.3f (%.3f)' % (name, sqrt(mean_squared_error(y_train, y_train_pred)), (mean_absolute_error(y_train, y_train_pred))))","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"Performance metrics on ***test set***:","execution_count":null},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"print('Test Set Performance Metrics: RMSE & MAE')\nfor name, model in models:\n    trained_model = model.fit(x_train, y_train)\n    y_test_pred = trained_model.predict(x_test)\n    print('%s: %.3f (%.3f)' % (name, sqrt(mean_squared_error(y_test, y_test_pred)), (mean_absolute_error(y_test, y_test_pred))))","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"#### *EXTRA: deep error check on individual model*","execution_count":null},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# Train model\nRFregressor = RandomForestRegressor().fit(x_train, y_train)\n\n\n# Predict y on train set\ny_train_pred = RFregressor.predict(x_train)\n\n# Train set performance metrics\nprint('Train Set Performance Metrics: RMSE')\nprint('%.3f' % (sqrt(mean_squared_error(y_train, y_train_pred))))\n\n# Predict y on test set\ny_test_pred = RFregressor.predict(x_test)\n\n# Test set performance metrics\nprint('Train Set Performance Metrics: RMSE')\nprint('%.3f' % (sqrt(mean_squared_error(y_test, y_test_pred))))","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# Visualize predicted vs actual mountain climb 'Success Percentage' -- if perfect, then a diagonal line\nplt.scatter(y_test, y_test_pred, alpha = 0.5)\nplt.xlabel('Actual')\nplt.ylabel('Predictions')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","toc-hr-collapsed":true,"toc-nb-collapsed":true},"cell_type":"markdown","source":"## Iteration (2)","execution_count":null},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"### Preprocess Data (2)\n#### Normalization (Min-Max)","execution_count":null},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# Min-Max norm all features\nminmax_scaler = MinMaxScaler()\nx_norm = minmax_scaler.fit_transform(x)\nx = pd.DataFrame(x_norm, columns=x.columns)\nx.head()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"Split *rescaled* dataset into train/test set:","execution_count":null},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# Split train/validation datasets (80-20%)\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=7)\n\n# dimensions of train/test set\nprint(x_train.shape, y_train.shape)\nprint(x_test.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"### Optimize Models by Fitting Parameters (2)","execution_count":null},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# Evaluate each model's accuracy on the validation set\nprint('Cross Validation Score: RMSE & SD')\nresults = []\nnames = []\nfor name, model in models:\n\tkfold = KFold(n_splits=10, random_state=7, shuffle=True)\n\tcv_results = cross_val_score(model, x_train, y_train, cv=kfold, scoring='neg_root_mean_squared_error')\n\tresults.append(cv_results)\n\tnames.append(name)\n\tprint('%s: %.3f (%.3f)' % (name, -cv_results.mean(), cv_results.std()))\n    \n# Visualize model comparison\nplt.boxplot(results, labels=names)\nplt.title('Model Comparison: Cross Validation Score (RMSE)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"### Evaluate Model Performance (2)","execution_count":null},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"Performance metrics on ***train set***:","execution_count":null},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"print('Train Set Performance Metrics: RMSE & MAE')\nfor name, model in models:\n    trained_model = model.fit(x_train, y_train)\n    y_train_pred = trained_model.predict(x_train)\n    print('%s: %.3f (%.3f)' % (name, sqrt(mean_squared_error(y_train, y_train_pred)), (mean_absolute_error(y_train, y_train_pred))))","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"Performance metrics on ***test set***:","execution_count":null},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"print('Test Set Performance Metrics: RMSE & MAE')\nfor name, model in models:\n    trained_model = model.fit(x_train, y_train)\n    y_test_pred = trained_model.predict(x_test)\n    print('%s: %.3f (%.3f)' % (name, sqrt(mean_squared_error(y_test, y_test_pred)), (mean_absolute_error(y_test, y_test_pred))))","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"#### *EXTRA: deep error check on individual model*","execution_count":null},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# Train model\nRFregressor = RandomForestRegressor().fit(x_train, y_train)\n\n\n# Predict y on train set\ny_train_pred = RFregressor.predict(x_train)\n\n# Train set performance metrics\nprint('Train Set Performance Metrics: RMSE')\nprint('%.3f' % (sqrt(mean_squared_error(y_train, y_train_pred))))\n\n# Predict y on test set\ny_test_pred = RFregressor.predict(x_test)\n\n# Test set performance metrics\nprint('Train Set Performance Metrics: RMSE')\nprint('%.3f' % (sqrt(mean_squared_error(y_test, y_test_pred))))","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# Visualize predicted vs actual mountain climb 'Success Percentage' -- if perfect, then a diagonal line\nplt.scatter(y_test, y_test_pred, alpha = 0.5)\nplt.xlabel('Actual')\nplt.ylabel('Predictions')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","toc-hr-collapsed":true,"toc-nb-collapsed":true},"cell_type":"markdown","source":"## Iteration (3)","execution_count":null},{"metadata":{"Collapsed":"false","toc-hr-collapsed":true,"toc-nb-collapsed":true},"cell_type":"markdown","source":"### Optimize Models by Tuning Hyperparameters (3)","execution_count":null},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"Random Forest Regressor had the best metrics in previous iterations, therefore let's only tune the hyperparameters for this one model.","execution_count":null},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# Random Forest Regressor (RFregressor)\n#Create dictionary of hyperparameters that we want to tune\nRFR_params = {\n    'bootstrap': [True],\n    'max_depth': [80, 90, 100, 110],\n    'max_features': [2, 3],\n    'min_samples_leaf': [3, 4, 5],\n    'min_samples_split': [8, 10, 12],\n    'n_estimators': [100, 200, 300, 1000]\n}\n\n# Create new RandomForestRegressor object using GridSearch\ngrid_RFR = GridSearchCV(RandomForestRegressor(), RFR_params, cv=3)\n\n#Fit the model\nbest_model_RFR = grid_RFR.fit(x_train, y_train)\n\n# Print the value of best hyperparameters\n#print('Best n_neighbors:', best_model_RFR.best_estimator_.get_params()['n_neighbors'])\n#print('Best n_neighbors:', best_model_RFR.best_estimator_.get_params()['weights'])\n#print('Best n_neighbors:', best_model_RFR.best_estimator_.get_params()['metric'])\n#print('Best leaf_size:', best_model_RFR.best_estimator_.get_params()['leaf_size'])\n#print('Best p:', best_model_RFR.best_estimator_.get_params()['p'])\nprint(best_model_RFR.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","toc-hr-collapsed":true,"toc-nb-collapsed":true},"cell_type":"markdown","source":"### Evaluate Model Performance (3)","execution_count":null},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# Predict y on train set\ny_train_pred_2 = best_model_RFR.predict(x_train)\n\n# Train set performance metrics\nprint('Train Set Performance Metrics: RMSE')\nprint('%.3f' % (sqrt(mean_squared_error(y_train, y_train_pred_2))))\n\n# Predict y on test set\ny_test_pred_2 = best_model_RFR.predict(x_test)\n\n# Test set performance metrics\nprint('Train Set Performance Metrics: RMSE')\nprint('%.3f' % (sqrt(mean_squared_error(y_test, y_test_pred_2))))","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# Visualize predicted vs actual mountain climb 'Success Percentage' -- if perfect, then a diagonal line\nplt.scatter(y_test, y_test_pred_2, alpha = 0.5)\nplt.xlabel('Actual')\nplt.ylabel('Predictions')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"# Save final model","execution_count":null},{"metadata":{"Collapsed":"false","trusted":false},"cell_type":"code","source":"# Save model to disk\nFinalModel_RandomForestRegressor = 'FinalModel.sav'\npickle.dump(best_model_RFR, open(FinalModel_RandomForestRegressor, 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"Collapsed":"false"},"cell_type":"markdown","source":"**Final Notes**\n* The best model was Random Forest Regressor. \n* We dummified the Route, normalized the features, tuned parameters and hyperparamters.\n* The RMSE of the model's performance in predicting the % successf rate of reaching the peak of Mt Rainier was only improved from 0.439 to 0.436. The dataset is too small (1889 total rows) for room for extensive further optimization and tuning and improvements. \n* In the future, we could try with a much larger dataset. ","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}