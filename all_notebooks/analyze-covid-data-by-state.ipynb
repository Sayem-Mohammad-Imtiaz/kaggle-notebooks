{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport datetime\nfrom datetime import datetime\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nimport math\n\npd.set_option(\"display.max_columns\", None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir(\"../input/uncover/UNCOVER/covid_tracking_project/\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Import data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\ndef load_data():\n  # Run this cell to download our data into a file called 'cifar_data'\n  import gdown\n  gdown.download('https://drive.google.com/uc?id=1-BjeqccJdLiBA6PnNinmXSQ6w5BluLem','cifar_data','True'); # dogs v road;\n\n  # now load the data from our cloud computer\n  import pickle\n  data_dict = pickle.load(open( \"cifar_data\", \"rb\" ));\n  \n  data   = data_dict['data']\n  labels = data_dict['labels']\n  \n  return data, labels\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_DIR = \"../input/uncover/UNCOVER/covid_tracking_project/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_covid_data = pd.read_csv(DATA_DIR + \"covid-statistics-by-us-states-daily-updates.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# how many rows do we have?\nus_covid_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### What does each row represent?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# ANSWER: one state's cases, for one day\nus_covid_data.iloc[0, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get basic summary statistics\nus_covid_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get number of NaNs\nus_covid_data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get only the columns that don't have a lot of NaNs","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_us_covid_data = us_covid_data[[\"date\", \"state\", \"positive\", \"negative\", \"death\", \"total\", \"totaltestresults\", \n                                        \"deathincrease\", \"hospitalizedincrease\", \"negativeincrease\", \"positiveincrease\", \n                                        \"totaltestresultsincrease\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, let's do some EDA:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# check out the number of positive test cases, across all states, by day since April 28th\nus_covid_data[\"positive\"].hist()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check out negative cases\nus_covid_data[\"negative\"].hist()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check out, by state\nstate = input(\"Insert the abbreviation for the state:\")\nprint(\"\\n\")\n\nif state not in filtered_us_covid_data[\"state\"].unique():\n    raise ValueError(\"Abbreviation isn't a state. Please try again\")\n\nprint(f\"You've chosen to see the data for the state of {state}\")\n\n# check out positive graphs\nus_covid_data[us_covid_data[\"state\"] == state][\"positive\"].hist()\nplt.title(f\"Graph of positive COVID cases, from January 22nd to April 28th, for the state of {state}\")\nplt.xlabel(\"Number of cases, on a given day\")\nplt.ylabel(\"Number of days with that many cases\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can model the date by the number of days since the first COVID case was reported in America, to avoid time series calculations and turn the date aspect into a simpler regression question. \n\nLet's set the first day to be January 22nd (since this is the first day in the dataset)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert date column to dates (from string)\nus_covid_data[\"converted_date\"] = pd.to_datetime(us_covid_data[\"date\"], format=\"%Y-%m-%d\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set date as the index\nus_covid_data.set_index(\"converted_date\", inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_covid_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_covid_data[us_covid_data[\"state\"] == state][\"positive\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's get the week of the date","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"us_covid_data[\"week_of_year\"] = pd.Int64Index(us_covid_data.index.isocalendar().week)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check out, by state\nstate = input(\"Insert the abbreviation for the state:\")\nprint(\"\\n\")\n\nif state not in filtered_us_covid_data[\"state\"].unique():\n    raise ValueError(\"Abbreviation isn't a state. Please try again\")\n\nprint(f\"You've chosen to see the data for the state of {state}\")\n\n# check out positive graphs\nus_covid_data[us_covid_data[\"state\"] == state][[\"positive\", \"week_of_year\"]].plot(x = \"week_of_year\", y = \"positive\")\nplt.title(f\"Number of positive cases, by week, for the state of {state}\")\nplt.ylabel(\"Number of positive cases\")\nplt.xlabel(\"Week of the year\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see if we can predict the increase in positive test cases, by week, and see if we can predict this using other metrics. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# create X, y training sets\nX = us_covid_data[[\"state\",\"positive\", \"negative\",\"total\", \"totaltestresults\", \"deathincrease\", \"week_of_year\"]]\ny = us_covid_data[\"positiveincrease\"]\n\n# let's set the index to be the state\nX.set_index(\"state\", inplace=True)\n\n# let's impute any NaNs with 0\nX.fillna(0, inplace=True)\ny.fillna(0, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pt 2: Model Fitting with Linear Regression","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Linear regression is a statistical approach to find and determine a relationship among an independent variable `x` and a dependent variable `y`. For us, our `x` is `Age` while our `y` is `Selling_Price`. In the below equation, linear regression helps us find the `m` and `b` that best relates our variables. \n\n$y= mx + b$\n\nAnother way to say this is: we create a line that 'summarizes' the story that the data tells us. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Let's explore linear regression through a demo!**\n\n[Playground!](http://setosa.io/ev/ordinary-least-squares-regression/)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's first start with a train-test split (80:20 split)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# first model: linear regression\nfrom sklearn import linear_model\n\n# set up our model\nlinear = linear_model.LinearRegression(fit_intercept = True)\n\n# train the model \nlinear.fit(X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make predictions\ny_pred = linear.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate performance with MSE\nfrom sklearn.metrics import mean_squared_error\n\n# calculate MSE\nmse_linear = mean_squared_error(y_true = y_test, \n                                y_pred = y_pred)\n\n# get RMSE\nrmse_linear = math.sqrt(mse_linear / X_test.shape[0])\n\nprint(f\"Our RMSE (root mean squared error) for the linear regression is: {rmse_linear}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pt 3: Neural Networks\n\nNow, let's try to create a neural network","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To build a simple neural network, we use `MLPClassifier` from scikit-learn. We will play with the **number of neurons** and the **number of hidden layers** to adjust the complexity of our model! Just like we did in Playground. \n\nLet's see how well we can do. :) \n\n**Example 1:**\n\nIf we want to create a neural network with 1 hidden layer and 3 neurons, we would say:\n\n`nnet = MLPClassifier(hidden_layer_sizes=(3)) `\n\n**Example 2:**\n\nIf we want to create a neural network with 2 hidden layers and 3 neurons in each layer:\n\n`nnet = MLPClassifier(hidden_layer_sizes=(3, 3)) `","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create and train our multi layer perceptron model\nnnet = MLPClassifier(hidden_layer_sizes=(3, 3, 3), max_iter= 100)  ## How many hidden layers? How many neurons does this have?\nnnet.fit(X_train, y_train)\n\n# Predict what the classes are based on the testing data\nnnet_preds = nnet.predict(X_test)\n\n# calculate MSE\nmse_nnet = mean_squared_error(y_true = y_test, \n                              y_pred = nnet_preds)\n\n# get RMSE\nrmse_nnet = math.sqrt(mse_nnet / X_test.shape[0])\n\nprint(f\"Our RMSE (root mean squared error) for the neural network is: {rmse_nnet}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**How well did your neural network perform?** \n\nMultilayer perceptrons are more complex models and it can be difficult to find the right \"settings\" for them. It takes some trial and error!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for ilayer in [(1,1), (3,3), (5,5), (8,6), (10,10,10), (10,10,5)]:\n    \n    # get shape of hidden layers\n    print(f\"Shape of hidden layers: {ilayer}\")\n\n    # fit neural net\n    nnet = MLPClassifier(hidden_layer_sizes=ilayer, max_iter= 1000)  ## How many hidden layers? How many neurons does this have?\n    nnet.fit(X_train, y_train)\n\n    # Predict what the classes are based on the testing data\n    nnet_preds = nnet.predict(X_test)\n\n    # calculate MSE\n    mse_nnet = mean_squared_error(y_true = y_test, \n                                  y_pred = nnet_preds)\n\n    # get RMSE\n    rmse_nnet = math.sqrt(mse_nnet / X_test.shape[0])\n\n    # print results\n    print(f\"Our parameters are: {size} layers, {numNeurons} neurons, and {numIt} iterations\\nOur RMSE (root mean squared error) for the neural network on the test set is: {rmse_nnet}\")\n    print(\"=====================\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}