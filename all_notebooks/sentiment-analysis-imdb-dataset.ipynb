{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**NLP stands for Natural Language Processing which is the task of mining the text and find out some meaningful insights like Sentiments, Named Entity, Topic of Discussion and even Summary of the text.**\n\nWith this IMDB dataset we will do the Sentiment Analysis.\n\nFirstly,we will apply some text cleaning techniques i.e do some text pre-processing since textual data is in free form.\n\nSince we cannot apply text to our Machine Learning Model directly we have to convert the text into mathematical form (vector representation) and explore different Vectorization / Text Encoding Techniques. ","metadata":{}},{"cell_type":"markdown","source":"***Importing basic libraries***","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Loading dataset***","metadata":{}},{"cell_type":"code","source":"dataset = pd.read_csv('../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\n\nprint(dataset.shape)\ndataset.head(10)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**There are two columns - review and sentiment.\nSentiment is the target column that we have to predict further.**","metadata":{}},{"cell_type":"code","source":"dataset['sentiment'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Dataset is balanced and has equal number of positive and negative sentiments.*","metadata":{}},{"cell_type":"markdown","source":"**Taking one review as sample and understanding the need of cleaning the text.**","metadata":{}},{"cell_type":"code","source":"review = dataset['review'].iloc[1]\nreview","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**In general any NLP task involves the following text cleaning techniques -**\n1. Removal of HTML contents like \"\\<br>\"\n2. Removal of punctuation and special characters.\n3. Removal of stopwords like the, when, how etc which do not offer much insights.\n4. Stemming/Lemmatization techniques to have the stem word of the words having multiple forms of words.\n5. Vectorization - encoding the textual data to numerical form after cleaning.\n6. Fitting the data to ML model.\n\n\n","metadata":{}},{"cell_type":"markdown","source":"**Applying the techniques to sample data to understand the process first -**","metadata":{}},{"cell_type":"markdown","source":"1. Removal of HTML contents","metadata":{}},{"cell_type":"code","source":"!pip install bs4\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from bs4 import BeautifulSoup\n\nsoup = BeautifulSoup(review, 'html.parser')\nreview = soup.get_text()\nreview","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**HTML tags are removed now remove everything except the lowercase/uppercase letters using regular expressions**","metadata":{}},{"cell_type":"code","source":"import re\nreview = re.sub('\\[[^]]*/]',' ',review)\nreview = re.sub('[^a-zA-Z]',' ',review)\nreview","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now converting everthing into lowercase**","metadata":{}},{"cell_type":"code","source":"review =  review.lower()\nreview","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now removal of Stopwords (common words) and for this we will create a list of words separated by .split().**\n\n**Note:- Split function splits a sentences by their whitespaces and returns a list containing words**","metadata":{}},{"cell_type":"code","source":"review = review.split()\nreview","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\n\nfrom nltk.corpus import stopwords\n\nreview = [word for word in review if not word in set(stopwords.words('english'))]\nreview","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Stemming/Lemmatization**\nWill apply and observe the differences in both the techniques.","metadata":{}},{"cell_type":"code","source":"from nltk.stem import PorterStemmer\nstemmer = PorterStemmer()\n\nreview_stemmer = [stemmer.stem(word) for word in review]\nreview_stemmer = ' '.join(review_stemmer)\nreview_stemmer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()\nreview_lemmatize = [lemmatizer.lemmatize(word) for word in review]\nreview_lemmatize = ' '.join(review_lemmatize)\nreview_lemmatize","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As seen in both the paragraphs the Stemming does not impart proper meaning to the stem word while in Lemmatizing stem words conveys a meaning ***eg-  fantasi & fantasy respectively.***\n\n**We will use Lemmatized review further**.","metadata":{}},{"cell_type":"markdown","source":"Now we will do Vectorization of out text for this we will create a corpus first.","metadata":{}},{"cell_type":"code","source":"corpus = []\ncorpus.append(review_lemmatize)\ncorpus","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**To vectorize we will apply -**\n1. Bag of Words model ( CountVectorizer)\n2. TF - IDF model (TfidfVectorizer)\n3.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer()\nx = cv.fit_transform(corpus).toarray()\nx","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf  =  TfidfVectorizer()\n\nreview_tfidf = tfidf.fit_transform(corpus).toarray()\nreview_tfidf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now we will apply the techiques on whole dataset keeping aside 25% of data for testing purposes**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(dataset['review'], dataset['sentiment'], test_size=0.25, random_state=42)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Converting sentiments into numerical form**","metadata":{}},{"cell_type":"code","source":"y_train = y_train.replace({'positive':1, 'negative':0})\ny_test = y_test.replace({'positive':1, 'negative':0})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Cleaning text and forming train and test corpus**","metadata":{}},{"cell_type":"code","source":"x_train.iloc[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpus_train = []\ncorpus_test = []\n\nfor i in range(x_train.shape[0]):\n    soup = BeautifulSoup(x_train.iloc[i],'html.parser')\n    review = soup.get_text()\n    review = re.sub('/[[^]]*/]',' ',review)\n    review = re.sub('[^a-zA-Z]',' ',review)\n    review = review.lower()\n    review = review.split()\n    \n    lm  = WordNetLemmatizer()\n    review = [lm.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    corpus_train.append(review)\n\n\nfor j in range(x_test.shape[0]):\n    soup = BeautifulSoup(x_test.iloc[j],'html.parser')\n    review = soup.get_text()\n    review = re.sub('/[[^]]*/]',' ',review)\n    review = re.sub('[^a-zA-Z]',' ',review)\n    review = review.lower()\n    review = review.split()\n    \n    lm = WordNetLemmatizer()\n    review = [lm.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    corpus_test.append(review)\n    \n    \n    \n\n\n    \n    \n  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Validating sample entry**","metadata":{}},{"cell_type":"code","source":"corpus_train[-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpus_test[-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Vectorization using TF-IDF Technique**","metadata":{}},{"cell_type":"code","source":"tfidf = TfidfVectorizer(ngram_range = (1, 3))\n\ntfidf_train = tfidf.fit_transform(corpus_train)\ntfidf_test = tfidf.transform(corpus_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Using Linear SupportVectorClassifier(SVC) as first model-**","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import LinearSVC\n\nlinear_svc = LinearSVC(C=0.5, random_state=42)\nlinear_svc.fit(tfidf_train,y_train)\n\npredict = linear_svc.predict(tfidf_test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Performance Metric**\n- Classification Report\n- Confusion Matrix\n- Accuracy Score","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\nprint('Classification Report: \\n', classification_report(y_test, predict, target_names = ['Negative', 'Positive']))\nprint('Confusion Matrix: \\n', confusion_matrix(y_test, predict))\nprint('Accuracy score: \\n', accuracy_score(y_test, predict))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}