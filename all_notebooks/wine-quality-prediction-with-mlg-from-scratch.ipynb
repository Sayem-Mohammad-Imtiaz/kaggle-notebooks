{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reading the data\nx1 = df['fixed acidity'].values\nx2 = df['volatile acidity'].values\nx3 = df['citric acid'].values\nx4 = df['residual sugar'].values\nx5 = df['chlorides'].values\nx6 = df['free sulfur dioxide'].values\nx7 = df['total sulfur dioxide'].values\nx8 = df['density'].values\nx9 = df['pH'].values\nx10 = df['sulphates'].values\nx11 = df['alcohol'].values\ny = df['quality'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feature scaling using Mean Normalization\nX1=x1\nX2=x2\nX3=x3\nX4=x4\nX5=x5\nX6=(x6-x6.mean())/x6.std()\nX7=(x7-x7.mean())/x7.std()\nX8=x8\nX9=x9\nX10=x10\nX11=x11","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#hypothesis\ndef hypothesis(theta, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11):\n    return theta[0] + theta[1]*x1 + theta[2]*x2 + theta[3]*x3 + theta[4]*x4 + theta[5]*x5 + theta[6]*x6 + theta[7]*x7 + theta[8]*x8 + theta[9]*x9 + theta[10]*x10 + theta[11]*x11","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cost function\ndef cost(theta, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, y):\n    m = x1.shape[0]\n    error = 0\n    for i in range(m):\n        hx = hypothesis(theta, x1[i], x2[i], x3[i], x4[i], x5[i], x6[i], x7[i], x8[i], x9[i], x10[i], x11[i])\n        error = error + (hx - y[i])**2\n    return error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#partial derivative of the cost function\ndef diffGradient(theta, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, y):\n    m = x1.shape[0]\n    grad = np.zeros((12,))\n    for i in range(m):\n        hx = hypothesis(theta, x1[i], x2[i], x3[i], x4[i], x5[i], x6[i], x7[i], x8[i], x9[i], x10[i], x11[i])\n        grad[0] = grad[0] + (hx - y[i])\n        grad[1] = grad[1] + (hx - y[i])*x1[i]\n        grad[2] = grad[2] + (hx - y[i])*x2[i]\n        grad[3] = grad[3] + (hx - y[i])*x3[i]\n        grad[4] = grad[4] + (hx - y[i])*x4[i]\n        grad[5] = grad[5] + (hx - y[i])*x5[i]\n        grad[6] = grad[6] + (hx - y[i])*x6[i]\n        grad[7] = grad[7] + (hx - y[i])*x7[i]\n        grad[8] = grad[8] + (hx - y[i])*x8[i]\n        grad[9] = grad[9] + (hx - y[i])*x9[i]\n        grad[10] = grad[10] + (hx - y[i])*x10[i]\n        grad[11] = grad[11] + (hx - y[i])*x11[i]\n    return grad","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#finding the gradient descent\ndef gradientDescent(x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, y, learning_rate = 0.0001):\n    theta = np.zeros((12,),dtype = float)\n    error_list = []\n    theta_list = []\n    max_iter = 300\n    m = x1.shape[0]\n    for i in range(max_iter):\n        grad = diffGradient(theta, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, y)\n        e = cost(theta, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, y)\n        error_list.append(e)\n        theta_list.append((theta[0],theta[1],theta[2],theta[3],theta[4],theta[5],theta[6],theta[7],theta[8],theta[9],theta[10],theta[11]))\n        #simultaneously update theta values\n        theta[0] = theta[0] - learning_rate*(1/m)*grad[0]\n        theta[1] = theta[1] - learning_rate*(1/m)*grad[1]\n        theta[2] = theta[2] - learning_rate*(1/m)*grad[2]\n        theta[3] = theta[3] - learning_rate*(1/m)*grad[3]\n        theta[4] = theta[4] - learning_rate*(1/m)*grad[4]\n        theta[5] = theta[5] - learning_rate*(1/m)*grad[5]\n        theta[6] = theta[6] - learning_rate*(1/m)*grad[6]\n        theta[7] = theta[7] - learning_rate*(1/m)*grad[7]\n        theta[8] = theta[8] - learning_rate*(1/m)*grad[8]\n        theta[9] = theta[9] - learning_rate*(1/m)*grad[9]\n        theta[10] = theta[10] - learning_rate*(1/m)*grad[10]\n        theta[11] = theta[11] - learning_rate*(1/m)*grad[11]\n    return theta, error_list, theta_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_theta, error_list, theta_list = gradientDescent(X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(final_theta)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(error_list, label='Cost Function')\nplt.xlabel(\"No. of iterations\")\nplt.ylabel(\"Error\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(theta, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11):\n    hx = hypothesis(final_theta, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11)\n    return hx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x1 = np.array([12.6])\nx2 = np.array([0.31])\nx3 = np.array([0.72])\nx4 = np.array([2.2])\nx5 = np.array([0.07200000000000001])\nx6 = np.array([6.0])\nx7 = np.array([29.0])\nx8 = np.array([0.9987])\nx9 = np.array([2.88])\nx10 = np.array([0.82])\nx11 = np.array([9.8])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = hypothesis(final_theta, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11)\nprint(prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}