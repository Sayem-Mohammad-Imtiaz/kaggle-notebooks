{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install jovian --upgrade --quiet","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing all the necessary libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom tqdm.notebook import tqdm\nimport torchvision.transforms as T\nimport torchvision.models as models\nfrom torch.utils.data import DataLoader\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import random_split\nimport jovian","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"project_name='pytorch-zero-to-gan-course-project'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Project description\n\nHere I am using a dataset of 32672 Train, 1175 Test, 1175 Validation images of size 224X224X3 jpg format having 235 bird species [Bird 235](https://www.kaggle.com/gpiosenka/100-bird-species) to train a CNN model to classify image of a never seen bird into the correct category. This is one of the classic problems of called image classification. The model uses pretrained resnet18 with last layer modified to classify the bird species.\n"},{"metadata":{},"cell_type":"markdown","source":"## Preparation of the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_DIR = \"../input/100-bird-species/train\"\nVAL_DIR = \"../input/100-bird-species/valid\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform_ds = T.Compose([\n    T.Resize((128, 128)),\n    T.RandomHorizontalFlip(),\n    T.ToTensor()\n])\n\ntrain_ds = torchvision.datasets.ImageFolder(root=TRAIN_DIR,\n                                           transform=transform_ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes= len(train_ds.classes)\nnum_classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_ds = torchvision.datasets.ImageFolder(root=VAL_DIR,\n                                         transform=transform_ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size= 512","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_dl = DataLoader(val_ds, batch_size, num_workers=4, pin_memory=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_images(train_dl):\n    for images, labels in train_dl:\n        fig, ax = plt.subplots(figsize=(12, 12))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images[:32], nrow=8).permute(1,2,0))\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_images(train_dl)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Helper function for moving the data to the GPU"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_device():\n    if torch.cuda.is_available():\n        return torch.device(\"cuda\")\n    else:\n        return torch.device(\"cpu\")\n    \ndef to_device(data, device):\n    if isinstance(data, (list, tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        for x in self.dl:\n            yield to_device(x, self.device)\n            \n    def __len__(self):\n        return len(self.dl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = get_device()\ndevice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Defining the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy(out, labels):\n    _, preds = torch.max(out, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch\n        out = self(images)\n        loss = F.cross_entropy(out, labels)\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch\n        out = self(images)\n        loss = F.cross_entropy(out, labels)\n        acc = accuracy(out, labels)\n        return {\"val_loss\": loss.detach(), \"val_acc\": acc}\n    \n    def validation_epoch_end(self, outputs):\n        batch_loss = [x[\"val_loss\"] for x in outputs]\n        epoch_loss = torch.stack(batch_loss).mean()\n        batch_acc = [x[\"val_acc\"] for x in outputs]\n        epoch_acc = torch.stack(batch_acc).mean()\n        return {\"val_loss\": epoch_loss.item(), \"val_acc\": epoch_acc.item()}\n    \n    def epoch_end(self, epoch, epochs, result):\n        print(\"Epoch: [{}/{}], last_lr: {:.6f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n        epoch+1, epochs, result[\"lrs\"][-1], result[\"train_loss\"], result[\"val_loss\"], result[\"val_acc\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" class model(ImageClassificationBase):\n     def __init__(self, num_classes):\n         super().__init__()\n         self.network = models.resnet18(pretrained=True)\n         number_of_features = self.network.fc.in_features\n         self.network.fc = nn.Linear(number_of_features, num_classes)\n        \n     def forward(self, xb):\n         return self.network(xb)\n    \n     def freeze(self):\n         for param in self.network.parameters():\n             param.requires_grad= False\n         for param in self.network.fc.parameters():\n             param.requires_grad= True\n        \n     def unfreeze(self):\n         for param in self.network.parameters():\n            param.requires_grad= True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = to_device(model(num_classes), device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training phase"},{"metadata":{"trusted":true},"cell_type":"code","source":"@torch.no_grad()\ndef evaluate(model, val_dl):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_dl]\n    return model.validation_epoch_end(outputs)\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group[\"lr\"]\n    \ndef fit_one_cycle(epochs, max_lr, model, train_dl, val_dl, weight_decay=0, grad_clip=None,\n                 opt_func=torch.optim.Adam):\n    \n    torch.cuda.empty_cache()\n    \n    history = []\n    opt = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    sched = torch.optim.lr_scheduler.OneCycleLR(opt, max_lr, epochs=epochs,\n                                                   steps_per_epoch=len(train_dl))\n    \n    for epoch in range(epochs):\n        model.train()\n        train_loss = []\n        lrs = []\n        for batch in tqdm(train_dl):\n            loss = model.training_step(batch)\n            train_loss.append(loss)\n            loss.backward()\n            \n            if grad_clip:\n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n                \n            opt.step()\n            opt.zero_grad()\n            \n            lrs.append(get_lr(opt))\n            sched.step()\n            \n        result = evaluate(model, val_dl)\n        result[\"train_loss\"] = torch.stack(train_loss).mean().item()\n        result[\"lrs\"] = lrs\n        model.epoch_end(epoch, epochs, result)\n        history.append(result)\n    return history\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = [evaluate(model, val_dl)]\nhistory","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training on current dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 10\nmax_lr = 10e-5\ngrad_clip = 0.1\nweight_decay = 10e-4\nopt_func=torch.optim.Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.freeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl, weight_decay=weight_decay,\n                        grad_clip=grad_clip, opt_func=opt_func)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 10\nmax_lr = 10e-5\ngrad_clip = 0.1\nweight_decay = 10e-4\nopt_func = torch.optim.Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history += fit_one_cycle(epochs, max_lr, model, train_dl, val_dl, \n                        weight_decay=weight_decay, grad_clip=grad_clip,\n                        opt_func=opt_func)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test prediction\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"TEST_DIR = \"../input/100-bird-species/test\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform_test = T.Compose([\n    T.Resize((128,128)),\n    T.ToTensor()\n])\ntest_ds = torchvision.datasets.ImageFolder(root=TEST_DIR,\n                                          transform=transform_test)\ndef prediction(model, images):\n    xb = to_device(images.unsqueeze(0), device)\n    out = model(xb)\n    _, preds = torch.max(out, dim=1)\n    predictions = test_ds.classes[preds[0].item()]\n    return predictions\nimages, labels = test_ds[0]\nprint(\"Label: \", test_ds.classes[labels])\nprint(\"Prediction: \", prediction(model, images))\nplt.imshow(images.permute(1,2,0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Performace measure\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = [x[\"val_acc\"] for x in history]\nplt.plot(accuracy, \"-rx\")\nplt.title(\"Accuracy vs number of epochs\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_loss = [x[\"val_loss\"] for x in history]\ntrain_loss = [x.get(\"train_loss\") for x in history]\nplt.plot(val_loss, \"-bx\")\nplt.plot(train_loss, \"-gx\")\nplt.title(\"Losses vs number of epochs\")\nplt.legend([\"Validation loss\", \"Train loss\"])\nplt.xlabel(\"Epochs\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model.state_dict(), 'BirdsResNet18.pth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jovian.commit(project=project_name, output=['BirdsResNet18.pth'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jovian.log_metrics(train_loss=history[-1]['train_loss'], \n                   val_loss=history[-1]['val_loss'], \n                   val_acc=history[-1]['val_acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}