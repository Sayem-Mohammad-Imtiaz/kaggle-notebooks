{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Visualization tools**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clone the tensorflow models repository\n!git clone --depth 1 https://github.com/tensorflow/models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%bash\nsudo apt install -y protobuf-compiler\ncd /kaggle/working/models/research\nprotoc object_detection/protos/*.proto --python_out=.\ncp object_detection/packages/tf2/setup.py .\npython -m pip install .","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from object_detection.utils import label_map_util\nfrom object_detection.utils import visualization_utils as viz_utils\nfrom object_detection.utils import ops as utils_ops","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH_TO_LABELS = './models/research/object_detection/data/mscoco_label_map.pbtxt'\ncategory_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"COCO17_HUMAN_POSE_KEYPOINTS = [(0, 1),\n (0, 2),\n (1, 3),\n (2, 4),\n (0, 5),\n (0, 6),\n (5, 7),\n (7, 9),\n (6, 8),\n (8, 10),\n (5, 6),\n (5, 11),\n (6, 12),\n (11, 12),\n (11, 13),\n (13, 15),\n (12, 14),\n (14, 16)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pathlib\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport io\nimport scipy.misc\nimport numpy as np\nfrom six import BytesIO\nfrom PIL import Image, ImageDraw, ImageFont\nfrom six.moves.urllib.request import urlopen\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\ntf.get_logger().setLevel('ERROR')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2 as cv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_np = cv.imread('../input/kitti-object-detection/kitti_single/training/image_2/000018.png')\nimage_np = cv.cvtColor(image_np, cv.COLOR_BGR2RGB)\nimage_np = np.expand_dims(image_np,axis=0)\n#img = cv.resize(img,(512,512))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_np.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nplt.imshow(image_np[0])\nplt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_tensor = tf.convert_to_tensor(image_np)\nimage_tensor = tf.cast(image_tensor,tf.uint8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply image detector on a single image.\ndetector = hub.load(\"https://tfhub.dev/tensorflow/centernet/hourglass_512x512_kpts/1\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = detector(image_tensor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tensor转化成numpy\nresult = {key:value.numpy() for key,value in results.items()}\nprint(result.keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_id_offset = 0\nimage_np_with_detections = image_np.copy()\n\n# Use keypoints if available in detections\nkeypoints, keypoint_scores = None, None\nif 'detection_keypoints' in result:\n  keypoints = result['detection_keypoints'][0]\n  keypoint_scores = result['detection_keypoint_scores'][0]\n\nviz_utils.visualize_boxes_and_labels_on_image_array(\n      image_np_with_detections[0],\n      result['detection_boxes'][0],\n      (result['detection_classes'][0] + label_id_offset).astype(int),\n      result['detection_scores'][0],\n      category_index,\n      use_normalized_coordinates=True,\n      max_boxes_to_draw=200,\n      min_score_thresh=.30,\n      agnostic_mode=False,\n      keypoints=keypoints,\n      keypoint_scores=keypoint_scores,\n      keypoint_edges=COCO17_HUMAN_POSE_KEYPOINTS)\n\nplt.figure(figsize=(24,32))\nplt.imshow(image_np_with_detections[0])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}