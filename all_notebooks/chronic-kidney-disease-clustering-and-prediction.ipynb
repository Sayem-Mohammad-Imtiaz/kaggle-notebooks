{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n## إن الحمد لله، نحمده و نستعينه ونستغفره\n## ونعوذ بالله من شرور انفسنا ومن سيئات أعمالنا\n##   من يهده الله فلا مضل له، ومن يضلل فلا هادي له \n## وأشهد أن لا إله إلا الله وحده لا شريك له\n##   وأشهد أن محمدا عبده ورسوله، صلى الله عليه وعلى آله وسلم","metadata":{"_kg_hide-input":true}},{"cell_type":"markdown","source":"# Project: Chronic Kidney Disease: Clustering & Prediction\n### By: Mahmoud Limam, a Data Science Student at Enet'com, Tunisia.","metadata":{}},{"cell_type":"markdown","source":"## This project is made of three parts:\n### - Pre-processing\n### - Exploratory Data Analysis\n### - Clustering & Prediction","metadata":{}},{"cell_type":"markdown","source":"## A brief description:\n### Data:\nI found the dataset on Kaggle.  \nLink: https://archive.ics.uci.edu/ml/datasets/Chronic_Kidney_Disease.  \n\nIt contains measures of 24 features for 400 people. Quite a lot of features for just 400 samples.  \n14 features are numerical, while 10 are categorical.\n### Pre-processing:\n   I Started with data cleaning because of typos and mistyped features.   \nMissing values were imputed with KNN.  \nI had to try many transformers before imputing.\n### Exploratory Data Analysis:\nI plotted graphs showing distributions of features and relationships between them.  \nDidn't see much correlation, but one can further do hypothesis testing to be more certain.  \nThis was also indicated by the fact that PCA didn't make any significant difference, and that Naive Bayes performed impressively.   \nI got the idea to use subplots from this notebook: https://www.kaggle.com/andreshg/xgboost-optuna-hyperparameter-tunning  \nI know subplots are a common thing, but I still wish to thank the author https://www.kaggle.com/andreshg  \n### Prediction & Cluster Analysis:\n   I actually used a clustering algorithm as a predictor. I thought that if the clusters corresponded with the target categories, then we'd have a predictive model and also different clusters to analyse for each category.  \nIt worked.  \nThen I compared different supervised models, combining them with Principal Component Analysis.  \nI also trained two neural nets of different sizes.","metadata":{}},{"cell_type":"markdown","source":"### بسم الله","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\nimport warnings\nwarnings.filterwarnings(action='ignore')","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2021-01-16T13:44:16.000508Z","iopub.status.busy":"2021-01-16T13:44:15.9999Z","iopub.status.idle":"2021-01-16T13:44:16.004056Z","shell.execute_reply":"2021-01-16T13:44:16.004523Z"},"papermill":{"duration":0.034112,"end_time":"2021-01-16T13:44:16.004695","exception":false,"start_time":"2021-01-16T13:44:15.970583","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pre-processing","metadata":{}},{"cell_type":"markdown","source":"### A bit of exploration","metadata":{}},{"cell_type":"code","source":"data=pd.read_csv(\"../input/ckdisease/kidney_disease.csv\")","metadata":{"execution":{"iopub.execute_input":"2021-01-16T13:44:16.070424Z","iopub.status.busy":"2021-01-16T13:44:16.069752Z","iopub.status.idle":"2021-01-16T13:44:16.088839Z","shell.execute_reply":"2021-01-16T13:44:16.088227Z"},"papermill":{"duration":0.05947,"end_time":"2021-01-16T13:44:16.088945","exception":false,"start_time":"2021-01-16T13:44:16.029475","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head(10)","metadata":{"execution":{"iopub.execute_input":"2021-01-16T13:44:16.141181Z","iopub.status.busy":"2021-01-16T13:44:16.14029Z","iopub.status.idle":"2021-01-16T13:44:16.180864Z","shell.execute_reply":"2021-01-16T13:44:16.180277Z"},"papermill":{"duration":0.067694,"end_time":"2021-01-16T13:44:16.180988","exception":false,"start_time":"2021-01-16T13:44:16.113294","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see there are missing values.  \nIf their number is considerable, then we'd have to be careful about which imputation technique to use.  \nThere is also an extra 'id' column that needs to be dropped.","metadata":{}},{"cell_type":"code","source":"data.columns","metadata":{"execution":{"iopub.execute_input":"2021-01-16T13:44:16.237333Z","iopub.status.busy":"2021-01-16T13:44:16.236693Z","iopub.status.idle":"2021-01-16T13:44:16.241203Z","shell.execute_reply":"2021-01-16T13:44:16.240589Z"},"papermill":{"duration":0.034504,"end_time":"2021-01-16T13:44:16.241311","exception":false,"start_time":"2021-01-16T13:44:16.206807","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Feature names are abbreviated.  \nYou can find their descriptions in the link i provided above.","metadata":{}},{"cell_type":"code","source":"for i in data.drop(\"id\",axis=1).columns:\n    print('unique values in \"{}\":\\n'.format(i),data[i].unique())","metadata":{"execution":{"iopub.execute_input":"2021-01-16T13:44:16.302773Z","iopub.status.busy":"2021-01-16T13:44:16.298831Z","iopub.status.idle":"2021-01-16T13:44:16.321671Z","shell.execute_reply":"2021-01-16T13:44:16.321119Z"},"papermill":{"duration":0.054593,"end_time":"2021-01-16T13:44:16.32178","exception":false,"start_time":"2021-01-16T13:44:16.267187","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see there are typos that need to be fixed.  \nIt's good that there are no missing values in the target column.  \nPlus, every categorical feature has 2 values, which means OHE won't add dimensions.","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Many features are mistyped.  \nSome features have quite a lot of missing values.  \nOne option is to drop them, but i prefer to impute them with a decent imputation technique that preserves distributions.  \nThere are many techniques to choose from.  \nI'll be using the KNNImputer from sklearn.","metadata":{}},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can see that some features have some serious outliers.  ","metadata":{}},{"cell_type":"markdown","source":"### Data Cleaning","metadata":{}},{"cell_type":"markdown","source":"Let's deal with typos first. ","metadata":{}},{"cell_type":"code","source":"for i in range(data.shape[0]):\n    if data.iloc[i,25]=='ckd\\t':\n        data.iloc[i,25]='ckd'\n    if data.iloc[i,20] in [' yes','\\tyes']:\n        data.iloc[i,20]='yes'\n    if data.iloc[i,20]=='\\tno':\n        data.iloc[i,20]='no'\n    if data.iloc[i,21]=='\\tno':\n        data.iloc[i,21]='no'\n    if data.iloc[i,16]=='\\t?':\n        data.iloc[i,16]=np.nan\n    if data.iloc[i,16]=='\\t43':\n        data.iloc[i,16]='43'\n    if data.iloc[i,17]=='\\t?':\n        data.iloc[i,17]=np.nan\n    if data.iloc[i,17]=='\\t6200':\n        data.iloc[i,17]= '6200'\n    if data.iloc[i,17]=='\\t8400':\n        data.iloc[i,17]= '6200'\n    if data.iloc[i,18]=='\\t?':\n        data.iloc[i,18]=np.nan\n    if data.iloc[i,25]=='ckd':\n        data.iloc[i,25]='yes'\n    if data.iloc[i,25]=='notckd':\n        data.iloc[i,25]='no'","metadata":{"execution":{"iopub.execute_input":"2021-01-16T13:44:17.775887Z","iopub.status.busy":"2021-01-16T13:44:17.775346Z","iopub.status.idle":"2021-01-16T13:44:17.781179Z","shell.execute_reply":"2021-01-16T13:44:17.781628Z"},"papermill":{"duration":0.035786,"end_time":"2021-01-16T13:44:17.781754","exception":false,"start_time":"2021-01-16T13:44:17.745968","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we drop that extra 'id' column.","metadata":{}},{"cell_type":"code","source":"data.drop('id',axis=1,inplace=True)\ndata.head()","metadata":{"execution":{"iopub.execute_input":"2021-01-16T13:44:18.490593Z","iopub.status.busy":"2021-01-16T13:44:18.489884Z","iopub.status.idle":"2021-01-16T13:44:18.49439Z","shell.execute_reply":"2021-01-16T13:44:18.493733Z"},"papermill":{"duration":0.060416,"end_time":"2021-01-16T13:44:18.494505","exception":false,"start_time":"2021-01-16T13:44:18.434089","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As feature names are abbreviated, I thought it would be better to use their actual (and meaningful) names.  ","metadata":{}},{"cell_type":"code","source":"feature_names=['Age (yrs)','Blood Pressure (mm/Hg)','Specific Gravity','Albumin','Sugar','Red Blood Cells',\n               'Pus Cells','Pus Cell Clumps','Bacteria','Blood Glucose Random (mgs/dL)','Blood Urea (mgs/dL)',\n               'Serum Creatinine (mgs/dL)','Sodium (mEq/L)','Potassium (mEq/L)','Hemoglobin (gms)','Packed Cell Volume',\n               'White Blood Cells (cells/cmm)','Red Blood Cells (millions/cmm)','Hypertension','Diabetes Mellitus',\n               'Coronary Artery Disease','Appetite','Pedal Edema','Anemia','Chronic Kidney Disease']\ndata.columns=feature_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's deal with mistyped features now.","metadata":{}},{"cell_type":"code","source":"for i in data.columns:\n    print(\"unique values in {}:\\n\".format(i),data[i].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some numerical features are mistyped as strings.  \nI'm really curious about how that could have happened.","metadata":{}},{"cell_type":"code","source":"mistyped=['Packed Cell Volume','White Blood Cells (cells/cmm)','Red Blood Cells (millions/cmm)']\nnumeric=[]\nfor i in data.columns:\n    if data[i].dtype=='float64':\n        numeric.append(i)\nnumeric=numeric+mistyped","metadata":{"execution":{"iopub.execute_input":"2021-01-16T13:44:17.840523Z","iopub.status.busy":"2021-01-16T13:44:17.839942Z","iopub.status.idle":"2021-01-16T13:44:17.842989Z","shell.execute_reply":"2021-01-16T13:44:17.842526Z"},"papermill":{"duration":0.035033,"end_time":"2021-01-16T13:44:17.843085","exception":false,"start_time":"2021-01-16T13:44:17.808052","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in mistyped:\n        data[col]=data[col].astype('float')","metadata":{"execution":{"iopub.execute_input":"2021-01-16T13:44:18.19323Z","iopub.status.busy":"2021-01-16T13:44:18.192622Z","iopub.status.idle":"2021-01-16T13:44:18.203159Z","shell.execute_reply":"2021-01-16T13:44:18.203638Z"},"papermill":{"duration":0.04043,"end_time":"2021-01-16T13:44:18.203798","exception":false,"start_time":"2021-01-16T13:44:18.163368","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data['Packed Cell Volume'].unique())\nprint(data['White Blood Cells (cells/cmm)'].unique())\nprint(data['Red Blood Cells (millions/cmm)'].unique())","metadata":{"execution":{"iopub.execute_input":"2021-01-16T13:44:18.260904Z","iopub.status.busy":"2021-01-16T13:44:18.260342Z","iopub.status.idle":"2021-01-16T13:44:18.269217Z","shell.execute_reply":"2021-01-16T13:44:18.268598Z"},"papermill":{"duration":0.038603,"end_time":"2021-01-16T13:44:18.269335","exception":false,"start_time":"2021-01-16T13:44:18.230732","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.execute_input":"2021-01-16T13:44:18.330473Z","iopub.status.busy":"2021-01-16T13:44:18.329176Z","iopub.status.idle":"2021-01-16T13:44:18.342963Z","shell.execute_reply":"2021-01-16T13:44:18.342404Z"},"papermill":{"duration":0.045833,"end_time":"2021-01-16T13:44:18.343065","exception":false,"start_time":"2021-01-16T13:44:18.297232","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that we've dealt with that, let's separate categorical and numerical features, as they won't be dealt with the same way.  \nNumerical features were already put together in a list.","metadata":{}},{"cell_type":"code","source":"categoricals=[]\nfor col in data.columns:\n    if not col in numeric:\n        categoricals.append(col)\ncategoricals.remove('Chronic Kidney Disease')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categoricals","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that the data is cleaned, we need to deal with those missing values.  \nWe'll do some further exploration first, as that could help us in picking a proper imputation method.","metadata":{}},{"cell_type":"markdown","source":"### Further Exploration","metadata":{}},{"cell_type":"markdown","source":"We'll start by visualizing feature distributions.","metadata":{}},{"cell_type":"code","source":"import matplotlib.style as style\nstyle.use('fivethirtyeight')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_rows, n_cols = (7,2)\n\nfigure, axes = plt.subplots(nrows=n_rows, ncols=n_cols,figsize=(20, 50))\nfigure.suptitle('\\n\\nDistributions of Numerical Features', fontsize=60)\n\nfor index, column in enumerate(numeric):\n    \n    i,j = (index // n_cols), (index % n_cols)\n    \n    miss_perc=\"%.2f\"%(100*(1-(data[column].dropna().shape[0])/data.shape[0]))\n    \n    collabel=column+\"\\n({}% is missing)\".format(miss_perc)\n    \n    fig=sns.distplot(data[column], color=\"g\", label=collabel, norm_hist=True,\n    \n    ax=axes[i,j], kde_kws={\"lw\":4})\n    \n    fig=fig.legend(loc='best', fontsize=18)\n    \n    axes[i,j].set_ylabel(\"Probability Density\",fontsize='medium')\n    \n    axes[i,j].set_xlabel(None)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Notes:\nSome features show some very distant outliers.  \nSome others have discrete values, but I'll be treating them like continuous ones.  \nThe reason being is that these are measures of biological variables which are in reality continuous.   \nThem being discrete is probably due to the method they've been measured with.  \nSome features have high proportions of missing values, thus they cannot be imputed with measures of central tendency. That would distort their distributions.  \nPlus, some features are very skewed while others are almost normal, some have a very distinct mode while some don't. Which means even if we didn't have so many missing values, we'd have to deal with each feature separately.  \nWhich would not be very enjoyable.","metadata":{}},{"cell_type":"markdown","source":"Let's take a look at categorical features now.","metadata":{}},{"cell_type":"code","source":"style.use('seaborn-darkgrid')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_rows, n_cols = (5,2)\n\nfigure, axes = plt.subplots(nrows=n_rows, ncols=n_cols,figsize=(30, 50))\nfigure.suptitle('\\n\\nCountplots of Categorical Features', fontsize=60)\n\nfor index, column in enumerate(categoricals):\n    \n    i,j = index // n_cols, index % n_cols\n    \n    miss_perc=\"%.2f\"%(100*(1-(data[column].dropna().shape[0])/data.shape[0]))\n    \n    collabel=column+\"\\n({}% is missing)\".format(miss_perc)\n    \n    fig = sns.countplot(x=column, data=data,label=collabel, palette=sns.cubehelix_palette(rot=-.35,light=0.85,hue=1),\n    \n    ax=axes[i,j])\n    \n    axes[i,j].set_title(collabel,fontsize=30)\n    \n    axes[i,j].set_xlabel(None)\n    \n    axes[i,j].set_ylabel(\"Count\",fontsize=20)\n    \n    axes[i,j].set_xticklabels(axes[i,j].get_xticklabels(), Fontsize=28)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Notes:\nSome features have very high percentages of missing values while some have almost none.  \nCertain abnormalities/diseases seem relatively commun in this dataset, such as diabetes and hypertension.  \nI'm no health expert, but I don't think this sample of 400 people well-represents the population of India (which is where the data was collected), nor any other population.  \nThis means we won't be doing any inferential statistics.  \nTo be honest, this project was initially intended to be a statistics project. I just wanted to practice resampling and hypothesis testing.  \nBut the plan kept changing.","metadata":{}},{"cell_type":"code","source":"miss_perc=\"%.2f\"%(100*(1-(data['Chronic Kidney Disease'].dropna().shape[0])/data.shape[0]))\n    \nlabel=\"Disease\\n(missing:\\n{}%)\".format(miss_perc)\nfig=sns.countplot(x=data['Chronic Kidney Disease'],label=label, palette=sns.cubehelix_palette(rot=-.35,light=0.85,hue=1))\nplt.title(\"Disease\\n({}% is missing)\".format(miss_perc))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Notes:\nThis further shows that this dataset represents neither a country/community nor even a group of ill people.  \nYeah, I ain't doing no inferential statistics...","metadata":{}},{"cell_type":"markdown","source":"Let's take a look at missing values.","metadata":{}},{"cell_type":"code","source":"style.use('seaborn-darkgrid')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d=((data.isnull().sum()/data.shape[0])).sort_values(ascending=False)\nd.plot(kind='bar',\n       color=sns.cubehelix_palette(start=2,\n                                    rot=0.15,\n                                    dark=0.15,\n                                    light=0.95,\n                                    reverse=True,\n                                    n_colors=24),\n        figsize=(20,10))\nplt.title(\"\\nProportions of Missing Values:\\n\",fontsize=40)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We're going with KNN for imputation.  \nBut we have to encode the categorical features first.  \nAs said earlier, One-Hot Encoding would be perfect here as every categorical feature has only 2 values, which means we won't be increasing dimensions.  ","metadata":{}},{"cell_type":"markdown","source":"### One-Hot Encoding","metadata":{}},{"cell_type":"code","source":"onehotdata=pd.get_dummies(data,drop_first=True,prefix_sep=': ')\nonehotdata.head()","metadata":{"execution":{"iopub.execute_input":"2021-01-16T13:44:18.57064Z","iopub.status.busy":"2021-01-16T13:44:18.567799Z","iopub.status.idle":"2021-01-16T13:44:18.593466Z","shell.execute_reply":"2021-01-16T13:44:18.592908Z"},"papermill":{"duration":0.070483,"end_time":"2021-01-16T13:44:18.593579","exception":false,"start_time":"2021-01-16T13:44:18.523096","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For some reason, all NaN (missing) values are now equal to 0.  \nWhich is a catastrophy.  \nThus, I have to turn them into NaNs again.  \nI'll just loop through the original data to get their indices.  ","metadata":{}},{"cell_type":"code","source":"names={}\nfor name in data.columns:\n    for ohname in onehotdata.columns:\n        if name+': ' in ohname and name in categoricals:\n            names[name]=ohname\n            for i in range(400):\n                if type(data.loc[i,name])!=str:\n                    if math.isnan(data.loc[i,name]):\n                        onehotdata.loc[i,ohname]=data.loc[i,name]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I apologize for the layers-upon-layers of nested loops and statements.  \nThere probably exists a more \"pythonic\" way to do this.  \nBut that'll do the trick.  ","metadata":{}},{"cell_type":"markdown","source":"The more complicated and complex your code is, the more it's prone to errors.  \nThus, I'll be testing what I did by counting the number of times a cell has NaN in the original data and not in the encoded one, and vice versa.  \nWe should get zero in every column.","metadata":{}},{"cell_type":"code","source":"test_oh_dt=pd.DataFrame(columns=data.columns)\nfor col in test_oh_dt.columns:\n    if col in categoricals:\n        test_oh_dt[col]=onehotdata[names[col]]\n    elif col=='Chronic Kidney Disease':\n        test_oh_dt[col]=onehotdata['Chronic Kidney Disease: yes']\n    else:\n        test_oh_dt[col]=onehotdata[col]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"((pd.isna(data)==pd.isna(test_oh_dt))==False).sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That went well.  \nNow we should impute our data, right?  \nWell, there is actually one more thing to do.  \nYou see, KNN measures distances (in some way), which means we have to make sure our features are on the same scale.  \nIf they're not, then distances will depend mostly on features with a wider spread.  \nWhich means the algorithm will almost only pay attention to those features.","metadata":{}},{"cell_type":"markdown","source":"There are many ways to do this.  \nAs we have a lot of missing values, I want to make sure that we deal with them in the best way possible.  \nImputed values are simulated data.  \nBut they too will be fed to the predictive model.  \nSo if the simulation doesn't represent reality that well, then our model will be learning unreal information.  \nThus, the criterea by which I will evaluate the imputed data is how much it ressembles the original data.  \nMissing data won't always be identical to existing data though, especially if a lot is missing.  \nBut as long as it's missing at random, It shouldn't have considerably different distributions.  \nSo I'll be trying a few different feature transformers to scale my data, then I'll compare their results after imputation.  \nI could just standardize all features but I'm worried about the outliers, so I'll be trying some non-linear transformations as well.","metadata":{}},{"cell_type":"markdown","source":"### Trying a Few Different Transformations","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import MinMaxScaler","metadata":{"execution":{"iopub.execute_input":"2021-01-16T13:44:18.65759Z","iopub.status.busy":"2021-01-16T13:44:18.656887Z","iopub.status.idle":"2021-01-16T13:44:18.662697Z","shell.execute_reply":"2021-01-16T13:44:18.662054Z"},"papermill":{"duration":0.0399,"end_time":"2021-01-16T13:44:18.662822","exception":false,"start_time":"2021-01-16T13:44:18.622922","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Quantile Transformer transforms a distribution into a normal or uniform one. We'll be trying both.  \nThe Power Transformer applies another non-linear transformation to make your data more normal-like.  \nStandardScaler standardizes your features.  \nRobustScaler centers data but, instead of dividing by the standard deviation, it divides by an inter-quantile range that can be specified.  \nYou can either specify the inter-quantile range or just leave it to default, which is [25,75].","metadata":{}},{"cell_type":"code","source":"NQT=QuantileTransformer(output_distribution='normal')\nUQT=QuantileTransformer(output_distribution='uniform')\nNSPT=PowerTransformer(standardize=False) #I'll feed its output to a normalizer and see if that makes any difference.\nSPT=PowerTransformer()\nRS=RobustScaler() #default\nWRS=RobustScaler(quantile_range=(15,85)) # a \"wider\" range\nSS=StandardScaler()\n\nTransformers=[NQT,UQT,NSPT,SPT,RS,WRS,SS]\nMMS=MinMaxScaler()\n\nPipes=[] #they're not actually pipelines, except for one,\n#but initially I was going to normalize all of them, and didn't bother to change the name later\nfor tr in Transformers:\n    p=make_pipeline(tr)\n    Pipes.append(p)\nPipes[2]=make_pipeline(NSPT,MMS)","metadata":{"execution":{"iopub.execute_input":"2021-01-16T13:44:18.727513Z","iopub.status.busy":"2021-01-16T13:44:18.726817Z","iopub.status.idle":"2021-01-16T13:44:18.730013Z","shell.execute_reply":"2021-01-16T13:44:18.729451Z"},"papermill":{"duration":0.037541,"end_time":"2021-01-16T13:44:18.730118","exception":false,"start_time":"2021-01-16T13:44:18.692577","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for pipe in Pipes:\n    print(pipe)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we just apply these transformers and store their results.","metadata":{}},{"cell_type":"code","source":"datarrays=[]\nfor pipe in Pipes:\n    arr=pipe.fit_transform(onehotdata)\n    datarrays.append(arr)","metadata":{"execution":{"iopub.execute_input":"2021-01-16T13:44:18.798469Z","iopub.status.busy":"2021-01-16T13:44:18.797782Z","iopub.status.idle":"2021-01-16T13:44:18.835946Z","shell.execute_reply":"2021-01-16T13:44:18.835176Z"},"papermill":{"duration":0.075619,"end_time":"2021-01-16T13:44:18.836095","exception":false,"start_time":"2021-01-16T13:44:18.760476","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframes=[onehotdata]\nfor arr in datarrays:\n    df=pd.DataFrame(arr,columns=onehotdata.columns)\n    dataframes.append(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's take a look at what these transformations did to our data.  \nP.S: the second (blue) robustscaler is the wider one, and the first (orange) powertransformer is the normalized one.","metadata":{}},{"cell_type":"code","source":"categorical_feats=onehotdata.columns[14:]\nnumerical_feats=onehotdata.columns[:14]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"style.use('fivethirtyeight')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colors=['crimson','steelblue','darkorange','darkviolet','gold','mediumblue','lime']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_rows, n_cols = (14,8)\n\nfigure, axes = plt.subplots(nrows=n_rows, ncols=n_cols,figsize=(70, 100))\nfigure.suptitle('\\n\\nDistributions of Numerical Features\\nAfter Different Transformations', fontsize=120)\nfor i in range(14):\n    fig = sns.distplot(onehotdata.iloc[:,i], color=\"g\", label='Original\\nDistribution', norm_hist=True,\n    \n    ax=axes[i,0], kde_kws={\"lw\":4})\n    \n    fig=fig.legend(loc='best', fontsize=35)\n    \n    axes[i,0].set_xlabel(axes[i,0].get_xlabel(),fontsize=33)\n    \n    axes[i,0].set_ylabel(\"Probability Density\",fontsize=25)\n\nfor j in range(1,8):\n    for i in range(14):\n        label=Pipes[j-1].steps[0][0]\n        \n        fig = sns.distplot(dataframes[j].iloc[:,i], color=colors[j-1], label=label, norm_hist=True,\n\n        ax=axes[i,j], kde_kws={\"lw\":4})\n        \n        fig=fig.legend(loc='best', fontsize=35)\n    \n        axes[i,j].set_ylabel(\"Probability Density\",fontsize=25)\n        \n        axes[i,j].set_xlabel(axes[i,j].get_xlabel(),fontsize=33)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Notes:\nNon-linear transformations (from red to purple) don't seem to have dealt with ordinal features well.  \nBut you never know, I only get to judge after seeing the imputation results.  \nThe gaussian quantile transformer (red) piled up outliers on the edges. I don't like that. I'm quite disappointed frankly.  \nLinear transformers (last three) didn't change shapes of distributions.  \nEverything will be evaluated after imputation.  ","metadata":{}},{"cell_type":"code","source":"colors2=['lightcoral','lightblue','peachpuff','plum','khaki','cornflowerblue','lightgreen']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_rows, n_cols = (10,8)\n\nfigure, axes = plt.subplots(nrows=n_rows, ncols=n_cols,figsize=(70, 100))\nfigure.suptitle('\\n\\nCountplots of Categorical Features\\nAfter Different Transformations', fontsize=120)\nfor i in range(10):\n    g = sns.countplot(onehotdata.iloc[:,i+14], color=\"mediumaquamarine\", label=\"Original Feature\",\n    \n    ax=axes[i,0])\n    \n    g=g.legend(loc='best', fontsize=35)\n    \n    axes[i,0].set_xlabel(axes[i,0].get_xlabel(),fontsize=33)\n    \n    axes[i,0].set_ylabel(\"Count\",fontsize=25)\n\nfor j in range(1,8):\n    for i in range(10):\n        label=Pipes[j-1].steps[0][0]\n        \n        g = sns.countplot(dataframes[j].iloc[:,i+14], color=colors2[j-1], label=label,\n\n        ax=axes[i,j])\n        \n        g=g.legend(loc='best', fontsize=35)\n    \n        axes[i,j].set_xlabel(axes[i,j].get_xlabel(),fontsize=33)\n    \n        axes[i,j].set_ylabel(\"Count\",fontsize=25)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Notes:\nApparently, these didn't change.  \nThat's about it I guess.","metadata":{}},{"cell_type":"markdown","source":"### Imputation","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import KNNImputer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knnimp=KNNImputer(weights='distance', n_neighbors=8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rrr=[onehotdata.to_numpy()]\nfor dfi in range(1,len(dataframes)):\n    rrr.append(knnimp.fit_transform(dataframes[dfi]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"arrs=[rrr[0]]\nfor i in range(1,len(rrr)):\n    arrs.append(Pipes[i-1].inverse_transform(rrr[i]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"impdf=[]\nfor i in range(len(arrs)):\n    impdf.append(pd.DataFrame(arrs[i],columns=onehotdata.columns))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_rows, n_cols = (14,8)\n\nfigure, axes = plt.subplots(nrows=n_rows, ncols=n_cols,figsize=(70, 100))\nfigure.suptitle('\\n\\nDistributions of Numerical Features\\nAfter Imputation', fontsize=120)\nfor i in range(14):\n    fig = sns.distplot(onehotdata.iloc[:,i], color=\"g\", label='Original Feature\\n Distribution', norm_hist=True,\n    \n    ax=axes[i,0], kde_kws={\"lw\":4})\n    \n    fig=fig.legend(loc='best', fontsize=35)\n    \n    axes[i,0].set_xlabel(axes[i,0].get_xlabel(),fontsize=33)\n    \n    axes[i,0].set_ylabel(\"Probability Density\",fontsize=25)\n\nfor j in range(1,8):\n    for i in range(14):\n        label=Pipes[j-1].steps[0][0]\n        \n        fig = sns.distplot(impdf[j].iloc[:,i], color=colors[j-1], label=label, norm_hist=True,\n\n        ax=axes[i,j], kde_kws={\"lw\":4})\n        \n        fig=fig.legend(loc='best', fontsize=35)\n    \n        axes[i,j].set_ylabel(\"Probability Density\",fontsize=25)\n        \n        axes[i,j].set_xlabel(axes[i,j].get_xlabel(),fontsize=33)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Notes:\nBoth quantile transformers did a very decent job (despite the piles of outliers mentionned earlier)  \nThe unstandardized, normalized powertransformer (orange) performed quite awfully.  \nThe Standardized power transformer (purple) is, in contrast, quite decent.  \nLinear transformers have almost identical results.  Good ones nonetheless.  ","metadata":{}},{"cell_type":"code","source":"n_rows, n_cols = (10,8)\n\nfigure, axes = plt.subplots(nrows=n_rows, ncols=n_cols,figsize=(70, 100))\nfigure.suptitle(\"\\n\\nHere's What Happened to\\nCategorical Features\\nAfter Imputation\", fontsize=120)\nfor i in range(10):\n    g = sns.countplot(onehotdata.iloc[:,i+14], color=\"mediumaquamarine\", label=categorical_feats[i],\n    \n    ax=axes[i,0])\n    \n    g=g.legend(loc='best', fontsize=35)\n    \n    axes[i,0].set_xlabel(axes[i,0].get_xlabel(),fontsize=33)\n    \n    axes[i,0].set_ylabel(\"Count\",fontsize=25)\n\nfor j in range(1,8):\n    for i in range(10):\n        label=Pipes[j-1].steps[0][0]\n        \n        g = sns.countplot(impdf[j].iloc[:,i+14], color=colors2[j-1], label=label,\n\n        ax=axes[i,j])\n        \n        g=g.legend(loc='best', fontsize=35)\n        \n        axes[i,j].set_xlabel(axes[i,j].get_xlabel(),fontsize=33)\n    \n        axes[i,j].set_ylabel(\"Count\",fontsize=25)\n\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I don't know why the orange transformer did this, and I don't actually care.  \nIt performed awfully on numerical features so it's out of the question.  \nAs for the thin bars that appeared in certain features' countplots, apparently some NaNs got replaced with values between zero and one.  \nTake a look:","metadata":{}},{"cell_type":"code","source":"impdf[6].iloc[:,15].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All we have to do is use 0.5 as a threshhold. Everything above becomes 1, everything under becomes 0.","metadata":{}},{"cell_type":"code","source":"test=impdf.copy()\nfor j in range(1,8):\n    dat=test[j]\n    for i in range(14,25):\n        col=dat.iloc[:,i]\n        for k in range(400):\n            if col[k]>=0.5:\n                col[k]=1\n            else:\n                col[k]=0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[6].iloc[:,16].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_rows, n_cols = (10,8)\n\nfigure, axes = plt.subplots(nrows=n_rows, ncols=n_cols,figsize=(70, 100))\nfigure.suptitle('\\n\\nCountplots of Categorical Features\\nAfter Imputation', fontsize=120)\nfor i in range(10):\n    g = sns.countplot(onehotdata.iloc[:,i+14], color=\"mediumaquamarine\", label=categorical_feats[i],\n    \n    ax=axes[i,0])\n    \n    g=g.legend(loc='best', fontsize=35)\n    \n    axes[i,0].set_xlabel(axes[i,0].get_xlabel(),fontsize=33)\n    \n    axes[i,0].set_ylabel(\"Count\",fontsize=25)\n\nfor j in range(1,8):\n    for i in range(10):\n        label=categorical_feats[i]+'\\n'+Pipes[j-1].steps[0][0]\n        \n        g = sns.countplot(test[j].iloc[:,i+14], color=colors2[j-1], label=label,\n\n        ax=axes[i,j])\n        \n        g=g.legend(loc='best', fontsize=35)\n        \n        axes[i,j].set_xlabel(axes[i,j].get_xlabel(),fontsize=33)\n    \n        axes[i,j].set_ylabel(\"Count\",fontsize=25)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Notes:\nThe StandardScaler is the only one that kept the distribution of the red blood cells feature exactly as it is.  \nRobustScalers slightly increased the proportion of \"0\" while non-linear transformers decreased it, especially the uniform QuantileTransformer.  \nBut it's the feature with most missing values at around 38%, so you never know...  ","metadata":{}},{"cell_type":"markdown","source":"Let's take a closer look at what happened to features with many missing values, as those are the ones for which all of this was done.  \nI'll pick three transformers which I think did a good job at keeping feature distributions:  \nGaussian QuantileTransformer (red)  \n\"Wide\" RobustScaler (blue)  \nand StandardScaler (green)  \nThe uniform QuantileTransformer did a decent job as well but oh well, I want to make a bigger graph ie a not-so-crammed one. So I'll be going with just three.  \nNow the ones I picked are not necessarily better, and the only way to know is to try them with the same machine learning models and compare results.  \nOr we can take a dataset, empty a few cells, impute with different techniques then compare results with the original data.","metadata":{}},{"cell_type":"code","source":"impdf=test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fwmmv=list(numerical_feats.copy())\nthe_other_ones=['Age (yrs)','Blood Pressure (mm/Hg)','Serum Creatinine (mgs/dL)','Blood Urea (mgs/dL)']\nfor f in range(len(the_other_ones)):\n    if the_other_ones[f] in fwmmv:\n        fwmmv.remove(the_other_ones[f])\nfwmmv.extend(('Red Blood Cells: normal','Pus Cells: normal'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fwmmv #features with many missing values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indices=[1,6,7]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_rows, n_cols = (12,4)\n\nfigure, axes = plt.subplots(nrows=n_rows, ncols=n_cols,figsize=(20, 60))\nfigure.suptitle('\\n\\nBest Results\\nFor Features With More\\nThan 10% Missing Values', fontsize=50)\n\nfor index, column in enumerate(fwmmv):\n    \n    if index<10:\n        \n        miss_perc1=\"%.2f\"%(100*(1-(onehotdata[column].dropna().shape[0])/onehotdata.shape[0]))\n\n        collabel1='Original Data'+\"\\n({}% is missing)\".format(miss_perc1)\n    \n        fig1=sns.distplot(onehotdata[column], color=\"g\", label=collabel1, norm_hist=True,\n    \n        ax=axes[index,0], kde_kws={\"lw\":4})\n    \n        fig1=fig1.legend(loc='best', fontsize=12)\n        \n        axes[index,0].set_ylabel(\"Probability Density\",fontsize='medium')\n    \n        for j in indices:\n\n            miss_perc2=\"%.2f\"%(100*(1-(impdf[j][column].dropna().shape[0])/impdf[j].shape[0]))\n\n            collabel2=Pipes[j-1].steps[0][0]+\"\\n({}% is missing)\".format(miss_perc2)\n\n            fig2=sns.distplot(impdf[j][column], color=colors[j-1], label=collabel2, norm_hist=True,\n\n            ax=axes[index,j-5+1], kde_kws={\"lw\":1.5})\n\n            fig2=fig2.legend(loc='best', fontsize=12)\n            \n            axes[index,j-5+1].set_ylabel(\"Probability Density\",fontsize='medium')\n    else:\n        \n        miss_perc1=\"%.2f\"%(100*(1-(onehotdata[column].dropna().shape[0])/onehotdata.shape[0]))\n\n        collabel1='Original Data'+\"\\n({}% is missing)\".format(miss_perc1)\n    \n        fig1=sns.countplot(onehotdata[column], color=\"mediumaquamarine\", label=collabel1,\n    \n        ax=axes[index,0])\n    \n        fig1=fig1.legend(loc='best', fontsize=12)\n        \n        axes[index,0].set_ylabel(\"Count\",fontsize='medium')\n        \n        for j in indices:\n\n            miss_perc2=\"%.2f\"%(100*(1-(impdf[j][column].dropna().shape[0])/impdf[j].shape[0]))\n\n            collabel2=Pipes[j-1].steps[0][0]+\"\\n({}% is missing)\".format(miss_perc2)\n\n            fig2=sns.countplot(impdf[j][column], color=colors2[j-1], label=collabel2,\n\n            ax=axes[index,j-5+1])\n\n            fig2=fig2.legend(loc='best', fontsize=12)\n            \n            axes[index,j-5+1].set_ylabel(\"Count\",fontsize='medium')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Which one should we pick for the rest of the work?  \nWell I tried the three of them.  \nThe best prediction results I got later were with the Gaussian transformer data.  \nHowever, I did not use it to scale my data for the predictive algorithms.  \nWell, I did but StandardScaler gave better results so I went with that.  \nIn conlusion, I used the Gaussian QuantileTransformer for imputation, and StandardScaler to scale features for prediction.  \nAs mentioned in the sklearn documentation \"..this transform is non-linear. It may distort linear correlations between variables measured at the same scale..\"  \nThis isn't an issue because -as you'll see later- there isn't really much correlation between variable.  ","metadata":{}},{"cell_type":"code","source":"onehotdata=impdf[1].copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"onehotdata.dropna().shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have no more missing values","metadata":{}},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"style.use('seaborn-darkgrid')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_rows, n_cols = (11,2)\n\nfigure, axes = plt.subplots(nrows=n_rows, ncols=n_cols,figsize=(25, 130))\nfigure.suptitle('\\n\\n\\nDistributions of Categorical Variables\\n(Original Data)', fontsize=80)\n\nfor i in range(len(categoricals)):\n    column=categoricals[i]\n    graph1=data[column].value_counts().plot.pie(autopct='%1.1f%%',\n                                                      ax=axes[i,0],\n                                                      colormap=\"tab20c\",\n                                                      fontsize=25,\n                                                      shadow=True,\n                                                      explode=[0.1,0])\n    axes[i,0].set_ylabel('%',fontsize=25)\n    axes[i,0].set_title(column+' (percentages)', fontsize=30)\n    graph2=sns.countplot(x=column,\n                         data=data,\n                         palette='Blues_r',\n                         ax=axes[i,1])\n    axes[i,1].set_xlabel(None)\n    axes[i,1].set_ylabel('Count',fontsize=25)\n    axes[i,1].set_xticklabels(axes[i,1].get_xticklabels(), Fontsize=18)\n    axes[i,1].set_title(column+' (value counts)', fontsize=30)\n    \n\ngraph1=data['Chronic Kidney Disease'].value_counts().plot.pie(autopct='%1.1f%%',\n                                                              ax=axes[10,0],\n                                                              colormap='tab20c',\n                                                              fontsize=25,\n                                                              shadow=True,\n                                                              explode=[0.1,0])\naxes[10,0].set_ylabel(\"%\",fontsize=25)\naxes[10,0].set_title('Chronic Kidney Disease (percentages)',fontsize=30)\n\n\ngraph2=sns.countplot(x='Chronic Kidney Disease',\n                     data=data,\n                     palette='Blues_r',\n                     ax=axes[10,1])\naxes[10,1].set_xlabel(None,fontsize=25)\naxes[10,1].set_ylabel(\"Count\",fontsize=25)\naxes[10,1].set_xticklabels(axes[10,1].get_xticklabels(), Fontsize=18)\naxes[10,1].set_title('Chronic Kidney Disease (value counts)', fontsize=30)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_rows, n_cols = (10,10)\n\nfigure, axes = plt.subplots(nrows=n_rows, ncols=n_cols,figsize=(70, 100))\nfigure.suptitle('\\n\\nCrosstabs of Categorical Variables (Original Data)\\n', fontsize=200)\n\nfor i in range(10):\n    for j in range(10):\n        sns.heatmap(#pd.crosstab(onehotdata.iloc[:,i+14],onehotdata.iloc[:,j+14]),\n                    pd.crosstab(data[categoricals[i]],data[categoricals[j]]),\n                    ax=axes[i,j],\n                    cmap=sns.cubehelix_palette(start=2.8, rot=.1),\n                    square='True',\n                    cbar=False,\n                    annot=True,\n                    annot_kws={'fontsize':52},\n                    fmt='d')\n        \n        axes[i,j].set_xlabel(axes[i,j].get_xlabel(),fontsize=28)\n        \n        axes[i,j].set_ylabel(axes[i,j].get_ylabel(),fontsize=28)\n        \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Notes:\nI don't see much correlation between features.  \nThe more correlated they are, the more effective dimensionality reduction techniques would be.  ","metadata":{}},{"cell_type":"code","source":"style.use('seaborn-darkgrid')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_rows, n_cols = (14,2)\n\nfigure, axes = plt.subplots(nrows=n_rows, ncols=n_cols,figsize=(25, 100))\nfigure.suptitle('\\n\\n\\nDistributions of Numerical Variables\\n(Original Data)', fontsize=100)\n\nfor i in range(len(numeric)):\n    col=numeric[i]\n    \n    label='Mean = {}\\nMedian = {}\\nStandard Deviation = {}'.format(\"%.2f\"%data[col].mean(),\n                                                                    \"%.2f\"%data[col].median(),\n                                                                    \"%.2f\"%data[col].std())\n    \n    graph1=sns.distplot(data[col],\n                        color=\"navy\",\n                        ax=axes[i,0],\n                        kde_kws={\"lw\":4},\n                        norm_hist=True,\n                        label=label).legend(loc='best',fontsize=20)\n    axes[i,0].set_title(col+': Density',fontsize=30)\n    axes[i,0].set_xlabel(None)\n    axes[i,0].set_ylabel(\"Pobability Density\",fontsize=18)\n\n    graph20=sns.violinplot(x=col,\n                          data=data,\n                          ax=axes[i,1],\n                          color='lavender',\n                          inner='box')\n    graph21=sns.boxplot(x=col,\n                        data=data,\n                        ax=axes[i,1],\n                        fliersize=8,\n                        boxprops=dict(alpha=0))\n    \n    axes[i,1].set_xlabel(None)\n    axes[i,1].set_title(col+': Quartiles',fontsize=30)\n    \n    \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numericdat=data.drop(categoricals, axis=1, inplace=False)\n\nplt.figure(figsize=(20,20))\n\nsns.heatmap(numericdat.corr(\"pearson\"),\n            cmap=sns.diverging_palette(280, 280, s=100, l=35, as_cmap=True,sep=80),\n            square=True,\n            annot=True,\n            annot_kws={'fontsize':20},\n            fmt='.2%',\n            cbar=False)\nplt.title(\"Pearson Correlation Matrix\\n\",fontsize=60)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Notes:\nSame thing as with categorical features: practically no correlations.  ","metadata":{}},{"cell_type":"code","source":"n_rows, n_cols = (5,2)\n\nfigure, axes = plt.subplots(nrows=n_rows, ncols=n_cols,figsize=(30, 100))\nfigure.suptitle('\\n\\nCategorical Features\\nVS\\nTarget Variable', fontsize=100)\n\nfor index, column in enumerate(categoricals):\n    \n    i,j = (index // n_cols), (index % n_cols)\n    \n    sns.heatmap(pd.crosstab(data[column],data['Chronic Kidney Disease']),\n                ax=axes[i,j],\n                cmap=sns.cubehelix_palette(start=2.8, rot=.1),\n                square='True',\n                cbar=False,\n                annot=True,\n                annot_kws={'fontsize':90},\n                fmt='d')\n        \n    axes[i,j].set_xlabel(\"Disease\", fontsize=90)\n\n    axes[i,j].set_ylabel(column,fontsize=90)\n    \n    axes[i,j].set_yticklabels(axes[i,j].get_yticklabels(),fontsize=50)\n    \n    axes[i,j].set_xticklabels([\"No CKD\",\"CKD\"],fontsize=50)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Notes:\nAgain, not much correlation.  \nI really wanted to test whether any of these features correlated (even slightly) with the target variable, but as I said earlier, I don't even know what the population is.  \nWell, I could just ignore what the actual population is. I could simply call it \"the population\" and do my thing.  \nBut I just don't feel like it now.","metadata":{}},{"cell_type":"code","source":"n_rows, n_cols = (7,2)\n\nfigure, axes = plt.subplots(nrows=n_rows, ncols=n_cols,figsize=(20, 80))\nfigure.suptitle('\\n\\nNumerical Features\\nVS\\nTarget Variable', fontsize=60)\n\nfor index, column in enumerate(numeric):\n    \n    i,j = (index // n_cols), (index % n_cols)\n    \n    bp=sns.boxenplot(y=column, x='Chronic Kidney Disease', data=data, color=\"paleturquoise\",\n    \n    ax=axes[i,j], showfliers=False)\n        \n    axes[i,j].set_xlabel(axes[i,j].get_xlabel(),fontsize=25)\n\n    axes[i,j].set_ylabel(column,fontsize=25)\n    \n    axes[i,j].set_xticklabels(axes[i,j].get_xticklabels(),fontsize=20)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Notes:\nNow this is some real hypothesis testing material.  \nThere's a lot one can test.  \nI'll leave that as an exercise to the viewer XD","metadata":{}},{"cell_type":"code","source":"colors3=['deepskyblue','turquoise','mediumspringgreen','turquoise']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_rows, n_cols = (14,10)\n\nfigure, axes = plt.subplots(nrows=n_rows, ncols=n_cols,figsize=(60, 60))\nfigure.suptitle('\\nNumerical and Categorical Features:\\nDistributions and Correlations', fontsize=80)\n\nfor i in range(14):\n    for j in range(10):\n        graph=sns.violinplot(y=numeric[i],x=categoricals[j],data=data,color=colors3[j%4],ax=axes[i,j])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Notes:\nSame as before, there's a lot to test.  \nMeans don't seem to differ that much by category for certain features, but the difference of spreads is quite considerable.  \nCategories don't have the same distributions for some features.  ","metadata":{}},{"cell_type":"markdown","source":"# Clustering & Prediction","metadata":{}},{"cell_type":"markdown","source":"### Prediction Using K-Means Clustering","metadata":{}},{"cell_type":"markdown","source":"Ever thought about classification by clustering ?  \n\"How?\", I hear you ask.    \nWell, if every cluster corresponds to a single category, then we've got a predictive model.  \nQuite simple, isn't it?  \nPlus, if it works, we would get different clusters in each category.  \nWhich would be quite enjoyable to analyze.  ","metadata":{}},{"cell_type":"markdown","source":"So how many clusters should we make?  \nWe can make an approximate guess by measuring inertia for different numbers of clusters.  \nIf we find an elbow point then that is quite likely to be the best choice.","metadata":{}},{"cell_type":"markdown","source":"P.S: Just like KNN, K-Means is sensitive to feature scales.  \nThus we have to, again, put features on the same scale.  \nAs I explained earlier, we'll be using sklearn's StandardScaler.","metadata":{}},{"cell_type":"code","source":"X=onehotdata.drop(\"Chronic Kidney Disease: yes\",axis=1,inplace=False)\nY=onehotdata[\"Chronic Kidney Disease: yes\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_scaled_data=SS.fit_transform(onehotdata)\nscaled_data=SS.fit_transform(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import KMeans","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inertias = []\n\nks=list(range(1,9))\n\nfor k in ks:\n    model=KMeans(n_clusters=k)\n    \n    model.fit(scaled_data)\n    \n    inertias.append(model.inertia_)\n\nplt.figure(figsize=(15,7.5))\nsns.barplot(ks, inertias, palette='mako')\nplt.xlabel('Number of Clusters',fontsize=30)\nplt.ylabel('Inertia',fontsize=35)\nplt.xticks(ks)\nplt.title(\"Inertia per Number of Clusters\\n(Target Variable Excluded from the Dataset)\",fontsize=40)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is no distinguishable elbow point.  \nGuess I'll have to try a few options.","metadata":{}},{"cell_type":"code","source":"n_rows, n_cols = (3,2)\n\nfigure, axes = plt.subplots(nrows=n_rows, ncols=n_cols,figsize=(20, 80))\nfigure.suptitle('\\n\\nK-Means Clusters Vs Target Variable', fontsize=60)\n\nfor index in range(6):\n    \n    i,j = (index // n_cols), (index % n_cols)\n    \n    model=KMeans(n_clusters=index+2)\n    \n    model.fit(scaled_data)\n    \n    cluster_labels=model.predict(scaled_data)\n    \n    sns.heatmap(pd.crosstab(cluster_labels,Y),\n                ax=axes[i,j],\n                cmap='Greens',\n                square='True',\n                cbar=False,\n                annot=True,\n                annot_kws={'fontsize':90},\n                fmt='d')\n    \n    axes[i,j].set_xlabel(\"Chronic Kidney Disease\",fontsize=30)\n\n    axes[i,j].set_ylabel(\"Cluster Labels\",fontsize=30)\n    \n    axes[i,j].set_yticklabels(axes[i,j].get_yticklabels(),fontsize=20)\n    \n    axes[i,j].set_xticklabels([\"No\",\"Yes\"],fontsize=20)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Notes:\nThere's always a cluster where the majority don't have the disease.  \nOther clusters only contain ill people.  \nWith 5 and 6 clusters, one can notice a cluster containing only two ill people.  \nI think that might be a sign of overfitting.","metadata":{}},{"cell_type":"markdown","source":"How about PCA?  \nWe might get better results by removing noise.  \nI don't think the mixed cluster is due to noise though.  \nYou see, we got a mixed cluser regardless of the number of clusters.  \nAnd the misclassified samples decreased progressively/slowly as the number of clusters increased.  \nI don't think that's noise.  \nIt could be due to the (relative) convexity of K-Means clusters.  \nPerhaps a density based algorithm like DBSCAN or OPTICS would give better results.  \nBut for now, let's try K-Means with PCA.","metadata":{}},{"cell_type":"markdown","source":"### K-Means with Dimensionality Reduction","metadata":{}},{"cell_type":"markdown","source":"Before applying PCA, let's take an approximate look at how our data is distributed in space by using T-SNE.","metadata":{}},{"cell_type":"code","source":"from sklearn.manifold import TSNE","metadata":{"execution":{"iopub.execute_input":"2021-01-16T13:44:19.328077Z","iopub.status.busy":"2021-01-16T13:44:19.327482Z","iopub.status.idle":"2021-01-16T13:44:19.392535Z","shell.execute_reply":"2021-01-16T13:44:19.393075Z"},"papermill":{"duration":0.099614,"end_time":"2021-01-16T13:44:19.393232","exception":false,"start_time":"2021-01-16T13:44:19.293618","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tsne_model = TSNE()\ntsne_data= tsne_model.fit_transform(full_scaled_data)\nxs=tsne_data[:,0]\nys=tsne_data[:,1]\nplt.figure(figsize=(15,10))\nplt.scatter(xs,ys,c=pd.get_dummies(onehotdata['Chronic Kidney Disease: yes'],drop_first=True).values,cmap=\"winter\")\nplt.title(\"T-SNE\\nTarget Variable Included\")\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2021-01-16T13:44:19.462379Z","iopub.status.busy":"2021-01-16T13:44:19.461546Z","iopub.status.idle":"2021-01-16T13:44:21.404188Z","shell.execute_reply":"2021-01-16T13:44:21.404838Z"},"papermill":{"duration":1.979029,"end_time":"2021-01-16T13:44:21.40501","exception":false,"start_time":"2021-01-16T13:44:19.425981","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Perfectly separated.  ","metadata":{}},{"cell_type":"code","source":"tsne_data= tsne_model.fit_transform(scaled_data)\nxs=tsne_data[:,0]\nys=tsne_data[:,1]\nplt.figure(figsize=(15,10))\nplt.scatter(xs,ys,c=pd.get_dummies(Y,drop_first=True).values,cmap=\"winter\")\nplt.title(\"T-SNE\\nTarget Variable Excluded\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Categories are quite well-separated here, but not as much as when the target variable was included.","metadata":{}},{"cell_type":"markdown","source":"Anyhow, let's take a look at variation for each PCA component.","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA()\npca.fit(scaled_data)","metadata":{"execution":{"iopub.execute_input":"2021-01-16T13:44:22.070868Z","iopub.status.busy":"2021-01-16T13:44:22.069944Z","iopub.status.idle":"2021-01-16T13:44:22.117858Z","shell.execute_reply":"2021-01-16T13:44:22.118371Z"},"papermill":{"duration":0.083865,"end_time":"2021-01-16T13:44:22.118509","exception":false,"start_time":"2021-01-16T13:44:22.034644","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca_features=list(range(1,25))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax=plt.figure(figsize=(15,7.5))\nsns.barplot(pca_features, pca.explained_variance_,palette=\"winter_r\")\nplt.ylabel('Variation',fontsize=20)\nplt.xlabel('PCA Components',fontsize=20)\nplt.title(\"PCA Components\\nRanked by Variation\")\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2021-01-16T13:44:22.269788Z","iopub.status.busy":"2021-01-16T13:44:22.268825Z","iopub.status.idle":"2021-01-16T13:44:22.464537Z","shell.execute_reply":"2021-01-16T13:44:22.463948Z"},"papermill":{"duration":0.234913,"end_time":"2021-01-16T13:44:22.464648","exception":false,"start_time":"2021-01-16T13:44:22.229735","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That is a very distinguishable elbow point.  \nLet's take a look at how well that main component separates categories.","metadata":{}},{"cell_type":"code","source":"pca1=PCA(n_components=1)\npca1_data=pca1.fit_transform(scaled_data)\nplt.figure(figsize=(15,10))\npca1_data=pca1_data.reshape((400,))\nbp=sns.boxenplot(y=pca1_data, x=data['Chronic Kidney Disease'], color=\"paleturquoise\",showfliers=True)\nplt.title(\"Separation of Categories\\nUsing the main PCA Component\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That's quite decent.  \nWe'll measure its accuracy later in the LDA section.","metadata":{}},{"cell_type":"markdown","source":"How about two PCA components?","metadata":{}},{"cell_type":"code","source":"pca2=PCA(n_components=2)\npca2_data=pca2.fit_transform(scaled_data)\nplt.figure(figsize=(15,5))\nplt.scatter(pca2_data[:,0],pca2_data[:,1],c=onehotdata[\"Chronic Kidney Disease: yes\"],cmap=\"winter_r\")\nplt.title('Two PCA Components')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks decent.  \nWe can zoom in on that mixed area:","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.scatter(pca2_data[:,0],pca2_data[:,1],c=onehotdata[\"Chronic Kidney Disease: yes\"],cmap=\"winter_r\")\nplt.xlim(right=-1.5,left=-3)\nplt.ylim(bottom=-2.5,top=2)\nplt.title(\"Zooming in on that mixed area\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fairly decent as well.  \nYou know what? Let's just do T-SNE with all possible numbers of components ie from 1 to 24.  \nPlease bear with me, I just love visuals.","metadata":{}},{"cell_type":"code","source":"n_rows, n_cols = (12,2)\n\nfigure, axes = plt.subplots(nrows=n_rows, ncols=n_cols,figsize=(20, 80))\nfigure.suptitle('\\n\\nPCA + T-SNE', fontsize=80)\n\nfor index in range(24):\n    \n    i,j = (index // n_cols), (index % n_cols)\n    \n    pca = PCA(n_components=index+1)\n    pca_data=pca.fit_transform(scaled_data)\n    tsne_data= tsne_model.fit_transform(pca_data)\n    xs=tsne_data[:,0]\n    ys=tsne_data[:,1]\n    sns.scatterplot(xs,ys,c=pd.get_dummies(Y,drop_first=True).values,cmap=\"winter_r\",ax=axes[i,j])\n    axes[i,j].set_title(\"T-SNE with {} PCA Components\".format(index+1))\naxes[0,0].set_title(\"T-SNE with 1 PCA Component\")\nplt.show()\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Notes:\nSome components, mainly the first few, separate further between categories.  \nSome others, mainly the last few, make the data more noisy on the \"edges\".  \nT-SNE is still approximative, so you never know.  \nLet's proceed to the main part of this section, which is K-Means with PCA.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(scaled_data, Y, test_size=0.4, random_state=12)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_rows, n_cols = (24,3)\n\nfigure, axes = plt.subplots(nrows=n_rows, ncols=n_cols,figsize=(20, 80))\n\nfigure.suptitle('\\n\\nPCA + K-Means VS Target Variable\\n', fontsize=80)\n\nfor index in range(72):\n    \n    i,j = (index // n_cols), (index % n_cols)\n    \n    pca = PCA(n_components=i+1)\n    \n    pca_data=pca.fit_transform(X_train)\n    \n    model=KMeans(n_clusters=j+4, random_state=5) #random_state is arbitrary,\n                                                    #I just fixed it to make sure I always get the same results\n    \n    model.fit(pca_data)\n    \n    cluster_labels=model.predict(pca_data)\n    \n    sns.heatmap(pd.crosstab(Y_train,cluster_labels),\n                ax=axes[i,j],\n                cmap='Greens',\n                square='True',\n                cbar=False,\n                annot=True,\n                annot_kws={'fontsize':18},\n                fmt='d')\n    \n    axes[i,j].set_title(\"{} PCA components and {} clusters\".format(i+1,j+4),fontsize=15)\n    \n    axes[i,j].set_ylabel(\"Chronic Kidney Disease\",fontsize=15)\n    \n    axes[i,j].set_xlabel(None)\n    \n    axes[i,j].set_xticklabels(axes[i,j].get_xticklabels(),fontsize=10)\n    \n    axes[i,j].set_yticklabels([\"No\",\"Yes\"],fontsize=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Notes:\nOur best result is with 1 PCA component and 6 clusters.  \n***Training Accuracy = 238/240 = 99%***  \nAdding components beyond the first one was, for the most part, useless.  \nAs the number of cluster increases, the mixed cluster becomes cleaner.  \nWe could keep increasing the number of clusters to further clean that mixed cluster, but we might get an overfit model.","metadata":{}},{"cell_type":"markdown","source":"To measure accuracy, we should train the model on a set of training data then test it on different data.  \nTo make predictions with a clustering algorithm, we can use one of the two following methods:  \n\n1-We train the model, associate each cluster with the appropriate category (which is the majority for mixed clusters), then assign each to-be-predicted sample to the nearest cluster centre (centroid).\nAgain, in mixed clusters, most represented values will be considered correct.  \n\n2-We train the model, associate each cluster with the appropriate category, then we determine a centroid for each category.  \nThis is done by calculating the weighted average of centroids for each category, the weights being cluster sizes.  \nThen we assign each to-be-predicted sample to the nearest category centroid.  \nI think this is very likely to reduce variance, but perhaps increase bias.  ","metadata":{}},{"cell_type":"markdown","source":"Let's calculate accuracy for the testing data now using the first method.","metadata":{}},{"cell_type":"code","source":"pca = PCA(n_components=1)\n    \npca_training_data=pca.fit_transform(X_train)\n\nmodel=KMeans(n_clusters=6, random_state=5)\n    \nmodel.fit(pca_training_data)\n\npca_testing_data=pca.transform(X_test)\n\ncluster_labels=model.predict(pca_testing_data)\n\nsns.heatmap(pd.crosstab(Y_test,cluster_labels),\n                cmap='Greens',\n                square='True',\n                cbar=False,\n                annot=True,\n                annot_kws={'fontsize':20},\n                fmt='d')\n\nplt.title(\"Results on Testing Data\",fontsize=25)\nplt.ylabel(\"Chronic Kidney Disease\",fontsize=10)\nplt.xlabel(\"Cluster labels\",fontsize=10)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nice! Only one sample out of 160 is misclassified.\n****Testing Accuracy = 159/160 = 99% ****","metadata":{}},{"cell_type":"markdown","source":"But how do you make sure your data is well separated in space?  \nYeah that's the major challenge. Once you've got that solved the rest shouldn't be difficult.  \nPCA did a nice job here. I'm sure there are other techniques one could try.  \nSince the best results corresponded with 1 PCA component, I would expect LDA to do a decent job as well.","metadata":{}},{"cell_type":"markdown","source":"Anyways, one could do some further cluster analysis now.  \nFor example, one can search for correlations between clusters and features.  \nI'm not doing that though. Maybe another time.  \nLet's try out some other models.","metadata":{}},{"cell_type":"markdown","source":"### LDA + Linear-Kernel SVC","metadata":{}},{"cell_type":"markdown","source":"I'm doing this one separately because I want to visualize LDA results for each PCA component.  \nThe distribitions shown in the next graph represent LDA results only on training data","metadata":{}},{"cell_type":"code","source":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nlin_svc=SVC(kernel='linear')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_rows, n_cols= 12,2\n\nfigure, axes = plt.subplots(nrows=n_rows,ncols= n_cols, figsize=(30, 120))\n\nfigure.suptitle('\\nLDA with Linear SVC\\n(Distributions represent\\nonly the training data)', fontsize=60)\n\nfor index in range(24):\n    \n    i,j = (index // n_cols), (index % n_cols)\n    \n    pca=PCA(n_components=index+1)\n    \n    lda=LinearDiscriminantAnalysis()\n    \n    some_pipe=make_pipeline(pca,lda)\n    \n    X_lda_train=some_pipe.fit_transform(X_train,Y_train)\n    \n    X_lda_test=some_pipe.fit_transform(X_test,Y_test)\n    \n    lin_svc.fit(X_lda_train,Y_train)\n    \n    y_pred_train=lin_svc.predict(X_lda_train)\n    \n    train_acc= accuracy_score(y_pred_train,Y_train)\n    \n    y_pred_test=lin_svc.predict(X_lda_test)\n    \n    test_acc= accuracy_score(y_pred_test,Y_test)\n    \n    X_lda_train=X_lda_train.reshape((240,))\n    \n    bp=sns.boxenplot(y=X_lda_train, x=Y_train, color=\"paleturquoise\",showfliers=True,ax=axes[i,j])\n    \n    axes[i,j].set_title(\"n° Of PCA Components: {}\\nTraining Accuracy: {}\\nTesting Accuracy: {}\".format(index+1,\n                                                                                                       \"%.3f\"%train_acc,\n                                                                                                       \"%.3f\"%test_acc))\n    axes[i,j].set_xlabel(None)\n    \n    axes[i,j].set_xticklabels([\"CKD\",\"No CKD\"])\n    \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Low variance despite the fact that the testing set is 0.4 of the whole dataset, which only has 400 samples.  ","metadata":{}},{"cell_type":"markdown","source":"### Evaluating A Few Other Models","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SVM_RBF=SVC()\n    \nSVM_Poly2=SVC(kernel='poly',degree=2)\n    \nSVM_Poly3=SVC(kernel='poly',degree=3)\n\nKNN3=KNeighborsClassifier(n_neighbors=3,weights='distance')\n\nKNN8=KNeighborsClassifier(n_neighbors=8,weights='distance')\n\nKNN15=KNeighborsClassifier(n_neighbors=15,weights='distance')\n\nNaive_Bayes=GaussianNB()\n\nLogReg=LogisticRegression()\n\nTree=DecisionTreeClassifier()\n\nForest=RandomForestClassifier()\n\nmodels=[SVM_RBF,SVM_Poly2,SVM_Poly3,KNN3,KNN8,KNN15,Naive_Bayes,LogReg,Tree,Forest]\n\nnames=[\"SVM_RBF\",\"SVM_Poly2\",\"SVM_Poly3\",\"Weighted 3NearestNeighbors\",\"Weighted 8NearestNeighbors\",\n       \"Weighted 15NearestNeighbors\",\"Naive Bayes\",\"Logistic Regression\",\"Decision Tree\",\"Random Forest\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_rows, n_cols= 10,1\n\nfigure, axes = plt.subplots(nrows=n_rows,ncols= n_cols, figsize=(30, 120))\n\nfigure.suptitle('\\nEvaluating Different Models', fontsize=120)\n\n\n\ntr_mask = np.empty(shape=(24,1),dtype=\"object\")\n    \nts_mask = np.empty(shape=(24,1),dtype=\"object\")\n\nfor i in range(24):\n    tr_mask[i]=\"Training\"\n    ts_mask[i]=\"Testing\"\n\nmask = np.vstack((tr_mask,ts_mask))\n\nmask=mask.reshape((48,))\n\ncmps=[i for i in range(1,25)] * 2\n\n\nfor index in range(10):\n    \n    pca_tr_acc=[]\n    \n    pca_ts_acc=[]\n    \n    \n    for n_comps in range(1,25):\n        \n        model=models[index]\n        \n        pca=PCA(n_components=n_comps)\n        \n        pca_model=make_pipeline(pca,model)\n        \n        pca_model.fit(X_train,Y_train)\n        \n        y_tr_pred= pca_model.predict(X_train)\n        \n        pca_tr_acc.append(accuracy_score(y_tr_pred,Y_train))\n        \n        y_ts_pred=pca_model.predict(X_test)\n        \n        pca_ts_acc.append(accuracy_score(y_ts_pred,Y_test))\n        \n    \n    model_data = pd.DataFrame()\n    \n    model_data[\"PCA\"] = pca_tr_acc + pca_ts_acc\n        \n    model_data[\"Results\"] = mask\n    \n    sns.barplot(x=cmps, y=\"PCA\", hue=\"Results\", data=model_data, palette='cool', ax=axes[index]).set(ylim=(0.8,1))\n    \n    axes[index].set_title(names[index],fontsize=40)\n    \n    axes[index].set_xlabel(\"n° of PCA Components\",fontsize=15)\n    \n    axes[index].set_ylabel(\"Accuracy\",fontsize=35)\n    \n    axes[index].set_xticklabels(axes[index].get_xticklabels(),fontsize=15)\n    \n    \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Notes:\nPCA didn't make any significant difference except for the degree-2 polynomial SVM, which performed awfully anyways.  \nBest results for SVM were with the polynomial kernel with degree 3.  \nNaive Bayes performed really well.  \nI would say this is due to the fact that there isn't much correlation between features.  \nNaive Bayes assumes that features are independent, which they pretty much are.  \nLogistic Regression seems to have no variance with many components.  \nThe random forest also has zero variance for certain values of n_components.  \nKNN has a higher variance compared than others, but it's still quite decent for the most part.  \nAll algorithms produced good results other than the degree-2 polynomial SVC.","metadata":{}},{"cell_type":"markdown","source":"### Neural Networks","metadata":{}},{"cell_type":"markdown","source":"So I'll be trying a small neural network with one hidden layer containing 4 neurons, and a bigger one with 3 hidden layers and lots of neurons.","metadata":{}},{"cell_type":"code","source":"import tensorflow\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.utils import to_categorical","metadata":{"execution":{"iopub.execute_input":"2021-01-16T13:44:25.564556Z","iopub.status.busy":"2021-01-16T13:44:25.563794Z","iopub.status.idle":"2021-01-16T13:44:31.552057Z","shell.execute_reply":"2021-01-16T13:44:31.550586Z"},"papermill":{"duration":6.033441,"end_time":"2021-01-16T13:44:31.552216","exception":false,"start_time":"2021-01-16T13:44:25.518775","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping_monitor = EarlyStopping(patience=5, monitor='accuracy')\nY_net = to_categorical(Y)","metadata":{"execution":{"iopub.execute_input":"2021-01-16T13:44:31.629774Z","iopub.status.busy":"2021-01-16T13:44:31.629183Z","iopub.status.idle":"2021-01-16T13:44:31.631705Z","shell.execute_reply":"2021-01-16T13:44:31.631096Z"},"papermill":{"duration":0.043032,"end_time":"2021-01-16T13:44:31.63181","exception":false,"start_time":"2021-01-16T13:44:31.588778","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca_tr_acc_1=[]\n    \npca_ts_acc_1=[]\n\n\npca_tr_acc_2=[]\n    \npca_ts_acc_2=[]\n\n\nfor i in range(1,25):\n    \n    pca=PCA(n_components=i)\n    \n    X_pca=pca.fit_transform(scaled_data)\n    \n    X_pca_train, X_pca_test, Y_train, Y_test = train_test_split(X_pca, Y_net, test_size=0.25, random_state=12)\n    \n    #little net\n    net1= Sequential()\n    \n    net1.add(Dense(4, activation='relu', input_shape = (i,)))\n    \n    net1.add(Dense(2, activation='softmax'))\n    \n    net1.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n    \n    net1.fit(X_pca_train, Y_train, epochs=50, callbacks=[early_stopping_monitor], verbose=0)\n    \n    y_tr_pred=net1.predict(X_pca_train)\n    \n    pca_tr_acc_1.append(accuracy_score(np.argmax(y_tr_pred, axis=1),Y_train[:,1]))\n    \n    y_ts_pred=net1.predict(X_pca_test)\n    \n    pca_ts_acc_1.append(accuracy_score(np.argmax(y_ts_pred, axis=1),Y_test[:,1]))\n    \n    \n    \n    #big net\n    net2= Sequential()\n    \n    net2.add(Dense(50, activation='relu', input_shape = (i,)))\n    \n    net2.add(Dense(30, activation='relu'))\n    \n    net2.add(Dense(20, activation='relu'))\n    \n    net2.add(Dense(10, activation='relu'))\n    \n    net2.add(Dense(2, activation='softmax'))\n    \n    net2.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n    \n    net2.fit(X_pca_train, Y_train, epochs=100, callbacks=[early_stopping_monitor], verbose=0)\n    \n    y_tr_pred=net2.predict(X_pca_train)\n    \n    pca_tr_acc_2.append(accuracy_score(np.argmax(y_tr_pred, axis=1),Y_train[:,1]))\n    \n    y_ts_pred=net2.predict(X_pca_test)\n    \n    pca_ts_acc_2.append(accuracy_score(np.argmax(y_ts_pred, axis=1),Y_test[:,1]))","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr_mask = np.empty(shape=(24,1),dtype=\"object\")\n    \nts_mask = np.empty(shape=(24,1),dtype=\"object\")\n\nfor i in range(24):\n    tr_mask[i]=\"Training\"\n    ts_mask[i]=\"Testing\"\n\nmask = np.vstack((tr_mask,ts_mask))\n\nmask=mask.reshape((48,))\n\ncmps=[i for i in range(1,25)] * 2\n\n\nnet1_data = pd.DataFrame()\n    \nnet1_data[\"PCA\"] = pca_tr_acc_1 + pca_ts_acc_1\n\nnet1_data[\"Results\"] = mask\n\n\nnet2_data = pd.DataFrame()\n    \nnet2_data[\"PCA\"] = pca_tr_acc_2 + pca_ts_acc_2\n\nnet2_data[\"Results\"] = mask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_rows, n_cols= 1,2\n\nfigure, axes = plt.subplots(nrows=n_rows,ncols= n_cols, figsize=(30, 10))\n\nfigure.suptitle('Little NN vs Big(ger) NN', fontsize=40)\n\n\n\ngraph1=sns.barplot(x=cmps, y=\"PCA\", hue=\"Results\", data=net1_data, palette='cool', ax=axes[0]).set(ylim=(0.5,1))\n\naxes[0].set_title(\"Little Neural Network\",fontsize=30)\n\naxes[0].set_xlabel(\"n° of PCA Components\",fontsize=25)\n\naxes[0].set_ylabel(\"Accuracy\",fontsize=25)\n\naxes[0].set_xticklabels(axes[0].get_xticklabels(),fontsize=15)\n\n\n\ngraph2=sns.barplot(x=cmps, y=\"PCA\", hue=\"Results\", data=net2_data, palette='cool', ax=axes[1]).set(ylim=(0.5,1))\n\naxes[1].set_title(\"Big(ger) Neural Network\",fontsize=30)\n\naxes[1].set_xlabel(\"n° of PCA Components\",fontsize=25)\n\naxes[1].set_ylabel(\"Accuracy\",fontsize=25)\n\naxes[1].set_xticklabels(axes[1].get_xticklabels(),fontsize=15)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Notes:\nObviously, the bigger network had better and more consistent results.  \nWith certain values of n_components there seems to be no variance.  \nI don't see why the smaller network gave such inconsistent results; accuracy changes drastically for certain values of n_components.","metadata":{"execution":{"iopub.execute_input":"2021-01-16T13:44:35.538809Z","iopub.status.busy":"2021-01-16T13:44:35.537962Z","iopub.status.idle":"2021-01-16T13:44:35.541081Z","shell.execute_reply":"2021-01-16T13:44:35.540516Z"},"papermill":{"duration":0.065789,"end_time":"2021-01-16T13:44:35.541204","exception":false,"start_time":"2021-01-16T13:44:35.475415","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Final Thoughts and Self-Criticism\n\n  \n  \nLinear, Gaussian, and Uniform transformations worked well with KNN imputation.  \n\nPCA didn't make any significant difference as there isn't much correlation between features.  \n\nK-Means clustering seems decent as a classification algorithm.  \n\nOne can further experiment with other clustering algorithms.  \n\nAnother interesting thing to try is training a model on the output of T-SNE.  \n\nOne can also try simply dropping features with a percentage of missing values higher than a specified threshhold.  \n\nI need to make my code more \"Pythonic\" and use less nested loops and if-statements.  \n\nI also need to start using functions for recurrent tasks.  ","metadata":{}},{"cell_type":"markdown","source":"That's about it I guess.  \nI hope you enjoyed it and found it beneficial.  ","metadata":{}},{"cell_type":"markdown","source":"##  الحمد لله الذي بنعمته تتم الصالحات\n## سبحانك اللهم وبحمدك\n## أشهد أن لا إله إلا أنت\n## أستغفرك وأتوب إليك","metadata":{}}]}