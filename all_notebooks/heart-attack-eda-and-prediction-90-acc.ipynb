{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nimport sklearn\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\n\n\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\n\n\n\nfrom skopt import BayesSearchCV\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import RepeatedKFold\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sqlalchemy import Table, Column, Float, Integer, BigInteger\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('../input/heart-attack-analysis-prediction-dataset/heart.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check for null value\nWe can see from below output no feature in data have missing value","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### This will help us to know about data type i.e. categorical or numerical","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Univariate Analysis","metadata":{}},{"cell_type":"markdown","source":"#### check feature distribution","metadata":{}},{"cell_type":"markdown","source":"#### To check the feature in normally distributed for continuous feature","metadata":{}},{"cell_type":"code","source":"cat_features = ['sex','cp','fbs','restecg', 'exng', 'slp', 'caa','thall']\ncont_features = ['age','trtbps','chol','thalachh']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### categorical feature distribution","metadata":{}},{"cell_type":"code","source":"for feature in cat_features:\n    plt.figure(figsize=(7,4))\n    sns.set_theme(style=\"whitegrid\")\n    ax = sns.countplot(df[feature])\n    plt.xticks(rotation=90)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in cat_features:\n    plt.figure(figsize=(7,4))\n    sns.set_theme(style=\"whitegrid\")\n    ax = sns.violinplot(x=feature,y='output',data=df)\n    plt.xticks(rotation=90)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### continuous feature distribution","metadata":{}},{"cell_type":"code","source":"for feature in cont_features:\n    plt.figure(figsize=(7,4))\n    sns.set_theme(style=\"whitegrid\")\n    ax = sns.distplot(df[feature])\n    plt.xticks(rotation=90)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in cont_features:\n    plt.figure(figsize=(7,4))\n    sns.set_theme(style=\"whitegrid\")\n    ax = sns.boxplot(df[feature])\n    plt.xticks(rotation=90)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"from the above boxplot we can say that some outlier is there in trtbps and chol","metadata":{}},{"cell_type":"code","source":"for feature in cont_features:\n    plt.figure(figsize=(7,4))\n    sns.set_theme(style=\"whitegrid\")\n    ax = sns.violinplot(feature,hue='output',data=df)\n    plt.xticks(rotation=90)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### By count plot we can check dependent variable distribution\nFrom the below plot we can clearly see the distribution is balanced","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8,5))\nsns.set_theme(style=\"whitegrid\")\nax = sns.countplot(x='output', data=df)\nplt.xticks(rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bivariate analysis","metadata":{}},{"cell_type":"markdown","source":"### With the help of corelation matrix we  see that how the features are related to each other","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14,12))\nsns.heatmap(df.corr(), annot=True, cmap='coolwarm')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = df['output']\nX = df.drop('output', axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape, y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting the data into train and test","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=24, test_size=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Standardization","metadata":{}},{"cell_type":"code","source":"sc = StandardScaler()\nX_train_sc = sc.fit_transform(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Applying PCA","metadata":{}},{"cell_type":"code","source":"pc = PCA(n_components=len(X.columns))\nX_train_pc=pc.fit_transform(X_train_sc)\nPC_df_train=pd.DataFrame(X_train_pc,columns=['PC_' +str(i) for i in range(1,pc.n_components_+1)])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PC_df_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scree Plot - PCA Analysis\nIn multivariate statistics, a scree plot is a line plot of the eigenvalues of factors or principal components in an analysis. The scree plot is used to determine the number of factors to retain in an exploratory factor analysis (FA) or principal components to keep in a principal component analysis (PCA)","metadata":{}},{"cell_type":"markdown","source":"#### To select number of principal components elbow method is used\n\nWe can clearly, proper elbow is not formed in the below graph, so we can select all the components","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nplt.plot(PC_df_train.std())\nplt.title('Scree Plot - PCA components')\nplt.xlabel('Principal Component')\nplt.ylabel('Standard deviation')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model building","metadata":{}},{"cell_type":"code","source":"print(PC_df_train.shape)\ny_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier = LogisticRegression()\nclassifier.fit(pc.fit_transform(X_train_sc),y_train)\nX_test_sc = sc.transform(X_test)\nX_test_pc = pc.transform(X_test_sc)\ny_lr=classifier.predict(X_test_pc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Confusion Matrix \\n',confusion_matrix(y_lr,y_test))\nprint()\nprint('Accuracy Score \\n', accuracy_score(y_lr,y_test))\nprint()\nprint('Classification Report \\n',classification_report(y_lr,y_test))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### SVC Classifier","metadata":{}},{"cell_type":"code","source":"classifier = SVC()\nclassifier.fit(pc.fit_transform(X_train_sc),y_train)\nX_test_sc = sc.transform(X_test)\nX_test_pc = pc.transform(X_test_sc)\ny_svc=classifier.predict(X_test_pc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Confusion Matrix \\n',confusion_matrix(y_svc,y_test))\nprint()\nprint('Accuracy Score \\n', accuracy_score(y_svc,y_test))\nprint()\nprint('Classification Report \\n',classification_report(y_svc,y_test))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### RandomForest Classifier","metadata":{}},{"cell_type":"code","source":"classifier = RandomForestClassifier()\nclassifier.fit(pc.fit_transform(X_train_sc),y_train)\nX_test_sc = sc.transform(X_test)\nX_test_pc = pc.transform(X_test_sc)\ny_rfc=classifier.predict(X_test_pc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Confusion Matrix \\n',confusion_matrix(y_rfc,y_test))\nprint()\nprint('Accuracy Score \\n', accuracy_score(y_rfc,y_test))\nprint()\nprint('Classification Report \\n',classification_report(y_rfc,y_test))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Gradient Boosting Classifier","metadata":{}},{"cell_type":"code","source":"classifier = GradientBoostingClassifier()\nclassifier.fit(pc.fit_transform(X_train_sc),y_train)\nX_test_sc = sc.transform(X_test)\nX_test_pc = pc.transform(X_test_sc)\ny_gbc=classifier.predict(X_test_pc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Confusion Matrix \\n',confusion_matrix(y_gbc,y_test))\nprint()\nprint('Accuracy Score \\n', accuracy_score(y_gbc,y_test))\nprint()\nprint('Classification Report \\n',classification_report(y_gbc,y_test))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"classifier = RandomForestClassifier(n_estimators=100,\n                                    min_samples_split=5,\n                                    min_samples_leaf=1,\n                                    max_depth=5)\nclassifier.fit(X_train_sc,y_train)\nX_test_sc = sc.transform(X_test)\ny_rfc=classifier.predict(X_test_sc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Confusion Matrix \\n',confusion_matrix(y_rfc,y_test))\nprint()\nprint('Accuracy Score \\n', accuracy_score(y_rfc,y_test))\nprint()\nprint('Classification Report \\n',classification_report(y_rfc,y_test))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Naive Bayes","metadata":{}},{"cell_type":"code","source":"classifier = GaussianNB()\nclassifier.fit(pc.fit_transform(X_train_sc),y_train)\nX_test_sc = sc.transform(X_test)\nX_test_pc = pc.transform(X_test_sc)\ny_gb=classifier.predict(X_test_pc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Confusion Matrix \\n',confusion_matrix(y_gb,y_test))\nprint()\nprint('Accuracy Score \\n', accuracy_score(y_gb,y_test))\nprint()\nprint('Classification Report \\n',classification_report(y_gb,y_test))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### XGboost Classifier","metadata":{}},{"cell_type":"code","source":"Xgboost=XGBClassifier(random_state=28)\nparams = {'n_estimators': (100,300),\n                  'learning_rate': (0.01, 0.6),\n                  'subsample': (0.3, 0.9),\n                  'max_depth': (2,5),\n                  'colsample_bytree': (0.5, 0.9),\n                  'min_child_weight': (1,5)\n                 }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_classifier = RandomForestClassifier(random_state=34)\n\nParam_rf={'max_depth':(2,5),\n                         'min_samples_split':(5,10), \n                         'n_estimators':(100,300),\n                         'min_samples_leaf':(1,3)\n\n         }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=1)\nsearch = RandomizedSearchCV(rf_classifier, Param_rf, cv=cv)\nsearch.fit(pc.fit_transform(X_train_sc), y_train)\nprint(search.best_params_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclassifier = XGBClassifier(subsample= 0.9,\n                           n_estimators=300,\n                           min_child_weight=5,\n                           max_depth=2,\n                           learning_rate=0.01,\n                           colsample_bytree= 0.9)\nclassifier.fit(pc.fit_transform(X_train_sc),y_train)\nX_test_sc = sc.transform(X_test)\nX_test_pc = pc.transform(X_test_sc)\ny_xg=classifier.predict(X_test_pc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Confusion Matrix \\n',confusion_matrix(y_xg,y_test))\nprint()\nprint('Accuracy Score \\n', accuracy_score(y_xg,y_test))\nprint()\nprint('Classification Report \\n',classification_report(y_xg,y_test))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_df = pd.DataFrame(data=[f1_score(y_test,y_lr),accuracy_score(y_test, y_lr), recall_score(y_test, y_lr), precision_score(y_test, y_lr), roc_auc_score(y_test, y_lr)], \n             columns=['Logistic Regression'], index=[\"F1\",\"Accuracy\", \"Recall\", \"Precision\", \"ROC AUC Score\"])\nrf_df = pd.DataFrame(data=[f1_score(y_test,y_rfc),accuracy_score(y_test, y_rfc), recall_score(y_test, y_rfc),precision_score(y_test, y_rfc), roc_auc_score(y_test, y_rfc)], \n             columns=['Random Forest Score'],index=[\"F1\",\"Accuracy\", \"Recall\", \"Precision\", \"ROC AUC Score\"])\nnb_df = pd.DataFrame(data=[f1_score(y_test,y_gb),accuracy_score(y_test, y_gb), recall_score(y_test, y_gb), precision_score(y_test, y_gb), roc_auc_score(y_test, y_gb)], \n             columns=['Naive Bayes'], index=[\"F1\",\"Accuracy\", \"Recall\", \"Precision\", \"ROC AUC Score\"])\n\nxg_df = pd.DataFrame(data=[f1_score(y_test,y_xg),accuracy_score(y_test, y_xg), recall_score(y_test, y_xg), precision_score(y_test, y_xg), roc_auc_score(y_test, y_xg)], \n             columns=['XG Boost'], index=[\"F1\",\"Accuracy\", \"Recall\", \"Precision\", \"ROC AUC Score\"])\ngbc_df = pd.DataFrame(data=[f1_score(y_test,y_gbc),accuracy_score(y_test, y_gbc), recall_score(y_test, y_gbc), precision_score(y_test, y_gbc), roc_auc_score(y_test,y_gbc)], \n             columns=['Gradient Boosting'], index=[\"F1\",\"Accuracy\", \"Recall\", \"Precision\", \"ROC AUC Score\"])\nsvc_df = pd.DataFrame(data=[f1_score(y_test,y_svc),accuracy_score(y_test, y_svc), recall_score(y_test, y_svc), precision_score(y_test, y_svc), roc_auc_score(y_test,y_svc)], \n             columns=['Gradient Boosting'], index=[\"F1\",\"Accuracy\", \"Recall\", \"Precision\", \"ROC AUC Score\"])\n\n\ndf_models = round(pd.concat([lr_df,rf_df,nb_df,gbc_df,xg_df,svc_df], axis=1),3)\ncolors = [\"bisque\",\"ivory\",\"sandybrown\",\"steelblue\",\"lightsalmon\"]\ncolormap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n\nbackground_color = \"white\"\n\nfig = plt.figure(figsize=(18,26)) # create figure\ngs = fig.add_gridspec(4, 2)\ngs.update(wspace=0.1, hspace=0.5)\nax0 = fig.add_subplot(gs[0, :])\n\nsns.heatmap(df_models.T, cmap=colormap,annot=True,fmt=\".1%\",vmin=0,vmax=0.95, linewidths=2.5,cbar=False,ax=ax0,annot_kws={\"fontsize\":16})\nfig.patch.set_facecolor(background_color) # figure background color\nax0.set_facecolor(background_color) \n\nax0.text(0,-0.5,'Model Comparison',fontsize=20,fontweight='bold',fontfamily='serif')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\n### We can conclude that almost all machine learning model perform well. However, Naive Bias gives the best accuracy 0f 90.2%","metadata":{}}]}