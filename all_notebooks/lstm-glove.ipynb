{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils import data\nimport torch.nn.functional as F\nfrom torch.autograd import Variable as V\nimport torch.optim as optim\nfrom tqdm import tqdm\nfrom torchtext import data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TEXT = data.Field(tokenize='spacy',batch_first=True,include_lengths=True)\nLABEL = data.LabelField(dtype = torch.float,batch_first=True)\n\nfields = [(None, None),('label', LABEL), ('text',TEXT)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data=data.TabularDataset(path = '/kaggle/input/deepnlp/Sheet_1.csv',format = 'csv',fields = fields,skip_header = True)\n\nprint(vars(training_data.examples[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\ntrain_data, valid_data = training_data.split(split_ratio=0.7, random_state = random.seed(SEED))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n#get GloVe vector embeddings\nembeddings_index = {}\nwith open('/kaggle/input/glove-global-vectors-for-word-representation/glove.6B.100d.txt','r') as f:\n    for line in tqdm(f):\n        values = line.split()\n        word = values[0]\n        coefs = np.asarray(values[1:], dtype='float32')\n        embeddings_index[word] = coefs\nf.close()\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''for key in embeddings_index:\n    print(key, ' : ', embeddings_index[key])\n'''    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TEXT.build_vocab(train_data,min_freq=3,vectors = 'glove.6B.100d')  \nLABEL.build_vocab(train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#No. of unique tokens in text\nprint(\"Size of TEXT vocabulary:\",len(TEXT.vocab))\n\n#No. of unique tokens in label\nprint(\"Size of LABEL vocabulary:\",len(LABEL.vocab))\n\n#Commonly used words\nprint(TEXT.vocab.freqs.most_common(10))  \n\n#Word dictionary\nprint(TEXT.vocab.stoi)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#set batch size\nBATCH_SIZE = 64\n\n#Load an iterator\ntrain_iterator, valid_iterator = data.BucketIterator.splits(\n    (train_data, valid_data), \n    batch_size = BATCH_SIZE,\n    sort_key = lambda x: len(x.text),\n    sort_within_batch=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Network(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n                 bidirectional, dropout):\n        super(Network, self).__init__()\n        self.embedding=nn.Embedding(vocab_size,embedding_dim)\n        self.lstm=nn.LSTM(embedding_dim,\n                  hidden_dim,\n                  num_layers=n_layers,\n                  bidirectional=bidirectional,\n                  dropout=dropout,\n                  batch_first=True)\n        self.fc=nn.Linear(hidden_dim * 2, output_dim)\n        self.sigmoid=nn.Sigmoid()\n    \n    def forward(self, text, text_lengths):\n        embedded=self.embedding(text)\n        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths,batch_first=True)\n        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n        dense_outputs=self.fc(hidden)\n        outputs=self.sigmoid(dense_outputs)\n        return outputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"size_of_vocab = len(TEXT.vocab)\nembedding_dim = 100\nnum_hidden_nodes = 32\nnum_output_nodes = 1\nnum_layers = 2\nbidirection = True\ndropout = 0.2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Network(size_of_vocab, embedding_dim, num_hidden_nodes,num_output_nodes, num_layers, \n                   bidirectional = True, dropout = dropout)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Initialize the pretrained embedding\npretrained_embeddings = TEXT.vocab.vectors\nmodel.embedding.weight.data.copy_(pretrained_embeddings)\n\nprint(pretrained_embeddings.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer=optim.Adam(model.parameters())\ncriterion=nn.BCELoss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def binary_accuracy(preds, y):\n    #round predictions to the closest integer\n    rounded_preds = torch.round(preds)\n    \n    correct = (rounded_preds == y).float() \n    acc = correct.sum() / len(correct)\n    return acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(iterator):\n    epoch_loss,epoch_acc=0,0\n    model.train()\n    for batch in iterator:\n        optimizer.zero_grad()\n        text, text_lengths = batch.text\n        predictions = model(text, text_lengths).squeeze()\n        loss = criterion(predictions, batch.label)\n        acc = binary_accuracy(predictions, batch.label)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()  \n        epoch_acc += acc.item()    \n    return epoch_loss / len(iterator), epoch_acc / len(iterator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(iterator):\n    epoch_loss = 0\n    epoch_acc = 0\n    \n    #deactivating dropout layers\n    model.eval()\n    \n    #deactivates autograd\n    with torch.no_grad():\n        for batch in iterator:\n            text, text_lengths = batch.text\n            #convert to 1d tensor (whyyyyyy)\n            predictions = model(text, text_lengths).squeeze()\n            \n            loss = criterion(predictions, batch.label)\n            acc = binary_accuracy(predictions, batch.label)\n            epoch_loss += loss.item()\n            epoch_acc += acc.item()\n        \n    return epoch_loss / len(iterator), epoch_acc / len(iterator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS=10\nbest_valid_loss = float('inf')\n\nfor epoch in range(EPOCHS):\n    train_loss, train_acc = train(train_iterator)\n    valid_loss, valid_acc = evaluate(valid_iterator)\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), 'saved_weights.pt')\n    \n    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path='saved_weights.pt'\nmodel.load_state_dict(torch.load(path));\nmodel.eval();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import spacy\nnlp = spacy.load('en')\n\ndef predict(model, sentence):\n    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]  #tokenize the sentence \n    indexed = [TEXT.vocab.stoi[t] for t in tokenized]          #convert to integer sequence\n    length = [len(indexed)]                                    #compute no. of words\n    tensor = torch.LongTensor(indexed)#.to(device)              #convert to tensor\n    tensor = tensor.unsqueeze(1).T                             #reshape in form of batch,no. of words\n    length_tensor = torch.LongTensor(length)                   #convert to tensor\n    prediction = model(tensor, length_tensor)                  #prediction \n    return prediction.item()                       ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}