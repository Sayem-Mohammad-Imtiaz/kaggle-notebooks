{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#### This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc50fddadd6fd4fa7c46e0567ffc1b4cd546af54"},"cell_type":"code","source":"#create dataset by yourself (BUILDING DATA FRAMES FROM SCRATCH)\n#way 1\ndict1 = {\"kind\": [\"cake\",\"donut\",\"ice cream\"], \"prize\": [10,5,3]}\nfirstdataframe = pd.DataFrame(dict1)\nfirstdataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"948ce67c343d5042546718bce1baa85754ee8980"},"cell_type":"code","source":"#way 2\nemploye_name = [\"Jonathan\",\"Stan\",\"Chris\"]     #list 1\nsalary = [150,170,125]                        #list 2\nlist_label = [\"employe name\",\"salary\"]       #columns' label\nlist_column = [employe_name,salary]           #list which used in below of column\nzipped = list(zip(list_label,list_column))     #zipping 2 columns, and making list from them \nmakedict = dict(zipped)                         #making dictionary \ndataframe2nd = pd.DataFrame(makedict)          #making data frame from dictionary \ndataframe2nd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca3480f48d163886ae529e629a437e4f2adefc86"},"cell_type":"code","source":"#adding a column\ndataframe2nd[\"departmant\"] = [\"accountancer\",\"manager\",\"editor\"]\ndataframe2nd[\"new column\"] = 0 #broadcasting  - add new column and give same values for all rows\ndataframe2nd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e950c5683d0cf47af6ec08c56bd2c67bf5df3d94"},"cell_type":"code","source":"data = pd.read_csv(\"../input/hfi_cc_2018.csv\")\ndata.plot() #making plot from all data - there are lots of columns, this plot is confusing. let's make it for some columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d8cba3481c7a92ea4eda58d3197d5b3c89b3462"},"cell_type":"code","source":"data1 = data.loc[:,[\"pf_rol_criminal\",\"pf_religion\"]]     #pf=personal freedom rol=rules of law - loc[:,[\"pf_rol_criminal\",\"pf_religion\"]] ->: all rows\ndata1.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3bbc1962752f11105dc0c4819d3ed3330504f704"},"cell_type":"code","source":"data1.plot(subplots = True) #subplots=True -> set plots in different areas but in same plot \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f0a324b8f6429b98eb2a18cb9035656608414b1"},"cell_type":"code","source":"#scatter plot\ndata1.plot(kind=\"scatter\",x=\"pf_rol_criminal\",y=\"pf_religion\")\nplt.show()\n#way 2\ndata1.plot.scatter(x=\"pf_rol_criminal\",y=\"pf_religion\",c=\"grey\",alpha=0.5)\nplt.show()           #c->color alpha->opacity ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"252f3086bd20f97cdafba86666a36305708c5a1d"},"cell_type":"code","source":"#histogram\ndata1.plot(kind = \"hist\",y = \"pf_rol_criminal\",bins = 40,range= (0,50),normed=True)\n#bins = 40 -> lines' thickness, range= (0,50)->detect last number on y line- normed=True -> normalizing frequency between 0-1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8736b05638f24b34bd7c0d47ac4671c5806011b0"},"cell_type":"code","source":"import warnings as w\nw.filterwarnings(\"ignore\")\nfig, axes = plt.subplots(nrows=2,ncols=1)#nrows-ncols : number of rows and columns\ndata1.plot(kind = \"hist\",y = \"pf_rol_criminal\",bins = 50,range= (0,20),ax = axes[0],normed=True) #axes[0] -> column wise  axes[1]-> row wise\ndata1.plot(kind = \"hist\",y = \"pf_rol_criminal\",bins = 50,range= (0,20),ax = axes[1],normed=True,cumulative = True) #cumulative = True -> as the name implies, previous plus next, plus next.. (it's like fibonacci numbers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67e84aacbc4d2ce7d41b31dc1714243cc6d7cdca"},"cell_type":"code","source":"#INDEXING PANDAS TIME SERIES\ntimes = [\"2019-01-24\",\"2004-01-08\",\"1923-04-23\"] #make a normal list, includes date\nprint(type(times[1]))  #elements of list are strings yet\ndatetimeObject = pd.to_datetime(times) #str converted to datetime object\nprint(type(datetimeObject))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a945d52487abbc06d47c3c767949c77d597bb17"},"cell_type":"code","source":"#let's use it in a dataset\ndata2 = data.head() #top 5\ndata2             #this dataset already have years but i will use that i will add","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d24241579ef93e1c42ba0e2add590653b873bd1c"},"cell_type":"code","source":"datelist = [\"2004-01-08\",\"2004-01-23\",\"1999-09-23\",\"1999-01-10\",\"2004-02-23\"] #make a list includes date\ndatetObject = pd.to_datetime(datelist)   #making datetime object from list\nprint(type(datetObject)) #confirm lists' elements are date time object  \ndata2[\"dates\"] = datetObject #make a new column and put elements under it\ndatanew = data2.set_index(\"dates\",inplace=True) #make new column index\ndatanew","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e66193025cdde7d1b70127cd6a8645d270462daf"},"cell_type":"code","source":"print(data2.loc[\"1998-01-19\":\"2000-03-16\"])      # loc[\"a-b-c\",\"d-e-f\"]-- now i can learn how many dates between the dates i want","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3e3d719e7d0a150d83ba4b127b63a65e5905f4a"},"cell_type":"code","source":"print(data2.loc[:\"2004-02-20\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1920b87021ed0003dd6d92ad1b2bc62767a34d7b"},"cell_type":"code","source":"data2.resample(\"M\").mean() #monthly mean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73c10e92dca602edaaf3f03adde72d5d39e05596"},"cell_type":"code","source":"data2.resample(\"A\").mean() #yearly mean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"58ff367bc2954b3456be8ef53822d78db40feb33"},"cell_type":"code","source":"data2.resample(\"A\").first().interpolate(\"linear\") #first(\"xD\") : get the rows for the first x days\n#interpolate(\"linear\") : ignore the index and treat the values as equally spaced","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5301124f7d443af25f3198fe572f03653e9f6f0e"},"cell_type":"code","source":"data2.resample(\"M\").mean().interpolate(\"linear\")  ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}