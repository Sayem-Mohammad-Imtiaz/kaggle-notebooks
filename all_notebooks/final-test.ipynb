{"cells":[{"metadata":{"_uuid":"aa78333d-4f84-4fd1-916b-4511ce4db2db","_cell_guid":"3d7cba17-d703-4480-91de-f35eb34a45d1","trusted":true},"cell_type":"code","source":"# Recently FastAI is updated to version v2 so this code will update you on what has been changed\n# remember in kaggle you have to turn internet to download the new packages (settings->internet(on))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ab0631f-b614-41c2-bc07-ca51a06c13ae","_cell_guid":"1695c7a0-c63a-4c29-a8e6-a467932dfd9f","trusted":true},"cell_type":"markdown","source":"# Importing the train and test csv files which contain the information whether the image is representing emergency vehicle or not"},{"metadata":{"_uuid":"e41ebcc2-da9a-4ed5-85d7-1830715e5986","_cell_guid":"96ca5159-543f-4fbe-957a-251282edaea4","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import fastai; print(fastai.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.vision.all import *","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6bb464c6-52f7-47a6-be0b-530b34c0d25d","_cell_guid":"e4770918-4154-470a-bfaf-9e1a6fc6553a","trusted":true},"cell_type":"code","source":"path = '../input/hackerearths-snakes-in-the-hood/dataset'\ntrain_data = pd.read_csv('../input/hackerearths-snakes-in-the-hood/dataset/train.csv')\ntest_data = pd.read_csv('../input/hackerearths-snakes-in-the-hood/dataset/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['image_id'] = train_data['image_id'].apply(lambda x:x+'.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['image_id'] = test_data['image_id'].apply(lambda x:x+'.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"84b118a3-38ab-44c0-91e2-514960d62497","_cell_guid":"9f03af9a-a672-4f98-b984-b2414bb56238","trusted":true},"cell_type":"markdown","source":"# Performing basic Augmentations"},{"metadata":{"_uuid":"4aefa6ca-ce46-4706-83c6-0fec6f268d63","_cell_guid":"6bfc9692-16c8-4d91-bd26-d138936b57f5","trusted":true},"cell_type":"code","source":"# this will add flip, warp, zoom and rotation to the images\n# tfms = aug_transforms(do_flip = True, max_lighting = 0.2, max_zoom= 1.1, max_warp = 0.15, max_rotate = 45)\nitem_tfms = [Resize(224, method='crop')]\nbatch_tfms=[*aug_transforms( do_flip=True,flip_vert=False ,max_rotate=20.0, max_zoom=1.3, max_lighting=0.5, max_warp=0.1, p_affine=0.2,\n                      p_lighting=0.55), Normalize.from_stats(*imagenet_stats)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# batch_tfms = [*tfms,Normalize.from_stats(*imagenet_stats)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nX,y = train_data['image_id'], train_data['breed']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Resnet101 "},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = np.zeros((test_data.shape[0], 35))\noof = np.zeros(train_data.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mapping_label_breed = dict(zip(train_data['breed'].unique(), range(len(train_data['breed'].unique()))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# inv_mapping_label_breed = dict(zip(range(len(train_data['breed'].unique())), train_data['breed'].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_data['breed'] = train_data['breed'].map(mapping_label_breed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pytorchcv torch>=0.4.0\nfrom pytorchcv.model_provider import get_model as ptcv_get_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def shufflenet(pretrained=True):\n    net = ptcv_get_model(\"squeezenet1_1\", pretrained=True)\n    net2 = nn.Sequential()\n    net2.add_module(\"features\", net.features)\n#     net2.add_module(\"features\", net.features[:-1])\n\n    net2.add_module(\"final_pool\", nn.AdaptiveAvgPool2d(output_size=1))\n    net2.add_module(\"fc\", nn.Linear(in_features=4096, out_features=35))\n    return net2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2530d611-cf9c-48fc-9a6c-b912169affd4","_cell_guid":"1d15285e-972a-444e-896d-ba854396c557","trusted":true},"cell_type":"code","source":"# we will be using resnet 101 model\n\nall_models = [models.resnet101]\n\nfnames = get_image_files('../input/hackerearths-snakes-in-the-hood/dataset/test')\n\nfor model in all_models:\n    for fold, (tr_ids, val_ids) in enumerate(StratifiedKFold(n_splits=5).split(X, y)):\n        import gc\n        gc.collect()\n        torch.cuda.empty_cache()\n        train_data.loc[val_ids,'valid'] = 1\n        train_data.loc[tr_ids,'valid'] = 0\n        \n        snake_breed_dls = ImageDataLoaders.from_df(train_data,path+'/train/', \n                              batch_tfms = batch_tfms,\n                              bs = 64,\n                              val_bs=64,\n                              item_tfms=item_tfms,\n                              valid_col = 'valid',\n                              fn_col='image_id',\n                              label_col='breed')\n        \n        print(snake_breed_dls.valid_ds.__len__())\n        \n        \n        learn = cnn_learner(snake_breed_dls, model,metrics=[CohenKappa(), F1Score(average='weighted'),accuracy], model_dir=\"/tmp/model/\",wd=1e-05)\n        \n        \n        learn.save('/tmp/model/'+model.__name__)\n        \n        sbs=SaveModelCallback(monitor='cohen_kappa_score', fname=model.__name__)\n        \n        torch.cuda.set_device(0)\n        learn.unfreeze()\n        learn.fit_one_cycle(25, cbs=[sbs, ])\n        \n        learn = learn.load('/tmp/model/'+model.__name__)\n       \n        dl = learn.dls.test_dl(fnames)\n        \n        res = learn.tta( dl=dl,n=8)\n        \n        predictions += np.array(res[0])\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"category = {'agkistrodon-contortrix':1,\n            'agkistrodon-piscivorus':2, \n            'coluber-constrictor':3, \n            'crotalus-atrox':4, \n            'crotalus-horridus':5, \n            'crotalus-ruber':6, \n            'crotalus-scutulatus':7, \n            'crotalus-viridis':8, \n            'diadophis-punctatus':9, \n            'haldea-striatula':10, \n            'heterodon-platirhinos':11, \n            'lampropeltis-californiae':12, \n            'lampropeltis-triangulum':13, \n            'masticophis-flagellum':14, \n            'natrix-natrix':15, \n            'nerodia-erythrogaster':16, \n            'nerodia-fasciata':17, \n            'nerodia-rhombifer':18, \n            'nerodia-sipedon':19, \n            'opheodrys-aestivus':20, \n            'pantherophis-alleghaniensis':21, \n            'pantherophis-emoryi':22, \n            'pantherophis-guttatus':23, \n            'pantherophis-obsoletus':24, \n            'pantherophis-spiloides':25, \n            'pantherophis-vulpinus':26, \n            'pituophis-catenifer':27, \n            'rhinocheilus-lecontei':28, \n            'storeria-dekayi':29, \n            'storeria-occipitomaculata':30, \n            'thamnophis-elegans':31, \n            'thamnophis-marcianus':32, \n            'thamnophis-proximus':33, \n            'thamnophis-radix':34, \n            'thamnophis-sirtalis':35}\n\n\nrev_category = {val: key for key, val in category.items()}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_submit = pd.DataFrame(columns=['image_id', 'breed'])\nfinal_submit['image_id'] = [str(i).split('/')[5].split('.')[0] for i in fnames]\nfinal_submit['breed'] = np.argmax(predictions, axis=1)+1\nfinal_submit['breed'] = final_submit['breed'].map(rev_category)\nfinal_submit.to_csv('submit.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_submit.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}