{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **IMPORTING DATA**","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data=pd.read_csv(\"../input/daily-temperature-of-major-cities/city_temperature.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now that we had a quick look over the data, let's try some TIMEEEE SERRIEESSSS MODEEELLLSS\n<img src=\"https://media.tenor.com/images/8636ae856342f311049ec5573e263889/tenor.gif\">","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**NOTE**: This dataset contains various cities and nations ,I will be using only the temperatures of Delhi.  ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Taking out only Delhi data\ndelhi=data[data[\"City\"]==\"Delhi\"]\ndelhi.reset_index(inplace=True)\ndelhi.drop('index',axis=1,inplace=True)\ndelhi.describe()           ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting the temperatures","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(15,6))\nplt.plot(delhi[\"AvgTemperature\"])\nplt.ylabel(\"Temperature\",fontsize=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"OHHHH BOY O BOY we have some wrong values too , as the data have some -99 degree temps. WOOOOSSSSHHH I dont think that is possible as a student of science. We have to deal with this data , so I will make these values imputed.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nimputer=SimpleImputer()\ndelhi[\"AvgTemperature\"].replace(-99,np.nan,inplace=True)#Replacing wrong entries with nan \ndelhi[\"AvgTemperature\"]=pd.DataFrame(imputer.fit_transform(delhi.loc[:,\"AvgTemperature\":]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see how many years of data we have in our data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(min(delhi[\"AvgTemperature\"]))\nyears=delhi[\"Year\"].unique()\nyears","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining training and testing data\ntraining_set=delhi[delhi[\"Year\"]<=2015]\ntest_set=delhi[delhi[\"Year\"]>2015]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Mean of the temperatures\ndelhi.iloc[:,-1].mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's see how our data looks after dealing with all the wrong values. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,7))\nplt.plot(delhi.iloc[:,-1])\nplt.xlabel(\"Time Series\",fontsize=20)\nplt.ylabel(\"Temperature\",fontsize=20)\n#making a list of values to be plotted on y axis\ny_values=[x for x in range(50,101,10)]\ny_values.extend([delhi.iloc[:,-1].min(),delhi.iloc[:,-1].max(),delhi.iloc[:,-1].mean()])\nplt.yticks(y_values)\nplt.axhline(y=delhi.iloc[:,-1].mean(), color='r', linestyle='--',label=\"Mean\")\nplt.legend(loc=1)\nplt.axhline(y=delhi.iloc[:,-1].max(), color='g', linestyle=':')\nplt.axhline(y=delhi.iloc[:,-1].min(), color='g', linestyle=':')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.graphics.tsaplots import plot_acf\nplot_acf(delhi[\"AvgTemperature\"],lags=365)\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Clearly the graph looks geometrical and there is no abrupt cutoff in the values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.graphics.tsaplots import plot_pacf\nplot_pacf(delhi[\"AvgTemperature\"],lags=50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### There is an early cutoff after the first lag in the graph","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's start with the AutoReg model\n**Lags taken into consideration in model = 1,2,3,.....365**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.ar_model import AutoReg\nmodel_AR=AutoReg(training_set[\"AvgTemperature\"],lags=365)\nmodel_fit_AR=model_AR.fit()\npredictions_AR = model_fit_AR.predict(training_set.shape[0],training_set.shape[0]+test_set.shape[0]-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport seaborn as sns\nplt.figure(figsize=(15,5))\nplt.ylabel(\"Temperature\",fontsize=20)\nplt.plot(test_set[\"AvgTemperature\"],label=\"Original Data\")\nplt.plot(predictions_AR,label=\"Predicted Data\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## *LOLLLLL This went down too well, worked like a charm but unfortunately other models won't work like this*\n<img src=\"https://media1.tenor.com/images/610c4fe56dad195b0ffe5e76d2a02761/tenor.gif?itemid=4461765\">","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's calculate the mean squared error of the predicted data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nmse=mean_squared_error(predictions_AR,test_set[\"AvgTemperature\"])\nmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now with only lag=365 taking into consideration ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.ar_model import AutoReg\nmodel_AR2=AutoReg(training_set[\"AvgTemperature\"],lags=[365])\nmodel_fit_AR2=model_AR2.fit()\npredictions_AR2= model_fit_AR2.predict(training_set.shape[0],training_set.shape[0]+test_set.shape[0]-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.ylabel(\"Temperature\",fontsize=20)\nplt.plot(test_set[\"AvgTemperature\"],label=\"Original Data\")\nplt.plot(predictions_AR2,label=\"Predicted Data\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**This graph looks accurate than the previous one but let's check if it actually works better or not**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mse=mean_squared_error(predictions_AR2,test_set[\"AvgTemperature\"])\nmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **MOVING AVERAGE**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.arima_model import ARMA\nmodel_MA=ARMA(training_set[\"AvgTemperature\"],order=(0,10))\nmodel_fit_MA=model_MA.fit()\npredictions_MA=model_fit_MA.predict(test_set.index[0],test_set.index[-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.ylabel(\"Temperature\",fontsize=20)\nplt.plot(test_set[\"AvgTemperature\"],label=\"Original Data\")\nplt.plot(predictions_MA,label=\"Predictions\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mse=mean_squared_error(predictions_MA,test_set[\"AvgTemperature\"])\nmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Autoregressive Moving Average (ARMA)**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_ARMA=ARMA(training_set[\"AvgTemperature\"],order=(5,10))\nmodel_fit_ARMA=model_ARMA.fit()\npredictions_ARMA=model_fit_ARMA.predict(test_set.index[0],test_set.index[-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.ylabel(\"Temperature\",fontsize=20)\nplt.plot(test_set[\"AvgTemperature\"],label=\"Original Data\")\nplt.plot(predictions_ARMA,label=\"Predictions\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mse=mean_squared_error(predictions_ARMA,test_set[\"AvgTemperature\"])\nmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# ***NOTE*:**\n\nIt is pretty lame to try to predict something that is going to happen over the next 5 years , but when we have data at our disposal why should'nt we ?\nThat's what data science is for.\nThe model used are just for showcase purposes i.e. how they perform when used on an *almost stationary* data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# I would be trying to create another notebook for ARIMA and ARIMAX models with a different data set, this is enough for now with the current dataset. Have a nice day.\n<img src=\"https://media1.tenor.com/images/b93d03f39d1b379cf648e5568a4537e7/tenor.gif?itemid=11696907\">","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}