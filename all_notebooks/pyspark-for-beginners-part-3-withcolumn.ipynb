{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install pyspark","metadata":{"execution":{"iopub.status.busy":"2021-06-23T10:59:55.538829Z","iopub.execute_input":"2021-06-23T10:59:55.539228Z","iopub.status.idle":"2021-06-23T11:00:00.959377Z","shell.execute_reply.started":"2021-06-23T10:59:55.539194Z","shell.execute_reply":"2021-06-23T11:00:00.958477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install findspark","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:00:00.96116Z","iopub.execute_input":"2021-06-23T11:00:00.961412Z","iopub.status.idle":"2021-06-23T11:00:06.273044Z","shell.execute_reply.started":"2021-06-23T11:00:00.961387Z","shell.execute_reply":"2021-06-23T11:00:06.27201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PySpark withColumn() is a transformation function which is used to UPDATE the value of an existing, convert the DATATYPE of an existing column, create a new column. trim columns","metadata":{}},{"cell_type":"code","source":"from pyspark.sql import SparkSession \nspark=SparkSession.builder.appName(\"withcol\").getOrCreate()\n\n ","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:00:06.274709Z","iopub.execute_input":"2021-06-23T11:00:06.275086Z","iopub.status.idle":"2021-06-23T11:00:06.280828Z","shell.execute_reply.started":"2021-06-23T11:00:06.275033Z","shell.execute_reply":"2021-06-23T11:00:06.280013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=spark.read.csv(\"../input/employee-salary-dataset/Employee_Salary_Dataset.csv\",header=True,inferSchema=True)\ndf.show(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:00:06.281961Z","iopub.execute_input":"2021-06-23T11:00:06.282208Z","iopub.status.idle":"2021-06-23T11:00:06.614721Z","shell.execute_reply.started":"2021-06-23T11:00:06.282184Z","shell.execute_reply":"2021-06-23T11:00:06.613727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.printSchema()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:00:06.624546Z","iopub.execute_input":"2021-06-23T11:00:06.626875Z","iopub.status.idle":"2021-06-23T11:00:06.63424Z","shell.execute_reply.started":"2021-06-23T11:00:06.626802Z","shell.execute_reply":"2021-06-23T11:00:06.633346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.Changing Data types","metadata":{}},{"cell_type":"markdown","source":"### I am changing the salary data type from Integer to string and putting it into another dataframe.In the first method I used the dataframe to fetch the column that I want to cast and in the second method I have used col","metadata":{}},{"cell_type":"code","source":"#Method 1:\ndf1=df.withColumn(\"Salary\",df[\"Salary\"].cast(\"String\"))\ndf1.printSchema()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:00:06.635742Z","iopub.execute_input":"2021-06-23T11:00:06.636203Z","iopub.status.idle":"2021-06-23T11:00:06.655097Z","shell.execute_reply.started":"2021-06-23T11:00:06.6361Z","shell.execute_reply":"2021-06-23T11:00:06.654289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Method 2:\nfrom pyspark.sql.functions import col\ndf2=df.withColumn(\"Salary\",col(\"Salary\").cast(\"String\"))\ndf2.printSchema()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:00:06.65652Z","iopub.execute_input":"2021-06-23T11:00:06.657161Z","iopub.status.idle":"2021-06-23T11:00:06.685099Z","shell.execute_reply.started":"2021-06-23T11:00:06.657124Z","shell.execute_reply":"2021-06-23T11:00:06.684198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Updating the value of an existing column","metadata":{}},{"cell_type":"code","source":"df1=df.withColumn(\"ID\",df[\"ID\"]+50)\ndf1.show(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:00:06.686515Z","iopub.execute_input":"2021-06-23T11:00:06.687101Z","iopub.status.idle":"2021-06-23T11:00:06.76337Z","shell.execute_reply.started":"2021-06-23T11:00:06.687048Z","shell.execute_reply":"2021-06-23T11:00:06.762295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2=df.withColumn(\"ID\",col(\"ID\") *20)\ndf2.show(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:00:06.764511Z","iopub.execute_input":"2021-06-23T11:00:06.76485Z","iopub.status.idle":"2021-06-23T11:00:06.846048Z","shell.execute_reply.started":"2021-06-23T11:00:06.764815Z","shell.execute_reply":"2021-06-23T11:00:06.845204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Create a new Column from an Existing","metadata":{}},{"cell_type":"code","source":"df1=df.withColumn(\"New_ID\",df[\"ID\"]+10)\ndf1.show(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:00:06.847459Z","iopub.execute_input":"2021-06-23T11:00:06.847806Z","iopub.status.idle":"2021-06-23T11:00:06.934278Z","shell.execute_reply.started":"2021-06-23T11:00:06.847765Z","shell.execute_reply":"2021-06-23T11:00:06.933291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2=df.withColumn(\"New_ID\",col(\"ID\") *10)\ndf2.show(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:00:06.93542Z","iopub.execute_input":"2021-06-23T11:00:06.938246Z","iopub.status.idle":"2021-06-23T11:00:07.026831Z","shell.execute_reply.started":"2021-06-23T11:00:06.938205Z","shell.execute_reply":"2021-06-23T11:00:07.02616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Create a fresh new column","metadata":{}},{"cell_type":"markdown","source":"### Lit function is use to add a value to the new column","metadata":{}},{"cell_type":"code","source":"from pyspark.sql.functions import lit\ndf1=df.withColumn(\"Country\", lit(\"   India   \"))\ndf1.show(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:00:07.027622Z","iopub.execute_input":"2021-06-23T11:00:07.027832Z","iopub.status.idle":"2021-06-23T11:00:07.137023Z","shell.execute_reply.started":"2021-06-23T11:00:07.027811Z","shell.execute_reply":"2021-06-23T11:00:07.135924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Rename a column","metadata":{}},{"cell_type":"code","source":"df1=df1.withColumnRenamed(\"gender\",\"sex\")\ndf1.show(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:00:07.138105Z","iopub.execute_input":"2021-06-23T11:00:07.138452Z","iopub.status.idle":"2021-06-23T11:00:07.22121Z","shell.execute_reply.started":"2021-06-23T11:00:07.138423Z","shell.execute_reply":"2021-06-23T11:00:07.220145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.Trim a column","metadata":{}},{"cell_type":"markdown","source":"### you can see I have left whitespace before and after India in country column. Lets trim this","metadata":{}},{"cell_type":"code","source":"from pyspark.sql.functions import ltrim,rtrim,trim\ndf2=df1.withColumn(\"Country\",ltrim(\"Country\")) #left trim\ndf2.show(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:00:07.222458Z","iopub.execute_input":"2021-06-23T11:00:07.222715Z","iopub.status.idle":"2021-06-23T11:00:07.304382Z","shell.execute_reply.started":"2021-06-23T11:00:07.222689Z","shell.execute_reply":"2021-06-23T11:00:07.303265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3=df1.withColumn(\"Country\",rtrim(\"Country\")) #right trim\ndf3.show(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:00:07.305705Z","iopub.execute_input":"2021-06-23T11:00:07.30603Z","iopub.status.idle":"2021-06-23T11:00:07.396281Z","shell.execute_reply.started":"2021-06-23T11:00:07.305997Z","shell.execute_reply":"2021-06-23T11:00:07.395224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df4=df1.withColumn(\"Country\",trim(\"Country\"))\ndf4.show(3)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:00:07.397437Z","iopub.execute_input":"2021-06-23T11:00:07.397795Z","iopub.status.idle":"2021-06-23T11:00:07.51064Z","shell.execute_reply.started":"2021-06-23T11:00:07.397757Z","shell.execute_reply":"2021-06-23T11:00:07.50956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Timestamp","metadata":{}},{"cell_type":"code","source":"from pyspark.sql.functions import current_date\ndf1 = df.withColumn(\"current_date\",current_date())\ndf1.show(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:06:27.168372Z","iopub.execute_input":"2021-06-23T11:06:27.168816Z","iopub.status.idle":"2021-06-23T11:06:27.275139Z","shell.execute_reply.started":"2021-06-23T11:06:27.168782Z","shell.execute_reply":"2021-06-23T11:06:27.274175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using When()","metadata":{}},{"cell_type":"code","source":"from pyspark.sql.functions import when\ndf_when = df.withColumn(\"new_col\", when(df.Salary < 50000,\"low\")\n                                 .when(df.Salary >=50 ,\"high\")\n                                 .when(df.Salary.isNull() ,\"\")\n                                 .otherwise(df.Salary))\ndf_when.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T11:10:56.463683Z","iopub.execute_input":"2021-06-23T11:10:56.463973Z","iopub.status.idle":"2021-06-23T11:10:56.596341Z","shell.execute_reply.started":"2021-06-23T11:10:56.463943Z","shell.execute_reply":"2021-06-23T11:10:56.595597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}