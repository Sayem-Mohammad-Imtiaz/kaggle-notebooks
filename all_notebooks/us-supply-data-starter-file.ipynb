{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Libraries and Packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read in Data\nRead in data dictionary for recoding data, read in main commodity flow file and also read in a state name variable "},{"metadata":{},"cell_type":"markdown","source":"The data dictionary files are used to recode the commodity flow survey data "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#read in the data dictionary  \ndata_dictionary = pd.ExcelFile('/kaggle/input/us-supply-chain-information-for-covid19/cfs-2012-pum-file-users-guide-app-a-jun2015.xlsx')\n\n# Print sheet names\n#print(data_dictionary.sheet_names)\n#['Data Dictionary', 'App A1', 'App A2', 'App A3', 'App A4']\n\n#parse app1 and app2 \napp1 = data_dictionary.parse('App A1', skiprows=[0,1], names=['MA', 'State','CFS_AREA','MA_TYPE','MA_Description'])\napp2 = data_dictionary.parse('App A2', skiprows=[0], names=['NAICS', 'NAICS_Description'])\n\n#read in app 3 and fill down file \napp3 = data_dictionary.parse('App A3', skiprows=[0], names=['Commodity_Code', 'Commodity_Description','Commodity_Group'])\napp3['Commodity_Group'] = app3['Commodity_Group'].ffill() #need to fill down the page \napp3['Commodity_Code'] = app3['Commodity_Code'].apply(lambda x: str(x))\n\n#app3 needs to be constructed from scratch \n# initialize list of lists \ndata = [['02', 'Single Mode'], \n        ['03', 'Truck'],\n        ['04', 'For-hire Truck'],\n        ['05', 'Private Truck'],\n        ['06', 'Rail'],\n        ['07', 'Water'],\n        ['08', 'Inland Water'],\n        ['09', 'Great Lakes'],\n        ['10', 'Deep Sea'],\n        ['101', 'Multiple Waterways'],\n        ['11', 'Air'],\n        ['12', 'Pipeline'],\n        ['13', 'Multiple Mode'],\n        ['14', 'Parcel-USPS-Courier'],\n        ['20', 'Non-parcel multimode'],\n        ['15', 'Truck and Rail'],\n        ['16', 'Truck and Water'],\n        ['17', 'Rail and Water'],\n        ['18', 'Other Multiple Mode'],\n        ['09', 'Other Mode'],\n        ['00', 'Mode Suppressed']] \n  \n# Create the pandas DataFrame \napp4 = pd.DataFrame(data, columns = ['Mode_Code', 'Mode_Description'])\napp3.head(20)\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#read in the state names data for short hand reference if needed\nstates = pd.read_csv('/kaggle/input/us-supply-chain-information-for-covid19/state_code_to_name.csv')\nstates.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#read in the flat file for commodity flow survey \ncfs = pd.read_csv('/kaggle/input/us-supply-chain-information-for-covid19/cfs-2012-pumf-csv/cfs_2012_pumf_csv.txt')\ncfs.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#cfs.shape #(4547661, 20) \n\nThis file is 4,547,661 rows by 20 columns. In the example of COVID19 perhaps we are most interested in states with shutdown orders and total values/types of flow. We can also try to subset on specific cities as a destination or we could try and focus on specific commdoity codes. Codes 21 + 38 are related to medical products that might be of interest"},{"metadata":{"trusted":true},"cell_type":"code","source":"#reduce size of data base \ncfs=cfs[['ORIG_STATE','DEST_STATE','SCTG','SHIPMT_VALUE']]\n\ncfs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cfs=cfs[(cfs['SCTG']=='21') | (cfs['SCTG']=='38')]\n#cfs.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Recode CFS Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#get shape of cfs\n#cfs_recode = pd.concat([cfs, states], axis=1, join='left')\n\n#recode orig state \ncfs = pd.merge(cfs, states, how='left',left_on='ORIG_STATE', right_on='StateCode')\ncfs = cfs.rename(columns = {\"StateName\":\"ORIG_STATE_NAME\"}) \ndel cfs['StateCode']\ndel cfs['ORIG_STATE']\n\ncfs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#recode dest_state\ncfs = pd.merge(cfs, states, how='left',left_on='DEST_STATE', right_on='StateCode')\ncfs = cfs.rename(columns = {\"StateName\":\"DEST_STATE_NAME\"}) \ndel cfs['StateCode']\ndel cfs['DEST_STATE']\n\ncfs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#recode sctg code \ncfs = pd.merge(cfs, app3, how='left',left_on='SCTG', right_on='Commodity_Code')\n#cfs = cfs.rename(columns = {\"MA_Description\":\"ORIG_MA_Description\"}) \ndel cfs['SCTG']\ndel cfs['Commodity_Code']\ndel cfs['Commodity_Group']\n\ncfs.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualize "},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nf, ax = plt.subplots(figsize=(15, 10))\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=90)\nsns.boxplot('Commodity_Description', 'SHIPMT_VALUE', data=cfs)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For this exercise well focus on Pharmaceuticals and Precision Instruments"},{"metadata":{"trusted":true},"cell_type":"code","source":"cfs=cfs[(cfs['Commodity_Description']=='Pharmaceutical Products') | (cfs['Commodity_Description']=='Precision Instruments and Apparatus')]\ncfs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set()\nf, ax = plt.subplots(figsize=(15, 10))\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=90)\nsns.boxplot('ORIG_STATE_NAME', 'SHIPMT_VALUE', data=cfs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cfs.pivot(\"ORIG_STATE_NAME\",\"DEST_STATE_NAME\",\"SHIPMT_VALUE\")\ncfs_nonzero = cfs[cfs.SHIPMT_VALUE>0]\ncfs_state=cfs_nonzero.pivot_table(index='ORIG_STATE_NAME', \n                        columns='DEST_STATE_NAME', \n                        values='SHIPMT_VALUE')\n\nf, ax = plt.subplots(figsize=(20, 15))\nsns.heatmap(cfs_state, linewidths=1, ax=ax)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}