{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Remenber use parameters \"encoding\" and \"thousands\" while importing the data, otherwise there will be an error with encoding or you will get 1.000 (number 'one' with decimal point) instead of 1000 if you want to read the number \"one thousand\""},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"raw_data = pd.read_csv('/kaggle/input/forest-fires-in-brazil/amazon.csv', encoding = 'latin1', thousands = '.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then convert spanish month into numerical month."},{"metadata":{"trusted":true},"cell_type":"code","source":"month_list = raw_data.groupby('month').size()\nmonth_inspan = month_list.index.values.tolist()\nmonth_innum = [4,8,12,2,1,7,6,5,3,11,10,9]\nreplace_dic = {}\nfor i in range(len(month_inspan)):\n    replace_dic[month_inspan[i]] = month_innum[i]\nfire_data = raw_data.replace({'month': replace_dic})\nprint('Converted Data looks like this:')\nfire_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sort the data, get the raw time line\nfire_data = fire_data.sort_values(by = ['state','year','month'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems that we have dupicate rows with different 'number' item. It is because some states in Brazil share the same abbrevation. This problem cannot be solved in this dataset. What we can do is to remove all states with the same abbrevation, just keep the ones that could be analyze.\n\nOr you can visit [This Discussion](https://www.kaggle.com/gustavomodelli/forest-fires-in-brazil/discussion/117901) for dataset with whole state name. I already put the seperated dataset in my github and attached that link in my comment.\n\nLet's see what to be removed in the dataset provided by Kaggle:"},{"metadata":{"trusted":true},"cell_type":"code","source":"state_rownum = fire_data.groupby('state').size()\nprint(state_rownum)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can simply remove 'Mato Grosso', 'Paraiba', 'Rio' because these have two or three times items more than the other abbrevitions toward states.\n\nBut what's wrong with 'Alagoas'?"},{"metadata":{},"cell_type":"markdown","source":"## Remove abnormal data in state 'Alagoas'"},{"metadata":{},"cell_type":"markdown","source":"Split Alagoas from the raw dataset so you don't have to load the whole dataset for analyze."},{"metadata":{"trusted":true},"cell_type":"code","source":"Alagoas_data = fire_data.query(\"state == 'Alagoas'\")\nAlagoas_data.sort_values(by = ['year','month'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are two ways to find out the abnormal data, one is to use set in python to find the duplicated variables automatically, another one is quite tricky."},{"metadata":{},"cell_type":"markdown","source":"### Solution 1. Using python set"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = set()\nfor i in range(len(Alagoas_data)):\n    # this is just for checking, so no matter how ugly the elements in temp set looks\n    if (Alagoas_data.iloc[i]['year'] * 100 + Alagoas_data.iloc[i]['month']) not in temp:\n        temp.add(Alagoas_data.iloc[i]['year'] * 100 + Alagoas_data.iloc[i]['month'])\n    else:\n        print('Duplicate Data')\n        print(Alagoas_data.iloc[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Alagoas_data.loc[(Alagoas_data.year == 2017)&(Alagoas_data.month ==1)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nWe can safely remove one of these two rows because they are exactly the same."},{"metadata":{},"cell_type":"markdown","source":"### Solution 2. Mathmetical T[](http://)rick"},{"metadata":{},"cell_type":"markdown","source":"First inspect both fire dataset and Alagoas data by using df.describe()"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Description of the fire dataset')\nprint(fire_data.describe())\nprint('\\n')\nprint('Description of Alagoas data')\nprint(Alagoas_data.describe())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Than locating the exact year by simple calculation"},{"metadata":{"trusted":true},"cell_type":"code","source":"2007.5 * 240 - 2007.461729 * 239","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Got it, the abnormal data will be either 2016 or 2017, let's inspect it."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_16 = Alagoas_data.query(\"year == 2016\")\nprint(data_16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_17 = Alagoas_data.query(\"year == 2017\")\nprint(data_17)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is easy to find there are two month '1's in 2017, it is the duplicate month number we need to remove."},{"metadata":{},"cell_type":"markdown","source":"Than we can drop this duplicate row in the fire dataset, as well as ambiguous state abbrevations."},{"metadata":{"trusted":true},"cell_type":"code","source":"fire_data = fire_data.drop(fire_data[(fire_data['state'] == 'Mato Grosso') | (fire_data['state'] == 'Paraiba') | (fire_data['state'] == 'Rio') ].index)\nif fire_data.iloc[258].empty == False:\n    fire_data = fire_data.drop(258)\nprint(fire_data.groupby('state').size())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fire_formatted = fire_data\n# need to do reset index otherwise rows removed will be an issue\nfire_formatted = fire_formatted.reset_index(drop = True)\nfor i in range(len(fire_formatted)):\n    fire_formatted.at[i,'happened_date'] = str(fire_formatted.at[i, 'year']) + '-' + str(fire_formatted.at[i, 'month'])\nfire_formatted","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop rows that is not useful:"},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = pd.DataFrame(fire_formatted, columns = ['state', 'number','happened_date'])\n# group data by different states\ngroupby_state = dt.groupby('state')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can create a dataset with states and time line"},{"metadata":{"trusted":true},"cell_type":"code","source":"fire = []\ntime = []\nstate_name = []\n\nfor i in range(len(dt)):\n    if dt.iloc[i,2] not in time:\n        time.append(dt.iloc[i,2])\n    if dt.iloc[i,0] not in state_name:\n        state_name.append(dt.iloc[i,0])\n\nfor state, item in groupby_state:\n        fire.append(item.iloc[:,1].values.tolist())\n\n\nfire_dt = pd.DataFrame(fire, columns = time)\nfire_dt.insert(loc = 0, column = 'state', value = state_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Head:')\nprint(fire_dt.head())\nprint('\\n')\nprint('Describe')\nprint(fire_dt.describe())\nprint('\\n')\nprint('info')\nprint(fire_dt.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fire_dt.to_csv('state_timeline.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Than you can do other things like visualization by using this new dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(50,25))\nfor i in range(1, fire_dt.shape[0]):\n    plt.plot(fire_dt.columns[1:].tolist(), fire_dt.iloc[i,1:].values.tolist(), label = fire_dt.iloc[i,0], color = np.random.rand(3,))\n\nplt.xlabel('Date')\nplt.ylabel('Number')\nplt.xticks(rotation=90)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}