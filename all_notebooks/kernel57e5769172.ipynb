{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Загрузка библиотек и предварительные настройки","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport os\nimport shutil\n\nsns.set()\n\n%matplotlib inline\n\nwarnings.filterwarnings(\"ignore\")\n\n# не обрезать колонки (видимость до 100 столбцов)\npd.set_option('max_columns',100)\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Удаляем папку logs (используется tensorboard и catboost) и её содержимое после последних запусков\n# if os.path.isdir('/kaggle/working/logs'):\n#    shutil.rmtree('/kaggle/working/logs')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Загрузка данных","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/craigslist-carstrucks-data/vehicles.csv', \n                 usecols=[4,5,6,7,8,9,10,11,12,13,15,16,17,18,22,23,24],\n                 encoding='latin',\n                 dtype={4:int, \n                        5:float, \n                        6:object, \n                        7:object, \n                        8:object, \n                        9:object, \n                        10:object, \n                        11:float, \n                        12:object, \n                        13:object,\n                        15:object, \n                        16:object, \n                        17:object,\n                        18:object, \n                        22:object, \n                        23:float, \n                        24:float})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Заполнение пропущенных данных","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# проверяем пропуски в cтолбцах\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# частотность и тип данных в столбце Year\ndf.iloc[:,2].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# частотность и тип данных в столбце Odometr\ndf.iloc[:,8].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# замена пропущенных данных в year и odometer на округлённый Mean\ndf['year'].fillna(round(df['year'].mean(), 0), inplace=True)\ndf['year'] = df['year'].astype(int)\n\n#df['odometer'].fillna(round(df['odometer'].mean(), 0), inplace=True)\n#df['odometer'] = df['odometer'].astype(int)\n\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# проверяем пропуски в cтолбцах\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Анализ данных","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Построим матрицу корреляций","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nspearman = df.corr(method = 'spearman')\nsns.heatmap(spearman, annot = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Цена имеет хорошую положительную корреляцию с годом выпуска и хорошую отрицательную с пробегом (odometer)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Гео-анализ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Интересные примеры","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Количество объявлений о продаже автобусов на карте","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# folium heatmap instructions: https://www.kaggle.com/daveianhickey/how-to-folium-for-maps-heatmaps-time-data\nimport folium\nfrom folium.plugins import HeatMap\n\ncars=df[df[\"type\"]==\"bus\"]\ncars.lat.fillna(0, inplace = True)\ncars.long.fillna(0, inplace = True) \ncars = cars[['lat', 'long']]\n\nCarMap=folium.Map(location=[35,-91],zoom_start=4)\nHeatMap(data=cars, radius=16).add_to(CarMap)\nCarMap","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Большая часть объявлений о продаже автобусов в основном сосредоточена на востоке США","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Стоимость ванов на карте","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Красным отмечены самые дорогие города","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# статистика по количеству типов автомобилей (что бы не перегружать карту)\ndf['type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# возьмём ваны (van) для примера \ncars=df[df[\"type\"]==\"van\"]\ncars.lat.fillna(0, inplace = True)\ncars.long.fillna(0, inplace = True) \ncars = cars[['lat', 'long', 'price']]\n\nCarMap=folium.Map(location=[35,-91],zoom_start=4)\nHeatMap(data=cars, radius=12).add_to(CarMap)\nCarMap","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В центральной части ваны мало продают. Самые высокие цены в крупных городах, на окраинах и в центральной части США цены ниже","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Распределение по признакам","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Посмотрим на распределение велечин по признакам в наших данных","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.hist(figsize=(15,12), bins=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видно, что в цене присутствуют сильные выбросы","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# пример выброса с максимальной ценой на полных данных\ndf['price'].max()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Чистим выбросы (Outliers)\nTukey method для численных столбцов.\n\nЧистим данные от выборосов.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# численные колонки\ndef get_num_cols(df):\n    num_cols = [col for col in df.columns if pd.api.types.is_numeric_dtype(df[col])]\n    return num_cols\n\ndef clear_outliers(df):\n    for col in get_num_cols(df):\n        Q1 = np.percentile(df[col], 25)\n        Q3 = np.percentile(df[col],75)\n\n        # Interquartile range\n        IQR = Q3 - Q1\n        outlier_step = 1.5 * IQR\n\n        # Outliers indices\n        outliers_indicies = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        df.drop(outliers_indicies, axis = 0)\n    \n    return df\n    \nclear_outliers(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# пример выброса с максимальной ценой на полных данных\ndf['price'].max()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Выборка","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Т.к. данных слишком много для анализа (недостаточно ресурсов для обработки), то сделаем случайную выборку","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.sample(frac=0.01, random_state=42)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Чистим выборку повторно от выбросов, что бы не было случайных всплесков","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clear_outliers(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Анализ распределений","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Цена положительно коррелирована с годом и отрицательно с пробегом. При этом одометр также положительно коррелирован с годом выпуска автомобиля.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Кодировка категориальных переменных","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Кодируем категориальные признаки","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# categorical columns\ndef get_cat_cols(df):\n    cat_cols = [col for col in df.columns if pd.api.types.is_object_dtype(df[col])]\n    return cat_cols\n\n# not categorical columns\ndef get_not_cat_cols(df):\n    not_cat_cols = [col for col in df.columns if not pd.api.types.is_object_dtype(df[col])]\n    return not_cat_cols\n\ndef encode_cats(df):\n    from sklearn.preprocessing import OneHotEncoder\n    \n    cat_cols = get_cat_cols(df)\n    not_cat_cols = get_not_cat_cols(df)\n    \n    # Замен NaN на None для categorical столбцов\n    for col in cat_cols:\n        df[col].fillna('None', inplace=True)\n    \n    # трансформируем категориальные колонки\n    ohe_df = pd.DataFrame(index=df.index)\n    ohe = OneHotEncoder(handle_unknown='ignore')\n\n    for col in cat_cols:\n        ohe.fit(df[[col]])\n        ohe_result = pd.DataFrame(ohe.transform(df[[col]]).toarray(),\n                                  columns=ohe.get_feature_names(input_features=[col]),\n                                  index=df.index)\n        ohe_df = ohe_df.join(ohe_result)\n    \n    return ohe_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# дата фрейм с закодированными категориальными признаками\ndf_cat_encoded = encode_cats(df)\ndf_cat_encoded.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Нормализация числовых переменных","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def scale_nums(df):\n    from sklearn.preprocessing import StandardScaler\n\n    std_df = pd.DataFrame(index=df.index)\n    scaler = StandardScaler()\n\n    for col in get_num_cols(df):\n        scaler.fit(df[[col]])\n        std_result = pd.DataFrame(scaler.transform(df[[col]]),\n                                  columns=[col],\n                                  index=df.index)\n        std_df = std_df.join(std_result)\n\n    return std_df\n\ndf_nums_scaled = scale_nums(df)\ndf_nums_scaled.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Объединение закодированных категориальных данных со стандартизиованными числовыми переменными","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# полная выборка со всеми необходимыми столбцами\ndf_transformed = df_nums_scaled.join(df_cat_encoded)\ndf_transformed.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Разделение выборки на train и test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_sample(df):\n    from sklearn.model_selection import train_test_split\n    \n    y = df['price']\n    X = df.drop(['price'], axis=1)\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,random_state = 42)\n    \n    return X_train, X_test, y_train, y_test\n\nX_train, X_test, y_train, y_test = split_sample(df_transformed)\nX_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Моделирование","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## CatBoost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom catboost import CatBoostRegressor, Pool\n\n# TENSORBOARD (не работает на Kaggle)\n#if not os.path.isdir('/kaggle/working/logs'):\n#    os.mkdir('/kaggle/working/logs')  \n#%load_ext tensorboard\n#%tensorboard --logdir '/kaggle/working/logs'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# лучший путь запуска Catboost, если использовать Tensorboard\n'''for learning_rate in [0.03, 0.1]:\n    for depth in [4, 10, 12]:\n        for l2_leaf_reg in [3, 5, 7, 9, 15]:\n            train_dir = f'/kaggle/working/logs/lr={learning_rate} depth={depth} l2_leaf_reg={l2_leaf_reg}'\n            try:\n                os.mkdir(train_dir)\n            except:\n                pass\n\n            model = CatBoostRegressor(iterations=50,\n                          loss_function = 'RMSE',\n                          # включаем GPU при большом количестве итераций\n                          #task_type=\"GPU\",\n                          devices='0:1',\n                          learning_rate= learning_rate,\n                          train_dir = train_dir,\n                          depth = depth,\n                          l2_leaf_reg = l2_leaf_reg)\n\n            model.fit(X = np.array(X_train, float),\n                      y = np.array(y_train, float),\n                      eval_set = (np.array(X_test, float), np.array(y_test, float)),\n                      silent = True,\n                      early_stopping_rounds=10)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# т.к. ресурсы ограничены, то ставим 50 итераций (но в идеале нужно ставить примерно несколько тысяч)\nmodel = CatBoostRegressor(iterations=50,\n                          loss_function = 'RMSE',\n                          # включаем GPU при большом количестве итераций\n                          # task_type=\"GPU\",\n                          # devices='0:1',\n                          # директория для tensorboard\n                          # train_dir = train_dir\n                         )\n\ngrid = {'learning_rate': [0.03, 0.1],\n        'depth': [4, 6, 10],\n        'l2_leaf_reg': [1, 3, 5, 7, 9]}\n\ngrid_search_result = model.grid_search(grid,\n                                        X=X_train, \n                                        y=y_train, \n                                        plot=True,\n                                        search_by_train_test_split = False )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Лучшие параметры для CatBoost, судя по графику:\n\n* learning_rate: 0.1\n* depth: 10\n* l2_leaf_reg: 1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search_result['params']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Обучаем CatBoost с лучшими параметрами\nmodel_cat = CatBoostRegressor(iterations=50,\n                          loss_function = 'RMSE',\n                          # включаем GPU при большом количестве итераций \n                          # task_type=\"GPU\",\n                          # devices='0:1',\n                          # директория для tensorboard\n                          # train_dir = train_dir,\n                          learning_rate = grid_search_result['params']['learning_rate'],\n                          depth = grid_search_result['params']['depth'],\n                          l2_leaf_reg = grid_search_result['params']['l2_leaf_reg'],\n                          verbose = True)\n\nmodel_cat.fit(X = np.array(X_train, float),\n                      y = np.array(y_train, float),\n                      eval_set = (np.array(X_test, float), np.array(y_test, float)),\n                      silent = True,\n                      # больше при большом количестве итерраций (1000 для 2000, например)\n                      early_stopping_rounds=20)\n\ny_pred = model_cat.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy_report(y_test, y_pred):\n    print(\"Точность предсказания \\n\")\n    from sklearn.metrics import r2_score, mean_squared_error\n    print(\"R^2 score: \", r2_score(y_test, y_pred), \"\\nMSE: \", mean_squared_error(y_test, y_pred))\n\n    plt.figure(figsize = (10, 8))\n    plt.scatter(y_test, y_pred)\n    plt.xlim(-1, 8)\n    plt.ylim(-1, 8)\n    plt.xlabel('y_test')\n    plt.ylabel('y_pred')\n    plt.title('Точность предсказания: y_predicted vs y_test')\n    # линия\n    x = np.linspace(-1, 8, 10)\n    plt.plot(x, x, '-r')\n    # Текстовые боксы\n    plt.text(0, 5, \"Недооценённые авто\", fontsize=14, verticalalignment='top')\n    plt.text(5, 0, \"Переоценёные авто\", fontsize=14, verticalalignment='top')\n\naccuracy_report(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видно, что есть отрицательные значения, но мы наверняка не знаем является ли это ошибкой маркетплейса, рекламным ходом, спамом или же продавцы реально готовы доплачивать за то, что их автомобиль заберут (например, на утилизацию), поэтому оставим отрицательные значения в модели.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## XGBoost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Для распределённых вычислений стоит работать с Dask\n# from dask_ml.xgboost import XGBRegressor\n# from dask.distributed import Client, progress\n# client = Client(processes=False, threads_per_worker=2, n_workers=8, memory_limit='20GB')\n# client\n\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import GridSearchCV\n\n# т.к. ресурсы ограничены, то ставим n_estimators = 10 (но в идеале нужно ставить значительно больше)\nxgb_model = XGBRegressor(n_estimators = 10)\n\n# параметры, которые были оптимальны для CatBoost: learning_rate=0.1, max_depth = 10, reg_lambda = 1\nparams = {'learning_rate': [0.03, 0.1],\n        'max_depth': [6, 10],\n        'reg_lambda': [1, 3]}\n\n# перебор параметров\nxgb_grid = GridSearchCV(xgb_model,\n                        params,\n                        n_jobs = 4,\n                        cv = 3)\n\n# обучаем с перебором параметров\nxgb_grid.fit(X_train, \n            y_train,\n            # больше при большом количестве итерраций (1000 для 2000, например)\n            early_stopping_rounds = 5,\n            eval_set = [(X_test, y_test)], \n            verbose = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"XGBoost лучшие папаметры: \", xgb_grid.best_params_, \"\\nЛучший score: \", xgb_grid.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# предсказываем и строим отчёт\ny_pred = xgb_grid.predict(X_test)\naccuracy_report(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Точность предсказания получилась хуже, чем у CatBoost, но это также может быть связано с меньшим числом парамтеров и итераций, которые были использованы для оценки модели","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Выводы по оценке авто на рынке","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<u>**Недооценённые авто**</u>\n\nТакже, на графике можно определить недооценённые авто - это самый недорогой сегмент. \n\n<u>**Переоценённые авто**</u>\n\nДорогие авто, судя по графику продаются обычно дороже, чем Они могут быть оценены исходя из классических характеристик - таких как пробег, год и т.п., очевидно, что оценка таких автомобилей делается исходя из других предпосылок и, например, такой парметр, как год, после определённой даты делает скорее положительный вклад в стоимость раритетного авто, чем отрицательный.\n\nТакже наблюдается общая тенденция к переоценке автомобилей.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Наиболее важные характеристики авто, влияющие на цену","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import plot_importance\n\n# запустим модель XGBoost повторно на лучших параметрах, что бы получить важность характеристик\nxgb_model_best = XGBRegressor(n_estimators = 10,\n                        learning_rate = 0.1, \n                        max_depth = 10, \n                        reg_lambda = 1)\n\nxgb_model_best.fit(X_train, \n                y_train,\n                # больше при большом количестве итерраций (1000 для 2000, например)\n                early_stopping_rounds = 5,\n                eval_set = [(X_test, y_test)], \n                verbose = False)\n\nplot_importance(xgb_model_best, max_num_features = 20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Вывод:**\n\nОсновными факторами, которые влияют на стоимость автомобиля являются:\n* пробег\n* год выпуска\n* место продажи\n\nОстальные факторы менее слабые.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Анализ недооценённых автомобилей","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# сделаем ещё раз оценку на базе CatBoost с лучшими параметрамии, т.к. эта модель отработала лучше всего\ny_pred = model_cat.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Самые недооценённые авто в зависимости от состояния","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# степень недооценённости автомобиля\ny_underestim = y_pred - y_test\n\nX_test['y_test'] = y_test\nX_test['y_pred'] = y_pred\nX_test['y_underestim'] = y_underestim\n\n# добавим данные для анализа\nvaluation = X_test[['y_test', 'y_pred', 'y_underestim']].join(df[['manufacturer', 'type']], on = X_test.index, how = 'left')\nvaluation.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# закодируем недооценённые авто как 'Недооценён', переоценённые как 'Переоценён', остальные как 'Норма'\nvaluation['estimation'] = 'Норма'\n\n# недооценённые\nvaluation.loc[valuation['y_underestim'] >= 0.3, 'estimation'] = 'Недооценён'\n\n# переоценённые\nvaluation.loc[valuation['y_underestim'] <= -0.3, 'estimation'] = 'Переоценён'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Сортируем авто по степени недооценённости y_underestim (самые недооценённые сверху)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"valuation_sorted = valuation.sort_values(by='y_underestim', ascending=False)\nvaluation_sorted","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valuation['estimation'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# уберём нейтральные значения ('Норма') из данных, что бы можно было сравнить недоценённые авто и переоценённые\nvaluation_to_plot = valuation[(valuation['estimation'] == 'Недооценён') | (valuation['estimation'] == 'Переоценён')]\n\nsns.catplot(x=\"manufacturer\", hue=\"estimation\", data=valuation_to_plot, kind=\"count\", orient = \"h\", height=6, aspect=2.5)\nsns.catplot(x=\"type\", hue=\"estimation\", data=valuation_to_plot, kind=\"count\", orient = \"h\", height=6, aspect=2.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Выводы**\n\nДля точных выводов желательно использовать значимость и сравнивать цифры в процентах, т.к. мы делали выборку данных, но т.к. общее количество недооценённых и переоценённых авто примерно одинаковое и находится около 300, то максимальная погрешность в самой пиковой точке будет около ~5% (ориентировочно), а в нижних точках порядка 1-2%, что позволяет нам делать определённые выводы об отличии некоторых данных между собой (мы будем смотреть только цифры, которые отличаются сильнее всего).\n\nОриентируясь на представленные результаты можно предположить, что автомобили типа <u>**Седан**</u>, а также авто <u>**без указания типа**</u> и автомобили марки <u>**Ford**</u> чаще бывают <u>**недооценёнными**</u>. Переоценёнными вероятнее всего чаще бывают авто типа Coupe и Pickup, а также марки GMC, Toyota и BMW.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}