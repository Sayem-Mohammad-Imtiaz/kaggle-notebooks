{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Computing libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Graphical libraries\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\nfrom pylab import rcParams\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build healthy/broken dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '/kaggle'\ninput_path = path + '/input/gearbox-fault-diagnosis-elaborated-datasets/gearbox-fault-diagnosis-elaborated-datasets/stdev/'\nbroken_dataset  = \"broken30hz_stdev_100.csv\"\nhealthy_dataset = \"healthy30hz_stdev_100.csv\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"healthyDataset = pd.read_csv(input_path + healthy_dataset)\nbrokenDataset = pd.read_csv(input_path + broken_dataset)\n\ndataset = pd.concat([healthyDataset, brokenDataset], axis=0)\ndataset.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluate classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictor variable (features)\ncolumns = ['a1', 'a2', 'a3', 'a4', 'load']\nX = dataset[columns]\n# Target variable: Failure (boolean)\n#y = dataset.iloc[:,-1]\ny = dataset[['failure']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Setup logistic regression model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the dataset: 80% train, 20% test\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n\n# Logistic regression classifier\nfrom sklearn.linear_model import LogisticRegression\n\n# Setup the model\nlogis = LogisticRegression(max_iter=1000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluate the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import mean\nfrom numpy import std\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\n# Define the model evaluation procedure\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n# evaluate the model and collect the scores\nn_scores = cross_val_score(logis, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n# report the model performance\nprint('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train and prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train the model\nlogis_trained = logis.fit(X_train,y_train)\n\ny_pred = logis.predict(X_test)\nprint(\"Prediction for the test data (first 10 rows):\", y_pred[:10])\nprint(\"Actual gearbox condition  (first 10 rows):   \", np.array(y_test)[:,0][:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Probability vs. predicted class"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print np arrays with 2 decimal places, without scientifc notation\nnp.set_printoptions(suppress=True, precision=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_prob = logis.predict_proba(X_test)[:,1]\nprint(\"Probability for the test data (first 10 rows): \\n\", y_prob[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select the first 100 points for clarity in the graph\nn_points = 100\nprobability = y_prob[:n_points]\npred_class = np.array(y_pred)[:n_points]\n\n# Plot the graph\nplt.figure(figsize = (5,5), dpi=100)\nplt.plot(probability, pred_class, 'o', color='red', label = \"Predicted class as a function of probability\")\n#plt.plot(y_pred, y_prob, 'o', color='black');\n\nplt.xlabel('Probability')\nplt.ylabel('Predicted class (1: broken / 0: healthy) ')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Probability vs. actual class"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select the first 100 points for clarity in the graph\nn_points = 100\nprobability = y_prob[:n_points]\nactual_class = np.array(y_test)[:n_points,0]\n\n# Plot the graph\nplt.figure(figsize = (5,5), dpi=100)\nplt.plot(probability, actual_class, 'o', color='blue', label = \"Actual state vs. probability\")\n\nplt.xlabel('Probability')\nplt.ylabel('Actual class (1: broken / 0: healthy) ')\n\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Probability vs. sensor data"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (5,5), dpi=100)\n\na1 = X_test.iloc[:,0]\na2 = X_test.iloc[:,1]\na3 = X_test.iloc[:,2]\na4 = X_test.iloc[:,3]\n\nplt.plot(a1, y_prob, 'o', color='red', label = \"Broken probability vs. a1\")\n#plt.plot(y_pred, y_prob, 'o', color='black');\n\nplt.xlabel('stdev(a1)')\nplt.ylabel('Probability of broken')\n\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ROC curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"# For the ROC curve we need not only the predicted class ('Outcome'), but also the scores on what the predictions are based\n# * if threshold 0\n#  ** predict>0 => Outcome=1\n#  ** predict<0 => Outcome=0 \n#  - Remember that predictions were calculated with METHOD .predict(X_test)\n#  - Now we also have to include METHOD .decision_function(X_test)\ny_pred_score = logis.decision_function(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, roc_auc_score, auc\n\n# If using the test set (X_test, y_test)\nfpr,tpr,threshold= roc_curve(y_test, y_pred_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Area Under Curve\nlr_auc = auc(fpr, tpr)\nprint(\"AUC=\", lr_auc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This default size comes from above\n#rcParams['figure.figsize'] = 12, 8\n\nplt.figure(figsize = (5,5), dpi=100)\n\nplt.plot(fpr, tpr, color='red', linestyle='-', label = \"Logistic Regression (auc  = %0.3f)\"%lr_auc)\nplt.plot([0,1],[0,1],color='blue',linestyle='--')\n\nplt.xlabel('False Positive Rate (1-specificity)')\nplt.ylabel('True Positive Rate (sensitivity)')\n\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}