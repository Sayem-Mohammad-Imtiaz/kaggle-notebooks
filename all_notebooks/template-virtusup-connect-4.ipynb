{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Notebook template para a competição Connect X do Virtus-UP.\n\nNessa competição vamos criar agentes inteligentes para o jogo connect X. Vamos utilizar o mesmo ambiente utilizado na competição https://www.kaggle.com/c/connectx/, essa competição ainda está em andamento.\n\nPara a nossa competição não vamos permitir apenas técnicas da IA clássica.\n\nLeia com atenção os textos. Qualquer dúvida crie uma discursão na página da competição ou mande mensagem para os monitores.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Setup do Notebook\n\n## IMPORTATE: Habilite a internet no painel lateral. Settings/Internet/On","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Precisamos fazer o download do ambiente de Connect X:\n# Vamos precisar de um kaggle-enviroments customizado para a avaliação.\n!pip install git+https://github.com/matheusgmaia/kaggle-environments\n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Criar ambiente\nfrom kaggle_environments import evaluate, make, utils\nimport numpy as np\n\nenv = make(\"connectx\", debug=True)\nenv.render()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exemplo de Agente\n\nTo create the submission, an agent function should be fully encapsulated (no external dependencies).  \n\nWhen your agent is being evaluated against others, it will not have access to the Kaggle docker image.  Only the following can be imported: Python Standard Library Modules, gym, numpy, scipy, pytorch (1.3.1, cpu only), and more may be added later.\n\n////\n\n\nPara a submissão funcionar o agente deve funcionar de maneira encapsulada (sem dependências externas).\n\n(Competição Oficial) Quando o seu seu agente for avaliado em relação a outros agentes não teremos acesso á sua imagem docker do Kaggle. Só as seguintes bibliotecas podem ser importadas: Python Standard Library Modules, gym, numpy, scipy, pytorch (1.3.1, cpu only), e outras podem ser adicionadas no futuro.\n\n(Competição Virtus Up) Pode utilizar bibliotecas diferentes.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exemplo de agente. Esse agente escolhe de maneira aleatória uma coluna que não esteja completa\nimport random\ndef my_agent(obs, cfg): #recebe o estado atual do jogo e a configuração do jogo\n    coluna = random.choice([c for c in range(cfg.columns) if obs.board[c] == 0])\n    return coluna","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testar o seu Agente\n\nEste trecho simula o comportamento do agente contra um agente randômico.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"env.reset()\nenv.run([my_agent, \"random\"]) #Agente definido em my_agent versus angente randômico.\nenv.render(mode=\"ipython\", width=500, height=450)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Debug/Train o seu Agent.\n\nAqui é possível ver como o seu agente funciona a cada etapa.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Play as first position against random agent.\ntrainer = env.train([None, \"random\"])\n\nobservation = trainer.reset()\n\nwhile not env.done:\n    my_action = my_agent(observation, env.configuration)\n    print(\"Ação do seu agente: Coluna\", my_action+1)\n    observation, reward, done, info = trainer.step(my_action)\n    env.render(mode=\"ipython\", width=100, height=90, header=False, controls=False)\nenv.render()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Jogue você mesmo\nClick on any column to place a checker there (\"manually select action\").\n\nVocê pode jogar contra o seu agente ou contra qualquer um dos 4 agentes já definidos (random, negamax, rules, greedy).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# \"None\" represents which agent you'll manually play as (first or second player).\nenv.play([None, my_agent], width=500, height=450) #Altere \"rules\" por my_agent para jogar contra o seu agente","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sua vez\n\n* Redefina o seu agente com as técnicas de IA clássicas aprendidas durante o curso. \n* É fundamental entender bem como funciona o jogo e como interagir com ele.\n* Utilize as funções de teste e avaliação para te ajudar. \n* Consulte Tutoriais e discurssões (Não copie código).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Sua vez\n## **Creating the base game**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def check_winner_piece(board, piece):\n    for row in range(board.shape[0]):\n        for column in range(board.shape[1]):\n            if (column + 3) < board.shape[1] and board[row,column] != 0:\n                if board[row,column] == board[row,column + 1] and \\\n                   board[row,column + 1] == board[row,column + 2] and \\\n                   board[row,column + 2] == board[row,column + 3]:\n                    return board[row,column] == piece\n\n            if (row + 3) < board.shape[0] and board[row,column] != 0:\n                if board[row,column] == board[row + 1,column] and \\\n                   board[row + 1,column] == board[row + 2,column] and \\\n                   board[row + 2,column] == board[row + 3,column]:\n                    return board[row,column] == piece\n\n            if (column + 3) < board.shape[1] and (row + 3) < board.shape[0] and board[row,column] != 0:\n                if board[row,column] == board[row + 1,column + 1] and \\\n                   board[row + 1,column + 1] == board[row + 2,column + 2] and \\\n                   board[row + 2,column + 2] == board[row + 3,column + 3]:\n                    return board[row,column] == piece\n\n            if (column + 3) < board.shape[1] and (row + 3) < board.shape[0] and board[row + 3,column] != 0:\n                if board[row + 3,column] == board[row + 2,column + 1] and \\\n                   board[row + 2,column + 1] == board[row + 1,column + 2] and \\\n                   board[row + 1,column + 2] == board[row,column + 3]:\n                    return board[row + 3,column] == piece\n    return False\n\ndef drop_piece(board, column, piece):  \n    temp_board = board.copy()\n    if temp_board[0,column] == 0:\n        best_mov1e = 0\n        for y in range(temp_board.shape[0]):\n            if temp_board[y,column] == 0:\n                best_move = y\n        temp_board[best_move, column] = piece\n        \n        return temp_board\n\ndef calculate_pontuation(piece, my_piece, good_score, bad_score):\n    return good_score if piece == my_piece else bad_score\n    \ndef greedy_score(board, column, my_piece):\n    score = 0\n    good_score_2x = 61\n    good_score_1x = 29\n    bad_score_2x = 33\n    bad_score_1x = 17\n    for row in range(board.shape[0]):\n        if (column + 3) < board.shape[1] and board[row,column] != 0:\n            if board[row,column] == board[row,column + 1] and \\\n               board[row,column + 1] == board[row,column + 2]:\n                score += calculate_pontuation(board[row,column + 2], my_piece, good_score_2x, bad_score_2x)\n            elif board[row,column] == board[row,column + 1]:\n                score += calculate_pontuation(board[row,column], my_piece, good_score_1x, bad_score_1x)\n\n        if (row + 3) < board.shape[0] and board[row,column] != 0:\n            if board[row,column] == board[row + 1,column] and \\\n               board[row + 1,column] == board[row + 2,column]:\n                score += calculate_pontuation(board[row + 2,column], my_piece, good_score_2x, bad_score_2x)\n            elif board[row,column] == board[row + 1,column]:\n                score += calculate_pontuation(board[row,column], my_piece, good_score_1x, bad_score_1x)\n\n        if (column + 3) < board.shape[1] and (row + 3) < board.shape[0] and board[row,column] != 0:\n            if board[row,column] == board[row + 1,column + 1] and \\\n               board[row + 1,column + 1] == board[row + 2,column + 2]:\n                score += calculate_pontuation(board[row + 2,column + 2], my_piece, good_score_2x, bad_score_2x)\n            elif board[row,column] == board[row + 1,column + 1]:\n                score += calculate_pontuation(board[row,column], my_piece, good_score_1x, bad_score_1x)\n\n        if (column + 3) < board.shape[1] and (row + 3) < board.shape[0] and board[row + 3,column] != 0:\n            if board[row + 3,column] == board[row + 2,column + 1] and \\\n               board[row + 2,column + 1] == board[row + 1,column + 2]:\n                score += calculate_pontuation(board[row + 1,column + 2], my_piece, good_score_2x, bad_score_2x)\n            elif board[row + 3,column] == board[row + 2,column + 1]:\n                score += calculate_pontuation(board[row,column], my_piece, good_score_1x, bad_score_1x)\n\n    return score\n\ndef drop_on_column(current_board, original_board):\n    current_board = current_board.flatten()\n    original_board = original_board.flatten()\n\n    for index in range(len(current_board)):\n        if current_board[index] != original_board[index]:\n            return index//7\n\ndef pick_best_move(board, valid_locations, my_piece, opp_piece):\n    best_score = -10000\n    best_locations = [valid_locations[0]]\n    save_opp_best = []\n    save_my_best = []\n    for location in valid_locations:\n        my_win_board = drop_piece(board, location, my_piece)\n        opp_win_board = drop_piece(board, location, opp_piece)\n        if check_winner_piece(my_win_board, my_piece):\n            boards = [my_win_board]\n            save_my_best.append(location)\n\n        elif check_winner_piece(opp_win_board, opp_piece):\n            boards = [opp_win_board]\n            save_opp_best.append(location)\n\n        else:\n            # calcula melhor escolha - guloso\n            current_score = greedy_score(board, location, my_piece)\n\n            if current_score > best_score:\n                best_score = current_score\n                best_locations = [location]\n    \n            elif current_score == best_score:\n                best_locations.append(location)\n\n    if len(save_my_best) != 0:\n        return random.choice(save_my_best)\n    elif len(save_opp_best) != 0:\n        return random.choice(save_opp_best)\n\n    return random.choice(best_locations)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sua vez\n## **Creating my agent**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def connectFour_agent(obs, cfg):\n    board = np.reshape(obs[\"board\"],(6,7))\n    #print(\"board: \", board)\n    valid_locations = [column for column in range(cfg.columns) if obs.board[column] == 0] # todo valor igual a zero\n    my_piece = obs[\"mark\"]\n    opp_piece = 2\n    if my_piece == 2:\n        opp_piece = 1\n\n    return pick_best_move(board, valid_locations, my_piece, opp_piece) \n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# \"None\" represents which agent you'll manually play as (first or second player).\nenv.play([None, connectFour_agent], width=500, height=450) #Altere \"rules\" por my_agent para jogar contra o seu agente","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sua vez\n## **TESTING/DEBUG - My agent(connect4_agent)**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"env.reset()\n# env.run([connectFour_agent, \"random\"]) #Agente definido em connectFour_agent versus angente randômico.\n# env.run([connectFour_agent, connectFour_agent]) #Agente definido em connectFour_agent versus connectFour_agent.\n# env.run([connectFour_agent, \"negamax\"]) #Agente definido em connectFour_agent versus angente negamax.\nenv.run([connectFour_agent, \"rules\"]) #Agente definido em connectFour_agent versus angente rules.\n# env.run([connectFour_agent, \"greedy\"]) #Agente definido em connectFour_agent versus angente greedy.\nenv.render(mode=\"ipython\", width=500, height=450)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sua vez\n## **Training my agent**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Play as first position against random agent.\ntrainer = env.train([None, \"random\"])\n\nobservation = trainer.reset()\n\nwhile not env.done:\n    my_action = connectFour_agent(observation, env.configuration)\n    print(\"Ação do seu agente: Coluna\", my_action+1)\n    observation, reward, done, info = trainer.step(my_action)\n    env.render(mode=\"ipython\", width=100, height=90, header=False, controls=False)\nenv.render()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Avalie o seu Agente\n\nA submissão na competição do kaggle será o resultado do seu agente contra 4 agentes previamente definidos.\nPode utilizar ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def mean_win_draw(rewards):\n    return sum( 1 for r in rewards if (r[0] == 1 or r[0] == 0.)) / len(rewards)\n\n# Run multiple episodes to estimate its performance.\nvs_random = mean_win_draw(evaluate(\"connectx\", [connectFour_agent, \"random\"], num_episodes=10))\nprint(\"My Agent vs Random Agent:\", vs_random)\n\nvs_negamax = mean_win_draw(evaluate(\"connectx\", [connectFour_agent, \"negamax\"], num_episodes=10))\nprint(\"My Agent vs Negamax Agent:\", vs_negamax)\n\nvs_rules = mean_win_draw(evaluate(\"connectx\", [connectFour_agent, \"rules\"], num_episodes=10))\nprint(\"My Agent vs Rule Agent:\", vs_rules)\n\nvs_greedy = mean_win_draw(evaluate(\"connectx\", [connectFour_agent, \"greedy\"], num_episodes=10))\nprint(\"My Agent vs Greedy Agent:\", vs_greedy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submissão para O Connect-X Virtus Up","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\n\nseu_nome = \"Mailson Nascimento Costa\"\n\nrows = [['Id', 'Predicted'],['random',vs_random],[ 'negamax', vs_negamax],[ 'rules', vs_rules],[ 'greedy', vs_greedy]]\nf = open(seu_nome+'-ConnectX.csv', 'w')\nwith f:\n    writer = csv.writer(f)\n    for row in rows:\n        writer.writerow(row)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Em Data/output você pode baixar o .csv com o seu resultado atual. Isso está acessível no painel lateral ou após realizar um commit no kernel. \n2. Submeta o csv na página da competição.\n\nNo fim da competição os monitores vão fazer um campeonato com todos os agentes.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Submissão Connect-X Original\n\nComo gerar um arquivo .py do seu agente.\n\nVamos pedir o arquivo do notebook (.ipynb) ou o arquivo python (.py) em um formulário.\n\nCaso queira competir na competição  original.\n\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import inspect\nimport os\n\ndef write_agent_to_file(function, file):\n    with open(file, \"a\" if os.path.exists(file) else \"w\") as f:\n        f.write(inspect.getsource(function))\n        print(function, \"written to\", file)\n\nwrite_agent_to_file(my_agent, \"submission.py\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Validar Submissão para Connect-X Original\nPlay your submission against itself.  This is the first episode the competition will run to weed out erroneous agents.\n\nWhy validate? This roughly verifies that your submission is fully encapsulated and can be run remotely.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Note: Stdout replacement is a temporary workaround.\nimport sys\nout = sys.stdout\nsubmission = utils.read_file(\"/kaggle/working/submission.py\")\nagent = utils.get_last_callable(submission)\nsys.stdout = out\n\nenv = make(\"connectx\", debug=True)\nenv.run([agent, agent])\nprint(\"Success!\" if env.state[0].status == env.state[1].status == \"DONE\" else \"Failed...\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submissão para Connect-X Original\n\n1. Commit this kernel.\n2. View the commited version.\n3. Go to \"Data\" section and find submission.py file.\n4. Click \"Submit to Competition\"\n5. Go to [My Submissions](https://kaggle.com/c/connectx/submissions) to view your score and episodes being played.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}