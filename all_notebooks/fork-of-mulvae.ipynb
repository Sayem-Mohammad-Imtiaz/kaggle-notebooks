{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nimport torch\nfrom torch import nn\nfrom torch.utils.data import TensorDataset\nfrom torch.utils.data import DataLoader\nimport numpy as np\nimport  pandas as pd\nimport os\nfrom scipy import sparse\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom tqdm import tqdm_notebook as tqdm\n\nimport seaborn as sn\nsn.set()\n\nimport sys\nimport warnings; \nwarnings.simplefilter('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-23T07:41:27.418453Z","iopub.execute_input":"2021-06-23T07:41:27.41881Z","iopub.status.idle":"2021-06-23T07:41:29.420678Z","shell.execute_reply.started":"2021-06-23T07:41:27.418773Z","shell.execute_reply":"2021-06-23T07:41:29.419878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATA_DIR ='../input/millionsong'\n# path = 'msd-VAE_nobeta.pt'\n# metrics_path = 'metrics_msd_VAE_nobeta.csv'","metadata":{"execution":{"iopub.status.busy":"2021-06-23T07:41:27.407574Z","iopub.execute_input":"2021-06-23T07:41:27.407941Z","iopub.status.idle":"2021-06-23T07:41:27.416898Z","shell.execute_reply.started":"2021-06-23T07:41:27.407855Z","shell.execute_reply":"2021-06-23T07:41:27.415981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = '../input/ml-20m'\n\npath = 'ml20m-VAE_beta02.pt'\n\nmetrics_path = 'metrics_MovieLens_VAE_beta02.csv'","metadata":{"execution":{"iopub.status.busy":"2021-06-23T02:26:05.334237Z","iopub.execute_input":"2021-06-23T02:26:05.334544Z","iopub.status.idle":"2021-06-23T02:26:05.339482Z","shell.execute_reply.started":"2021-06-23T02:26:05.33451Z","shell.execute_reply":"2021-06-23T02:26:05.337804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(DATA_DIR + '/train.csv')\nval_data = pd.read_csv(DATA_DIR + '/val.csv')\ntest_data = pd.read_csv(DATA_DIR + '/test.csv')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-23T07:41:35.967171Z","iopub.execute_input":"2021-06-23T07:41:35.9675Z","iopub.status.idle":"2021-06-23T07:42:24.21977Z","shell.execute_reply.started":"2021-06-23T07:41:35.967468Z","shell.execute_reply":"2021-06-23T07:42:24.21885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nItems = train_data.sid.nunique()\nnItems","metadata":{"execution":{"iopub.status.busy":"2021-06-23T07:42:24.221262Z","iopub.execute_input":"2021-06-23T07:42:24.221617Z","iopub.status.idle":"2021-06-23T07:42:24.419422Z","shell.execute_reply.started":"2021-06-23T07:42:24.221565Z","shell.execute_reply":"2021-06-23T07:42:24.41848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = sparse.csr_matrix((np.ones_like(train_data.uid), (train_data.uid.values, train_data.sid.values)), \n                             dtype='float64',\n                             shape=(train_data.uid.nunique(),nItems))\n\n\nval_data = sparse.csr_matrix((np.ones_like(val_data.uid), (val_data.uid.values, val_data.sid.values)), \n                             dtype='float64',\n                             shape=(val_data.uid.nunique(), nItems))\n\ntest_data = sparse.csr_matrix((np.ones_like(test_data.uid), (test_data.uid.values, test_data.sid.values)), \n                             dtype='float64',\n                             shape=(test_data.uid.nunique(), nItems))","metadata":{"execution":{"iopub.status.busy":"2021-06-23T07:42:24.421218Z","iopub.execute_input":"2021-06-23T07:42:24.421575Z","iopub.status.idle":"2021-06-23T07:42:26.677438Z","shell.execute_reply.started":"2021-06-23T07:42:24.421539Z","shell.execute_reply":"2021-06-23T07:42:26.676446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class netflixDataset(torch.utils.data.Dataset):\n    def __init__(self, scr_matrix, eval = False,prop=0.2):\n        self.scr_matrix = scr_matrix\n        self.eval = eval\n        self.prop = prop\n      \n          \n    def __getitem__(self, idx):\n      \n      item = {}\n        \n      \n\n      if self.eval:\n        u_items = self.scr_matrix[idx,:].toarray()[0]\n        \n        nu_items = u_items.sum()       \n        val_size = int(nu_items*self.prop)\n        idx_labels = np.where(u_items == 1)[0]\n        data = np.ones_like(u_items)\n        \n        \n                \n        val_idx = np.random.choice(idx_labels, size=val_size, replace=False)                   \n        data[val_idx] = 0\n         \n        \n        \n        \n        item['data'] = torch.tensor(u_items*data,dtype=torch.float64)     \n        \n        item['ground_truth'] = torch.tensor(np.logical_not(data),dtype=torch.float64)             \n        \n        \n       \n      else:\n        item['data'] = torch.tensor(self.scr_matrix[idx,:].toarray(),dtype=torch.float64)\n      return item\n        \n\n    def __len__(self):\n        return self.scr_matrix.shape[0]","metadata":{"execution":{"iopub.status.busy":"2021-06-23T07:42:26.679131Z","iopub.execute_input":"2021-06-23T07:42:26.679481Z","iopub.status.idle":"2021-06-23T07:42:26.689264Z","shell.execute_reply.started":"2021-06-23T07:42:26.679445Z","shell.execute_reply":"2021-06-23T07:42:26.688164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VAE(nn.Module):\n    def __init__(self,n_Items, hidden=600, dimz= 200, p=0.5):\n        super(VAE, self).__init__()\n\n        self.n_Items = n_Items\n        self.dimz = dimz\n        self.hidden = hidden\n        self.p = p\n\n        self.inference = nn.Sequential(\n           \n            nn.Dropout(self.p),\n            nn.Linear(self.n_Items,self.hidden),\n            nn.Tanh(),\n            nn.Linear(self.hidden,2*self.dimz)          \n        )\n        self.generative = nn.Sequential(\n            nn.Linear(self.dimz,self.hidden),\n            nn.Tanh(),\n            nn.Linear(self.hidden,self.n_Items),\n            \n        )\n  \n        \n\n    def reparameterize(self, mu, logvar):\n        std = torch.exp(0.5*logvar)\n        eps = torch.randn_like(std)\n        \n        return mu + std*eps* ( 1 if self.Mode =='train' else 0)\n\n\n    def forward(self, x,Mode='train'):       \n        self.Mode = Mode\n        x = F.normalize(x, p=2, dim=1)  \n        distribution = self.inference(x)\n\n\n\n        mu, logvar = distribution[:, :self.dimz], distribution[:, self.dimz:]\n        z = self.reparameterize(mu, logvar)\n        logit = self.generative(z)\n\n        \n        return logit, mu, logvar","metadata":{"execution":{"iopub.status.busy":"2021-06-23T07:42:26.690872Z","iopub.execute_input":"2021-06-23T07:42:26.691236Z","iopub.status.idle":"2021-06-23T07:42:26.703646Z","shell.execute_reply.started":"2021-06-23T07:42:26.691199Z","shell.execute_reply":"2021-06-23T07:42:26.702787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loss_function(recon_x, x,mu,logvar,anneal):   \n    \n    CE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1))\n    KLD = -0.5 * torch.mean(torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1))\n   \n    return CE + anneal * KLD","metadata":{"execution":{"iopub.status.busy":"2021-06-23T07:42:26.705036Z","iopub.execute_input":"2021-06-23T07:42:26.705438Z","iopub.status.idle":"2021-06-23T07:42:26.71616Z","shell.execute_reply.started":"2021-06-23T07:42:26.705398Z","shell.execute_reply":"2021-06-23T07:42:26.71529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def NDCG_at_k(labels, scores, k = 100):\n    device = scores.device\n    arg_sort_scores = torch.argsort(scores,1,descending=True)\n    arg_sort_labels = torch.argsort(labels,1,descending=True)\n\n\n    pred_labels = torch.gather(labels,1,arg_sort_scores[:,:k]).to(device)\n\n\n    tp = (1. /torch.log(torch.arange(2,2+k).float())).to(device)\n\n\n    dcg = (tp * pred_labels).sum(axis = 1)\n\n    idcg = torch.Tensor([tp[:min(int(n),k)].sum() for n in labels.sum(1)]).to(device)\n\n    ndcg = (dcg/idcg).mean()\n\n    return ndcg","metadata":{"execution":{"iopub.status.busy":"2021-06-23T07:42:26.717271Z","iopub.execute_input":"2021-06-23T07:42:26.717729Z","iopub.status.idle":"2021-06-23T07:42:26.727142Z","shell.execute_reply.started":"2021-06-23T07:42:26.717689Z","shell.execute_reply":"2021-06-23T07:42:26.726283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Recall_at_k(labels, scores, k = 20):\n    device = scores.device\n    arg_sort_scores = torch.argsort(scores,1,descending=True)\n    arg_sort_labels = torch.argsort(labels,1,descending=True)\n\n    pred_labels = torch.gather(labels,1,arg_sort_scores[:,:k]).to(device)\n\n#     denominator = torch.Tensor([min(M, k) for M in labels.sum(1)]).to(device)\n    denominator = labels.sum(1)\n    denominator[denominator > k] = k\n\n    return (pred_labels.sum(1) / denominator).mean()","metadata":{"execution":{"iopub.status.busy":"2021-06-23T07:42:26.729171Z","iopub.execute_input":"2021-06-23T07:42:26.729519Z","iopub.status.idle":"2021-06-23T07:42:26.736546Z","shell.execute_reply.started":"2021-06-23T07:42:26.729484Z","shell.execute_reply":"2021-06-23T07:42:26.735866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Declare Model\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel = VAE(nItems).to(device)\nn_Epochs = 200\n\n\n# prepare Data\ntrain_ds = netflixDataset(train_data)\ntrain_dl = DataLoader(train_ds, batch_size=512)\n\nval_ds = netflixDataset(val_data,eval=True)\nval_dl = DataLoader(val_ds, batch_size=1024)\n\n\noptimizer = optim.AdamW(model.parameters(), lr=1e-3,weight_decay=0.01)","metadata":{"execution":{"iopub.status.busy":"2021-06-23T07:56:32.555634Z","iopub.execute_input":"2021-06-23T07:56:32.555952Z","iopub.status.idle":"2021-06-23T07:56:32.896716Z","shell.execute_reply.started":"2021-06-23T07:56:32.555923Z","shell.execute_reply":"2021-06-23T07:56:32.895902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# total_loss = []\n# total_ndcgs = []\n# total_recalls = []\ncur_metric = -np.inf","metadata":{"execution":{"iopub.status.busy":"2021-06-23T07:42:38.825234Z","iopub.execute_input":"2021-06-23T07:42:38.825606Z","iopub.status.idle":"2021-06-23T07:42:38.831206Z","shell.execute_reply.started":"2021-06-23T07:42:38.82555Z","shell.execute_reply":"2021-06-23T07:42:38.830252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, val_loader, record = True, ndcg_k = [100], recall_k = [20,50]):\n    '''Evaluate model at Recall and NDCG metrics'''\n    metrics = {}\n    for k in ndcg_k:\n        metrics[f'ndcg@{k}'] = []\n    for k in recall_k:\n        metrics[f'recall@{k}'] = []\n    for data in val_loader:\n        X = data['data'].float().to(device)  \n        X = X.squeeze(1)\n\n\n        ground_truth = torch.stack([data['ground_truth'][i,:] for i in range(X.shape[0])])\\\n                      .squeeze(1).to(device)\n\n        pred,_,_ = model(X,Mode ='eval')\n\n        pred = pred.detach()\n\n\n        pred[X!=0] = -np.inf\n        for k in ndcg_k:\n            ndcg = NDCG_at_k(ground_truth,pred, k)\n            metrics[f'ndcg@{k}'] = ndcg.item()\n        for k in recall_k:\n            recall = Recall_at_k(ground_truth,pred, k)\n            metrics[f'recall@{k}'] = recall.item()\n\n    for k in ndcg_k:\n        metrics[f'ndcg@{k}'] = np.mean(metrics[f'ndcg@{k}'])\n    for k in recall_k:\n        metrics[f'recall@{k}'] = np.mean(metrics[f'recall@{k}'])\n    return metrics","metadata":{"execution":{"iopub.status.busy":"2021-06-23T07:42:43.147028Z","iopub.execute_input":"2021-06-23T07:42:43.147396Z","iopub.status.idle":"2021-06-23T07:42:43.158801Z","shell.execute_reply.started":"2021-06-23T07:42:43.147363Z","shell.execute_reply":"2021-06-23T07:42:43.157691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"par = tqdm(range(n_Epochs),total = n_Epochs)\nfor epoch in par:\n    train_loss =  []\n    # train phase\n    model.train()\n    #train_par = tqdm(train_dl,total =len(train_dl))\n    for data in train_dl:\n        x = data['data'].float().to(device)\n        x = x.squeeze(1)\n        optimizer.zero_grad()  \n\n\n        recon_x,mu,logvar = model(x)   \n        loss = loss_function(recon_x, x,mu,logvar,0.2)          \n        loss.backward()\n        optimizer.step()\n        train_loss.append(loss.item())\n\n    # Eval phases\n    model.eval()\n    metrics = evaluate(model, val_dl)\n    metrics['loss'] = np.mean(train_loss)\n\n    ndcg = list(metrics.values())[0]\n    if ndcg > cur_metric:\n        cur_metric = ndcg\n        torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n#                 'loss': metrics['loss'],\n                'evaluate': metrics                    \n                }, path)\n   \n    with open(metrics_path, 'a') as f:\n        # write metrics to file\n        s = ['{:.4f}'.format(v) for v in metrics.values()]\n        f.write(','.join(s) + '\\n')","metadata":{"execution":{"iopub.status.busy":"2021-06-23T07:47:31.803446Z","iopub.execute_input":"2021-06-23T07:47:31.803818Z","iopub.status.idle":"2021-06-23T07:56:26.602833Z","shell.execute_reply.started":"2021-06-23T07:47:31.803784Z","shell.execute_reply":"2021-06-23T07:56:26.600767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(metrics_path, header = None, names = metrics.keys(),index_col = False)\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 3))\nplt.plot(df['loss'])\nplt.ylabel(\"loss\")\nplt.xlabel(\"Epochs\")\npass","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 3))\nplt.plot(df['ndcg@100'],)\nplt.ylabel(\"ndcg@100\")\nplt.xlabel(\"Epochs\")\npass","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 3))\nplt.plot(df['recall@20'])\nplt.ylabel(\"recall@20\")\nplt.xlabel(\"Epochs\")\npass","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 3))\nplt.plot(df['recall@50'])\nplt.ylabel(\"recall@50\")\nplt.xlabel(\"Epochs\")\npass","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}