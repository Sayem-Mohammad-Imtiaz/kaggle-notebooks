{"cells":[{"metadata":{},"cell_type":"markdown","source":"Identify the snake breed\nhttps://www.hackerearth.com/challenges/competitive/hackerearth-deep-learning-challenge-snake-breed-detection/machine-learning/identify-the-snake-breed-5-66d9a9f5/\n\nThis is a challenge from HackerEarth.com, and one of the participant from HE has uploaded the dataset on Kaggle. Refer below details on the challenge.\n\n# Problem statement\nThe government has been facing a long-standing issue of wild animals entering residential areas due to various reasons. It's of critical importance that if any such dangerous animal is encountered, the concerned authority should be notified immediately. Reptiles, especially snakes, are among the most dangerous animals and they often enter residential areas.\n\nRecently due to an incident of a youngster getting bitten by a snake, the government decided to install cameras at every corner of the road to detect snakes and other animals.\n\nYou have been hired as a Deep Learning engineer to create a sophisticated model that can detect the breed of a snake from its image."},{"metadata":{},"cell_type":"markdown","source":"# Import Library"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport random, os\n\nimport matplotlib.pyplot as plt \n%matplotlib inline\n\nfrom keras.applications.resnet50 import preprocess_input\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.applications import imagenet_utils\n\nfrom keras.callbacks import EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train Images"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_dir = '../input/hackerearth-deep-learning-identify-the-snake-breed/dataset'\ntrain_dir = os.path.join(base_dir, 'train')\nfiles = os.listdir(train_dir)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Target Information from csv file"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(os.path.join(base_dir, 'train.csv'))\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_file_df = pd.DataFrame({'image_id':list(map(lambda x:x.replace('.jpg', ''), files))})\n# train_file_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Mapping File with Breed."},{"metadata":{"trusted":true},"cell_type":"code","source":"# label_info = pd.merge(left = train_file_df, right = train_df)\n# label_info.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Convert Target to One-Hot Encoding."},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = len(train_df.breed.unique())\nnum_classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom keras.utils import np_utils","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\nbreed = le.fit_transform(train_df.breed)\ny = np_utils.to_categorical(breed, num_classes = num_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Convert Images to numpy array"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_dim = (224, 224)\n\nX = np.zeros((y.shape[0], *input_dim, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, img in enumerate(files):\n    image = load_img(os.path.join(train_dir, img), target_size = input_dim)\n    image = img_to_array(image)\n    image = image.reshape((1, *image.shape))\n    image = preprocess_input(image)\n    X[i] = image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Callbacks"},{"metadata":{"trusted":true},"cell_type":"code","source":"earlystop = EarlyStopping(\n    monitor = 'val_loss',\n    min_delta = 0,\n    patience = 2,\n    verbose = 0,\n    mode = 'auto'\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.vgg19 import VGG19\nfrom keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D, Flatten, Dropout","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg_model = VGG19(\n    weights = 'imagenet',\n    include_top = False\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg_x = vgg_model.output\nvgg_x = GlobalAveragePooling2D()(vgg_x)\nvgg_x = Dropout(0.2)(vgg_x)\nout = Dense(num_classes, activation = 'softmax')(vgg_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Model(inputs = vgg_model.input, outputs = out)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in vgg_model.layers:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import Adam\nopt = Adam()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n    optimizer=opt,\n    loss = 'categorical_crossentropy',\n    metrics = ['accuracy']\n)\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist = model.fit(\n    X,\n    y,\n    batch_size = 256,\n    epochs = 20,\n    validation_split = 0.2, \n    verbose = 2,\n    callbacks = [earlystop]\n)\n# model.save('snake_vgg_model1.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist.history.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_acc = hist.history.get('val_accuracy')\nacc = hist.history.get('accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"overfit_info = pd.DataFrame({'acc':acc, 'val_acc':val_acc})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"overfit_info.plot.line()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict \nImage ID : 8b492b973d\t\n\nBreed : pantherophis-vulpinus\n   "},{"metadata":{"trusted":true},"cell_type":"code","source":"image_path = os.path.join(train_dir,'8b492b973d'+'.jpg')\nimage_path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = plt.imread(image_path)\nplt.imshow(img)\nplt.title('Original Bree --> pantherophis-vulpinus')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_for_prediction = load_img(image_path, target_size = input_dim)\nimg_for_prediction = img_to_array(img_for_prediction)\nimg_for_prediction = img_for_prediction.reshape((1, *img_for_prediction.shape))\nimg_for_prediction = preprocess_input(img_for_prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(img_for_prediction)\npred = np.argsort(predictions)[0][-5:]\npred \n# the Order is from 0 to 5 and 5th Position breed is highest.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le.inverse_transform(pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model has predicted \"thamnophis-sirtalis\" with highest probability."},{"metadata":{},"cell_type":"markdown","source":"# More layers to train"},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg_x = vgg_model.output\nvgg_x = GlobalAveragePooling2D()(vgg_x)\nvgg_x = Dropout(0.3)(vgg_x)  # Change 1 : Increase the drop out\nout = Dense(num_classes, activation = 'softmax')(vgg_x)\n\nmodel2 = Model(inputs = vgg_model.input, outputs = out)\n\nfor layer in vgg_model.layers[:-2]:  # Change 2 : Skip training for last 2 layers\n    layer.trainable = False\n\nfor layer in vgg_model.layers[-2:]:  # Change 3 : training last 2 layers\n    layer.trainable = True\n\nmodel2.compile(\n    optimizer=opt,\n    loss = 'categorical_crossentropy',\n    metrics = ['accuracy']\n)\n\nmodel2.summary()\n\nhist2 = model2.fit(\n    X,\n    y,\n    batch_size = 256,\n    epochs = 20,\n    validation_split = 0.2, \n    verbose = 2,\n    callbacks = [earlystop]\n)\n\n# model2.save('snake_vgg_model2.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model2.predict(img_for_prediction)\npred = np.argsort(predictions)[0][-5:]\n\nle.inverse_transform(pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# With Image Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import load_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True\n)\n\ndatagen.fit(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using the reference to the model created at very first.\nhist_aug = model.fit_generator(\n    datagen.flow(X, y, batch_size = 256),\n    steps_per_epocs = len(X)/32,\n    epochs = 20,\n    verbose = 2\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_aug.history.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_aug.save('model_img_augement.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model3 = load_model('model_img_augement.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model3.predict(img_for_prediction)\npred = np.argsort(predictions)[0][-5:]\n\nle.inverse_transform(pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Augement with more layers."},{"metadata":{"trusted":true},"cell_type":"code","source":"# using the reference to the model created at very first.\nhist2_aug = model2.fit_generator(\n    datagen.flow(X, y, batch_size = 256),\n    steps_per_epocs = len(X)/32,\n    epochs = 20,\n    verbose = 2\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist2_aug.save('model2_img_augement.h5')\n\nmodel4 = load_model('model2_img_augement.h5')\n\npredictions = model3.predict(img_for_prediction)\npred = np.argsort(predictions)[0][-5:]\n\nle.inverse_transform(pred)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}