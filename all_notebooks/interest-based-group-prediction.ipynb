{"cells":[{"metadata":{},"cell_type":"raw","source":"Hello, I want to share my humble work regarding this dataset. I tried to make ML models to predict the groups based on the interests. Here you can see the performance difference between the ML algorithms (decision tree, random forest, KNN, ANN)."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/clustering-categorical-peoples-interests/kaggle_Interests_group.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()\nsns.countplot(x='group',data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#see the distinct values per column\nfor col in df:\n    print(df[col].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#see the columns that real missing value, since the dataset also use NaN to indicate the value equal to zero\nfor col in df:\n    if df[col].nunique()>1:\n        print(col)\n    else:\n        pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fill the NaN value with zero, only for columns use NaN to indicate the value equal to zero\na=[]\nfor col in df:\n    if df[col].nunique()==1:\n        a.append(col)\n    else:\n        pass\ndf[a] = df[a].fillna(0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop the columns with the number of missing value >10% of total data\nthreshold=0.1*6340\n\nb=[]\nfor col in df:\n    if df[col].isnull().sum()>threshold:\n        b.append(col)\n    else:\n        pass\ndf=df.drop(b,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop the rows with the number of missing value from columns with the number of missing value <10% of total data\nc=[]\nfor col in df:\n    if (df[col].isnull().sum()<threshold) & (df[col].isnull().sum()>0):\n        c.append(col)\n    else:\n        pass\ndf = df.dropna(subset=c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in df:\n    print(df[col].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['group'] = df['group'].map({'C':0,'P':1,'R':2,'I':3})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df #cleaned dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=df.drop('group',axis=1).values \ny=df['group'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(x_train)\nx_train = scaler.transform(x_train)\nx_test = scaler.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"**Decision Tree**"},{"metadata":{"trusted":true},"cell_type":"code","source":"scores=[]\nfor i in range(1,50):\n  tree=DecisionTreeClassifier(max_depth = i) \n  tree.fit(x_train, y_train) \n  scores.append(tree.score(x_test,y_test)) \nplt.plot(range(1,50),scores) \nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree=DecisionTreeClassifier(max_depth =5) \ntree.fit(x_train, y_train) \ntree.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = tree.predict(x_test) \nfrom sklearn.metrics import classification_report,confusion_matrix \nprint(classification_report(y_test,predictions)) \nprint(confusion_matrix(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Random Forest**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n\nscores=[]\nfor i in (np.arange(100,2000,100)):\n  classifier = RandomForestClassifier(n_estimators =i, max_depth=10, random_state =101) \n  classifier.fit(x_train, y_train) \n  scores.append(classifier.score(x_test,y_test)) \nplt.plot(np.arange(100,2000,100),scores) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = RandomForestClassifier(n_estimators =700,max_depth=10, random_state =101)\nclassifier.fit(x_train, y_train)\nprint(classifier.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = classifier.predict(x_test) \nfrom sklearn.metrics import classification_report,confusion_matrix \nprint(classification_report(y_test,predictions)) \nprint(confusion_matrix(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**KNN**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\naccuracies=[]\nfor k in range(1,101):\n  classifier = KNeighborsClassifier(n_neighbors = k)\n  classifier.fit(x_train, y_train)\n  accuracies.append(classifier.score(x_test, y_test)) \n  \nk_list=list(range(1,101)) \n\nplt.plot(k_list,accuracies)\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = KNeighborsClassifier(n_neighbors =54)\nclassifier.fit(x_train, y_train)\nclassifier.score(x_test, y_test) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = classifier.predict(x_test) \nfrom sklearn.metrics import classification_report,confusion_matrix \nprint(classification_report(y_test,predictions)) \nprint(confusion_matrix(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ANN**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\ny_cat_train = to_categorical(y_train) \ny_cat_test = to_categorical(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation\nfrom tensorflow.keras.callbacks import EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Dropout\nmodel = Sequential()\nmodel.add(Dense(units=160,activation='relu',kernel_regularizer=tf.keras.regularizers.l1_l2(0.01)))\n\nmodel.add(Dense(units=4,activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n\nmodel.fit(x_train,y_cat_train,epochs=300,validation_data=(x_test,y_cat_test),verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.metrics_names)\nprint(model.evaluate(x_test,y_cat_test,verbose=0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"losses = pd.DataFrame(model.history.history)\nlosses[['accuracy','val_accuracy']].plot()\nlosses[['loss','val_loss']].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix\n\npredictions = model.predict_classes(x_test)\nprint(classification_report(y_test,predictions))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}