{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Time Series Analysis of Stock Prices Using Auto Arima\nThis Notebook analyses the Closing Stock Prices of Yes Bank Limited right from the time it got listed (July 2005) until very recent of this month (November 2020). Using the monthly prices of stocks, Time Series Analysis is used to predict the future prices based on trend and seasonal components. \nAuto ARIMA is demonstrated in Python and its working is explained in detail."},{"metadata":{},"cell_type":"markdown","source":"### Importing Necessary Libraries "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n%matplotlib inline\n\n# Load specific forecasting tools\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX, SARIMAXResults\nfrom statsmodels.tsa.arima_model import ARMA,ARMAResults,ARIMA,ARIMAResults\n\nfrom statsmodels.graphics.tsaplots import plot_acf,plot_pacf # for determining (p,q) orders\nfrom statsmodels.tsa.seasonal import seasonal_decompose      # for ETS Plots\n                          # for determining ARIMA orders\n\n# Ignore harmless warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Installing the pmdarima package in order to use autoarima"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pmdarima","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pmdarima import auto_arima","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading Data\nThe Data has Opening, Highest, Lowest and the Closing Prices of the Stock in every month. For this analysis, only Closing Stock Prices have been considered. "},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/yes-bank-stock-prices/YesBank_StockPrices.csv\", usecols=[\"Date\", \"Close\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preparing the Time Series and Basic EDA\nTo be able to apply ARIMA to a data, the date column needs to be converted into a date time object and then made the index of the dataframe. This is achieved by using strptime of the datetime library. The Given Date format MMM-YY is converted to proper date of YYYY-MM-DD, that Date is set as index and frequency of the Date is set to 'MS' which is monthly"},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\ndata['Date'] = data['Date'].apply(lambda x: datetime.strptime(x, '%b-%y'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = data.set_index('Date')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts.index.freq = 'MS'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Once the Time Series Data is prepared, Data is plotted to see if there is a recurring pattern. While no pattern is observed directly, on further decomposing the series, it can be observed that there is a distinct seasonality and trend hidden along with the variations. This explains that ARIMA might be a good way for predictions.\n\nAnother thing that should be kept in mind is that up until 2018, the stock prices more or less, kept increasing but there was a sudden dip after that. This can be attributed to the Yes bank fraud case against Rana Kapoor. Read more about that here: https://economictimes.indiatimes.com/topic/yes-bank-scam"},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting the data\n\nax = ts['Close'].plot(figsize=(12,6))\nax.autoscale(axis='x',tight=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#TS Decomposition\nresult = seasonal_decompose(ts['Close'], model='add')\nresult.plot();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Preparation for (S)ARIMA\nNow that the dataframe is ready, we divide it into train and test for modeling and testing. For this example, The last two years, Jan 2019- Nov 2020, are taken as test, Rest everything is train"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(ts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set two years for testing\ntrain = ts.iloc[:162]\ntest = ts.iloc[162:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Applying Auto ARIMA\nJust to give a brief about how Auto ARIMA works. Auto ARIMA is like a grid search for time series models, it tries ARIMA, SARIMA, SARIMAX, all ARIMA related models depending on the parameters that are supplied to it.  The auto_arima function seeks to identify the most optimal parameters for an ARIMA model, and returns a fitted ARIMA model. This function is based on the commonly-used R function, forecast::auto.arima \n\nThe auto_arima function works by conducting differencing tests (i.e., Kwiatkowski–Phillips–Schmidt–Shin, Augmented Dickey-Fuller or Phillips–Perron) to determine the order of differencing, d, and then fitting models within ranges of defined start_p, max_p, start_q, max_q ranges. If the seasonal optional is enabled, auto_arima also seeks to identify the optimal P and Q hyper- parameters after conducting the Canova-Hansen to determine the optimal order of seasonal differencing, D.\n\nHere's the link to its documentation and User Guide, if you want to know about it in detail: https://alkaline-ml.com/pmdarima/0.9.0/modules/generated/pyramid.arima.auto_arima.html\n\nThe main idea is that you don't really need to worry about differencing orders and keep trying different orders or look at ACF charts to come to the correct fitted parameters, Auto ARIMA would do that for you automatically.\n\nHere, the parameters which are supplied are:\nm= 12 indicatinng monthly range of Date\n\nseasonal True, which we saw from the decomposed chart\n\nand max iterations is set to 200 so that it analyses as many possible combinations of parameters before sticking to a local minima. Usually 200 works, However, higher the better, though that may take longer time. \n\nBasic steps to use Auto ARIMA include:\n1. Using the Auto_Arima funtion on the series to obtain Model Parameters  (p,d,q) (P, D, Q, m)\n2. Using the parameters obtained, running a model through statsmodels ARIMA/SARIMA on your training set\n3. Obtaining predicted values on the test set based on the model run in Step 2\n4. Comparing and Plotting predictions to expected values\n5. Evaluating the model through MSE OR MAE\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Applying the Auto ARIMA Function\nauto_arima(ts['Close'],m=12,seasonal = True,maxiter=200).summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#statsmodel function implementation\nmodel = SARIMAX(train['Close'],order=(1,1,1))\nresults = model.fit(maxiter=200)\nresults.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Obtain predicted values\nstart=len(train)\nend=len(train)+len(test)-1\npredictions = results.predict(start=start, end=end, dynamic=False, typ='levels', full_results = True).rename('SARIMA Predictions')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compare predictions to expected values\nfor i in range(len(predictions)):\n    print(f\"predicted={predictions[i]:<11.10}, expected={test['Close'][i]}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting Predictions and Original/Expected Values\nax = test['Close'].plot(legend=True,figsize=(6,6))\npredictions.plot(legend=True)\nax.autoscale(axis='x',tight=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calcalutaing MSE\nfrom sklearn.metrics import mean_squared_error\n\nerror = mean_squared_error(test['Close'], predictions)\nprint(f'SARIMA MSE Error: {error:11.10}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculating RMSE\nfrom statsmodels.tools.eval_measures import rmse\n\nerror = rmse(test['Close'], predictions)\nprint(f'SARIMA RMSE Error: {error:11.10}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Making Future Predictions of next year that is 2021\nmodel = SARIMAX(ts['Close'],order=(1,1,1))\nresults = model.fit(maxiter=200)\nfcast = results.predict(len(ts),len(ts)+11,typ='levels').rename('SARIMA Forecast')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting Future Predictions with Old values\nax = ts['Close'].plot(legend=True,figsize=(12,6))\nfcast.plot(legend=True)\nax.autoscale(axis='x',tight=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Insights and Discussion\nAs can be seen through the expected and predicted values, initial few are correct but ARIMA is unable to predict the Dip that happened because of the fraud. The MSE was extremely high and not acceptable for prediction models. However, This is fair as it is quite unlikely to be able to predict such a huge dip without having any other parameters in the model such as market reputation. With the trend that the model saw, the model obviously followed that trend pattern and showed prices above or around the last highest price that was observed. Seasonality was kept in place, however that cannot really make any model estimate a Dip without additional information.\n\nTo check if Auto ARIMA works well if the data isnt influenced by Frauds or such sudden dips, data from 2018-2020 was neglected for trial. data for 2017 was then considered to be test and the remaining data before that was considered to be train, the model and the results that were obtained as follows:"},{"metadata":{},"cell_type":"markdown","source":"### Model for 2017 as Test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"ts2017 = ts.iloc[:150]\ntrain2017 = ts.iloc[:138]\ntest2017 = ts.iloc[138:150]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting the data\n\nax = ts2017['Close'].plot(figsize=(12,6))\nax.autoscale(axis='x',tight=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test2017","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Applying the Auto ARIMA Function\nauto_arima(ts2017['Close'],m=12,seasonal = True,maxiter=200).summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#statsmodel function implementation\nmodel2017 = SARIMAX(train2017['Close'],order=(0,1,0))\nresults2017 = model2017.fit(maxiter=200)\nresults2017.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Obtain predicted values\nstart2017=len(train2017)\nend2017=len(train2017)+len(test2017)-1\npredictions2017 = results2017.predict(start=start2017, end=end2017, dynamic=False, typ='levels', full_results = True).rename('SARIMA Predictions 2017')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compare predictions to expected values\nfor i in range(len(predictions2017)):\n    print(f\"predicted={predictions2017[i]:<11.10}, expected={test2017['Close'][i]}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting Predictions and Original/Expected Values\nax = test2017['Close'].plot(legend=True,figsize=(6,6))\npredictions2017.plot(legend=True)\nax.autoscale(axis='x',tight=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nerror = mean_squared_error(test2017['Close'], predictions2017)\nprint(f'SARIMA MSE Error: {error:11.10}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As can be seen by this Model, the 2017 model predictions are still very poor. Though MSE is much better than the one with all data, it is evident that even with infraudulent data, something is amiss. \n\nUpon searching online, I was introduced with the concept of **Stationarity**.\nTo be able to apply Models like ARIMA, a time series should always be stationary. \nTo know what Staionary time series means, read here: https://towardsdatascience.com/stationarity-in-time-series-analysis-90c94f27322\n\nDickey Fuller test is used to check stationarity of the data which was done next. "},{"metadata":{},"cell_type":"markdown","source":"### Checking Stationarity\nif test statistic < critical value in the Dickey Fuller Test, series is stationary, otherwise it is not\nIn this case, series came out to be non stationary"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller\ndef adf_test(timeseries):\n    #Perform Dickey-Fuller test:\n    print ('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n       dfoutput['Critical Value (%s)'%key] = value\n    print (dfoutput)\n\n\n#apply adf test on the series\nadf_test(ts2017['Close'])\n\n#if test statistic < critical value, series is stationary\n#series not stationary","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Detrending for Improved Model\nIn order to solve the problem of stationarity, after further searching stuff online\nThe method of de trending was identified appropriate.\nTo know more about detrending, read here: https://machinelearningmastery.com/time-series-trends-in-python/\n\nThe concept is basically removing the trend component from the series. Forecasting the trend component separately, seasonality + random component separately and then adding the two together to get the final results. \n\nThe Trend componenet is removed in the following cell and the remainder series is converted into a dataframe called detrended:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using statmodels: Subtracting the Trend Component.\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nres = seasonal_decompose(ts2017['Close'], extrapolate_trend='freq')\ndetrended = ts2017.Close.values - res.trend\nplt.plot(detrended)\nplt.title('Stock Prices detrended by subtracting the trend component', fontsize=16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detrended","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detrended =  pd.DataFrame(detrended)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now checking the detrended component in Dickey Fuller Test.\nCritical Value > Test Statistic \nHence, series is stationary now. ARIMA can now be applied easily. "},{"metadata":{"trusted":true},"cell_type":"code","source":"adf_test(detrended.trend)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preparing the Data to apply ARIMA to the detrended portion"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(detrended)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set one year for testing\nstrain = detrended.iloc[:138]\nstest = detrended.iloc[138:150]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#SARIMA\nauto_arima(detrended.trend,m=12,seasonal = True,maxiter=200).summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smodel = SARIMAX(detrended['trend'],order=(4,0,2))\nsresults = smodel.fit(maxiter=200)\nsresults.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Obtain predicted values\nsstart=len(strain)\nsend=len(strain)+len(stest)-1\nspredictions = sresults.predict(start=sstart, end=send, dynamic=False, typ='levels', full_results = True).rename('SARIMA Predictions Detrended')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compare predictions to expected values\nfor i in range(len(spredictions)):\n    print(f\"predicted={spredictions[i]:<11.10}, expected={stest['trend'][i]}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = stest['trend'].plot(legend=True,figsize=(6,6))\nspredictions.plot(legend=True)\nax.autoscale(axis='x',tight=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nerror = mean_squared_error(stest['trend'], spredictions)\nprint(f'SARIMA MSE Error: {error:11.10}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Up until now, the detrended componeent is predicted through the ARIMA model and the MSE is SIGNIFICANTLY less. This definitely shows that detrending worked.\n\nHowever, the process is only half done.\nNow, the subtracted trend component will be predicted separately.\nFor that the trend component that was subytacyed is used, converted to a dataframe called TRENDY and ARIMA is applied with seasonality = False"},{"metadata":{"trusted":true},"cell_type":"code","source":"res.trend","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(res.trend)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trendy = pd.DataFrame(res.trend)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#SARIMA\nauto_arima(trendy.trend,m=12,seasonal = False, maxiter=200).summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set one year for testing\ntraint = trendy.iloc[:138]\ntestt = trendy.iloc[138:150]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelt = SARIMAX(trendy['trend'],order=(0,2,0))\nresultst = modelt.fit(maxiter=200)\nresultst.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Obtain predicted values\nstart=len(traint)\nend=len(traint)+len(testt)-1\npredictionst = resultst.predict(start=start, end=end, dynamic=False, typ='levels', full_results = True).rename('SARIMA Predictions')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compare predictions to expected values\nfor i in range(len(predictionst)):\n    print(f\"predicted={predictionst[i]:<11.10}, expected={testt['trend'][i]}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = testt['trend'].plot(legend=True,figsize=(6,6))\npredictionst.plot(legend=True)\nax.autoscale(axis='x',tight=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nerror = mean_squared_error(testt['trend'], predictionst)\nprint(f'SARIMA MSE Error: {error:11.10}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"The Trend is easily predicted with ARIMA with minimum MSE.\nNote: Trend could also be predicted through a linear regression model, I chose to go with ARIMA just to trythe seasonal = False part\n\nOnce both trend component and seasonality + random  compoenent were predicted for 2017\nThey were added together and compared with the original 2017 values"},{"metadata":{"trusted":true},"cell_type":"code","source":" finalpreds = (predictionst + spredictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test2017","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = test2017['Close'].plot(legend=True,figsize=(6,6))\nfinalpreds.plot(legend=True)\nax.autoscale(axis='x',tight=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nerror = mean_squared_error(test2017['Close'], finalpreds)\nprint(f'SARIMA MSE Error: {error:11.10}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This model is MUCH MUCH better than the original 2017 model without detrending.\n\nTo understand why this works better, you can have a look at this research paper: https://research.cs.aalto.fi/aml/Publications/Publication173.pdf\nBut a whole lot of it has improved because of the series being staionary. "},{"metadata":{},"cell_type":"markdown","source":"### Questions I am still looking answers to for the Next Version\n1. How can these predictions be further improved?\n2. Why did the Auto ARIMA function not give any seasonal components (P,Q,D,m) despite the stock prices having seasonality?\n3. Is there any better way like detrending to improve the predictions?\n4. Does Auto ARIMA actually help in the process or not?\n5. Which other algorithms apart from ARIMA can be used for time series modeling?\n6. Can additional features such as market reputation be added and will multivariate time series forecasting be possible?\n\nSuggestions and Collaborations are welcome!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}