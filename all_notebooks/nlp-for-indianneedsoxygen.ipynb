{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/indianeedsoxygen-tweets/IndiaWantsOxygen.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dropna(subset=['user_name'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Top 30 location","metadata":{}},{"cell_type":"code","source":"df.groupby('user_location')['user_location'].count().sort_values(ascending=False).head(30).plot.bar(figsize=(10,5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Top 20 user names","metadata":{}},{"cell_type":"code","source":"df.groupby('user_name')['user_name'].count().sort_values(ascending=False).head(20).plot.bar(figsize=(10,5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Top 20 user names by followers","metadata":{}},{"cell_type":"code","source":"df.groupby('user_name')['user_followers'].sum().sort_values(ascending=False).head(20).plot.bar(figsize=(10,5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Top 20 user names by friends","metadata":{}},{"cell_type":"code","source":"df.groupby('user_name')['user_friends'].sum().sort_values(ascending=False).head(20).plot.bar(figsize=(10,5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Top 20 user names by favourites","metadata":{}},{"cell_type":"code","source":"df.groupby('user_name')['user_favourites'].sum().sort_values(ascending=False).head(20).plot.bar(figsize=(10,5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Top 20 sources","metadata":{}},{"cell_type":"code","source":"df.groupby('source')['source'].count().sort_values(ascending=False).head(20).plot.bar(figsize=(10,5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime\ndf['date'] = pd.to_datetime(df['date'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['date2']=df['date'].dt.date","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['hour']=df['date'].dt.hour","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Time series analysis","metadata":{}},{"cell_type":"markdown","source":"day by day","metadata":{}},{"cell_type":"code","source":"df.groupby('date2')['date2'].count().plot.bar(figsize=(10,5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"trend by hours","metadata":{}},{"cell_type":"code","source":"df.groupby('hour')['hour'].count().plot.bar(figsize=(10,5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"trend by hour and day","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"df.groupby(['date2','hour'])['hour'].count().plot(figsize=(10,5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**I tried to search the infcetion numbers in India around 22nd to 24th in April.**","metadata":{}},{"cell_type":"code","source":"#this is the data which I got from website.https://www3.nhk.or.jp/news/special/coronavirus/world-data/\n\nlist=[295158,314644,332921,346786,349691,352991,323023,360927]\ndf_infection=pd.DataFrame(list)\ndf_infection.index=['0420','0421','0422','0423','0424','0425','0426','0427']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_infection = df_infection.rename(columns={0: 'number of infection'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_infection.plot(label='number of infection',figsize=(10,5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**Actually, the infection is increasing rapidly between 20th and 23rd and down on 26th.**","metadata":{}},{"cell_type":"markdown","source":"Tokenize by NLTK","metadata":{}},{"cell_type":"code","source":"from nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom string import punctuation\nimport string\n\nlist_stopwords = set(stopwords.words('english'))\ndf2= df[['text']]\ndf2['text'] = df2['text'].str.lower()\ndf2['text'] = df2['text'].apply(word_tokenize)\ndf2['text'] = df2['text'].apply(lambda x: [word for word in x if word not in list_stopwords])\ndf2['text'] = df2['text'].apply(lambda x : [word.translate(str.maketrans('', '', string.punctuation)) for word in x])\ndf2['text'] = df2['text'].apply(lambda x : [word for word in x if len(word) > 1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3=df2['text'].explode()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3=pd.DataFrame(df3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_rows',30)\ndf3.groupby('text')['text'].count().sort_values(ascending=False).head(30).plot.bar(figsize=(10,5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}