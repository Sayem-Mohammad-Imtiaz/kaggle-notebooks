{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Machine Learning Visualization 4","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import axes3d, Axes3D\nimport matplotlib.animation as animation\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/goodreadsbooks/books.csv',error_bad_lines=False)\ndf = df.reset_index(drop=True)\ndf.authors = [i.split('/')[0] for i in df.authors]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Wordclouds","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\n\nd = {}\nfor x, a in zip(df.authors.value_counts(), df.authors.value_counts().index):\n    d[a] = x\n\nwordcloud = WordCloud()\nwordcloud.generate_from_frequencies(frequencies=d)\nplt.figure(num=None, figsize=(12, 10), dpi=80, facecolor='w', edgecolor='k')\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.title(\"Word Cloud\", fontsize=20)\nplt.savefig(\"cloud.png\", dpi=200)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Embeddings","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop_duplicates('authors')\ndf = df.reset_index(drop=True)\ndf = df[:30]\nsize = len(df.authors)\nencoder, scaler = LabelEncoder(), MinMaxScaler()\naut = encoder.fit_transform(df.authors) \nrat = scaler.fit_transform(df[['average_rating']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Latent_Embed(nn.Module):\n    def __init__(self, vocab_size, embedding_dim):\n        super(Latent_Embed, self).__init__()\n        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n        self.linear1 = nn.Linear(3, 2)\n        self.linear2 = nn.Linear(2, 1)\n\n    def forward(self, inputs):\n        embeds = self.embeddings(inputs)\n        out = F.relu(self.linear1(embeds))\n        out = F.relu(self.linear2(out))\n        return out\n\n\naut_t = torch.tensor(aut)\nrat_t = torch.tensor(rat)\nloss_function = nn.MSELoss()\nmodel = Latent_Embed(size, 3)\noptimizer = optim.SGD(model.parameters(), lr=0.0001)\n\nfor epoch in range(10):\n    total_loss = 0\n    for context, target in zip(aut_t, rat_t):\n        model.zero_grad()\n        log_probs = model(context)\n        loss = loss_function(log_probs.double(), target.view(1).double())\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    print(\"Loss: \", total_loss/len(aut_t))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_weights = pd.DataFrame(model.embeddings.weight.detach().numpy())\nembedding_weights.columns = ['X1','X2','X3']\nembedding_weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(num=None, figsize=(14, 12), dpi=80, facecolor='w', edgecolor='k')\nax = plt.axes(projection='3d')\nfor index, (x, y, z) in enumerate(zip(embedding_weights['X1'], \n                                      embedding_weights['X2'], \n                                      embedding_weights['X3'])):\n    ax.scatter(x, y, z, color='b', s=12)\n    ax.text(x, y, z, str(df.authors[index]), size=12, zorder=2.5, color='k')\n\nax.set_title(\"Word Embedding\", fontsize=20)\nax.set_xlabel(\"X1\", fontsize=20)\nax.set_ylabel(\"X2\", fontsize=20)\nax.set_zlabel(\"X3\", fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rotate(angle):\n    ax.view_init(azim=angle)\n\nprint(\"Making animation\")\nres_animation = animation.FuncAnimation(fig, rotate, frames=np.arange(0, 365, 2), interval=100)\nres_animation.save('embedding.gif', dpi=100, writer='imagemagick')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}