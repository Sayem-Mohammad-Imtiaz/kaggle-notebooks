{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nUsing v6_text files produced by Mike Honey.\n\nEach row is a sentence with a section label.\n\n\"\"\"\ntext_files = glob.glob('../input/coronawhy-plus/v6_text/*tsv')\n\n\"\"\"\nUse 999 paper ids from annotation table for Task - Treatments team.\n\"\"\"\n\nannotation_task_table = '../input/annotation-treatment-task/_AnnotationSample_Task-Treatment - AnnotationSample_2020_04_02.tsv'\n\nannot_task_df = pd.read_csv(annotation_task_table, sep='\\t', index_col=0)\n\n#Skip first uid, which is header (displaced by instruction in table)\npaper_uid_list = annot_task_df.index.tolist()[1:]\n\n#Skip first sha\npaper_sha_list = annot_task_df.iloc[:, 0].tolist()[1:]\n\n#Some papers have multiple shas, delimited by ';'.  Taking the first one for now, will come back if I cannot locate the text for it.\nedit_paper_sha_list = [i.split(';')[0] for i in paper_sha_list]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_section_dict(text_df, paper_sha_list, sections):\n    \n    text_df_with_ids = text_df.loc[text_df.paper_id.isin(paper_sha_list)]\n    text_df_of_sections = text_df_with_ids.loc[text_df_with_ids.section.isin(sections)]\n    section_dict = text_df_of_sections.groupby('paper_id')['sentence'].apply(list).to_dict()\n\n    #concatenate sentences\n\n    section_concat_sentences_dict = {k: \" \".join(v) for k,v in section_dict.items()}\n    \n    return section_concat_sentences_dict\n   \ndef process_text_tsv_files(text_files, paper_sha_list, sections_oi):\n    \n    master_dict = {}\n      \n    for text_file in text_files:\n        print(\"Processing %s...\" % text_file)\n        text_df = pd.read_csv(text_file, sep='\\t')\n        text_df.loc[:, 'sentence'] = text_df.loc[:, 'sentence'].astype(str)\n        \n        for section in sections_oi:\n            print(\"Extracting %s section...\" % section)\n            \n            if section not in master_dict.keys():\n                master_dict[section] = {}\n                \n            tmp_dict = generate_section_dict(text_df, paper_sha_list, [section])\n            for k, v in tmp_dict.items():\n                master_dict[section].setdefault(k, []).append(v)\n        \n    return master_dict\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sections_oi = ['methods', 'results']\n\ntest_dict = process_text_tsv_files(text_files, edit_paper_sha_list, sections_oi)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_ids = (set(list(test_dict['results'])))\nmethods_ids = set(list(test_dict['methods']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids_with_no_results = list(set(edit_paper_sha_list) - set(results_ids))\nids_with_no_methods = list(set(edit_paper_sha_list) - set(methods_ids))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nGet paper section headers\n\n if section not in master_dict.keys():\n                master_dict[section] = {}\n                \n            tmp_dict = generate_section_dict(text_df, paper_sha_list, [section])\n            for k, v in tmp_dict.items():\n                master_dict[section].setdefault(k, []).append(v)\n\"\"\"\n\ndef extract_paper_section_headers(text_files, paper_sha_ids):\n    master_dict = {}\n    for text_file in text_files:\n        print(\"Processing %s...\" % text_file)\n        text_df = pd.read_csv(text_file, sep='\\t')\n        \n        text_df_for_ids = text_df.loc[text_df.paper_id.isin(paper_sha_ids)]\n        section_dict = text_df_for_ids.groupby('paper_id')['section'].apply(list).to_dict()\n        section_dict_unique = {k: list(set(v)) for k,v in section_dict.items()}\n        \n        for paper_id, sections in section_dict_unique.items():\n            for section in sections:\n                master_dict.setdefault(paper_id, set([])).add(section)\n        \n        \n    return master_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sections_of_papers_with_no_results = extract_paper_section_headers(text_files, ids_with_no_results)\nsections_of_papers_with_no_methods = extract_paper_section_headers(text_files, ids_with_no_methods)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sha_id_title_dict = {k: v for k,v in zip(annot_task_df.iloc[:, 0], annot_task_df.iloc[:, 1])}\nedited_sha_id_title_dict = {k.split(';')[0] : v for k, v in sha_id_title_dict.items()}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('sections_of_papers_with_no_results.txt', 'w') as f:\n\n    for paper_id, sections in sections_of_papers_with_no_results.items():\n        f.write(\"%s\\t%s\\n\" % (paper_id, edited_sha_id_title_dict[paper_id]))\n        for section in sections:\n            f.write(\"%s\\n\" % section)\n        f.write('\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nwith open('sections_of_papers_with_no_methods.txt', 'w') as f:\n\n    for paper_id, sections in sections_of_papers_with_no_methods.items():\n        f.write(\"%s\\t%s\\n\" % (paper_id, edited_sha_id_title_dict[paper_id]))\n        for section in sections:\n            f.write(\"%s\\n\" % section)\n        f.write('\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}