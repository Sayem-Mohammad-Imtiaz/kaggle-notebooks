{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Applying a neural network for genre classification\n## Overview\nIn this notebook, I create and test a simple _music genre classifier_, explain the workflow and parameters involved in processing data and building the network.\n\n> Note: to understand this, one should be familiar with how Digital Signal Processing works and how Neural Neworks work. These are explained in 2 of my previous notebooks that can be found here:\n> * https://www.kaggle.com/mantasu/how-neural-network-works\n> * https://www.kaggle.com/mantasu/asp-cheatsheet\n\n## Motivation\nThis notebook helps to understand how a deep neural network can be implemented on audio data\n\n## Resources\nThe main sources of reference are these videos:\n* https://www.youtube.com/watch?v=szyGiObZymo\n* https://www.youtube.com/watch?v=_xcFAiufwd0\n* https://www.youtube.com/watch?v=Gf5DO6br0ts","metadata":{}},{"cell_type":"markdown","source":"# Preprocessing audio data\n## Understanding constants\n* `DATA_PATH` - the path of the direcory which contains sub-folders named after each genre in the dataset. Each sub-folder contains a number of 30 sec audio files\n* `JSON-PATH` - the path of a `.json` file where the features of each audio file will be saved in a structurised way\n* `DURATION` - the length of each track (will help with calculations)\n* `SAMPLE_RATE` - number of amplitude samples we take per second when sampling an analogous signal. We don't need a high one because most of the information is contained in lower frequencies anyway\n* `SAMPLES_PER_TRACK` - total number of soundwave samples for a whole duration of the song \n\n## Defining the method\n`save_mfcc` - saves the MFCCs of each song in a JSON file genre-wise which will be used as training data:\n* `dataset_path` - the root directory which contains all the genre sub-directories with audio files\n* `json_path` - path of the JSON file to which the training data will be saved\n* `n_mfccs` - number of Mel-frequency cepstral coefficients we want to extract for each song\n    * `13` by default because they provide the most information\n* `n_fft` - number of samples for each frame the FFT will be applied to. Frames are perceivable audio chunks (~10ms) so the higher the sampling rate is, the higher the frame size should be\n    * `2048` by default because power of 2 allows us to perform STFT\n* `hop_length` - step size we take when shifting on performing FFT on next frame. Because frames are windowed (silenced at both ends) before each FFT, we need frames to overlap so usually `hop_length` is half the size of frame size but lower values make it more precise\n    * `512` by default as 1/4 th of the default `n_fft` value\n* `num_segments` - number of segments we split the audio file to (each piece of training data for one audio file will be split to segments with suffixes denoting the segment ID). With data, more is always better\n    * `5` by default considering the length of the audio and assuming just a couple of samples will be taken from each genre\n* `files_per_genre` - number of files to consider for one genre\n    * `-1` by default indicating all the genres will be considered\n\n## Workflow\nBefore we enter the main loop, we define a dictionary object wich will shape our training data:\n* `data` - a dictionary which will represent the training data that will be saved in `.json` file\n    * `mapping` - labels of each genre the coefficients will be mapped to (e.g., \"blues\")\n    * `mfccs` - MFCC vectors for each segment (e.g., [0, 0.123, ...])\n    * `labels` - values which represent to which genre each MFCC vector belongs to (e.g., 1)\n\n### Main loop\n1. We loop through each sub-folder in the dataset path\n    * Ensure the sub-folder is not the root folder (i.e., is not the dataset path itself) because it is given as a result of the first iteration by the `os.walk`\n    * Save the semantic label (the name of the sub-folder which represents the genre)\n2. We loop through each audio file in the sub-folder\n    * Load the audio file with `librosa`\n3. We loop through each segment in audio file\n    * Define start and end points at which the audio should be sliced\n    * Extract MFCCs for that silce/segment\n    * Store the data in the `data` dictionary","metadata":{}},{"cell_type":"code","source":"import os       # traversing directories\nimport librosa  # extracting audio features\nimport math     # allows to perform ceiling\nimport json     # saving data in json format\n\n# Define important constants\nDATA_PATH = \"/kaggle/input/gtzan-fixed/Data/genres_original\"\nJSON_PATH = \"/kaggle/temp/data.json\"\nDURATION = 30\nSAMPLE_RATE = 22050\nSAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n\ndef save_mfcc(dataset_path, json_path, n_mfcc=13, n_fft=2048, hop_length=512, num_segments=5, files_per_genre=-1):\n    \"\"\"Calculates MFCC vectors for each segment for each song in each genre and saves the data to a JSON file.\n        \n        Args:\n            dataset_path (str):    path to audio files grouped genre-wise\n            json_path (str):       path to json file where input and target data will be saved\n            n_mfcc (int):          number of Mel-frequency cepstral coefficients to extract for each frame\n            n_fft (int):           frame size\n            hop_length (int):      step size when shifting to new frame\n            num_segments (int):    number of segments each song will be divided into\n            files_per_genre (int): number of files to consider for each genre\n    \"\"\"\n    # Dictionary to store data\n    data = {\n        \"mapping\": [],\n        \"mfcc\": [],\n        \"labels\": []\n    }\n    \n    # Find how many samples there are in one segment\n    num_samples_per_segment = SAMPLES_PER_TRACK // num_segments\n    \n    # Define how many MFCC vectors there chould be for one segment\n    expected_number_mfcc_vectors_per_segment = math.ceil(num_samples_per_segment / hop_length) # ceil because mfcc works that way\n    \n    # Loop through all the genres\n    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n        # Ensure we're not at the root level\n        if dirpath is not dataset_path:\n            # Save the semantic label\n            semantic_label = dirpath.split(\"/\")[-1]\n            data[\"mapping\"].append(semantic_label)\n            \n            # Print which folder we are processing\n            print(f\"\\nProcessing {semantic_label}\")\n            \n            # Process files for a specific genre\n            for filename in filenames[:files_per_genre]:\n                # Load audio file\n                file_path = os.path.join(dirpath, filename)\n                signal, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n                \n                # Print which file we are processing\n                print(f\"Processing {filename}\")\n                \n                # Process the segments\n                for segment in range(num_segments):\n                    start_sample = num_samples_per_segment * segment\n                    end_sample = start_sample + num_samples_per_segment\n                    \n                    # Extract MFCC vectors for a particular segment\n                    mfcc = librosa.feature.mfcc(signal[start_sample:end_sample],\n                                                sr=SAMPLE_RATE,\n                                                n_mfcc=n_mfcc,\n                                                n_fft=n_fft,\n                                                hop_length=hop_length)\n                    \n                    # Take the transpose for simpler calculations\n                    mfcc = mfcc.T\n                    \n                    # Store MFCC vectors for segment if it has the expected length\n                    if len(mfcc) == expected_number_mfcc_vectors_per_segment:\n                        data[\"mfcc\"].append(mfcc.tolist()) # tolist required to store as json file\n                        data[\"labels\"].append(i-1)         # because when i=0, we're at the dataset path so we ignore\n                        # print(f\"{file_path}, segment: {segment+1}\")\n    \n    # Create \"/kaggle/temp/\" directory where temporary files can be stored\n    if not os.path.exists(\"/kaggle/temp/\"):\n        os.makedirs(\"/kaggle/temp/\")\n    \n    # Write a JSON file to the temporary directory\n    with open(json_path, \"w\") as fp:\n        json.dump(data, fp, indent=4)\n\n# Use the method to save the data\nsave_mfcc(DATA_PATH, JSON_PATH, num_segments=10, files_per_genre=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T08:37:56.086155Z","iopub.execute_input":"2021-07-16T08:37:56.08663Z","iopub.status.idle":"2021-07-16T08:38:01.466049Z","shell.execute_reply.started":"2021-07-16T08:37:56.086509Z","shell.execute_reply":"2021-07-16T08:38:01.464808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Implementing NN for genre classification\n## Loading data\n1. We create a helper method `load_data` which takes in dataset path of a `.json` file and returns inputs and target labels\n2. We split inputs and targets to train and test sets\n\n## Building NN\n1. Input layer is a flattened matrix of segment length $\\times$ mfcc count\n2. 3 hidden layers use `512`, `256` and `64` neurons respectively and use **ReLU** as activation function\n    * **ReLU** - improves convergence and reduces the likelihood of _vanishing gradient_\n3. Output layer has 10 output nodes representing 10 genres and uses **softmax** as activation function\n    * **softmax** - normalizes the values so that summing all of them results in `1`\n4. Define `Adam` as our optimizer with learning rate `0.0001`\n    * `Adam` - variation of _SGD_ that's very effective with deep learning\n5. Compile the model and print the summary\n\n## Training\nWe pass in parameters to the `train` method:\n* Training and validation data\n* Number of epochs (number of times we do training on a selected batch of samples)\n* Batch size (gradient is computed only on a subset of the dataset)","metadata":{}},{"cell_type":"code","source":"import numpy as np                                    # linear algebra\nfrom sklearn.model_selection import train_test_split  # splitting data\nimport tensorflow.keras as keras                      # model creation\n\ndef load_data(dataset_path):\n    \"\"\"Loads training dataset from json file.\n    \n        :param data_path (str): Path to json file containing data\n        :return X (ndarray): Inputs\n        :return y (ndarray): Targets\n    \"\"\"\n    # Open the dataset file and parse data to lists\n    with open(dataset_path, \"r\") as fp:\n        data = json.load(fp)\n        \n    # Convert lists to numpy arrays\n    inputs = np.array(data[\"mfcc\"])\n    targets = np.array(data[\"labels\"])\n    \n    # Return the data\n    return inputs, targets\n    \n# Load the data with the helper method\ninputs, targets = load_data(JSON_PATH)\n\n# Split the data to train and test sets\ninputs_train, inputs_test, targets_train, targets_test = train_test_split(inputs, targets, test_size=.3)\n\n# Build the network architecture\nmodel = keras.Sequential([\n    keras.layers.Flatten(input_shape=(inputs.shape[1], inputs.shape[2])),\n    keras.layers.Dense(512, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001)),\n    keras.layers.Dropout(0.3),\n    keras.layers.Dense(256, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001)),\n    keras.layers.Dropout(0.3),\n    keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001)),\n    keras.layers.Dropout(0.3),\n    keras.layers.Dense(10, activation=\"softmax\"),\n])\n\n# Compile network\noptimizer = keras.optimizers.Adam(learning_rate=.0001)\nmodel.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\nmodel.summary()\n\n# Train network\nhistory = model.fit(inputs_train, targets_train, validation_data=(inputs_test, targets_test), epochs=50, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T09:52:55.898598Z","iopub.execute_input":"2021-07-16T09:52:55.899066Z","iopub.status.idle":"2021-07-16T09:53:01.722706Z","shell.execute_reply.started":"2021-07-16T09:52:55.899029Z","shell.execute_reply":"2021-07-16T09:53:01.721848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Accuracy\n## Checking accuracy\nWe define a helper plot function for plotting accuracy and error evaluations for both training and test data.\n\n## Solving overfiting\nThere are several ways to solve overfitting:\n* _Simpler architecture_ - a simpler model won't learn all the tiny patterns and possible artifacts\n    * Imlementation: reduce # neurons (no universal rule)\n* _Data augumentation_ - artificially increase # of training samples\n    * Implementation: apply transformations to actual files (e.g., pitch shifing, time stretching)\n* _Early stopping_ - choose rules to stop training\n    * Implementation: stop the training if the test error doesn't improve after some number of iterations\n* _Dropout_ - randomly drop neurons while training (increases network robustness because it can't rely too much on some specific neurons)\n    * Implementation: on each batch, some neurons and their connections are not considered (probabiliy is chosen to be between `0.1` and `0.5`)\n* _Regularization_ - adds penalty to error function and punishes large weights\n    * **L1**: $E(\\mathbf{p},\\mathbf{y})=\\frac{1}{2}(\\mathbf{p} - \\mathbf{y})^2+\\lambda\\sum|W_i|$\n        * We get the absolute value of all the weights and weight it by a regularization term\n        * Minimises absolute value of weights, is robust to outliers, generates simple model\n    * **L2**: $E(\\mathbf{p},\\mathbf{y})=\\frac{1}{2}(\\mathbf{p} - \\mathbf{y})^2+\\lambda\\sum W_i^2$\n        * We get the total value of all the squared weights and weight it by a regularization term\n        * Minimises squared value of weights, _not_ robust to outliers, learns complex patterns\n\nWe implemented dropout and _L2_ regularisation in our model","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt # visualizing plots\n\ndef plot_history(history):\n    \"\"\"Plots accuracy and error evaluations for both training and test data.\n    \n        :param history (ndarray): dictionary where history object is located\n    \"\"\"\n    \n    # Get figure and axis objects form 2 subplots\n    fig, axs = plt.subplots(2)\n    \n    # Create accuracy subplot\n    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n    axs[0].set_ylabel(\"Accuracy\")\n    axs[0].legend(loc=\"lower right\")\n    axs[0].set_title(\"Accuracy eval\")\n    \n    # Create error subplot\n    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n    axs[1].set_ylabel(\"Error\")\n    axs[1].set_xlabel(\"Epoch\")\n    axs[1].legend(loc=\"upper right\")\n    axs[1].set_title(\"Error eval\")\n    \n    # Show the plot\n    fig.tight_layout()\n    plt.show()\n    \n# Plot accuracy and error over the epochs\nplot_history(history)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T09:53:06.738634Z","iopub.execute_input":"2021-07-16T09:53:06.738994Z","iopub.status.idle":"2021-07-16T09:53:07.094745Z","shell.execute_reply.started":"2021-07-16T09:53:06.738962Z","shell.execute_reply":"2021-07-16T09:53:07.093706Z"},"trusted":true},"execution_count":null,"outputs":[]}]}