{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Time Series**- ARIMA | SARIMA","metadata":{}},{"cell_type":"markdown","source":"## **1. Introduction to Time Series Forecasting** \n\n* A Time Series is defined as a series of data points recorded at different time intervals. The time order can be daily, monthly, or even yearly.\n* \n* Time Series forecasting is the process of using a statistical model to predict future values of a time series based on past results.\n\n* Forecasting is the step where we want to predict the future values the series is going to take. Forecasting a time series is often of tremendous commercial value.\n\n**Forecasting a time series can be broadly divided into two types:**\n1. If we use only the previous values of the time series to predict its future values, it is called Univariate Time Series Forecasting.\n\n2. If we use predictors other than the series (like exogenous variables) to forecast it is called Multi Variate Time Series Forecasting.","metadata":{}},{"cell_type":"markdown","source":"## **2. Introduction to ARIMA Models** \n\nARIMA stands for Autoregressive Integrated Moving Average Model. It belongs to a class of models that explains a given time series based on its own past values -i.e.- its own lags and the lagged forecast errors. The equation can be used to forecast future values. Any ‘non-seasonal’ time series that exhibits patterns and is not a random white noise can be modeled with ARIMA models.\nSo, ARIMA, short for AutoRegressive Integrated Moving Average, is a forecasting algorithm based on the idea that the information in the past values of the time series can alone be used to predict the future values.\nARIMA Models are specified by three order parameters: (p, d, q),\n\nwhere,\n\np is the order of the AR term\n\nq is the order of the MA term\n\nd is the number of differencing required to make the time series stationary\n\n* AR(p) Autoregression – a regression model that utilizes the dependent relationship between a current observation and observations over a previous period. An auto regressive (AR(p)) component refers to the use of past values in the regression equation for the time series.\n* I(d) Integration – uses differencing of observations (subtracting an observation from observation at the previous time step) in order to make the time series stationary. Differencing involves the subtraction of the current values of a series with its previous values d number of times.\n* MA(q) Moving Average – a model that uses the dependency between an observation and a residual error from a moving average model applied to lagged observations. A moving average component depicts the error of the model as a combination of previous error terms. The order q represents the number of terms to be included in the model.\n\n**Types of ARIMA Model**\n1. ARIMA : Non-seasonal Autoregressive Integrated Moving Averages\n2. SARIMA : Seasonal ARIMA\n3. SARIMAX : Seasonal ARIMA with exogenous variables\nIf a time series, has seasonal patterns, then we need to add seasonal terms and it becomes SARIMA, short for Seasonal ARIMA.\n\n## **3. The meaning of p, d and q in ARIMA model** \n\n### 3.1 The meaning of p\np is the order of the Auto Regressive (AR) term. It refers to the number of lags of Y to be used as predictors.\n### 3.2 The meaning of d\nThe term Auto Regressive’ in ARIMA means it is a linear regression model that uses its own lags as predictors. Linear regression models, as we know, work best when the predictors are not correlated and are independent of each other. So we need to make the time series stationary.\nThe most common approach to make the series stationary is to difference it. That is, subtract the previous value from the current value. Sometimes, depending on the complexity of the series, more than one differencing may be needed.\nThe value of d, therefore, is the minimum number of differencing needed to make the series stationary. If the time series is already stationary, then d = 0.\n### 3.3 The meaning of q\nq is the order of the Moving Average (MA) term. It refers to the number of lagged forecast errors that should go into the ARIMA Model.\n## **4. AR and MA models** \n\n### 4.1 AR model\nAn Auto Regressive (AR) model is one where Yt depends only on its own lags.\n\nThat is, Yt is a function of the lags of Yt. It is depicted by the following equation -\n\nAR Model\n\nimage source : https://www.machinelearningplus.com/wp-content/uploads/2019/02/Equation-1-min.png?ezimgfmt=ng:webp/ngcb1\n\nwhere,\n\n𝑌𝑡−1\nY\nt\n−\n1\n  is the lag1 of the series,\n\n𝛽1\nβ\n1\n  is the coefficient of lag1 that the model estimates, and\n\n𝛼\nα\n  is the intercept term, also estimated by the model.\n\n### 4.2 MA model\nLikewise a Moving Average (MA) model is one where Yt depends only on the lagged forecast errors. It is depicted by the following equation -\nMA Model\n\nimage source : https://www.machinelearningplus.com/wp-content/uploads/2019/02/Equation-2-min.png?ezimgfmt=ng:webp/ngcb1\n\nwhere the error terms are the errors of the autoregressive models of the respective lags.\n\nThe errors Et and E(t-1) are the errors from the following equations :\n\nError Terms of the AR Model\n\nimage source : https://www.machinelearningplus.com/wp-content/uploads/2019/02/Equation-3-min.png?ezimgfmt=ng:webp/ngcb1\n\nThus, we have discussed AR and MA Models respectively.\n\n### 4.3 ARIMA model\nAn ARIMA model is one where the time series was differenced at least once to make it stationary and we combine the AR and the MA terms. So the equation of an ARIMA model becomes :\nARIMA Model\n\nimage source : https://www.machinelearningplus.com/wp-content/uploads/2019/02/Equation-4-min-865x77.png?ezimgfmt=ng:webp/ngcb1\n\nARIMA model in words:\n\nPredicted Yt = Constant + Linear combination Lags of Y (upto p lags) + Linear Combination of Lagged forecast errors (upto q lags)\n\n## **5. How to find the order of differencing (d) in ARIMA model**\n\nAs stated earlier, the purpose of differencing is to make the time series stationary. But we should be careful to not over-difference the series. An over differenced series may still be stationary, which in turn will affect the model parameters.\nSo we should determine the right order of differencing. The right order of differencing is the minimum differencing required to get a near-stationary series which roams around a defined mean and the ACF plot reaches to zero fairly quick.\nIf the autocorrelations are positive for many number of lags (10 or more), then the series needs further differencing. On the other hand, if the lag 1 autocorrelation itself is too negative, then the series is probably over-differenced.\nIf we can’t really decide between two orders of differencing, then we go with the order that gives the least standard deviation in the differenced series.\nNow, we will explain these concepts with the help of an example as follows:-\n* First, I will check if the series is stationary using the Augmented Dickey Fuller test (ADF Test), from the statsmodels package. The reason being is that we need differencing only if the series is non-stationary. Else, no differencing is needed, that is, d=0.\n* The null hypothesis (Ho) of the ADF test is that the time series is non-stationary. So, if the p-value of the test is less than the significance level (0.05) then we reject the null hypothesis and infer that the time series is indeed stationary.\nSo, in our case, if P Value > 0.05 we go ahead with finding the order of differencing.","metadata":{}},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nsns.set_style(\"whitegrid\")\nplt.style.use(\"fivethirtyeight\")","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:25:27.987436Z","iopub.execute_input":"2021-06-14T13:25:27.988061Z","iopub.status.idle":"2021-06-14T13:25:28.95172Z","shell.execute_reply.started":"2021-06-14T13:25:27.987942Z","shell.execute_reply":"2021-06-14T13:25:28.95059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/perrin-freres-monthly-champagne-sales/Perrin Freres monthly champagne sales millions.csv\")\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:25:31.855765Z","iopub.execute_input":"2021-06-14T13:25:31.856394Z","iopub.status.idle":"2021-06-14T13:25:31.916586Z","shell.execute_reply.started":"2021-06-14T13:25:31.856327Z","shell.execute_reply":"2021-06-14T13:25:31.915356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# change column names\ndf.columns=[\"Month\",\"Sales\"]\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:25:32.397608Z","iopub.execute_input":"2021-06-14T13:25:32.398241Z","iopub.status.idle":"2021-06-14T13:25:32.409074Z","shell.execute_reply.started":"2021-06-14T13:25:32.39817Z","shell.execute_reply":"2021-06-14T13:25:32.408046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.tail()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:25:39.285392Z","iopub.execute_input":"2021-06-14T13:25:39.285787Z","iopub.status.idle":"2021-06-14T13:25:39.296854Z","shell.execute_reply.started":"2021-06-14T13:25:39.28573Z","shell.execute_reply":"2021-06-14T13:25:39.295598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:25:40.607128Z","iopub.execute_input":"2021-06-14T13:25:40.6075Z","iopub.status.idle":"2021-06-14T13:25:40.616378Z","shell.execute_reply.started":"2021-06-14T13:25:40.607467Z","shell.execute_reply":"2021-06-14T13:25:40.615056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dropna(inplace=True)\ndf.tail()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:25:43.137882Z","iopub.execute_input":"2021-06-14T13:25:43.138262Z","iopub.status.idle":"2021-06-14T13:25:43.171948Z","shell.execute_reply.started":"2021-06-14T13:25:43.138228Z","shell.execute_reply":"2021-06-14T13:25:43.170614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.Month = pd.to_datetime(df.Month)\ndf.set_index(\"Month\", inplace=True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:25:44.440703Z","iopub.execute_input":"2021-06-14T13:25:44.441077Z","iopub.status.idle":"2021-06-14T13:25:44.457399Z","shell.execute_reply.started":"2021-06-14T13:25:44.441043Z","shell.execute_reply":"2021-06-14T13:25:44.456598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:25:45.263101Z","iopub.execute_input":"2021-06-14T13:25:45.263651Z","iopub.status.idle":"2021-06-14T13:25:45.282797Z","shell.execute_reply.started":"2021-06-14T13:25:45.263586Z","shell.execute_reply":"2021-06-14T13:25:45.281793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:25:46.819025Z","iopub.execute_input":"2021-06-14T13:25:46.819442Z","iopub.status.idle":"2021-06-14T13:25:46.840573Z","shell.execute_reply.started":"2021-06-14T13:25:46.819402Z","shell.execute_reply":"2021-06-14T13:25:46.839428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---------------------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"## Visualize Data","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14,6))\nplt.plot(df)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:35:57.252312Z","iopub.execute_input":"2021-06-14T13:35:57.252726Z","iopub.status.idle":"2021-06-14T13:35:57.572359Z","shell.execute_reply.started":"2021-06-14T13:35:57.252688Z","shell.execute_reply":"2021-06-14T13:35:57.57131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing for Stationarity: When a time series is stationary, it can be easier to model.\n* adfuller is a function used to check Stationarity in dataset.","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller\ntest_fuller = adfuller(df[\"Sales\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:35:52.339748Z","iopub.execute_input":"2021-06-14T13:35:52.340195Z","iopub.status.idle":"2021-06-14T13:35:52.601755Z","shell.execute_reply.started":"2021-06-14T13:35:52.340163Z","shell.execute_reply":"2021-06-14T13:35:52.600593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nHypothesis Test\nHo: It is non stationary.\nH1: It is stationary.\n\"\"\"\n\ndef adfuller_test(sales):\n    result = adfuller(sales)\n    labels = [\"ADF Test Statistic\",'p-value',\"#Lags Used\",\"No. of observations\"]\n    for value,label in zip(result, labels):\n        print(label,':',str(value))\n        \n    if result[1] <= 0.05:\n        print(\"Strong Evidence against null hypothesis(Ho),reject the null hypothesis. Data has no unit root and is stationary\")\n    else:\n        print(\"Weak Evidence against null hypothesis(H1), time series has a unit root, indicating it is non-stationary \")","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:36:02.757482Z","iopub.execute_input":"2021-06-14T13:36:02.757879Z","iopub.status.idle":"2021-06-14T13:36:02.763352Z","shell.execute_reply.started":"2021-06-14T13:36:02.757837Z","shell.execute_reply":"2021-06-14T13:36:02.762398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"adfuller_test(df[\"Sales\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:36:03.822886Z","iopub.execute_input":"2021-06-14T13:36:03.823237Z","iopub.status.idle":"2021-06-14T13:36:03.840901Z","shell.execute_reply.started":"2021-06-14T13:36:03.823206Z","shell.execute_reply":"2021-06-14T13:36:03.839757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Differencing**:\n* Differencing is a popular and widely used data transform for making time series data stationary.\n\n* Differencing can help stabilise the mean of a time series by removing changes in the level of a time series, and therefore eliminating (or reducing) trend and seasonality.\n\n* Differencing shifts ONE/MORE row towards downwards.","metadata":{}},{"cell_type":"code","source":"df[\"Seasonal First Difference\"] = df[\"Sales\"]- df[\"Sales\"].shift(12)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:36:11.951289Z","iopub.execute_input":"2021-06-14T13:36:11.951645Z","iopub.status.idle":"2021-06-14T13:36:11.965722Z","shell.execute_reply.started":"2021-06-14T13:36:11.951597Z","shell.execute_reply":"2021-06-14T13:36:11.964658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:36:12.717152Z","iopub.execute_input":"2021-06-14T13:36:12.717526Z","iopub.status.idle":"2021-06-14T13:36:12.729213Z","shell.execute_reply.started":"2021-06-14T13:36:12.717491Z","shell.execute_reply":"2021-06-14T13:36:12.727928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"adfuller_test(df['Seasonal First Difference'].dropna())","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:36:13.535049Z","iopub.execute_input":"2021-06-14T13:36:13.535407Z","iopub.status.idle":"2021-06-14T13:36:13.553544Z","shell.execute_reply.started":"2021-06-14T13:36:13.535376Z","shell.execute_reply":"2021-06-14T13:36:13.552598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14,6))\nplt.plot(df[\"Seasonal First Difference\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:36:16.959488Z","iopub.execute_input":"2021-06-14T13:36:16.959845Z","iopub.status.idle":"2021-06-14T13:36:17.20893Z","shell.execute_reply.started":"2021-06-14T13:36:16.959813Z","shell.execute_reply":"2021-06-14T13:36:17.207847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now our data is Stationary.**","metadata":{}},{"cell_type":"markdown","source":"------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"## Auto-Correlation and Partial Auto-Correlation","metadata":{}},{"cell_type":"code","source":"from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom pandas.plotting import autocorrelation_plot\nplt.figure(figsize=(14,6))\nautocorrelation_plot(df[\"Sales\"])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:36:23.637544Z","iopub.execute_input":"2021-06-14T13:36:23.637922Z","iopub.status.idle":"2021-06-14T13:36:23.927082Z","shell.execute_reply.started":"2021-06-14T13:36:23.63789Z","shell.execute_reply":"2021-06-14T13:36:23.92551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import statsmodels.api as sm\nfig = plt.figure(figsize=(12,8))\nax1 = fig.add_subplot(211)\nfig2 = sm.graphics.tsa.plot_acf(df['Seasonal First Difference'].iloc[13:],lags=40,ax=ax1)\nax2 = fig.add_subplot(212)\nfig = sm.graphics.tsa.plot_pacf(df['Seasonal First Difference'].iloc[13:],lags=40,ax=ax2)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:36:26.223079Z","iopub.execute_input":"2021-06-14T13:36:26.223421Z","iopub.status.idle":"2021-06-14T13:36:27.453309Z","shell.execute_reply.started":"2021-06-14T13:36:26.223391Z","shell.execute_reply":"2021-06-14T13:36:27.452288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**These graph will give us values of p and q.**\n* Partial AutoCorrelation graph will give p value.\n* While, AutoCorrelation graph will give q value.","metadata":{}},{"cell_type":"markdown","source":"## **6. How to find the order of the AR term (p)** \n\nThe next step is to identify if the model needs any AR terms. We will find out the required number of AR terms by inspecting the Partial Autocorrelation (PACF) plot.\n* Partial autocorrelation can be imagined as the correlation between the series and its lag, after excluding the contributions from the intermediate lags. So, PACF sort of conveys the pure correlation between a lag and the series. This way, we will know if that lag is needed in the AR term or not.\n* Partial autocorrelation of lag (k) of a series is the coefficient of that lag in the autoregression equation of Y.\n* 𝑌𝑡=𝛼0+𝛼1𝑌𝑡−1+𝛼2𝑌𝑡−2+𝛼3𝑌𝑡−3\n\nThat is, suppose, if Y_t is the current series and Y_t-1 is the lag 1 of Y, then the partial autocorrelation of lag 3 (Y_t-3) is the coefficient  𝛼3\nα\n3\n  of Y_t-3 in the above equation.\nNow, we should find the number of AR terms. Any autocorrelation in a stationarized series can be rectified by adding enough AR terms. So, we initially take the order of AR term to be equal to as many lags that crosses the significance limit in the PACF plot.","metadata":{}},{"cell_type":"markdown","source":"-----------------------------","metadata":{}},{"cell_type":"markdown","source":"## ARIMA MODEL\n\nLet’s Break it Down:-\n\n* AR: Autoregression. A model that uses the dependent relationship between an observation and some number of lagged observations.\n\n* I: Integrated. The use of differencing of raw observations in order to make the time series stationary.\n\n* MA: Moving Average. A model that uses the dependency between an observation and a residual error from a moving average model applied to lagged observations.\n\nThe parameters of the ARIMA model are defined as follows:\n\n* p: The number of lag observations included in the model, also called the lag order.\n* d: The number of times that the raw observations are differenced, also called the degree of differencing.\n* q: The size of the moving average window, also called the order of moving average.","metadata":{}},{"cell_type":"code","source":" # For non-seasonal data\n#p=1, d=1, q=0 or 1 depending upon performance\nfrom statsmodels.tsa.arima_model import ARIMA\nmodel = ARIMA(df[\"Sales\"], order=(1,1,1))\nmodel_fit = model.fit()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:36:43.518359Z","iopub.execute_input":"2021-06-14T13:36:43.518907Z","iopub.status.idle":"2021-06-14T13:36:43.65511Z","shell.execute_reply.started":"2021-06-14T13:36:43.518866Z","shell.execute_reply":"2021-06-14T13:36:43.653915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model_fit.summary())","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:36:54.228157Z","iopub.execute_input":"2021-06-14T13:36:54.228529Z","iopub.status.idle":"2021-06-14T13:36:54.252939Z","shell.execute_reply.started":"2021-06-14T13:36:54.228491Z","shell.execute_reply":"2021-06-14T13:36:54.251546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Forecast\"] = model_fit.predict(start=85, end=103, dynamic=True)\nplt.figure(figsize=(14,6))\nplt.plot(df[[\"Sales\",\"Forecast\"]])","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:37:04.7591Z","iopub.execute_input":"2021-06-14T13:37:04.759455Z","iopub.status.idle":"2021-06-14T13:37:05.039343Z","shell.execute_reply.started":"2021-06-14T13:37:04.759422Z","shell.execute_reply":"2021-06-14T13:37:05.038494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-box alert-info\">\nThis model didn't work well because our data is seasonal which cannot be predicted by ARIMA and thus we have to use SARIMA.\n    </div>","metadata":{}},{"cell_type":"markdown","source":"## SARIMA Model\n* Seasonal Autoregressive Integrated Moving Average, SARIMA or Seasonal ARIMA, is an extension of ARIMA that explicitly supports univariate time series data with a seasonal component.\n\n* It adds three new hyperparameters to specify the autoregression (AR), differencing (I) and moving average (MA) for the seasonal component of the series, as well as an additional parameter for the period of the seasonality.\n\n* A seasonal ARIMA model is formed by including additional seasonal terms in the ARIMA.\n\n* The seasonal part of the model consists of terms that are very similar to the non-seasonal components of the model, but they involve backshifts of the seasonal period.","metadata":{}},{"cell_type":"code","source":"import statsmodels.api as sm\nmodel2 = sm.tsa.statespace.SARIMAX(df[\"Sales\"], order=(1,1,1),seasonal_order=(1,1,1,12))\nmodel2_fit = model2.fit()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:37:13.459775Z","iopub.execute_input":"2021-06-14T13:37:13.460349Z","iopub.status.idle":"2021-06-14T13:37:14.327136Z","shell.execute_reply.started":"2021-06-14T13:37:13.460295Z","shell.execute_reply":"2021-06-14T13:37:14.325762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model2_fit.summary())","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:37:19.340289Z","iopub.execute_input":"2021-06-14T13:37:19.340678Z","iopub.status.idle":"2021-06-14T13:37:19.357299Z","shell.execute_reply.started":"2021-06-14T13:37:19.340644Z","shell.execute_reply":"2021-06-14T13:37:19.356082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Forecast_SARIMA\"] = model2_fit.predict(start=90, end=103, dynamic=True)\nplt.figure(figsize=(14,6))\nplt.plot(df[[\"Sales\",\"Forecast_SARIMA\"]])\nplt.legend(labels=[\"Sales\",\"Forecast\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:37:24.04337Z","iopub.execute_input":"2021-06-14T13:37:24.043745Z","iopub.status.idle":"2021-06-14T13:37:24.348095Z","shell.execute_reply.started":"2021-06-14T13:37:24.043713Z","shell.execute_reply":"2021-06-14T13:37:24.346876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-box alert-info\">\nAs we can observe from the graph above, SARIMA model predicted very well.\n    </div>","metadata":{}},{"cell_type":"markdown","source":"--------","metadata":{}},{"cell_type":"markdown","source":"## Forecasting Future Sales","metadata":{}},{"cell_type":"code","source":"from pandas.tseries.offsets import DateOffset\n#Here USING FOR LOOP we are adding some additional data for prediction purpose:\nfuture_dates=[df.index[-1]+ DateOffset(months=x)for x in range(0,24)]\n\n#Convert that list into DATAFRAME:\nfuture_datest_df=pd.DataFrame(index=future_dates[1:],columns=df.columns)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:37:34.645611Z","iopub.execute_input":"2021-06-14T13:37:34.645994Z","iopub.status.idle":"2021-06-14T13:37:34.655348Z","shell.execute_reply.started":"2021-06-14T13:37:34.645964Z","shell.execute_reply":"2021-06-14T13:37:34.654176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"future_datest_df.tail()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:37:35.329201Z","iopub.execute_input":"2021-06-14T13:37:35.329574Z","iopub.status.idle":"2021-06-14T13:37:35.34254Z","shell.execute_reply.started":"2021-06-14T13:37:35.32954Z","shell.execute_reply":"2021-06-14T13:37:35.341256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CONCATENATE THE ORIGINAL AND THE NEWLY CREATED DATASET FOR VISUALIZATION\nfuture_df=pd.concat([df,future_datest_df])","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:37:35.891756Z","iopub.execute_input":"2021-06-14T13:37:35.89212Z","iopub.status.idle":"2021-06-14T13:37:35.89779Z","shell.execute_reply.started":"2021-06-14T13:37:35.89209Z","shell.execute_reply":"2021-06-14T13:37:35.896782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#PREDICT\nfuture_df['Future_forecast'] = model2_fit.predict(start = 104, end = 120, dynamic= True) \nplt.figure(figsize=(14,6))\nplt.plot(future_df[['Sales', 'Future_forecast']])\nplt.legend(labels=[\"Sales\",\"Future Forecasting\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:37:37.168665Z","iopub.execute_input":"2021-06-14T13:37:37.16907Z","iopub.status.idle":"2021-06-14T13:37:37.430017Z","shell.execute_reply.started":"2021-06-14T13:37:37.169033Z","shell.execute_reply":"2021-06-14T13:37:37.428952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-box alert-warning\">\n Hence, we have successfully predicted future seasonal sales for two years.\n    </div>","metadata":{}},{"cell_type":"markdown","source":"## **Auto Arima Forecasting in Python** \n\n* In Python, the pmdarima package provides auto_arima() function which can be used to automate the process of ARIMA Forecasting in Python.\n\n* auto_arima() uses a stepwise approach to search multiple combinations of p,d,q parameters and chooses the best model that has the least AIC.\n\n* We need to install the pmdarima package first.","metadata":{}},{"cell_type":"code","source":"!pip install pmdarima","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:39:47.978479Z","iopub.execute_input":"2021-06-14T13:39:47.978941Z","iopub.status.idle":"2021-06-14T13:39:57.331815Z","shell.execute_reply.started":"2021-06-14T13:39:47.978903Z","shell.execute_reply":"2021-06-14T13:39:57.330775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.tsa.arima_model import ARIMA\n\nimport pmdarima as pm\n\nmodel = pm.auto_arima(df.Sales, start_p=1, start_q=1,\n                      test='adf',       # use adftest to find optimal 'd'\n                      max_p=3, max_q=3, # maximum p and q\n                      m=1,              # frequency of series\n                      d=None,           # let model determine 'd'\n                      seasonal=False,   # No Seasonality\n                      start_P=0, \n                      D=0, \n                      trace=True,\n                      error_action='ignore',  \n                      suppress_warnings=True, \n                      stepwise=True)\n\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:41:52.610447Z","iopub.execute_input":"2021-06-14T13:41:52.610854Z","iopub.status.idle":"2021-06-14T13:41:54.852311Z","shell.execute_reply.started":"2021-06-14T13:41:52.610818Z","shell.execute_reply":"2021-06-14T13:41:54.851174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.plot_diagnostics(figsize=(10,8))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:42:18.589439Z","iopub.execute_input":"2021-06-14T13:42:18.589832Z","iopub.status.idle":"2021-06-14T13:42:19.311153Z","shell.execute_reply.started":"2021-06-14T13:42:18.589795Z","shell.execute_reply":"2021-06-14T13:42:19.309902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Interpretation of plots in plot diagnostics**\n* Standardized residual: The residual errors seem to fluctuate around a mean of zero and have a uniform variance.\n\n* Histogram: The density plot suggest normal distribution with mean slighlty shifted towards right.\n\n* Theoretical Quantiles: Mostly the dots fall perfectly in line with the red line. Any significant deviations would imply the distribution is skewed.\n\n* Correlogram: The Correlogram, (or ACF plot) shows the residual errors are not autocorrelated. The ACF plot would imply that there is some pattern in the residual errors which are not explained in the model. So we will need to look for more X’s (predictors) to the model.\n\nOverall, the model seems to be a good fit. So, let's use it to forecast.","metadata":{}},{"cell_type":"code","source":"# Forecast\nn_periods = 24\nfc, confint = model.predict(n_periods=n_periods, return_conf_int=True)\nindex_of_fc = np.arange(len(df.Sales), len(df.Sales)+n_periods)\n\n# make series for plotting purpose\nfc_series = pd.Series(fc, index=index_of_fc)\nlower_series = pd.Series(confint[:, 0], index=index_of_fc)\nupper_series = pd.Series(confint[:, 1], index=index_of_fc)\n\n# Plot\nplt.plot(df.Sales)\nplt.plot(fc_series, color='darkgreen')\nplt.fill_between(lower_series.index, \n                 lower_series, \n                 upper_series, \n                 color='k', alpha=.15)\n\nplt.title(\"Final Forecast of Usage\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:43:53.312611Z","iopub.execute_input":"2021-06-14T13:43:53.313012Z","iopub.status.idle":"2021-06-14T13:43:53.589303Z","shell.execute_reply.started":"2021-06-14T13:43:53.312976Z","shell.execute_reply":"2021-06-14T13:43:53.588104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SARIMA Model (Auto-ARIMA)","metadata":{}},{"cell_type":"code","source":"import pmdarima as pm\nsmodel = pm.auto_arima(df.Sales, start_p=1, start_q=1,test='adf',\n                         max_p=3, max_q=3, m=12,\n                         start_P=0, seasonal=True,\n                         d=None, D=1, trace=True,\n                         error_action='ignore',  \n                         suppress_warnings=True, \n                         stepwise=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:47:38.11099Z","iopub.execute_input":"2021-06-14T13:47:38.111383Z","iopub.status.idle":"2021-06-14T13:47:46.398097Z","shell.execute_reply.started":"2021-06-14T13:47:38.111349Z","shell.execute_reply":"2021-06-14T13:47:46.396943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(smodel.summary())","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:47:48.173807Z","iopub.execute_input":"2021-06-14T13:47:48.174452Z","iopub.status.idle":"2021-06-14T13:47:48.188718Z","shell.execute_reply.started":"2021-06-14T13:47:48.174414Z","shell.execute_reply":"2021-06-14T13:47:48.187354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Forecast\nn_periods = 200\nfitted, confint = smodel.predict(n_periods=n_periods, return_conf_int=True)\nindex_of_fc = np.arange(len(df.Sales), len(df.Sales)+n_periods)\n\n# make series for plotting purpose\nfitted_series = pd.Series(fitted, index=index_of_fc)\nlower_series = pd.Series(confint[:, 0], index=index_of_fc)\nupper_series = pd.Series(confint[:, 1], index=index_of_fc)\n\n# Plot\nplt.plot(df.Sales)\nplt.plot(fitted_series, color='darkgreen')\nplt.fill_between(lower_series.index, \n                 lower_series, \n                 upper_series, \n                 color='k', alpha=.15)\n\nplt.title(\"SARIMA -Final Forecast of Sales\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:50:56.019282Z","iopub.execute_input":"2021-06-14T13:50:56.019688Z","iopub.status.idle":"2021-06-14T13:50:56.292156Z","shell.execute_reply.started":"2021-06-14T13:50:56.019644Z","shell.execute_reply":"2021-06-14T13:50:56.291231Z"},"trusted":true},"execution_count":null,"outputs":[]}]}