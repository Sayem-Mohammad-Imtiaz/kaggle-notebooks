{"cells":[{"execution_count":null,"outputs":[],"source":"from urllib.request import urlopen\nfrom json import loads\nimport pandas as pd\nfrom itertools import chain\nfrom dask import bag\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"_cell_guid":"e1123138-8e2e-4ef2-9dee-d1a9a2516d10","_uuid":"2212a0934c7903ab3c06ca856405b7205ceced80","collapsed":true},"cell_type":"code"},{"execution_count":null,"outputs":[],"source":"drink_df = pd.read_csv('../input/all_drinks.csv')\ndrink_df.sample(3)","metadata":{"_cell_guid":"d0a5183e-c5ae-41b9-bf28-de76164157ce","_uuid":"a868c0c3d38211945c73b8f0b1a569d66d05b69c"},"cell_type":"code"},{"source":"# Parse the drink names \nThey are the input for our model (this is a simple approach by just counting the letters that show up","metadata":{"_cell_guid":"7fa8fa7c-e1ba-47b6-a177-4034f2ea6c53","_uuid":"6e0ca8001831dc818b62a6ec9ad63bc1a2852718","collapsed":true},"cell_type":"markdown"},{"execution_count":null,"outputs":[],"source":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(analyzer = 'char_wb')\ncv.fit(drink_df['strDrink'].values)\nnew_vocab_dict = {id: word for word,id in cv.vocabulary_.items()}","metadata":{"_cell_guid":"ee82ba99-7440-42be-b806-d396afbc47ba","_uuid":"51b2f4a86b8ed1e5ae76ddf65b297de790631fc2","collapsed":true},"cell_type":"code"},{"execution_count":null,"outputs":[],"source":"cv_mat = cv.transform(drink_df['strDrink'].values)","metadata":{"_cell_guid":"c0df8a46-4154-45ae-a98c-2a234534099b","_uuid":"a9dd9e38ad408f2fb28f97580c328019595d5120","collapsed":true},"cell_type":"code"},{"source":"## Tokenize the names\nHere we translate the names into a tokenized vector so we can feed it to a sequence to sequence model","metadata":{"_cell_guid":"3ca3a733-1fd8-4984-b52e-780fe8c84821","_uuid":"d280d5547c87806938f2a3d976bad68db46d31e0"},"cell_type":"markdown"},{"execution_count":null,"outputs":[],"source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences","metadata":{"_cell_guid":"a518cdb3-71c0-49fc-afad-c75cfdeb7997","_uuid":"9e9d8ccdf28d242a5d7c8f27b466c440c886d830"},"cell_type":"code"},{"execution_count":null,"outputs":[],"source":"str_vec = drink_df['strDrink'].str.lower()\nMAX_NB_WORDS, MAX_SEQUENCE_LENGTH = 5000, 30\ntokenizer = Tokenizer(num_words=MAX_NB_WORDS, char_level=True)\ntokenizer.fit_on_texts(str_vec)\ntrain_sequences = tokenizer.texts_to_sequences(str_vec)\ntrain_data = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))","metadata":{"_cell_guid":"64fd19ee-dede-4940-886f-c6d3a621df00","_uuid":"1fea9a5d1cafc7578f4308b523dcab5dde68cf00"},"cell_type":"code"},{"execution_count":null,"outputs":[],"source":"plt.matshow(train_data)","metadata":{"_cell_guid":"50ea8525-2b59-4170-b026-96347049d1c1","_uuid":"1e78278a4cb3783e018522a9e8d278247b600390"},"cell_type":"code"},{"source":"# Process Ingredients\nThis is what we want to predict so we need to transform it to a reasonable vector","metadata":{"_cell_guid":"b926a062-1449-445e-8266-a70a28fb3b59","_uuid":"e77cddff1d5b7b4cae534a583f24b8f6aa5fbd51"},"cell_type":"markdown"},{"execution_count":null,"outputs":[],"source":"def isempty(x):\n    try:\n        if x is None: \n            return True\n        elif len(x)<1:\n            return True\n        else:\n            return False\n    except:\n        # floating point nans\n        return True\nall_ingred = drink_df[[x for x in drink_df.columns \n                       if 'Ingredient' in x]].apply(lambda c_row: [v.lower() for k,v in c_row.items() if not isempty(v)],1)\nall_ingred[0:3]","metadata":{"_cell_guid":"0c8d1a89-3ec6-4dc4-95bb-428b204aa163","_uuid":"33a4cab25e8e2e0f457a311e24fa61293405b13a"},"cell_type":"code"},{"execution_count":null,"outputs":[],"source":"from sklearn.preprocessing import LabelEncoder\nfrom keras.utils.np_utils import to_categorical\ningred_label = LabelEncoder()\ningred_label.fit(list(chain(*all_ingred.values)))\nprint('Found', len(ingred_label.classes_), 'unique ingredients, ', ingred_label.classes_[0:3])","metadata":{"_cell_guid":"d26f3f18-d557-43ce-9ba2-d343fb6c5a72","_uuid":"784f9194253392a774953c1d64bf551819747822"},"cell_type":"code"},{"source":"Convert each ingredient to a one hot vector and sum them all together","metadata":{"_cell_guid":"e3c74555-ee49-4543-b26b-31e9572ad5ae","_uuid":"74f4108e276917eea4441a8b4f5de4eb64ece207"},"cell_type":"markdown"},{"execution_count":null,"outputs":[],"source":"y_vec = np.stack(all_ingred.map(lambda x: np.sum(to_categorical(ingred_label.transform(x), \n                                        num_classes=len(ingred_label.classes_)),0)),0).clip(0,1)\nplt.matshow(y_vec)","metadata":{"_cell_guid":"5c81fc12-c67b-41f6-beaf-e3922b297f3e","_uuid":"d29263fb7838e29197baecccc8087b5889ff5bb0"},"cell_type":"code"},{"source":"# Prepare Training","metadata":{"_cell_guid":"95e8b660-5747-412d-9fbf-8ab983579ad8","_uuid":"d3183b1aeb6a4df04b0ab8be218f79a6df2965c5"},"cell_type":"markdown"},{"execution_count":null,"outputs":[],"source":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\ntrain_idx, test_idx = train_test_split(range(y_vec.shape[0]), \n                                                    random_state = 12345,\n                                                   train_size = 0.7)\nfrom sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor()\nrf.fit(cv_mat[train_idx], y_vec[train_idx])\npred_vec = rf.predict(cv_mat[test_idx])\n\nprint('Mean Error %2.2f%%' % (100*mean_absolute_error(y_vec[test_idx], pred_vec)))","metadata":{"_cell_guid":"651bcde0-a5ba-4c2a-b860-259e7d6364df","_uuid":"6452ce385f21f5ec3c899f9be64cbc54009ea973"},"cell_type":"code"},{"source":"# Test Case","metadata":{"_cell_guid":"09e05733-bb31-4460-b998-f580baa4ee17","_uuid":"ee3e419cefcecebf314f72a64029e84931a44db5"},"cell_type":"markdown"},{"execution_count":null,"outputs":[],"source":"print('Input Name:', drink_df['strDrink'].values[test_idx[0]])\nprint('Real Ingredients', all_ingred.values[test_idx[0]])\n\nproc_pred = lambda out_pred: sorted([(ingred_label.inverse_transform(idx), out_pred[idx])\n                              for idx in np.where(out_pred>0)[0]], key = lambda x: -x[1])\n\nprint('Predicted Ingredients')\nfor (i,j) in proc_pred(pred_vec[0]):\n    print('%25s\\t\\t%2.2f%%' % (i,100*j))","metadata":{"_cell_guid":"1f13b070-b5a8-40c0-92dd-47ddfa74c542","_uuid":"1f7d6cb0aa7c1104a6ca02f864231d3d96bea378"},"cell_type":"code"},{"execution_count":null,"outputs":[],"source":"print('Input Name:', drink_df['strDrink'].values[test_idx[1]])\nprint('Real Ingredients', all_ingred.values[test_idx[1]])\n\nproc_pred = lambda out_pred: sorted([(ingred_label.inverse_transform(idx), out_pred[idx])\n                              for idx in np.where(out_pred>0)[0]], key = lambda x: -x[1])\n\nprint('Predicted Ingredients')\nfor (i,j) in proc_pred(pred_vec[1]):\n    print('%25s\\t\\t%2.2f%%' % (i,100*j))","metadata":{"_cell_guid":"f620ce4d-995a-4c0d-8337-2359a5f286bf","_uuid":"9fd833d3a046795e083ed27f9944983320527f54"},"cell_type":"code"},{"execution_count":null,"outputs":[],"source":"","metadata":{"_cell_guid":"72c72250-9974-4ce0-a9e8-9e2c639283c0","_uuid":"afe45444321d5158f1530e1987d3bce4c482d36a","collapsed":true},"cell_type":"code"}],"nbformat_minor":1,"nbformat":4,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"mimetype":"text/x-python","pygments_lexer":"ipython3","file_extension":".py","version":"3.6.1","nbconvert_exporter":"python","name":"python","codemirror_mode":{"name":"ipython","version":3}}}}