{"nbformat_minor":1,"metadata":{"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"name":"python","pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.1","file_extension":".py","mimetype":"text/x-python"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"cells":[{"outputs":[],"metadata":{"collapsed":true,"_uuid":"bba7e97634f1c73ed8dbe8ed1df9754384b0ad1b","_cell_guid":"897f7a88-83f1-418d-b727-df3087816e1b","_execution_state":"idle","trusted":true},"cell_type":"code","execution_count":null,"source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nsns.set()"},{"outputs":[],"metadata":{"_uuid":"42fe93946c61507a4f2ed1a2e4c9c2b1dc5bc013","trusted":true},"cell_type":"code","execution_count":null,"source":"dataset = pd.read_csv('../input/wfp_market_food_prices.csv', encoding = 'ISO-8859-1')\ndataset.head()"},{"outputs":[],"metadata":{"_uuid":"f71f099790be81a7065c4b8f98a81ca919758095"},"cell_type":"markdown","execution_count":null,"source":"I want to remove ID columns, I dont trust them!"},{"outputs":[],"metadata":{"_uuid":"787b5eeeb933e360967f9fcc67cff77a38a9d5b5","trusted":true},"cell_type":"code","execution_count":null,"source":"# remove *id columns\nfor i in list(dataset):\n    if i.find('id') >= 0:\n        del dataset[i]\n        \ndataset.head()"},{"outputs":[],"metadata":{"_uuid":"dba1da37ff5637d1e5de9493641daf660729397a","trusted":true},"cell_type":"code","execution_count":null,"source":"# so what is unique and freq countries?\n\ncountry_unique, country_freq = np.unique(dataset['adm0_name'], return_counts = True)\nfor i in range(country_unique.shape[0]):\n    \n    # print unsorted\n    print(country_unique[i], ': ', country_freq[i])"},{"outputs":[],"metadata":{"_uuid":"97ec258340127bef8dd501acbac7c169dd335236","trusted":true},"cell_type":"code","execution_count":null,"source":"# now we want to visualize bar graph for top 10 countries\n# copy actual arrays\n\ncountry_unique_cp = country_unique.copy()\ncountry_freq_cp = country_freq.copy()\n\ncountries_name, countries_freq = [], []\n\nfor i in range(10):\n    index = np.argmax(country_freq_cp)\n    countries_freq.append(country_freq_cp[index])\n    countries_name.append(country_unique_cp[index])\n    country_freq_cp = np.delete(country_freq_cp, index, axis = 0)\n    country_unique_cp = np.delete(country_unique_cp, index, axis = 0)\n    \nplt.figure(figsize = (20, 10))\ny = np.arange(len(countries_name))\nplt.bar(y, countries_freq)\nplt.xticks(y, countries_name)\nplt.ylabel('freq')\nplt.show()"},{"outputs":[],"metadata":{"_uuid":"f0422737533d672c4a9c15d3c995ea15687434ae"},"cell_type":"markdown","execution_count":null,"source":"Rwanda is the highest, India second highest. What? what is Rwanda population? from wikipedia, 11.92 million (2016)\n\nIndia, 1.324 billion (2016)\n\nYou must be joking?"},{"outputs":[],"metadata":{"_uuid":"9278521af7fe9c906ea81f37acbf4f395365138d","trusted":true},"cell_type":"code","execution_count":null,"source":"# so what is unique and freq commoduties?\n\ncommo_unique, commo_freq = np.unique(dataset['cm_name'], return_counts = True)\nfor i in range(country_unique.shape[0]):\n    \n    # print unsorted\n    print(commo_unique[i], ': ', commo_freq[i])"},{"outputs":[],"metadata":{"_uuid":"983cebae7a8b1453f716593a024ecfd623ccde76","trusted":true},"cell_type":"code","execution_count":null,"source":"# now we want to visualize bar graph for top 10 countries\n# copy actual arrays\n\ncommo_unique_cp = commo_unique.copy()\ncommo_freq_cp = commo_freq.copy()\n\ncommo_name, commo_freq = [], []\n\nfor i in range(10):\n    index = np.argmax(commo_freq_cp)\n    commo_freq.append(commo_freq_cp[index])\n    commo_name.append(commo_unique_cp[index])\n    commo_freq_cp = np.delete(commo_freq_cp, index, axis = 0)\n    commo_unique_cp = np.delete(commo_unique_cp, index, axis = 0)\n    \nplt.figure(figsize = (20, 10))\ny = np.arange(len(commo_name))\nplt.bar(y, commo_freq)\nplt.xticks(y, commo_name)\nplt.ylabel('freq')\nplt.show()"},{"outputs":[],"metadata":{"_uuid":"efbd861c3dd1061af4e79e97f68a9e30375007ae"},"cell_type":"markdown","execution_count":null,"source":"Seriously, I never eat Maize or any family of it in entire of my life."},{"outputs":[],"metadata":{"_uuid":"abe7fe4caad3447b6114da720ea7de013ea081fb","trusted":true},"cell_type":"code","execution_count":null,"source":"# how about some countries vs commoduties visualization 2014 data, shall we?\n# i got some trust issues with original unique id, so i will use LabelEncoder\n\n# copy first\ndataset_matrix = dataset[['adm0_name', 'cm_name']].loc[dataset['mp_year'] == 2014].values.copy()\n\ncountry_name = np.unique(dataset_matrix[:, 0])\nfood_name = np.unique(dataset_matrix[:, 1])\n\nfrom sklearn.preprocessing import LabelEncoder\n\n# change into int\nfor i in range(dataset_matrix.shape[1]):\n    dataset_matrix[:, i] = LabelEncoder().fit_transform(dataset_matrix[:, i])\n    \ncountry_id = np.unique(dataset_matrix[:, 0])\nfood_id = np.unique(dataset_matrix[:, 1])\n\nheatmap_2014 = np.zeros([country_id.shape[0], food_id.shape[0]])\nfor i in range(dataset_matrix.shape[0]):\n    x = dataset_matrix[i, 0]\n    y = dataset_matrix[i, 1]\n    heatmap_2014[x, y] += 1\n\n\nplt.figure(figsize = (60, 30))\nsns.heatmap(heatmap_2014, annot = False, fmt = \"d\", linewidths = .5)\nplt.yticks([i for i in range(country_id.shape[0])], country_name, rotation ='horizontal')\nplt.xticks([i for i in range(food_id.shape[0])], food_name, rotation ='vertical')\nplt.show()"},{"outputs":[],"metadata":{"_uuid":"de3af35090beb020007235f7c1849dbb5547f20b"},"cell_type":"markdown","execution_count":null,"source":"Ya, i know it looks very tiny, but you can zoom it up after download it! or maybe use pyplot?"},{"outputs":[],"metadata":{"_uuid":"3703f62a71d37398c2916453c0e47da70844d042","trusted":true},"cell_type":"code","execution_count":null,"source":"# How about we check, how many times each country do some exchange every month?\n\n# i got some trust issues with original unique id, so i will use LabelEncoder\n\n# copy first\ndataset_matrix = dataset[['adm0_name', 'mp_month']].values.copy()\n\ncountry_name = np.unique(dataset_matrix[:, 0])\nmonth_name = np.unique(dataset_matrix[:, 1])\n\nfrom sklearn.preprocessing import LabelEncoder\n\n# change into int\ndataset_matrix[:, 0] = LabelEncoder().fit_transform(dataset_matrix[:, 0])\n    \ncountry_id = np.unique(dataset_matrix[:, 0])\n\nheatmap_2014 = np.zeros([country_id.shape[0], 12])\nfor i in range(dataset_matrix.shape[0]):\n    x = dataset_matrix[i, 0]\n    y = dataset_matrix[i, 1] - 1\n    heatmap_2014[x, y] += 1\n\n\nplt.figure(figsize = (30, 10))\nsns.heatmap(heatmap_2014.T, annot = False, fmt = \"d\", linewidths = .5)\nplt.xticks([i for i in range(country_id.shape[0])], country_name, rotation ='vertical')\nplt.yticks([i for i in range(month_name.shape[0])], month_name, rotation ='horizontal')\nplt.show()"},{"outputs":[],"metadata":{"_uuid":"57ef4024e3541062f00b0025a726134592807a26"},"cell_type":"markdown","execution_count":null,"source":"Oh wow, all countries consistent in every months, I thought the commoduties depend on seasons"},{"outputs":[],"metadata":{"_uuid":"9bb6bbb0b4526ac4f234d25a4b41d4d77e32a963","trusted":true},"cell_type":"code","execution_count":null,"source":"# how about we check, is it the price of commoduties increased every year?\n\nyears = np.unique(dataset['mp_year'])\nprices, freq = [], []\nfor i in range(years.shape[0]):\n    price_in_year = dataset['mp_price'].loc[dataset['mp_year'] == years[i]].values.copy()\n    freq.append(price_in_year.shape[0])\n    prices.append(np.sum(price_in_year))\n    \n# separate the graph because the gap of the values is too huge\nplt.figure(figsize = (40, 10))\nplt.subplot(1, 2, 1)\nxtick = [i for i in range(years.shape[0])]\nplt.plot(xtick, prices, c = 'r', label = 'price')\nplt.legend()\nplt.title('total payment')\nplt.xticks(xtick, years)\nplt.subplot(1, 2, 2)\nplt.plot(xtick, freq, c = 'g', label = 'freq-transaction')\nplt.xticks(xtick, years)\nplt.legend()\nplt.title('total freq-transaction')\nplt.show()"},{"outputs":[],"metadata":{"_uuid":"aaf5631fc55b4a53b6d543d52a0b80f42e624eba"},"cell_type":"markdown","execution_count":null,"source":"During 2015, both graphs on the highest peak, got any issues during 2015?\n\nOr got mortality problem? Maybe data not collected enough?"}],"nbformat":4}