{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np \nimport pandas as pd \nimport tensorflow as tf\nimport keras\nimport matplotlib.pyplot as plt\nimport itertools\nimport pickle\nimport random\n\nfrom PIL import Image\nfrom scipy import interp\nfrom random import randint\nfrom sklearn import metrics, decomposition\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix\n\nfrom keras import backend as K\nfrom keras import callbacks\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Dense, Activation, Dropout, Flatten, BatchNormalization, Input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.metrics import categorical_accuracy\nfrom keras.models import model_from_json, Model, Sequential\nfrom keras.optimizers import *\n\nfrom keras.preprocessing import image\nfrom keras.applications import VGG19\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions, ResNet50\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, TensorBoard, EarlyStopping\nfrom keras.regularizers import l2\nfrom keras.utils.data_utils import Sequence","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# detect and init the TPU\n# tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n# tf.config.experimental_connect_to_cluster(tpu)\n# tf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\n# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nsimple_model_epochs = 40\nsimple_model_bs = 32\n\nresnet_model_epochs = 16\nresnet_model_bs = 64\n\nvgg_model_epochs = 50\nvgg_model_bs = 16","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"filname = '../input/fer2013/fer2013.csv'\nnames = ['emotion','pixels','usage']\nlabel_map = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\nnum_classes = len(label_map)\n\ndf = pd.read_csv('../input/fer2013/fer2013.csv', names=names, na_filter=False)\nim = df['pixels']\n\ndef getData(filname):\n    Y = []\n    X = []\n    first = True\n    for line in open(filname):\n        if first:\n            first = False\n        else:\n            row = line.split(',')\n            Y.append(int(row[0]))\n            X.append([int(p) for p in row[1].split()])\n\n    X, Y = np.array(X) / 255.0, np.array(Y)\n    return X, Y\n\nX, Y = getData(filname)\nnum_class = len(set(Y))\nX = X * 255\n\nN, D = X.shape\nX = X.reshape(N, 48, 48, 1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n\ny_train_flat = y_train\ny_test_flat = y_test\n\ny_train = (np.arange(num_class) == y_train[:, None]).astype(np.float32)\ny_test = (np.arange(num_class) == y_test[:, None]).astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (15, 10))\n\nfor counter, img in enumerate(X_train[:12]):\n    ax = fig.add_subplot(3, 4, counter + 1)\n    ax.imshow(np.asarray(X_train[counter]).reshape(48, 48), cmap = 'gray')\n    plt.title(label_map[Y[counter]])\n    ax.axes.get_xaxis().set_visible(False)\n    ax.axes.get_yaxis().set_visible(False)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(featurewise_center=False,\n        samplewise_center=False,\n        featurewise_std_normalization=False,\n        samplewise_std_normalization=False,\n        zca_whitening=False,\n        zca_epsilon=1e-06,\n        rotation_range=0,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        shear_range=0.,\n        zoom_range=0.,\n        channel_shift_range=0.,\n        fill_mode='nearest',\n        cval=0.,\n        horizontal_flip=True,\n        vertical_flip=False,\n        rescale=None,\n        preprocessing_function=None,\n        data_format=None,\n        validation_split=0.0)\n\ndatagen.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(y_test, \n                          y_pred,\n                          title='Unnormalized confusion matrix'):\n    \n    classes=np.array((\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"))\n    \n    cmap=plt.cm.Blues\n    cm = confusion_matrix(y_test, y_pred)\n    \n    # if normalize:\n        # cm = np.round(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], 2)\n        \n    np.set_printoptions(precision=2)\n        \n    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.min() + (cm.max() - cm.min()) / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True expression')\n    plt.xlabel('Predicted expression')\n    plt.show()\n    plt.savefig(title + '.png')\n    \ndef randomColorGenerator(number_of_colors = 1, seed = 0):\n    '''Generate list of random colors'''\n    np.random.seed(seed)\n    return [\"#\"+''.join([np.random.choice(list('0123456789ABCDEF')) for j in range(6)]) for i in range(number_of_colors)]\n\ndef make_fpr_tpr_auc_dicts(y, probs_list):\n    '''Compute and return the ROC curve and ROC area for each class in dictionaries'''\n    # Dicts\n    fpr = dict()\n    tpr = dict()\n    thresholds = dict()\n    roc_auc = dict()\n    \n    # For test\n    for i in range(num_classes):\n        fpr[i], tpr[i], thresholds[i] = metrics.roc_curve(y[:, i], probs_list[:, i])\n        roc_auc[i] = metrics.auc(fpr[i], tpr[i])\n        \n    # Compute micro-average ROC curve and ROC area\n    fpr[\"micro\"], tpr[\"micro\"], _ = metrics.roc_curve(y.ravel(), probs_list.ravel())\n    roc_auc[\"micro\"] = metrics.auc(fpr[\"micro\"], tpr[\"micro\"])\n    \n    # Compute macro-average ROC curve and ROC area\n    \n    # First aggregate all false positive rates\n    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(num_classes)]))\n    \n    # Then interpolate all ROC curves at this points\n    mean_tpr = np.zeros_like(all_fpr)\n    for i in range(num_classes):\n        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n    \n    # Finally average it and compute AUC\n    mean_tpr /= num_classes\n    \n    fpr[\"macro\"] = all_fpr\n    tpr[\"macro\"] = mean_tpr\n    roc_auc[\"macro\"] = metrics.auc(fpr[\"macro\"], tpr[\"macro\"])\n    \n    return fpr, tpr, thresholds, roc_auc\n\ndef plot_roc_auc_curves(fpr, tpr, roc_auc, xlim=(-0.0025, 0.03), ylim=(0.99, 1.001), seed=0, save_title=None):\n    '''Plot ROC AUC Curves'''\n    fig, axes = plt.subplots(nrows=1, ncols=2, dpi=150, figsize=(10,5))\n    \n    lw = 2\n    axes[0].set_xlabel('False Positive Rate')\n    axes[1].set_xlabel('False Positive Rate')\n    axes[0].set_ylabel('True Positive Rate')\n    \n    if num_classes!=4:\n        class_colors = randomColorGenerator(num_classes, seed)\n    \n    for i in range(num_classes):\n        axes[0].plot(fpr[i], tpr[i], color=class_colors[i], label='{0} ({1:0.2f}%)' ''.format(label_map[i], roc_auc[i]*100))\n        axes[1].plot(fpr[i], tpr[i], color=class_colors[i], lw=lw, label='{0} ({1:0.2f}%)' ''.format(label_map[i], roc_auc[i]*100))\n    \n    axes[0].plot(fpr['micro'], tpr['micro'], label='Micro avg ({:0.2f}%)' ''.format(roc_auc['micro']*100), linestyle=':', color='deeppink')\n    axes[0].plot(fpr['macro'], tpr['macro'], label='Macro avg ({:0.2f}%)' ''.format(roc_auc['macro']*100), linestyle=':', color='navy')\n    axes[0].plot([0, 1], [0, 1], color='k', linestyle='--', lw=0.5)\n    axes[0].scatter(0,1, label='Ideal', s=2)\n    \n    axes[1].plot(fpr['micro'], tpr['micro'], lw=lw, label='Micro avg ({:0.2f}%)'.format(roc_auc['micro']*100), linestyle=':', color='deeppink')\n    axes[1].plot(fpr['macro'], tpr['macro'], lw=lw, label='Macro avg ({:0.2f}%)'.format(roc_auc['macro']*100), linestyle=':', color='navy')\n    axes[1].plot([0, 1], [0, 1], color='k', linestyle='--', lw=0.5)\n    axes[1].scatter(0,1, label='Ideal', s=50)\n    \n    axes[1].set_xlim(xlim)\n    axes[1].set_ylim(ylim)\n    \n    axes[0].grid(True, linestyle='dotted', alpha=1)\n    axes[1].grid(True, linestyle='dotted', alpha=1)\n    \n    axes[0].legend(loc=4)\n    axes[1].legend(loc=4)\n    \n    plt.legend(loc=\"lower right\")\n    plt.tight_layout()\n    fig.savefig(f'{save_title}.pdf', bbox_inches='tight', format='pdf', dpi=200)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DEFINE MODELS","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"### SIMPLE MODEL\n\ndef simple_model():\n    input_shape = (48,48,1)\n    simple_model = Sequential()\n    simple_model.add(Conv2D(6, (5, 5), input_shape=input_shape, padding='same', activation = 'relu'))\n    simple_model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n    simple_model.add(Conv2D(16, (5, 5), padding='same', activation = 'relu'))\n    simple_model.add(Activation('relu'))\n    simple_model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n    simple_model.add(Conv2D(64, (3, 3), activation = 'relu'))\n    simple_model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n    simple_model.add(Flatten())\n    simple_model.add(Dense(128, activation = 'relu'))\n    simple_model.add(Dropout(0.5))\n    \n    simple_model.add(Dense(7, activation = 'softmax'))\n    \n    simple_model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='RMSprop')\n\n    return simple_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### RESNET MODEL\n\nsubtract_pixel_mean = True\nn = 3\n# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\nversion = 1\nif version == 1:\n    depth = n * 6 + 2\nelif version == 2:\n    depth = n * 9 + 2\n\nbatch_size = 16\nepochs = 20\ndata_augmentation = True\nnum_classes = 7\ninput_shape = X_train.shape[1:]\n\ndef resnet_layer(inputs,num_filters=16, kernel_size=3, strides=1, activation='relu', batch_normalization=True, conv_first=True):\n    conv = Conv2D(num_filters,\n                  kernel_size=kernel_size,\n                  strides=strides,\n                  padding='same',\n                  kernel_initializer='he_normal',\n                  kernel_regularizer=l2(1e-4))\n\n    x = inputs\n    if conv_first:\n        x = conv(x)\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n    else:\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n        x = conv(x)\n    return x\n\ndef resnet_v1(input_shape, depth, num_classes=7):\n    if (depth - 2) % 6 != 0:\n        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n   \n    # Start model definition.\n    num_filters = 16\n    num_res_blocks = int((depth - 2) / 6)\n\n    inputs = Input(shape=input_shape)\n    x = resnet_layer(inputs=inputs)\n    \n    # Instantiate the stack of residual units\n    for stack in range(3):\n        for res_block in range(num_res_blocks):\n            strides = 1\n            if stack > 0 and res_block == 0:  # first layer but not first stack\n                strides = 2  # downsample\n            y = resnet_layer(inputs=x,\n                             num_filters=num_filters,\n                             strides=strides)\n            y = resnet_layer(inputs=y,\n                             num_filters=num_filters,\n                             activation=None)\n            if stack > 0 and res_block == 0:  # first layer but not first stack\n                # linear projection residual shortcut connection to match\n                # changed dims\n                x = resnet_layer(inputs=x,\n                                 num_filters=num_filters,\n                                 kernel_size=1,\n                                 strides=strides,\n                                 activation=None,\n                                 batch_normalization=False)\n            x = keras.layers.add([x, y])\n            x = Activation('relu')(x)\n        num_filters *= 2\n\n    # Add classifier on top.\n    # v1 does not use BN after last shortcut connection-ReLU\n    x = AveragePooling2D(pool_size=8)(x)\n    y = Flatten()(x)\n    outputs = Dense(num_classes,activation='softmax',kernel_initializer='he_normal')(y)\n    \n    # Instantiate model.\n    model = Model(inputs=inputs, outputs=outputs)\n    return model\n\nresnet_model = resnet_v1(input_shape=input_shape,depth=depth)\noptimizer = Adam(lr=0.0001)\n\nresnet_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n# resnet_model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SIMPLE MODEL","execution_count":null},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"### SIMPLE MODEL - FIT\n\npath_model='/kaggle/working/simple_model.h5'\nsimple_model=simple_model()\n\n# K.tensorflow_backend.clear_session()\n# with tpu_strategy.scope():\nsimple_model_result = simple_model.fit_generator(datagen.flow(X_train, y_train, batch_size = simple_model_bs),\n                                                     validation_data = (X_test, y_test),\n                                                     epochs = simple_model_epochs,\n                                                     # steps_per_epoch = 4096,\n                                                     verbose = 1,\n                                                     callbacks = [ModelCheckpoint(filepath = path_model)])\n\n# Save trained model to disk\nfilename = 'trained_simple_model.sav'\npickle.dump(simple_model_result, open(filename, 'wb'))\n# loaded_model = pickle.load(open(filename, 'rb'))\n\nsimple_model_scores = simple_model.evaluate(X_test, y_test, verbose=1)\nprint('Simple Model Test Loss:', simple_model_scores[0])\nprint('Simple Model Test Accuracy:', simple_model_scores[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rnd = random.randint(0, X_train.shape[0])\nrnd = 2\ns1 = np.array(X_train[rnd].reshape(48, 48))\nimg = Image.fromarray(s1)\nimg = img.resize((400,400))\n\nplt.title(label_map[Y[rnd]])\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### SIMPLE MODEL - PLOTS\n\nplt.plot(simple_model_result.history['accuracy'])\nplt.plot(simple_model_result.history['val_accuracy'])\nplt.title('Simpe Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\nplt.savefig('Simpe Model Accuracy.png')\n\nplt.plot(simple_model_result.history['loss'])\nplt.plot(simple_model_result.history['val_loss'])\nplt.title('Simpe Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\nplt.savefig('Simpe Model Loss.png')\n\nsimple_model_y_pred_ = simple_model.predict(X_test, verbose=1)\nsimple_model_y_pred = np.argmax(simple_model_y_pred_, axis=1)\nsimple_model_t_te = np.argmax(y_test, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### SIMPLE MODEL - PLOTS\n\nfig = plot_confusion_matrix(y_test=simple_model_t_te,\n                            y_pred=simple_model_y_pred,\n                            title='Simple Model Average Accuracy: ' + str(round(np.sum(simple_model_y_pred == simple_model_t_te)/len(simple_model_t_te), 2)) + '\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### SIMPLE MODEL - PLOTS\n\nfpr, tpr, thresholds, roc_auc = make_fpr_tpr_auc_dicts(y_test, simple_model_y_pred_)\nplot_roc_auc_curves(fpr, tpr, roc_auc, xlim=(0, 0.2), ylim=(0.8, 1), seed=5, save_title='Simple: ROC')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# VGG19 Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#aug_train = ImageDataGenerator(fill_mode=\"nearest\")\n#aug_train.fit(X_train)\n\n#generator_val = ImageDataGenerator()\n#generator_val.fit(X_test)\n\nvgg_conv = VGG19(weights=None, include_top=False, input_shape=(48, 48,1))\n\nvgg_model = Sequential()\nvgg_model.add(vgg_conv)\n\nvgg_model.add(Flatten())\nvgg_model.add(Dense(7,  kernel_initializer='normal', activation='softmax'))\nvgg_model.compile(loss='mean_squared_error', optimizer=Adadelta(), metrics=['accuracy'])\n\naug = ImageDataGenerator(rotation_range=25,\n                         width_shift_range=0.1,\n                         height_shift_range=0.1,\n                         shear_range=0.2,\n                         zoom_range=0.2,\n                         horizontal_flip=True,\n                         fill_mode=\"nearest\")\n\nfilename='model_train_new.csv'\nfilepath=\"Best-weights-my_model-{epoch:03d}-{loss:.4f}-{acc:.4f}.hdf5\"\n\ncsv_log=callbacks.CSVLogger(filename, separator=',', append=False)\ncheckpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\ncallbacks_list = [csv_log,checkpoint]\ncallbacks_list = [csv_log]\n\n# with tpu_strategy.scope():\nvgg_model_result = model.fit_generator(aug.flow(X_train, y_train, batch_size=vgg_model_bs),\n                                       validation_data=(X_test, y_test),\n                                       steps_per_epoch=len(X_train) // vgg_model_bs,\n                                       epochs=vgg_model_epochs,\n                                       verbose=1,\n                                       callbacks = callbacks_list)\n\nvgg_model_scores = vgg_model.evaluate(X_test, y_test, verbose=1)\nprint('VGG Model Test Loss:', vgg_model_scores[0])\nprint('VGG Model Test Accuracy:', vgg_model_scores[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### VGG MODEL - PLOTS\n\nplt.plot(vgg_model_result.history['accuracy'])\nplt.plot(vgg_model_result.history['val_accuracy'])\nplt.title('VGG19 Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\nplt.savefig('VGG19 Model Loss.png')\n\nplt.plot(vgg_model_result.history['loss'])\nplt.plot(vgg_model_result.history['val_loss'])\nplt.title('VGG19 Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\nplt.savefig('VGG19 Model Loss.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### VGG MODEL - PLOTS\n\nvgg_model_y_pred_ = vgg_model.predict(X_test, verbose=1)\nvgg_model_y_pred = np.argmax(vgg_model_y_pred_, axis=1)\nvgg_model_t_te = np.argmax(y_test, axis=1)\n\nfig = plot_confusion_matrix(y_test=vgg_model_t_te, y_pred=vgg_model_y_pred,\n                            title='VGG19 Average Accuracy: ' + str(round(np.sum(vgg_model_y_pred == vgg_model_t_te)/len(vgg_model_t_te), 2)) + '\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### VGG MODEL - PLOTS\n\nfpr, tpr, thresholds, roc_auc = make_fpr_tpr_auc_dicts(y_test, vgg_model_y_pred_)\nplot_roc_auc_curves(fpr, tpr, roc_auc, xlim=(0, 0.2), ylim=(0.8, 1), seed=5, save_title='ROC: VGG19')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RESNET MODEL","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"### RESNET MODEL - FIT\n\nfilepath = '/kaggle/working/resnet_model.h5'\n\n# with tpu_strategy.scope():\nresnet_model_result = resnet_model.fit_generator(datagen.flow(X_train, y_train, batch_size=256), \n                                                 steps_per_epoch=1024,\n                                                 validation_data=(X_test, y_test),\n                                                 epochs=20,\n                                                 verbose=1,\n                                                 workers=4,\n                                                 callbacks=[ModelCheckpoint(filepath=filepath)])\n\n# Save trained model to disk\nfilename = 'trained_resnet_model.sav'\npickle.dump(resnet_model_result, open(filename, 'wb'))\n# loaded_model = pickle.load(open(filename, 'rb'))\n\nresnet_model_scores = resnet_model.evaluate(X_test, y_test, verbose=1)\nprint('ResNet Model Test Loss:', resnet_model_scores[0])\nprint('ResNet Model Test Accuracy:', resnet_model_scores[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### SIMPLE MODEL - PLOTS\n\nplt.plot(resnet_model_result.history['accuracy'])\nplt.plot(resnet_model_result.history['val_accuracy'])\nplt.title('ResNet Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\nplt.savefig('ResNet Model Loss.png')\n\nplt.plot(resnet_model_result.history['loss'])\nplt.plot(resnet_model_result.history['val_loss'])\nplt.title('ResNet Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\nplt.savefig('ResNet Model Loss.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### SIMPLE MODEL - PLOTS\n\nresnet_model_y_pred_ = resnet_model.predict(X_test, verbose=1)\nresnet_model_y_pred = np.argmax(resnet_model_y_pred_, axis=1)\nresnet_model_t_te = np.argmax(y_test, axis=1)\n\nfig = plot_confusion_matrix(y_test=resnet_model_t_te, y_pred=resnet_model_y_pred,\n                            title='ResNet Average Accuracy: ' + str(round(np.sum(resnet_model_y_pred == resnet_model_t_te)/len(resnet_model_t_te), 2)) + '\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### SIMPLE MODEL - PLOTS\n\nfpr, tpr, thresholds, roc_auc = make_fpr_tpr_auc_dicts(y_test, resnet_model_y_pred_)\nplot_roc_auc_curves(fpr, tpr, roc_auc, xlim=(0, 0.2), ylim=(0.8, 1), seed=5, save_title='ROC: ResNet')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}