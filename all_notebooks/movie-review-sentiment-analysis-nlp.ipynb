{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Sentiment Analysis\nWe will use NLTK and Spacy library to cover our case study.\n* Upvote and share our notebook.\n* Like us on facebook: http://www.facebook.com/codemakerz"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport spacy\nimport nltk\nnlp = spacy.load(\"en_core_web_lg\") # Loading english large corpus\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_raw = pd.read_csv(\"/kaggle/input/imdb-movie-review-dataset/movie_data.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we can see we have two columns review and sentiment. Sentiment column tells the sentiment of the text, which mean whether your text is positive or negative. \ne.g; \n* He is a very good boy - This text has a positive sentiment.\n* He is a very bad boy - It has negative sentiment.\n* We will talk about sentiment later in detail. For now lets focus on EDA process."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_raw.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_raw.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_raw.isnull().sum() # We do not have null values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before any analysis, we should have question to ourself. It means what you are going to find in the given data?\nEveryone has different questions. So there is not right way of analysis. What matters is your final output should be correct. There is not a single way to conclude one thing. So before start lets ask some question which we will solve in this analysis.\n* How many positive and negative reviews are there?\n* What are the most common words in positive and negative reviews?\n* Find the sentiment of each review and compare it with existing sentiment value.\n\nAs there are only two columns, So there is no more things to analyse. If you have anything else in your mind which you want or can analyse, comment it below."},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_counts = df_raw[\"sentiment\"].value_counts().reset_index()\ndf_counts.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_counts[\"index\"] = df_counts[\"index\"].apply(lambda x : 'Positive' if x == 1 else 'Negative' )\ndf_counts.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# So we can say that we almost have same number of reviews. That mean we have very good data.\nplt.figure(figsize=(10, 7))\nsns.barplot(data=df_counts, x='index', y='sentiment')\nplt.xlabel(\"Sentiment Type\");\nplt.ylabel(\"Total Count\");\nplt.title(\"Total Postive & Negative Reviews\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# There may be a case where reviews are not null but empty/blank. Lets check for that\n#for i, lb, rv in df_raw.itertuples()[0:10]:\n#    print(i, lb, rv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"empty_review_index = []\nfor i, review, sentiment in df_raw.itertuples():\n    # if review type is string\n    if type(review) == str:\n        #if review is empty space\n        if review.isspace():\n            # Appent its index to the list\n            empty_review_index.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"empty_review_index # So we do not have any empty review","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Positive & Negative Token Count & Frequency Distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will create a function which applies following action on reviews:\n* Remove special characters\n* Remove stop words\n* Tokenization\n* Apply lemmatization"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re # for regular expression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos_token = [] # to save positive tokens\nneg_token = [] # to save negative tokens\ncorpus=[]\nnoun = []\ndef process_reviews(df):\n    for index, reviews, sentiment in df.itertuples():\n        if type(reviews) == str:\n            reviews = re.sub('[^a-zA-Z]', ' ', reviews)\n            reviews = reviews.lower()\n            doc = nlp(reviews)\n            temp = []\n            for token in doc:\n                if not token.text.isspace():\n                    if not token.is_stop and len(token.text) > 2:\n                        if token.pos_ == 'NOUN':\n                            noun.append(token.text)\n                        if sentiment == 1:\n                            pos_token.append(token.text)\n                        else:\n                           \n                            neg_token.append(token.text)\n                        temp.append(token.lemma_)\n                        corpus.append(' '.join(temp))\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_test = df_raw.head(20)\n#df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"process_reviews(df_raw)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# all the positive token list\npos_token[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# all the negative token list\nneg_token[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk import FreqDist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preparing frequency distribution variables\nfreq_pos = FreqDist(pos_token)\nfreq_neg = FreqDist(neg_token)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_pos","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_neg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Top 20 most repeated words in positive comments\nplt.figure(figsize=(15, 10))\nfreq_pos.plot(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# top 20 most repeated words in negative comments\nplt.figure(figsize=(15, 10))\nfreq_neg.plot(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# All the nouns used in our reviews. It will give you an idea like what are the famous keywords?\nnoun[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Word Cloud"},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Most famous nouns used in movie reviews\n\nwordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"black\").generate(' '.join(noun))\nplt.figure(figsize=(12, 10))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sentiment Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import library for sntiment analysis.\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sm = SentimentIntensityAnalyzer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# polarit_Scores acuallly gives one dictionary containing 4 valus. negative, positive, neutral and overall value\n# compound. So you can see that below sentence has 0.4 neutral and 0.6 negative and overall -0.6696.\n# - sign shows it is a negatvie sentence.\nsm.polarity_scores(\"you are so bad\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets try some more sentences. SO below you can see it contains both negative and positive feedback.\n# so nltk is smart enough to undertand it. It actually calculate the score of each word and finally calulates\nprint(sm.polarity_scores(\"Star wars is amazing. But the the picturization is not good.\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now lets see a wierd thing here. I wrote the same sentense as above but score is different. can you say why?\n# Actually if you observer i have capitalize the word AMAZING. So here nltk understands the we want to focus\n# on word amazing. That is why below sentence is more positive than the above one. Lets try to capitalize\n# more words.\nprint(sm.polarity_scores(\"Star wars is AMAZING. But the the picturization is not good.\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Few basic rcommendation\n* Do not remove stop words form your sentence if you want to perform sentiment analysis. it will change the sentiment of the sentence. e.g.\nI do not love you ----remove stop words -----> i love you ( So here we can see a complete different sentiment.\n* Do not change the case of text before performing sentiment analysis as your know I LOVE YOU has more weightage than i love you.\n* Do not remove special character like !!. I HATE YOU !!! has stronger sentiment than i hate you.\n\nI think we understand here how nltk understand the sentiment of words.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets apply sentiment analysis on our reviews.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_raw.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_raw[\"score\"] = df_raw[\"review\"].apply(lambda review : sm.polarity_scores(review))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# extract only compound score\ndf_raw[\"sentiment_score\"] = df_raw[\"score\"].apply(lambda x: x[\"compound\"]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_raw.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now lets change our sentiment_score column to binary value 0 or 1.\ndf_raw[\"sentiment_score\"] = df_raw[\"sentiment_score\"].apply(lambda x: 'pos' if x >= 0 else 'neg') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now lets change our sentiment_score column to binary value 0 or 1.\ndf_raw[\"sentiment\"] = df_raw[\"sentiment\"].apply(lambda x: 'pos' if x == 1 else 'neg') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_raw.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(df_raw[\"sentiment\"], df_raw[\"sentiment_score\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# so we can see we have an accuracy score of 69% which is good in sentiment analysis. Sentiment analysis is not \n# very easy for most of the models as you can not predict srcasm in text. Many people write review as sarcasm,\n# which is very difficult or impossible to predict. example:\n\nsm.polarity_scores('Yaaa.. You said it was a good movie... :/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In above example i wrote a sarcasm followed by a crap face text smiley but for computer program its just a \n# special characted. So here it doesnt understand the sarcasm. That is why because of these kind of exceptions\n# 69% accuracy will be considered as fine number.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Thank you so much.. Upvote if it helps you."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}