{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# import required libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load the dataset\ndataset_train = pd.read_csv(\"/kaggle/input/house-prices-dataset/train.csv\",sep=',')\ndataset_test = pd.read_csv(\"/kaggle/input/house-prices-dataset/test.csv\",sep=',')\ndataset_test[\"SalePrice\"]=-99999\n# Append the test data with train for final result\ndataset = dataset_train.append(dataset_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# See the head of the data\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# See the info of dataset\ndataset.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop the ID column\ndataset.drop(\"Id\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# See the correlation heatmap of the features\nplt.figure(figsize=(20,20))\nsns.heatmap(dataset[dataset.columns[:-1]].corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop the correlated columns\ndataset.drop(\"GarageCars\",axis=1,inplace=True)\ndataset.drop(\"GarageYrBlt\",axis=1,inplace=True)\ndataset.drop(\"1stFlrSF\",axis=1,inplace=True)\ndataset.drop(\"2ndFlrSF\",axis=1,inplace=True)\ndataset.drop(\"BsmtFullBath\",axis=1,inplace=True)\ndataset.drop(\"FullBath\",axis=1,inplace=True)\ndataset.drop(\"HalfBath\",axis=1,inplace=True)\ndataset.drop(\"TotRmsAbvGrd\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find columns which has null values and data type object\ncolumns_missing_data = []\nfor column_name in dataset.columns:\n    if dataset[column_name].isnull().any() and dataset[column_name].dtype==object:\n        columns_missing_data.append(column_name)\n        \nprint(columns_missing_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Columns for which null value will be filled based on existing data ratio\ncol_names_ratio_fill = ['MSZoning','Alley','SaleType']\n\n# Columns for which null value will be filled by NONE\ncol_names_blank_fill = ['Utilities', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature', ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col_name in col_names_blank_fill:\n    dataset[col_name].fillna(\"NONE\",inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill missing Data based on existing data ratio\ndef fill_nan_cols(col_name,value_names,val_counts):\n    \"\"\"This method takes column name,existing values and existing value count \n    and fills the NaN columns with the existing values based on their ratio\"\"\"\n    total_null_rows = dataset[dataset[col_name].isnull()].shape[0]\n    total_nonnull_rows = val_counts.sum()\n    \n    np.random.seed(0)\n    \n    for name,cnt in zip(value_names[:-1],val_counts[:-1]):\n        fill_cnt = int((cnt / total_nonnull_rows) * total_null_rows)\n        na_ind = np.array(dataset[dataset[col_name].isnull()==True][col_name].index)\n        \n        if len(na_ind) > fill_cnt:\n            ind = np.random.choice(na_ind,size = fill_cnt,replace=False)\n            dataset.at[ind,col_name] = name\n    \n    if len(na_ind) > 0:\n        dataset[col_name].fillna(value_names[-1],inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find string columns and fill missing data based on existing data ratio\nfor column_name in col_names_ratio_fill:\n    fill_nan_cols(column_name,np.array(dataset[column_name].value_counts().index),np.array(dataset[column_name].value_counts()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill missing values for numeric columns with Mean\nfor column_name in dataset.columns:\n    if dataset[column_name].isnull().any() and dataset[column_name].dtype!=object:\n        dataset[column_name].fillna(dataset[column_name].mean(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Categorical columns for label encoding\ncategorical_columns = [dataset.columns.get_loc(column_name) for column_name in dataset.columns[:-1] if dataset[column_name].dtype == object]\ncategorical_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seperate the features and target\nX = dataset.iloc[:,:-1].values\ny = dataset.iloc[:,-1].values\ncolumns = dataset.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Categorical columns for OneHotEncoding\ncat_cols_onehot = categorical_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Do the label encoding for all categorical features\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\nfor index in categorical_columns:\n    X[:,index] = label_encoder.fit_transform(X[:,index])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Do OneHotEncoding for categorical features\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\nct = ColumnTransformer([(\"hot\", OneHotEncoder(), categorical_columns)], remainder = 'passthrough')\nX = ct.fit_transform(X).toarray()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\nrobust_scaler = RobustScaler()\nX = robust_scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X = X[y!=-99999]\ntrain_y = y[y!=-99999]\ntest_X = X[y==-99999]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare train and test sets\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(train_X,train_y,test_size=0.2,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create instance of models\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import AdaBoostRegressor\n\n\nlogisregress_regressor = LinearRegression()\nkneighbors_regressor = KNeighborsRegressor()\ndecisiontree_regressor = DecisionTreeRegressor(max_depth=4)\nrandomforest_regressor = RandomForestRegressor()\nsvr_regressor = SVR()\nada_regressor = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train the models with the training data\nlogisregress_regressor.fit(X_train,y_train)\nkneighbors_regressor.fit(X_train,y_train)\ndecisiontree_regressor.fit(X_train,y_train)\nrandomforest_regressor.fit(X_train,y_train)\nsvr_regressor.fit(X_train,y_train)\nada_regressor.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find out predicted value on test data\ny_pred_logisregress = logisregress_regressor.predict(X_test)\ny_pred_kneighbors = kneighbors_regressor.predict(X_test)\ny_pred_decisiontree = decisiontree_regressor.predict(X_test)\ny_pred_randomforest = randomforest_regressor.predict(X_test)\ny_pred_svr = svr_regressor.predict(X_test)\ny_pred_ada = ada_regressor.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find the scored based on different evaluation metric\nfrom sklearn.metrics import mean_squared_error\nscores_df = pd.DataFrame(data=[\"Logistic Regression\",\"K Nearest Neighbor Classifier\",\"Decision Tree Classifier\",\"Random Forest Classifier\",\"Support Vector Classifier\",\"AdaBoost Regressor\"],columns=[\"Model Names\"])\nscores_df[\"Root_Mean_Squared_Error\"] = pd.DataFrame([mean_squared_error(y_test,y_pred_logisregress)**0.5,mean_squared_error(y_test,y_pred_kneighbors),mean_squared_error(y_test,y_pred_decisiontree)**0.5,mean_squared_error(y_test,y_pred_randomforest)**0.5,mean_squared_error(y_test,y_pred_svr)**0.5,mean_squared_error(y_test,y_pred_ada)**0.5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# See the evaluation metrics output\nscores_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"randomforest_regressor.fit(train_X,train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_y_pred = randomforest_regressor.predict(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_result = pd.DataFrame(dataset_test[\"Id\"])\npred_result[\"SalePrice\"] = pd.DataFrame(test_y_pred)\npred_result.to_csv(\"test_pred.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":4}