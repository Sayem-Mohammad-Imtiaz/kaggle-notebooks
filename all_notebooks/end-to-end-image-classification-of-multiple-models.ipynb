{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"If you've time, expand the following cell to read some note. Thanks. ","metadata":{}},{"cell_type":"markdown","source":"**Note**, I'm doing some experiment on some more complex data set in my local. And I was making some note on **some fancy technique** during my experiment and thought to share few things here for [this data set](https://www.kaggle.com/alxmamaev/flowers-recognition). \n\n---\n\nI was making this notebook off line and so I imported my desire pre-trained weights. Please, check out the following to data set. It may come to you handy. :)\n\n- [Pretrained Model Weights (Keras)](https://www.kaggle.com/ipythonx/keras-pretrained-imagenet-weights)\n- [EfficientNet Keras Noisy-Student Weights B0-B7](https://www.kaggle.com/ipythonx/efficientnet-keras-noisystudent-weights-b0b7)\n\nThe [pre-trained model weights](https://www.kaggle.com/ipythonx/keras-pretrained-imagenet-weights) contains almost all the imagenet pre-trained weights. If you love to use it, please check this [starting notebook](https://www.kaggle.com/ipythonx/keras-all-models-weights-loader) too, you'll find it helpful. \n\n\n# Version Update\n\n- Version 1: Evaluate **SeResNeXT50 and EfficientNet B3**\nValidation scores are:\n```\n    - SeResNeXT50    : 0.9117305\n    - EfficientNetB3 : 0.9047619\n```\n- Version 2: Ensemble of **SeResNeXT50 and EfficientNet B3** \nValidation score increased\n```\n    - Ensemble :  0.93147504\n``` ","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"!pip install /kaggle/input/efficientnet-keras-source-code/ -q --no-deps\n!pip install /kaggle/input/keras-pretrained-imagenet-weights/image_classifiers-1.0.0-py3-none-any.whl","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-06T17:44:46.346366Z","iopub.execute_input":"2021-07-06T17:44:46.3471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Content\n\nIt's important to know the content of this notebook, otherwise it may not come helpful to you at the end and waste your time. **If you're new to deep learning and image classification in general, or want to brush up some old experience, you may stay. :)**\n\n- Multi-class Image Classification with `tf.keras` or `keras`\n- Usage of simple `flow_from_directory` data generator \n- Train 2 state-of-the-art models and compute \n    - loss curve, confusion matrix, classification report \n    - roc auc score \n- How to Ensemble these models for better performance. ","metadata":{}},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import os, numpy, random, pandas, seaborn\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n                                        EarlyStopping, ReduceLROnPlateau, \n                                        TensorBoard, CSVLogger)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nimport efficientnet.tfkeras as efn\nfrom classification_models.tfkeras import Classifiers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Set Param","metadata":{}},{"cell_type":"code","source":"# root\ntrain_data_dir = '../input/flowers-recognition/flowers/flowers'\n\n# hyper parameter\nSEED       = 1234\ndim        = 226, 226   # dimensions of our images.\nepochs     = 80         # epochs  \nbatch_size = 16         # batch size\n\ndef seed_all(SEED):\n    tf.random.set_seed(SEED)\n    random.seed(SEED)\n    numpy.random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    \nseed_all(SEED)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Generator","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    validation_split=0.20,\n    horizontal_flip=True)\n\n# flow_from_directory\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=dim,\n    batch_size=batch_size,\n    seed=42, \n    shuffle=True,\n    class_mode='categorical', subset='training')\n\n# flow_from_directory\nvalidation_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=dim,\n    batch_size=batch_size,\n    seed=42,\n    shuffle=False,\n    class_mode='categorical', subset='validation')","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Callbacks","metadata":{}},{"cell_type":"code","source":"# defining some callbacks\ndef Call_Back():\n    # model check point\n    checkpoint = ModelCheckpoint('flowertrainedwg/seresnext.h5', \n                                 monitor = 'val_loss', \n                                 verbose = 0, save_best_only=True, \n                                 mode = 'min',\n                                 save_weights_only = True)\n    \n    csv_logger = CSVLogger('flowerhistory/seresnext.csv')\n\n    # reduce learning rate plateau\n    rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.3,\n                            patience=5, verbose=1, \n                            mode='auto', \n                            epsilon=0.0001)\n    return [checkpoint, rlr, csv_logger]\n\n# calling all callbacks \ncallbacks = Call_Back()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build Model\n\nI will try on `SeResNeXT50` and `EfficientNetB3` model. The following `create_model` method is same for both backbone model.","metadata":{}},{"cell_type":"code","source":"# model arch\ndef create_model(input_dim, base_model):\n    inp = L.Input(input_dim)\n    \n    curr_output   = base_model(inp)\n    curr_output_1 = L.GlobalAveragePooling2D()(curr_output)\n    curr_output_2 = L.GlobalMaxPooling2D()(curr_output)\n    curr_output   = L.concatenate([curr_output_1, curr_output_2])\n\n    curr_output   = L.BatchNormalization()(curr_output)\n    curr_output   = L.Dense(512, activation='elu')(curr_output)\n    curr_output   = L.Dropout(0.5)(curr_output)\n    curr_output   = L.BatchNormalization()(curr_output)\n    curr_output   = L.Dense(252, activation='elu')(curr_output)\n    curr_output   = L.Dropout(0.5)(curr_output)\n    \n    out = L.Dense(5, activation='softmax') (curr_output)\n    model = Model(inp, out)\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model: SeResNeXT50","metadata":{}},{"cell_type":"code","source":"class_wg_root = '/kaggle/input/keras-pretrained-imagenet-weights/'\n\n# backbone: \nSeResNeXT50, preprocess_input = Classifiers.get('seresnext50')\nSRNXT = SeResNeXT50(input_shape=(*dim, 3), include_top=False, weights=None)\nSRNXT.load_weights(class_wg_root + 'seresnext50_imagenet_1000_no_top.h5')\n\n# build model\nmodel = create_model(input_dim=(*dim, 3), base_model = SRNXT)\n\n# compile it.\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.Adam(lr=0.0001),\n              metrics=['accuracy'])\n\n# plot the model structure\nplot_model(model, to_file='model.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**!Training, Inferencing**","metadata":{}},{"cell_type":"code","source":"training = False\n\nif training:\n    # fit the model  \n    model.fit_generator(\n        train_generator,\n        steps_per_epoch=len(train_generator) // batch_size,\n        epochs=epochs,\n        callbacks=callbacks,\n        validation_data=validation_generator,\n        validation_steps=len(validation_generator) // batch_size)\nelse:\n    model.load_weights('../input/flowertrainedwg/seresnext.h5')\n    history = pandas.read_csv('../input/flowerhistory/seresnext.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Learning Curve**","metadata":{}},{"cell_type":"code","source":"plt.style.use(\"seaborn\")\n\ndef plot_log(filename, show=True):\n\n    data = filename\n\n    fig = plt.figure(figsize=(8,10))\n    fig.subplots_adjust(top=0.95, bottom=0.05, right=0.95)\n    fig.add_subplot(211)\n    \n    for key in data.keys():\n        if key.find('loss') >= 0:  # loss\n            plt.plot(data['epoch'].values, data[key].values, label=key)\n    plt.legend()\n    plt.title('Training and Validtion Loss')\n\n    fig.add_subplot(212)\n    for key in data.keys():\n        if key.find('acc') >= 0:  # acc\n            plt.plot(data['epoch'].values, data[key].values, label=key)\n    plt.legend()\n    plt.title('Training and Validation Accuracy')\n\n    if show:\n        plt.show()\n        \n# plt\nplot_log(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Evaluate**","metadata":{}},{"cell_type":"code","source":"validation_generator.reset()\nscores = model.evaluate_generator(validation_generator, \n                                  verbose = False,\n                                  steps=len(validation_generator)) \nprint(\"Accuracy = \", scores[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Confusion Matrix**","metadata":{}},{"cell_type":"code","source":"# set plot figure size for better view\nplt.figure(figsize=(10,7))\n\n# reset the generator\nvalidation_generator.reset()\ny_pred = model.predict_generator(validation_generator, \n                                 steps=len(validation_generator),\n                                 verbose = False)\ny_pred = numpy.argmax(y_pred, axis=1)\n\nconf_mat = confusion_matrix(validation_generator.classes, y_pred)\nseaborn.heatmap(conf_mat, annot=True, fmt=\"d\", cbar = False,  cmap = plt.cm.Blues)\n\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Classification Report**","metadata":{}},{"cell_type":"code","source":"target = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n\nprint('Classification Report')\nprint('Validation Acc: %2.2f%%' %(100*accuracy_score(validation_generator.classes, y_pred)))\nprint(classification_report(validation_generator.classes, y_pred, target_names = target))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**ROC AUC**","metadata":{}},{"cell_type":"code","source":"# set plot figure size\nfig, c_ax = plt.subplots(1,1, figsize = (12, 8))\n\n# function for scoring roc auc score for multi-class\ndef multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n    lb = LabelBinarizer()\n    lb.fit(y_test)\n    y_test = lb.transform(y_test)\n    y_pred = lb.transform(y_pred)\n\n    for (idx, c_label) in enumerate(target):\n        fpr, tpr, thresholds = roc_curve(y_test[:,idx].astype(int), y_pred[:,idx])\n        c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n    c_ax.plot(fpr, fpr, 'b-', label = 'Random Guessing')\n    return roc_auc_score(y_test, y_pred, average=average)\n\nprint('ROC AUC score:', multiclass_roc_auc_score(validation_generator.classes, y_pred))\n\nc_ax.legend()\nc_ax.set_xlabel('False Positive Rate')\nc_ax.set_ylabel('True Positive Rate')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model: EfficientNet B3","metadata":{}},{"cell_type":"code","source":"efn_wg_root   = '/kaggle/input/efficientnet-keras-noisystudent-weights-b0b7/'\n\n# backbone: \nefnet =  efn.EfficientNetB3(include_top=False, input_shape=(*dim, 3), weights=None)\nefnet.load_weights(efn_wg_root + 'efficientnet-b3_noisy-student_notop.h5')\n\n# build model\nmodel = create_model(input_dim=(*dim, 3), base_model = efnet)\n\n# compile it.\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.Adam(lr=0.0001),\n              metrics=['accuracy'])\nmodel.summary()\n\n# plot the model structure\nplot_model(model, to_file='model.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if training:\n    # fit the model  \n    model.fit_generator(\n        train_generator,\n        steps_per_epoch=len(train_generator) // batch_size,\n        epochs=epochs,\n        callbacks=callbacks,\n        validation_data=validation_generator,\n        validation_steps=len(validation_generator) // batch_size)\nelse:\n    model.load_weights('../input/flowertrainedwg/efficient.h5')\n    history = pandas.read_csv('../input/flowerhistory/efficient.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt\nplot_log(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Evaluate**","metadata":{}},{"cell_type":"code","source":"validation_generator.reset()\nscores = model.evaluate_generator(validation_generator, \n                                  verbose = False,\n                                  steps=len(validation_generator)) \nprint(\"Accuracy = \", scores[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Confusion Matrix**","metadata":{}},{"cell_type":"code","source":"# set plot figure size for better view\nplt.figure(figsize=(10,7))\n\n# reset the generator\nvalidation_generator.reset()\ny_pred = model.predict_generator(validation_generator, \n                                 steps=len(validation_generator),\n                                 verbose = False)\ny_pred = numpy.argmax(y_pred, axis=1)\n\nconf_mat = confusion_matrix(validation_generator.classes, y_pred)\nseaborn.heatmap(conf_mat, annot=True, fmt=\"d\", cbar = False,  cmap = plt.cm.Blues)\n\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Classification Report**","metadata":{}},{"cell_type":"code","source":"target = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n\nprint('Classification Report')\nprint('Validation Acc: %2.2f%%' %(100*accuracy_score(validation_generator.classes, y_pred)))\nprint(classification_report(validation_generator.classes, y_pred, target_names = target))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**ROC AUC**","metadata":{}},{"cell_type":"code","source":"# set plot figure size\nfig, c_ax = plt.subplots(1,1, figsize = (12, 8))\n\n# function for scoring roc auc score for multi-class\ndef multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n    lb = LabelBinarizer()\n    lb.fit(y_test)\n    y_test = lb.transform(y_test)\n    y_pred = lb.transform(y_pred)\n\n    for (idx, c_label) in enumerate(target):\n        fpr, tpr, thresholds = roc_curve(y_test[:,idx].astype(int), y_pred[:,idx])\n        c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n    c_ax.plot(fpr, fpr, 'b-', label = 'Random Guessing')\n    return roc_auc_score(y_test, y_pred, average=average)\n\nprint('ROC AUC score:', multiclass_roc_auc_score(validation_generator.classes, y_pred))\n\nc_ax.legend()\nc_ax.set_xlabel('False Positive Rate')\nc_ax.set_ylabel('True Positive Rate')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ensemble (EfficientNetB3 + SeResNeXT50)","metadata":{}},{"cell_type":"code","source":"def ensemble(models, model_input):\n    \n    Models_output=[model(model_input) for model in models]\n    Avg = L.average(Models_output)\n    \n    modelEnsemble = Model(inputs=model_input, outputs=Avg, name='ensemble')\n    modelEnsemble.summary()\n    modelEnsemble.compile(optimizers.Adam(lr=0.0001),\n                          loss='categorical_crossentropy', \n                          metrics=['accuracy'])\n    return modelEnsemble","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_EF = create_model(input_dim=(*dim, 3), base_model = efnet)\nmodel_SE = create_model(input_dim=(*dim, 3), base_model = SRNXT)\n\nmodels = []\n\n# Load weights \nmodel_EF.load_weights('../input/flowertrainedwg/efficient.h5')\nmodels.append(model_EF)\n\nmodel_SE.load_weights('../input/flowertrainedwg/seresnext.h5')\nmodels.append(model_SE)\n\nmodel_input = L.Input(shape=models[0].input_shape[1:])\nensemble_model = ensemble(models, model_input)\n\n# plot the model structure\nplot_model(ensemble_model, to_file='model.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_generator.reset()\nscores = ensemble_model.evaluate_generator(validation_generator, \n                                  verbose = False,\n                                  steps=len(validation_generator)) \nprint(\"Accuracy = \", scores[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ensemble of SeResNeXT50 and EfficientNetB3\n```\n- Confusion Metrix , \n- Classification Report , and \n- ROC AUC Graph\n```","metadata":{}},{"cell_type":"code","source":"# set plot figure size for better view\nplt.figure(figsize=(10,7))\n\n# reset the generator\nvalidation_generator.reset()\ny_pred = ensemble_model.predict_generator(validation_generator, \n                                 steps=len(validation_generator),\n                                 verbose = False)\ny_pred = numpy.argmax(y_pred, axis=1)\n\nconf_mat = confusion_matrix(validation_generator.classes, y_pred)\nseaborn.heatmap(conf_mat, annot=True, fmt=\"d\", cbar = False,  cmap = plt.cm.Blues)\n\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n\nprint('Classification Report')\nprint('Validation Acc: %2.2f%%' %(100*accuracy_score(validation_generator.classes, y_pred)))\nprint(classification_report(validation_generator.classes, y_pred, target_names = target))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set plot figure size\nfig, c_ax = plt.subplots(1,1, figsize = (12, 8))\n\n# function for scoring roc auc score for multi-class\ndef multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n    lb = LabelBinarizer()\n    lb.fit(y_test)\n    y_test = lb.transform(y_test)\n    y_pred = lb.transform(y_pred)\n\n    for (idx, c_label) in enumerate(target):\n        fpr, tpr, thresholds = roc_curve(y_test[:,idx].astype(int), y_pred[:,idx])\n        c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n    c_ax.plot(fpr, fpr, 'b-', label = 'Random Guessing')\n    return roc_auc_score(y_test, y_pred, average=average)\n\nprint('ROC AUC score:', multiclass_roc_auc_score(validation_generator.classes, y_pred))\n\nc_ax.legend()\nc_ax.set_xlabel('False Positive Rate')\nc_ax.set_ylabel('True Positive Rate')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"End for Now. ","metadata":{}}]}