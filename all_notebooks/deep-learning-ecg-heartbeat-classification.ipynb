{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Load Dataset\ndf_train = pd.read_csv(\"../input/ecgmitbit/mitbih_train.csv/mitbih_train.csv\", header=None)\ndf_test = pd.read_csv(\"../input/ecgmitbit/mitbih_test.csv/mitbih_test.csv\", header=None)\ndf_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#show one data\nplt.plot(df_train.iloc[0,:186])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(df_test.iloc[0,:186])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Equilibre","metadata":{}},{"cell_type":"code","source":"# plot the circle of value counts in dataset\ndef plot_equilibre(equilibre):\n    plt.figure(figsize=(10,10))\n    my_circle=plt.Circle( (0,0), 0.7, color='white')\n    plt.pie(equilibre, labels=['n','q','v','s','f'], colors=['red','green','blue','skyblue','orange'],autopct='%1.1f%%')\n    p=plt.gcf()\n    p.gca().add_artist(my_circle)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_train[187].value_counts())\n\nplot_equilibre(df_train[187].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_test[187].value_counts())\n\nplot_equilibre(df_test[187].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare Dataset","metadata":{}},{"cell_type":"code","source":"X_train = df_train.values[:, :-1]\ny_train = df_train.values[:, -1].astype(int)\n\nX_test  = df_test.values[:, :-1]\ny_test  = df_test.values[:, -1].astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# show data","metadata":{}},{"cell_type":"code","source":"# plot one ECG for each category\nC0 = np.argwhere(y_train == 0).flatten()\nC1 = np.argwhere(y_train == 1).flatten()\nC2 = np.argwhere(y_train == 2).flatten()\nC3 = np.argwhere(y_train == 3).flatten()\nC4 = np.argwhere(y_train == 4).flatten()\n\nx = np.arange(0, 187)*8/1000\n\nplt.figure(figsize=(20,6))\nplt.plot(x, X_train[C0, :][0], label=\"Normal\")\nplt.plot(x, X_train[C1, :][0], label=\"Artial Premature\")\nplt.plot(x, X_train[C2, :][0], label=\"Premature ventricular contraction\")\nplt.plot(x, X_train[C3, :][0], label=\"Fusion of ventricular and normal\")\nplt.plot(x, X_train[C4, :][0], label=\"Fusion of paced and normal\")\nplt.legend()\nplt.title(\"1-beat ECG for every category\", fontsize=20)\nplt.ylabel(\"Amplitude\", fontsize=15)\nplt.xlabel(\"Time (ms)\", fontsize=15)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = np.expand_dims(X_train, 2)\nX_test = np.expand_dims(X_test, 2)\n\nprint(X_train.shape)\nprint(X_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import utils\ny_train = utils.to_categorical(y_train)\ny_test  = utils.to_categorical(y_test)\n\nprint(y_train.shape)\nprint(y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom IPython.display import Image\nImage(\"../input/structuremodel/strucure.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_obs, feature, depth = X_train.shape\nnum_classes= 5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build Model\nfrom tensorflow.keras import models, layers, optimizers, callbacks\n\ninputs = layers.Input(shape=(feature,depth))\nC   = layers.Conv1D(filters=32, kernel_size=5, strides=1)(inputs)\n\nC11 = layers.Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(C)\nA11 = layers.Activation(\"relu\")(C11)\nC12 = layers.Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A11)\nS11 = layers.Add()([C12, C])\nA12 = layers.Activation(\"relu\")(S11)\nM11 = layers.MaxPooling1D(pool_size=5, strides=2)(A12)\n\n\nC21 = layers.Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M11)\nA21 = layers.Activation(\"relu\")(C21)\nC22 = layers.Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A21)\nS21 = layers.Add()([C22, M11])\nA22 = layers.Activation(\"relu\")(S11)\nM21 = layers.MaxPooling1D(pool_size=5, strides=2)(A22)\n\n\nC31 = layers.Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M21)\nA31 = layers.Activation(\"relu\")(C31)\nC32 = layers.Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A31)\nS31 = layers.Add()([C32, M21])\nA32 = layers.Activation(\"relu\")(S31)\nM31 = layers.MaxPooling1D(pool_size=5, strides=2)(A32)\n\n\nC41 = layers.Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M31)\nA41 = layers.Activation(\"relu\")(C41)\nC42 = layers.Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A41)\nS41 = layers.Add()([C42, M31])\nA42 = layers.Activation(\"relu\")(S41)\nM41 = layers.MaxPooling1D(pool_size=5, strides=2)(A42)\n\n\nC51 = layers.Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M41)\nA51 = layers.Activation(\"relu\")(C51)\nC52 = layers.Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A51)\nS51 = layers.Add()([C52, M41])\nA52 = layers.Activation(\"relu\")(S51)\nM51 = layers.MaxPooling1D(pool_size=5, strides=2)(A52)\n\nF1  = layers.Flatten()(M51)\n\nD1  = layers.Dense(32)(F1)\nA6  = layers.Activation(\"relu\")(D1)\nD2  = layers.Dense(32)(A6)\n\noutputs = layers.Dense(num_classes, activation=\"softmax\")(D2)\n\nmodel = models.Model(inputs=inputs, outputs=outputs)\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile Model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Model","metadata":{}},{"cell_type":"code","source":"batch_size = 100\nnum_epochs = 10 ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train Model\nhistory = model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_data=(X_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save Model","metadata":{}},{"cell_type":"code","source":"# Save Model\nmodels.save_model(model, 'ecg_arrhythmia.hdf5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Model","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\n\nlabels = [\"Normal\",\n          \"Artial Premature\",\n          \"Premature ventricular contraction\",\n          \"Fusion of ventricular and normal\",\n          \"Fusion of paced and normal\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test Model\npredY = model.predict(X_test)\ny_pred = np.argmax(predY,axis=1)\ny_actual = np.argmax(y_test,axis=1)\ncm = confusion_matrix(y_actual, y_pred)\nprint(cm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_actual, y_pred, target_names=labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}