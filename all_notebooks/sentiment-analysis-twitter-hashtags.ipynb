{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/covid19-india-sentiment-analysis/COVID-19_Sentiments.csv')\ntest = pd.read_csv('../input/covid19-india-sentiment-analysis/COVID-19_Sentiments.csv')\ntest.drop(['Text_Id'], axis = 1, inplace = True)\ntrain.drop(['Text_Id'], axis = 1, inplace = True)\ntest.drop(['Date'], axis = 1, inplace = True)\ntrain.drop(['Date'], axis = 1, inplace = True)\n\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\nimport matplotlib.pyplot as plt\ntxt = \" \".join(text for text in test['Text'])\n\nwordcloud = WordCloud(max_font_size = 100, max_words = 50, background_color = 'yellow').generate(txt)\n\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nimport re\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\n\ntest = pd.read_csv('../input/covid19-india-sentiment-analysis/COVID-19_Sentiments.csv')\nstop_words = stopwords.words('english')\nstop_words.append('@user')\n\n\ntxt = \" \".join(text for text in test['Text'])\n\nprint('before -- ',len(txt))\ntxt = txt.split()\nred_txt = []\nfor i in (range(len(txt))):\n    if txt[i] not in stop_words and len(txt[i])>3:\n        red_txt.append(txt[i])\nprint('After===',len(red_txt))\nred_txt = ' '.join(red_txt)\nred_txt = red_txt.split()\n\nhashtags = []\nfor i in red_txt:\n    ht = re.findall(r\"#(\\w+)\", i)\n    hashtags.append(ht)\nhashtags\n\ncomments = sum(hashtags,[])\nfreq = nltk.FreqDist(comments)\nfreq","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({'tag' : list(freq.keys()),\n                  'counts' : list(freq.values())\n                  })\ntop10 = df.nlargest(10, 'counts')\ntop10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(16,5))\nax = sns.barplot(data=top10, x= \"tag\", y = \"counts\")\nax.set(ylabel = 'counts')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top80 = df.nlargest(25, 'counts')\nwords = ' '.join(words for words in top80['tag'])\nwordcloud = WordCloud(max_font_size = 100, max_words = 50, background_color = 'orange').generate(words)\nplt.figure(figsize = (12, 6))\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}