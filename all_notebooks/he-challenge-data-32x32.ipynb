{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_csv(\"../input/flower-recognition-he/he_challenge_data/data/train.csv\")\ntest=pd.read_csv(\"../input/flower-recognition-he/he_challenge_data/data/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":">>> import numpy as np\n>>> import cv2\n>>> img = cv2.imread('../input/flower-recognition-he/he_challenge_data/data/train/0.jpg')\nimport matplotlib.pyplot as plt\nprint(img.shape)\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image \ndef rewind1(image_path,dataset,desired_size=32):\n    img=cv2.imread(f\"../input/flower-recognition-he/he_challenge_data/data/{dataset}/{image_path}.jpg\")\n    img=cv2.resize(img,(32,)*2).astype('uint8')\n   # img=Image.open(\"../input/flower-recognition-he/he_challenge_data/data/{dataset}/{image_path}.jpg\")\n   # img=img.resize((32,32))\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image \ndef rewind2(image_path,dataset,desired_size=64):\n    img=cv2.imread(f\"../input/flower-recognition-he/he_challenge_data/data/{dataset}/{image_path}.jpg\")\n    img=cv2.resize(img,(64,)*2).astype('uint8')\n   # img=Image.open(\"../input/flower-recognition-he/he_challenge_data/data/{dataset}/{image_path}.jpg\")\n   # img=img.resize((32,32))\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image \ndef rewind3(image_path,dataset,desired_size=64):\n    img=cv2.imread(f\"../input/flower-recognition-he/he_challenge_data/data/{dataset}/{image_path}.jpg\")\n    img=cv2.resize(img,(128,)*2).astype('uint8')\n   # img=Image.open(\"../input/flower-recognition-he/he_challenge_data/data/{dataset}/{image_path}.jpg\")\n   # img=img.resize((32,32))\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image \ndef rewind4(image_path,dataset,desired_size=64):\n    img=cv2.imread(f\"../input/flower-recognition-he/he_challenge_data/data/{dataset}/{image_path}.jpg\")\n    img=cv2.resize(img,(256,)*2).astype('uint8')\n   # img=Image.open(\"../input/flower-recognition-he/he_challenge_data/data/{dataset}/{image_path}.jpg\")\n   # img=img.resize((32,32))\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_resized_images_32=[]\n# test_resized_images_32=[]\n# for img_id in train[\"image_id\"]:\n#     train_resized_images_32.append(rewind1(img_id,'train'))\n# for img_id in test[\"image_id\"]:\n#     test_resized_images_32.append(rewind1(img_id,'test')) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_resized_images_64=[]\n# test_resized_images_64=[]\n# for img_id in train[\"image_id\"]:\n#     train_resized_images_64.append(rewind2(img_id,'train'))\n# for img_id in test[\"image_id\"]:\n#     test_resized_images_64.append(rewind2(img_id,'test')) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_resized_images_128=[]\n# test_resized_images_128=[]\n# for img_id in train[\"image_id\"]:\n#     train_resized_images_128.append(rewind3(img_id,'train'))\n# for img_id in test[\"image_id\"]:\n#     test_resized_images_128.append(rewind3(img_id,'test'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_resized_images_256=[]\ntest_resized_images_256=[]\nfor img_id in train[\"image_id\"]:\n    train_resized_images_256.append(rewind4(img_id,'train'))\nfor img_id in test[\"image_id\"]:\n    test_resized_images_256.append(rewind4(img_id,'test'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train_32=np.stack(train_resized_images_32)\n# X_test_32=np.stack(test_resized_images_32)\n# X_train_64=np.stack(train_resized_images_64)\n# X_test_64=np.stack(test_resized_images_64)\n# X_train_128=np.stack(train_resized_images_128)\n# X_test_128=np.stack(test_resized_images_128)\nX_train_256=np.stack(train_resized_images_256)\nX_test_256=np.stack(test_resized_images_256)\ny=train['category']\nY_train=pd.get_dummies(y,columns=[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_test_256.shape,\"     \",X_train_256.shape,\"     \",Y_train.shape,\"      \")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# np.save(\"X_train_32.npy\",X_train_32)\n# np.save(\"X_test_32.npy\",X_test_32)\n# np.save(\"X_test_64.npy\",X_test_64)\n# np.save(\"X_train_64.npy\",X_train_64)\n# np.save(\"X_test_128.npy\",X_test_128)\n# np.save(\"X_train_128.npy\",X_train_128)\nnp.save(\"X_test_256.npy\",X_test_256)\nnp.save(\"X_train_256.npy\",X_train_256)\nY_train.to_csv('Y_train.csv')\nnp.save(\"Y_train_np.npy\",Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k=1000\nplt.imshow(X_train_256[k])\nprint(train['category'][k])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yy=train['category']\nyy=pd.get_dummies(yy,columns=['category'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# yy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kk=yy.idxmax( axis=1, skipna=True)\n# kk","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales = [{1},{2},{3},{10}]\ndf = pd.DataFrame(sales)\ndf = pd.get_dummies(df, columns=[0])\n# y=df['Mar'].argmax(axis=1)\nkk=df.idxmax( axis=1, skipna=True)\nprint(kk)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}