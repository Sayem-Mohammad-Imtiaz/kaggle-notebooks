{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport pylab as pl\nimport scipy.optimize as opt\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline \nimport matplotlib.pyplot as plt\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-05T13:18:05.232375Z","iopub.execute_input":"2021-07-05T13:18:05.232799Z","iopub.status.idle":"2021-07-05T13:18:05.257225Z","shell.execute_reply.started":"2021-07-05T13:18:05.232731Z","shell.execute_reply":"2021-07-05T13:18:05.256115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.Import Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/heart-attack-analysis-prediction-dataset/heart.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:18:05.259018Z","iopub.execute_input":"2021-07-05T13:18:05.259631Z","iopub.status.idle":"2021-07-05T13:18:05.277511Z","shell.execute_reply.started":"2021-07-05T13:18:05.259581Z","shell.execute_reply":"2021-07-05T13:18:05.276656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Visualization","metadata":{}},{"cell_type":"markdown","source":"### Check Tableau repo at: https://public.tableau.com/app/profile/saadeddine.loughzali/viz/HeartAttackProject-Analysis/CasesSummary","metadata":{}},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:18:05.278939Z","iopub.execute_input":"2021-07-05T13:18:05.279399Z","iopub.status.idle":"2021-07-05T13:18:05.316912Z","shell.execute_reply.started":"2021-07-05T13:18:05.279366Z","shell.execute_reply":"2021-07-05T13:18:05.316066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Pre-processing","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Convert Categorical features to numerical values","metadata":{}},{"cell_type":"code","source":"cat_cols = ['sex','exng','caa','cp','fbs','restecg','slp','thall']\ncon_cols = [\"age\",\"trtbps\",\"chol\",\"thalachh\",\"oldpeak\"]\noutput_col = [\"output\"]","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:18:05.318206Z","iopub.execute_input":"2021-07-05T13:18:05.31865Z","iopub.status.idle":"2021-07-05T13:18:05.322894Z","shell.execute_reply.started":"2021-07-05T13:18:05.318618Z","shell.execute_reply":"2021-07-05T13:18:05.321926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2 One Hot Encoding","metadata":{}},{"cell_type":"code","source":"dfc = df\n\ndfc = pd.get_dummies(dfc, columns = cat_cols, drop_first = True)\n\nX = dfc.drop(['output'],axis=1)\ny = dfc[['output']]","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:18:05.324219Z","iopub.execute_input":"2021-07-05T13:18:05.324669Z","iopub.status.idle":"2021-07-05T13:18:05.356553Z","shell.execute_reply.started":"2021-07-05T13:18:05.324637Z","shell.execute_reply":"2021-07-05T13:18:05.355207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.3 Feature Selection","metadata":{}},{"cell_type":"markdown","source":"### 3.4 Normalize Data","metadata":{}},{"cell_type":"markdown","source":"Data Standardization give data zero mean and unit variance (technically should be done after train test split)","metadata":{}},{"cell_type":"markdown","source":"# 4. Classification","metadata":{}},{"cell_type":"markdown","source":"let's build an accurate model. Then use the test set to report the accuracy of the model\nlet's try the following algorithms:\n\n*   K Nearest Neighbor(KNN)\n*   Decision Tree\n*   Support Vector Machine\n*   Logistic Regression","metadata":{}},{"cell_type":"markdown","source":"### Train / Test Split","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:18:05.35809Z","iopub.execute_input":"2021-07-05T13:18:05.358518Z","iopub.status.idle":"2021-07-05T13:18:05.369298Z","shell.execute_reply.started":"2021-07-05T13:18:05.3584Z","shell.execute_reply":"2021-07-05T13:18:05.368177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.1. Logistic Regression","metadata":{}},{"cell_type":"markdown","source":"### 4.1.1 Modeling and Predicting","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nLR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\nLR","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:18:05.370869Z","iopub.execute_input":"2021-07-05T13:18:05.371243Z","iopub.status.idle":"2021-07-05T13:18:05.394676Z","shell.execute_reply.started":"2021-07-05T13:18:05.371212Z","shell.execute_reply":"2021-07-05T13:18:05.393592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yhat = LR.predict(X_test)\nyhat","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:18:05.397929Z","iopub.execute_input":"2021-07-05T13:18:05.398307Z","iopub.status.idle":"2021-07-05T13:18:05.40813Z","shell.execute_reply.started":"2021-07-05T13:18:05.398268Z","shell.execute_reply":"2021-07-05T13:18:05.406882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.1.2 Metrics","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import jaccard_score\njaccard_score(y_test, yhat,pos_label=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:18:05.410082Z","iopub.execute_input":"2021-07-05T13:18:05.410481Z","iopub.status.idle":"2021-07-05T13:18:05.422055Z","shell.execute_reply.started":"2021-07-05T13:18:05.410432Z","shell.execute_reply":"2021-07-05T13:18:05.420792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\nprint(confusion_matrix(y_test, yhat, labels=[1,0]))","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:18:05.42374Z","iopub.execute_input":"2021-07-05T13:18:05.424081Z","iopub.status.idle":"2021-07-05T13:18:05.440825Z","shell.execute_reply.started":"2021-07-05T13:18:05.424049Z","shell.execute_reply":"2021-07-05T13:18:05.439688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, yhat, labels=[1,0])\nnp.set_printoptions(precision=2)\n\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['output=1','output=0'],normalize= False,  title='Confusion matrix')","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:18:05.442157Z","iopub.execute_input":"2021-07-05T13:18:05.442601Z","iopub.status.idle":"2021-07-05T13:18:05.732826Z","shell.execute_reply.started":"2021-07-05T13:18:05.442554Z","shell.execute_reply":"2021-07-05T13:18:05.731631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2 K Nearest Neighbor(KNN)\n","metadata":{}},{"cell_type":"markdown","source":"### 4.2.1 Modeling, Predicting and metrics","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:18:05.734521Z","iopub.execute_input":"2021-07-05T13:18:05.73501Z","iopub.status.idle":"2021-07-05T13:18:05.817349Z","shell.execute_reply.started":"2021-07-05T13:18:05.73496Z","shell.execute_reply":"2021-07-05T13:18:05.81613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k = 4\n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\nneigh","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:18:05.819136Z","iopub.execute_input":"2021-07-05T13:18:05.819661Z","iopub.status.idle":"2021-07-05T13:18:05.838276Z","shell.execute_reply.started":"2021-07-05T13:18:05.819601Z","shell.execute_reply":"2021-07-05T13:18:05.836594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yhat = neigh.predict(X_test)\nyhat","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:18:05.840125Z","iopub.execute_input":"2021-07-05T13:18:05.84068Z","iopub.status.idle":"2021-07-05T13:18:05.867636Z","shell.execute_reply.started":"2021-07-05T13:18:05.840629Z","shell.execute_reply":"2021-07-05T13:18:05.866036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Ks = 50\nmean_acc = np.zeros((Ks-1))\nstd_acc = np.zeros((Ks-1))\n\nfor n in range(1,Ks):\n    \n    #Train Model and Predict  \n    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train.values.ravel())\n    yhat=neigh.predict(X_test)\n    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n\n    yhat=yhat.reshape(61,1)\n    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n\nmean_acc\n\n#Best results for K=11 then K= 12 13 14 then K=6","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:18:05.870495Z","iopub.execute_input":"2021-07-05T13:18:05.871437Z","iopub.status.idle":"2021-07-05T13:18:06.664008Z","shell.execute_reply.started":"2021-07-05T13:18:05.871372Z","shell.execute_reply":"2021-07-05T13:18:06.662793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.3 Decision Tree","metadata":{}},{"cell_type":"markdown","source":"### 4.1.1 Modeling and Predicting","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n#X_train, X_test, y_train, y_test","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:18:06.66587Z","iopub.execute_input":"2021-07-05T13:18:06.666644Z","iopub.status.idle":"2021-07-05T13:18:06.711782Z","shell.execute_reply.started":"2021-07-05T13:18:06.666594Z","shell.execute_reply":"2021-07-05T13:18:06.710601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"haTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\nhaTree # it shows the default parameters","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:18:06.713763Z","iopub.execute_input":"2021-07-05T13:18:06.714631Z","iopub.status.idle":"2021-07-05T13:18:06.723017Z","shell.execute_reply.started":"2021-07-05T13:18:06.714572Z","shell.execute_reply":"2021-07-05T13:18:06.721869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"haTree.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:18:06.72494Z","iopub.execute_input":"2021-07-05T13:18:06.725931Z","iopub.status.idle":"2021-07-05T13:18:06.746096Z","shell.execute_reply.started":"2021-07-05T13:18:06.725868Z","shell.execute_reply":"2021-07-05T13:18:06.744775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predTree = haTree.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:18:06.748238Z","iopub.execute_input":"2021-07-05T13:18:06.749137Z","iopub.status.idle":"2021-07-05T13:18:06.758644Z","shell.execute_reply.started":"2021-07-05T13:18:06.749076Z","shell.execute_reply":"2021-07-05T13:18:06.757413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"DecisionTrees's Accuracy: \", metrics.accuracy_score(y_test, predTree))","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:21:27.609447Z","iopub.execute_input":"2021-07-05T13:21:27.609867Z","iopub.status.idle":"2021-07-05T13:21:27.616185Z","shell.execute_reply.started":"2021-07-05T13:21:27.609825Z","shell.execute_reply":"2021-07-05T13:21:27.615048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.4 Support Vector Machine","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = SVC(kernel='linear', C=1, random_state=42).fit(X_train,y_train)\n\ny_pred = clf.predict(X_test)\n\nprint(\"SVM accuracy score: \", accuracy_score(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-07-05T13:19:44.412067Z","iopub.execute_input":"2021-07-05T13:19:44.412423Z","iopub.status.idle":"2021-07-05T13:19:44.857558Z","shell.execute_reply.started":"2021-07-05T13:19:44.412391Z","shell.execute_reply":"2021-07-05T13:19:44.856309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"markdown","source":"## Highest scores:\n#### Logistic Regression: 0.72\n#### KNN: 0,75 K=11\n#### Decision Tree: 0,67\n#### SVM: 0,85","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}