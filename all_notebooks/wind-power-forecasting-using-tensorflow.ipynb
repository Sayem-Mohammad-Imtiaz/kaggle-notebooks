{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Aim: The aim of this notebook is to predict wind power that could be generated from the windmill for the next 15 days**\n\n## Approach:\n\nThis is a learning project, where I want to use TensorFlow for doing Time Series Project. \n\nAlgorithms tried:\n1. ","metadata":{"id":"3ft6IxvKVtV_"}},{"cell_type":"markdown","source":"## Import statements","metadata":{"id":"r_lhWw6tTL1M"}},{"cell_type":"code","source":"import os\nimport datetime\n\nimport IPython\nimport IPython.display\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\n\nmpl.rcParams['figure.figsize'] = (8, 6)\nmpl.rcParams['axes.grid'] = False\n\n# to display all columns\npd.options.display.max_columns = None\npd.options.display.max_rows = None","metadata":{"id":"-U1YqIXoV-RI","execution":{"iopub.status.busy":"2021-06-14T09:44:27.688978Z","iopub.execute_input":"2021-06-14T09:44:27.689291Z","iopub.status.idle":"2021-06-14T09:44:33.115451Z","shell.execute_reply.started":"2021-06-14T09:44:27.689258Z","shell.execute_reply":"2021-06-14T09:44:33.11437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read the data","metadata":{"id":"eRiW4_Y1Q_X5"}},{"cell_type":"code","source":"# read the data\ndata = pd.read_csv('../input/wind-power-forecasting/Turbine_Data.csv')\ndata.head()","metadata":{"id":"LF6lGzmWbSnK","outputId":"50bb751c-e748-474b-a638-999f73272682","execution":{"iopub.status.busy":"2021-06-14T09:44:33.12014Z","iopub.execute_input":"2021-06-14T09:44:33.1205Z","iopub.status.idle":"2021-06-14T09:44:33.827821Z","shell.execute_reply.started":"2021-06-14T09:44:33.120465Z","shell.execute_reply":"2021-06-14T09:44:33.826197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that the data is populated at intervals of 10 minutes. ","metadata":{"id":"usqkO_DVUBPs"}},{"cell_type":"code","source":"data.info()","metadata":{"id":"uBlWKTabcFnV","outputId":"9e1b03b3-a21f-4c1e-f898-f6f176f0575b","execution":{"iopub.status.busy":"2021-06-14T09:44:33.82964Z","iopub.execute_input":"2021-06-14T09:44:33.830004Z","iopub.status.idle":"2021-06-14T09:44:33.868027Z","shell.execute_reply.started":"2021-06-14T09:44:33.829966Z","shell.execute_reply":"2021-06-14T09:44:33.867071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"id":"yHl_Q_8LcHf6","outputId":"277c6608-d41c-4689-aed7-a825cf15a03e","execution":{"iopub.status.busy":"2021-06-14T09:44:33.869721Z","iopub.execute_input":"2021-06-14T09:44:33.870088Z","iopub.status.idle":"2021-06-14T09:44:34.009187Z","shell.execute_reply.started":"2021-06-14T09:44:33.870052Z","shell.execute_reply":"2021-06-14T09:44:34.008213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing\n\n1. The column `Unnanmed: 0` looks to be a date column. Let's change the type to datetime. \n\n2. Looking closely at df.describe(), we can see that `Blade2PitchAngle` and `Blade3PitchAngle` are having same values. We will validate this by `df1['col'].equals(df2['col']`, and if both are equal, we will drop one of the columns.","metadata":{"id":"hozDQAJwcTMF"}},{"cell_type":"code","source":"# change the Unnamed: 0 to datetype\ndf_updated = data.copy()\ndf_updated['Unnamed: 0'] = pd.to_datetime(df_updated['Unnamed: 0'])\ndf_updated.rename(columns={'Unnamed: 0': 'date_column'}, inplace=True)\n\nif (df_updated['Blade2PitchAngle'].equals(df_updated['Blade3PitchAngle'])==True):\n  df_updated = df_updated.drop('Blade3PitchAngle', axis=1) \n\n# check if the column is dropped\nassert 'Blade3PitchAngle' not in df_updated.columns","metadata":{"id":"N8N3FIQQeaxs","execution":{"iopub.status.busy":"2021-06-14T09:44:34.01082Z","iopub.execute_input":"2021-06-14T09:44:34.011172Z","iopub.status.idle":"2021-06-14T09:44:34.103294Z","shell.execute_reply.started":"2021-06-14T09:44:34.011133Z","shell.execute_reply":"2021-06-14T09:44:34.102439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_updated.head()","metadata":{"id":"GBTrisVW3aez","outputId":"8888240c-5fcb-4351-c588-42964e0c51ee","execution":{"iopub.status.busy":"2021-06-14T09:44:34.104582Z","iopub.execute_input":"2021-06-14T09:44:34.104944Z","iopub.status.idle":"2021-06-14T09:44:34.130698Z","shell.execute_reply.started":"2021-06-14T09:44:34.104905Z","shell.execute_reply":"2021-06-14T09:44:34.129792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check for null values","metadata":{"id":"6yLvYybBRjNO"}},{"cell_type":"code","source":"# Check null values\ndf_updated.isnull().sum()","metadata":{"id":"fbJBwIIEdXm8","outputId":"a51d55fa-8cae-4ed0-89a7-a3cdc57cc48e","execution":{"iopub.status.busy":"2021-06-14T09:44:34.132042Z","iopub.execute_input":"2021-06-14T09:44:34.132465Z","iopub.status.idle":"2021-06-14T09:44:34.156231Z","shell.execute_reply.started":"2021-06-14T09:44:34.132422Z","shell.execute_reply":"2021-06-14T09:44:34.155267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**To do**:\nHow to handle the missing data here:\n\n1. Populate the NaN values by `df.fillna(method='ffill')`\n2. Populate the missing values by median value/ average value? (or moving average value)\n\n","metadata":{"id":"chggmPrLi_mH"}},{"cell_type":"code","source":"df_updated = df_updated.fillna(method='ffill').fillna(method='bfill')\ndf_updated.isnull().sum()","metadata":{"id":"D60g3X2_i1c8","outputId":"36c0c903-06ea-4abf-b8c6-2b53b22dc7b4","execution":{"iopub.status.busy":"2021-06-14T09:44:34.158341Z","iopub.execute_input":"2021-06-14T09:44:34.158677Z","iopub.status.idle":"2021-06-14T09:44:34.222683Z","shell.execute_reply.started":"2021-06-14T09:44:34.158634Z","shell.execute_reply":"2021-06-14T09:44:34.221712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df_updated[['date_column', 'ActivePower', 'WindSpeed', 'GeneratorRPM', 'ReactivePower', 'RotorRPM', 'AmbientTemperatue', \\\n                 'WindDirection', 'Blade1PitchAngle', 'Blade2PitchAngle', 'HubTemperature', 'MainBoxTemperature', 'GearboxBearingTemperature', \\\n                 'GearboxOilTemperature']].copy()","metadata":{"id":"6TXdMpmsBAvV","execution":{"iopub.status.busy":"2021-06-14T09:44:34.224285Z","iopub.execute_input":"2021-06-14T09:44:34.224642Z","iopub.status.idle":"2021-06-14T09:44:34.236714Z","shell.execute_reply.started":"2021-06-14T09:44:34.224604Z","shell.execute_reply":"2021-06-14T09:44:34.235869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# crete a new column called Weekday\ndf['weekday'] = df['date_column'].dt.dayofweek\n# get one hot encoding\nohe = pd.get_dummies(df['weekday'])\ndf = df.join(ohe)\ndf = df.drop('weekday', axis=1)\ndate = pd.to_datetime(df.pop('date_column'))\ndf.head()","metadata":{"id":"3xrr_So2YTdR","outputId":"3f1fcd4b-f7a2-420e-bb25-a156d3954db7","execution":{"iopub.status.busy":"2021-06-14T09:44:34.23809Z","iopub.execute_input":"2021-06-14T09:44:34.238452Z","iopub.status.idle":"2021-06-14T09:44:34.291791Z","shell.execute_reply.started":"2021-06-14T09:44:34.238414Z","shell.execute_reply":"2021-06-14T09:44:34.290867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Date column\n  * The `date` column in string format is not a useful input. \n  * It could have clear daily and yearly periodicity.\n  * Use `sin` and `cos` to convert the time to clear \"Time of day\" and \"Time of  year signals.","metadata":{"id":"ROcuLc_qSCYk"}},{"cell_type":"code","source":"# convert datetime column to seconds\nimport datetime\ntimestamp_s = date.map(datetime.datetime.timestamp)","metadata":{"id":"LiXf2kkAwvWT","execution":{"iopub.status.busy":"2021-06-14T09:44:34.293269Z","iopub.execute_input":"2021-06-14T09:44:34.293629Z","iopub.status.idle":"2021-06-14T09:44:35.250634Z","shell.execute_reply.started":"2021-06-14T09:44:34.293591Z","shell.execute_reply":"2021-06-14T09:44:35.249794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# time in seconds may not be an useful input. We could convert it into sin and cos\nday = 24*60*60\nyear = (365.2425)*day\n\ndf['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\ndf['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\ndf['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\ndf['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))","metadata":{"id":"ZnoJKI-8wvbd","execution":{"iopub.status.busy":"2021-06-14T09:44:35.252724Z","iopub.execute_input":"2021-06-14T09:44:35.252992Z","iopub.status.idle":"2021-06-14T09:44:35.286144Z","shell.execute_reply.started":"2021-06-14T09:44:35.252966Z","shell.execute_reply":"2021-06-14T09:44:35.285405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"id":"OeaHk3gxLqAy","outputId":"95ec5764-c607-49e4-f03f-33833bfbcfba","execution":{"iopub.status.busy":"2021-06-14T09:44:35.287942Z","iopub.execute_input":"2021-06-14T09:44:35.288293Z","iopub.status.idle":"2021-06-14T09:44:35.312018Z","shell.execute_reply.started":"2021-06-14T09:44:35.288255Z","shell.execute_reply":"2021-06-14T09:44:35.311047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(np.array(df['Day sin'])[:200])\nplt.plot(np.array(df['Day cos'])[:200])\nplt.xlabel('Time [h]')\nplt.title('Time of day signal');","metadata":{"id":"RriPzlXb0PU-","outputId":"e0291574-bcdd-4614-c2e1-8b2fb3a5db9c","execution":{"iopub.status.busy":"2021-06-14T09:44:35.313653Z","iopub.execute_input":"2021-06-14T09:44:35.314036Z","iopub.status.idle":"2021-06-14T09:44:35.481092Z","shell.execute_reply.started":"2021-06-14T09:44:35.313997Z","shell.execute_reply":"2021-06-14T09:44:35.480192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split the data\n\n* We will use `70%, 20%, 10%` split for the training, validation and test sets.\n\n* Data is not randomly sampled before splitting:\n  * Chopping the data into windows of consecutive samples is still possible.\n  * Ensures that validation/test sets are more realistic.","metadata":{"id":"6G5XMtG13Fm5"}},{"cell_type":"code","source":"column_indices = {name: i for i, name in enumerate(df.columns)}\n\nn = len(df)\ntrain_df = df[0:int(n*0.7)]\nval_df = df[int(n*0.7):int(n*0.9)]\ntest_df = df[int(n*0.9):]\n\nnum_features = df.shape[1]","metadata":{"id":"CKWNCnS70Pab","execution":{"iopub.status.busy":"2021-06-14T09:44:35.482329Z","iopub.execute_input":"2021-06-14T09:44:35.482669Z","iopub.status.idle":"2021-06-14T09:44:35.488139Z","shell.execute_reply.started":"2021-06-14T09:44:35.482634Z","shell.execute_reply":"2021-06-14T09:44:35.487308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"id":"MUdDg1uc0PdM","outputId":"56f17218-5903-4e83-8903-0bb830013081","execution":{"iopub.status.busy":"2021-06-14T09:44:35.716109Z","iopub.execute_input":"2021-06-14T09:44:35.716386Z","iopub.status.idle":"2021-06-14T09:44:35.738025Z","shell.execute_reply.started":"2021-06-14T09:44:35.716359Z","shell.execute_reply":"2021-06-14T09:44:35.736947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Normalize the data\n\n* It is important to scale features before training a Neural Network\n* Normalization = Subtract the mean and divide by the standard deviation of each feature.\n\n* **thinktank**: normalization could be done using moving averages.","metadata":{"id":"Q7naLS42TcCr"}},{"cell_type":"code","source":"# Normalize the data\ntrain_mean = train_df.mean()\ntrain_std = train_df.std()\n\ntrain_df = (train_df - train_mean) / train_std\nval_df = (val_df - train_mean) / train_std\ntest_df = (test_df - train_mean) / train_std","metadata":{"id":"xZDMVIsX3I_x","execution":{"iopub.status.busy":"2021-06-14T09:44:36.172034Z","iopub.execute_input":"2021-06-14T09:44:36.17233Z","iopub.status.idle":"2021-06-14T09:44:36.240381Z","shell.execute_reply.started":"2021-06-14T09:44:36.172301Z","shell.execute_reply":"2021-06-14T09:44:36.239518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualize the distribution","metadata":{"id":"WnbJE3RVUWM9"}},{"cell_type":"code","source":"# the code below visualizes the normalized data\ndf_std = (df - train_mean) / train_std\ndf_std = df_std.melt(var_name='Column', value_name='Normalized')\nplt.figure(figsize=(12, 6))\nax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n_ = ax.set_xticklabels(df.keys(), rotation=90)","metadata":{"id":"T0UYEnkwm8Fe","outputId":"eff2ab5e-2eb0-4f49-b1fc-9e6a2f9b36bc","execution":{"iopub.status.busy":"2021-06-14T09:44:36.754183Z","iopub.execute_input":"2021-06-14T09:44:36.754487Z","iopub.status.idle":"2021-06-14T09:44:46.42142Z","shell.execute_reply.started":"2021-06-14T09:44:36.754456Z","shell.execute_reply":"2021-06-14T09:44:46.420627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Windowing\n\n* Models will make predictions based on a window of consecutive samples from the data\n* The main features of the input windows are:\n  * The width (number of timesteps) of the input and label windows\n  * The time offset between them\n  * Which features are used as inputs, labels, or both.","metadata":{"id":"n6yfZTq-4S33"}},{"cell_type":"markdown","source":"#### Indexes and offset","metadata":{"id":"RKZ_QkeZ4h7K"}},{"cell_type":"code","source":"class WindowGenerator():\n  def __init__(self, input_width, label_width, shift,\n               train_df=train_df, val_df=val_df, test_df=test_df,\n               label_columns=None):\n    # Store the raw data.\n    self.train_df = train_df\n    self.val_df = val_df\n    self.test_df = test_df\n\n    # Work out the label column indices.\n    self.label_columns = label_columns\n    if label_columns is not None:\n      self.label_columns_indices = {name: i for i, name in\n                                    enumerate(label_columns)}\n    self.column_indices = {name: i for i, name in\n                           enumerate(train_df.columns)}\n\n    # Work out the window parameters.\n    self.input_width = input_width\n    self.label_width = label_width\n    self.shift = shift\n\n    self.total_window_size = input_width + shift\n    self.input_slice = slice(0, input_width)\n    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n\n    self.label_start = self.total_window_size - self.label_width\n    self.labels_slice = slice(self.label_start, None)\n    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n\n  def __repr__(self):\n    return '\\n'.join([\n        f'Total window size: {self.total_window_size}',\n        f'Input indices: {self.input_indices}',\n        f'Label indices: {self.label_indices}',\n        f'Label column name(s): {self.label_columns}'])","metadata":{"id":"Kow_F-034Q1J","execution":{"iopub.status.busy":"2021-06-14T09:44:46.422991Z","iopub.execute_input":"2021-06-14T09:44:46.42334Z","iopub.status.idle":"2021-06-14T09:44:46.432118Z","shell.execute_reply.started":"2021-06-14T09:44:46.423301Z","shell.execute_reply":"2021-06-14T09:44:46.431204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* In our case, we want to predict 15 days into the future. \n* input_width = `30*24*6`\n* label_with = `30*24*6`\n* shift = 1","metadata":{"id":"-vseNAbla_Ak"}},{"cell_type":"code","source":"w2 = WindowGenerator(input_width=30*24*6, label_width=15*24*6, shift=15*24*6,\n                     label_columns=['ActivePower'])\n\nw2","metadata":{"id":"4ddMZku94Q5N","outputId":"df8ed960-ee0a-48ff-8534-c7cf7849287c","execution":{"iopub.status.busy":"2021-06-14T09:44:46.434356Z","iopub.execute_input":"2021-06-14T09:44:46.434756Z","iopub.status.idle":"2021-06-14T09:44:46.446464Z","shell.execute_reply.started":"2021-06-14T09:44:46.434719Z","shell.execute_reply":"2021-06-14T09:44:46.445463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split\n\n* Given a list of consecutive inputs, the `split_window` method will convert them to a window of inputs and a window of labels. ","metadata":{"id":"_--2o9ON4jzR"}},{"cell_type":"code","source":"def split_window(self, features):\n  inputs = features[:, self.input_slice, :]\n  labels = features[:, self.labels_slice, :]\n  if self.label_columns is not None:\n    labels = tf.stack(\n        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n        axis=-1)\n\n  # Slicing doesn't preserve static shape information, so set the shapes\n  # manually. This way the `tf.data.Datasets` are easier to inspect.\n  inputs.set_shape([None, self.input_width, None])\n  labels.set_shape([None, self.label_width, None])\n\n  return inputs, labels\n\nWindowGenerator.split_window = split_window","metadata":{"id":"UxV0cew43JFA","execution":{"iopub.status.busy":"2021-06-14T09:44:46.448057Z","iopub.execute_input":"2021-06-14T09:44:46.448526Z","iopub.status.idle":"2021-06-14T09:44:46.454639Z","shell.execute_reply.started":"2021-06-14T09:44:46.448492Z","shell.execute_reply":"2021-06-14T09:44:46.453867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Stack three slices, the length of the total window:\nexample_window = tf.stack([np.array(train_df[:w2.total_window_size]),\n                           np.array(train_df[100:100+w2.total_window_size]),\n                           np.array(train_df[200:200+w2.total_window_size])])\n\n\nexample_inputs, example_labels = w2.split_window(example_window)\n\nprint('All shapes are: (batch, time, features)')\nprint(f'Window shape: {example_window.shape}')\nprint(f'Inputs shape: {example_inputs.shape}')\nprint(f'labels shape: {example_labels.shape}')","metadata":{"id":"B-xt1Sqq3JJt","outputId":"7e3b8959-ce5e-4a77-d5ff-99da482987bc","execution":{"iopub.status.busy":"2021-06-14T09:44:46.455831Z","iopub.execute_input":"2021-06-14T09:44:46.456372Z","iopub.status.idle":"2021-06-14T09:44:48.661251Z","shell.execute_reply.started":"2021-06-14T09:44:46.456336Z","shell.execute_reply":"2021-06-14T09:44:48.65942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* This example takes a batch of 3, 4320 timestep windows, with 24 features at each timestep. \n* It splits them into a batch of 2160 timestep, 24 feature inputs, and a 2160 timestep, 1 feature output label. \n* The label only has one feature, because the `WindowGenerator` was initialized with one column. ","metadata":{"id":"6OKYFxZ7eEDT"}},{"cell_type":"markdown","source":"## Plot\n\n* A plot method that allows a simple visualization of the split window","metadata":{"id":"FGwZFTFgVcAu"}},{"cell_type":"code","source":"w2.example = example_inputs, example_labels","metadata":{"id":"YcY0GJ394k22","execution":{"iopub.status.busy":"2021-06-14T09:44:48.662674Z","iopub.execute_input":"2021-06-14T09:44:48.663035Z","iopub.status.idle":"2021-06-14T09:44:48.667424Z","shell.execute_reply.started":"2021-06-14T09:44:48.662997Z","shell.execute_reply":"2021-06-14T09:44:48.666453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot(self, model=None, plot_col='ActivePower', max_subplots=5):\n  inputs, labels = self.example\n  plt.figure(figsize=(70, 20))\n  plot_col_index = self.column_indices[plot_col]\n  max_n = min(max_subplots, len(inputs))\n  for n in range(max_n):\n    plt.subplot(max_n, 1, n+1)\n    plt.ylabel(f'{plot_col} [normed]')\n    plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n             label='Inputs', marker='.', zorder=-10)\n\n    if self.label_columns:\n      label_col_index = self.label_columns_indices.get(plot_col, None)\n    else:\n      label_col_index = plot_col_index\n\n    if label_col_index is None:\n      continue\n\n    plt.scatter(self.label_indices, labels[n, :, label_col_index],\n                edgecolors='k', label='Labels', c='#2ca02c', s=124)\n    if model is not None:\n      predictions = model(inputs)\n      plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n                  marker='X', label='Predictions',\n                  c='#ff0000', s=154)\n\n    if n == 0:\n      plt.legend(prop={'size': 20})\n\n  plt.xlabel('Time [20 min]')\n\nWindowGenerator.plot = plot","metadata":{"id":"tdVxLPjq4k5T","execution":{"iopub.status.busy":"2021-06-14T09:44:48.66891Z","iopub.execute_input":"2021-06-14T09:44:48.669239Z","iopub.status.idle":"2021-06-14T09:44:48.680598Z","shell.execute_reply.started":"2021-06-14T09:44:48.669204Z","shell.execute_reply":"2021-06-14T09:44:48.679517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"w2.plot()","metadata":{"id":"SY5e9l8w4k-N","outputId":"7eaeeaf3-68c2-4740-dc01-6fc616fddb1c","execution":{"iopub.status.busy":"2021-06-14T09:44:48.683399Z","iopub.execute_input":"2021-06-14T09:44:48.683805Z","iopub.status.idle":"2021-06-14T09:44:49.487642Z","shell.execute_reply.started":"2021-06-14T09:44:48.683778Z","shell.execute_reply":"2021-06-14T09:44:49.486088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create tf.Datasets \n* The `make_dataset` method below will take a timeseries DataFrame and convert it to a `tf.data.Dataset` of (input_window, label_window) pairs using the `preprocessing.timeseries_dataset_from_array` function.","metadata":{"id":"hx36z6U44-lE"}},{"cell_type":"code","source":"def make_dataset(self, data):\n  data = np.array(data, dtype=np.float32)\n  ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n      data=data,\n      targets=None,\n      sequence_length=self.total_window_size,\n      sequence_stride=1,\n      shuffle=True,\n      batch_size=120,)\n\n  ds = ds.map(self.split_window)\n\n  return ds\n\nWindowGenerator.make_dataset = make_dataset","metadata":{"id":"J46l_emF4q_9","execution":{"iopub.status.busy":"2021-06-14T09:44:49.489386Z","iopub.execute_input":"2021-06-14T09:44:49.4899Z","iopub.status.idle":"2021-06-14T09:44:49.496369Z","shell.execute_reply.started":"2021-06-14T09:44:49.489863Z","shell.execute_reply":"2021-06-14T09:44:49.495316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The `WindowGenerator` ibhect holds training, validation, and test data. Add properties for accessing them using the above `make_dataset` method. Also, add a standard example batch for easy access and plotting. ","metadata":{"id":"H1WXCtr4f0_k"}},{"cell_type":"code","source":"@property\ndef train(self):\n  return self.make_dataset(self.train_df)\n\n@property\ndef val(self):\n  return self.make_dataset(self.val_df)\n\n@property\ndef test(self):\n  return self.make_dataset(self.test_df)\n\n@property\ndef example(self):\n  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n  result = getattr(self, '_example', None)\n  if result is None:\n    # No example batch was found, so get one from the `.train` dataset\n    result = next(iter(self.train))\n    # And cache it for next time\n    self._example = result\n  return result\n\nWindowGenerator.train = train\nWindowGenerator.val = val\nWindowGenerator.test = test\nWindowGenerator.example = example","metadata":{"id":"wN8C_3v45BVw","execution":{"iopub.status.busy":"2021-06-14T09:44:49.498332Z","iopub.execute_input":"2021-06-14T09:44:49.499043Z","iopub.status.idle":"2021-06-14T09:44:49.508496Z","shell.execute_reply.started":"2021-06-14T09:44:49.499005Z","shell.execute_reply":"2021-06-14T09:44:49.507326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Each element is an (inputs, label) pair\nw2.train.element_spec","metadata":{"id":"4t6-3N635BYH","outputId":"5f1c02fe-6840-4d4f-ee07-b0ea49a7a797","execution":{"iopub.status.busy":"2021-06-14T09:44:49.509891Z","iopub.execute_input":"2021-06-14T09:44:49.510556Z","iopub.status.idle":"2021-06-14T09:44:49.715539Z","shell.execute_reply.started":"2021-06-14T09:44:49.510522Z","shell.execute_reply":"2021-06-14T09:44:49.714771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Iterating over a dataset yields concrete batches. ","metadata":{"id":"2OIB7Lf5kXol"}},{"cell_type":"code","source":"for example_inputs, example_labels in w2.train.take(1):\n  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n  print(f'Labels shape (batch, time, features): {example_labels.shape}')","metadata":{"id":"7d_0ZpHg5Baw","outputId":"f385ef1d-db9b-4940-cc55-4f85d7cf4e83","execution":{"iopub.status.busy":"2021-06-14T09:44:49.717681Z","iopub.execute_input":"2021-06-14T09:44:49.718348Z","iopub.status.idle":"2021-06-14T09:44:50.340962Z","shell.execute_reply.started":"2021-06-14T09:44:49.718305Z","shell.execute_reply":"2021-06-14T09:44:50.339499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wide_window = WindowGenerator(\n    input_width=2*6, label_width=2*6, shift=1,\n    label_columns=['ActivePower'])\n\nwide_window","metadata":{"id":"Aw2rWx8ZkUQs","outputId":"9b85c323-9a94-48f4-9cbb-c2c58687999f","execution":{"iopub.status.busy":"2021-06-14T09:44:50.342485Z","iopub.execute_input":"2021-06-14T09:44:50.342816Z","iopub.status.idle":"2021-06-14T09:44:50.350205Z","shell.execute_reply.started":"2021-06-14T09:44:50.342779Z","shell.execute_reply":"2021-06-14T09:44:50.349225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Compile and fit","metadata":{"id":"oBCwryRwDNGt"}},{"cell_type":"code","source":"# package the training into a function\nMAX_EPOCHS = 20\n\ndef compile_and_fit(model, window, patience=3):\n  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                                    patience=3,\n                                                    mode='min')\n\n  model.compile(loss=tf.losses.MeanAbsoluteError(),\n                optimizer=tf.optimizers.Adam(lr=0.01),\n                metrics=[tf.metrics.MeanAbsoluteError()])\n\n  history = model.fit(window.train, epochs=MAX_EPOCHS,\n                      validation_data=window.val,\n                      callbacks=[early_stopping])\n  return history\n","metadata":{"id":"UW9IYQQBmloM","execution":{"iopub.status.busy":"2021-06-14T09:44:50.351674Z","iopub.execute_input":"2021-06-14T09:44:50.352493Z","iopub.status.idle":"2021-06-14T09:44:50.359971Z","shell.execute_reply.started":"2021-06-14T09:44:50.352453Z","shell.execute_reply":"2021-06-14T09:44:50.359131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Multi step model\n\n* We want to predict multiple steps into the future (15 days into the future)\n\n* In multi-step prediction, the model needs to learn to predict a range of future values. A sequence of future values are predicted. \n\n* **Two approaches**:\n\n1. Single shot predictions where the entire timeseries is predicted at once\n2. AutoRegressive model: the model makes only single step predictions and its output is fed back as input. ","metadata":{"id":"jD_qHMX85O5i"}},{"cell_type":"markdown","source":"Here's a window object that generates these slices from the dataset","metadata":{"id":"uIlDFZPoyk7S"}},{"cell_type":"code","source":"OUT_STEPS = 15*24*6\nmulti_window = WindowGenerator(input_width=15*24*6,\n                               label_width=OUT_STEPS,\n                               shift=OUT_STEPS)\n\nmulti_window.plot()\nmulti_window\n","metadata":{"id":"9Gk0Z91xjOwv","outputId":"19ec0d4e-d1fe-4833-ec94-69cb9d524948","execution":{"iopub.status.busy":"2021-06-14T09:44:50.360968Z","iopub.execute_input":"2021-06-14T09:44:50.363023Z","iopub.status.idle":"2021-06-14T09:44:51.605732Z","shell.execute_reply.started":"2021-06-14T09:44:50.362992Z","shell.execute_reply":"2021-06-14T09:44:51.604829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Baseline model\n\n##### Repeat last input: A simple baseline is to repeat the last input timestep for the required number of output timesteps. ","metadata":{"id":"uIIB7kcX6vlx"}},{"cell_type":"code","source":"class MultiStepLastBaseline(tf.keras.Model):\n  def call(self, inputs):\n    return tf.tile(inputs[:, -1:, :], [1, OUT_STEPS, 1])\n\nlast_baseline = MultiStepLastBaseline()\nlast_baseline.compile(loss=tf.losses.MeanAbsoluteError(),\n                      metrics=[tf.metrics.MeanAbsoluteError()])\n\nmulti_val_performance = {}\nmulti_performance = {}\n\nmulti_val_performance['Last'] = last_baseline.evaluate(multi_window.val)\nmulti_performance['Last'] = last_baseline.evaluate(multi_window.test)\nmulti_window.plot(last_baseline)\n","metadata":{"id":"szboiUO25FvG","outputId":"b74fd2c9-3886-4526-d8be-c8570045417c","execution":{"iopub.status.busy":"2021-06-14T09:44:51.607189Z","iopub.execute_input":"2021-06-14T09:44:51.607506Z","iopub.status.idle":"2021-06-14T09:45:09.183451Z","shell.execute_reply.started":"2021-06-14T09:44:51.607472Z","shell.execute_reply":"2021-06-14T09:45:09.182624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Repeat Baseline: Repeat previous 15 days, assuming the next 15 days will be similar.","metadata":{"id":"n1qDfCUeYrF6"}},{"cell_type":"code","source":"class RepeatBaseline(tf.keras.Model):\n  def call(self, inputs):\n    return inputs\n\nrepeat_baseline = RepeatBaseline()\nrepeat_baseline.compile(loss=tf.losses.MeanAbsoluteError(),\n                        metrics=[tf.metrics.MeanAbsoluteError()])\n\nmulti_val_performance['Repeat'] = repeat_baseline.evaluate(multi_window.val)\nmulti_performance['Repeat'] = repeat_baseline.evaluate(multi_window.test)\nmulti_window.plot(repeat_baseline)\n","metadata":{"id":"KCWZma1X4rCp","outputId":"ba0882ac-a605-4796-ace8-e997d83831fe","execution":{"iopub.status.busy":"2021-06-14T09:45:09.184804Z","iopub.execute_input":"2021-06-14T09:45:09.185401Z","iopub.status.idle":"2021-06-14T09:45:26.137815Z","shell.execute_reply.started":"2021-06-14T09:45:09.185354Z","shell.execute_reply":"2021-06-14T09:45:26.136736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Single shot model\n\n* The model makes the entire sequence prediction in one step\n* Model only needs to reshape the output","metadata":{"id":"mvV8NqbN7zDg"}},{"cell_type":"markdown","source":"#### Linear model\n\n* `multi_linear_model`: \n  \n  * Groups a linear stack of layers into a `tf.keras.Model`. ","metadata":{"id":"sZKS7MIkZQnO"}},{"cell_type":"code","source":"OUT_STEPS = 15*24*6\nmulti_window = WindowGenerator(input_width=30*24*6,\n                               label_width=OUT_STEPS,\n                               shift=OUT_STEPS)\n\nmulti_window.plot()\nmulti_window\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T09:45:26.139577Z","iopub.execute_input":"2021-06-14T09:45:26.139976Z","iopub.status.idle":"2021-06-14T09:45:27.54916Z","shell.execute_reply.started":"2021-06-14T09:45:26.139939Z","shell.execute_reply":"2021-06-14T09:45:27.548239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"multi_linear_model = tf.keras.Sequential([\n    # Take the last time-step.\n    # Shape [batch, time, features] => [batch, 1, features]\n    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n    # Shape => [batch, 1, out_steps*features]\n    tf.keras.layers.Dense(OUT_STEPS*num_features,\n                          kernel_initializer=tf.initializers.zeros()),\n    # Shape => [batch, out_steps, features]\n    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n])\n\nhistory = compile_and_fit(multi_linear_model, multi_window)\n\n#IPython.display.clear_output()\nmulti_val_performance['Linear'] = multi_linear_model.evaluate(multi_window.val)\nmulti_performance['Linear'] = multi_linear_model.evaluate(multi_window.test)\nmulti_window.plot(multi_linear_model)\n","metadata":{"id":"tj4DMYO660PD","outputId":"2e95effc-5dcc-4e47-84bd-9ec9e7a1afb0","execution":{"iopub.status.busy":"2021-06-14T09:45:27.5505Z","iopub.execute_input":"2021-06-14T09:45:27.550811Z","iopub.status.idle":"2021-06-14T09:53:44.402328Z","shell.execute_reply.started":"2021-06-14T09:45:27.550778Z","shell.execute_reply":"2021-06-14T09:53:44.395551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This model does better than baseline, but still underpowered. (Also we haven't made use of other feature columns).","metadata":{"id":"qAxu7Od4Zfrf"}},{"cell_type":"markdown","source":"#### Dense\n* Add layers.dense  between the input and output","metadata":{"id":"sJLZXfl78Ahw"}},{"cell_type":"code","source":"multi_dense_model = tf.keras.Sequential([\n    # Take the last time step.\n    # Shape [batch, time, features] => [batch, 1, features]\n    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n    # Shape => [batch, 1, dense_units]\n    tf.keras.layers.Dense(512, activation='relu'),\n    # Shape => [batch, out_steps*features]\n    tf.keras.layers.Dense(OUT_STEPS*num_features,\n                          kernel_initializer=tf.initializers.zeros()),\n    # Shape => [batch, out_steps, features]\n    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n])\n\nhistory = compile_and_fit(multi_dense_model, multi_window)\n\nmulti_val_performance['Dense'] = multi_dense_model.evaluate(multi_window.val)\nmulti_performance['Dense'] = multi_dense_model.evaluate(multi_window.test)\nmulti_window.plot(multi_dense_model)\n","metadata":{"id":"MPhn8bY760Sz","outputId":"f758cd81-b9d4-4522-937a-5521344b2664","execution":{"iopub.status.busy":"2021-06-14T10:03:54.52141Z","iopub.execute_input":"2021-06-14T10:03:54.521729Z","iopub.status.idle":"2021-06-14T10:10:29.041078Z","shell.execute_reply.started":"2021-06-14T10:03:54.521698Z","shell.execute_reply":"2021-06-14T10:10:29.039981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### CNN","metadata":{"id":"iCK45P0l8Fh_"}},{"cell_type":"code","source":"CONV_WIDTH = 3\nmulti_conv_model = tf.keras.Sequential([\n    # Shape [batch, time, features] => [batch, CONV_WIDTH, features]\n    tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n    # Shape => [batch, 1, conv_units]\n    tf.keras.layers.Conv1D(256, activation='relu', kernel_size=(CONV_WIDTH)),\n    # Shape => [batch, 1,  out_steps*features]\n    tf.keras.layers.Dense(OUT_STEPS*num_features,\n                          kernel_initializer=tf.initializers.zeros()),\n    # Shape => [batch, out_steps, features]\n    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n])\n\nhistory = compile_and_fit(multi_conv_model, multi_window)\n\nmulti_val_performance['Conv'] = multi_conv_model.evaluate(multi_window.val)\nmulti_performance['Conv'] = multi_conv_model.evaluate(multi_window.test)\nmulti_window.plot(multi_conv_model)\n","metadata":{"id":"-JMOHF0q71QO","outputId":"fbb570ec-5b06-4ee1-9b85-a32ceb0de4ec","execution":{"iopub.status.busy":"2021-06-13T22:52:45.83182Z","iopub.execute_input":"2021-06-13T22:52:45.832195Z","iopub.status.idle":"2021-06-13T22:59:34.370682Z","shell.execute_reply.started":"2021-06-13T22:52:45.832156Z","shell.execute_reply":"2021-06-13T22:59:34.369669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### RNN","metadata":{"id":"cJNFLXno8HpX"}},{"cell_type":"code","source":"multi_lstm_model = tf.keras.Sequential([\n    # Shape [batch, time, features] => [batch, lstm_units]\n    # Adding more `lstm_units` just overfits more quickly.\n    tf.keras.layers.LSTM(32, return_sequences=False),\n    # Shape => [batch, out_steps*features]\n    tf.keras.layers.Dense(OUT_STEPS*num_features,\n                          kernel_initializer=tf.initializers.zeros()),\n    # Shape => [batch, out_steps, features]\n    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n])\n\nhistory = compile_and_fit(multi_lstm_model, multi_window)\n\nmulti_val_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.val)\nmulti_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.test)\nmulti_window.plot(multi_lstm_model)\n","metadata":{"id":"WdbIu0_g71Tw","outputId":"40f56a85-0886-4fd3-c9a8-c0a1e4fc69de","execution":{"iopub.status.busy":"2021-06-13T22:59:34.372819Z","iopub.execute_input":"2021-06-13T22:59:34.373427Z","iopub.status.idle":"2021-06-13T23:13:27.509222Z","shell.execute_reply.started":"2021-06-13T22:59:34.373367Z","shell.execute_reply":"2021-06-13T23:13:27.49793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Improvements/ future development**\n\n* Add more layers to RNN/CNN\n\n* Try Autoregressive model\n\n* Create custom evaluation metric:\n  * to give more weightage to the closest predictions\n\n* Feature engineering + apply the known datafields to future dates which are fed to the predict function. \n","metadata":{"id":"DzdYcUhnBDSV"}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}