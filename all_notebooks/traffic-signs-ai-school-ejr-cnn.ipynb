{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"SEED_VALUE = 42\n\nimport random\nrandom.seed(SEED_VALUE)\nimport numpy as np\nnp.random.seed(SEED_VALUE)\nimport tensorflow as tf\ntf.random.set_seed(SEED_VALUE)\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nprint(tf.__version__)\nprint(keras.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. 학습데이터 및 검증데이터 준비\n\nTraining & Test Set 의 사진 이미지에서 표지판 영역만 잘라내서 사용하고자 한다. 메타데이터로 주어진 표지판 좌표값을 활용하여 원본 이미지를 crop 처리한다.가공한 데이터셋은 여기에서 참조 가능하다: https://www.kaggle.com/eunjurho/german-traffic-sign-recognition-benchmark-cropped#german-traffic-signs-preprocessing.ipynb\n\n이렇게 가공된 이미지 데이터를 바탕으로 학습데이터 및 검증데이터를 준비한다."},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_PATH = '../input/german-traffic-sign-recognition-benchmark-cropped/gtsrb-preprocessed/'\nMETA_PATH = '../input/gtsrb-german-traffic-sign/'\n\nimport os\nprint(os.listdir(IMAGE_PATH))\nprint(os.listdir(META_PATH))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(META_PATH + 'Train.csv')\ndf_train['Path'] = df_train['Path'].str.lower()\ndf_train['ClassId'] = df_train['ClassId'].apply(str)\n\nprint(df_train.shape)\ndf_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv(META_PATH + 'Test.csv')\ndf_test['Path'] = df_test['Path'].str.lower()\ndf_test['ClassId'] = df_test['ClassId'].apply(str)\n\nprint(df_test.shape)\ndf_test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 24\nIMG_ROWS = 24\nIMG_COLS = 24\nNUM_CLASS = 43","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n(df_train, df_validation) = train_test_split(df_train, test_size=0.3, random_state=SEED_VALUE)\n\n# Train 디렉토리로부터 학습 데이터셋과 검증 데이터셋을 나눠서 불러오기\ntrain_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n        df_train,\n        directory=IMAGE_PATH,\n        x_col='Path',\n        y_col='ClassId',\n        shuffle=True,\n        seed=SEED_VALUE,\n        target_size=(IMG_ROWS, IMG_COLS),\n        color_mode='rgb',\n        class_mode='categorical',    \n        batch_size=BATCH_SIZE)\n\nvalidation_generator = train_datagen.flow_from_dataframe(\n        df_validation,\n        directory=IMAGE_PATH,\n        x_col='Path',\n        y_col='ClassId',\n        shuffle=True,\n        seed=SEED_VALUE,\n        target_size=(IMG_ROWS, IMG_COLS),\n        color_mode='rgb',\n        class_mode='categorical',    \n        batch_size=BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 학습 데이터셋이 잘 읽어지는지 확인\nx_train_batch, y_train_batch = train_generator.next()\nprint('train y data shape: {}'.format(y_train_batch.shape))\nprint('train x data shape: {}'.format(x_train_batch.shape))\n\nf, ax = plt.subplots(1, 5, figsize=(10, 40))\nax[0].imshow(x_train_batch[0])\nax[0].set_title(np.argmax(y_train_batch[0]))\nax[1].imshow(x_train_batch[1])\nax[1].set_title(np.argmax(y_train_batch[1]))\nax[2].imshow(x_train_batch[2])\nax[2].set_title(np.argmax(y_train_batch[2]))\nax[3].imshow(x_train_batch[3])\nax[3].set_title(np.argmax(y_train_batch[3]))\nax[4].imshow(x_train_batch[4])\nax[4].set_title(np.argmax(y_train_batch[4]))\nplt.show()\n    \ntrain_generator.reset()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 검증 데이터셋이 잘 읽어지는지 확인\nx_valid_batch, y_valid_batch = validation_generator.next()\nprint('validation y data shape: {}'.format(y_valid_batch.shape))\nprint('validation x data shape: {}'.format(x_valid_batch.shape))\n\nf, ax = plt.subplots(1, 5, figsize=(10, 40))\nax[0].imshow(x_valid_batch[0])\nax[0].set_title(np.argmax(y_valid_batch[0]))\nax[1].imshow(x_valid_batch[1])\nax[1].set_title(np.argmax(y_valid_batch[1]))\nax[2].imshow(x_valid_batch[2])\nax[2].set_title(np.argmax(y_valid_batch[2]))\nax[3].imshow(x_valid_batch[3])\nax[3].set_title(np.argmax(y_valid_batch[3]))\nax[4].imshow(x_valid_batch[4])\nax[4].set_title(np.argmax(y_valid_batch[4]))\nplt.show()\n\nvalidation_generator.reset()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. 모델 및 학습과정 설정\n\nMNIST 숫자 분류를 위한 CNN 분류기 수업때 사용한 모델 구조를 참고하였다: https://colab.research.google.com/github/visionNoob/Keras_Tutorial/blob/master/Keras_1_CNN.ipynb#scrollTo=R6EeL-OAJpKd "},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\n\nmodel = Sequential()\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same',activation='relu', input_shape=(IMG_ROWS, IMG_COLS, 3)))\nmodel.add(Conv2D(64, (3, 3), padding='same',activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(NUM_CLASS, activation='softmax'))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. 모델 학습시키기"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(train_generator, \n                    validation_data=validation_generator,\n                    epochs=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. 모델 학습 결과 출력"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(history.history.keys())\n\nf, ax = plt.subplots(1, 2, figsize=(15, 5))\n\nax[0].plot(history.history['loss'])\nax[0].plot(history.history['val_loss'])\nax[0].set_xlabel('Epochs')\nax[0].set_ylabel('Loss')\nax[0].legend(('train_loss', 'val_loss'))\n\nax[1].plot(history.history['accuracy'])\nax[1].plot(history.history['val_accuracy'])\nax[1].set_xlabel('Epochs')\nax[1].set_ylabel('Accuracy')\nax[1].legend(('train_accuracy', 'val_accuracy'))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. 테스트 데이터셋으로 모델 평가"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale=1./255)\n\ntest_generator = test_datagen.flow_from_dataframe(\n        df_test,\n        directory=IMAGE_PATH,\n        x_col='Path',\n        y_col='ClassId',\n        shuffle=False,\n        target_size=(IMG_ROWS, IMG_COLS),\n        color_mode='rgb',\n        class_mode='categorical',    \n        batch_size=BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate_generator(test_generator, verbose=1)\nprint('Test dataset accuracy: {}'.format(score[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generator.reset()\n\npred = model.predict_generator(test_generator)\npred = np.argmax(pred, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://github.com/keras-team/keras/blob/master/keras/preprocessing/image.py#L521-L526\n\ngenerator_idx_to_label_map = {v: k for k, v in test_generator.class_indices.items()}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nmeasures_by_class_str = classification_report(test_generator.classes, pred, target_names=list(generator_idx_to_label_map.values()))\nprint(measures_by_class_str)\n\n# precision: tp / (tp + fp), positive 가 아닌 것을 positive 로 분류하지 않는 능력.\n# recall: tp / p, positive 인 것을 모두 식별해낼 수 있는 능력.\n# f1-score: precision 과 recall 의 조화 평균.\n# support: 실제 데이터셋에서 출현 횟수.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 클래스별 metrics 리포트 포맷을 pandas dataframe 으로 변환\n\nmeasures_by_class = classification_report(test_generator.classes, pred, target_names=list(generator_idx_to_label_map.values()), output_dict=True)\n\nclass_ids = []\nprecisions = []\nrecalls = []\nf1_scores = []\nsupports = []\n\nfor class_id, measures in measures_by_class.items():\n    if (class_id.isdigit()):\n        class_ids.append(class_id)\n        precisions.append(measures['precision'])\n        recalls.append(measures['recall'])\n        f1_scores.append(measures['f1-score'])\n        supports.append(measures['support'])\n\ndf_report = pd.DataFrame(list(zip(class_ids, precisions, recalls, f1_scores, supports)),\n               index=class_ids,\n               columns=['ClassId', 'Precision', 'Recall', 'F1-score', 'Support'])\n\nprint(df_report.shape)\ndf_report.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 클래스별 metrics 리포트에 클래스별 accuracy 계산해서 추가\n\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(test_generator.classes, pred)\ncm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\ndf_report['Accuracy'] = pd.Series(cm.diagonal(), index=list(generator_idx_to_label_map.values()))\n\nprint(df_report.shape)\ndf_report.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(3, 1, figsize=(20, 15))\n\norder_by_class_size = df_train.ClassId.value_counts().index\n\nsns.countplot(x='ClassId', data=df_train, ax=ax[0], order=order_by_class_size, palette=\"GnBu_d\")\nax[0].set_title('Number of images by class within training dataset')\n\nsns.barplot(x=df_report.index, y=df_report['Accuracy'], ax=ax[1], order=order_by_class_size, palette=\"GnBu_d\")\nax[1].set_title('Accuracy by class')\n\nsns.barplot(x=df_report.index, y=df_report['F1-score'], ax=ax[2], order=order_by_class_size, palette=\"GnBu_d\")\nax[2].set_title('F1-score by class')\n\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}