{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **GAN - Generative Adversarial Network**<br/>\nThis Kernel is a Toy example for GAN implementation using TensorFlow. <br/>\nThis example is implemented on MNIST dataset for learning the GAN concepts. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":false},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom scipy.misc import imread\n\nimport os\nfrom IPython import display\nimport PIL\nimport time\n\nimport glob\n#import imageio\n\nimport warnings\nwarnings.filterwarnings(action='ignore')\n# Any results you write to the current directory are saved as output.\n\nimport gc\n\nimport tensorflow as tf\ntf.enable_eager_execution()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Import and preprocess the MNIST DataSet**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train= pd.read_csv('/kaggle/input/mnist_train.csv')\ntest= pd.read_csv('/kaggle/input/mnist_test.csv')\ntrain = pd.concat([train, test])\ntrain.drop(train.columns[0], axis=1, inplace=True)\ntrain = np.array(train)\ntrain = train.reshape(train.shape[0],28,28,1).astype('float32')\ntrain = (train -127.5) / 127.5\ndel test\ngc.collect()\nprint(train.shape)\nplt.imshow(train[0].reshape(28,28), cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Setting Up *Dataset* batch to feed into the network**"},{"metadata":{"trusted":true},"cell_type":"code","source":"BUFFER_S = 70000\nBATCH_S = 256\n# Create batches and shuffle the dataset\ntraindata = tf.data.Dataset.from_tensor_slices(train).shuffle(BUFFER_S).batch(BATCH_S)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Create Models**:  The Generator and The Discriminator<br/>\n***Generator***<br/>\nHere we are doing upsampling (double the size of original image) using Convolution2DTranspose(). Remember that we started the image generation from random noise (100,0)<br/>\n<br/>\n***Discriminator***<br/>\nSimilar to the regular CNN Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def Generator():\n    model = tf.keras.Sequential()\n    model.add(tf.keras.layers.Dense(7*7*256, use_bias=False, input_shape=(100,))) # input the random noise to the dense layer \n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Reshape((7,7,256)))\n    \n    assert model.output_shape == (None,7,7,256)\n    model.add(tf.keras.layers.Convolution2DTranspose(128, (5,5), strides=(1,1), padding='same', use_bias=False)) #[[outshape = (n-f+2p)/s + 1]]\n    assert model.output_shape ==(None,7,7,128)\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Convolution2DTranspose(64,(5,5), strides=(2,2), padding='same', use_bias=False))\n    assert model.output_shape == (None, 14,14,64)\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.LeakyReLU())\n    \n    model.add(tf.keras.layers.Convolution2DTranspose(1, (5,5), strides=(2,2), padding='same', use_bias=False))\n    assert model.output_shape == (None, 28,28,1)\n    \n    return model\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Discriminator():\n    model = tf.keras.Sequential()\n    model.add(tf.keras.layers.Conv2D(64, (5,5), strides=(2,2), padding='same'))\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Dropout(0.3))\n    \n    model.add(tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n    model.add(tf.keras.layers.LeakyReLU())\n    model.add(tf.keras.layers.Dropout(0.3))\n    \n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dense(1))\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# instantiate the models\ngenerator = Generator()\ndiscriminator = Discriminator()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Define loss functions for Generator and Discriminator**"},{"metadata":{},"cell_type":"markdown","source":"**The Generator loss** is \"SigmoidCrossEntropyLoss\" from the generated image and array of Ones. this is because generator want to learn as much fake images it can generate."},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef gLoss(generated_output):\n    return tf.losses.sigmoid_cross_entropy(tf.ones_like(generated_output), generated_output)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The Discriminator loss** is a sum of losses generated by the Generator n/w:- i.e. real_loss from the real_output and generated_loss from generated fake output."},{"metadata":{"trusted":true},"cell_type":"code","source":"def dLoss(real_output, generated_output):\n    real_loss = tf.losses.sigmoid_cross_entropy(tf.ones_like(real_output), real_output)\n    gen_loss = tf.losses.sigmoid_cross_entropy(tf.zeros_like(generated_output), generated_output)\n    \n    total_loss = real_loss + gen_loss\n    return total_loss\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Define Optimizers for the models**"},{"metadata":{"trusted":true},"cell_type":"code","source":"gOptimizer = tf.train.AdamOptimizer(1e-4)\ndOptimizer = tf.train.AdamOptimizer(1e-4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**CheckPoints: ** Definition"},{"metadata":{"trusted":true},"cell_type":"code","source":"chkpt_dir = './trng_chkpts'\nchkpt_prefix = os.path.join(chkpt_dir,'ckpt')\ncheckpt = tf.train.Checkpoint(generator=generator, discriminator=discriminator, generator_optimizer=gOptimizer, discriminator_optimizer=dOptimizer)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SETUP TRAINING **"},{"metadata":{"trusted":true},"cell_type":"code","source":"noise_dim = 100\nEPOCHS = 50\nresults = 10\nrandom_vector = tf.random_normal([results, noise_dim])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gantraining(images):\n    noise = tf.random_normal([BATCH_S, noise_dim])\n    \n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_images = generator(noise, training=True)\n        \n        #Outputs from models\n        real_output = discriminator(images, training=True)\n        generated_output = discriminator(generated_images, training=True)\n        \n        #respective losses\n        gen_loss = gLoss(generated_output)\n        disc_loss = dLoss(real_output, generated_output)\n    \n    #calculate gradients\n    grad_gen = gen_tape.gradient(gen_loss, generator.variables)\n    grad_disc = disc_tape.gradient(disc_loss, discriminator.variables)\n    \n    #Apply gradients from optimizer\n    gOptimizer.apply_gradients(zip(grad_gen,generator.variables))\n    dOptimizer.apply_gradients(zip(grad_disc, discriminator.variables))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def image_processing(model, epoch, test_input):\n    #predictions at each epoch using the input random_vector. Note the model (generator) training is set 'False'\n    predictions = model(test_input,training=False)\n    \n    fig = plt.figure(figsize=(4,4))\n    print('Epoch: ' + str(epoch))\n    for i in range(predictions.shape[0]):\n        plt.subplot(4,4,i+1)\n        plt.imshow(predictions[i,:,:,0]*127.5 + 127.5, cmap='gray')\n        plt.axis('off')\n    \n    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gantraining = tf.contrib.eager.defun(gantraining)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **TRAINING THE GAN **"},{"metadata":{"trusted":true},"cell_type":"code","source":"def theGAN(dataset, epochs):\n    for epoch in range(epochs):\n        for images in dataset:\n            gantraining(images)\n        \n        display.clear_output(wait=True)\n        image_processing(generator, epoch+1, random_vector)\n        \n        # saving (checkpoint) the model every 15 epochs\n        if (epoch + 1) % 15 == 0:\n            checkpt.save(file_prefix = chkpt_prefix)\n    \n    display.clear_output(wait=True)\n    image_processing(generator, epoch, random_vector)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"theGAN(traindata, EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpt.restore(tf.train.latest_checkpoint(chkpt_dir))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Resultant Output"},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_image(epoch_no):\n  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_image(EPOCHS)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}