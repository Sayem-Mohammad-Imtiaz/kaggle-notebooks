{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\nfrom plotly.offline import iplot, init_notebook_mode\n\nimport cufflinks as cf\nimport plotly.graph_objs as go\n# import chart_studio.plotly as py\n\ninit_notebook_mode(connected=True)\ncf.go_offline(connected=True)\n\n# Set global theme\ncf.set_config_file(world_readable=True, theme='ggplot')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/employee-attrition/employee_attrition_train.csv', na_values= np.nan)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"AGE Numerical Value\n\nATTRITION Employee leaving the company (0=no, 1=yes)\n\nBUSINESS TRAVEL (1=No Travel, 2=Travel Frequently, 3=Travel Rarely)\n\nDAILY RATE Numerical Value - Salary Level\n\nDEPARTMENT (1=HR, 2=R&D, 3=Sales)\n\nDISTANCE FROM HOME Numerical Value - THE DISTANCE FROM WORK TO HOME\n\nEDUCATION Numerical Value. (1 'Below College' 2 'College' 3 'Bachelor' 4 'Master' 5 'Doctor')\n\nEDUCATION FIELD (1=HR, 2=LIFE SCIENCES, 3=MARKETING, 4=MEDICAL SCIENCES, 5=OTHERS, 6= TECHNICAL)\n\nEMPLOYEE COUNT Numerical Value\n\nEMPLOYEE NUMBER Numerical Value - EMPLOYEE ID\n\nENVIRONMENT SATISFACTION Numerical Value - SATISFACTION WITH THE ENVIRONMENT (1 'Low' 2 'Medium' 3 'High' 4 'Very High')\n\nGENDER (1=FEMALE, 2=MALE)\n\nHOURLY RATE Numerical Value - HOURLY SALARY\n\nJOB INVOLVEMENT Numerical Value - JOB INVOLVEMENT (1 'Low' 2 'Medium' 3 'High' 4 'Very High')\n\nJOB LEVEL Numerical Value - LEVEL OF JOB\n\nJOB ROLE (1=HR REP, 2=HR, 3=LAB TECHNICIAN, 4=MANAGER, 5= MANAGING DIRECTOR, 6= RESEARCH DIRECTOR, 7= RESEARCH SCIENTIST, 8=SALES EXECUTIVE, 9= SALES REPRESENTATIVE)\n\nJOB SATISFACTION Numerical Value - SATISFACTION WITH THE JOB (1 'Low' 2 'Medium' 3 'High' 4 'Very High')\n\nMARITAL STATUS (1=DIVORCED, 2=MARRIED, 3=SINGLE)\n\nMONTHLY INCOME Numerical Value - MONTHLY SALARY\n\nMONTHLY RATE Numerical Value - MONTHLY RATE\n\nNUMCOMPANIES WORKED Numerical Value - NO. OF COMPANIES WORKED AT\n\nOVER 18 (1=YES, 2=NO)\n\nOVERTIME (1=NO, 2=YES)\n\nPERCENT SALARY HIKE Numerical Value - PERCENTAGE INCREASE IN SALARY\n\nPERFORMANCE RATING Numerical Value - PERFORMANCE RATING\n\nRELATIONS SATISFACTION Numerical Value - RELATIONS SATISFACTION\n\nSTANDARD HOURS Numerical Value - STANDARD HOURS\n\nSTOCK OPTIONS LEVEL Numerical Value - STOCK OPTIONS (Higher the number, the more stock option an employee has)\n\nTOTAL WORKING YEARS Numerical Value - TOTAL YEARS WORKED\n\nTRAINING TIMES LAST YEAR Numerical Value - HOURS SPENT TRAINING\n\nWORK LIFE BALANCE Numerical Value - TIME SPENT BETWEEN WORK AND OUTSIDE\n\nYEARS AT COMPANY Numerical Value - TOTAL NUMBER OF YEARS AT THE COMPANY\n\nYEARS IN CURRENT ROLE Numerical Value -YEARS IN CURRENT ROLE\n\nYEARS SINCE LAST PROMOTION Numerical Value - LAST PROMOTION\n\nYEARS WITH CURRENT MANAGER Numerical Value - YEARS SPENT WITH CURRENT MANAGER"},{"metadata":{},"cell_type":"markdown","source":"Lets change the column names and casings"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns.str.upper().values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns = ['AGE', 'ATTRITION', 'BUSINESS_TRAVEL', 'DAILY_RATE', 'DEPARTMENT',\n 'DISTANCE_FROM_HOME', 'EDUCATION', 'EDUCATION_FIELD', 'EMPLOYEE_COUNT',\n 'EMPLOYEE_NUMBER', 'ENVIRONMENT_SATISFACTION', 'GENDER',\n 'HOURLY_RATE', 'JOB_INVOLVEMENT', 'JOB_LEVEL', 'JOB_ROLE',\n 'JOB_SATISFACTION', 'MARITAL_STATUS', 'MONTHLY_INCOME', 'MONTHLY_RATE',\n 'NUM_COMPANIES_WORKED', 'OVER_18', 'OVER_TIME', 'PERCENT_SALARY_HIKE',\n 'PERFORMANCE_RATING', 'RELATIONSHIP_SATISFACTION', 'STANDARD_HOURS',\n 'STOCK_OPTION_LEVEL', 'TOTAL_WORKING_YEARS', 'TRAINING_TIMES_LAST_YEAR',\n 'WORK_LIFE_BALANCE', 'YEARS_AT_COMPANY', 'YEARS_IN_CURRENT_ROLE',\n 'YEARS_SINCE_LAST_PROMOTION', 'YEARS_WITH_CURR_MANAGER']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[:,df.dtypes==\"object\"].columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's first separate true categorical columns "},{"metadata":{},"cell_type":"markdown","source":"According to column information and df info these following are the columns that are infact a categoical types which are now represented as numeric values:\n\n\"Employee Number\" ,\"environment statisfaction\" , \"jobinvolvement\", 'job level', 'job satisfaction', 'relation satisfaction','stock_option_level','worklife balance',"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['EMPLOYEE_NUMBER','ENVIRONMENT_SATISFACTION','JOB_INVOLVEMENT','JOB_LEVEL','JOB_SATISFACTION','RELATIONSHIP_SATISFACTION','WORK_LIFE_BALANCE','STOCK_OPTION_LEVEL']] = df[['EMPLOYEE_NUMBER','ENVIRONMENT_SATISFACTION','JOB_INVOLVEMENT','JOB_LEVEL','JOB_SATISFACTION','RELATIONSHIP_SATISFACTION','WORK_LIFE_BALANCE','STOCK_OPTION_LEVEL']].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.iloc[:2,:10].head())\nprint(df.iloc[:2,10:20].head())\nprint(df.iloc[:2,20:].head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def customized_heatmap(corr_df):\n#     corr_mat = corr_df.iloc[1:,:-1].copy()\n    corr_mat = corr_df.copy()\n    \n    #Create masks\n    mask = np.triu(np.ones_like(corr_mat), k=1)\n    \n    # Plot\n    plt.figure(figsize=(20,14))\n    plt.title(\"Heatmap Corrleation\")\n    ax = sns.heatmap(corr_mat, vmin=-1, vmax=1, cbar=False,\n                     cmap='coolwarm', mask=mask, annot=True)\n    \n    # format the text in the plot to make it easier to read\n    for text in ax.texts:\n        t = float(text.get_text())\n        if -0.15 < t < 0.15:\n            text.set_text('')        \n        else:\n            text.set_text(round(t, 2))\n        text.set_fontsize('x-large')\n    plt.xticks( size='x-large')\n    plt.yticks(rotation=0, size='x-large')\n    plt.savefig(\"Correlation Heatmap\")\n    plt.show()\n    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install dython\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from dython.nominal import associations","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_4_corr = df.copy()\n\ndf_4_corr.drop(['EMPLOYEE_NUMBER',\"EMPLOYEE_COUNT\"], inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assoc = associations(df_4_corr,plot=False,bias_correction=False)\ncorr_df = assoc['corr']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customized_heatmap(corr_df)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets see as expected job level has postive and higher correlation with other features like years expeirence, monthly income and the department people are working on. \n\nLooks like relationship with current manager gives a good boost on your chances for your current role and you continue on having your job. "},{"metadata":{},"cell_type":"markdown","source":"## Null Columns"},{"metadata":{},"cell_type":"markdown","source":"## Dealing With Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df.loc[:,missing_df.isnull().sum()>0].info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Age "},{"metadata":{},"cell_type":"markdown","source":"Age has highest correlation with workingyears so, lets make 5 bins 0-9, 9-18.. so on and the average the age value by bins and fill the values."},{"metadata":{"trusted":true},"cell_type":"code","source":"bins = [i for i in range(0,49,9)]\nlabels =[str(val-9)+\"-\"+str(val) for val in bins[1:]]\n\nworking_years_bins = pd.cut(missing_df['TOTAL_WORKING_YEARS'], bins=bins, labels=labels, right=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df['WORKING_YEARS_BINS'] = working_years_bins","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grp_by_age_exp = missing_df[['WORKING_YEARS_BINS','JOB_ROLE','AGE']].groupby(['WORKING_YEARS_BINS']).mean().round()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(grp_by_age_exp.index.values)\nprint(\"*\"*20)\nprint(grp_by_age_exp.AGE.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df.WORKING_YEARS_BINS.unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\n\n# \ndef age_missing_values(cols):\n    age = cols[0]\n    years_experience= cols[1]\n    if math.isnan(age): # if age is missing\n        if years_experience == '1-9':\n            return 32.0\n        elif years_experience == '9-18':\n            return 38.0\n        elif years_experience == '18-27':\n            return 45.0\n        elif years_experience == '27-36':\n            return 52.0\n        else:\n            return 56.0\n    else:# if age is not missing\n        \n        return age\n        \n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"age =missing_df[['AGE','WORKING_YEARS_BINS']].apply(age_missing_values, axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df['AGE']= age","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Distance From Home"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# missing_df.distancefromhome.value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df[['DISTANCE_FROM_HOME','STANDARD_HOURS','OVER_TIME','GENDER']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df.STANDARD_HOURS.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Standard hours seems to have only one values,it would not help us either in analysis or model prediction so lets drop it. "},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df.drop('STANDARD_HOURS', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df[['DISTANCE_FROM_HOME','OVER_TIME','GENDER']].groupby(['GENDER','OVER_TIME']).mean().round(2).unstack(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I am using the logic that gender has a relation with distance from home, and also overtime is differnt genderwise."},{"metadata":{"trusted":true},"cell_type":"code","source":"def fill_distance_frm_home(cols):\n    distance = cols[0]\n    gender = cols[1]\n    overtime=cols[2]\n    \n    if math.isnan(distance):\n        if gender==\"Male\" and overtime==\"Yes\":\n            return 10.82\n        elif gender==\"Male\" and overtime==\"No\":\n            return 9.32\n        elif gender==\"Female\" and overtime==\"No\":\n            return 10.33\n        else:\n            return 10.10\n    else:\n        return distance\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"distance_frm_home = missing_df[['DISTANCE_FROM_HOME','OVER_TIME','GENDER']].apply(fill_distance_frm_home,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df['DISTANCE_FROM_HOME'] = distance_frm_home","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Daily Rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df.loc[:,missing_df.columns.str.contains('MONTH')].columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df.loc[:,missing_df.columns.str.contains('YEAR')].columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df.loc[:,missing_df.columns.str.contains('RATE')].columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df.DAILY_RATE.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df.DAILY_RATE.hist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"looks like distribution is kinda uniform. Theres no clarification what exactly is daily rate. Lets just fill the missing values with mean."},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df.DAILY_RATE.fillna(value=missing_df.DAILY_RATE.mean(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Business Travel"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df.loc[missing_df.BUSINESS_TRAVEL.isna()][['BUSINESS_TRAVEL','JOB_ROLE','DEPARTMENT' ]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets fill the value with most popular travel stats from the same job role."},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df[(missing_df.JOB_ROLE==\"Research Scientist\")]['BUSINESS_TRAVEL'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df[(missing_df.JOB_ROLE==\"Manufacturing Director\")]['BUSINESS_TRAVEL'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df[(missing_df.JOB_ROLE==\"Sales Executive\")]['BUSINESS_TRAVEL'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df[(missing_df.JOB_ROLE==\"Sales Representative\")]['BUSINESS_TRAVEL'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df[(missing_df.JOB_ROLE==\"Laboratory Technician\")]['BUSINESS_TRAVEL'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Travel Rarely* is the popular option."},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df.BUSINESS_TRAVEL.fillna(value=\"Travel_Rarely\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Marital Status"},{"metadata":{},"cell_type":"markdown","source":"Lets check marital stats of same gender of same departments."},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df.MARITAL_STATUS.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df.loc[missing_df.MARITAL_STATUS.isna()][['GENDER','AGE','DEPARTMENT','JOB_ROLE' ]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df[(missing_df.GENDER==\"Female\") & (missing_df.DEPARTMENT==\"Research & Development\")]['MARITAL_STATUS'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df[(missing_df.GENDER==\"Male\") & (missing_df.DEPARTMENT==\"Research & Development\")]['MARITAL_STATUS'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df[(missing_df.GENDER==\"Male\") & (missing_df.DEPARTMENT==\"Sales\")]['MARITAL_STATUS'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can fill married as the people of same gender in same department are mostly married. But this seems realy biased view. So, i'll just drop the missing values. Corrleation fig shows marital status has higher corelation with stock option level but it does not makes any sense to me. "},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df.dropna(inplace=True, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df.loc[:,missing_df.isna().sum()>0].columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like we have filled missing data."},{"metadata":{},"cell_type":"markdown","source":"# EDA "},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_df = missing_df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_df.drop('WORKING_YEARS_BINS',axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Distribution plot\n\nLets plot a dist plot to check if some properites are sure fire way to distinguish attrition, but lets first drop this employee count column it has only one value."},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_df.drop('EMPLOYEE_COUNT', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"int_columns = eda_df.loc[:,eda_df.dtypes!='object'].columns\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sns.pairplot(eda_df[int_columns])\n\nfig,axes = plt.subplots(len(int_columns), figsize=(8,35))\nfor i,col in enumerate(int_columns):\n    axes[i].hist(eda_df[eda_df.ATTRITION == \"No\"][col].values, alpha=0.5, color=\"maroon\", bins=15 )\n    axes[i].hist(eda_df[eda_df.ATTRITION == \"Yes\"][col].values, alpha=0.5, bins=15)\n    axes[i].set_title(col)\n    axes[i].set_yticks(())#cause we are not actually looking for numbers\naxes[0].set_xlabel(\"Feature Columns\")\naxes[0].set_ylabel(\"Frequency\")\naxes[0].legend([\"No\", \"Yes\"], loc=\"best\")\n# plt.savefig(\"Distribution Plot\")\nfig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Unfortunately, it seems the values are quite mixed to be sure. But if we look closely, attrition(value \"Yes\") are higher for employess with lesser monthly income, less total_working_years. And if we check age column either younger employees who are just starting thier career or older employees at retiring age are more likely to leave company than the middle aged ones. \n\nInterestingly if u check that num_of_companies worked, chances of leaving or staying are same as the number of companies increases."},{"metadata":{"trusted":true},"cell_type":"code","source":" # lets drop employee_id\n\neda_df.drop('EMPLOYEE_NUMBER', inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(eda_df.OVER_18.unique())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets drop this column since it has only one values\neda_df.drop('OVER_18', inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"str_columns = eda_df.loc[:,eda_df.dtypes=='object'].columns\neda_df[str_columns].head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Field of Educations"},{"metadata":{},"cell_type":"markdown","source":"Lets change values of education column to get clear meaning."},{"metadata":{"trusted":true},"cell_type":"code","source":"edu_levels= {    \n    1: 'Highschool', \n    2 :'College  ' ,\n    3: 'Bachelor', \n    4: 'Master' ,\n    5 :'PHD'\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_df.EDUCATION = eda_df.EDUCATION.replace(edu_levels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !conda install -c plotly plotly-orca","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = eda_df.EDUCATION.value_counts().index.values\nvalues = eda_df.EDUCATION.value_counts().values\n\nfig = go.Figure()\nfig.add_trace(go.Pie(labels=labels, values=values))\nfig.update_layout(title=\"Qualifications Of Employees\", legend_title=\"Degrees\", template=\"plotly_dark\")\n# fig.write_image(\"/kaggle/working/Employee_Qualifications.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It appears most of the employess are undergraduates, while the ones with doctorates are the least."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nemployee_by_education_norm =eda_df[['AGE','TOTAL_WORKING_YEARS','MONTHLY_INCOME','EDUCATION']].copy()\nemployee_by_education_norm[['AGE','TOTAL_WORKING_YEARS','MONTHLY_INCOME']] = scaler.fit_transform(employee_by_education_norm[['AGE','TOTAL_WORKING_YEARS','MONTHLY_INCOME']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nemployee_grp_by_education = eda_df[['AGE','TOTAL_WORKING_YEARS','MONTHLY_INCOME','EDUCATION']].groupby(['EDUCATION']).mean()\nemployee_grp_by_education_norm = employee_by_education_norm.groupby(['EDUCATION']).mean().sort_values('MONTHLY_INCOME',ascending=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_value= employee_grp_by_education_norm.index.values\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x=x_value, y = employee_grp_by_education_norm.AGE, name=\"Average Age\", hovertext =employee_grp_by_education.AGE.values))\nfig.add_trace(go.Bar(x=x_value, y = employee_grp_by_education_norm.TOTAL_WORKING_YEARS, name=\"Average Experience\", hovertext =employee_grp_by_education.TOTAL_WORKING_YEARS.values))\nfig.add_trace(go.Scatter(x=x_value,\n                         y = employee_grp_by_education_norm.MONTHLY_INCOME,\n                         mode=\"lines+markers\", name=\"Monthly Income\",\n                         hovertext =employee_grp_by_education.MONTHLY_INCOME.values,\n                         marker=dict(size =200*employee_grp_by_education_norm.MONTHLY_INCOME.values)))\n\nfig.update_layout(title=\"Employees Education, Experience and Salary\",\n                  xaxis_title=\"Education Qualifications\",\n                  yaxis_title=\"Normalized Range\",\n                  template=\"plotly_white\", \n                  xaxis_showgrid=False,\n                  yaxis_showgrid=False)\n# fig.write_image(\"/kaggle/working/Employee_Qualifications_n_Salary.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Salary is increasing more with qualifications but difference is not that much. I am quite surprised by so less variation in salary. Lets check salary coluumn to check for outliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_df.MONTHLY_INCOME.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As u can see the salary column is quite streteched, having 50% of values less than 5k and then max being 19k. "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(eda_df.MONTHLY_INCOME)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets check for IQR \n# IQR  = third_quartile - first_quartile\n\niqr = eda_df.MONTHLY_INCOME.describe()[-2] - eda_df.MONTHLY_INCOME.describe()[4]\n\n\n# Upper and Lower boundry of box plot \nupper_bound = 1.5*iqr + eda_df.MONTHLY_INCOME.describe()[-2]\nlower_bound = eda_df.MONTHLY_INCOME.describe()[4] - 1.5*iqr \n\n\nprint(iqr, upper_bound,lower_bound)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, it seems any salary above 16.5k are outliers for this dataset. Lets only take the salary upto 17k and check the graph again."},{"metadata":{"trusted":true},"cell_type":"code","source":"employee_after_filtered_income_norm =eda_df[eda_df.MONTHLY_INCOME <=17000][['AGE','TOTAL_WORKING_YEARS','MONTHLY_INCOME','EDUCATION']].copy()\nemployee_after_filtered_income_norm[['AGE','TOTAL_WORKING_YEARS','MONTHLY_INCOME']] = scaler.fit_transform(employee_after_filtered_income_norm[['AGE','TOTAL_WORKING_YEARS','MONTHLY_INCOME']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"employee_filetered_income_grp_by_education = eda_df[eda_df.MONTHLY_INCOME <=17000][['AGE','TOTAL_WORKING_YEARS','MONTHLY_INCOME','EDUCATION']].groupby(['EDUCATION']).mean()\nemployee_filetered_income_grp_by_education_norm = employee_after_filtered_income_norm.groupby(['EDUCATION']).mean().sort_values('MONTHLY_INCOME',ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_value= employee_filetered_income_grp_by_education_norm.index.values\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x=x_value,\n                     y = employee_filetered_income_grp_by_education_norm.AGE,\n                     name=\"Average Age\", \n                     hovertext =employee_filetered_income_grp_by_education.AGE.values))\nfig.add_trace(go.Bar(x=x_value,\n                     y = employee_filetered_income_grp_by_education_norm.TOTAL_WORKING_YEARS, \n                     name=\"Average Experience\", \n                     hovertext =employee_filetered_income_grp_by_education.TOTAL_WORKING_YEARS.values))\nfig.add_trace(go.Scatter(x=x_value,\n                         y = employee_filetered_income_grp_by_education_norm.MONTHLY_INCOME,\n                         mode=\"lines+markers\", \n                         name=\"Monthly Income\",\n                         hovertext =employee_filetered_income_grp_by_education.MONTHLY_INCOME.values,\n                         marker=dict(size =200*employee_filetered_income_grp_by_education_norm.MONTHLY_INCOME.values)))\n\nfig.update_layout(title=\"Employees Education, Experience and Salary\",\n                  xaxis_title=\"Qualifications\",\n                  yaxis_title=\"Normalized Range\",\n                  template=\"plotly_white\", \n                  xaxis_showgrid=False,\n                  yaxis_showgrid=False)\n# fig.write_image(\"/kaggle/working/Employee_Qualifications_n_Salary.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Salary does increase with qualifications. But college graduates seems to have more salary with less experience in comparision to those bachelor's degree. Though filtering outliers has not changed the order in terms of income. If you check previous graph, you'll notice the experience for each bar has decreased in some amount. \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_df[eda_df.EDUCATION ==\"Highschool\"]['AGE'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"highschool_education = eda_df[eda_df.EDUCATION==\"Highschool\"].sort_values('AGE', ascending=True).copy()\nhighschool_education_norm = highschool_education.copy()\nhighschool_education_norm.loc[:,highschool_education_norm.dtypes!= 'object'] = scaler.fit_transform(highschool_education_norm.loc[:,highschool_education_norm.dtypes!= 'object'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# highschool_education.loc[:,highschool_education.dtypes!= 'object'].columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"highschool_grp_by_age = highschool_education.groupby(['AGE']).mean()\nhighschool_grp_by_age_norm = highschool_education_norm.groupby(['AGE']).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_value= highschool_grp_by_age.index.values\n\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x=x_value, y = highschool_grp_by_age_norm.MONTHLY_INCOME,\n                         name=\"Average Monthly Income\",mode=\"lines+markers\",\n                         hovertext=highschool_grp_by_age.MONTHLY_INCOME.values ))\n\nfig.add_trace(go.Bar(x=x_value, y = highschool_grp_by_age_norm.YEARS_AT_COMPANY, \n                     name=\"Average Years On Company \",\n                     hovertext= highschool_grp_by_age.YEARS_AT_COMPANY.values))\n# fig.update_layout(hovermode=\"x\")\nfig.update_layout(hovermode=\"x unified\")\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Research Paper on Employee Attrition\n\nUp unitl now I was just analyzing based on my intuitions. But i recently went through an research paper on [employee attrition](http://kth.diva-portal.org/smash/get/diva2:1461317/FULLTEXT01.pdf). Here are few highlights I could capture.\n\n### Few keypoints\n\n- **Employee satisfaction is inversely related to Attrition.**\n\n\n- **Effect of Attrition on a company.**\n    - Negative effect on producticity.\n    - Knowledge loss, gone with the employee.\n    - Increase in workload for remaining employees.\n    - Negative impact on companies morale.\n    - More expense on process for hiring and training new employess.\n    \n\n- **Why employess leave job(internal reasons)?**\n    - Disatisfaction\n    - No-commitment to the company\n\n\n- **Factors affecting satisfaction(internal).**\n    - Connectedness to others \n    - Feeling of belonging somewhere.\n    - Feeling of support from organization.\n    - Resonable workload.\n    \n    \n- **Using ML in HRM (Human Resource Management).**\n    - Small data, and sometimes not even recorded.\n    - Decision made by HR have heavy consequences.\n    - Measuring performace is hard, depends on teamwork. And individual performance is difficult to extract from teams performance.\n    - Hiring/Firing is not only based on tangible reasons but also on psychological relations between employees.\n    - ML algorithms can be biased and can not take into account of everything about future employees for instance race can cause bias. *Author also gives example of Amazon removing gender column to remove biases.*\n        \n\n**ML Model Interpreteability**\n\nLocal: Relation between prediction and small subsets of data.\n\nGlobal: Relation between prediction and large segment of data. \n\nGlobal helps to understand how the model works as a whole. Local can be more descriptive of how model is performing.\n\nAs far as the ML alorigthms, author has used SVM, Logistic Regression and Random forest and did comparision between them. \n\n(*Again these all info's are something I took as a note from the research paper I mentioned above and not my work.*)\n   "},{"metadata":{},"cell_type":"markdown","source":"Based on above notes lets extract some relevant columns from our data to explore. "},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_df.ENVIRONMENT_SATISFACTION.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the employees have higher satisfaction meaning most of them have good relation with other co-workers."},{"metadata":{},"cell_type":"markdown","source":"## Dis-satisfaction\n\nLets make some groups by Attrition and level of satisfaction."},{"metadata":{"trusted":true},"cell_type":"code","source":"# eda_df[(eda_df.ATTRITION==\"Yes\") & (eda_df.JOB_SATISFACTION==\"1\")]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Attrition And Environment Satisfaction \nattrition_n_env_satisfaction = eda_df[['ATTRITION','ENVIRONMENT_SATISFACTION','JOB_SATISFACTION']].groupby(['ATTRITION','ENVIRONMENT_SATISFACTION']).count().unstack(0)\nattrition_n_env_satisfaction.columns= ['Attrition_No', \"Attrition_Yes\"]\nattrition_n_env_satisfaction.index= ['level_1','level_2','level_3','level_4']\n\n\n# Attrition And  JOB_INVOLVEMENT\nattrition_n_job_involvement = eda_df[['ATTRITION','JOB_INVOLVEMENT','JOB_SATISFACTION']].groupby(['ATTRITION','JOB_INVOLVEMENT']).count().unstack(0)\nattrition_n_job_involvement.columns= ['Attrition_No', \"Attrition_Yes\"]\nattrition_n_job_involvement.index= ['level_1','level_2','level_3','level_4']\n\n\n# Attrition And  JOB_SATISFACTION\nattrition_n_job_satisfaction = eda_df[['ATTRITION','JOB_INVOLVEMENT','JOB_SATISFACTION']].groupby(['ATTRITION','JOB_SATISFACTION']).count().unstack(0)\nattrition_n_job_satisfaction.columns= ['Attrition_No', \"Attrition_Yes\"]\nattrition_n_job_satisfaction.index= ['level_1','level_2','level_3','level_4']\n\n\n# Attrition And  RELATIONSHIP_SATISFACTION\nattrition_n_rel_satisfaction = eda_df[['ATTRITION','JOB_INVOLVEMENT','RELATIONSHIP_SATISFACTION']].groupby(['ATTRITION','RELATIONSHIP_SATISFACTION']).count().unstack(0)\nattrition_n_rel_satisfaction.columns= ['Attrition_No', \"Attrition_Yes\"]\nattrition_n_rel_satisfaction.index= ['level_1','level_2','level_3','level_4']\n\n\n# Attrition And  WORK_LIFE_BALANCE\nattrition_n_work_life_bal = eda_df[['ATTRITION','JOB_INVOLVEMENT','WORK_LIFE_BALANCE']].groupby(['ATTRITION','WORK_LIFE_BALANCE']).count().unstack(0)\nattrition_n_work_life_bal.columns= ['Attrition_No', \"Attrition_Yes\"]\nattrition_n_work_life_bal.index= ['level_1','level_2','level_3','level_4']\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #Now Lets plot them by satisfaction level and attrition No\n\n# fig = go.Figure()\n\n# fig.add_trace(go.Scatter(x= attrition_n_work_life_bal.index.values, y= attrition_n_work_life_bal.Attrition_Yes, name=\"Work Life Balance\"))\n\n\n# fig.add_trace(go.Scatter(x= attrition_n_rel_satisfaction.index.values, y= attrition_n_rel_satisfaction.Attrition_Yes, name=\"Relatoinship Satisfaction\"))\n# fig.add_trace(go.Scatter(x= attrition_n_env_satisfaction.index.values, y= attrition_n_env_satisfaction.Attrition_Yes, name=\"Environment Satisfaction\"))\n# fig.add_trace(go.Scatter(x= attrition_n_job_involvement.index.values, y= attrition_n_job_involvement.Attrition_Yes, name=\"Job Involivement \"))\n# fig.add_trace(go.Scatter(x= attrition_n_job_satisfaction.index.values, y= attrition_n_job_satisfaction.Attrition_Yes, name=\"Job Satisfaction\"))\n\n# fig.update_layout(title=\"Satisfaction Lvl Vs Attrition = 'Yes'\", \n#                  xaxis_title=\"Satisfaction Level, more the better\",\n#                 yaxis_title=\"Frequency\",\n#                   template=\"plotly_white\", \n#                   xaxis_showgrid=False,\n#                   yaxis_showgrid=False,\n#                   legend_title=\"Features\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now Lets plot them by satisfaction level and attrition No\n\nfig = go.Figure()\n\nfig.add_trace(go.Bar(x= attrition_n_work_life_bal.index.values, y= attrition_n_work_life_bal.Attrition_Yes, name=\"Work Life Balance\"))\n\n\nfig.add_trace(go.Bar(x= attrition_n_rel_satisfaction.index.values, y= attrition_n_rel_satisfaction.Attrition_Yes, name=\"Relatoinship Satisfaction\"))\nfig.add_trace(go.Bar(x= attrition_n_env_satisfaction.index.values, y= attrition_n_env_satisfaction.Attrition_Yes, name=\"Environment Satisfaction\"))\nfig.add_trace(go.Bar(x= attrition_n_job_involvement.index.values, y= attrition_n_job_involvement.Attrition_Yes, name=\"Job Involivement \"))\nfig.add_trace(go.Bar(x= attrition_n_job_satisfaction.index.values, y= attrition_n_job_satisfaction.Attrition_Yes, name=\"Job Satisfaction\"))\n\nfig.update_layout(title=\"Satisfaction Lvl Vs Attrition = 'Yes'\", \n                 xaxis_title=\"Satisfaction Level, more the better\",\n                yaxis_title=\"Frequency\",\n                  template=\"plotly_white\", \n                  xaxis_showgrid=False,\n                  yaxis_showgrid=False,\n                  legend_title=\"Features\")\n\n# fig.write_image(\"/kaggle/working/Satisfaction_Lvls_n_Attrition_Yes.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now Lets plot them by satisfaction level and attrition No\n\nfig = go.Figure()\n\nfig.add_trace(go.Bar(x= attrition_n_work_life_bal.index.values, y= attrition_n_work_life_bal.Attrition_No, name=\"Work Life Balance\"))\n\n\nfig.add_trace(go.Bar(x= attrition_n_rel_satisfaction.index.values, y= attrition_n_rel_satisfaction.Attrition_No, name=\"Relatoinship Satisfaction\"))\nfig.add_trace(go.Bar(x= attrition_n_env_satisfaction.index.values, y= attrition_n_env_satisfaction.Attrition_No, name=\"Environment Satisfaction\"))\nfig.add_trace(go.Bar(x= attrition_n_job_involvement.index.values, y= attrition_n_job_involvement.Attrition_No, name=\"Job Involivement \"))\nfig.add_trace(go.Bar(x= attrition_n_job_satisfaction.index.values, y= attrition_n_job_satisfaction.Attrition_No, name=\"Job Satisfaction\"))\n\nfig.update_layout(title=\"Satisfaction Lvl Vs Attrition = 'No'\", \n                 xaxis_title=\"Satisfaction Level, more the better\",\n                yaxis_title=\"Frequency\",\n                  template=\"plotly_white\", \n                  xaxis_showgrid=False,\n                  yaxis_showgrid=False,\n                  legend_title=\"Features\")\n# fig.write_image(\"/kaggle/working/Satisfaction_Lvls_n_Attrition_No.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you check the graph, work life balance and involvement of employee's involvement needs to be at most satisfying level incomparision to other factors. \n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# eda_df[['ENVIRONMENT_SATISFACTION','ATTRITION', 'DEPARTMENT', 'GENDER','JOB_INVOLVEMENT','JOB_LEVEL','JOB_SATISFACTION','MARITAL_STATUS',\n#        'OVER_TIME','PERFORMANCE_RATING','RELATIONSHIP_SATISFACTION', 'WORK_LIFE_BALANCE','YEARS_SINCE_LAST_PROMOTION']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Selection Using PCA"},{"metadata":{},"cell_type":"markdown","source":"lets drop the gender column before we approach pca."},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_df = eda_df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_df.drop('GENDER', inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"int_columns = feature_df.loc[:,feature_df.dtypes==\"int\"].columns\nobj_columns = feature_df.loc[:,feature_df.dtypes!=\"int\"].columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dummify "},{"metadata":{"trusted":true},"cell_type":"code","source":"dummified_feature_df = pd.get_dummies(feature_df.loc[:,feature_df.columns != \"ATTRITION\"],drop_first=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target =feature_df['ATTRITION']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Normalize"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummified_feature_df[int_columns] = scaler.fit_transform(dummified_feature_df[int_columns])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, KFold, cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(dummified_feature_df, target, test_size=0.3, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_hold, X_test_final, y_hold, y_test_final = train_test_split(X_test, y_test, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_folds = 10\nscoring = \"accuracy\"\nmodels=[]\nrand_seed= 101\n\nmodels.append((\"Knn\",KNeighborsClassifier(n_neighbors=5,p=2,leaf_size=10,) ))\nmodels.append((\"Svm\",SVC(random_state=rand_seed )))\nmodels.append((\"Rf\", RandomForestClassifier(n_estimators=50,max_depth=5,random_state=rand_seed )))\n\n\n\nresults=[]\nnames=[]\nmetrics=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name, model in models:\n    kfold = KFold(n_splits=num_folds, random_state=rand_seed, shuffle=True)\n    cv_score = cross_val_score(model,X_train,y_train, cv=kfold, scoring=scoring)\n    \n    names.append(name)\n    results.append(cv_score)\n    metrics.append(cv_score.mean())\n    \n    print(\"{name}: {score}\".format(name=name,score= cv_score.mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These following codes are commented to save version faster."},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Number of trees in random forest\n# n_estimators = [i for i in range(200,2001, 200)]\n# # Number of features to consider at every split\n# max_features = ['auto', 'sqrt']\n# # Maximum number of levels in tree\n# max_depth = [i for i in range(10, 111,10)]\n# max_depth.append(None)\n# # Minimum number of samples required to split a node\n# min_samples_split = [2, 5, 10]\n# # Minimum number of samples required at each leaf node\n# min_samples_leaf = [1, 2, 4]\n# # Method of selecting samples for training each tree\n# bootstrap = [True, False]\n# # Create the random grid\n# random_grid = {'n_estimators': n_estimators,\n#                'max_features': max_features,\n#                'max_depth': max_depth,\n#                'min_samples_split': min_samples_split,\n#                'min_samples_leaf': min_samples_leaf,\n#                'bootstrap': bootstrap}\n# print(random_grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# COmmented to save version faster\n\n\n# rf = RandomForestClassifier()\n\n\n# # Random search of parameters, using 3 fold cross validation, \n# # search across 80 different combinations, and use all available cores\n# rf_random_cv = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 80, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n# # Fit the random search model\n# rf_random_cv.fit(X_train,y_train)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(rf_random_cv.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Results from best parmas of randmonized RF :\n\n{'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 50, 'bootstrap': False}\n\n\n\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid_rf = {\n    'bootstrap':[False],\n    'max_depth': [10,20,30,20,50],\n    'max_features': ['auto'],\n    'min_samples_leaf': [ 1,3,4, 8],\n    'min_samples_split': [2,4,6,8],\n    'n_estimators': [200,400,600,1200,1000]\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Instantiate the grid search model\n# grid_search_cv_rf = GridSearchCV(RandomForestClassifier(), param_grid = param_grid_rf, \n#                           cv = 10, n_jobs = -1, verbose = 0)\n\n# grid_search_cv_rf.fit(X_train, y_train)\n\n\n#Commented to run version ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(grid_search_cv_rf.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_rf= RandomForestClassifier(bootstrap=False,                                \n                                   max_depth=50,\n                                   min_samples_leaf=8,\n                                   min_samples_split=8,\n                                   n_estimators=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_start = time.time()\n\nfinal_rf.fit(X_train,y_train)\nrf_end = time.time()\neval_time_rf = rf_end -rf_start\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(\"Accuracy For Random Forest on Test Set: {}.\".format(pipe.score(X_test_final,y_test_final)*100) )\nprint(\"Accuracy For Random Forest on Hold out Set: {}.\".format(final_rf.score(X_hold,y_hold)*100) )\nprint(\"Total time taken by RF to fit the model: {:.2f} sec\".format(eval_time_rf))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Selection with PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_transformed= pca.fit_transform(dummified_feature_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_transformed_df = pd.DataFrame(pca.components_, columns=dummified_feature_df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,5))\nsns.heatmap(pca_transformed_df,cmap=\"viridis\", yticklabels=[\"Comp 1\", \"Comp 2\"] ,lw=1,linecolor=\"black\" );\nplt.yticks(rotation=360);\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.abs(pca_transformed_df.iloc[0,:]).sort_values().iplot(kind=\"bar\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.abs(pca_transformed_df.iloc[1,:]).sort_values().iplot(kind=\"bar\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.abs(pca_transformed_df.iloc[0,:].sort_values())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}