{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# The link of the data set:\nhttps://www.kaggle.com/datatattle/covid-19-nlp-text-classification","metadata":{}},{"cell_type":"markdown","source":"## Importing the libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport re\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read the data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/covid-19-nlp-text-classification/Corona_NLP_train.csv', encoding = \"ISO-8859-1\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Explore the data","metadata":{}},{"cell_type":"code","source":"f'The data has {df.shape[0]} Rows and {df.shape[1]} Columns'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot the Sentiment column","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.countplot(y=df['Sentiment'])\nplt.yticks(size=13)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Remove the unnecessary columns","metadata":{}},{"cell_type":"code","source":"df = df.iloc[:,4:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Sentiment'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Text Preprocessing","metadata":{}},{"cell_type":"code","source":"# Create a function to clean the tweets\ndef cleanTxt(text):\n    text = re.sub('@[A-Za-z0â€“9]+', '', text) #Removing @mentions\n    text = re.sub('#', '', text) # Removing '#' hash tag\n    text = re.sub('RT[\\s]+', '', text) # Removing RT\n    text = re.sub('https?:\\/\\/\\S+', '', text) # Removing hyperlink\n \n    return text\n\n\ndf = df[df['Sentiment'] != \"Neutral\"]\ndf = df[df['Sentiment'] != \"Extremely Negative\"]\ndf = df[df['Sentiment'] != \"Extremely Positive\"]\n\n# apply the function (Clean Text)\ndf['OriginalTweet'] = df['OriginalTweet'].apply(cleanTxt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Find subjectivity and polarity","metadata":{}},{"cell_type":"code","source":"# Create a function to get the subjectivity\ndef getSubjectivity(text):\n    return TextBlob(text).sentiment.subjectivity\n\n# Create a function to get the polarity\ndef getPolarity(text):\n    return  TextBlob(text).sentiment.polarity\n\n\n# Create two new columns 'Subjectivity' & 'Polarity'\ndf['Subjectivity'] = df['OriginalTweet'].apply(getSubjectivity)\ndf['Polarity'] = df['OriginalTweet'].apply(getPolarity)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot a Word Cloud","metadata":{}},{"cell_type":"code","source":"allWords = ' '.join([twts for twts in df['OriginalTweet']])\nwordCloud = WordCloud(width=500, height=300, random_state=21, max_font_size=110).generate(allWords)\n\n\nplt.figure(figsize=(10,6))\nplt.imshow(wordCloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Comvert the probability to Negative or Positive","metadata":{}},{"cell_type":"code","source":"def getAnalysis(score):\n    if score < 0:\n        return 'Negative'\n    else:\n        return 'Positive'\ndf['Analysis'] = df['Polarity'].apply(getAnalysis)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Show the top 10 Positive Tweets","metadata":{}},{"cell_type":"code","source":"print('Printing positive tweets:\\n')\nj=1\nsortedDF = df.sort_values(by=['Polarity']) #Sort the tweets\nfor i in range(sortedDF.shape[0]):\n    if j > 10:\n        break\n    if( sortedDF.iloc[i,-1] == 'Positive'):\n        print(str(j) + ') '+ sortedDF.iloc[i,0])\n        print()\n        j += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Show the top 10 Negative Tweets","metadata":{}},{"cell_type":"code","source":"print('Printing Negative tweets:\\n')\nj=1\nsortedDF = df.sort_values(by=['Polarity'], ascending=False) #Sort the tweets\nfor i in range(sortedDF.shape[0]):\n    if j > 10:\n        break\n    if( sortedDF.iloc[i,-1] == 'Negative'):\n        print(str(j) + ') '+ sortedDF.iloc[i,0])\n        print()\n        j += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot the Subjectivity and the Polarity of the first 100 row","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,6)) \nfor i in range(100):\n    plt.scatter(df.iloc[i,-2], df.iloc[i,-3], color='skyblue') \n# plt.scatter(x,y,color)   \nplt.title('Sentiment Analysis', size=20) \nplt.xlabel('Polarity', size=15) \nplt.ylabel('Subjectivity', size=15) \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Classify with Keras and tensorflow","metadata":{}},{"cell_type":"markdown","source":"## Import the libraries","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils.np_utils import to_categorical","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read the data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/covid-19-nlp-text-classification/Corona_NLP_train.csv', encoding = \"ISO-8859-1\")\ndf = df[['OriginalTweet', 'Sentiment']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Map Negative and Extremely Negative to 0 else 1","metadata":{}},{"cell_type":"code","source":"def getAnalysis(score):\n    if score == 'Negative' or score == 'Extremely Negative':\n        return 0\n    else:\n        return 1\ndf['Sentiment'] = df['Sentiment'].apply(getAnalysis)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = Tokenizer(num_words=1500, split=' ')\ntokenizer.fit_on_texts(df['OriginalTweet'].values)\n\nX = tokenizer.texts_to_sequences(df['OriginalTweet'])\nX = pad_sequences(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build the model","metadata":{}},{"cell_type":"code","source":"embed_dim = 128\nlstm_out = 196\n\nmodel = Sequential()\nmodel.add(Embedding(1500, embed_dim,input_length = 28))\nmodel.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(1,activation='softmax'))\nmodel.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Label encoder for the Sentiment column","metadata":{}},{"cell_type":"code","source":"Le = LabelEncoder()\ny = Le.fit_transform(df['Sentiment'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split the data","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## train the model ","metadata":{}},{"cell_type":"code","source":"model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=5, batch_size=32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(X_test,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}