{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h3>Given:</h3>\nThe data contains features extracted from the silhouette of\nvehicles in different angles. Four \"Corgie\" model vehicles were\nused for the experiment: a double decker bus, Cheverolet van,\nSaab 9000 and an Opel Manta 400 cars. This particular\ncombination of vehicles was chosen with the expectation that\nthe bus, van and either one of the cars would be readily\ndistinguishable, but it would be more difficult to distinguish\nbetween the cars.\n<h3>Objective:</h3>\nApply the dimensionality reduction technique â€“ PCA and train\na model using principal components instead of training the\nmodel using just the raw data."},{"metadata":{},"cell_type":"markdown","source":"<h2>1. Reading the data</h2>"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Importing the libraries\nimport pandas as pd        # for data manipulation\nimport seaborn as sns      # for statistical data visualisation\nimport numpy as np         # for linear algebra\nimport matplotlib.pyplot as plt      # for data visualization\nfrom scipy import stats        # for calculating statistics\n\n# Importing various machine learning algorithm from sklearn\n\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score\nfrom sklearn.metrics import mean_absolute_error,roc_curve,auc,accuracy_score\nfrom scipy.stats import zscore\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dataframe= pd.read_csv(\"vehicle.csv\")  # Reading the data\ndataframe.head()   # showing first 5 datas","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dataframe.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data given has  19 columns and consist of 846 data. And all the data is read correctly."},{"metadata":{"trusted":false},"cell_type":"code","source":"dataframe.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Obv</h3>\n    The above information shows the following<br>\n    a. The attributes are either int or float except class which is object <br>\n    b. Further there maybe necessary to label encode class objects<br>\n       <br><br>\n"},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"dataframe.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are many missing values. Should impute them."},{"metadata":{"trusted":false},"cell_type":"code","source":"dataframe.apply(lambda x: len(x.unique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>From  the data:</h4>\n\nAll variable have interval data except class attribute\n"},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"dataframe.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>We can infer that:</h3>\ncompactness is  normal distribution <br>\ncircularity is Slightly right skewed as mean and max have wide range gap<br>\ndistance_circularity as Left skewed<br>\nskewness_about as right skewed<br>\n\n\n\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"dataframe.fillna(dataframe.mean(),axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dataframe.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dataframe.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dt=dataframe.iloc[:,0:18].copy()\ndt","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"sns.pairplot(dt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of these columns share a strong correlation with each other. <br>\nBoth negative and positive correlation can be seen among the data<br>\nWe can also notice certain outliers in this data."},{"metadata":{"trusted":false},"cell_type":"code","source":"dataframe['class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Class will be our target column<h3>"},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"f = plt.subplots(1, figsize=(12,6))\n\ncolors = [\"#FA5858\", \"#64FE2E\",\"#ac3e9a\"]\nlabels =\"Car\", \"Bus\",\"Van\"\n\nplt.suptitle('Information on Term Deposits', fontsize=20)\n\nplt.pie(dataframe['class'].value_counts(),labels=labels,explode=(0,0.1,0.15),shadow=True,colors=colors, startangle=25,autopct='%1.1f%%')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is a data imbalance as car has a significantly higher count as compared to bus and van.The count of car is higher as because there are 2 type of car present. And also we can see van has the lowest count."},{"metadata":{"trusted":false},"cell_type":"code","source":"dataframe.skew()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.subplot(6,1,1)\nsns.boxplot(dataframe.compactness)\nplt.subplot(6,1,2)\nsns.boxplot(dataframe.circularity)\nplt.subplot(6,1,3)\nsns.boxplot(dataframe.distance_circularity)\nplt.subplot(6,1,4)\nsns.boxplot(dataframe.radius_ratio)\nplt.subplot(6,1,5)\nsns.boxplot(dataframe[\"pr.axis_aspect_ratio\"])\nplt.subplot(6,1,6)\nsns.boxplot(dataframe[\"scaled_radius_of_gyration.1\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.subplot(6,1,1)\nsns.distplot(dataframe.compactness)\nplt.subplot(6,1,2)\nsns.distplot(dataframe.circularity)\nplt.subplot(6,1,3)\nsns.distplot(dataframe.distance_circularity)\nplt.subplot(6,1,4)\nsns.distplot(dataframe.radius_ratio)\nplt.subplot(6,1,5)\nsns.distplot(dataframe[\"pr.axis_aspect_ratio\"])\nplt.subplot(6,1,6)\nsns.distplot(dataframe[\"scaled_radius_of_gyration.1\"])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Obv</h3>\n<li>Compactness column shows an approximately normal distribution curve while having no outliers.</li>\n\n<li>The distribution plot of the circularity column has 3 peaks and is right skewed.</li><li>Distance Circularity is left skewed and has 2 peaks in the plot.\n</li>\n<li>Radius ratio has outliers and is right screwed a bit</li>\n<li>Pr.Axis aspect ratio is approx normally distributed as well as right skewed and there is presence of outliers.</li>\n<li> Scaled_radius_of_gyration.1 approximatly normal distribution with no outliers.</li>\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"fig,(a1,a2)=plt.subplots(nrows = 1, ncols = 2, figsize = (13, 5))\nsns.boxplot(x = 'hollows_ratio', data = dataframe, orient = 'v', ax = a1)\nsns.distplot(dataframe.hollows_ratio, ax = a2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hollow_ratio has 2 peaks and no outliers in the data."},{"metadata":{"trusted":false},"cell_type":"code","source":"dataframe[\"class\"].hist(bins=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As in the data, the count of car is more compared to bus and van. Due to which there maybe chances that the model perdiction will be effected due to this.<br>\n<h2>Checking the influence of various attributes on customer subscribing term deposit </h2>\n\nHere we can see some attributes are positively correlated (ex. circularity and max.length_rectangularity)<br>\nnegatively correlated (elongatedness and scatter_ratio<br>\nand no correlation at all (compactness and skewness_about.1)\n<br>Checking the effect of these variables om target i.e class attribute\n<h3>Influence of Elongatedness & scatter_ratio on Target</h3>\n\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nsns.scatterplot(x='elongatedness',y='scatter_ratio' ,data=dataframe,hue='class')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>Obv:</h4>  Looks like bus has lesser elongatedness  but scatter ratio is highest<br>\nvan is quite opposite to bus where elongatedness is higher and scatter ratio  is in lesser range<br>\n<h3>Influence of circularity & max.length_rectangularity on target\n</h3>\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"fig,(a1,a2)=plt.subplots(nrows = 2, ncols = 1, figsize = (13, 15))\nsns.boxplot(x='class',y='max.length_rectangularity',data=dataframe,ax=a1)\nsns.scatterplot(x='circularity',y='max.length_rectangularity',hue='class',data=dataframe,ax=a2)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>Obv</h4>a. car has a wide range of cicularity and also max.length_rectangularity.<br>\nb. Whereas the bus and van do not.<br>\nc. So cicularity and max.lenght_rectangularity can be used to classify mainly bus and van but not cars"},{"metadata":{},"cell_type":"markdown","source":"\n<h3>Influence of scaled_radius_of_gyration.1 on class\n</h3>"},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.catplot(x=\"class\",y='scaled_radius_of_gyration.1', data=dataframe)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Obv</h3>\nWe can see that scaled_radius_of_gyration.1 cant only use alone to classify the vehicles."},{"metadata":{},"cell_type":"markdown","source":"<h3>Influence of circularity and distance_circularity on class\n</h3>"},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.lineplot(x='circularity',y='distance_circularity',data=dataframe,hue='class')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>Obv</h4>\nThe distance_circularity increases as circularity increases for all the class of vehicles.\n<br>\nalso we can infer that the van has lesser cirularity and distance_circularity than others\n"},{"metadata":{},"cell_type":"markdown","source":"\n<h2>Corelation of Attributes</h2>"},{"metadata":{"trusted":false},"cell_type":"code","source":"corelation=dt.corr()\ncorelation","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(20,20))\na=sns.heatmap(corelation,annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Obv</h3>\n<li>Here most of the column share high collinearity both negatively and positively. </li>\n<li>And also we can see that elongatedness is most negatively corelated with almost all the data.</li>\n<li>This should not be the case in the model.</li>\n<li>As data are correlated, we can drop some of the columns which are corelated.</li>\n\n<h2>Preparing the data for modeling</h2>\n"},{"metadata":{},"cell_type":"markdown","source":"\n<h2>Classification Models</h2>\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"dataframe.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"features=['compactness', 'circularity', 'distance_circularity', 'radius_ratio',\n       'pr.axis_aspect_ratio', 'max.length_aspect_ratio', 'scatter_ratio',\n       'elongatedness', 'pr.axis_rectangularity', 'max.length_rectangularity',\n       'scaled_variance', 'scaled_variance.1', 'scaled_radius_of_gyration',\n       'scaled_radius_of_gyration.1', 'skewness_about', 'skewness_about.1',\n       'skewness_about.2', 'hollows_ratio']\nX=dataframe[features]\nY=dataframe['class']         ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Normalising the data"},{"metadata":{"trusted":false},"cell_type":"code","source":"X=X.apply(zscore)\nX","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Label Encoding the target \"class\" column where<br>\nvan is label encoded as 1 <br>\ncar is label encoded as 2 <br>\nbus is label encoded as 3<br>"},{"metadata":{"trusted":false},"cell_type":"code","source":"Y.replace(['van','car','bus'],[1,2,3],inplace=True)\nY","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3> Splitting the Data</h3>\nSplitting the model in 7:3 ratio"},{"metadata":{"trusted":false},"cell_type":"code","source":"train_X,test_X,train_y,test_y=train_test_split(X,Y,test_size=0.3,random_state=1)\ntrain_X.count() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_X.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_X.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Using SVC for prediction</h2><br>\nTrianing the model"},{"metadata":{"trusted":false},"cell_type":"code","source":"parameters={\n    'C':[0.01,0.25,0.5,1],\n    'kernel':['rbf','linear']\n}\nmodel=SVC()\nbest_SVC=GridSearchCV(model,param_grid=parameters,scoring='accuracy',cv=10)\nbest_SVC","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predicting from the trained model and showing the confusion matrix"},{"metadata":{"trusted":false},"cell_type":"code","source":"best_SVC.fit(train_X,train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"best_SVC.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"svm_model=SVC(C=1,kernel='rbf',random_state=1)\nsvm_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"svm_model=svm_model.fit(train_X,train_y)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"predict=svm_model.predict(test_X)\nprint(predict[0:1000])\nmetrics=confusion_matrix(test_y,predict)\nmetrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.heatmap(metrics,annot=True,fmt='g',cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"print(classification_report(test_y,predict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"svm_accuracy=accuracy_score(test_y,predict)\nsvm_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\nsvm_eval = cross_val_score(estimator = svm_model, X = train_X, y = train_y, cv = 10)\nsvm_eval.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Obv:</h3>\nThe heat map shows that the model perdicts the outcome pretty good as the data are pretty much correlated.<br>\nThe f1 score is also looks fine (91%)<br>\nAs we can see the accuracy is 95.27% which indicates the model predicts well enough.<br>\nThe mean after the cross validation is also showing the better result 95.94%<br>\n<br>\n<h2> Using PCA with SVM model</h2>\n<br>\n\n"},{"metadata":{},"cell_type":"markdown","source":"Giving n_components as 18 i.e the number of columns (Except class)"},{"metadata":{"trusted":false},"cell_type":"code","source":"pca=PCA(n_components=18)\npca","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fitting the mondel the pca and displaying Eigen values"},{"metadata":{"trusted":false},"cell_type":"code","source":"pca.fit(X)\npca.explained_variance_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Variance ratio will  be"},{"metadata":{"trusted":false},"cell_type":"code","source":"pca.explained_variance_ratio_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And the eigen vectors will be"},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"pca.components_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bar plotting the eigen values"},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.barplot(x=list(range(1,19)),y=pca.explained_variance_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Elbow plotting the eigen values"},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.plot(list(range(1,19)),pca.explained_variance_,'ro-', linewidth=2)\nplt.title('Elbow Plot')\nplt.xlabel('Principal Component')\nplt.ylabel('Eigenvalue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.step(list(range(1,19)), np.cumsum(pca.explained_variance_ratio_), where = 'mid')\nplt.ylabel('Cum of variation explained')\nplt.xlabel('Eigen value')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have 8 components in this model that explain 95% variation in this data.\n<br>\nSo giving n_components as 8 and performing PCA"},{"metadata":{"trusted":false},"cell_type":"code","source":"pca=PCA(n_components=8)\npca.fit(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The eigen value, variance ratio will be"},{"metadata":{"trusted":false},"cell_type":"code","source":"pca.explained_variance_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pca.explained_variance_ratio_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pca_X = pca.transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.pairplot(pd.DataFrame(pca_X))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we can see that the correlation is removed among the data and is ready to be get trained on. <br>The data is reduced to 8 columns"},{"metadata":{},"cell_type":"markdown","source":"Again splitting and training the model"},{"metadata":{"trusted":false},"cell_type":"code","source":"train_X,test_X,train_y,test_y=train_test_split(pca_X,Y,test_size=0.3,random_state=1)\npd.DataFrame(train_X).count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Preparing SVC model with GridSearch for getting the best model</h3>"},{"metadata":{"trusted":false},"cell_type":"code","source":"parameters={\n    'C':[0.01,0.25,0.5,1],\n    'kernel':['rbf','linear']\n}\nmodel=SVC()\nbest_PCA_SVC_grid=GridSearchCV(model,param_grid=parameters,scoring='accuracy',cv=10)\nbest_PCA_SVC_grid","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Fitting the model with gridsearch</h3>"},{"metadata":{"trusted":false},"cell_type":"code","source":"best_PCA_SVC_grid.fit(train_X,train_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Getting the best parameters for the model"},{"metadata":{"trusted":false},"cell_type":"code","source":"best_PCA_SVC_grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3> Trainig the model on the above parameters<h3>"},{"metadata":{"trusted":false},"cell_type":"code","source":"best_PCA_SVC=SVC(C=1,kernel='rbf',random_state=1)\nbest_PCA_SVC","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fitting the data in the model"},{"metadata":{"trusted":false},"cell_type":"code","source":"best_PCA_SVC=best_PCA_SVC.fit(train_X,train_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predicting from the model"},{"metadata":{"trusted":false},"cell_type":"code","source":"predict=best_PCA_SVC.predict(test_X)\nprint(predict[0:1000])\nmetrics_pca=confusion_matrix(test_y,predict)\nmetrics_pca","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.heatmap(metrics_pca,annot=True,fmt='g',cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(classification_report(test_y,predict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pca_svm_accuracy=accuracy_score(test_y,predict)\npca_svm_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\npca_svm_eval = cross_val_score(estimator = best_PCA_SVC, X = train_X, y = train_y, cv = 10)\npca_svm_eval.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Obv:</h3>\nThe heat map shows that the model perdicts the outcome pretty good as the data are pretty much correlated.<br>\nThe f1 score is also looks fine (90%)<br>\nAs we can see the accuracy is 94.09% which indicates the model predicts well enough.<br>\nThe mean after the cross validation is also showing the better result 94.4%<br>"},{"metadata":{},"cell_type":"markdown","source":"<h2>Comparig the model </h2><h4>with and without PCA</h4>"},{"metadata":{"trusted":false},"cell_type":"code","source":"data=[[svm_accuracy,svm_eval.mean()],[pca_svm_accuracy,pca_svm_eval.mean()]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"compare=pd.DataFrame(data,columns=[\"Accuracy\",\"Cross validation Mean\"],index=[\"SVC\",\"SVC with PCA\"])\ncompare","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.subplot(2,2,1)\nsns.heatmap(metrics,annot=True,fmt='g',cmap='Blues')\nplt.subplot(2,2,2)\nsns.heatmap(metrics_pca,annot=True,fmt='g',cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>We can see that SVM is good model for classification as it gives good accuracy score<br>\n    And also Principal Companent Analysis is good for reducing the dimension of the dataset ( here from 18 to 8 ) with neglegible accuracy and cross validation score (nearly 1 % of decrease) which is good."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}