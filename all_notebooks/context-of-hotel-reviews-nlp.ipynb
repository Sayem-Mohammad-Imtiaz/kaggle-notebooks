{"cells":[{"metadata":{"_uuid":"d12f520a017611e1d1d71954d65bef5cde87b565","_cell_guid":"e4a23f25-7cb6-460a-b41e-3e4048300ef1"},"cell_type":"markdown","source":"**Happy to stay here or not? – Hotel reviews**"},{"metadata":{"_uuid":"f4db780b8c88ddadf15f33c2b41c5bdf22f71a18","_cell_guid":"e5e1544d-2986-4752-b214-344b9443ca78"},"cell_type":"markdown","source":"**Introduction**\nHere I will use the data published by Anurag Sharma about hotel reviews that were given by costumers.  \nThe data is given in two files, a train and test. \n* *train.csv* – is the training data, containing unique **User_ID** for each entry with the review entered by a costumer and the browser and device used. The target variable is **Is_Response**, a variable that stats whether the costumes was **happy** or **not_happy** while staying in the hotel.  This type of variable makes the project to a classification problem. \n* *test.csv* – is the testing data, contains similar headings as the train data, without the target variable. \n"},{"metadata":{"_uuid":"cafe84417eedd74772afcd4fd2ff700ae0372f1f","_cell_guid":"4e46ff64-cc18-4037-90a9-943180667b79"},"cell_type":"markdown","source":"**Helper functions and libraries**"},{"metadata":{"_uuid":"6a8bd764b1d09deb61df05398fc5f36db44cbcf3","_cell_guid":"4b113dd1-b917-451c-8dd3-072a90f00172","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n#visualizations\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\npal = sns.color_palette()\nfrom wordcloud import WordCloud, STOPWORDS\n\n#text preprocessing\nfrom sklearn.preprocessing import LabelEncoder\nimport nltk\nfrom nltk.corpus import stopwords\neng_stopwords = set(stopwords.words(\"english\"))\nimport string\nimport re\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom scipy.sparse import hstack, csr_matrix\n\n#ML model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score, make_scorer\nfrom sklearn.model_selection import KFold, cross_val_score\n\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"00cfc7281ccec740f66ca7d82a59602a1d29576b","_cell_guid":"b843feae-8efd-448d-9337-2558dd94d963"},"cell_type":"markdown","source":"**Load data**"},{"metadata":{"_uuid":"872d2446f9d6c06a32aff602ca2125ee87e00dae","_cell_guid":"242b8a7e-c1b4-4289-b0ae-42b5b1bdbe3a","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/train.csv')\ndf_test = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05a3e35a20b3bcc18e84b146a27626946a548736","_cell_guid":"c64d9b03-7a31-4fdd-bb58-24bf847cf603"},"cell_type":"markdown","source":"**Overview of train data**"},{"metadata":{"_uuid":"a2eb351d31fd38919309e8f841ec1e221e1598b6","_cell_guid":"0dd92afc-79d3-4878-9472-7e410114bc5e","trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d856ac6b872dea94343fbab79c7cfcf427485808","_cell_guid":"2d85f850-9aa7-4a75-b0ce-d6d97a678cb1"},"cell_type":"markdown","source":"**Overview of test data**"},{"metadata":{"_uuid":"b38a4326e3622e4012715721ff00507c8637f9b7","_cell_guid":"3b051e83-0beb-4062-87d7-c095030fd359","trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"71a998bcca175c10212234f03fd44a099317f884","_cell_guid":"18aae27f-8109-4970-a127-faed9337c02f","trusted":true},"cell_type":"code","source":"print('Total number of reviews for training: {}'.format(len(df_train)))\nprint('Total number of reviews for testing: {}'.format(len(df_test)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02139ded850e09a6975b94fa02e9c8b671860fa9","_cell_guid":"b3378b65-08f5-489e-ada5-5fae7665c84c"},"cell_type":"markdown","source":"**Check for missing values in test and train**"},{"metadata":{"_uuid":"3dbf644e433e335687ee8789869e9c6b30377877","_cell_guid":"733f3b39-288a-4554-871a-4c0cb5cb1575","trusted":true},"cell_type":"code","source":"df_train.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4bd8aa8476c8ec011600823016ee265e00cd8852","_cell_guid":"936984d9-bc5e-4ec6-8eaf-39cc65ed0998","trusted":true},"cell_type":"code","source":"df_test.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e50bf3277da9570882271a02c1046f9742fcfd2f","_cell_guid":"37478503-26fb-45c5-b095-13bf968f9fa5"},"cell_type":"markdown","source":"**Preprocessing the train and test sets**"},{"metadata":{"_uuid":"03cd6dfcb2beecd9a21dcf8400c78e43bc0a8b7f","_cell_guid":"5aebd54d-93e5-4830-885a-56e493352d08","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\ndf_train[\"Is_Response\"] = labelencoder.fit_transform(df_train[\"Is_Response\"])\n#1 not happy, 0 happy\n\ndf_train[\"Device_Used\"] = labelencoder.fit_transform(df_train[\"Device_Used\"])\ndf_test[\"Device_Used\"] = labelencoder.transform(df_test[\"Device_Used\"])\n\ndf_train[\"Browser_Used\"] = labelencoder.fit_transform(df_train[\"Browser_Used\"])\ndf_test[\"Browser_Used\"] = labelencoder.transform(df_test[\"Browser_Used\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0140db68fa161689f81b23add8e0da45181da2e7","_cell_guid":"49529069-de62-42c0-8f32-4d1642cddda3"},"cell_type":"markdown","source":"**Overview after preprocessing**"},{"metadata":{"_uuid":"f130b493b1d8ebe70f6916cfc5f8bd064c591424","_cell_guid":"cc90afed-cd9c-4542-91a0-c748c055a07c","trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80f963835e9881d0ff3cbcc06a9ad5a61a187132","_cell_guid":"b1d8eded-1152-45a3-bd4c-0e0b74a04843","trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"20fa04232c5eab921959cdba0a0b61daaa555466","_cell_guid":"04cf8e8a-7b5b-4cbb-bad6-ed8b957793f9"},"cell_type":"markdown","source":"**The target feature**\n\nIs the target feature balanced?"},{"metadata":{"_uuid":"e94ce5fecb30dfafd8fd7a940e54bcb2a26d843f","_cell_guid":"8bbda9aa-b7be-47f5-9237-d1c2eae2982b","trusted":true},"cell_type":"code","source":"ax = df_train['Is_Response'].value_counts().plot(kind='bar')\ntotals = []\n\n# find the values and append to list\nfor i in ax.patches:\n    totals.append(i.get_height())\n\n# set individual bar lables using above list\ntotal = sum(totals)\n\n# set individual bar lables using above list\nfor i in ax.patches:\n    ax.text(i.get_x()+0.1, i.get_height(), \\\n            str(round((i.get_height()/total)*100, 1))+'%', fontsize = 13,\n                color = 'black')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"94af04b837d7eecb4b9cb9094ddf715303cc5401","_cell_guid":"0759acdd-eb32-4940-86da-38aba56b0dd2"},"cell_type":"markdown","source":"The data is clearly imbalanced. 68% of the reviews are happy costumers and approximately 32% are not happy. The imbalance of the target variable requires a careful consideration in the prediction stage in this project. "},{"metadata":{"_uuid":"c2bc83c25433410ea69717d010bacf3b6da2313d","_cell_guid":"12a5fe46-dcc9-4a0e-a92d-e2e43e59341a"},"cell_type":"markdown","source":"**Text preprocessing**"},{"metadata":{"_uuid":"621c150cefe9c48ba78653121a946dc59b99f186","_cell_guid":"66be1cfc-b7d0-4d93-8b69-0ff11d60754f"},"cell_type":"markdown","source":"Some of the text in the description column is contracted so expansion of the text in needed. Here I will use the function *decontracted* in order to expand the text. "},{"metadata":{"_uuid":"5912bba2701dc84457cd1c4a6a96567d954b5b6c","_cell_guid":"1c918ebd-a80b-4f62-a2bc-508e886d97ef","trusted":true},"cell_type":"code","source":"import re\ndef decontracted(phrase):\n    phrase = re.sub(r\"won't\", \"will not\", phrase)\n    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n    phrase = re.sub(r\"\\'cause\", \" because\", phrase)\n    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n    phrase = re.sub(r\"\\'em\", \" them\", phrase)\n    phrase = re.sub(r\"\\'t've\", \" not have\", phrase)\n    phrase = re.sub(r\"\\'d've\", \" would have\", phrase)\n    phrase = re.sub(r\"\\'clock\", \"f the clock\", phrase)\n    return phrase\n\nprint(\"finished  decontracted\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d7901d819079be4479752a1da6706d2ba76fc039","_cell_guid":"9d936888-a567-432f-81a1-21bf848cdfd3"},"cell_type":"markdown","source":"Example for the function *decontracted* :"},{"metadata":{"_uuid":"778d1151c13292dee9747c32ab10dd953aa638fb","_cell_guid":"74ad1c0a-3389-4670-a4a2-16df66f8aa14","trusted":true},"cell_type":"code","source":"text = \"very good hotel in the midst of it all.best:you can't starve:carnegie-deli next doordel frisco's and ruths chris some blocks awaygordon ramsay with - michelin-stars downstairs. park-view from vista-suites looking north\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0f6fab1cc1f3acb833353799960ce008abaf8f5c","_cell_guid":"f010a556-143e-42d8-930f-9c6bd08e4bc0","trusted":true},"cell_type":"code","source":"decontracted(text)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a6659259d2b08e901c3dd34061b4798042d50ed","_cell_guid":"fd026839-c32d-4817-bed1-be5dd00aeede"},"cell_type":"markdown","source":"Let's apply the fuction *decontracted* on the Description column in test and train:"},{"metadata":{"_uuid":"ea7b7e6c1b7b1aa125657487f568b220ba9dfa6e","_cell_guid":"8d829a2f-6fe7-4db8-805d-e27c08fa20f1","trusted":true},"cell_type":"code","source":"df_train[\"Description\"] = df_train[\"Description\"].apply(decontracted)\ndf_test[\"Description\"] = df_test[\"Description\"].apply(decontracted)\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64c2f6a2fff1425ace32eb4910458b58afb18f3b","_cell_guid":"450e1d2a-ac8c-4832-a7e9-21f4d311303f"},"cell_type":"markdown","source":"**Most frequent Description words**"},{"metadata":{"_uuid":"78351ec8ac0a6585a8949499160c85cb418032c5","_cell_guid":"20dabe57-b6ac-4bc3-98df-1956a4af8440","trusted":true},"cell_type":"code","source":"train_desc = pd.Series(df_train['Description'].tolist()).astype(str)\ncloud = WordCloud(width=1440, height=1080,stopwords=STOPWORDS).generate(\" \".join(train_desc.astype(str)))\nplt.figure(figsize=(20, 15))\nplt.imshow(cloud)\nplt.title(\"Most frequent words in the Description column\")\nplt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aaddfc24cdfb64771377a442655a2cf0a3c8bc31","_cell_guid":"510637b5-260a-4d39-8824-57b73648bd48"},"cell_type":"markdown","source":"Oh WOW! The most frequent words in the reviews of the hotels is \"front desk\"! This is very intresting because my first thught here was that the most frequent word will be something like \"comfortable bed\" or \"breakfast\". This means that people that write positive/negative reviews about hotels refers to the front desk as a main property in their review."},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to plot most frequent terms\ndef freq_words(x, terms = 30):\n  all_words = ' '.join([text for text in x])\n  all_words = all_words.split()\n\n  fdist = FreqDist(all_words)\n  words_df = pd.DataFrame({'word':list(fdist.keys()), 'count':list(fdist.values())})\n\n  # selecting top 20 most frequent words\n  d = words_df.nlargest(columns=\"count\", n = terms) \n  plt.figure(figsize=(20,5))\n  ax = sns.barplot(data=d, x= \"word\", y = \"count\")\n  ax.set(ylabel = 'Count')\n  plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk import FreqDist\nfreq_words(df_train['Description'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most common words are ‘the’, ‘and’, ‘to’, so on and so forth. These words are not so important for our task and they do not tell any story. We’ have to get rid of these kinds of words. Before that let’s remove the punctuations and numbers from our text data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove unwanted characters, numbers and symbols\ndf_train['Description'] = df_train['Description'].str.replace(\"[^a-zA-Z#]\", \" \")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let’s try to remove the stopwords and short words (<2 letters) from the reviews.\nfrom nltk.corpus import stopwords\nstop_words = stopwords.words('english')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to remove stopwords\ndef remove_stopwords(rev):\n    rev_new = \" \".join([i for i in rev if i not in stop_words])\n    return rev_new\n\n# remove short words (length < 3)\ndf_train['Description'] = df_train['Description'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>2]))\n\n# remove stopwords from the text\nreviews = [remove_stopwords(r.split()) for r in df_train['Description']]\n\n# make entire text lowercase\nreviews = [r.lower() for r in reviews]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let’s again plot the most frequent words and see if the more significant words have come out.\n\nfreq_words(reviews, 35)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import spacy\nnlp = spacy.load('en', disable=['parser', 'ner'])\n\ndef lemmatization(texts, tags=['NOUN', 'ADJ']): # filter noun and adjective\n       output = []\n       for sent in texts:\n             doc = nlp(\" \".join(sent)) \n             output.append([token.lemma_ for token in doc if token.pos_ in tags])\n       return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let’s tokenize the reviews and then lemmatize the tokenized reviews.\n\ntokenized_reviews = pd.Series(reviews).apply(lambda x: x.split())\nprint(tokenized_reviews[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews_2 = lemmatization(tokenized_reviews)\nprint(reviews_2[1]) # print lemmatized review","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#As you can see, we have not just lemmatized the words but also filtered only nouns and adjectives. Let’s de-tokenize the lemmatized reviews and plot the most common words.\n\nreviews_3 = []\nfor i in range(len(reviews_2)):\n    reviews_3.append(' '.join(reviews_2[i]))\n\ndf_train['Description'] = reviews_3\n\nfreq_words(df_train['Description'], 40)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems that now most frequent terms in our data are relevant. We can now go ahead and start building our topic model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Building an LDA model\n# We will start by creating the term dictionary of our corpus, where every unique term is assigned an index\nimport gensim\nfrom gensim import corpora\ndictionary = corpora.Dictionary(reviews_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Then we will convert the list of reviews (reviews_2) into a Document Term Matrix using the dictionary prepared above.\n\ndoc_term_matrix = [dictionary.doc2bow(rev) for rev in reviews_2]\n# Creating the object for LDA model using gensim library\nLDA = gensim.models.ldamodel.LdaModel\n\n# Build LDA model\nlda_model = LDA(corpus=doc_term_matrix, id2word=dictionary, num_topics=7, random_state=100,\n                chunksize=1000, passes=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The code above will take a while. Please note that I have specified the number of topics as 7 for this model using the num_topics parameter. You can specify any number of topics using the same parameter.\n\n# Let’s print out the topics that our LDA model has learned.\n\nlda_model.print_topics()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Topics Visualization\n# To visualize our topics in a 2-dimensional space we will use the pyLDAvis library. This visualization is interactive in nature and displays topics along with the most relevant words.\n# libraries for visualization\nimport pyLDAvis\nimport pyLDAvis.gensim\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n# Visualize the topics\npyLDAvis.enable_notebook()\nvis = pyLDAvis.gensim.prepare(lda_model, doc_term_matrix, dictionary)\nvis","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}