{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, GRU, Embedding,CuDNNGRU\nfrom tensorflow.python.keras.optimizers import Adam\nfrom tensorflow.python.keras.preprocessing.text import Tokenizer\nfrom tensorflow.python.keras.preprocessing.sequence import pad_sequences","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ce3df5aa599e87973d39fddcebe04e72d45e57f"},"cell_type":"code","source":"dataset = pd.read_csv('../input/hepsiburada.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"857bdd8017dea83c5f1a8b0e040166fa6281cec3"},"cell_type":"markdown","source":"Datasetimizi inceleyelim"},{"metadata":{"_uuid":"2a646ff4893dab1c051f43bbedce03cac3a003b4"},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_uuid":"e1f33f8179cc301965623f4ff947283deb2bb0a1"},"cell_type":"code","source":"dataset","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"71fd344e3b9d5a56c04a6d2931379115f801979a"},"cell_type":"markdown","source":"Datasetimizde 2 kısımdan oluşuyor 1. kısım yorumların iyi/kötü olduğunu belirleyen 1/0 lar 2. kısım ise kullanıcıların yorumları"},{"metadata":{"_uuid":"4a6dd0781d7d67ad509d5d9c61e3dcacc2200575"},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_uuid":"b529480cba5ff1415918ff35d3bb0c8b3eef7a16"},"cell_type":"code","source":"target = dataset['Rating'].values.tolist()\ndata = dataset['Review'].values.tolist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2465d2ceed7e250178f23ec3209f2c8b4900baef"},"cell_type":"markdown","source":"Test ve train kısmına ayırdık"},{"metadata":{"trusted":true,"_uuid":"9ff542a95aeeb17b41e37adae984a76e4aa5279b"},"cell_type":"code","source":"seperate = int(len(data)/0.8)\nx_train , x_test = data[:seperate], data[seperate:]\ny_train , y_test = target[:seperate], target[seperate:]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa9d420af8c7b943c697390c4feba6667b7e112b"},"cell_type":"markdown","source":"Tokenleştirme için kelime sayısını belirlemeliyiz."},{"metadata":{"trusted":true,"_uuid":"a0a78c8f265d109a7ff02167ee3b728f2d78ce90"},"cell_type":"code","source":"limit = 10000\ntokenizer = Tokenizer(num_words =limit)\ntokenizer.fit_on_texts(data) ###tokenleştirme#","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99031b16aa6811c0cb84b12ef11bad1dcac00e1a"},"cell_type":"code","source":"tokenizer.word_index ### en çok kullanılan 10000 kelimeyi tokenleştirdi.###","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d19a09899756980c716a6d9f7fbf151c9884558"},"cell_type":"code","source":"x_train_tokens = tokenizer.texts_to_sequences(x_train) ### cümleleri bir token haline dönüştürdük###","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ed7abc0b32cad377db7390d5fdde564e449d518"},"cell_type":"code","source":"x_train[800]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c589f8a8236bad1f2e734dcd4d36480769198021"},"cell_type":"code","source":"print(x_train_tokens[800])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8cdf803b68947188571f6bb3be6ea00a5de42225"},"cell_type":"code","source":"x_test_tokens = tokenizer.texts_to_sequences(x_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f913de04de2b42b1123cc053058f5ad0a5b25bb9"},"cell_type":"markdown","source":"RNN işlemlerinde eşit boyut olmasını sağlamalıyız bunun için padding yapıyoruz. Padding yapacağımız sayı aralığını belirlemeliyiz."},{"metadata":{"trusted":true,"_uuid":"c5a175a523b80bf3da6ca598bb4ae21e8d0ce4a0"},"cell_type":"code","source":"num_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens ]\nnum_tokens = np.array(num_tokens)\nmax_tokens = np.mean(num_tokens) + 2*np.std(num_tokens)\nmax_tokens = int(max_tokens)\nmax_tokens","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ddb5799f6b21ad7c2ee0b5758011dbd447e41df4"},"cell_type":"code","source":"x_train_pad = pad_sequences(x_train_tokens,maxlen = max_tokens)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"630cfee43e91934b55c775ed6b87253c50d70e4c"},"cell_type":"code","source":"x_test_pad = pad_sequences(x_test_tokens,maxlen = max_tokens)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5780aad1f7358ed83fc4bfe47c85cc0302143a0c"},"cell_type":"code","source":"x_train_pad[800]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35cad10cc9fc41b6b951ac195208f943a992c192"},"cell_type":"markdown","source":"Tokenleri tekrardan kelimelere çevirebilmek için fonksiyon oluştur\n"},{"metadata":{"trusted":true,"_uuid":"b836e21f00118abc9fed28fb2f7f41f2fcfa4f34"},"cell_type":"code","source":"idx = tokenizer.word_index\ninverse_map = dict(zip(idx.values(), idx.keys()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a1c2dde0a91f62f5fa78cb0f275a9dc6c65c5ca"},"cell_type":"code","source":"def tokens_to_string(tokens):\n    words=[inverse_map[token] for token in tokens if token!=0]\n    text = ' '.join(words)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2916d562212e59c93c47c9817ca506568156a485"},"cell_type":"code","source":"x_train[800]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3cea4bdbc2f49e0f0d5e3fbbbc78a671e36eeed6"},"cell_type":"code","source":"tokens_to_string(x_train_tokens[800])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64826025c1643786b26e82c88b99f79a7ed25a5b"},"cell_type":"code","source":"model = Sequential()\nembedding_size = 50 # her kelimeye karşılık gelen 50 uzunluğundaki vektör","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8136d324c163dd0bb8e0feea2813415ec581a689"},"cell_type":"code","source":"model.add(Embedding(input_dim=limit,output_dim=embedding_size,input_length=max_tokens,name='embedding_layer'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ddf77f0d16a2959bb9e2657334405dbc872be56b"},"cell_type":"code","source":"model.add(CuDNNGRU(units=16,return_sequences=True))\nmodel.add(CuDNNGRU(units=8,return_sequences=True))\nmodel.add(CuDNNGRU(units=4))\nmodel.add(Dense(1,activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbb479dfd56df584a18431e2d076a3916c6ea41e"},"cell_type":"code","source":"optimizer = Adam(lr=1e-3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f90e5b961c00ff3e24063368345d1795692c9c09"},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d90b5fd6bf2d6bfe8721af84127e7bb8d7cb2ec"},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50eb216f2cde750e35e0fe71656bad88ead5f2e2"},"cell_type":"code","source":"model.fit(x_train_pad, y_train,epochs=5,batch_size=256)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8dce9a7968bd5bbd4a363d41e27e2ba463013255"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03270e712b66226adbef6fd9ad63447c6247a36c"},"cell_type":"markdown","source":"Kaynak : https://www.udemy.com/dogal-dil-isleme"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}