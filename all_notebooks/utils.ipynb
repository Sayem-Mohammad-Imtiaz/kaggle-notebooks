{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"markdown","source":"These utils convert between the common flare classes and the X-ray flux. (Useful for e.g. converting peak_label to a class label)\nFurther, the function to calculate True Skill Statistic (TSS) makes use of class_to_flux."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# statistics.py\nimport numpy as np\nimport math\nfrom sklearn.metrics import confusion_matrix\n\ngoes_classes = ['quiet','A','B','C','M','X']\n\n\ndef flux_to_class(f: float, only_main=False):\n    'maps the peak_flux of a flare to one of the following descriptors: \\\n    *quiet* = 1e-9, *B* >= 1e-7, *C* >= 1e-6, *M* >= 1e-5, and *X* >= 1e-4\\\n    See also: https://en.wikipedia.org/wiki/Solar_flare#Classification'\n    decade = int(min(math.floor(math.log10(f)), -4))\n    sub = round(10 ** -decade * f)\n    if decade < -4: # avoiding class 10\n        decade += sub // 10\n        sub = max(sub % 10, 1)\n    main_class = goes_classes[decade + 9] if decade >= -8 else 'quiet'\n    sub_class = str(sub) if main_class != 'quiet' and only_main != True else ''\n    return main_class + sub_class\n\ndef class_to_flux(c: str):\n    'Inverse of flux_to_class \\\n    Maps a flare class (e.g. B6, M, X9) to a GOES flux value'\n    if c == 'quiet':\n        return 1e-9\n    decade = goes_classes.index(c[0])-9\n    sub = float(c[1:]) if len(c) > 1 else 1\n    return round(10 ** decade * sub, 10)\n\n\n#\n#   See https://arxiv.org/pdf/1608.06319.pdf for details about scores and statistics\n#\n\ndef true_skill_statistic(y_true, y_pred, threshold='M'):\n    'Calculates the True Skill Statistic (TSS) on binarized predictions\\\n    It is not sensitive to the balance of the samples\\\n    This statistic is often used in weather forecasts (including solar weather)\\\n    1 = perfect prediction, 0 = random prediction, -1 = worst prediction'\n    separator = class_to_flux(threshold)\n    y_true = [1 if yt >= separator else 0 for yt in y_true]\n    y_pred = [1 if yp >= separator else 0 for yp in y_pred]\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n    return tp / (tp + fn) - fp / (fp + tn)","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"3a0ba7d8e2a0b0b653d8ec4835ecf6945ea05301"},"cell_type":"markdown","source":"If you want to split your training set into a dev and validation set (e.g. for cross-validation), here's a recommended way to do it:"},{"metadata":{"trusted":true,"_uuid":"cbf29a7fe7c346d5952a006d392f28f2210085fd"},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import GroupShuffleSplit\n\ndf = pd.read_csv('../input/sdobenchmark_full/training/meta_data.csv', sep=\",\", parse_dates=[\"start\", \"end\"], index_col=\"id\")\ny = df.pop('peak_flux')\nX = df\nactive_regions = df.index.str[:5]\n\ngss = GroupShuffleSplit(n_splits=4, test_size=0.2, random_state=0)\nfor train, test in gss.split(X, y, groups=active_regions):\n    # X.iloc[train], y.iloc[test]\n    print(f'{len(train)} train and {len(test)} test')","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"9c90ccddd73efb91445f19dc806774aacfc832b2"},"cell_type":"markdown","source":"The keras generator is a customly built data generator for the keras deeplearning framework. No need to write your own!"},{"metadata":{"trusted":true,"_uuid":"631e161e4849915284c0aa0e00600a7c48ea4c9e"},"cell_type":"code","source":"# keras_generator.py\nimport keras.utils.data_utils\nfrom keras.preprocessing.image import load_img, img_to_array\nimport pandas as pd\nimport numpy as np\nimport os\nimport datetime as dt\n\nclass SDOBenchmarkGenerator(keras.utils.data_utils.Sequence):\n    'Generates data for keras \\\n    Inspired by https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly.html'\n    def __init__(self, base_path, batch_size=32, dim=(4, 256, 256), channels=['magnetogram'], shuffle=True, augment=True, label_func=None, data_format=\"channels_last\"):\n        'Initialization'\n        self.batch_size = batch_size\n        self.base_path = base_path\n        self.data_format = data_format\n        self.label_func = label_func\n        self.dim = dim if len(dim) == 4 else (dim + (len(channels),) if data_format=='channels_last' else (len(channels),) + dim)\n        self.channels = channels\n        self.time_steps = [0, 7*60, 10*60+30, 11*60+50]\n        self.data = self.loadCSV(augment)\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def loadCSV(self, augment=True):\n        data = pd.read_csv(os.path.join(self.base_path, 'meta_data.csv'), sep=\",\", parse_dates=[\"start\", \"end\"], index_col=\"id\")\n\n        # augment by doubling the data and flagging them to be flipped horizontally\n        data['flip'] = False\n        if augment:\n            new_data = data.copy()\n            new_data.index += '_copy'\n            new_data['flip'] = True\n            data = pd.concat([data, new_data])\n        return data\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.data))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, indexes):\n        'Generates data containing batch_size samples'  # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = [\n            np.empty((self.batch_size, 1)),\n            np.empty((self.batch_size, *self.dim))\n        ]\n\n        # Generate data\n        data = self.data.iloc[indexes]\n        X[0] = np.asarray(list(map(self.loadImg, data.index)))\n        ind = np.where(data['flip'])\n        X[0][ind] = X[0][ind, ::-1, ...]\n        X[1] = (data['start'] - pd.Timestamp('2012-01-01 00:00:00')).view('int64')\n        X[1] /= (pd.Timestamp('2018-01-01 00:00:00') - pd.Timestamp('2012-01-01 00:00:00')).view('int64')\n        y = np.array(data['peak_flux'])\n        if self.label_func is not None:\n            y = self.label_func(y)\n        return X, y\n\n    def loadImg(self, sample_id):\n        'Load the images of each timestep as channels'\n        ar_nr, p = sample_id.replace('_copy','').split(\"_\", 1)\n        path = os.path.join(self.base_path, ar_nr, p)\n\n        slices = np.zeros(self.dim)\n\n        sample_date = dt.datetime.strptime(p[:p.rfind('_')], \"%Y_%m_%d_%H_%M_%S\")\n        time_steps = [sample_date + dt.timedelta(minutes=offset) for offset in self.time_steps]\n        for img in [name for name in os.listdir(path) if name.endswith('.jpg')]:\n            img_datetime_raw, img_wavelength = os.path.splitext(img)[0].split(\"__\")\n            img_datetime = dt.datetime.strptime(img_datetime_raw, \"%Y-%m-%dT%H%M%S\")\n\n            # calc wavelength and datetime index\n            datetime_index = [di[0] for di in enumerate(time_steps) if abs(di[1] - img_datetime) < dt.timedelta(minutes=15)]\n            if img_wavelength in self.channels and len(datetime_index) > 0:\n                val = np.squeeze(img_to_array(load_img(os.path.join(path, img), grayscale=True)), 2)\n                if self.data_format == 'channels_first':\n                    slices[datetime_index[0],:,:,self.channels.index(img_wavelength)] = val\n                else:\n                    slices[self.channels.index(img_wavelength),:,:,datetime_index[0]] = val\n\n\n\n        return slices\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.data) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n\n        # Generate data\n        X, y = self.__data_generation(indexes)\n\n        return X, y","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"92e612551683407d65d63b7009840ff3027b0877"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}