{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n%matplotlib inline\nimport matplotlib as mpl \nimport matplotlib.pyplot as plt\nmpl.rc(\"axes\",labelsize=16)\nmpl.rc('xtick',labelsize=14)\nmpl.rc('ytick',labelsize=14)\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"X= 2 * np.random.rand(100,1)\ny=4+3 * X+np.random.randn(100,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(X,y,\"b.\")\nplt.xlabel(\"$x_1$\",fontsize=18)\nplt.ylabel(\"$y$\",rotation=0,fontsize=18)\nplt.axis([0,2,0,15])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_b=np.c_[np.ones((100,1)),X]\ntheta_best=np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"theta_best","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_new=np.array([[0],[2]])\nX_new_b=np.c_[np.ones((2,1)),X_new]\ny_predict=X_new_b.dot(theta_best)\ny_predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(X_new,y_predict,\"r-\")\nplt.plot(X,y,\"b.\")\nplt.axis([0,2,0,15])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(X_new,y_predict,\"r-\",linewidth=2,label=\"Predictions\")\nplt.plot(X,y,\"b.\")\nplt.xlabel(\"$x_1$\",fontsize=18)\nplt.ylabel(\"$y$\",rotation=0,fontsize=18)\nplt.legend(loc=\"upper left\", fontsize=14)\nplt.axis([0, 2, 0, 15])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlin_reg=LinearRegression()\nlin_reg.fit(X,y)\nlin_reg.intercept_,lin_reg.coef_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lin_reg.predict(X_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"theta_best_svd,residuals,rank,s=np.linalg.lstsq(X_b,y,rcond=1e-6)\ntheta_best_svd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.linalg.pinv(X_b).dot(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eta=0.1\nn_iterations=1500\nm=100\ntheta=np.random.randn(2,1)\n\nfor iteration in range(n_iterations):\n    gradients=2/m*X_b.T.dot(X_b.dot(theta)-y)\n    theta=theta-eta*gradients","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"theta","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_new_b.dot(theta)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"theta_path_bgd=[]\n\ndef plot_gradient_descent(theta,eta,theta_path=None):\n    m=len(X_b)\n    plt.plot(X,y,\"b.\")\n    n_iterations=1000\n    for iteration in range(n_iterations):\n        if iteration <10:\n            y_predict=X_new_b.dot(theta)\n            style=\"b-\"if iteration >0 else \"r--\"\n            plt.plot(X_new,y_predict,style)\n        gradients=2/m*X_b.T.dot(X_b.dot(theta)-y)\n        theta=theta-eta*gradients\n        if theta_path is not None:\n            theta_path.append(theta)\n    plt.xlabel(\"$x_1$\",fontsize=18)\n    plt.ylabel(\"$y$\",rotation=0,fontsize=18)\n    plt.legend(loc=\"upper left\", fontsize=14)\n    plt.axis([0, 2, 0, 15])\n    plt.title(r\"$\\eta={}$\".format(eta),fontsize=16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(17)\ntheta=np.random.randn(2,1)\n\nplt.figure(figsize=(10,4))\nplt.subplot(131);plot_gradient_descent(theta,eta=0.02)\nplt.ylabel(\"$y$\",rotation=0,fontsize=18)\nplt.subplot(132),plot_gradient_descent(theta,eta=0.1,theta_path=theta_path_bgd)\nplt.subplot(133),plot_gradient_descent(theta,eta=0.5)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"theta_path_sgd=[]\nm=len(X_b)\nnp.random.seed(17)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_epochs=50\nt0, t1=5, 50\n\ndef learning_schedule(t):\n    return t0/(t+t1)\n\ntheta = np.random.randn(2,1)\n\nfor epoch in range(n_epochs):\n    for i in range(m):\n        if epoch == 0 and i <20:\n            y_predict= X_new_b.dot(theta)\n            style=\"b-\" if i>0 else \"r--\"\n            plt.plot(X_new,y_predict,style)\n        random_index=np.random.randint(m)\n        xi=X_b[random_index:random_index+1]\n        yi=y[random_index:random_index+1]\n        gradients=2*xi.T.dot(xi.dot(theta)-yi)\n        eta=learning_schedule(epoch*m+i)\n        theta=theta-eta*gradients\n        theta_path_sgd.append(theta)\n        \nplt.plot(X,y,\"b.\")\nplt.xlabel(\"$x_1$\",fontsize=18)\nplt.ylabel(\"$y$\",rotation=0,fontsize=18)\nplt.axis([0,2,0,15])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import SGDRegressor\nsgd_reg=SGDRegressor(max_iter=10,tol=-np.infty,penalty=None,eta0=0.1,random_state=17)\nsgd_reg.fit(X,y.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sgd_reg.intercept_,sgd_reg.coef_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"theta_path_mgd=[]\nn_iterations= 50 \nminibatch_size= 20 \nnp.random.seed(17)\ntheta=np.random.randn(2,1)\n\nt0,t1=200,1000\ndef learning_schedule(t):\n    return t0/(t+t1)\n\nt=0\nfor epoch in range(n_iterations):\n    shuffled_indices=np.random.permutation(m)\n    X_b_shuffled=X_b[shuffled_indices]\n    y_shuffled=y[shuffled_indices]\n    for i in range(0,m,minibatch_size):\n        t+=1\n        ix=X_b_shuffled[i:i+minibatch_size]\n        iy=y_shuffled[i:i+minibatch_size]\n        gradients= 2/minibatch_size * xi.T.dot(xi.dot(theta) - yi)\n        eta=learning_schedule(t)\n        theta=theta-eta*gradients\n        theta_path_mgd.append(theta)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"theta","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"theta_path_bgd = np.array(theta_path_bgd)\ntheta_path_sgd = np.array(theta_path_sgd)\ntheta_path_mgd = np.array(theta_path_mgd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nplt.plot(theta_path_sgd[:,0],theta_path_sgd[:,1],\"r-s\",linewidth=1,label=\"Stochastic\")\nplt.plot(theta_path_mgd[:,0],theta_path_mgd[:,1],\"g-+\",linewidth=2,label=\"Mini-Batch\")\nplt.plot(theta_path_bgd[:,0],theta_path_bgd[:,1],\"b-o\",linewidth=3,label=\"Batch\")\nplt.legend(loc=\"upper left\",fontsize=16)\nplt.xlabel(r\"$\\theta_0$\",fontsize=16)\nplt.ylabel(r\"$\\theta_1$\",fontsize=16,rotation=0)\nplt.axis([2.5,4.5,2.3,3.9])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport numpy.random as rnd\nnp.random.seed(17)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m=100\nX=6*np.random.rand(m,1)-3\ny=0.5*X**2+X+2+np.random.randn(m,1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(X,y,\"b.\")\nplt.xlabel(\"$x_1$\",fontsize=18)\nplt.ylabel(\"$y$\",rotation=0,fontsize=18)\nplt.axis([-3,3,0,10])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\npoly_features=PolynomialFeatures(degree=2,include_bias=False)\nX_poly=poly_features.fit_transform(X)\nX[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_poly[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lin_reg=LinearRegression()\nlin_reg.fit(X_poly,y)\nlin_reg.intercept_,lin_reg.coef_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_new=np.linspace(-3,3,100).reshape(100,1)\nX_new_poly=poly_features.transform(X_new)\ny_new=lin_reg.predict(X_new_poly)\nplt.plot(X,y,\"b.\")\nplt.plot(X_new,y_new,\"r-\",linewidth=2,label=\"Predictions\")\nplt.xlabel(\"$x_1$\", fontsize=18)\nplt.ylabel(\"$y$\", rotation=0, fontsize=18)\nplt.legend(loc=\"upper left\", fontsize=14)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\nfor style,width,degree in ((\"g-\",1,300),(\"b-\",2,2),(\"r-+\",2,1)):\n    polybig_features=PolynomialFeatures(degree=degree,include_bias=False)\n    std_scalar=StandardScaler()\n    lin_reg=LinearRegression()\n    polynomial_regression=Pipeline([\n        (\"poly_features\",polybig_features),\n        (\"std_scalar\",std_scalar),\n        (\"lin_reg\",lin_reg),\n    ])\n    polynomial_regression.fit(X,y)\n    y_newbig=polynomial_regression.predict(X_new)\n    plt.title('high_degree_polynomials_plot')\n    plt.plot(X_new,y_newbig,style,label=str(degree),linewidth=width)\n    \nplt.plot (X,y,\"b.\",linewidth=3)\nplt.legend(loc=\"upper left\")\nplt.xlabel(\"$x_1$\",fontsize=18)\nplt.ylabel(\"$y$\",rotation=0,fontsize=18)\nplt.axis([-3,3,0,10])\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\n\ndef plot_learning_curves(model,X,y):\n    X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.2)\n    train_errors,val_errors=[],[]\n    for m in range(1,len(X_train)):\n        model.fit(X_train[:m],y_train[:m])\n        y_train_predict=model.predict(X_train[:m])\n        y_val_predict=model.predict(X_val)\n        train_errors.append(mean_squared_error(y_train[:m],y_train_predict))\n        val_errors.append(mean_squared_error(y_val,y_val_predict))\n        \n    plt.plot(np.sqrt(train_errors),\"r-+\",linewidth=2,label=\"train\")\n    plt.plot(np.sqrt(val_errors),\"b-\",linewidth=3,label=\"val\")\n    plt.legend(loc=\"upper right\",fontsize=14)\n    plt.xlabel(\"Training set size\",fontsize=14)\n    plt.ylabel(\"RMSE\",fontsize=14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lin_reg=LinearRegression()\nplot_learning_curves(lin_reg,X,y)\nplt.axis([0,80,0,3])\nplt.title(\"Underfitting_learning_curves_plot\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\n\npolynomial_regression=Pipeline([\n    (\"poly_features\",PolynomialFeatures(degree=10 ,include_bias=False)),\n    (\"lin_reg\",LinearRegression()),\n])\nplot_learning_curves(polynomial_regression,X,y)\nplt.axis([0,80,0,3])\nplt.title('learning_curves_plot')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge\n\nnp.random.seed(42)\nm = 20\nX= 3 * np.random.rand(m,1)\ny= 1 + 0.5 * X + np.random.randn(m,1) / 1.5\nX_new=np.linspace(0,3,100).reshape(100,1)\nprint(X)\ndef plot_model(model_class,polynomial,alphas,**model_kargs):\n    for alpha,style in zip(alphas,(\"b-\",\"g--\",\"r:\")):\n        model=model_class(alpha,**model_kargs)if alpha>0 else LinearRegression()\n        if polynomial:\n            model=Pipeline([\n            (\"Poly_features\",PolynomialFeatures(degree=10,include_bias=False)),\n            (\"std_scalar\",StandardScaler()),\n            (\"regul_reg\",model),\n             ])\n        model.fit(X,y)\n        y_new_regul=model.predict(X_new)\n        lw=2 if alpha >0 else 1\n        plt.plot(X_new,y_new_regul,style,linewidth=lw,label=r\"$\\alpha = {}$\".format(alpha))\n    plt.plot(X,y,\"b.\",linewidth=3)\n    plt.legend(loc=\"upper left\", fontsize=15)\n    plt.xlabel(\"$x_1$\",fontsize=18)\n    plt.axis([0,3,0,4])\n    \nplt.figure(figsize=(8,4))\nplt.subplot(121)\nplot_model(Ridge,polynomial=False,alphas=(0,10,100),random_state=17)\nplt.ylabel(\"$y$\",rotation=0,fontsize=18)\nplt.subplot(122)\nplot_model(Ridge,polynomial=True,alphas=(0,10**-5,1),random_state=17)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge\nridge_reg=Ridge(alpha=1,solver=\"cholesky\",random_state=17)\nridge_reg.fit(X,y)\nridge_reg.predict([[1.5]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Lasso \nplt.figure(figsize=(8,4))\nplt.subplot(121)\nplot_model(Lasso,polynomial=False,alphas=(0,0.1,1),random_state=17)\nplt.ylabel(\"$y$\",rotation=0,fontsize=18)\nplt.subplot(122)\nplot_model(Lasso,polynomial=True,alphas=(0,10**-7,1),tol=1,random_state=17)\nplt.title(\"lasso_regression_plot\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Lasso\nlasso_reg=Lasso(alpha=0.1)\nlasso_reg.fit(X,y)\nlasso_reg.predict([[1.5]])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import ElasticNet\nEls_reg=ElasticNet(alpha=0.1,l1_ratio=0.5,random_state=17)\nEls_reg.fit(X,y)\nEls_reg.predict([[1.5]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(17)\nm=100\nX=6*np.random.rand(m,1)-3\ny=2+X+0.5*X**2+np.random.randn(m,1)\n\nX_train,X_val,y_train,y_val=train_test_split(X[:50],y[:50].ravel(),test_size=0.5,random_state=42)\n\npoly_scaler=Pipeline([\n    (\"poly_features\",PolynomialFeatures(degree=90,include_bias=False)),\n    (\"std_scalar\",StandardScaler()),\n])\n\nX_train_poly_scaled=poly_scaler.fit_transform(X_train)\nX_val_poly_scaled=poly_scaler.transform(X_val)\n\n\nsgd_reg= SGDRegressor(max_iter=1,tol=-np.infty,penalty=None,eta0=0.0005,\n                     warm_start=True,learning_rate=\"constant\",random_state=17)\n\nn_epochs=500\ntrain_errors,val_errors=[],[]\nfor epoch in range(n_epochs):\n    sgd_reg.fit(X_train_poly_scaled,y_train)\n    y_train_predict=sgd_reg.predict(X_train_poly_scaled)\n    y_val_predict=sgd_reg.predict(X_val_poly_scaled)\n    train_errors.append(mean_squared_error(y_train,y_train_predict))\n    val_errors.append(mean_squared_error(y_val,y_val_predict))\n\nbest_epoch=np.argmin(val_errors)\nbest_val_rmse=np.sqrt(val_errors[best_epoch])\n\nplt.annotate('Best model',\n            xy=(best_epoch,best_val_rmse),\n            xytext=(best_epoch,best_val_rmse+1),\n            ha=\"center\",\n            arrowprops=dict(facecolor='black',shrink=0.05),\n            fontsize=16,\n            )\nbest_val_rmse-=0.03\nplt.plot([0,n_epochs],[best_val_rmse,best_val_rmse],\"k:\",linewidth=2)\nplt.plot(np.sqrt(val_errors),\"b-\",linewidth=3,label=\"Validation set\")\nplt.plot(np.sqrt(train_errors),\"r--\",linewidth=2,label=\"Training set\")\nplt.legend(loc=\"upper right\",fontsize=14)\nplt.xlabel(\"Epoch\",fontsize=14)\nplt.ylabel(\"RMSE\",fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.base import clone\nsgd_reg=SGDRegressor(max_iter=1,tol=-np.infty,warm_start=True,learning_rate=\"constant\"\n                     ,eta0=0.0005,random_state=17)\nminimum_val_error=float(\"inf\")\nbest_epoch=None\nbest_model=None\nfor epoch in range(1000):\n    sgd_reg.fit(X_train_poly_scaled,y_train)\n    y_val_predict=sgd_reg.predict(X_val_poly_scaled)\n    val_error=mean_squared_error(y_val,y_val_predict)\n    if val_error < minimum_val_error :\n        minimum_val_error=val_error\n        best_epoch=epoch\n        best_model=clone(sgd_reg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_epoch,best_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t1a, t1b, t2a, t2b = -1, 3, -1.5, 1.5\n\n# ignoring bias term\nt1s = np.linspace(t1a, t1b, 500)\nt2s = np.linspace(t2a, t2b, 500)\nt1, t2 = np.meshgrid(t1s, t2s)\nT = np.c_[t1.ravel(), t2.ravel()]\nXr = np.array([[-1, 1], [-0.3, -1], [1, 0.1]])\nyr = 2 * Xr[:, :1] + 0.5 * Xr[:, 1:]\n\nJ = (1/len(Xr) * np.sum((T.dot(Xr.T) - yr.T)**2, axis=1)).reshape(t1.shape)\n\nN1 = np.linalg.norm(T, ord=1, axis=1).reshape(t1.shape)\nN2 = np.linalg.norm(T, ord=2, axis=1).reshape(t1.shape)\n\nt_min_idx = np.unravel_index(np.argmin(J), J.shape)\nt1_min, t2_min = t1[t_min_idx], t2[t_min_idx]\n\nt_init = np.array([[0.25], [-1]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def bgd_path(theta, X, y, l1, l2, core = 1, eta = 0.1, n_iterations = 50):\n    path = [theta]\n    for iteration in range(n_iterations):\n        gradients = core * 2/len(X) * X.T.dot(X.dot(theta) - y) + l1 * np.sign(theta) + 2 * l2 * theta\n\n        theta = theta - eta * gradients\n        path.append(theta)\n    return np.array(path)\n\nplt.figure(figsize=(12, 8))\nfor i, N, l1, l2, title in ((0, N1, 0.5, 0, \"Lasso\"), (1, N2, 0,  0.1, \"Ridge\")):\n    JR = J + l1 * N1 + l2 * N2**2\n    \n    tr_min_idx = np.unravel_index(np.argmin(JR), JR.shape)\n    t1r_min, t2r_min = t1[tr_min_idx], t2[tr_min_idx]\n\n    levelsJ=(np.exp(np.linspace(0, 1, 20)) - 1) * (np.max(J) - np.min(J)) + np.min(J)\n    levelsJR=(np.exp(np.linspace(0, 1, 20)) - 1) * (np.max(JR) - np.min(JR)) + np.min(JR)\n    levelsN=np.linspace(0, np.max(N), 10)\n    \n    path_J = bgd_path(t_init, Xr, yr, l1=0, l2=0)\n    path_JR = bgd_path(t_init, Xr, yr, l1, l2)\n    path_N = bgd_path(t_init, Xr, yr, np.sign(l1)/3, np.sign(l2), core=0)\n\n    plt.subplot(221 + i * 2)\n    plt.grid(True)\n    plt.axhline(y=0, color='k')\n    plt.axvline(x=0, color='k')\n    plt.contourf(t1, t2, J, levels=levelsJ, alpha=0.9)\n    plt.contour(t1, t2, N, levels=levelsN)\n    plt.plot(path_J[:, 0], path_J[:, 1], \"w-o\")\n    plt.plot(path_N[:, 0], path_N[:, 1], \"y-^\")\n    plt.plot(t1_min, t2_min, \"rs\")\n    plt.title(r\"$\\ell_{}$ penalty\".format(i + 1), fontsize=16)\n    plt.axis([t1a, t1b, t2a, t2b])\n    if i == 1:\n        plt.xlabel(r\"$\\theta_1$\", fontsize=20)\n    plt.ylabel(r\"$\\theta_2$\", fontsize=20, rotation=0)\n\n    plt.subplot(222 + i * 2)\n    plt.grid(True)\n    plt.axhline(y=0, color='k')\n    plt.axvline(x=0, color='k')\n    plt.contourf(t1, t2, JR, levels=levelsJR, alpha=0.9)\n    plt.plot(path_JR[:, 0], path_JR[:, 1], \"w-o\")\n    plt.plot(t1r_min, t2r_min, \"rs\")\n    plt.title(title, fontsize=16)\n    plt.axis([t1a, t1b, t2a, t2b])\n    if i == 1:\n        plt.xlabel(r\"$\\theta_1$\", fontsize=20)\n\nplt.show()\n             ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t=np.linspace(-10,10,100)\nsig=1/(1+np.exp(-t))\nplt.figure(figsize=(9,3))\nplt.plot([-10,10],[0,0],\"k-\")\nplt.plot([-10,10],[0.5,0.5],\"k:\")\nplt.plot([-10,10],[1,1],\"k:\")\nplt.plot([0,0],[-1.1,1.1],\"k-\")\nplt.plot(t,sig,\"b-\",linewidth=2,label=r\"$\\sigma(t)=\\frac{1}{1+e^{-t}}$\")\nplt.xlabel(\"t\")\nplt.legend(loc=\"upper left\",fontsize=20)\nplt.axis([-10,10,-0.1,1.1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iris=pd.read_csv(\"../input/iris/Iris.csv\")\nprint(iris)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\niris=iris.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\nX = iris[:, 3:5]\nprint(X)\ny = iris[:,5] \nz=le.fit_transform(y)\nl = (z == 2).astype(np.int)\nfrom sklearn.linear_model import LogisticRegression\nlog_reg = LogisticRegression(solver=\"liblinear\", random_state=42)\nlog_reg.fit(X, l)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_new=np.linspace(0,3,1000).reshape(-1,1)\ny_proba=log_reg.predict_proba(X_new)\n\nplt.plot(X_new,y_proba[:,1],\"g-\",linewidth=2,label=\"Iris-Virginica\")\nplt.plot(X_new,y_proba[:,0],\"b--\",linewidth=2,label=\" Not Iris-Virginica\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decision_boundary = X_new[y_proba[:, 1] >= 0.5][0]\ndecision_boundary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg.predict([[1.7],[1.5]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nX = iris[:, (3,4)]\n\nlog_reg=LogisticRegression(solver=\"liblinear\",C=10**10,random_state=42)\nlog_reg.fit(X,l)\n\nx0,x1=np.meshgrid(\n      np.linspace(2.9,7,500).reshape(-1,1),\n      np.linspace(0.8,2.7,200).reshape(-1,1),\n      )\n\nX_new=np.c_[x0.ravel(),x1.ravel()]\n\ny_proba=log_reg.predict_proba(X_new)\n\nplt.figure(figsize=(10,4))\nplt.plot(X[l==0,0],X[l==0,1],\"bs\")\nplt.plot(X[l==1,0],X[l==1,1],\"g^\")\n\nzz = y_proba[:, 1].reshape(x0.shape)\ncontour = plt.contour(x0, x1, zz, cmap=plt.cm.brg)\n\nleft_right = np.array([2.9, 7])\nboundary = -(log_reg.coef_[0][0] * left_right + log_reg.intercept_[0]) / log_reg.coef_[0][1]\n\n\nplt.clabel(contour, inline=1, fontsize=12)\nplt.plot(left_right, boundary, \"k--\", linewidth=3)\nplt.text(3.5, 1.5, \"Not Iris-Virginica\", fontsize=14, color=\"b\", ha=\"center\")\nplt.text(6.5, 2.3, \"Iris-Virginica\", fontsize=14, color=\"g\", ha=\"center\")\nplt.xlabel(\"Petal length\", fontsize=14)\nplt.ylabel(\"Petal width\", fontsize=14)\nplt.axis([2.9, 7, 0.8, 2.7])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = iris[:, (3,4)]\nsoftmax_reg=LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\",C=10,random_state=42)\nsoftmax_reg.fit(X,z)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x0,x1=np.meshgrid(\n      np.linspace(0,8,500).reshape(-1,1),\n      np.linspace(0,3.5,200).reshape(-1,1),\n)\nX_new=np.c_[x0.ravel(),x1.ravel()]\n\ny_proba=softmax_reg.predict_proba(X_new)\ny_predict=softmax_reg.predict(X_new)\n\nzz1=y_proba[:,1].reshape(x0.shape)\nzz=y_predict.reshape(x0.shape)\n\nplt.figure(figsize=(10,4))\nplt.plot(X[z==2, 0], X[z==2, 1], \"g^\", label=\"Iris-Virginica\")\nplt.plot(X[z==1, 0], X[z==1, 1], \"bs\", label=\"Iris-Versicolor\")\nplt.plot(X[z==0, 0], X[z==0, 1], \"yo\", label=\"Iris-Setosa\")\n\nfrom matplotlib.colors import ListedColormap\nfrom matplotlib.colors import ListedColormap\ncustom_cmap=ListedColormap(['#fafab0',\"#9898ff\",\"#a0faa0\"])\n\nplt.contourf(x0,x1,zz, cmap=custom_cmap)\ncontour=plt.contour(x0,x1,zz1,cmap=plt.cm.brg)\nplt.clabel(contour, inline=1, fontsize=12)\nplt.xlabel(\"Petal length\", fontsize=14)\nplt.ylabel(\"Petal width\", fontsize=14)\nplt.legend(loc=\"center left\",fontsize=14)\nplt.axis([0, 7, 0, 3.5])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"softmax_reg.predict([[5, 2]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"softmax_reg.predict_proba([[5, 2]])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}