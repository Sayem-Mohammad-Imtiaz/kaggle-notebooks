{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"FILEPATH = '/kaggle/input/netflix-shows/netflix_titles.csv'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Notes\n\n* I have used various libraries to make it better\n* Though import libraries on top section is good and clean, but for learning purposes I have used all imports whereever they needed to understand better.\n* I have added `Observation` after some analysis with a little summary. Hope it helps!\n* Enjoy learning and give me some feedback\n\n(still adding more documentation)"},{"metadata":{},"cell_type":"markdown","source":"## Reading Time\n\nLet's start read the data first"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(FILEPATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\nThere are 6234 entries in the dataset.\n\nThere are 2 integer types and rest of them are string objects. \n\nshow_id and release_year are mentioned in integers. Later, we will create year_added and month_added for better analysis"},{"metadata":{},"cell_type":"markdown","source":"## Finding Null and Correlation\n\nwe will find what columns have null and some relationships between the columns. \n\nWe will use **missingno** library as it gives better visualiation"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\n\nThere are 3036 entries are null which are mostly from director col. \n\ndirector, cast, and country columns have most null entries!\n\nLet's do the visualization of those null entires with missingno library."},{"metadata":{"trusted":true},"cell_type":"code","source":"import missingno as miss\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"miss.matrix(df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Also, we will try to find the relationship by using dendogram and heatmap"},{"metadata":{"trusted":true},"cell_type":"code","source":"miss.heatmap(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"miss.dendrogram(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"miss.bar(df.sample(len(df)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Extra columns\n\nAs we need year and month for content added analysis, we are going to create those columns from date_added column."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's convert added_date to year\ndf['date_added'] = pd.to_datetime(df['date_added'])\ndf['month_added'] = df['date_added'].dt.month\ndf['year_added'] = df['date_added'].dt.year\n\ndf['year_added'] = df['year_added'].fillna(2008)\ndf['month_added'] = df['month_added'].fillna(0)\n\n# convert float to int\ndf['year_added'] = df['year_added'].astype(int)\ndf['month_added'] = df['month_added'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\n\nIn the above code, we have used 2008 to fill the NA columns on year_added to avoid the visualization confusion. I will talk about later. If you have a better idea, please share with me in the comment section.\n\nLet's verify those columns to make sure the datatype."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check head one more time to confirm the newly created columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## TV Show Dataset\n\nAs we will be analyzing only TV Shows, it's better to divide the dataset for TV Show alone. We will create them below."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get only TV Shows\ndf_tv = df[df['type'] == 'TV Show']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### TV Show Content Growt\n\nLet's do a simple plot to understand the TV Show content growth over years."},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nax = sns.barplot(\n    x = df_tv['year_added'].value_counts().keys(), \n    y = df_tv['year_added'].value_counts().values\n)\nax.set_xticklabels(ax.get_xticklabels(), rotation = 45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\n\nIt seems Netflix have added the most TV Show contents in 2019 following by year 2018. As we may not have much data collected for 2020, we can't comment on that!"},{"metadata":{},"cell_type":"markdown","source":"## TV Show - Top countries\n\nWe will analyze in which countries Netflix added more contents with the help of barplot! We have analyzed only top 10 countries to avoid confusion in the plot."},{"metadata":{"trusted":true},"cell_type":"code","source":"group_country_movies = df.groupby('country')['show_id'].count().sort_values(ascending = False).head(10)\n\ncountries_list = []\ncount_list = []\nfor index, value in group_country_movies.items():\n    countries_list.append(index)\n    count_list.append(value)\n    \ncars = {\n    'country': countries_list,\n    'count': count_list\n}\n\ndf4 = pd.DataFrame(cars, columns = ['country', 'count'])\n\n\nsns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n# possible styles: whitegrid, dark, white\n\nsns.set_context(\"notebook\")\n\n\nax = sns.barplot(x = \"country\", y = \"count\", data = df4)\nax.set_xticklabels(ax.get_xticklabels(), rotation = 90)\n\n# You can collect more aesthetics from here:\n# https://seaborn.pydata.org/tutorial/aesthetics.html","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\n\n* United States tops the list when it comes to TV Show content added from Netflix. More than 2000 contents added in the United States followed by India.\n* In India, Netflix added 750 contents.\n* UK and Japan become third and fourth place in Netflix content growth.\n\n#### Questions for future analysis:\n* How many TV Show contents added in India?\n* Which year is the best for UK in terms of content growth?"},{"metadata":{},"cell_type":"markdown","source":"Let's try to visualize the dataset by rating with the help of donut plot. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's create a donut pie chart with \n\ndef show_donut_plot(col):\n    \n    rating_data = df.groupby(col)[['show_id']].count()\n    plt.figure(figsize = (12, 8))\n    plt.pie(rating_data['show_id'], autopct = '%1.0f%%', startangle = 140, pctdistance = 1.1, shadow = True)\n\n    # create a center circle for more aesthetics to make it better\n    gap = plt.Circle((0, 0), 0.5, fc = 'white')\n    fig = plt.gcf()\n    fig.gca().add_artist(gap)\n    \n    plt.axis('equal')\n    plt.legend(df[col])\n    \n    plt.title('Donut Plot by ' +str(col), loc='center')\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_donut_plot('rating')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's find the starting and ending year of the dataset as they will help us in our upcoming data analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check tv shows added every year\nmin_year = int(df_tv['year_added'].min())\nmax_year = int(df_tv['year_added'].max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min_year, max_year","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Movies and TV Shows with subgroup (2017 - 2019)\n\nLet's try to see the Movies and TV Shows growth by using plots with subgroups. We have used only 3 years to keep it clean for the analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show Movies, TV Shows with subgroups\n\nyear_3_data = df[df['year_added'] > 2016]\n\nyear_3_data = year_3_data.drop(['title', 'director', 'cast', 'country', 'release_year', 'duration', 'rating', 'listed_in', 'description', 'date_added'], axis = 1)\n\n# year_3_data\nmovie_count = len(year_3_data[year_3_data.type == 'Movie'])\ntv_show_count = len(year_3_data[year_3_data.type == 'TV Show'])\n\nyear_3_data_movie = year_3_data[df['type'] == 'Movie']\nyear_3_data_tv = year_3_data[df['type'] == 'TV Show']\n\nmenu_sub= year_3_data[(year_3_data[\"type\"] == 'Movie') & (year_3_data[\"year_added\"] == 2018)] \n\n# Make data:\ngroup_names = ['Movies', 'TV Shows']\ngroup_size = [movie_count, tv_show_count]\nsubgroup_names = [\"'17\", \"'18\", \"'19\", \"'17\", \"'18\", \"'19\"]\nsubgroup_size = [\n    len(year_3_data[(year_3_data[\"type\"] == 'Movie') & (year_3_data[\"year_added\"] == 2017)]), \n    len(year_3_data[(year_3_data[\"type\"] == 'Movie') & (year_3_data[\"year_added\"] == 2018)]), \n    len(year_3_data[(year_3_data[\"type\"] == 'Movie') & (year_3_data[\"year_added\"] == 2019)]), \n    \n    len(year_3_data[(year_3_data[\"type\"] == 'TV Show') & (year_3_data[\"year_added\"] == 2017)]),\n    len(year_3_data[(year_3_data[\"type\"] == 'TV Show') & (year_3_data[\"year_added\"] == 2018)]),\n    len(year_3_data[(year_3_data[\"type\"] == 'TV Show') & (year_3_data[\"year_added\"] == 2019)]),\n]\n\n# Create colors\na, b = [plt.cm.Blues, plt.cm.Reds]\n\n# First Ring (outside)\nfig, ax = plt.subplots()\nax.axis('equal')\nmypie, _ = ax.pie(group_size, radius=1.3, labels=group_names, colors=[a(0.6), b(0.6)] )\nplt.setp( mypie, width=0.3, edgecolor='white')\n\n# Second Ring (Inside)\nmypie2, _ = ax.pie(subgroup_size, radius=1.3-0.3, labels=subgroup_names, \n                labeldistance=0.7, \n                colors=[a(0.1), a(0.2), a(0.3), b(0.2), b(0.3), b(0.4), b(0.5)]\n            )\nplt.setp( mypie2, width=0.4, edgecolor='white')\nplt.margins(0,0)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\n\n* In 2019, Netflix added more Movie content than in TV Shows"},{"metadata":{},"cell_type":"markdown","source":"## TV Shows - Growth - Visualization\n\nLet's check the content growth in simple plot. We are using plotly for better visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"year_list = []\ntv_shows_per_year = []\n\nfor year in range(min_year, max_year):\n    year = int(year)\n    \n    c_year = len(df_tv[df_tv['year_added'] == year])\n    \n    year_list.append(year)\n    tv_shows_per_year.append(c_year)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Do a simple graph with Plotly\nimport plotly.graph_objects as go\n\ndata1 = go.Scatter(x = year_list, y = tv_shows_per_year, mode = 'lines+markers', name = 'TV Shows Count')\n\ndata = [data1]\n\nlayout = go.Layout(\n    title = 'TV Shows per year',\n    legend = dict (x = 0.1, y = 0.8, orientation = 'h')\n)\n\nfig = go.Figure(data, layout = layout)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\n\n* We can see that more contents added from 2014 to 2019. It might be good news for people like me who prefer TV Shows than movies.\n\n* We have ignored 2020 as it it not finished yet."},{"metadata":{},"cell_type":"markdown","source":"## TV Show - Content Bubble\n\nTo understand the content growth better, we can use the bubble plot. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Content by year\npclass = df_tv['year_added'].value_counts().to_frame().reset_index().rename(columns={'index':'year_added','year_added':'Count'})\n\n\nfig1 = go.Figure(data=[go.Scatter(\n    x = pclass['year_added'], \n    y = pclass['Count'],\n    mode = 'markers',\n    marker = dict(\n        color = pclass['Count'],\n        size = pclass['Count'] * 0.2,\n        showscale = False\n    ))])\n\n# Use theme [plotly_dark, ggplot2, plotly_dark, seaborn, plotly, plotly_white, presentation, xgridoff]\nfig1.layout.template = 'seaborn'\n\nfig1.update_layout(title = 'Content by Year', xaxis_title = \"Class\", yaxis_title = \"Count\", title_x = 0.5)\nfig1.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## TV Show - USA vs Canada"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check US vs Canada\nyear_list             = []\ntv_shows_per_year_us  = []\ntv_shows_per_year_can = []\nfor year in range(min_year, max_year):\n    year = int(year)\n\n    count_year_us = len(df_tv.loc[(df_tv['year_added'] == year) & (df_tv.country == 'United States')])\n    count_year_can = len(df_tv.loc[(df_tv['year_added'] == year) & (df_tv.country == 'Canada')])\n    \n    year_list.append(year)\n    tv_shows_per_year_us.append(count_year_us)\n    tv_shows_per_year_can.append(count_year_can)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = go.Scatter(x = year_list, y = tv_shows_per_year_us, mode = 'lines+markers', name = 'TV Shows - USA')\ndata2 = go.Scatter(x = year_list, y = tv_shows_per_year_can, mode = 'lines+markers', name = 'TV Shows - Canada')\n\ndata = [data1, data2]\n\nlayout = go.Layout(\n    title = 'TV Shows per year - USA vs Canada',\n    legend = dict (x = 0.1, y = 0.9, orientation = 'h')\n)\n\nfig = go.Figure(data, layout = layout)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\n\n* Comparing USA, Canada doesn't have much contents (sad news for Canada). \n* I presume that most of the USA contents can be viewed in Canada so Netflix didn't care much about adding local contents. (Only Netflix can answer this question huh?)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find top 10 countries and TV Shows\ntop_10_countries_se = df_tv.country.value_counts().head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_10_countries = []\nfor i, v in top_10_countries_se.items():\n    top_10_countries.append(i)\n    \nprint(top_10_countries)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check top 10 countries' TV shows\n\nyear_list                  = []\ntv_shows_per_year_country  = {}\n\nfor country in top_10_countries:\n    tv_shows_per_year_country[country] = []\n\nfor year in range(min_year, max_year):\n    year = int(year)\n    \n    current_country = {}\n    \n    for country in top_10_countries:\n        current_country[country] = len(df_tv.loc[(df_tv['year_added'] == year) & (df_tv.country == country)])\n    \n    year_list.append(year)\n\n    for country in top_10_countries:\n        tv_shows_per_year_country[country].append(current_country[country])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dict = {}\ndata = []\n\nfor country in top_10_countries:\n    \n    data_dict[country] = go.Scatter(\n        x = year_list, \n        y = tv_shows_per_year_country[country], \n        mode = 'lines+markers', \n        name = str(country)\n    )\n    data.append(data_dict[country])\n\nlayout = go.Layout(\n    title = 'TV Shows per year - Various Countries',\n    legend = dict (x = 0.1, y = 0.9, orientation = 'h')\n)\n\nfig = go.Figure(data, layout = layout)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\n\n* Comparing other countries, more TV Show contents added more.\n* Netflix started adding TV Show contents from 2014 rigorously.\n* Netflix doubled the contents every year since 2014 in the US."},{"metadata":{},"cell_type":"markdown","source":"## TV Show Contents by Region\n\nLet's try to get for different regions by using external API. In here we are using restcoutries API to get the countries for each region like `nafta`, `asean`, `au`, and etc.\n\nAPI Links:\n* [ASEAN](https://restcountries.eu/rest/v2/regionalbloc/asean)\n* [African Union - au](https://restcountries.eu/rest/v2/regionalbloc/au)\n* [Pacific Alliance region - pa](https://restcountries.eu/rest/v2/regionalbloc/pa)\n* [North American Free Trade Agreement - nafta](https://restcountries.eu/rest/v2/regionalbloc/nafta)\n* [South Asian Association for Regional Cooperation - saarc](https://restcountries.eu/rest/v2/regionalbloc/saarc)\n\nAPI Base Links:\n* [API Base](https://restcountries.eu/)\n* [API Endpoints - Region](https://restcountries.eu/#api-endpoints-region)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get countries by region [https://restcountries.eu/#api-endpoints-name]\nimport requests\n\n# This method will get countries by region\ndef get_countries_by_region(region):\n    \n    # Find asean countries\n    resp = requests.get('https://restcountries.eu/rest/v2/regionalbloc/'+str(region))\n\n    # if resp.status_code != 200:\n    #     raise ApiError('GET /tasks/ {}'.format(resp.status_code))\n\n    countries = []\n    for item in resp.json():\n        \n        if(item['name'] == 'United States of America'):\n            item['name'] = 'United States'\n        \n        countries.append(item['name'])\n\n    # Check matched countries\n    matched_countries = []\n    for i, v in df_tv.country.value_counts().items():\n\n        for country in countries:\n            if(country == i):\n                matched_countries.append(country)\n    \n    return matched_countries\n\ndef show_graph_by_region(region, region_title):\n\n    matched_countries = get_countries_by_region(region)\n    \n    year_list                  = []\n    tv_shows_per_year_country  = {}\n\n    for country in matched_countries:\n        tv_shows_per_year_country[country] = []\n\n    for year in range(min_year, max_year):\n        year = int(year)\n\n        current_country = {}\n\n        for country in matched_countries:\n            current_country[country] = len(df_tv.loc[(df_tv['year_added'] == year) & (df_tv.country == country)])\n\n        year_list.append(year)\n\n        for country in matched_countries:\n            tv_shows_per_year_country[country].append(current_country[country])\n\n    data_dict = {}\n    data = []\n\n    for country in matched_countries:\n\n        data_dict[country] = go.Scatter(\n            x = year_list, \n            y = tv_shows_per_year_country[country], \n            mode = 'lines+markers', \n            name = str(country)\n        )\n        data.append(data_dict[country])\n\n    layout = go.Layout(\n        title = 'TV Shows - '+ region_title,\n        legend = dict (x = 0.1, y = 0.9, orientation = 'h')\n    )\n\n    fig = go.Figure(data, layout = layout)\n\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show Association of Southeast Asian Nations\nshow_graph_by_region('asean', 'Association of Southeast Asian Nations (ASEAN)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\n\n* Thailand's content increase in the last 3 years.\n* Singapore's content spiked suddenly in 2017 alone and no more growth after that.\n* Netflix added very least in Indonesia"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show African Union region (au)\nshow_graph_by_region('au', 'African Union region (AU)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\n\n* AU region is growing slowly, however it's a good progress for Netflix in the long term"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show Pacific Alliance region (pa)\nshow_graph_by_region('pa', 'Pacific Alliance (PA)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\n\n* Netflix added more TV Show contents in Mexico than other countries in the region\n* Chile doesn't have much contents"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show NAFTA (North American Free Trade Agreement)\nshow_graph_by_region('nafta', 'North American Free Trade Agreement (NAFTA)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\n\n* Netflix added contents in the US 10 times more than other countries in the NAFTA region\n* Same volume of contents added in Canada and Mexico"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show SAARC (South Asian Association for Regional Cooperation)\nshow_graph_by_region('SAARC', 'South Asian Association for Regional Cooperation (SAARC)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\n\n* India has more contents than Pakistan"},{"metadata":{},"cell_type":"markdown","source":"## Movie Content Growth\n\nSo far we have seen only TV Show contents. We will start collecting movies alone and then do analysis here."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get only Movies\ndf_movie = df[df['type'] == 'Movie']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_movie.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This method will get countries by region\ndef get_countries_by_region_for_movies(region):\n    \n    # Find asean countries\n    resp = requests.get('https://restcountries.eu/rest/v2/regionalbloc/'+str(region))\n\n    # if resp.status_code != 200:\n    #     raise ApiError('GET /tasks/ {}'.format(resp.status_code))\n\n    countries = []\n    for item in resp.json():\n        \n        if(item['name'] == 'United States of America'):\n            item['name'] = 'United States'\n        \n        countries.append(item['name'])\n\n    # Check matched countries\n    matched_countries = []\n    for i, v in df_movie.country.value_counts().items():\n\n        for country in countries:\n            if(country == i):\n                matched_countries.append(country)\n    \n    return matched_countries\n\ndef show_movie_graph_by_region(region, region_title):\n\n    matched_countries = get_countries_by_region_for_movies(region)\n    \n    year_list                  = []\n    tv_shows_per_year_country  = {}\n\n    for country in matched_countries:\n        tv_shows_per_year_country[country] = []\n\n    for year in range(min_year, max_year):\n        year = int(year)\n\n        current_country = {}\n\n        for country in matched_countries:\n            current_country[country] = len(df_movie.loc[(df_movie['year_added'] == year) & (df_movie.country == country)])\n\n        year_list.append(year)\n\n        for country in matched_countries:\n            tv_shows_per_year_country[country].append(current_country[country])\n\n    data_dict = {}\n    data = []\n\n    for country in matched_countries:\n\n        data_dict[country] = go.Scatter(\n            x = year_list, \n            y = tv_shows_per_year_country[country], \n            mode = 'lines+markers', \n            name = str(country)\n        )\n        data.append(data_dict[country])\n\n    layout = go.Layout(\n        title = 'Movies - '+ region_title,\n        legend = dict (x = 0.1, y = 0.9, orientation = 'h')\n    )\n\n    fig = go.Figure(data, layout = layout)\n\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show Association of Southeast Asian Nations\nshow_movie_graph_by_region('asean', 'Association of Southeast Asian Nations (ASEAN)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\n\n* More movies added in Philippies in 2019 than other countries in this region.\n* Thailand and Indonesia has more movies added in the last 3 years.\n* Cambodia has the least movies added than other countries in the region."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show Pacific Alliance region (pa)\nshow_movie_graph_by_region('pa', 'Pacific Alliance (PA)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\n\n* In PA region, Mexico has more movies added than other countries.\n* Since 2015, movies spiked in Mexico, reaching the highest in 2017.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show NAFTA (North American Free Trade Agreement)\nshow_movie_graph_by_region('nafta', 'North American Free Trade Agreement (NAFTA)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\n\n* Like TV Shows, more movies added in the US than Mexico and Canada.\n* Significant amount of movies added in the US since 2014 and it kept increasing.\n* Comparing Mexico, Canada has more movies."},{"metadata":{},"cell_type":"markdown","source":"## Movie and TV Shows by Country\n\nLet's start comparing Movies vs TV Shows for countries. For sample we will use USA and Canada"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check TV Shows and Movies\n\ndef show_movies_vs_tvshows(country = 'United States'):\n\n    year_list        = []\n    movies_country   = []\n    tv_shows_country = []\n    \n    for year in range(min_year, max_year):\n        year = int(year)\n\n        movies_count_country = len(df.loc[(df['year_added'] == year) & (df.country == country) & (df.type == 'TV Show')])\n        tv_shows_count_country = len(df.loc[(df['year_added'] == year) & (df.country == country) & (df.type == 'Movie')])\n\n        year_list.append(year)\n        movies_country.append(movies_count_country)\n        tv_shows_country.append(tv_shows_count_country)\n\n    data_movies = go.Scatter(x = year_list, y = movies_country, mode = 'lines+markers', name = 'Movies ('+str(country) + ')')\n    data_tv_shows = go.Scatter(x = year_list, y = tv_shows_country, mode = 'lines+markers', name = 'TV Shows ('+str(country) + ')')\n\n    data = [data_movies, data_tv_shows]\n\n    layout = go.Layout(\n        title = 'Movies vs TV Shows - '+str(country),\n        legend = dict (x = 0.1, y = 0.9, orientation = 'h')\n    )\n\n    fig = go.Figure(data, layout = layout)\n\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_movies_vs_tvshows('United States')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\n\n* In the US, though same amount of contents added in movies and TV Show, TV show content addition started incrasing from 2014 and kept increasing.\n* In 2019, more than double TV Show contents added than movie contents. It's a good news for TV Show fans like me!"},{"metadata":{"trusted":true},"cell_type":"code","source":"show_movies_vs_tvshows('Canada')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\n\n* In Canada, though movie contents added more in the initial time, TV Show contents increased from 2017 and kept going."},{"metadata":{"trusted":true},"cell_type":"code","source":"show_movies_vs_tvshows('United Kingdom')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\n\n* In the UK, almost same amount of TV Show contents and Movie contents added."},{"metadata":{},"cell_type":"markdown","source":"## Treemap\n\nLet's get more visualization with the help of Treemap. \n\nFor treemap, we need a new library called squarify. I have installed it by using pip install. Check the code below."},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install squarify\n# !pip show squarify","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's do a simple Treemap plot by type. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# show a treemap\n\nimport squarify\n\ndf_type_series = df.groupby('type')['show_id'].count()\n\ntype_sizes = []\ntype_labels = []\nfor i, v in df_type_series.items():\n    type_sizes.append(v)\n    type_labels.append(i)\n    \n\nfig, ax = plt.subplots(1, figsize = (12,12))\nsquarify.plot(sizes=type_sizes, \n              label=type_labels, \n              alpha=.8 )\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\n\n* You can clearly see that movie contents are 4 times higher than TV Show contents."},{"metadata":{},"cell_type":"markdown","source":"Let's convert the treemap plot as a function to test with other columns. I have used only top 20 items to keep it simple and clean. Otherwise, it will be full of confusion and no use to understand."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's create more treemap by converting the code as function\n# I have used only top 20 item to avoid confusion\n\ndef show_treemap(col):\n    df_type_series = df.groupby(col)['show_id'].count().sort_values(ascending = False).head(20)\n\n    type_sizes = []\n    type_labels = []\n    for i, v in df_type_series.items():\n        type_sizes.append(v)\n        \n        type_labels.append(str(i) + ' ('+str(v)+')')\n\n\n    fig, ax = plt.subplots(1, figsize = (12,12))\n    squarify.plot(sizes=type_sizes, \n                  label=type_labels[:10],  # show labels for only first 10 items\n                  alpha=.2 )\n    plt.title('TreeMap by '+ str(col))\n    plt.axis('off')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_treemap('country')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\n\n* More contents added in the States and India followed by the United Kingdom.\n* Double the contents added in the UK than Japan.\n* Almost same amount of contents added in Mexico and France. Same goes to South Korea and Canada.\n* India has double the contents added than the UK."},{"metadata":{"trusted":true},"cell_type":"code","source":"show_treemap('year_added')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\n\n* Almost 500 more contents added every year from 2017.\n* Netflix added more contents in 2019 than ever.\n* 23 times more content added in 2019 than in 2015."},{"metadata":{"trusted":true},"cell_type":"code","source":"show_treemap('rating')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\n\n* Matured Audience based contents is highest type comparing other types.\n* TV-14 stands in the second place."},{"metadata":{"trusted":true},"cell_type":"code","source":"show_treemap('month_added')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Observation:\n\n* In the month of December, Netflix added more contents than any other months.\n* From October to December, more contents added by Netflix. May be holiday seasons?"},{"metadata":{},"cell_type":"markdown","source":"## Final Notes\n\n* Hope you have enjoyed my notebook. \n* Please **upvote if you like it**. \n* Also, please share some feedback so I can improve things and learn from you, may be."},{"metadata":{},"cell_type":"markdown","source":"**To do:**\n\n* Find top directors, actors for each country\n* Rating per country and year"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"<font color=\"blue\" size=+1.5><b>Check out my other kernels</b></font>\n\n<table style=\"font-family: 'Trebuchet MS', Arial, Helvetica, sans-serif;border-collapse: collapse;width: 100%;\">\n  <tr>\n    <th style=\"border: 1px solid #ddd;padding: 8px; padding-top: 12px;padding-bottom: 12px;text-align: left;background-color: #2987E7;color: white;\">Notebook</th>\n    <th style=\"border: 1px solid #ddd;padding: 8px; padding-top: 12px;padding-bottom: 12px;text-align: left;background-color: #2987E7;color: white;\">Tags</th>\n  </tr>\n  <tr>\n    <td style=\"text-align: left\"><a href=\"https://www.kaggle.com/rajacsp/sof-questions-eda-and-visual\">SOF Questions - EDA and Visual</a> </td>\n    <td style=\"text-align: left\">Data Visual, Plotly</td>\n  </tr>\n  <tr>\n    <td style=\"background-color: #f2f2f2;text-align: left\"><a href=\"https://www.kaggle.com/rajacsp/netflix-visualization-plotly-plots-treemap\">Netflix - Visualization, Plotly, Plots, and Treemap</a> </td>\n    <td style=\"background-color: #f2f2f2;text-align: left\">Data Visual, Data Cleaning, Plotly</td>\n  </tr>\n  <tr>\n    <td style=\"text-align: left\"><a href=\"https://www.kaggle.com/rajacsp/prediction-with-various-algorithms\">Prediction with various Algorithms</a> </td>\n    <td style=\"text-align: left\">Random Forest, Logistic Regression</td>\n  </tr>\n  <tr>\n    <td style=\"background-color: #f2f2f2;text-align: left\"><a href=\"https://www.kaggle.com/rajacsp/eda-and-visualization\">EDA and Visualization</a> </td>\n    <td style=\"background-color: #f2f2f2;text-align: left\">Data Cleaning, Data Visual</td>\n  </tr>\n  <tr>\n    <td style=\"text-align: left\"><a href=\"https://www.kaggle.com/rajacsp/job-analysis-eda-visual\">Job Analysis - EDA and Visual</a> </td>\n    <td style=\"text-align: left\">Data Visual, EDA, Plotly</td>\n  </tr>   \n  <tr>\n    <td style=\"background-color: #f2f2f2;text-align: left\"><a href=\"https://www.kaggle.com/rajacsp/estonia-disaster-visualization\">Estonia Disaster - Visualization</a> </td>\n    <td style=\"background-color: #f2f2f2;text-align: left\">Data Visual, EDA, Data Cleaning</td>\n  </tr>\n    \n  <tr>\n    <td style=\"text-align: left\"><a href=\"https://www.kaggle.com/rajacsp/pandas-dundas-challenge-100\" >Pandas 100+ exercises collection</a></td>\n    <td style=\"text-align: left\">Pandas, Data Manipulation</td>\n  </tr>   \n  <tr>\n    <td style=\"background-color: #f2f2f2;text-align: left\"><a href=\"https://www.kaggle.com/rajacsp/prediction-with-various-algorithms\">Credit Card Fraud - Prediction with various algorithms</a></td>\n    <td style=\"background-color: #f2f2f2;text-align: left\">Various ML Algorithms</td>\n  </tr>  \n  <tr>\n    <td style=\"text-align: left\"><a href=\"https://www.kaggle.com/rajacsp/linear-equations-real-time\">Linear Equations - Real Time</a> </td>\n    <td style=\"text-align: left\">Linear Equation</td>\n  </tr>  \n</table>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}