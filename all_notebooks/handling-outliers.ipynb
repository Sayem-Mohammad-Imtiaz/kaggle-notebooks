{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Discussion Related With Outliers And Impact On Machine Learning","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"### Which Machine LEarning Models Are Sensitive To Outliers?\nNaivye Bayes Classifier--- Not Sensitive To Outliers\n\nSVM-------- Not Sensitive To Outliers\n\nLinear Regression---------- Sensitive To Outliers\n\nLogistic Regression------- Sensitive To Outliers\n\nDecision Tree Regressor or Classifier---- Not Sensitive\n\nEnsemble(RF,XGboost,GB)------- Not Sensitive\n\nKNN--------------------------- Not Sensitive\n\nKmeans------------------------ Sensitive\n\nHierarichal------------------- Sensitive\n\nPCA-------------------------- Sensitive\n\nNeural Networks-------------- Sensitive","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('../input/titanic/train.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Gaussian Distributed","metadata":{}},{"cell_type":"code","source":"#Checking the outliers after plotting a histogram\nfigure=df.Age.hist(bins=50)\nfigure.set_title('Age')\nfigure.set_xlabel('Age')\nfigure.set_ylabel('No of passenger')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking the outliers using boxplot. The black dots are the outliers\nfigure=df.boxplot(column=\"Age\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Age'].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### If The Data Is Normally Distributed We use this","metadata":{}},{"cell_type":"code","source":"# Assuming Age follows A Gaussian Distribution we will calculate the boundaries which differentiates the outliers\n\nuppper_boundary=df['Age'].mean() + 3* df['Age'].std()\nlower_boundary=df['Age'].mean() - 3* df['Age'].std()\nprint(lower_boundary), print(uppper_boundary),print(df['Age'].mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### If Features Are Skewed We Use the below TechniqueÂ¶","metadata":{}},{"cell_type":"code","source":"figure=df.Fare.hist(bins=50)\nfigure.set_title('Fare')\nfigure.set_xlabel('Fare')\nfigure.set_ylabel('No of passenger')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.boxplot(column=\"Fare\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Fare'].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#It can be noted that the difference between 75% and max value has a huge difference","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets compute the Interquantile range to calculate the boundaries\nIQR=df.Fare.quantile(0.75)-df.Fare.quantile(0.25)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Outliers using IQR*1.5\nlower_bridge=df['Fare'].quantile(0.25)-(IQR*1.5)\nupper_bridge=df['Fare'].quantile(0.75)+(IQR*1.5)\nprint(lower_bridge), print(upper_bridge)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extreme outliers (using IQR*3)\nlower_bridge=df['Fare'].quantile(0.25)-(IQR*3)\nupper_bridge=df['Fare'].quantile(0.75)+(IQR*3)\nprint(lower_bridge), print(upper_bridge)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Copying df into data\ndata=df.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Replacing all the Age outliers with 73\ndata.loc[data['Age']>=73,'Age']=73","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Replacing all the Fare outliers with 100\ndata.loc[data['Fare']>=100,'Fare']=100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure=data.Age.hist(bins=50)\nfigure.set_title('Fare')\nfigure.set_xlabel('Fare')\nfigure.set_ylabel('No of passenger')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure=data.Fare.hist(bins=50)\nfigure.set_title('Fare')\nfigure.set_xlabel('Fare')\nfigure.set_ylabel('No of passenger')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(data[['Age','Fare']].fillna(0),data['Survived'],test_size=0.3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nclassifier=LogisticRegression()\nclassifier.fit(X_train,y_train)\ny_pred=classifier.predict(X_test)\ny_pred1=classifier.predict_proba(X_test)\n\nfrom sklearn.metrics import accuracy_score,roc_auc_score\nprint(\"Accuracy_score: {}\".format(accuracy_score(y_test,y_pred)))\nprint(\"roc_auc_score: {}\".format(roc_auc_score(y_test,y_pred1[:,1])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}