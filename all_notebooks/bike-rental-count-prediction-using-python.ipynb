{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Project title :- Bike Renting using Python**"},{"metadata":{},"cell_type":"markdown","source":"**Problem statement :-**"},{"metadata":{},"cell_type":"markdown","source":"The objective of this Case is to Predication of bike rental count on daily based on the environmental and seasonal settings."},{"metadata":{},"cell_type":"markdown","source":"**Contents :-**\n             \n        1. Exploratory Data Analysis\n           * Loading the dataset and libraries\n           * Data cleaning\n           * Typecasting the attributes\n           * Missing value analysis\n        2. Attributes distributions and trends\n           * Monthly distribution of counts\n           * Yearly distribution of counts\n           * Outliers analysis\n        3. Normality test\n        4. Correlation matrix \n        5. Split the dataset into train and test dataset\n        6. Encoding the categorical features\n        7. Modelling the training dataset\n           * Linear Regression Model\n           * Decision Tree Regressor Model\n           * Random Forest Model\n        8. Cross Validation Prediction\n           * Linear Regression CV Prediction\n           * Decision Tree Regressor CV Prediction\n           * Random Forest CV Prediction\n        9. Model performance on test dataset\n           * Linear Regression Prediction\n           * Decision Tree Regressor Prediction\n           * Random Forest Prediction\n        10. Model Evaluation Metrics\n           * R-squared score\n           * Root mean square error\n           * Mean absolute error\n        11.Choosing best model for predicting bike rental count"},{"metadata":{},"cell_type":"markdown","source":"**Exploratory Data Analysis**"},{"metadata":{},"cell_type":"markdown","source":"**Import the required libraries**"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nprint(os.listdir(\"../input\"))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Read the training data**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#import the csv file\nbike_df=pd.read_csv(\"../input/day.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Shape of the dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Shape of the dataset\nbike_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dataset contains 731 observations and 16 attributes."},{"metadata":{},"cell_type":"markdown","source":"**Data types**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data types\nbike_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Read the data\nbike_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Rename the columns for better understanding of variables**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Rename the columns\nbike_df.rename(columns={'instant':'rec_id','dteday':'datetime','yr':'year','mnth':'month','weathersit':'weather_condition',\n                       'hum':'humidity','cnt':'total_count'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Read the data\nbike_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Typecasting the datetime and numerical attributes**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Type casting the datetime and numerical attributes to category\n\nbike_df['datetime']=pd.to_datetime(bike_df.datetime)\n\nbike_df['season']=bike_df.season.astype('category')\nbike_df['year']=bike_df.year.astype('category')\nbike_df['month']=bike_df.month.astype('category')\nbike_df['holiday']=bike_df.holiday.astype('category')\nbike_df['weekday']=bike_df.weekday.astype('category')\nbike_df['workingday']=bike_df.workingday.astype('category')\nbike_df['weather_condition']=bike_df.weather_condition.astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Summary of the dataset\nbike_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Missing value analysis**"},{"metadata":{},"cell_type":"markdown","source":"No missing values present in training dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Missing values in dataset\nbike_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Attributes distributions and trends**"},{"metadata":{},"cell_type":"markdown","source":"**Monthly distribution of counts**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(figsize=(15,8))\nsns.set_style('white')\n#Bar plot for seasonwise monthly distribution of counts\nsns.barplot(x='month',y='total_count',data=bike_df[['month','total_count','season']],hue='season',ax=ax)\nax.set_title('Seasonwise monthly distribution of counts')\nplt.show()\n#Bar plot for weekday wise monthly distribution of counts\nfig,ax1=plt.subplots(figsize=(15,8))\nsns.barplot(x='month',y='total_count',data=bike_df[['month','total_count','weekday']],hue='weekday',ax=ax1)\nax1.set_title('Weekday wise monthly distribution of counts')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above plots, we can observed that increasing the bike rental count in springe and summer season and then decreasing the bike rental count in fall and winter season.\nHere, \n\nseason 1-> spring season 2 -> summer season 3 -> fall season 4 -> winter"},{"metadata":{},"cell_type":"markdown","source":"**Yearly wise distribution of counts**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(figsize=(15,8))\n#Violin plot for yearly distribution of counts\nsns.violinplot(x='year',y='total_count',data=bike_df[['year','total_count']])\nax.set_title('Yearly distribution of counts')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the violin plot, we can observed that the bike rental count distribution is highest in year 2012 then in year 2011. \n\nHere,  \nyear 0-> 2011, year 1-> 2012"},{"metadata":{},"cell_type":"markdown","source":"**Holiday wise distribution of counts**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(figsize=(15,8))\n#Barplot for Holiday distribution of counts\nsns.barplot(data=bike_df,x='holiday',y='total_count',hue='season')\nax.set_title('Holiday wise distribution of counts')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above bar plot, we can observed that during no holiday the bike rental counts is highest compared to during holiday for different seasons.\n\nHere, 0->No holiday, 1-> holiday"},{"metadata":{},"cell_type":"markdown","source":"**Workingday wise distribution of counts**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(figsize=(15,8))\n#Bar plot for workingday distribution of counts\nsns.barplot(data=bike_df,x='workingday',y='total_count',hue='season')\nax.set_title('Workingday wise distribution of counts')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above bar plot, we can observed that during workingday the bike rental counts is quite highest compared to during no workingday for different seasons.\n\nHere, 0-> No workingday, 1-> workingday"},{"metadata":{},"cell_type":"markdown","source":"**Weather_condition distribution of counts**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax1=plt.subplots(figsize=(15,8))\n#Bar plot for weather_condition distribution of counts\nsns.barplot(x='weather_condition',y='total_count',data=bike_df[['month','total_count','weather_condition']],ax=ax1)\nax1.set_title('Weather_condition wise monthly distribution of counts')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above bar plot, we can observed that during clear,partly cloudy weather the bike rental count is highest and the second highest is during mist cloudy weather and followed by third highest during light snow and light rain weather."},{"metadata":{},"cell_type":"markdown","source":"**Outlier analysis**"},{"metadata":{},"cell_type":"markdown","source":"**Total_Count_Outliers**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(figsize=(15,8))\n#Boxplot for total_count outliers\nsns.boxplot(data=bike_df[['total_count']])\nax.set_title('total_count outliers')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the box plot, we can observed that no outliers are present in total_count variable."},{"metadata":{},"cell_type":"markdown","source":"**Temp_windspeed_humidity_outliers**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(figsize=(15,8))\n#Box plot for Temp_windspeed_humidity_outliers\nsns.boxplot(data=bike_df[['temp','windspeed','humidity']])\nax.set_title('Temp_windspeed_humidity_outiers')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the box plot, we can observed that no outliers are present in normalized temp but few outliers are present in normalized windspeed and humidity variable."},{"metadata":{},"cell_type":"markdown","source":"**Replace and impute the outliers**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from fancyimpute import KNN\n\n#create dataframe for outliers\nwind_hum=pd.DataFrame(bike_df,columns=['windspeed','humidity'])\n #Cnames for outliers                     \ncnames=['windspeed','humidity']       \n                      \nfor i in cnames:\n    q75,q25=np.percentile(wind_hum.loc[:,i],[75,25]) # Divide data into 75%quantile and 25%quantile.\n    iqr=q75-q25 #Inter quantile range\n    min=q25-(iqr*1.5) #inner fence\n    max=q75+(iqr*1.5) #outer fence\n    wind_hum.loc[wind_hum.loc[:,i]<min,:i]=np.nan  #Replace with NA\n    wind_hum.loc[wind_hum.loc[:,i]>max,:i]=np.nan  #Replace with NA\n#Imputating the outliers by mean Imputation\nwind_hum['windspeed']=wind_hum['windspeed'].fillna(wind_hum['windspeed'].mean())\nwind_hum['humidity']=wind_hum['humidity'].fillna(wind_hum['humidity'].mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Replace the original dataset to imputated data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Replacing the imputated windspeed\nbike_df['windspeed']=bike_df['windspeed'].replace(wind_hum['windspeed'])\n#Replacing the imputated humidity\nbike_df['humidity']=bike_df['humidity'].replace(wind_hum['humidity'])\nbike_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Normal Probability Plot**"},{"metadata":{},"cell_type":"markdown","source":"Normal probability plot is a graphical technique to identify substantive departures from normality and also it tells about goodness of fit."},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy\nfrom scipy import stats\n#Normal plot\nfig=plt.figure(figsize=(15,8))\nstats.probplot(bike_df.total_count.tolist(),dist='norm',plot=plt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above probability plot, the some target variable data points are deviates from normality."},{"metadata":{},"cell_type":"markdown","source":"**Correlation matrix**"},{"metadata":{},"cell_type":"markdown","source":"Correlation matrix is tells about linear relationship between attributes and help us to build better models."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create the correlation matrix\ncorreMtr=bike_df[[\"temp\",\"atemp\",\"humidity\",\"windspeed\",\"casual\",\"registered\",\"total_count\"]].corr()\nmask=np.array(correMtr)\nmask[np.tril_indices_from(mask)]=False\n#Heat map for correlation matrix of attributes\nfig,ax=plt.subplots(figsize=(15,8))\nsns.heatmap(correMtr,mask=mask,vmax=0.8,square=True,annot=True,ax=ax)\nax.set_title('Correlation matrix of attributes')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From correlation plot, we can observed that some features are positively correlated or some are negatively correlated to each other. The temp and atemp are highly positively correlated to each other, it means that both are carrying same information.The total_count,casual and registered are highly positively correlated to each other. So, we are going to ignore atemp,casual and registered variable for further analysis."},{"metadata":{},"cell_type":"markdown","source":"**Modelling the dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#load the required libraries\nfrom sklearn import preprocessing,metrics,linear_model\nfrom sklearn.model_selection import cross_val_score,cross_val_predict,train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split the dataset into train and test in the ratio of 70:30"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split the dataset into the train and test data\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(bike_df.iloc[:,0:-3],bike_df.iloc[:,-1],test_size=0.3, random_state=42)\n\n#Reset train index values\nX_train.reset_index(inplace=True)\ny_train=y_train.reset_index()\n\n# Reset train index values\nX_test.reset_index(inplace=True)\ny_test=y_test.reset_index()\n\nprint(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\nprint(y_train.head())\nprint(y_test.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Split the features into categorical and numerical features**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create a new dataset for train attributes\ntrain_attributes=X_train[['season','month','year','weekday','holiday','workingday','weather_condition','humidity','temp','windspeed']]\n#Create a new dataset for test attributes\ntest_attributes=X_test[['season','month','year','weekday','holiday','workingday','humidity','temp','windspeed','weather_condition']]\n#categorical attributes\ncat_attributes=['season','holiday','workingday','weather_condition','year']\n#numerical attributes\nnum_attributes=['temp','windspeed','humidity','month','weekday']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decoding the training attributes**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#To get dummy variables to encode the categorical features to numeric\ntrain_encoded_attributes=pd.get_dummies(train_attributes,columns=cat_attributes)\nprint('Shape of transfomed dataframe::',train_encoded_attributes.shape)\ntrain_encoded_attributes.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training dataset for modelling\nX_train=train_encoded_attributes\ny_train=y_train.total_count.values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Linear Regression Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#training model\nlr_model=linear_model.LinearRegression()\nlr_model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**fit the training model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#fit the trained model\nlr_model.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Accuracy of model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Accuracy of the model\nlr=lr_model.score(X_train,y_train)\nprint('Accuracy of the model :',lr)\nprint('Model coefficients :',lr_model.coef_)\nprint('Model intercept value :',lr_model.intercept_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cross validation prediction**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cross validation prediction\npredict=cross_val_predict(lr_model,X_train,y_train,cv=3)\npredict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cross validation prediction plot**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cross validation plot\nfig,ax=plt.subplots(figsize=(15,8))\nax.scatter(y_train,y_train-predict)\nax.axhline(lw=2,color='black')\nax.set_title('Cross validation prediction plot')\nax.set_xlabel('Observed')\nax.set_ylabel('Residual')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cross validation prediction plot tells about finite variance between actual target value and predicted target value. In this plot, some data points are have same finite variance between them and for some are not have it."},{"metadata":{},"cell_type":"markdown","source":"**Model evalution metrics**"},{"metadata":{},"cell_type":"markdown","source":"**R-squared and mean squared error score**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#R-squared scores\nr2_scores = cross_val_score(lr_model, X_train, y_train, cv=3)\nprint('R-squared scores :',np.average(r2_scores))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The R-squared or coefficient of determination is 0.80 on average for 3-fold cross validation , it means that predictor is only able to predict 80% of the variance in the target variable which is contributed by independent variables."},{"metadata":{},"cell_type":"markdown","source":"**Decoding the test attributes**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#To get dummy variables to encode the categorical features to numeric\ntest_encoded_attributes=pd.get_dummies(test_attributes,columns=cat_attributes)\nprint('Shape of transformed dataframe :',test_encoded_attributes.shape)\ntest_encoded_attributes.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model performance on test dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test dataset for prediction\nX_test=test_encoded_attributes\ny_test=y_test.total_count.values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Predict the model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#predict the model\nlr_pred=lr_model.predict(X_test)\nlr_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model evaluation metrics**"},{"metadata":{},"cell_type":"markdown","source":"**Root mean square error and mean absolute error scores**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\n#Root mean square error \nrmse=math.sqrt(metrics.mean_squared_error(y_test,lr_pred))\n#Mean absolute error\nmae=metrics.mean_absolute_error(y_test,lr_pred)\nprint('Root mean square error :',rmse)\nprint('Mean absolute error :',mae)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Residual plot**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Residual plot\nfig, ax = plt.subplots(figsize=(15,8))\nax.scatter(y_test, y_test-lr_pred)\nax.axhline(lw=2,color='black')\nax.set_xlabel('Observed')\nax.set_ylabel('Residuals')\nax.title.set_text(\"Residual Plot\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Residual plot tells about finite variance between actual target value and predicted target value.In this plot,very less data points are have same finite variance between them and for most are not have it."},{"metadata":{},"cell_type":"markdown","source":"**Decision tree regressor**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#training the model\nfrom sklearn.tree import DecisionTreeRegressor\ndtr=DecisionTreeRegressor(min_samples_split=2,max_leaf_nodes=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Fit the model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fit the trained model\ndtr.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision tree regression accuracy score**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Accuracy score of the model\ndtr_score=dtr.score(X_train,y_train)\nprint('Accuracy of model :',dtr_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot the learned model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot the learned model\nfrom sklearn import tree\nimport pydot\nimport graphviz\n\n# export the learned model to tree\ndot_data = tree.export_graphviz(dtr, out_file=None) \ngraph = graphviz.Source(dot_data) \ngraph","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cross validation prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"predict=cross_val_predict(dtr,X_train,y_train,cv=3)\npredict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cross validation prediction plot**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross validation prediction plot\nfig,ax=plt.subplots(figsize=(15,8))\nax.scatter(y_train,y_train-predict)\nax.axhline(lw=2,color='black')\nax.set_title('Cross validation prediction plot')\nax.set_xlabel('Observed')\nax.set_ylabel('Residual')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cross validation prediction plot tells about finite variance between actual target value and predicted target value. In this plot,some data points are have same finite variance between them and for some are not have it."},{"metadata":{},"cell_type":"markdown","source":"**Model evalution metrics**"},{"metadata":{},"cell_type":"markdown","source":"**R-squared and mean squared error scores**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#R-squared scores\nr2_scores = cross_val_score(dtr, X_train, y_train, cv=3)\nprint('R-squared scores :',np.average(r2_scores))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The R-squared or coefficient of determination is 0.74 on average for 3-fold cross validation ,it means that predictor is only able to predict 74% of the variance in the target variable which is contributed by independent variables."},{"metadata":{},"cell_type":"markdown","source":"**Model performance on test dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#predict the model\ndtr_pred=dtr.predict(X_test)\ndtr_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Root mean squared error and mean absolute error**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Root mean square error\nrmse=math.sqrt(metrics.mean_squared_error(y_test,dtr_pred))\n#Mean absolute error\nmae=metrics.mean_absolute_error(y_test,dtr_pred)\nprint('Root mean square error :',rmse)\nprint('Mean absolute error :',mae)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Residual plot**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Residual scatter plot\nresiduals = y_test-dtr_pred\nfig, ax = plt.subplots(figsize=(15,8))\nax.scatter(y_test, residuals)\nax.axhline(lw=2,color='black')\nax.set_xlabel('Observed')\nax.set_ylabel('Residual')\nax.set_title('Residual plot')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Residual plot tells about finite variance between actual target value and predicted target value. In this plot, some data points are have same finite variance between them and for some are not have it."},{"metadata":{},"cell_type":"markdown","source":"**Random Forest**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training the model\nfrom sklearn.ensemble import RandomForestRegressor\nX_train=train_encoded_attributes\nrf=RandomForestRegressor(n_estimators=200)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Fit the model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fit the trained model\nrf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Random forest accuracy score**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#accuracy of the model\nrf_score =rf.score(X_train,y_train)\nprint('Accuracy of the model :',rf_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cross validation prediction**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cross validation prediction\npredict=cross_val_predict(rf,X_train,y_train,cv=3)\npredict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cross validation prediction plot**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cross validation prediction plot\nfig,ax=plt.subplots(figsize=(15,8))\nax.scatter(y_train,y_train-predict)\nax.axhline(lw=2,color='black')\nax.set_title('Cross validation prediction plot')\nax.set_xlabel('Observed')\nax.set_ylabel('Residual')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cross validation prediction plot tells about finite variance between actual target value and predicted target value. In this plot,some data points are have same finite variance between them and for some are not have it."},{"metadata":{},"cell_type":"markdown","source":"**R-squared and mean squared error scores**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#R-squared scores\nr2_scores = cross_val_score(rf, X_train, y_train, cv=3)\nprint('R-squared scores :',np.average(r2_scores))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The R-squared or coefficient of determination is 0.85 on average for 3-fold cross validation , it means that predictor is only able to predict 85% of the variance in the target variable which is contributed by independent variables."},{"metadata":{},"cell_type":"markdown","source":"**Model performance on test dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#predict the model\nX_test=test_encoded_attributes\nrf_pred=rf.predict(X_test)\nrf_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Root mean squared error and mean absolute error**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Root mean square error\nrmse = math.sqrt(metrics.mean_squared_error(y_test,rf_pred))\nprint('Root mean square error :',rmse)\n#Mean absolute error\nmae=metrics.mean_absolute_error(y_test,rf_pred)\nprint('Mean absolute error :',mae)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Residual plot**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Residual scatter plot\nfig, ax = plt.subplots(figsize=(15,8))\nresiduals=y_test-rf_pred\nax.scatter(y_test, residuals)\nax.axhline(lw=2,color='black')\nax.set_xlabel('Observed')\nax.set_ylabel('Residuals')\nax.set_title('Residual plot')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cross validation prediction plot tells about finite variance between actual target value and predicted target value.In this plot,some data points are have same finite variance between them and for some are not have it."},{"metadata":{},"cell_type":"markdown","source":"**Final model for predicting the bike rental count on daily basis**"},{"metadata":{},"cell_type":"markdown","source":"When we compare the root mean squared error and mean absolute error of all 3 models, the random forest model has less root mean squared error and mean absolute error. So, finally random forest model is bset for predicting the bike rental count on daily basis."},{"metadata":{"trusted":true},"cell_type":"code","source":"Bike_df1=pd.DataFrame(y_test,columns=['y_test'])\nBike_df2=pd.DataFrame(rf_pred,columns=['rf_pred'])\nBike_predictions=pd.merge(Bike_df1,Bike_df2,left_index=True,right_index=True)\nBike_predictions.to_csv('Bike_Renting_Python.csv')\nBike_predictions","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}