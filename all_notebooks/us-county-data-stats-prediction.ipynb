{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.metrics import roc_curve,auc\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, KBinsDiscretizer\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# show all columns of dataframe\npd.set_option('display.max_columns', None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read counties dataset\norig_df = pd.read_csv('/kaggle/input/covid19-in-usa/us_counties_covid19_daily.csv')\n\nproc_df = orig_df.copy()\n\n# dataset size\nprint('df shape: {}'.format(proc_df.shape))\nproc_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## basic info of dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 数据集中最后统计的时间\nprint('lattest date in dataset: {}'.format(proc_df.sort_values(by=['date'], ascending=False)['date'].max()))\nprint('earliest date in dataset: {}'.format(proc_df.sort_values(by=['date'], ascending=False)['date'].min()))\nprint('total states number: {}'.format(len(proc_df.state.unique())))\nprint('total counties number: {}'.format(len(proc_df[proc_df['date'] == '2020-07-20']['county'])))\nprint('total unique counties number(different state may have same county name): {}'.format(len(proc_df.county.unique()))) # 不同州的county的名字是有重复的","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1. Until July, total cases and deaths of all counties","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# As the cases and deaths number is accumulated, so we just use the last day of month\ndef summarize_total_numbers(df, date):\n    tmp_df = df.copy()\n    \n    final_df = tmp_df[tmp_df['date'] == date]\n    print('total cases: {}'.format(final_df.cases.sum()))\n    print('total deaths: {}'.format(final_df.deaths.sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summarize_total_numbers(df=proc_df, date='2020-07-20')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Until July, most cases/deaths of states&counties and least cases/deaths of states&counties","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_max_min_cases_deaths_per_state_county(df, date):\n    tmp_df = df.copy()\n    \n    final_df = tmp_df[tmp_df['date'] == date]\n        \n    # most cases/deaths of states\n    max_case_state_df = final_df.groupby('state')['cases'].apply(sum).sort_values(ascending=False).reset_index()\n    max_death_state_df = final_df.groupby('state')['deaths'].apply(sum).sort_values(ascending=False).reset_index()\n    print('max case number of states - {}: {}'.format(max_case_state_df.iloc[0]['state'], max_case_state_df.iloc[0]['cases']))\n    print('max death number of states - {}: {}'.format(max_death_state_df.iloc[0]['state'], max_death_state_df.iloc[0]['deaths']))\n    \n    # least cases/deaths of states\n    min_case_state_df = final_df.groupby('state')['cases'].apply(sum).sort_values(ascending=True).reset_index()\n    min_death_state_df = final_df.groupby('state')['deaths'].apply(sum).sort_values(ascending=True).reset_index()\n    print('min case number of states - {}: {}'.format(min_case_state_df.iloc[0]['state'], min_case_state_df.iloc[0]['cases']))\n    print('min death number of states - {}: {}'.format(min_death_state_df.iloc[0]['state'], min_death_state_df.iloc[0]['deaths']))\n    \n    # most cases/deaths of counties\n    max_cases_county_df = final_df.sort_values(by=['cases'], ascending=False).head(1)\n    max_deaths_county_df = final_df.sort_values(by=['deaths'], ascending=False).head(1)\n    print('state: {}, county: {}, max cases: {}'.format(max_cases_county_df.iloc[0]['state'], max_cases_county_df.iloc[0]['county'], max_cases_county_df.iloc[0]['cases']))\n    print('state: {}, county: {}, max deaths: {}'.format(max_deaths_county_df.iloc[0]['state'],max_deaths_county_df.iloc[0]['county'], max_deaths_county_df.iloc[0]['deaths']))\n    \n    # least cases/deaths of counties\n    min_cases_county_df = final_df.sort_values(by=['cases'], ascending=True).head(1)\n    min_deaths_county_df = final_df.sort_values(by=['deaths'], ascending=True).head(1)\n    print('state: {}, county: {}, min cases: {}'.format(min_cases_county_df.iloc[0]['state'], min_cases_county_df.iloc[0]['county'], min_cases_county_df.iloc[0]['cases']))\n    print('state: {}, county: {}, min deaths: {}'.format(min_deaths_county_df.iloc[0]['state'], min_deaths_county_df.iloc[0]['county'], min_deaths_county_df.iloc[0]['deaths']))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_max_min_cases_deaths_per_state_county(df=proc_df, date='2020-07-20')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Util July, avg/median of all states & counties","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def avg_and_median_of_state_county_cases_deaths(df, date):\n    tmp_df = df.copy()\n    final_df = tmp_df[tmp_df['date'] == date]\n    \n    gb_df = final_df.groupby('state')['cases','deaths'].apply(sum).reset_index()\n    \n    # avg/median of states\n    print('states avg cases: {}, median cases: {}'.format(gb_df.cases.mean(), gb_df.cases.median()))\n    print('states avg deaths: {}, median cases: {}'.format(gb_df.deaths.mean(), gb_df.deaths.median()))\n    \n    # avg/median of counties\n    print('mean cases of each state:')\n    print(final_df.groupby('state')['cases','deaths'].mean().reset_index().sort_values(by=['cases'], ascending=False))\n    \n    print('median cases of each state:')\n    print(final_df.groupby('state')['cases','deaths'].median().reset_index().sort_values(by=['cases'], ascending=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_and_median_of_state_county_cases_deaths(df=proc_df, date='2020-07-20')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. During Jan to July, diff cases and deaths of each state","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def each_month_increment_cases_deaths_of_states(df):\n    tmp_df = df.copy()\n    \n    def get_last_day_of_month():\n        from pandas.tseries.offsets import MonthEnd\n        dates = (pd.to_datetime(tmp_df['date']) + MonthEnd(1)).dt.strftime('%Y-%m-%d').unique()\n        return dates\n    \n    last_dates = get_last_day_of_month()\n    \n    # replace 7-31 with 7-20\n    last_dates = np.append(last_dates, ['2020-07-20'])\n    \n    # get final stats of each state and county by selecting data with last day\n    month_stats_df = tmp_df[tmp_df['date'].isin(last_dates)]\n    month_stats_df['month'] = pd.to_datetime(month_stats_df['date'], format='%Y-%m').dt.strftime('%Y-%m')\n    \n    \n    state_month_df = month_stats_df.groupby(['state', 'month']).sum().reset_index()\n    \n    # iterate each state, output diff figures of each state in 7 months\n    for state in tmp_df['state'].unique():\n        state_df = state_month_df[state_month_df['state']==state].sort_values(by=['month'], ascending=True)\n        \n        # cases/death diff\n        state_df['case_diff'] = state_df['cases'].diff()\n        state_df['death_diff'] = state_df['deaths'].diff()\n        \n        print('state month cases/death diff: {}'.format(state))\n        print(state_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"each_month_increment_cases_deaths_of_states(proc_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## severe county of federal and states","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### we get data from (5,6,7) - three month. if 6-7 incr is faster than incr of 5-6, we do think the tendency of Covid'19 in this state or county is spreading. \n#### if some of counties do not have records in July, then it means they are under control. For this, the counties are not under calculation.\n#### The above is Condition-I for defining the severe counties.\n\n#### Here is Condition-II.\n#### As to the Federal and States, if the incr of one county is larger than the avg incr of counties of the federal, it will be counted in the severe counties of the Federal. \n#### The same to States, if the incr of one county is larger than the avg incr of counties of the state, it will be added to the list of severe counties of the State.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# get the severe counties of fed & state.\ndef severe_county_by_month(df):\n    tmp_df = df.copy()\n    \n    last_dates = ['2020-05-31', '2020-06-30','2020-07-20']\n    \n    # get data with the last day filter\n    month_stats_df = tmp_df[tmp_df['date'].isin(last_dates)]\n    month_stats_df['month'] = pd.to_datetime(month_stats_df['date'], format='%Y-%m').dt.strftime('%Y-%m')\n    \n    # As county in different states may have the same name, so we combine State and County name to distinguish.\n    month_stats_df['new_county'] = month_stats_df['state'] + '_' + month_stats_df['county']\n    \n    county_month_df = month_stats_df.groupby(['new_county', 'month']).sum().reset_index()\n    \n    # all counties in the Federal\n    county_list = county_month_df['new_county'].unique()\n    \n    # the avg incr of all counties in the federal\n    fed_county_diff=[]\n    for cty in county_list:\n        cty_df = county_month_df[county_month_df['new_county']==cty]\n        \n        # there is no such situation that no records in previous month but have records in latter month\n        if len(cty_df) < 3:\n            continue\n        \n        cases_diff = cty_df['cases'].reset_index().diff()['cases'][2]\n        \n        fed_county_diff.append(cases_diff)\n    fed_avg_cases_diff = sum(fed_county_diff)/len(fed_county_diff)\n    print('fed avg cases incr: {}'.format(fed_avg_cases_diff))\n    \n    # avg incr of counties of states\n    state_county_diff_sum={}\n    for cty in county_list:\n        cty_df = county_month_df[county_month_df['new_county']==cty]\n        \n        if len(cty_df) < 3:\n            continue\n            \n        cases_diff = cty_df['cases'].reset_index().diff()['cases'][2]\n        \n        arr = cty.split('_')\n        \n        state_name=arr[0]\n        cty_name=arr[1]\n        \n        if state_name in state_county_diff_sum:\n            cty_value = state_county_diff_sum[state_name]\n            state_county_diff_sum[state_name] = cty_value + float(cases_diff)\n        else:\n            state_county_diff_sum[state_name] = float(cases_diff)\n            \n    state_county_number_dict = tmp_df[['state','county']].drop_duplicates().groupby(['state']).count().to_dict()['county']\n    \n    state_county_diff={}\n    for state in state_county_diff_sum:\n        cty_sum = state_county_diff_sum[state]\n        num=state_county_number_dict[state]\n        \n        state_county_diff[state]=cty_sum/num\n    \n    print('state avg cases incr: {}'.format(state_county_diff))\n        \n    \n    severe_county_fed = []\n    severe_county_state = []\n    for cty in county_list:\n        cty_df = county_month_df[county_month_df['new_county']==cty]\n        \n        if len(cty_df) < 3:\n            continue\n        \n        cases_diff = cty_df['cases'].reset_index().diff()\n        deaths_diff = cty_df['deaths'].reset_index().diff()\n        \n\n        # incr larger than avg incr of federal\n        if cases_diff['cases'][2] >= cases_diff['cases'][1] and deaths_diff['deaths'][2] >= deaths_diff['deaths'][1] and cases_diff['cases'][2] >= fed_avg_cases_diff:\n            severe_county_fed.append(cty)\n            \n        # incr larger than avg incr of states\n        arr = cty.split('_')\n        \n        state_name=arr[0]\n        cty_name=arr[1]\n        state_cty_incr=state_county_diff[state_name]\n        if cases_diff['cases'][2] >= cases_diff['cases'][1] and deaths_diff['deaths'][2] >= deaths_diff['deaths'][1] and cases_diff['cases'][2] >= state_cty_incr:\n            severe_county_state.append(cty)\n            \n        \n    print('severe counties count of fed: {}, list: {}'.format(len(severe_county_fed), severe_county_fed))\n    print('severe counties count of state: {}, list: {}'.format(len(severe_county_state), severe_county_state))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"severe_county_by_month(df=proc_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## predict tendency of states","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# create train set \ndef build_train_set(df):\n    tmp_df=df.copy()\n    \n    def get_last_day_of_month():\n        from pandas.tseries.offsets import MonthEnd\n        dates = (pd.to_datetime(tmp_df['date']) + MonthEnd(1)).dt.strftime('%Y-%m-%d').unique()\n        return dates\n    \n    last_dates = get_last_day_of_month()\n    \n    last_dates = np.append(last_dates, ['2020-07-20'])\n    # last_dates.append(['2020-07-20'])\n    \n    month_stats_df = tmp_df[tmp_df['date'].isin(last_dates)]\n    month_stats_df['month'] = pd.to_datetime(month_stats_df['date'], format='%Y-%m').dt.strftime('%Y-%m')\n    \n    \n    state_month_df = month_stats_df.groupby(['state', 'month']).sum().reset_index()\n    \n    train_df = pd.DataFrame(columns=['state','m2_c','m2_d','m3_c','m3_d','m4_c','m4_d','m5_c','m5_d','m6_c','m6_d','m7_c','m7_d','future'])\n    \n    month_list = ['2020-01','2020-02','2020-03','2020-04','2020-05','2020-06','2020-07']\n    \n    # iterate each state, output diff of cases and deaths of each state during 7 months.\n    state_train_row=[]\n    for state in tmp_df['state'].unique():\n        state_df = state_month_df[state_month_df['state']==state].sort_values(by=['month'], ascending=True)\n        \n        # cases/death diff\n        state_df['case_diff'] = state_df['cases'].diff()\n        state_df['death_diff'] = state_df['deaths'].diff()\n        \n        cases_month_list = state_df['month'].unique()\n        \n        lst = list(set(month_list) - set(cases_month_list))\n        \n        if len(lst) == 0:\n            pass\n        else:\n            for m in lst:\n                state= state_df.iloc[0][0]\n                new_df = pd.DataFrame([[state, m, 0, 0,0,0,0]], columns=['state','month','fips ','cases','deaths','case_diff','death_diff'])\n                state_df = pd.concat([state_df,new_df], axis=0)\n            \n        state_sort_df = state_df.sort_values(by=['month'], ascending=True)\n        #print(state_sort_df)\n        train_row = []\n        for row in state_sort_df.itertuples():\n            \n            state = row.state\n            month = row.month\n            case_diff = row.case_diff\n            death_diff = row.death_diff\n            \n            if len(train_row) == 0:\n                train_row.append(state)\n            \n            train_row.append(case_diff)\n            train_row.append(death_diff)\n        \n        state_train_row.append(train_row)\n        \n#         print('train row:')\n#         print(train_row)\n        \n#         print('state train row:')\n#         print(state_train_row)\n        \n    return pd.DataFrame(state_train_row, columns=['state','m1_c','m1_d','m2_c','m2_d','m3_c','m3_d','m4_c','m4_d','m5_c','m5_d','m6_c','m6_d','m7_c','m7_d'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = build_train_set(df=proc_df)\ntrain_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# if incr of cases and deaths both go down, we set label as 1 for this sample, it means the tendency is controlled. Otherwise,\n# the label of this samples will be set to 0, which means the tendency keeps spreading.\ndef set_label(row):\n    if row['m6_c']>=row['m7_c'] and row['m6_d']>=row['m7_d']:\n        return 1\n    else:\n        return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['label']=train_df.apply(set_label, axis=1)\ntrain_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Use Logistic Regression to predict tendency label of states.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set = train_df.copy()\ntrain_set = train_set.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### model training while using cross_validation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# generate X and y \ny=train_set.pop('label')\nX=train_set\n\nstates = X.pop('state')\nstates","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_validate\nfrom sklearn import linear_model\n\n#lr=LogisticRegression(random_state=0)\nlr=linear_model.RidgeClassifier()\nscores = cross_validate(lr,X, y, cv=10, return_estimator=True, return_train_score=True, scoring=['accuracy', 'roc_auc'])\nscores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"AUC: %0.2f (+/- %0.2f)\" % (scores['train_roc_auc'].mean(), scores['train_roc_auc'].std() * 2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### get best model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cls_model = scores.get('estimator')[1]\ncls_model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### predict tendency for states","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_state = cls_model.predict(X)\nstate_tendency_df = pd.concat([pd.DataFrame(states, columns=['state']),pd.DataFrame(predict_state, columns=['tendency'])], axis=1)\nstate_tendency_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### results of states Covid'19 tendency","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"spreading_states = state_tendency_df[state_tendency_df['tendency']==0]['state'].unique()\ncontrolled_states = state_tendency_df[state_tendency_df['tendency']==1]['state'].unique()\n\nprint('keep spreading states, count: {}, state list:{}'.format(len(spreading_states), spreading_states))\nprint('controlled states, count: {}, state list:{}'.format(len(controlled_states), controlled_states))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}