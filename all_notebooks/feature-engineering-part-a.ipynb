{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Feature Engineering_Part A_ <b style=\"color:black;\"> Handling Missing Values & Outliers** </b>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-size:160%;\"> In this note book, I will be practising various techniques used to handle missing values and outliers in a dataset. The content of this post borrowed from the notebook \"Feature Engineering from scratch\" by https://www.kaggle.com/harshjain123.</p> ","metadata":{}},{"cell_type":"markdown","source":"# <b style=\"color:blue;\"> Techniques for Handling Missing Values </b>\n<p style=\"font-size:160%;\"> Here is the list of typical techniques use to handle the missing values in a dataset: </p>\n<li style=\"font-size:150%;\"> Mean/Median/Mode\n<li style=\"font-size:150%;\"> Random Sample Imputation\n<li style=\"font-size:150%;\"> End of Distribution Imputation\n<li style=\"font-size:150%;\"> Arbitrary Imputation\n<li style=\"font-size:150%;\"> Regression Imputation\n<li style=\"font-size:150%;\"> KNN Imputation","metadata":{}},{"cell_type":"markdown","source":"<p style=\"font-size:180%;\"><b> 1. Mean/Median/Mode</b></p>\n<p style=\"font-size:160%;\"> This is used when data is missing completely at random (MCAR). The missing values most likely look like the majority of observations in the variable aka mean/median/mode. In this case, it is reasonable to assume that the missing values are close to the mean/median/mode of the distribution</p>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Import dataset\ndf = pd.read_csv('../input/titanic/train.csv')\n\n# Check for missing values\ndf.isnull().sum()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Selecting & printing columns with missing values\ndf = pd.read_csv('../input/titanic/train.csv', usecols=['Age', 'Cabin', 'Embarked'])\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find percentage of missing values\ndf.isnull().mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to impute missing values with mean/mode/median\ndef impute_nan(df, variable, mean, mode, median):\n    df[variable + '_mean'] = df[variable].fillna(mean)\n    df[variable + '_mode'] = df[variable].fillna(mode)\n    df[variable + '_median'] = df[variable].fillna(median)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find mean, mode & median for 'Age' column\nmean = df.Age.mean()\nmode = df.Age.mode()\nmedian = df.Age.median()\n\n# Call function 'ampute_nan'\nimpute_nan(df, 'Age', mean, mode, median)\n\n# Check for updated dataframe\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the 'Age' column with missing values & replaced one\nimport matplotlib.pyplot as plt\nfig = plt.figure()\nax = fig.add_subplot(111)\n\ndf.Age.plot(kind='density', ax=ax)\ndf.Age_mean.plot(kind='density', ax=ax)\ndf.Age_mode.plot(kind='density', ax=ax)\ndf.Age_median.plot(kind='density', ax=ax)\n\nlines, labels = ax.get_legend_handles_labels()\nax.legend(lines, labels, loc='best')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:180%;\"><b> 2. Random Sample Imputation</b></p>\n<p style=\"font-size:160%;\"> This involves taking of random sample of observations from the dataset and replace the missing values with it. This technique is suitable when data are missing completely at random (MCAR)</p>","metadata":{}},{"cell_type":"code","source":"# Selecting & printing columns with missing values\nimport pandas as pd\ndf = pd.read_csv('../input/titanic/train.csv', usecols=['Age', 'Cabin', 'Embarked'])\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to impute missing values with random sample\ndef impute_nan(df, variable, median):\n    df[variable + '_median'] = df[variable].fillna(median)\n    df[variable + '_random'] = df[variable]\n    # Get random sample\n    random_sample = df[variable].dropna().sample(df[variable].isnull().sum(), random_state=0)\n    # Get index to merge the dataset\n    random_sample.index = df[df[variable].isnull()].index\n    df.loc[df[variable].isnull(), variable + '_random'] = random_sample\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find median & call function\nmedian = df.Age.median()\nimpute_nan(df, 'Age', median)\n\n# Check for Dataframe updation\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the 'Age' column with missing values & replaced one\nimport matplotlib.pyplot as plt\nfig = plt.figure()\nax = fig.add_subplot(111)\n\ndf.Age.plot(kind='density', ax=ax)\ndf.Age_median.plot(kind='density', ax=ax)\ndf.Age_random.plot(kind='density', ax=ax)\n\nlines, labels = ax.get_legend_handles_labels()\nax.legend(lines, labels, loc='best')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:180%;\"><b> 3. Capturing NaN with New Feature </b></p>\n<p style=\"font-size:160%;\"> This technique is well suited for the data that is missing not at random (MNAR). In this method, the NaN values are captured and replaced with new feature</p>","metadata":{}},{"cell_type":"code","source":"# Selecting & printing columns with missing values\nimport pandas as pd\ndf = pd.read_csv('../input/titanic/train.csv', usecols=['Age', 'Cabin', 'Embarked'])\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add a new feature 'Age_NaN' based on missing values\ndf['Age_NaN'] = np.where(df.Age.isnull(), 1, 0)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the 'Age' column with missing values & replaced one\nimport matplotlib.pyplot as plt\nfig = plt.figure()\nax = fig.add_subplot(111)\n\ndf.Age_NaN.plot(kind='density', ax=ax)\n\nlines, labels = ax.get_legend_handles_labels()\nax.legend(lines, labels, loc='best')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:180%;\"><b> 4. End of Distribution </b></p>\n<p style=\"font-size:160%;\"> This is a tricky method in which ends of distribution are replaced. </p>","metadata":{}},{"cell_type":"code","source":"# Selecting & printing columns with missing values\nimport numpy as np\nimport pandas as pd\ndf = pd.read_csv('../input/titanic/train.csv', usecols=['Age', 'Cabin', 'Embarked'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize 'Age' as histogram\ndf.Age.hist(bins=50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize 'Age' as box-plot\nimport seaborn as sns\nsns.boxplot('Age', data=df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set extreme values\nextreme = df.Age.mean() + 3*df.Age.std()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function with passing parameters: df, variable, median, extreme\ndef impute_nan(df, variable, median, extreme):\n    df[variable + '_end_distribution'] = df[variable].fillna(extreme)\n    df[variable].fillna(median, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Call function\nimpute_nan(df, 'Age', df.Age.median(), extreme)\n# Check updated dataframe\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:180%;\"><b> 5. Arbitrary Value Imputation </b></p>\n<p style=\"font-size:160%;\"> It consists of replacing all occurrences of missing values within a variable with an arbitrary value. The arbitrary value should be different from the mean or median and not within the normal values of the variable. </p>","metadata":{}},{"cell_type":"code","source":"# Selecting & printing columns with missing values\nimport numpy as np\nimport pandas as pd\ndf = pd.read_csv('../input/titanic/train.csv', usecols=['Age', 'Cabin', 'Embarked'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define function for arbitrary value imputation\ndef impute_nan(df, variable):\n    df[variable + '_zero'] = df[variable].fillna(0)\n    df[variable + '_hundred'] = df[variable].fillna(100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Call function\nimpute_nan(df, 'Age')\n# Check updated dataframe\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the 'Age' column with missing values & replaced one\nimport matplotlib.pyplot as plt\nfig = plt.figure()\nax = fig.add_subplot(111)\n\ndf.Age.plot(kind='density', ax=ax)\ndf.Age_zero.plot(kind='density', ax=ax)\ndf.Age_hundred.plot(kind='density', ax=ax)\n\nlines, labels = ax.get_legend_handles_labels()\nax.legend(lines, labels, loc='best')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:180%;\"><b> 6. Frequent Category Imputation </b></p>\n<p style=\"font-size:160%;\"> It consists of replacing all occurrences of missing values with most frequent one. Use this method when data contains no more than 5% of missing values. </p>","metadata":{}},{"cell_type":"code","source":"# Selecting & printing columns with missing values\nimport numpy as np\nimport pandas as pd\ndf = pd.read_csv('../input/titanic/train.csv', usecols=['Age', 'Cabin', 'Embarked'])\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute frequency of each type\ndf['Embarked'].value_counts().plot.bar()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define function to imputate missing value with the frequent one\ndef impute_nan(df, variable):\n    most_frequent_value = df[variable].mode()[0]\n    df[variable].fillna(most_frequent_value, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Call function and check for updates\nimpute_nan(df, 'Embarked')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:180%;\"><b> 7. Regression Imputation </b></p>\n<p style=\"font-size:160%;\"> This method is used when there is a probable correlation between the missing values and other variables. </p>","metadata":{}},{"cell_type":"code","source":"# Selecting & printing columns with missing values\nimport numpy as np\nimport pandas as pd\ndf = pd.read_csv('../input/titanic/train.csv', usecols=['PassengerId', 'Age', 'Fare', 'Survived'])\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find correlation among variables & plot it\ncorr = df.corr()\ncorr.style.background_gradient(cmap='coolwarm').set_precision(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a subset of data where there no missing value\n# Note: 'Fare' has no missing values, 'Age' has missing values i.e. subset ['Age', 'Fare']\ndf_Age_Fare = df.dropna(axis=0, subset = ['Age', 'Fare'])\ndf_Age_Fare = df_Age_Fare.loc[:,['Age', 'Fare']]\n\n# Find entries of 'Age' with missing values\nmissing_Age = df['Age'].isnull()\n\n# Extract entries of 'Fare' corresponding to missing values of 'Age'\nFare_missAge = pd.DataFrame(df['Fare'] [missing_Age])\n\n# Assign x & y variables\nX = df_Age_Fare[['Fare']]\ny = df_Age_Fare[['Age']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split dataset into training data & testing data\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Peform linear regression analysis\nfrom sklearn.linear_model import LinearRegression\nlm = LinearRegression().fit(X_train, y_train)\nAge_pred = lm.predict(Fare_missAge)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot regression results\nimport matplotlib.pyplot as plt\nplt.scatter(Fare_missAge, df['Age'] [missing_Age], color='gray')\nplt.plot(Fare_missAge, Age_pred, color='royalblue', linewidth=2)\nplt.xlabel('Fare')\nplt.ylabel('Age')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p style=\"font-size:180%;\"><b> 8. KNN Imputation </b></p>\n<p style=\"font-size:160%;\"> This method i.e. K-Nearest Neighbour (KNN) is just like regression imputation that can be used. </p>","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import KNNImputer\nimport numpy as np\n\nX = [ [3, np.NaN, 5], [1, 0, 0], [3, 3, 3] ]\nprint(\"X: \", X)\nprint(\"===========\")\n\nimputer = KNNImputer(n_neighbors=1)\nimpute_with_1 = imputer.fit_transform(X)\nprint(\"\\n Impute with 1 Neighbours: \\n\", impute_with_1)\n\nimputer = KNNImputer(n_neighbors=2)\nimpute_with_2 = imputer.fit_transform(X)\nprint(\"\\n Impute with 2 Neighbours: \\n\", impute_with_1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b style=\"color:blue;\"> Techniques for Handling Outliers </b>\n<p style=\"font-size:160%;\"> Here is the list of typical techniques use to handle the missing values in a dataset: </p>\n<li style=\"font-size:150%;\"> Box Plot\n<li style=\"font-size:150%;\"> Scatter Plot\n<li style=\"font-size:150%;\"> Z-Score\n<li style=\"font-size:150%;\"> IQR-Score    \n<p style=\"font-size:160%;\"> Algorithms NOT sensitive to outliers: </p>\n<li style=\"font-size:150%;\"> Naive Bayes\n<li style=\"font-size:150%;\"> SVM\n<li style=\"font-size:150%;\"> Decision Trees\n<li style=\"font-size:150%;\"> XGBoost, GBM\n<li style=\"font-size:150%;\"> KNN    \n<p style=\"font-size:160%;\"> Algorithms sensitive to outliers: </p>\n<li style=\"font-size:150%;\"> Linear Regression\n<li style=\"font-size:150%;\"> Logistic Regression\n<li style=\"font-size:150%;\"> K-Means Clustering\n<li style=\"font-size:150%;\"> Hierarchical Clustering\n<li style=\"font-size:150%;\"> PCA\n<li style=\"font-size:150%;\"> Neural NetWorks","metadata":{}},{"cell_type":"markdown","source":"## <center>If You find this kernel helpful, please give an upvote. Thank you!!</center>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}