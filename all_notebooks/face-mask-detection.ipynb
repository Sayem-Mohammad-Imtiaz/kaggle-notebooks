{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import AveragePooling2D\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport matplotlib.pyplot as plt\nimport os\nfrom mtcnn import MTCNN\nimport cv2\nimport json\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"lr = 1e-4\nbs = 32\nepochs = 20","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimages=[]\nlabels=[]\nfor filename in os.listdir(images_dir):\n    num = filename.split('.')[ 0 ]\n    if int(num) > 1800:\n        class_name = None\n        anno = filename + \".json\"\n        with open(os.path.join(annotations_dir, anno)) as json_file:\n            json_data = json.load(json_file)\n            no_anno = json_data[\"NumOfAnno\"]\n            k = 0\n            for i in range(0, no_anno):\n                class_nam = json_data['Annotations'][i]['classname']\n                if class_nam == 'face_with_mask':\n                    class_name = 'face_with_mask'\n                    k = i\n                    break\n                elif class_nam == 'face_no_mask':\n                    class_name = 'face_no_mask'\n                    k = i\n                    break\n                else:\n                    if class_nam in ['hijab_niqab', 'face_other_covering', \"face_with_mask_incorrect\", \"scarf_bandana\", \"balaclava_ski_mask\", \"other\" ]:\n                        class_name = 'face_no_mask'\n                    elif class_nam in [\"gas_mask\", \"face_shield\", \"mask_surgical\", \"mask_colorful\"]:\n                        class_name = 'face_with_mask'\n            box = json_data[ 'Annotations' ][k][ 'BoundingBox' ]\n            (x1, x2, y1, y2) = box\n        if class_name is not None:\n            image = cv2.imread(os.path.join(images_dir, filename))\n            img = image[x2:y2, x1:y1]\n            img = cv2.resize(img, (224, 224))\n            img = img[...,::-1].astype(np.float32)\n            img = preprocess_input(img)\n            images.append(img)\n            labels.append(class_name)  \n   \nimages = np.array(images, dtype=\"float32\")\nlabels = np.array(labels)\nprint(len(images))\nprint(len(labels))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"annotations_dir='../input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/annotations/'\nimages_dir='../input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lb = LabelBinarizer()\nlabels = lb.fit_transform(labels)\nlabels = to_categorical(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(trainX, testX, trainY, testY) = train_test_split(images, labels,test_size=0.20, stratify=labels, random_state=42)\nprint(len(trainX))\nprint(len(trainY))\nprint(len(testX))\nprint(len(testY))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nimagedata = ImageDataGenerator(rotation_range=20, zoom_range=0.15, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n                      fill_mode=\"nearest\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Model1 = MobileNetV2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224,224,3)))\nModel2 = Model1.output\nModel2 = AveragePooling2D(pool_size=(7,7))(Model2)\nModel2 = Flatten(name=\"flatten\")(Model2)\nModel2 = Dense(128, activation=\"relu\")(Model2)\nModel2 = Dropout(0.5)(Model2)\nModel2 = Dense(2, activation=\"softmax\")(Model2)\nmodel = Model(inputs=Model1.input, outputs=Model2)\nfor layer in Model1.layers:\n    layer.trainable = False\noptimizer = Adam(lr=lr,decay=lr/epochs)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"his = model.fit(imagedata.flow(trainX, trainY, batch_size=bs), steps_per_epoch=len(trainX)//bs, validation_data=(testX,testY), \n               validation_steps=len(testX)//bs, epochs=epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(testX, batch_size=bs)\npred = np.argmax(pred, axis=1)\nprint(classification_report(testY.argmax(axis=1), pred, target_names=lb.classes_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detector = MTCNN()\nimage = cv2.imread(os.path.join(images_dir, '0004.jpg'))\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nfaces = detector.detect_faces(image)\ntemp = []\nmaxx = max(faces, key=lambda x:x['confidence'])\nx,y,w,h = maxx['box']\nprint(x)\n\n# for i in range(len(faces)):\n#     x,y,w,h = faces[i]['box']\n#     x, y = abs(x), abs(y)\n#     roi = image[y:y+h, x:x+w]            \n#     roi = cv2.resize(roi, (224, 224))\n#     roi = roi.astype(np.float32)\n#     roi = preprocess_input(roi)\n#     print(roi.shape)\n#     seq = [x['confidence'] for x in faces]\n#         print(\"pred\")\n#         temp.append(roi)\n        \n\n# temp = np.asarray(temp)\n# print(type(testX))\n# print(type(temp))\n# [(a,b)] = model.predict(temp, batch_size=bs)\n# print(a)\n# print(b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nsubmissio = pd.DataFrame(columns=['name', 'x1','x2','y1','y2','classname'])\ndetector = MTCNN()\nfor filename in os.listdir(images_dir):\n    temp = []\n    num = filename.split('.')[0]    \n    if int(num) <= 1800:\n        if int(num) % 100 == 0:\n            print(int(num))\n        image = cv2.imread(os.path.join(images_dir, filename))\n        if image is None:\n            continue\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        (h, w) = image.shape[:2]\n        faces = detector.detect_faces(image)\n        if len(faces)==0:\n            class_curr = 'face_no_mask'\n            x,y,w,h=50,50,50,50\n        else:\n            face = max(faces, key=lambda x:x['confidence'])\n            x,y,w,h = face['box']\n            x, y = abs(x), abs(y)\n            roi = image[y:y+h, x:x+w]            \n            roi = cv2.resize(roi, (224, 224))\n            roi = roi.astype(np.float32)\n            roi = preprocess_input(roi)\n            temp.append(roi)\n            temp = np.asarray(temp)            \n            [(a,b)] = model.predict(temp, batch_size=bs)\n            if a > b:\n                class_curr = 'face_no_mask'\n            else:\n                class_curr = 'face_with_mask'\n        data = {'name': filename,'x1':x,'x2':y,'y1':x+w,'y2':y+h,'classname': class_curr}\n        submissio = submissio.append(data, ignore_index=True)\n\nprint(len(submissio))\n                ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submissio.sort_values(by=['name'], inplace=True)\nprint(len(submissio))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import base64\nfrom IPython.display import HTML\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\ncreate_download_link(submissio)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}