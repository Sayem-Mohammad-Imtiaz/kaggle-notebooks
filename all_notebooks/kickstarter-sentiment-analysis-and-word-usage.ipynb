{"cells":[{"metadata":{},"cell_type":"markdown","source":"# KickStarter - NLP Sentiment Analysis and Word Usage or: Help Us to Film a New, Short, Documentary about a Tabletop Miniature Festival (which I am slightly unhappy about)\n\nThe dataset for this project contains the English blurb or description of 215513 kickstarter's projects in 2017; 108310 successful and 107203 failed. All this data was collected by webrobots.io, who performed the web scraping. They cleaned and tidied the scraped data, keeping just the two columns with blurbs in english and with final state of \"successful\" or \"failed\". My analysis builds on this cleaned state.\n\n> Kickstarter is an American public-benefit corporation based in  Brooklyn, New York, that maintains a global crowdfunding platform  focused on creativity and merchandising. The company's stated mission is to \"help bring creative projects to life\". Kickstarter has reportedly received more than $1.9 billion in pledges from 9.4  million backers to fund 257,000 creative projects, such as films, music, stage shows, comics, journalism, video games, technology and food-related projects. People who back Kickstarter projects are offered tangible rewards or experiences in exchange for their pledges. This model traces its roots to subscription model of arts patronage, where artists would go directly to their audiences to fund their work.\n\n<b>- Wikipedia</b>\n\nThe goal of this notebook is to perform sentiment word and usage analysis on successful and failed blurbs, to visualize the results and identify trends in blurb writing that may be useful for future Kickstarter blurb writers.\n\nData Visualization performed using Plotly\n"},{"metadata":{},"cell_type":"markdown","source":"## Import Data to Pandas DataFrame"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ks=pd.read_csv('../input/kickstarter-nlp/df_text_eng.csv',index_col='Unnamed: 0')\ndf_ks.dropna(inplace=True)\ndf_ks.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sentiment Analysis \nNLTK's Vader Sentiment Analyzer [1] is used to score blurbs on Positive, Neutral or Negative sentiment and a Compound score for overall sentiment\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"import nltk\nnltk.download('vader_lexicon')\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nsid = SentimentIntensityAnalyzer()\nsid.polarity_scores(df_ks['blurb'].iloc[2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create a function to generate new dataframe features from sentiment analysis scores"},{"metadata":{"trusted":false},"cell_type":"code","source":"def tag_conf_gen(df):\n    neg=[]\n    neu=[]\n    pos=[]\n    compound=[]\n    for text in df['blurb']:\n        result = sid.polarity_scores(text)\n        neg.append(result['neg'])\n        neu.append(result['neu'])\n        pos.append(result['pos'])\n        compound.append(result['compound'])\n    df['neg']=neg\n    df['neu']=neu\n    df['pos']=pos\n    df['compound']=compound\n    return df","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"df_ks_sent=tag_conf_gen(df_ks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_ks_sent.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_ks_sent.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_ks.loc[df_ks.state=='successful'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_ks.loc[df_ks.state=='failed'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import plotly.graph_objects as go\nlabels=['Positive','Neutral','Negative']\nvalues=[np.sum([df_ks_sent['compound']>0]),np.sum([df_ks_sent['compound']==0]),np.sum([df_ks_sent['compound']<0])]\nfig = go.Figure(data=[go.Pie(labels=labels, values=values,marker_colors=['blue','yellow','red'])])\nfig.update_layout(title_text=\"Sentiment of Kickstarter blurbs\",)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from plotly.subplots import make_subplots\nfig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\n\nfor n,s in enumerate(['successful','failed']):\n    df=df_ks_sent.loc[df_ks_sent['state']==s]\n    labels=['Positive','Neutral','Negative']\n    values=[np.sum([df['compound']>0]),np.sum([df['compound']==0]),np.sum([df['compound']<0])]\n    colors=['blue','yellow','red']\n    fig.add_trace(go.Pie(labels=labels, values=values, name=s, marker_colors=colors),\n              1, n+1)\n\n# Use `hole` to create a donut-like pie chart\nfig.update_traces(hole=.4, hoverinfo=\"label+percent\")\n\nfig.update_layout(\n    title_text=\"Sentiment of Successful and Failed Kickstarter blurbs\",\n    # Add annotations in the center of the donut pies.\n    annotations=[dict(text='Successful', x=0.16, y=0.5, font_size=12, showarrow=False),\n                 dict(text='Failed', x=0.8, y=0.5, font_size=12, showarrow=False)])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from plotly.subplots import make_subplots\nfig = make_subplots(rows=1, cols=3, specs=[[{'type':'domain'}, {'type':'domain'}, {'type':'domain'}]])\n\nlabels=['Successful','Failed']\ncolors=['green','darkred']\n\ndf=df_ks_sent.loc[df_ks_sent['compound']>0]\nvalues=[np.sum([df['state']=='successful']),np.sum([df['state']=='failed'])]\nfig.add_trace(go.Pie(labels=labels, values=values, name=s, marker_colors=colors),\n              1, 1)\n\ndf=df_ks_sent.loc[df_ks_sent['compound']==0]\nvalues=[np.sum([df['state']=='successful']),np.sum([df['state']=='failed'])]\nfig.add_trace(go.Pie(labels=labels, values=values, name=s, marker_colors=colors),\n              1, 2)\n\ndf=df_ks_sent.loc[df_ks_sent['compound']<0]\n\nvalues=[np.sum([df['state']=='successful']),np.sum([df['state']=='failed'])]\nfig.add_trace(go.Pie(labels=labels, values=values, name=s, marker_colors=colors),\n              1, 3)\n\n# Use `hole` to create a donut-like pie chart\nfig.update_traces(hole=.4, hoverinfo=\"label+percent\")\n\nfig.update_layout(\n    title_text=\"Sentiment of Successful and Failed Kickstarter blurbs\",\n    # Add annotations in the center of the donut pies.\n    annotations=[dict(text='Positive', x=0.1, y=0.5, font_size=10, showarrow=False),\n                 dict(text='Neutral', x=0.5, y=0.5, font_size=10, showarrow=False),\n                 dict(text='Negative', x=0.9, y=0.5, font_size=10, showarrow=False)])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"fig=go.Figure(data=[go.Histogram(x=df_ks_sent['compound'])])\nfig.update_layout(title_text='Sentiment Histogram')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Histogram(x=df_ks_sent.loc[df_ks_sent['state']=='successful']['compound'],nbinsx=50,name='successful'))\nfig.add_trace(go.Histogram(x=df_ks_sent.loc[df_ks_sent['state']=='failed']['compound'],nbinsx=50,name='failed'))\n# Overlay both histograms\nfig.update_layout(barmode='overlay',title_text='Successful and Failed Sentiment Histograms')\n# Reduce opacity to see both histograms\nfig.update_traces(opacity=0.35)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"import plotly.figure_factory as ff\ndata=[df_ks_sent.loc[df_ks_sent['state']=='successful']['compound'],df_ks_sent.loc[df_ks_sent['state']=='failed']['compound']]\nlabels=['successful','failed']\nfig = ff.create_distplot(data, labels, bin_size=.1)\nfig.update_layout(title_text='Successful and Failed Sentiment Distplots')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Statistical analysis on Compound scores for successful vs. failed blurbs\nNull Hypothesis: The Compound Sentiment of successful and failed blurbs have identical distributions\nAlternate Hypothesis: The Compound Sentiment of successful and failed blurbs have different distributions\nP-value threshold: 0.05"},{"metadata":{"trusted":false},"cell_type":"code","source":"from scipy import stats\nt_stat, p= stats.ttest_ind(df_ks_sent.loc[df_ks_sent['state']=='successful']['compound'],df_ks_sent.loc[df_ks_sent['state']=='failed']['compound'],equal_var=False)\nprint('T-Statistic: ',round(t_stat,2))\nprint('P-value: ',p)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"P-Value well below a threshold for rejecting the null hypothesis that the populations have the same Compound Senitment distribution<br>\nNegative T-Statistic indicates that the mean Compound Sentiment of successsful blurbs is **lower** than failed blurbs"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"df_ks_sent['state_binary']=df_ks_sent['state']=='successful'\ndf_ks_sent.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig=go.Figure(data=go.Heatmap(z=df_ks_sent.corr(),\n                             x=df_ks_sent.corr().columns,\n                             y=df_ks_sent.corr().index,\n                             xgap=5,\n                             ygap=5,\n                             colorscale=[[0.0, \"rgb(300,100,100)\"],\n                [0.4, \"lightpink\"],\n                [0.45, \"white\"],\n                [0.5,\"lightblue\"],\n                [1.0, \"rgb(100,100,300)\"]]))\nfig.update_layout(title_text='Sentiment Correlation Heatmap')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Correlation matrix indicates a very slight negative correlation between compound sentiment successful blurbs"},{"metadata":{},"cell_type":"markdown","source":"## Word Usage Analysis"},{"metadata":{},"cell_type":"markdown","source":"blurbs are tokenized using NLTK's Tokenizer tool. Stopwords, punctuation and numbers are all removed.  Word Frequency is determined and compared for Successful and Failed blurbs."},{"metadata":{"trusted":false},"cell_type":"code","source":"import nltk\nfrom nltk.corpus import gutenberg, stopwords\nfrom nltk.collocations import *\nfrom nltk import FreqDist, word_tokenize\nimport string\nimport re\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\nnltk.download('stopwords')\nstopwords_list = stopwords.words('english')\nstopwords_list += [string.punctuation]\nstopwords_list += ['0','1','2','3','4','5','6','7','8','9']\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Determine Word Frequency Distribution for successful and failed blurbs"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"succ_blurbs=df_ks_sent.loc[df_ks_sent['state']=='successful']['blurb'].values\nsucc_flat=' '.join(succ_blurbs)\n\nsucc_words= nltk.regexp_tokenize(succ_flat,pattern)\nsucc_tokens = [word.lower() for word in succ_words]\n\n\nsucc_tokens_stopped = [word for word in succ_tokens if word not in stopwords_list]\n\nsucc_freqdist = FreqDist(succ_tokens_stopped)\nsucc_freqdist.most_common(50)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"fail_blurbs=df_ks_sent.loc[df_ks_sent['state']=='failed']['blurb'].values\nfail_flat=' '.join(fail_blurbs)\n\nfail_words= nltk.regexp_tokenize(fail_flat,pattern)\nfail_tokens = [word.lower() for word in fail_words]\n\nfail_tokens_stopped = [word for word in fail_tokens if word not in stopwords_list]\n\nfail_freqdist = FreqDist(fail_tokens_stopped)\nfail_freqdist.most_common(50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Word Frequency DataFrame is created with features 'diff' and 'ratio' for (success-failure) and (success/failure) usage measures"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"succall_df=pd.DataFrame.from_dict(dict(succ_freqdist),orient='index',columns=['freq_success'])\nfailall_df=pd.DataFrame.from_dict(dict(fail_freqdist),orient='index',columns=['freq_fail'])\ndf_freqdist_all=succall_df.join(failall_df,how='left').fillna(0)\ndf_freqdist_all['diff']=df_freqdist_all['freq_success']-df_freqdist_all['freq_fail']\ndf_freqdist_all['ratio']=df_freqdist_all['freq_success']/df_freqdist_all['freq_fail']\ndf_freqdist_all['freq_fail']=np.negative(df_freqdist_all['freq_fail'])\ndf_freqdist_all.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_freq_succ20=df_freqdist_all.sort_values(by='freq_success',ascending=False).head(20)\ndf_freq_succ20","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"fig=go.Figure()\nfig.add_trace(go.Bar(x=df_freq_succ20['freq_success'],y=df_freq_succ20.index,orientation='h',marker_color='blue',name='Usage - successful'))\nfig.add_trace(go.Bar(x=df_freq_succ20['freq_fail'],y=df_freq_succ20.index,orientation='h',marker_color='red',name='Usage - failed'))\nfig.add_trace(go.Bar(x=df_freq_succ20['diff'],y=df_freq_succ20.index,orientation='h',marker_color='green',name='Usage - net difference'))\nfig.update_traces(opacity=.6)\nfig.update_layout(barmode='overlay',yaxis=dict(autorange=\"reversed\"),title_text='Most Commonly Used Words In Successful Blurbs Totals and Difference')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most commonly used words most used in successful blurbs has a lot of crossover with the most commonly used words in failed blurbs. \n\nSome words, however, are used much more frequently by the successful blurbs than the failed blurbs. Two measures of this are below. The words with the highest net difference in usage by successful blurbs minus failed blurbs and the words with the highest ratio of usage by successful blurbs over failed blurbs (with a minimum usage of 500)"},{"metadata":{"trusted":false},"cell_type":"code","source":"df_freq_diff20=df_freqdist_all.sort_values(by='diff',ascending=False).head(20)\ndf_freq_diff20","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig=go.Figure()\nfig.add_trace(go.Bar(x=df_freq_diff20['freq_success'],y=df_freq_diff20.index,orientation='h',marker_color='blue',name='Usage - successful'))\nfig.add_trace(go.Bar(x=df_freq_diff20['freq_fail'],y=df_freq_diff20.index,orientation='h',marker_color='red',name='Usage - failed'))\nfig.add_trace(go.Bar(x=df_freq_diff20['diff'],y=df_freq_diff20.index,orientation='h',marker_color='green',name='Usage - net difference'))\nfig.update_traces(opacity=.6)\nfig.update_layout(barmode='overlay',yaxis=dict(autorange=\"reversed\"),title_text='Words With Largest Usage Difference Between Successful and Failed Blurbs')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_freq_ratio20=df_freqdist_all.loc[df_freqdist_all['freq_success']>500].sort_values(by='ratio',ascending=False).head(20)\ndf_freq_ratio20","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig=go.Figure()\nfig.add_trace(go.Bar(x=df_freq_ratio20['freq_success'],y=df_freq_ratio20.index,orientation='h',marker_color='blue',name='Usage - successful'))\nfig.add_trace(go.Bar(x=df_freq_ratio20['freq_fail'],y=df_freq_ratio20.index,orientation='h',marker_color='red',name='Usage - failed'))\nfig.add_trace(go.Bar(x=df_freq_ratio20['diff'],y=df_freq_ratio20.index,orientation='h',marker_color='green',name='Usage - net difference'))\nfig.update_traces(opacity=.6)\nfig.update_layout(barmode='overlay',yaxis=dict(autorange=\"reversed\"),title_text='Words With Largest Usage Ratio Between Successful and Failed Blurbs (Minimum 500 Usages)')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notes on word meanings:<br>\n\"th\" is most like a leftover from removing the numbers eg. \"4th\" becomes just \"th\". From the above charts this would indicate successive campaigns i.e those that merits a 4th campaign have 3 prior successful campaigns and therefore are likely to have returning backers.\n\"mm\" may relate to miniatures and tabletop games, which are have very high success to failure differences and ratios "},{"metadata":{},"cell_type":"markdown","source":"## Conclusions\n\nThe Sentiment of Kickstarter blurbs is mostly positive, however this seems to actually be detrimental to success as demonstrated in the t-test.<br>\nInterestingly, things that are \"new\" and \"first\" have high positive success differences and so do successive projects to previous kickstarters i.e things that merit a 'th'. Being both new AND repetitious are postive attributes <br>\n\"Tabletop\", \"miniature\" and \"dice\" have incredibly high success rates as do \"film\", especially a \"documentary\", as do \"dance\" projects.<br>\n\"Us\" and \"We're\" both have significant positive differences and ratios indicating backers are in favour of group efforts.<br>\nPhrasing does appear to matter somewhat - \"music\" projects are mostly unsuccessful but \"albums\" are mostly successful. <br>\n\nAsking to <b>\"help us film a new, short, documentary about a tabletop miniature festival\"</b> is a sure-fire hit! "},{"metadata":{},"cell_type":"markdown","source":"[1] Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for\nSentiment Analysis of Social Media Text. Eighth International Conference on\nWeblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014."},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":1}