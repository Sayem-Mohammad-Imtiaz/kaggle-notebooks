{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# loading a simple library I created that scales, imputes and one-hot encodes the data.\n\n!pip install git+https://github.com/sd274/pipeline_tools.git\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pipeline_tools as pt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.pipeline import Pipeline\nimport xgboost as xgb\nimport optuna","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/weather-dataset-rattle-package/weatherAUS.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe(include='object')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe(exclude='object')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are some missing values. We will ignore the categorical ones for now and impute the numerical ones."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build a Basic Pipe"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features = [\n    'Location',\t\n    'WindGustDir',\n    'WindDir9am',\n    'WindDir3pm',\n    'RainToday',\n]\n\nnum_features = [\n    'MinTemp',\n    'MaxTemp',\n    'Rainfall',\n    'Evaporation',\n    'Sunshine',\n    'WindGustSpeed',\n    'WindSpeed9am',\n    'WindSpeed3pm',\n    'Humidity9am',\n    'Humidity3pm',\n    'Pressure9am',\n    'Pressure3pm'\n]\n\ntarget = 'RainTomorrow'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df[cat_features + num_features]\ny = pd.get_dummies(df[target])[['Yes']]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pre_pipe = pt.standard_preprocessing_pipe(cat_features=cat_features, num_features=num_features)\n\npipe = Pipeline([\n    ('pre_pipe', pre_pipe),\n    ('learn', xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def objective(trial,data=X_train,target=y_train):\n    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.15,random_state=42)\n    param = {\n#         'learn__tree_method':'gpu_hist',  # this parameter means using the GPU when training our model to speedup the training process\n        'learn__reg_lambda': trial.suggest_loguniform('learn__reg_lambda', 1e-3, 10.0),\n        'learn__reg_alpha': trial.suggest_loguniform('learn__reg_alpha', 1e-3, 10.0),\n        'learn__colsample_bytree': trial.suggest_categorical('learn__colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n        'learn__subsample': trial.suggest_categorical('learn__subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learn__learning_rate': trial.suggest_categorical('learn__learning_rate', [0.001, 0.003,0.03,0.3,0.6]),\n        'learn__n_estimators': trial.suggest_int(\"learn__n_estimators\", 100, 1000),\n        'learn__max_depth': trial.suggest_categorical('learn__max_depth', [5,7,9,11,13,15,17,20]),\n        'learn__random_state': trial.suggest_categorical('learn__random_state', [24, 48,2020]),\n    }\n#     try:\n    pipe.set_params(**param)\n\n    pipe.fit(train_x, train_y)\n\n#     preds = pipe.predict_proba(test_x)[:,1]\n    preds = pipe.predict(test_x)\n\n    score = metrics.accuracy_score(test_y, preds)\n\n    return score\n#     except:\n#         return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"study = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=50)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)\nprint('Best Score: ', study.best_trial.value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_params = study.best_trial.params\n\nbest_params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe.set_params(**best_params)\n\npipe.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\ntest_prediction = pipe.predict_proba(X_test)[:,1]\npredictions = pipe.predict(X_test)\n\nscore = metrics.roc_auc_score(y_test, test_prediction)\naccuracy = metrics.accuracy_score(y_test, predictions)\n\nprint(f'Area under ROC of Model On Test Set - {score:,.2%}')\nprint(f'Accuracy - {accuracy:,.2%}')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}