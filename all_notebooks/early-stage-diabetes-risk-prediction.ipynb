{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Imports**","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom mlxtend.plotting import plot_confusion_matrix\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score, precision_recall_curve, average_precision_score\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/early-stage-diabetes-risk-prediction-dataset/diabetes_data_upload.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Exploration**","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe().T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The target variable is the diagnosis located in the \"class\" column, it has a binary value Positive or Negative.<br>\nExcept for the age all the other features are categorical with binary values Yes or No.<br>\nThere are no NULL values","metadata":{}},{"cell_type":"markdown","source":"# Age factor Analysis","metadata":{}},{"cell_type":"code","source":"# age distribution\n\nhist_data =[df[\"Age\"].values]\ngroup_labels = ['Age'] \n\nfig = ff.create_distplot(hist_data, group_labels)\nfig.update_layout(title_text='Age Distribution plot')\n\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Box(x=df['Age'], name=\"All patients\", boxpoints='all', boxmean='sd'))\nfig.update_layout(title_text=\"Box plot and distribution by Age\")\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"with the boxplot we can appreciate the interquartile range that tells us that 50% of the patients are between 39 and 57 years old, with a mean of 48 and standard deviation of 12. There are only few patients younger than 25 and older than 72.","metadata":{}},{"cell_type":"code","source":"# diagnosis distribution by age and total count by diagnosis\n\nfig = make_subplots(rows=1, cols=2)\nfig.add_trace(go.Box(y=df['Age'].where(df['class']=='Negative'), name=\"Negatives by Age\", boxpoints='all', boxmean='sd'),\n    row=1, col=1\n            )\n\nfig.add_trace(go.Box(y=df['Age'].where(df['class']=='Positive'), name=\"Positives by Age\", boxpoints='all', boxmean='sd'),\n              row=1, col=1\n             )\n\n\ny_list = [df['Age'].where(df['class']=='Negative').agg('count'),\n          df['Age'].where(df['class']=='Positive').agg('count')]\nfig.add_trace(\n    go.Bar(y=y_list, x=['Negative', 'Positive'], name=\"Diagnosis Counts\",text=y_list, textposition='auto', \n           marker_color='rgb(158,202,225)', marker_line_color='rgb(8,48,107)',\n           marker_line_width=1.5, opacity=0.6),\n    row=1, col=2\n)\nfig.update_layout(height=600, width=1000, title_text=\"Diagnosis distribution by Age total count by Diagnosis\")\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Gender factor Analysis","metadata":{}},{"cell_type":"code","source":"fig = px.box(df, x='Gender', y='Age', color=\"class\", points=\"all\", width=800, height=600, color_discrete_sequence=['#F04B50','#2C85C1'])\nfig.update_layout(legend=dict(\n    title='Diagnosis:',\n    yanchor=\"top\",\n    y=0.98,\n    xanchor=\"right\",\n    x=0.98\n))\n\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fig = px.violin(df, x='Gender', y='Age', color=\"class\", points=\"all\", box=True, width=800, height=600, color_discrete_sequence=['#F04B50','#2C85C1'])\n# fig.update_layout(legend=dict(\n#     title='Diagnosis:',\n#     yanchor=\"top\",\n#     y=0.98,\n#     xanchor=\"right\",\n#     x=0.98\n# ))\n\n# fig.show()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset is fairly balanced between the overall positive and negative diagnosis, however there is an imbalance between female patients diagnosis that should not create any issue. We will use a stratified split to minimize any problem that may occur.","metadata":{}},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"## Encoding the categorical features\nTrees based algorithms are capable to handle categorical features, thus the label encoder is enough, there is no need of the one hot encoder","metadata":{}},{"cell_type":"code","source":"df1=df.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=df1.copy()\nle = LabelEncoder()\nfor i in df.columns[1:] :\n    df[i] = le.fit_transform(df[i])\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Ranking with Mutual Information\nBecause the target and the majority of the features are categorical (nominal variables), the heatmap of the correlation matrix it's not the right tool to rank the feaures ([source](https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/)).<br>\nWe're going to use mutual information (have a look to the [2nd lesson of the Kaggle Feature Engineering course](https://www.kaggle.com/ryanholbrook/mutual-information)).","metadata":{}},{"cell_type":"code","source":"X = df.copy()\ny = X.pop('class')\n\ndef plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    color = np.array([\"C0\"] * scores.shape[0])\n    # Create plot\n    plt.barh(width, scores, color=color)\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\")\n    \ndef make_mi_scores(X, y):\n    mi_scores = mutual_info_classif(X, y)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores\n\nmi_scores = make_mi_scores(X, y)\nmi_scores  # show a few features with their MI scores\nplt.figure(dpi=100, figsize=(8, 5))\nplot_mi_scores(mi_scores.head(20))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Split\nSplitting the data using the default train_test_split stratified split to assure that train and test set have the same distribution of the target variable","metadata":{}},{"cell_type":"code","source":"X = df.copy()\ny = X.pop('class')\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DecisionTreeClassifier\n\ndt = DecisionTreeClassifier(max_features=0.5,max_depth=15, random_state=1)\n\ndt.fit(X_train, y_train)\ndt_pred = dt.predict(X_test)\ndt_pred_proba = dt.predict_proba(X_test)\ndt_acc = accuracy_score(y_test, dt_pred)\nprint(dt_acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_test, dt_pred)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(4,4), hide_ticks=True, cmap=plt.cm.Blues)\nplt.title(\"Random Forest Model - Confusion Matrix\")\nplt.xticks(range(2), [\"No Diabetes\",\"Diabetes\"], fontsize=16)\nplt.yticks(range(2), [\"No Diabetes\",\"Diabetes\"], fontsize=16)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RandomForestClassifier\n\nrf = RandomForestClassifier(max_features=0.5,max_depth=15, random_state=1)\n# rf = RandomForestClassifier(max_features=0.5, max_depth=15, random_state=1)\nrf.fit(X_train, y_train)\nrf_pred = rf.predict(X_test)\nrf_pred_proba = rf.predict_proba(X_test)\nrf_acc = accuracy_score(y_test, rf_pred)\nprint(rf_acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_test, rf_pred)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(4,4), hide_ticks=True, cmap=plt.cm.Blues)\nplt.title(\"Random Forest Model - Confusion Matrix\")\nplt.xticks(range(2), [\"No Diabetes\",\"Diabetes\"], fontsize=16)\nplt.yticks(range(2), [\"No Diabetes\",\"Diabetes\"], fontsize=16)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb = XGBClassifier(eval_metric='logloss' ,use_label_encoder=False)\n\nxgb.fit(X_train, y_train)\nxgb_pred = xgb.predict(X_test)\nxgb_pred_proba = xgb.predict_proba(X_test)\nxgb_acc = accuracy_score(y_test, xgb_pred)\nprint(xgb_acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_test, xgb_pred)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(4,4), hide_ticks=True, cmap=plt.cm.Blues)\nplt.title(\"XGBoost Model - Confusion Matrix\")\nplt.xticks(range(2), [\"No Diabetes\",\"Diabetes\"], fontsize=16)\nplt.yticks(range(2), [\"No Diabetes\",\"Diabetes\"], fontsize=16)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ROC CURVES\n\"ROC curves describe the trade-off between the true positive rate (TPR) and false positive (FPR) rate along different probability thresholds for a classifier. True positive rate is also known as recall and sometimes Sensitivity — it’s a measure of how well you can find the needle in a haystack.\" [(source)](https://medium.com/cascade-bio-blog/making-sense-of-real-world-data-roc-curves-and-when-to-use-them-90a17e6d1db)","metadata":{}},{"cell_type":"code","source":"plt.figure(0).clf()\nplt.figure(dpi=150)\nfpr, tpr, thresh = roc_curve(y_test, dt_pred_proba[:,1])\nroc_auc = roc_auc_score(y_test, dt_pred_proba[:,1])\nplt.plot(fpr,tpr,label=\"Decision Tree, auc= %.4f\"% roc_auc)\n\nfpr, tpr, thresh = roc_curve(y_test, rf_pred_proba[:,1])\nroc_auc = roc_auc_score(y_test, rf_pred_proba[:,1])\nplt.plot(fpr,tpr,label=\"Random Forest, auc= %.4f\"% roc_auc)\n\nfpr, tpr, thresh = roc_curve(y_test, xgb_pred_proba[:,1])\nroc_auc = roc_auc_score(y_test, xgb_pred_proba[:,1])\nplt.plot(fpr,tpr,label=\"XGBoost, auc= %.4f\"% roc_auc)\n\nplt.title('ROC Curves Classifiers Comparison')\nplt.xlabel('False Positive Rate (1-Specificity)')\nplt.ylabel('True Positive Rate (Recall)')\nplt.legend(loc=0)\nplt.grid(True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PR Curves\n\"Precision-Recall curves describe the relationship between true TPR and the precision or positive predictive value (PPV), which is the ratio of your true positives to all positives. In other words, it helps you understand how many fake needles you will discover on your way to finding all the real ones.\" [(source)](https://medium.com/cascade-bio-blog/making-sense-of-real-world-data-roc-curves-and-when-to-use-them-90a17e6d1db)","metadata":{}},{"cell_type":"code","source":"plt.figure(0).clf()\nplt.figure(dpi=150)\nprecision, recall, thresholds = precision_recall_curve(y_test, dt_pred_proba[:,1])\navg_precision = average_precision_score(y_test, dt_pred_proba[:,1])\npr_auc = auc(recall, precision)\nplt.plot(recall, precision, label=f'Decision Tree, AP={avg_precision:.3f}; AUC={pr_auc:.3f}')\n\nprecision, recall, thresholds = precision_recall_curve(y_test, rf_pred_proba[:,1])\navg_precision = average_precision_score(y_test, rf_pred_proba[:,1])\npr_auc = auc(recall, precision)\nplt.plot(recall, precision, label=f'Random Forest, AP={avg_precision:.3f}; AUC={pr_auc:.3f}')\n\nprecision, recall, thresholds = precision_recall_curve(y_test, xgb_pred_proba[:,1])\navg_precision = average_precision_score(y_test, xgb_pred_proba[:,1])\npr_auc = auc(recall, precision)\nplt.plot(recall, precision, label=f'XGBoost, AP={avg_precision:.3f}; AUC={pr_auc:.3f}')\n\nplt.title('PR Curves Classifiers Comparison')\nplt.xlabel('Recall (TPR)')\nplt.ylabel('Precision')\nplt.legend(loc=0)\nplt.grid(True)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]}]}