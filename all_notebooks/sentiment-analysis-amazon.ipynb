{"cells":[{"metadata":{"trusted":true,"_uuid":"88f03ea42eb3607b04773d9e1701a8342146ecd7","collapsed":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndf=pd.read_csv('../input/Amazon_Unlocked_Mobile.csv')\n\ndf=df.sample(frac=0.1,random_state=10)\ndf.head()","execution_count":24,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b397c8351d876b3904a103e676d4fbcfc3274434","collapsed":true},"cell_type":"code","source":"df.shape","execution_count":25,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"314d69e63ae349d4b64dceef7ac6fccecf310bb3","collapsed":true},"cell_type":"code","source":"#Droping missing values\ndf.dropna(inplace=True)\n\n\n#Removing any neutral rating =3\ndf=df[df['Rating']!=3]\n\n#encode 4 an 5 as 1\n#1 and 2 as 0\ndf['Positively Rated']=np.where(df['Rating']>3,1,0)\ndf.head()","execution_count":26,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0108c3e3a450c48edcfa4d373b5343aff195053","collapsed":true},"cell_type":"code","source":"df['Positively Rated'].mean()","execution_count":27,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"cd739a33f9f45f6195da5cce766cbd79466eeac8"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n#spliting data into training and test \nX_train,X_test,y_train,y_test=train_test_split(df['Reviews'],df['Positively Rated'],random_state=0)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c48fb3c01c886dcc056a5bbd6cf475e74b43d1c6","collapsed":true},"cell_type":"code","source":"X_train.iloc[0]","execution_count":29,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99863cc7a402faf1079899fc20de0790ee6ce013","collapsed":true},"cell_type":"code","source":"X_train.shape","execution_count":30,"outputs":[]},{"metadata":{"_uuid":"769f7e74d12e0cd29aea8165356b7b580c31d118"},"cell_type":"markdown","source":"looking at extreme we have a series over 23052 reviews or documents we need to convert this into numerical representation with sklearn, the bag of words approch is simple and commonly used way to represent text for use in machine learning it ignores sructure and only counts how often each word occurs "},{"metadata":{"_uuid":"5f2a8b2c0b283d063167fd334cdc0d00088abaae"},"cell_type":"markdown","source":"# count vectorizer\ncourt vectorizer allows us to use bag of words approch by converting collection of text documents in to a matrix of token counts \n\nFirst we initiate the count vectorizer and fit it to our training data. Fitting the count vectorizer consists of the tokens of the training data and building of the vocabulary \n\nFitting the count vectorizer tokenizes each document by finding all sequences of characters that is numbers or letters seperated by word boundaries converts every thing to lower case and builds a vocabulary using these tokens "},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"816a3eeccd22af90e06c587daccc0c8dc8c19ec9"},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\nvect=CountVectorizer().fit(X_train)","execution_count":31,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a2843a8ef9d9718c5342dc7e32507e12908c219","collapsed":true},"cell_type":"code","source":"vect.get_feature_names()[::2000]","execution_count":32,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"70c156b139b3949ba734464d5749953cf5e630b7","collapsed":true},"cell_type":"code","source":"len(vect.get_feature_names())","execution_count":33,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11078d3b1e5743c91d2223dc8205b1868ec0221d","collapsed":true},"cell_type":"code","source":"X_train_vectorized = vect.transform(X_train)\n\nX_train_vectorized","execution_count":34,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1330438f87bb1408a8adc0ad7d4335aa27fb7e02","collapsed":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nmodel=LogisticRegression()\nmodel.fit(X_train_vectorized,y_train)","execution_count":35,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e0af3425537ecde464ba8d9c5062a54a4d1ebdf","collapsed":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\npredictions=model.predict(vect.transform(X_test))\nprint('AUC:',roc_auc_score(y_test,predictions))","execution_count":36,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b33f2353c15f4ede340864e7d304ca9655951136","collapsed":true},"cell_type":"code","source":"# get the feature names as numpy array\nfeature_names = np.array(vect.get_feature_names())\n\n# Sort the coefficients from the model\nsorted_coef_index = model.coef_[0].argsort()\n\n# Find the 10 smallest and 10 largest coefficients\n# The 10 largest coefficients are being indexed using [:-11:-1] \n# so the list returned is in order of largest to smallest\nprint('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\nprint('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))","execution_count":37,"outputs":[]},{"metadata":{"_uuid":"edd07b6513a3e2414f69302147377204ad2c90d4"},"cell_type":"markdown","source":"\n# tfidf(term frequency inverse document frequency(allows us to rescale features)\n \ntfidf allows us to weight terms how imp they are to the document\nhigh weight are given to the terms that apper to the document but dont appear often in a corpus \nfeatures with low tfidf are come in use in all documents "},{"metadata":{"trusted":true,"_uuid":"9f0a077c48a6f84fe81b47ac384a85985f79a039","collapsed":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 5\nvect = TfidfVectorizer(min_df=5).fit(X_train)\nlen(vect.get_feature_names())","execution_count":38,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d99612785b276c47c676f9a582de9af1c6ed4d2f","collapsed":true},"cell_type":"code","source":"X_train_vectorized = vect.transform(X_train)\n\nmodel = LogisticRegression()\nmodel.fit(X_train_vectorized, y_train)\n\npredictions = model.predict(vect.transform(X_test))\n\nprint('AUC: ', roc_auc_score(y_test, predictions))","execution_count":39,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dfdb40f2b26235af180ba4d9c70f905ea614f92f","collapsed":true},"cell_type":"code","source":"#features with smallest and largest tfidf\nfeature_names = np.array(vect.get_feature_names())\n\nsorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\n\nprint('Smallest tfidf:\\n{}\\n'.format(feature_names[sorted_tfidf_index[:10]]))\nprint('Largest tfidf: \\n{}'.format(feature_names[sorted_tfidf_index[:-11:-1]]))","execution_count":40,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e25cf8a96775ce7a2a4a53882cf761e280377518","collapsed":true},"cell_type":"code","source":"sorted_coef_index = model.coef_[0].argsort()\n\nprint('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\nprint('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))","execution_count":41,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ade56a62f4c8836f8e830c2ae0d1ac5bba76f23","collapsed":true},"cell_type":"code","source":"# These reviews are treated the same by our current model\nprint(model.predict(vect.transform(['not an issue, phone is working',\n                                    'an issue, phone is not working'])))","execution_count":42,"outputs":[]},{"metadata":{"_uuid":"fa06110a83bc0ebb40ca4508814a6d45a8305567"},"cell_type":"markdown","source":"# NGRAM\n"},{"metadata":{"trusted":true,"_uuid":"9b7047fe2b5c2d2ffdb647905296b9628a29071e","collapsed":true},"cell_type":"code","source":"# Fit the CountVectorizer to the training data specifiying a minimum \n# document frequency of 5 and extracting 1-grams and 2-grams\nvect = CountVectorizer(min_df=5, ngram_range=(1,2)).fit(X_train)\n\nX_train_vectorized = vect.transform(X_train)\n\nlen(vect.get_feature_names())","execution_count":43,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"55a21ef12831fc7224aedcfe186b01411bfe9f2c","collapsed":true},"cell_type":"code","source":"model = LogisticRegression()\nmodel.fit(X_train_vectorized, y_train)\n\npredictions = model.predict(vect.transform(X_test))\n\nprint('AUC: ', roc_auc_score(y_test, predictions))","execution_count":44,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f8219546af6786392402350b7f323d483da7c20","collapsed":true},"cell_type":"code","source":"feature_names = np.array(vect.get_feature_names())\n\nsorted_coef_index = model.coef_[0].argsort()\n\nprint('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\nprint('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))","execution_count":45,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"ce7d2b66d33d5c020ee18b97a58f27bd2ab35315"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2eae5983a84822275d442df70fa82ea229358b20"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}