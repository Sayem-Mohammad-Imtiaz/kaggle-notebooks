{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fake News Detection\n\nFake news denotes a type of yellow press which intentionally presents misinformation or hoaxes spreading through both traditional print news media and recent online social media. In recent years, due to the booming developments of online social networks, fake news for various commercial and political purposes has been appearing in large numbers and widespread in the online world. With deceptive words, online social network users can get infected by these online fake news easily, which has brought about tremendous effects on the offline society already.\n\nSo, it is important to detect fake and real news.\n\n","metadata":{}},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport pandas as pd\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom collections import Counter\nfrom nltk.tokenize import word_tokenize\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading data\n\nWe have a csv file named news in which there is a column named label which has two values REAL and FAKE for real news and fake news. This dataset has a shape of 6335Ã—4.","metadata":{}},{"cell_type":"code","source":"news=pd.read_csv('../input/fake-news-predict-data/fake_or_real_news.csv')\nnews.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Counting the number of REAL and FAKE values\nCounter(news['label'])    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting data \n\nSplitting the data into training and testing data.","metadata":{}},{"cell_type":"code","source":"\nx_train,x_test,y_train,y_test=train_test_split(news['text'],news['label'],test_size=0.2)\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### TfidfVectorizer\nThe TfidfVectorizer converts a collection of raw documents into a matrix of TF-IDF features.\n##### TF (Term Frequency): \nThe number of times a word appears in a document is its Term Frequency. A higher value means a term appears more often than others, and so, the document is a good match when the term is part of the search terms.\n\n##### IDF (Inverse Document Frequency): \nWords that occur many times a document, but also occur many times in many others, may be irrelevant. IDF is a measure of how significant a term is in the entire corpus.","metadata":{}},{"cell_type":"code","source":"tfidf=TfidfVectorizer(stop_words='english',max_df=0.8)\nx_train=tfidf.fit_transform(x_train)\nx_test=tfidf.transform(x_test)\nprint(x_test.shape)\nprint(x_train.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fitting the model\nWe have to build a model to accurately classify a piece of news as REAL or FAKE.\n\nWe have used six models PassiveAggressiveClassifier, GaussianNB, DecisionTreeClassifier, RandomForestClassifier, SVC, LogisticRegression so as to compare the accuracy of these models. It will help us to find which model fits the data and predict real and fake news accurately.","metadata":{}},{"cell_type":"code","source":"model1=PassiveAggressiveClassifier(max_iter=300)\nmodel1.fit(x_train,y_train)\nmodel2=GaussianNB()\nmodel2.fit(x_train.toarray(),y_train)\nmodel3=DecisionTreeClassifier()\nmodel3.fit(x_train,y_train)\nmodel4=RandomForestClassifier()\nmodel4.fit(x_train,y_train)\nmodel5=SVC()\nmodel5.fit(x_train,y_train)\nmodel6=LogisticRegression()\nmodel6.fit(x_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction for testing data\n\nWe are predicting for testing data with all models. ","metadata":{}},{"cell_type":"code","source":"y_pred1=model1.predict(x_test)\ny_pred2=model2.predict(x_test.toarray())\ny_pred3=model3.predict(x_test)\ny_pred4=model4.predict(x_test)\ny_pred5=model5.predict(x_test)\ny_pred6=model6.predict(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculating accuracy score\nacc1=accuracy_score(y_test,y_pred1)\nacc2=accuracy_score(y_test,y_pred2)\nacc3=accuracy_score(y_test,y_pred3)\nacc4=accuracy_score(y_test,y_pred4)\nacc5=accuracy_score(y_test,y_pred5)\nacc6=accuracy_score(y_test,y_pred6)\n\nlabels={'PassiveAggressiveClassifier':acc1,'GaussianNB':acc2,'DecisionTreeClassifier':acc3,'RandomForestClassifier':acc4,\n        'SVC':acc5,'LogisticRegression':acc6}\nfor model,accuracy in labels.items():\n    print(str(model)+' : '+str(accuracy))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"PassiveAggressiveClassifier gives the highest accuracy score.","metadata":{}},{"cell_type":"markdown","source":"### Data Visualization","metadata":{}},{"cell_type":"code","source":"fig, (ax1,ax2)=plt.subplots(1,2,figsize=(15,8))\nfig.suptitle('Characters in News Title',fontsize=20)\nnews_len=news[news['label']=='REAL']['title'].str.len()\nax1.hist(news_len,color='orange',linewidth=2,edgecolor='black')\nax1.set_title('REAL news',fontsize=15)\nnews_len=news[news['label']=='FAKE']['title'].str.len()\nax2.hist(news_len,linewidth=2,edgecolor='black')\nax2.set_title('Fake news',fontsize=15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1,ax2)=plt.subplots(1,2,figsize=(15,8))\nfig.suptitle('Characters in News Text',fontsize=20)\nnews_len=news[news['label']=='REAL']['text'].str.len()\nax1.hist(news_len,color='orange',linewidth=2,edgecolor='black')\nax1.set_title('REAL news',fontsize=15)\nnews_len=news[news['label']=='FAKE']['text'].str.len()\nax2.hist(news_len,linewidth=2,edgecolor='black')\nax2.set_title('Fake news',fontsize=15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,8))\nplt.title('Comparing Accuracy of ML Models',fontsize=20)\ncolors=['red','yellow','orange','green','magenta','cyan']\nplt.xticks(fontsize=10,color='blue')\nplt.yticks(fontsize=20,color='blue')\nplt.ylabel('Accuracy',fontsize=20)\nplt.xlabel('Models',fontsize=20)\nplt.bar(labels.keys(),labels.values(),edgecolor='black',color=colors, linewidth=2,alpha=0.5)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Calculating confusion matrix to gain insight into the number of false and true negatives and positives.","metadata":{}},{"cell_type":"code","source":"cm1=confusion_matrix(y_test,y_pred1)\ncm2=confusion_matrix(y_test,y_pred2)\ncm3=confusion_matrix(y_test,y_pred3)\ncm4=confusion_matrix(y_test,y_pred4)\ncm5=confusion_matrix(y_test,y_pred5)\ncm6=confusion_matrix(y_test,y_pred6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Confusion Matrix for PassiveAggressiveClassifier')\ncm1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Confusion Matrix for PassiveAggressiveClassifier')\nplot_confusion_matrix(conf_mat=cm1,show_absolute=True,\n                                show_normed=True,\n                                colorbar=True,class_names=['FAKE','REAL'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Confusion Matrix for GaussianNB')\ncm2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Confusion Matrix for GaussianNB')\nplot_confusion_matrix(conf_mat=cm2,show_absolute=True,\n                                show_normed=True,\n                                colorbar=True,class_names=['FAKE','REAL'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Confusion Matrix for DecisionTreeClassifier')\ncm3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Confusion Matrix for DecisionTreeClassifier')\nplot_confusion_matrix(conf_mat=cm3,show_absolute=True,\n                                show_normed=True,\n                                colorbar=True,class_names=['FAKE','REAL'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Confusion Matrix for RandomForestClassifier')\ncm4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Confusion Matrix for RandomForestClassifier')\nplot_confusion_matrix(conf_mat=cm4,show_absolute=True,\n                                show_normed=True,\n                                colorbar=True,class_names=['FAKE','REAL'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Confusion Matrix for SVC')\ncm5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Confusion Matrix for SVC')\nplot_confusion_matrix(conf_mat=cm5,show_absolute=True,\n                                show_normed=True,\n                                colorbar=True,class_names=['FAKE','REAL'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Confusion Matrix for LogisticRegression')\ncm6","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Confusion Matrix for LogisticRegression')\nplot_confusion_matrix(conf_mat=cm6,show_absolute=True,\n                                show_normed=True,\n                                colorbar=True,class_names=['FAKE','REAL'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}