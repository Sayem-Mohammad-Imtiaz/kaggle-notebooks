{"cells":[{"metadata":{"_uuid":"1152b104-4840-4b63-b7cc-01748c6e7d19","_cell_guid":"8ce2ff89-a873-428c-9b18-4805846787ac","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as pyplot\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6722eb1f-bf9f-4766-8ede-e27c9dc4ea0f","_cell_guid":"b3d1fb1e-20d8-4f52-8b72-ce91db181ed7","trusted":true},"cell_type":"code","source":"#Read data from csv file\ndata = pd.read_csv('../input/mushroom-classification/mushrooms.csv')\ndata.head(4)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ef202aa-91a3-401b-91e1-3d8f628e4da6","_cell_guid":"575a0ede-8cc2-4dd2-93ac-de11cff38590","trusted":true},"cell_type":"code","source":"#Basic stats\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4fb4c0bd-b00f-46d4-bd56-76786e69f032","_cell_guid":"f127125a-5e0b-4563-83bf-da84ee57fbe3","trusted":true},"cell_type":"code","source":"#Lets try to see which input variable has the greatest impact on response variable \n\n#First, I found chi2 values for each variable, to see which ones are most dependant. \nchi2vals = []\nn = len(data[data['class'] == 'e'].index)\nfor var in data.columns.values:\n    groups = data[var].value_counts().axes[0]\n    chi2 = 0\n    for group in groups:\n        expected = n / (len(groups))\n        actual = len(data[(data[var] == group) & (data['class'] == 'e')].index)\n        \n        chi2 += ((actual - expected)**2)/expected\n    chi2vals.append(chi2)\n\ncols = data.columns.values\npd.DataFrame(list(zip(cols, chi2vals)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee371d6d-17b4-4e9f-9d50-b67ba475da3e","_cell_guid":"3abdc62d-e19a-4d45-80e8-d7a4eaa74c6c","trusted":true},"cell_type":"code","source":"#From those results, odor has by far the highest chi2 value, so its likely the most determining variable\n#Other variables that seem highly dependant are stalk color above and below ring, and veil color\n#Lets how the distribution of mushrooms looks when split by odor.\n\nbars_edible = []\nbars_poisonous = []\nwidth = 0.3\n\npyplot.figure(figsize=(10,6), dpi = 100)\n\nfor odor in data['odor'].value_counts().axes[0]:\n    bars_edible.append(len(data[(data['odor'] == odor) & (data['class'] == 'e')].index))\n    bars_poisonous.append(len(data[(data['odor'] == odor) & (data['class'] == 'p')].index))\n    \nlabels = data['odor'].value_counts().axes[0]    \n    \npyplot.bar(np.arange(len(bars_edible)), bars_edible, width=width)\npyplot.bar(np.arange(len(bars_poisonous))+ width, bars_poisonous, width=width)\npyplot.xticks(range(len(labels)), labels)\npyplot.xlabel('Odor')\npyplot.ylabel('Count')\n\n\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0761c15f-802d-40ec-8d6e-83e78bcb3334","_cell_guid":"a1e15665-ee1f-489b-862d-f5908e79f378","trusted":true},"cell_type":"code","source":"#From the graph above, it seems like in almost all cases, edibility is can be determined solely by odor.\n#However, in the case of no odor, while almost all mushrooms are edible, there is still a small chance of getting a poisonous one. \n\n#Finally, I will try to generate a decision tree based on the data to decide the class of a mushroom. \n#This tree is certainly not very reliable, since converting unorderable categorical data to numberical data can and will create strange results\n#However, it might be somewhat useful...\n#To prevent the tree from being too specific to this particular dataset (overfit) I set the max depth allowed to 5\n\n\nfrom sklearn.preprocessing import LabelEncoder\n\nencoder = LabelEncoder()\nfor col in data.columns:\n    data[col] = encoder.fit_transform(data[col])\n\nX=data.drop(['class'], axis=1)\nY=data['class']\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\nimport graphviz\n\nX_train, X_test,Y_train,Y_test = train_test_split(X,Y, test_size = 0.1)\n\ntree = DecisionTreeClassifier(max_depth = 5)\ntree.fit(X_train, Y_train)\ndot_data = export_graphviz(tree, out_file=None, feature_names=X.columns)  \ngraph = graphviz.Source(dot_data)  \ngraph","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fdeef678-d3cf-462d-bc28-1b5a11ab80e0","_cell_guid":"681267d3-371b-4f31-be65-81ce4392024c","trusted":true},"cell_type":"code","source":"#In conclusion, it seems like Odor is the most dependant variable to determine if a mushroom is poisonous, and most odors can tell you exactly whether or not a mushroom is poisonous. \n#Other variables that seem highly dependant are stalk color above and below ring, and veil color.\n#By converting our data to numerical, we can create a somewhat-reliable decision tree to find if a mushroom is poisonous or not. \n#However, the conversion from categrical to numerical data does mean that the tree is far from perfect, and some of the splits make little or no sense.","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}