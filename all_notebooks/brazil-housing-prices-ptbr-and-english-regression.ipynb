{"cells":[{"metadata":{},"cell_type":"markdown","source":"O objetivo principal deste notebook é realizar uma regressão multipla para verificar o preço total em R$ de um imóvel.\nIrei escrever baseado no que já conheço, nos notebooks que vejo aqui e ir melhorando com o tempo. Irei adicionar comentários\nIrei adicionar comentários em portugues e ingles\n\nThe main objective of this notebook is to perform a multiple regression to check the total price in R $ of a property.\nI will write based on what I already know, on the notebooks I see here and get better with time. I will add comments\nI will add comments in Portuguese and English"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import linear_model\nfrom sklearn.preprocessing import StandardScaler\nscale = StandardScaler()\n\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ndf = pd.read_csv('/kaggle/input/brasilian-houses-to-rent/houses_to_rent_v2.csv')\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Análise Exploratória de Dados / Explodaroty Data Analisys - EDA "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visão geral dos dados / General view od data\ndf.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Os valores únicos da coluna cidade / Unique values from city colum\ndf.city.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Os tipos de dados (Dtype) são diferentes, transformar depois.\n> The data types (Dtype) are different, transform it later."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cidades mais populares / Most popular cities\ndf.groupby(['city'])['city'].aggregate(lambda x: x.count()/ 10692).plot(kind='pie',autopct='%.2f',fontsize=13);\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Nota-se que a maioria dos dados concentra-se em São Paulo o que favorece a análise.\n> Note that most data is concentrated in São Paulo, which favors the analysis. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Valor médio das casas por cidade /  Average Total value by city\ndf.groupby(['city'])['total (R$)'].aggregate(lambda x: x.mean()).plot(kind='bar',color=['blue','orange','green','red','purple']\\\n    , label='Average R$', title='Average R$ in a city', fontsize=15);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1,2, figsize=(14,5))\n\nsns.countplot(x='city', hue='animal', data=df, palette=sns.color_palette(), ax=axes[0]);\nsns.countplot(x='city', hue='furniture', data=df, palette='Set1', ax=axes[1]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> A maioria das casas aceitam animais e não possuem móveis.\n> Most houses accept animals and have no furniture."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df, hue = \"city\", corner = True, height=2.5, kind = 'reg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Pode-se notar a relação entre as variáveis, que não se parece tão linear. Isto será mais evidente no final da análise.\n> One can notice the relationship between the variables, which does not seem so linear. This will be most evident at the end of the analysis."},{"metadata":{},"cell_type":"markdown","source":"## Correlação / Correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"correlacao = df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mapa de calor da correlaçao / Heatmap fo Correlation\nplt.figure(figsize=(8, 7))\nsns.heatmap(correlacao, cmap=\"Oranges\", center=0, annot=True,vmin=-1, vmax=1,linewidth=1, linecolor='w', square=True,mask= np.triu(correlacao));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Devido a alta correlação entre fire insurance e rent amount (0.99), irei retirar a fire insurance para evitar multicolinearidade"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.scatter(x ='fire insurance (R$)', y = 'rent amount (R$)', data = df, s = 100, alpha = 0.3, edgecolor = 'white');\nplt.title('fire insurance  rent amounttal', fontsize = 16);\nplt.ylabel('fire insurance (R$)', fontsize = 12);\nplt.xlabel('rent amount (R$)', fontsize = 12);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Aqui pode-se ver a alta correlação linear entre as duas variáveis selecionadas;\n> Here you can see the high linear correlation between the two selected variables."},{"metadata":{},"cell_type":"markdown","source":"## Tratamento de Dados / Data Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Como alguns dados deveriam ser do tipo inteiro (int64), mas aparecem como objeto, irei verificar quais são e transformar em inteiros\n# As some data should be of the integer type (int64), but appear as an object, I will check who they are and transform them into integers\nfor i in df.select_dtypes('object'):\n    print(i,df[i].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> o sinal '-' em \"floor\" \n> the sign '-' in \"floor\""},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vou considerar o valor ' - ' como indicando uma casa e não apartamento para facilitar as análises e transformar em Inteiro\n# I will consider the value '-' as indicating a house and not an apartment to facilitate analysis and transform it into Integer\n\ndf['floor'] = df['floor'].apply(lambda x: -1 if x == '-' else x).astype(int)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transformando dados categoricos em dummys\n# turning categorical data into dummys\ndummy_city = pd.get_dummies(df.city, prefix='city')\ndummy_animal = pd.get_dummies(df.animal, prefix='animal',drop_first = True) \ndummy_furniture = pd.get_dummies(df.furniture, prefix='furniture',drop_first = True)\n\nprint(dummy_furniture.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# concatenando dummys/ concatenate dummys\ndf = pd.concat([df,dummy_city], axis=1)\ndf = pd.concat([df,dummy_animal], axis=1)\ndf = pd.concat([df,dummy_furniture], axis=1)\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"correlacao_02 = df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Nova correlação com os dados transformados\n# New correlation with transformed data\nplt.figure(figsize=(15, 12))\nsns.heatmap(correlacao_02, cmap=\"coolwarm\", center=0, annot=True,vmin=-1, vmax=1,linewidth=1, linecolor='w', square=True,mask= np.triu(correlacao_02));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Não mudou muita coisa e algumas variáveis deram pequena correlação negativa;\n> Not much has changed and some variables gave a small negative correlation."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decidi usar apenas as casas de São Paulo pois usando todas as cidades obtive mais erros;\n# I decided to use only the houses in São Paulo because using all the cities I got more errors;\n\ndf_Sao_Paulo = df.loc[df['city'] == 'São Paulo']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Valores / Values\n\n\n# Variável Dependente / Dependent Variable \nX_var = df_Sao_Paulo[['hoa (R$)','rent amount (R$)','property tax (R$)']]\n\n# Variável Independente / Independent Variable \ny_var = df_Sao_Paulo['total (R$)']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dividindo em Treino e Teste\n# Splitting the dataset into the Training set and Test set\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_var, y_var, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Usando regressor\n# Fitting Multiple Linear Regression to the Training set\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predizendo com r2 score / Predicting with r2 score\ny_pred = regressor.predict(X_test)\n\nfrom sklearn.metrics import r2_score\nscore=r2_score(y_test,y_pred)\nscore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Coeficientes \nregressor.coef_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Intercept\nregressor.intercept_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Testando com o primeiro valor do Data Frame"},{"metadata":{"trusted":true},"cell_type":"code","source":"valor_teste = df_Sao_Paulo.loc[0][12]\nvalor_teste","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf_Sao_Paulo.loc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predizendo um valor, inserir:\n'''  \n\nX_var = df_Sao_Paulo[['hoa (R$)','rent amount (R$)','property tax (R$)']]\n\n'''\npredicted = regressor.predict([[2065,3300,211]])\n\nprint(\"O valor predito era pra ser {:03d} R$ e foi {:03d} R$.\".format(valor_teste,int(predicted)))\n\ndiferenca = predicted - valor_teste\n\nprint(\"com uma diferença de {:02d} R$.\".format(int(diferenca)))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Pouca diferença...\n> Little difference ..."},{"metadata":{},"cell_type":"markdown","source":"## OLS Regression Results"},{"metadata":{},"cell_type":"markdown","source":"O OLS permite uma visão mais detalhada da regressão permitindo uma melhor análise e ajuste\n\nThe OLS allows a more detailed view of the regression allowing for better analysis and adjustment"},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm \nfrom termcolor import colored as cl # para mudar fonte do terminal e deixar em negrito\n\nslr_model = sm.OLS(y_var, X_var) # Ordinary Least Squares \nslr_reg = slr_model.fit()\n\n# sumario\nprint(cl(slr_reg.summary(),attrs = ['bold']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* R-squared (uncentered): 1.000    \n    * Deve estar proximo de 1\n* F-statistic(significance of the regression): 1.773e+09\n    * Deve estar proximo de 0\n* AIC(It is calculated as number of parameters minus the likelihood of the overall model): 4.427e+04\n    * Deve ser o menor possível\n* Omnibus(normal distribuition of errors): 11494.474\n    * Deve estar proximo de 1\n* Durbin-Watson(homoscedasticity , constant variance of erros): 2.000\n    * Deve estar entre 1 e 2\n*  Jarque-Bera (JB)(distribution analysis of the regression errors): 70846183.405\n    * Quanto maior, indica que os erros não estão distribuidos normalmente"},{"metadata":{},"cell_type":"markdown","source":"**In English**"},{"metadata":{},"cell_type":"markdown","source":"* R-squared (uncentered): 1,000\n     * Must be close to 1\n* F-statistic (significance of the regression): 1,773e + 09\n     * Must be close to 0\n* AIC (It is calculated as number of parameters minus the likelihood of the overall model): 4.427e + 04\n     * Must be as small as possible\n* Omnibus (normal distribution of errors): 11494.474\n     * Must be close to 1\n* Durbin-Watson (homoscedasticity, constant variance of errors): 2,000\n     * Must be between 1 and 2\n* Jarque-Bera (JB) (distribution analysis of the regression errors): 70846183.405\n     * The larger, indicates that errors are not normally distributed"},{"metadata":{},"cell_type":"markdown","source":"## Considerações finais /  Final considerations"},{"metadata":{},"cell_type":"markdown","source":"O modelo ainda está muito impreciso, segundo os dados da OLS. Irei testar outros algoritmos como Àrvores de Decisão, Redes Neurais e outros. Qualquer ajuda é bem vinda.\n\nThe model is still very inaccurate, according to OLS data. I will test other algorithms like Decision Trees, Neural Networks and others. Every help is welcome."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}