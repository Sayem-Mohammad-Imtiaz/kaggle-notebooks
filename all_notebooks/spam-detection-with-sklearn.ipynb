{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this Tutorial, we will try to analyse the **SMS SPAM COLLECTION DATASET** (a pre-labelled Spam/Not-Spam message dataset). We will be building a model to classify the messages, so lets see how well our model would perform.\n\nThis exercise is a Text mining exerise. Text mining is usually is process in which we try to analyse a set of Text to find meaningful information. This is achieved by attempting to automatically identify themes, patterns and keywords which could lead to the discovery of helpful information instead of having to go through the dataset manually.\n\n# Let's build a Spam Detection Model\n\n1. **Load the Data**\n\nWe will remove every other column and leave only columns we will be working with *\"V1\" & \"V2\"*\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport warnings; warnings.simplefilter('ignore')\n\ndataset= pd.read_csv('../input/sms-spam-collection-dataset/spam.csv',encoding='ISO-8859-1')\nto_drop=['Unnamed: 2','Unnamed: 3','Unnamed: 4']\ndataset.drop(columns=to_drop,inplace=True)\n\ndataset.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we use Label Encoding, and since we have only tow possiblities in the Label Column (Ham, Spam); Our resulting encoded label would hold(0,1)."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['encoded_labels']=dataset['v1'].map({'spam':0,'ham':1})\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. **Split Dataset and extract Features**\n\nWe can see that our Dataset is composed of sentences. We need to extract the features in these sentences. In this example, we achieve this by using the Count Vectorizer which generates a Vector holding the frequency values for words in the sentence."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split as split_data\n\nlabels=dataset.pop('encoded_labels')\n\ntrain_data,test_data,train_label,test_label=split_data(dataset,labels, test_size=0.3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\nc_v = CountVectorizer(decode_error='ignore')\ntrain_data = c_v.fit_transform(train_data['v2'])\ntest_data = c_v.transform(test_data['v2'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. **Build Classifier & Evaluate Accuracy**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import naive_bayes as nb\nfrom sklearn.metrics import accuracy_score\n\n\n\nclf=nb.MultinomialNB()\nmodel=clf.fit(train_data, train_label)\npredicted_label=model.predict(test_data)\nprint(\"train score:\", clf.score(train_data, train_label))\nprint(\"test score:\", clf.score(test_data, test_label))\nprint(\"Classifier Accuracy\",accuracy_score(test_label, predicted_label))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}