{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import random\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, label_ranking_average_precision_score, label_ranking_loss, coverage_error \nfrom sklearn.utils import shuffle\nfrom scipy.signal import resample\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, IterableDataset, DataLoader\nfrom torch import autograd\nfrom torch.autograd import Variable\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/heartbeat/mitbih_train.csv\", header = None)\ntest_df = pd.read_csv(\"../input/heartbeat/mitbih_test.csv\", header = None)\n\ndf = pd.concat([train_df, test_df], axis=0)\ndf.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[187].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_array = df.values\ninputs = data_array[:, :-1]\nlabels = data_array[:, -1].astype(int)\n\nprint(data_array.shape)\n\ndel train_df\ndel test_df\ndel data_array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c0 = np.argwhere(labels == 0).flatten()\nc1 = np.argwhere(labels == 1).flatten()\nc2 = np.argwhere(labels == 2).flatten()\nc3 = np.argwhere(labels == 3).flatten()\nc4 = np.argwhere(labels == 4).flatten()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.arange(0, 187)*8/1000\nplt.figure(figsize=(20,12))\nplt.plot(x, inputs[c0, :][0], label=\"Cat. N\")\nplt.plot(x, inputs[c1, :][0], label=\"Cat. S\")\nplt.plot(x, inputs[c2, :][0], label=\"Cat. V\")\nplt.plot(x, inputs[c3, :][0], label=\"Cat. F\")\nplt.plot(x, inputs[c4, :][0], label=\"Cat. Q\")\nplt.legend()\nplt.title(\"1-beat ECG for every category\", fontsize=20)\nplt.ylabel(\"Amplitude\", fontsize=15)\nplt.xlabel(\"Time (ms)\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def stretch(x):\n    l = int(187 * (1 + (random.random()-0.5)/3))\n    y = resample(x, l)\n    if l < 187:\n        y_ = np.zeros(shape=(187, ))\n        y_[:l] = y\n    else:\n        y_ = y[:187]\n    return y_\n\ndef amplify(x):\n    alpha = (random.random()-0.5)\n    factor = -alpha*x + (1+alpha)\n    return x*factor\n\ndef augment(x):\n    result = np.zeros(shape= (4, 187))\n    for i in range(3):\n        if random.random() < 0.33:\n            new_y = stretch(x)\n        elif random.random() < 0.66:\n            new_y = amplify(x)\n        else:\n            new_y = stretch(x)\n            new_y = amplify(new_y)\n        result[i, :] = new_y\n    return result\n\nplt.plot(inputs[10000,:])\n\nresult = np.apply_along_axis(augment, axis=1, arr=inputs[c3]).reshape(-1, 187)\nc = np.ones(shape=(result.shape[0],), dtype=int)*3\ninputs = np.vstack([inputs, result])\nlabels = np.hstack([labels, c])\nprint(inputs.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subC0 = np.random.choice(c0, 900)\nsubC1 = np.random.choice(c1, 900)\nsubC2 = np.random.choice(c2, 900)\nsubC3 = np.random.choice(c3, 900)\nsubC4 = np.random.choice(c4, 900)\n\n\n\n\nx_test = np.vstack([inputs[subC0], inputs[subC1], inputs[subC2], inputs[subC3], inputs[subC4]]).reshape(-1,1,187)\ny_test = np.hstack([labels[subC0], labels[subC1], labels[subC2], labels[subC3], labels[subC4]])\n\nx_train = np.delete(inputs, [subC0, subC1, subC2, subC3, subC4], axis=0).reshape(-1,1,187)\ny_train = np.delete(labels, [subC0, subC1, subC2, subC3, subC4], axis=0)\n\nx_train, y_train = shuffle(x_train, y_train, random_state=0)\nx_test, y_test = shuffle(x_test, y_test, random_state=0)\n\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)\n\ndel inputs\ndel labels\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = x_train.shape[0]\n\n#train val split\ndef train_val_split(x,y,n,split_ratio,seed):\n    np.random.seed(100)\n    n_val = int(split_ratio*n)\n\n    idxs = np.random.permutation(n)\n    train_idxs, val_idxs = idxs[n_val:], idxs[:n_val]\n    \n    return x[train_idxs],y[train_idxs],x[val_idxs],y[val_idxs]\nx_train,y_train,x_val,y_val = train_val_split(x_train,y_train,n,0.2,343543)\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_val.shape)\nprint(y_val.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MyDataset(IterableDataset):\n    def __init__(self,data):\n        self.data = data\n    def __iter__(self):\n        return iter(self.data)\n\ntrain_inputs = torch.from_numpy(x_train)\ntrain_targets = torch.from_numpy(y_train)\ntrain_ds = TensorDataset(train_inputs,train_targets)\n# train_iter = MyDataset(train_ds)\ntrain_loader = DataLoader(train_ds,batch_size=64,shuffle=True)\n\nval_inputs = torch.from_numpy(x_val)\nval_targets = torch.from_numpy(y_val)\nval_ds = TensorDataset(val_inputs,val_targets)\n# train_iter = MyDataset(train_ds)\nval_loader = DataLoader(val_ds,batch_size=64,shuffle=True)\n\ntest_inputs = torch.from_numpy(x_test)\ntest_targets = torch.from_numpy(y_test)\ntest_ds = TensorDataset(test_inputs,test_targets)\n# test_iter = MyDataset(x_test)\ntest_loader = DataLoader(test_ds,batch_size=64,shuffle=True)\n\nfor xbatch,ybatch in train_loader:\n    print(xbatch)\n    print(ybatch)\n    break\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Resnet Block\nclass ResNet(nn.Module):\n    def __init__(self, module_1, module_2):\n        super(ResNet, self).__init__()\n        self.module_1 = module_1\n        self.module_2 = module_2\n        self.shortcut = nn.Identity() \n    def forward(self, inputs):\n        return self.module_2(self.shortcut(self.module_1(inputs)) + self.shortcut(inputs))\n          \nclass Network(nn.Module):\n    def __init__(self):\n        super(Network, self).__init__()\n        self.model = nn.Sequential(\n          nn.Conv1d(1,32,kernel_size=5,stride=1,padding=2),\n          # 5 Residual blocks\n          ResNet(\n              nn.Sequential(\n                  nn.Conv1d(32,32,kernel_size=5,stride=1,padding=2),\n                  nn.ReLU(),\n                  nn.Conv1d(32,32,kernel_size=5,stride=1,padding=2),\n              ),\n              nn.Sequential(\n                  nn.ReLU(),\n                  nn.MaxPool1d(5,stride=2)\n              )\n          ),\n          ResNet(\n              nn.Sequential(\n                  nn.Conv1d(32,32,kernel_size=5,stride=1,padding=2),\n                  nn.ReLU(),\n                  nn.Conv1d(32,32,kernel_size=5,stride=1,padding=2),\n              ),\n              nn.Sequential(\n                  nn.ReLU(),\n                  nn.MaxPool1d(5,stride=2)\n              )\n          ),\n          ResNet(\n              nn.Sequential(\n                  nn.Conv1d(32,32,kernel_size=5,stride=1,padding=2),\n                  nn.ReLU(),\n                  nn.Conv1d(32,32,kernel_size=5,stride=1,padding=2),\n              ),\n              nn.Sequential(\n                  nn.ReLU(),\n                  nn.MaxPool1d(5,stride=2)\n              )\n          ),\n          ResNet(\n              nn.Sequential(\n                  nn.Conv1d(32,32,kernel_size=5,stride=1,padding=2),\n                  nn.ReLU(),\n                  nn.Conv1d(32,32,kernel_size=5,stride=1,padding=2),\n              ),\n              nn.Sequential(\n                  nn.ReLU(),\n                  nn.MaxPool1d(5,stride=2)\n              )\n          ),\n          ResNet(\n              nn.Sequential(\n                  nn.Conv1d(32,32,kernel_size=5,stride=1,padding=2),\n                  nn.ReLU(),\n                  nn.Conv1d(32,32,kernel_size=5,stride=1,padding=2),\n              ),\n              nn.Sequential(\n                  nn.ReLU(),\n                  nn.MaxPool1d(5,stride=2)\n              )\n          ),\n          nn.Flatten(),\n            \n          nn.Linear(in_features=64,out_features=32),\n          nn.ReLU(),\n          nn.Linear(in_features=32,out_features=5)\n      )\n    \n    def forward(self, x):\n#           x = x.view(x.size(0), 784)\n#           c = self.label_emb(labels)\n#           x = torch.cat([x, c], 1)\n          out = self.model(x)\n            \n          return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = nn.Sequential(\n          nn.Conv1d(1,32,kernel_size=5,stride=1,padding=2),\n#           nn.ReLU(),\n          # 5 Residual blocks\n          ResNet(\n              nn.Sequential(\n                  nn.Conv1d(32,32,kernel_size=5,stride=1,padding=2),\n                  nn.ReLU(),\n                  nn.Conv1d(32,32,kernel_size=5,stride=1,padding=2),\n              ),\n              nn.Sequential(\n                  nn.ReLU(),\n                  nn.MaxPool1d(5,stride=2)\n              )\n          ),\n          ResNet(\n              nn.Sequential(\n                  nn.Conv1d(32,32,kernel_size=5,stride=1,padding=2),\n                  nn.ReLU(),\n                  nn.Conv1d(32,32,kernel_size=5,stride=1,padding=2),\n              ),\n              nn.Sequential(\n                  nn.ReLU(),\n                  nn.MaxPool1d(5,stride=2)\n              )\n          ),\n          ResNet(\n              nn.Sequential(\n                  nn.Conv1d(32,32,kernel_size=5,stride=1,padding=2),\n                  nn.ReLU(),\n                  nn.Conv1d(32,32,kernel_size=5,stride=1,padding=2),\n              ),\n              nn.Sequential(\n                  nn.ReLU(),\n                  nn.MaxPool1d(5,stride=2)\n              )\n          ),\n          ResNet(\n              nn.Sequential(\n                  nn.Conv1d(32,32,kernel_size=5,stride=1,padding=2),\n                  nn.ReLU(),\n                  nn.Conv1d(32,32,kernel_size=5,stride=1,padding=2),\n              ),\n              nn.Sequential(\n                  nn.ReLU(),\n                  nn.MaxPool1d(5,stride=2)\n              )\n          ),\n          ResNet(\n              nn.Sequential(\n                  nn.Conv1d(32,32,kernel_size=5,stride=1,padding=2),\n                  nn.ReLU(),\n                  nn.Conv1d(32,32,kernel_size=5,stride=1,padding=2),\n              ),\n              nn.Sequential(\n                  nn.ReLU(),\n                  nn.MaxPool1d(5,stride=2)\n              )\n          ),\n          nn.Flatten(),\n          nn.Linear(in_features=64,out_features=32),\n          nn.ReLU(),\n          nn.Linear(in_features=32,out_features=32),\n          nn.Linear(in_features=32,out_features=5)\n      ).to('cuda')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model[1].weight","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# network = Network().to('cuda')\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr=0.001,betas=(0.9,0.999))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_epoch_loss = []\nval_accuracy = []\n\n\ndef train(num_epochs, model, loss_fn, optimizer):\n    for epoch in range(num_epochs):\n        train_step = 0\n        avg_loss = 0.0\n        correct = 0.0\n        total = 0\n        #training\n        model.train()\n        for xb,yb in train_loader:  \n            xb,yb = xb.to('cuda').float(), yb.to('cuda')\n            preds = model(xb)\n            preds_act = torch.nn.functional.softmax(preds,dim=1)\n            _,y_pred = torch.max(preds_act,1)\n            loss = loss_fn(preds,yb)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            train_step += 1\n            avg_loss += loss.item()\n            \n            total += yb.size(0)\n            correct += (y_pred == yb).sum().item()\n            \n        train_epoch_loss.append(avg_loss / train_step)\n        print('Epoch [{}/{}]'.format(epoch+1,num_epochs))\n        print('Avg Train Loss : {}'.format(avg_loss / train_step))\n        print('Train Accuracy : {}'.format(100 *correct / total))\n        \n        #Evaluation\n        correct = 0.0\n        val_step = 0\n        total = 0\n        model.eval()\n        for xb,yb in val_loader:\n            xb,yb = xb.to('cuda').float(), yb.to('cuda')\n            preds = model(xb) \n            _,y_pred = torch.max(preds,1)\n            correct += (y_pred == yb).sum().item()\n            val_step += 1\n            total += yb.size(0)\n        val_accuracy.append(correct / total)\n        print('Validation Accuracy : {}'.format(correct / total))\n            \n            \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(5,model,loss_fn,optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train_epoch_loss)\nplt.xlabel('Epoch')\nplt.ylabel('Loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(val_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct = 0.0\ntotal = 0\noriginal_output = []\npredicted_output = []\nmodel.eval()\nlast_conv_output = []\nlast_conv_pool_output = []\neachlayer_output = []\nfor xb,yb in test_loader:\n    xb,yb = xb.to('cuda').float(), yb.to('cuda')\n#     preds = model(xb)\n    n = 5\n    for i,l in enumerate(model.children()):\n        xb = l(xb)\n        eachlayer_output.append(xb)\n        if(i == n):\n            last_conv_pool_output.append(xb.view(xb.shape[0],-1))\n            n = n + 11\n    preds = eachlayer_output[-1]\n    preds = torch.nn.functional.softmax(preds,dim=1)\n    print(preds.shape)\n    _,y_pred = torch.max(preds,1)\n    print(y_pred.shape)\n    correct += (y_pred == yb).sum().item()\n    total += yb.size(0)\n    y_pred = y_pred.cpu()\n    predicted_output.append(y_pred.numpy())\n    yb = yb.cpu()\n    original_output.append(yb.numpy())\nval_accuracy.append(correct / total)\nprint('Test Accuracy : {}'.format(correct / total))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(last_conv_pool_output)):\n    print(last_conv_pool_output[i])\ntsne_input = torch.cat(last_conv_pool_output,dim=0)\nprint(tsne_input.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tsnecuda import TSNE\nX_embedded = TSNE(n_components=2, perplexity=15, learning_rate=10).fit_transform(tsne_input)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = [11,12,13]\n\nfor i,ele in enumerate(x):\n    print(i)\n    print(ele)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for l in model.modules():\n    print(l)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_output = np.concatenate(predicted_output,axis=0)\noriginal_output = np.concatenate(original_output,axis=0)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nprint(classification_report(original_output,predicted_output))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Greys):\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(original_output,predicted_output)\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplt.figure(figsize=(10, 10))\nplot_confusion_matrix(cnf_matrix, classes=['N', 'S', 'V', 'F', 'Q'],normalize=True,\n                      title='Confusion matrix, without normalization')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ptbdb_normal = pd.read_csv('../input/heartbeat/ptbdb_normal.csv', header=None)\ndf_ptbdb_abnormal = pd.read_csv('../input/heartbeat/ptbdb_abnormal.csv', header=None)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_ptbdb_normal.info())\nprint(df_ptbdb_abnormal.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ptbdb = pd.concat([df_ptbdb_normal, df_ptbdb_abnormal], axis=0)\ndf_ptbdb.info()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = df_ptbdb.values[:, :-1]\nlabels = df_ptbdb.values[:, -1].astype(int)\n\nprint(inputs.shape)\nprint(labels.shape)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c0 = np.argwhere(labels == 0).flatten()\nc1 = np.argwhere(labels == 1).flatten()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.arange(0, 187)*8/1000\nplt.figure(figsize=(20,12))\nplt.plot(x, inputs[c0, :][0], label=\"Cat. Normal\")\nplt.plot(x, inputs[c1, :][0], label=\"Cat. Abnormal\")\nplt.legend()\nplt.title(\"1-beat ECG for every category\", fontsize=20)\nplt.ylabel(\"Amplitude\", fontsize=15)\nplt.xlabel(\"Time (ms)\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,y_train,x_test,y_test = train_val_split(inputs,labels,inputs.shape[0],0.1,100)\n\nx_train,y_train,x_val,y_val = train_val_split(x_train,y_train,x_train.shape[0],0.2,100)\n\n\nprint(x_train.shape)\nprint(y_train.shape)\n\nprint(x_val.shape)\nprint(y_val.shape)\n\nprint(x_test.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}