{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Problem Statement**\n\nA US bike-sharing provider BoomBikes has recently suffered considerable dips in their revenues due to the ongoing Corona pandemic. The company is finding it very difficult to sustain in the current market scenario. So, it has decided to come up with a mindful business plan to be able to accelerate its revenue as soon as the ongoing lockdown comes to an end, and the economy restores to a healthy state. \n\nYou are required to model the demand for shared bikes with the available independent variables. It will be used by the management to understand how exactly the demands vary with different features. They can accordingly manipulate the business strategy to meet the demand levels and meet the customer's expectations. Further, the model will be a good way for management to understand the demand dynamics of a new market. \n\n","metadata":{}},{"cell_type":"markdown","source":"## Step 1: Reading and Understanding the Data","metadata":{}},{"cell_type":"code","source":"# Supress Warnings\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Reading CSV data\nbike= pd.read_csv(\"../input/boombikes/day.csv\")\nbike.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Inspecting the data frame","metadata":{}},{"cell_type":"code","source":"bike.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike.describe() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dropping the unwanted columns in the data frame\n\n","metadata":{}},{"cell_type":"markdown","source":"instant-it's just index and it will be of no use for building model\n","metadata":{}},{"cell_type":"markdown","source":"dteday-yr is already present as boolean and day of week is present as categorical variable,so this becomes unwanted or extra colmun\n","metadata":{}},{"cell_type":"markdown","source":"casual,registered-it is directly related to cnt the target variable\n","metadata":{}},{"cell_type":"markdown","source":"atemp-it is just feel temperature and we have already orginal temperature so this becomes an extra feature \n\nso by all these reasons above variables can be dropped from the dropped","metadata":{}},{"cell_type":"code","source":"#Drooping unwanted columns from Data frame\nbike.drop(['instant','casual','registered','dteday','atemp'],axis=1,inplace=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike.head(150)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 2: Visualizing the Data ","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Pairplot for numerical variables\nsns.pairplot(bike,vars=['cnt','temp','windspeed','hum','weathersit','weekday','season'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can observere there is some positive correlation between temp(temperature) and cnt (Total number of bikes rented)","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,10))\nplt.subplot(1,3,1)\nsns.boxplot(x = 'holiday', y = 'cnt', data = bike)\nplt.subplot(1,3,2)\nsns.boxplot(x = 'workingday', y = 'cnt', data = bike)\nplt.subplot(1,3,3)\nsns.boxplot(x = 'yr', y = 'cnt', data = bike)\nplt.show()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can observe in 2019 the number of cnt has increased a lot compared to 2018","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (10, 5))\nsns.boxplot(x = 'yr', y = 'cnt', hue = 'holiday', data = bike)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10, 5))\nsns.boxplot(x = 'season', y = 'cnt', hue = 'weathersit', data = bike)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (15,10))\nsns.boxplot(x = 'yr', y = 'cnt', hue = 'mnth', data = bike)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Heat map for the variables\nplt.figure(figsize=(15,10))\nsns.heatmap(bike.corr(),annot=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step3:Data Preparation","metadata":{}},{"cell_type":"markdown","source":"### Dummy Variables\n","metadata":{}},{"cell_type":"code","source":"# Get the dummy variables for the feature 'Season' and store it in a new variable - 'seas'\nbike['season']=bike['season'].astype(object)\nseas = pd.get_dummies(bike['season'],drop_first=True)\nseas.head(350)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, you don't need three columns. You can drop the spring column(1st column), as the type of season can be identified with just the last three columns where ","metadata":{}},{"cell_type":"markdown","source":"000- spring season\n\n100- summer season\n\n010- fall season\n\n001- winter season","metadata":{}},{"cell_type":"code","source":"#Changing the names columns so that it can be understood easily\nseas = seas.rename(columns={1:'spring', 2:'summer', 3:'fall', 4:'winter'})\nseas.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add the results to the original housing dataframe\n\nbike = pd.concat([bike, seas], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike.head(300)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop 'season' as we have created the dummies for it\nbike.drop(['season'], axis = 1, inplace = True)\n\nbike.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the dummy variables for the feature 'weekday' and store it in a new variable - 'wday'\nbike['weekday']=bike['weekday'].astype(object)\nwday = pd.get_dummies(bike['weekday'],drop_first=True)\nwday.head(150)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Changing the names columns so that it can be understood easily\n\nwday = wday.rename(columns={0:'sun',1:'mon', 2:'tue', 3:'wed', 4:'thu',5:'fri',6:'sat'})\nwday.head(350)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, you don't need seven columns and we dropped  the sun(0 column) column, as the day can be identified with just the last six columns where","metadata":{}},{"cell_type":"markdown","source":"100000-mon\n\n010000-tue\n\n001000-wed\n\n000100-thu\n\n000010-fri\n\n000001-sat\n\n000000-sun","metadata":{}},{"cell_type":"code","source":"#lets concat this data frame to original data frame\nbike = pd.concat([bike, wday], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop 'weekday' as we have created the dummies for it\nbike.drop(['weekday'], axis = 1, inplace = True)\n\nbike.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the dummy variables for the feature 'mnth' and store it in a new variable - 'month'\nbike['mnth']=bike['mnth'].astype(object)\nmonth = pd.get_dummies(bike['mnth'],drop_first=True)\nmonth.head(150)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Changing the names columns so that it can be understood easily\n\nmonth = month.rename(columns={1:'jan', 2:'feb', 3:'mar',4:'apr',5:'may',6:'jun',7:'jul',8:'aug',9:'sep',10:'oct',11:'nov',12:'dec'})\nmonth.head(350)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, you don't need twelve columns. You can drop the jan(1st) column, as the month can be identified with just the last eleven columns where\n\n10000000000-feb\n\n01000000000-mar\n\n00100000000-apr\n\n00010000000-may\n\n00001000000-jun\n\n00000100000-jul\n\n00000010000-aug\n\n00000001000-sep\n\n00000000100-oct\n\n00000000010-nov\n\n00000000001-dec\n\n00000000000-jan","metadata":{}},{"cell_type":"code","source":"#lets concat this data frame to original data frame\nbike = pd.concat([bike, month], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike.head(200)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop 'mnth' as we have created the dummies for it\nbike.drop(['mnth'], axis = 1, inplace = True)\n\nbike.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the dummy variables for the feature 'weathersit' and store it in a new variable - 'wsit'\nbike['weathersit']=bike['weathersit'].astype(object)\nwsit = pd.get_dummies(bike['weathersit'],drop_first=True)\nwsit.head(150)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Changing the names columns so that it can be understood easily\n\nwsit = wsit.rename(columns={1:'clear', 2:'mist+cloudy', 3:'lightsnow',4:'heavyrain'})\nwsit.head(350)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, you don't need three columns. You can drop the 'clear'(1 cloumn) column, as the 'weathersit' can be identified with just the last two columns where\n\n00-clear\n\n10-mist+cloudy\n\n01-lightsnow\n\n","metadata":{}},{"cell_type":"code","source":"#lets concat this data frame to original data frame\n\nbike = pd.concat([bike, wsit], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop 'weathersit' as we have created the dummies for it\nbike.drop(['weathersit'], axis = 1, inplace = True)\n\nbike.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('max_columns',300)\nbike.shape","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting the Data into Training and Testing Sets","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# We specify this so that the train and test data set always have the same rows, respectively\n\nbike_train, bike_test = train_test_split(bike, train_size = 0.7, test_size = 0.3, random_state = 100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Rescaling the Features \n","metadata":{}},{"cell_type":"code","source":"#MinMaxScaling\n\nfrom sklearn.preprocessing import MinMaxScaler","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = MinMaxScaler()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply scaler() to all the columns except the 'yes-no' and 'dummy' variables\nnum_vars = ['temp', 'hum', 'windspeed','cnt']\n\nbike_train[num_vars] = scaler.fit_transform(bike_train[num_vars])\n\nbike_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dividing into X and Y sets for the model building","metadata":{}},{"cell_type":"code","source":"y_train = bike_train.pop('cnt')\nX_train = bike_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building our model","metadata":{}},{"cell_type":"markdown","source":"#### RFE","metadata":{}},{"cell_type":"code","source":"# Importing RFE and LinearRegression\n\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Running RFE with the output number of the variable equal to 10\nlm = LinearRegression()\nlm.fit(X_train, y_train)\n\nrfe = RFE(lm, 15)             # running RFE\nrfe = rfe.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col = X_train.columns[rfe.support_]\ncol","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.columns[~rfe.support_]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building model using statsmodel, for the detailed statistics","metadata":{}},{"cell_type":"code","source":"# Creating X_test dataframe with RFE selected variables\nX_train_rfe = X_train[col]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding a constant variable \nimport statsmodels.api as sm  \nX_train_rfe = sm.add_constant(X_train_rfe)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm = sm.OLS(y_train,X_train_rfe).fit()   # Running the linear model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's see the summary of our linear model\nprint(lm.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"'fall' variable is insignificant so let's drop it ","metadata":{}},{"cell_type":"code","source":"X_train_new = X_train_rfe.drop([\"fall\"], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Rebuilding model without fall","metadata":{}},{"cell_type":"code","source":"# Adding a constant variable \nimport statsmodels.api as sm  \nX_train_lm = sm.add_constant(X_train_new)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm = sm.OLS(y_train,X_train_lm).fit()   # Running the linear model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's see the summary of our linear model\nprint(lm.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_new.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_new = X_train_new.drop(['const'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculate the VIFs for the new model\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nX = X_train_new\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#hum vif value is too high so the presence of the variable might be ineffective to model so let's drop it\nX_train_new1 = X_train_new.drop([\"hum\"], axis = 1)\nX_train_new1.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding a constant variable \nimport statsmodels.api as sm  \nX_train_lm = sm.add_constant(X_train_new1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm1 = sm.OLS(y_train,X_train_lm).fit() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(lm1.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculate the VIFs for the new model\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nX = X_train_new1\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#holiday has high p-value so it makes model insignificant so let's drop it\nX_train_new2 = X_train_new1.drop([\"holiday\"], axis = 1)\nX_train_new2.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding a constant variable \nimport statsmodels.api as sm  \nX_train_lm = sm.add_constant(X_train_new2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm2 = sm.OLS(y_train,X_train_lm).fit() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(lm2.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculate the VIFs for the new model\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nX = X_train_new2\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Drooping windspeed column as the temp is important to our model\nX_train_new3 = X_train_new2.drop([\"windspeed\"], axis = 1)\nX_train_new3.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding a constant variable \nimport statsmodels.api as sm  \nX_train_lm= sm.add_constant(X_train_new3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm3 = sm.OLS(y_train,X_train_lm).fit() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(lm3.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculate the VIFs for the new model\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nX = X_train_new3\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#workingday variable has high vif value and temp is very important to our business so we need to keep temp but have to reduce it so let's drop the workingday variable t\nX_train_new4 = X_train_new3.drop([\"workingday\"], axis = 1)\nX_train_new4.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding a constant variable \nimport statsmodels.api as sm  \nX_train_lm = sm.add_constant(X_train_new4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm4 = sm.OLS(y_train,X_train_lm).fit() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(lm4.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculate the VIFs for the new model\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nX = X_train_new4\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We need to drop 'sat' column as it is having high p-value hence it is insignificant\nX_train_new5 = X_train_new4.drop([\"oct\"], axis = 1)\nX_train_new5.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding a constant variable \nimport statsmodels.api as sm  \nX_train_lm = sm.add_constant(X_train_new5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm5 = sm.OLS(y_train,X_train_lm).fit() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(lm5.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculate the VIFs for the new model\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nX = X_train_new5\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We need to drop 'windspeed' column as it is having high p-value hence it is insignificant\nX_train_new6 = X_train_new5.drop([\"sat\"], axis = 1)\nX_train_new6.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding a constant variable \nimport statsmodels.api as sm  \nX_train_lm = sm.add_constant(X_train_new6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lm6 = sm.OLS(y_train,X_train_lm).fit() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(lm6.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculate the VIFs for the new model\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nX = X_train_new6\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Residual Analaysis","metadata":{}},{"cell_type":"code","source":"\ny_train_cnt = lm6.predict(X_train_lm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing the required libraries for plots.\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the histogram of the error terms\nfig = plt.figure()\nsns.distplot((y_train - y_train_cnt), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \nplt.xlabel('Errors', fontsize = 18)                         # X-label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The error graph is normal distributing with mean 0.0 ","metadata":{}},{"cell_type":"markdown","source":"## Making predictions","metadata":{}},{"cell_type":"code","source":"#Apply scaling on test sets\n\nnum_vars = ['temp', 'hum', 'windspeed','cnt']\n\nbike_test[num_vars] = scaler.fit_transform(bike_test[num_vars])\n\nbike_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test = bike_test.pop('cnt')\nX_test = bike_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now let's use our model to make predictions.\n\n# Creating X_test_new dataframe by dropping variables from X_test\nX_test_new = X_test[X_train_new6.columns]\n\n# Adding a constant variable \nX_test_new = sm.add_constant(X_test_new)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Making predictions\ny_cnt = lm6.predict(X_test_new)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking r-squared on test set\nr_squared = r2_score(y_test, y_cnt)\nr_squared","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Making Predictions","metadata":{}},{"cell_type":"code","source":"# Plotting y_test and y_pred to understand the spread.\nfig = plt.figure()\nplt.scatter(y_test,y_cnt)\nfig.suptitle('y_test vs y_cnt', fontsize=20)              # Plot heading \nplt.xlabel('y_test', fontsize=18)                          # X-label\nplt.ylabel('y_cnt', fontsize=16)                          # Y-label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### y=0.2316 * yr+0.5431 * temp+0.0972 * summer+0.1453 * winter+0.0601 * aug+0.1207 * sep-0.0793 * mist+cloudy-0.2931 * lightsnow+0.0645","metadata":{}},{"cell_type":"code","source":"#FinalModel\nprint(lm6.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" **Number of bikes\nrented increases from January to June**\n\n**in the 4 month (April) the number of bikes\nrented will rapidly increase compared to previous month,\nSo in April month there will be more demand for the\nbikes**\n\n**If weathersit is ‘heavy rain’(4 in dataset) we don’t have any\nbikes rented that day in all the seasons,If weather situation is light snow (3 in dataset) then we have\nvery less number of bikes rented in all seasons**\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}