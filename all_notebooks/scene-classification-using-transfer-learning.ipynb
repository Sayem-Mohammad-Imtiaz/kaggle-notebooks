{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Firstly, we will load the Dataset which have Image name and corresponding Labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"Dataset = pd.read_csv(\"/kaggle/input/scene-classification/train-scene classification/train.csv\")    # Dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting Class number to strings\nDataset[\"label\"] = Dataset[\"label\"].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displaying number of samples for each Disease\nfig, ax = plt.subplots(figsize = (10, 4))                                # Setting Figure Size\nsns.countplot(x ='label', data=Dataset)                                  # Creating Seaborn Count Plot\nplt.xlabel(\"Class Label\")                                                # X-Label of the plot\nplt.ylabel(\"Number of Samples\")                                          # Y-Label of the plot\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Data is almost balanced."},{"metadata":{},"cell_type":"markdown","source":"## Splitting Data into Train/Test"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Data_train, Data_test = train_test_split(Dataset, test_size=0.2)                   # Splitting in 80:20","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating Keras Image Data Flow"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(rescale=1./255)                            # Normalizing pixels of images","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating Training Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training Set Directory\ndir1='/kaggle/input/scene-classification/train-scene classification/train/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen=datagen.flow_from_dataframe(dataframe = Data_train,           # Training Dataframe\n                                      directory=dir1,                   # Training set Directory\n                                      batch_size=20,                    # Size of Batch\n                                      class_mode=\"categorical\",         # Type of Labels\n                                      x_col=\"image_name\",               # Input Column\n                                      color_mode=\"rgb\",                 # Image Format\n                                      y_col=\"label\",                    # Target Column\n                                      target_size=(224,224))            # Image Size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating Validation Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_gen=datagen.flow_from_dataframe(dataframe = Data_test,            # Training Dataframe\n                                      directory=dir1,                   # Training set Directory\n                                      batch_size=20,                    # Size of Batch\n                                      class_mode=\"categorical\",         # Type of Labels\n                                      x_col=\"image_name\",               # Input Column\n                                      color_mode=\"rgb\",                 # Image Format\n                                      y_col=\"label\",                    # Target Column\n                                      target_size=(224,224))            # Image Size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing Resnet Model to apply Transfer Learning"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ResNet_model = keras.applications.ResNet152V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Building Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import Model \nfrom keras.layers import Conv2D, Dense, MaxPooling2D, Dropout, Flatten,GlobalAveragePooling2D\nfrom keras.models import Sequential","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in ResNet_model.layers[:-15]:       # Freezing all layers other than last 15 Layers\n    layer.trainable = False\n\nx = ResNet_model.output\nx = GlobalAveragePooling2D()(x)\nx = Flatten()(x)\nx = Dense(units=512, activation='relu')(x)\nx = Dropout(0.3)(x)\nx = Dense(units=512, activation='relu')(x)\nx = Dropout(0.3)(x)\noutput  = Dense(units=6, activation='softmax')(x)\nmodel = Model(ResNet_model.input, output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model Summary\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Setting Loss function, Optimizer and Compling the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = keras.losses.CategoricalCrossentropy()\noptimizer = keras.optimizers.Adam(learning_rate=0.001)\nmodel.compile(optimizer=optimizer, loss=loss, metrics= ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compiling the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"STEP_SIZE_TRAIN=train_gen.n//train_gen.batch_size\nSTEP_SIZE_VALID=valid_gen.n//valid_gen.batch_size\n\nprint(STEP_SIZE_TRAIN)\nprint(STEP_SIZE_VALID)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transfer_learning_history = model.fit_generator(generator=train_gen,\n                            steps_per_epoch=STEP_SIZE_TRAIN,\n                            validation_data=valid_gen,\n                            validation_steps=STEP_SIZE_VALID,\n                            epochs=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualizing accuracy and loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nacc = transfer_learning_history.history['accuracy']\nval_acc = transfer_learning_history.history['val_accuracy']\n\nloss = transfer_learning_history.history['loss']\nval_loss = transfer_learning_history.history['val_loss']\n\nepochs_range = range(3)\n\nplt.figure(figsize=(20, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Since, we are using Pre-trained Moedl. The Model Convergers very fast.\n# This is the reason we are getting best results in only 2 epochs"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}