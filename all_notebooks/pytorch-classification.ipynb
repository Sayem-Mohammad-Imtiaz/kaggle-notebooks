{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport random\nfrom sklearn.model_selection import train_test_split\nimport cv2\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn  as nn\nimport torch.nn.functional  as F\nfrom torch.autograd import Variable\nimport torch.optim as optim\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms,utils","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = \"/kaggle/input/flower-recognition-he/he_challenge_data/data/train/\"\ndata_csv = \"/kaggle/input/flower-recognition-he/he_challenge_data/data/train.csv\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(data_csv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['category'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nfor i in range(16):\n    ind = random.randrange(0, 18500, 1)\n    sample_img = data_dir + str(train_data.iloc[ind][0]) + \".jpg\"\n    img = cv2.imread(sample_img)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.subplot(4,4,i+1)\n    plt.imshow(img)\n    plt.ylabel(str(train_data.iloc[ind][1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes_dist = train_data[\"category\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(classes_dist,bins=102);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class FlowerDataset(Dataset):\n    def __init__(self, data_csv, data_path, transform=None):\n        self.data_csv = pd.read_csv(data_csv)\n        self.data_path = data_path\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data_csv)\n    \n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        \n        img = cv2.imread(self.data_path + str(self.data_csv.iloc[idx][0]) + \".jpg\")\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = np.array(img).astype(\"float\")\n        lbl = self.data_csv.iloc[idx][1] -1\n        lbl = np.array(lbl) #.astype(\"float\")\n        sample = {'image': img, 'label': lbl}\n        \n        if(self.transform):\n            sample = self.transform(sample)\n            \n        return sample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"flower_data = FlowerDataset(data_csv, data_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(flower_data[10]['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Rescale(object):\n    def __init__(self, output_size):\n        assert isinstance(output_size, (int, tuple))\n        self.output_size = output_size\n        \n    def __call__(self, sample):\n        img, lbl = sample['image'], sample['label']\n        img = cv2.resize(img, self.output_size)\n        sample = {'image': img, 'label': lbl}        \n        return sample\n\nclass RandCrop(object):\n    def __init__(self, output_size):\n        assert isinstance(output_size, (int, tuple))\n        self.output_size = output_size\n    \n    def __call__(self, sample):\n        img, lbl = sample['image'], sample['label']\n        h,w = img.shape[:2]\n        new_h, new_w = self.output_size\n        top = np.random.randint(0,h - new_h)\n        left= np.random.randint(0,w - new_w)\n        \n        img = img[top:top+new_h, left:left+new_w]\n        \n        sample = {'image': img, 'label': lbl}\n        return sample\n    \nclass ToTensor(object):\n    def __call__(self, sample):\n        img, lbl = sample['image'], sample['label']\n        img = img.transpose(2,0,1)\n        \n        sample = {'image': torch.from_numpy(img), 'label': torch.from_numpy(lbl)}\n        return sample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scale = Rescale((110,110))\nrcrop = RandCrop((100,100))\ncomposed = transforms.Compose([scale,rcrop])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"samp = flower_data[20]\ntsfr_smp = composed(samp)\nplt.imshow(tsfr_smp['image'].astype(\"int\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"flower_data_transformed = FlowerDataset(data_csv, data_dir, transforms.Compose([Rescale((110,110)), RandCrop((100,100)), ToTensor()]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataloader = DataLoader(flower_data_transformed, batch_size=10, shuffle=True, num_workers=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Flower_Net(nn.Module):\n    def __init__(self):\n        super(Flower_Net, self).__init__()\n        self.conv1 = nn.Conv2d(3,6,3)\n        self.linear1 = nn.Linear(6*49*49, 1000)\n        self.linear2 = nn.Linear(1000, 500)\n        self.linear3 = nn.Linear(500, 102)\n        \n    def forward(self,x):\n#         print(x)\n        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n        x = x.view(-1, self.num_flat_features(x))\n        x = F.relu(self.linear1(x))\n        x = F.relu(self.linear2(x))\n        x = self.linear3(x)\n        return x\n        \n    def num_flat_features(self, x):\n        size = x.size()[1:]  # all dimensions except the batch dimension\n#         print(size)\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = Flower_Net()\nprint(net)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nnet.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = list(net.parameters())\nprint(len(params))\nprint(params[2].size()) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input = torch.randn(1, 3, 100, 100)\nout = net(input.to(device))\nprint(out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataiter = iter(train_dataloader)\nsample = dataiter.next()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imshow(utils.make_grid(sample['image']))\nprint(' '.join('%5s' % sample['label'][j] for j in range(10)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=1e-3,  momentum=0.9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Starting Training....\")\nfor epoch in range(10):\n    \n    running_loss=0.0\n    \n    for i, data in enumerate(train_dataloader, 0):\n        \n        inputs = data['image'].to(device, dtype=torch.float)\n        label = data['label'].to(device)\n        \n        optimizer.zero_grad()\n        \n        outputs = net(inputs)\n#         print(len(outputs))\n        loss = criterion(outputs, label)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        if i % 200 == 199: \n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / 200))\n            running_loss = 0.0\n\nprint('Finished Training')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testdataiter = iter(train_dataloader)\nsampletest = testdataiter.next()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = np.arange(0,102,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('GroundTruth: ', ' '.join('%5s' % classes[sampletest['label'][j]] for j in range(10)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outputs = net(sampletest['image'].float().to(device))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, predicted = torch.max(outputs, 1)\n\nprint('Predicted: ', ' '.join('%5s' % classes[ predicted[j]]\n                              for j in range(10)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in train_dataloader:\n        images = data['image'].to(device)\n        labels = data['label'].to(device)\n        outputs = net(images.float())\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 18000 train images: %d %%' % (\n    100 * correct / total))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_correct = list(0. for i in range(102))\nclass_total = list(0. for i in range(102))\nwith torch.no_grad():\n    for data in train_dataloader:\n        images = data['image'].to(device)\n        labels = data['label'].to(device)\n        outputs = net(images.float())\n        _, predicted = torch.max(outputs, 1)\n        c = (predicted == labels).squeeze()\n        for i in range(10):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\n\nfor i in range(102):\n    print('Accuracy of %5s : %2d %%' % (\n        classes[i], 100 * class_correct[i] / class_total[i]))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}