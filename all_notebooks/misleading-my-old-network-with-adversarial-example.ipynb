{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Introduction"},{"metadata":{},"cell_type":"markdown","source":"The purpose of this notebook is to create an adversarial example against my old simple Convolutionnal Neural Network which recognize hand gestures for sign language. We will mislead the network."},{"metadata":{},"cell_type":"markdown","source":"## 1.1. Imports and remake former network "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img,img_to_array\nfrom tensorflow.keras.layers import Input\nfrom matplotlib import pyplot as plt\nimport matplotlib.image as mpimg\nfrom tensorflow.python.keras import backend\n\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/sign-language-mnist/sign_mnist_train/sign_mnist_train.csv\")\nalphabet=['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\nadversarial = df_train.loc[0]\ndf_train.drop(0, inplace=True) #lets keep this one for the misleading\n\ny = df_train[\"label\"]\nX = df_train.drop(['label'], axis=1)\n\nX = np.array(X) / 255\ny = np.array(y)\n\nY = np.zeros((len(alphabet),df_train.shape[0]))\nfor i in range(len(y)):\n    Y[y[i],i] = 1\nX = X.reshape((-1, 28,28,1))\nY = Y.reshape((26,-1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential()\nmodel.add(tf.keras.layers.Input(shape=(28,28,1)))\nmodel.add(tf.keras.layers.Convolution2D(32, (3, 3), activation='relu',padding='same'))\nmodel.add(tf.keras.layers.Convolution2D(32, (3, 3), activation='relu',padding='same'))\nmodel.add(tf.keras.layers.MaxPooling2D((2,2), strides=None,padding='same'))\nmodel.add(tf.keras.layers.Dropout(0.2))\n\nmodel.add(tf.keras.layers.Convolution2D(64, (3, 3), activation='relu',padding='same'))\nmodel.add(tf.keras.layers.Convolution2D(64, (3, 3), activation='relu',padding='same'))\nmodel.add(tf.keras.layers.MaxPooling2D((2,2), strides=None,padding='same'))\nmodel.add(tf.keras.layers.Dropout(0.2))\n\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(556, activation='relu'))\nmodel.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.1))\nmodel.add(tf.keras.layers.Dense(26, activation='softmax', name=\"predictions\"))\n\nmodel.summary()\n\nmodel.compile(loss=\"sparse_categorical_crossentropy\",optimizer='adam',metrics=[\"accuracy\"])\n\n#history = model.fit(X,y,batch_size=64,epochs=3, validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Adversarial example"},{"metadata":{},"cell_type":"markdown","source":"Here is our example that will tear apart that network."},{"metadata":{"trusted":true},"cell_type":"code","source":"target_class = df_train.loc[26][0]\nimg_in = np.array(adversarial[1:])\n\nif not issubclass(img_in.dtype.type, np.floating):\n    img_in = img_in.astype(backend.floatx(), copy=False) #one day of not understanding why gradiant is 0\n\nplt.imshow(img_in.reshape(28,28,1).astype(int), cmap=\"gray\")\nplt.show()\nimg_in = tf.convert_to_tensor(img_in.reshape((1,28,28,1)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is a 'd', but we will make the network think it is a 'y', which looks totaly different."},{"metadata":{"trusted":true},"cell_type":"code","source":"ar = np.array(df_train.loc[26][1:]).reshape((28,28))\nplt.imshow(ar, cmap='gray')\nplt.title(alphabet[df_train.loc[26][0]])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to extract the last layer of the network as it does the classification work."},{"metadata":{"trusted":true},"cell_type":"code","source":"target_class = df_train.loc[26][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_layer = model.get_layer(\"predictions\").output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_backend = model.input\nadversarial_model = tf.keras.Model(inputs=img_backend, outputs=last_layer)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We must redefine the loss function for the adversarial model and also redefine the gradient step function, so that it calls the new adversarial loss, and so that it takes a new parameter target_class as an input. \nThis means that our new loss is actually <b>the guess of the network for the target class</b> as we will try to create an image that will make the highest loss possible."},{"metadata":{"trusted":true},"cell_type":"code","source":"def adversarial_loss(model_in,img_in,target_class):\n    activation = model_in(img_in) \n\n    total_loss = activation[0,target_class]\n    return total_loss\n\ndef adversarial_gradient_step(model_in, img_in, step_size,target_class):\n    with tf.GradientTape() as tape:\n        tape.watch(img_in)\n        loss = adversarial_loss(model_in,img_in,target_class)\n        grads = tape.gradient(loss,img_in)\n    grads = grads/(tf.math.reduce_std(grads)+1e-8)\n    img_in += grads * step_size\n    return img_in, loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"step = 0.5  # Gradient ascent step size\nn_iterations = 200  # Number of gradient ascent steps\ncounter = 0\nfor ii in range(0,n_iterations):\n    img_in, loss = adversarial_gradient_step(model,img_in,step,target_class)\n    if (ii%5==0):\n        y_predicted = model.predict(img_in)\n        print(alphabet[np.argmax(y_predicted)], np.amax(y_predicted))\n        if (np.argmax(y_predicted) == target_class) & (np.amax(y_predicted) >= 0.9):\n            counter += 1\n        else:\n            counter = 0\n    if counter >= 5:\n        break\n\nprint('End of optimisation')\nplt.imshow(img_in.numpy().reshape(28,28,1), cmap=\"gray\")\nplt.title(alphabet[np.argmax(model.predict(img_in))])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Remarks : "},{"metadata":{},"cell_type":"markdown","source":"* As this technique works, I can't achieve to make it work when I train the network. The gradient is way too small and I can't mislead the network.\n* Often, the gradient descent (which is more of an ascension) seems to get stuck and the network must be reset."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}