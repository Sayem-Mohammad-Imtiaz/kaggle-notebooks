{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import os\n\n# Time\nimport time\nimport datetime\n\n# Numerical\nimport numpy as np\nimport pandas as pd\n\n# Tools\nimport itertools\nfrom collections import Counter\n\n# NLP\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\n\n# Preprocessing\nfrom sklearn import preprocessing\nfrom sklearn.utils import class_weight as cw\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\n# Model Selection\nfrom sklearn.model_selection import train_test_split\n\n# Evaluation Metrics\nfrom sklearn import metrics \nfrom sklearn.metrics import f1_score, accuracy_score,confusion_matrix,classification_report\n\n# Deep Learing Preprocessing - Keras\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\nfrom keras.utils import to_categorical\n\n# Deep Learning Model - Keras\nfrom keras.models import Model\nfrom keras.models import Sequential\n\nfrom keras.layers import Dense, Embedding\nfrom keras.models import Sequential\n\n# Deep Learning Model - Keras - RNN\nfrom keras.layers import Embedding, LSTM, Bidirectional\n\n# Deep Learning Model - Keras - General\nfrom keras.layers import Input, Add, concatenate, Dense, Activation, BatchNormalization, Dropout, Flatten\nfrom keras.layers import LeakyReLU, PReLU, Lambda, Multiply\n\nfrom keras.preprocessing import sequence\nfrom keras import regularizers\n\n# Deep Learning Parameters - Keras\nfrom keras.optimizers import RMSprop, Adam\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom fastai.imports import *\nfrom fastai.text import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = Path(os.path.abspath(os.curdir))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#File Import\nfilepath = Path('../input')\ndf = pd.read_csv(filepath/'Tweets.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Transfer Learning\n#### Loading pre-trained language model and fine-tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[['airline_sentiment','text']]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = df[:int(len(df)*.99)]\nvalid = df[int(len(df)*.99):]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm_dat = TextLMDataBunch.from_df(path, train, valid)\nlm_dat.save('data_lm_export.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm_learn = language_model_learner(lm_dat, AWD_LSTM, drop_mult=0.4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm_learn.lr_find()\nlm_learn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm_learn.fit_one_cycle(4, 1e-2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm_learn.unfreeze()\nlm_learn.lr_find(); lm_learn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm_learn.fit_one_cycle(4, 1e-3)\n#Encoder\nlm_learn.save_encoder('ft_enc')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fine-tuning Classifier \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting the dataset in 80:20 ratio\ntrain = df[:int(len(df)*.80)]\nvalid = df[int(len(df)*.80):]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Classifier model data\ndata_clas = TextClasDataBunch.from_df(path, train, valid, vocab=lm_dat.train_ds.vocab, bs=32)\ndata_clas.save('data_clas_export.pkl') ; data_clas = load_data(path, 'data_clas_export.pkl', bs=16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Building a classifier with fine-tuned encoder \nlm_learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=.3, metrics=[accuracy,Precision(average='weighted'),Recall(average='weighted')])\nlm_learn.load_encoder('ft_enc')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_clas.show_batch()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm_learn.lr_find()\nlm_learn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm_learn.fit_one_cycle(4, 1e-2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm_learn.freeze_to(-2)\nlm_learn.fit_one_cycle(4, slice(1e-3/(2.6**4), 1e-3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#unfreezing the model and fine-tuning it\nlm_learn.unfreeze()\nlm_learn.fit_one_cycle(8, slice(1e-5/(2.6**4),1e-5))\nlm_learn.save('final')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Obtaining Test Accuracy\nvalid['pred_sentiment'] = valid['text'].apply(lambda row: str(lm_learn.predict(row)[0]))\nprint(\"Test Accuracy: \", accuracy_score(valid['airline_sentiment'], valid['pred_sentiment']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## References\n[1] “Application to NLP, including ULMFiT fine-tuning,” text | fastai. [Online]. Available: https://docs.fast.ai/text.html#Text-models,-data,-and-training. [Accessed: 24-Jul-2019].\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}