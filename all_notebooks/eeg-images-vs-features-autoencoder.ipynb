{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport random\nimport os\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.fftpack import fft, fftfreq, rfft, rfftfreq\nfrom sklearn.preprocessing import quantile_transform\nfrom sklearn.preprocessing import minmax_scale\nfrom sklearn.preprocessing import normalize\nfrom sklearn.preprocessing import scale\nfrom sklearn.preprocessing import robust_scale\nimport mne\nimport matplotlib \nfrom collections import defaultdict\nfrom math import cos, sin, acos, radians, pi\nfrom scipy.interpolate import griddata\nfrom numpy import newaxis\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\n\nprint(\"Starting...\")\nprint()\n#GPU check     )\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(\"Current device is:\", device, \". Please abort and turn on cuda, if not already activated.\")\nprint()\nprint(\"Importing data from file...\")\n\n\n#Random Seed\nseed = 123\nrandom.seed = seed\n\n#File Import\n      \nfilenames_list = os.listdir('/kaggle/input/Alcoholics/SMNI_CMI_TRAIN/Train/') ## list of file names in the directory\n\n\nEEG_data = pd.DataFrame({}) ## create an empty df that will hold data from each file\nEEG_data_control = pd.DataFrame({})\nnumber = 0\n\nfor file_name in filenames_list:\n    temp_df = pd.read_csv('/kaggle/input/Alcoholics/SMNI_CMI_TRAIN/Train/' + file_name, engine = 'c') ## read from the file to df\n    number += 1\n    \n    if 'a' in temp_df['subject identifier'].values:\n                    \n        EEG_data = EEG_data.append(temp_df) ## add the file data to the main df\n        \n        \n    if 'c' in temp_df['subject identifier'].values:\n                    \n        EEG_data_control = EEG_data_control.append(temp_df) ## add the file data to the main df\n\n\n\nEEG_data = EEG_data.drop(['Unnamed: 0'], axis=1) ## remove the unused column\nEEG_data.loc[EEG_data['matching condition'] == 'S2 nomatch,', 'matching condition'] =  'S2 nomatch' ## remove comma sign from stimulus name   \n\n## replace some 'sensor position' values\nEEG_data.loc[EEG_data['sensor position'] == 'AF1', 'sensor position'] = 'AF3'\nEEG_data.loc[EEG_data['sensor position'] == 'AF2', 'sensor position'] = 'AF4'\nEEG_data.loc[EEG_data['sensor position'] == 'PO1', 'sensor position'] = 'PO3'\nEEG_data.loc[EEG_data['sensor position'] == 'PO2', 'sensor position'] = 'PO4'\n\nEEG_data.loc[EEG_data['sensor position'] == 'FP1', 'sensor position'] = 'Fp1'\nEEG_data.loc[EEG_data['sensor position'] == 'FP2', 'sensor position'] = 'Fp2'\nEEG_data.loc[EEG_data['sensor position'] == 'CPZ', 'sensor position'] = 'CPz'\nEEG_data.loc[EEG_data['sensor position'] == 'FZ', 'sensor position'] = 'Fz'\n\nEEG_data.loc[EEG_data['sensor position'] == 'CZ', 'sensor position'] = 'Cz' ## exclusion of this position because it has a systematically extrem value\n\nEEG_data.loc[EEG_data['sensor position'] == 'PZ', 'sensor position'] = 'Pz'\nEEG_data.loc[EEG_data['sensor position'] == 'FPZ', 'sensor position'] = 'Fpz'\nEEG_data.loc[EEG_data['sensor position'] == 'AFZ', 'sensor position'] = 'AFz'\nEEG_data.loc[EEG_data['sensor position'] == 'FCZ', 'sensor position'] = 'FCz'\n\nEEG_data.loc[EEG_data['sensor position'] == 'POZ', 'sensor position'] = 'POz'\nEEG_data.loc[EEG_data['sensor position'] == 'OZ', 'sensor position'] = 'Oz'\n\n###same for control\n\nEEG_data_control = EEG_data_control.drop(['Unnamed: 0'], axis=1) ## remove the unused column\nEEG_data_control.loc[EEG_data_control['matching condition'] == 'S2 nomatch,', 'matching condition'] =  'S2 nomatch' ## remove comma sign from stimulus name    \n## replace some 'sensor position' values\nEEG_data_control.loc[EEG_data_control['sensor position'] == 'AF1', 'sensor position'] = 'AF3'\nEEG_data_control.loc[EEG_data_control['sensor position'] == 'AF2', 'sensor position'] = 'AF4'\nEEG_data_control.loc[EEG_data_control['sensor position'] == 'PO1', 'sensor position'] = 'PO3'\nEEG_data_control.loc[EEG_data_control['sensor position'] == 'PO2', 'sensor position'] = 'PO4'\n\nEEG_data_control.loc[EEG_data_control['sensor position'] == 'FP1', 'sensor position'] = 'Fp1'\nEEG_data_control.loc[EEG_data_control['sensor position'] == 'FP2', 'sensor position'] = 'Fp2'\nEEG_data_control.loc[EEG_data_control['sensor position'] == 'CPZ', 'sensor position'] = 'CPz'\nEEG_data_control.loc[EEG_data_control['sensor position'] == 'FZ', 'sensor position'] = 'Fz'\n\nEEG_data_control.loc[EEG_data_control['sensor position'] == 'CZ', 'sensor position'] = 'Cz' ## exclusion of this position because it has a systematically extrem value\n\nEEG_data_control.loc[EEG_data_control['sensor position'] == 'PZ', 'sensor position'] = 'Pz'\nEEG_data_control.loc[EEG_data_control['sensor position'] == 'FPZ', 'sensor position'] = 'Fpz'\nEEG_data_control.loc[EEG_data_control['sensor position'] == 'AFZ', 'sensor position'] = 'AFz'\nEEG_data_control.loc[EEG_data_control['sensor position'] == 'FCZ', 'sensor position'] = 'FCz'\n\nEEG_data_control.loc[EEG_data_control['sensor position'] == 'POZ', 'sensor position'] = 'POz'\nEEG_data_control.loc[EEG_data_control['sensor position'] == 'OZ', 'sensor position'] = 'Oz'\n\nprint()\nprint(\"Preprocessing data...\")\nprint()\n\n# build matrix 64 by 256 FOR each trial number\n\nAlc_base = EEG_data['trial number'].unique()\nCon_base = EEG_data_control['trial number'].unique()\n\n##Train Test split 33% \n\nlstp_Alc1 = int(round((len(Alc_base)/100)*33.33))\nlstp_Alc2 = int(round((len(Alc_base)/100)*66.66))\n\nAlc_train_extractor = Alc_base[:lstp_Alc1]\nAlc_train_classifier =Alc_base[lstp_Alc1:lstp_Alc2]\nAlc_test = Alc_base[lstp_Alc2:]\n\n\nlstp_Con1 = int(round((len(Con_base)/100)*33.33))\nlstp_Con2 = int(round((len(Con_base)/100)*66.66))\n\nCon_train_extractor = Con_base[:lstp_Con1]\nCon_train_classifier = Con_base[lstp_Con1:lstp_Con2]\nCon_test = Con_base[lstp_Con2:]\n\n\ndef trialfunction(input_data):\n    \n    trials_dic = {}\n    \n    dbc = 0\n    \n    if Alc_train_extractor.shape == Con_train_extractor.shape:\n        \n        print('Same shape error:')\n        print(X_train.shape)\n        print(y_train.shape)\n        raise SystemExit \n    \n    if (input_data.shape == Alc_train_extractor.shape) or (input_data.shape == Alc_train_classifier.shape) or (input_data.shape == Alc_test.shape):\n        dbc = EEG_data\n        \n        \n    if (input_data.shape == Con_train_extractor.shape) or (input_data.shape == Con_train_classifier.shape) or (input_data.shape == Con_test.shape):\n        dbc = EEG_data_control\n        \n    \n    for pos in input_data:               \n        \n        Trial = dbc.loc[dbc['trial number'] == pos]\n    \n        columns =['channel','time', 'sensor value']\n \n        Trial = Trial.pivot_table(index='channel', columns='time', values = 'sensor value')\n    \n        trials_dic[pos] = Trial\n\n\n\n    RGB_dic = {}\n    \n \n\n    for key in trials_dic:\n        data = trials_dic.get(key)\n\n        # Get real amplitudes of FFT (only in postive frequencies)\n\n        fft_raw = fft(data)\n\n        fft_vals = np.absolute(fft_raw)\n\n        fft_vals = normalize(fft_vals, axis=1)\n\n        # Get frequencies for amplitudes in Hz\n\n        fs = 256    # Sampling rate\n\n        fft_freq = fftfreq(fs, 1.0/fs)\n\n        # Define EEG bands\n        eeg_bands = {'Theta': (4, 7),\n                 'Alpha': (8, 12),\n                 'Beta': (13, 30),\n                 }\n    \n        # Take the  sum of squared absolute values/amplitudes for each EEG band\n\n        eeg_band_fft = defaultdict(list)\n\n        for band in eeg_bands:  \n        \n    \n            freq_ix = np.where((fft_freq >= eeg_bands[band][0]) & \n                               (fft_freq <= eeg_bands[band][1]))[0]\n    \n\n           \n            for channel in fft_vals:\n        \n                filterdch = channel[freq_ix]\n               \n                sqdvals = np.square(filterdch)\n               \n                sumvals = np.sum(sqdvals, axis=0)\n                \n                eeg_band_fft[band].append(sumvals)\n               \n\n\n\n        extracted_df =  pd.DataFrame(eeg_band_fft)\n\n    \n   \n\n        neeg = EEG_data.drop(columns=['matching condition','name','trial number', 'subject identifier','time', 'sample num', 'sensor value'])\n\n        neeg = neeg.drop_duplicates()\n\n\n        #get names of source elctrodes:\n\n        extracted_df = extracted_df.reset_index(drop=True)\n        neeg = neeg.reset_index(drop=True)\n\n\n\n        e_names =  neeg\n        e_names = e_names.rename(columns = {'sensor position' : 0})\n\n\n\n        extracted_df = extracted_df.join(neeg)\n\n\n        #get coordinates in 3d from robertoostenveld.nl/electrodes/plotting_1005.txt\n\n        coords = pd.read_csv('/kaggle/input/httpsrobertoostenveldnlelectrodes/plotting_1005.txt', sep='\\t',  header = None)\n\n        coords = coords.drop(coords.columns[4], axis=1)\n\n        #print(coords)\n        testerd = pd.merge(e_names, coords, on=0,  how='inner')\n\n\n        testerd.set_index('channel', inplace=True)\n\n        testerd.columns = ['pos','x', 'y', 'z']\n\n\n        extracted_df = extracted_df.rename(columns={'sensor position': \"pos\"})\n\n        #filter values and coordinates\n        extracted_df = pd.merge(extracted_df, testerd, on=\"pos\", how='inner')\n        extracted_df = extracted_df.drop(['x','y','z'], axis=1)\n        extracted_df.set_index('channel', inplace=True)\n\n        extracted_df = extracted_df.drop(columns=['pos'])\n        extracted_df.index.names = ['pos']\n\n      \n        #adapted from https://www.samuelbosch.com/2014/02/azimuthal-equidistant-projection.html\n\n        class Point(object):\n            def __init__(self,x, y, z):\n                self.x = x\n                self.y = y\n                self.z = z\n\n        class AzimuthalEquidistantProjection(object):\n            \"\"\" \n                http://mathworld.wolfram.com/AzimuthalEquidistantProjection.html\n                http://mathworld.wolfram.com/SphericalCoordinates.html\n            \"\"\"\n            def __init__(self):\n    \n                self.t1 = pi / 2 ## polar latitude center of projection , https://en.wikipedia.org/wiki/Azimuthal_equidistant_projection\n                self.l0 = 0 ## arbitrary longitude center of projection\n                self.cost1 = cos(self.t1)\n                self.sint1 = sin(self.t1)\n        \n            def project(self, point):\n        \n                #ADDAPTED FOR 3D CARTESIAN TO SPHERICAL \n        \n                hxy = np.hypot(point.x, point.y)\n        \n                t = np.arctan2(point.z, hxy)\n                l = np.arctan2(point.y, point.x)\n        \n                ###\n        \n                costcosll0 = cos(t) * cos(l-self.l0)\n                sint = sin(t)\n        \n                c = acos ((self.sint1) * (sint) + (self.cost1) * costcosll0)\n                k = c / sin(c)\n        \n                x = k * cos(t) * sin(l-self.l0)\n                y = k * (self.cost1 * sint - self.sint1 * costcosll0)\n                return x, y\n\n\n        \n        #Projection df\n\n        projected_df =  pd.DataFrame()\n\n        for index, row in testerd.iterrows():\n    \n            x = row['x']\n            y = row['y']\n            z = row['z']\n    \n    \n            p = AzimuthalEquidistantProjection()\n            r = p.project(Point(x,y,z))\n    \n            r = pd.Series(r)\n    \n            projected_df = projected_df.append(r,ignore_index=True)\n    \n\n        projected_df =  projected_df.rename(columns={0: 'X',1: 'Y'})\n\n\n        ###map coodinate with valuies\n\n        new_df = projected_df.join(extracted_df)\n        new_df = new_df.drop([31]) # drop row because i contains no values\n        #print(new_df)\n\n        Theta_df = new_df.drop(['Alpha','Beta','X','Y'], axis=1)\n        Alpha_df = new_df.drop(['Theta','Beta','X','Y'], axis=1)\n        Beta_df = new_df.drop(['Theta','Alpha','X','Y'], axis=1)\n        \n\n        #map onto mesh\n\n        xpoints = np.array(new_df[['X']].squeeze())\n        ypoints = np.array(new_df[['Y']].squeeze())\n\n        Thetavalues = np.array(Theta_df).squeeze()\n        Alphavalues = np.array(Alpha_df).squeeze()\n        Betavalues = np.array(Beta_df).squeeze()\n        \n\n        xx,yy = np.mgrid[-1.5:1.5:32j, -1.5:1.5:32j]\n\n        Thetavalues = minmax_scale(Thetavalues,feature_range=(0.0, 1.0), axis=0)\n        Alphavalues = minmax_scale(Alphavalues,feature_range=(0.0, 1.0), axis=0)\n        Betavalues = minmax_scale(Betavalues,feature_range=(0.0, 1.0), axis=0)\n\n\n        Thetagrid = griddata((xpoints, ypoints), Thetavalues, (xx, yy),method='cubic', fill_value = 0.0)\n        Alphagrid = griddata((xpoints, ypoints), Alphavalues, (xx, yy),method='cubic', fill_value = 0.0)\n        Betagrid = griddata((xpoints, ypoints), Betavalues, (xx, yy),method='cubic', fill_value = 0.0)\n     \n\n        ##RGB construction\n\n        RGB = np.empty((32, 32, 3))\n\n        RGB[:,:,0] = Thetagrid\n        RGB[:,:,1] = Alphagrid\n        RGB[:,:,2] = Betagrid\n    \n    \n    \n        RGB_dic[key] = RGB\n\n\n        \n    ##creating new dict with new keys\n\n    lendict = len(RGB_dic)\n    #print('lendict: ',lendict)\n\n    lenlist=np.arange(0,lendict)\n\n    #print(lenlist)\n\n    final_dict = dict(zip(lenlist, list(RGB_dic.values()))) \n    \n    \n    return final_dict\n    \nprint(\"Constructing Dataset...\")\n\n###Dataset construction\n\nclass EEGRGBDataset(Dataset):\n\n    def __init__(self, file, transform=None):\n        \n        self.file = file\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.file)\n\n\n    def __getitem__(self, idx): \n          \n        sample = self.file[idx]\n        \n        if self.transform:\n            sample = self.transform(sample)\n            \n        return sample\n\n####Tensor transform\n\n\nclass ToTensor(object):\n    def __call__(self, sample):\n\n        sample = sample.transpose((2, 0, 1))\n        sample = torch.tensor(sample, dtype = torch.float, device = device)\n\n        return sample \n    \n### Function Call\n\nfinal_dict1 = trialfunction(Alc_train_extractor)\nfinal_dict2 = trialfunction(Con_train_extractor)\nfinal_dict3 = trialfunction(Alc_train_classifier)\nfinal_dict4 = trialfunction(Con_train_classifier)    \nfinal_dict5 = trialfunction(Alc_test)\nfinal_dict6 = trialfunction(Con_test)\n\n##\n\neeg_dataset1 = EEGRGBDataset(final_dict1)\neeg_dataset2 = EEGRGBDataset(final_dict2)\n\neeg_dataset3 = EEGRGBDataset(final_dict3)\neeg_dataset4 = EEGRGBDataset(final_dict4)\n\neeg_dataset5 = EEGRGBDataset(final_dict5)\neeg_dataset6 = EEGRGBDataset(final_dict6)\n\n##\n    \ntransformed_dataset1 = EEGRGBDataset(eeg_dataset1, transform=transforms.Compose([ToTensor()]))\ntransformed_dataset2 = EEGRGBDataset(eeg_dataset2, transform=transforms.Compose([ToTensor()]))\n\ntransformed_dataset3 = EEGRGBDataset(eeg_dataset3, transform=transforms.Compose([ToTensor()]))\ntransformed_dataset4 = EEGRGBDataset(eeg_dataset4, transform=transforms.Compose([ToTensor()]))\n\ntransformed_dataset5 = EEGRGBDataset(eeg_dataset5, transform=transforms.Compose([ToTensor()]))\ntransformed_dataset6 = EEGRGBDataset(eeg_dataset6, transform=transforms.Compose([ToTensor()]))\n\n###Batch construction\n\nbsize = 10\nworkers = 0 \n\n\nloader1_Alc_train_extractor = DataLoader(transformed_dataset1, batch_size=bsize, num_workers=workers)\nloader2_Con_train_extractor = DataLoader(transformed_dataset2, batch_size=bsize, num_workers=workers)\n\nloader3_Alc_train_classifier = DataLoader(transformed_dataset3, batch_size=bsize, num_workers=workers)\nloader4_Con_train_classifier = DataLoader(transformed_dataset4, batch_size=bsize, num_workers=workers)\n\nloader5_Alc_test = DataLoader(transformed_dataset5, batch_size=bsize, num_workers=workers)\nloader6_Con_test = DataLoader(transformed_dataset6, batch_size=bsize, num_workers=workers)\n\n\n###Autoencoder\n\nclass Autoencoder(nn.Module):\n    \n    def __init__(self):\n        super(Autoencoder,self).__init__()\n        \n        #Encoder Convolutions\n        self.conv1 = nn.Conv2d(in_channels= 3, out_channels=8, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(in_channels= 8, out_channels=12, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv2d(in_channels= 12, out_channels=16, kernel_size=3, stride=1, padding=1)\n        \n\n        #Decoder Convolutions\n        self.deconv1 = nn.ConvTranspose2d(in_channels= 16, out_channels= 12, kernel_size=3, stride=1, padding=1)\n        self.deconv2 = nn.ConvTranspose2d(in_channels= 12, out_channels= 8, kernel_size=3, stride=1, padding=1)\n        self.deconv3 = nn.ConvTranspose2d(in_channels= 8, out_channels= 3, kernel_size=3, stride=1, padding=1)\n        \n        #Shared functions\n        self.pool = nn.MaxPool2d(kernel_size= 2,return_indices=True)\n        self.unpool = nn.MaxUnpool2d(kernel_size= 2)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout2d(p=0.25, inplace=False)\n        \n        \n    def forward(self,x):\n        #Encoder\n        encoded = self.conv1(x)\n        encoded, indices1 = self.pool(encoded)\n        encoded = self.relu(encoded)\n        encoded = self.dropout(encoded)\n        encoded = self.conv2(encoded)\n        encoded, indices2 = self.pool(encoded)\n        encoded = self.relu(encoded)\n        encoded = self.dropout(encoded)\n        encoded = self.conv3(encoded)\n        encoded = self.relu(encoded)\n        \n        #Decoder\n        \n        decoded = self.deconv1(encoded)\n        decoded = self.unpool(decoded, indices2)\n        decoded = self.relu(decoded)\n        decoded = self.deconv2(decoded)  \n        decoded = self.unpool(decoded, indices1)\n        decoded = self.relu(decoded)\n        decoded = self.deconv3(decoded)\n\n   \n        return decoded, encoded\n    \n\n\n#Train \nprint()\nprint(\"Traing model on dataset...\")\nprint()\nmodel1 = Autoencoder().cuda()\nmodel2 = Autoencoder().cuda()\n\ndistance = nn.MSELoss()\n\noptimizer1 = torch.optim.Adam(model1.parameters(),lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\noptimizer2 = torch.optim.Adam(model2.parameters(),lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n\n\n# Tensor construction\n# for pytorch, the right format for image is [batch, channels, height, width]\n\n#Training procedure\n\nnum_epochs = 1000\n\ndef trainer(loaderx, model, optimizer):\n    \n    for epoch in range(num_epochs):\n        #print(epoch)\n        \n        for i, batch in enumerate(loaderx):\n            \n           \n            #input\n            inputs = batch\n    \n            #optimizer zeroing\n            optimizer.zero_grad()\n    \n    \n            #forward\n            output  = model(inputs)\n            loss = distance(output[0],inputs)\n    \n            #backward\n            loss.backward()\n            optimizer.step()\n            \n        \n            # images\n            \n            if i == 1 and epoch == 9:\n           \n                firstimg_inp = inputs\n                firstimg_out = output[0]\n              \n                \n            \n            if i == 1  and epoch == num_epochs-1:\n        \n                lastimg_inp = inputs\n                lastimg_out = output[0]\n            \n                \n                return firstimg_inp, firstimg_out, lastimg_inp, lastimg_out\n\n\nfirstimg_inp1, firstimg_out1, lastimg_inp1, lastimg_out1 = trainer(loader1_Alc_train_extractor, model1, optimizer1)\nfirstimg_inp2, firstimg_out2, lastimg_inp2, lastimg_out2 = trainer(loader2_Con_train_extractor, model2, optimizer2)\n\n    \nprint('Finished Training')\nprint()\n\n##Training starting\nfor i in firstimg_inp1:\n    RGB1 = i.permute(1, 2, 0)\n    RGB1 = RGB1.cpu()\n    RGB1 = RGB1.detach().numpy()\n    break\n    \nfor i in firstimg_out1:\n    RGB12 = i.permute(1, 2, 0)\n    RGB12 = RGB12.cpu()\n    RGB12 = RGB12.detach().numpy()\n    break\n\n##Training Ending\nfor i in lastimg_inp1:\n    RGB2 = i.permute(1, 2, 0)\n    RGB2 = RGB2.cpu()\n    RGB2 = RGB2.detach().numpy()\n    break\nfor i in lastimg_out1:\n    RGB22 = i.permute(1, 2, 0)\n    RGB22 = RGB22.cpu()\n    RGB22 = RGB22.detach().numpy()\n    break\n\n\n### Image Plotting\nprint(\"Plotting input and output images at the beggining of training...\")\nprint()\n\nplt.subplot(441)\nplt.imshow(RGB1, interpolation='none', origin='upper')\nplt.title('Full')\n\n\nplt.subplot(442)\nplt.imshow(RGB1[:,:,0], interpolation='none', origin='upper', cmap = 'Reds')\nplt.title('Theta')\n\n\nprint(\"Plotting input and output images at the end of training...\")\nprint()\nplt.subplot(443)\nplt.imshow(RGB1[:,:,1], interpolation='none', origin='upper', cmap = 'Greens')\nplt.title('Alpha')\n\n\nplt.subplot(444)\nplt.imshow(RGB1[:,:,2], interpolation='none', origin='upper', cmap = 'Blues')\nplt.title('Beta')\n\nplt.gcf().set_size_inches(20, 20)\n\nplt.show()\n\nplt.subplot(441)\nplt.imshow(RGB12, interpolation='none', origin='upper')\nplt.title('Full')\n\n\nplt.subplot(442)\nplt.imshow(RGB12[:,:,0], interpolation='none', origin='upper', cmap = 'Reds')\nplt.title('Theta')\n\n\nplt.subplot(443)\nplt.imshow(RGB12[:,:,1], interpolation='none', origin='upper', cmap = 'Greens')\nplt.title('Alpha')\n\n\nplt.subplot(444)\nplt.imshow(RGB12[:,:,2], interpolation='none', origin='upper', cmap = 'Blues')\nplt.title('Beta')\n\nplt.gcf().set_size_inches(20, 20)\n\nplt.show()\n\n##########################\n\nplt.subplot(441)\nplt.imshow(RGB2, interpolation='none', origin='upper')\nplt.title('Full')\n\n\nplt.subplot(442)\nplt.imshow(RGB2[:,:,0], interpolation='none', origin='upper', cmap = 'Reds')\nplt.title('Theta')\n\n\nplt.subplot(443)\nplt.imshow(RGB2[:,:,1], interpolation='none', origin='upper', cmap = 'Greens')\nplt.title('Alpha')\n\n\nplt.subplot(444)\nplt.imshow(RGB2[:,:,2], interpolation='none', origin='upper', cmap = 'Blues')\nplt.title('Beta')\n\nplt.gcf().set_size_inches(20, 20)\n\nplt.show()\n\nplt.subplot(441)\nplt.imshow(RGB22, interpolation='none', origin='upper')\nplt.title('Full')\n\n\nplt.subplot(442)\nplt.imshow(RGB22[:,:,0], interpolation='none', origin='upper', cmap = 'Reds')\nplt.title('Theta')\n\n\nplt.subplot(443)\nplt.imshow(RGB22[:,:,1], interpolation='none', origin='upper', cmap = 'Greens')\nplt.title('Alpha')\n\n\nplt.subplot(444)\nplt.imshow(RGB22[:,:,2], interpolation='none', origin='upper', cmap = 'Blues')\nplt.title('Beta')\n\nplt.gcf().set_size_inches(20, 20)\n\nplt.show()\n\n\n#Saving & Loading Model\n\ntorch.save({'model_state_dict': model1.state_dict(),'optimizer_state_dict': optimizer1.state_dict()}, 'mymodel1.pth')\ntorch.save({'model_state_dict': model2.state_dict(),'optimizer_state_dict': optimizer2.state_dict()}, 'mymodel2.pth')\n\nthe_model1 = Autoencoder().cuda()\nthe_model2 = Autoencoder().cuda()\n\nmodelname1 = 'mymodel1.pth'\nmodelname2 = 'mymodel2.pth'\n\n\nthe_model1.load_state_dict(torch.load(modelname1)['model_state_dict'])\nthe_model1.eval()\nthe_model2.load_state_dict(torch.load(modelname2)['model_state_dict'])\nthe_model2.eval()\n\nprint(\"Saving autoencoder models alcohol group and control group:\")\nprint(\"Model1 saved as: \", modelname1)\nprint(\"Model2 saved as: \", modelname2)\n\n\n####Warmstarting Extractors on classifer training pool (basically tesing extractor)\n\n\ndef feature_extractor(loader, model):\n        \n    with torch.no_grad():\n        \n        outputlist = 0\n        imagebatch = 0\n        n = 0\n        \n        \n        for batch in loader:\n            n += 1\n            \n            inputs = batch\n\n        \n            #forward\n        \n            decoded, encoded  = model(inputs)\n            \n         \n            if n == 1:\n                outputlist = encoded\n                imagebatch = batch\n                \n            else:\n                outputlist = torch.cat((outputlist, encoded), dim=0, out=None)\n                imagebatch = torch.cat([imagebatch, batch], dim=0, out=None)\n                    \n        return outputlist, imagebatch\n\n### images for input\n\nfeatures_Alc_train_classifier, images_Alc_train_classifier = feature_extractor(loader3_Alc_train_classifier, the_model1)  \nfeatures_Con_train_classifier, images_Con_train_classifier = feature_extractor(loader4_Con_train_classifier, the_model2)\n\nfeatures_Alc_test_classifier, images_Alc_test_classifier = feature_extractor(loader5_Alc_test, the_model1)\nfeatures_Con_test_classifier, images_Con_test_classifier = feature_extractor(loader6_Con_test, the_model2)\n\n        \nimport numpy as np\n    \n\n##Labels\n\ny_Alc_train_classifier = np.ones([features_Alc_train_classifier.shape[0]])\ny_Con_train_classifier = np.zeros([features_Con_train_classifier.shape[0]])\n\ny_Alc_test_classifier = np.ones([features_Alc_test_classifier.shape[0]])\ny_Con_test_classifier= np.zeros([features_Con_test_classifier.shape[0]])\n\nfeatures_train_classifier = torch.cat([features_Alc_train_classifier, features_Con_train_classifier], dim=0)\ny_train_classifier = np.concatenate([y_Alc_train_classifier, y_Con_train_classifier], axis=0)\n\nfeatures_test_classifier = torch.cat([features_Alc_test_classifier, features_Con_test_classifier], dim=0)\ny_test_classifier = np.concatenate([y_Alc_test_classifier, y_Con_test_classifier], axis=0)\n\nimages_train_classifier = torch.cat([images_Alc_train_classifier, images_Con_train_classifier], dim=0)\nimages_test_classifier = torch.cat([images_Alc_test_classifier, images_Con_test_classifier], dim=0)\n\n\n\n\n###into multiarray\nfeatures_train_classifier = features_train_classifier.cpu().numpy()\n\nfeatures_test_classifier = features_test_classifier.cpu().numpy()\n\nimages_train_classifier = images_train_classifier.cpu().numpy()\n\nimages_test_classifier = images_test_classifier.cpu().numpy()\n\n\n###\n\nfrom sklearn.utils import shuffle\n\nS_features_train_classifier, S_y_train_classifier = shuffle(features_train_classifier, y_train_classifier, random_state=0)\nS_features_test_classifier, S_y_test_classifier = shuffle(features_test_classifier, y_test_classifier, random_state=0)\nS_images_train_classifier, S_y_train_classifier = shuffle(images_train_classifier, y_train_classifier, random_state=0)\nS_images_test_classifier, S_y_test_classifier = shuffle(images_test_classifier, y_test_classifier, random_state=0)\n\n\n###back to tensor\nS_features_train_classifier = torch.tensor(S_features_train_classifier, dtype=torch.float, device = device)\nS_y_train_classifier = torch.tensor(S_y_train_classifier, dtype=torch.float, device = device)\n\nS_features_test_classifier = torch.tensor(S_features_test_classifier, dtype=torch.float, device = device)\nS_y_test_classifier = torch.tensor(S_y_test_classifier, dtype=torch.float, device = device)\n\nS_images_train_classifier = torch.tensor(S_images_train_classifier, dtype=torch.float, device = device)\n\nS_images_test_classifier = torch.tensor(S_images_test_classifier, dtype=torch.float, device = device)\n\n\n\n\n###flatten\n\nFlat_S_features_train_classifier = torch.flatten(S_features_train_classifier,start_dim=1, end_dim=-1)\nFlat_S_features_test_classifier = torch.flatten(S_features_test_classifier,start_dim=1, end_dim=-1)\nFlat_S_images_train_classifier = torch.flatten(S_images_train_classifier,start_dim=1, end_dim=-1)\nFlat_S_images_test_classifier = torch.flatten(S_images_test_classifier,start_dim=1, end_dim=-1)\n\n\nclass FeedforwardNeuralNetModel(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(FeedforwardNeuralNetModel, self).__init__()\n        \n        self.input_size = input_size\n        self.hidden_size  = hidden_size\n        self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n        self.relu = torch.nn.ReLU()\n        self.fc2 = torch.nn.Linear(self.hidden_size, 1)\n        self.sigmoid = torch.nn.Sigmoid()\n\n    def forward(self, x):\n        hidden = self.fc1(x)\n        relu = self.relu(hidden)\n        output = self.fc2(relu)\n        output = self.sigmoid(output)\n        return output\n\n####\nprint()\nprint(\"Training classification models for images and features for 100 epochs..\")\nprint()\n#Train FeedforwardNeuralNetModel\n\nmodel3 = FeedforwardNeuralNetModel(1024,10).cuda()\nmodel4 = FeedforwardNeuralNetModel(3072,10).cuda()\n\ndistance =  nn.BCELoss()\n\nFFoptimizer1 = torch.optim.SGD(model3.parameters(), lr = 0.01)\nFFoptimizer2 = torch.optim.SGD(model4.parameters(), lr = 0.01)\n\n#Training procedure\n\nFFnum_epochs = 100\n\ndef FFtrainer(loaderx,labels, model, optimizer):\n    \n    for epoch in range(FFnum_epochs):\n                  \n        optimizer.zero_grad()\n        # Forward pass\n        y_pred = model(loaderx)\n        # Compute Loss\n        loss = distance(y_pred.squeeze(), labels)\n   \n        # Backward pass\n        loss.backward()\n        optimizer.step()\n        \n        #Print loss per epoch\n        #if epoch == 0 or epoch == FFnum_epochs-1:\n            #print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n\n\n### Determine test loss before training on test set\n\nmodel3.eval()\ny_pred1 = model3(Flat_S_features_test_classifier)\nbefore_train = distance(y_pred1.squeeze(), S_y_test_classifier)\nprint('Test loss before training on features' , before_train.item())\n\nmodel4.eval()\ny_pred2 = model4(Flat_S_images_test_classifier)\nbefore_train = distance(y_pred2.squeeze(), S_y_test_classifier)\nprint('Test loss before training on images' , before_train.item())\n\n\n#Training Call\n\nmodel3.train()\nModel_features_train_classifier = FFtrainer(Flat_S_features_train_classifier,S_y_train_classifier,model3,FFoptimizer1) \n\nmodel4.train()\nModel_images_train_classifier = FFtrainer(Flat_S_images_train_classifier,S_y_train_classifier,model4,FFoptimizer2)  \n\n\n# Evaluation\nmodel3.eval()\ny_pred3 = model3(Flat_S_features_test_classifier)\nafter_train = distance(y_pred3.squeeze(), S_y_test_classifier) \nprint('Test loss after Training on features' , after_train.item())\n\nmodel4.eval()\ny_pred4 = model4(Flat_S_images_test_classifier)\nafter_train = distance(y_pred4.squeeze(), S_y_test_classifier) \nprint('Test loss after Training on images' , after_train.item())\n\n\n#Accuracy\n\noutput_pred3 = (y_pred3>0.5).float()\ncorrect3 = (output_pred3.squeeze() == S_y_test_classifier).cpu().numpy().sum()\nincorrect3 = (output_pred3.squeeze() != S_y_test_classifier).cpu().numpy().sum()\ntotal3 = correct3 + incorrect3\naccuracy3 = 100 * correct3 / total3\n\n\noutput_pred4 = (y_pred4>0.5).float()\ncorrect4 = (output_pred4.squeeze() == S_y_test_classifier).cpu().numpy().sum()\nincorrect4 = (output_pred4.squeeze() != S_y_test_classifier).cpu().numpy().sum()\ntotal4 = correct4 + incorrect4\naccuracy4 = 100 * correct4 / total4\n\n\nprint()\nprint(\"Summary of classifier accuracy:\")\nprint()\nprint('Image accuracy:',accuracy4,'%')\nprint('Feature accuracy:',accuracy3,'%')\nprint()\nprint('In ',total4,' test cases, Changing classifier input form images to features lead to:' )\nprint()\nprint('Correct cases increased by: ', correct3 - correct4)\nprint('Accuracy increases by: ', accuracy3 - accuracy4,'%')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}