{"cells":[{"metadata":{},"cell_type":"markdown","source":"#MLJAR Automated Machine Learning\n\nThe mljar-supervised is an Automated Machine Learning Python package that works with tabular data. It is designed to save time for a data scientist. It abstracts the common way to preprocess the data, construct the machine learning models, and perform hyper-parameters tuning to find the best model. It is no black-box as you can see exactly how the ML pipeline is constructed (with a detailed Markdown report for each ML model).\n\nhttps://github.com/mljar/mljar-supervised#automated-machine-learning-rocket"},{"metadata":{},"cell_type":"markdown","source":"![](https://pbs.twimg.com/media/EeQGDN4XoAArvSC.png)twitter.com"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/covid19-in-angola/summary.csv\")\npd.set_option('display.max_columns', None)\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Codes by Abid Ali Awan https://www.kaggle.com/kingabzpro/automljar-golden-features/notebook"},{"metadata":{"_kg_hide-output":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"!pip install -q -U git+https://github.com/mljar/mljar-supervised.git@master\n!pip install -q -U matplotlib==3.1.3 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from supervised import AutoML","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.set_style(\"whitegrid\", {'axes.grid' : False})\nimport os\nfrom tqdm.notebook import tqdm\nimport gc\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns; sns.set()\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import ParameterGrid\nfrom sklearn.metrics import accuracy_score,mean_squared_error,auc\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TARGET_COL = \"Total de Recuperados\"\ndf = pd.read_csv(\"../input/covid19-in-angola/summary.csv\")\nprint(df.shape)\ntest = pd.read_csv(\"../input/covid19-in-angola/summary.csv\")\nprint(test.shape)\ndf['label']='train'\ntest['label']='test'\nframes = [df,test]\njoin_df = pd.concat(frames, keys=['x', 'y'])\nassert len(join_df) == len(df) + len(test)\nlst = join_df.isna().sum()/len(join_df)\np = pd.DataFrame(lst)\np.reset_index(inplace=True)\np.columns = ['a','b']\nlow_count = p[p['b']>0.8]\ntodelete=low_count['a'].values\njoin_df.drop(todelete,axis=1,inplace=True)\njoin_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"join_df.drop(['Novos Recuperados'],inplace=True,axis=1)\nnumerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n\nnewdf = join_df.select_dtypes(include=numerics)\nnumeric_cols = newdf.columns\n\n# Need to do column by column due to memory constraints\ncategorical_cols =  ['Data','label']\nfor i, v in tqdm(enumerate(categorical_cols)):\n    join_df[v] = join_df[v].fillna(join_df[v].value_counts().index[0])\nfor i, v in tqdm(enumerate([numeric_cols])):\n    join_df[v] =join_df.groupby(['Data','label'], sort=False)[v].apply(lambda x: x.fillna(x.mean()))\njoin_df[categorical_cols].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\n\n# In loop to minimize memory use\nfor i, v in tqdm(enumerate(categorical_cols)):\n    join_df[v] = OrdinalEncoder(dtype=\"int\").fit_transform(join_df[[v]])\n    \n\ngc.collect()\n\ntrain = join_df[join_df['label']==\"train\"]\npredict = join_df[join_df['label']=='test']\n\ntrain.reset_index(inplace=True)\ntrain.drop(['level_0','level_1','label'],inplace=True,axis =1 )\n\npredict.reset_index(inplace=True)\npredict.drop(['level_0','level_1','Total de Recuperados','label'],inplace=True,axis=1)\nfeatures = train.columns\nnum_feature = [col for col in features if col not in categorical_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_feature = [col for col in features if col not in categorical_cols and train[col].dtype != 'object']\ndrop_columns=[]\ncorr = train[num_feature].corr()\n# Drop highly correlated features \ncolumns = np.full((corr.shape[0],), True, dtype=bool)\n\nfor i in range(corr.shape[0]):\n    for j in range(i+1, corr.shape[0]):\n        if corr.iloc[i,j] >=0.999 :\n            if columns[j]:\n                columns[j] = False\n                print('FEAT_A: {} FEAT_B: {} - Correlation: {}'.format(train[num_feature].columns[i] , train[num_feature].columns[j], corr.iloc[i,j]))\n        elif corr.iloc[i,j] <= -0.995:\n            if columns[j]:\n                columns[j] = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Below, it's not suppose to be empty drop columns. "},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_columns = train[num_feature].columns[columns == False].values\nprint('drop_columns',len(drop_columns),drop_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(drop_columns,inplace=True,axis =1 )\npredict.drop(drop_columns,inplace=True,axis =1 )\ntrain[TARGET_COL].value_counts()/len(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.rename(columns={'Total de Recuperados':'totrecup'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Only errors till the End."},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\ndf_majority = train[train['Total de Recuperados']==0]\ndf_minority = train[train['Total de Recuperados']==1]\n\ndf_minority_upsampled = resample(df_minority, \n                                 replace=True,     # sample with replacement\n                                 n_samples=83798,    # to match majority class\n                                 random_state= 303) # reproducible results\n \n# Combine majority class with upsampled minority class\ndf_upsampled = pd.concat([df_majority, df_minority_upsampled])\n \n# Display new class counts\ndf_upsampled.totrecup.value_counts()\ntrain = df_upsampled","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n     train[[c for c in train if TARGET_COL != c]], train[TARGET_COL], test_size=0.20, random_state=42)\nprint(X_train.shape,X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.20, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Fast AutoMlJar"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"X=train[[c for c in train if TARGET_COL != c]]\ny=train[TARGET_COL]\nautoml = AutoML(mode=\"Compete\",total_time_limit=4*3600)\nautoml.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#My predict is empty."},{"metadata":{"trusted":true},"cell_type":"code","source":"predict","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"Final=automl.predict_all(predict)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"test[TARGET_COL] = Final['prediction_1']\ntest[[\"Novos Casos\",\"Total de Recuperados\"]].to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"#predictions = automl.predict_all(X_valid)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"#print(\"Test MSE:\", mean_squared_error(y_valid, predictions['prediction_1'],squared=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#automl.report()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}