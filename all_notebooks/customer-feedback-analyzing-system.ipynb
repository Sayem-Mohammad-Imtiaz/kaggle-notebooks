{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"dataset = pd.read_csv(\"../input/Womens Clothing E-Commerce Reviews.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"989a5308d9dfc5ffa31db9b9aba6891f47404fbf","collapsed":true},"cell_type":"code","source":"# Cleaning the texts\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"794d67514d1aee54ff25cf4e2b8fbe72e37cbf29"},"cell_type":"code","source":"corpus_title = []\nempty_set = []\ny_title = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"eb341d672fe5d2ced753f9f6592a9d2d02002d03"},"cell_type":"code","source":"for i in range(0, 500):\n    if (str(dataset['Title'][i]) == 'nan'):\n        empty_set.append(i)\n        continue\n    review = re.sub('[^a-zA-Z]', ' ', str(dataset['Title'][i]))\n    review = review.lower()\n    review = review.split()\n    review = [lemmatizer.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    corpus_title.append(review)\n    y_title.append(dataset.iloc[i,6])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bdccb0e034d5eb889e072fffceef0daf21ad3f8e"},"cell_type":"code","source":"# Creating the Bag of Words model\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features = 250)\nX_title = cv.fit_transform(corpus_title).toarray()\ny_title = np.array(y_title)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bfcaeaa2667b72213116d7c2c2a149906aedd445"},"cell_type":"code","source":"corpus_descrip = []\nempty_set = []\ny_descrip = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"269890997fe14790bc6fad35f67d26569b1e951b"},"cell_type":"code","source":"for i in range(0, 500):\n    if (str(dataset['Review Text'][i]) == 'nan'):\n        empty_set.append(i)\n        continue\n    review = re.sub('[^a-zA-Z]', ' ', str(dataset['Review Text'][i]))\n    review = review.lower()\n    review = review.split()\n    review = [lemmatizer.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    corpus_descrip.append(review)\n    y_descrip.append(dataset.iloc[i,5])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"65eb6e55838df797bc20fae3cc1631b6c0948c33"},"cell_type":"code","source":"# Creating the Bag of Words model\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv1 = CountVectorizer(max_features = 1500)\nX_descrip = cv1.fit_transform(corpus_descrip).toarray()\ny_descrip = np.array(y_descrip)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b70adb12f908ce1d00738df4b15b2e8826b7975","collapsed":true},"cell_type":"code","source":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.cross_validation import train_test_split\nX_train_t, X_test_t, y_train_t, y_test_t = train_test_split(X_title, y_title, test_size = 0.2, random_state = 0)\n\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.cross_validation import train_test_split\nX_train_d, X_test_d, y_train_d, y_test_d = train_test_split(X_descrip, y_descrip, test_size = 0.2, random_state = 0)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b08f8443af1f82a737ea997f9504dd52c063f5cf"},"cell_type":"code","source":"# Fitting Naive Bayes to the Training set\nfrom sklearn.naive_bayes import GaussianNB\nclassifier_title = GaussianNB()\nclassifier_title.fit(X_train_t, y_train_t)\n\n# Predicting the Test set results\ny_pred_t = classifier_title.predict(X_test_t)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test_t, y_pred_t)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"550188acb543bd88853132d622165a8979bc7c51"},"cell_type":"code","source":"\n# Fitting Naive Bayes to the Training set\nfrom sklearn.naive_bayes import GaussianNB\nclassifier_descrip = GaussianNB()\nclassifier_descrip.fit(X_train_d, y_train_d)\n\n# Predicting the Test set results\ny_pred_d = classifier_descrip.predict(X_test_d)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm_d = confusion_matrix(y_test_d, y_pred_d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29cb1a3269c896368ba430fab27e2acb55930651","collapsed":true},"cell_type":"code","source":"print('**************************************************************')\nprint(\"Do you want to give us your valuable feedback ?  1 for yes , 0 to skip\")\nchoice = input()\ni = 0\nfeedback_data = []\nwhile (choice == '1'):\n    print('Title')\n    in_title = []\n    Title = str(input())\n    title = Title\n    Title = re.sub('[^a-zA-Z]', ' ', Title)\n    Title = Title.lower()\n    Title = Title.split()\n    Title = [lemmatizer.lemmatize(word) for word in Title if not word in set(stopwords.words('english'))]\n    Title = ' '.join(Title)\n    in_title.append(Title)\n    Title = cv.transform(in_title).toarray()\n    Title_res =  classifier_title.predict(Title)[0]\n\n    if (Title_res == 1):\n        print ('\\nThanks !!! please describe your wonderful experience with us \\n')\n    else:\n        print('\\nSorry for your trouble! Please do describe your concern, so that we can make your experience better from next time \\n' )\n    \n    print('Description :')\n    in_title = []\n    Title = str(input())\n    descrip = Title\n    Title = re.sub('[^a-zA-Z]', ' ', Title)\n    Title = Title.lower()\n    Title = Title.split()\n    Title = [lemmatizer.lemmatize(word) for word in Title if not word in set(stopwords.words('english'))]\n    Title = ' '.join(Title)\n    in_title.append(Title)\n    Title = cv1.transform(in_title).toarray()\n    descrip_res =  classifier_descrip.predict(Title)[0]    \n    print(descrip_res)\n    print('\\n we have recorded your issues \\n' )\n    i= i+1\n    feedback_data.append([title , descrip , Title_res , descrip_res])\n    print(\"Do you want to give us your valuable feedback ?  1 for yes , 0 to skip\")\n    choice = input()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8169b1c40bd6ff867fde25d49fe377e50dff293b"},"cell_type":"code","source":"feedback_data = pd.DataFrame(np.array(feedback_data) , columns = ['Title' ,'description' , 'like it ?' , 'Rating'])    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9819ccb61b1b69177a037752d7b7cf80313a151b","collapsed":true},"cell_type":"code","source":"feedback_data","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}