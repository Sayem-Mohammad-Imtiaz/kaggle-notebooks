{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d0bb38d7-e380-7f1a-5846-975c68a386d8"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom collections import Counter\nfrom wordcloud import WordCloud\nimport datetime as dt\nimport seaborn as sb\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\nparser = lambda x: dt.datetime.strptime(x[:-6], '%Y-%m-%d %H:%M:%S')\ndata = pd.read_csv(\"../input/Tweets.csv\",parse_dates=[12], date_parser = parser)\ndata.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"893179c9-6e75-c157-3177-605f0814425b"},"outputs":[],"source":"# Check the ratio of positive and negative tweets for each airline\ndata['countval'] = 1\ngroupby_object = data[['airline','airline_sentiment','countval']] \\\n                 .groupby(['airline','airline_sentiment']).aggregate(sum)\ngroupby_object.unstack(level=1).plot(kind='bar',figsize=(12, 8))\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f4a38ea4-6410-99ff-4a9f-1b0e04af8096"},"outputs":[],"source":"data['dow'] = data.tweet_created.dt.dayofweek\n\ng = sb.FacetGrid(data, row = 'airline_sentiment', \n                 hue = 'airline', legend_out = True,\n                 aspect = 4, size = 2.5)\ng.map(sb.distplot, 'dow', hist = False)\ng.add_legend()\ng.axes.flat[0].set_xlim(0,6)\ng.axes.flat[2].set_xlabel('Day of Week')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"29427191-951b-bb0d-ac60-766285c0453a"},"outputs":[],"source":"pf = data.groupby(['negativereason']).airline.value_counts()\nmy_plot = pf.unstack().plot(kind='bar',stacked=True,figsize=(12, 16),rot=0,title=\"Negetive Reasons by Airlines\")\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=90)\nmy_plot.set_xlabel(\"Negative Reason\")\nmy_plot.set_ylabel(\"Airline\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"38a472cc-08ab-078c-6076-14bab5c584a2"},"outputs":[],"source":"# Word cloud for POSITIVE tweets\ndf=data[data['airline_sentiment']=='positive'] \n# join positive tweets to a single string\nwords = ' '.join(df['text'])\n# remove URLs, RTs, and twitter handles\ncleaned_words = \" \".join([word for word in words.split()\n                            if 'http' not in word\n                                and not word.startswith('@')\n                                and word != 'RT'\n                            ])\nwordcloud = WordCloud(background_color='black',\n                      width=2000,\n                      height=1500\n                     ).generate(cleaned_words)\nplt.figure(1,figsize=(12, 12))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"85ae4603-274e-cb28-e6c8-19c4387850b5"},"outputs":[],"source":"# Word cloud for Negative tweets\ndf=data[data['airline_sentiment']=='negative'] \n# join positive tweets to a single string\nwords = ' '.join(df['text'])\n# remove URLs, RTs, and twitter handles\ncleaned_words = \" \".join([word for word in words.split()\n                            if 'http' not in word\n                                and not word.startswith('@')\n                                and word != 'RT'\n                            ])\nwordcloud = WordCloud(background_color='black',\n                      width=2000,\n                      height=1500\n                     ).generate(cleaned_words)\nplt.figure(1,figsize=(12, 12))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0bd4d7c4-a13f-e3e2-0c8f-d036b245f82a"},"outputs":[],"source":"# Word cloud for NEUTRAL tweets\ndf=data[data['airline_sentiment']=='neutral'] \n# join positive tweets to a single string\nwords = ' '.join(df['text'])\n# remove URLs, RTs, and twitter handles\ncleaned_words = \" \".join([word for word in words.split()\n                            if 'http' not in word\n                                and not word.startswith('@')\n                                and word != 'RT'\n                            ])\nwordcloud = WordCloud(background_color='black',\n                      width=2000,\n                      height=1500\n                     ).generate(cleaned_words)\nplt.figure(1,figsize=(12, 12))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"beb660b4-d841-2c3d-c969-da4424145487"},"outputs":[],"source":"def find_emojies ( raw_review, emoji ):\n    for a in raw_review:\n        a = a.encode('unicode_escape')\n        if str(a,'utf-8').lower().startswith('\\\\u') and str(a,'utf-8') != '\\\\ufe0f':\n            key = a.decode('unicode_escape') + \" \"+str(a,'utf-8')\n            if key in emoji: \n                emoji[key] += 1\n            else:\n                emoji[key] = 1\n\nemoji = dict()\nfor tweet in data['text']:\n    find_emojies(tweet, emoji)\n    \nfor key in emoji:\n     print (key, emoji[key])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"07d9590c-5732-a758-422d-a0adba521623"},"outputs":[],"source":"import re\n          \ndef replace_emoji (raw_review):\n    encoded_review = str(raw_review.encode('unicode_escape'),'utf-8')\n    \n    encoded_review = encoded_review.replace('\\\\U0001f44d', 'like ') \n    encoded_review = encoded_review.replace('\\\\U0001f44c', 'great ')\n    encoded_review = encoded_review.replace('\\\\U0001f60e', 'cool ')\n    encoded_review = encoded_review.replace('\\\\U0001f44f', 'applause ')\n    encoded_review = encoded_review.replace('\\\\U0001f44e', 'dislike ')\n    encoded_review = encoded_review.replace('\\\\U0001f618', 'kiss ')\n    encoded_review = encoded_review.replace('\\\\U0001f625', 'disappointed ')\n    encoded_review = encoded_review.replace('\\\\U0001f389', 'celebrate ')\n    encoded_review = encoded_review.replace('\\\\U0001f64c', 'celebrate ')\n    encoded_review = encoded_review.replace('\\\\U0001f494', 'heartbreak ')\n    \n    happy_emoticons = ['\\\\u263a','\\\\U0001f60a','\\\\U0001f603','\\\\U0001f601','\\\\U0001f602','\\\\U0001f600',\n                       '\\\\U0001f604','\\\\U0001f609','\\\\U0001f61c','\\\\U0001f624','\\\\U0001f60b','\\\\U0001f60f',\n                       '\\\\U0001f605','\\\\U0001f3b5','\\\\U0001f606',':)',':-)','=)',';)',';-)',':D',':-D',';P',':P',';D']\n    sad_emoticons = ['\\\\U0001f622','\\\\U0001f62d','\\\\U0001f61e','\\\\U0001f614','\\\\U0001f615','\\\\U0001f623','\\\\U0001f613',':(',':|',':-(']\n    heart_emoticons = ['\\\\u2764','\\\\U0001f60d','\\\\U0001f49c','\\\\U0001f495','\\\\U0001f497','\\\\u2665','\\\\U0001f496','\\\\U0001f498','\\\\U0001f49d','\\\\U0001f499',]\n    angry_emoticons = ['\\\\U0001f621','\\\\U0001f612','\\\\U0001f62c','\\\\U0001f611','\\\\U0001f620','\\\\U0001f610','\\\\U0001f626']\n    surprised_emoticons = ['\\\\U0001f631','\\\\U0001f62e','\\\\U0001f632']\n    tired_emoticons = ['\\\\U0001f629','\\\\U0001f62b','\\\\U0001f62a']\n    \n    for emoticon in happy_emoticons:\n        encoded_review = encoded_review.replace(emoticon, 'happy ') \n    for emoticon in sad_emoticons:\n        encoded_review = encoded_review.replace(emoticon, 'sad ')\n    for emoticon in heart_emoticons:\n        encoded_review = encoded_review.replace(emoticon, 'heart ')\n    for emoticon in angry_emoticons:\n        encoded_review = encoded_review.replace(emoticon, 'angry ')\n    for emoticon in surprised_emoticons:\n        encoded_review = encoded_review.replace(emoticon, 'surprised ')\n    for emoticon in tired_emoticons:\n        encoded_review = encoded_review.replace(emoticon, 'tired ')  \n            \n    decoded_review = bytes(encoded_review,'utf-8').decode('unicode_escape')\n    return decoded_review\n    \ndef tweet_to_words( raw_review ):\n    # Function to convert a raw review to a string of words\n    # The input is a single string (a raw tweet), and \n    # the output is a single string (a preprocessed tweet)\n    #\n    review_text = raw_review  \n   \n    # 1. Remove non-letters and tweeter handlers\n    \n    no_handlers = re.sub(\"@[a-zA-Z1-9]+\", \" \", review_text)\n    letters_only = re.sub(\"[^a-zA-Z]\", \" \", no_handlers)\n    #\n    # 2. Convert to lower case, split into individual words\n    words = letters_only.lower().split()                            \n  \n    # 3. Remove stop words and lematize them\n    meaningful_words = [wordnet_lemmatizer.lemmatize(w) for w in words]\n    #  \n    # 4. Join the words back into one string separated by space, \n    # and return the result.\n    return(\" \".join( meaningful_words ))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4489492e-5568-87c6-d7ff-88b9171f624e"},"outputs":[],"source":"from nltk.corpus import stopwords\nfrom nltk import PorterStemmer\nfrom nltk.stem.snowball import SnowballStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom nltk.stem import WordNetLemmatizer\n\n# Set stemmer\n#if stemmer_name == \"snowball\":\n    #stemmer = SnowballStemmer(\"english\")\n#else:\n    #stemmer = PorterStemmer()\n    \nwordnet_lemmatizer = WordNetLemmatizer()\nstops = set(stopwords.words(\"english\"))   \nnegations = ['no', 'not','didn', 'won','couldn','haven']\nstops = [x for x in stops if x not in negations]\n\nprocessed_tweets = []\nfor tweet in data['text']:\n    tweet = replace_emoji(tweet)\n    processed = tweet_to_words(tweet)\n    processed_tweets.append(processed)\n     \n#data[\"text\"] = processed_tweets\n\nvect = CountVectorizer()\nprocessed_text = vect.fit_transform(processed_tweets)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b67bfbb1-5670-c714-776a-3aae9e09a14c"},"outputs":[],"source":"from sklearn import metrics\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import svm\n\nX_train, X_test, y_train, y_test = train_test_split(processed_text, data['airline_sentiment'], test_size=0.20,random_state=42)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dd00398b-6d02-2f22-f6f0-e9d6f130a8e1"},"outputs":[],"source":"# Train Multinominal Naive Bayes\n\nmodel = MultinomialNB()\nmodel.fit(X_train, y_train)\n\n# make predictions\nexpected_bayes = y_test\npredicted_bayes = model.predict(X_test)\n\n# summarize the fit of the model\nprint(metrics.classification_report(expected_bayes, predicted_bayes))\nprint(metrics.confusion_matrix(expected_bayes, predicted_bayes))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c0646e34-683f-3ad5-f978-29a621f11226"},"outputs":[],"source":"# Train Random Forest Classifier\nmodel  = RandomForestClassifier()\nmodel.fit(X_train, y_train)\n\n# make predictions\nexpected_rfc = y_test\npredicted_rfc = model.predict(X_test)\n\n# summarize the fit of the model\nprint(metrics.classification_report(expected_rfc, predicted_rfc))\nprint(metrics.confusion_matrix(expected_rfc, predicted_rfc))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f4d3195b-596d-02f5-f264-267b59f495b6"},"outputs":[],"source":"# Train SVM\nmodel = svm.LinearSVC(C=1.0, random_state=0, class_weight='balanced')\nmodel.fit(X_train, y_train)\n\n# make predictions\nexpected_svm = y_test\npredicted_svm = model.predict(X_test)\n\n# summarize the fit of the model\nprint(metrics.classification_report(expected_svm, predicted_svm))\nprint(metrics.confusion_matrix(expected_svm, predicted_svm))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"94c3d1f8-df0d-bafc-6e05-68f07219b585"},"outputs":[],"source":"# Train SVM with Tfidf\ntf = TfidfVectorizer()\nprocessed_text = tf.fit_transform(processed_tweets)\nX_train, X_test, y_train, y_test = train_test_split(processed_text, data['airline_sentiment'], test_size=0.20,random_state=42)\n\nmodel = svm.LinearSVC(C=1.0, random_state=0, class_weight='balanced')\nmodel.fit(X_train, y_train)\n\n# make predictions\nexpected_tf = y_test\npredicted_tf = model.predict(X_test)\n# summarize the fit of the model\nprint(metrics.classification_report(expected_tf, predicted_tf))\nprint(metrics.confusion_matrix(expected_tf, predicted_tf))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"50236b7d-0358-6c8e-3c42-027d050fd2a5"},"outputs":[],"source":"# Predict tweet sentiment with dictionary approach \nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nsid = SentimentIntensityAnalyzer()\ntweet_scores = [sid.polarity_scores(tweet) for tweet in processed_tweets]  \n#print(tweet_scores[:20])\npredicted_dict = []\nfor score in tweet_scores:\n    if score['compound'] < 0:\n        predicted_dict.append('negative')\n    elif score['compound'] < 0.35:\n        predicted_dict.append('neutral')\n    else:\n        predicted_dict.append('positive')\nprint(metrics.classification_report(data['airline_sentiment'], predicted_dict))\nprint(metrics.confusion_matrix(data['airline_sentiment'], predicted_dict))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8b72bebf-156e-2703-fc7e-321cd957126d"},"outputs":[],"source":"errors = []   \nfor tweet, e_sentiment, p_sentiment in zip( X_test, expected_tf.values, predicted_tf):\n    if e_sentiment != p_sentiment:\n        errors.append((tweet, e_sentiment,p_sentiment))\n\t\t#print('%s => %s' % (tweet, p_sentiment))\nidx = 0\nfor error in errors:\n    a =[idx[1] for idx in np.transpose(np.nonzero(error[0]))]\n    words=[]\n    for i in a:\n        words.append(tf.get_feature_names()[i])\n    if idx < 30:\n        for tweet in data['text']:\n            if len(set(words) - set(tweet_to_words(replace_emoji(tweet)).split())) == 0:\n                print(tweet)\n                print(\"Expected: \"+error[1]+'\\nPredicted: '+error[2])\n                print(\"---------------------------------------------------------------------------\")\n                break\n        \n    idx = idx + 1"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}