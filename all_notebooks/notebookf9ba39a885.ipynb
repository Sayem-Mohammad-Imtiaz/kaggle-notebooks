{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom glob import glob\n%matplotlib inline\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-30T11:02:14.980172Z","iopub.execute_input":"2021-07-30T11:02:14.980628Z","iopub.status.idle":"2021-07-30T11:02:14.991082Z","shell.execute_reply.started":"2021-07-30T11:02:14.980591Z","shell.execute_reply":"2021-07-30T11:02:14.989676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd '../'","metadata":{"execution":{"iopub.status.busy":"2021-07-30T11:02:50.444761Z","iopub.execute_input":"2021-07-30T11:02:50.445322Z","iopub.status.idle":"2021-07-30T11:02:50.454243Z","shell.execute_reply.started":"2021-07-30T11:02:50.445269Z","shell.execute_reply":"2021-07-30T11:02:50.453169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"../input/chexpert-dataset/\"","metadata":{"execution":{"iopub.status.busy":"2021-07-30T11:03:59.357856Z","iopub.execute_input":"2021-07-30T11:03:59.358265Z","iopub.status.idle":"2021-07-30T11:03:59.362934Z","shell.execute_reply.started":"2021-07-30T11:03:59.358232Z","shell.execute_reply":"2021-07-30T11:03:59.361733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/modifieddataset/modifiedv2_train.csv')\nvalid_df = pd.read_csv('../input/modifieddataset/modifiedv2_valid.csv')\ntrain_df[\"path\"] = path + train_df[\"Path\"]\nvalid_df[\"path\"] = path + valid_df[\"Path\"]\n# all_image_paths = {os.path.basename(x): x for x in \n#                    glob(os.path.join('..', 'input', 'images*', '*', '*.png'))}\n# print('Scans found:', len(all_image_paths), ', Total Headers', all_xray_df.shape[0])\n# all_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\n# all_xray_df['Patient Age'] = all_xray_df['Patient Age'].map(lambda x: int(x[:-1]))\ntrain_df.sample(3)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T11:37:59.572583Z","iopub.execute_input":"2021-07-30T11:37:59.573066Z","iopub.status.idle":"2021-07-30T11:38:00.415431Z","shell.execute_reply.started":"2021-07-30T11:37:59.573026Z","shell.execute_reply":"2021-07-30T11:38:00.414525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_counts = train_df['Finding Labels'].value_counts()[:15]\nfig, ax1 = plt.subplots(1,1,figsize = (12, 8))\nax1.bar(np.arange(len(label_counts))+0.5, label_counts)\nax1.set_xticks(np.arange(len(label_counts))+0.5)\n_ = ax1.set_xticklabels(label_counts.index, rotation = 90)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T11:38:20.941642Z","iopub.execute_input":"2021-07-30T11:38:20.942174Z","iopub.status.idle":"2021-07-30T11:38:21.309701Z","shell.execute_reply.started":"2021-07-30T11:38:20.942141Z","shell.execute_reply":"2021-07-30T11:38:21.308561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df[train_df[\"Finding Labels\"].notnull()]","metadata":{"execution":{"iopub.status.busy":"2021-07-30T11:38:25.102305Z","iopub.execute_input":"2021-07-30T11:38:25.102718Z","iopub.status.idle":"2021-07-30T11:38:25.136239Z","shell.execute_reply.started":"2021-07-30T11:38:25.102682Z","shell.execute_reply":"2021-07-30T11:38:25.135433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.shape, valid_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-30T11:38:27.523195Z","iopub.execute_input":"2021-07-30T11:38:27.523759Z","iopub.status.idle":"2021-07-30T11:38:27.530697Z","shell.execute_reply.started":"2021-07-30T11:38:27.523707Z","shell.execute_reply":"2021-07-30T11:38:27.529834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['Finding Labels'] = train_df['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\nfrom itertools import chain\nall_labels = np.unique(list(chain(*train_df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\nall_labels = [x for x in all_labels if len(x)>0]\nprint('All Labels ({}): {}'.format(len(all_labels), all_labels))\nfor c_label in all_labels:\n    if len(c_label)>1: # leave out empty labels\n        train_df[c_label] = train_df['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\ntrain_df.sample(3)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T11:38:29.878431Z","iopub.execute_input":"2021-07-30T11:38:29.878988Z","iopub.status.idle":"2021-07-30T11:38:31.627404Z","shell.execute_reply.started":"2021-07-30T11:38:29.878927Z","shell.execute_reply":"2021-07-30T11:38:31.626252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MIN_CASES = 1000\nall_labels = [c_label for c_label in all_labels if train_df[c_label].sum()>MIN_CASES]\nprint('Clean Labels ({})'.format(len(all_labels)), \n      [(c_label,int(train_df[c_label].sum())) for c_label in all_labels])","metadata":{"execution":{"iopub.status.busy":"2021-07-30T11:38:40.193943Z","iopub.execute_input":"2021-07-30T11:38:40.194469Z","iopub.status.idle":"2021-07-30T11:38:40.211139Z","shell.execute_reply.started":"2021-07-30T11:38:40.194423Z","shell.execute_reply":"2021-07-30T11:38:40.210014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_counts = 100*np.mean(train_df[all_labels].values,0)\nfig, ax1 = plt.subplots(1,1,figsize = (12, 8))\nax1.bar(np.arange(len(label_counts))+0.5, label_counts)\nax1.set_xticks(np.arange(len(label_counts))+0.5)\nax1.set_xticklabels(all_labels, rotation = 90)\nax1.set_title('Adjusted Frequency of Diseases in Patient Group')\n_ = ax1.set_ylabel('Frequency (%)')","metadata":{"execution":{"iopub.status.busy":"2021-07-30T11:38:42.808691Z","iopub.execute_input":"2021-07-30T11:38:42.80905Z","iopub.status.idle":"2021-07-30T11:38:43.099732Z","shell.execute_reply.started":"2021-07-30T11:38:42.809021Z","shell.execute_reply":"2021-07-30T11:38:43.098569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['disease_vec'] = train_df.apply(lambda x: [x[all_labels].values], 1).map(lambda x: x[0])\n# valid_df['disease_vec'] = valid_df.apply(lambda x: [x[all_labels].values], 1).map(lambda x: x[0])","metadata":{"execution":{"iopub.status.busy":"2021-07-30T11:41:46.804202Z","iopub.execute_input":"2021-07-30T11:41:46.804601Z","iopub.status.idle":"2021-07-30T11:42:44.380263Z","shell.execute_reply.started":"2021-07-30T11:41:46.804569Z","shell.execute_reply":"2021-07-30T11:42:44.379193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_df, valid_df = train_test_split(train_df, \n                                   test_size = 0.25, \n                                   random_state = 2018,\n                                   stratify = train_df['Finding Labels'].map(lambda x: x[:4]))\nprint('train', train_df.shape[0], 'validation', valid_df.shape[0])","metadata":{"execution":{"iopub.status.busy":"2021-07-30T11:42:51.131888Z","iopub.execute_input":"2021-07-30T11:42:51.13231Z","iopub.status.idle":"2021-07-30T11:42:51.531927Z","shell.execute_reply.started":"2021-07-30T11:42:51.132278Z","shell.execute_reply":"2021-07-30T11:42:51.530842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = '../input/chexpert-dataset/CheXpert-v1.0-small/train'\nimage_size = 128\nbatch_size = 32","metadata":{"execution":{"iopub.status.busy":"2021-07-30T09:53:40.954188Z","iopub.execute_input":"2021-07-30T09:53:40.954549Z","iopub.status.idle":"2021-07-30T09:53:40.959783Z","shell.execute_reply.started":"2021-07-30T09:53:40.954519Z","shell.execute_reply":"2021-07-30T09:53:40.958504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nIMG_SIZE = (128, 128)\ncore_idg = ImageDataGenerator(samplewise_center=True, \n                              samplewise_std_normalization=True, \n                              horizontal_flip = True, \n                              vertical_flip = False, \n                              height_shift_range= 0.05, \n                              width_shift_range=0.1, \n                              rotation_range=5, \n                              shear_range = 0.1,\n                              fill_mode = 'reflect',\n                              zoom_range=0.15)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T11:42:55.644913Z","iopub.execute_input":"2021-07-30T11:42:55.645293Z","iopub.status.idle":"2021-07-30T11:42:55.650531Z","shell.execute_reply.started":"2021-07-30T11:42:55.645257Z","shell.execute_reply":"2021-07-30T11:42:55.649804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n    base_dir = os.path.dirname(in_df[path_col].values[0])\n    print('## Ignore next message from keras, values are replaced anyways')\n    df_gen = img_data_gen.flow_from_directory(base_dir, \n                                     class_mode = 'sparse',\n                                    **dflow_args)\n    df_gen.filenames = in_df[path_col].values\n    df_gen.classes = np.stack(in_df[y_col].values)\n    df_gen.samples = in_df.shape[0]\n    df_gen.n = in_df.shape[0]\n    df_gen._set_index_array()\n    df_gen.directory = '' # since we have the full path\n    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n    return df_gen","metadata":{"execution":{"iopub.status.busy":"2021-07-30T11:42:58.477868Z","iopub.execute_input":"2021-07-30T11:42:58.478367Z","iopub.status.idle":"2021-07-30T11:42:58.484862Z","shell.execute_reply.started":"2021-07-30T11:42:58.478322Z","shell.execute_reply":"2021-07-30T11:42:58.483831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gen = flow_from_dataframe(core_idg, train_df, \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'grayscale',\n                            batch_size = 32)\n\nvalid_gen = flow_from_dataframe(core_idg, valid_df, \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'grayscale',\n                            batch_size = 256) # we can use much larger batches for evaluation\n# used a fixed dataset for evaluating the algorithm\ntest_X, test_Y = next(flow_from_dataframe(core_idg, \n                               valid_df, \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'grayscale',\n                            batch_size = 1024)) # one big batch","metadata":{"execution":{"iopub.status.busy":"2021-07-30T11:43:00.847808Z","iopub.execute_input":"2021-07-30T11:43:00.848164Z","iopub.status.idle":"2021-07-30T11:43:01.716615Z","shell.execute_reply.started":"2021-07-30T11:43:00.848134Z","shell.execute_reply":"2021-07-30T11:43:01.715417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t_x, t_y = next(train_gen)\nfig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\nfor (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n    c_ax.imshow(c_x[:,:,0], cmap = 'bone', vmin = -1.5, vmax = 1.5)\n    c_ax.set_title(', '.join([n_class for n_class, n_score in zip(all_labels, c_y) \n                             if n_score>0.5]))\n    c_ax.axis('off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications.mobilenet import MobileNet\nfrom keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\nfrom keras.models import Sequential\nmobilenet_model = MobileNet(input_shape =  t_x.shape[1:], \n                                 include_top = False, weights = None)\nmulti_disease_model = Sequential()\nmulti_disease_model.add(mobilenet_model)\nmulti_disease_model.add(GlobalAveragePooling2D())\nmulti_disease_model.add(Dropout(0.5))\nmulti_disease_model.add(Dense(512))\nmulti_disease_model.add(Dropout(0.5))\nmulti_disease_model.add(Dense(len(all_labels), activation = 'sigmoid'))\nmulti_disease_model.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n                           metrics = ['binary_accuracy', 'mae'])\nmulti_disease_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_weights.best.hdf5\".format('xray_class')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=3)\ncallbacks_list = [checkpoint, early]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"multi_disease_model.fit_generator(train_gen, \n                                  steps_per_epoch=100,\n                                  validation_data = (test_X, test_Y), \n                                  epochs = 15, \n                                  callbacks = callbacks_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}