{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#Se importan las librerias\n\nimport pandas as pd\nimport numpy as np\n\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout\nfrom tensorflow.keras.utils import to_categorical \n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n\n#librosa es un paquete de python para analisis de audio\n#Documentacion Librosa: https://librosa.org/doc/latest/index.html\n\nimport os\nimport librosa\nimport librosa.display\nimport glob \nimport skimage","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Se carga el dataset UrbanSound8K que posee 8732 sonidos etiquetados\ndf = pd.read_csv(\"../input/urbansound8k/UrbanSound8K.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Se carga y se muestra un ejemplo de sonido humano que contiene el Dataset (children_playing)\ndat1, sampling_rate1 = librosa.load('../input/urbansound8k/fold5/100263-2-0-121.wav')\nplt.figure(figsize=(20, 10))\nD = librosa.amplitude_to_db(np.abs(librosa.stft(dat1)), ref=np.max)\nplt.subplot(4, 2, 1)\nlibrosa.display.specshow(D, y_axis='linear')\nplt.colorbar(format='%+2.0f dB')\nplt.title('children_playing')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Se recorre el dataset y se obtienen sus caracteristicas mediante librosa\n\nfeature = []\nlabel = []\n\ndef parser(row):\n    for i in range(8732):\n        file_name = '../input/urbansound8k/fold' + str(df[\"fold\"][i]) + '/' + df[\"slice_file_name\"][i]\n        X, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n        mels = np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T,axis=0)        \n        feature.append(mels)\n        label.append(df[\"classID\"][i])\n    return [feature, label]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Se declaran variables necesarias para el entrenamiento\n\ntemp = parser(df)\ntemp = np.array(temp)\ndata = temp.transpose()\nX_ = data[:, 0]\nY = data[:, 1]\nX = np.empty([8732, 128])\n\nfor i in range(8732):\n    X[i] = (X_[i])\n    \nY = to_categorical(Y)\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 1)\nX_train = X_train.reshape(6549, 16, 8, 1)\nX_test = X_test.reshape(2183, 16, 8, 1)\ninput_dim = (16, 8, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Se crea el modelo Keras para el entrenamiento\n\nmodel = Sequential()\nmodel.add(Conv2D(64, (3, 3), padding = \"same\", activation = \"tanh\", input_shape = input_dim))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Conv2D(128, (3, 3), padding = \"same\", activation = \"tanh\"))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.1))\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation = \"tanh\"))\nmodel.add(Dense(10, activation = \"softmax\"))\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Se definen las epocas y el batch size del entrenamiento\n\nmodel.fit(X_train, Y_train, epochs = 90, batch_size = 50, validation_data = (X_test, Y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Resumen de lo obtenido con el entrenamiento del modelo\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Resultados obtenidos de las predicciones realizadas al Dataset de sonidos\n\npredictions = model.predict(X_test)\nscore = model.evaluate(X_test, Y_test)\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Se almacena el resultado obtenido de las predicciones en un archivo .csv (output)\n\npreds = np.argmax(predictions, axis = 1)\nresult = pd.DataFrame(preds)\n\n#Si la prediccion es 2 proviene de children_playing\nresult.to_csv(\"PrediccionesResultado.csv\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}