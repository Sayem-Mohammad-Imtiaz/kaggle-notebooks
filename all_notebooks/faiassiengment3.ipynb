{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import scatter_matrix\nfrom sklearn.impute import SimpleImputer\n\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense, Softmax\nfrom tensorflow.keras import optimizers\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.pipeline import Pipeline\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\n\nfrom numpy.random import seed\nimport tensorflow \n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"housingData = pd.read_csv('/kaggle/input/california-housing-prices/housing.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housingData.head() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(housingData.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housingData.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housingData.hist(bins=50,figsize=(50,45))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = housingData.corr()\ncorr_matrix['median_house_value'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housingData.shape\nhousingData['ocean_proximity'] = housingData['ocean_proximity'].astype('category')\nhousingData['ocean_proximity'] = housingData['ocean_proximity'].cat.codes\n\ncontinuous = ['population', 'median_income', 'median_house_value', 'latitude', 'longitude','housing_median_age','total_rooms','total_bedrooms','households','housing_median_age','ocean_proximity']\nscaler = MinMaxScaler()\n\nfor var in continuous:\n    housingData[var] = housingData[var].astype('float64')\n    housingData[var] = scaler.fit_transform(housingData[var].values.reshape(-1, 1))\n\n\nhousingData.drop(['population', 'latitude', 'longitude','total_bedrooms','households'],axis=1,inplace=True)\n\nX_data=housingData.drop('median_house_value',axis=1)\nY_data=housingData['median_house_value'].copy()\n\nX=X_data.values\nY=Y_data.values\n\nprint(X)\nprint(\"************\")\nprint(Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#finish all data things \n\n#from sklearn.preprocessing import StandardScaler\n#scaler = StandardScaler()\n#X_train = scaler.fit_transform(X_train)\n#X_test = scaler.transform(X_test)\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel = Sequential([\n    Dense(10, activation='relu',input_shape=(4,)),\n    Dense(8,  activation='relu'),\n    Dropout(0.0),\n    Dense(1,activation='relu'),\n])\n\nopt= keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.9, beta_2=0.999, amsgrad=False)\n\nmodel.compile(optimizer='adam', loss=\"mean_squared_error\",metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training = model.fit(X_train, Y_train, epochs=100, batch_size=40, validation_split=0.2, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_acc = np.mean(training.history['val_accuracy'])\nprint(\"val_accuracy \",\"%.3f\"%(val_acc*100),\"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(training.history['accuracy'])\nplt.plot(training.history['val_accuracy'])\nplt.title('accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(lyrs=[10,8], act='relu', opt= keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.9, beta_2=0.999, amsgrad=False), dr=0.0):\n    \n    # set random seed for reproducibility\n    seed(42)\n    tensorflow.random.set_seed(42)\n    \n    model = Sequential()\n    \n    # create first hidden layer\n    model.add(Dense(lyrs[0], input_dim=X_train.shape[1], activation=act))\n    \n    # create additional hidden layers\n    for i in range(1,len(lyrs)):\n        model.add(Dense(lyrs[i], activation=act))\n    \n    # add dropout, default is none\n    model.add(Dropout(dr))\n    \n    # create output layer\n    model.add(Dense(1, activation='relu'))  # output layer\n    opt.lr=0.0002\n    model.compile(loss=\"mean_squared_error\", optimizer=opt, metrics=['accuracy'])\n    \n    return model\n\nmodel = create_model()\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.model_selection import GridSearchCV\n\nmodel = KerasClassifier(build_fn=create_model, epochs=50, batch_size=40, verbose=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drops = [0.0, 0.01, 0.05,0.1]\nparam_grid = dict(dr=drops)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, verbose=1)\ngrid_result = grid.fit(X_train, Y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(\"Best: %f using %s\" % (grid_result.best_score_*100, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"activation = ['linear','sigmoid','relu']\nparam_grid = dict(act=activation)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, verbose=0)\ngrid_result = grid.fit(X_train, Y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(\"Best: %f using %s\" % (grid_result.best_score_*100, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(lyrs=[10,8], act='relu', opt= keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.9, beta_2=0.999, amsgrad=False), dr=0.0):\n    \n    # set random seed for reproducibility\n    seed(42)\n    tensorflow.random.set_seed(42)\n    \n    model = Sequential()\n    \n    # create first hidden layer\n    model.add(Dense(lyrs[0], input_dim=X_train.shape[1], activation=act))\n    \n    # create additional hidden layers\n    for i in range(1,len(lyrs)):\n        model.add(Dense(lyrs[i], activation=act))\n    \n    # add dropout, default is none\n    model.add(Dropout(dr))\n    \n    # create output layer\n    model.add(Dense(1, activation='relu'))  # output layer\n    #opt.lr=0.0002\n    model.compile(loss=\"mean_squared_error\", optimizer=opt, metrics=['accuracy'])\n    \n    return model\n\nmodel = create_model()\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nmodel = KerasClassifier(build_fn=create_model, epochs=50, batch_size=40, verbose=0)\n\n# define the grid search parameters\noptimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Nadam']\n\nparam_grid = dict(opt=optimizer)\n\n# search the grid\n\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, verbose=1)\ngrid_result = grid.fit(X_train, Y_train)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(\"Best: %f using %s\" % (grid_result.best_score_*100, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel = create_model(lyrs=[10,8], act='linear', opt=keras.optimizers.Nadam(learning_rate=0.0002, beta_1=0.9, beta_2=0.999) , dr= 0.1)\n\n\nprint(model.summary())\n\ntraining = model.fit(X_train, Y_train, epochs=50, batch_size=32, \n                     validation_split=0.2, verbose=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_acc = np.mean(training.history['val_accuracy'])\nprint(\"val_accuracy \",\"%.3f\"%(val_acc*100),\"%\")\n\nplt.plot(training.history['accuracy'])\nplt.plot(training.history['val_accuracy'])\nplt.title('accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nscores = model.evaluate(X_test, Y_test)\nprint(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}