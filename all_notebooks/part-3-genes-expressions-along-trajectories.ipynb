{"cells":[{"metadata":{},"cell_type":"markdown","source":"# What is about \n\nThe main aim of the present notebook is to produce plot for genes expressions changing along trajectories (found in previous parts).\n\n\nPS\n\nJust for info PAM50 list of genes can be found at the end of the notebook.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#pd.set_option('display.max_rows', 500)\n#pd.set_option('display.max_columns', 500)\n#pd.set_option('display.width', 1000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Example of using ClinTrajan"},{"metadata":{},"cell_type":"markdown","source":"# Part 1. Quantification of Data"},{"metadata":{},"cell_type":"markdown","source":"### Importing/installing libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nfrom scipy.stats import mode\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom importlib import reload  \nimport scipy.stats\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install lifelines\nfrom lifelines import KaplanMeierFitter\nfrom lifelines.utils import concordance_index\n!pip install  --no-dependencies  git+https://github.com/j-bac/elpigraph-python.git\nimport elpigraph\n!pip install trimap\n\nimport sys\nsys.path.insert(0,'/kaggle/input/breast-cancer-omics-bulk-data/code/')# \"/path/to/your/package_or_module\")\nprint(sys.path)\n\nfrom clintraj_qi import *\nfrom clintraj_eltree import *\nfrom clintraj_util import *\nfrom clintraj_ml import *\nfrom clintraj_optiscale import *","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading data (categorical variables are assumed to be dummy-encoded already)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load omics data\ndf1 = pd.read_csv('/kaggle/input/breast-cancer-omics-bulk-data/METABRIC.txt', sep = '\\t', index_col = 0)\ndf1=df1.T\ni1 = [s.replace('BRCA-METABRIC-S1-','') for s in df1.index ]\n#print('number of common ids:', len(set(i2) & set(df1.index) ) )\ndf1.index = i1\ndf1\n# load clinical data\ndf2 = pd.read_csv('/kaggle/input/breast-cancer-omics-bulk-data/METABRIC_clinical.txt', sep = '\\t')#, index_col = 0)\ndf2 = df2.set_index('Patient ID')\ndf2\ndf = df2.join(df1, how = 'inner')\nprint('Joined data shape', df.shape)\ndf\nm = df['Relapse Free Status'].notnull()\nprint( m.sum() )\ndf = df[m].copy()\ndf['Relapse Free Status'] = df['Relapse Free Status'].map({'0:Not Recurred':0,'1:Recurred':1 } )\nprint(df.shape)\ndisplay(df.head())\n\ndf_full = df.copy()\ndf = df.iloc[:,37:] # OMICS data only","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(df)\nquantify_nans(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing \n\nCut 1000 top variance variables \n\nStep is intended to use for gene expression data , so we leave 1000 out of dozen thousands of gene expressions \n\n\nDetect variable types\n\nQuantify (and optimize) the ordinal variables via optimal scaling\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_var = df.values.var(axis = 0)\nprint( X_var.shape, X_var[:5] )\nix = np.argsort(X_var)\ndf = df.iloc[:,ix[-1000:]]\nprint(df.shape)\n\n# Detect variable types\nvariable_types, binary, continuous, ordinal = detect_variable_type(df,10,verbose=False)\n# All variables for current data will be recognized as \"continous\"\nprint( type(variable_types), type(binary), type(continuous), type(ordinal) ) # All are list\nprint( variable_types[:3], binary[:3], continuous[:3], ordinal[:3] )\nprint()\n\n\n#Now we quantify (and optimize) the ordinal variables via optimal scaling\n# Now, we are ready to quantify the data table. We will do it by applying optimal scaling to the ordinal values.\ndf = remove_constant_columns_from_dataframe(df)\nvariable_names = [str(s) for s in df.columns[0:]]\nX = df.to_numpy().copy()\nX_original = X.copy()\nX_before_scaling = X.copy()\nX,cik = optimal_scaling(X,variable_types,verbose=True,vmax=0.6)\nX_save = X.copy()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = 'Pam50 + Claudin-low subtype' #   'pam50_+_claudin-low_subtype'\nvec4color = df_full[f]\n\nfrom sklearn.decomposition import PCA\nimport seaborn as sns\nimport matplotlib.pyplot as plt\npca = PCA\nr = pca().fit_transform(X = X )\nplt.figure(figsize = (20,10))\nsns.scatterplot( x=r[:,0], y=r[:,1], hue = vec4color )\nplt.title('PCA for Omics data colored by Pam50 groups')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### OK, we finished preparing the data matrix X, which is now complete and properly quantified. We also keep the 'original matrix' X_original, with 'raw' values of the variables (will be needed for visualizations)"},{"metadata":{"trusted":true},"cell_type":"code","source":"'ERBB2' in df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'EGFR' in df.columns,'EGFR' in df_full.columns, ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'ERBB3' in df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part 2. Computing the principal tree"},{"metadata":{},"cell_type":"markdown","source":"## Visualization function"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\ntry :\n    import umap\nexcept:\n    print('cannot import umap')\n\ndef plot_graph(edges, nodes_positions, data = None, dim_reduction = 'PCA', graph_color = 'black', graph_linewidth=2, \n               plot_data = True, data_linewidth = 1,  data_color = 'tab:red', data_transparency_alpha = 0.9,\n               showNodeNumbers = True, # Shows text with internal number of each node\n               umap_n_neighbors = 50, umap_min_dist = 0.99):\n  '''\n  #' Plots graphs defined by edges and nodes_positions, optionally - scatter plot the \"data\" on the same plot,\n  #' Optionally performs PCA/etc (depending on dim_reduction)\n  #'\n  #' @param edges Nx2-shape matrix with edges ends, i.e. edges[k,0], edges[k,1] - ends of k-th edge  \n  #' @param nodes_positions  matrix of nodes positions \n  #' @param data  \"original dataset\", basically arbitrary dataset for scatter plot, it should have same shape[1] as nodes_positions\n  #' @param plot_data  True/False - to scatterplot or not data\n  #' @param dim_reduction  'PCA', 'plot_first2axis', 'umap'\n  #' @param data_color can be a vector or predefined color - argument for c = data_color in scatter\n\n  #' @examples\n  # edges = np.array([ [0,1],[1,2],[2,0] ] )\n  # nodes_positions = np.random.rand(3,10) # 3 points in 10d space\n  # plot_graph(edges, nodes_positions)\n  #\n  # t = elpigraph_output\n  # edges = t[0]['Edges'][0]\n  # nodes_positions = t[0]['NodePositions']\n  # plot_graph(edges, nodes_positions)\n  '''\n  str_dim_reduction = dim_reduction\n  if dim_reduction in ['PCA', 'umap' ]: #  not 'plot_first2axis':\n    if dim_reduction.upper() == 'PCA':\n      reducer = PCA()\n    elif dim_reduction.lower() == 'umap':\n      n_neighbors = umap_n_neighbors#  50\n      min_dist= umap_min_dist # 0.99\n      #n_components=n_components\n      reducer = umap.UMAP( n_neighbors=n_neighbors,        min_dist=min_dist, n_components = 2)\n\n    if data is not None:\n      data2 = reducer.fit_transform(data)\n      if plot_data == True:\n        if data_color is None:\n          plt.scatter(data2[:,0],data2[:,1], linewidth = data_linewidth , alpha = data_transparency_alpha)# ,cmap=plt.cm.Paired) # ,c=np.array(irx) \n          plt.xlabel(str_dim_reduction+'1')\n          plt.ylabel(str_dim_reduction+'2')\n        else:\n          #plt.scatter(data2[:,0],data2[:,1] ,cmap=plt.cm.Paired,c= data_color, linewidth = data_linewidth, alpha = data_transparency_alpha ) \n          sns.scatterplot( x=data[:,0], y=data[:,1], hue = data_color )\n\n          plt.xlabel(str_dim_reduction+'1')\n          plt.ylabel(str_dim_reduction+'2')\n    else:\n      reducer.fit(nodes_positions)\n\n    nodes_positions2 = reducer.transform( nodes_positions )\n  else:\n    if plot_data == True:\n      if data is not None:\n        if data_color is None:\n          plt.scatter(data[:,0],data[:,1] , linewidth = linewidth, alpha = data_transparency_alpha )# ,cmap=plt.cm.Paired) # ,c=np.array(irx) \n        else:\n          plt.scatter(data[:,0],data[:,1] ,cmap=plt.cm.Paired,c= data_color , linewidth = data_linewidth, alpha = data_transparency_alpha ) \n          #sns.scatterplot( x=data[:,0], y=data[:,1], hue = data_color )\n\n    nodes_positions2 = nodes_positions\n\n  plt.scatter(nodes_positions2[:,0],nodes_positions2[:,1],c = graph_color, linewidth = graph_linewidth)#, cmap=plt.cm.Paired)\n\n  edgeCount = edges.shape[0]\n  for k in range(edgeCount):\n    n0 = edges[k,0]\n    n1 = edges[k,1]\n    x_line = [ nodes_positions2[n0,0],  nodes_positions2[n1,0] ]\n    y_line = [ nodes_positions2[n0,1],  nodes_positions2[n1,1] ]\n    plt.plot(x_line, y_line, graph_color, linewidth = graph_linewidth) # 'black')\n\n  if showNodeNumbers:\n    for i in range(nodes_positions2.shape[0]):\n      plt.text(nodes_positions2[i,0],nodes_positions2[i,1],str(i),FontSize=20,bbox=dict(facecolor='grey', alpha=0.5))    \n    \nedges = np.array([ [0,1],[1,2],[2,0] ] )\nnodes_positions = np.random.rand(3,10) # 3 points in 10d space\nplot_graph(edges, nodes_positions)\nplt.title('Example graph plot with  plot_graph function')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## First of all, we will reduce the dimension using PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X_save.copy()\nX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduced_dimension = 30\nX = scipy.stats.zscore(X)\n\nX_save_after_zscore = X.copy()\n\npca = PCA(n_components= reduced_dimension, svd_solver='full' ) # )#,svd_solver='full') # reduced_dimension ) #\nY = pca.fit_transform(X)\nv = pca.components_.T\nmean_val = np.mean(X,axis=0)\nX = Y[:,0:reduced_dimension]\nX.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## We are ready to compute the principal tree, let us do it"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"#import sys\n#print(sys.path)\n#sys.path.append('/home/zinovyev/anaconda3/lib/python3.7/site-packages')\n#print(sys.path)\n\nnnodes = 20\ntree_elpi = elpigraph.computeElasticPrincipalTree(X,nnodes, # drawPCAView=True,\n                                                  alpha=0.01,Mu=0.1,Lambda=0.05,\n                                                  FinalEnergy='Penalized')\ntree_elpi = tree_elpi[0]\n# some additional pruning of the graph\nprune_the_tree(tree_elpi)\n\ntree_save = tree_elpi\n# extend the leafs to reach the extreme data points\ntree_extended = ExtendLeaves_modified(X, tree_elpi, Mode = \"QuantDists\", ControlPar = .5, DoSA = False)\n#tree_extended = tree_elpi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = 'Pam50 + Claudin-low subtype' #   'pam50_+_claudin-low_subtype'\nvec4colors = df_full[f].values\n\n\ntree = tree_extended\n#nodes_positions = tree['NodePositions'] # ['AllNodePositions'][k]\n#matrix_edges_weights = tree['ElasticMatrix'] # ['AllElasticMatrices'][k]\n#matrix_edges_weights = np.triu(matrix_edges_weights,1 )\n#edges = np.array( np.nonzero(matrix_edges_weights), dtype = int ).transpose()    \nnodes_positions = tree['NodePositions']\nedges = tree['Edges'][0]\n\nplt.figure(figsize = (20,15))\n#plot_graph(edges, nodes_positions, data = X , data_color = 'tab:blue', data_transparency_alpha = 0.3 )\nplot_graph(edges, nodes_positions, data = X , data_color = vec4colors) # df[f]) # 'tab:blue', data_transparency_alpha = 0.3 )\nplt.title('PCA for METABRIC dataset and PAM50(+Claudin-low) subtypes', fontsize =15)\nplt.grid()\nplt.legend( fontsize =15 )\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"root_node = 20\nall_trajectories,all_trajectories_edges = extract_trajectories(tree_extended,root_node)\nprint(len(all_trajectories),' trajectories found.')\nProjStruct = project_on_tree(X,tree_extended)\nPseudoTimeTraj = quantify_pseudotime(all_trajectories,all_trajectories_edges,ProjStruct)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = 'ERBB3'\n# f = 'Pam50 + Claudin-low subtype' #   'pam50_+_claudin-low_subtype'\nvec4colors = df_full[f].values\n\n\ntree = tree_extended\n#nodes_positions = tree['NodePositions'] # ['AllNodePositions'][k]\n#matrix_edges_weights = tree['ElasticMatrix'] # ['AllElasticMatrices'][k]\n#matrix_edges_weights = np.triu(matrix_edges_weights,1 )\n#edges = np.array( np.nonzero(matrix_edges_weights), dtype = int ).transpose()    \nnodes_positions = tree['NodePositions']\nedges = tree['Edges'][0]\n\nplt.figure(figsize = (20,15))\n#plot_graph(edges, nodes_positions, data = X , data_color = 'tab:blue', data_transparency_alpha = 0.3 )\nplot_graph(edges, nodes_positions, data = X , data_color = vec4colors) # df[f]) # 'tab:blue', data_transparency_alpha = 0.3 )\nplt.title('Colored by ' + f, fontsize =15)\nplt.grid()\nplt.legend( fontsize =15 )\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xbig = X_save_after_zscore\nNodePositions2 = pca.inverse_transform(tree_extended['NodePositions'])\n\npartition, dists = elpigraph.src.core.PartitionData(X = Xbig, NodePositions = NodePositions2,\n                                                        MaxBlockSize = 100000000, TrimmingRadius = np.inf,\n                                                        SquaredX = np.sum(Xbig**2,axis=1,keepdims=1)) \n\nnodes4data = NodePositions2[partition.ravel(),:]\nnodes4data.shape\n\nD = Xbig - nodes4data\ner = np.sum(D**2, axis = 0)/D.shape[0]\nr2 = 1- er/np.var(Xbig,axis = 0)\nprint(r2.shape)\n#plt.plot(np.sort(r2))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,4))\ndf_stat = pd.DataFrame()\nfor i,pstt in enumerate(PseudoTimeTraj):\n    if len(all_trajectories_edges[i]) == 0: continue \n    #if i == 0: continue \n    #if i == 1: continue \n        \n    TrajName = 'Trajectory:'+str(pstt['Trajectory'][0])+'--'+str(pstt['Trajectory'][-1])\n    points = pstt['Points']\n    print( TrajName )\n    \n    DT = D[points,:]\n    \n    er = np.sum(DT**2, axis = 0)/DT.shape[0]\n    r2 = 1- er/np.var(Xbig[points,:],axis = 0)\n    \n    r2b = pd.Series(r2, index = df.columns ) \n    r2b = r2b.sort_values(ascending=False )\n    print(r2.shape)\n    \n    n_top = 1000\n    \n    plt.plot(np.sort(r2)[-n_top:], '*-', label = TrajName )\n    plt.title('r2 for top ' + str(n_top)+ ' genes ')\n    plt.grid()\n    plt.legend()\n    \n    df_stat.loc[:,TrajName] = r2b.index[:50]\n    df_stat.loc[:,TrajName+' r2'] = r2b.values[:50]\n    #break\n    \ndf_stat    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = 'Pam50 + Claudin-low subtype' #   'pam50_+_claudin-low_subtype'\nf = 'FOXA1' #  # FOXA1, CDC20, C1S, ESR1, CCL15, TFF3 CXCL12\n\nvec4colors = df_full[f].values\n\ntree = tree_extended\n#nodes_positions = tree['NodePositions'] # ['AllNodePositions'][k]\n#matrix_edges_weights = tree['ElasticMatrix'] # ['AllElasticMatrices'][k]\n#matrix_edges_weights = np.triu(matrix_edges_weights,1 )\n#edges = np.array( np.nonzero(matrix_edges_weights), dtype = int ).transpose()    \nnodes_positions = tree['NodePositions']\nedges = tree['Edges'][0]\n\nplt.figure(figsize = (20,10))\n#plot_graph(edges, nodes_positions, data = X , data_color = 'tab:blue', data_transparency_alpha = 0.3 )\nplot_graph(edges, nodes_positions, data = X , data_color = vec4colors) # df[f]) # 'tab:blue', data_transparency_alpha = 0.3 )\nplt.title('Colored by ' + f, fontsize =15)\nplt.grid()\nplt.legend( fontsize =15 )\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_name = 'FOXA1'\n#for  col_name in [ 'FOXA1', 'CDC20', 'C1S', 'ESR1', 'CCL15', 'TFF3', 'CXCL12']:\n#for  col_name in [ 'ERBB2', 'ERBB3']:\n# Ну ладно, хрен с ними. Предлагаю сделать рисунок в статью с такими генами - ESR1, FOXA1, ERBB2, CDC20, C1S\n\n# 'FOXA1'\n#  мощный транскрипционный фактор в дифференцировке клеток, связан с гормоном эстрогена\n# Но про него известно что он по разному себя ведет в подтипах рака груди, поэтому он и в PAM50\n\ncol_vec = ['blue','orange' ,'green']\n\nfig = plt.figure(figsize = (20,20))\nc = 0\n\nfor  col_name in ['ESR1', 'FOXA1', 'ERBB2', 'CDC20', 'C1S' ]: # 'PLAC9', 'SFRP1']: #  'CAV1', 'OSR1']:\n\n    c+=1; fig.add_subplot(5, 1 , c) \n    ix = list(df.columns).index(col_name)\n\n\n    ii = -1\n    for i,pstt in enumerate(PseudoTimeTraj):\n        if len(all_trajectories_edges[i]) == 0: continue \n        #if i == 0: continue \n        #if i == 1: continue \n        ii += 1\n        \n        TrajName = 'Trajectory:'+str(pstt['Trajectory'][0])+'--'+str(pstt['Trajectory'][-1])\n        points = pstt['Points']\n        print( TrajName )\n\n        v = Xbig[points, ix]\n\n        d = pd.DataFrame( )\n        d[col_name] = v\n        d['Pseudotime'] =  pstt['Pseudotime']\n        d = d.sort_values('Pseudotime')\n        #break\n\n        plt.plot(d['Pseudotime'] , d[col_name], label = TrajName, color = col_vec[ii]  )\n        plt.plot( range(len(pstt['Trajectory'])),  NodePositions2[ pstt['Trajectory'],ix ]  , color = col_vec[ii] , linewidth = 10 )\n        \n        if c == 1:\n            plt.legend(fontsize = 15)\n        plt.grid()\n        plt.title(col_name, fontsize = 25)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PAM50 genes list\n\nSee : \n\nhttps://www.biostars.org/p/77590/\n\nhttps://www.kaggle.com/alexandervc/breast-cancer-omics-bulk-data/discussion/211259#1185668\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# version 1, later check that it is the same as version 2 - so correct\n\nl50 =['UBE2T',\n'BIRC5',\n'NUF2',\n'CDC6',\n'CCNB1',\n'TYMS',\n'MYBL2',\n'CEP55',\n'MELK',\n'NDC80',\n'RRM2',\n'UBE2C',\n'CENPF',\n'PTTG1',\n'EXO1',\n'ORC6L',\n'ANLN',\n'CCNE1',\n'CDC20',\n'MKI67',\n'KIF2C',\n'ACTR3B',\n'MYC',\n'EGFR',\n'KRT5',\n'PHGDH',\n'CDH3',\n'MIA',\n'KRT17',\n'FOXC1',\n'SFRP1',\n'KRT14',\n'ESR1',\n'SLC39A6',\n'BAG1',\n'MAPT',\n'PGR',\n'CXXC5',\n'MLPH',\n'BCL2',\n'MDM2',\n'NAT1',\n'FOXA1',\n'BLVRA',\n'MMP11',\n'GPR160',\n'FGFR4',\n'GRB7',\n'TMEM45B',\n'ERBB2',]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(l50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# version 2, later check that it is the same as version 1 - so correct\n\nl50b = ['ACTR3B' , 'ANLN' , 'BAG1' , 'BCL2' , 'BIRC5' , 'BLVRA' , 'CCNB1' , 'CCNE1' , 'CDC20' , 'CDC6' , 'CDH3' , 'CENPF' , 'CEP55' , 'CXXC5' , 'EGFR' , 'ERBB2' , 'ESR1' , 'EXO1' , 'FGFR4' , 'FOXA1' , 'FOXC1' , 'GPR160' , 'GRB7' , 'KIF2C' , 'KRT14' , 'KRT17' , 'KRT5' , 'MAPT' , 'MDM2' , 'MELK' , 'MIA' , 'MKI67' , 'MLPH' , 'MMP11' , 'MYBL2' , 'MYC' , 'NAT1' , 'NDC80' , 'NUF2' , 'ORC6L' , 'PGR' , 'PHGDH' , 'PTTG1' , 'RRM2' , 'SFRP1' , 'SLC39A6' , 'TMEM45B' , 'TYMS' , 'UBE2C' , 'UBE2T']\nlen(l50b)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check coincidence \nlen ( set(l50) & set(l50b) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}