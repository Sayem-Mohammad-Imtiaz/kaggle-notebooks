{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import LinearSVC\nfrom sklearn.neural_network import MLPClassifier\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nimport random\nimport os\n\npd.set_option('max_columns',None)\npd.options.display.width = 2000\npd.set_option('display.max_colwidth', -1)\nnp.set_printoptions(threshold=np.nan)\nnp.set_printoptions(suppress=True)\nprint(os.listdir(\"../input\"))\n\ndf_kp = pd.read_csv(\"../input/Youtube02-KatyPerry.csv\")\ndf_em = pd.read_csv(\"../input/Youtube04-Eminem.csv\")\ndf_psy = pd.read_csv(\"../input/Youtube01-Psy.csv\")\ndf_sh = pd.read_csv(\"../input/Youtube05-Shakira.csv\")\ndf_lm = pd.read_csv(\"../input/Youtube03-LMFAO.csv\")\n\ndf_main = pd.concat([df_kp,df_em,df_psy,df_sh,df_lm], ignore_index=True, verify_integrity=True)\nprint(\"Total size of dataset\",len(df_main))\n#print(\"Null values\",df_main.isnull().sum())\ndisplay(df_main.head())\ndf_tr,df_te = train_test_split(df_main,train_size=0.7,test_size=0.3)\nprint(\"Train & Test size\",df_tr.shape[0],df_te.shape[0])\n\ncount_vec = CountVectorizer(stop_words=\"english\",lowercase=True) #,ngram_range=(1,3) reduced accuracy\ncount_mat = count_vec.fit_transform(df_tr[\"CONTENT\"])\ntf_idf_transform = TfidfTransformer(use_idf=True) #,sublinear_tf=True\ntr_tf_idf = tf_idf_transform.fit_transform(count_mat) #(1369, 3214)\n\ncount_mat_te = count_vec.transform(df_te[\"CONTENT\"])\ntf_idf_te = tf_idf_transform.transform(count_mat_te)\nprint(\"vector shape\",tr_tf_idf.shape)\n#Naive-Bayes\nclf = MultinomialNB().fit(tr_tf_idf, df_tr[\"CLASS\"])\ny = clf.predict(tf_idf_te)\nprint(\"Bayesian Accuracy\",np.mean(np.squeeze(np.asarray(df_te[\"CLASS\"].values)) == y)*100)\n#df_res = pd.DataFrame({\"Comment\":df_te[\"CONTENT\"],\"PredClass\":y,\"RealClass\":df_te[\"CLASS\"]})\n#display(df_res[df_res[\"PredClass\"] != df_res[\"RealClass\"]])\n\n#Linear SVC\nsvc_clf = LinearSVC()\nsvc_clf.fit(tr_tf_idf,df_tr[\"CLASS\"])\ny = svc_clf.predict(tf_idf_te)\nprint(\"SVC Accuracy\",np.mean(np.squeeze(np.asarray(df_te[\"CLASS\"].values)) == y)*100)\n\n#Try NLTK,stemming,gensim word2Vec\n\n#Neural Net\nclf = Sequential()\nclf.add(Dense(4000,input_shape=(tr_tf_idf.shape[1],)))\nclf.add(Dense(1000))\nclf.add(Dense(1, activation='sigmoid'))\nclf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nclf.fit(tr_tf_idf,df_tr[\"CLASS\"],epochs=9,verbose=1)\nscores = clf.evaluate(tf_idf_te,df_te[\"CLASS\"])\nprint(\"NN Accuracy\",scores[1]*100)\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}