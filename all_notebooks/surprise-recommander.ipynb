{"cells":[{"metadata":{"trusted":true,"_uuid":"61530c2858ba555b38438a2001673cd4158b9f01"},"cell_type":"code","source":"import time\nimport datetime\nimport random\n\nimport numpy as np\nimport six\nfrom tabulate import tabulate\n\nfrom surprise import Dataset\nfrom surprise.model_selection import cross_validate\nfrom surprise.model_selection import KFold\nimport numpy as np\nimport pandas as pd\nfrom scipy import sparse\nfrom time import time\nfrom numpy import matrix\nfrom numpy.random import rand\nimport re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c911f3f787887ed0f63ccd8453a8ab737f73ed68"},"cell_type":"code","source":"%%time\ndef load_and_clean (): \n    anime =  pd.read_csv(\"../input/anime.csv\", sep=\",\")\n    rating = pd.read_csv(\"../input/rating.csv\", sep=\",\")\n    \n    anime[\"episodes\"] = anime[\"episodes\"].map(lambda x:np.nan if x==\"Unknown\" else x)\n    anime[\"type\"] = anime[\"type\"].map(lambda x:np.nan if x==\"Unknown\" else x)\n    anime[\"genre\"] = anime[\"genre\"].map(lambda x:np.nan if x==\"Unknown\" else x)\n    anime[\"episodes\"].fillna(anime[\"episodes\"].median(),inplace = True)\n    anime[\"name\"] = anime[\"name\"].map(lambda name:re.sub('[^A-Za-z0-9]+', \" \", name))\n    anime[\"rating\"] = anime[\"rating\"].astype(float) \n    anime.rating.replace({-1: np.nan}, regex=True, inplace = True)\n    rating.rating.replace({-1: np.nan}, regex=True, inplace = True)\n    rating.dropna(inplace = True)\n    \n    return anime, rating\n\nanime, rating  = load_and_clean()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c94119a68e18a2b5e3993dd7813dac30f2e82c5c"},"cell_type":"code","source":"def merge_it_all(df1, df2, n_sample) :\n    df = pd.merge(df1, df2, left_on =\"anime_id\", right_on = \"anime_id\")\n    df = df[df[\"user_id\"] <= n_sample]\n    return df\n\ndf = merge_it_all(anime, rating, 5000)\n\ndef get_unbiased_rating(df) : \n    users_interactions_count_df = df.groupby(['user_id', 'anime_id']).size().groupby('user_id').size()\n    print('# users: %d' % len(users_interactions_count_df))\n    users_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 8].reset_index()[['user_id']]\n    print('# users with at least 8 interactions: %d' % len(users_with_enough_interactions_df))\n    print('# of interactions: %d' % len(df))\n    interactions_from_selected_users_df = df.merge(users_with_enough_interactions_df, \n               how = 'right',\n               left_on = 'user_id',\n               right_on = 'user_id')\n    print('# of interactions from users with at least 8 interactions: %d' % len(interactions_from_selected_users_df))\n    popularity = interactions_from_selected_users_df.groupby('anime_id').size().reset_index(name='popularity')\n    interactions_full_df = pd.merge(popularity, interactions_from_selected_users_df)\n    interactions_full_df.rename({\"rating_y\" : \"user_rating\"}, inplace = True, axis = 1)\n    return interactions_full_df, interactions_from_selected_users_df\n\ninteractions_full_df, interactions_from_selected_users_df = get_unbiased_rating(df)\ninteractions_full_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"16594c9b2343157fe375ad10b2de57bb13af2842"},"cell_type":"code","source":"from surprise import Reader \nreader = Reader()\ndata = Dataset.load_from_df(interactions_full_df[['user_id', 'anime_id', 'user_rating']], reader)\ndata.split(n_folds=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"091182bdd69f25b3fd480370460ead6e25021983"},"cell_type":"code","source":"from surprise import NormalPredictor\nnormal_pred =  NormalPredictor()\nfrom surprise import BaselineOnly\nB0 =  BaselineOnly()\nfrom surprise import KNNBasic\nKNNbasic =  KNNBasic()\nfrom surprise import KNNWithMeans\nmean_knn = KNNWithMeans()\nfrom surprise import KNNBaseline\nKNNbaseline = KNNBaseline()\nfrom surprise import SVD\nsvd = SVD()\nfrom surprise import SVDpp\nsvdpp = SVDpp()\nfrom surprise import NMF\nNMF_model =  NMF()\nfrom surprise import SlopeOne\nSlop =  SlopeOne()\nfrom surprise import CoClustering\nCClus =  CoClustering()\n\nfrom surprise import evaluate\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32d5517da252f9da064e3a04b7818072b4cce0da"},"cell_type":"code","source":"for reco in [svdpp, Slop, CClus, KNNbaseline, mean_knn, \n             KNNbasic, NMF_model, normal_pred, B0] :\n    evaluate(reco, data, measures=['RMSE', 'MAE'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f99ce0c9b4cd4057228cf778721b403a41e65285"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}