{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade tensorflow","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nfrom glob import glob\nimport seaborn as sns\nfrom PIL import Image\nnp.random.seed(42)\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\nfrom sklearn.metrics import accuracy_score\nimport itertools\n\n\nimport keras\nfrom keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras import backend as K\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau, Callback\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.applications.resnet50 import ResNet50\nfrom keras import backend as K \n\n\nimport csv\nfrom keras.callbacks import Callback\nfrom sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, balanced_accuracy_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('../input/data/data/NR-ER-train')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"smiles_train = pd.read_csv('../input/data/data/NR-ER-train/names_labels.csv', names=[\"names\", \"label\"])\nsmiles_test = pd.read_csv('../input/data/data/NR-ER-test/names_labels.csv', names=[\"names\", \"label\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root = '/kaggle/input/data'\npath_train_names = root + '/data/NR-ER-train/names_onehots.npy'\npath_train_labels = root + '/data/NR-ER-train/names_labels.csv'\npath_test_names = root + '/data/NR-ER-test/names_onehots.npy'\npath_test_labels = root + '/data/NR-ER-test/names_labels.csv'\n\n# Write Lables from csv to onehot list\ndef construct_labels(path_to_file):\n        labels = []\n        with open(path_to_file) as csv_file:\n                csv_reader = csv.reader(csv_file, delimiter= ',')\n                for row in csv_reader:\n                        if int(row[1]) == 0:\n                                labels.append([1,0])\n                \n                        elif int(row[1]) == 1:\n                                labels.append([0,1])\n\n        return np.asarray(labels)\n\n# Write OneHots to list\ndef construct_names (path_to_file):\n        names = []\n        df = np.load(path_to_file, allow_pickle=True).tolist()\n        names = df.get('onehots')\n        return np.asarray(names).astype(np.float64)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = construct_labels(path_train_labels)\ny_test = construct_labels(path_test_labels)\n\nX_train = construct_names(path_train_names)\nX_test = construct_names(path_test_names)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=11)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = X_train.transpose(0,2,1)\nX_test = X_test.transpose(0,2,1)\nX_val = X_val.transpose(0,2,1)\n\nprint(X_train.shape)\nprint(X_val.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_val.shape)\nprint(y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.DataFrame(np.argmax(y_train, axis=-1))\ntrain_df.hist()\ntrain_df[0].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df = pd.DataFrame(np.argmax(y_val, axis=-1))\nval_df.hist()\nval_df[0].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils import class_weight\nclass_weight = class_weight.compute_class_weight('balanced', np.unique(np.argmax(y_train, axis=-1)), np.argmax(y_train, axis=-1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SpliceAI [1]\n[1] https://www.sciencedirect.com/science/article/pii/S0092867418316295","metadata":{}},{"cell_type":"code","source":"class ResBlock(tf.keras.layers.Layer):\n    def __init__(self, N, W, D):\n        super(ResBlock, self).__init__()\n        self.BN_1 = tf.keras.layers.BatchNormalization()\n        self.BN_2 = tf.keras.layers.BatchNormalization()\n        self.conv_1 = tf.keras.layers.Conv1D(N, W, dilation_rate=D, padding=\"same\")\n        self.conv_2 = tf.keras.layers.Conv1D(N, W, dilation_rate=D, padding=\"same\")\n\n    def call(self, inputs, training=None):\n        x = self.BN_1(inputs, training)\n        x = tf.keras.activations.relu(x)\n        x = self.conv_1(x)\n        x = self.BN_2(x, training)\n        x = tf.keras.activations.relu(x)\n        x = self.conv_2(x)\n\n        return x + inputs\n\n\nclass SpliceAI80(tf.keras.Model):\n    def __init__(self):\n        super(SpliceAI80, self).__init__()\n        self.conv_1 = tf.keras.layers.Conv1D(32, 1, dilation_rate=1)\n        self.conv_2 = tf.keras.layers.Conv1D(32, 1, dilation_rate=1)\n        self.conv_3 = tf.keras.layers.Conv1D(32, 1, dilation_rate=1)\n        self.conv_4 = tf.keras.layers.Conv1D(1, 1, dilation_rate=1)\n\n        self.block_1 = ResBlock(32, 11, 1)\n        self.block_2 = ResBlock(32, 11, 1)\n        self.block_3 = ResBlock(32, 11, 1)\n        self.block_4 = ResBlock(32, 11, 1)\n\n        self.crop = tf.keras.layers.Cropping1D(cropping=(41, 40))\n\n    def call(self, inputs):\n        x_1 = self.conv_1(inputs)\n\n        # main branch\n        x = self.block_1(x_1)\n        x = self.block_2(x)\n        x = self.block_3(x)\n        x = self.block_4(x)\n        x = self.conv_3(x)\n\n        # residual branch\n        x_1 = self.conv_2(x_1)\n\n        # come together\n        x = x + x_1\n        x = self.crop(x)\n        x = self.conv_4(x)\n        out = tf.keras.activations.sigmoid(x)\n\n        return out\n\n\nclass SpliceAI400(tf.keras.Model):\n    def __init__(self):\n        super(SpliceAI400, self).__init__()\n        self.conv_1 = tf.keras.layers.Conv1D(32, 1, dilation_rate=1)\n        self.conv_2 = tf.keras.layers.Conv1D(32, 1, dilation_rate=1)\n        self.conv_3 = tf.keras.layers.Conv1D(32, 1, dilation_rate=1)\n        self.conv_4 = tf.keras.layers.Conv1D(32, 1, dilation_rate=1)\n\n        # first blocks\n        self.block_1 = ResBlock(32, 11, 1)\n        self.block_2 = ResBlock(32, 11, 1)\n        self.block_3 = ResBlock(32, 11, 1)\n        self.block_4 = ResBlock(32, 11, 1)\n\n        # second blocks\n        self.block_5 = ResBlock(32, 11, 4)\n        self.block_6 = ResBlock(32, 11, 4)\n        self.block_7 = ResBlock(32, 11, 4)\n        self.block_8 = ResBlock(32, 11, 4)\n\n        self.pool = tf.keras.layers.GlobalAveragePooling1D()\n        self.fc = tf.keras.layers.Dense(2)\n\n    def call(self, inputs):\n        x = self.conv_1(inputs)\n        x_1 = self.conv_2(x)\n\n        # main branch\n        x = self.block_1(x)\n        x = self.block_2(x)\n        x = self.block_3(x)\n        x = self.block_4(x)\n        x_2 = self.conv_3(x)\n\n        x = self.block_5(x)\n        x = self.block_6(x)\n        x = self.block_7(x)\n        x = self.block_8(x)\n        x = self.conv_4(x)\n\n        # come together\n        x = x + x_1 + x_2\n        x = self.pool(x)\n        x = self.fc(x)\n        out = tf.keras.activations.softmax(x)\n\n        return out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SpliceAI400()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=['accuracy'])\n\ninput_shape = (1, *X_train.shape[1:])\nx = tf.random.normal(input_shape)\nmodel(x)\n\nprint(model.summary())\n\n# for this to succeed run `brew install graphviz && pip install pydot_ng`\ntf.keras.utils.plot_model(\n    model,\n    to_file='model.png',\n    show_shapes=False,\n    show_layer_names=True,\n    rankdir='TB',\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 30\nbatch_size = 256","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Balanced_Accuracy(tf.keras.callbacks.Callback):\n    def __init__(self, val_data, batch_size = 128):\n        super().__init__()\n        self.validation_data = val_data\n        self.batch_size = batch_size\n        \n    def on_train_begin(self, logs={}):\n        self._data = [] \n\n    def on_epoch_end(self, epoch, logs={}):\n        batches = len(self.validation_data)\n        total = batches * self.batch_size\n\n        xVal, yVal = self.validation_data\n        val_pred = np.argmax((self.model.predict(xVal, verbose= 0)), axis= 1)\n        val_true = np.argmax(yVal, axis= 1)\n            \n        val_pred = np.squeeze(val_pred)\n        _val_ba = balanced_accuracy_score(val_true, val_pred)\n        \n        print('val balanced accuracy: ', _val_ba)\n        self._data.append({'val_balanced_accuracy': _val_ba})\n        return\n\nbalanced_accuracy = Balanced_Accuracy((X_val, y_val), batch_size = batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_weights = {i: class_weight[i] for i in range(2)}\nhistory = model.fit(x= X_train, y=y_train, validation_data=(X_val, y_val), class_weight= class_weights,\n                    epochs= epochs, batch_size= batch_size, verbose=1, \n                    callbacks=[balanced_accuracy]\n                   )\n \n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import recall_score\npred_val = model.predict(X_val)\nprint(balanced_accuracy_score(np.argmax(y_val,  axis= -1), np.argmax(pred_val,  axis= -1)))\nprint(recall_score(np.argmax(y_val,  axis= -1), np.argmax(pred_val,  axis= -1)))\nprint(recall_score(np.argmax(y_val,  axis= -1), np.argmax(pred_val,  axis= -1), pos_label=0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(np.argmax(y_test,  axis= -1), np.argmax(y_pred,  axis= -1)))\nprint(balanced_accuracy_score(np.argmax(y_test,  axis= -1), np.argmax(y_pred,  axis= -1)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}