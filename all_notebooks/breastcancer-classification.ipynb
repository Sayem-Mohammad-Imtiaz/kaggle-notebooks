{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Goal:\n\nPredict whether the cancer is benign or malignant. \n\n### Short Description:\n\n\"Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.\"\n\nUCI ML Repository Link: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np \nimport pandas as pd \nimport xgboost\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split, cross_val_predict\nfrom sklearn.metrics import f1_score, precision_score, recall_score, classification_report, confusion_matrix\nimport os\n\ndef encodeBinaryLabel(val, one_val):\n    if pd.isna(val):\n        raise ValueError('Null value found!')\n    else:\n        if val == one_val:\n            return 1\n        else:\n            return 0\n\ndef evaluateBinaryClassifier(x_array, y_array, clf_model, use_cross_val=False, folds = 5):\n    try:\n        if use_cross_val == False:\n            clf_y_pred = clf_model.predict(x_array)\n        else:\n            clf_y_pred = cross_val_predict(clf_model, x_array, y_array, cv = folds)\n    except Exception as e:\n        print(e)\n        print(\"An error occurred while trying to execute the classification model's predict method.\")\n    try:\n        conf_mtrx = confusion_matrix(y_array, clf_y_pred)\n        precision = precision_score(y_array, clf_y_pred)\n        recall = recall_score(y_array, clf_y_pred)\n    except Exception as e:\n        print(e)\n        print(\"An error occurred while calling the metric methods.\")\n    eval_dict = {'conf_mtrx': conf_mtrx, 'precision': precision, 'recall': recall}\n    return eval_dict","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\n\ndf.columns = df.columns.str.lower().str.replace(' ', '_')\n\nprint('count(*): ' + str(len(df.index)) + '\\n')\n\nsns.countplot(x = 'diagnosis', data = df)\nplt.title('Counts by Diagnosis')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Binary Classification\n\nI'm just starting out with random forest and stochastic gradient descent. The model with the best evaluation results will be fitted to the whole training dataset then compared to results obtained from ensembling methods. \n\n#### Data Prep"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in df.columns:\n    if df[col].isnull().sum() > 0:\n        print(str(col) + ' null count: ' + str(df[col].isnull().sum()))\n\n# check for duplicate id's\nprint(\"Row count matches distinct count of id's?\", len(df.index) == len(df['id'].unique()))\n\n# convert diagnosis values to binary\ndf['labels'] = df['diagnosis'].apply(lambda x: encodeBinaryLabel(x, 'M'))\n\ndf = df.drop(labels = 'unnamed:_32', axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df.drop(labels=['id', 'diagnosis', 'labels'], axis = 1).values\ny = df['labels'].values\n\n# separate data into train and test sets\nseed = 7\nnp.random.seed(seed)\nx_train, x_test_val, y_train, y_test_val = train_test_split(x, y, test_size=0.3, random_state=seed)\nx_test, x_val, y_test, y_val = train_test_split(x_test_val, y_test_val, test_size = 0.5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Binary Classification Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest\nrf_clf = RandomForestClassifier(random_state=42)\n\n# Stochastic Gradient Descent\nsgd_clf = SGDClassifier(random_state = 42)\n\n# Logistic Regression\nlog_reg = LogisticRegression(random_state=42, max_iter=3000)\n\n# SVM\nsup_vec = SVC(random_state=42)\n\nprint('---- Random Forest ----')\nrf_scores = evaluateBinaryClassifier(x_array=x_train, y_array=y_train, clf_model=rf_clf, use_cross_val=True, folds=3)\nfor key, value in rf_scores.items():\n    print(str(key) + ': \\n', value)\n\nprint('---- Stochastic Gradient Descent ----')\nsgd_scores = evaluateBinaryClassifier(x_array=x_train, y_array=y_train, clf_model=sgd_clf, use_cross_val=True, folds=3)\nfor key, value in sgd_scores.items():\n    print(str(key) + ': \\n', value)\n\nprint('---- Logistic Regression ----')\nlog_reg_scores = evaluateBinaryClassifier(x_array=x_train, y_array=y_train, clf_model=log_reg, use_cross_val=True, folds=3)\nfor key, value in log_reg_scores.items():\n    print(str(key) + ': \\n', value)\n\nprint('---- SVM Classifier ----')\nsup_vec_scores = evaluateBinaryClassifier(x_array=x_train, y_array=y_train, clf_model=sup_vec, use_cross_val=True, folds=3)\nfor key, value in sup_vec_scores.items():\n    print(str(key) + ': \\n', value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_clf.fit(x_train, y_train)\nrf_y_val_pred = rf_clf.predict(x_val)\n\nlog_reg.fit(x_train, y_train)\nlr_y_val_pred = log_reg.predict(x_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Utilizing Ensemble Methods\n\n#### Adaboost"},{"metadata":{"trusted":true},"cell_type":"code","source":"ada_clf = AdaBoostClassifier(RandomForestClassifier(), n_estimators=200, learning_rate=0.5)\n\nada_clf.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ada_y_val_pred = ada_clf.predict(x_val)\n\nprint('------- AdaBoost -------')\nprint('Confusion Matrix: \\n', confusion_matrix(y_val, ada_y_val_pred))\nprint('Precision:', precision_score(y_val, ada_y_val_pred))\nprint('Recall:', recall_score(y_val, ada_y_val_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"xg_rf = xgboost.XGBRFClassifier()\nxg_rf.fit(x_train, y_train)\n\nxg_y_val_pred = xg_rf.predict(x_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Random Forest: ', f1_score(y_val, rf_y_val_pred))\nprint('Logistic Regression: ', f1_score(y_val, lr_y_val_pred))\nprint('AdaBoost w/ RF: ', f1_score(y_val, ada_y_val_pred))\nprint('XGBoost RF: ', f1_score(y_val, xg_y_val_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ada_y_test_pred = ada_clf.predict(x_test)\nrf_y_test_pred = rf_clf.predict(x_test)\nlr_y_test_pred = log_reg.predict(x_test)\n\nprint('Random Forest: ', f1_score(y_test, rf_y_test_pred))\nprint('Logistic Regression: ', f1_score(y_test, lr_y_test_pred))\nprint('AdaBoost w/ RF: ', f1_score(y_test, ada_y_test_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Exporting Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# exporting model \nimport pickle\n# preferred for sklearn\nfrom joblib import dump, load\nfrom datetime import datetime\n\ncurrent_dt = datetime.today().strftime('%Y-%m-%d').replace('-', '')\n\nif os.path.isfile('/kaggle/working/ada_breast_cancer_clf_{today}.joblib'.format(today = current_dt)) != True:\n    dump(ada_clf, '/kaggle/working/ada_breast_cancer_clf_{today}.joblib'.format(today = current_dt))\nelse:\n    print('Export already exists!')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! ls -l *.joblib","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# quick example of how we could use model for later\nold_model = load('/kaggle/working/ada_breast_cancer_clf_{today}.joblib'.format(today = current_dt))\n\nold_model.predict(x_test)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}