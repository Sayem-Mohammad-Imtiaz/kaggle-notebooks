{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Text Classification with HuggingFace & ktrain\n\nIn this notebook, we'll perform text classification on the [NY Room Rental Ads](https://www.kaggle.com/vaishnavivenkatesan/newyork-room-rentalads) dataset with **HuggingFace Transformer Model** using **ktrain**\n\n**ktrain** is a Python library that makes deep learning and AI more accessible and easier to apply.\n\n\nFollowing are some of the pre-trained Transformer Model that we'll use & calculate their accuracy \n\n* roberta-base\n* bert-base-uncased\n* distilbert-base-uncased\n* xlm-roberta-base\n\n\n**Note**: 0 = Vague & 1 = Not Vague\n\n\nAs always will keep this notebook well commented & organized for easy reading. Please do UPVOTE if you find it helpful :)"},{"metadata":{},"cell_type":"markdown","source":"## Libraries"},{"metadata":{"trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"# Install ktrain\n!pip install --upgrade pip -q\n!pip install -q ktrain","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Generic\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings, gc\nwarnings.filterwarnings(\"ignore\")\n\n# Tensorflow\nimport tensorflow as tf\n\n# ktrain\nimport ktrain\nfrom ktrain import text\n\n# sklearn\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Load\nurl = '../input/newyork-room-rentalads/room-rental-ads.csv'\ndf = pd.read_csv(url, header='infer')\n\n# Dropping Null Values\ndf.dropna(inplace=True)\n\n# Total Records\nprint(\"Total Records: \", df.shape[0])\n\n# Inspect\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Split\ntarget = ['Vague/Not']\ndata = ['Description']\n\nX = df[data]\ny = df[target]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.1, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Common Parameters\nmax_len = 500\nbatch_size = 6\nlearning_rate = 5e-5\nepochs = 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## With Transformer = Roberata-base"},{"metadata":{"trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"# Transformer Model\nmodel_ = 'roberta-base'\nt_mod = text.Transformer(model_, maxlen=max_len, classes = [0,1])\n\n\n'''Converting split data to list [so it can processed]'''\n#train\nX_tr = X_train['Description'].tolist()\ny_tr = y_train['Vague/Not'].tolist()\n\n#test\nX_ts = X_test['Description'].tolist()\ny_ts = y_test['Vague/Not'].tolist()\n\n\n# Pre-processing training & test data\ntrain = t_mod.preprocess_train(X_tr,y_tr)\ntest = t_mod.preprocess_train(X_ts,y_ts)\n\n# Model Classifier\nmodel = t_mod.get_classifier()\n\nlearner = ktrain.get_learner(model, train_data=train, val_data=test, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"# Train Model\nlearner.fit_onecycle(learning_rate, epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate\nx = learner.validate(class_names=t_mod.get_classes())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Accuracy of ~ 77% achieved with Roberta"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction\nclasses = ['Vague', 'Not Vague']\npredictor = ktrain.get_predictor(learner.model, preproc=t_mod)\npred_class = predictor.predict(X_test['Description'][67])\nprint(\"Predicted Class: \", classes[pred_class])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## With Transformer = bert-base-uncased"},{"metadata":{"_kg_hide-output":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"# Transformer Model\nmodel_ = 'bert-base-uncased'\nt_mod = text.Transformer(model_, maxlen=500, classes = [0,1])\n\n\n'''Converting split data to list [so it can processed]'''\n#train\nX_tr = X_train['Description'].tolist()\ny_tr = y_train['Vague/Not'].tolist()\n\n#test\nX_ts = X_test['Description'].tolist()\ny_ts = y_test['Vague/Not'].tolist()\n\n\n# Pre-processing training & test data\ntrain = t_mod.preprocess_train(X_tr,y_tr)\ntest = t_mod.preprocess_train(X_ts,y_ts)\n\n# Model Classifier\nmodel = t_mod.get_classifier()\n\nlearner = ktrain.get_learner(model, train_data=train, val_data=test, batch_size=6)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"# Train Model\nlearner.fit_onecycle(learning_rate, epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate\nx = learner.validate(class_names=t_mod.get_classes())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Accuracy of ~ 81% achieved with Bert"},{"metadata":{},"cell_type":"markdown","source":"## With Transformer = distilbert-base-uncased"},{"metadata":{"_kg_hide-output":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"# Transformer Model\nmodel_ = 'distilbert-base-uncased'\nt_mod = text.Transformer(model_, maxlen=500, classes = [0,1])\n\n\n'''Converting split data to list [so it can processed]'''\n#train\nX_tr = X_train['Description'].tolist()\ny_tr = y_train['Vague/Not'].tolist()\n\n#test\nX_ts = X_test['Description'].tolist()\ny_ts = y_test['Vague/Not'].tolist()\n\n\n# Pre-processing training & test data\ntrain = t_mod.preprocess_train(X_tr,y_tr)\ntest = t_mod.preprocess_train(X_ts,y_ts)\n\n# Model Classifier\nmodel = t_mod.get_classifier()\n\nlearner = ktrain.get_learner(model, train_data=train, val_data=test, batch_size=6)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"# Train Model\nlearner.fit_onecycle(learning_rate, epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate\nx = learner.validate(class_names=t_mod.get_classes())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Accuracy of ~ 71% achieved with DistilBert"},{"metadata":{},"cell_type":"markdown","source":"## With Transformer = xlm-roberta-base"},{"metadata":{"_kg_hide-output":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"# Transformer Model\nmodel_ = 'xlm-roberta-base'\nt_mod = text.Transformer(model_, maxlen=500, classes = [0,1])\n\n\n'''Converting split data to list [so it can processed]'''\n#train\nX_tr = X_train['Description'].tolist()\ny_tr = y_train['Vague/Not'].tolist()\n\n#test\nX_ts = X_test['Description'].tolist()\ny_ts = y_test['Vague/Not'].tolist()\n\n\n# Pre-processing training & test data\ntrain = t_mod.preprocess_train(X_tr,y_tr)\ntest = t_mod.preprocess_train(X_ts,y_ts)\n\n# Model Classifier\nmodel = t_mod.get_classifier()\n\nlearner = ktrain.get_learner(model, train_data=train, val_data=test, batch_size=6)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"# Train Model\nlearner.fit_onecycle(learning_rate, epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate\nx = learner.validate(class_names=t_mod.get_classes())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Accuracy of ~ 45% achieved with XLM-Roberta"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Garbage Collect\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hope that was helpful & gave you an idea of ktrain & using pre-trained HuggingFace Models."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}