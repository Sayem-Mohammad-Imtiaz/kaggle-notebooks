{"cells":[{"metadata":{"_uuid":"e787cb6bb0f544899eec229f7b75a3ceb4a8ee10"},"cell_type":"markdown","source":"This kernel describes step by step process to classify Spam message using Decision Tree algorithm"},{"metadata":{"_uuid":"fb1162b07edad904a91705a5e0d53d55c719777d"},"cell_type":"markdown","source":"# Data preprocessing and WordCloud"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport nltk\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom wordcloud import WordCloud\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import LabelEncoder\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/SPAM text message 20170820 - Data.csv')\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8fd8b7da43c6dd553ca476740b0fe80d1f69c714"},"cell_type":"code","source":"# get all spam and ham massage as list\nspam_data = df[df['Category']=='spam'].Message.tolist()\nham_data = df[df['Category']=='ham'].Message.tolist()\n# join all lists\nspam_data = ' '.join(spam_data)\nham_data = ' '.join(ham_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e59942f6931f367619dee72d304c6a511355a99"},"cell_type":"code","source":"# remove punctuation and stop words from data\npunctuation = string.punctuation\nstopwords = stopwords.words('english')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84d2d2bedbc93c57a49b144db0ac60849d734f92"},"cell_type":"code","source":"# remove punctuation\nfiltered_ham_data = ''.join(i for i in ham_data if i not in punctuation)\nfiltered_spam_data = ''.join(i for i in spam_data if i not in punctuation)\nfiltered_spam_data[:200]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b9a05e0064586e8457bfbf9a1bf22e38c8c3bb6"},"cell_type":"code","source":"# remove stopwords\nfiltered_ham_data = ' '.join(i for i in filtered_ham_data.lower().split() if i not in stopwords)\nfiltered_spam_data = ' '.join(i for i in filtered_spam_data.lower().split() if i not in stopwords)\nfiltered_spam_data[:200]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"661187854ccafa25becda2ac492ce112603d7127"},"cell_type":"code","source":"# lemmatizer\nlemmatizer = WordNetLemmatizer()\nfiltered_ham_data = ' '.join([lemmatizer.lemmatize(i) for i in filtered_ham_data.split()])\nfiltered_spam_data = ' '.join([lemmatizer.lemmatize(i) for i in filtered_spam_data.split()])\nfiltered_spam_data[:200]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"043223e2f2a84a681688583dfa4928374fe8ee1e"},"cell_type":"code","source":"# Generate WordCloud for Spam\nx, y = np.ogrid[:300, :300]\nmask = (x - 150) ** 2 + (y - 150) ** 2 > 130 ** 2\nmask = 255 * mask.astype(int)\n\nwc = WordCloud(max_font_size=40, max_words=200, background_color='white', random_state=1337, mask=mask).generate(filtered_spam_data)\nplt.figure(figsize=(10,10))\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.title(\"Spam Words\", fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b5b0a2d0859ee30363c76ea7d1e1a911dba1eb7"},"cell_type":"code","source":"# Generate WordCloud for Ham\nwc = WordCloud(max_font_size=40, max_words=200, background_color='white', random_state=1337).generate(filtered_ham_data)\nplt.figure(figsize=(10,10))\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.title(\"Ham Words\", fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59db2456b002e9f3fde68533ae0acd7ac60e882e"},"cell_type":"code","source":"def data_clean(msg):\n    w = ''.join(i for i in msg if i not in punctuation)\n    w = ' '.join(i for i in w.lower().split() if i not in stopwords)\n    lemmatizer = WordNetLemmatizer()\n    lem = ' '.join(lemmatizer.lemmatize(i) for i in w.split())\n    return lem","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"008f7062dc4b49be1be15f0c33437b4b8c44d104"},"cell_type":"code","source":"df['preprocess_message']=\"\"\nfor i in range(df['Message'].count()):\n    df['preprocess_message'][i]= data_clean(df['Message'][i])\n    #df.iloc[i]['preprocess_message']= df.iloc[i]['Message']\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51c6cf058ca4ba7867b56a1bf2c37bb2452151e7"},"cell_type":"markdown","source":"# Extract features by converting text message to vector matrix "},{"metadata":{"trusted":true,"_uuid":"2ef13a1a94bb2003b06a3ad0d4120984485c0c64"},"cell_type":"code","source":"cv = CountVectorizer()\ndata = cv.fit_transform(df.preprocess_message)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7be3daf9b0bae485ae83e5eda27e772359d2c67a"},"cell_type":"code","source":"le = LabelEncoder()\nlabel = le.fit_transform(df.Category)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15394b519d403b5a5a0a686a5502a2032cf65fb6"},"cell_type":"code","source":"print(df.shape, data.shape, label.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70b7d76a7ce7fb381548570d6692c68f1f447525"},"cell_type":"markdown","source":"# Train with Decision Tree"},{"metadata":{"trusted":true,"_uuid":"b86297441dd0fe99ece7617e38c39b6c816eb137"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, KFold\nfrom sklearn import tree\nfrom sklearn.metrics import mean_absolute_error as mae\ntrain_set_X, test_X, train_set_Y, test_Y = train_test_split(data, label, test_size=0.2)\n\nclf = tree.DecisionTreeClassifier(random_state=1337)\nclf.fit(train_set_X, train_set_Y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"469cf1b278d00677762ff51f25647e55426df8a5"},"cell_type":"markdown","source":"# Predict Test set accuracy"},{"metadata":{"trusted":true,"_uuid":"8d1cda3fa89eaf7b39acdafbbc7a86488a8196e7"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\ntest_pred = clf.predict(test_X)\nacc = accuracy_score(test_pred, test_Y)\nprint(\"Test accuracy {}\".format(acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2763fa0107b0c537730cd3495f198697a71aba3a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}