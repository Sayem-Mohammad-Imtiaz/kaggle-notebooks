{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Spam filtering using LR, SVM, NN and Decision trees"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing necessary packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn import tree","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/emails.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data  Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['text'].replace({'Subject:': ''}, inplace=True, regex=True)\nX=data['text']\ny=data['spam']\nvectorizer=CountVectorizer()\nX = vectorizer.fit_transform(X)\nprint(X.toarray())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,Y_train,Y_test=train_test_split(X, y, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Initiating models"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr=LogisticRegression()\nnb=GaussianNB()\nsvm=SVC(kernel='rbf')\nnn=NearestNeighbors(n_neighbors=2, algorithm='ball_tree')\ndt=tree.DecisionTreeClassifier()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training all 4 models"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr.fit(X_train,Y_train)\n# nb.fit(X_train,Y_train)\nsvm.fit(X_train,Y_train)\nnn.fit(X_train,Y_train)\ndt.fit(X_train,Y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction step"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_predicted=lr.predict(X_test)\nsvm_predicted=svm.predict(X_test)\nnn_predicted=nn.kneighbors(X_test)\ndt_predicted=dt.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classification arror for the 4 algos"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_cls_report=classification_report(Y_test,lr_predicted)\nsvm_cls_report=classification_report(Y_test,svm_predicted)\n# nb_cls_report=classification_report(Y_test,nb_predicted)\ndt_cls_report=classification_report(Y_test,dt_predicted)\nprint(\"Logistic regression : \"+lr_cls_report)\nprint(\"SVM : \"+svm_cls_report)\n# print(\"Naive Bayes : \"+nb_cls_report)\nprint(\"Decision tree : \"+dt_cls_report)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## All 4 algos have done ok but LR has achieved the best performance. You'll NB algo is commenting because it needs more memory resources(run on aws sagemaker) as compared the algos shown here. So, although NB is known to be the best algo for spam filtering, as per the code run above, it requires more resources. Don't know why? If you know, please comment/modify the code and let me know."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}