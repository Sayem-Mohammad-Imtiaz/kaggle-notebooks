{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport keras\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\n# calculate accuracy measures and confusion matrix\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score, auc\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### EDA & Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"#### 1. Read the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#importing the dataset, set RowNumber as index\n#load the csv file and make the data frame\ndf = pd.read_csv('/kaggle/input/bank-customer-churn-modeling/Churn_Modelling.csv',index_col='RowNumber')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape # 10,000 rows, 13 columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(2) #Exited is target column","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check datatypes\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Surname, Gender and Gepgraphy are Object type"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check for missing values\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" There is no missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"#look at distribution of exited and non-exited customers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"Exited\", data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data set has has only around 2000 exited customers and about 8000 Customers are still with Bank- it has bias towards existing customers."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"Gender\", data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bank has bout 4500 female customers and 5500 male customers"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"Geography\", data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the Customers are from France,  Customers from spain and Genrmany are about half in numbers of France"},{"metadata":{"trusted":true},"cell_type":"code","source":" sns.countplot(x=\"Exited\", hue=\"Gender\", data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Above plot says that female customers have higher propensity to exit the Bank"},{"metadata":{"trusted":true},"cell_type":"code","source":" sns.countplot(x=\"Exited\", hue=\"Geography\", data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Customers from Germany have highest propensity to to exit the Bank"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets Check Distribution of exited/non-exited Customers as per the age","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['Age'][df['Exited']==0],color='blue',label='non-exited')\nsns.distplot(df['Age'][df['Exited']==1],color='red',label='exited')\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Age distribution of customers who exited bank is normally distributed while those who stays with bank is right skewed\nindicating that most of the existing customers of bank are lower than 50 years of age. This may also indicate that\nold age customers have exited the bank."},{"metadata":{},"cell_type":"markdown","source":"#### 2. Drop the columns which are unique for all users like IDs & 3. Distinguish the feature and target set"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert data into feature and Target set. Also CustomerId and Surname will not contribute to model building\n#hence we wil drop these 2 colmns as well\nX=df.drop(labels=['CustomerId','Surname','Exited'], axis=1) # Feature Set\ny=df['Exited'] # Target set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Geography and gender are object type, we will convert this into one hot encoding","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X= pd.get_dummies(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Object columns- Geography and Genders have been converted to one hot encoded columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets Check first few rows of feature set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4. Divide the data set into training and test sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n#test train split\ntest_size = 0.30 # taking 70:30 training and test set\nseed = 7  # Random numbmer seeding for reapeatability of the code\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#hCheck Shape of test/trainset\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 5. Normalize the train and test data \n\na)Normalise Following features using standard scaler: CreditScore,Age, tenure,Balance,NumOfProducts,EstimatedSalary as these  have running/continuous values\n\nb)We will not normalise following features as they have discrete values either 0 or 1: HasCrCard,IsActiveMember,Geography_France,Geography_Germany,Geography_Spain,Gender_Female,Gender_Male\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']].head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler.fit(X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_scaled=scaler.transform(X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform test set on the same fit as train set\nX_test_scaled=scaler.transform(X_test[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Following step puts back scaled data into the dataframe for the columns which  have been scaled while keeping other data intact"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Put back scaled data into the dataframe for the columns which  have been scaled while keeping other data intact\nX_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']]=X_train_scaled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']]=X_test_scaled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Convert Data into Numpy arrays"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert Data into Numpy arrays\nX_train_array=np.array(X_train)\nX_test_array=np.array(X_test)\ny_train_array=np.array(y_train)\ny_test_array=np.array(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_train_array.shape,X_test_array.shape,y_train_array.shape,y_test_array.shape#check shapes of array","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### MODEL BUILDING"},{"metadata":{},"cell_type":"markdown","source":"#### 6. Initialize & build the model (Basic Model with 2 hidden layers)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize Sequential model\nmodel = tf.keras.models.Sequential()\n\n\n# Add Input layer to the model\nmodel.add(tf.keras.Input(shape=(13,))) # 13 Features\n\n# Batch Normalization Layer\nmodel.add(tf.keras.layers.BatchNormalization())\n\n# Hidden layers\nmodel.add(tf.keras.layers.Dense(13, activation='relu', name='Layer_1'))\nmodel.add(tf.keras.layers.Dense(10, activation='relu', name='Layer_2'))\n\n#Output layer\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid', name='Output'))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Compile Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Summarise Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Fit Model & Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train_array, y_train_array, validation_data=(X_test_array, y_test_array), epochs=150,\n          batch_size = 32)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 5.Predict the results using 0.5 as a threshold"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.predict(X_test_array)[:5] # Observe first 5 probabilities","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"th=0.5 # Threshold\ny_test_preds = np.where(model.predict(X_test_array) > th, 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_preds[:5] # Observe First 5 predictions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion matrix with optimal Threshold on test set\nmetrics.confusion_matrix(y_test, y_test_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Test Metrics at 0.5 Threshold with basic DNN model\\n')\nTest_Metrics_Basic_DNN=pd.DataFrame(data=[accuracy_score(y_test, y_test_preds), \n                   recall_score(y_test, y_test_preds), \n                   precision_score(y_test, y_test_preds),\n                   f1_score(y_test, y_test_preds)], columns=['Basic DNN'],\n             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\"])\nprint(Test_Metrics_Basic_DNN)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### MODEL TUNING"},{"metadata":{},"cell_type":"markdown","source":"#### A) With 3 Dense Layer"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize Sequential model\nmodel = tf.keras.models.Sequential()\n\n\n# Add Input layer to the model\nmodel.add(tf.keras.Input(shape=(13,))) # 13 Features\n\n# Batch Normalization Layer\nmodel.add(tf.keras.layers.BatchNormalization())\n\n# Hidden layers\nmodel.add(tf.keras.layers.Dense(13, activation='relu', name='Layer_1'))\nmodel.add(tf.keras.layers.Dense(13, activation='relu', name='Layer_2'))\nmodel.add(tf.keras.layers.Dense(10, activation='relu', name='Layer_3'))\n#Output layer\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid', name='Output'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train_array, y_train_array, validation_data=(X_test_array, y_test_array), epochs=150,\n          batch_size = 32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"th=0.5 # Threshold\ny_test_preds = np.where(model.predict(X_test_array) > th, 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Test Metrics at 0.5 Threshold with 3 Hidden layer DNN model\\n')\nTest_Metrics_3_HiddenLayer_DNN=pd.DataFrame(data=[accuracy_score(y_test, y_test_preds), \n                   recall_score(y_test_array, y_test_preds), \n                   precision_score(y_test_array, y_test_preds),\n                   f1_score(y_test_array, y_test_preds)], columns=['3 Hidden Layer DNN'],\n             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\"])\nprint(Test_Metrics_3_HiddenLayer_DNN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion matrix with optimal Threshold on test set\nmetrics.confusion_matrix(y_test_array, y_test_preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Not much improvement in accuracy, precision has improved, recall has gone down,overall accuracy is almost same"},{"metadata":{},"cell_type":"markdown","source":"#### B) With Batch normalisation after each hidden layer"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize Sequential model\nmodel = tf.keras.models.Sequential()\n\n\n# Add Input layer to the model\nmodel.add(tf.keras.Input(shape=(13,))) # 13 Features\n\n# Batch Normalization Layer\n#model.add(tf.keras.layers.BatchNormalization())\n\n# Hidden layers\nmodel.add(tf.keras.layers.Dense(13, activation='relu', name='Layer_1'))\n# Batch Normalization Layer\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dense(13, activation='relu', name='Layer_2'))\n# Batch Normalization Layer\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dense(10, activation='relu', name='Layer_3'))\n# Batch Normalization Layer\nmodel.add(tf.keras.layers.BatchNormalization())\n#Output layer\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid', name='Output'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train_array, y_train_array, validation_data=(X_test_array, y_test_array), epochs=150,\n          batch_size = 32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"th=0.5 # Threshold\ny_test_preds = np.where(model.predict(X_test_array) > th, 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Test Metrics at 0.5 Threshold with  Batch Norm after each hidden layer DNN model\\n')\nTest_Metrics_BatchNorm=pd.DataFrame(data=[accuracy_score(y_test, y_test_preds), \n                   recall_score(y_test_array, y_test_preds), \n                   precision_score(y_test_array, y_test_preds),\n                   f1_score(y_test_array, y_test_preds)], columns=['BatchNorm Hidden layers'],\n             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\"])\nprint(Test_Metrics_BatchNorm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion matrix with optimal Threshold on test set\nmetrics.confusion_matrix(y_test_array, y_test_preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Overall Accuracy, recall and F1 score has improved after adding Batch Normalisation after each hidden layer"},{"metadata":{},"cell_type":"markdown","source":"#### C) Using Weight and Bias initializer"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import initializers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize Sequential model\nmodel = tf.keras.models.Sequential()\n\n\n# Add Input layer to the model\nmodel.add(tf.keras.Input(shape=(13,))) # 13 Features\n\n\n# Hidden layers\nmodel.add(tf.keras.layers.Dense(13, kernel_initializer='he_normal', bias_initializer='Ones',activation='relu', name='Layer_1'))\n# Batch Normalization Layer\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dense(13, kernel_initializer='he_normal',bias_initializer='Ones',activation='relu', name='Layer_2'))\n# Batch Normalization Layer\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dense(10,kernel_initializer='he_normal',bias_initializer='Ones', activation='relu', name='Layer_3'))\n# Batch Normalization Layer\nmodel.add(tf.keras.layers.BatchNormalization())\n#Output layer\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid', name='Output'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train_array, y_train_array, validation_data=(X_test_array, y_test_array), epochs=50,\n          batch_size = 32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"th=0.5 # Threshold\ny_test_preds = np.where(model.predict(X_test_array) > th, 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Test Metrics at 0.5 Threshold withv Weight and Bias initialization &  Batch Norm after each hidden layer DNN model\\n')\nTest_Metrics_Weight_Init=pd.DataFrame(data=[accuracy_score(y_test, y_test_preds), \n                   recall_score(y_test_array, y_test_preds), \n                   precision_score(y_test_array, y_test_preds),\n                   f1_score(y_test_array, y_test_preds)], columns=['Weight Initialize'],\n             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\"])\nprint(Test_Metrics_Weight_Init)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion matrix with optimal Threshold on test set\nmetrics.confusion_matrix(y_test_array, y_test_preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Accuracy has dropped"},{"metadata":{},"cell_type":"markdown","source":"#### D) Apply Dropout"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize Sequential model\nmodel = tf.keras.models.Sequential()\n\n\n# Add Input layer to the model\nmodel.add(tf.keras.Input(shape=(13,))) # 13 Features\n\n\n# Hidden layers\nmodel.add(tf.keras.layers.Dense(13, activation='relu', name='Layer_1'))\nmodel.add(tf.keras.layers.Dense(13, activation='relu', name='Layer_2'))\n\n# Dropout layer\nmodel.add(tf.keras.layers.Dropout(0.5))\n\n# Hidden layers\nmodel.add(tf.keras.layers.Dense(10, activation='relu', name='Layer_3'))\n\n\n# Dropout layer\nmodel.add(tf.keras.layers.Dropout(0.3))\n\n#Output layer\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid', name='Output'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train_array, y_train_array, validation_data=(X_test_array, y_test_array), epochs=100,\n          batch_size = 32, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"th=0.5 # Threshold\ny_test_preds = np.where(model.predict(X_test_array) > th, 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Test Metrics at 0.5 Threshold Dropout DNN model\\n')\nTest_Metrics_DropOut=pd.DataFrame(data=[accuracy_score(y_test, y_test_preds), \n                   recall_score(y_test_array, y_test_preds), \n                   precision_score(y_test_array, y_test_preds),\n                   f1_score(y_test_array, y_test_preds)], columns=['DropOut'],\n             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\"])\nprint(Test_Metrics_DropOut)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion matrix with optimal Threshold on test set\nmetrics.confusion_matrix(y_test_array, y_test_preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Still Accuracy has not improved "},{"metadata":{},"cell_type":"markdown","source":"### MODEL COMPARISON"},{"metadata":{"trusted":true},"cell_type":"code","source":"Model_Comparison_df=Test_Metrics_Basic_DNN\nModel_Comparison_df['3 Hidden Layer DNN']=Test_Metrics_3_HiddenLayer_DNN['3 Hidden Layer DNN']\nModel_Comparison_df['BatchNorm Hidden layers']=Test_Metrics_BatchNorm['BatchNorm Hidden layers']\nModel_Comparison_df['Weight Initialize']=Test_Metrics_Weight_Init['Weight Initialize']\nModel_Comparison_df['DropOut']=Test_Metrics_DropOut['DropOut']\n#Model_Comparison_df['Naive Bayes']=Naive_Bayes_metrics['Naive Bayes']\nModel_Comparison_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Among the models tried above Model with bath normalization after each hidden layer gives best Accurracy and F1 score"}],"metadata":{"kernelspec":{"display_name":"Python 3.7 (tensorflow)","language":"python","name":"tensorflow"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}