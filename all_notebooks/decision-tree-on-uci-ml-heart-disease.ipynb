{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/heart.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79a20d0a571aebfc4c00220c136fd89a6e6e79d6"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"36ab3301175db952d40188a3885847c4f648b0a5"},"cell_type":"markdown","source":"Attribute Information:\n> 1. age\n> 2. sex\n> 3. chest pain type (4 values)\n> 4. resting blood pressure\n> 5. serum cholestoral in mg/dl\n> 6. fasting blood sugar > 120 mg/dl\n> 7. resting electrocardiographic results (values 0,1,2)\n> 8. maximum heart rate achieved\n> 9. exercise induced angina\n> 10. oldpeak = ST depression induced by exercise relative to rest\n> 11. the slope of the peak exercise ST segment\n> 12. number of major vessels (0-3) colored by flourosopy\n> 13. thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n\n"},{"metadata":{"trusted":true,"_uuid":"03344a2fa947c5b3e8056ed12992faa2993da7c7"},"cell_type":"code","source":"# stats\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7cd3920b34d8b5e0e8bcdc2de02165b7d2b718b7"},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"16bf268940516a4f3bdfb310e5acff105376fe07"},"cell_type":"markdown","source":"## Observations:\n1. 303 rows of data\n2. population age: 29 -> 77 (avg 54)\n3. Sex (=1) is 68.32 % of the population\n4. Target (=1) is 54.46 % of the population\n5. All features are encoded to class numbers\n6. Most variables have a finite number of classes"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"40734055c31d3c71748d92ebe67a18d5e5422599"},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (20,8)\ndf.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb726a6dc8e4ca269eb2d8de512626e6439033ea"},"cell_type":"code","source":"y = df['target']\ndf.drop('target', axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d1e84ac499c3236e9fefdc73678813a55a9fcf3"},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier, export_graphviz\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1f05508d7be77e2f19c6b976b128b7bc7180c01"},"cell_type":"code","source":"labelEncoder = LabelEncoder()\ndf['oldpeak'] = labelEncoder.fit_transform(y=df['oldpeak'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0e85a104006616838eeaa62dff43005e591a2b5"},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.3, random_state=17)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"0441383a15d176c725855ce233e7d6c151725572"},"cell_type":"code","source":"tree = DecisionTreeClassifier(random_state=17, max_depth=3, min_samples_leaf=2)\ntree.fit(X=X_train, y=y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e11f2faef6cd25cb27dfda6be5e37350621255f"},"cell_type":"code","source":"tree.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e83935816c17d6d424dc6099640fc2f0da6109c8"},"cell_type":"code","source":"preds = tree.predict(X_test)\naccuracy_score(y_true=y_test, y_pred=preds)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e4d047f79894d9d57c4937e533c639d47101e3fe"},"cell_type":"markdown","source":"Training a very basic DT classifier, we can see that it is possible to achieve a 75% accuracy. This is not a good performance, let's see if we can improve on this performance by using cross-validation."},{"metadata":{"trusted":true,"_uuid":"ee44c2bc4ee6bc6fb8962ffeb4274d1329b1d5fe"},"cell_type":"code","source":"export_graphviz(tree, 'tree1.dot', filled=True, feature_names=X_train.columns, rounded=True)\n!dot -Tpng 'tree1.dot' -o  'tree1.png'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d08f0b4b856b6341d7b402071af6adb1b72d17e1"},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2d16c49df658550513cb92ac5319654e7f3fadf"},"cell_type":"markdown","source":"<img src='tree1.png'>"},{"metadata":{"_uuid":"c6f4a866950a70147f1751b7a9262de0aff9125a"},"cell_type":"markdown","source":"Let's use GridSearch and Stratified K-fold Cross-validation"},{"metadata":{"trusted":true,"_uuid":"35cfcc505a1c56970aedb8ebf82a2894dacd7c1a"},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV, StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"247d3fab66691aebff9a27315a5fd4e0a804b7a9"},"cell_type":"code","source":"# Let's vary hyperparameters from 2 - 10\nbest_parameters = {'max_depth': np.arange(2,11), 'min_samples_leaf': np.arange(2,11)}\ndecision_tree = DecisionTreeClassifier(criterion='entropy') # for information gain and entropy\nmodel = GridSearchCV(estimator=decision_tree, param_grid=best_parameters, n_jobs=-1, verbose=1, cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=17))\nmodel.fit(X_train, y_train)\nmodel.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f52c8749078591c975cceb0f4200dbfdd3140498"},"cell_type":"code","source":"model.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fdfca5f75d8744bd352830894b0da78cceefa3e2"},"cell_type":"code","source":"preds_2 = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7a2faada8cf9e4213534cb3bed45d63da70f282"},"cell_type":"code","source":"accuracy_score(y_test, preds_2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05db20c4bb7575aff1da2b5d2b3c8e144d20c547"},"cell_type":"markdown","source":"We can notice that we got a 8% improvement in the results when we use a grid search to find optimal hyperparameters and then use the derived tree to classify. So, let's visualize the tree again."},{"metadata":{"trusted":true,"_uuid":"af61e73345a5321036ab9c10294044a2b64e1a65"},"cell_type":"code","source":"export_graphviz(model.best_estimator_, out_file='tree2.dot', filled=True, feature_names=X_train.columns, rounded=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08995ec4d8c9e8426620614e9714a98607bbe7f9"},"cell_type":"code","source":"!dot -Tpng 'tree2.dot' -o 'tree2.png'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"042f68a5b1e39058769e46bcb2797617957ce2ca"},"cell_type":"markdown","source":"<img src='tree2.png'>"},{"metadata":{"trusted":true,"_uuid":"eec7542616a0dd04da62fee42a6838055a6c1da8"},"cell_type":"markdown","source":"Okay, so now, we have an accuracy of approximately 83%. Let's see if Logistic Regression can help."},{"metadata":{"trusted":true,"_uuid":"6f1a8ae3b08aed1e9878767b0a5ba2a17c99e9c8"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}