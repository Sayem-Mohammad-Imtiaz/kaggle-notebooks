{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# EDA and Profiling the data with pandas_profiler","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-04T15:12:08.554901Z","iopub.execute_input":"2021-07-04T15:12:08.555234Z","iopub.status.idle":"2021-07-04T15:12:08.559368Z","shell.execute_reply.started":"2021-07-04T15:12:08.555205Z","shell.execute_reply":"2021-07-04T15:12:08.558237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Load Libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn import datasets\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom pandas_profiling import ProfileReport","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-07-04T15:12:08.573895Z","iopub.execute_input":"2021-07-04T15:12:08.574222Z","iopub.status.idle":"2021-07-04T15:12:08.579135Z","shell.execute_reply.started":"2021-07-04T15:12:08.574191Z","shell.execute_reply":"2021-07-04T15:12:08.578263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Data Prep**","metadata":{}},{"cell_type":"code","source":"#Raw data from the first file\ndata = pd.read_csv('../input/unsw-nb15/UNSW-NB15_1.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-04T15:12:08.580878Z","iopub.execute_input":"2021-07-04T15:12:08.581329Z","iopub.status.idle":"2021-07-04T15:12:12.129164Z","shell.execute_reply.started":"2021-07-04T15:12:08.581287Z","shell.execute_reply":"2021-07-04T15:12:12.128131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#quick info about the data\ndata.info","metadata":{"execution":{"iopub.status.busy":"2021-07-04T15:12:12.131513Z","iopub.execute_input":"2021-07-04T15:12:12.13227Z","iopub.status.idle":"2021-07-04T15:12:12.264529Z","shell.execute_reply.started":"2021-07-04T15:12:12.132217Z","shell.execute_reply":"2021-07-04T15:12:12.263389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#that was hard to read....here is a prettier version, but missing some details in the middle\ndata.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T15:12:12.266616Z","iopub.execute_input":"2021-07-04T15:12:12.267042Z","iopub.status.idle":"2021-07-04T15:12:12.304284Z","shell.execute_reply.started":"2021-07-04T15:12:12.266997Z","shell.execute_reply":"2021-07-04T15:12:12.302971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Well the data has no headers....we can find what they 'should be' via the features file.\n#then lets reload the data\n# and we'll make two copies of it in case we want to experiment later\ndata2 = data = pd.read_csv('../input/unsw-nb15/UNSW-NB15_1.csv', header = None, names = ['srcip','sport','dstip','dsport','proto','state','dur','sbytes','dbytes','sttl','dttl','sloss','dloss','service','Sload','Dload','Spkts','Dpkts','swin','dwin','stcpb','dtcpb','smeansz','dmeansz','trans_depth','res_bdy_len','Sjit','Djit','Stime','Ltime','Sintpkt','Dintpkt','tcprtt','synack','ackdat','is_sm_ips_ports','ct_state_ttl','ct_flw_http_mthd','is_ftp_login','ct_ftp_cmd','ct_srv_src','ct_srv_dst','ct_dst_ltm','ct_src_ ltm','ct_src_dport_ltm','ct_dst_sport_ltm','ct_dst_src_ltm','attack_cat','Label'])","metadata":{"execution":{"iopub.status.busy":"2021-07-04T15:12:12.305675Z","iopub.execute_input":"2021-07-04T15:12:12.306229Z","iopub.status.idle":"2021-07-04T15:12:15.919381Z","shell.execute_reply.started":"2021-07-04T15:12:12.306187Z","shell.execute_reply":"2021-07-04T15:12:15.918186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(data)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T15:12:15.920884Z","iopub.execute_input":"2021-07-04T15:12:15.921299Z","iopub.status.idle":"2021-07-04T15:12:15.926599Z","shell.execute_reply.started":"2021-07-04T15:12:15.921256Z","shell.execute_reply":"2021-07-04T15:12:15.925586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T15:12:15.927975Z","iopub.execute_input":"2021-07-04T15:12:15.928283Z","iopub.status.idle":"2021-07-04T15:12:15.956734Z","shell.execute_reply.started":"2021-07-04T15:12:15.928256Z","shell.execute_reply":"2021-07-04T15:12:15.955771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#What were the column names again?\ndf.columns","metadata":{"execution":{"iopub.status.busy":"2021-07-04T15:12:15.958046Z","iopub.execute_input":"2021-07-04T15:12:15.958382Z","iopub.status.idle":"2021-07-04T15:12:15.969552Z","shell.execute_reply.started":"2021-07-04T15:12:15.958353Z","shell.execute_reply":"2021-07-04T15:12:15.968583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This is a noisy data set.  Traditional netflow is a lot simpler.  \n#Let's make a smaller data set....if you don't know what these are...check out the data dictionary '....features.csv'\n\nfeatures = df[[\"sport\",\"dsport\",\"proto\",\"Dpkts\", \"Spkts\",\"Label\"]]","metadata":{"execution":{"iopub.status.busy":"2021-07-04T15:12:15.973445Z","iopub.execute_input":"2021-07-04T15:12:15.973737Z","iopub.status.idle":"2021-07-04T15:12:15.999306Z","shell.execute_reply.started":"2021-07-04T15:12:15.973712Z","shell.execute_reply":"2021-07-04T15:12:15.99835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T15:12:16.001284Z","iopub.execute_input":"2021-07-04T15:12:16.001646Z","iopub.status.idle":"2021-07-04T15:12:16.01418Z","shell.execute_reply.started":"2021-07-04T15:12:16.001615Z","shell.execute_reply":"2021-07-04T15:12:16.01305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-07-04T15:12:16.015725Z","iopub.execute_input":"2021-07-04T15:12:16.016205Z","iopub.status.idle":"2021-07-04T15:12:16.027117Z","shell.execute_reply.started":"2021-07-04T15:12:16.016146Z","shell.execute_reply":"2021-07-04T15:12:16.026123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features['sport'] = pd.to_numeric(features['sport'], errors='coerce')","metadata":{"execution":{"iopub.status.busy":"2021-07-04T15:12:16.028446Z","iopub.execute_input":"2021-07-04T15:12:16.028884Z","iopub.status.idle":"2021-07-04T15:12:16.364884Z","shell.execute_reply.started":"2021-07-04T15:12:16.028843Z","shell.execute_reply":"2021-07-04T15:12:16.363742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#well shoot....now the coorect way is to do a .loc, but lets try a quicker route...\n#copy/paste.  Note this is the the 'correct' way, but it works for now\nfeatures2=features.copy()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T15:12:16.366636Z","iopub.execute_input":"2021-07-04T15:12:16.367069Z","iopub.status.idle":"2021-07-04T15:12:16.38211Z","shell.execute_reply.started":"2021-07-04T15:12:16.367027Z","shell.execute_reply":"2021-07-04T15:12:16.381044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Machines read numbers, so let's convert to numbers\n#BTW when ran the first time sport and dsport were 'rejected', so this is a 'must'.\nfeatures2['sport'] = pd.to_numeric(features['sport'], errors='coerce')\nfeatures2['dsport'] = pd.to_numeric(features['sport'], errors='coerce')","metadata":{"execution":{"iopub.status.busy":"2021-07-04T15:12:16.383263Z","iopub.execute_input":"2021-07-04T15:12:16.383525Z","iopub.status.idle":"2021-07-04T15:12:16.397849Z","shell.execute_reply.started":"2021-07-04T15:12:16.3835Z","shell.execute_reply":"2021-07-04T15:12:16.396949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We can also do label encoding...\n#Label encoding per: https://www.datacamp.com/community/tutorials/categorical-data\nfrom sklearn.preprocessing import LabelEncoder\n\nlb_make = LabelEncoder()\nfeatures2['proto'] = lb_make.fit_transform(features2['proto'])\n","metadata":{"execution":{"iopub.status.busy":"2021-07-04T15:12:16.399906Z","iopub.execute_input":"2021-07-04T15:12:16.400325Z","iopub.status.idle":"2021-07-04T15:12:16.625674Z","shell.execute_reply.started":"2021-07-04T15:12:16.400281Z","shell.execute_reply":"2021-07-04T15:12:16.624926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#run the profiler\n#https://github.com/pandas-profiling/pandas-profiling\nprofile = ProfileReport(features2, title = \"Features to Evaluate Data Profile\")","metadata":{"execution":{"iopub.status.busy":"2021-07-04T15:12:16.62676Z","iopub.execute_input":"2021-07-04T15:12:16.627236Z","iopub.status.idle":"2021-07-04T15:12:16.637217Z","shell.execute_reply.started":"2021-07-04T15:12:16.627191Z","shell.execute_reply":"2021-07-04T15:12:16.636425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's look at the data from within the notebook\nprofile.to_notebook_iframe()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T15:12:16.63832Z","iopub.execute_input":"2021-07-04T15:12:16.638766Z","iopub.status.idle":"2021-07-04T15:12:52.87519Z","shell.execute_reply.started":"2021-07-04T15:12:16.638724Z","shell.execute_reply":"2021-07-04T15:12:52.873955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Well...that's a pretty powerful profiling tool and you can interact with it dynamically!\n## Ughhh...more 'data janitor' work.....\n* sport and dsport are missing values.\n* sport and dsport are highly correlated.  Leave for now, but may need to clean up later.  \n\n## Notes....\n* ports can go up to 65K+ and the data gets close to that number, but less than 10% is unique\n* ports should never be '0'.  This is a possible hacker technique\n* ports  histograms are fairly normal, and that's wierd.  Most traffic is under the 1024 well known ports.  Anything  above that is 'wild west', so having a relatively even distribution is super wierd.  Might be  a lot of 'port scanning' in the data set\n\n### There is a lot you can do here already using statistical inference.  ML is not required to spot anomolies or identify attacks.","metadata":{}},{"cell_type":"code","source":"features2.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T15:12:52.876956Z","iopub.execute_input":"2021-07-04T15:12:52.877501Z","iopub.status.idle":"2021-07-04T15:12:52.892376Z","shell.execute_reply.started":"2021-07-04T15:12:52.877462Z","shell.execute_reply":"2021-07-04T15:12:52.891406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#drop all rows with null values\n#make a new variable so you can trace back your work when troubleshooting\nfeatures3 = features2.dropna(how='any',axis=0) ","metadata":{"execution":{"iopub.status.busy":"2021-07-04T15:12:52.893628Z","iopub.execute_input":"2021-07-04T15:12:52.893932Z","iopub.status.idle":"2021-07-04T15:12:52.925617Z","shell.execute_reply.started":"2021-07-04T15:12:52.893904Z","shell.execute_reply":"2021-07-04T15:12:52.924594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Validate this has been corrected\nfeatures3.isnull().sum()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-04T15:12:52.926799Z","iopub.execute_input":"2021-07-04T15:12:52.927111Z","iopub.status.idle":"2021-07-04T15:12:52.942372Z","shell.execute_reply.started":"2021-07-04T15:12:52.927082Z","shell.execute_reply":"2021-07-04T15:12:52.941497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data has now been profiled, cleaned, and preprocessed.  Time for actual analysis and machine learning","metadata":{}},{"cell_type":"code","source":"from sklearn import model_selection\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import MinMaxScaler","metadata":{"execution":{"iopub.status.busy":"2021-07-04T15:12:52.94361Z","iopub.execute_input":"2021-07-04T15:12:52.943915Z","iopub.status.idle":"2021-07-04T15:12:52.948671Z","shell.execute_reply.started":"2021-07-04T15:12:52.943887Z","shell.execute_reply":"2021-07-04T15:12:52.947599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inspired by https://www.datacamp.com/community/tutorials/ensemble-learning-python\n#Lets scale the data so all columns are relative to one another\n\nscaler = MinMaxScaler(feature_range=(0, 1))\nnormalizedData = scaler.fit_transform(features3)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T15:12:52.950121Z","iopub.execute_input":"2021-07-04T15:12:52.950487Z","iopub.status.idle":"2021-07-04T15:12:53.020555Z","shell.execute_reply.started":"2021-07-04T15:12:52.950445Z","shell.execute_reply":"2021-07-04T15:12:53.019476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(normalizedData)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T15:12:53.022108Z","iopub.execute_input":"2021-07-04T15:12:53.022412Z","iopub.status.idle":"2021-07-04T15:12:53.028252Z","shell.execute_reply.started":"2021-07-04T15:12:53.022385Z","shell.execute_reply":"2021-07-04T15:12:53.027232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#input variables = X and Y = Label.  There are 6 variables, and python starts at 0 \nX = normalizedData[:,0:5]\nY = normalizedData[:,5]","metadata":{"execution":{"iopub.status.busy":"2021-07-04T15:12:53.029645Z","iopub.execute_input":"2021-07-04T15:12:53.030058Z","iopub.status.idle":"2021-07-04T15:12:53.039464Z","shell.execute_reply.started":"2021-07-04T15:12:53.030013Z","shell.execute_reply":"2021-07-04T15:12:53.038511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 10-fold cross-validation fold, then using decision tree clasifier with 100 trees\nkfold = model_selection.KFold(n_splits=10, random_state=7)\ncart = DecisionTreeClassifier()\nnum_trees = 100\nmodel = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=7)\nresults = model_selection.cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())","metadata":{"execution":{"iopub.status.busy":"2021-07-04T15:12:53.040712Z","iopub.execute_input":"2021-07-04T15:12:53.041159Z","iopub.status.idle":"2021-07-04T16:04:43.626972Z","shell.execute_reply.started":"2021-07-04T15:12:53.04113Z","shell.execute_reply":"2021-07-04T16:04:43.625854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## As you can see there is a 97% overall accuracy score.  This is a problem when at scale of 100B connections, however its a great start/filter or a great secondary back up to analyze those connections that passed through the perimeter/firewall as a secondary check.","metadata":{}}]}