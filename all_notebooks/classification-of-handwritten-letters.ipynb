{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import Necessary Packages","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n\nimport os\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Collection and Preprocessing ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"letters = pd.read_csv(\"../input/classification-of-handwritten-letters/letters.csv\")\nletters2 = pd.read_csv(\"../input/classification-of-handwritten-letters/letters2.csv\")\nletters3 = pd.read_csv(\"../input/classification-of-handwritten-letters/letters3.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"source = pd.Series([])\n\nletters[\"source\"] = source\nletters2[\"source\"] = source\nletters3[\"source\"] = source\nfor i in range(len(letters)): \n    letters[\"source\"][i] = \"/letters\"\n\nfor i in range(len(letters2)): \n    letters2[\"source\"][i] = \"/letters2\"\n    \nfor i in range(len(letters3)):\n    letters3[\"source\"][i] = \"/letters3\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.concat((letters, letters2, letters3), axis = 0, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = shuffle(data, random_state = 42).reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dirname = \"../input/classification-of-handwritten-letters\"\nimgs = []\nfor i in range(len(data)):\n    imgs.append(load_img(os.path.join(dirname + data[\"source\"][i], data[\"file\"][i]), target_size = (32, 32)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imgs_array = np.array([img_to_array(img) for img in imgs])/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imgs_array.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Both the letter and the background are considered as labels.\n\nTargets is a list of 2 element lists where the first element is the letter and the second is the background. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"targets = []\nfor i, row in data.iterrows(): \n    t = [data.letter[i], data.background[i]]\n    targets.append(t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targets_array = np.array(targets)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scikir-learn library's MultiLabelBinarizer allows to one-hot encode features with multiple labels. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(imgs_array, targets_array, \n                                                test_size=0.2,  \n                                                random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mlb = MultiLabelBinarizer()\ny_train = mlb.fit_transform(y_train)\ny_val = mlb.transform(y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for (i, target) in enumerate(mlb.classes_):\n    print(\"{}. {}\".format(i + 1, target))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 33 distinct letters and 4 different backgrounds. \n\nBackrground Labels: \n* 0 => striped\n* 1 => gridded\n* 2 => no background\n* 3 => graph paper","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_image(images, list_of_labels = np.arange(15)): \n    plt.figure(figsize=(12,12))\n    for i in list_of_labels: \n        plt.subplot(3, 5, i+1)\n        plt.title('Letter: %s \\n'%targets[i][0]+\\\n                    'Background: %s\\n'%targets[i][1],\n                         fontsize=18)\n        plt.imshow(imgs[i])\n        \n    plt.subplots_adjust(bottom = 0.001)\n    plt.subplots_adjust(top = 0.99)\n    plt.show()\n   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_image(imgs_array)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"shape of X_train: {} \\nshape of X_val: {} \\nshape of y_train: {} \\nshape of y_val: {}\".format(\n    X_train.shape, X_val.shape, y_train.shape, y_val.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The CNN Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"img_rows = 32\nimg_cols = 32\nchannels = 3\nclasses = len(mlb.classes_)\n\nmodel = Sequential()\n\nmodel.add(Conv2D(64, kernel_size = (3, 3), padding = 'Same',\n                     activation = 'relu',\n                     input_shape = (img_rows, img_cols, channels)))\nmodel.add(BatchNormalization(axis=-1))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Conv2D(64, (3, 3), padding = 'Same', activation = 'relu'))\nmodel.add(BatchNormalization(axis=-1))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(128, (3, 3), padding = 'Same', activation = 'relu'))\nmodel.add(BatchNormalization(axis=-1))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Conv2D(128, (3, 3), padding = 'Same', activation = 'relu'))\nmodel.add(BatchNormalization(axis=-1))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation = 'relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(classes, activation='sigmoid'))\n\nmodel.summary()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=keras.losses.binary_crossentropy,\n              optimizer='adam',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = ImageDataGenerator(\n        rotation_range=5, \n        zoom_range = 0.2, \n        width_shift_range=0.2,  \n        height_shift_range=0.2 \n        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stop = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BS = 32\nEPOCHS = 100\nhistory = model.fit(x=aug.flow(X_train, y_train, batch_size = BS),\n                    steps_per_epoch = len(X_train)//BS,   \n                    epochs = EPOCHS,\n                    verbose = 1,\n                    validation_data = (X_val, y_val), callbacks=[early_stop])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Evaluation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_accuracy = pd.DataFrame(model.history.history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_accuracy.plot()\nplt.title(\"Training Loss and Accuracy\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend(loc=\"upper left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(X_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions[predictions>0.5] = 1\npredictions[predictions<=0.5] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_val, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_results = mlb.inverse_transform(predictions)\ntrue_results = mlb.inverse_transform(y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct = 0 \ntotal = 0 \nfor i in range(len(y_val)):\n    if pred_results[i] == true_results[i]:\n        correct += 1\n        \n    total += 1 \n    \nprint(\"Accuracy: \", round(correct/total, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_predicted_image(images, list_of_labels = np.arange(15)): \n    plt.figure(figsize=(12,12))\n    for i in list_of_labels:\n        if len(pred_results[i]) != 2:\n            print(\"Sorry, prediction {} has the wrong size, WRONG PREDICTION\".format(i+1))\n        else:\n            plt.subplot(3, 5, i+1)\n            plt.title('Prediction %s \\n'%(i+1)+\\\n                        'True Letter: %s \\n'%true_results[i][1]+\\\n                            'True Background: %s\\n'%true_results[i][0]+\\\n                                'Predicted Letter: %s \\n'%pred_results[i][1]+\\\n                                  'Predicted Background: %s \\n'%pred_results[i][0],\n                                     fontsize=18)\n        \n            plt.imshow(images[i])\n        \n    plt.subplots_adjust(bottom = 0.005)\n    plt.subplots_adjust(top = 1.5)\n    plt.subplots_adjust(left = 0.125)\n    plt.subplots_adjust(right = 1.5)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_predicted_image(X_val, list_of_labels = np.arange(15))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Saving the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"handwritten_classification_model.h5\")\nprint(\"Saved model to disk\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}