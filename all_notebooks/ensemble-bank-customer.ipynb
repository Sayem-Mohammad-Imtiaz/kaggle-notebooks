{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # 基础线性代数扩展包\nimport pandas as pd # 数据处理工具箱\ndf_bank = pd.read_csv(\"../input/bank-customer/BankCustomer.csv\") # 读取文件\ndf_bank.head() # 显示文件前5行","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:31:17.831035Z","iopub.execute_input":"2021-08-04T12:31:17.831719Z","iopub.status.idle":"2021-08-04T12:31:17.899033Z","shell.execute_reply.started":"2021-08-04T12:31:17.831656Z","shell.execute_reply":"2021-08-04T12:31:17.897952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt #导入matplotlib画图工具箱\nimport seaborn as sns #导入seaborn画图工具箱\n# 显示不同特征的分布情况\nfeatures=[ 'City', 'Gender','Age','Tenure', \n           'ProductsNo', 'HasCard', 'ActiveMember', 'Exited']\nfig=plt.subplots(figsize=(15,15))\nfor i, j in enumerate(features):\n    plt.subplot(4, 2, i+1)\n    plt.subplots_adjust(hspace = 1.0)\n    sns.countplot(x=j,data = df_bank)\n    plt.title(\"No. of costumers\")","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:31:20.768029Z","iopub.execute_input":"2021-08-04T12:31:20.768403Z","iopub.status.idle":"2021-08-04T12:31:22.912708Z","shell.execute_reply.started":"2021-08-04T12:31:20.768374Z","shell.execute_reply":"2021-08-04T12:31:22.9115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 把二元类别文本数字化\ndf_bank['Gender'].replace(\"Female\",0,inplace = True)\ndf_bank['Gender'].replace(\"Male\",1,inplace=True)\n# 显示数字类别\nprint(\"Gender unique values\",df_bank['Gender'].unique())\n# 把多元类别转换成多个二元哑变量，然后贴回原始数据集\nd_city = pd.get_dummies(df_bank['City'], prefix = \"City\")\ndf_bank = [df_bank, d_city]\ndf_bank = pd.concat(df_bank, axis = 1)\n# 构建特征和标签集合\ny = df_bank['Exited']\nX = df_bank.drop(['Name', 'Exited', 'City'], axis=1)\nX.head() #显示新的特征集","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:31:43.967882Z","iopub.execute_input":"2021-08-04T12:31:43.968238Z","iopub.status.idle":"2021-08-04T12:31:44.006269Z","shell.execute_reply.started":"2021-08-04T12:31:43.968208Z","shell.execute_reply":"2021-08-04T12:31:44.005255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split # 拆分数据集\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                   test_size=0.2, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:31:54.272056Z","iopub.execute_input":"2021-08-04T12:31:54.272471Z","iopub.status.idle":"2021-08-04T12:31:54.451151Z","shell.execute_reply.started":"2021-08-04T12:31:54.272436Z","shell.execute_reply":"2021-08-04T12:31:54.450238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 对多棵决策树进行Bagging，即树的聚合\nfrom sklearn.ensemble import BaggingClassifier # 导入Bagging分类器\nfrom sklearn.tree import DecisionTreeClassifier # 导入决策树分类器\nfrom sklearn.metrics import (f1_score, confusion_matrix) # 导入评估标准\ndt = BaggingClassifier(DecisionTreeClassifier()) # 只使用一棵决策树\ndt.fit(X_train, y_train) # 拟合模型\ny_pred = dt.predict(X_test) # 进行预测\nprint(\"决策树测试准确率: {:.2f}%\".format(dt.score(X_test, y_test)*100))\nprint(\"决策树测试F1分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))\nbdt = BaggingClassifier(DecisionTreeClassifier()) #树的Bagging\nbdt.fit(X_train, y_train) # 拟合模型\ny_pred = bdt.predict(X_test) # 进行预测\nprint(\"决策树Bagging测试准确率: {:.2f}%\".format(bdt.score(X_test, y_test)*100))\nprint(\"决策树Bagging测试F1分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:32:13.878365Z","iopub.execute_input":"2021-08-04T12:32:13.878751Z","iopub.status.idle":"2021-08-04T12:32:14.695817Z","shell.execute_reply.started":"2021-08-04T12:32:13.878718Z","shell.execute_reply":"2021-08-04T12:32:14.69479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV # 导入网格搜索工具\n# 使用网格搜索优化参数\nbdt_param_grid = {\n    'base_estimator__max_depth' : [5,10,20,50,100],\n    'n_estimators' : [1, 5, 10, 50]}\nbdt_gs = GridSearchCV(BaggingClassifier(DecisionTreeClassifier()),\n                   param_grid = bdt_param_grid, scoring = 'f1',\n                   n_jobs= 10, verbose = 1)\nbdt_gs.fit(X_train, y_train) # 拟合模型\nbdt_gs = bdt_gs.best_estimator_ # 最佳模型\ny_pred = bdt.predict(X_test) # 进行预测\nprint(\"决策树Bagging测试准确率: {:.2f}%\".format(bdt_gs.score(X_test, y_test)*100)) \nprint(\"决策树Bagging测试F1分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:32:39.635189Z","iopub.execute_input":"2021-08-04T12:32:39.635528Z","iopub.status.idle":"2021-08-04T12:33:00.786672Z","shell.execute_reply.started":"2021-08-04T12:32:39.6355Z","shell.execute_reply":"2021-08-04T12:33:00.78557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier # 导入随机森林分类器\nrf = RandomForestClassifier() # 随机森林模型\n# 使用网格搜索优化参数\nrf_param_grid = {\"max_depth\": [None],\n              \"max_features\": [1, 3, 10],\n               \"min_samples_split\": [2, 3, 10],\n               \"min_samples_leaf\": [1, 3, 10],\n              \"bootstrap\": [True,False],\n              \"n_estimators\" :[100,300],\n              \"criterion\": [\"gini\"]}\nrf_gs = GridSearchCV(rf,param_grid = rf_param_grid, \n                     scoring=\"f1\", n_jobs= 10, verbose = 1)\nrf_gs.fit(X_train,y_train) # 拟合模型\nrf_gs = rf_gs.best_estimator_ # 最佳模型\ny_pred = rf_gs.predict(X_test) # 进行预测\nprint(\"随机森林测试准确率: {:.2f}%\".format(rf_gs.score(X_test, y_test)*100))\nprint(\"随机森林测试F1分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100)) ","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:33:22.281577Z","iopub.execute_input":"2021-08-04T12:33:22.282009Z","iopub.status.idle":"2021-08-04T12:42:23.650993Z","shell.execute_reply.started":"2021-08-04T12:33:22.281972Z","shell.execute_reply":"2021-08-04T12:42:23.649888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier # 导入极端随机森林模型\next = ExtraTreesClassifier() # 极端随机森林模型\n# 使用网格搜索优化参数\next_param_grid = {\"max_depth\": [None],\n              \"max_features\": [1, 3, 10],\n              \"min_samples_split\": [2, 3, 10],\n              \"min_samples_leaf\": [1, 3, 10],\n              \"bootstrap\": [True,False],\n              \"n_estimators\" :[100,300],\n              \"criterion\": [\"gini\"]}\next_gs = GridSearchCV(ext,param_grid = ext_param_grid, scoring=\"f1\", \n                     n_jobs= 4, verbose = 1)\next_gs.fit(X_train,y_train) # 拟合模型\next_gs = ext_gs.best_estimator_ # 最佳模型\ny_pred = ext_gs.predict(X_test) # 进行预测\nprint(\"更多树测试准确率: {:.2f}%\".format(ext_gs.score(X_test, y_test)*100))\nprint(\"更多树测试F1分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:42:47.570374Z","iopub.execute_input":"2021-08-04T12:42:47.57075Z","iopub.status.idle":"2021-08-04T12:46:44.914449Z","shell.execute_reply.started":"2021-08-04T12:42:47.570718Z","shell.execute_reply":"2021-08-04T12:46:44.913197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier # 导入AdaBoost模型\ndt = DecisionTreeClassifier() # 选择决策树分类器作为AdaBoost的基准算法\nada = AdaBoostClassifier(dt) # AdaBoost模型\n# 使用网格搜索优化参数\nada_param_grid = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n                  \"base_estimator__splitter\" :   [\"best\", \"random\"],\n                  \"base_estimator__random_state\" :   [7,9,10,12,15],\n                  \"algorithm\" : [\"SAMME\",\"SAMME.R\"],\n                  \"n_estimators\" :[1,2,5,10],\n                  \"learning_rate\":  [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5]}\nada_gs = GridSearchCV(ada,param_grid = ada_param_grid, \n                        scoring=\"f1\", n_jobs= 10, verbose = 1)\nada_gs.fit(X_train,y_train) # 拟合模型\nada_gs = ada_gs.best_estimator_ # 最佳模型\ny_pred = ada_gs.predict(X_test) # 进行预测\nprint(\"Adaboost测试准确率: {:.2f}%\".format(ada_gs.score(X_test, y_test)*100))\nprint(\"Adaboost测试F1分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:47:15.383395Z","iopub.execute_input":"2021-08-04T12:47:15.383783Z","iopub.status.idle":"2021-08-04T12:48:58.373946Z","shell.execute_reply.started":"2021-08-04T12:47:15.383749Z","shell.execute_reply":"2021-08-04T12:48:58.372717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier # 导入梯度提升分类器\ngb = GradientBoostingClassifier() # 梯度提升分类器\n# 使用网格搜索优化参数\ngb_param_grid = {'loss' : [\"deviance\"],\n                 'n_estimators' : [100,200,300],\n                 'learning_rate': [0.1, 0.05, 0.01],\n                 'max_depth': [4, 8],\n                 'min_samples_leaf': [100,150],\n                 'max_features': [0.3, 0.1]}\ngb_gs = GridSearchCV(gb,param_grid = gb_param_grid,\n                     scoring=\"f1\", n_jobs= 10, verbose = 1)\ngb_gs.fit(X_train,y_train) # 拟合模型\ngb_gs = gb_gs.best_estimator_ # 最佳模型\ny_pred = gb_gs.predict(X_test) # 进行预测\nprint(\"梯度提升测试准确率: {:.2f}%\".format(gb_gs.score(X_test, y_test)*100))\nprint(\"梯度提升测试F1分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:50:31.224625Z","iopub.execute_input":"2021-08-04T12:50:31.225028Z","iopub.status.idle":"2021-08-04T12:53:03.984078Z","shell.execute_reply.started":"2021-08-04T12:50:31.224993Z","shell.execute_reply":"2021-08-04T12:53:03.982862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier # 导入XGB分类器\nxgb = XGBClassifier() # XGB分类器\n# 使用网格搜索优化参数\nxgb_param_grid = {'min_child_weight': [1, 5, 10],\n                  'gamma': [0.5, 1, 1.5, 2, 5],\n                  'subsample': [0.6, 0.8, 1.0],\n                  'colsample_bytree': [0.6, 0.8, 1.0],\n                  'max_depth': [3, 4, 5]}\nxgb_gs = GridSearchCV(xgb,param_grid = xgb_param_grid,  \n                     scoring=\"f1\", n_jobs= 10, verbose = 1)\nxgb_gs.fit(X_train,y_train) # 拟合模型\nxgb_gs = xgb_gs.best_estimator_ # 最佳模型\ny_pred = xgb_gs.predict(X_test) # 进行预测\nprint(\"XGB测试准确率: {:.2f}%\".format(xgb_gs.score(X_test, y_test)*100))\nprint(\"XGB测试F1分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T13:24:59.110771Z","iopub.execute_input":"2021-08-04T13:24:59.111369Z","iopub.status.idle":"2021-08-04T13:29:35.673697Z","shell.execute_reply.started":"2021-08-04T13:24:59.111318Z","shell.execute_reply":"2021-08-04T13:29:35.671686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import  VotingClassifier # 导入Voting分类器\n# 把各种模型的分类结果进行Voting，同学们还可以加入更多模型如SVM，kNN等\nvoting = VotingClassifier(estimators=[('rf', rf_gs),\n                                      ('gb',gb_gs),\n                                      ('ext', ext_gs),\n                                      ('ada', ada_gs)],\n\n                          voting='soft', n_jobs=10)\nvoting = voting.fit(X_train, y_train) # 拟合模型\ny_pred = voting.predict(X_test) # 进行预测\nprint(\"Voting测试准确率: {:.2f}%\".format(voting.score(X_test, y_test)*100)) \nprint(\"Voting测试F1分数: {:.2f}%\".format(f1_score(y_test, y_pred)*100))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T13:29:55.482571Z","iopub.execute_input":"2021-08-04T13:29:55.483956Z","iopub.status.idle":"2021-08-04T13:30:03.238202Z","shell.execute_reply.started":"2021-08-04T13:29:55.483901Z","shell.execute_reply":"2021-08-04T13:30:03.236976Z"},"trusted":true},"execution_count":null,"outputs":[]}]}