{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-24T14:32:39.586267Z","iopub.execute_input":"2021-05-24T14:32:39.586772Z","iopub.status.idle":"2021-05-24T14:32:39.605806Z","shell.execute_reply.started":"2021-05-24T14:32:39.586664Z","shell.execute_reply":"2021-05-24T14:32:39.604419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n \n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n \n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n","metadata":{"execution":{"iopub.status.busy":"2021-05-24T14:32:39.6081Z","iopub.execute_input":"2021-05-24T14:32:39.608488Z","iopub.status.idle":"2021-05-24T14:32:41.213524Z","shell.execute_reply.started":"2021-05-24T14:32:39.608451Z","shell.execute_reply":"2021-05-24T14:32:41.212411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/titanic-machine-learning-from-disaster/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-05-24T14:32:41.214838Z","iopub.execute_input":"2021-05-24T14:32:41.215375Z","iopub.status.idle":"2021-05-24T14:32:41.238369Z","shell.execute_reply.started":"2021-05-24T14:32:41.215338Z","shell.execute_reply":"2021-05-24T14:32:41.237428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T14:32:41.240418Z","iopub.execute_input":"2021-05-24T14:32:41.240907Z","iopub.status.idle":"2021-05-24T14:32:41.282684Z","shell.execute_reply.started":"2021-05-24T14:32:41.240863Z","shell.execute_reply":"2021-05-24T14:32:41.281513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(df)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T14:32:41.2856Z","iopub.execute_input":"2021-05-24T14:32:41.286257Z","iopub.status.idle":"2021-05-24T14:32:41.293272Z","shell.execute_reply.started":"2021-05-24T14:32:41.286207Z","shell.execute_reply":"2021-05-24T14:32:41.292395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T14:32:41.294863Z","iopub.execute_input":"2021-05-24T14:32:41.295325Z","iopub.status.idle":"2021-05-24T14:32:41.32433Z","shell.execute_reply.started":"2021-05-24T14:32:41.295289Z","shell.execute_reply":"2021-05-24T14:32:41.322635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1.Which are available in the dataset? \n            ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare','Cabin', 'Embarked']\n2.Which features are categorical?\n    Sex ,  Pclass, Embarked\n3.Which features are numerical?\n    Age,sibSP, Parch, Fare, Ticket, cabin\n4.Which features are mixed data types?\n    Age,\n5.Which features may contain errors or typos?\n    Name,fare , age, sibsp, parch\n6.Which features contain blank, null or empty values?\n    \nWhat are the data types for various features?\n","metadata":{}},{"cell_type":"code","source":"y = df['Name'].unique()\ny","metadata":{"execution":{"iopub.status.busy":"2021-05-24T14:32:41.326163Z","iopub.execute_input":"2021-05-24T14:32:41.326699Z","iopub.status.idle":"2021-05-24T14:32:41.350255Z","shell.execute_reply.started":"2021-05-24T14:32:41.326661Z","shell.execute_reply":"2021-05-24T14:32:41.349161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Name'].isnull().values.any()\n","metadata":{"execution":{"iopub.status.busy":"2021-05-24T14:32:41.351422Z","iopub.execute_input":"2021-05-24T14:32:41.351706Z","iopub.status.idle":"2021-05-24T14:32:41.360009Z","shell.execute_reply.started":"2021-05-24T14:32:41.351676Z","shell.execute_reply":"2021-05-24T14:32:41.358815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/titanic-machine-learning-from-disaster/train.csv')\ntest_df = pd.read_csv('/kaggle/input/titanic-machine-learning-from-disaster/test.csv')\ncombine = [train_df, test_df]\n","metadata":{"execution":{"iopub.status.busy":"2021-05-24T14:32:41.361514Z","iopub.execute_input":"2021-05-24T14:32:41.361825Z","iopub.status.idle":"2021-05-24T14:32:41.389512Z","shell.execute_reply.started":"2021-05-24T14:32:41.361794Z","shell.execute_reply":"2021-05-24T14:32:41.388268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combine[0].head(10)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T14:32:41.392517Z","iopub.execute_input":"2021-05-24T14:32:41.392901Z","iopub.status.idle":"2021-05-24T14:32:41.415272Z","shell.execute_reply.started":"2021-05-24T14:32:41.392863Z","shell.execute_reply":"2021-05-24T14:32:41.414045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#remove NAN values\n\nfor dataset in combine:\n    dataset['Age'].fillna((dataset['Age'].mean()), inplace=True)\n    dataset['SibSp'].fillna((dataset['SibSp'].mean()), inplace=True)\n    dataset['Parch'].fillna((dataset['Parch'].mean()), inplace=True)\n    dataset['Fare'].fillna((dataset['Fare'].mean()), inplace=True)\n    dataset['Pclass'].fillna((dataset['Pclass'].mean()), inplace=True)\n    dataset['Embarked'].fillna('S', inplace=True)\n\n\n\nfor dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n    dataset.loc[ dataset['Age'] <= 18, 'isKid'] = 1\n    dataset.loc[ dataset['Age'] > 18, 'isKid'] = 0\n    dataset['isKid'] = dataset['isKid'].astype(int)\n    \n\n    \n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-24T14:32:41.416939Z","iopub.execute_input":"2021-05-24T14:32:41.417293Z","iopub.status.idle":"2021-05-24T14:32:41.459579Z","shell.execute_reply.started":"2021-05-24T14:32:41.417259Z","shell.execute_reply":"2021-05-24T14:32:41.458399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in combine:\n    dataset.loc[(dataset['isKid'] == 1) & (dataset['Pclass']==1), 'Tal'] = 1\n    dataset.loc[(dataset['isKid'] == 0) | (dataset['Pclass']>1), 'Tal'] = 0\n    dataset.loc[(dataset['Sex'] == \"female\") & (dataset['Pclass']==1), 'Asaf'] = 1\n    dataset.loc[(dataset['Sex'] != \"female\") | (dataset['Pclass']>1), 'Asaf'] = 0\n\n    dataset.loc[(dataset['FamilySize']>4), 'Bigfamily'] = 1\n    dataset.loc[(dataset['FamilySize']<=4), 'Bigfamily'] = 0\n","metadata":{"execution":{"iopub.status.busy":"2021-05-24T14:32:41.462443Z","iopub.execute_input":"2021-05-24T14:32:41.462808Z","iopub.status.idle":"2021-05-24T14:32:41.491386Z","shell.execute_reply.started":"2021-05-24T14:32:41.462771Z","shell.execute_reply":"2021-05-24T14:32:41.490166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combine[0].corr()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T14:32:41.492965Z","iopub.execute_input":"2021-05-24T14:32:41.493824Z","iopub.status.idle":"2021-05-24T14:32:41.523474Z","shell.execute_reply.started":"2021-05-24T14:32:41.493779Z","shell.execute_reply":"2021-05-24T14:32:41.522443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#The women finder\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\nfor dataset in combine:\n\n    dataset.loc[(dataset['Title']==\"Mrs\"), 'Iswomen'] = 1\n    dataset.loc[(dataset['Title']==\"Miss\"), 'Iswomen'] = 1\n    \nfor dataset in combine:\n    dataset['Iswomen'].fillna(0, inplace=True)\ndataset['Iswomen'] = dataset['Iswomen'].astype(int)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-24T14:32:41.525262Z","iopub.execute_input":"2021-05-24T14:32:41.525588Z","iopub.status.idle":"2021-05-24T14:32:41.544497Z","shell.execute_reply.started":"2021-05-24T14:32:41.525557Z","shell.execute_reply":"2021-05-24T14:32:41.543245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combine[0].isnull().sum(axis = 0)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-05-24T14:32:41.546299Z","iopub.execute_input":"2021-05-24T14:32:41.546752Z","iopub.status.idle":"2021-05-24T14:32:41.562044Z","shell.execute_reply.started":"2021-05-24T14:32:41.546692Z","shell.execute_reply":"2021-05-24T14:32:41.56078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#change string values to int \nfor dataset in combine:\n    dataset.loc[(dataset['Sex']==\"male\"), 'Sex'] = 1\n    dataset.loc[(dataset['Sex']==\"female\"), 'Sex'] = 0\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\n\n\n    ","metadata":{"execution":{"iopub.status.busy":"2021-05-24T14:32:41.563737Z","iopub.execute_input":"2021-05-24T14:32:41.56417Z","iopub.status.idle":"2021-05-24T14:32:41.582796Z","shell.execute_reply.started":"2021-05-24T14:32:41.564123Z","shell.execute_reply":"2021-05-24T14:32:41.581578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combine[0].head(10)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-24T14:32:41.584416Z","iopub.execute_input":"2021-05-24T14:32:41.584746Z","iopub.status.idle":"2021-05-24T14:32:41.621087Z","shell.execute_reply.started":"2021-05-24T14:32:41.584714Z","shell.execute_reply":"2021-05-24T14:32:41.619632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#drop to cols I dont want \ndf_trainx = combine[0].drop(['PassengerId','Name','SibSp','Parch','Ticket','Cabin','Title'], axis=1)\ndf_testx = combine[1].drop(['PassengerId','Name','SibSp','Parch','Ticket','Cabin','Title'], axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-24T14:32:41.622463Z","iopub.execute_input":"2021-05-24T14:32:41.623009Z","iopub.status.idle":"2021-05-24T14:32:41.638759Z","shell.execute_reply.started":"2021-05-24T14:32:41.622955Z","shell.execute_reply":"2021-05-24T14:32:41.637509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_trainx.head(10)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-24T14:33:33.066717Z","iopub.execute_input":"2021-05-24T14:33:33.067181Z","iopub.status.idle":"2021-05-24T14:33:33.092652Z","shell.execute_reply.started":"2021-05-24T14:33:33.067115Z","shell.execute_reply":"2021-05-24T14:33:33.091274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train= df_trainx.drop('Survived', axis=1)\nY_train= df_trainx['Survived']\nX_test= df_testx.copy()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T14:33:35.504553Z","iopub.execute_input":"2021-05-24T14:33:35.505031Z","iopub.status.idle":"2021-05-24T14:33:35.513025Z","shell.execute_reply.started":"2021-05-24T14:33:35.504992Z","shell.execute_reply":"2021-05-24T14:33:35.511765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\n\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","metadata":{"execution":{"iopub.status.busy":"2021-05-24T14:33:36.308571Z","iopub.execute_input":"2021-05-24T14:33:36.308991Z","iopub.status.idle":"2021-05-24T14:33:36.631016Z","shell.execute_reply.started":"2021-05-24T14:33:36.308956Z","shell.execute_reply":"2021-05-24T14:33:36.629971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}