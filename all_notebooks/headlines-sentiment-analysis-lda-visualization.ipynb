{"nbformat_minor":1,"nbformat":4,"cells":[{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"644fe876d41b25011a0dc309f5cdee9f8c467698","_cell_guid":"6062ebf7-8e27-423f-9601-70b513d906c4"},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":2},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"16fb6cfb0b94d305d3b773febf4a1649534d0748","_cell_guid":"1b031c59-a5db-425d-9a03-be940c876c67"},"cell_type":"code","source":"df = pd.read_csv(\"../input/abcnews-date-text.csv\",error_bad_lines=False,warn_bad_lines=False)\ndf.head()","execution_count":3},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"b9c003574b4dc81f157036e4a76141926610dfb0","_cell_guid":"3925eef5-7e44-49e2-ac77-d1f5e485aaf8"},"cell_type":"code","source":"df.shape","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"e5fe1dc63c9c1f6baec33c82dc52ac8935104851","_cell_guid":"a04f99be-fb3e-4bb1-b64c-799741987508"},"cell_type":"code","source":"df.publish_date = pd.to_datetime(df.publish_date,format=\"%Y%m%d\")","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"fdcc5e5d313bf778ee98668f5a69b599422a3a3d","_cell_guid":"b1ba89a6-f293-47f5-9bd9-9af6480c5365"},"cell_type":"code","source":"df.publish_date.min(),df.publish_date.max()","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"f039e4cd1d2e7c6db4093bd22a17312c4411941b","_cell_guid":"4c78c741-ff43-4959-b4c6-f6ffb6a7f9a4"},"cell_type":"code","source":"df.publish_date.max() - df.publish_date.min()","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"262a3700e0a2b05e2d560fc823ffd1438a1032bd","_cell_guid":"1ae6bee2-c9be-49cf-98dd-54e3700ed6cf"},"cell_type":"code","source":"len(df.publish_date.unique())","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","collapsed":true,"trusted":false,"_uuid":"1509315781762367b13d0925302a48df764f0c2c","_cell_guid":"f7433627-04f5-40dc-b9b9-04796fe317de"},"cell_type":"code","source":"s = df.groupby('publish_date').tail(2)","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"b3625125831a5344b476fb551fa70f504ec5b542","_cell_guid":"0e2db3e7-5f16-4714-bc73-5ab517e50d3e"},"cell_type":"code","source":"s.head()","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","collapsed":true,"trusted":false,"_uuid":"7082c05ecd10591bb00dd9ac71e0215ad7d557f6","_cell_guid":"6500dd9e-3ed2-4f79-84c4-b14e75f7cbb6"},"cell_type":"code","source":"all_headlines = s.headline_text.values","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","_uuid":"cb277662e5329419f42d51d204fc885d96132e27","_cell_guid":"c4069cab-af9e-4ad2-b8bb-1cbd38b1506b"},"cell_type":"markdown","source":"## Get the sentiment for each headline and list positive , negative and neutral headlines separately","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"b80a32e84e44cecadb4f78d1bd2e3e14339c38b5","_cell_guid":"5963aa2c-ee72-4d3a-a22a-cf3277a1374f"},"cell_type":"code","source":"from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\nfrom nltk.corpus import stopwords\nStopWords = stopwords.words(\"english\")\nfrom nltk.stem import PorterStemmer\nstemmer = PorterStemmer()","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"78048e18a56828ea2bb96899c7e7d7d4fc1b2c28","_cell_guid":"94568261-26a5-4c77-b60e-57c6bca00291"},"cell_type":"code","source":"%%time\nsia = SIA()\npos_list = []\nneg_list = []\nneu_list = []\nfor post in all_headlines:\n    post = \" \".join([stemmer.stem(word) for word in str(post).lower().split() if word not in set(StopWords)])\n    res = sia.polarity_scores(post)\n    if res['compound'] > 0.0:\n        pos_list.append(post)\n    elif res['compound'] < 0.0:\n        neg_list.append(post)\n    else:\n        neu_list.append(post)","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"7561c2329d0b414e1c90589d1172181e9efaeceb","_cell_guid":"755bd5ef-88fa-4a8e-9919-620c5ee6ad9d"},"cell_type":"code","source":"print(\"Number of Positive Headlines : {}\\nNumber of Negative Headlines : {}\\nNumber of Neutral Headlines : {}\".format(len(pos_list),len(neg_list),len(neu_list)))","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"5dc383b2550541d12a4f4d4f0c2d331e0a7763f6","_cell_guid":"b99587cd-5d80-4625-bc3d-1493111bb049"},"cell_type":"code","source":"from nltk.tokenize import RegexpTokenizer\ntokenizer = RegexpTokenizer(r'\\w+')","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"11c55ec3bf2e2530e42a1ea9b199c0f2b3564978","_cell_guid":"76056268-426c-4c99-bb84-040753cdc6ec"},"cell_type":"code","source":"pos_words = []\nfor line in pos_list:\n    words = tokenizer.tokenize(line)\n    for w in words:\n        pos_words.append(w.lower())\n    \n    ","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"4af8981bebba0c11251e929b660077e2c2e0726e","_cell_guid":"36814346-fc19-4c7d-ac97-c14b45285630"},"cell_type":"code","source":"neg_words = []\nfor line in neg_list:\n    words = tokenizer.tokenize(line)\n    for w in words:\n        neg_words.append(w.lower())","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","_uuid":"c838b5739fa83129665da1bb8bdd319468b24465","_cell_guid":"e28b453a-dc34-4749-85cb-5c8d8e5df9e2"},"cell_type":"markdown","source":"## Most common positive words in the headlines","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"42dce2fdad24f0675a60111bf070eb285f1678a3","_cell_guid":"f348777d-f062-46aa-bf17-ea5f4f0bee86"},"cell_type":"code","source":"from nltk import FreqDist\npos_words = FreqDist(pos_words)\nfor x in pos_words.most_common(10):\n    print(x[0],\":\",x[1])","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","_uuid":"79d649632fb9b875ba2049e22207faae25134c3b","_cell_guid":"e7f2cfcd-99e7-4f37-9a0f-c61d2ba91f56"},"cell_type":"markdown","source":"## Most common negative words in the headlines","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"178e2b673aefea37b45760a83e5346dc750af31c","_cell_guid":"a070d82f-3784-4ffc-a145-30298a05817d"},"cell_type":"code","source":"neg_words = FreqDist(neg_words)\nfor x in neg_words.most_common(10):\n    print(x[0],\":\",x[1])","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","_uuid":"1c8749d2038a4737bb5c91d58a6bdda4ee39523f","_cell_guid":"5a68a97e-84ad-4a8d-ac03-89865d908656"},"cell_type":"markdown","source":"## Distribution of words in Positive Headlines","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"c7286e787617d651732043a31436bfa1ca3f547a","_cell_guid":"6337f7ba-bd0d-4668-9f58-dbef309bbe6b"},"cell_type":"code","source":"import matplotlib\nimport matplotlib.pylab as plt\n%matplotlib inline\nmatplotlib.rcParams['xtick.labelsize'] = 14\nplt.figure(figsize=(20,10))\npos_words.plot(50,cumulative=False)","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","_uuid":"cf84e00895c88995603e8089701a60649f3381b2","_cell_guid":"4d650270-f9c3-45eb-b915-2051ae255e40"},"cell_type":"markdown","source":"## Distribution of words in Negative Headlines","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"6488a404534820983e6e280bb7ea70cb1de3e52e","_cell_guid":"f2bc8276-1108-4f83-84d0-89c75e49cf7d"},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nneg_words.plot(50,cumulative=False)","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","_uuid":"98ba92344e829359cee851af5822535e9184e9bb","_cell_guid":"dd2d5c75-6653-48e0-80bb-d49d0b68ab39"},"cell_type":"markdown","source":"####  The distribution is as expected, few words repeated most of the times in both positive and negative headlines. The frequency in case of Positive words dips quickly than Negative words","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","_uuid":"00f25673e4394bde381f1f33282a083039df057f","_cell_guid":"dba8a2eb-e5b4-4fd7-ad1e-3d4ef3deae62"},"cell_type":"markdown","source":"## NEXT UP : CLUSTERING INTO TOPICS","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"20afad7fdcb9a45165fe6dfe7077fbc8e6d251aa","_cell_guid":"ae820b38-9348-4760-8f19-061af7d4ea4b"},"cell_type":"code","source":"sample = pos_list+neg_list+neu_list","execution_count":null},{"outputs":[],"metadata":{"_uuid":"a275f8c9868ee12ac694b37808e0db6cfa8850fb","_cell_guid":"670bd44a-d622-4edf-8503-c891d9b11541"},"cell_type":"markdown","source":"### Load gensim package for LDA and create a document-term matrix out of the headlines","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"5614f9d7d2a14ce6b22a9c0327d637877e42b815","_cell_guid":"e529aa99-6676-4168-9d96-817104b281dd"},"cell_type":"code","source":"import gensim\nfrom gensim import corpora\n\nsample_clean = [text.split() for text in sample] ","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"cf71c03594ba5c5539b38c186d4732892cbb4cc6","_cell_guid":"e0b693f7-ab27-4be4-bbcb-ee8a62e852a3"},"cell_type":"code","source":"# Creating the term dictionary of our courpus, where every unique term is assigned an index. \ndictionary = corpora.Dictionary(sample_clean)\n\n# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\ndoc_term_matrix = [dictionary.doc2bow(doc) for doc in sample_clean]","execution_count":null},{"outputs":[],"metadata":{"_uuid":"d4a345c1727cd4a43d73c04a82be953652e59cfc","_cell_guid":"1701c639-9363-499e-aeb6-c472252871d2"},"cell_type":"markdown","source":"### Fit a LDA model for the document-term matrix, number of topics is set to be 10. \n### If you have only few documents increasing passes might help and if the documents are small (sparse) increasing iterations should help","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"233cca7e8fb392615cca4fa8c14a3c0dbc3b566d","_cell_guid":"181af15c-b37f-4075-b7f0-f5a3a821a0a7"},"cell_type":"code","source":"%%time\n# Creating the object for LDA model using gensim library\nLda = gensim.models.ldamodel.LdaModel\nnum_topics = 10\n# Running and Trainign LDA model on the document term matrix.\nldamodel = Lda(doc_term_matrix, num_topics=num_topics, id2word = dictionary, passes=50,iterations=100)","execution_count":null},{"outputs":[],"metadata":{"_uuid":"bc3cccb0283e816fa33616763d3c7e9539824a53","_cell_guid":"2860fc06-377c-4fe0-84ca-1730c5f7ffb3"},"cell_type":"markdown","source":"### Get the Document-Topic distribution and Topic-Word distributions","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"032ddc9e1c7686adabff4f1ae0d85cc8824c5208","_cell_guid":"f0bd3343-3fbd-407a-83bf-33a6b17f4ac3"},"cell_type":"code","source":"dtm = ldamodel.get_document_topics(doc_term_matrix)\nK = ldamodel.num_topics\ntopic_word_matrix = ldamodel.print_topics(K)","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"bf5f48e3c14063ecfbf991646483237ac2956f26","_cell_guid":"f128b77c-1de2-4b17-9058-377f80a04c06"},"cell_type":"code","source":"print(\"The topics are: \\n\")\nfor x in topic_word_matrix:\n    print(x[0],\":\",x[1],\"\\n\")","execution_count":null},{"outputs":[],"metadata":{"_uuid":"99567201430a12f52dd10eccb32f2a6f3c7bdf95","_cell_guid":"369230b5-6c30-4119-a9f5-9faa26efca36"},"cell_type":"markdown","source":"### Preparing the document-topic matrix for t-SNE visualization","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","collapsed":true,"trusted":false,"_uuid":"30bee09d77753767825e64706d5eb3b567a203b9","_cell_guid":"1a6cf267-4979-4c2e-9d66-ef43a15f3189"},"cell_type":"code","source":"from gensim import matutils","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"33251cd48cebecc1131f0cc6fb2e089a256d124a","_cell_guid":"608b2e05-0956-488d-ab40-cf0e003a3335"},"cell_type":"code","source":"document_topic_matrix = matutils.corpus2dense(corpus=dtm,num_docs=len(all_headlines),num_terms=K)","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","collapsed":true,"trusted":false,"_uuid":"8b180cc06cfded93be7666528858ad2fa3945a05","_cell_guid":"533f92f5-12ad-4db7-8307-b1524ebd295b"},"cell_type":"code","source":"a = document_topic_matrix.transpose()","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"abc364dbe8d942e488281f4ab99b43754bee847f","_cell_guid":"1a8cb146-2bb3-4232-9747-d73a68b38de1"},"cell_type":"code","source":"%%time\nfrom sklearn.manifold import TSNE\n\n# a t-SNE model\n# angle value close to 1 means sacrificing accuracy for speed\n# pca initializtion usually leads to better results \ntsne_model = TSNE(n_components=2, verbose=1, random_state=0,init='pca',)\n\n# 8-D -> 2-D\ntsne_lda = tsne_model.fit_transform(a)","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"d47e9a01773c6786f55def4b6ed56e4ebcee8beb","_cell_guid":"0a491b07-b270-4412-9200-cc6d26aab88b"},"cell_type":"code","source":"_lda_keys = []\nfor i in range(a.shape[0]):\n    _lda_keys.append(a[i].argmax())\nlen(_lda_keys)","execution_count":null},{"outputs":[],"metadata":{"_uuid":"1c43c36456e68bf99842fb7021fd401009dce6f4","_cell_guid":"a5356955-c79b-4ba0-806d-50326217cd76"},"cell_type":"markdown","source":"### Using Bokeh to plot a interactive-visualization","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"680f90b97cb81cba01716654a6d4b53cc8fcc9e4","_cell_guid":"a2d3a885-9376-4fba-b566-43f11836d39a"},"cell_type":"code","source":"import bokeh.plotting as bp\nfrom bokeh.io import output_notebook\nfrom bokeh.plotting import show\n\n# 10 colors\ncolormap = np.array([\"#1f77b4\", \"#aec7e8\", \"#ff7f0e\", \"#ffbb78\", \"#2ca02c\",\"#98df8a\", \"#d62728\", \"#ff9896\",\"#bcbd22\", \"#dbdb8d\"])\noutput_notebook()","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"7be9bac73d39dec84eec7ff67728bab82fa1f79b","_cell_guid":"e402ac4c-b676-4ddf-b944-3b9ac435987a"},"cell_type":"code","source":"plot_lda = bp.figure(plot_width=1000, plot_height=1000,\n                     title=\"LDA t-SNE Viz\",\n                     tools=\"pan,wheel_zoom,box_zoom,reset,hover,previewsave\",\n                     x_axis_type=None, y_axis_type=None, min_border=1)\n","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"af9b679daa5f95067d8edae415a3b76444a13871","_cell_guid":"ddd762f7-dfba-4de3-b492-e6a1568970ce"},"cell_type":"code","source":"n = len(a)\nplot_lda.scatter(x=tsne_lda[:, 0], y=tsne_lda[:, 1],\n                 color=colormap[_lda_keys][:n],\n                 source=bp.ColumnDataSource({\n                   \"content\": sample_clean[:n],\n                   \"topic_key\": _lda_keys[:n]\n                   }))","execution_count":null},{"outputs":[],"metadata":{"_uuid":"6d103f75a0247152ae72b9daacb174da61ba1346","_cell_guid":"cd62c277-7ab2-4db1-a157-948dbdc169d4"},"cell_type":"markdown","source":"### Annotate the graph with words from each topic. Below we are just setting the coordinats for the text and get the word distribution form topic-word matrix","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"88279f558a3b4f43382d02396fc565f03978fe2b","_cell_guid":"a960c4a7-fd45-4451-9ba2-1351c0eb7a6c"},"cell_type":"code","source":"topic_summaries = [x[1] for x in topic_word_matrix]\ntopic_coord = np.empty((a.shape[1], 2)) * np.nan\nfor topic_num in _lda_keys:\n    topic_coord[topic_num] = tsne_lda[_lda_keys.index(topic_num)]","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"0b9abaf69a63ecef6ca07e285c8517edd1133814","_cell_guid":"c2fe8af8-b627-4455-81e6-5002f6ab8c8a"},"cell_type":"code","source":"# add topic words to graph\nfor i in range(a.shape[1]):\n    plot_lda.text(topic_coord[i, 0], topic_coord[i, 1], [topic_summaries[i]])","execution_count":null},{"outputs":[],"metadata":{"_execution_state":"idle","trusted":false,"_uuid":"61783b85b2664ca9aaaaa73294ed17c080de8f5d","_cell_guid":"0074e77f-b434-40d9-b1f2-2429c2e0aee5"},"cell_type":"code","source":"show(plot_lda)","execution_count":null},{"outputs":[],"metadata":{"_uuid":"85d14201b5efb4a4b6e2800e069d4e797d788a39","_cell_guid":"fd4b2d04-2eb9-4b13-bf8a-eea38c35fe89"},"cell_type":"markdown","source":"### The plot is really messy, reason should definitely be LDA model.. Each topic consist of similar words like \"world\",\"women\",\"australia\"..  For documents, the probablity of even most probable topic is also really low. Model can't distinguish documents into topics. Using more documents and tuning parameters should help.","execution_count":null}],"metadata":{"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.1","file_extension":".py","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","mimetype":"text/x-python"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}}}