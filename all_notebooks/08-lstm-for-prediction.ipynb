{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"循環神經網路（Recurrent Neural Network，RNN）是一種用於處理序列數據的神經網路。相比一般的神經網路來說，他能夠處理序列變化的數據。比如某個單詞的意思會因為上文提到的內容不同而有不同的含義，RNN就能夠很好地解決這類問題。架構如下圖\n\n![RNN](https://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Recurrent-neural-network.png)"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"RNN 模型用於股價預測\n\n[李宏毅老師的投影片](https://www.youtube.com/watch?v=xCGidAeyS4M)\n\nX 為當前狀態下的輸入， h 表示接收到的上一個節點的輸入。\n\nY 為當前狀態下的輸出，而 h' 為傳遞到下一個節點的輸出。\n\n可以看得出來：h' 與 X 、h 密切相關，當我們把很多單元結合再一起的時候，就是一種 RNN 模型"},{"metadata":{},"cell_type":"markdown","source":"### LSTM"},{"metadata":{},"cell_type":"markdown","source":"LSTM (Long-Short Term Memory) 是一種 RNN (循環神經網路)，跟一般深度神經網路不同，多了資料的方向性(時序關聯)，RNN 會將每一個隱藏層的結果儲存在記憶單元，並且當新的資料近來的時候，會考慮記憶單元的值去計算\n\nLSTM 與一般 RNN 的差別\n[李宏毅老師的投影片](https://www.youtube.com/watch?v=xCGidAeyS4M)\n\n簡單的說，LSTM 一共包含 4 個元件：輸入閘道、記憶單元、輸出閘道、清除閘道\n\n- 輸入閘道：當將feature輸入時，input gate會去控制是否將這次的值輸入\n- 記憶單元：將計算出的值儲存起來，以利下個階段拿出來使用\n- 輸出閘道：控制是否將這次計算出來的值output\n- 清除閘道：是否將Memory清掉(format)，restart的概念。"},{"metadata":{},"cell_type":"markdown","source":"## 使用 LSTM 模型預測股價"},{"metadata":{},"cell_type":"markdown","source":"### 加入套件，包含 Keras (TensorFlow)、scikit-learn"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom pandas import read_csv\nimport time\nimport math\nimport tensorflow as tf\n\nfrom keras.layers.core import Dense, Activation, Dropout\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 設定訓練常數"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 訓練樣本數比例\nSPLIT_RATIO = 0.5\n# 感知器記憶長度\nLOOK_BACK = 240","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 設定排序隨機碼，之後能夠重現訓練過程"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 載入市場資料，在 data 資料夾裡面：\n- NVDA.csv ： 輝達 > 每分鐘間隔\n- SPY.csv ： 標普 500 ETF > 每日間隔\n\n**要注意資料欄位格式不一樣**"},{"metadata":{"trusted":true},"cell_type":"code","source":"nvda_prices = read_csv('../input/quantitative-trading/NVDA.csv', index_col=None, delimiter=',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = nvda_prices['close'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = labels.reshape(-1, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'資料集 {dataset[:10]} 長度 {len(dataset)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 標準化資料"},{"metadata":{"trusted":true},"cell_type":"code","source":"Scaler = MinMaxScaler(feature_range=(0, 1))\ndataset = Scaler.fit_transform(dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"split_size = int(len(dataset) * SPLIT_RATIO)\ntest_size = len(dataset) - split_size\n\ntrain_dataset = dataset[0:split_size, :]\ntest_dataset = dataset[split_size:len(dataset), :]\n\nprint(f'訓練資料集 {train_dataset[:10]} 長度 {len(train_dataset)}')\nprint(f'測試資料集 {test_dataset[:10]} 長度 {len(test_dataset)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 拆分 訓練資料、測試資料"},{"metadata":{"trusted":true},"cell_type":"code","source":"def buildDataset(dataset, look_back=1):\n    dataX, dataY = [], []\n    for i in range(len(dataset) - look_back - 1):\n        a = dataset[i:(i + look_back), 0]\n        dataX.append(a)\n        dataY.append(dataset[i + look_back, 0])\n    return np.array(dataX), np.array(dataY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x, train_y = buildDataset(train_dataset, LOOK_BACK)\ntest_x, test_y = buildDataset(test_dataset, LOOK_BACK)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 重塑訓練資料"},{"metadata":{},"cell_type":"markdown","source":"### [樣本, 序列(時間)跨度, 特徵]"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = np.reshape(train_x, (train_x.shape[0], 1, train_x.shape[1]))\ntest_x = np.reshape(test_x, (test_x.shape[0], 1, test_x.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 建立 LSTM 模型"},{"metadata":{},"cell_type":"markdown","source":"### 使用 adam 優化器、單層 250 個神經元、隨機排除 10% 權重"},{"metadata":{"trusted":true},"cell_type":"code","source":"Model = Sequential()\nModel.add(LSTM(250, input_shape=(1, LOOK_BACK)))\nModel.add(Dropout(0.1))\nModel.add(Dense(1))\nModel.compile(loss='mse', optimizer='adam')\n# 調整訓練次數可以提升準度，也可以觀察到過擬合的問題\nModel.fit(train_x, train_y, epochs=1000, batch_size=240, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 預測資料"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_predict = Model.predict(train_x)\ntest_predict = Model.predict(test_x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 反轉預測結果，方便結果比對"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_predict = Scaler.inverse_transform(train_predict)\ntrain_y = Scaler.inverse_transform([train_y])\ntest_predict = Scaler.inverse_transform(test_predict)\ntest_y = Scaler.inverse_transform([test_y])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 計算預測誤差 Root Mean Squared Error"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_score = math.sqrt(mean_squared_error(train_y[0], train_predict[:,0]))\nprint(f'訓練誤差分數(RMSE)：{np.round(train_score, 3)}')\n\ntest_score = math.sqrt(mean_squared_error(test_y[0], test_predict[:,0]))\nprint(f'測試誤差分數(RMSE)：{np.round(test_score, 3)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 整理繪圖資料"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_predict_plot = np.empty_like(dataset)\ntrain_predict_plot[:, :] = np.nan\ntrain_predict_plot[LOOK_BACK:len(train_predict) + LOOK_BACK, :] = train_predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predict_plot = np.empty_like(dataset)\ntest_predict_plot[:, :] = np.nan\ntest_predict_plot[len(train_predict) + (LOOK_BACK * 2) + 1:len(dataset)-1, :] = test_predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 7))\nplt.plot(Scaler.inverse_transform(dataset))\n\nplt.plot(train_predict_plot)\nplt.plot(test_predict_plot)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 匯出 CSV 檔案"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_prices=Scaler.inverse_transform(dataset[test_size+LOOK_BACK:])\n\nresult = pd.DataFrame(\n    data={\n        \"測試價格\": np.around(list(test_prices.reshape(-1)), decimals=2),\n        \"預測價格\": np.around(list(test_predict.reshape(-1)), decimals=2)\n    }\n)\nresult.to_csv(\"股價預測對比.csv\", sep=',', index=None)\nprint(result)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}