{"nbformat_minor":1,"cells":[{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"3418394073d9d5005ea11701cce3aa8c3583b0f4","_cell_guid":"323adbdd-10bc-4b1a-b67c-f57f37e68d44"},"outputs":[],"source":"import json\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.decomposition import PCA # Principal Component Analysis module\nfrom sklearn.cluster import KMeans # KMeans clustering \nimport nltk\nfrom nltk.corpus import wordnet\nPS = nltk.stem.PorterStemmer()\nimport matplotlib.pyplot as plt\nimport plotly.offline as pyo\npyo.init_notebook_mode()\nfrom plotly.graph_objs import *\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode,iplot\ninit_notebook_mode(connected=True)\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output"},{"cell_type":"markdown","metadata":{"_uuid":"21de5ce363782a0d8ae712c5cea091983c7b3842","_cell_guid":"df16442c-3826-43af-b093-416afeac7aaa"},"source":"# Part 1 Country Analysis"},{"cell_type":"markdown","metadata":{"_uuid":"3543596af104cfad578238afe68e763e21b43b74","_cell_guid":"e744675f-4854-466b-a0a6-f5c0cbc0644c"},"source":"We are interested in the following question: What countries produce the most movies?[](http://)\n\nWe start off by loading the TMDB dataset."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"bbc044561edfc1f63a6d28f78831b8bab4f6002f","_cell_guid":"79e46ac9-5c8a-4242-a90d-3f86326ae1cc","collapsed":true},"outputs":[],"source":"def load_tmdb_movies(path):\n    df = pd.read_csv(path)\n    df['release_date'] = pd.to_datetime(df['release_date']).apply(lambda x: x.date())\n    json_columns = ['genres', 'keywords', 'production_countries', 'production_companies', 'spoken_languages']\n    for column in json_columns:\n        df[column] = df[column].apply(json.loads)\n    return df\n#____________________________\ndef load_tmdb_credits(path):\n    df = pd.read_csv(path)\n    json_columns = ['cast', 'crew']\n    for column in json_columns:\n        df[column] = df[column].apply(json.loads)\n    return df\n#_______________________________________\ndef safe_access(container, index_values):\n    result = container\n    try:\n        for idx in index_values:\n            result = result[idx]\n        return result\n    except IndexError or KeyError:\n        return pd.np.nan\n#_______________________________________\nLOST_COLUMNS = [\n    'actor_1_facebook_likes',\n    'actor_2_facebook_likes',\n    'actor_3_facebook_likes',\n    'aspect_ratio',\n    'cast_total_facebook_likes',\n    'color',\n    'content_rating',\n    'director_facebook_likes',\n    'facenumber_in_poster',\n    'movie_facebook_likes',\n    'movie_imdb_link',\n    'num_critic_for_reviews',\n    'num_user_for_reviews']\n#_______________________________________\nTMDB_TO_IMDB_SIMPLE_EQUIVALENCIES = {\n    'budget': 'budget',\n    'genres': 'genres',\n    'revenue': 'gross',\n    'title': 'movie_title',\n    'runtime': 'duration',\n    'original_language': 'language',  \n    'keywords': 'plot_keywords',\n    'vote_count': 'num_voted_users'}\n#_______________________________________     \nIMDB_COLUMNS_TO_REMAP = {'imdb_score': 'vote_average'}\n#_______________________________________\ndef get_director(crew_data):\n    directors = [x['name'] for x in crew_data if x['job'] == 'Director']\n    return safe_access(directors, [0])\n#_______________________________________\ndef pipe_flatten_names(keywords):\n    return '|'.join([x['name'] for x in keywords])\n#_______________________________________\ndef convert_to_original_format(movies, credits):\n    tmdb_movies = movies.copy()\n    tmdb_movies.rename(columns=TMDB_TO_IMDB_SIMPLE_EQUIVALENCIES, inplace=True)\n    tmdb_movies['title_year'] = pd.to_datetime(tmdb_movies['release_date']).apply(lambda x: x.year)\n    # I'm assuming that the first production country is equivalent, but have not been able to validate this\n    tmdb_movies['country'] = tmdb_movies['production_countries'].apply(lambda x: safe_access(x, [0, 'name']))\n    tmdb_movies['language'] = tmdb_movies['spoken_languages'].apply(lambda x: safe_access(x, [0, 'name']))\n    tmdb_movies['director_name'] = credits['crew'].apply(get_director)\n    tmdb_movies['actor_1_name'] = credits['cast'].apply(lambda x: safe_access(x, [1, 'name']))\n    tmdb_movies['actor_2_name'] = credits['cast'].apply(lambda x: safe_access(x, [2, 'name']))\n    tmdb_movies['actor_3_name'] = credits['cast'].apply(lambda x: safe_access(x, [3, 'name']))\n    tmdb_movies['genres'] = tmdb_movies['genres'].apply(pipe_flatten_names)\n    tmdb_movies['plot_keywords'] = tmdb_movies['plot_keywords'].apply(pipe_flatten_names)\n    return tmdb_movies"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"0c0b0e9d7ea7a22738c185ef93b1569c8beb55aa","_cell_guid":"dc8fd9a6-1e29-4ae0-8df4-ef2f327b1951"},"outputs":[],"source":"#______________\n# the packages\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode,iplot\ninit_notebook_mode(connected=True)\n#___________________\n# and the dataframe\ncredits = load_tmdb_credits(\"../input/tmdb_5000_credits.csv\")\nmovies = load_tmdb_movies(\"../input/tmdb_5000_movies.csv\")\ndf = convert_to_original_format(movies, credits)\n#___________________________\n# countries in the dataframe\ndf['country'].unique()"},{"cell_type":"markdown","metadata":{"_uuid":"c83e29977f6646b4393f840c1fb7d622c4ec269d","_cell_guid":"8ad4be8f-9e08-41f2-8eff-4e3d9d0f3f7e"},"source":"We extract the number of films per country."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"a6ba715797d8d2ff94136dffa9acea3dfd7b9067","_cell_guid":"0a90ed16-fccd-4de8-9dca-423f5cba0326","collapsed":true},"outputs":[],"source":"df_countries = df['title_year'].groupby(df['country']).count()\ndf_countries = df_countries.reset_index()\ndf_countries.rename(columns ={'title_year':'count'}, inplace = True)\ndf_countries = df_countries.sort_values('count', ascending = False)\ndf_countries.reset_index(drop=True, inplace = True)"},{"cell_type":"markdown","metadata":{"_uuid":"141e27596d6a6a2308adc67de29e7f41788d1378","_cell_guid":"37818a51-a4c1-4b59-9d2f-bd0562bc7377"},"source":"Now we create a pie chart with the number of films per country."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"3a86af1f243a413194b3be324dcef52aa9af290c","_cell_guid":"a7c24332-c411-4ae4-b806-be9960a72ca0"},"outputs":[],"source":"sns.set_context(\"poster\", font_scale=0.6)\nplt.rc('font', weight='bold')\nf, ax = plt.subplots(figsize=(11, 6))\nlabels = [s[0] if s[1] > 80 else ' ' \n          for index, s in  df_countries[['country', 'count']].iterrows()]\nsizes  = df_countries['count'].values\nexplode = [0.0 if sizes[i] < 100 else 0.0 for i in range(len(df_countries))]\nax.pie(sizes, explode = explode, labels = labels,\n       autopct = lambda x:'{:1.0f}%'.format(x) if x > 1 else '',\n       shadow=False, startangle=45)\nax.axis('equal')\nax.set_title('% of films per country',\n             bbox={'facecolor':'k', 'pad':5},color='w', fontsize=16);"},{"cell_type":"markdown","metadata":{"_uuid":"9a887f41d2962b507ba1a07be3a82bafb6a6213c","_cell_guid":"8043e007-78be-4d7a-94d5-bef6298384a6"},"source":"As one would have expected, most of the movies were created in the united states.\n\nNext, we create a so-called chloropleth map."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"2be8f2e07b91c4b31e7029cbfc87986ea9c38b25","_cell_guid":"23aa283e-14fc-4a65-bc3f-f3d9f9032344","collapsed":true},"outputs":[],"source":"data = dict(type='choropleth',\nlocations = df_countries['country'],\nlocationmode = 'country names', z = df_countries['count'],\ntext = df_countries['country'], colorbar = {'title':'Films nb.'},\ncolorscale=[[0, 'rgb(224,255,255)'],\n            [0.01, 'rgb(166,206,227)'], [0.02, 'rgb(31,120,180)'],\n            [0.03, 'rgb(178,223,138)'], [0.05, 'rgb(51,160,44)'],\n            [0.10, 'rgb(251,154,153)'], [0.20, 'rgb(255,255,0)'],\n            [1, 'rgb(227,26,28)']],    \nreversescale = False)\n\nlayout = dict(title='Number of films in the TMDB database',\ngeo = dict(showframe = True, projection={'type':'Mercator'}))"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"db8405c28841f0eef3d9d6d19cde6d359371cafb","_cell_guid":"ba259022-37f8-4032-be1e-a0ee0dcdc787"},"outputs":[],"source":"choromap = go.Figure(data = [data], layout = layout)\niplot(choromap, validate=False)"},{"cell_type":"markdown","metadata":{"_uuid":"b4ca62e189fc0441af3ce41b70eefdb8282cf0b8","_cell_guid":"f3882dcd-fa7e-46f4-b07c-162a4e5b923f"},"source":"# Part 2: Keyword Analysis"},{"cell_type":"markdown","metadata":{"_uuid":"758e705ce3debc21fe7401170ac697db1d90fa6e","_cell_guid":"95572bc1-d870-46be-a652-0f684be4b2ec"},"source":"## 4.1 Cleaning the data"},{"cell_type":"markdown","metadata":{"_uuid":"4f39fd85bc44b98604821affcd8b548a6d09a01b","_cell_guid":"64e61193-d281-4489-8318-70027a3f1428"},"source":"For the analysis of the keywords, we will be using the same method we applied in the genre analysis. However, before it is possible for us to analyze the data, it needs a lot of cleaning. To clean the data, we use the same method as applied in this notebook: https://www.kaggle.com/fabiendaniel/film-recommendation-engine."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"ff53f1fb182b8fb7715061d880c3fade97fd28ed","_cell_guid":"ebcbf390-ae7c-467b-93b6-53fcd21721c2","collapsed":true},"outputs":[],"source":"def load_tmdb_movies(path):\n    df = pd.read_csv(path)\n    df['release_date'] = pd.to_datetime(df['release_date']).apply(lambda x: x.date())\n    json_columns = ['genres', 'keywords', 'production_countries', 'production_companies', 'spoken_languages']\n    for column in json_columns:\n        df[column] = df[column].apply(json.loads)\n    return df\n\ndef load_tmdb_credits(path):\n    df = pd.read_csv(path)\n    json_columns = ['cast', 'crew']\n    for column in json_columns:\n        df[column] = df[column].apply(json.loads)\n    return df\n\ndef pipe_flatten_names(keywords):\n    return '|'.join([x['name'] for x in keywords])\n\ncredits = load_tmdb_credits(\"../input/tmdb_5000_credits.csv\")\nmovies = load_tmdb_movies(\"../input/tmdb_5000_movies.csv\")\n\ndel credits['title']\ndf = pd.concat([movies, credits], axis=1)\n\ndf['keywords'] = df['keywords'].apply(pipe_flatten_names)\n\nliste_keywords = set()\nfor s in df['keywords'].str.split('|'):\n    liste_keywords = set().union(s, liste_keywords)\nliste_keywords = list(liste_keywords)\nliste_keywords.remove('')"},{"cell_type":"markdown","metadata":{"_uuid":"3558613a32f77fc099db1313f1708a1cb26a5ddf","_cell_guid":"3a07116e-6989-417d-b81c-f3f77161cbf2"},"source":"We are interested in which keywords occur the most in our dataset. We use the following function to count them."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"45263cc1e370bd97d98ee79804f0b0e6ce21c23e","_cell_guid":"355fe9fa-0ce5-47d4-b891-6129f82ac341","collapsed":true},"outputs":[],"source":"def count_word(df, ref_col, liste):\n    keyword_count = dict()\n    for s in liste: keyword_count[s] = 0\n    for liste_keywords in df[ref_col].str.split('|'):        \n        if type(liste_keywords) == float and pd.isnull(liste_keywords): continue        \n        for s in [s for s in liste_keywords if s in liste]: \n            if pd.notnull(s): keyword_count[s] += 1\n    #______________________________________________________________________\n    # convert the dictionary in a list to sort the keywords by frequency\n    keyword_occurences = []\n    for k,v in keyword_count.items():\n        keyword_occurences.append([k,v])\n    keyword_occurences.sort(key = lambda x:x[1], reverse = True)\n    return keyword_occurences, keyword_count"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"8831f7188ce42c1bd4bca36b9067d73ca686f3d6","_cell_guid":"8ee8b2eb-307f-42c7-8fd0-2df84d1b1285"},"outputs":[],"source":"keyword_occurences, dum = count_word(df, 'keywords', liste_keywords)\nkeyword_occurences[:5]"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"188f2927af52908a7c1f49681f32734ab7521417","_cell_guid":"04315b1b-14c3-4600-837f-a7f21f9aa620","collapsed":true},"outputs":[],"source":"# Collect the keywords\n#----------------------\ndef keywords_inventory(dataframe, colonne = 'keywords'):\n    PS = nltk.stem.PorterStemmer()\n    keywords_roots  = dict()  # collect the words / root\n    keywords_select = dict()  # association: root <-> keyword\n    category_keys = []\n    icount = 0\n    for s in dataframe[colonne]:\n        if pd.isnull(s): continue\n        for t in s.split('|'):\n            t = t.lower() ; racine = PS.stem(t)\n            if racine in keywords_roots:                \n                keywords_roots[racine].add(t)\n            else:\n                keywords_roots[racine] = {t}\n    \n    for s in keywords_roots.keys():\n        if len(keywords_roots[s]) > 1:  \n            min_length = 1000\n            for k in keywords_roots[s]:\n                if len(k) < min_length:\n                    clef = k ; min_length = len(k)            \n            category_keys.append(clef)\n            keywords_select[s] = clef\n        else:\n            category_keys.append(list(keywords_roots[s])[0])\n            keywords_select[s] = list(keywords_roots[s])[0]\n                   \n    print(\"Nb of keywords in variable '{}': {}\".format(colonne,len(category_keys)))\n    return category_keys, keywords_roots, keywords_select"},{"cell_type":"markdown","metadata":{"_uuid":"623d35dbec360bc01335febc9649d31d1c2b830b","_cell_guid":"e1386592-33d3-48e7-9c42-ef2ca42948aa"},"source":"Of course, different movies use different keywords for their movies. A problem is, that often a lot of those keywords are the same, although they are communicated in a different form by the different movie producers. The function above inventorizes the different keywords using nltk. The package identifies the 'roots' of different words and groups the different words according to its root. Then, we can replace the words that have a common root with their root. In this way, similar words that are phrased differently are assigned a common 'root'.\n\nWhen executing the function, it also shows the amount of different keywords, 9474 in our case."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"f9c265a6856aa0973a4cd957efef72bdf653aaa1","_cell_guid":"aedc2c92-b971-4720-99fc-f21f2a8caf03"},"outputs":[],"source":"keywords, keywords_roots, keywords_select = keywords_inventory(df, colonne = 'keywords')"},{"cell_type":"markdown","metadata":{"_uuid":"fb941a8657333067c5e9026d448ba27567105c0b","_cell_guid":"3c720172-2e86-4ea3-9e3b-ca44cf130fff"},"source":"Below are 14 examples of different words with similar roots."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"57be28c33a9ae4105b8184e95ebfae1eabb02105","_cell_guid":"00011593-376b-4435-9d72-f3721336277d"},"outputs":[],"source":"# Plot of a sample of keywords that appear in close varieties \n#------------------------------------------------------------\nicount = 0\nfor s in keywords_roots.keys():\n    if len(keywords_roots[s]) > 1: \n        icount += 1\n        if icount < 15: print(icount, keywords_roots[s], len(keywords_roots[s]))"},{"cell_type":"markdown","metadata":{"_uuid":"11ace91b5c6516333994ede6bd69e61dde53d246","_cell_guid":"18e3cc58-d0af-4cdc-800c-aca70cd99be3"},"source":"The function below replaces the different forms of the words by their root."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"f06e877fbfd02e930079d5cd1841390bab5fe0c9","_cell_guid":"f0016fc8-6849-4e31-b3f0-ca6d061b67be","collapsed":true},"outputs":[],"source":"def remplacement_df_keywords(df, dico_remplacement, roots = False):\n    df_new = df.copy(deep = True)\n    for index, row in df_new.iterrows():\n        chaine = row['keywords']\n        if pd.isnull(chaine): continue\n        nouvelle_liste = []\n        for s in chaine.split('|'): \n            clef = PS.stem(s) if roots else s\n            if clef in dico_remplacement.keys():\n                nouvelle_liste.append(dico_remplacement[clef])\n            else:\n                nouvelle_liste.append(s)       \n        df_new.set_value(index, 'keywords', '|'.join(nouvelle_liste)) \n    return df_new"},{"cell_type":"markdown","metadata":{"_uuid":"7ab69aee60884047dd1ce0b4e1e6ca430efac217","_cell_guid":"c158da81-469c-4c45-a563-b674f22c98ca"},"source":"We store the cleaned keywords in a new dataframe."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"4540b04695c62d597c6d726911c0d3189fcb67a9","_cell_guid":"02571d3e-c36c-42e9-9344-813835131bd6","collapsed":true},"outputs":[],"source":"df_keywords_cleaned = remplacement_df_keywords(df, keywords_select,\n                                               roots = True)"},{"cell_type":"markdown","metadata":{"_uuid":"2354befbd7f6484a36b88ba17581e4d3132b3dce","_cell_guid":"92873a33-3f92-4eed-ab61-4005b8ceab33"},"source":"Next, we will use the nltk package to get rid of synonyms. The function below take a word as a parameter and returns all of the synonyms of that word according to the nltk package."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"b4c29a9af2b9815640bfe6cfa5e5b91720191e17","_cell_guid":"394937ca-820d-45a3-96f5-e965f1a3820a","collapsed":true},"outputs":[],"source":"def get_synonymes(word):\n    lemma = set()\n    for ss in wordnet.synsets(word):\n        for w in ss.lemma_names():\n            #_______________________________\n            # We just get the 'nouns':\n            index = ss.name().find('.')+1\n            if ss.name()[index] == 'n': lemma.add(w.lower().replace('_',' '))\n    return lemma   "},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"74a3d6cc5ceaecaf377534b1ec48385506e9ccbb","_cell_guid":"3d874dad-21bc-4804-b07b-dc9e89dee77b","collapsed":true},"outputs":[],"source":"def test_keyword(mot, key_count, threshold):\n    return (False , True)[key_count.get(mot, 0) >= threshold]"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"2dd6645757f7b5257996290c0ed2b8d124a17681","_cell_guid":"9d0c9a84-5709-4a4b-b429-4660c3702288"},"outputs":[],"source":"keyword_occurences.sort(key = lambda x:x[1], reverse = False)\nkey_count = dict()\nfor s in keyword_occurences:\n    key_count[s[0]] = s[1]\n#__________________________________________________________________________\n# Creation of a dictionary to replace keywords by higher frequency keywords\nremplacement_mot = dict()\nicount = 0\nfor index, [mot, nb_apparitions] in enumerate(keyword_occurences):\n    if nb_apparitions > 5: continue  # only the keywords that appear less than 5 times\n    lemma = get_synonymes(mot)\n    if len(lemma) == 0: continue     # case of the plurals\n    #_________________________________________________________________\n    liste_mots = [(s, key_count[s]) for s in lemma \n                  if test_keyword(s, key_count, key_count[mot])]\n    liste_mots.sort(key = lambda x:(x[1],x[0]), reverse = True)    \n    if len(liste_mots) <= 1: continue       # no replacement\n    if mot == liste_mots[0][0]: continue    # replacement by himself\n    icount += 1\n    if  icount < 8:\n        print('{:<12} -> {:<12} (init: {})'.format(mot, liste_mots[0][0], liste_mots))    \n    remplacement_mot[mot] = liste_mots[0][0]\n\nprint(90*'_'+'\\n'+'The replacement concerns {}% of the keywords.'\n      .format(round(len(remplacement_mot)/len(keywords)*100,2)))"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"71f9c78e67c27cb6cdf73bdac290d44c63577d3e","_cell_guid":"099d8891-79cb-475f-97f5-42819407e392"},"outputs":[],"source":"# 2 successive replacements\n#---------------------------\nprint('Keywords that appear both in keys and values:'.upper()+'\\n'+45*'-')\nicount = 0\nfor s in remplacement_mot.values():\n    if s in remplacement_mot.keys():\n        icount += 1\n        if icount < 10: print('{:<20} -> {:<20}'.format(s, remplacement_mot[s]))\n\nfor key, value in remplacement_mot.items():\n    if value in remplacement_mot.keys():\n        remplacement_mot[key] = remplacement_mot[value]                    "},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"03804e858d8aec0eb60673c8ab05d536b5648f04","_cell_guid":"4e5e80c6-face-4d87-8c15-65f9f46351da"},"outputs":[],"source":"# replacement of keyword varieties by the main keyword\n#----------------------------------------------------------\ndf_keywords_synonyms = remplacement_df_keywords(df_keywords_cleaned, remplacement_mot, roots = False)   \nkeywords, keywords_roots, keywords_select = keywords_inventory(df_keywords_synonyms, colonne = 'keywords')"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"46a194221c81dbe05ea6641de6239b35f8168282","_cell_guid":"b29fa491-89db-4d7b-81ef-4aec67d1c8ef"},"outputs":[],"source":"# New count of keyword occurences\n#-------------------------------------\nkeywords.remove('')\nnew_keyword_occurences, keywords_count = count_word(df_keywords_synonyms,\n                                                    'keywords',keywords)\nnew_keyword_occurences[:5]"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"b06b80fe0223ef55f312c209b052fdf25aeb4ca2","_cell_guid":"be9b7a3b-cb6d-41b6-bee9-d9b038c8881c","collapsed":true},"outputs":[],"source":"# deletion of keywords with low frequencies\n#-------------------------------------------\ndef remplacement_df_low_frequency_keywords(df, keyword_occurences):\n    df_new = df.copy(deep = True)\n    key_count = dict()\n    for s in keyword_occurences: \n        key_count[s[0]] = s[1]    \n    for index, row in df_new.iterrows():\n        chaine = row['keywords']\n        if pd.isnull(chaine): continue\n        nouvelle_liste = []\n        for s in chaine.split('|'): \n            if key_count.get(s, 4) > 3: nouvelle_liste.append(s)\n        df_new.set_value(index, 'keywords', '|'.join(nouvelle_liste))\n    return df_new"},{"cell_type":"markdown","metadata":{"_uuid":"7d7c5abf915226134c79b71beb52746108cba654","_cell_guid":"a654c4cf-3f61-4951-a14d-30dbfaf3a87b"},"source":"If we analyze the amount of keywords again, we see a drastic decrease in different keywords"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"f9779521965b7bea188da18bf3bc90fa0ae61014","_cell_guid":"9060c10d-d54a-4953-b40b-eb5d7dfe35ad"},"outputs":[],"source":"# Creation of a dataframe where keywords of low frequencies are suppressed\n#-------------------------------------------------------------------------\ndf_keywords_occurence = remplacement_df_low_frequency_keywords(df_keywords_synonyms, new_keyword_occurences)\nkeywords, keywords_roots, keywords_select = keywords_inventory(df_keywords_occurence, colonne = 'keywords')   "},{"cell_type":"markdown","metadata":{"_uuid":"964a09258935f1c2b2145c2f19d2f48ee6721852","_cell_guid":"3b5e62ce-4abf-4f0c-919c-f84ec3508ec4"},"source":"We now show the 50 most occuring keywords in a histogram"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"11965f950543a2ac70f277d8a522fccc5eefa312","_cell_guid":"1d8eb4a4-ef5f-4038-9f27-296828de71c2"},"outputs":[],"source":"fig = plt.figure(1, figsize=(18,13))\ntrunc_occurences = new_keyword_occurences[0:50]\n# LOWER PANEL: HISTOGRAMS\nax2 = fig.add_subplot(2,1,2)\ny_axis = [i[1] for i in trunc_occurences]\nx_axis = [k for k,i in enumerate(trunc_occurences)]\nx_label = [i[0] for i in trunc_occurences]\nplt.xticks(rotation=85, fontsize = 15)\nplt.yticks(fontsize = 15)\nplt.xticks(x_axis, x_label)\nplt.ylabel(\"Nb. of occurences\", fontsize = 18, labelpad = 10)\nax2.bar(x_axis, y_axis, align = 'center', color='g')\n#_______________________\nplt.title(\"Keywords popularity\",bbox={'facecolor':'k', 'pad':5},color='w',fontsize = 25)\nplt.show()"},{"cell_type":"markdown","metadata":{"_uuid":"cdf26b798ff2cd0903ff4ac0c51dd815c010985f","_cell_guid":"1785dfa0-fac4-484f-a4a3-b56df36994d0"},"source":"Lastly, we rename our new dataset."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"34cdaeb66f88d9f228b9b90fbeec107aa52fa4c3","_cell_guid":"0b15f589-ebb2-4ed0-ad85-6781b699ef7c","collapsed":true},"outputs":[],"source":"df2 = df_keywords_occurence"},{"cell_type":"markdown","metadata":{"_uuid":"e31dcc4455f72eed4c24098e06339366e891e1bd","_cell_guid":"91b0aa9a-35fc-4644-b15d-6fc08bea8488"},"source":"## 4.2 Analysis"},{"cell_type":"markdown","metadata":{"_uuid":"10a1e9f88de6fed02bd3f8e79f3c84343b480226","_cell_guid":"b9658ad8-0dd2-442b-a13a-dd613ba69ff2"},"source":"For our analysis of the keywords, not every single column is relevent, so we remove a couple of columns from the dataset, the same way we did before. We also add a column for every single keyword, containing a 1 or 0 depending on whether that keyword belongs to a specific movie or not.\n\nThen, we are interested in computing the means of several categories for all the keywords, the same way as we did with the genres."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"8ae19f7cb2daddac842d8ddf442f9a592385203e","_cell_guid":"33bf561b-7404-4d82-9aa8-4bf7717e5807","collapsed":true},"outputs":[],"source":"liste_keywords = set()\nfor s in df2['keywords'].str.split('|'):\n    liste_keywords = set().union(s, liste_keywords)\nliste_keywords = list(liste_keywords)\nliste_keywords.remove('')"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"e53b285581090829cfeb1de5042a77103b299ae8","scrolled":true,"_cell_guid":"df7892da-0889-46e3-989d-7c322a9bdf93"},"outputs":[],"source":"df_reduced = df2[['title','vote_average','release_date','runtime','budget','revenue']].reset_index(drop=True)\n\nfor keywords in liste_keywords:\n    df_reduced[keywords] = df2['keywords'].str.contains(keywords).apply(lambda x:1 if x else 0)\ndf_reduced[:5]\n\ndf_reduced.head()"},{"cell_type":"markdown","metadata":{"_uuid":"4650ebf8a5f981a03e47bd54e2dfedfbef726792","_cell_guid":"4f36fb29-540f-4e01-93d8-f2da4ad47320"},"source":"Our way of computing the means for all the keywords, cannot handle brackets in the name of the keyword, meaning we have to remove them. We identified three keywords containing brackets, we remove them as follows:"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"6f2119cbd3ae0e0064c82e4920d2c59d13ca795e","_cell_guid":"77bce843-48d0-490b-8151-93d2b0622e0a","collapsed":true},"outputs":[],"source":"liste_keywords.remove('national security agency (nsa)')\nliste_keywords.remove('middle-earth (tolkien)')\nliste_keywords.remove('lover (female)')"},{"cell_type":"markdown","metadata":{"_uuid":"ffaabd11260753f618712e733eb8b51a7069b361","_cell_guid":"d8b936c4-7db6-4529-a392-675e7edc7489"},"source":"Now, we use the exact same way as we did with the genres to compute several averages for the keywords."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"283c1606daae53282d196e0612407da9646593fa","_cell_guid":"4256a228-14ed-4af0-988b-a3de84f52c85","collapsed":true},"outputs":[],"source":"mean_per_keywords = pd.DataFrame(liste_keywords)\n\n#Mean votes average\nnewArray = []*len(liste_keywords)\nfor keywords in liste_keywords:\n    newArray.append(df_reduced.groupby(keywords, as_index=True)['vote_average'].mean())\nnewArray2 = []*len(liste_keywords)\nfor i in range(len(liste_keywords)):\n    # print(newArray[i][1], i)\n    newArray2.append(newArray[i][1])\n\nmean_per_keywords['mean_votes_average']=newArray2\n\n#Mean budget\nnewArray = []*len(liste_keywords)\nfor keywords in liste_keywords:\n    newArray.append(df_reduced.groupby(keywords, as_index=True)['budget'].mean())\nnewArray2 = []*len(liste_keywords)\nfor i in range(len(liste_keywords)):\n    newArray2.append(newArray[i][1])\n\nmean_per_keywords['mean_budget']=newArray2\n\n#Mean revenue \nnewArray = []*len(liste_keywords)\nfor keywords in liste_keywords:\n    newArray.append(df_reduced.groupby(keywords, as_index=True)['revenue'].mean())\nnewArray2 = []*len(liste_keywords)\nfor i in range(len(liste_keywords)):\n    newArray2.append(newArray[i][1])\n\nmean_per_keywords['mean_revenue']=newArray2\n\nmean_per_keywords['profit'] = mean_per_keywords['mean_revenue']-mean_per_keywords['mean_budget']\n\nmean_per_keywords.head()"},{"cell_type":"markdown","metadata":{"_uuid":"41427f335ad3f2d8aa6e4ef7ba1841aa3d086d21","_cell_guid":"1a52f816-f322-4c77-a2f8-e3a409055f0b"},"source":"Let's give a small impression of the means. We show the five largest for every category."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"6437ab40a1162fdb9525d6548d6034c74837ba9e","_cell_guid":"ff9eae61-134a-4f34-bc91-e67549aca881","collapsed":true},"outputs":[],"source":"mean_per_keywords.sort_values('mean_votes_average', ascending=False).head()"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"dbf3ae700777941f1189d56fe0e4c67cea840bd1","_cell_guid":"539bd499-f362-4f54-8011-311d58655f57","collapsed":true},"outputs":[],"source":"mean_per_keywords.sort_values('mean_budget', ascending=False).head()"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"88802913f49b50246cee5a06063326762c0fcc9b","_cell_guid":"0105ad9c-4618-4df7-8617-50b654c24525","collapsed":true},"outputs":[],"source":"mean_per_keywords.sort_values('mean_revenue', ascending=False).head()"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"c7d688b4101de402644043f701686359c8fb1349","_cell_guid":"4ba2f2be-20cc-4217-9a7c-3b945f457d1f","collapsed":true},"outputs":[],"source":"mean_per_keywords.sort_values('profit', ascending=False).head()"},{"cell_type":"markdown","metadata":{"_uuid":"72d9a87d6426e120cba541eb142dbe45f1a38d06","_cell_guid":"b6b066aa-b70d-4cd6-aae1-a85025f06664"},"source":"For the highest average votes, it is fairly difficult to identify themes. However, in the other three categories we can identify some of the biggest blockbuster movies. Jurassic Park, Harry Potter, the Lord of the Rings and the Marvel Universe all seem to be represented. This is not surprising at all, one would expect these movies to have a high budget and make a lot of money!"},{"cell_type":"markdown","metadata":{"_uuid":"c7b121db147436b1c876d60278ac12e680fa4454","_cell_guid":"de934269-6b48-40ea-afb9-fe50fdfff250"},"source":"We can further visualize our findings using bar plots. In order to do so we restructure our dataframe a little bit."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"478889d1827eb67dfde81b251de016a9992b20dd","_cell_guid":"c0d1cc43-f84c-4ada-8b1f-e0728d3a25f2","collapsed":true},"outputs":[],"source":"mean_per_keywords.index = mean_per_keywords.loc[:,0]\nmean_per_keywords = mean_per_keywords.drop(0,axis=1)"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"0433788599f14546933714c77501c1d8dc6e0794","scrolled":false,"_cell_guid":"579a054d-aa3c-4e5c-8656-bb163cc077a0","collapsed":true},"outputs":[],"source":"df = mean_per_keywords.sort_values('mean_votes_average', ascending=False)\ndf = df[0:50]\nfig = plt.figure(1, figsize=(18,13))\n\nimport matplotlib.pyplot as plt\nax = df['mean_votes_average'].plot(kind='bar', title =\"mean_vote_average\", figsize=(15, 4), \n                                   legend=True, fontsize=12, color='green')\nax.set_xlabel(\"Keyword\", fontsize=12)\nax.set_ylabel(\"mean_votes_average\", fontsize=12)\nplt.show()"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"5ab0336b3650f0d1db10efe56f72151f74459776","_cell_guid":"505bb214-dd68-4a62-ba2b-dd88775e084a","collapsed":true},"outputs":[],"source":"df = mean_per_keywords.sort_values('mean_budget', ascending=False)\ndf = df[0:50]\nfig = plt.figure(1, figsize=(18,13))\n\nimport matplotlib.pyplot as plt\nax = df['mean_budget'].plot(kind='bar', title =\"mean_budget\", figsize=(15, 4), legend=True, fontsize=12, color='red')\nax.set_xlabel(\"Keyword\", fontsize=12)\nax.set_ylabel(\"mean_budget\", fontsize=12)\nplt.show()"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"b8145bfa23dfda2dc5ea8ee4575246dde3600153","_cell_guid":"b06b1795-3c1d-4213-8b1f-d03c7b3ab482","collapsed":true},"outputs":[],"source":"df = mean_per_keywords.sort_values('mean_revenue', ascending=False)\ndf = df[0:50]\nfig = plt.figure(1, figsize=(18,13))\n\nimport matplotlib.pyplot as plt\nax = df['mean_revenue'].plot(kind='bar', title =\"mean_revenue\", figsize=(15, 4), legend=True, fontsize=12, color='blue')\nax.set_xlabel(\"Keyword\", fontsize=12)\nax.set_ylabel(\"mean_revenue\", fontsize=12)\nplt.show()"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"cc5da347d6277160b331ac3ef5d68e3b1c4c3b78","_cell_guid":"a7889587-5c12-464e-a8b3-01b77a7b6638","collapsed":true},"outputs":[],"source":"df = mean_per_keywords.sort_values('profit', ascending=False)\ndf = df[0:50]\nfig = plt.figure(1, figsize=(18,13))\n\nimport matplotlib.pyplot as plt\nax = df['profit'].plot(kind='bar', title =\"Profit\", figsize=(15, 4), legend=True, fontsize=12, color='pink')\nax.set_xlabel(\"Keyword\", fontsize=12)\nax.set_ylabel(\"Profit\", fontsize=12)\nplt.show()"},{"cell_type":"markdown","metadata":{"_uuid":"d1522f23eff51686c88c382407c2654fc57a1184","_cell_guid":"dd8f736f-b756-41f2-bfec-1b4e5f4e64f3"},"source":"# Part 3 Cast analysis"},{"cell_type":"markdown","metadata":{"_uuid":"c327911ca0c5e3d4a8897374aeaf5bcbd1938135","_cell_guid":"de042d96-1de6-411b-917f-eea9ffe65acb"},"source":"A previous version of this dataset only contained the top three actors per movie. Since we only want to analyze the most important actors of a movie and since the old dataset was a bit more suited to do that, we convert the dataset back to its previous state using Sohier Dane's method."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"7c051ab8470bef385884db504c52e387ee485889","_cell_guid":"ea1e80d8-34ae-45b8-ac24-3ccd06d78285","collapsed":true},"outputs":[],"source":"# Columns that existed in the IMDB version of the dataset and are gone.\nLOST_COLUMNS = [\n    'actor_1_facebook_likes',\n    'actor_2_facebook_likes',\n    'actor_3_facebook_likes',\n    'aspect_ratio',\n    'cast_total_facebook_likes',\n    'color',\n    'content_rating',\n    'director_facebook_likes',\n    'facenumber_in_poster',\n    'movie_facebook_likes',\n    'movie_imdb_link',\n    'num_critic_for_reviews',\n    'num_user_for_reviews'\n                ]\n\n# Columns in TMDb that had direct equivalents in the IMDB version. \n# These columns can be used with old kernels just by changing the names\nTMDB_TO_IMDB_SIMPLE_EQUIVALENCIES = {\n    'budget': 'budget',\n    'genres': 'genres',\n    'revenue': 'gross',\n    'title': 'movie_title',\n    'runtime': 'duration',\n    'original_language': 'language',  # it's possible that spoken_languages would be a better match\n    'keywords': 'plot_keywords',\n    'vote_count': 'num_voted_users',\n                                         }\n\nIMDB_COLUMNS_TO_REMAP = {'imdb_score': 'vote_average'}\n\n\ndef safe_access(container, index_values):\n    # return a missing value rather than an error upon indexing/key failure\n    result = container\n    try:\n        for idx in index_values:\n            result = result[idx]\n        return result\n    except IndexError or KeyError:\n        return pd.np.nan\n\n\ndef get_director(crew_data):\n    directors = [x['name'] for x in crew_data if x['job'] == 'Director']\n    return safe_access(directors, [0])\n\n\ndef pipe_flatten_names(keywords):\n    return '|'.join([x['name'] for x in keywords])\n\n\ndef convert_to_original_format(movies, credits):\n    # Converts TMDb data to make it as compatible as possible with kernels built on the original version of the data.\n    tmdb_movies = movies.copy()\n    tmdb_movies.rename(columns=TMDB_TO_IMDB_SIMPLE_EQUIVALENCIES, inplace=True)\n    tmdb_movies['title_year'] = pd.to_datetime(tmdb_movies['release_date']).apply(lambda x: x.year)\n    # I'm assuming that the first production country is equivalent, but have not been able to validate this\n    tmdb_movies['country'] = tmdb_movies['production_countries'].apply(lambda x: safe_access(x, [0, 'name']))\n    tmdb_movies['language'] = tmdb_movies['spoken_languages'].apply(lambda x: safe_access(x, [0, 'name']))\n    tmdb_movies['director_name'] = credits['crew'].apply(get_director)\n    tmdb_movies['actor_1_name'] = credits['cast'].apply(lambda x: safe_access(x, [1, 'name']))\n    tmdb_movies['actor_2_name'] = credits['cast'].apply(lambda x: safe_access(x, [2, 'name']))\n    tmdb_movies['actor_3_name'] = credits['cast'].apply(lambda x: safe_access(x, [3, 'name']))\n    tmdb_movies['genres'] = tmdb_movies['genres'].apply(pipe_flatten_names)\n    tmdb_movies['plot_keywords'] = tmdb_movies['plot_keywords'].apply(pipe_flatten_names)\n    return tmdb_movies"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"3f150035d498a548f39c20f30aa760e04cbdbaca","_cell_guid":"239e8771-e5bf-42f4-b4d2-deaf8ec0d2af","collapsed":true},"outputs":[],"source":"credits = load_tmdb_credits(\"../input/tmdb_5000_credits.csv\")\nmovies = load_tmdb_movies(\"../input/tmdb_5000_movies.csv\")\ndf = convert_to_original_format(movies, credits)"},{"cell_type":"markdown","metadata":{"_uuid":"3afe50e7996ebe60dc49d0b0d19ef0ae48654e68","_cell_guid":"21b7a3e2-bfa2-4c34-ada2-0b7f0cbe5cb9"},"source":"We can now see the dataframe is simplified."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"91c520fc393ea44eb8dd687e6bf235b2114c336f","_cell_guid":"4a7e233d-60f5-4c89-b026-4209616cb3d5","collapsed":true},"outputs":[],"source":"df"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"1a379625ed0c14aa8986767b3f19ebd02df4c9af","_cell_guid":"679bf77d-4911-4505-888a-6faa73a9e848","collapsed":true},"outputs":[],"source":"df3 = df # We store a copy of the dataframe for later use"},{"cell_type":"markdown","metadata":{"_uuid":"9c3f4025183e23ae7b263b06139914e0852f7761","_cell_guid":"e9ea9295-f4a0-4d1f-b07f-a07abd875683"},"source":"Next, we delete all the columns we won't be needing for this analysis."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"0341e759612658ef66090889421e3277b1ca7044","_cell_guid":"b8a17b81-b518-4242-8e20-75897d29ff36","collapsed":true},"outputs":[],"source":"columns = ['homepage', 'plot_keywords', 'language', 'overview', 'popularity', 'tagline',\n           'original_title', 'num_voted_users', 'country', 'spoken_languages', 'duration',\n          'production_companies', 'production_countries', 'status']\n\ndf = df.drop(columns, axis=1)"},{"cell_type":"markdown","metadata":{"_uuid":"e43dc876b95a699c3d46fc3e5e7d46e7e74c33fa","_cell_guid":"838a62a6-ea53-441b-a290-0feb5a979b5f"},"source":"We are interested in the same descriptives for the actors, as we were for keywords and the genres. To do that, we first have to, once again, restructure the dataframe.\n\nWe first create a seperate dataframe for each of the three actors, after which we can combine them to get one dataframe with all three types of actor."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"cf07dcf6f2688843096d37692c37940cf4cd8af5","scrolled":false,"_cell_guid":"290ce7f8-4e63-4a91-9d9a-25d5db8f178d","collapsed":true},"outputs":[],"source":"liste_genres = set()\nfor s in df['genres'].str.split('|'):\n    liste_genres = set().union(s, liste_genres)\nliste_genres = list(liste_genres)\nliste_genres.remove('')"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"322d5f5e7376c6064567452737cf04ee04d86a7a","_cell_guid":"09428d55-d92e-4f19-9364-9fad17ceed0b","collapsed":true},"outputs":[],"source":"df_reduced = df[['actor_1_name', 'vote_average',\n                 'title_year', 'movie_title', 'gross', 'budget']].reset_index(drop = True)\nfor genre in liste_genres:\n    df_reduced[genre] = df['genres'].str.contains(genre).apply(lambda x:1 if x else 0)\n\ndf_reduced2 = df[['actor_2_name', 'vote_average',\n                 'title_year', 'movie_title', 'gross', 'budget']].reset_index(drop = True)\nfor genre in liste_genres:\n    df_reduced2[genre] = df['genres'].str.contains(genre).apply(lambda x:1 if x else 0)\n\ndf_reduced3 = df[['actor_3_name', 'vote_average',\n                 'title_year', 'movie_title', 'gross', 'budget']].reset_index(drop = True)\nfor genre in liste_genres:\n    df_reduced3[genre] = df['genres'].str.contains(genre).apply(lambda x:1 if x else 0)"},{"cell_type":"markdown","metadata":{"_uuid":"d5b5829b51687e63c1fe374883f702309ac193c6","_cell_guid":"f67e6794-288a-443d-ae9c-92e38e8d080e"},"source":"Next, we combine the three dataframes."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"74bc74ee91f75080b9d26cdce67ac451f1ac0ee9","_cell_guid":"8bf4c9c9-3ad1-4317-bef0-e737a8290fdd","collapsed":true},"outputs":[],"source":"df_reduced = df_reduced.rename(columns={'actor_1_name': 'actor'})\ndf_reduced2 = df_reduced2.rename(columns={'actor_2_name': 'actor'})\ndf_reduced3 = df_reduced3.rename(columns={'actor_3_name': 'actor'})\n\ntotal = [df_reduced, df_reduced2, df_reduced3]\ndf_total = pd.concat(total)\ndf_total"},{"cell_type":"markdown","metadata":{"_uuid":"786b742ab69d71f8d897e5e0db294e860506754c","_cell_guid":"e08ba722-e33d-4db3-b17e-22960d25595e"},"source":"We compute averages for all actors in two categories: vote_average and title_year. We also compute an actors favorite genre."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"5baa2e4793bc92533813c85280e1ab14bfd9ca80","_cell_guid":"c5e54fa7-ef34-4e16-b5e8-437a9d77d200","collapsed":true},"outputs":[],"source":"df_actors = df_total.groupby('actor').mean()\ndf_actors.loc[:, 'favored_genre'] = df_actors[liste_genres].idxmax(axis = 1)\ndf_actors.drop(liste_genres, axis = 1, inplace = True)\ndf_actors = df_actors.reset_index()"},{"cell_type":"markdown","metadata":{"_uuid":"d9327f0dae7c75eb41456af003ae96f96cd48621","_cell_guid":"b5374797-b029-44f2-ab6e-5cf5561e1586"},"source":"We expect the dataframe to contain a lot of actors that have only a single observation. These observation are likely to cause outliers if these observations are very extreme. We delete all actors that are linked to less than 10 movies in our dataframe."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"b58d9ab9aa43ae5a3b933a3fc50d93585e02153d","_cell_guid":"31e1a610-d54e-49d7-af53-b34b7372f29d","collapsed":true},"outputs":[],"source":"df_appearance = df_total[['actor', 'title_year']].groupby('actor').count()\ndf_appearance = df_appearance.reset_index(drop = True)\nselection = df_appearance['title_year'] > 9\nselection = selection.reset_index(drop = True)\nmost_prolific = df_actors[selection]"},{"cell_type":"markdown","metadata":{"_uuid":"601c5ae12e303fb0701ad6fa9ed80d59e4855af8","_cell_guid":"0f1c010a-67e0-4b7b-995c-725edd43da09"},"source":"Now that we have a clear dataframe, let us show some descriptive statistics. We first sort the dataframe on all the different attributes from highest to lowest."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"cc097ff1d0ad1ad77aa70481f9a2bb6a012485de","_cell_guid":"6ad62202-35fe-4c1a-8e7d-42f5bfca00f0","collapsed":true},"outputs":[],"source":"most_prolific.sort_values('vote_average', ascending=False).head()"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"f74696d2ceaf81050d34489e2ac95792a5c9c42e","_cell_guid":"98291ca6-b15f-4321-a881-9969f6f35fe9","collapsed":true},"outputs":[],"source":"most_prolific.sort_values('gross', ascending=False).head()"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"261766ed7126d17d82c3e23b4fbb738dcd617ccd","_cell_guid":"9b22e626-5e38-4ffb-87c9-ca529f1817c3","collapsed":true},"outputs":[],"source":"most_prolific.sort_values('budget', ascending=False).head()"},{"cell_type":"markdown","metadata":{"_uuid":"1e1403eb1b859385ab642a7303cd0b5f48bed6d7","_cell_guid":"98cfaac1-8200-42cb-8846-ff80234ab726"},"source":"Looks like Sir Ian McKellen has had quite a career. He came out on top on all three of our attributes. He plays in the movies with the highsest budget, but returns this with the highest average revenues. It makes sense that these enormous budgets lead to good movies. This is reflected by him having the highest average score on IMDB.\n\nWe can now develop several plots to analyze our actors. Let us start by plotting the average budget per actor and the average revenue per actor."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"530ded832f989dc42839605b8cf599c8ba7d8dde","_cell_guid":"86a1357c-d5fc-47c5-82b9-623c6389424e","collapsed":true},"outputs":[],"source":"genre_count = []\nfor genre in liste_genres:\n    genre_count.append([genre, df_reduced[genre].values.sum()])\ngenre_count.sort(key = lambda x:x[1], reverse = True)\nlabels, sizes = zip(*genre_count)\nlabels_selected = [n if v > sum(sizes) * 0.01 else '' for n, v in genre_count]\nreduced_genre_list = labels[:19]\ntrace=[]\nfor genre in reduced_genre_list:\n    trace.append({'type':'scatter',\n                  'mode':'markers',\n                  'y':most_prolific.loc[most_prolific['favored_genre']==genre,'gross'],\n                  'x':most_prolific.loc[most_prolific['favored_genre']==genre,'budget'],\n                  'name':genre,\n                  'text': most_prolific.loc[most_prolific['favored_genre']==genre,'actor'],\n                  'marker':{'size':10,'opacity':0.7,\n                            'line':{'width':1.25,'color':'black'}}})\nlayout={'title':'Actors favored genres',\n       'xaxis':{'title':'mean year of activity'},\n       'yaxis':{'title':'mean score'}}\nfig=Figure(data=trace,layout=layout)\npyo.iplot(fig)"},{"cell_type":"markdown","metadata":{"_uuid":"5da8b5a3626512fda737e20416fc7ea6ad7c403f","_cell_guid":"79623ddf-5029-4a9f-85d8-9a5a4bc2600b"},"source":"Except for some outliers, this looks like a very nice linear regression. This gives us the insight that overall, actors are worth their money. For most actors it is so, that if they play in a high budget movie, the movie is likely to have high revenue as well.\n\nNext, let us look at the average vote an actor receives and their mean year of activity."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"083cc11e7623d849c469d35249b3d60ab902bc97","_cell_guid":"7ee9a8a6-7c87-4b36-811a-522dbb6297ef","collapsed":true},"outputs":[],"source":"reduced_genre_list = labels[:19]\ntrace=[]\nfor genre in reduced_genre_list:\n    trace.append({'type':'scatter',\n                  'mode':'markers',\n                  'y':most_prolific.loc[most_prolific['favored_genre']==genre,'vote_average'],\n                  'x':most_prolific.loc[most_prolific['favored_genre']==genre,'title_year'],\n                  'name':genre,\n                  'text': most_prolific.loc[most_prolific['favored_genre']==genre,'actor'],\n                  'marker':{'size':10,'opacity':0.7,\n                            'line':{'width':1.25,'color':'black'}}})\nlayout={'title':'Actors favored genres',\n       'xaxis':{'title':'mean year of activity'},\n       'yaxis':{'title':'mean score'}}\nfig=Figure(data=trace,layout=layout)\npyo.iplot(fig)"},{"cell_type":"markdown","metadata":{"_uuid":"2d439d2a03088a74b01051cac152da0f0fdeeb6e","_cell_guid":"c276b969-3393-4fc3-9977-b686a3ee115e"},"source":"We can also use this data to highlight single actors. Let us take a look at actors for who we have data of more than 20 movies."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"f62c33a5ba1f688bd4eeb9090bfc383a0312ec02","_cell_guid":"9acb7377-d092-4489-aa2b-faadf8de1881","collapsed":true},"outputs":[],"source":"selection = df_appearance['title_year'] > 20\nmost_prolific = df_actors[selection]\nmost_prolific"},{"cell_type":"markdown","metadata":{"_uuid":"075fca72be48df4f41b779ae04e7d82954ee9abd","_cell_guid":"ae121bde-bdcf-4c1c-8db9-f706c762a29b"},"source":"So let's have a look at Morgan Freeman. We would like to have a clear overview of all the movies he played in and what his movies scored on IMDB. We can do this using a polar chart."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"f766b24641645a5ccef9d4ee4870ec37b946cb4d","_cell_guid":"b2400f30-f628-49bc-8fae-4710956a7aa9","collapsed":true},"outputs":[],"source":"class Trace():\n    #____________________\n    def __init__(self, color):\n        self.mode = 'markers'\n        self.name = 'default'\n        self.title = 'default title'\n        self.marker = dict(color=color, size=110,\n                           line=dict(color='white'), opacity=0.7)\n        self.r = []\n        self.t = []\n    #______________________________\n    def set_color(self, color):\n        self.marker = dict(color = color, size=110,\n                           line=dict(color='white'), opacity=0.7)\n    #____________________________\n    def set_name(self, name):\n        self.name = name\n    #____________________________\n    def set_title(self, title):\n        self.na = title\n    #__________________________\n    def set_values(self, r, t):\n        self.r = np.array(r)\n        self.t = np.array(t)"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"91385352c309ed4c6e5843dc432cf8f7ce4cfa70","_cell_guid":"03276988-81f9-46c9-83ed-15dccf88605e","collapsed":true},"outputs":[],"source":"df2 = df_reduced[df_reduced['actor'] == 'Morgan Freeman']\ntotal_count  = 0\nyears = []\nimdb_score = []\ngenre = []\ntitles = []\nfor s in liste_genres:\n    icount = df2[s].sum()\n    #__________________________________________________________________\n    # Here, we set the limit to 3 because of a bug in plotly's package\n    if icount > 3: \n        total_count += 1\n        genre.append(s)\n        years.append(list(df2[df2[s] == 1]['title_year']))\n        imdb_score.append(list(df2[df2[s] == 1]['vote_average'])) \n        titles.append(list(df2[df2[s] == 1]['movie_title']))\nmax_y = max([max(s) for s in years])\nmin_y = min([min(s) for s in years])\nyear_range = max_y - min_y\n\nyears_normed = []\nfor i in range(total_count):\n    years_normed.append( [360/total_count*((an-min_y)/year_range+i) for an in years[i]])"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"71b8e4e672cbea225d928a7aa8e3b3245a9988c5","_cell_guid":"916b942c-0dca-4931-b447-b0554d651d84","collapsed":true},"outputs":[],"source":"color = ('royalblue', 'grey', 'wheat', 'c', 'firebrick', 'seagreen', 'lightskyblue',\n          'lightcoral', 'yellowgreen', 'gold', 'tomato', 'violet', 'aquamarine', 'chartreuse')"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"9445d46d34c5b761a89d1d498ee475d450ffaf23","_cell_guid":"8653d86c-aa2c-4d3e-ab2b-b35f3b1379dc","collapsed":true},"outputs":[],"source":"trace = [Trace(color[i]) for i in range(total_count)]\ntr    = []\nfor i in range(total_count):\n    trace[i].set_name(genre[i])\n    trace[i].set_title(titles[i])\n    trace[i].set_values(np.array(imdb_score[i]),\n                        np.array(years_normed[i]))\n    tr.append(go.Scatter(r      = trace[i].r,\n                         t      = trace[i].t,\n                         mode   = trace[i].mode,\n                         name   = trace[i].name,\n                         marker = trace[i].marker,\n#                         text   = ['default title' for j in range(len(trace[i].r))], \n                         hoverinfo = 'all'\n                        ))        \nlayout = go.Layout(\n    title='Morgan Freeman movies',\n    font=dict(\n        size=15\n    ),\n    plot_bgcolor='rgb(223, 223, 223)',\n    angularaxis=dict(        \n        tickcolor='rgb(253,253,253)'\n    ),\n    hovermode='Closest',\n)\nfig = go.Figure(data = tr, layout=layout)\npyo.iplot(fig)"},{"cell_type":"markdown","metadata":{"_uuid":"c47d6018325bd5ed2e190894c8fccc9454145605","_cell_guid":"a90fd7cb-533f-4b6d-81b1-c53363cf06f9"},"source":"Unfortunately, plotly doesn't allow us to put hover text on the different notes. This means we can't add the movie name and year of release to all the different nodes."},{"cell_type":"markdown","metadata":{"_uuid":"cd2355099f830a2216532c17c31f7b512d0b485d","_cell_guid":"4b836acf-4f7d-41c4-af0d-a49043a4f0e7"},"source":"# Part 4 Director Analysis"},{"cell_type":"markdown","metadata":{"_uuid":"21056d287fcceb73add062a56ce259af786a12f6","_cell_guid":"670fe650-03f8-4d08-a3b3-db83b3d6affe"},"source":"We start by retrieving the copy of the database we created earlier."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"1b0b4a69a6a2c79f5a267692826c3ec109e17ec2","_cell_guid":"d166b531-e87c-408f-8090-6e2ce35a55d5","collapsed":true},"outputs":[],"source":"df = df3"},{"cell_type":"markdown","metadata":{"_uuid":"17c43fccbe4d2aa4b9b74d677bcfc372407aadf1","_cell_guid":"b76a75d4-6271-472c-9579-77efc3b3411a"},"source":"We start the actual analysis by computing the average per movie and total gross of the directors. We only took into account the directs for which we have at least 4 movies as observations, to exclude extreme outliers. Not surprisingly, the top rated directors are probably directors you have heard about.title_"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"a867804f2703d663f6420fec79d2aa22ecb29819","_cell_guid":"59f096cb-4cd6-4300-87fd-d28842615423","collapsed":true},"outputs":[],"source":"def create_comparison_database(name, value, x, no_films):\n    \n    comparison_df = df3.groupby(name, as_index=False)\n    \n    if x == 'mean':\n        comparison_df = comparison_df.mean()\n    elif x == 'median':\n        comparison_df = comparison_df.median()\n    elif x == 'sum':\n        comparison_df = comparison_df.sum() \n    \n    # Create database with either name of directors or actors, the value being compared i.e. 'gross',\n    # and number of films they're listed with. Then sort by value being compared.\n    name_count_key = df[name].value_counts().to_dict()\n    comparison_df['films'] = comparison_df[name].map(name_count_key)\n    comparison_df.sort_values(value, ascending=False, inplace=True)\n    comparison_df[name] = comparison_df[name].map(str) + \" (\" + comparison_df['films'].astype(str) + \")\"\n   # create a Series with the name as the index so it can be plotted to a subgrid\n    comp_series = comparison_df[comparison_df['films'] >= no_films][[name, value]][10::-1].set_index(name).ix[:,0]\n    \n    return comp_series"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"fa7c47b4bf67785e875f90b7fe5b9689a29d36fa","scrolled":false,"_cell_guid":"fdbdf305-11bd-45de-834e-784f938f1384","collapsed":true},"outputs":[],"source":"fig = plt.figure(figsize=(18,6))\n\n# Director_name\nplt.subplot2grid((2,3),(0,0), rowspan = 2)\ncreate_comparison_database('director_name','gross','sum', 4).plot(kind='barh', color='#006600')\nplt.legend().set_visible(False)\nplt.title(\"Total Gross for Directors with 4+ Films\")\nplt.ylabel(\"Director (no. films)\")\nplt.xlabel(\"Gross (in billons)\")\n\nplt.subplot2grid((2,3),(0,1), rowspan = 2)\ncreate_comparison_database('director_name','gross','mean', 4).plot(kind='barh', color='#ffff00')\nplt.legend().set_visible(False)\nplt.title('Average revenue for Directors with 4+ Films')\nplt.ylabel(\"Director (no. films)\")\nplt.xlabel(\"Gross (in billons)\")\n\nplt.tight_layout()"},{"cell_type":"markdown","metadata":{"_uuid":"b6c846371b7e2b62e25ca75acdbc36997bf284d0","_cell_guid":"f19f8656-103f-4d26-85c2-91a94c8150c6"},"source":"Next, we plot the average IMDB score and average year of activity for the directors."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"3dffadedc9ab34df34f2822068a2a0b0c4c77f75","_cell_guid":"39ca29d5-0e48-4ae5-840b-eeb65d80f299","collapsed":true},"outputs":[],"source":"fig = plt.figure(figsize=(18,6))\n\n# Director_name\nplt.subplot2grid((2,3),(0,0), rowspan = 2)\ncreate_comparison_database('director_name','budget','mean', 4).plot(kind='barh', color='#006600')\nplt.legend().set_visible(False)\nplt.title(\"Average budget for Directors with 4+ Filmss\")\nplt.ylabel(\"Director (no. films)\")\nplt.xlabel(\"Budget (in billons)\")\n\nplt.subplot2grid((2,3),(0,1), rowspan = 2)\ncreate_comparison_database('director_name','vote_average','mean', 4).plot(kind='barh', color='#ffff00')\nplt.legend().set_visible(False)\nplt.title('Mean IMDB Score for Directors with 4+ Films')\nplt.ylabel(\"Director (no. films)\")\nplt.xlabel(\"IMDB Score\")\nplt.xlim(0,10)\n\nplt.tight_layout()"},{"cell_type":"markdown","metadata":{"_uuid":"301bbade5efe50f5446659251ec0ba0cbc50ceb0","_cell_guid":"cd07f457-7546-43d0-ac14-be9df119afcd"},"source":"Notice how many of the directors that have a very high average budget per movie were nowhere to be seen in the revenue plot. Implying that, although they make expensive movies, they don't make the most grossing movies. Also note that a lot of high scoring directors are not found in the top ten highest budgeted directors. This implies that a big budget doesn't necessarily lead to a good, or well-received, movie. On the other hand, it shows that some directors, for instance Hayao Miyazaki, is capable of creating excellent movies with needing a very high budget. \n\nNow, all of this is of course only true for directors with 4+ movies. It is possible that directors with few movies were lucky. A question to ask the dataset could be whether there exist any directors that are capable of consistently creating well-received movies, without the need for big budgets. To answer this question we plot the average budget next to the average score per director, for directors with at least 15 movies."},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"797b55947a994008f9151dfa839b0f796d763135","_cell_guid":"640eb2e9-4fec-44d4-b357-a9b67c4cc0c7","collapsed":true},"outputs":[],"source":"fig = plt.figure(figsize=(18,6))\n\n# Director_name\nplt.subplot2grid((2,3),(0,0), rowspan = 2)\ncreate_comparison_database('director_name','budget','mean', 10).plot(kind='barh', color='#006600')\nplt.legend().set_visible(False)\nplt.title(\"Average budget for Directors with 15+ Filmss\")\nplt.ylabel(\"Director (no. films)\")\nplt.xlabel(\"Budget (in billons)\")\n\nplt.subplot2grid((2,3),(0,1), rowspan = 2)\ncreate_comparison_database('director_name','vote_average','mean', 10).plot(kind='barh', color='#ffff00')\nplt.legend().set_visible(False)\nplt.title('Mean IMDB Score for Directors with 15+ Films')\nplt.ylabel(\"Director (no. films)\")\nplt.xlabel(\"IMDB Score\")\nplt.xlim(0,10)\n\nplt.tight_layout()"},{"cell_type":"markdown","metadata":{"_uuid":"ac53b5f23d200ce8377834312050c013a4e8dd48","_cell_guid":"7b8a7830-b75c-4a75-b23e-7b7bd0c70a09"},"source":"Now, we easily see that the two bar plots have more directors in common. Still, there are some directors who manage to create excellent movies without the need for a big budget. A funny observation is Michael Bay. While he is easily the king of budget, he is nowhere to be found in the top ten highest scoring directors."},{"cell_type":"markdown","metadata":{"_uuid":"77cc6fc2590b85ddedfebc2a93d275f3c2e3109d","_cell_guid":"ec524f22-a859-404b-b213-fa2ad8e01ce0"},"source":"Resources:\n\nhttps://www.kaggle.com/fabiendaniel/film-recommendation-engine\n\nhttps://www.kaggle.com/fabiendaniel/categorizing-actors-hands-on-plotly\n\nhttps://www.kaggle.com/willacy/director-and-actor-s-total-gross-and-imdb-score\n\nhttps://www.kaggle.com/fabiendaniel/choropleth-map-with-plotly"},{"execution_count":null,"cell_type":"code","metadata":{"_uuid":"80474815faadc5d7d9892195302f8dd716943228","_cell_guid":"87209812-bcb8-4caa-b61c-e549544ddf05","collapsed":true},"outputs":[],"source":""}],"nbformat":4,"metadata":{"language_info":{"nbconvert_exporter":"python","version":"3.6.3","name":"python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","file_extension":".py","mimetype":"text/x-python"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}}}