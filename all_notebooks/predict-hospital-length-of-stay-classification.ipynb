{"cells":[{"metadata":{"_uuid":"93872ca38637cdc1a3144b647b710c30108387b4"},"cell_type":"markdown","source":"* The original data is from MIMIC2 - Multiparameter Intelligent Monitoring in Intensive Care (deidentified DB) available freely from \nhttps://mimic.physionet.org/\n* Each instance in the mldata.csv attached is one admission\n* Testing a theory I have, that one can predict LOS just by the number of interactions betweeen patient and hospital per day, \nLOS days was grouped 0-4, 4-8, etc.\n\nLet me know *your* results on this  dataset"},{"metadata":{"trusted":true,"_uuid":"be5e7a1a7278c138e277e90b019db4961154c731"},"cell_type":"code","source":"# IMPORT MODULES\n# TURN ON the GPU !\n\nimport os\nfrom operator import itemgetter    \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nget_ipython().magic(u'matplotlib inline')\nplt.style.use('ggplot')\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import Imputer\nfrom pandas.tools.plotting import scatter_matrix\nfrom sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder, LabelBinarizer\nfrom sklearn.metrics import mean_squared_error, accuracy_score, mean_absolute_error\n#from sklearn.cross_validation import KFold, cross_val_score\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, KFold, cross_val_predict, StratifiedKFold, train_test_split, learning_curve, ShuffleSplit\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection, preprocessing\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV,KFold, cross_val_predict, StratifiedKFold, train_test_split, learning_curve, ShuffleSplit\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC \nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV, ShuffleSplit\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_recall_curve, average_precision_score, auc\nfrom sklearn.utils.fixes import signature\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\nfrom mlxtend.plotting import plot_learning_curves\nfrom mlxtend.preprocessing import shuffle_arrays_unison\n\nimport tensorflow as tf\n\nfrom keras import models, regularizers, layers, optimizers, losses, metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import np_utils\nfrom keras.utils import to_categorical\n\nprint(os.getcwd())\nprint(\"Modules imported \\n\")\nimport os\nprint(os.listdir(\"../input/\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input/\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d624986c6d662b3dec980c593981fb913cb00c01"},"cell_type":"code","source":"# Load MIMIC2 data \n\ndata = pd.read_csv('../input/mimic3d/mimic3d.csv')\nprint(\"With id\", data.shape)\ndata_full = data.drop('hadm_id', 1)\nprint(\"No id\",data_full.shape)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"a3d700d5763270c86b368668e9ef7af00372c79c"},"cell_type":"code","source":"print(data_full.shape)\ndata_full.info()\ndata_full.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1fce3fd763d30cf516d00815bb386cd95cea14ec","scrolled":true},"cell_type":"code","source":"data_full.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"798b9834d32ba534e5aca36d5763b9624fe00565"},"cell_type":"code","source":"# Label = LOS\n\ny = data_full['LOSgroupNum']\nX = data_full.drop('LOSgroupNum', 1)\nX = X.drop('LOSdays', 1)\nX = X.drop('ExpiredHospital', 1)\nX = X.drop('AdmitDiagnosis', 1)\nX = X.drop('AdmitProcedure', 1)\nX = X.drop('marital_status', 1)\nX = X.drop('ethnicity', 1)\nX = X.drop('religion', 1)\nX = X.drop('insurance', 1)\n\nprint(\"y - Labels\", y.shape)\nprint(\"X - No Label No id \", X.shape)\nprint(X.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dfe87481713cb5fd1ca62ec4ad6178eea875fc85"},"cell_type":"code","source":"data_full.groupby('LOSgroupNum').size().plot.bar()\nplt.show()\ndata_full.groupby('admit_type').size().plot.bar()\nplt.show()\ndata_full.groupby('admit_location').size().plot.bar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8bae4396cb26c3c9c08932f56b860207a2dae336"},"cell_type":"markdown","source":"# IMPUTE missing values\n\nX.fillna(value='unknown', axis=1, inplace=True)"},{"metadata":{"trusted":true,"_uuid":"c2a17ce91d1523ebda4d7ecf75cc6a2b055f814b","scrolled":true},"cell_type":"code","source":"# Check that all X columns have no missing values\nX.info()\nX.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"45c8a4a2737cf1a44f6be54e4d4424530e59b096"},"cell_type":"code","source":"# MAP Text to Numerical Data\n# Use one-hot-encoding to convert categorical features to numerical\n\nprint(X.shape)\ncategorical_columns = [\n                    'gender',                     \n                    'admit_type',\n                    'admit_location'\n                      ]\n\nfor col in categorical_columns:\n    #if the original column is present replace it with a one-hot\n    if col in X.columns:\n        one_hot_encoded = pd.get_dummies(X[col])\n        X = X.drop(col, axis=1)\n        X = X.join(one_hot_encoded, lsuffix='_left', rsuffix='_right')\n        \nprint(X.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60be44d230f432f3f087f15a238feb21deb68bbf"},"cell_type":"code","source":"\nprint(data_full.shape)\nprint(X.shape)\n#XnotNorm = np.array(X.copy())\nXnotNorm = X.copy()\nprint('XnotNorm ', XnotNorm.shape)\n\nynotNorm = y.copy()\nprint('ynotNorm ', ynotNorm.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63cee0b5231c742bacfb4318b16959e4f6394b1b"},"cell_type":"code","source":"# Normalize X\n\nx = XnotNorm.values #returns a numpy array\nscaler = preprocessing.StandardScaler()\nx_scaled = scaler.fit_transform(x)\nXNorm = pd.DataFrame(x_scaled, columns=XnotNorm.columns)\n#print(XNorm)\n#print(y)\nprint('X normalized')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aefe400392c73d77e55bf9f2410e7b725df2e77c"},"cell_type":"code","source":"# SPLIT into Train & Test\n\nX_train, X_test, y_train, y_test = train_test_split(XNorm, y, test_size=0.2, random_state=7)\nprint ('X_train: ', X_train.shape)\nprint ('X_test: ', X_test.shape)\nprint ('y_train: ', y_train.shape)\nprint ('y_test: ', y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f03ccf0923716b07035356abcf3acb4a51d23025"},"cell_type":"code","source":"# Test Models and evaluation metric\nseed = 42\nscoring = 'accuracy' \n\n# Spot Check Algorithms\nMymodels = []\n#Mymodels.append(('LogReg', LogisticRegression()))\nMymodels.append(('RandomForestClassifier', RandomForestClassifier()))\nMymodels.append(('SGDclassifier', SGDClassifier()))\n#Mymodels.append(('KNearestNeighbors', KNeighborsClassifier()))\nMymodels.append(('DecisionTreeClassifier', DecisionTreeClassifier()))\n#Mymodels.append(('GaussianNB', GaussianNB()))\n#Mymodels.append(('SVM', SVC()))\n\n# Evaluate each model in turn\nresults = []\nnames = []\nfor name, model in Mymodels:\n    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0d67a66679ee59af083b102408c69db5646ba33"},"cell_type":"code","source":"# Optimize hyper params for one model\n\nmodel = RandomForestClassifier()\n\nparam_grid = [{},]\n\ngrid_search = GridSearchCV(model, param_grid, cv=5, scoring=scoring)\ngrid_search.fit(XNorm, y)\n\nprint(grid_search.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a406c3bcd3c161727af4b5dcab74dca35daf853"},"cell_type":"code","source":"model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=None, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9097a12c41f10f3b86e0915577ce0d781e4758c"},"cell_type":"code","source":"# FEATURE IMPORTANCE - NORMALIZED - last model\n\ntrainFinalFI = XNorm\nyFinalFI = y\n\nmodel.fit(trainFinalFI,yFinalFI)\n\nFI_model = pd.DataFrame({\"Feature Importance\":model.feature_importances_,}, index=trainFinalFI.columns)\nFI_model[FI_model[\"Feature Importance\"] > 0.005].sort_values(\"Feature Importance\").plot(kind=\"barh\",figsize=(15,25))\nplt.xticks(rotation=90)\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49522e46d392dfcf95d60a54481d1dce22cdef30"},"cell_type":"code","source":"# List of important features for model\nFI_model = pd.DataFrame({\"Feature Importance\":model.feature_importances_,}, index=trainFinalFI.columns)\nFI_model=FI_model.sort_values('Feature Importance', ascending = False)\nprint(FI_model[FI_model[\"Feature Importance\"] > 0.001])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e4dc0ce72a8131e32acda585f4b76061034f7f0"},"cell_type":"code","source":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 10)):\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Error\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = 1-np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = 1-np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afe92f8617e5290fc0317d2331947583282bac65"},"cell_type":"code","source":"# LEARNING CURVES Train / Validation\n\ntitle = \"Learning Curves \"\ncv = ShuffleSplit(n_splits=7, test_size=0.2)\nplot_learning_curve(model, title, X_train, y_train, cv=cv, n_jobs=4)\n#plot_learning_curve(model, title, XNorm, y, ylim=(0.01, 0.99), cv=cv, n_jobs=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91574fedd82e85ae7d616e23f4c5174213926f24"},"cell_type":"code","source":"# Split into Train & Test\n\nX_train, X_test, y_train, y_test = train_test_split(XNorm, y, test_size=0.2, random_state=42)\nprint ('X_train: ', X_train.shape)\nprint ('X_test: ', X_test.shape)\nprint ('y_train: ', y_train.shape)\nprint ('y_test: ', y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3c18714aca39c174cd2c2d747f3ee23c2491362"},"cell_type":"code","source":"# Model FINAL fit and evaluation on test\n\nmodel.fit(X_train, y_train)\nfinal_predictions = model.predict(X_test)\n\n#final_acc = accuracy(y_test, final_predictions)\n# Confusion matrix\n\nconf_mx = confusion_matrix(y_test, final_predictions)\nprint('conf_mx ready')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f5410cd3c3f20bbee11842580a4cb0fb828b883"},"cell_type":"code","source":"def plot_confusion_matrix(cm,target_names,title='Confusion Matrix',cmap=None,\n                          normalize=False):\n    import itertools\n    accuracy = np.trace(cm) / float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        \n    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c064c815e2cb9ca1fa26681cc8d68998571911a"},"cell_type":"code","source":"plot_confusion_matrix(conf_mx, \n                      normalize    = False,\n                      target_names = [0,1,2,3],\n                      title        = \"Confusion Matrix\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"837aba4cbecd2bde6bdaab1cb8417348ee823dea"},"cell_type":"code","source":"# Confusion matrix and all metrics - for EACH class separately\n\nNumClasses = 4\n\nTP = 0\nTN = 0\nFP = 0\nFN = 0\n\nfor z in range(NumClasses):\n# One class at a time - calculate confusion matrix\n    SumCM = np.sum(conf_mx)\n    TPz = conf_mx[z,z]\n    FNz = np.sum(conf_mx[z,:], axis=0) -TPz\n    FPz = np.sum(conf_mx[:,z], axis=0) -TPz\n    TNz = SumCM - (TPz+FNz+FPz)\n    #FPz = np.sum(conf_mx[z], axis=-1) \n    #FPz = sum(conf_mx(:, z))-conf_mx(z, z)\n    #FNz = sum(conf_mx(x, :), 2)-conf_mx(x, x)\n    print('Class ',z)\n  \n\n    # Create conf matrix for class z\n    cmZ = np.zeros([2, 2], dtype=np.int32)\n    cmZ[0,0] = TNz\n    cmZ[0,1] = FPz\n    cmZ[1,0] = FNz\n    cmZ[1,1] = TPz\n\n    plot_confusion_matrix(cmZ, \n                          normalize    = False,\n                          target_names = [0,1],\n                          title        = \"Confusion matrix for one class \")\n\n    accuracy = (TPz+TNz)/(TPz+TNz+FPz+FNz)\n    recall = TPz/(TPz+FNz)\n    precision = TPz/(TPz+FPz)\n    f1score = 2*recall*precision/(recall+precision)\n    #roc_auc = auc(FPz, TPz)\n    \n    print('TPz ',TPz)\n    print('FNz ',FNz)\n    print('FPz ',FPz)\n    print('TNz ',TNz)\n    print('sum ', TPz+TNz+FPz+FNz)\n    print(cmZ)\n    print('Sum of CM ', np.sum(cmZ))\n    print ('accuracy ',round(accuracy,4))\n    print('recall ', round(recall,4))\n    print('precision ', round(precision,4))\n    print('F1Score ', round(f1score,4))\n    print('-'*40)\n    \n    TP = TP + TPz\n    TN = TN + TNz\n    FP = FP + FPz\n    FN = FN + FNz\nprint ('TN: ', TN)\nprint ('FP: ', FP)\nprint ('FN: ', FN)\nprint ('TP: ', TP)\nprint('_'*40)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d04b2db06faa9b5a97616249890ac562ec4ed4e"},"cell_type":"code","source":"# Confusion Matrix for the WHOLE MODEL - ALL Classes\n\nprint('Confusion Matix for ALL Classes')\n\nTP = TP / NumClasses\nTN = TN / NumClasses\nFP = FP / NumClasses\nFN = FN / NumClasses\n\n\ncm = np.zeros([2, 2], dtype=np.int32)\ncm[0,0] = TN\ncm[0,1] = FP\ncm[1,0] = FN\ncm[1,1] = TP\n\nplot_confusion_matrix(cm, \n                      normalize    = False,\n                      target_names = [0,1],\n                      title        = \"Confusion Matrix\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05d2a4ae23ffc67198475612f25c3a2d9bb58f06"},"cell_type":"code","source":"def multiclass_roc_auc_score(y_test, final_predictions, average=\"macro\"):\n    lb = LabelBinarizer()\n    lb.fit(y_test)\n    y_test = lb.transform(y_test)\n    y_pred = lb.transform(final_predictions)\n\n    return roc_auc_score(y_test, y_pred, average=average)\n\nprint('AUC ROC ',multiclass_roc_auc_score(y_test, final_predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27853b996b38fbcf56419a7c9963410928055e53"},"cell_type":"markdown","source":"**NN model**  "},{"metadata":{"trusted":true,"_uuid":"201db6f9eb3432ad3e76948f1343d507d5176e46"},"cell_type":"code","source":"# Split into Train & Test\n\nX_train, X_test, y_train, y_test = train_test_split(XNorm, y, test_size=0.2, random_state=42)\nprint ('X_train: ', X_train.shape)\nprint ('X_test: ', X_test.shape)\nprint ('y_train: ', y_train.shape)\nprint ('y_test: ', y_test.shape)\n\nprint(y_train)\nprint(y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b45ff6a343f8e9b8a2400dadc703d7cd62a2add"},"cell_type":"code","source":"# Transfer data to NN format\n\nx_val = X_test\npartial_x_train = X_train\ny_val = y_test\npartial_y_train = y_train\n\nprint(\"partial_x_train \", partial_x_train.shape)\nprint(\"partial_y_train \", partial_y_train.shape)\n\nprint(\"x_val \", x_val.shape)\nprint(\"y_val \", y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a4761290ca85629cb95e98fdfc0fefbed0aa871"},"cell_type":"code","source":"yTrain = to_categorical(partial_y_train)\nyVal = to_categorical(y_val)\nprint(yTrain.shape)\nprint(yVal.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"330a7c3a8a64fc1d079c0367bec4437723aca5a0"},"cell_type":"code","source":"# NN MODEL\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(2048, activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=(30,)))\n#model.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(2048, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n#model.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(2048, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n#model.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(2048, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n#model.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(4, activation='softmax'))\nprint(model.summary())\n\n# FIT / TRAIN model\n\nNumEpochs = 100\nBatchSize = 16\n\nmodel.compile(optimizer=optimizers.Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n\nhistory = model.fit(partial_x_train, yTrain, epochs=NumEpochs, batch_size=BatchSize, validation_data=(x_val, yVal))\n\nresults = model.evaluate(x_val, yVal)\nprint(\"_\"*100)\nprint(\"Test Loss and Accuracy\")\nprint(\"results \", results)\nhistory_dict = history.history\nhistory_dict.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c50e9f8b3702332944a2bf4157152474824538d"},"cell_type":"code","source":"# VALIDATION LOSS curves\n\nplt.clf()\nhistory_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nepochs = range(1, (len(history_dict['loss']) + 1))\nplt.plot(epochs, loss_values, 'bo', label='Training loss')\nplt.plot(epochs, val_loss_values, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# VALIDATION ACCURACY curves\n\nplt.clf()\nacc_values = history_dict['categorical_accuracy']\nval_acc_values = history_dict['val_categorical_accuracy']\nepochs = range(1, (len(history_dict['categorical_accuracy']) + 1))\nplt.plot(epochs, acc_values, 'bo', label='Training acc')\nplt.plot(epochs, val_acc_values, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb2fa916bc883388474a2649dad790dc5c651c79"},"cell_type":"code","source":"# Final Fit / Predict\n\nfinal_predictions = model.predict(x_val)\nprint(final_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7abb85e63a2b8b176b98f9b47b66a122459b75dc"},"cell_type":"code","source":"# PREDICT & ARGMAX to get the digit from the probability of softmax layer\n\nprint(final_predictions)\npred = []\nnumTest = final_predictions.shape[0]\nfor i in range(numTest):\n    pred.append(np.argmax(final_predictions[i])) \npredictions = np.array(pred)  \nprint(predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"602525e0e93d979636c69eef688c292644e8dcb4"},"cell_type":"code","source":"# PREDICT & ARGMAX to get the digit from the probability of softmax layer\n\nprint(yVal)\npred = []\nnumTest = yVal.shape[0]\nfor i in range(numTest):\n    pred.append(np.argmax(yVal[i])) \nyValNum = np.array(pred)  \nprint(yValNum)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f3de9b05c64e6084885d86ec7b285c101155532"},"cell_type":"code","source":"conf_mx = confusion_matrix(yValNum, predictions)\nprint('conf_mx ready')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"074d2939a86c28ee1e5f47de485dc3357c89686a"},"cell_type":"code","source":"plot_confusion_matrix(conf_mx, \n                      normalize    = False,\n                      target_names = [0,1,2,3],\n                      title        = \"Confusion Matrix\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a03f7d094d3546c4de59827448afc3fe99b4591"},"cell_type":"code","source":"# Confusion matrix and all metrics - for EACH class separately\n\nNumClasses = 4\n\nTP = 0\nTN = 0\nFP = 0\nFN = 0\n\nfor z in range(NumClasses):\n# One class at a time - calculate confusion matrix\n    SumCM = np.sum(conf_mx)\n    TPz = conf_mx[z,z]\n    FNz = np.sum(conf_mx[z,:], axis=0) -TPz\n    FPz = np.sum(conf_mx[:,z], axis=0) -TPz\n    TNz = SumCM - (TPz+FNz+FPz)\n    #FPz = np.sum(conf_mx[z], axis=-1) \n    #FPz = sum(conf_mx(:, z))-conf_mx(z, z)\n    #FNz = sum(conf_mx(x, :), 2)-conf_mx(x, x)\n    print('Class ',z)\n  \n\n    # Create conf matrix for class z\n    cmZ = np.zeros([2, 2], dtype=np.int32)\n    cmZ[0,0] = TNz\n    cmZ[0,1] = FPz\n    cmZ[1,0] = FNz\n    cmZ[1,1] = TPz\n\n    plot_confusion_matrix(cmZ, \n                          normalize    = False,\n                          target_names = [0,1],\n                          title        = \"Confusion matrix for one class \")\n\n    accuracy = (TPz+TNz)/(TPz+TNz+FPz+FNz)\n    recall = TPz/(TPz+FNz)\n    precision = TPz/(TPz+FPz)\n    f1score = 2*recall*precision/(recall+precision)\n    #roc_auc = auc(FPz, TPz)\n    \n    print('TPz ',TPz)\n    print('FNz ',FNz)\n    print('FPz ',FPz)\n    print('TNz ',TNz)\n    print('sum ', TPz+TNz+FPz+FNz)\n    print(cmZ)\n    print('Sum of CM ', np.sum(cmZ))\n    print ('accuracy ',round(accuracy,4))\n    print('recall ', round(recall,4))\n    print('precision ', round(precision,4))\n    print('F1Score ', round(f1score,4))\n    print('-'*40)\n    \n    TP = TP + TPz\n    TN = TN + TNz\n    FP = FP + FPz\n    FN = FN + FNz\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aedfc2f2f164effbd20f826391db3124320ea457"},"cell_type":"code","source":"# Confusion Matrix for the WHOLE MODEL - ALL Classes\n\nprint('Confusion Matix for ALL Classes')\n\nTP = TP / NumClasses\nTN = TN / NumClasses\nFP = FP / NumClasses\nFN = FN / NumClasses\n\n\ncm = np.zeros([2, 2], dtype=np.int32)\ncm[0,0] = TN\ncm[0,1] = FP\ncm[1,0] = FN\ncm[1,1] = TP\n\nplot_confusion_matrix(cm, \n                      normalize    = False,\n                      target_names = [0,1],\n                      title        = \"Confusion Matrix\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d48f5ba2f3b10a78d85214d0626c8ecd1f637a8b"},"cell_type":"code","source":"print('AUC ROC ',multiclass_roc_auc_score(yValNum, predictions))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}