{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport seaborn as sns\nsns.set()\n\nfrom scipy import stats\nstats.chisqprob = lambda chisq, df:stats.chi12.sf(chisq,df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data = pd.read_csv('../input/logistic-regression-heart-disease-prediction/framingham_heart_disease.csv')\nraw_data.describe(include = 'all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_no_mv = raw_data.dropna(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_no_mv.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data_no_mv.drop(['education'], axis = 1)\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Defining Features and Targets"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data['TenYearCHD']\nx1 = data.drop(['TenYearCHD'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating the Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = sm.add_constant(x1)\nreg_log = sm.Logit(y,x)\nresults_log = reg_log.fit()\nresults_log.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cleaned = x.copy()\ndata_cleaned = data_cleaned.drop(['BPMeds'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train, y_test = train_test_split(data_cleaned, y, test_size=0.2, random_state = 365)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_cleaned = x_train\nx_new = sm.add_constant(x_cleaned)\nreg_log = sm.Logit(y_train,x_new)\nresults_log = reg_log.fit()\nresults_log.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def confusion_matrix(data,actual_values,model):\n        \n        # Confusion matrix \n        \n        # Parameters\n        # ----------\n        # data: data frame or array\n            # data is a data frame formatted in the same way as your input data (without the actual values)\n            # e.g. const, var1, var2, etc. Order is very important!\n        # actual_values: data frame or array\n            # These are the actual values from the test_data\n            # In the case of a logistic regression, it should be a single column with 0s and 1s\n            \n        # model: a LogitResults object\n            # this is the variable where you have the fitted model \n            # e.g. results_log in this course\n        # ----------\n\n        #Predict the values using the Logit model\n        pred_values = model.predict(data)\n        # Specify the bins \n        bins=np.array([0,0.5,1])\n        # Create a histogram, where if values are between 0 and 0.5 tell will be considered 0\n        # if they are between 0.5 and 1, they will be considered 1\n        cm = np.histogram2d(actual_values, pred_values, bins=bins)[0]\n        # Calculate the accuracy\n        accuracy = (cm[0,0]+cm[1,1])/cm.sum()\n        # Return the confusion matrix and\n        string = 'Accuracy is ' + repr(accuracy*100)+' %'\n        return cm, string","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(x_new,y_train,results_log)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Testing Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test1 = x_test\nreg_log = sm.Logit(y_test,x_test)\nresults_log1 = reg_log.fit()\nresults_log1.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def confusion_matrix(data,actual_values,model):\n        \n        # Confusion matrix \n        \n        # Parameters\n        # ----------\n        # data: data frame or array\n            # data is a data frame formatted in the same way as your input data (without the actual values)\n            # e.g. const, var1, var2, etc. Order is very important!\n        # actual_values: data frame or array\n            # These are the actual values from the test_data\n            # In the case of a logistic regression, it should be a single column with 0s and 1s\n            \n        # model: a LogitResults object\n            # this is the variable where you have the fitted model \n            # e.g. results_log in this course\n        # ----------\n\n        #Predict the values using the Logit model\n        pred_values = model.predict(data)\n        # Specify the bins \n        bins=np.array([0,0.5,1])\n        # Create a histogram, where if values are between 0 and 0.5 tell will be considered 0\n        # if they are between 0.5 and 1, they will be considered 1\n        cm = np.histogram2d(actual_values, pred_values, bins=bins)[0]\n        # Calculate the accuracy\n        accuracy = (cm[0,0]+cm[1,1])/cm.sum()\n        # Return the confusion matrix and\n        string = 'Accuracy is ' + repr(accuracy*100)+' %'\n        return cm, string","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(x_new,y_train,results_log)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_df = pd.DataFrame(results_log.pred_table())\ncm_df.columns = ['Predicted 0','Predicted 1']\ncm_df = cm_df.rename(index={0:'Actual 0',1:'Actual 1'})\ncm_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hence, the model produced an accurate prediction 2496 times out of 2924 times resulting in,\n# Accuracy = 85.36%"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}