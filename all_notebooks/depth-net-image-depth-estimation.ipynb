{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport math\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Device configuration\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint(device)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-19T10:28:31.187986Z","iopub.execute_input":"2021-08-19T10:28:31.188338Z","iopub.status.idle":"2021-08-19T10:28:31.193812Z","shell.execute_reply.started":"2021-08-19T10:28:31.188291Z","shell.execute_reply":"2021-08-19T10:28:31.192883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reading Dataset","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ntrain = pd.read_csv(\"../input/image-depth-estimation/data/nyu2_test.csv\", names = ['image', 'label'])\ntest = pd.read_csv(\"../input/image-depth-estimation/data/nyu2_test.csv\", names = ['image', 'label'])\n\n\ntrain.label = train.label.map(lambda x: f\"../input/image-depth-estimation/{x}\")\ntrain.image = train.image.map(lambda x: f\"../input/image-depth-estimation/{x}\")\nprint(len(train))\ntrain.head()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-19T10:28:31.195286Z","iopub.execute_input":"2021-08-19T10:28:31.19583Z","iopub.status.idle":"2021-08-19T10:28:31.22507Z","shell.execute_reply.started":"2021-08-19T10:28:31.195787Z","shell.execute_reply":"2021-08-19T10:28:31.224038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Loader","metadata":{}},{"cell_type":"code","source":"import torch\nimport os\nfrom PIL import Image\nimport torchvision.transforms as transforms\n\n\n\n\nclass DepthDataset(torch.utils.data.Dataset):\n    def __init__(self, df):\n\n        self.images = list(df['image'].values)\n        self.labels = list(df['label'].values)\n        \n        # load image\n        random_sample_image = random.choice([i for i in range(len(self.images) - 1)])\n        image = Image.open(self.images[random_sample_image])\n        depth = Image.open(self.labels[random_sample_image])\n        \n        plt.imshow(image)\n        plt.title(\"Image\")\n        plt.show()\n        \n        # Denormaling Image\n        plt.imshow(np.asarray(depth) * 256)\n        plt.title(\"Depth\")\n        plt.show()\n\n    def __getitem__(self, index):\n        # load image\n        image = Image.open(self.images[index])\n        depth = Image.open(self.labels[index])\n        \n       \n        # transformation\n        comm_trans = transforms.Compose([\n            transforms.Resize((240, 320)),\n            transforms.CenterCrop((228, 304)),\n            transforms.RandomHorizontalFlip()\n        ])\n        image_trans = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n        ])\n        depth_trans = transforms.Compose([\n            transforms.Resize((64, 80)),\n            transforms.ToTensor(),\n            transforms.Lambda(lambda x: x.float()),\n            transforms.Lambda(lambda x: torch.div(x, 65535.0)),\n            #transforms.Normalize((0.5, ), (0.5, ))\n        ])\n        image = image_trans(comm_trans(image))\n        depth = depth_trans(comm_trans(depth))\n        return image, depth\n\n    def __len__(self):\n        return len(self.images)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-19T10:28:31.22687Z","iopub.execute_input":"2021-08-19T10:28:31.227244Z","iopub.status.idle":"2021-08-19T10:28:31.240306Z","shell.execute_reply.started":"2021-08-19T10:28:31.227206Z","shell.execute_reply":"2021-08-19T10:28:31.238953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## hyperparameter","metadata":{}},{"cell_type":"code","source":"\nbatch_size = 32\nlearning_rate = 0.001\ntotal_epoch = 50\nreport_rate = 20","metadata":{"execution":{"iopub.status.busy":"2021-08-19T10:28:31.242163Z","iopub.execute_input":"2021-08-19T10:28:31.242633Z","iopub.status.idle":"2021-08-19T10:28:31.251072Z","shell.execute_reply.started":"2021-08-19T10:28:31.242571Z","shell.execute_reply":"2021-08-19T10:28:31.25029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Datasets and loader","metadata":{}},{"cell_type":"code","source":"import random\ndataset_train = DepthDataset(train)\n\n\nlengths = [int(math.floor(len(train) * 0.8)), int(math.ceil(len(train) * 0.2))]\ntrain_dataset, test_dataset = torch.utils.data.random_split(dataset_train, lengths)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T10:28:31.2524Z","iopub.execute_input":"2021-08-19T10:28:31.252911Z","iopub.status.idle":"2021-08-19T10:28:31.620867Z","shell.execute_reply.started":"2021-08-19T10:28:31.252871Z","shell.execute_reply":"2021-08-19T10:28:31.620048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                     batch_size=batch_size,\n                                     shuffle=False)\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n                                     batch_size=batch_size,\n                                     shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-19T10:28:31.62212Z","iopub.execute_input":"2021-08-19T10:28:31.62262Z","iopub.status.idle":"2021-08-19T10:28:31.627532Z","shell.execute_reply.started":"2021-08-19T10:28:31.62258Z","shell.execute_reply":"2021-08-19T10:28:31.626691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LOSS FUCNTIONS (WE CAN USE FOR THE MODEL)","metadata":{}},{"cell_type":"code","source":"#Cite from: https://github.com/simonmeister/pytorch-mono-depth\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom math import log\n\n\ndef _mask_input(input, mask=None):\n    if mask is not None:\n        input = input * mask\n        count = torch.sum(mask).data[0]\n    else:\n        count = np.prod(input.size(), dtype=np.float32).item()\n    return input, count\n\n\nclass BerHuLoss(nn.Module):\n    def forward(self, input, target, mask=None):\n        x = input - target\n        abs_x = torch.abs(x)\n        c = torch.max(abs_x).item() / 5\n        leq = (abs_x <= c).float()\n        l2_losses = (x ** 2 + c ** 2) / (2 * c)\n        losses = leq * abs_x + (1 - leq) * l2_losses\n        losses, count = _mask_input(losses, mask)\n        return torch.sum(losses) / count\n\n\nclass HuberLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.loss = nn.SmoothL1Loss(size_average=False)\n\n    def forward(self, input, target, mask=None):\n        if mask is not None:\n            loss = self.loss(input * mask, target * mask)\n            count = torch.sum(mask).data[0]\n            return loss / count\n\n        count = np.prod(input.size(), dtype=np.float32).item()\n        return self.loss(input, target) / count\n\n\nclass DistributionLogLoss(nn.Module):\n    def __init__(self, distribution):\n        super().__init__()\n        self.distribution = distribution\n\n    def forward(self, input, target, mask=None):\n        d = self.distribution(*input)\n        loss = d.log_loss(target)\n        loss, count = _mask_input(loss, mask)\n        return torch.sum(loss) / count\n\n\nclass RMSLoss(nn.Module):\n    def forward(self, input, target, mask=None):\n        loss = torch.pow(input - target, 2)\n        loss, count = _mask_input(loss, mask)\n        return torch.sqrt(torch.sum(loss) / count)\n\n\nclass RelLoss(nn.Module):\n    def forward(self, input, target, mask=None):\n        loss = torch.abs(input - target) / target\n        loss, count = _mask_input(loss, mask)\n        return torch.sum(loss) / count\n\nclass MseLoss(nn.Module):  \n    def forward(self, input, target, mask=None):\n        loss = torch.sum((input - target) ** 2)\n        loss, count = _mask_input(loss, mask)\n        return torch.sum(loss) / count\n\nclass Log10Loss(nn.Module):\n    def forward(self, input, target, mask=None):\n        loss = torch.abs((torch.log(target) - torch.log(input)) / log(10))\n        loss, count = _mask_input(loss, mask)\n        return torch.sum(loss) / count\n\n\nclass TestingLosses(nn.Module):\n    def __init__(self, scalar_losses):\n        super().__init__()\n        self.scalar_losses = nn.ModuleList(scalar_losses)\n\n    def forward(self, input, target):\n        scalars = [m(input, target) for m in self.scalar_losses]\n        return torch.cat(scalars)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T10:28:31.629945Z","iopub.execute_input":"2021-08-19T10:28:31.630312Z","iopub.status.idle":"2021-08-19T10:28:31.780096Z","shell.execute_reply.started":"2021-08-19T10:28:31.630271Z","shell.execute_reply":"2021-08-19T10:28:31.779163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resnet 50","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport math\nimport torch.utils.model_zoo as model_zoo\n\n\n__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n           'resnet152']\n\n\nmodel_urls = {\n    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n}\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    \"3x3 convolution with padding\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7)\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x\n\n\ndef resnet18(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-18 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n    return model\n\n\n\ndef resnet34(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-34 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n    return model\n\n\n\ndef resnet50(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n    return model\n\n\n\ndef resnet101(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-101 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n    return model\n\n\n\ndef resnet152(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-152 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-08-19T10:28:31.781702Z","iopub.execute_input":"2021-08-19T10:28:31.78207Z","iopub.status.idle":"2021-08-19T10:28:31.817073Z","shell.execute_reply.started":"2021-08-19T10:28:31.782032Z","shell.execute_reply":"2021-08-19T10:28:31.816149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Resnet-50 Model with Up-sampling","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\n\n# Device configuration\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n# 3x3 convolution\ndef conv3x3(in_channels, out_channels, stride=1):\n    return nn.Conv2d(in_channels, out_channels, kernel_size=3,\n                     stride=stride, padding=1, bias=False)\n# 5x5 convolution\ndef conv5x5(in_channels, out_channels, stride=1):\n    return nn.Conv2d(in_channels, out_channels, kernel_size=5,\n                     stride=stride, padding=2, bias=False)\n\n# UpSampling Block\nclass UpSamplingBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(UpSamplingBlock, self).__init__()\n        self.unpool = nn.MaxUnpool2d(2, stride=2)\n        self.pool = nn.MaxPool2d(2, stride=2, return_indices=True)\n        self.conv1 = conv5x5(in_channels, out_channels)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(out_channels, out_channels)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n    def forward(self, x):\n        # create indices for unpool\n        size = x.size()\n        _, indices = self.pool(torch.empty(size[0], size[1], size[2]*2, size[3]*2))\n        # unpool and assign residual\n        out = self.unpool(x, indices.to(device))\n        residual = self.conv1(out)\n        residual = self.bn1(residual)\n        # forward and projection\n        out = self.conv1(out)\n        out = self.bn1(residual)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(residual)\n        out += residual\n        return out\n\n\n# DepthNet\nclass DepthNet(nn.Module):\n    def __init__(self):\n        super(DepthNet, self).__init__()\n        # Remove FC and AvgPool layer from Resnet50\n        resnet = resnet50(pretrained=True)\n        modules = list(resnet.children())[:-2]\n        self.resnet = nn.Sequential(*modules)\n        self.conv1 = nn.Conv2d(2048, 1024, kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn = nn.BatchNorm2d(1024)\n        # Add new upsampling layer\n        self.up1 = nn.Sequential(UpSamplingBlock(1024, 512),\n                                 nn.ReLU(),\n                                 UpSamplingBlock(512, 256),\n                                 nn.ReLU(),\n                                 UpSamplingBlock(256, 128),\n                                 nn.ReLU())\n        self.conv2 = conv3x3(128, 1)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, inputs):\n        out = self.resnet(inputs)\n        out = self.conv1(out)\n        out = self.bn(out)\n        out = self.up1(out)\n        out = self.conv2(out)\n        out = self.relu(out)\n        return out\n","metadata":{"execution":{"iopub.status.busy":"2021-08-19T10:28:31.819293Z","iopub.execute_input":"2021-08-19T10:28:31.819912Z","iopub.status.idle":"2021-08-19T10:28:31.837633Z","shell.execute_reply.started":"2021-08-19T10:28:31.81987Z","shell.execute_reply":"2021-08-19T10:28:31.836682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load model\nmodel = DepthNet().to(device)\n\n# Loss and optimizer\ncriterion  = BerHuLoss()\ncriterion2 = MseLoss()\noptimizer  = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n# learning rate decay\ndef update_lr(opt, lr):\n    for param_group in opt.param_groups:\n        param_group['lr'] = lr\n\n# validation\ndef validate(model, test_loader):\n    model.eval()\n    with torch.no_grad():\n        loss2, loss = 0.0, 0.0\n        for t_image, t_depth in test_loader:\n            t_image = t_image.to(device)\n            t_depth = t_depth.to(device)\n            t_outputs = model(t_image)\n            \n            curr_loss = criterion(t_depth, t_outputs)\n            curr_loss2 = criterion2(t_depth, t_outputs)\n            loss += curr_loss.item()\n            loss2 += curr_loss2.item()\n        print(\"Validation BerHuLoss: {:.4f}\"\n              .format(loss/(len(test_loader) * batch_size)))\n        print(\"Validation MSE LOSS: {:.4f}\"\n              .format(loss2/(len(test_loader) * batch_size)))\n        \n        \n    model.train()\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-19T10:28:31.83892Z","iopub.execute_input":"2021-08-19T10:28:31.839482Z","iopub.status.idle":"2021-08-19T10:28:32.668204Z","shell.execute_reply.started":"2021-08-19T10:28:31.839444Z","shell.execute_reply":"2021-08-19T10:28:32.667291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train\ntotal_step = len(train_dataset)\ncurr_lr = learning_rate\nfor epoch in range(total_epoch):\n    running_loss, running_loss2 = 0.0, 0.0\n    epoch_loss = 0.0\n    for i, (image, depth) in enumerate(train_loader):\n        \n        image = image.to(device)\n        depth = depth.to(device)\n\n        # forward pass\n        outputs = model(image)\n        loss = criterion(outputs, depth)\n        loss2 = criterion2(depth, outputs)\n\n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Calculate loss\n        running_loss += loss.item()\n        running_loss2 += loss2.item()\n        \n        epoch_loss += running_loss2\n\n        if (i + 1) % report_rate == 0:\n            print(\"Epoch: [{}/{}] Step [{}/{}] Loss: {:.4f} MSE LOSS {:.4f}\"\n                  .format((epoch+1), total_epoch, (i+1), total_step, (running_loss/batch_size), (running_loss2/batch_size)))\n            running_loss, running_loss2 = 0.0, 0.0\n\n    #Decay learning rate\n    if (epoch + 1) % 5 == 0:\n        curr_lr /= 3\n        update_lr(optimizer, curr_lr)\n\n    # Report epoch loss\n    print(\"Epoch: [{}/{}] Epoch Loss: {:.4f}\\n\"\n          .format((epoch+1), total_epoch, (epoch_loss / (len(train_loader) * batch_size))))\n\n    validate(model, test_loader)\n\n# Save the model checkpoint\ntorch.save(model.state_dict(), 'depthnet.ckpt')","metadata":{"execution":{"iopub.status.busy":"2021-08-19T10:28:32.670173Z","iopub.execute_input":"2021-08-19T10:28:32.670774Z","iopub.status.idle":"2021-08-19T10:57:27.05986Z","shell.execute_reply.started":"2021-08-19T10:28:32.670734Z","shell.execute_reply":"2021-08-19T10:57:27.058635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validate Model By Seeing the Predictions Manually","metadata":{}},{"cell_type":"code","source":"\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\nfor i, (image, depth) in enumerate(test_loader):\n    print(i, end='\\r')\n    image = image.to(device)\n    y_pred = model(image)\n    plt.imshow(y_pred.permute(1,0,2,3).squeeze(axis=0)[1:2,:,:].squeeze(axis=0).cpu().detach().numpy() * 256)\n    plt.show()\n    \n    if i == 2:\n        break\n        \n","metadata":{"execution":{"iopub.status.busy":"2021-08-19T10:59:01.446642Z","iopub.execute_input":"2021-08-19T10:59:01.447065Z","iopub.status.idle":"2021-08-19T10:59:05.888119Z","shell.execute_reply.started":"2021-08-19T10:59:01.447026Z","shell.execute_reply":"2021-08-19T10:59:05.887287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}