{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# GENERAL INTRODUCTION TO HYPERPARAMETERS:\n\n**Hyperparameters are certain weights that determine the learning process of an algorithm. \nXGBoost algorithm has become the ultimate weapon of many data scientist. Itâ€™s a highly sophisticated algorithm, powerful enough to deal with all sorts of irregularities of data. It is a powerful machine learning algorithm especially where speed and accuracy are concerned. Building a model using XGBoost is easy. But, improving the model using XGBoost is difficult as it contains multiple parameters.**","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-24T05:41:02.306546Z","iopub.execute_input":"2021-05-24T05:41:02.307231Z","iopub.status.idle":"2021-05-24T05:41:02.329705Z","shell.execute_reply.started":"2021-05-24T05:41:02.307108Z","shell.execute_reply":"2021-05-24T05:41:02.328934Z"}}},{"cell_type":"markdown","source":"# XGBOOST PARAMETERS\n**GENERAL PARAMETERS:** **They define the overall functionality of XGBoost algorithm. These include the following parameters:**\n\n**a) booster [default=gbtree]**\n\n**b) silent [default=0]**\n\n**c) nthread [default to maximum number of threads available if not set]**\n\n**BOOSTER PARAMETERS:-** **Guide the individual booster (tree/regression) at each step**\n\n**a)eta [default=0.3]**\n\n**b) min_child_weight [default=1]**\n\n**c) min_child_weight [default=1]**\n\n**d) max_leaf_nodes**\n\n**e) gamma [default=0]**\n\n**f) max_delta_step [default=0]**\n\n**g) subsample [default=1]**\n\n**h) colsample_bytree [default=1]**\n\n**i) colsample_bylevel [default=1]**\n\n**j) lambda [default=1]**\n\n**k) alpha [default=0]**\n\n**l) scale_pos_weight [default=1]**\n\n**LEARNING TASK PARAMETERS:-** **They Guide the optimization performed**\n\n**a) objective [default=reg:linear]**\n\n**b) eval_metric [ default according to objective ]**\n\n**c) seed [default=0]**","metadata":{}},{"cell_type":"markdown","source":"# Hyperparameter Tuning with an example\n\n**Now let us perform the hyperparameter tuning on the dataset to understand the working**","metadata":{}},{"cell_type":"markdown","source":"**Importing the libraries**","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:18:35.260018Z","iopub.execute_input":"2021-05-24T06:18:35.260514Z","iopub.status.idle":"2021-05-24T06:18:35.269601Z","shell.execute_reply.started":"2021-05-24T06:18:35.260482Z","shell.execute_reply":"2021-05-24T06:18:35.268657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport xgboost as xgb\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.model_selection import cross_validate   #Additional scklearn functions\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom hyperopt import STATUS_OK, Trials, fmin, hp, tpe","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:18:35.272091Z","iopub.execute_input":"2021-05-24T06:18:35.272621Z","iopub.status.idle":"2021-05-24T06:18:35.279389Z","shell.execute_reply.started":"2021-05-24T06:18:35.272564Z","shell.execute_reply":"2021-05-24T06:18:35.278243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings  \nwarnings.filterwarnings('ignore')\nimport matplotlib.pylab as plt\n%matplotlib inline\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize'] = 12, 4\n\ntrain = pd.read_csv('../input/bank-customers/Churn Modeling.csv')\ntarget = 'Exited'\nIDcol = 'ID'","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:18:35.280999Z","iopub.execute_input":"2021-05-24T06:18:35.281342Z","iopub.status.idle":"2021-05-24T06:18:35.320531Z","shell.execute_reply.started":"2021-05-24T06:18:35.281311Z","shell.execute_reply":"2021-05-24T06:18:35.319558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Importing and reading of data**","metadata":{}},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:18:35.322899Z","iopub.execute_input":"2021-05-24T06:18:35.323221Z","iopub.status.idle":"2021-05-24T06:18:35.352798Z","shell.execute_reply.started":"2021-05-24T06:18:35.323185Z","shell.execute_reply":"2021-05-24T06:18:35.35175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:18:35.354631Z","iopub.execute_input":"2021-05-24T06:18:35.355231Z","iopub.status.idle":"2021-05-24T06:18:35.370298Z","shell.execute_reply.started":"2021-05-24T06:18:35.355184Z","shell.execute_reply":"2021-05-24T06:18:35.368876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop(columns=['Surname', 'Geography'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:18:35.371625Z","iopub.execute_input":"2021-05-24T06:18:35.371942Z","iopub.status.idle":"2021-05-24T06:18:35.387284Z","shell.execute_reply.started":"2021-05-24T06:18:35.371908Z","shell.execute_reply":"2021-05-24T06:18:35.386224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Gender']=train['Gender'].map({'Female':0, 'Male':1})","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:18:35.388756Z","iopub.execute_input":"2021-05-24T06:18:35.389424Z","iopub.status.idle":"2021-05-24T06:18:35.404727Z","shell.execute_reply.started":"2021-05-24T06:18:35.389385Z","shell.execute_reply":"2021-05-24T06:18:35.403822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:18:35.405998Z","iopub.execute_input":"2021-05-24T06:18:35.406602Z","iopub.status.idle":"2021-05-24T06:18:35.43957Z","shell.execute_reply.started":"2021-05-24T06:18:35.406566Z","shell.execute_reply":"2021-05-24T06:18:35.438582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:18:35.440925Z","iopub.execute_input":"2021-05-24T06:18:35.441293Z","iopub.status.idle":"2021-05-24T06:18:35.465881Z","shell.execute_reply.started":"2021-05-24T06:18:35.441215Z","shell.execute_reply":"2021-05-24T06:18:35.46476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:18:35.46837Z","iopub.execute_input":"2021-05-24T06:18:35.468664Z","iopub.status.idle":"2021-05-24T06:18:35.473799Z","shell.execute_reply.started":"2021-05-24T06:18:35.468635Z","shell.execute_reply":"2021-05-24T06:18:35.472855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:18:35.475424Z","iopub.execute_input":"2021-05-24T06:18:35.47599Z","iopub.status.idle":"2021-05-24T06:18:35.489356Z","shell.execute_reply.started":"2021-05-24T06:18:35.475958Z","shell.execute_reply":"2021-05-24T06:18:35.488263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features=['RowNumber', 'CustomerId', 'CreditScore', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary' ]","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:18:35.490767Z","iopub.execute_input":"2021-05-24T06:18:35.491077Z","iopub.status.idle":"2021-05-24T06:18:35.503335Z","shell.execute_reply.started":"2021-05-24T06:18:35.491047Z","shell.execute_reply":"2021-05-24T06:18:35.501896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=train['Exited']\nX=train[features]","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:18:35.504955Z","iopub.execute_input":"2021-05-24T06:18:35.505418Z","iopub.status.idle":"2021-05-24T06:18:35.519276Z","shell.execute_reply.started":"2021-05-24T06:18:35.505379Z","shell.execute_reply":"2021-05-24T06:18:35.518254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:18:35.520453Z","iopub.execute_input":"2021-05-24T06:18:35.520971Z","iopub.status.idle":"2021-05-24T06:18:35.534678Z","shell.execute_reply.started":"2021-05-24T06:18:35.520928Z","shell.execute_reply":"2021-05-24T06:18:35.533802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:18:35.535866Z","iopub.execute_input":"2021-05-24T06:18:35.536365Z","iopub.status.idle":"2021-05-24T06:18:35.551355Z","shell.execute_reply.started":"2021-05-24T06:18:35.536327Z","shell.execute_reply":"2021-05-24T06:18:35.550249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.info","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:18:35.552791Z","iopub.execute_input":"2021-05-24T06:18:35.553263Z","iopub.status.idle":"2021-05-24T06:18:35.572697Z","shell.execute_reply.started":"2021-05-24T06:18:35.55323Z","shell.execute_reply":"2021-05-24T06:18:35.571405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Splitting into train and test set**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:18:35.574165Z","iopub.execute_input":"2021-05-24T06:18:35.574543Z","iopub.status.idle":"2021-05-24T06:18:35.590253Z","shell.execute_reply.started":"2021-05-24T06:18:35.574509Z","shell.execute_reply":"2021-05-24T06:18:35.589162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Correlation heatmap**","metadata":{}},{"cell_type":"code","source":"corrmat=train.corr()\ntop_corr_features=corrmat.index\nplt.figure(figsize=(20,20))\nfig=sns.heatmap(train[top_corr_features].corr(),annot=True,\n                cmap=\"Accent\")","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:18:35.591678Z","iopub.execute_input":"2021-05-24T06:18:35.592009Z","iopub.status.idle":"2021-05-24T06:18:36.7456Z","shell.execute_reply.started":"2021-05-24T06:18:35.591966Z","shell.execute_reply":"2021-05-24T06:18:36.744864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bayesian Optimisation with HYPEROPT\n\n**Optimization is the process of finding a minimum of cost function , that determines an overall better performance of a model on both train-set and test-set.**\n\n**Bayesian optimization is optimization or finding the best parameter for a machine learning or deep learning algorithm.**\n\n**Here, we train the model with various possible range of parameters until a best fit model is obtained.**\n\n**Hyperparameter tuning helps in determining the optimal tuned parameters and return the best fit model.**","metadata":{}},{"cell_type":"markdown","source":"# HYPEROPT\n**HYPEROPT is a powerful python library that search through an hyperparameter space of values and find the best possible values that yield the minimum of the loss function.**\n\n**Bayesian Optimization technique uses Hyperopt to tune the model hyperparameters. Hyperopt is a Python library which is used to tune model hyperparameters.**","metadata":{}},{"cell_type":"markdown","source":"**Initializing Domain space for range of values**","metadata":{}},{"cell_type":"code","source":"space={'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n        'gamma': hp.uniform ('gamma', 1,9),\n        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n        'n_estimators': 180,\n        'seed': 0\n    }","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:18:36.746695Z","iopub.execute_input":"2021-05-24T06:18:36.747118Z","iopub.status.idle":"2021-05-24T06:18:36.753057Z","shell.execute_reply.started":"2021-05-24T06:18:36.747081Z","shell.execute_reply":"2021-05-24T06:18:36.752047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Define Objective Function**","metadata":{}},{"cell_type":"code","source":"def objective(space):\n    clf=xgb.XGBClassifier(\n                    n_estimators =space['n_estimators'], max_depth = int(space['max_depth']), gamma = space['gamma'],\n                    reg_alpha = int(space['reg_alpha']),min_child_weight=int(space['min_child_weight']),\n                    colsample_bytree=int(space['colsample_bytree']))\n    \n    evaluation = [( X_train, y_train), ( X_test, y_test)]\n    \n    clf.fit(X_train, y_train,\n            eval_set=evaluation, eval_metric=\"auc\",\n            early_stopping_rounds=10,verbose=False)\n    \n\n    pred = clf.predict(X_test)\n    accuracy = accuracy_score(y_test, pred>0.5)\n    print (\"SCORE:\", accuracy)\n    return {'loss': -accuracy, 'status': STATUS_OK }","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:18:36.754783Z","iopub.execute_input":"2021-05-24T06:18:36.755749Z","iopub.status.idle":"2021-05-24T06:18:36.767993Z","shell.execute_reply.started":"2021-05-24T06:18:36.75553Z","shell.execute_reply":"2021-05-24T06:18:36.767186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Optimization Algorithm**","metadata":{}},{"cell_type":"code","source":"trials = Trials()\n\nbest_hyperparams = fmin(fn = objective,\n                        space = space,\n                        algo = tpe.suggest,\n                        max_evals = 100,\n                        trials = trials)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:18:36.769049Z","iopub.execute_input":"2021-05-24T06:18:36.769513Z","iopub.status.idle":"2021-05-24T06:18:48.019556Z","shell.execute_reply.started":"2021-05-24T06:18:36.76948Z","shell.execute_reply":"2021-05-24T06:18:48.018751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Results**","metadata":{}},{"cell_type":"code","source":"print(\"The best hyperparameters are : \",\"\\n\")\nprint(best_hyperparams)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:18:48.020817Z","iopub.execute_input":"2021-05-24T06:18:48.021349Z","iopub.status.idle":"2021-05-24T06:18:48.02624Z","shell.execute_reply.started":"2021-05-24T06:18:48.021311Z","shell.execute_reply":"2021-05-24T06:18:48.025317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"","metadata":{}}]}