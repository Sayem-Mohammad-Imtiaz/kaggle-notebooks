{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Importing the required libraries and the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")\nplt.style.use(['seaborn-bright','dark_background'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/california-housing-prices/housing.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Computing the missing value percentage in data."},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in data.columns:\n    prct_missing = np.mean(data[i].isnull())\n    print(\"{} = {}%\".format(i,prct_missing*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Treating the missing values\n#### 1. Droping entire columns:- Whenever we see that column consists of maximum data missing we drop that column , otherwise we choose take another method to treat missing values.\n#### 2. Replace the values:- Sometimes we can replace the missing values as per our requirements like by numeric value for numeric feature and by any string for categorical value.\n#### 3. Imputing :- The missing values can be imputed by using the mean/average value or median value  for numeric feature and by most frequent i.e. mode for categorical feature.\n#### 4. Drop the rows:- If the missing value percentage is very less as compare to total percentage of data we can drop the rows which consists of missing values as we done in this case. Here total_bedrooms feature contain only 1% data missing so we drop the rows with missing values."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.dropna(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Identify outliers\n#### Using the describe method or plots like histogram , heatmap , scatter plot ot box-plot we can identify outliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.boxplot('longitude',data = data,palette=\"Blues\")\nplt.title('Longitude',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.boxplot('latitude',data = data,palette=\"plasma\")\nplt.title('Latitude',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.boxplot('housing_median_age',data = data,palette=\"hsv\")\nplt.title('Housing Median Age',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.boxplot('total_rooms',data = data,palette=\"flag\")\nplt.title('Total Rooms',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.boxplot('total_bedrooms',data = data,palette=\"YlGn\")\nplt.title('Total Bedrooms',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.boxplot('population',data = data,palette=\"PuOr\")\nplt.title('Population',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.boxplot('households',data = data,palette=\"Purples\")\nplt.title('Households',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.boxplot('median_income',data = data,palette=\"Reds\")\nplt.title('Median Income',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.boxplot('median_house_value',data = data,palette=\"bone\")\nplt.title('Median House Value',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Treating Outliers.\n#### Like missing values we can drop the rows or columns , or replace the outliers with the  mean or median values.\n#### We can drop the rows with value lower than lower whisker or upper than upper whisker.\n#### Now here we replace the outliers with the lower whisker and upper whisker. These whiskers can be calculated by using inter quartile range(IQR). The formula for IQR is IQR = 3rd quantile - 1st quantile."},{"metadata":{"trusted":true},"cell_type":"code","source":"def IQR(col):\n    q1 = data[col].quantile(0.25)\n    q3 = data[col].quantile(0.75)\n    iqr = q3 - q1\n    return iqr,q1,q3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def whisker(col):\n    iqr,q1,q3 = IQR(col)\n    lower_whisker = q1 - 1.5*iqr\n    upper_whisker = q3 + 1.5*iqr\n    return lower_whisker,upper_whisker","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in data.columns:\n    if data[col].dtype!=\"object\":\n        lw,uw = whisker(col)\n        print(\"Feature:-{} Lower:-{} Upper:-{}\".format(col,lw,uw))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def treat_outliers(value):\n    lower_limit,upper_limit = whisker(col)\n    data[col] = np.where(data[col]<lower_limit,lower_limit,data[col])\n    data[col] = np.where(data[col]>upper_limit,upper_limit,data[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in data.columns:\n    if data[col].dtype!=\"object\":\n        treat_outliers(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Column with repetative value.\n#### Whenever we see any case like a column consists of a maximum percent of same data or a data which is very less in percent as compare to other we can drop the entire column."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Here other than ocean proximity all features are numeric. So ocean_proximity consists of 5 unique value out of which ISLAND consists of only 5 value counts. So by droping the rows with ISLAND in feature dosen't impact our dataset so much."},{"metadata":{"trusted":true},"cell_type":"code","source":"data['ocean_proximity'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(data[data['ocean_proximity']==\"ISLAND\"].index, inplace = True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Non relatable data.\n#### Sometimes our data set consists of feature that does not impact our data set or is not inportant or informative we can drop the column."},{"metadata":{},"cell_type":"markdown","source":"## Duplicate values\n#### Our data set may contain some rows with exact same data values for all features , we can drop that rows to lower dataset size."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_remove_duplicates = pd.DataFrame.drop_duplicates(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_remove_duplicates.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Inconsistence categorical values\n#### Sometimes our data contain inconsistence data strings like iSlAnD or date and time 12-03-12 , we can treat these values by converting categorical values to lower case and extracting date, day , month ,time ,etc from date data."},{"metadata":{},"cell_type":"markdown","source":"#### Now converting the data in ocean proximity to lower case"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['ocean_proximity'] = data['ocean_proximity'].str.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['ocean_proximity'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Our data may contain spelling mistakes or white spaces in categorical values or measurement units in numeric values ,so can can replace white spaces or units and correct spells of categorical values."},{"metadata":{"trusted":true},"cell_type":"code","source":"data['ocean_proximity'] = data['ocean_proximity'].str.replace(\" \",\"_\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['ocean_proximity'].value_counts()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}