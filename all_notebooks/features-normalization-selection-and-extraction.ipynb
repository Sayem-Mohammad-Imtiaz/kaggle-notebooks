{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings \nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC, LinearSVC, NuSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom scipy.stats import skew\nfrom scipy import stats\nfrom scipy.stats import boxcox\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import SelectKBest, chi2, mutual_info_regression, f_regression\nfrom sklearn import ensemble\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tx = pd.read_csv('/kaggle/input/house-prices-data/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"year_all = ['YearBuilt', 'YearRemodAdd','YrSold','MoSold','GarageYrBlt']\nfor i in tx:\n    if tx[i].dtypes == object or i in year_all:\n        tx[i] = tx[i].fillna(tx[i].mode()[0])\n    else:\n        tx[i] = tx[i].fillna(tx[i].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tx = tx.select_dtypes(exclude=object).copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Features Extraction</h1>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\nfeatures = StandardScaler().fit_transform(tx)\n# Create a PCA that will retain 90% of variance\npca = PCA(n_components=0.90, whiten=True)\n# Conduct PCA\ntrain = pca.fit_transform(features)\n# Show results\nprint(\"Original number of features:\", features.shape[1])\nprint(\"Reduced number of features:\", train.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Features Selection</h>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# feature selection using SelectKBest\ndef select_features(X, Y, func):\n  bestfeatures = SelectKBest(score_func=func, k='all')\n  fit = bestfeatures.fit(X,Y)\n  return fit,bestfeatures\nfit,fs = select_features(tx, tx['SalePrice'], mutual_info_regression)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(tx.columns)\nfeatureScores = pd.concat([dfcolumns,dfscores],axis=1)\nfeatureScores.columns = ['Specs','Score'] \n\nmutual_info = featureScores.nlargest(32,'Score')\nmutual_info = list(mutual_info['Specs'])\nprint(len(mutual_info),'\\n',mutual_info)\nprint(featureScores.nlargest(32,'Score'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using Heatmap to see features importance and correlation with output\n\nf,ax = plt.subplots(figsize=(50, 50))\ncorrmat = tx.corr()\nk =10\ncols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\ncm = np.corrcoef(tx[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=False, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using GradientBoostingRegressor to see features importance\ntx1 = tx.copy()\ntx1.drop(['SalePrice'],axis=1,inplace=True)\nty1 = np.log1p(tx['SalePrice'])\ntx1 = np.log1p(tx1)\n\nX_train, X_test, y_train, y_test = train_test_split(tx1, ty1, test_size=0.2, random_state=13)\n\nparams = {'n_estimators': 500,\n          'max_depth': 4,\n          'min_samples_split': 5,\n          'learning_rate': 0.01,\n          'loss': 'ls'}\nreg = ensemble.GradientBoostingRegressor(**params)\nreg.fit(X_train, y_train)\n\nmse = mean_squared_error(y_test, reg.predict(X_test))\nprint(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))\n\ntest_score = np.zeros((params['n_estimators'],), dtype=np.float64)\nfor i, y_pred in enumerate(reg.staged_predict(X_test)):\n    test_score[i] = reg.loss_(y_test, y_pred)\n\nfig = plt.figure(figsize=(6, 6))\nplt.subplot(1, 1, 1)\nplt.title('Deviance')\nplt.plot(np.arange(params['n_estimators']) + 1, reg.train_score_, 'b-',\n         label='Training Set Deviance')\nplt.plot(np.arange(params['n_estimators']) + 1, test_score, 'r-',\n         label='Test Set Deviance')\nplt.legend(loc='upper right')\nplt.xlabel('Boosting Iterations')\nplt.ylabel('Deviance')\nfig.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importance = reg.feature_importances_\nsorted_idx = np.argsort(feature_importance)\npos = np.arange(sorted_idx.shape[0]) + .5\n#print(pos)\n#print(np.array(tx.columns)[sorted_idx])\nfig = plt.figure(figsize=(40, 30))\nplt.subplot(1, 2, 1)\nplt.barh(pos, feature_importance[sorted_idx], align='center')\nplt.yticks(pos, np.array(tx.columns)[sorted_idx])\naa = (pos, np.array(tx.columns)[sorted_idx])\nplt.title('Feature Importance (MDI)')\n'''\nresult = permutation_importance(reg, X_test, y_test, n_repeats=10,\n                                random_state=42, n_jobs=2)\nsorted_idx = result.importances_mean.argsort()\nplt.subplot(1, 2, 2)\nplt.boxplot(result.importances[sorted_idx].T,vert=False, labels=np.array(tx.columns)[sorted_idx])\nplt.title(\"Permutation Importance (test set)\")\nfig.tight_layout()\nplt.show() '''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Data Normalization</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nl = 0\nlog_data = np.log1p(tx)\nsqrt_data = np.sqrt(tx)\nbox_data = tx.copy()\nfor i in box_data:\n  box_data[i],lam = stats.boxcox(box_data[i]+1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(12, 3, figsize=(50, 100), sharex=True)\nc = 0\nfor i in range(12):\n  for j in range(3):\n    sns.kdeplot(log_data.iloc[:,c], color=\"red\", cumulative=True, bw=1.5, ax=axes[i,j])\n    c+=1\nfor i, ax in enumerate(axes.reshape(-1)):\n    ax.text(x=0.97, y=0.97, transform=ax.transAxes, s=\"Skewness: %f\" % log_data.iloc[:,i].skew(),\\\n        fontweight='demibold', fontsize=20, verticalalignment='top', horizontalalignment='right',\\\n        backgroundcolor='white', color='xkcd:poo brown')\n    ax.text(x=0.97, y=0.91, transform=ax.transAxes, s=\"Kurtosis: %f\" % log_data.iloc[:,i].kurt(),\\\n        fontweight='demibold', fontsize=20, verticalalignment='top', horizontalalignment='right',\\\n        backgroundcolor='white', color='xkcd:dried blood')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(12, 3, figsize=(50, 100), sharex=True)\nc = 0\nfor i in range(12):\n  for j in range(3):\n    sns.kdeplot(sqrt_data.iloc[:,c], color=\"red\", cumulative=True, bw=1.5, ax=axes[i,j])\n    c+=1\nfor i, ax in enumerate(axes.reshape(-1)):\n    ax.text(x=0.97, y=0.97, transform=ax.transAxes, s=\"Skewness: %f\" % log_data.iloc[:,i].skew(),\\\n        fontweight='demibold', fontsize=20, verticalalignment='top', horizontalalignment='right',\\\n        backgroundcolor='white', color='xkcd:poo brown')\n    ax.text(x=0.97, y=0.91, transform=ax.transAxes, s=\"Kurtosis: %f\" % log_data.iloc[:,i].kurt(),\\\n        fontweight='demibold', fontsize=20, verticalalignment='top', horizontalalignment='right',\\\n        backgroundcolor='white', color='xkcd:dried blood')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(12, 3, figsize=(50, 100), sharex=True)\nc = 0\nfor i in range(12):\n  for j in range(3):\n    sns.kdeplot(box_data.iloc[:,c], color=\"red\", cumulative=True, bw=1.5, ax=axes[i,j])\n    c+=1\nfor i, ax in enumerate(axes.reshape(-1)):\n    ax.text(x=0.97, y=0.97, transform=ax.transAxes, s=\"Skewness: %f\" % log_data.iloc[:,i].skew(),\\\n        fontweight='demibold', fontsize=20, verticalalignment='top', horizontalalignment='right',\\\n        backgroundcolor='white', color='xkcd:poo brown')\n    ax.text(x=0.97, y=0.91, transform=ax.transAxes, s=\"Kurtosis: %f\" % log_data.iloc[:,i].kurt(),\\\n        fontweight='demibold', fontsize=20, verticalalignment='top', horizontalalignment='right',\\\n        backgroundcolor='white', color='xkcd:dried blood')\nplt.tight_layout()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}