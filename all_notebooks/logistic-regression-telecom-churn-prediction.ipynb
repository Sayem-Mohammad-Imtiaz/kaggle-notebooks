{"cells":[{"metadata":{},"cell_type":"markdown","source":"**LOGISTIC REGRESSION**\n\nProblem Statement :\n\n \"You have a telecom firm which has collected data of all its customers\"\nThe main types of attributes are :\n\n\t1.Demographics (age, gender etc.)\n    \n\t2.Services availed (internet packs purchased, special offers etc)\n    \n\t3.Expenses (amount of recharge done per month etc.)\n    \nBased on all this past information, you want to build a model which will predict whether a particular customer will churn or not. \nSo the variable of interest, i.e. the target variable here is ‘Churn’ which will tell us whether or not a particular customer has churned. It is a binary variable  1 means that the customer has churned and 0 means the customer has not churned.\nWith 21 predictor variables we need to predict whether a particular customer will switch to another telecom provider or not.\n"},{"metadata":{},"cell_type":"markdown","source":"**Import necessary libraries**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Supress Warnings\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Import the numpy and pandas package\n\nimport numpy as np\nimport pandas as pd\n\n# Data Visualisation\n\nimport matplotlib.pyplot as plt \n ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**\tImporting all datasets**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Importing all datasets\nchurn_data = pd.read_csv('../input/churn_data.csv')\ncustomer_data = pd.read_csv('../input/customer_data.csv')\ninternet_data = pd.read_csv('../input/internet_data.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**\tMerging all datasets based on condition (\"customer_id \")**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merging on 'customerID'\ndf_1 = pd.merge(churn_data, customer_data, how='inner', on='customerID')\n\n# Final dataframe with all predictor variables\ndataset = pd.merge(df_1, internet_data, how='inner', on='customerID')\n\n# Let's see the head of our master dataset\ndataset.head()\n\n# let's look at the statistical aspects of the dataframe\ndataset.describe()\n\n# Let's see the type of each column\ndataset.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** \tData Cleaning - checking the null values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking Null values\ndataset.isnull().sum()*100/dataset.shape[0]\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**# There are no NULL values in the dataset, hence it is clean**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Replacing NAN values in totalcharges\ndataset['TotalCharges'].describe()\ndataset['TotalCharges'] = dataset['TotalCharges'].replace(' ', np.nan)\ndataset['TotalCharges'] = pd.to_numeric(dataset['TotalCharges'])\n\nvalue = (dataset['TotalCharges']/dataset['MonthlyCharges']).median()*dataset['MonthlyCharges']\ndataset['TotalCharges'] = value.where(dataset['TotalCharges'] == np.nan, other =dataset['TotalCharges'])\ndataset['TotalCharges'].describe()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Model building******"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Model Building\n#Data Preparation\n#Converting some binary variables (Yes/No) to 0/1\n# List of variables to map\n\nvarlist =  ['PhoneService', 'PaperlessBilling', 'Churn', 'Partner', 'Dependents']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" \tBinary encoding**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining the map function\ndef binary_map(x):\n    return x.map({'Yes': 1, \"No\": 0})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** \tOne hot encoding**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying the function to the var list\ndataset[varlist] = dataset[varlist].apply(binary_map)\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** \tCreating dummy variables and removing the extra columns**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#For categorical variables with multiple levels, create dummy features (one-hot encoded)\n# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummy1 = pd.get_dummies(dataset[['Contract', 'PaymentMethod', 'gender', 'InternetService']], drop_first=True)\n\n# Adding the results to the master dataframe\ndataset = pd.concat([dataset, dummy1], axis=1)\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating dummy variables for the remaining categorical variables and dropping the level with big names.\n\n# Creating dummy variables for the variable 'MultipleLines'\nml = pd.get_dummies(dataset['MultipleLines'], prefix='MultipleLines')\n# Dropping MultipleLines_No phone service column\nml1 = ml.drop(['MultipleLines_No phone service'], 1)\n#Adding the results to the master dataframe\ndataset = pd.concat([dataset,ml1], axis=1)\n\n# Creating dummy variables for the variable 'OnlineSecurity'.\nos = pd.get_dummies(dataset['OnlineSecurity'], prefix='OnlineSecurity')\nos1 = os.drop(['OnlineSecurity_No internet service'], 1)\n# Adding the results to the master dataframe\ndataset = pd.concat([dataset,os1], axis=1)\n\n# Creating dummy variables for the variable 'OnlineBackup'.\nob = pd.get_dummies(dataset['OnlineBackup'], prefix='OnlineBackup')\nob1 = ob.drop(['OnlineBackup_No internet service'], 1)\n# Adding the results to the master dataframe\ndataset = pd.concat([dataset,ob1], axis=1)\n\n# Creating dummy variables for the variable 'DeviceProtection'. \ndp = pd.get_dummies(dataset['DeviceProtection'], prefix='DeviceProtection')\ndp1 = dp.drop(['DeviceProtection_No internet service'], 1)\n# Adding the results to the master dataframe\ndataset = pd.concat([dataset,dp1], axis=1)\n\n# Creating dummy variables for the variable 'TechSupport'. \nts = pd.get_dummies(dataset['TechSupport'], prefix='TechSupport')\nts1 = ts.drop(['TechSupport_No internet service'], 1)\n# Adding the results to the master dataframe\ndataset = pd.concat([dataset,ts1], axis=1)\n\n# Creating dummy variables for the variable 'StreamingTV'.\nst =pd.get_dummies(dataset['StreamingTV'], prefix='StreamingTV')\nst1 = st.drop(['StreamingTV_No internet service'], 1)\n# Adding the results to the master dataframe\ndataset = pd.concat([dataset,st1], axis=1)\n\n# Creating dummy variables for the variable 'StreamingMovies'. \nsm = pd.get_dummies(dataset['StreamingMovies'], prefix='StreamingMovies')\nsm1 = sm.drop(['StreamingMovies_No internet service'], 1)\n# Adding the results to the master dataframe\ndataset = pd.concat([dataset,sm1], axis=1)\ndataset.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We have created dummies for the below variables, so we can drop them\ndataset = dataset.drop(['Contract','PaymentMethod','gender','MultipleLines','InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n       'TechSupport', 'StreamingTV', 'StreamingMovies'], 1)\ndataset.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for outliers in the continuous variables\nnum_telecom = dataset[['tenure','MonthlyCharges','SeniorCitizen','TotalCharges']]\n# Checking outliers at 25%, 50%, 75%, 90%, 95% and 99%\nnum_telecom.describe(percentiles=[.25, .5, .75, .90, .95, .99])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking up the missing values (column-wise)\ndataset.isnull().sum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing NaN TotalCharges rows\ndataset = dataset[~np.isnan(dataset['TotalCharges'])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking percentage of missing values after removing the missing values\nround(100*(dataset.isnull().sum()/len(dataset.index)), 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Putting feature variable to X\nfrom sklearn.model_selection import train_test_split #use 'cross_validation' instead of\n                                                     #'model_selection' Executing in jupyter or spyder \nX = dataset.drop(['Churn','customerID'], axis=1)\nX.head()\n\n# Putting response variable to y\ny = dataset['Churn']\n\ny.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the data into train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\nX_train[['tenure','MonthlyCharges','TotalCharges']] = scaler.fit_transform(X_train[['tenure','MonthlyCharges','TotalCharges']])\n\nX_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Building\n# Logistic regression model\nimport statsmodels.api as sm\nlogm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\nlogm1.fit().summary()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature Selection Using RFE\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\nfrom sklearn.feature_selection import RFE\nrfe = RFE(logreg, 15)             # running RFE with 13 variables as output\nrfe = rfe.fit(X_train, y_train)\nrfe.support_\n\nlist(zip(X_train.columns, rfe.support_, rfe.ranking_))\n\n\ncol = X_train.columns[rfe.support_]\nX_train.columns[~rfe.support_]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adding a constant\n\nX_train_sm = sm.add_constant(X_train[col])\nlogm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm2.fit()\nres.summary()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** \tGetting the predicted values on train set**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the predicted values on the train set\ny_train_pred = res.predict(X_train_sm)\ny_train_pred[:10]\n\n\ny_train_pred_final = pd.DataFrame({'Churn':y_train.values, 'Churn_Prob':y_train_pred})\ny_train_pred_final['CustID'] = y_train.index\ny_train_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**\tCreating a new column predicted with 1  if churn  > 0.5  else 0**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating new column 'predicted' with 1 if Churn_Prob > 0.5 else 0\ny_train_pred_final['predicted'] = y_train_pred_final.Churn_Prob.map(lambda x: 1 if x > 0.5 else 0)\n\n# Let's see the head\ny_train_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** \tCreate a confusion matrix on train set and test**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion matrix\nfrom sklearn import metrics\nconfusion_matrix = metrics.confusion_matrix(y_train_pred_final.Churn, y_train_pred_final.predicted )\nprint(confusion_matrix)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the overall accuracy.\nprint(metrics.accuracy_score(y_train_pred_final.Churn, y_train_pred_final.predicted))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Making predictions on the test set\nX_test[['tenure','MonthlyCharges','TotalCharges']] = scaler.fit_transform(X_test[['tenure','MonthlyCharges','TotalCharges']])\nX_test = X_test[col]\nX_test.head()\n\nX_test_sm = sm.add_constant(X_test)\ny_test_pred = res.predict(X_test_sm)\ny_test_pred[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting y_pred to a dataframe which is an array\ny_pred_1 = pd.DataFrame(y_test_pred)\ny_pred_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting y_test to dataframe\ny_test_df = pd.DataFrame(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Putting CustID to index\ny_test_df['CustID'] = y_test_df.index\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing index for both dataframes to append them side by side \ny_pred_1.reset_index(drop=True, inplace=True)\ny_test_df.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Appending y_test_df and y_pred_1\ny_pred_final = pd.concat([y_test_df, y_pred_1],axis=1)\ny_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rearranging the columns\ny_pred_final = y_pred_final.reindex_axis(['CustID','Churn','Churn_Prob'], axis=1)\n# Let's see the head of y_pred_final\ny_pred_final.head()\ny_pred_final['final_predicted'] = y_pred_final.Churn_Prob.map(lambda x: 1 if x > 0.42 else 0)\ny_pred_final.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** \t Check the overall accuracy**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the overall accuracy.\nmetrics.accuracy_score(y_pred_final.Churn, y_pred_final.final_predicted)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}