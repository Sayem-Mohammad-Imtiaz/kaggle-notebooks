{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom plotly.offline import init_notebook_mode\ninit_notebook_mode(connected = True)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-26T11:09:57.027834Z","iopub.execute_input":"2021-05-26T11:09:57.028227Z","iopub.status.idle":"2021-05-26T11:09:57.050486Z","shell.execute_reply.started":"2021-05-26T11:09:57.028194Z","shell.execute_reply":"2021-05-26T11:09:57.04905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/customer-segmentation/Train.csv')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T11:09:57.623001Z","iopub.execute_input":"2021-05-26T11:09:57.623361Z","iopub.status.idle":"2021-05-26T11:09:57.663504Z","shell.execute_reply.started":"2021-05-26T11:09:57.623331Z","shell.execute_reply":"2021-05-26T11:09:57.662178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"|Variable|\tDefinition|\n|---|---|\n|ID\tUnique| ID|\n|Gender|\tGender of the customer|\n|Ever_Married|\tMarital status of the customer|\n|Age|\tAge of the customer|\n|Graduated|\tIs the customer a graduate?|\n|Profession|\tProfession of the customer|\n|Work_Experience|\tWork Experience in years|\n|Spending_Score|\tSpending score of the customer|\n|Family_Size|\tNumber of family members for the customer (including the customer)|\n|Var_1|\tAnonymised Category for the customer|\n|Segmentation|\t(target) Customer Segment of the customer|","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T11:10:01.344993Z","iopub.execute_input":"2021-05-26T11:10:01.34534Z","iopub.status.idle":"2021-05-26T11:10:01.370117Z","shell.execute_reply.started":"2021-05-26T11:10:01.34531Z","shell.execute_reply":"2021-05-26T11:10:01.368406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"plot_data = data.groupby('Segmentation')['Segmentation'].agg(['count']).reset_index()\n\nfig = px.pie(plot_data, values = plot_data['count'], names = plot_data['Segmentation'])\n\nfig.update_traces(textposition = 'inside', textinfo = 'percent + label', hole = 0.5, \n                  marker = dict(colors = ['#2A3132','#336B87'], line = dict(color = 'white', width = 2)))\n\nfig.update_layout(title_text = 'Customer<br>Segmentation', title_x = 0.5, title_y = 0.55, title_font_size = 26, \n                  title_font_family = 'Calibri', title_font_color = 'black', showlegend = False)\n                  \nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T06:08:03.212228Z","iopub.execute_input":"2021-05-26T06:08:03.212636Z","iopub.status.idle":"2021-05-26T06:08:03.299131Z","shell.execute_reply.started":"2021-05-26T06:08:03.212598Z","shell.execute_reply":"2021-05-26T06:08:03.297565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_category(feature, figsize=None):\n    A_count = data[data['Segmentation']=='A'].groupby([feature]).size()\n    B_count = data[data['Segmentation']=='B'].groupby([feature]).size()\n    C_count = data[data['Segmentation']=='C'].groupby([feature]).size()\n    D_count = data[data['Segmentation']=='D'].groupby([feature]).size()\n    labels = A_count.index\n\n    x = np.arange(len(labels)) # the label locations\n    width = 0.7  # the width of the bars\n\n    if figsize:\n        fig, ax = plt.subplots(figsize=figsize)\n    else:\n        fig, ax = plt.subplots()\n    rects1 = ax.bar(x-width/3, round(A_count*100/data.groupby([feature]).size(), 2), \n                    width/5, label='A')\n    rects2 = ax.bar(x-width/8, round(B_count*100/data.groupby([feature]).size(), 2), \n                    width/5, label='B')\n    rects3 = ax.bar(x+width/8, round(C_count*100/data.groupby([feature]).size(), 2), \n                    width/5, label='C')\n    rects4 = ax.bar(x+width/3, round(D_count*100/data.groupby([feature]).size(), 2), \n                    width/5, label='D')\n\n    ax.set_ylabel('Count')\n    ax.set_title('Based on %s'%feature)\n    ax.set_xticks(x)\n    ax.set_xticklabels(labels, rotation=80)\n    ax.legend(loc=0, bbox_to_anchor=(1, 1));\n\n    ax.bar_label(rects1, padding=1)\n    ax.bar_label(rects2, padding=1)\n    ax.bar_label(rects3, padding=1)\n    ax.bar_label(rects4, padding=1)\n\n    fig.tight_layout()\n    plt.show()\n    \ndef plot_numerical(feature, figsize=None):\n    fig = plt.figure(figsize=(10,6))\n\n    sns.kdeplot(data[data['Segmentation']=='A'][feature])\n    sns.kdeplot(data[data['Segmentation']=='B'][feature])\n    sns.kdeplot(data[data['Segmentation']=='C'][feature])\n    sns.kdeplot(data[data['Segmentation']=='D'][feature])\n\n    fig.legend(labels=['Segmentation A', 'Segmentation B', 'Segmentation C', 'Segmentation D'])\n    plt.title('Based on %s'%feature)\n    plt.show()\n    \ndef plot_pie(feature):\n    plot_data = data.groupby([feature, 'Segmentation'])[feature].agg({'count'}).reset_index()\n\n    fig = px.sunburst(plot_data, path = [feature, 'Segmentation'], values = 'count', color = feature, \n                      title = 'Affect of %s on Customer Segmentation'%feature, width = 600, height = 600)\n\n    fig.update_layout(plot_bgcolor = 'white', title_font_family = 'Calibri Black', title_font_color = '#221f1f', \n                      title_font_size = 22, title_x = 0.5)\n\n    fig.update_traces(textinfo = 'label + percent parent')\n    fig.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T06:00:21.666381Z","iopub.execute_input":"2021-05-26T06:00:21.666871Z","iopub.status.idle":"2021-05-26T06:00:21.688273Z","shell.execute_reply.started":"2021-05-26T06:00:21.666829Z","shell.execute_reply":"2021-05-26T06:00:21.686963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in ['Gender', 'Ever_Married', 'Graduated', 'Spending_Score']:\n    plot_pie(feature)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T06:14:29.811339Z","iopub.execute_input":"2021-05-26T06:14:29.811743Z","iopub.status.idle":"2021-05-26T06:14:30.262111Z","shell.execute_reply.started":"2021-05-26T06:14:29.811708Z","shell.execute_reply":"2021-05-26T06:14:30.260495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in ['Profession', 'Var_1']:\n    plot_pie(feature)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T06:02:24.505821Z","iopub.execute_input":"2021-05-26T06:02:24.506271Z","iopub.status.idle":"2021-05-26T06:02:24.766881Z","shell.execute_reply.started":"2021-05-26T06:02:24.50623Z","shell.execute_reply":"2021-05-26T06:02:24.765231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in ['Age', 'Work_Experience', 'Family_Size']:\n    plot_numerical(feature)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T06:15:33.886557Z","iopub.execute_input":"2021-05-26T06:15:33.887003Z","iopub.status.idle":"2021-05-26T06:15:35.157386Z","shell.execute_reply.started":"2021-05-26T06:15:33.88696Z","shell.execute_reply":"2021-05-26T06:15:35.156221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations-**\n* Ever_Married - UnMarried customers are usually in segment D while married are in segment A, B or C\n* Graduated - Graduated customers are usually in segment A, B or C while Ungraduated are in segment D\n* Profession - Customers in healthcare & marketing are mostly in segment D, Artist & engineers are usually in A, B or C\n* Spending_Score - Usually 'Low' spenders are in segment A or D while 'high' and 'average' spenders are in segment B or C\n* Age - <30 are in segment D, 30-40 or >70 are in segment A while 45-70 are in segment C\n* Work_Experience - <2 are in segment C while 6-11 are in segment A & D\n* Family_Size - <1 are in segment A, 1-3 are in Segment C and 4+ in segment D","metadata":{}},{"cell_type":"code","source":"categorical_features = ['Gender', 'Ever_Married', 'Graduated', 'Profession', 'Spending_Score', 'Var_1']\nnumerical_features = ['Age', 'Work_Experience', 'Family_Size']\n\nto_drop = ['ID'] # contain unique values","metadata":{"execution":{"iopub.status.busy":"2021-05-26T11:10:17.275135Z","iopub.execute_input":"2021-05-26T11:10:17.275709Z","iopub.status.idle":"2021-05-26T11:10:17.282158Z","shell.execute_reply.started":"2021-05-26T11:10:17.275655Z","shell.execute_reply":"2021-05-26T11:10:17.280878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CORRELATION","metadata":{}},{"cell_type":"markdown","source":"### Label encoding category features for correlation","metadata":{"execution":{"iopub.status.busy":"2021-05-26T06:28:48.240399Z","iopub.execute_input":"2021-05-26T06:28:48.240835Z","iopub.status.idle":"2021-05-26T06:28:48.246039Z","shell.execute_reply.started":"2021-05-26T06:28:48.240802Z","shell.execute_reply":"2021-05-26T06:28:48.244674Z"}}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\nimport os\nimport joblib","metadata":{"execution":{"iopub.status.busy":"2021-05-26T11:10:08.192354Z","iopub.execute_input":"2021-05-26T11:10:08.192879Z","iopub.status.idle":"2021-05-26T11:10:08.198184Z","shell.execute_reply.started":"2021-05-26T11:10:08.192818Z","shell.execute_reply":"2021-05-26T11:10:08.197032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = data.copy()\npath = '/kaggle/working'\nfor i, feature in enumerate(categorical_features):\n    le = LabelEncoder()\n\n    # create directory to save label encoding models\n    if not os.path.exists(os.path.join(path, \"TextEncoding\")):\n        os.makedirs(os.path.join(path, \"TextEncoding\"))\n\n    # perform label encoding\n    le.fit(df[feature])\n    \n    # save the encoder\n    joblib.dump(le, open(os.path.join(path, \"TextEncoding/le_{}.sav\".format(feature)), 'wb'))\n    \n    # transfrom training data\n    df[feature] = le.transform(df[feature])\n\n    # get classes & remove first column to elude from dummy variable trap\n    columns = list(map(lambda x: feature+' '+str(x), list(le.classes_)))[1:]\n    \n    # save classes\n    joblib.dump(columns, \n                open(os.path.join(path, \"TextEncoding/le_{}_classes.sav\".format(feature)), 'wb'))","metadata":{"execution":{"iopub.status.busy":"2021-05-26T10:02:00.554834Z","iopub.execute_input":"2021-05-26T10:02:00.555282Z","iopub.status.idle":"2021-05-26T10:02:00.596114Z","shell.execute_reply.started":"2021-05-26T10:02:00.555237Z","shell.execute_reply":"2021-05-26T10:02:00.594819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bivariate Analysis Correlation plot with the Numeric variables\n","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(5, 2))\nsns.heatmap(round(data[numerical_features].corr(), 2), annot=True,\n            mask=None, cmap='GnBu')\ncorr_mat = data[numerical_features].corr()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T10:02:02.667959Z","iopub.execute_input":"2021-05-26T10:02:02.668389Z","iopub.status.idle":"2021-05-26T10:02:02.910651Z","shell.execute_reply.started":"2021-05-26T10:02:02.668353Z","shell.execute_reply":"2021-05-26T10:02:02.909873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bivariate Analysis Correlation plot with the Categorical variables","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.heatmap(round(df[categorical_features+numerical_features].corr(method='spearman'), 2), annot=True,\n            mask=None, cmap='GnBu')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T06:32:51.136368Z","iopub.execute_input":"2021-05-26T06:32:51.136766Z","iopub.status.idle":"2021-05-26T06:32:51.974691Z","shell.execute_reply.started":"2021-05-26T06:32:51.136732Z","shell.execute_reply":"2021-05-26T06:32:51.973736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations-**\n* Ever_Married - Spending_Score\n* Ever_Married - Age","metadata":{}},{"cell_type":"markdown","source":"# Analyzing features using VIF","metadata":{}},{"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor","metadata":{"execution":{"iopub.status.busy":"2021-05-26T06:36:43.738874Z","iopub.execute_input":"2021-05-26T06:36:43.739288Z","iopub.status.idle":"2021-05-26T06:36:43.88208Z","shell.execute_reply.started":"2021-05-26T06:36:43.739256Z","shell.execute_reply":"2021-05-26T06:36:43.88075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculating VIF\nvif = pd.DataFrame()\ntemp = df.dropna()\nvif[\"variables\"] = [feature for feature in categorical_features+numerical_features if feature not in ['Age', 'Var_1']]\nvif[\"VIF\"] = [variance_inflation_factor(temp[vif['variables']].values, i) for i in range(len(vif[\"variables\"]))]\nprint(vif)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T06:37:48.761543Z","iopub.execute_input":"2021-05-26T06:37:48.761891Z","iopub.status.idle":"2021-05-26T06:37:48.833082Z","shell.execute_reply.started":"2021-05-26T06:37:48.761862Z","shell.execute_reply":"2021-05-26T06:37:48.831775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Age and Var_1 have high VIF score","metadata":{}},{"cell_type":"markdown","source":"# Handling Missing Values","metadata":{"execution":{"iopub.status.busy":"2021-05-26T06:38:24.978266Z","iopub.execute_input":"2021-05-26T06:38:24.978859Z","iopub.status.idle":"2021-05-26T06:38:24.983147Z","shell.execute_reply.started":"2021-05-26T06:38:24.978809Z","shell.execute_reply":"2021-05-26T06:38:24.982094Z"}}},{"cell_type":"code","source":"missingValueFeatures = pd.DataFrame({'missing %': data.isnull().sum()*100/len(data)})\nmissingValueFeatures[missingValueFeatures['missing %']>0]","metadata":{"execution":{"iopub.status.busy":"2021-05-26T06:38:35.783585Z","iopub.execute_input":"2021-05-26T06:38:35.784186Z","iopub.status.idle":"2021-05-26T06:38:35.806744Z","shell.execute_reply.started":"2021-05-26T06:38:35.784147Z","shell.execute_reply":"2021-05-26T06:38:35.805562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As most of the features are uncorrelated, it is difficult to fill the NA values. Hence for the time being let's drop all NA.","metadata":{}},{"cell_type":"code","source":"data_missing = data.dropna().reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T11:10:23.580618Z","iopub.execute_input":"2021-05-26T11:10:23.581009Z","iopub.status.idle":"2021-05-26T11:10:23.599607Z","shell.execute_reply.started":"2021-05-26T11:10:23.580974Z","shell.execute_reply":"2021-05-26T11:10:23.598815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Looking at Outliers","metadata":{}},{"cell_type":"code","source":"NumericData = data_missing[[feature for feature in numerical_features if feature not in []]]\nNumericMelt = NumericData.melt()\nplt.figure(figsize=(15,10))\nplt.title(\"Boxplots for Numerical variables\")\nbp = sns.boxplot(x='variable', y='value', data=NumericMelt)\nbp.set_xticklabels(bp.get_xticklabels(), rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:18:37.935406Z","iopub.execute_input":"2021-05-26T07:18:37.935939Z","iopub.status.idle":"2021-05-26T07:18:38.162195Z","shell.execute_reply.started":"2021-05-26T07:18:37.935888Z","shell.execute_reply":"2021-05-26T07:18:38.161332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Percentage of outliers present in each variable\noutlier_percentage = {}\nfor feature in numerical_features:\n    tempData = data_missing.sort_values(by=feature)[feature]\n    Q1, Q3 = tempData.quantile([0.25, 0.75])\n    IQR = Q3 - Q1\n    Lower_range = Q1 - (1.5 * IQR)\n    Upper_range = Q3 + (1.5 * IQR)\n    outlier_percentage[feature] = round((((tempData<(Q1 - 1.5 * IQR)) | (tempData>(Q3 + 1.5 * IQR))).sum()/tempData.shape[0])*100,2)\noutlier_percentage","metadata":{"execution":{"iopub.status.busy":"2021-05-26T07:18:38.527293Z","iopub.execute_input":"2021-05-26T07:18:38.527803Z","iopub.status.idle":"2021-05-26T07:18:38.552012Z","shell.execute_reply.started":"2021-05-26T07:18:38.52777Z","shell.execute_reply":"2021-05-26T07:18:38.550671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Handling Categorical Features (Label and One Hot Encoding)","metadata":{}},{"cell_type":"code","source":"df = data_missing.copy()\npath = '/kaggle/working'\nfor i, feature in enumerate(categorical_features):\n    \n    le = LabelEncoder()\n    ohe = OneHotEncoder(sparse=False)\n\n    # create directory to save label encoding models\n    if not os.path.exists(os.path.join(path, \"TextEncoding\")):\n        os.makedirs(os.path.join(path, \"TextEncoding\"))\n\n    # perform label encoding\n    le.fit(df[feature])\n    # save the encoder\n    joblib.dump(le, open(os.path.join(path, \"TextEncoding/le_{}.sav\".format(feature)), 'wb'))\n    \n    # transfrom training data\n    df[feature] = le.transform(df[feature])\n\n    # get classes & remove first column to elude from dummy variable trap\n    columns = list(map(lambda x: feature+' '+str(x), list(le.classes_)))[1:]\n    \n    # save classes\n    joblib.dump(columns, \n                open(os.path.join(path, \"TextEncoding/le_{}_classes.sav\".format(feature)), 'wb'))\n    # load classes\n    columns = joblib.load(\n        open(os.path.join(path, \"TextEncoding/le_{}_classes.sav\".format(feature)), 'rb'))\n\n    if len(le.classes_)>2:\n        # perform one hot encoding\n        ohe.fit(df[[feature]])\n        # save the encoder\n        joblib.dump(ohe, open(os.path.join(path, \"TextEncoding/ohe_{}.sav\".format(feature)), 'wb'))\n\n        # transfrom training data\n        # removing first column of encoded data to elude from dummy variable trap\n        tempData = ohe.transform(df[[feature]])[:, 1:]\n\n        # create Dataframe with columns as classes\n        tempData = pd.DataFrame(tempData, columns=columns)\n    else:\n        tempData = df[[feature]]\n    \n    # create dataframe with all the label encoded categorical features along with hot encoding\n    if i==0:\n        encodedData = pd.DataFrame(data=tempData, columns=tempData.columns.values.tolist())\n    else:\n        encodedData = pd.concat([encodedData, tempData], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T11:10:27.418291Z","iopub.execute_input":"2021-05-26T11:10:27.420356Z","iopub.status.idle":"2021-05-26T11:10:27.483925Z","shell.execute_reply.started":"2021-05-26T11:10:27.420313Z","shell.execute_reply":"2021-05-26T11:10:27.48304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merge numerical features and categorical encoded features\ndf = df[numerical_features+['Segmentation']]\ndf = pd.concat([df, encodedData], axis=1)\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T11:10:29.148345Z","iopub.execute_input":"2021-05-26T11:10:29.148771Z","iopub.status.idle":"2021-05-26T11:10:29.178791Z","shell.execute_reply.started":"2021-05-26T11:10:29.148736Z","shell.execute_reply":"2021-05-26T11:10:29.177479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Model","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics, preprocessing\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom xgboost import XGBClassifier","metadata":{"execution":{"iopub.status.busy":"2021-05-26T11:10:31.954077Z","iopub.execute_input":"2021-05-26T11:10:31.95451Z","iopub.status.idle":"2021-05-26T11:10:31.959524Z","shell.execute_reply.started":"2021-05-26T11:10:31.954467Z","shell.execute_reply":"2021-05-26T11:10:31.95875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = df.copy()\nfeature_cols = [feature for feature in train_data.columns if feature not in(['Segmentation'])]\nprint('features used- ', feature_cols)\n\n''' Rescaling to [0,1] '''\nscaler = StandardScaler()\nscaler.fit(train_data[feature_cols])\ntrain_data[feature_cols] = scaler.transform(train_data[feature_cols])","metadata":{"execution":{"iopub.status.busy":"2021-05-26T11:10:37.73183Z","iopub.execute_input":"2021-05-26T11:10:37.73268Z","iopub.status.idle":"2021-05-26T11:10:37.813468Z","shell.execute_reply.started":"2021-05-26T11:10:37.732622Z","shell.execute_reply":"2021-05-26T11:10:37.812092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['Segmentation'] = train_data['Segmentation'].map({'A':0, 'B':1, 'C':2, 'D':3})\nX = train_data[feature_cols]\ny = train_data['Segmentation']\n\nvalidation_size = 0.25\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=validation_size, \n                                                    random_state=0, stratify=y)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T11:10:40.879099Z","iopub.execute_input":"2021-05-26T11:10:40.879472Z","iopub.status.idle":"2021-05-26T11:10:40.898841Z","shell.execute_reply.started":"2021-05-26T11:10:40.879431Z","shell.execute_reply":"2021-05-26T11:10:40.897708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 1: Logistic Regression","metadata":{}},{"cell_type":"code","source":"model = LogisticRegression()\nmodel.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T11:10:43.204492Z","iopub.execute_input":"2021-05-26T11:10:43.204867Z","iopub.status.idle":"2021-05-26T11:10:43.37901Z","shell.execute_reply.started":"2021-05-26T11:10:43.204815Z","shell.execute_reply":"2021-05-26T11:10:43.37791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_train)\n\nprint('Train metrics...')\nprint(confusion_matrix(y_train, y_pred))\nprint(classification_report(y_train, y_pred))\n\ny_pred = model.predict(X_test)\n\nprint('Validation metrics...')\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-05-26T11:10:43.980931Z","iopub.execute_input":"2021-05-26T11:10:43.981324Z","iopub.status.idle":"2021-05-26T11:10:44.0543Z","shell.execute_reply.started":"2021-05-26T11:10:43.98129Z","shell.execute_reply":"2021-05-26T11:10:44.053107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"''' metrics on original data '''\ny_pred = model.predict(train_data[feature_cols])\n\ndef make_cm(matrix, columns):\n    n = len(columns)\n    act = ['actual Segmentation'] * n\n    pred = ['predicted Segmentation'] * n\n\n    cm = pd.DataFrame(matrix, \n        columns=[pred, columns], index=[act, columns])\n    return cm\n\ndf_matrix=make_cm(\n    confusion_matrix(train_data['Segmentation'], y_pred),['A', 'B', 'C', 'D'])\n\ndisplay(df_matrix)\nprint(classification_report(train_data['Segmentation'], y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-05-26T11:10:50.606376Z","iopub.execute_input":"2021-05-26T11:10:50.606726Z","iopub.status.idle":"2021-05-26T11:10:50.69955Z","shell.execute_reply.started":"2021-05-26T11:10:50.606696Z","shell.execute_reply":"2021-05-26T11:10:50.698308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 2: XGB","metadata":{}},{"cell_type":"code","source":"model = XGBClassifier(\n    learning_rate=0.05, \n    max_depth=3,\n    min_child_weight=5, \n    n_estimators=1000, \n    random_state=7, \n    reg_lambda=1.5,\n    reg_alpha=0.5,\n    use_label_encoder=False\n)\n\nmodel.fit(X_train, y_train,\n          eval_metric='mlogloss',\n          verbose=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T11:10:54.497883Z","iopub.execute_input":"2021-05-26T11:10:54.498231Z","iopub.status.idle":"2021-05-26T11:11:00.673678Z","shell.execute_reply.started":"2021-05-26T11:10:54.498198Z","shell.execute_reply":"2021-05-26T11:11:00.672372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_train)\n\nprint('Train metrics...')\nprint(confusion_matrix(y_train, y_pred))\nprint(classification_report(y_train, y_pred))\n\ny_pred = model.predict(X_test)\n\nprint('Test metrics...')\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-05-26T11:11:00.675568Z","iopub.execute_input":"2021-05-26T11:11:00.675932Z","iopub.status.idle":"2021-05-26T11:11:00.846506Z","shell.execute_reply.started":"2021-05-26T11:11:00.6759Z","shell.execute_reply":"2021-05-26T11:11:00.845441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"''' metrics on original data '''\ny_pred = model.predict(train_data[feature_cols])\n\ndef make_cm(matrix, columns):\n    n = len(columns)\n    act = ['actual Segmentation'] * n\n    pred = ['predicted Segmentation'] * n\n\n    cm = pd.DataFrame(matrix, \n        columns=[pred, columns], index=[act, columns])\n    return cm\n\ndf_matrix=make_cm(\n    confusion_matrix(train_data['Segmentation'], y_pred),['A', 'B', 'C', 'D'])\n\ndisplay(df_matrix)\nprint(classification_report(train_data['Segmentation'], y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-05-26T11:11:06.967646Z","iopub.execute_input":"2021-05-26T11:11:06.968153Z","iopub.status.idle":"2021-05-26T11:11:07.142796Z","shell.execute_reply.started":"2021-05-26T11:11:06.96812Z","shell.execute_reply":"2021-05-26T11:11:07.141156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 3: Deep Learning","metadata":{}},{"cell_type":"code","source":"\nnp.random.seed(123)  # for reproducibility\n\nimport keras\nfrom keras.models import Sequential, Input, Model\nfrom keras.layers import Dense, Dropout","metadata":{"execution":{"iopub.status.busy":"2021-05-26T11:11:13.210654Z","iopub.execute_input":"2021-05-26T11:11:13.211082Z","iopub.status.idle":"2021-05-26T11:11:13.217014Z","shell.execute_reply.started":"2021-05-26T11:11:13.211048Z","shell.execute_reply":"2021-05-26T11:11:13.215557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the constructor\nmodel = Sequential()\n# Add an input layer \n# arguemtns of dense: output shape, activation, input shape\n# activation(define the output function) = [relu', 'tanh']\nmodel.add(Dense(64, activation='relu', input_shape=(len(feature_cols),)))\nmodel.add(Dropout(0.3))\n# Add one hidden layer \n# after first layer no need to give input shape\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(8, activation='relu'))\n# Add an output layer \n# activation = [regression: 'linear', binary classification: 'sigmoid', multiclass: 'softmax']\n# threshold: >0 or <0\n# sigmoid: 1/(1+e^-x), usually applied in output layer\n# rectifier: max(x,0), usually applied in hidden layer: relu\n# hyperbolic tangent tanh: (1-e^-2x)/(1+e^-2x)\nmodel.add(Dense(4, activation='softmax'))\n\n# optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n# loss = [regression: 'mse', binary: 'binary_crossentropy', multi: 'categorical_crossentropy']\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='RMSprop',\n              metrics=['accuracy']\n         )\n\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2021-05-26T11:18:30.319942Z","iopub.execute_input":"2021-05-26T11:18:30.320307Z","iopub.status.idle":"2021-05-26T11:18:30.39754Z","shell.execute_reply.started":"2021-05-26T11:18:30.320275Z","shell.execute_reply":"2021-05-26T11:18:30.396217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit = model.fit(X_train, pd.get_dummies(y_train), epochs=150, batch_size=500, verbose=1, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T11:18:31.312635Z","iopub.execute_input":"2021-05-26T11:18:31.313112Z","iopub.status.idle":"2021-05-26T11:18:47.930471Z","shell.execute_reply.started":"2021-05-26T11:18:31.313072Z","shell.execute_reply":"2021-05-26T11:18:47.929405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Final evaluation of the model\nloss, accuracy = model.evaluate(X_test, pd.get_dummies(y_test), verbose=1)\n#print(\"Accuracy: \", accuracy*100, \"%\")\n\n# plot training vs validation for overfiiting\nplt.plot(fit.history['accuracy'], label='train accuracy')\nplt.plot(fit.history['val_accuracy'], label='validation accuracy')\nplt.plot(fit.history['loss'], label='train loss')\nplt.plot(fit.history['val_loss'], label='validation loss')\nplt.title('model_accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(loc=0, bbox_to_anchor=[1,1])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T11:18:47.932825Z","iopub.execute_input":"2021-05-26T11:18:47.933299Z","iopub.status.idle":"2021-05-26T11:18:48.403987Z","shell.execute_reply.started":"2021-05-26T11:18:47.933252Z","shell.execute_reply":"2021-05-26T11:18:48.402747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}