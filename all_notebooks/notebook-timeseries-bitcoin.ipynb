{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Dataset Bitcoin","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Présentation et objectifs","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Le Bitcoin est la plus ancienne crypto-monnaie, publiée pour la première fois en open source en 2009 par Satoshi Nakamoto. C'est un support décentralisé d'échange numérique, avec des transactions vérifiées et enregistrées publiquement (blockchain).L'intéret réside dans le fait qu'il n'y a pas besoin d'une autorité de tenue de dossiers  ou d'un intermédiaire central. Les blocs de transaction contiennent un hachage cryptographique des blocs de transaction précédents et sont donc \"enchaînés\" ensemble, cela sert d'enregistrement de toutes les transactions. Comme pour toute devise, le trading de bitcoins et les instruments financiers ont rapidement suivi l'adoption publique du bitcoin. \n\n\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Le but de ce notebook est de prédire les prix du Bitcoin en s'aidant de différents modèles prédictifs, afin de determiner lequel est le plus performant.<br>\nLa difficulté réside dans le fait que le bitcoin est tres volatile.<br>\nOn procédera tout d'abord à une analyse exploratoire des données puis une analyse des séries temporelles avant d'introduire différents modeles prédictifs","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Analyse Exploratoire","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"On dispose de 2 fichiers csv qui determinent les transactions de bitcoin dans une période définie entre le 31/12/2011 et le 22/04/2020 avec des mises a jour minute par minute.<br>\nL'horodatage se fait en temps Unix","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import de librairies","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport seaborn as sns\nfrom statsmodels.tsa.stattools import adfuller\nimport statsmodels.api as sm\nfrom scipy import stats\nfrom itertools import product\nimport warnings\n\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Chargement des fichiers csv et visualisation des premieres valeurs","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/bitcoin-historical-data/coinbaseUSD_1-min_data_2014-12-01_to_2019-01-09.csv')\ndf2 = pd.read_csv('../input/bitcoin-historical-data/bitstampUSD_1-min_data_2012-01-01_to_2020-04-22.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Dimension du 1er fichier',df.shape)\nprint('Dimension du 2eme fichier',df2.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"frames=[df, df2]\ndata=pd.concat(frames).drop_duplicates().reset_index(drop=True)\nprint(data.shape)\ndata.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conversion du Timestamp","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime, pytz\n#define a conversion function for the native timestamps in the csv file\ndef dateparse (time_in_secs):    \n    return pytz.utc.localize(datetime.datetime.fromtimestamp(float(time_in_secs)))\n\n\ndata1 = pd.read_csv('../input/bitcoin-historical-data/coinbaseUSD_1-min_data_2014-12-01_to_2019-01-09.csv', parse_dates=[0], date_parser=dateparse)\ndata2 = pd.read_csv('../input/bitcoin-historical-data/bitstampUSD_1-min_data_2012-01-01_to_2020-04-22.csv', parse_dates=[0], date_parser=dateparse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Infos sur les dates des deux dataframes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# intervalle de temps concerné data1\nprint(data1.Timestamp.min(), data1.Timestamp.max())\n\n#intervalle data2\nprint(data2.Timestamp.min(), data2.Timestamp.max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fusion des deux dataframes et suppression des valeurs dupliquées","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"frames=[data1, data2]\ndata=pd.concat(frames).drop_duplicates().reset_index(drop=True)\nprint(data.shape)\ndata.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Les données du dataframe comporte 6,43 millions des lignes et de 8 variables informant sur les prix du bitcoin a un instant précis.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualisation\ndata=data.sort_values(by='Timestamp', ascending=True)\ndata_corr=data.copy()\ndata.head(3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Génére des grosse erreurs (modifier le temps pris en compte par 3 courbes journalieres (min/moyenne/max))\n'''import plotly.express as px\n\nfig = px.line(data, x='Timestamp', y='Weighted_Price')\nfig.show()\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Prétraitement: remplacement des NaN par des zéros et des données suivantes.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# On remplace les nan par la valeur 0 quand il n'y a pas de transaction de bitcoin\ndata['Volume_(BTC)'].fillna(value=0, inplace=True)\ndata['Volume_(Currency)'].fillna(value=0, inplace=True)\ndata['Weighted_Price'].fillna(value=0, inplace=True)\n\n# on attribue des valeurs aux données OHLC qui sont des données continues\n# on remplace les valeurs manquantes avec la suivante\ndata['Open'].fillna(method='backfill', inplace=True)\ndata['High'].fillna(method='backfill', inplace=True)\ndata['Low'].fillna(method='backfill', inplace=True)\ndata['Close'].fillna(method='backfill', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# conversion timestamp\ndata.Timestamp = pd.to_datetime(data.Timestamp, unit='s')\n\n# conversion jours\ndata.index = data.Timestamp\ndata = data.resample('D').mean()\n\n#conversion mois\ndata_month = data.resample('M').mean()\n\n#conversion année\ndata_year = data.resample('A-DEC').mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# intervalle de temps concerné df\ndata.index.min(), data.index.max()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualisation des variation des prix du bitcoin en fonction de la date ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#variation du prix du bitcoin (1er df)\nfig = plt.figure(figsize=(20,5))\n#variation quotidienne\nplt.subplot(131)\nplt.plot(data.Weighted_Price, '-', label='Quotidien')\nplt.legend()\n#variation mensuelle\nplt.subplot(132)\nplt.plot(data_month.Weighted_Price, '-', label='Mensuel')\nplt.legend()\n#variation annuelle\nplt.subplot(133)\nplt.plot(data_year.Weighted_Price, '-', label='Annuel')\nplt.legend()\nplt.suptitle('Variation des prix du bitcoin')\n# plt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# variation quotidienne du prix du bitcoin pour le 1er df\nfig = plt.figure(figsize=(20,5))\nplt.plot(data.Weighted_Price, '-', label='Quotidien')\nplt.legend()\nplt.suptitle('Variation quotidienne des prix du bitcoin')\nplt.grid(linestyle='dotted')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,15))\ndata.High.plot(kind='line',color='g',label='high',linewidth=1,alpha=0.5,grid=True,linestyle=':')\ndata.Low.plot(color='r',label='Low',linewidth=1,alpha=0.5,linestyle='-.',grid=True)\nplt.legend('upper right')\nplt.suptitle('Bitcoin')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Interprétation graphique de la valeur du bitcoin: \n- Stable entre 2011 et 2017;\n- Forte augmentation durant l'année 2017 jusqu'a atteindre sa valeur maximale fin 2017 (pres de 20000 dollars/unité);\n- Forte chute début 2018, puis stagnation 7500 dollars/unité dans le courant d'année et nouvelle chute fin d'année;\n- Hausse début 2019 et depuis mai \"stabilisation\" ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Un bref historique du bitcoin\n- 2008, le  domaine bitcoin.org a été enregistré.\n- novembre 2010, le capital social de Bitcoin atteint 1 million dollars. Son taux de change: 0,50 USD par BTC.\n- juin 2011, taux 10 USD/BTC. \n- mars 2013, taux 32 USD/BTC.\n- avril 2013, taux 100 USD/BTC.\n- février 2015, taux 260 USD/BTC.\n- janvier 2017, franchit taux 1000 USD/BTC\n- juin 2017, taux dépasse 3000 USD/BTC.\n- decembre 2017, taux 10000 USD/BTC.\n- fin décembre 2017, Bitcoin atteint un niveau record, mais n'atteint pas 20 000 USD.\n- 28 décembre 2017, le taux du bitcoin chute apres une aznnonce de la Corée du Sud du controle du prix \n- novembre 2018, taux 6300 USD/BT","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Corrélation entre les variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax=plt.subplots(figsize=(10,10))\nsns.heatmap(data_corr.corr(),annot=True,linewidths=.5,fmt='.1f',ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Décomposition STL (tendence/saisonnalité/résidu) et visualisation ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# meilleure visualisation de decomposition STL\nplt.style.use('seaborn-poster')\n\n#plt.figure(figsize=(20,15))\nsm.tsa.seasonal_decompose(data_month.Weighted_Price).plot()\nplt.title('decomposition saison du df')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Interprétation de la décomposition:\non constate effectivement beaucoup de bruit dans l'annalyse saisonnière lors des periodes de forte variatoin de prix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# test de dickey fuller\nprint(\"Dickey–Fuller test: p=%f\" % sm.tsa.stattools.adfuller(data_month.Weighted_Price)[1])\n# Transformtion Box-Cox \ndata_month['Weighted_Price_box'], lmbda = stats.boxcox(data_month.Weighted_Price)\nprint(\"Dickey–Fuller test: p=%f\" % sm.tsa.stattools.adfuller(data_month.Weighted_Price)[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Les séries temporelles ont plusieurs caractéristiques clés telles que la tendance, la saisonnalité et le bruit.La prévision est le processus de prédiction de l'avenir, basé sur les données passées et présentes.\n\nDans ce notebook, nous tentons d'effectuer une analyse de séries temporelles sur les données historiques du prix du Bitcoin. On voit, que les prix du Bitcoin étaient assez volatils et incohérents avec le temps. Il est très difficile d'effectuer une analyse de séries chronologiques sur de telles données volatiles. Mais ici, on essaye d'explorer différents modèles de prévision de séries temporelles.\n\n- Prévision de séries chronologiques avec XGBoost\n- Prévision de séries chronologiques avec ARIMA\n- Prévision de séries chronologiques avec Facebook Prophet\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Modèles prédictifs","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# XGBoost\nXGBoost est une implémentation d'arbres de décision à gradient amélioré conçus pour sa vitesse et ses performances. On regarde dans quelle mesure XGBoost fonctionne pour prédire les valeurs de cette série temporelle","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# fonction definition recherche croisée\ndef my_xgb(data, target, params):\n    \n    # crée X & y\n    X = data.drop(target, axis=1)\n    y = data[target]\n    \n    # mise a l'échelle X\n    scaler = StandardScaler()\n    scaler.fit(X)\n    X_scaled = scaler.transform(X)\n    \n    # XGBoost classifier \n    xgb_clf = xgb.XGBClassifier()\n    \n    # recherche grille \n    kf = KFold(n_splits=10, random_state=42, shuffle=True)\n    gridsearch = GridSearchCV(xgb_clf, param_grid=params, scoring=\"accuracy\", cv=kf, return_train_score=True)\n    gridsearch.fit(X_scaled, y)\n    \n    # Return the gridsearch results plus the scaler\n    return gridsearch, scaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom fbprophet import Prophet\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.read_csv('../input/bitcoin-historical-data/coinbaseUSD_1-min_data_2014-12-01_to_2019-01-09.csv', parse_dates=[0], date_parser=dateparse)\ndf2 = pd.read_csv('../input/bitcoin-historical-data/bitstampUSD_1-min_data_2012-01-01_to_2020-04-22.csv', parse_dates=[0], date_parser=dateparse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"frames=[df1, df2]\ndata=pd.concat(frames).drop_duplicates().reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#regle Timestamp en fonction des heures\ndata['Timestamp'] = data['Timestamp'].dt.tz_localize(None)\ndata = data.groupby([pd.Grouper(key='Timestamp', freq='H')]).first().reset_index()\ndata = data.set_index('Timestamp')\ndata = data[['Weighted_Price']]\ndata['Weighted_Price'].fillna(method='backfill', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# graphe de variation des prix train/test sets\nplt.style.use('fivethirtyeight')\n_ = data.plot(style='', figsize=(15,5), title='Prix du bitcoin(donnés des heure)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Selection de date limite train/test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#detemination de la date limite train/test set suivant le ratio 70/30\nprint(data.shape)\ndata.head(51000)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On fixe le 25 octobre 2017 comme date de séparation cette date représentant le sueil du ratio 70/30. Et on introduit les données de test et d'entrainement","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# selection de la date de séparation des train/test sets\nsplit_date = '25-Oct-2017'\ndata_train = data.loc[data.index <= split_date].copy()\ndata_test = data.loc[data.index > split_date].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# graphe de variation des prix train/test sets\n_ = data_test.rename(columns={'Weighted_Price': 'Test Set'}).join(data_train.rename(columns={'Weighted_Price': 'Training Set'}), how='outer').plot(figsize=(15,5), title='Variation du prix du bitcoin(donnés des heure)', style='')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On peut douter de la qualité de cette selection de date, tant elle n'est pas représentative de la tendance entre 2018 et 2020. La prédiction qui en aurait découlé n'aurait fait que croitre. <br>\nIl s'agit de choisir un date plus cohérente, deux intervalles pourraeint convenir, celui entre aout et novembre 2018 et un autre vers mi 2019.\nOn choisit une date dans l'un de ces deux intervalles (je choisis le 31 octobre 2018 -date des 10 ans du bitcoin-)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Autre date de test 31/10/2018 - 10 ans du Bitcoin","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# selection de la date de séparation des train/test sets\nsplit_date = '31-Oct-2018'\ndata_train = data.loc[data.index <= split_date].copy()\ndata_test = data.loc[data.index > split_date].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# graphe de variation des prix train/test sets\n_ = data_test.rename(columns={'Weighted_Price': 'Test Set'}).join(data_train.rename(columns={'Weighted_Price': 'Training Set'}), how='outer').plot(figsize=(15,5), title='Variation du prix du bitcoin(donnés des heure)', style='')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creation fonction timeseries a partir dun index de date\n\ndef create_features(df, label=None):\n    df['date'] = df.index\n    df['hour'] = df['date'].dt.hour\n    df['dayofweek'] = df['date'].dt.dayofweek\n    df['quarter'] = df['date'].dt.quarter\n    df['month'] = df['date'].dt.month\n    df['year'] = df['date'].dt.year\n    df['dayofyear'] = df['date'].dt.dayofyear\n    df['dayofmonth'] = df['date'].dt.day\n    df['weekofyear'] = df['date'].dt.weekofyear\n    \n    X = df[['hour','dayofweek','quarter','month','year',\n           'dayofyear','dayofmonth','weekofyear']]\n    if label:\n        y = df[label]\n        return X, y\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# introduction de la configuration du XGBoost\nX_train, y_train = create_features(data_train, label='Weighted_Price')\nX_test, y_test = create_features(data_test, label='Weighted_Price')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prediction XGBoost\n\nimport xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom xgboost import XGBClassifier\n\n\nparams = {\n        'min_child_weight': [1, 5, 10],\n        'gamma': [0.5, 1, 1.5, 2, 5],\n        'subsample': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5]\n        }","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"grid = GridSearchCV(estimator=xgb, param_grid=params, scoring='roc_auc', n_jobs=4, cv=skf.split(X,Y), verbose=3 )","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model =  xgb.XGBRegressor(objective ='reg:squarederror',min_child_weight=10, booster='gbtree', colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 100)\n\nmodel.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], early_stopping_rounds=50, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# jointure des données test/train\ndata_test['Weighted_Price_Prediction'] = model.predict(X_test)\ndata_all = pd.concat([data_test, data_train], sort=False)\ndata_all","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#introduction données finales pour comparer les modeles\nfinal_data = data_all\nfinal_data = final_data.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Comparaison entre modeles\nfinal_data = pd.merge(final_data, data_all, sort=False)\nfinal_data = final_data.rename(columns={'Weighted_Price_Prediction': 'xgboost'})\nfinal_data = final_data[['Timestamp','Weighted_Price','xgboost']]\nfinal_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualisation prédiction/réelles\n_ = data_all[['Weighted_Price','Weighted_Price_Prediction']].plot(figsize=(15, 5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Autre date: 04/07/2019 ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# selection de la date de séparation des train/test sets\nsplit_date = '04-Jul-2019'\ndata_train = data.loc[data.index <= split_date].copy()\ndata_test = data.loc[data.index > split_date].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# graphe de variation des prix train/test sets\n_ = data_test.rename(columns={'Weighted_Price': 'Test Set'}).join(data_train.rename(columns={'Weighted_Price': 'Training Set'}), how='outer').plot(figsize=(15,5), title='Variation du prix du bitcoin(donnés des heure)', style='')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# introduction de la configuration du XGBoost\nX_train, y_train = create_features(data_train, label='Weighted_Price')\nX_test, y_test = create_features(data_test, label='Weighted_Price')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prediction XGBoost\n\nimport xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\n\nmodel =  xgb.XGBRegressor(objective ='reg:squarederror',min_child_weight=10, booster='gbtree', colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 100)\n\nmodel.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], early_stopping_rounds=50, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# jointure des données test/train\ndata_test['Weighted_Price_Prediction'] = model.predict(X_test)\ndata_all = pd.concat([data_test, data_train], sort=False)\ndata_all","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualisation prédiction/réelles\n_ = data_all[['Weighted_Price','Weighted_Price_Prediction']].plot(figsize=(15, 5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Arima","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"On a clairement vu que la série temporelle n'estt pas stationnaire.\nIl faut essayer de la rendre stationnaire c'est a dire que la moyenne de la variance reste constante en fonction du temps. On utilise un test de Dickey-Fuller pour savoir la stationarité ou non.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Guide pour les séries temporelles: https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Nous utilisons le modèle ARIMA pour analyser d'abord nos séries chronologiques. Nous savons que pour cela, nous avons besoin que notre série soit stationnaire. Nous utilisons donc les techniques décrites ci-dessous pour réaliser si notre série est stationnaire:\n-  décomposition saisonnière pour visualiser les composantes saisonnières et tendancielles des séries chronologiques. Nous visons à obtenir un résidu indépendant de tendances et de saisonnalité.\n- test de Dicky Fuller considère l'hypothèse nulle que la série chronologique considérée n'est pas stationnaire. Si la valeur de p est suffisamment faible (inférieure à 0,05) lors du test d'hypothèse, alors seulement nous rejetons l'hypothèse nulle et on peut considérons la série comme stationnaire","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller\nfrom scipy.stats import boxcox\n\n### test Dickey-Fuller\ndef DFTest(series):\n    testdf = adfuller(series)\n    print(\"DF test p-value : %.16f\" %testdf[1] )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\nimport statsmodels.api as sm\nimport warnings\nfrom itertools import product","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.read_csv('../input/bitcoin-historical-data/coinbaseUSD_1-min_data_2014-12-01_to_2019-01-09.csv', parse_dates=[0], date_parser=dateparse)\ndf2 = pd.read_csv('../input/bitcoin-historical-data/bitstampUSD_1-min_data_2012-01-01_to_2020-04-22.csv', parse_dates=[0], date_parser=dateparse)\nframes=[df1, df2]\ndata=pd.concat(frames).drop_duplicates().reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Open'].fillna(method='backfill', inplace=True)\ndata['High'].fillna(method='backfill', inplace=True)\ndata['Low'].fillna(method='backfill', inplace=True)\ndata['Close'].fillna(method='backfill', inplace=True)\ndata['Weighted_Price'].fillna(method='backfill', inplace=True)\ndata['Volume_(BTC)'].fillna(method='backfill', inplace=True)\ndata['Volume_(Currency)'].fillna(method='backfill', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On s'interesse a la saisonalité donc on utilisera les données mensuelles","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Timestamp'] = data['Timestamp'].dt.tz_localize(None)\ndata = data.groupby([pd.Grouper(key='Timestamp', freq='M')]).first().reset_index()\ndata = data.set_index('Timestamp')\ndata['Weighted_Price'].fillna(method='backfill', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=[20,8])\nplt.title('Variation prix bicoin par mois')\nplt.plot(data.Weighted_Price, '-', label='By Months')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.figure(figsize=(20,15))\nsm.tsa.seasonal_decompose(data_month.Weighted_Price).plot()\nplt.title('decomposition saison du df')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Test Dickey–Fuller : p=%f\" % sm.tsa.stattools.adfuller(data.Weighted_Price)[1])\nDFTest(data.Weighted_Price)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom matplotlib import pyplot\npyplot.figure(figsize=(20,8))\npyplot.subplot(211)\nplot_acf(data.Weighted_Price, ax=pyplot.gca(),lags=40)\npyplot.subplot(212)\nplot_pacf(data.Weighted_Price, ax=pyplot.gca(), lags=50)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### transformation logarithmique","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"prices = data.Weighted_Price\nprices_log = np.log(prices)\nDFTest(prices_log)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On obtient une valeur de p=0.3 avec le Test de DF donc on ne peut pas considérer la série comme stationnaire","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"prices_log_r = prices_log - prices_log.shift(12)\nprices_log_r.dropna(inplace = True)\n\nDFTest(prices_log_r)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Transformation de Box-Cox","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"prices_box_cox_, lambda_ = boxcox(prices)\nprices_box_cox = pd.Series(data = prices_box_cox_, index = data.index) \nDFTest(prices_box_cox)\nprint('lambda value:', lambda_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prices_box_cox_r = prices_box_cox - prices_box_cox.shift(12)\nprices_box_cox_r.dropna(inplace = True)\n\nDFTest(prices_box_cox_r)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Maintenant qu'on a obtenu des résultats satisfaisants au test de Dickey-Fuller, tracons les graphes ACF/PACF des dfonctions transformées afin d'avoir une idée de comment âramétrer Arima","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Maintenant qu'on a obtenue la stationnarirté, il faut faire une selection de modele\n\nFonction d'autocorrélation - ACF: Le graphique résume la corrélation d'une observation avec des valeurs de décalage. L'axe des x montre le décalage et l'axe des y montre le coefficient de corrélation entre -1 et 1 pour la corrélation négative et positive\nFonction d'autocorrélation partielle - PACF: Le graphique résume les corrélations d'une observation avec des valeurs de décalage qui ne sont pas prises en compte par les observations antérieures. On peut obtenir une image de base de l'intervalle de paramètres, puis décider quels sont les meilleurs p, q, d pour ARIMA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import acf, pacf\n\nplt.figure(figsize = (14,7)) \na = acf(prices_log_r)\np = pacf(prices_log_r)\n\nplt.subplot(221)\nsns.lineplot(data = a)\nplt.axhline(y=0, linestyle='--', color='gray')\nplt.grid(linestyle='dotted')\nplt.title('Courbe ACF')\n\nplt.subplot(222)\nsns.lineplot(data = p)\nplt.axhline(y=0, linestyle='--', color='gray')\nplt.grid(linestyle='dotted')\nplt.title('Courbe PACF')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### interprétation (doc: https://people.duke.edu/~rnau/411arim.htm)\nNous déduisons du graphique que L'ACF et le PACF se rapprochent de zéro tandis que le décalage approche 1.<br>\nEssai différentes valeurs de p et q <br>\nD = 1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.arima_model import ARIMA\n\na = [[1,2,3], [1],[1,2,3]]\nparams = list(product(*a))\n\nresults = []   \nmin_aic = float('inf')\nbest_param = []\n\n# checking different set of params for best fit\nfor param in params:\n    try:\n        model = ARIMA(prices_log, order = param).fit(disp = -1)\n    except LinAlgError:\n        print('Rejected Parameters:', param)\n        continue\n    except ValueError:\n        print('Rejected Parameters:', param)\n        continue\n    if(min_aic > model.aic):\n        min_aic = model.aic\n        best_param = param\n        best_model = model\n        \n    results.append([param, model.aic])\n\nprint(best_param,min_aic)\nprint(results)\n\nprint(best_model.fittedvalues)\n\nplt.figure(figsize=(16,8))\nsns.lineplot(data = prices_log_r, color = 'blue')\nsns.lineplot(data = best_model.fittedvalues, color = 'red')\nplt.grid(linestyle='dotted')\nplt.title('Valeurs du meilleur modele (rouge) VS. valeur prix apres trandformation log')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fitted_values = best_model.fittedvalues\nfitted_values = fitted_values.cumsum()\n\nfitted_values = fitted_values + prices_log[0]\n\nfinal_values = np.exp(fitted_values)\n\nd = {'prices' : prices, 'prices_log' : prices_log, 'price_log_r' : prices_log_r, 'fitted_values' : fitted_values, 'final_values' : final_values}\nsummaryDF = pd.DataFrame(data = d)\n\nplt.figure(figsize=(16,8))\nsns.lineplot(data = summaryDF['prices'], color = 'blue', label='réelle')\nsns.lineplot(data = summaryDF['final_values'], color = 'red', label='predite')\nplt.grid(linestyle='dotted')\nplt.title('valeurs prédites(rouge) / valeurs réelles')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialisation parametres\nQs = range(0, 2)\nqs = range(0, 3)\nPs = range(0, 3)\nps = range(0, 3)\nD=1\nd=1\nparameters = product(ps, qs, Ps, Qs)\nparameters_list = list(parameters)\nlen(parameters_list)\n\n# Selection Modele\nresults = []\nbest_aic = float(\"inf\")\nwarnings.filterwarnings('ignore')\nfor param in parameters_list:\n    try:\n        model=sm.tsa.statespace.SARIMAX(data.Weighted_Price, order=(param[0], d, param[1]), \n                                        seasonal_order=(param[2], D, param[3], 12),enforce_stationarity=False,\n                                            enforce_invertibility=False).fit(disp=-1)\n    except ValueError:\n        #print('wrong parameters:', param)\n        continue\n    aic = model.aic\n    if aic < best_aic:\n        best_model = model\n        best_aic = aic\n        best_param = param\n    results.append([param, model.aic])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Meilleurs modeles\nresult_table = pd.DataFrame(results)\nresult_table.columns = ['parameters', 'aic']\nprint(result_table.sort_values(by = 'aic', ascending=True).head())\nprint(best_model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Test Dickey–Fuller : p=%f\" % sm.tsa.stattools.adfuller(best_model.resid)[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#figure résidus meilleur modele\nfig = plt.figure(figsize=(20,8))\nbest_model.resid.plot()\nfig.suptitle('Residus meilleur modele')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#graphe comparatif précdiction valeurs réelles\ndf_month2 = data[['Weighted_Price']]\nfuture = pd.DataFrame()\ndf_month2 = pd.concat([df_month2, future])\ndf_month2['forecast'] = best_model.predict(start=0, end=200)\nplt.figure(figsize=(15,7))\ndf_month2.Weighted_Price.plot()\ndf_month2.forecast.plot(color='r', ls='--', label='Predicted Weighted_Price')\nplt.legend()\nplt.title('Comparatif Prediction/Données réelles des variation du bitcoin ')\nplt.ylabel('$')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prophet","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Prophet est un modele prédictif développé par Facebook de time seies. Il est basé sur un modèle additif où les tendances non linéaires sont adaptées aux saisonnalité quotidiennes, annuelles et hebdomadaires, ainsi que les effets des vacances.<br>\nLe fonctionnement de Prophet est s'améliore des séries temporelles qui ont de forts effets saisonniers et plusieurs saisons de données historiques. Prophet résiste aux données manquantes et aux changements de tendance, et gère généralement bien les valeurs aberrantes. <br>\nDoc Prophet: [Fonctionnement et documentation Prophet](https://facebook.github.io/prophet/)\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.read_csv('../input/bitcoin-historical-data/coinbaseUSD_1-min_data_2014-12-01_to_2019-01-09.csv', parse_dates=[0], date_parser=dateparse)\ndf2 = pd.read_csv('../input/bitcoin-historical-data/bitstampUSD_1-min_data_2012-01-01_to_2020-04-22.csv', parse_dates=[0], date_parser=dateparse)\nframes=[df1, df2]\ndata=pd.concat(frames).drop_duplicates().reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#regle Timestamp en fonction des heures\ndata['Timestamp'] = data['Timestamp'].dt.tz_localize(None)\ndata = data.groupby([pd.Grouper(key='Timestamp', freq='H')]).first().reset_index()\ndata = data.set_index('Timestamp')\ndata = data[['Weighted_Price']]\ndata['Weighted_Price'].fillna(method='backfill', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = data.plot(style='', figsize=(15,5), title='Prix du bitcoin(donnés des heure)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Split date","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"split_date = '04-Jul-2018'\ndata_train = data.loc[data.index <= split_date].copy()\ndata_test = data.loc[data.index > split_date].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# graphe de variation des prix train/test sets\n_ = data_test.rename(columns={'Weighted_Price': 'Test Set'}).join(data_train.rename(columns={'Weighted_Price': 'Training Set'}), how='outer').plot(figsize=(15,5), title='Variation du prix du bitcoin(donnés des heure)', style='')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Configuration Prophet:\nOn doit nécéssairement avoir un dataframe composé de deux colonnes 'ds' et 'y'.<br>\nds correspondant au datestamp et y devant correspondre a une valeur numérique et représente la variable qu'on veut prédire","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#import de la librairie Prophet\nfrom fbprophet import Prophet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# configuration du modele d'entrainement\n# On renomme les colonnes selon les normes de Prophet\ndata_train = data_train.reset_index().rename(columns={'Timestamp':'ds', 'Weighted_Price':'y'})\n\nm = Prophet()\nm.fit(data_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prediction sur l'ensemble training set\ndata_test_fcst = m.predict(df=data_test.reset_index().rename(columns={'Timestamp':'ds'}))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# graphe de la prediction \nf, ax = plt.subplots()\nf.set_figheight(12)\nf.set_figwidth(15)\nfig = m.plot(data_test_fcst, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# composantes temporelles\nfig = m.plot_components(data_test_fcst)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# graphe prédiction/réelles\nf, ax = plt.subplots(1)\nf.set_figheight(12)\nf.set_figwidth(15)\nax.scatter(data_test.index, data_test['Weighted_Price'], color='r')\nfig = m.plot(data_test_fcst, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Remarques:","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Manifestement sur l'ensemble des modeles qu'on a introduit, on n'aobtient pas de résultat tres significatifs.<br>\nPour obtenir de meilleurs résultats on peut imaginer deux hypotheses: \n- intervalle de données plus réduit\n- prediction sur une courte période (10 jours/1 mois)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_date='01-Apr-2018'\nsplit_date = '01-Feb-2020'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGBoost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_boost=data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#regle Timestamp en fonction des heures\ndata_boost['Timestamp'] = data_boost['Timestamp'].dt.tz_localize(None)\ndata_boost = data_boost.groupby([pd.Grouper(key='Timestamp', freq='H')]).first().reset_index()\ndata_boost = data_boost.set_index('Timestamp')\ndata_boost = data_boost[['Weighted_Price']]\ndata_boost['Weighted_Price'].fillna(method='backfill', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = data_boost.loc[(data_boost.index <= split_date) & (data_boost.index > start_date)].copy()\ndata_test = data_boost.loc[(data_boost.index > split_date)].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# introduction de la configuration du XGBoost\nX_train, y_train = create_features(data_train, label='Weighted_Price')\nX_test, y_test = create_features(data_test, label='Weighted_Price')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model =  xgb.XGBRegressor(objective ='reg:squarederror',min_child_weight=10, booster='gbtree', colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 100)\n\nmodel.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], early_stopping_rounds=50, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# jointure des données test/train\ndata_test['Weighted_Price_Prediction'] = model.predict(X_test)\ndata_all = pd.concat([data_test, data_train], sort=False)\ndata_all","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Comparaison entre modeles\nfinal_data = pd.merge(final_data, data_all, sort=False)\nfinal_data = final_data.rename(columns={'Weighted_Price_Prediction': 'xgboost'})\nfinal_data = final_data[['Timestamp','Weighted_Price','xgboost']]\nfinal_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualisation prédiction/réelles\n_ = data_all[['Weighted_Price','Weighted_Price_Prediction']].plot(figsize=(15, 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ARIMA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.read_csv('../input/bitcoin-historical-data/coinbaseUSD_1-min_data_2014-12-01_to_2019-01-09.csv', parse_dates=[0], date_parser=dateparse)\ndf2 = pd.read_csv('../input/bitcoin-historical-data/bitstampUSD_1-min_data_2012-01-01_to_2020-04-22.csv', parse_dates=[0], date_parser=dateparse)\nframes=[df1, df2]\ndata=pd.concat(frames).drop_duplicates().reset_index(drop=True)\nraw_data=data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Open'].fillna(method='backfill', inplace=True)\ndata['High'].fillna(method='backfill', inplace=True)\ndata['Low'].fillna(method='backfill', inplace=True)\ndata['Close'].fillna(method='backfill', inplace=True)\ndata['Weighted_Price'].fillna(method='backfill', inplace=True)\ndata['Volume_(BTC)'].fillna(method='backfill', inplace=True)\ndata['Volume_(Currency)'].fillna(method='backfill', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Timestamp'] = data['Timestamp'].dt.tz_localize(None)\ndata = data.groupby([pd.Grouper(key='Timestamp', freq='M')]).first().reset_index()\ndata = data.set_index('Timestamp')\ndata['Weighted_Price'].fillna(method='backfill', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=data.loc[data.index > start_date]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=[20,8])\nplt.title('Variation prix bicoin par mois')\nplt.plot(data.Weighted_Price, '-', label='By Months')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.figure(figsize=(20,15))\nsm.tsa.seasonal_decompose(data_month.Weighted_Price).plot()\nplt.title('decomposition saison du df')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Test Dickey–Fuller : p=%f\" % sm.tsa.stattools.adfuller(data.Weighted_Price)[1])\nDFTest(data.Weighted_Price)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prices = data.Weighted_Price\nprices_log = np.log(prices)\nDFTest(prices_log)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prices_box_cox_, lambda_ = boxcox(prices)\nprices_box_cox = pd.Series(data = prices_box_cox_, index = data.index) \nDFTest(prices_box_cox)\nprint('lambda value:', lambda_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prices_box_cox_r = prices_box_cox - prices_box_cox.shift(12)\nprices_box_cox_r.dropna(inplace = True)\n\nDFTest(prices_box_cox_r)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = [[1,2,3], [1],[1,2,3]]\nparams = list(product(*a))\n\nresults = []   \nmin_aic = float('inf')\nbest_param = []\n\n# checking different set of params for best fit\nfor param in params:\n    try:\n        model = ARIMA(prices_log, order = param).fit(disp = -1)\n    except LinAlgError:\n        print('Rejected Parameters:', param)\n        continue\n    except ValueError:\n        print('Rejected Parameters:', param)\n        continue\n    if(min_aic > model.aic):\n        min_aic = model.aic\n        best_param = param\n        best_model = model\n        \n    results.append([param, model.aic])\n\nprint(best_param,min_aic)\nprint(results)\n\nprint(best_model.fittedvalues)\n\nplt.figure(figsize=(16,8))\nsns.lineplot(data = prices_log_r, color = 'blue')\nsns.lineplot(data = best_model.fittedvalues, color = 'red')\nplt.grid(linestyle='dotted')\nplt.title('Valeurs du meilleur modele (rouge) VS. valeur prix apres trandformation log')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fitted_values = best_model.fittedvalues\nfitted_values = fitted_values.cumsum()\n\nfitted_values = fitted_values + prices_log[0]\n\nfinal_values = np.exp(fitted_values)\n\nd = {'prices' : prices, 'prices_log' : prices_log, 'price_log_r' : prices_log_r, 'fitted_values' : fitted_values, 'final_values' : final_values}\nsummaryDF = pd.DataFrame(data = d)\n\nplt.figure(figsize=(16,8))\nsns.lineplot(data = summaryDF['prices'], color = 'blue', label='réelle')\nsns.lineplot(data = summaryDF['final_values'], color = 'red', label='predite')\nplt.grid(linestyle='dotted')\nplt.title('valeurs prédites(rouge) / valeurs réelles')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialisation parametres\nQs = range(0, 2)\nqs = range(0, 3)\nPs = range(0, 3)\nps = range(0, 3)\nD=1\nd=1\nparameters = product(ps, qs, Ps, Qs)\nparameters_list = list(parameters)\nlen(parameters_list)\n\n# Selection Modele\nresults = []\nbest_aic = float(\"inf\")\nwarnings.filterwarnings('ignore')\nfor param in parameters_list:\n    try:\n        model=sm.tsa.statespace.SARIMAX(data.Weighted_Price, order=(param[0], d, param[1]), \n                                        seasonal_order=(param[2], D, param[3], 12),enforce_stationarity=False,\n                                            enforce_invertibility=False).fit(disp=-1)\n    except ValueError:\n        #print('wrong parameters:', param)\n        continue\n    aic = model.aic\n    if aic < best_aic:\n        best_model = model\n        best_aic = aic\n        best_param = param\n    results.append([param, model.aic])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Meilleurs modeles\nresult_table = pd.DataFrame(results)\nresult_table.columns = ['parameters', 'aic']\nprint(result_table.sort_values(by = 'aic', ascending=True).head())\nprint(best_model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Test Dickey–Fuller : p=%f\" % sm.tsa.stattools.adfuller(best_model.resid)[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#figure résidus meilleur modele\nfig = plt.figure(figsize=(20,8))\nbest_model.resid.plot()\nfig.suptitle('Residus meilleur modele')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#graphe comparatif précdiction valeurs réelles\ndf_month2 = data[['Weighted_Price']]\nfuture = pd.DataFrame()\ndf_month2 = pd.concat([df_month2, future])\ndf_month2['forecast'] = best_model.predict(start=0, end=200)\nplt.figure(figsize=(15,7))\ndf_month2.Weighted_Price.plot()\ndf_month2.forecast.plot(color='r', ls='--', label='Predicted Weighted_Price')\nplt.legend()\nplt.title('Comparatif Prediction/Données réelles des variation du bitcoin ')\nplt.ylabel('$')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prophet","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Au vu des résultats des prédictions précédentes qui ne sont pas d'une précision suffisante, on choisit de ne considérer que les valeurs a partir de 2018, et on observera les résultats des valeurs prédites du prix du Bitcoin","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.read_csv('../input/bitcoin-historical-data/coinbaseUSD_1-min_data_2014-12-01_to_2019-01-09.csv', parse_dates=[0], date_parser=dateparse)\ndf2 = pd.read_csv('../input/bitcoin-historical-data/bitstampUSD_1-min_data_2012-01-01_to_2020-04-22.csv', parse_dates=[0], date_parser=dateparse)\nframes=[df1, df2]\ndata=pd.concat(frames).drop_duplicates().reset_index(drop=True)\nraw_data=data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#regle Timestamp en fonction des heures\ndata['Timestamp'] = data['Timestamp'].dt.tz_localize(None)\ndata = data.groupby([pd.Grouper(key='Timestamp', freq='H')]).first().reset_index()\ndata = data.set_index('Timestamp')\ndata = data[['Weighted_Price']]\ndata['Weighted_Price'].fillna(method='backfill', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=data.loc[data.index > start_date]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = data.plot(style='', figsize=(15,5), title='Prix du bitcoin(donnés des heure)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndata_train = data.loc[(data.index <= split_date)].copy()\ndata_test = data.loc[data.index > split_date].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# graphe de variation des prix train/test sets\n_ = data_test.rename(columns={'Weighted_Price': 'Test Set'}).join(data_train.rename(columns={'Weighted_Price': 'Training Set'}), how='outer').plot(figsize=(15,5), title='Variation du prix du bitcoin(donnés des heure)', style='')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# configuration du modele d'entrainement\n# On renomme les colonnes selon les normes de Prophet\ndata_train = data_train.reset_index().rename(columns={'Timestamp':'ds', 'Weighted_Price':'y'})\n\nm = Prophet()\nm.fit(data_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prediction sur l'ensemble training set\ndata_test_fcst = m.predict(df=data_test.reset_index().rename(columns={'Timestamp':'ds'}))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# graphe de la prediction \nf, ax = plt.subplots()\nf.set_figheight(8)\nf.set_figwidth(15)\nfig = m.plot(data_test_fcst, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# composantes temporelles\nfig = m.plot_components(data_test_fcst)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# graphe prédiction/réelles\nf, ax = plt.subplots(1)\nf.set_figheight(8)\nf.set_figwidth(15)\nax.scatter(data_test.index, data_test['Weighted_Price'], color='r')\nfig = m.plot(data_test_fcst, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" # Deuxieme modele ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tests","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_date='01-Apr-2019'\nsplit_date = '01-Apr-2020'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.read_csv('../input/bitcoin-historical-data/coinbaseUSD_1-min_data_2014-12-01_to_2019-01-09.csv', parse_dates=[0], date_parser=dateparse)\ndf2 = pd.read_csv('../input/bitcoin-historical-data/bitstampUSD_1-min_data_2012-01-01_to_2020-04-22.csv', parse_dates=[0], date_parser=dateparse)\nframes=[df1, df2]\ndata=pd.concat(frames).drop_duplicates().reset_index(drop=True)\nraw_data=data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tests\npas assez de RAM !\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# erreur intentionnelle \nx=","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndata_test=raw_data.copy()\ndata_test['Timestamp'] = data_test['Timestamp'].dt.tz_localize(None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test.rename(columns={'Timestamp': 'ds', 'Weighted_Price': 'y'},inplace=True)\ndata_test['ds'] = pd.to_datetime(data_test['ds'])\ndata_test['y']=data_test['y'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\nimport pytz\nimport datetime\n\nx = datetime.datetime.now()\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fit the model \ndf_prophet = Prophet(changepoint_prior_scale=0.15, daily_seasonality=True)\ndf_prophet.fit(data_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fcast_time=365   # 1 year\ndf_forecast = df_prophet.make_future_dataframe(periods= fcast_time, freq='D')\ndf_forecast","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}