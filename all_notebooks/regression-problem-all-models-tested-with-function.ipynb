{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport missingno as msno\nplt.rcParams['figure.figsize']= (12,6)\nplt.style.use('fivethirtyeight')\nsns.set(context=\"notebook\", palette='dark', style=\"whitegrid\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/diamonds/diamonds.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shape of the data\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop Unnamed column\ndf.drop(df.columns[0], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking data types\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking null values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No Null values in the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualizing missing numbers\nmsno.matrix(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"x, y and z minimum values are 0 which doesn't seem realistic. Let's check\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[(df['x']==0) | (df['y']==0) | (df['z']==0)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Only few rows with such scenario, we will drop them"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df[~((df['x']==0) | (df['y']==0) | (df['z']==0))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"confirming that these rows were removed"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[(df['x']==0) | (df['y']==0) | (df['z']==0)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check correlation b/w features\nplt.figure(figsize=(12,6))\nsns.heatmap(df.corr(), annot=True, cmap='viridis', cbar=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check the plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_cols=df.select_dtypes(include=np.number).columns.to_list()\ncategorical_cols=df.select_dtypes(exclude=np.number).columns.to_list()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_cols","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking categorical columns\n"},{"metadata":{},"cell_type":"markdown","source":"**Feature \"CUT\" EDA**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot('cut', data=df, kind='count',aspect=2.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='cut', y='price', kind='box', data=df, aspect=2.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature \"color\" EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot('color', kind='count', data=df, aspect=2.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='color', y='price', data=df, aspect =2.5, kind='box')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Numerical columns EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df[numerical_cols], kind='reg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's create a new column volume\ndf['volume']=df['x']*df['y']*df['z']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['x', 'y', 'z'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply categorical encoding\ndf=pd.get_dummies(df, drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Conver to X & y\nX=df.drop('price', axis=1)\ny=df['price']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now splitting the X & y into train and test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X , y , test_size=0.2, random_state=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\nfrom sklearn.neighbors import KNeighborsRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc=StandardScaler()\nX_train_tx=sc.fit_transform(X_train)\nX_test_tx=sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Let's wrap up the dataset in a tuple so that if required we can create a new feature engineered dataset to run the models again"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_1=(X_train, X_test, y_train, y_test, 'dataset_1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Blank lists for all the details\nmodel_=[]\ncv_score_test=[]\ncv_score_train=[]\nmse_=[]\nmae_=[]\nrmse_=[]\nr2_=[]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_model(model, dataset, modelname):\n    model.fit(dataset[0], dataset[2])\n    accuracies=cross_val_score(estimator=model, X=dataset[0], y=dataset[2], cv=5, verbose=1)\n    y_pred=model.predict(dataset[1])\n    print('')\n    score_1=model.score(dataset[1], dataset[3])\n    print(f'#### {modelname} ####')\n    print(\"score :%.4f\" %score_1)\n    print(accuracies)\n    \n    \n    mse=mean_squared_error(dataset[3], y_pred)\n    mae=mean_absolute_error(dataset[3], y_pred)\n    rmse=mean_squared_error(dataset[3], y_pred)**0.5\n    r2=r2_score(dataset[3], y_pred)\n    \n    \n    print('')\n    print('MSE    : %0.2f ' % mse)\n    print('MAE    : %0.2f ' % mae)\n    print('RMSE   : %0.2f ' % rmse)\n    print('R2     : %0.2f ' % r2)\n    \n    ## appending to the lists\n    \n    model_.append(modelname)\n    cv_score_test.append(score_1)\n    cv_score_train.append(np.mean(accuracies))\n    mse_.append(mse)\n    mae_.append(mae)\n    rmse_.append(rmse)\n    r2_.append(r2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_dict={'LinearRegression': LinearRegression(), 'LassoRegression': Lasso(normalize=True), \n             'AdaBoostRegressor': AdaBoostRegressor(n_estimators=1000),\n            'RidgeRegression': Ridge(normalize=True),\n            'GradientBoostingRegressor': GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=1, verbose=1),\n           'RandomForestRegressor': RandomForestRegressor(), \n           'KNeighborsRegressor': KNeighborsRegressor()\n           }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run_model(model_dict['LinearRegression'], dataset_1, \"LinearRegression\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for models in model_dict:\n    run_model(model_dict[models], dataset_1, models)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**RandomForest has 98% accuracy. Model is giving excellent results**"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_data=pd.DataFrame(zip(model_, cv_score_test, cv_score_train, mse_, mae_, rmse_, r2_), columns=['Model', 'CV Test score', 'CV Train score (mean)', '%%SVGean Squared error', 'Mean Absolute error', 'Root Mean Squared error', 'R2 Score'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_data","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}