{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout   # Incase you want to use dropout, but I don't use it because overfitting is pretty hard\nfrom keras import optimizers\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-20T04:29:33.088256Z","iopub.execute_input":"2021-07-20T04:29:33.088689Z","iopub.status.idle":"2021-07-20T04:29:34.207088Z","shell.execute_reply.started":"2021-07-20T04:29:33.088654Z","shell.execute_reply":"2021-07-20T04:29:34.205633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(0)\n\ndata = pd.read_csv(\"/kaggle/input/heart-disease-uci/heart.csv\")\ndata.sample(n=5)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-07-20T04:29:34.209858Z","iopub.execute_input":"2021-07-20T04:29:34.210241Z","iopub.status.idle":"2021-07-20T04:29:34.257153Z","shell.execute_reply.started":"2021-07-20T04:29:34.210204Z","shell.execute_reply":"2021-07-20T04:29:34.255435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-07-20T04:29:34.258872Z","iopub.execute_input":"2021-07-20T04:29:34.25924Z","iopub.status.idle":"2021-07-20T04:29:34.269685Z","shell.execute_reply.started":"2021-07-20T04:29:34.259204Z","shell.execute_reply":"2021-07-20T04:29:34.268321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T04:29:34.271512Z","iopub.execute_input":"2021-07-20T04:29:34.272Z","iopub.status.idle":"2021-07-20T04:29:34.294033Z","shell.execute_reply.started":"2021-07-20T04:29:34.271952Z","shell.execute_reply":"2021-07-20T04:29:34.292907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nplt.style.use('ggplot')\nsns.set_style('dark')","metadata":{"execution":{"iopub.status.busy":"2021-07-20T04:29:34.298205Z","iopub.execute_input":"2021-07-20T04:29:34.298583Z","iopub.status.idle":"2021-07-20T04:29:34.427214Z","shell.execute_reply.started":"2021-07-20T04:29:34.298546Z","shell.execute_reply":"2021-07-20T04:29:34.426243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\n\nax = sns.barplot(x=data.thal.value_counts().index, y=data.thal[data.target==1].value_counts().values, color='g', alpha=0.5)\nax2 = sns.barplot(x=data.thal.value_counts().index, y=data.thal[data.target==0].value_counts().values, color='r', alpha=0.5)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T04:29:34.428738Z","iopub.execute_input":"2021-07-20T04:29:34.42918Z","iopub.status.idle":"2021-07-20T04:29:34.688542Z","shell.execute_reply.started":"2021-07-20T04:29:34.429148Z","shell.execute_reply":"2021-07-20T04:29:34.687347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\n\nax = sns.pairplot(data, corner=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T04:29:34.69185Z","iopub.execute_input":"2021-07-20T04:29:34.692351Z","iopub.status.idle":"2021-07-20T04:30:08.797584Z","shell.execute_reply.started":"2021-07-20T04:29:34.692297Z","shell.execute_reply":"2021-07-20T04:30:08.796414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\n\nax = sns.distplot(a=data.oldpeak[data.target==1], bins=15)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T04:30:08.799518Z","iopub.execute_input":"2021-07-20T04:30:08.80025Z","iopub.status.idle":"2021-07-20T04:30:09.162691Z","shell.execute_reply.started":"2021-07-20T04:30:08.800194Z","shell.execute_reply":"2021-07-20T04:30:09.161379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\n\nax = sns.distplot(a=data.oldpeak[data.target==0], bins=15)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T04:30:09.164196Z","iopub.execute_input":"2021-07-20T04:30:09.164545Z","iopub.status.idle":"2021-07-20T04:30:09.49231Z","shell.execute_reply.started":"2021-07-20T04:30:09.164513Z","shell.execute_reply":"2021-07-20T04:30:09.490884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\nax = sns.barplot(x='slope', y='target', data=data)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T04:30:09.494267Z","iopub.execute_input":"2021-07-20T04:30:09.494689Z","iopub.status.idle":"2021-07-20T04:30:09.809013Z","shell.execute_reply.started":"2021-07-20T04:30:09.494654Z","shell.execute_reply":"2021-07-20T04:30:09.807665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\n\nax = sns.barplot(x='ca', y='target', data=data)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T04:30:09.810793Z","iopub.execute_input":"2021-07-20T04:30:09.811147Z","iopub.status.idle":"2021-07-20T04:30:10.769361Z","shell.execute_reply.started":"2021-07-20T04:30:09.811115Z","shell.execute_reply":"2021-07-20T04:30:10.767803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\n\nax = sns.barplot(x='thal', y='target', data=data)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T04:30:10.771105Z","iopub.execute_input":"2021-07-20T04:30:10.771471Z","iopub.status.idle":"2021-07-20T04:30:11.113105Z","shell.execute_reply.started":"2021-07-20T04:30:10.771423Z","shell.execute_reply":"2021-07-20T04:30:11.111659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The below step is highly important to increasing accuracy.\nThis basically creates more features/colummns for algorithms to learn from. This does require a data scientist to look through the data and see the correlations though. ","metadata":{}},{"cell_type":"code","source":"dummy1 = pd.get_dummies(data.cp)\ndummy2 = pd.get_dummies(data.thal)\ndummy3 = pd.get_dummies(data.restecg)\ndummy4 = pd.get_dummies(data.slope)\ndummy5 = pd.get_dummies(data.ca)\nmerge = pd.concat([data,dummy1,dummy2,dummy3,dummy4,dummy5], axis=1)   # This turns the continuous data into binary form, easier for algorithms to understand","metadata":{"execution":{"iopub.status.busy":"2021-07-20T04:30:11.114597Z","iopub.execute_input":"2021-07-20T04:30:11.114913Z","iopub.status.idle":"2021-07-20T04:30:11.129325Z","shell.execute_reply.started":"2021-07-20T04:30:11.11488Z","shell.execute_reply":"2021-07-20T04:30:11.128105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = merge['target']\nX = merge.drop(['target', 'cp', 'thal', 'restecg', 'slope', 'ca'], axis=1)\n\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T04:30:11.13066Z","iopub.execute_input":"2021-07-20T04:30:11.130982Z","iopub.status.idle":"2021-07-20T04:30:11.145556Z","shell.execute_reply.started":"2021-07-20T04:30:11.130951Z","shell.execute_reply":"2021-07-20T04:30:11.144689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T04:30:11.146811Z","iopub.execute_input":"2021-07-20T04:30:11.147332Z","iopub.status.idle":"2021-07-20T04:30:11.170429Z","shell.execute_reply.started":"2021-07-20T04:30:11.147302Z","shell.execute_reply":"2021-07-20T04:30:11.169683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_X.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T04:30:11.171533Z","iopub.execute_input":"2021-07-20T04:30:11.171986Z","iopub.status.idle":"2021-07-20T04:30:11.194047Z","shell.execute_reply.started":"2021-07-20T04:30:11.171955Z","shell.execute_reply":"2021-07-20T04:30:11.19312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T04:30:11.195309Z","iopub.execute_input":"2021-07-20T04:30:11.19583Z","iopub.status.idle":"2021-07-20T04:30:11.223391Z","shell.execute_reply.started":"2021-07-20T04:30:11.195798Z","shell.execute_reply":"2021-07-20T04:30:11.222021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_X.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T04:30:11.224934Z","iopub.execute_input":"2021-07-20T04:30:11.225267Z","iopub.status.idle":"2021-07-20T04:30:11.242232Z","shell.execute_reply.started":"2021-07-20T04:30:11.225235Z","shell.execute_reply":"2021-07-20T04:30:11.241156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can now get the mean of the training data and normalize it so that the neural network can \"understand\" it better","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nfeature_scaler = MinMaxScaler()\ntrain_X = feature_scaler.fit_transform(train_X)\ntest_X = feature_scaler.transform(test_X)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T04:30:11.243909Z","iopub.execute_input":"2021-07-20T04:30:11.24422Z","iopub.status.idle":"2021-07-20T04:30:11.260533Z","shell.execute_reply.started":"2021-07-20T04:30:11.24419Z","shell.execute_reply":"2021-07-20T04:30:11.258964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(train_X).head()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T04:42:48.457804Z","iopub.execute_input":"2021-07-20T04:42:48.458161Z","iopub.status.idle":"2021-07-20T04:42:48.491025Z","shell.execute_reply.started":"2021-07-20T04:42:48.45813Z","shell.execute_reply":"2021-07-20T04:42:48.489753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We also have to create our validation data","metadata":{}},{"cell_type":"code","source":"Xtrain, Xval, Ytrain, Yval = train_test_split(train_X, train_y, test_size=0.2, random_state=5)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T04:30:11.262323Z","iopub.execute_input":"2021-07-20T04:30:11.262747Z","iopub.status.idle":"2021-07-20T04:30:11.276255Z","shell.execute_reply.started":"2021-07-20T04:30:11.262709Z","shell.execute_reply":"2021-07-20T04:30:11.274694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First will be the neural network with Keras","metadata":{}},{"cell_type":"code","source":"Ytrain.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-20T04:39:32.995357Z","iopub.execute_input":"2021-07-20T04:39:32.995827Z","iopub.status.idle":"2021-07-20T04:39:33.003944Z","shell.execute_reply.started":"2021-07-20T04:39:32.995791Z","shell.execute_reply":"2021-07-20T04:39:33.002304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Yval.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-20T04:39:41.932844Z","iopub.execute_input":"2021-07-20T04:39:41.933252Z","iopub.status.idle":"2021-07-20T04:39:41.941706Z","shell.execute_reply.started":"2021-07-20T04:39:41.93322Z","shell.execute_reply":"2021-07-20T04:39:41.940391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Dense(train_X.shape[1], input_dim=train_X.shape[1]))   \nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T04:37:55.290602Z","iopub.execute_input":"2021-07-20T04:37:55.290997Z","iopub.status.idle":"2021-07-20T04:37:55.343457Z","shell.execute_reply.started":"2021-07-20T04:37:55.290966Z","shell.execute_reply":"2021-07-20T04:37:55.342567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = optimizers.Adam()\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n\nhistory = model.fit(Xtrain, Ytrain, epochs=40, validation_data=(Xval, Yval))","metadata":{"execution":{"iopub.status.busy":"2021-07-20T04:37:57.520982Z","iopub.execute_input":"2021-07-20T04:37:57.521422Z","iopub.status.idle":"2021-07-20T04:38:00.635926Z","shell.execute_reply.started":"2021-07-20T04:37:57.521389Z","shell.execute_reply":"2021-07-20T04:38:00.634605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we can plot the history of the training","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"plt.plot(history.history['accuracy'], label='acc')\nplt.plot(history.history['val_accuracy'], label='val_acc')\nplt.ylim((0.6, 1.1))\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T04:38:08.71175Z","iopub.execute_input":"2021-07-20T04:38:08.712132Z","iopub.status.idle":"2021-07-20T04:38:09.029402Z","shell.execute_reply.started":"2021-07-20T04:38:08.712087Z","shell.execute_reply":"2021-07-20T04:38:09.028128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can now get our prediction based on the test data and see its accuracy","metadata":{}},{"cell_type":"code","source":"prediction = model.predict(test_X) > 0.5\nprediction = (prediction > 0.5) * 1\naccuracy_nn = metrics.accuracy_score(test_y, prediction) * 100\nprint(accuracy_nn)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we can try to use LogisticRegression and see how well it works in comparison to the neural network.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\n\nL = LogisticRegression()\n\nparameters = {'C': [.1, .2, .3, .4, .5, 1, 2, 5, 10]}\n\nlogreg = GridSearchCV(L, parameters, scoring='neg_mean_squared_error')\n\nlogreg.fit(train_X, train_y)\nlogreg.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = LogisticRegression(C=0.1)\nmodel1.fit(train_X, train_y)\naccuracy1 = model1.score(test_X, test_y)\n\nprint('Logistic Regression Accuracy -->',((accuracy1)*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc_test_log = round(model1.score(test_X, test_y) * 100, 2)\nprint(acc_test_log)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# coeff_df = pd.DataFrame(train_X.columns.delete(0))\n# coeff_df.columns = ['Feature']\n# coeff_df[\"Correlation\"] = pd.Series(logreg_model.coef_[0])\n\n# coeff_df.sort_values(by='Correlation', ascending=False)\n\n\n### this block no longer works because of the minmaxscaler turning train_X and test_X into ndarrays\n### wasn't that important anyway","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The RandomForestRegressor is actually quite nice as well, especially when there is very linear data that has been created with the pd.get_dummies function.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nmodel6 = RandomForestClassifier(criterion = 'entropy',max_features = 'log2',n_estimators = 250)\nmodel6.fit(train_X, train_y)\naccuracy6 = model6.score(test_X, test_y)\n\nprint('Random Forest Classifier Accuracy -->',((accuracy6)*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nmultiNB = MultinomialNB()\n\nmultiNB.fit(train_X, train_y)\naccuracy5 = multiNB.score(test_X, test_y)\nprint('Multinomial NB Accuracy -->',((accuracy5)*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}