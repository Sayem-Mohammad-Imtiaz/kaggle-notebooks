{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Problem - Multi-class classification\n\n### We have title and abstract of various projects, classified into\n\n1)Computer Science\t\n2)Physics\t\n3)Mathematics\t\n4)Statistics\t\n5)Quantitative Biology\t\n6)Quantitative Finance","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Using bert for the task","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Installing transformers and upgrading it so that it is compatible with simpletransformers.\n### Then, installing simpletransformers.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install transformers\n!pip install --upgrade transformers\n!pip install simpletransformers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#A package for easing return of multiple values\n!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#GPUtil is a Python module for getting the GPU status from NVIDA GPUs using nvidia-smi.\n!pip install gputil\n\n#Cross-platform lib for process and system monitoring in Python.\n!pip install psutil","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing other necessary packages and ClassificationModel for bert\nfrom tqdm import tqdm\nimport warnings\nwarnings.simplefilter('ignore')\n\nfrom simpletransformers.classification import ClassificationModel\nfrom sklearn.preprocessing import LabelEncoder\n\nimport torch\nfrom scipy.special import softmax","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train-full/train.csv')\ntest = pd.read_csv('../input/independence-data-av/test.csv')\nsample_sub = pd.read_csv('../input/independence-data-av/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_copy = pd.read_csv('../input/train-full/train.csv')\ntrain_copy.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"text\"] = train[\"TITLE\"] + train[\"ABSTRACT\"]\ntest[\"text\"] = test[\"TITLE\"] + test[\"ABSTRACT\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cleaning text using clean-text","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install clean-text[gpl]\nfrom cleantext import clean\ndef text_cleaning(text):\n    text=clean(text,\n    fix_unicode=True,               # fix various unicode errors\n    to_ascii=True,                  # transliterate to closest ASCII representation\n    lower=True,                     # lowercase text\n    no_line_breaks=True,           # fully strip line breaks as opposed to only normalizing them\n    no_urls=True,                  # replace all URLs with a special token\n    no_emails=True,                # replace all email addresses with a special token\n    no_phone_numbers=True,         # replace all phone numbers with a special token\n    no_numbers=True,               # replace all numbers with a special token\n    no_digits=True,                # replace all digits with a special token\n    no_currency_symbols=True,      # replace all currency symbols with a special token\n    no_punct=True,                 # fully remove punctuation\n    replace_with_url=\"<URL>\",\n    replace_with_email=\"<EMAIL>\",\n    replace_with_phone_number=\"<PHONE>\",\n    replace_with_number=\"<NUMBER>\",\n    replace_with_digit=\"0\",\n    replace_with_currency_symbol=\"<CUR>\",\n    lang=\"en\"                       # set to 'de' for German special handling\n    )\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(train)):\n    train['text'].iloc[i]=text_cleaning(train['text'].iloc[i])\n    \nfor i in range(len(test)):\n    test['text'].iloc[i]=text_cleaning(test['text'].iloc[i])    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['text'].iloc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['text'].iloc[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using LabelEncoder to convert string classes into integers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"target_classes = [\"Computer Science\" ,\"Physics\" , \"Mathematics\", \"Statistics\" , \"Quantitative Biology\" , \"Quantitative Finance\"]\ntrain['label'] = train[target_classes].values.tolist()\n\nle = LabelEncoder()\ntrain['label'] = le.fit_transform(train['label'].astype(str))\ntrain = train[[\"text\",\"label\"]]\n\ntest = test[[\"text\"]]\n#initialising test labels\ntest[\"label\"] = 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Running the ClassificationModel and training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ClassificationModel('bert', 'bert-base-uncased', use_cuda=True,num_labels=24, args={'train_batch_size':32,\n                                                                                             'reprocess_input_data': True,\n                                                                                             'overwrite_output_dir': True,\n                                                                                             'fp16': False,\n                                                                                             'do_lower_case': False,\n                                                                                             'num_train_epochs': 2,\n                                                                                             'max_seq_length': 256,\n                                                                                             'regression': False,\n                                                                                             'manual_seed': 2,\n                                                                                             \"learning_rate\":4e-5,\n                                                                                             'weight_decay':0.0,\n                                                                                             \"save_eval_checkpoints\": False,\n                                                                                             \"save_model_every_epoch\": False,\n                                                                                             \"silent\": False})\n\nmodel.train_model(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get the evaluations from training bert","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_result, test_model_outputs, test_wrong_predictions = model.eval_model(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = softmax(test_model_outputs,axis=1)\nfinal_pred = [np.argmax(x) for x in predictions]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Processing and converting integer classes back to string classes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sub1=sample_sub.copy()\nsub1['target'] = le.inverse_transform(final_pred)\nfrom ast import literal_eval\nsub1.loc[:,'target'] = sub1.loc[:,'target'].apply(lambda x: literal_eval(x))\nsub1[target_classes] = pd.DataFrame(sub1.target.tolist(), index= sub1.index)\nsub1.drop(\"target\",axis=1,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub1.to_csv('sub_new1.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}