{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Mobilenet-v2 (width_multiplier=0.5), Pytorch for Sign Language MNIST"},{"metadata":{},"cell_type":"markdown","source":"That's a quick notebook for training very efficient and accurate network suitable for mobile devices. It achieves 97% top-1 accuracy."},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"LpCN9VqO6i0m","outputId":"16c78292-ef72-41bb-91d1-3c98c3958932","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","id":"-En1BYW06i0s","trusted":true},"cell_type":"code","source":"#import necessary libraries\nimport numpy as np\nimport torch\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom torchvision import datasets,transforms,models\nimport torch.nn.functional as F\nfrom torch import nn,optim\n\nfrom torch.utils.data import Dataset, TensorDataset\nfrom torch.optim import lr_scheduler\n\nimport torchvision\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"id":"xE_KnADF6i0v","trusted":true},"cell_type":"code","source":"train_dir='/kaggle/input/sign-language-mnist/sign_mnist_train.csv'\ntest_dir='/kaggle/input/sign-language-mnist/sign_mnist_test.csv'\n\ntrain=pd.read_csv(train_dir)\ntest=pd.read_csv(test_dir)","execution_count":null,"outputs":[]},{"metadata":{"id":"yeRLiDUv6i0y","outputId":"c0983a50-6be8-4dc3-99c1-751d09e6e2ce","trusted":true},"cell_type":"code","source":"#check train data\ntrain.head(10) ","execution_count":null,"outputs":[]},{"metadata":{"id":"VZH3EnkX6i03","outputId":"310e3edb-49b6-4808-e9de-3984c09e93dc","trusted":true},"cell_type":"code","source":"#check test data\ntest.head(10)","execution_count":null,"outputs":[]},{"metadata":{"id":"x_-LTv-e6i06","outputId":"0bac282c-50f2-48cf-9331-82a159074ccb","trusted":true},"cell_type":"code","source":"#Number of classes we have \n\nprint(train['label'].unique())\n\nprint(\"Number of classes : \",len(train['label'].unique()))","execution_count":null,"outputs":[]},{"metadata":{"id":"mD-qAwph6i08","outputId":"e2683a74-04a2-4cf0-9817-75d948561ee3","trusted":true},"cell_type":"code","source":"#obtain all rows and all columns except the 0 index column\n\ntrain_data = train.iloc[:, 1:].values\nprint(\"Number of train images:\", train_data.shape[0])\ntrain_labels=train.loc[:, 'label']\nprint(\"Number of pixels in each image:\", train_data.shape[1])\n\ntest_data = test.iloc[:, 1:].values\nprint(\"Number of test images:\", test_data.shape[0])\ntest_labels=test.loc[:, 'label']\nprint(\"Number of pixels in each image:\", test_data.shape[1])\n\n\n\nnew_train_labels=np.where(train_labels>8, train_labels-1, train_labels)\nnew_test_labels=np.where(test_labels>8, test_labels-1, test_labels)\n\n\n\nunique_val = np.array(new_test_labels)\n#np.append (unique_val, 9)\nprint(np.unique(unique_val))\n","execution_count":null,"outputs":[]},{"metadata":{"id":"Bun_bAy66i0_","outputId":"30488c46-cb75-45cc-88e3-67641f54977a","trusted":true},"cell_type":"code","source":"train_data.shape , new_train_labels.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"nsm8WSz56i1D","outputId":"d45af2bd-0381-4aa0-e5fd-06837a31faa3","trusted":true},"cell_type":"code","source":"from PIL import Image \n\nImage.open(\"/kaggle/input/sign-language-mnist/amer_sign2.png\")","execution_count":null,"outputs":[]},{"metadata":{"id":"-R6eO3O86i1G","trusted":true},"cell_type":"code","source":"letters={0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'k',10:'L',11:'M',12:'N',13:'O',14:'P',15:'Q',16:'R',17:'S',18:'T',19:'U',20:'V',21:'W',22:'X',23:'Y'}","execution_count":null,"outputs":[]},{"metadata":{"id":"VWaV_BnQ6i1J","outputId":"c00c1586-ed4d-4406-8d77-62152c0d4e05","trusted":true},"cell_type":"code","source":"\nplt.figure(figsize=(24,8))\n\nfor i in range(27):\n  \n  plt.subplot(3,9,i+1)\n  plt.imshow(train_data[i].reshape(28,28))\n  plt.axis('off')\n  plt.title(letters[int((new_train_labels[i]))])","execution_count":null,"outputs":[]},{"metadata":{"id":"XS-3IDbH6i1M","outputId":"6de859ca-44b8-46d9-d073-368b1100b9bc","trusted":true},"cell_type":"code","source":"plt.figure(figsize = (30,10))\nsns.countplot(new_train_labels)","execution_count":null,"outputs":[]},{"metadata":{"id":"_t3NG8HZ6i1P","trusted":true},"cell_type":"code","source":"\n#Data Augmentation\n\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.ToPILImage(),\n        \n        #transforms.RandomHorizontalFlip(),\n        transforms.RandomAffine(10,translate=(0.1,0.1)),\n        transforms.RandomResizedCrop(size=28,scale=(0.9,1.1), ratio=(0.95, 1.05)),\n        transforms.ToTensor(),\n]),\n    \n    'valid': transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.ToTensor(),\n    ]),\n}","execution_count":null,"outputs":[]},{"metadata":{"id":"bvKjmxqf6i1S","trusted":true},"cell_type":"code","source":"class DtProcessing(Dataset):\n    \n    #initialise the class variables - transform, data, target\n    def __init__(self, data, target, transform=None): \n        self.transform = transform\n        self.data = data.reshape((-1,28,28)).astype(np.float32)[:,:,:,None]\n        # converting target to torch.LongTensor dtype\n        self.target = torch.from_numpy(target).long() \n    \n    #retrieve the X and y index value and return it\n    def __getitem__(self, index): \n        return self.transform(self.data[index]), self.target[index]\n    \n    #returns the length of the data\n    def __len__(self): \n        return len(list(self.data))\n      \n","execution_count":null,"outputs":[]},{"metadata":{"id":"-xtXH_a46i1V","trusted":true},"cell_type":"code","source":"#divide train set into train and validation set\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_valid, y_train, y_valid = train_test_split(train_data, new_train_labels, test_size = .15, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"id":"_PsjD8NN6i1Y","trusted":true},"cell_type":"code","source":"      \ndset_train = DtProcessing(X_train, y_train, transform=data_transforms['train'])\n\ntrain_loader = torch.utils.data.DataLoader(dset_train, batch_size=120,\n                                          shuffle=True, num_workers=0)\n\ndset_valid = DtProcessing(X_valid, y_valid, transform=data_transforms['valid'])\n\nvalid_loader = torch.utils.data.DataLoader(dset_valid, batch_size=40,\n                                          shuffle=True, num_workers=0)\n\n\ndset_test = DtProcessing(test_data, new_test_labels, transform=data_transforms['valid'])\n\ntest_loader =torch.utils.data.DataLoader(dset_test, batch_size=40, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"7CT-Vzmg6i1c","trusted":true},"cell_type":"code","source":"import torch.nn as nn\nimport math\n\n\ndef _make_divisible(v, divisor, min_value=None):\n    \"\"\"\n    This function is taken from the original tf repo.\n    It ensures that all layers have a channel number that is divisible by 8\n    It can be seen here:\n    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n    :param v:\n    :param divisor:\n    :param min_value:\n    :return:\n    \"\"\"\n    if min_value is None:\n        min_value = divisor\n    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n    # Make sure that round down does not go down by more than 10%.\n    if new_v < 0.9 * v:\n        new_v += divisor\n    return new_v\n\n\ndef conv_3x3_bn(inp, oup, stride):\n    return nn.Sequential(\n        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n        nn.BatchNorm2d(oup),\n        nn.ReLU(inplace=True)\n    )\n\n\ndef conv_1x1_bn(inp, oup):\n    return nn.Sequential(\n        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n        nn.BatchNorm2d(oup),\n        nn.ReLU(inplace=True)\n    )\n\n\nclass InvertedResidual(nn.Module):\n    def __init__(self, inp, oup, stride, expand_ratio):\n        super(InvertedResidual, self).__init__()\n        assert stride in [1, 2]\n\n        hidden_dim = round(inp * expand_ratio)\n        self.identity = stride == 1 and inp == oup\n\n        if expand_ratio == 1:\n            self.conv = nn.Sequential(\n                # dw\n                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                nn.ReLU(inplace=True),\n                # pw-linear\n                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n            )\n        else:\n            self.conv = nn.Sequential(\n                # pw\n                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                nn.ReLU(inplace=True),\n                # dw\n                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                nn.ReLU(inplace=True),\n                # pw-linear\n                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n            )\n\n    def forward(self, x):\n        if self.identity:\n            return x + self.conv(x)\n        else:\n            return self.conv(x)\n\n\nclass MobileNetV2(nn.Module):\n    def __init__(self, num_classes=1000, width_mult=1., gray=False):\n        super(MobileNetV2, self).__init__()\n        # setting of inverted residual blocks\n        self.cfgs = [\n            # t, c, n, s\n            [1,  16, 1, 1],\n            [6,  24, 2, 2],\n            [6,  32, 3, 2],\n            [6,  64, 4, 2],\n            [6,  96, 3, 1],\n            [6, 160, 3, 2],\n            [6, 320, 1, 1],\n        ]\n\n        # building first layer\n        input_channel = _make_divisible(32 * width_mult, 4 if width_mult == 0.1 else 8)\n        layers = [conv_3x3_bn(3 if not gray else 1, input_channel, 2)]\n        # building inverted residual blocks\n        block = InvertedResidual\n        for t, c, n, s in self.cfgs:\n            output_channel = _make_divisible(c * width_mult, 4 if width_mult == 0.1 else 8)\n            for i in range(n):\n                layers.append(block(input_channel, output_channel, s if i == 0 else 1, t))\n                input_channel = output_channel\n        self.features = nn.Sequential(*layers)\n        # building last several layers\n        output_channel = _make_divisible(1280 * width_mult, 4 if width_mult == 0.1 else 8) if width_mult > 1.0 else 1280\n        self.conv = conv_1x1_bn(input_channel, output_channel)\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.classifier = nn.Linear(output_channel, num_classes)\n\n        self._initialize_weights()\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.conv(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.weight.data.normal_(0, 0.01)\n                m.bias.data.zero_()\n\ndef mobilenetv2(**kwargs):\n    \"\"\"\n    Constructs a MobileNet V2 model\n    \"\"\"\n    return MobileNetV2(**kwargs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = mobilenetv2(width_mult=0.5, num_classes=24, gray=True)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"kfPBrIee6i1g","trusted":true},"cell_type":"code","source":"import torch\nimport os\nimport glob\nimport numpy as np\nfrom torch.utils.data import ConcatDataset, DataLoader, random_split\n\nfrom tqdm import tqdm\n\nSTEPS = 100\nEPOCHS = 41\nDEVICE = \"cuda\"\nnp.random.seed(seed=1987)\ntorch.manual_seed(1987)\n\ndef writeToFile(text):\n    file_name = \"output_full.log\"\n    with open(file_name, \"a+\") as f:\n        f.write(text + \"\\n\")\n\n\ndef accuracy(output, target, topk=(3,1)):\n    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res\n\ndef validation(model, valid_loader, device, lossf, scoref):\n    model.eval()\n    loss, score3, score1 = 0, 0, 0\n    vlen = len(valid_loader)\n    for x, y in valid_loader:\n        x = x.squeeze()\n        if len(x.shape) != 3:\n            # Skip single or empty data\n            continue\n        x = x.unsqueeze(1)\n        y = y.squeeze()\n        x, y = x.to(device), y.to(device)\n        output = model(x)\n        loss += lossf(output, y).item()\n        score3 += scoref(output, y)[0].item()\n        score1 += scoref(output, y)[1].item()\n    model.train()\n    return loss / vlen, score3 / vlen, score1 / vlen","execution_count":null,"outputs":[]},{"metadata":{"id":"tbCstCPq6i1i","trusted":true},"cell_type":"code","source":"\noptimizer = torch.optim.Adam(net.parameters(), lr=0.002)\ncriterion = torch.nn.CrossEntropyLoss()\n\nitr = 1\nnet.train().cuda()\ntloss, score3, score1 = 0, 0, 0\nfor epoch in range(EPOCHS):\n    for x, y in tqdm(train_loader):\n        x = x.squeeze()\n        if len(x.shape) != 3:\n            # Skip single or empty data\n            continue\n        x = x.unsqueeze(1)\n        y = y.squeeze()\n        x, y = x.to(DEVICE), y.to(DEVICE)\n        optimizer.zero_grad()\n        output = net(x)\n        loss = criterion(output, y)\n        loss.backward()\n        optimizer.step()\n        tloss += loss.item()\n        score3 += accuracy(output, y)[0].item()\n        score1 += accuracy(output, y)[1].item()\n        \n\n        if itr % STEPS == 0:\n            writeToFile('Epoch {} Iteration {} -> Train Loss: {:.4f}, MAP@3: {:.3f}, MAP@1: {:.3f} '.format(epoch, itr, tloss / itr,\n                                                                                      score3 / itr, score1 / itr))\n            tloss, score = 0, 0\n        itr += 1\n    vloss, vscore3, vscore1 = validation(net, valid_loader, DEVICE, criterion, accuracy)\n    writeToFile('Epoch {} -> Valid Loss: {:.4f}, MAP@3: {:.3f}, MAP@1: {:.3f}'.format(epoch, vloss, vscore3, vscore1))\n    filename_pth = 'new_checkpoint' + str(epoch) + '_mobilenet.pth'\n    torch.save(net.state_dict(), filename_pth)","execution_count":null,"outputs":[]},{"metadata":{"id":"uThd29AD6i1p","trusted":true},"cell_type":"code","source":"net.load_state_dict(torch.load('new_checkpoint36_mobilenet.pth'))\n\nclasses=['A','B','C','D','E','F','G','H','I','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y']","execution_count":null,"outputs":[]},{"metadata":{"id":"GRoW1YXZ6i1r","trusted":true},"cell_type":"code","source":"\n\n  model = net\n  test_loss = 0.0\n  class_correct = list(0. for i in range(24))\n  class_total = list(0. for i in range(24))\n\n  model.eval()\n# iterate over test data\n  for data, target in test_loader:\n\n    batch_size = data.size(0)\n    #print(batch_size)\n    # move tensors to GPU if CUDA is available\n    if torch.cuda.is_available():\n        data, target = data.cuda(), target.cuda()\n    # forward pass: compute predicted outputs by passing inputs to the model\n    output = model(data)\n\n    # calculate the batch loss\n    loss = criterion(output, target)\n    # update test loss \n    test_loss += loss.item()*data.size(0)\n    # convert output probabilities to predicted class\n    _, pred = torch.max(output, 1)    \n    # compare predictions to true label\n    correct_tensor = pred.eq(target.data.view_as(pred))\n    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n    # calculate test accuracy for each object class\n    for i in range(batch_size):\n        label = target.data[i]\n        class_correct[label] += correct[i].item()\n        class_total[label] += 1\n\n# average test loss\n  test_loss = test_loss/len(test_loader)\n  print('Test Loss: {:.6f}\\n'.format(test_loss))\n\n  for i in range(24):\n    if class_total[i] > 0 :\n        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n            classes[i], 100 * class_correct[i] / class_total[i],\n            np.sum(class_correct[i]), np.sum(class_total[i])))\n    else:\n        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n\n  print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n    100. * np.sum(class_correct) / np.sum(class_total),\n    np.sum(class_correct), np.sum(class_total)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.onnx.export(model, data[0][None,...], 'signlang_mobilenet05.onnx')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}