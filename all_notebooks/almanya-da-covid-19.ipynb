{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n        # Load libraries\nfrom pandas import read_csv\nfrom pandas.plotting import scatter_matrix\nfrom matplotlib import pyplot\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn import preprocessing\nfrom sklearn import utils\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns # fancy statistics plots\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport matplotlib.dates as mdates\nfrom matplotlib.dates import DateFormatter\nimport geopandas as gpd\nimport scipy\nfrom scipy.optimize import curve_fit\nimport datetime\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nimport matplotlib.animation as animation\nfrom IPython.display import HTML\nimport seaborn as sns\nfrom plotly.subplots import make_subplots\n%matplotlib inline\n\n\nimport plotly.tools as tls\nimport cufflinks as cf\nfrom plotly import __version__\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset=pd.read_csv('../input/covid19-tracking-germany/covid_de.csv')\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shape\nprint(dataset.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# head\nprint(dataset.head(20))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cov_cases = dataset.groupby(['date']).sum().reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(16,9))\nax.plot(cov_cases[\"date\"],\n        cov_cases[\"cases\"],\n        color=\"g\");\nax.set_title(\"germany confirmed cases per day\");\nax.spines[\"top\"].set_visible(False);\nax.spines[\"right\"].set_visible(False);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(16,9))\nax.plot(cov_cases[\"date\"],\n        cov_cases[\"deaths\"],\n        color=\"r\");\nax.set_title(\"germany confirmed deaths per day\");\nax.spines[\"top\"].set_visible(False);\nax.spines[\"right\"].set_visible(False);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(16,9))\nax.plot(cov_cases[\"date\"],\n        cov_cases[\"recovered\"],\n        color=\"b\");\nax.set_title(\"germany recovered cases per day\");\nax.spines[\"top\"].set_visible(False);\nax.spines[\"right\"].set_visible(False);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_reg=dataset.groupby(['county']).agg({'cases':'sum','deaths':'sum'}).sort_values([\"cases\"],ascending=False).reset_index()\ndf_reg.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure(data=[go.Table(\n    columnwidth = [50],\n    header=dict(values=('county', 'cases', 'deaths'),\n                fill_color='#104E8B',\n                align='center',\n                font_size=14,\n                font_color='white',\n                height=40),\n    cells=dict(values=[df_reg['county'].head(10), df_reg['cases'].head(10), df_reg['deaths'].head(10)],\n               fill=dict(color=['#509EEA', '#A4CEF8',]),\n               align='right',\n               font_size=12,\n               height=30))\n])\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.pie(df_reg.head(10),\n             values=\"cases\",\n             names=\"county\",\n             title=\"cases\",\n             template=\"seaborn\")\nfig.update_traces(rotation=90, pull=0.05, textinfo='value+label')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Satir Sayisi\nprint(\"Satır Sayısı:\\n\",data.shape[0:])\n\n# Sutun Adlari\nprint(\"Sütun Adlari:\\n\",data.columns.tolist())\n\n# Veri Tipleri\nprint(\"Veri Tipleri:\\n\",data.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Eksik Deger Tablosu Olusturalım\n\ndef eksik_deger_tablosu(dataset):\n    eksik_deger=dataset.isnull().sum()\n    eksik_deger_yuzde=100* dataset.isnull().sum()/len(dataset)\n    eksik_deger_tablo= pd.concat([eksik_deger,eksik_deger_yuzde], axis=1)\n    eksik_deger_tablo_son=eksik_deger_tablo.rename(\n    columns = {0 : 'Eksik Değerler',1: '% Değeri'} )\n    return eksik_deger_tablo_son\n\neksik_deger_tablosu(dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.dropna()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nlabel_encoder = preprocessing.LabelEncoder() \ndataset['state_Encoded']= label_encoder.fit_transform(dataset['state'])\ndataset['county_Encoded']= label_encoder.fit_transform(dataset['county'])\n\ndataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset =dataset.drop(columns ='state')\ndataset =dataset.drop(columns ='county')\ndataset =dataset.drop(columns ='age_group')\ndataset =dataset.drop(columns ='gender')\ndataset =dataset.drop(columns ='date')\ndataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# class distribution\nprint(dataset.groupby('county_Encoded').size())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# descriptions\nprint(dataset.describe())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# box and whisker plots\ndataset.plot(kind='box', subplots=True, layout=(3,3), sharex=False, sharey=False)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# histograms\ndataset.hist()\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scatter plot matrix\nscatter_matrix(dataset)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"array = dataset.values\nX = array[:,0:5]\ny = array[:,0:1]\nX_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=0.20, random_state=1)\n\nprint(\"Dataframe boyutu: \",dataset.shape)\nprint(\"Eğitim verisi boyutu: \",X_train.shape, Y_train.shape)\nprint(\"Test verisi boyutu: \",X_validation.shape, Y_validation.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# type error için target typesı \"Label Encoder\" ile  multiclassa çevirdim.(Target=Y_train)\nfrom sklearn import preprocessing\nfrom sklearn import utils\n\nlab_enc = preprocessing.LabelEncoder()\nencoded = lab_enc.fit_transform(y)\nprint(utils.multiclass.type_of_target(y))\nprint(utils.multiclass.type_of_target(Y_train.astype('int')))\nprint(utils.multiclass.type_of_target(encoded))\n\nlab_enc = preprocessing.LabelEncoder()\nY_train = lab_enc.fit_transform(Y_train)\nprint(utils.multiclass.type_of_target(Y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\n#Decision Trees\ncellTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\nprint(cellTree) # it shows the default parameters\n  #I fit the data with the training\ncellTree.fit(X_train,Y_train)\n  #now predictions\nyhat_dt = cellTree.predict(X_validation)\n\n  #Accuracy evaluation\nacc = metrics.accuracy_score(Y_validation, yhat_dt)\nprint('karar agaci icin accuracy: ',acc)\n\n#karar agaci icin confusion matrix ve metrik degerler\ncellTree_dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\n#train model with cv of 10 burda modeli 10 cross validasyon ile scorelari verdik\ncv_scores_dt = cross_val_score(cellTree_dt, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores_dt)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores_dt)))\nfrom sklearn.metrics import classification_report\nprec_dt = classification_report(yhat_dt,Y_validation)\nprint(prec_dt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#call the models\nfrom sklearn.neighbors import KNeighborsClassifier\nknn_model = KNeighborsClassifier(n_neighbors = 3)\n# fit the models\nneigh = knn_model.fit(X_train,Y_train)\n#predict the mode;\nyhatknn=neigh.predict(X_validation)\n\n  #Accuracy evaluation\naccknn = metrics.accuracy_score(Y_validation, yhatknn)\nprint('en yakin komsular icin accuracy',accknn)\n\n#knn=3 icin confusion matrix ve metrik degerler\nknn_knn = KNeighborsClassifier(n_neighbors = 3)\n#train model with cv of 10 burda modeli 10 cross validasyon ile scorelari verdik\ncv_scores_knn = cross_val_score(knn_knn, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores_knn)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores_knn)))\n\n#knn scores\nfrom sklearn.metrics import classification_report\nprec_knn = classification_report(yhatknn,Y_validation)\nprint(prec_knn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lojistik regresyon\nfrom sklearn.linear_model import LogisticRegression\nLR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,Y_train)\nLR\n#predict\nyhatlr = LR.predict(X_validation)\n#print('yhat', yhat)\n  #Accuracy evaluation\nacclr = metrics.accuracy_score(Y_validation, yhatlr)\nprint('lojistik regresyon icin accuracy',acclr)\n\n\n#lojistik regresyon icin confusion matrix ve metrik degerler\nlr_lr = LogisticRegression(C=0.01, solver='liblinear')\n#train model with cv of 10 burda modeli 10 cross validasyon ile scorelari verdik\ncv_scores_lr = cross_val_score(lr_lr, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores_lr)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores_lr)))\n\n\nfrom sklearn.metrics import classification_report\nprec_lr = classification_report(yhatlr,Y_validation)\nprint(prec_lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#SVM \nfrom sklearn import svm\nclf = svm.SVC(kernel='rbf')\nclf.fit(X_train, Y_train) \n#predict\nyhatsvm = clf.predict(X_validation)\n#yhat [0:5]\naccsvm = metrics.accuracy_score(Y_validation, yhatsvm)\nprint('svm icin accuracy',accsvm)\n\n\n\n#svm icin confusion matrix ve metrik degerler\nclf_svm = svm.SVC(kernel='rbf')\n#train model with cv of 10 burda modeli 10 cross validasyon ile scorelari verdik\ncv_scores_svm = cross_val_score(clf_svm, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores_svm)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores_svm)))\n\n\nfrom sklearn.metrics import classification_report\nprec_svm = classification_report(yhatsvm,Y_validation)\nprint(prec_svm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gaussian NB \n# Gaussian Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\n#call the models\ngnb = GaussianNB()\n  #fit the model\ngnb.fit(X_train, Y_train) \n  #predict\nyhatgnb = gnb.predict(X_validation)\naccgnb = metrics.accuracy_score(Y_validation, yhatgnb)\nprint('gaussian naive bayes icin accuracy',accgnb)\n\n\n#gaussian naive bayes icin confusion matrix ve metrik degerler\nclf_gnb = GaussianNB()\n#train model with cv of 10 burda modeli 10 cross validasyon ile scorelari verdik\ncv_scores_gnb = cross_val_score(clf_gnb, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores_gnb)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores_gnb)))\n\n#klasifikasyon tablosu\nfrom sklearn.metrics import classification_report\nprec_gnb = classification_report(yhatgnb,Y_validation)\nprint(prec_gnb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#linear discriminant analysis \nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nlda = LinearDiscriminantAnalysis()\n#fit the model\nlda.fit(X_train, Y_train) \n#predict\nyhatlda = lda.predict(X_validation)\nacclda = metrics.accuracy_score(Y_validation, yhatlda)\nprint('linear discriminant analiz icin accuracy',acclda)\n\n\n\n\n#linear discrimant icin confusion matrix ve metrik degerler\nclf_ld = LinearDiscriminantAnalysis()\n#train model with cv of 10 burda modeli 10 cross validasyon ile scorelari verdik\ncv_scores_ld = cross_val_score(clf_ld, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores_ld)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores_ld)))\n\n#klasifikasyon linear diskrimannt\nfrom sklearn.metrics import classification_report\nprec_lda = classification_report(yhatlda,Y_validation)\nprint(prec_lda)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nrfc = RandomForestClassifier(max_depth=5, n_estimators=100, max_features='auto')\nrfc.fit(X_train, Y_train) \n#predict\nyhat1 = rfc.predict(X_validation)\n#yhat [0:5]\n#evaluate\n\n#create a new SVM model\nrfc_cv = RandomForestClassifier(max_depth=5, n_estimators=100, max_features='auto')\n#train model with cv of 10\ncv_scores = cross_val_score(rfc_cv, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores)))\n\n\n\n\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools\nfrom sklearn.metrics import f1_score\nprint('f1_score for Random Forest Classifier:',f1_score(Y_validation, yhat1, average='weighted'))\n#print(\"Train set Accuracy for Random Forest Classifier: \", metrics.accuracy_score(Y_validation, rfc.predict(X_train)))\n#print(\"Test set Accuracy for Random Forest Classifier: \", metrics.accuracy_score(Y_validation, yhat1))\nfrom sklearn.metrics import classification_report\nprec_rec = classification_report(yhat1,Y_validation)\nprint(prec_rec)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}