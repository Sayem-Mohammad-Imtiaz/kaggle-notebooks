{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Case study\n### Google Data Analytics Capstone - Coursera\n\nHow Does a Bike-Share Navigate Speedy Success?","metadata":{}},{"cell_type":"markdown","source":"### Scenario\nYou are a junior data analyst working in the marketing analyst team at Cyclistic, a bike-share company in Chicago. The director of\nmarketing believes the companyâ€™s future success depends on maximizing the number of annual memberships. Therefore, your\nteam wants to understand how casual riders and annual members use Cyclistic bikes differently. From these insights, your team\nwill design a new marketing strategy to convert casual riders into annual members. But first, Cyclistic executives must approve\nyour recommendations, so they must be backed up with compelling data insights and professional data visualizations.","metadata":{}},{"cell_type":"markdown","source":"### Business task\nDesign marketing strategies aimed at converting casual riders into annual members.\n### My assignment\nHow do annual members and casual riders use Cyclistic bikes differently?","metadata":{}},{"cell_type":"markdown","source":"### Set up the environment","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Discover datasets\nThere is 2 type of datasets:\n<ul>\n    <li>Per year -> one dataset is one quarter of one year -> 13 attributes for 426 887 entries</li>\n    <li>Per month -> one dataset is one month -> 13 attributes for 84 776 entries</li>\n</ul>\nLet's compare the 2 types to spot differences and decide which one to use.\n<br>\nBoth dataset have the same number of attributes and the same attribute names, but a different entry value.","metadata":{}},{"cell_type":"code","source":"df_2020_Q1 = pd.read_csv('../input/cyclistic-dataset-google-certificate-capstone/Divvy_Trips_2020_Q1.csv')\ndf_202004 = pd.read_csv('../input/cyclistic-dataset-google-certificate-capstone/202004-divvy-tripdata.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_2020_Q1.head()","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_202004.head()","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_2020_Q1.info()","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_202004.info()","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our assignment is to compare annual members with casual members. Let's study the column <i>member_casual</i>.\n<br>\nThere are 2 types of member_casual:\n<ul>\n    <li>member -> annual members</li>\n    <li>casual -> casual members</li>\n</ul>\nThat's perfect. From there we know that we could group by member type to have insight.","metadata":{}},{"cell_type":"code","source":"df_2020_Q1['member_casual'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prepare","metadata":{}},{"cell_type":"markdown","source":"We know what the datasets are like. Now we can start preparing the data. The important question is: how many months or quarters do we take for analysis.\n<br>\nTaking the every single entry of every single month will make the dataset huge to analyze. We could select a sample size.\n<br>\n<br>\nLet's start by filtering the whole year of 2020 and choose a sample size from it.","metadata":{}},{"cell_type":"markdown","source":"The new data frame has 13 attributes and 3 541 683 entries. Which is waaaaaay too much entries.\n<br>\nLet's take a sample size (https://www.surveymonkey.com/mp/sample-size-calculator/)","metadata":{}},{"cell_type":"markdown","source":"I recall the datasets from there no to destroy the analysis of the 2 datasets made previously.\n<br>\n<br>\nAccording to our assignment the only attributes which are going to give use usefull insight are: meber_casual, started_at, and ended_at. Why? Because according the the company's pricing plan, price are defined in 3 ways:\n<ul>\n    <li>single_ride passe</li>\n    <li>full_day passe</li>\n    <li>annual membership</li>\n</ul>\nSo, what's differ between casual and annual members will be the time spend on the bike, or, trip time.","metadata":{}},{"cell_type":"code","source":"df_2020_Q1 = pd.read_csv('../input/cyclistic-dataset-google-certificate-capstone/Divvy_Trips_2020_Q1.csv', usecols = ['ride_id', 'started_at', 'ended_at', 'member_casual'])\ndf_202004 = pd.read_csv('../input/cyclistic-dataset-google-certificate-capstone/202004-divvy-tripdata.csv', usecols = ['ride_id', 'started_at', 'ended_at', 'member_casual'])\ndf_202005 = pd.read_csv('../input/cyclistic-dataset-google-certificate-capstone/202005-divvy-tripdata.csv', usecols = ['ride_id', 'started_at', 'ended_at', 'member_casual'])\ndf_202006 = pd.read_csv('../input/cyclistic-dataset-google-certificate-capstone/202006-divvy-tripdata.csv', usecols = ['ride_id', 'started_at', 'ended_at', 'member_casual'])\ndf_202007 = pd.read_csv('../input/cyclistic-dataset-google-certificate-capstone/202007-divvy-tripdata.csv', usecols = ['ride_id', 'started_at', 'ended_at', 'member_casual'])\ndf_202008 = pd.read_csv('../input/cyclistic-dataset-google-certificate-capstone/202008-divvy-tripdata.csv', usecols = ['ride_id', 'started_at', 'ended_at', 'member_casual'])\ndf_202009 = pd.read_csv('../input/cyclistic-dataset-google-certificate-capstone/202009-divvy-tripdata.csv', usecols = ['ride_id', 'started_at', 'ended_at', 'member_casual'])\ndf_202010 = pd.read_csv('../input/cyclistic-dataset-google-certificate-capstone/202010-divvy-tripdata.csv', usecols = ['ride_id', 'started_at', 'ended_at', 'member_casual'])\ndf_202011 = pd.read_csv('../input/cyclistic-dataset-google-certificate-capstone/202011-divvy-tripdata.csv', usecols = ['ride_id', 'started_at', 'ended_at', 'member_casual'])\ndf_202012 = pd.read_csv('../input/cyclistic-dataset-google-certificate-capstone/202012-divvy-tripdata.csv', usecols = ['ride_id', 'started_at', 'ended_at', 'member_casual'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create a new dataframe for the year 2020\nframe_2020 = [df_2020_Q1, df_202004, df_202005, df_202006, df_202007, df_202008, df_202009, df_202010, df_202011, df_202012]\ndf_2020 = pd.concat(frame_2020)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a new column that will display the lenght of each trip.\n<br>\nended_at - started_at = length_trip","metadata":{}},{"cell_type":"code","source":"#the 2 columns started_at and ended_at were object type \n#let's turn them into a date and time format\ndf_2020['started_at'] = pd.to_datetime(df_2020['started_at'])\ndf_2020['ended_at'] = pd.to_datetime(df_2020['ended_at'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We create a new column which will give the length for each trip (in date and time type)","metadata":{}},{"cell_type":"code","source":"df_2020['length_trip'] = df_2020['ended_at'] - df_2020['started_at']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We create a column that will give the day of the week when the ride started.\n<br>\n<br>\n/!\\\n<ul>\n    <li>0 = Monday</li>\n    <li>1 = Tuesday</li>\n    <li>2 = Wednesday</li>\n    <li>3 = Thursday</li>\n    <li>4 = Friday</li>\n    <li>5 = Saturday</li>\n    <li>6 = Sunday</li>\n</ul>","metadata":{}},{"cell_type":"code","source":"df_2020['day_started'] = df_2020['started_at'].dt.dayofweek","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a new column to extract the month of the started_at column. So that a seasonal analysis could be perform.","metadata":{}},{"cell_type":"code","source":"df_2020['month_started'] = pd.DatetimeIndex(df_2020['started_at']).month","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, our dataset is a giant dataframe of 6 attributes for 3.5 million entries. This is a big chunk to study. That's why it would be better to select a sample size of it. However, in the case study, stakeholders don't specify the confidence level and the margin error wanted. \n<br>\n<br>\nAfter trying to plot some distibution, my laptop transformed itslef into a rocket and took ages to plot one histogram (truly I don't know how long, I stopped the kernel because it was too long). \n<br>\n<br>\nI can play Destiny 2 on my laptop but can't plot a little graph with 3.5 entries. LOL\n<br>\n<br>\nI have no choice but to choose a sample size. (https://www.surveymonkey.com/mp/sample-size-calculator/)\n<br>\n<br>\nI'll choose the following parameters:\n<ul>\n    <li>Confidence level: 99%</li>\n    <li>Margin error: 5%</li>\n</ul>\nSample size : 666\n<br>\nLet's round that to 700. So, if there's rows to remove, the analysis will be still good.","metadata":{}},{"cell_type":"markdown","source":"<br>\nI'll choose the sample size randomly and quickly check it to avoid unfair conclusion.\n<br>\n<br>\nThe proportion of member type is almost the same between the entire dataset (0.63) and the sampled one (0.63). It seems that the sample size is fair.","metadata":{}},{"cell_type":"code","source":"df_2020_sampled = df_2020.sample(n = 700)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_2020_sampled.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#compare proportion member type in the sample size\nprop = df_2020_sampled.groupby('member_casual')['member_casual'].count()\nprop","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#compare proportion member type in the entire dataset\nprop2 = df_2020.groupby('member_casual')['member_casual'].count()\nprop2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#proportion sample, between casual and annual members\nprop.iloc[0]/prop.iloc[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#proportion entire, between casual and annual members\nprop2.iloc[0]/prop2.iloc[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Process\nCheck it there are mistakes in the data.","metadata":{}},{"cell_type":"code","source":"df_2020_sampled.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check for nan of null values","metadata":{}},{"cell_type":"code","source":"df_2020_sampled.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_2020_sampled.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Start with the day_started column. Days have to be in the range 0 to 6. Seems to be good.","metadata":{}},{"cell_type":"code","source":"df_2020_sampled['day_started'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then with length of trip. They should be all positive values.\n<br>\nThe min value is negative. So we have a problem in the length_trip column.\n<br>\n<br>\nThere are only 3 negative values. This type of error might be a human error. The value of started_at and ended_at might have been switch.\n<br>\n3 possibilities to fix it:\n<ol>\n    <li>Remove these 3 rows. But the sample size won't be good anymore. </li>\n    <li>Switch the started_at values and ended_at values for these 3 errors.</li>\n    <li>Or, simply turn the 3 values in length_trip_sec positive.</li>\n</ol>\nLet's go with the 3rd possibility","metadata":{}},{"cell_type":"code","source":"#to make it easy to detect them, turn the length_trip in seconds in a new column\ndf_2020_sampled['length_trip_sec'] = df_2020_sampled['length_trip'].astype('timedelta64[s]')","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_2020_sampled[df_2020_sampled['length_trip_sec'] < 0].count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_2020_sampled.loc[df_2020_sampled['length_trip_sec'] < 0]","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#replace all values by its absolute value\ndf_2020_sampled['length_trip_sec'] = df_2020_sampled['length_trip_sec'].abs()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Another problem detected is the maximum length_trip. Some lenght_trip are huge. We can directly put them in the case of outlier. Let's see more about it.\n<br>\nThe box plot and histogram shows us that some length_trip_sec takes gigantic values. \n<br>\nMost of the outliers are with the casual members.","metadata":{}},{"cell_type":"code","source":"sns.boxplot(df_2020_sampled['length_trip_sec'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(df_2020_sampled['length_trip_sec'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's detect the outliers","metadata":{}},{"cell_type":"code","source":"#calculate the interquartile range\nq25, q50, q75 = np.percentile(df_2020_sampled['length_trip_sec'], [25, 50, 75])\niqr = q75 - q25\niqr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#define the min and max limites to be considered an outlier\nmini = q25 - 1.5*iqr\nmaxi = q25 + 1.5*iqr\n\nmaxi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#identify the points to remove\npoints = [x for x in df_2020_sampled['length_trip_sec'] if x > maxi]\nprint('the max points is max point is', max(points))\nprint('the max points is min point is', min(points))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"According to the outlier detection, all values of length_trip_sec superior to 1049 seconds are considered outliers.\n<br>\n<b>/!\\ The outliers here are not something to erase and forget. It tells us a lot about how a member uses a bike. In that case it appears that casual members are causing these huge outliers.</b>\n<br>\n<br>\n<i>Here again, it seems to be a human error. The day seems to be the mistake but I can't be 100% sure.</i>\n<br>\n<br>\nLet's delete the huge values to see the boxplot better.","metadata":{}},{"cell_type":"code","source":"df_2020_sampled[df_2020_sampled['length_trip_sec'] > 10000].count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_2020_sampled = df_2020_sampled[df_2020_sampled['length_trip_sec'] <= 10000]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see the outliers better. And there's a lot of outliers. In this case study, outliers are non negligible so I'll keep them for the sake of the business task.","metadata":{}},{"cell_type":"code","source":"sns.boxplot(df_2020_sampled['length_trip_sec'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Analysis with sampled dataset","metadata":{}},{"cell_type":"markdown","source":"##### Display the distribution of length_trip","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,7))\nsns.histplot(df_2020_sampled, x = 'length_trip_sec', hue = 'member_casual', ax=ax, kde = True) #plot distribution\nplt.title('Distribution of the length of a trip in 2020, annual vs casual member')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pivot = df_2020_sampled.groupby('member_casual')['length_trip_sec'].agg(['mean','max', 'min'])\npivot = pivot.reset_index()\npivot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Create a summary table grouped by member types and days","metadata":{}},{"cell_type":"code","source":"summary = df_2020_sampled.groupby(['member_casual', 'day_started'])['length_trip_sec'].agg(['mean','max', 'min'])\nsummary = summary.reset_index()\nsummary","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Visualize the average length of a trip per day and per member type.","metadata":{}},{"cell_type":"code","source":"summary['day_started'] = summary['day_started'].apply(str) #turn date into string for the plot bar","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(data = summary, kind = 'bar', x = 'day_started', y = 'mean', hue = 'member_casual', height = 7, aspect = 1.2)\nplt.title('Average length of a trip per day and per member type')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Verify which day is the most solicitated.","metadata":{}},{"cell_type":"code","source":"day = df_2020_sampled.groupby(['member_casual','day_started'])['day_started'].agg(['count'])\nday = day.reset_index()\nday","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,7))\nsns.histplot(df_2020_sampled, x = 'day_started', hue = 'member_casual', ax=ax, kde = True) #plot distribution\nplt.title('Distribution of number of use per day of the week')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Check the average trip length per month","metadata":{}},{"cell_type":"code","source":"summary2 = df_2020_sampled.groupby(['member_casual', 'month_started'])['length_trip_sec'].agg(['mean','max', 'min'])\nsummary2 = summary2.reset_index()\nsummary2","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary2['month_started'] = summary2['month_started'].apply(str) #turn date into string for the plot bar","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(data = summary2, kind = 'bar', x = 'month_started', y = 'mean', hue = 'member_casual', height = 7, aspect = 1.2)\nplt.title('Average length of a trip per month and per member type')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Which is the most solicited month","metadata":{}},{"cell_type":"code","source":"df_2020_sampled.groupby(['member_casual', 'month_started'])['month_started'].agg(['count'])","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (10,7))\nsns.histplot(df_2020_sampled, x = 'month_started', hue = 'member_casual', ax=ax, kde = True) #plot distribution\nplt.title('Distribution of number of use per month of the week')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Conclusion","metadata":{}},{"cell_type":"markdown","source":"In the conclusion no numbers will appear since the sample size is taken randomly. If the entire kernel is ran again, different values and different plots will be displayed.\n<br>\n<br>\nBut, in general, the analysis tell us the following:\n<br>\n<br>\n<b>The average time spent on a bike per ride is clear:</b>\n<ul>\n    <li>While Casual members spend on average more time on their bike than annual members, the distribution remain inconsistent during week days.</li>\n    <li>Annual members seem to be more predictible is a more consitant average time spent on their bike.</li>\n    <li>In both case, casual and annual members seem to spend more time on a bike during the weekends.</li>\n</ul>\n<b>While the number of rides is clearly on annual members side:</b>\n<ul>\n    <li>Annual members have more rides in a day than casual members</li>\n    <li>On the weekends (Saturday and Sunday), is the period where casual member have different rides more often</li>\n    <li>Same remark as before, the number of rides stay consistent throuhout the week with annual members</li>\n</ul>\n<b>During seasonal period, behaviors are distinct:</b>\n<ul>\n    <li>The period of spring and summer are the best season so far both in term of number of unique ride and average time per ride</li>\n    <li>However, casual members are still unpredictable. With the average time spent on a bike varying from month to month unconsistantly.</li>\n</ul>\n<br>\nIn clear, casual members spend averagely more time on a bike than their peers the annual members. It appears that casual members create the most and biggest outliers for the ride time. However, annual members use their benifit well since they are using more bikes in a day than casual members.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}