{"cells":[{"metadata":{},"cell_type":"markdown","source":"Creating a Deep learning predictive model from the data set to get the prediction whether a country can have banking crisis in future with the given set of data with simple hold out validation.\n\nNote: However I will be using simple hold out validation but K fold validation and iterated K fold will be a better choice as we have a small dataset of 1059 rows."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/africa-economic-banking-and-systemic-crisis-data/african_crises.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking for null values in dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature engineering => dropping unneccessary columns which do not have effect of predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['cc3'],axis=1,inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Label encoding to covert string values to integers"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\ndf.country = le.fit_transform(df.country)\ndf.banking_crisis = le.fit_transform(df.banking_crisis)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Randomizing the data for non bias and doing train and test split in 80% and 20%"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_split = np.random.rand(len(df)) < 0.7\ntrain = df[train_test_split]\ntest = df[~train_test_split]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"looking few rows of train and test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Column 12 - \"banking_crisis\" is what i have to predict from the given dataset so I will map 'train_data' from col 0 to col 11 and will map 'train_label' to col 12 which we have to predict and the same for test data as well"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train.iloc[:,0:12]\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_label = train.iloc[:,12]\ntrain_label.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = test.iloc[:,0:12]\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_label = test.iloc[:,12]\ntest_label.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating the network architecture: selecting 3 layer model (one input, one hidden and one output) with 8 hidden units of layer for input and hidden layer (to lessen the complexity) and one for output layer with activation function as sigmoid"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import models\nfrom keras import layers\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(8, activation = 'relu', input_shape = (12,)))\nmodel.add(layers.Dense(8, activation = 'relu'))\nmodel.add(layers.Dense(1, activation = 'sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compiling the model and fixing the required metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics =['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seggregating 100 validation samples from training data to check training accuracy and loss and validation accuracy and loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_val = train_data[:100]\npartial_x_train = train_data[100:]\ny_val = train_label[:100]\npartial_y_train = train_label[100:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Running model fit to train the model and test on validation data, after the 9th epochs the model started to show appreciable and consistant accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(partial_x_train, partial_y_train, epochs = 60, batch_size = 10, validation_data = (x_val, y_val))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally running the model on the test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_data,train_label, epochs = 60, batch_size = 10)\nresults = model.evaluate(test_data, test_label)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The final accuracy turned out to be 96.04%"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(results)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A fairly naive approach achieved an accuracy of 96.04% which can be increased with other state of art approaches such as K fold validation and iterated K fold."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}