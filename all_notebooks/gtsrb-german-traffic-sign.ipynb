{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from warnings import filterwarnings\nfilterwarnings('ignore')\n\nimport os\nimport shutil\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, Activation, Dropout, Flatten, Dense, BatchNormalization\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\nfrom sklearn.metrics import confusion_matrix, classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BASE_PATH = '../input/gtsrb-german-traffic-sign/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_data():\n    files,labels=[],[]\n    for dirname in os.listdir(f'{BASE_PATH}Train'):\n        for file in os.listdir(f'{BASE_PATH}Train/{dirname}'):\n            if file.endswith('.png'):\n                files.append(file)\n                labels.append(dirname)\n    return pd.DataFrame(data={\n        'filename': files,\n        'target': labels\n    })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = get_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_gb_target = data.groupby(['target'])['filename'].agg({'count'}).reset_index().sort_values(by=['count'], ascending=False)\n\nplt.figure(figsize=(21,9))\nax = sns.barplot(x=\"target\", y='count', data=data_gb_target, order=data_gb_target['target'])\n\nfor i in ax.patches:\n    ax.annotate(f'{int(i.get_height())}', (i.get_x()+0.4, i.get_height()),\n                    ha='center', va='bottom',\n                    color= 'black')\n\nplt.title(\"Image count in each class\")\nplt.ylabel(\"Counts\")\nplt.xlabel(\"Classes\")    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_filenames = [file for file in os.listdir(f'{BASE_PATH}Test') if file.endswith('.png')]\ntest_df = pd.DataFrame({\n    'filename': test_filenames\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_H = 30\nIMG_W = 30\nIMG_C = 3\n\nBATCH_SIZE = 32\nEPOCHS = 30\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_img(img):\n  # convert the compressed string to a 3D uint8 tensor\n  img = tf.image.decode_jpeg(img, channels=IMG_C)\n  # resize the image to the desired size\n  return tf.image.resize(img, [IMG_W, IMG_H])\n\ndef process_path(file_path):\n    img = tf.io.read_file(file_path)\n    img = decode_img(img)\n    return img","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  f\"{BASE_PATH}Train\",\n  validation_split=0.25,\n  subset=\"training\",\n  seed=123,\n  image_size=(IMG_W, IMG_H),\n  batch_size=BATCH_SIZE)\n\nvalidation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  f\"{BASE_PATH}Train\",\n  validation_split=0.25,\n  subset=\"validation\",\n  seed=123,\n  image_size=(IMG_W, IMG_H),\n  batch_size=BATCH_SIZE)\n\ntest_ds = tf.data.Dataset.list_files(str(f'{BASE_PATH}Test/*.png'), shuffle=False)\ntest_ds = test_ds.map(process_path, num_parallel_calls=AUTOTUNE)\ntest_ds = test_ds.map(lambda x: tf.reshape(x, [-1, IMG_W, IMG_H, IMG_C]))\nprint(f\"Using {len(test_ds)} files for testing\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names = train_ds.class_names\nprint(len(class_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nvalidation_ds = validation_ds.cache().prefetch(buffer_size=AUTOTUNE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\n\nnormalized_train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\nnormalized_val_ds = validation_ds.map(lambda x, y: (normalization_layer(x), y))\nnormalized_test_ds = test_ds.map(lambda x: (normalization_layer(x)))\n\nimage_batch, labels_batch = next(iter(normalized_train_ds))\nfirst_image = image_batch[0]\n\n# Notice the pixels values are now in `[0,1]`.\nprint(np.min(first_image), np.max(first_image))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    \n    data_augmentation = tf.keras.Sequential([\n        tf.keras.layers.experimental.preprocessing.RandomRotation(0.1)\n    ])\n    \n    tf.keras.backend.clear_session()\n    if tf.keras.backend.image_data_format() == 'channels_first':\n        input_shape = (IMG_C, IMG_W, IMG_H)\n    else:\n        input_shape = (IMG_W, IMG_H, IMG_C)\n    inputs = Input(shape=input_shape)\n\n    x = data_augmentation(inputs)\n    \n    x = Conv2D(32, (5,5), activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(32, (5,5), activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D(pool_size=(2,2), strides=(2,2))(x)\n    x = Dropout(.25)(x)\n\n    x = Conv2D(64, (3,3), activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(64, (3,3), activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D(pool_size=(2,2), strides=(2,2))(x)\n    x = Dropout(.25)(x)\n\n    x = Conv2D(128, (3,3), activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(128, (3,3), activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D(pool_size=(2,2), strides=(2,2))(x)\n    x = Dropout(.25)(x)\n    \n\n    x = Flatten()(x)\n    x = Dense(128, activation='relu')(x)\n    x = Dropout(.3)(x)\n\n    outputs = Dense(len(class_names), activation='softmax')(x)\n\n    tf.keras.backend.clear_session()\n    cmodel = Model(inputs, outputs)\n    cmodel.summary()\n    \n    return cmodel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = create_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\nes = EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=5,\n                              verbose=0, mode='auto')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adamax', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\ncallbacks_list = [es, lr_reduction]\n\nhistory = model.fit(\n                      normalized_train_ds,\n                      validation_data=normalized_val_ds,\n                      epochs=EPOCHS,\n                      callbacks=callbacks_list,\n                      shuffle=True\n                    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(normalized_train_ds), model.evaluate(normalized_val_ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_val_org = []\nfor i,kk in normalized_val_ds:\n    y_val_org.extend(kk.numpy())\n\ny_val_org = np.array(y_val_org)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(y_val_org)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ypred_val = model.predict(normalized_val_ds)\nypred_val = np.argmax(ypred_val, axis=1)\n\ncf_matrix = confusion_matrix(y_val_org, ypred_val)\n\nplt.figure(figsize=(20,8))\nax = sns.heatmap(cf_matrix, annot=True, fmt='g')\nplt.show()\n\nprint(\"\\n\\n\")\nprint(classification_report(y_val_org, ypred_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = model.predict(normalized_test_ds)\nresults = np.argmax(results,axis = 1)\n\ntest_df['label'] = results\ntest_df.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}