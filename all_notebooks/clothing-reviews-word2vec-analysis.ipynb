{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Word2Vec practice with Clothing review Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's first import all the necessary libraries and read our datafile","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport spacy\nimport re\nfrom time import time","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df = pd.read_csv('../input/womens-ecommerce-clothing-reviews/Womens Clothing E-Commerce Reviews.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df = df[['Title', 'Review Text']] #I only want to use the text based values, so I modify the dataframe\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.isnull().sum() #finding the null values","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df = df.dropna().reset_index(drop=True) #and dropping them \ndf.isnull().sum() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's load Spacy for to lemmatize and clean our text (this will not work with dirtier, more unruly data).","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\", disable=['ner', 'parser'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def cleaning(doc): #the lemmatizing function\n    txt = [token.lemma_ for token in doc if not token.is_stop]\n    if len(txt) > 2:\n        return ' '.join(txt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in df['Review Text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"t = time()\n\ntxt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_threads=-1)]\n\nprint('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_clean = pd.DataFrame({'clean': txt})\ndf_clean = df_clean.dropna().drop_duplicates()\ndf_clean.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And this will be the final clean text data we are going to be wokring with.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"df_clean.head() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And finally importing the Word2Vec model","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"import gensim \nfrom gensim.models import Word2Vec","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sent = [row.split() for row in df_clean['clean']] #splitting the columns into the correct format","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(sent[:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training the model:","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"t = time()\n\nmodel = Word2Vec(sent, min_count=1,size= 50,workers=3, window =3, sg = 1)\n\nprint('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Finally we are able to get some insights out of our model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Most smilar words:","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"model.wv.most_similar(positive=[\"dress\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model.wv.most_similar(positive=[\"jumper\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model.wv.most_similar(positive=[\"skirt\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model.wv.most_similar(positive=[\"favorite\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model.wv.most_similar(positive=[\"favourite\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How similar are two words?","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"model.wv.similarity(\"little\", 'petite')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model.wv.similarity(\"pencil\", 'skirt')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Which one doesn't fit?","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"model.wv.doesnt_match(['skirt', 'dress', 'book'])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}