{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Exploring Goodreads Data","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport nltk\nimport urllib.request\nfrom PIL import Image\nfrom io import BytesIO\nfrom nltk.corpus import stopwords\nfrom re import sub, match\nfrom wordcloud import WordCloud, ImageColorGenerator\nfrom random import shuffle\nfrom matplotlib import rcParams\n\nrcParams.update({'figure.autolayout': True})\n\nbooks = pd.read_csv(\"../input/goodreads-books/goodreads_books.csv\")\nbooks.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ## Correlation Matrix\nBuild a simple correlation matrix to examine relationships between features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = books.corr()\nfig, ax = plt.subplots(figsize=(12,10))\nsn.heatmap(corr_matrix)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Encode genres with over 1000 occurances\nReformat the array-based genre structure into many vote based columns. For example, the genre array {fiction 123, sci-fi 70, romance 12} becomes seperate columns: fiction: 123, sci-fi: 70, romance: 12, and any genres listed by other books but not this one: 0. ","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def populate_genre_cols(books, genre):\n    book_genres = books[\"genre_and_votes\"]\n    if type(book_genres) == type(float('nan')):\n        return None\n    genre_list = book_genres.split(\",\")\n    for i in genre_list:\n        if genre == \" \".join(i.split()[:-1]):\n            return int(i.split()[-1].replace(\"user\", \"\"))\n    return None\n        \ngenre_count = {}\n\nfor i in books[\"genre_and_votes\"]:\n    if type(i) != type(float('nan')):\n        book_genres = [\" \".join(j.split()[:-1]) for j in i.split(\",\")]\n        for j in book_genres:\n            if j not in genre_count.keys():\n                genre_count[j] = 1\n            else:\n                genre_count[j] += 1\n                \ngenres_to_use = set()\n\nfor k, v in genre_count.items():\n    if v >= 1000:\n        genres_to_use.add(k)\n\nfor i in genres_to_use:\n    books[i.lower().replace(\" \", \"_\")] = books.apply(populate_genre_cols, genre=i, axis=1)\n\nprint(\"Percentage of books with specific genre listed\")\nfor i in genres_to_use:\n    i = i.lower().replace(\" \", \"_\")\n    print(f\"{i}: {round(books[i].notna().sum() / books.shape[0] * 100, 2)}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Graph genre distribution\nDisplay mean, median, and sum of genre votes, along with distribution of books tagged with an individual genre.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"base_colors = [\"indianred\", \"red\", \"orangered\", \"chocolate\", \"saddlebrown\",\n          \"orange\", \"gold\", \"yellow\", \"yellowgreen\", \"greenyellow\", \"limegreen\",\n          \"mediumseagreen\", \"mediumaquamarine\", \"turquoise\", \"deepskyblue\", \"dodgerblue\",\n          \"royalblue\", \"darkblue\", \"mediumpurple\", \"darkviolet\", \"purple\", \"mediumvioletred\",\n          \"crimson\"]\n\ngenre_df = books[[i.lower().replace(\" \", \"_\") for i in genres_to_use]]\nunique_genres = genre_df.columns\nshuffle(base_colors)\nfig, ax = plt.subplots(4, figsize=(18,32))\n\nmean_genres = genre_df.mean().tolist()\nsorted_mean_genres = mean_genres.copy()\nsorted_mean_genres.sort()\nsorted_mean_genres.reverse()\nsorted_mean_genre_str = [None for i in range(len(sorted_mean_genres))]\nfor i in range(len(sorted_mean_genres)):\n    sorted_mean_genre_str[i] = unique_genres[mean_genres.index(sorted_mean_genres[i])]\nax[0].bar(sorted_mean_genre_str, sorted_mean_genres, color = base_colors)\nax[0].set_title(\"Mean genre votes\")\nax[0].tick_params(labelrotation=90)\n\nshuffle(base_colors)\nmedian_genres = genre_df.median().tolist()\nsorted_median_genres = median_genres.copy()\nsorted_median_genres.sort()\nsorted_median_genres.reverse()\nsorted_median_genre_str = [None for i in range(len(sorted_median_genres))]\nfor i in range(len(sorted_median_genres)):\n    sorted_median_genre_str[i] = unique_genres[median_genres.index(sorted_median_genres[i])]\nax[1].bar(sorted_median_genre_str, sorted_median_genres, color = base_colors)\nax[1].set_title(\"Median genre votes\")\nax[1].tick_params(labelrotation=90)\n\nshuffle(base_colors)\nsum_genres = genre_df.sum().tolist()\nsorted_sum_genres = sum_genres.copy()\nsorted_sum_genres.sort()\nsorted_sum_genres.reverse()\nsorted_sum_genres_str = [None for i in range(len(sorted_sum_genres))]\nfor i in range(len(sorted_sum_genres)):\n    sorted_sum_genres_str[i] = unique_genres[sum_genres.index(sorted_sum_genres[i])]\nax[2].bar(sorted_sum_genres_str, sorted_sum_genres, color = base_colors)\nax[2].set_title(\"Sum of genre votes\")\nax[2].tick_params(labelrotation=90)\n\nshuffle(base_colors)\npresent_genres = genre_df[genre_df != 0].count().tolist()\nsorted_present_genres = present_genres.copy()\nsorted_present_genres.sort()\nsorted_present_genres.reverse()\nsorted_present_genres_str = [None for i in range(len(sorted_present_genres))]\nfor i in range(len(sorted_present_genres)):\n    sorted_present_genres_str[i] = unique_genres[present_genres.index(sorted_present_genres[i])]\nax[3].bar(sorted_present_genres_str, sorted_present_genres, color = base_colors)\nax[3].set_title(\"Number of books with labeled genre\")\nax[3].tick_params(labelrotation=90)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Book Description Word Cloud\nBuild a word cloud using frequencey of words used in books' descriptions.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sw = stopwords.words('english')\nwords = []\n\nfor text in books[\"description\"]:\n    if type(text) == type(float(\"nan\")):\n        continue\n    text = text.lower()\n    text = sub(r'\\[.*?\\]', '', text)\n    text = sub(r'([.!,?])', r' \\1 ', text)\n    text = sub(r'[^a-zA-Z.,!?]+', r' ', text)\n    text = [i for i in text.split() if i not in sw]\n    for word in text:\n        words.append(word)\n\nword_freq = nltk.FreqDist([i for i in words if len(i) > 2])\n# plt.figure(figsize=(16, 6))\n# word_freq.plot(50)\n\nbook_img = 'https://www.pinclipart.com/picdir/middle/365-3651885_book-black-and-white-png-peoplesoft-learn-peoplesoft.png'\nwith urllib.request.urlopen(book_img) as url:\n    f = BytesIO(url.read())\nimg = Image.open(f)\n\nmask = np.array(img)\nimg_color = ImageColorGenerator(mask)\n\nwc = WordCloud(background_color='white',\n              mask=mask,\n              max_font_size=2000,\n              max_words=2000,\n              random_state=42)\nwcloud = wc.generate_from_frequencies(word_freq)\nplt.figure(figsize=(16, 10))\nplt.axis('off')\nplt.imshow(wc.recolor(color_func=img_color), interpolation=\"bilinear\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Average Rating Distribution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.gcf()\nfig.set_size_inches(18.5, 10.5)\nn, bins, patches = plt.hist(books['average_rating'], bins=100, facecolor='#2ab0ff', edgecolor='#e0e0e0', linewidth=0.5, alpha=0.7)\nn = n.astype('int') # it MUST be integer\nfor i in range(len(patches)):\n    patches[i].set_facecolor(plt.cm.viridis(n[i]/max(n)))\nplt.title('Average Rating Distribution', fontsize=20)\nplt.xlabel('Average Rating', fontsize=14)\nplt.ylabel('Count', fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Year Published Distribution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def parse_year(date):\n    if type(date) == type(float(\"nan\")):\n        return\n    year_check = match(r'.*([1-3][0-9]{3})', date)\n    if year_check != None:\n        return int(year_check.group(1))\n\nbooks['year_published'] = books[\"date_published\"].apply(parse_year)\nfig, ax = plt.subplots(1,1)\nfig.set_size_inches(18.5, 10.5)\nax.tick_params(labelrotation=90)\nn, bins, patches = ax.hist(books['year_published'].dropna(inplace=False), bins=250, facecolor='#2ab0ff', edgecolor='#e0e0e0', linewidth=0.5, alpha=0.7)\nn = n.astype('int') # it MUST be integer\nfor i in range(len(patches)):\n    patches[i].set_facecolor(plt.cm.viridis(n[i]/max(n)))\n\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}