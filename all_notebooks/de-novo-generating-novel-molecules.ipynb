{"cells":[{"metadata":{},"cell_type":"markdown","source":"Simplified Molecular Input Line Entry System (SMILES) representation"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!conda install -c rdkit rdkit -y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.listdir(\"../input/smiles-toxicity/data/data/NR-ER-train\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"import pandas as pd\nfilename = \"../input/smiles-toxicity/data/data/NR-ER-train/names_smiles.csv\"\nnames = ['id', 'sequence']\n\ndata_df = pd.read_csv(filename, names = names)\n\nraw_text = '\\n'.join(data_df['sequence'].tolist())\n\nprint(raw_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfilenamey = \"../input/smiles-toxicity/data/data/NR-ER-train/names_labels.csv\"\nnames = ['id', 'label']\n\ndata_dfy = pd.read_csv(filenamey, names = names)['label']\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dfy.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"from rdkit import Chem\nm = Chem.MolFromSmiles('CCC1=NC=CN=C1C')\nm\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"import rdkit\nfrom rdkit import Chem\nfrom rdkit.Chem.Draw import IPythonConsole\nfrom rdkit.Chem import Draw\nimport matplotlib.pyplot as plt\n\n# Chem.MolFromSmiles('c1ccccccccccc1')\n#m = Chem.MolFromSmiles('c1ccccccccccc1')\n#Draw.MolToMPL(d, size=(200, 200))\n#m = Chem.MolFromSmiles('C1=C2C(=CC(=C1Cl)Cl)OC3=CC(=C(C=C3O2)Cl)Cl')\nx = 'O1C=C[C@H]([C@H]1O2)c3c2cc(OC)c4c3OC(=O)C5=C4CCC(=O)5'\nm = Chem.MolFromSmiles(x)\nDraw.MolToMPL(m, size=(100, 100))\n\n#m","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"unique_chars = sorted(list(set(raw_text)))\nchar_to_int = dict((c, i) for i, c in enumerate(unique_chars))\n#char_to_int.update({-1 : \"\\n\"})\nchar_to_int","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_chars = len(raw_text)\nn_vocab = len(unique_chars)\nprint(\"Total Characters: \", n_chars)\nprint(\"Total Vocab: \", n_vocab)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prepare the dataset of input to output pairs encoded as integers\nseq_length = 100\ndataX = []\ndataY = []\nfor i in range(0, n_chars - seq_length, 1):\n   seq_in = raw_text[i:i + seq_length]\n   seq_out = raw_text[i + seq_length]\n   dataX.append([char_to_int[char] for char in seq_in])\n   dataY.append(char_to_int[seq_out])\nn_patterns = len(dataX)\nprint(\"Total Patterns: \", n_patterns) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom keras.utils import np_utils\n# reshape X to be [samples, time steps, features]\nX = np.reshape(dataX, (n_patterns, seq_length, 1))\n# normalize\nX=X/ float(n_vocab)\n# one hot encode the output variable\ny = np_utils.to_categorical(dataY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(y) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import LSTM\nfrom keras.callbacks import ModelCheckpoint\n# define the LSTM model\nmodel = Sequential()\nmodel.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(y.shape[1], activation= 'softmax' ))\nmodel.compile(loss= 'categorical_crossentropy' , optimizer= 'adam', metrics = ['accuracy'])\n# define the checkpoint\nfilepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor= 'loss' , verbose=1, save_best_only=True,\nmode= 'min' )\ncallbacks_list = [checkpoint]\n# fit the model\nmodel.fit(X, y, epochs=5, batch_size=1000, callbacks=callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"int_to_char = dict((i, c) for i, c in enumerate(unique_chars))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport sys\nfrom keras.models import load_model\n# load the network weights\nfilename = \"weights-improvement-05-1.7667.hdf5\"\nmodel.load_weights(filename)\nmodel.compile(loss= 'categorical_crossentropy' , optimizer= 'adam' )\n# pick a random seed\nstart = np.random.randint(0, len(dataX)-1)\npattern = dataX[start]\nprint(\"Seed:\")\nprint(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\") \n# generate characters\nfor i in range(1000):\n  x = np.reshape(pattern, (1, len(pattern), 1))\n  x=x/ float(n_vocab)\n  prediction = model.predict(x, verbose=0)\n  index = np.argmax(prediction)\n  result = int_to_char[index]\n  seq_in = [int_to_char[value] for value in pattern]\n  sys.stdout.write(result)\n  pattern.append(index)\n  pattern = pattern[1:len(pattern)]\nprint(\"\\nDone.\") ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}