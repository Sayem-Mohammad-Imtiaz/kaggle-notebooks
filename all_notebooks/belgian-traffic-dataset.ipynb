{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Install tf 2.0 preview GPU version\n!pip install tensorflow-gpu==2.0.0-beta1 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Common Imports\nimport os                                   # For os commands (dir cwd etc)\nimport zipfile                              # for extracting data set files\n                                 \nimport skimage                              # for scikit-learn image operations\nfrom matplotlib import pyplot as plt        # for visualizing data\nimport numpy as np                          # for numerical python\nimport random                               # for random sampling in range(),number_of_values\n\nimport tensorflow as tf\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tf.test.gpu_device_name())\nprint(tf.version)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**CHANGE WORKING DIRECTORY TO UPLOADED FILES**\n\n---"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.getcwd())\nprint(os.listdir('../'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATASET_PATH = \"../input/belgiumts-dataset/\"\nos.chdir(DATASET_PATH)\nprint(os.getcwd())\nprint(os.listdir())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading Data into Python"},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_images(data_directory):\n  \n  # lists to store Images and labels\n  images = []\n  labels = []\n  log_index = 0\n  # get list of all directories present in the data_directory path\n  directories = [dir for dir in os.listdir(data_directory)\n                 if os.path.isdir(os.path.join(data_directory,dir))] # to make sure that we include only directories and not any files present in the folder\n  print(len(directories))\n  for dir in directories:\n    current_directory = os.path.join(data_directory,dir)\n    # Gather all fileNames in the given directory to load images into images array using sklearn\n    file_names = [os.path.join(current_directory,file) \n                  for file in os.listdir(current_directory)\n                  if file.endswith('.ppm')\n                 ]\n    \n    # Load all given Images into the Images array\n    for file in file_names:\n      images.append(skimage.data.imread(file))\n      labels.append(int(dir))\n      log_index+=1\n      # print('Loading File: {0}'.format(log_index))\n  print('Successfully Loadded  {0} images!'.format(len(images)))\n  return np.array(images),np.array(labels)\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LOAD IMAGES \n  \nROOT_PATH = os.getcwd()  \nTRAININ_DATA_PATH = ROOT_PATH + '/BelgiumTSC_Training/Training'  \nTEST_DATA_PATH = ROOT_PATH + '/BelgiumTSC_Testing/Testing'\n  \ntraining_images, training_labels = load_images(TRAININ_DATA_PATH)\nprint('Training Data Sucessfully Loaded!!')\ntesting_images,testing_labels = load_images(TEST_DATA_PATH)\nprint('Test data sucessfully loaded!!')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**To Verify and get some facts about our Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"index = 1                          # Replace the index to check out the shape of input images\nprint('Dimension of Image at index ' + str(index) + ':', training_images[index].shape)  \nprint('Number of training Images :' , training_images.size)\nprint('Number of Dimensions of Images array : ',training_images.ndim)                 # ndims - number of dimensions for np array images\n\nprint('Dimensions for labels :', training_labels.shape)\nprint('Label for Image at index ' + str(index) +': ',training_labels[index])\nprint('Number of Classes : ',len(set(training_labels)))\n\nprint('Some additional tidbits about the memory requirements of data ')\nprint('Size of an individual image: ' ,training_images.itemsize)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lets split these into 2 sets Validation and testing  with approx 1500 images for validation and 2000 for testing \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def transform_images(images,height,width):\n  transformed_images = [skimage.transform.resize(image,(height,width)) for image in images]\n  return  np.array(transformed_images)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### TEST FOR STRATIFIED SPLIT "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(training_images[0].shape)\nprint(training_images.size)\nfull_data = np.append(training_images,testing_images)\nfull_labels = np.append(training_labels,testing_labels)\nprint('Collated Image Data size :',full_data.shape)\nprint('Collated Image Labels size :',full_labels.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Remove Data for classes with unknown labels\n##idx = [index for index in range(len(full_labels)) if full_labels[index] != 42  if full_labels[index] != 43  if full_labels[index] != 55 ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##print('Filtered Data Lenght:',len(idx))\n##print('Full Data Length :',len(full_data))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"44 + 36 + 27 = 107 \n\n7095(Total - 107 (class 42 ,43 and 55)\n\nNow dataset doesn't have classes without labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nfull_data = full_data[idx]\nfull_labels = full_labels[idx]\n#full_labels = [label-2 for label in full_labels if  55 > label > 43]\n#full_labels = [label-1 for label in full_labels if   label > 55]\ntemp = []\nfor label in full_labels:\n    if label < 55 and label > 43 :\n        temp.append(label - 2)\n    elif label > 55 :\n        temp.append(label - 1)\n    else :\n        temp.append(label)\n\nfull_labels = np.array(temp)\nprint(full_data.size)\nprint(full_labels.size)\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images_split,test_images_split,train_labels_split,test_labels_split = train_test_split(full_data,full_labels,stratify = full_labels,test_size = 0.2)\nprint('Train Image Split dims: ',train_images_split.size)\nprint('Train Labels Split dims: ',train_labels_split.size)\nprint('Test Image Split dims: ',test_images_split.size)\nprint('Test Labels Split dims: ',test_labels_split.size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Further split training data for Validation data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images_split,val_images_split,train_labels_split,val_labels_split = train_test_split(train_images_split,train_labels_split,stratify = train_labels_split,test_size = 0.2)\nprint('Train Image Split dims: ',train_images_split.size)\nprint('Train Labels Split dims: ',train_labels_split.size)\nprint('Test Image Split dims: ',val_images_split.size)\nprint('Test Labels Split dims: ',val_labels_split.size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_split_images = transform_images(train_images_split,128,128)\ntest_split_images = transform_images(test_images_split,128,128)\nval_split_images = transform_images(val_images_split,128,128)\n\nprint('Finished Trasforming Images for Train,Test and Validation Sets')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we have our basic image sets ready. All we need to do is Transform them to appropriate sizes before trying out the model.\n\nTraining Set (128x128)--  train_split_images , train_labels_split  \n\nTesting Set  --  test_split_images, test_labels_split\n\nValidation Set --  val_split_images,val_labels_split"},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_images_of_all_classes(train_images,training_labels):\n  num_cols =  8\n  classes = len(set(training_labels))\n  if classes % num_cols == 0:\n      num_rows =  classes / num_cols\n  else:\n      num_rows = int(classes / num_cols) + 1\n  plt.figure(figsize=(15,15))\n  i = 1\n  for class_number in set(training_labels):\n    \n    indices = np.where(training_labels == class_number)\n    plt.subplot(num_rows,num_cols, i)\n    i += 1\n    plt.axis('off')\n    plt.imshow(train_images[indices[0][1]])\n    plt.title('Class :{0} [{1}] '.format(class_number,len(indices[0])))   #np.count_nonzero(labels == labels[index])))\n  plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(set(full_labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_images_of_all_classes(full_data,full_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### FINAL LABELS DICTIONARY"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a dictionary with Class Names\nclassnames = {\n              0 : 'Warning for a bad road surface',\n              1 : 'Warning for a speed bump',\n              2 : 'Warning for a slippery road surface',\n              3 : 'Warning for a curve to the left',\n              4 : 'Warning for a curve to the right',\n              5 : 'Warning for a double curve, first left then right',                                                    # Merge Classes 5 & 6 later\n              6 : 'Warning for a double curve, first left then right',\n              7 : 'Watch out for children ahead',\n              8 : 'Watch out for  cyclists',\n              9 : 'Watch out for cattle on the road',\n              10: 'Watch out for roadwork ahead',\n              11: 'Traffic light ahead',\n              12: 'Watch out for railroad crossing with barriers ahead',\n              13: 'Watch out ahead for unknown danger',\n              14: 'Warning for a road narrowing',\n              15: 'Warning for a road narrowing on the left',\n              16: 'Warning for a road narrowing on the right',\n              17: 'Warning for side road on the right',\n              18: 'Warning for an uncontrolled crossroad',\n              19: 'Give way to all drivers',\n              20: 'Road narrowing, give way to oncoming drivers',\n              21: 'Stop and give way to all drivers',\n              22: 'Entry prohibited (road with one-way traffic)',\n              23: 'Cyclists prohibited',\n              24: 'Vehicles heavier than indicated prohibited',\n              25: 'Trucks prohibited',\n              26: 'Vehicles wider than indicated prohibited',\n              27: 'Vehicles higher than indicated prohibited',\n              28: 'Entry prohibited',\n              29: 'Turning left prohibited',\n              30: 'Turning right prohibited',\n              31: 'Overtaking prohibited',\n              32: 'Driving faster than indicated prohibited (speed limit)',\n              33: 'Mandatory shared path for pedestrians and cyclists',\n              34: 'Driving straight ahead mandatory',\n              35: 'Mandatory left',\n              36: 'Driving straight ahead or turning right mandatory',\n              37: 'Mandatory direction of the roundabout',\n              38: 'Mandatory path for cyclists',\n              39: 'Mandatory divided path for pedestrians and cyclists',\n              40: 'Parking prohibited',\n              41: 'Parking and stopping prohibited',\n              42: '',\n              43: '',\n              44: 'Road narrowing, oncoming drivers have to give way',\n              45: 'Parking is allowed',\n              46: 'parking for handicapped',\n              47: 'Parking for motor cars',\n              48: 'Parking for goods vehicles',\n              49: 'Parking for buses',\n              50: 'Parking only allowed on the sidewalk',\n              51: 'Begin of a residential area',\n              52: 'End of the residential area',\n              53: 'Road with one-way traffic',\n              54: 'Dead end street',\n              55: '', \n              56: 'Crossing for pedestrians',\n              57: 'Crossing for cyclists',\n              58: 'Parking exit',\n              59: 'Information Sign : Speed bump',\n              60: 'End of the priority road',\n              61: 'Begin of a priority road'\n    }","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Image Augmentation\n\nKeras provides a handy api to do various operations on our input images before passing them to the model.\nThese changes range from cropping the image to flipping it and even providing shearing effects......\n\nSo Let's look at how it looks in action:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training Data Generator\n\ntraining_datagen = tf.keras.preprocessing.image.ImageDataGenerator(zoom_range=0.2,width_shift_range=0.3,height_shift_range=0.2,shear_range=0.25,fill_mode='nearest')\n\nvalidation_datagen = tf.keras.preprocessing.image.ImageDataGenerator()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ready our generators for passing into models \ntrain_generator = training_datagen.flow(train_split_images,train_labels_split,batch_size=32)\n\nvalidation_generator = validation_datagen.flow(val_split_images,val_labels_split,batch_size=32)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A little test\n# try and visualize your images\n\nnyan_generator = training_datagen.flow(train_split_images[1:2], train_labels_split[1:2],batch_size=1)\n\nsign = [next(nyan_generator) for i in range(0,10)]\nfig, ax = plt.subplots(1,10, figsize=(16, 6))\nprint('Labels:', [item[1][0] for item in sign])\nl = [ax[i].imshow(sign[i][0][0]) for i in range(0,10)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define Convolutional Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"def conv_net(train_images_dims,num_of_classes,filter_size = 2,num_convolutions=64,num_strides=2):\n  # pre process image dimensions\n  if (len(train_images_dims) == 3):    # Channel Last\n    train_images_dims = (train_images_dims[1],train_images_dims[2])   \n  elif (len(train_images_dims) == 4):\n    train_images_dims = (train_images_dims[1],train_images_dims[2],train_images_dims[3])\n  \n  model  = tf.keras.Sequential()\n  \n  #Conv1\n  model.add(tf.keras.layers.Conv2D(int(num_convolutions),(filter_size,filter_size),activation='relu',input_shape= train_images_dims))\n  model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=num_strides))\n    \n  #Conv2\n  model.add(tf.keras.layers.Conv2D(int(num_convolutions),(filter_size,filter_size),activation='relu'))\n  model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=num_strides))\n\n  #Conv3\n  model.add(tf.keras.layers.Conv2D(int(num_convolutions),(filter_size,filter_size),activation='relu'))\n  model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=num_strides))\n    \n  #Conv4\n  model.add(tf.keras.layers.Conv2D(int(num_convolutions),(filter_size,filter_size),activation='relu'))\n  model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=num_strides))\n\n  #Conv5\n  model.add(tf.keras.layers.Conv2D(int(num_convolutions) ,(filter_size,filter_size),activation='relu'))\n  model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=num_strides))\n  \n  #Flatten and add Dense Layer\n  model.add(tf.keras.layers.Flatten())\n  #Dense 1\n  model.add(tf.keras.layers.Dense(512,activation='relu'))\n  model.add(tf.keras.layers.Dropout(0.5))\n  #Dense 2\n  model.add(tf.keras.layers.Dense(512,activation='relu'))\n  model.add(tf.keras.layers.Dropout(0.5))\n  \n  #Output Layer\n  model.add(tf.keras.layers.Dense(num_of_classes,activation = 'softmax'))\n  return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define Callback"},{"metadata":{"trusted":true},"cell_type":"code","source":"monitor = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',patience = 8,restore_best_weights = True, min_delta = 0.01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_regularized = conv_net(train_split_images.shape,len(set(train_labels_split)),filter_size=2,num_convolutions=512)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_regularized.compile(optimizer=tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy',metrics = ['accuracy'])\nmodel_regularized.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" about 32 "},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model_regularized.fit_generator(train_generator, validation_data=validation_generator,steps_per_epoch=(len(train_split_images) / 32),epochs = 52,verbose=1,callbacks=[monitor])  # 32 = batch size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualize the losses"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get training and test loss histories\ntraining_loss = history.history['loss']\nvalidation_loss = history.history['val_loss']\n\n# Create count of the number of epochs\nepoch_count = range(1, len(training_loss) + 1)\n\n# Visualize loss history\nplt.plot(epoch_count, training_loss, 'r--')\nplt.plot(epoch_count, validation_loss, 'b-')\nplt.legend(['Training Loss', 'Validation Loss'])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#history = model_regularized.fit_generator(train_generator, validation_data=validation_generator,steps_per_epoch=(len(training_images128) / 32),epochs = 30,verbose=1)  # 32 = batch size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get training and test loss histories\ntraining_loss = history.history['loss']\ntest_loss = history.history['val_loss']\n\n# Create count of the number of epochs\nepoch_count = range(1, len(training_loss) + 1)\n\n# Visualize loss history\nplt.plot(epoch_count, training_loss, 'r--')\nplt.plot(epoch_count, test_loss, 'b-')\nplt.legend(['Training Loss', 'Validation Loss'])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"indexes = []\nfor label in set(test_labels_split):\n        indexes.append(np.where(test_labels_split == label)[0])\n   \n#indexes = [ind[0][0] for ind in indexes]\nprint(len(indexes))\nid  = []\nfor i in indexes:\n    id.append(i.flat[0])\n\nclass_wise_test_img = test_split_images[id]\nclass_wise_test_labels = test_labels_split[id]\nprint(class_wise_test_img.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_regularized.evaluate(test_split_images,test_labels_split)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Class wise image test\nmodel_regularized.evaluate(class_wise_test_img,class_wise_test_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,img in enumerate(class_wise_test_img):\n     show_img = img\n     img_arr = np.expand_dims(img,axis=0) # to add new dimension to meet required input dims\n\n     classes = model_regularized.predict(img_arr)\n\n     plt.imshow(img)\n     #plt.axis('off')\n     plt.show()\n     predicted_class = np.argmax(classes)\n     print('PREDICTION : The Image belongs to class : {}, with description : {}'.format(predicted_class,classnames[predicted_class]))\n     print('ACTUAL : The Image belongs to class : {}, with description : {}'.format(class_wise_test_labels[i],classnames[class_wise_test_labels[i]]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing Custom Images"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_image(model,directory):\n    for file_name in os.listdir(directory):\n        if '.jpg' in file_name or '.png' in file_name:\n            img = tf.keras.preprocessing.image.load_img(os.path.join(directory,file_name),target_size = (128,128))  # Defaults to rgb mode and returns a PIL Instance\n            \n            img_arr = tf.keras.preprocessing.image.img_to_array(img) # returns 3d numpy array\n            show_img = img_arr\n            img_arr = np.expand_dims(img_arr,axis=0) # to add new dimension to meet required input dims\n            \n            classes = model.predict(img_arr)\n            \n            plt.imshow(img)\n            #plt.axis('off')\n            plt.show()\n            predicted_class = np.argmax(classes)\n            print('The Image belongs to class : {}, with description : {}'.format(predicted_class,classnames[predicted_class]))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(os.listdir('../'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_image(model_regularized,'../belgium-new-test-images')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Change directory to working to save the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir(r'../../working')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SAVE THE MODEL AS H5 File\nmodel_regularized.save('final_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Try out tensorflow saved model to save the model\ntf.saved_model.save(model_regularized,'model_regularized_tf2')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Trying  out tensorflow js for the model to serve using javascript"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tensorflowjs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir('../../working'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflowjs as tfjs\ntfjs.converters.save_keras_model(model_regularized, \"model_js\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'final_model.h5')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}