{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np\nimport pandas as pd \nimport nltk\nfrom nltk.stem import PorterStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nimport seaborn as sns\nfrom nltk.corpus import stopwords\nimport plotly.graph_objs as go\nfrom plotly import tools\nfrom nltk.stem import PorterStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nimport random\nfrom sklearn.metrics import f1_score, roc_auc_score\nfrom sklearn.pipeline import make_pipeline\nimport plotly.offline as py\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.figure_factory as ff\ndef random_colors(number_of_colors):\n    color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n                 for i in range(number_of_colors)]\n    return color\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport re, os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/twitter-hate-speech/train_E6oV3lV.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.groupby('label').describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['length'] = train['tweet'].apply(len)\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_Class = pd.value_counts(train.label, sort = True)\n\n# Data to Plot\nlabels = '0', '1'\nsizes = [count_Class[0], count_Class[1]]\ncolors = ['red', 'skyblue']\nexplode = (0.1, 0.1)\n\n# Plot\nplt.pie(sizes, explode = explode, labels = labels, colors = colors,\n        autopct = '%1.1f%%', shadow = True, startangle = 90)\nplt.axis('equal')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"species_count = train['label'].value_counts()\ndata = [go.Bar(\n    x = species_count.index,\n    y = species_count.values,\n    marker = dict(color = random_colors(3))\n)]\npy.iplot(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['cleaned_tweet'] = train.tweet.apply(lambda x: ' '.join([word for word in x.split() if not word.startswith('@')]))\ntrain['hashtags'] = train.tweet.apply(lambda x: ' '.join([word[1:] for word in x.split() if word.startswith('#')]))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Select all words from normal tweet\nnormal_words = ' '.join([word for word in train['cleaned_tweet']])\n#Collect all hashtags\npos_htag = [htag for htag in normal_words.split() if htag.startswith('#')]\n#Remove hashtag symbol (#)\npos_htag = [pos_htag[i][1:] for i in range(len(pos_htag))]\n#Count frequency of each word\npos_htag_freqcount = nltk.FreqDist(pos_htag)\npos_htag_df = pd.DataFrame({'Hashtag' : list(pos_htag_freqcount.keys()),\n                            'Count' : list(pos_htag_freqcount.values())})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Select top 20 most frequent hashtags and plot them   \nmost_frequent = pos_htag_df.nlargest(columns=\"Count\", n = 20) \nplt.figure(figsize=(16,5))\nax = sns.barplot(data=most_frequent, x= \"Hashtag\", y = \"Count\")\nax.set(ylabel = 'Count')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_text(sen):\n    sentence = re.sub('(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w \\.-]*)',' ',sen) # Removing html tags\n    sentence = re.sub('[^a-zA-Z]', ' ', sentence) # Remove punctuations and numbers\n    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence) # Single character removal\n    sentence = re.sub(r'\\s+', ' ', sentence) # Removing multiple spaces\n    sentence = sentence.replace(\"ain't\", \"am not\").replace(\"aren't\", \"are not\")\n    sentence = ' '.join(text.lower() for text in sentence.split(' ')) # Lowering cases\n    sw = stopwords.words('english')\n    sentence = ' '.join(text for text in sentence.split() if text not in sw) #removing stopwords\n    #sentence = ' '.join(text.lemmatize() for text in sentence.split()) #lemmatization\n    return sentence","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['cleaned_tweet'] = train.tweet.apply(preprocess_text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['cleaned_tweet'] = train['cleaned_tweet'].apply(nltk.word_tokenize)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stemmer = PorterStemmer()\ntrain['cleaned_tweet'] = train['cleaned_tweet'].apply(lambda x: [stemmer.stem(y) for y in x])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['cleaned_tweet']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['cleaned_tweet'] = train['cleaned_tweet'].apply(lambda x: ' '.join(x))\ncount_vect = CountVectorizer()\ncounts = count_vect.fit_transform(train['cleaned_tweet']);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer = TfidfTransformer().fit(counts)\ncounts = transformer.fit_transform(counts)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(counts, train['label'], test_size=0.3, random_state=69)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# implementing naive bayes\nNB = MultinomialNB().fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted = NB.predict(X_test)\n\nprint(np.mean(predicted == y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(y_test, predicted))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,predicted))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# implementing disession tree\n\ndt = DecisionTreeClassifier().fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted = dt.predict(X_test)\n\nprint(np.mean(predicted == y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,predicted))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(y_test, predicted))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# implementing adabost \nab = AdaBoostClassifier().fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted = ab.predict(X_test)\n\nprint(np.mean(predicted == y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,predicted))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(y_test, predicted))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}