{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"'''\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/working'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n'''","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"RANDOM_SEED_CONSTANT = 42  # FOR_REPRODUCIBILITY\n\nimport os\nos.environ['PYTHONHASHSEED']=str(RANDOM_SEED_CONSTANT)\n####*IMPORANT*: Have to do this line *before* importing tensorflow\n\nimport tensorflow   \ntensorflow.random.set_seed(RANDOM_SEED_CONSTANT)\n\nimport numpy as np\nnp.random.seed(RANDOM_SEED_CONSTANT)\n\nimport random\nrandom.seed(RANDOM_SEED_CONSTANT)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras\nprint(tensorflow.__version__)\nprint(keras.__version__)\n\nfrom keras.models import load_model\n\n# Prevent NHWC errors\n#https://www.nuomiphp.com/eplan/en/50125.html\nfrom tensorflow.keras import backend as K\n\nif K.image_data_format()=='channels_first':\n    K.set_image_data_format('channels_last')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import load_model\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nfrom sklearn.metrics import confusion_matrix, f1_score\nfrom sklearn.metrics import roc_auc_score, balanced_accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_binaryclassif_perf(labels, predictions, p=0.5, verbose=True):\n\n    #labels      = np.concatenate([y for x, y in ds], axis=0).flatten()\n    #labels      = labels.astype('int32')\n    #predictions = model.predict(ds).flatten()\n\n    assert(labels.shape==predictions.shape)\n    assert(type(labels)==type(predictions))\n    \n    cm = confusion_matrix(labels, predictions > p)\n    \n    predictions = (predictions > p).astype('int32')\n    assert(labels.dtype==predictions.dtype)\n        \n    plt.figure(figsize=(5,5))\n    sns.heatmap(cm, annot=True, fmt=\"d\")\n    plt.title('Confusion matrix @{:.2f}'.format(p))\n    plt.ylabel('Actual label')\n    plt.xlabel('Predicted label')\n\n    tn, fp, fn, tp  = cm.ravel()\n    \n    if verbose:\n        print('True Negatives\\t: ',  tn)\n        print('False Positives\\t: ', fp)\n        print('False Negatives\\t: ', fn)\n        print('True Positives\\t: ',  tp)\n    \n    print('Accuracy\\t= {}'.format(accuracy_score(labels, predictions)))\n    print('Precision\\t= {}'.format(precision_score(labels, predictions)))\n    print('TPR/Recall\\t= {} (a.k.a Sensitivity)'.format(recall_score(labels, predictions)))\n    print('TNR\\t\\t= {} (a.k.a Specificity)'.format((tn/(tn+fp))))\n    print('F1_score\\t= {}'.format(f1_score(labels, predictions)))\n    print('roc_auc\\t\\t = {}'.format(roc_auc_score(labels, predictions)))\n    print('Balanced acc\\t = {}'.format(balanced_accuracy_score(labels, predictions)))\n\ndef print_metrics_on(model, ds):\n    '''Dataset can be val_ds or train_ds or test_ds'''\n    ytrue_val = np.concatenate([y for x, y in ds], axis=0).flatten()\n    ytrue_val = ytrue_val.astype('int32')\n    ypred_val = model.predict(ds).flatten()\n    print_binaryclassif_perf(ytrue_val, ypred_val)\n\ndef plot_learning_history(history, filetosave=None):\n    pd.DataFrame(history.history).plot(figsize=(8,5))\n    plt.grid(True)\n    plt.gca().set_ylim(0, 1)\n    if filetosave is None:\n        plt.show()\n    else:\n        plt.savefig(filetosave)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGES_DIR    = '/kaggle/input/glasses-or-no-glasses/faces-spring-2020/faces-spring-2020/'\nPATH_TRAINCSV = '/kaggle/input/glasses-or-no-glasses/train.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, dirs, filenames in os.walk(IMAGES_DIR):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare the data by creating two directories of glass and noglass images\nDIR_IMAGES_SUBFOLDERED = '/kaggle/working/images_ord'\nos.makedirs(DIR_IMAGES_SUBFOLDERED)\nos.mkdir(os.path.join(DIR_IMAGES_SUBFOLDERED, '0'))\nos.mkdir(os.path.join(DIR_IMAGES_SUBFOLDERED, '1'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Copy all images to separate 0 and 1 class\ndf = pd.read_csv(PATH_TRAINCSV, dtype={'glasses':str})\n#print(df.head())\nfor row in df.itertuples():\n    srcimg       = 'face-{}.png'.format(row.id)\n    path_srcimg  = os.path.join(IMAGES_DIR, srcimg)\n    path_dstimg  = os.path.join(DIR_IMAGES_SUBFOLDERED, row.glasses, srcimg) \n    if not os.path.exists(path_dstimg):\n        os.symlink(path_srcimg, path_dstimg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 32 # defaults for most functions in tf2\nIMG_HEIGHT = 56\nIMG_WIDTH  = 56\n\ntrain_ds = keras.preprocessing.image_dataset_from_directory(\n            directory=DIR_IMAGES_SUBFOLDERED,\n            label_mode='binary',\n            color_mode='rgb',\n            image_size=(56, 56),\n            batch_size=BATCH_SIZE,\n            seed=RANDOM_SEED_CONSTANT,\n            validation_split=0.1,\n            subset='training')\n\nval_ds =  keras.preprocessing.image_dataset_from_directory(\n            directory=DIR_IMAGES_SUBFOLDERED,\n            label_mode='binary',\n            color_mode='rgb',\n            image_size=(56, 56),\n            batch_size=BATCH_SIZE,\n            seed=RANDOM_SEED_CONSTANT,\n            validation_split=0.1,\n            subset='validation')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_vgg16_based_cnn(BIAS_OPDENSE_LAYER=None, verbose=True):\n    \n    # To counteract the impact of imbalanced classes, we add an output bias\n    if BIAS_OPDENSE_LAYER is not None:\n        output_bias = keras.initializers.Constant(BIAS_OPDENSE_LAYER)\n    else:\n        output_bias = 'zeros'\n    \n    init_glorotuni = keras.initializers.GlorotUniform(seed=RANDOM_SEED_CONSTANT)\n        \n    model_backbone  = VGG16(weights='imagenet',\n                      include_top=False,          # Don't use the prediction part of this network. We don't need it\n                      input_shape=(56, 56, 3))\n                        \n    print('Backbone model')\n    print(model_backbone.summary())\n\n    if verbose:\n        print('No. of trainable weights before freezing the model_backbone:', len(model_backbone.trainable_weights))\n        model_backbone.trainable = False\n        print('No. of trainable weights after freezing the model_backbone:', len(model_backbone.trainable_weights))\n    \n    model = keras.models.Sequential()\n    model.add(model_backbone)\n    model.add(keras.layers.Flatten())\n    model.add(keras.layers.Dense(256, activation='relu', kernel_initializer=init_glorotuni))\n    model.add(keras.layers.Dropout(rate=0.15))\n    model.add(keras.layers.Dense(1, activation='sigmoid',kernel_initializer=init_glorotuni, \n                           bias_initializer=output_bias))\n    \n    print('Model to do transfer learning')\n    print(model.summary())\n    \n    rmsprop = keras.optimizers.RMSprop(lr=2e-5)\n    \n    # Set information about which loss function and what optimization algorithm we will use to optimize it\n    model.compile(loss='binary_crossentropy', \n                  optimizer=rmsprop, \n                  metrics=['acc', tensorflow.keras.metrics.AUC()])\n\n    print('No. of trainable tensors after compilation:', len(model.trainable_weights))\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_cnn = make_vgg16_based_cnn()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = tensorflow.keras.callbacks.EarlyStopping(\n                 monitor='val_acc', \n                 verbose=1,\n                 patience=5,\n                 mode='max',\n                 restore_best_weights=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tensorflow.config.list_physical_devices('GPU')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history =  model_cnn.fit(\n                train_ds,\n                epochs=2,\n                steps_per_epoch=10,\n                validation_data=val_ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model_cnn.save('/kaggle/working/model_cnn_trained.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_cnn.evaluate(val_ds) # These values should correspond to val_loss, val_acc and val_auc printed in epoch2 above","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot_learning_history(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_metrics_on(model_cnn, val_ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Why are preds1 and preds2 below different?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds1 = model_cnn.predict(val_ds).flatten() \nprint(preds1[0:5])\nprint(preds1[-5:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds2 = model_cnn.predict(val_ds).flatten() \nprint(preds2[0:5])\nprint(preds2[-5:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}