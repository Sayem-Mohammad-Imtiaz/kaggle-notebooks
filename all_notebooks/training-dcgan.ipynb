{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing import image\n\nimg1 = image.load_img(\"../input/celeba-dataset/img_align_celeba/img_align_celeba/000001.jpg\", target_size = (128, 128))\nimg1_arr = image.img_to_array(img1, dtype = 'int64')\nimg1_arr = np.asarray(img1_arr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img1_arr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.imshow(img1_arr)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load all the images from the dataset\n\npath = \"../input/celeba-dataset/img_align_celeba/img_align_celeba\"\ndef load_image_data(path):\n    \n    ''' Reads the images from the path and returns the images in to form of numpy array.'''\n    \n    img_folder = os.listdir(path)\n    \n    # Create an Image data list\n    img_data = []\n    \n    # Iterate over each image load it using image.load_img and then convert it using img_to_array\n    for img in img_folder[:5000]:\n        \n        # load the img\n        ith_img = image.load_img(os.path.join(path,img), target_size = (128, 128))\n        ith_img_arr = image.img_to_array(ith_img, dtype = 'int64')\n        \n        # append into the list\n        img_data.append(ith_img_arr)\n        \n    return img_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(os.listdir(path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images = load_image_data(path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot first 10 images\nplt.figure(figsize = (10, 10))\nfor i in range(10):\n    \n    plt.subplot(2, 5, i+1)\n    plt.imshow(images[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_arr = np.asarray(images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_arr = (images_arr.astype('float32') - 127.5)/127.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.max(images_arr), np.min(images_arr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_arr.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building a DCGAN"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import *\nfrom keras.models import Model, Sequential\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 50\nbatch_size = 256\nhalf_batch_size = 128\nno_of_batches = int(images_arr.shape[0]/batch_size)\nnoise_dim = 100\nadam = Adam(lr = 2e-4, beta_1 = 0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_arr.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the Generator\n\ngenerator = Sequential()\ngenerator.add(Dense(16*16*128, input_shape = (noise_dim, )))\ngenerator.add(Reshape((16,16,128)))\ngenerator.add(LeakyReLU(0.2))\ngenerator.add(BatchNormalization())\n\n# Double the activation sie 32 X 32 X 64\ngenerator.add(UpSampling2D())\ngenerator.add(Conv2D(64, kernel_size = (5,5), padding = 'same'))\ngenerator.add(LeakyReLU(0.2))\ngenerator.add(BatchNormalization())\n\n# Double the activation sie 64 X 64 X 32\ngenerator.add(UpSampling2D())\ngenerator.add(Conv2D(32, kernel_size = (5,5), padding = 'same'))\ngenerator.add(LeakyReLU(0.2))\ngenerator.add(BatchNormalization())\n\n# Double the activation sie 128 X 128 X 3\ngenerator.add(UpSampling2D())\ngenerator.add(Conv2D(3,activation = 'tanh', kernel_size = (5,5), padding = 'same'))\n\n\n# Compile the model\ngenerator.compile(loss='binary_crossentropy', optimizer = adam)\ngenerator.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build a Discriminator\ndiscriminator = Sequential()\n\n# Input layer with shape 128 X 128 X 3\ndiscriminator.add(Conv2D(32, (5,5), strides = (2,2), padding = 'same', input_shape =(128,128,3)))\ndiscriminator.add(LeakyReLU(0.2))\n\n# Reduce the size from 64 X 64 X 32 to 32 X 32 X 64\ndiscriminator.add(Conv2D(64, (5,5), strides = (2,2), padding = 'same'))\ndiscriminator.add(LeakyReLU(0.2))\n\n# Reduce the size further from 32 X 32 X 64 to 16 X 16 X 128\ndiscriminator.add(Conv2D(128, (5,5), strides = (2,2), padding = 'same'))\ndiscriminator.add(LeakyReLU(0.2))\n\n# Flatten the layer\ndiscriminator.add(Flatten())\ndiscriminator.add(Dense(1, activation = 'sigmoid'))\n\n# Compile the model\ndiscriminator.compile(loss = 'binary_crossentropy', optimizer = adam)\ndiscriminator.summary()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training the GANs"},{"metadata":{"trusted":true},"cell_type":"code","source":"discriminator.trainable = False\ngan_input = Input(shape = (noise_dim,))\ngenerated_img = generator(gan_input)\ngan_output = discriminator(generated_img)\n\n# Functional API\nmodel = Model(gan_input, gan_output)\nmodel.compile(loss = 'binary_crossentropy', optimizer = adam)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_imgs(epoch, samples = 100):\n    \n    noise = np.random.normal(0,1, size = (samples, noise_dim))\n    generated_imgs = generator.predict(noise)\n    generated_imgs = generated_imgs.reshape(samples, 128, 128, 3)\n    \n    # Plot the generated images\n    plt.figure(figsize = (20, 20))\n    for i in range(samples):\n        \n        plt.subplot(10, 10, i+1)\n        plt.imshow(generated_imgs[i], interpolation = 'nearest')\n        plt.axis(\"off\")\n        \n    plt.tight_layout()\n    plt.show()\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training Loop\nfor epoch in range(epochs):\n    \n    epoch_d_loss = 0.\n    epoch_g_loss = 0.\n    \n    # Mini bathc SGD\n    for step in range(no_of_batches):\n        \n        # Step 1 train discriminator: 50% real data + 50% Fake images\n        \n        # Real Data\n        idx = np.random.randint(0, 5000, half_batch_size)\n        real_imgs = images_arr[idx]\n        \n        # Fake Data\n        noise = np.random.normal(0,1, size = (half_batch_size, noise_dim))\n        fake_imgs = generator.predict(noise)\n        \n        # Labels\n        real_y = np.ones((half_batch_size,1))*0.9\n        fake_y = np.zeros((half_batch_size,1))\n        \n        # Train our discriminator\n        d_real_loss = discriminator.train_on_batch(real_imgs, real_y)\n        d_fake_loss = discriminator.train_on_batch(fake_imgs, fake_y)\n        \n        d_loss = 0.5*d_real_loss + 0.5*d_fake_loss\n        \n        epoch_d_loss += d_loss\n        \n        # Train the generator (Considering Generator as frozen)\n        noise = np.random.normal(0,1, size = (batch_size, noise_dim))\n        ground_truth_y = np.ones((batch_size, 1))\n        \n        g_loss = model.train_on_batch(noise, ground_truth_y)\n        \n        epoch_g_loss =+ g_loss\n    \n    print(\"Epoch %d Disc. loss %.4f Generator Loss %.4f\"%((epoch+1), epoch_d_loss/no_of_batches, epoch_g_loss/no_of_batches))\n    if (epoch + 1)%5 == 0:\n        \n        plot_imgs(epoch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}