{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\nimport time\n\nimport math\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\n\nfrom sklearn.metrics import mean_absolute_error as MAE, mean_squared_error as MSE\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.feature_selection import RFE\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom IPython.display import display","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-07T04:27:40.739812Z","iopub.execute_input":"2021-06-07T04:27:40.74024Z","iopub.status.idle":"2021-06-07T04:27:42.034756Z","shell.execute_reply.started":"2021-06-07T04:27:40.740151Z","shell.execute_reply":"2021-06-07T04:27:42.033856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mpl.rcParams['figure.figsize'] = (20, 13)\nmpl.rcParams['axes.grid'] = False\n\nsns.set(style=\"ticks\", color_codes=True)\n\npd.set_option('display.max_rows', 50)\npd.set_option('display.max_columns', 100)\npd.set_option('display.width', 256)\n\nfrom pandas.core.common import SettingWithCopyWarning\n\nimport warnings\nwarnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:27:42.03625Z","iopub.execute_input":"2021-06-07T04:27:42.036535Z","iopub.status.idle":"2021-06-07T04:27:42.043473Z","shell.execute_reply.started":"2021-06-07T04:27:42.036507Z","shell.execute_reply":"2021-06-07T04:27:42.042435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Loading**","metadata":{}},{"cell_type":"code","source":"from dateutil.parser import parse\n\ndate_parser = lambda date: parse(date)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:27:42.045288Z","iopub.execute_input":"2021-06-07T04:27:42.045604Z","iopub.status.idle":"2021-06-07T04:27:42.056107Z","shell.execute_reply.started":"2021-06-07T04:27:42.045575Z","shell.execute_reply":"2021-06-07T04:27:42.055054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_raw = pd.read_csv('../input/jena-climate-2009-2016/jena_climate_2009_2016.csv',\n                     parse_dates=['Date Time'],\n                     date_parser=date_parser)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:27:42.058116Z","iopub.execute_input":"2021-06-07T04:27:42.058538Z","iopub.status.idle":"2021-06-07T04:28:18.805839Z","shell.execute_reply.started":"2021-06-07T04:27:42.058493Z","shell.execute_reply":"2021-06-07T04:28:18.804864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_raw.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:28:18.807086Z","iopub.execute_input":"2021-06-07T04:28:18.807375Z","iopub.status.idle":"2021-06-07T04:28:18.85897Z","shell.execute_reply.started":"2021-06-07T04:28:18.807347Z","shell.execute_reply":"2021-06-07T04:28:18.858145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in ['wv (m/s)', 'max. wv (m/s)']:\n    df_raw[col] = df_raw[col].replace(-9999.00, 0)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:28:18.859999Z","iopub.execute_input":"2021-06-07T04:28:18.860413Z","iopub.status.idle":"2021-06-07T04:28:18.874079Z","shell.execute_reply.started":"2021-06-07T04:28:18.860383Z","shell.execute_reply":"2021-06-07T04:28:18.873101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_exog = ['p (mbar)', 'VPmax (mbar)', 'VPdef (mbar)', 'sh (g/kg)', 'rho (g/m**3)', 'wv (m/s)', ]\nfeature_endog = ['T (degC)', ]\n\ndf = df_raw[['Date Time']+features_exog+feature_endog].copy()\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:28:18.875267Z","iopub.execute_input":"2021-06-07T04:28:18.875676Z","iopub.status.idle":"2021-06-07T04:28:18.912391Z","shell.execute_reply.started":"2021-06-07T04:28:18.875645Z","shell.execute_reply":"2021-06-07T04:28:18.911435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Add **seasonality** by **Sin-Cos Extraction**","metadata":{}},{"cell_type":"code","source":"df.set_index('Date Time', inplace=True, drop=True)\ndate_time = pd.Series(df.index)\ndate_time.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:28:18.914898Z","iopub.execute_input":"2021-06-07T04:28:18.915232Z","iopub.status.idle":"2021-06-07T04:28:18.925167Z","shell.execute_reply.started":"2021-06-07T04:28:18.915198Z","shell.execute_reply":"2021-06-07T04:28:18.923996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datetime import date, datetime\n\ntimestamp_dt = date_time.map(datetime.timestamp)\n\n# Define timestamp constants\nSECOND, MINUTE, HOUR = 1, 60, 3_600\nDAY = 24*HOUR\nWEEK = 7*DAY\nMONTH = DAY*30.4375 # (7*31 + 4*30 +28.25) / 12 = 30.4375\nYEAR = DAY*365.25\ndt_features = [MINUTE, HOUR, DAY, WEEK, MONTH, YEAR,]\n\n# Generate new periodic features\ndt_names = ['minute', 'hour', 'day', 'week', 'month', 'year', ]\nfor dt_n, dt_f in zip(dt_names, dt_features):\n    print(f\"Generating features for {dt_n} ...\")\n    t1 = time.time()\n    df[f\"{dt_n}_sin\"] = np.sin(timestamp_dt * (2 * np.pi / dt_f)).values\n    df[f\"{dt_n}_cos\"] = np.cos(timestamp_dt * (2 * np.pi / dt_f)).values\n    t2 = time.time()\n    print(f\"\\t\\t ... in {round(t2-t1, 2)} seconds\")\n\n# for col in dt_names:\n#     plt.plot(date_time.values, df[col+'_sin'].values, 'ro', \n#              date_time.values, df[col+'_cos'].values, 'bo')\n#     plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:28:18.926866Z","iopub.execute_input":"2021-06-07T04:28:18.927346Z","iopub.status.idle":"2021-06-07T04:28:44.695977Z","shell.execute_reply.started":"2021-06-07T04:28:18.927293Z","shell.execute_reply":"2021-06-07T04:28:44.694739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(df))\nfor year in range(2009, 2020):\n    print(year, len(df[df.index.year==year]))","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:28:44.697358Z","iopub.execute_input":"2021-06-07T04:28:44.697757Z","iopub.status.idle":"2021-06-07T04:28:45.196785Z","shell.execute_reply.started":"2021-06-07T04:28:44.697722Z","shell.execute_reply":"2021-06-07T04:28:45.195611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_dt = [col+'_sin' for col in dt_names] + \\\n              [col+'_cos' for col in dt_names]\ncolumns = features_dt + feature_endog\ntrain_df = df[columns][ (df.index.year >= 2013) & (df.index.year <= 2014) ]\ntest_df = df[columns][ (df.index.year == 2015) & (df.index.year <= 2016) ]\ndisplay(train_df.tail(5))\ndisplay(test_df.head(5))\n\ntrain_size, test_size = len(train_df), len(test_df)\nprint(train_size, test_size)\n\ncompose_df = pd.concat([train_df, test_df])\n\nplt.plot(train_df.index, train_df['T (degC)'], 'bo',\n          test_df.index, test_df['T (degC)'], 'ro')","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:28:45.198132Z","iopub.execute_input":"2021-06-07T04:28:45.198441Z","iopub.status.idle":"2021-06-07T04:28:45.830724Z","shell.execute_reply.started":"2021-06-07T04:28:45.198402Z","shell.execute_reply":"2021-06-07T04:28:45.829377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for col in list(compose_df.columns):\n#     if col == 'Date Time':\n#         continue\n#     compose_df[[col]].plot()\n#     plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:28:45.832404Z","iopub.execute_input":"2021-06-07T04:28:45.832763Z","iopub.status.idle":"2021-06-07T04:28:45.837798Z","shell.execute_reply.started":"2021-06-07T04:28:45.832725Z","shell.execute_reply":"2021-06-07T04:28:45.836571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for col in features_exog+feature_endog:\n#     sns.distplot(train_df[col])\n#     sns.distplot(test_df[col])\n#     plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:28:45.840487Z","iopub.execute_input":"2021-06-07T04:28:45.840821Z","iopub.status.idle":"2021-06-07T04:28:45.849635Z","shell.execute_reply.started":"2021-06-07T04:28:45.840787Z","shell.execute_reply":"2021-06-07T04:28:45.848528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Build dataset**","metadata":{}},{"cell_type":"code","source":"# 1 day: 24*6=144 samples\n# 1 week: 7*24*6=1008 samples\nSEQ_LEN = 256\n\ndatasets = dict()\ndatasets['train'] = train_df\ndatasets['test'] = pd.concat([train_df[-SEQ_LEN+1:], test_df])","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:28:45.850932Z","iopub.execute_input":"2021-06-07T04:28:45.851392Z","iopub.status.idle":"2021-06-07T04:28:45.865004Z","shell.execute_reply.started":"2021-06-07T04:28:45.851338Z","shell.execute_reply":"2021-06-07T04:28:45.864064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datasets['train'].describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:28:45.866293Z","iopub.execute_input":"2021-06-07T04:28:45.866564Z","iopub.status.idle":"2021-06-07T04:28:45.94422Z","shell.execute_reply.started":"2021-06-07T04:28:45.866537Z","shell.execute_reply":"2021-06-07T04:28:45.943149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import timeseries_dataset_from_array\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nscaler = StandardScaler()\nBATCH_SIZE = 64\ndata_generators = dict()\n\nfor ds_name, ds in datasets.items():\n    data = ds.values\n    X, y = data[:,:-1].astype(np.float32), data[:,-1].astype(np.float32)\n    if ds_name == 'train':\n        y = scaler.fit_transform(y.reshape(-1, 1)).flatten()\n    else:\n        y = scaler.transform(y.reshape(-1, 1)).flatten()\n    print(f\"{ds_name}: {data.shape} --> {X.shape} + {y.shape}\")\n    data_generators[ds_name] = timeseries_dataset_from_array(\n        X, y, batch_size=BATCH_SIZE, \n        sampling_rate=1,\n        sequence_stride=1,\n        sequence_length=SEQ_LEN, \n    )\n    for batch in data_generators[ds_name].take(1):\n        inputs, targets = batch\n        # print(targets)\n        print(\"\\t Input shape:\", inputs.numpy().shape)\n        print(\"\\t Target shape:\", targets.numpy().shape)\n        \n    del ds","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:28:45.94609Z","iopub.execute_input":"2021-06-07T04:28:45.946512Z","iopub.status.idle":"2021-06-07T04:28:52.202901Z","shell.execute_reply.started":"2021-06-07T04:28:45.946466Z","shell.execute_reply":"2021-06-07T04:28:52.202151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LEN = dict()\nfor ds_name, generator in data_generators.items():\n    LEN[ds_name] = 0\n    for b_i, (X_batch, y_batch) in enumerate(generator):\n        LEN[ds_name] += X_batch.shape[0]\n        \nprint(LEN)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:28:52.204113Z","iopub.execute_input":"2021-06-07T04:28:52.20454Z","iopub.status.idle":"2021-06-07T04:29:00.36743Z","shell.execute_reply.started":"2021-06-07T04:28:52.204506Z","shell.execute_reply":"2021-06-07T04:29:00.366372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_FEATURES = len(train_df.columns) - 1\nN_FEATURES","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:29:00.368668Z","iopub.execute_input":"2021-06-07T04:29:00.368947Z","iopub.status.idle":"2021-06-07T04:29:00.375112Z","shell.execute_reply.started":"2021-06-07T04:29:00.36892Z","shell.execute_reply":"2021-06-07T04:29:00.374003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_batch = dict()\n\nfor ds_name, generator in data_generators.items():\n    # Use memory-mapping to reduce RAM usage\n    X_all = np.memmap(f\"{ds_name}_X.npy\", dtype='float32', mode='w+', shape=(LEN[ds_name], SEQ_LEN, N_FEATURES))\n    y_all = np.memmap(f\"{ds_name}_y.npy\", dtype='float32', mode='w+', shape=(LEN[ds_name], ))\n    \n    for b_i, (X_batch, y_batch) in enumerate(generator):\n        if len(X_batch) == BATCH_SIZE:\n            b_start, b_end = b_i*BATCH_SIZE, (b_i+1)*BATCH_SIZE\n            X_all[b_start:b_end, ...] = X_batch.numpy()[...]\n            y_all[b_start:b_end] = y_batch.numpy()[:]\n\n    del generator\n        \n    # TSAI Input Shape: (N_samples, N_features, Max_seq_len)\n    X_all = np.transpose(X_all, axes=(0,2,1))\n    \n    data_batch[ds_name] = [X_all, y_all]\n    print(ds_name, X_all.shape, y_all.shape)\n    \n    del X_all, y_all","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:29:00.376571Z","iopub.execute_input":"2021-06-07T04:29:00.376921Z","iopub.status.idle":"2021-06-07T04:29:09.02487Z","shell.execute_reply.started":"2021-06-07T04:29:00.376855Z","shell.execute_reply":"2021-06-07T04:29:09.023751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, y_train = data_batch['train']\nX_test, y_test = data_batch['test']","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:29:09.02656Z","iopub.execute_input":"2021-06-07T04:29:09.026895Z","iopub.status.idle":"2021-06-07T04:29:09.032267Z","shell.execute_reply.started":"2021-06-07T04:29:09.026861Z","shell.execute_reply":"2021-06-07T04:29:09.031127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Modelling**","metadata":{}},{"cell_type":"markdown","source":"## **Loss Function**","metadata":{}},{"cell_type":"code","source":"# Huber Loss, aka Smoothed Mean Absolute Error\nfrom tensorflow.keras.losses import Huber, Reduction\n\nloss_func = Huber(reduction=Reduction.NONE)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:29:09.033954Z","iopub.execute_input":"2021-06-07T04:29:09.034411Z","iopub.status.idle":"2021-06-07T04:29:09.044909Z","shell.execute_reply.started":"2021-06-07T04:29:09.034366Z","shell.execute_reply":"2021-06-07T04:29:09.044163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_df = pd.DataFrame()\nloss_df['Date'] = test_df.index","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:29:09.046022Z","iopub.execute_input":"2021-06-07T04:29:09.046541Z","iopub.status.idle":"2021-06-07T04:29:09.06544Z","shell.execute_reply.started":"2021-06-07T04:29:09.046509Z","shell.execute_reply":"2021-06-07T04:29:09.064175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **TSAI**","metadata":{}},{"cell_type":"code","source":"!pip install --ignore-installed tsai","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-07T04:29:09.06972Z","iopub.execute_input":"2021-06-07T04:29:09.07008Z","iopub.status.idle":"2021-06-07T04:31:28.465528Z","shell.execute_reply.started":"2021-06-07T04:29:09.07002Z","shell.execute_reply":"2021-06-07T04:31:28.464027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tsai.all import *\n\nimport torch\n\ndef torch2np(tensor: torch.Tensor) -> np.array:\n    if torch.cuda.is_available():\n        tensor = tensor.cpu()\n    return tensor.numpy()\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:31:28.469027Z","iopub.execute_input":"2021-06-07T04:31:28.469418Z","iopub.status.idle":"2021-06-07T04:32:34.99834Z","shell.execute_reply.started":"2021-06-07T04:31:28.469371Z","shell.execute_reply":"2021-06-07T04:32:34.997221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **MiniRocket**","metadata":{}},{"cell_type":"code","source":"# params = {'num_features': 10_000, \n#           'max_dilations_per_kernel': 64, \n#           'normalize_features': False, \n#           'scoring': make_scorer(MSE, greater_is_better=False),\n#           'verbose': True, }\n\n# for n_estimators in [1,3,5]:\n#     if n_estimators == 1:\n#         model = MiniRocketRegressor(**params)\n#     else:\n#         model = MiniRocketVotingRegressor(n_estimators=n_estimators, **params)\n\n#     print(f\"\\n\\n Training MiniRocket-{n_estimators} ...\")\n#     timer.start(False)\n#     model.fit(X_train, y_train)\n#     t = timer.stop()\n#     print(f\"\\t ... in {t}\")\n    \n#     predictions = model.predict(X_test)\n#     predictions = scaler.inverse_transform(predictions.reshape((-1,1)))\n    \n#     plt.plot(train_df.index, train_df['T (degC)'], 'ro',\n#              test_df.index, test_df['T (degC)'], 'yo', \n#              test_df.index, predictions, 'bo')\n#     plt.show()\n    \n#     loss = loss_func(test_df['T (degC)'].values.reshape(-1,1),\n#                      predictions).numpy()\n#     loss_df[f'MiniRocket-{n_estimators}'] = loss.flatten()\n    \n#     del model\n    \n# loss_df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:32:34.999781Z","iopub.execute_input":"2021-06-07T04:32:35.000126Z","iopub.status.idle":"2021-06-07T04:32:35.005004Z","shell.execute_reply.started":"2021-06-07T04:32:35.000091Z","shell.execute_reply":"2021-06-07T04:32:35.003655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Deep Neural Networks**:\n* **ResNet**\n* **XceptionTime**\n* **InceptionTime**\n* **TSTransformer**","metadata":{}},{"cell_type":"code","source":"DL_models = {\n    \"ResNet\": (ResNetPlus, {'nf': 16, 'ks': [5, 3, 2], 'seq_len': SEQ_LEN}), \n    \"XceptionTime\": (XceptionTime, {'nf': 16, 'adaptive_size': 24, 'residual': True}), \n    \"XceptionTimePlus\": (XceptionTimePlus, {'nf': 24, 'adaptive_size': 28, 'residual': True}), \n    \"InceptionTime\": (InceptionTime, {'nf': 16, 'ks': SEQ_LEN//2}), \n    \"InceptionTimePlus\": (InceptionTimePlus, {'nf': 24, 'ks': SEQ_LEN//2, 'bottleneck': True, 'depth': 4, 'dilation': 1, 'stride': 1}), \n    \"TSTransformer\": (TST, {'max_seq_len': SEQ_LEN, 'd_model': 32, 'd_ff': 16, 'n_layers': 2, 'n_heads': 4, }), \n    \"TSTransformerPlus\": (TSTPlus, {'max_seq_len': SEQ_LEN, 'd_model': 32, 'd_ff': 16, 'n_layers': 2, 'n_heads': 4, }), \n}","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:32:35.006484Z","iopub.execute_input":"2021-06-07T04:32:35.006832Z","iopub.status.idle":"2021-06-07T04:32:35.026192Z","shell.execute_reply.started":"2021-06-07T04:32:35.006797Z","shell.execute_reply":"2021-06-07T04:32:35.024998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_dl, y_dl, splits = combine_split_data([X_train, X_test], [y_train, y_test])\n\ntransformations = [None, [TSRegression()]]\nbatch_transformations = [TSStandardize(by_sample=False, by_var=False)]\ndsets = TSDatasets(X_dl, y_dl, splits=splits, tfms=transformations, inplace=True)\ndloaders = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 32], batch_tfms=batch_transformations, num_workers=0)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:32:35.027892Z","iopub.execute_input":"2021-06-07T04:32:35.02836Z","iopub.status.idle":"2021-06-07T04:32:53.438022Z","shell.execute_reply.started":"2021-06-07T04:32:35.028309Z","shell.execute_reply":"2021-06-07T04:32:53.437136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dloaders.show_batch(sharey=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:32:53.442457Z","iopub.execute_input":"2021-06-07T04:32:53.444608Z","iopub.status.idle":"2021-06-07T04:32:55.76703Z","shell.execute_reply.started":"2021-06-07T04:32:53.444555Z","shell.execute_reply":"2021-06-07T04:32:55.76587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for model_name, (model, params) in DL_models.items():\n    \n    print(f\"\\n\\n Training {model_name} ...\")\n    timer.start(False)\n    \n    # Create model\n    model = create_model(model, dls=dloaders, **params)\n    learner = Learner(dls=dloaders, model=model, metrics=[mae, rmse], opt_func=Adam)\n    \n    # Find best learning-rate\n    try:\n        lr_lowest, lr_steepest = learner.lr_find(start_lr=1e-7, end_lr=1e0, num_it=169)\n    except Exception as e:\n        print('\\t', e)\n        lr_lowest = 1e-3\n    print(f\"\\t ... with learning-rate = {lr_lowest}\")\n\n    # Train\n    try:\n        learner.fit_one_cycle(n_epoch=7, lr_max=lr_lowest)\n    except Exception as e:\n        print('\\t', e)\n\n    t = timer.stop()\n    print(f\"\\t ... in {t}\")\n        \n    # Evaluate\n    # X_test = torch.Tensor(X_test).to(device)\n    # y_pred = learner.get_X_preds(X_test)[0]\n    y_pred = learner.get_preds(dl=dloaders.valid)[0]\n    y_pred = torch2np(y_pred.detach())\n    \n    predictions = scaler.inverse_transform(y_pred.reshape((-1,1)))\n    \n    # Visualize\n    plt.show()\n    plt.plot(train_df.index, train_df['T (degC)'], 'ro', \n              test_df.index, test_df['T (degC)'], 'yo', \n              test_df.index, predictions, 'bo')\n    plt.show()\n    \n    # Loss statistics\n    loss = loss_func(test_df['T (degC)'].values.reshape(-1,1),\n                     predictions).numpy()\n    loss_df[f'{model_name}'] = loss.flatten()\n    \n    del model, learner","metadata":{"execution":{"iopub.status.busy":"2021-06-07T04:32:55.768582Z","iopub.execute_input":"2021-06-07T04:32:55.769056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}