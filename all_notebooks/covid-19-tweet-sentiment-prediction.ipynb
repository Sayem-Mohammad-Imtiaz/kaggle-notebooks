{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Task for Today  \n\n***\n\n## COVID-19 Tweet Sentiment Prediction  \n\nGiven *tweets about the COVID-19 pandemic*, let's try to predict the **sentiment** of a given tweet.  \n  \nWe will use a TensorFlow RNN to make our predictions."},{"metadata":{},"cell_type":"markdown","source":"# Getting Started"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport plotly.express as px\n\nimport re\nfrom nltk.corpus import stopwords\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/covid-19-nlp-text-classification/Corona_NLP_train.csv', encoding='latin-1')\ntest_df = pd.read_csv('../input/covid-19-nlp-text-classification/Corona_NLP_test.csv', encoding='latin-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_inputs = train_df['OriginalTweet'].copy()\ntest_inputs = test_df['OriginalTweet'].copy()\n\ntrain_labels = train_df['Sentiment'].copy()\ntest_labels = test_df['Sentiment'].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment_encoding = {\n    'Extremely Negative': 0,\n    'Negative': 0,\n    'Neutral': 1,\n    'Positive': 2,\n    'Extremely Positive': 2\n}\n\ntrain_labels = train_labels.replace(sentiment_encoding)\ntest_labels = test_labels.replace(sentiment_encoding)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_inputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop_words = stopwords.words('english')\n\ndef process_tweet(tweet):\n    \n    # remove urls\n    tweet = re.sub(r'http\\S+', ' ', tweet)\n    \n    # remove html tags\n    tweet = re.sub(r'<.*?>', ' ', tweet)\n    \n    # remove digits\n    tweet = re.sub(r'\\d+', ' ', tweet)\n    \n    # remove hashtags\n    tweet = re.sub(r'#\\w+', ' ', tweet)\n    \n    # remove mentions\n    tweet = re.sub(r'@\\w+', ' ', tweet)\n    \n    #removing stop words\n    tweet = tweet.split()\n    tweet = \" \".join([word for word in tweet if not word in stop_words])\n    \n    return tweet\n\n# Function taken from @Shahraiz's wonderful notebook","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_inputs = train_inputs.apply(process_tweet)\ntest_inputs = test_inputs.apply(process_tweet)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_inputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_seq_length = np.max(train_inputs.apply(lambda tweet: len(tweet)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts(train_inputs)\n\nvocab_length = len(tokenizer.word_index) + 1\n\n\ntrain_inputs = tokenizer.texts_to_sequences(train_inputs)\ntest_inputs = tokenizer.texts_to_sequences(test_inputs)\n\ntrain_inputs = pad_sequences(train_inputs, maxlen=max_seq_length, padding='post')\ntest_inputs = pad_sequences(test_inputs, maxlen=max_seq_length, padding='post')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Vocab length:\", vocab_length)\nprint(\"Max sequence length:\", max_seq_length)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_inputs.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_dim = 16\n\n\ninputs = tf.keras.Input(shape=(max_seq_length,), name='input_layer')\n\nembedding = tf.keras.layers.Embedding(\n    input_dim=vocab_length,\n    output_dim=embedding_dim,\n    input_length=max_seq_length,\n    name='word_embedding'\n)(inputs)\n\ngru_layer = tf.keras.layers.Bidirectional(\n    tf.keras.layers.GRU(units=256, return_sequences=True, name='gru_layer'),\n    name='bidirectional_layer'\n)(embedding)\n\nmax_pooling = tf.keras.layers.GlobalMaxPool1D(name='max_pooling')(gru_layer)\n\ndropout_1 = tf.keras.layers.Dropout(0.4, name='dropout_1')(max_pooling)\n\ndense = tf.keras.layers.Dense(64, activation='relu', name='dense')(dropout_1)\n\ndropout_2 = tf.keras.layers.Dropout(0.4, name='dropout_2')(dense)\n\noutputs = tf.keras.layers.Dense(3, activation='softmax', name='output_layer')(dropout_2)\n\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nprint(model.summary())\n\ntf.keras.utils.plot_model(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n\nbatch_size = 32\nepochs = 2\n\nhistory = model.fit(\n    train_inputs,\n    train_labels,\n    validation_split=0.12,\n    batch_size=batch_size,\n    epochs=epochs,\n    verbose=2\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.line(\n    history.history,\n    y=['loss', 'val_loss'],\n    labels={'index': \"epoch\", 'value': \"loss\"}\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(test_inputs, test_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps://youtu.be/-jPZvbG4M2c"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}