{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.dummy import DummyClassifier\nimport xgboost as xgb\nfrom sklearn.metrics import accuracy_score\nfrom itertools import combinations\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/loan-prediction/train_loan.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#I see some 'object' type and need to deal with them\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For this dataset I will comment my choices for each column in the related cell","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Loan_ID: unuseful fot the model, can be removed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gender: There are some NaN but there is no way to infer this, so unfortunately I remove the related rows\ndf = df[df['Gender'].notna()]\ndf.Gender.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Married: I assume NaN for this feature means \"Divorced\"\n\nmissing_married = len(df[ df.Married.isna()])\nprint('Missing married before: %d' %(missing_married))\n\nnan_married = df[df.Married.isna()].index\ndf.loc[nan_married,'Married'] = 'Divorced'\n\nmissing_married = len(df[df.Married.isna()])\nprint('Missing married after : %d' %(missing_married))\ndf.Married.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I assume that when Self_Employed is set to nan it means the guy lives with a revenue\ndef fix_self_employed(self_employed):\n    ret = self_employed\n    if str(self_employed) == 'nan':\n        ret = 'Revenue'\n    #print(ret)\n    return ret\n\ndf['Self_Employed'] = df.apply(lambda row : fix_self_employed(row['Self_Employed']),axis=1)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Dependent (number): I tried different setup here but nothing changed that much the results.\n# I keep this where I set category '1' for more than 3 dependents, 0 for less than '3', -1 when the value is not applicable\n\ndef fix_dependents(num_dependents):\n    \n    map = {'3+' : 1, '3': 0, '2': 0, '1': 0, '0': 0, 'nan': -1 }\n    return map[str(num_dependents)]\n           \ndf['Dependents'] = df.apply(lambda row : fix_dependents(row['Dependents']),axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Education: all values are there. I do not see any issue in this column\ndf['Education'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ApplicantIncome: all values are there. I do not see any issue in this column\nlen(df[df['ApplicantIncome'].isna()]) == 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CoapplicantIncome: when there is no coapplicant this value is set to zero\ncoapplicant_income_set_to_zero = len(df[df['CoapplicantIncome'] == 0])\ncoapplicant_income_set_to_nan = len(df[df['CoapplicantIncome'].isna()])\nprint(coapplicant_income_set_to_zero,coapplicant_income_set_to_nan)\n\n# create a new feature as the sum of ApplicantIncome and CoapplicantIncome\ndf['TotalApplicantIncome'] = df['ApplicantIncome'] + df['CoapplicantIncome']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loanAmount : there are 22 rows without any value \n# (the dataset is already tiny so better replace them with mean rather than get rid of them)\n\nprint(len(df[df['LoanAmount'].isna()]))\n\nloan_amount_mean = df['LoanAmount'].mean()\n\ndef replace_NaN_loan_Amount(loan_amount, replace_value):\n    ret = loan_amount\n    if str(loan_amount) == 'nan':\n        #print(str(loan_amount))\n        ret = replace_value\n    return ret\n\ndf['LoanAmount'] = df['LoanAmount'].fillna(loan_amount_mean)\n\nprint(len(df[df['LoanAmount'].isna()]))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Loan_Amount_Term : there are 14 rows without any value\n# (the dataset is already tiny so better replace them with mean rather than get rid of them)\n\nprint(len(df[df['Loan_Amount_Term'].isna()]))\ndf.Loan_Amount_Term.unique()\n\nloan_amount_term_mean = df['Loan_Amount_Term'].mean()\n\ndef replace_NaN_Loan_Amount_Term(loan_amount, replace_value):\n    ret = loan_amount\n    if str(loan_amount) == 'nan':\n        #print(str(loan_amount))\n        ret = replace_value\n    return ret\n\ndf['Loan_Amount_Term'] = df['Loan_Amount_Term'].fillna(loan_amount_term_mean)\n\nprint(len(df[df['Loan_Amount_Term'].isna()]))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Credit_History : some people (50) don't have a credit history. I assign them a new category = 2. (unrated)\n    \nprint(len(df[df['Credit_History'].isna()]))\n\ndf['Credit_History'] = df['Credit_History'].fillna(2.)\n\nprint(len(df[df['Credit_History'].isna()]))\ndf['Credit_History'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Property_Area: this column seems fine: all values set and no NaN\nlen(df[df.Property_Area.isna()])\ndf.Property_Area.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encode all values\nfor column in df.columns:\n    if df[column].dtype == 'O':\n        # object values are label-encoded\n        le = LabelEncoder()\n        df[column] = le.fit_transform(df[column].apply(str))\n    # numerical values are scaled\n    scaler = MinMaxScaler()\n    df[column] = scaler.fit_transform(np.array(df[column]).reshape(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At this point the dataset is consistent","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop unuseful/meaningless features\nfeatures_to_be_dropped = ['Loan_ID','ApplicantIncome', 'CoapplicantIncome']\ndf.drop(features_to_be_dropped,inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split in train and test\nY = df['Loan_Status'].values\nX = df.drop(['Loan_Status'], axis=1).values\n\nX_train, X_test, Y_train, Y_test =  train_test_split(X,Y, test_size=0.3, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# try a Dummy Classifier to see what is the reference accuracy for my model\ndc = DummyClassifier()\ndc.fit(X_train,Y_train)\nY_train_pred = dc.predict(X_train)\nY_test_pred = dc.predict(X_test)\n\nprint('Dummy ACCURACY train: %.4f, test: %.4f' %(accuracy_score(Y_train,Y_train_pred), accuracy_score(Y_test,Y_test_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# try with RandomForest\nrfc = RandomForestClassifier(n_estimators=30)\nrfc.fit(X_train,Y_train)\n\nY_train_pred = rfc.predict(X_train)\nY_test_pred = rfc.predict(X_test)\n\nprint('RandomForest ACCURACY train: %.4f, test: %.4f' %(accuracy_score(Y_train,Y_train_pred), accuracy_score(Y_test,Y_test_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# try with XGBoost\nxg_reg = xgb.XGBClassifier(n_estimators=30)\n\nxg_reg.fit(X_train,Y_train)\n\nY_train_pred = xg_reg.predict(X_train)\nY_test_pred = xg_reg.predict(X_test)\n\nprint('XGBoost ACCURACY train: %.4f, test: %.4f' %(accuracy_score(Y_train,Y_train_pred), accuracy_score(Y_test,Y_test_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We have a lot of feature and I wonder whether a differnt combination of them can lead to better result,\n#so here I try all the feature's combinations and see what happens\n\nfeature_list = []\nfor column in df.columns:\n    if column == 'Loan_Status' or column == 'Loan_ID':\n        continue\n    feature_list.append(column)\nprint(feature_list)\n\nfor num_features_step in range(1,len(feature_list)+1):\n\n    combs = combinations(feature_list, num_features_step) \n    features_for_model = []\n    \n    for comb in combs:\n        features_for_model = [feature for feature in comb]\n        print(features_for_model)\n        # drop unuseful/meaningless features\n        Y = df['Loan_Status'].values\n        X = df[features_for_model].values\n        X_train, X_test, Y_train, Y_test =  train_test_split(X,Y, test_size=0.3, random_state=1)\n        rfc = RandomForestClassifier(n_estimators=30)\n        rfc.fit(X_train,Y_train)\n        Y_train_pred = rfc.predict(X_train)\n        Y_test_pred = rfc.predict(X_test)\n        print('---ITERATION---')\n        print(features_for_model)\n        print('RandomForestClassifier ACCURACY train: %.4f, test: %.4f' %(accuracy_score(Y_train,Y_train_pred), accuracy_score(Y_test,Y_test_pred)))\n        xg_reg = xgb.XGBClassifier(n_estimators=30)\n        xg_reg.fit(X_train,Y_train)\n        Y_train_pred = xg_reg.predict(X_train)\n        Y_test_pred = xg_reg.predict(X_test)\n        print('XGBClassifier          ACCURACY train: %.4f, test: %.4f' %(accuracy_score(Y_train,Y_train_pred), accuracy_score(Y_test,Y_test_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On my PC, with the features set as described above, I see that a relatively high score is reached by using only the 'Credit History' feature\n\n**Features: ['Credit_History']**\n\n**RandomForestClassifier ACCURACY train: 0.8190, test: 0.7845**\n\n**XGBClassifier          ACCURACY train: 0.8190, test: 0.7845**\n\n\nWith the following two features only I already reach the max accuracy seen, with quite balanced values between train and test set:\n\n**Features: ['Self_Employed', 'Credit_History']**\n\n**RandomForestClassifier ACCURACY train: 0.8214, test: 0.8011**\n\n**XGBClassifier          ACCURACY train: 0.8214, test: 0.8011**\n\n\nAdding more features to the model does not improve my results :-|\n\n\nI ran out of ideas on this dataset: if you have any comments/suggestion/criticism/ideas please share them in the comments","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}