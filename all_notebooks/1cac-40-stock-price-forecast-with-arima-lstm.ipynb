{"cells":[{"metadata":{},"cell_type":"markdown","source":"# CAC 40 Stock Price Forecast with ARIMA & LSTM"},{"metadata":{},"cell_type":"markdown","source":"### Reference Material"},{"metadata":{},"cell_type":"markdown","source":"* CAC 40 data Donwload: https://www.euronext.com/en/products/indices/FR0003500008-XPAR\n* Jupyter Notebook Connect with HDFS: http://nbviewer.jupyter.org/github/ofermend/IPython-notebooks/blob/master/blog-part-1.ipynb\n* Time Series Prediction with LSTM: https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n* Data Science with Apache Hadoop: Predicting Airline Delays: https://fr.hortonworks.com/blog/data-science-apacheh-hadoop-predicting-airline-delays/"},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"## PART 1. Data pre processing"},{"metadata":{},"cell_type":"markdown","source":"Start by uploading data from HDFS or Local machine"},{"metadata":{},"cell_type":"markdown","source":"### 1.1. Import Dataset from HDFS"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.1. Import Dataset from Local Hard Drive"},{"metadata":{},"cell_type":"markdown","source":"* If you are not using HDFS, import the csv file directly from the local disk.\n* Ignore this step if you have imported csv files from HDFS."},{"metadata":{"trusted":true},"cell_type":"code","source":"cac_df = pd.read_csv('/kaggle/input/cac1data/cac40.csv')\ncac_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2 Display a summary of statistical measure of this data"},{"metadata":{"trusted":true},"cell_type":"code","source":"cac_df.info() # give the complacte inforamtion of dataset including datatypes null values ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cac_df.describe() # give the statistical informaion of our dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.3. Change String Date to Datetime Format"},{"metadata":{"trusted":true},"cell_type":"code","source":"cac_df['Date'] = pd.to_datetime(cac_df['Date']) \ncac_df.Date.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('There are {} number of days in the dataset.'.format(cac_df.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.4. Set Datetime to Index"},{"metadata":{"trusted":true},"cell_type":"code","source":"cac_df.set_index('Date', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cac_df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.5. Feature Selection & Data Resampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_technical_indicators(dataset): #function to generate feature technical indicators\n    \n    \n    # Create 7 and 21 days Moving Average\n    dataset['ma7'] = dataset['Close'].rolling(window = 7).mean()\n    dataset['ma21'] = dataset['Close'].rolling(window = 21).mean()\n    \n    #Create MACD\n    dataset['26ema'] = dataset['Close'].ewm(span=26).mean()\n    dataset['12ema'] = dataset['Close'].ewm(span=12).mean()\n    dataset['MACD'] = (dataset['12ema']-dataset['26ema'])\n    \n    #Create Bollinger Bands\n    dataset['20sd'] = dataset['Close'].rolling(window = 20).std()\n    dataset['upper_band'] = (dataset['Close'].rolling(window = 20).mean()) + (dataset['20sd']*2)\n    dataset['lower_band'] = (dataset['Close'].rolling(window = 20).mean()) - (dataset['20sd']*2)\n    \n    \n    #Create Exponential moving average\n    dataset['ema'] = dataset['Close'].ewm(com=0.5).mean()\n    \n    #Create Momentum\n    dataset['momentum'] = (dataset['Close']/100)-1\n    #Create ARIMA\n    dataset['ARIMA'] = 0\n    \n    return dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cac1_df = get_technical_indicators(cac_df)\ncac1_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cac1_df[['Open','Close']].plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.6. Split Dataset to train and test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data, test_data = cac1_df[0:int(len(cac1_df)*0.7)], cac1_df[int(len(cac1_df)*0.7):]\ntraining_data = train_data['Close'].values\ntest_data = test_data['Close'].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.7. Plot Training Data & Observation Data Trends"},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data1=pd.Series(training_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot training_data\ntraining_data1.plot(figsize=(15, 6))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"## Part 2. CAC 40 Stock Price Forecast with ARIMA"},{"metadata":{},"cell_type":"markdown","source":"### 2.1. Make First Order Difference or Second Order Difference"},{"metadata":{},"cell_type":"markdown","source":"#### 2.1.1. Make First Order Difference"},{"metadata":{"trusted":true},"cell_type":"code","source":"cac1_df['First Order Difference'] = cac1_df['Close'] - cac1_df['Close'].shift(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2.2.2. Plot the Training Data After the First Order Difference"},{"metadata":{"trusted":true},"cell_type":"code","source":"cac1_df['First Order Difference'].plot(figsize=(12, 6))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2. Draw ACF&PACF Chart and Select Hyperparameter q&p"},{"metadata":{},"cell_type":"markdown","source":"#### 2.2.1. Draw ACF Chart and Chose Hyperparameter q in MA Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import acf, pacf\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\n\nfig = plt.figure(figsize=(12,8))\nax1 = fig.add_subplot(211)\nfig = sm.graphics.tsa.plot_acf(training_data1, lags=40, ax=ax1) # \nax2 = fig.add_subplot(212)\nfig = sm.graphics.tsa.plot_pacf(training_data1, lags=40, ax=ax2)# , lags=40","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2.2.2. Draw PACF Chart and Chose Hyperparameter p in AR Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,8))\nax1 = fig.add_subplot(211)\nfig = sm.graphics.tsa.plot_acf(cac1_df.Open, lags=40, ax=ax1) # \nax2 = fig.add_subplot(212)\nfig = sm.graphics.tsa.plot_pacf(cac1_df.Open, lags=40, ax=ax2)# , lags=40","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3. Define then train the ARIMA Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.arima_model import ARIMA\nfrom pandas import DataFrame\nfrom pandas import datetime\n\nseries = cac1_df['Close']\nmodel = ARIMA(series, order=(5, 1, 0))\nmodel_fit = model.fit(disp=0)\nprint(model_fit.summary())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas.plotting import autocorrelation_plot\nautocorrelation_plot(series)\nplt.figure(figsize=(10, 7), dpi=80)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.4. Use ARIMA Model to Predict CAC 40 Stock Price After 2016 (Weekly Forecast)"},{"metadata":{},"cell_type":"markdown","source":"#### 2.4.1. Use ARIMA Model to Predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.arima_model import ARIMA\nfrom sklearn.metrics import mean_squared_error\n\nX = series.values\ntrain_data, test_data = X[0:int(len(X)*0.7)], X[int(len(X)*0.7):]\nhistory = [x for x in train_data]\npredictions = list()\nfor t in range(len(test_data)):\n    model = ARIMA(history, order=(5, 1, 0))\n    model_fit = model.fit(disp=0)\n    output = model_fit.forecast()\n    yhat = output[0]\n    predictions.append(yhat)\n    obs = test_data[t]\n    history.append(obs)\n\ncac1_df['ARIMA'] = pd.DataFrame(predictions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2.4.2. Evaluation the arima predicted model using RMSE"},{"metadata":{"trusted":true},"cell_type":"code","source":"error = mean_squared_error(test_data, predictions)\nprint('Test RMSE: %.3f' % error)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2.4.3. Plot the Predict Result"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the predicted (from ARIMA) and real prices\n\nplt.figure(figsize=(12, 6), dpi=100)\nplt.plot(test_data, color='black', label='Real')\nplt.plot(predictions, color='yellow', label='Predicted')\nplt.xlabel('Days')\nplt.ylabel('USD')\nplt.title('ARIMA model on CAC')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cac1_df.head(8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Total dataset has {} samples, and {} features.'.format(cac1_df.shape[0], \\\n                                                              cac1_df.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"## Part 3. CAC 40 Stock Price Forecast with LSTM [optional]"},{"metadata":{},"cell_type":"markdown","source":"#### instead of using the ARIMA model use LSTM and do the same steps as ARIMA one. You may also need to add a normalisation step in the pre processing part"},{"metadata":{"trusted":true},"cell_type":"code","source":"cac1_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Total dataset has {} samples, and {} features.'.format(cac1_df.shape[0], \\\n                                                              cac1_df.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Following steps are done:**\n\n**1.  Clean up the data-Remove any NAs**\n\n**2.   Create a test, train and validate set**\n\n**3.   Create train for Open**\n\n**4.   Normalize data** \n\n**5.Create feature and label set**\n\n**6. Train, test data and  check with validation set**\n\n**7. Make a prediction**\n\n**8. Based on this prediction find if the feature extraction method of LSTM works**\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating test, train and validate trains\ntrain, validate, test = np.split(cac1_df.sample(frac=1), [int(.6*len(cac1_df)), int(.8*len(cac1_df))])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Split dataset into train,test and validate sets**"},{"metadata":{"trusted":true},"cell_type":"code","source":"open_training = train.iloc[:, 1:2].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Normalize data:\nThe data is not normalized and the range for each column varies, especially Volume. Normalizing data helps the algorithm in converging i.e. to find local/ global minimum efficiently. I will use MinMaxScaler from Sci-kit Learn. Use a range to keep values similar for that much range**\n\n**Keep a window for the length 2000 for your data between 50 and 500...since our length is slightly more than 2000 ill make it 60 to 450**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#normalise\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range = (0, 1))\nopen_training = scaler.fit_transform(open_training)\n#convert to right shape\nfeatures_set_1 = []\nlabels_1 = []\nfor i in range(60,450): \n    features_set_1.append(open_training[i-60:i, 0])\n    labels_1.append(open_training[i, 0])\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_set_1, labels_1 = np.array(features_set_1), np.array(labels_1)\nfeatures_set_1 = np.reshape(features_set_1, (features_set_1.shape[0], features_set_1.shape[1], 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#training it\nmodel = Sequential()\nmodel.add(LSTM(units=50, return_sequences=True, input_shape=(features_set_1.shape[1],1)))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(units=50, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(units = 1))\nmodel.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['mean_absolute_error'])\nmodel.fit(features_set_1, labels_1, epochs = 100, batch_size = 32,validation_data = (features_set_1, labels_1))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#TESTING THE MODEL\nopen_testing_processed = test.iloc[:, 1:2].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert test data to right format\nopen_total = pd.concat((train['Open'], test['Open']), axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Start predictions: Reshape, scale and then oredict the model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_inputs = open_total[len(open_total) - len(test) - 60:].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scaling data\ntest_inputs = test_inputs.reshape(-1,1)\ntest_inputs = scaler.transform(test_inputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features = []\nfor i in range(60, 151):\n    test_features.append(test_inputs[i-60:i, 0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features = np.array(test_features)\ntest_features.shape\ntest_features = np.reshape(test_features, (test_features.shape[0], test_features.shape[1], 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#make predictions\npredictions = model.predict(test_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = scaler.inverse_transform(predictions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot the prediction model for the number of test days and train days**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.plot(open_testing_processed, color='pink', label='Actual Stock Price')\nplt.plot(predictions , color='yellow', label='Predicted Stock Price')\nplt.title('Actual Value vs Predicted')\nplt.xlabel('Date')\nplt.ylabel('Predicted Price')\nplt.legend()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">**This wasn't a great result with one feature so let's try using more features and then train them on LSTM model**"},{"metadata":{},"cell_type":"markdown","source":"**USING 5 FEATURES :**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = cac1_df[['Open','High','Low','Close','Turnover']]\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# FUNCTION TO CREATE 1D DATA INTO TIME SERIES DATASET\ndef new_dataset(dataset, step_size):\n\tdata_X, data_Y = [], []\n\tfor i in range(len(dataset)-step_size-1):\n\t\ta = dataset[i:(i+step_size), 0]\n\t\tdata_X.append(a)\n\t\tdata_Y.append(dataset[i + step_size, 0])\n\treturn np.array(data_X), np.array(data_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# IMPORTING IMPORTANT LIBRARIES\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\nfrom keras.layers import LSTM","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# FOR REPRODUCIBILITY\nnp.random.seed(7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# IMPORTING DATASET \ndataset = dataset.reindex(index = dataset.index[::-1])\n# CREATING OWN INDEX FOR FLEXIBILITY\nobs = np.arange(1, len(dataset) + 1, 1)\n# TAKING DIFFERENT INDICATORS FOR PREDICTION\nOHLC_avg = dataset.mean(axis = 1)\nHLC_avg = dataset[['High', 'Low', 'Close']].mean(axis = 1)\nclose_val = dataset[['Close']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PLOTTING All INDICATORS IN PLOT\nplt.plot(OHLC_avg, 'yellow', label = 'OHLC avg')\nplt.plot(close_val, 'blue', label = 'Closing price')\nplt.xlabel('Days')\nplt.ylabel('OHLC average')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(HLC_avg, 'red', label = 'HLC avg')\nplt.xlabel('Days')\nplt.ylabel('HLC average')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(close_val, 'blue', label = 'Closing price')\nplt.xlabel('Days')\nplt.ylabel('Closing Values')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PREPARATION OF TIME SERIES DATASE\nOHLC_avg = np.reshape(OHLC_avg.values, (len(OHLC_avg),1)) \nscaler = MinMaxScaler(feature_range=(0, 1))\nOHLC_avg = scaler.fit_transform(OHLC_avg)\n# TRAIN-TEST SPLIT\ntrain_OHLC = int(len(OHLC_avg) * 0.75)\ntest_OHLC = len(OHLC_avg) - train_OHLC\ntrain_OHLC, test_OHLC = OHLC_avg[0:train_OHLC,:], OHLC_avg[train_OHLC:len(OHLC_avg),:]\n# TIME-SERIES DATASET (FOR TIME T, VALUES FOR TIME T+1)\ntrainX, trainY = new_dataset(train_OHLC, 1)\ntestX, testY = new_dataset(test_OHLC, 1)\n# RESHAPING TRAIN AND TEST DATA\ntrainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\ntestX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\nstep_size = 1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LSTM MODEL\nmodel = Sequential()\nmodel.add(LSTM(32, input_shape=(1, step_size), return_sequences = True))\nmodel.add(LSTM(16))\nmodel.add(Dense(1))\nmodel.add(Activation('linear'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MODEL COMPILING AND TRAINING\nmodel.compile(loss='mean_squared_error', optimizer='adagrad',metrics = ['mae']) # Try mae, adam, adagrad and compare!!!\nmodel.fit(trainX, trainY, epochs=50, batch_size=1, verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mae = model.evaluate(testX, testY, batch_size=16)\nprint('Mean Absolute Error for Y:', mae)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PREDICTION\ntrainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DE-NORMALIZING FOR PLOTTING\ntrainPredict = scaler.inverse_transform(trainPredict)\ntrainY = scaler.inverse_transform([trainY])\ntestPredict = scaler.inverse_transform(testPredict)\ntestY = scaler.inverse_transform([testY])\n# TRAINING RMSE\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train RMSE: %.2f' % (trainScore))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TEST RMSE\ntestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test RMSE: %.2f' % (testScore))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CREATING SIMILAR DATASET TO PLOT TRAINING PREDICTIONS\ntrainPredictPlot = np.empty_like(OHLC_avg)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[step_size:len(trainPredict)+step_size, :] = trainPredict\n# CREATING SIMILAR DATASSET TO PLOT TEST PREDICTIONS\ntestPredictPlot = np.empty_like(OHLC_avg)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(trainPredict)+(step_size*2)+1:len(OHLC_avg)-1, :] = testPredict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PLOT OF MAIN OHLC VALUES, TRAIN PREDICTIONS AND TEST PREDICTIONS\nplt.plot(trainPredictPlot, 'r', label = 'training set')\nplt.plot(testPredictPlot, 'b', label = 'predicted stock price/test set')\nplt.legend(loc = 'upper right')\nplt.xlabel('Time in Days')\nplt.ylabel('Trend of training and prediction data')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PREDICT FUTURE VALUES\nlast_val = testPredict[-1]\nlast_val_scaled = last_val/last_val\nnext_val = model.predict(np.reshape(last_val_scaled, (1,1,1)))\nprint(\"Last Day Value:\", np.asscalar(last_val))\nprint(\"Next Day Value:\", np.asscalar(last_val*next_val))\n# print np.append(last_val, next_val)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}