{"cells":[{"metadata":{},"cell_type":"markdown","source":"\n# <center>![](https://catho-edu-ssr-assets.eduadvice.co/images/holders/iesb-centro-universitario-do-instituto-de-educacao-superior-de-brasilia-iesb@logo2x.jpeg)</center>\n\n# <center>DATA MINING E MACHINE LEARNING II</center>\n# <center>PROJETO FINAL</center>\n\n> Prof.: Marcos\n> \n> Aluno: Ramonn\n"},{"metadata":{},"cell_type":"markdown","source":"### Contexto\n\n> O departamento de crédito ao consumidor de um banco deseja automatizar o processo de tomada de decisão para aprovação das linhas de crédito do patrimônio líquido. Para fazer isso, eles seguirão as recomendações da Lei da Igualdade de Oportunidades de Crédito para criar um modelo de pontuação de crédito derivado empiricamente e estatisticamente sólido. O modelo será baseado em dados coletados de solicitantes recentes concedidos crédito através do processo atual de subscrição de empréstimos. O modelo será construído a partir de ferramentas de modelagem preditiva, mas o modelo criado deve ser suficientemente interpretável para fornecer um motivo para qualquer ação adversa (rejeição).\n\n\n### Conteúdo\n\n> O conjunto de dados de Home Equity (HMEQ) contém informações de linha de base e de desempenho de empréstimos para 5.960 empréstimos recentes de home equity. O alvo (BAD) é uma variável binária que indica se um requerente acabou por falhar ou se foi gravemente delinqüente. Esse desfecho adverso ocorreu em 1.189 casos (20%). Para cada candidato, foram registradas 12 variáveis de entrada.\n\n\n### Inspiração\n> E se você puder prever clientes que não pagam seus empréstimos?\n\n\n### Descrição dos dados:\n* BAD/RUIM: 1 = cliente inadimplente no empréstimo 0 = empréstimo reembolsado\n* LOAN/EMPRÉSTIMO: Montante do pedido de empréstimo\n* MORTDUE: Valor devido da hipoteca existente\n* VALUE: valor da propriedade atual\n* REASON/MOTIVO: DebtCon = consolidação da dívida HomeImp = melhoria da casa\n* JOB/TRABALHO: Seis categorias profissionais (Manager, Office, Other, Prof.Executive, Sales, Self)\n* YOJ: Anos no emprego atual\n* DEROG: Número de principais relatórios depreciativos\n* DELINQ: número de linhas de crédito inadimplentes\n* CLAGE: Idade da linha comercial mais antiga em meses\n* NINQ: Número de linhas de crédito recentes\n* CLNO: Número de linhas de crédito\n* DEBTINC/DÍVIDA: Taxa de receita da dívida (é a porcentagem da renda bruta mensal de um consumidor que é destinada ao pagamento de dívidas)\n\n### Dados renomeados para melhor entendimento:\n* inadim: 1 = cliente inadimplente no empréstimo 0 = empréstimo reembolsado\n* vl_emp: Montante do pedido de empréstimo\n* vl_dev_hip: Valor devido da hipoteca existente\n* vl_prop: valor da propriedade atual\n* mot_emp: DebtCon = consolidação da dívida HomeImp = melhoria da casa\n* prof: Seis categorias profissionais (Manager, Office, Other, Prof.Executive, Sales, Self)\n* anos_emp: Anos no emprego atual\n* nr_rel_dep: Número de principais relatórios depreciativos\n* lin_cred_inadim: número de linhas de crédito inadimplentes\n* meses_lin_ant: Idade da linha comercial mais antiga em meses\n* lin_cred_rec: Número de linhas de crédito recentes\n* lin_cred_atuais: Número de linhas de crédito\n* tx_div_mes: Taxa de receita da dívida (é a porcentagem da renda bruta mensal de um consumidor que é destinada ao pagamento de dívidas)"},{"metadata":{},"cell_type":"markdown","source":"## Importo as bibliotecas"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Arrays, matrizes, cálculos e dataframes\nimport numpy as np\nimport pandas as pd\n\n# Importando a métrica\nfrom sklearn.metrics import accuracy_score\n\n# Divisão dataframe\nfrom sklearn.model_selection import train_test_split\n\n# Métodos de árvores\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\n\n# GridSearch e Cross-validation\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV, StratifiedKFold\n\n# Gráficos\nimport matplotlib.pyplot as plt\n\n# Importo o arquivo\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        df = pd.read_csv(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizo\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Trato os dados"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Renomeio as colunas\ndf.columns = ['inadim', 'vl_emp', 'vl_dev_hip', 'vl_prop', 'mot_emp', 'prof', \n              'anos_emp', 'nr_rel_dep', 'lin_cred_inadim', 'meses_lin_ant', 'lin_cred_rec', \n              'lin_cred_atuais', 'tx_div_mes']        \n\nprint('Qtd inicial de linhas: ', df.shape)\n\n# Removo as linhas que possuem menos de 5 colunas preenchidas\ndf = df[~(df.count(1) <= 5)]\nprint('Qtd final de linhas: ', df.shape)\n\n# Seto 'Other' em prof (Profissão), quando estiver nula\ndf['prof'] = np.where(df['prof'].isna(), 'Other', df['prof'])\n\n# Seto 0 em vl_dev_hip (valor devido de hipoteca), quando estiver nulo\ndf['vl_dev_hip'] = np.where(df['vl_dev_hip'].isna(), 0, df['vl_dev_hip'])\n\n# Para os casos onde existe inadimplência e o valor da casa está nulo, seto 0, isto porque, possivelmente, a pessoa já tenha perdido o imóvel\ndf['vl_prop'] = np.where(df['vl_prop'].isna(), 0, df['vl_prop'])\n\n# Se o motivo do empréstimo estiver nulo e o valor da hipoteca for zero, seto HomeImp, caso contrário, DebtCon\ndf['mot_emp'] = np.where((df['mot_emp'].isna()) & (df['vl_dev_hip'] == 0), 'HomeImp', df['mot_emp'])\ndf['mot_emp'] = np.where((df['mot_emp'].isna()) & (df['vl_dev_hip'] > 0), 'DebtCon', df['mot_emp'])\n\n# Seto 0 em anos_emp quando for nulo\ndf['anos_emp'] = np.where(df['anos_emp'].isna(), 0, df['anos_emp'])\n\n# Preencho a coluna tx_div_mes com a média da mesma coluna, isso porque ninguém tem 0% da renda comprometida, então a média é mais interessante\ndf['tx_div_mes'].fillna(df['tx_div_mes'].mean(), inplace=True)\n\n# Demais colunas, preencho com 0\ndf.fillna(0, inplace=True)\n\n# Transformo texto em número\nfor col in df.columns:\n    if df[col].dtype == 'object':\n        df[col + '_n'] = df[col].astype('category').cat.codes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualizo como ficaram os dados"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizo como ficaram os dados\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizo o tipo dos dados\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Separação das variáveis a serem utilizadas"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separo as colunas que vou utilizar\nfeats = [c for c in df.columns if c not in ['inadim', 'mot_emp', 'prof']]\nfeats_wt = [c for c in df.columns if c not in ['mot_emp', 'prof']]\n\n# Separo as bases de treino e teste\ntrain, test = train_test_split(df[feats_wt], test_size=0.15, random_state=42)\n\n# Verifico o tamanho dos dataframes de treino e teste\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Início dos testes com árvores"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Testo com RandomForest\nrf = RandomForestClassifier(n_estimators=200, random_state=42)\nrf.fit(train[feats], train['inadim'])\nprint('Porcentagem de acerto: ', accuracy_score(test['inadim'], rf.predict(test[feats])))\n\n# Checo a importância das variáveis neste modelo\npd.Series(rf.feature_importances_, index=feats).sort_values().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Testo com GBM\ngbm = GradientBoostingClassifier(n_estimators=200, random_state=42)\ngbm.fit(train[feats], train['inadim'])\nprint('Porcentagem de acerto: ', accuracy_score(test['inadim'], gbm.predict(test[feats])))\n\n# Checo a importância das variáveis neste modelo\npd.Series(gbm.feature_importances_, index=feats).sort_values().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Testo com XGBoost\nxgb = XGBClassifier(n_estimators=200, random_state=42)\nxgb.fit(train[feats], train['inadim'])\nprint('Porcentagem de acerto: ', accuracy_score(test['inadim'], xgb.predict(test[feats])))\n\n# Checo a importância das variáveis neste modelo\npd.Series(xgb.feature_importances_, index=feats).sort_values().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sem adicionar mais parâmetros, senão o random_state, RandomForestClassifier retornou um resultado melhor, por isso vou explorá-lo."},{"metadata":{},"cell_type":"markdown","source":"## Explorando o RandomForestClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# seto os valores que quero testar\nparams = {\n    'n_estimators': [200, 400],\n    'max_depth': [None, 0, 2, 4],\n    'min_samples_split': [1, 2, 4],\n    'min_samples_leaf': [1, 2, 4]\n    #'max_features': [None, 'auto', 'log2'] removi, senão nem roda\n}\n\n# executo antes para conseguir uma melhor combinação de valores\nrf = RandomForestClassifier(n_estimators=200, random_state=42)\n\n# validação cruzada que retorna dobras estratificadas\n# as dobras são feitas preservando a porcentagem de amostras para cada classe\nskf = StratifiedKFold(n_splits=5, shuffle = True, random_state = 42)\n\n# aplicação da grid\ngsc = GridSearchCV(estimator=rf, param_grid=params, cv=skf.split(train[feats], train['inadim'].values), n_jobs=4)\ngsc.fit(train[feats], train['inadim'])\nprint (gsc.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Utilizo os parâmetros sugeridos e testo\nrf = RandomForestClassifier(n_estimators=200, min_samples_leaf=1, max_depth=None, min_samples_split=4, random_state=42)\nrf.fit(train[feats], train['inadim'])\nprint('Porcentagem de acerto: ', accuracy_score(test['inadim'], rf.predict(test[feats])))\n\n# Checo a importância das variáveis\npd.Series(rf.feature_importances_, index=feats).sort_values().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apresentou o mesmo resultado, portanto tentarei evoluir outro método."},{"metadata":{},"cell_type":"markdown","source":"## Explorando também o XGBoost\nXGBoost me retornou o segundo melhor resultado, então vou explorar as opções dele também"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Grid para usar com XGBoost\nparams = {\n        'min_child_weight': [1, 3, 5, 8, 10],\n        'gamma': [0, 0.5, 1, 1.5, 2, 5],\n        'subsample': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [2, 4, 6, 8, 10],\n        'learning_rate': [0.2, 0.4, 0.5, 0.6, 1.0],\n        'max_delta_step': [0, 3, 5, 10],\n        'base_score': [0, 0.3, 0.5, 0.7, 1.0],\n        'n_estimators': [200, 400, 600]\n        }\n\nxgb = XGBClassifier(random_state=42)\n\n# cross-validation\nskf = StratifiedKFold(n_splits=5, shuffle = True, random_state = 42)\n\nrandom_search = RandomizedSearchCV(xgb, \n                                   param_distributions=params,\n                                   n_iter=6,\n                                   scoring='roc_auc', \n                                   n_jobs=4, \n                                   cv=skf.split(train[feats], train['inadim'].values), \n                                   verbose=3, \n                                   random_state=42)\n\nrandom_search.fit(train[feats], train['inadim'].values)\n\nprint('\\n Melhor resultado:')\nprint(random_search.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Utilizo o resultado do RandomSearch\nxgb = XGBClassifier(base_score=0.7, booster=None, colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.6, gamma=1.5, gpu_id=-1,\n              importance_type='gain', interaction_constraints=None,\n              learning_rate=0.5, max_delta_step=10, max_depth=10,\n              min_child_weight=5, monotone_constraints=None,\n              n_estimators=400, n_jobs=0, num_parallel_tree=1,\n              objective='binary:logistic', random_state=42, reg_alpha=0,\n              reg_lambda=1, scale_pos_weight=1, subsample=1.0, tree_method=None,\n              validate_parameters=False, verbosity=None)\n\nxgb.fit(train[feats], train['inadim'])\nprint('Porcentagem de acerto: ', accuracy_score(test['inadim'], xgb.predict(test[feats])))\n\n# Checo a importância das variáveis com os novos parâmetros\npd.Series(xgb.feature_importances_, index=feats).sort_values().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nesse caso, tive um resultado pior do que antes, vou então testar com a mudança de menos parâmetros."},{"metadata":{},"cell_type":"markdown","source":"## Explorando XGBoost com menos parâmetros"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Grid para usar com XGBoost\nparams = {\n        'learning_rate': [0.2, 0.4, 0.5, 0.6, 1.0],\n        'n_estimators': [200, 400, 600]\n        }\n\nxgb = XGBClassifier(random_state=42)\n\n# cross-validation\nskf = StratifiedKFold(n_splits=5, shuffle = True, random_state = 42)\n\nrandom_search = RandomizedSearchCV(xgb, \n                                   param_distributions=params,\n                                   n_iter=6,\n                                   scoring='roc_auc', \n                                   n_jobs=4, \n                                   cv=skf.split(train[feats], train['inadim'].values), \n                                   verbose=3, \n                                   random_state=42)\n\nrandom_search.fit(train[feats], train['inadim'].values)\n\nprint('\\n Melhor resultado:')\nprint(random_search.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Utilizo o resultado do RandomSearch\nxgb = XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n              importance_type='gain', interaction_constraints=None,\n              learning_rate=0.4, max_delta_step=0, max_depth=6,\n              min_child_weight=1, monotone_constraints=None,\n              n_estimators=600, n_jobs=0, num_parallel_tree=1,\n              objective='binary:logistic', random_state=42, reg_alpha=0,\n              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n              validate_parameters=False, verbosity=None)\n\nxgb.fit(train[feats], train['inadim'])\nprint('Porcentagem de acerto: ', accuracy_score(test['inadim'], xgb.predict(test[feats])))\n\n# Checo a importância das variáveis\npd.Series(xgb.feature_importances_, index=feats).sort_values().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Utilizando menos parâmetros, tive uma porcentagem de acerto maior, portanto irei utilizar este último modelo."},{"metadata":{},"cell_type":"markdown","source":"## Conclusão\nPor fim, resolvo utilizar o XGBoost, com a alteração de apenas dois parâmetros, obtendo então mais de 94% de acerto."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apresento os valores referentes aos registros previstos e não previstos\ntest['t_inadim'] = xgb.predict(test[feats]).astype(int)\ntest['acerto'] = test['t_inadim'] == test['inadim']\ntest['acerto'] = np.where(test['acerto'] == True, 'Previsto', 'Não Previsto')\nprint('Previstos: ', str(np.round(test['acerto'].value_counts(normalize=True)[0], 3)) + '%', '-', test['acerto'].value_counts()[0])\nprint('Não Previstos: ', str(np.round(test['acerto'].value_counts(normalize=True)[1], 3)) + '%', '-', test['acerto'].value_counts()[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apresento o resultado em gráfico\npd.value_counts(test['acerto']).plot.bar(color='#4682B4')\nplt.xticks(rotation=0)\nplt.title('Total de registros previstos e não previstos')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}