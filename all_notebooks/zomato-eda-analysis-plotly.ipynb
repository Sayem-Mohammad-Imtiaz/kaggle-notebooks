{"cells":[{"metadata":{},"cell_type":"markdown","source":"Hello!!\n\nLets work analyzing the restaurant and bar chain. To do that, I have though in the following objectives:\n\n1. To plot and analyze in a visual way data we have\n2. To plot the distribution of restaurants in the country\n\nLets see if we can"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/zomato.csv\")\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As first observation we can see that there are 17 columns and 51717 rows. Now, what i am gonna do is to see the meaning of each column and according the objectives that I have written at the beginning, I will see which columns are interesting or not.\n\n1. url - url of the bar - not interesting for my purposes \n2. address - Not interesting for my purposes at the beginning. With the location is enough\n3. Name - Lets keep it\n4. Online order - Interesting\n5. book table - Interesting\n6. rate - very interesting\n7. votes - it is interesting due to with this information I could interpret how many people is attending the bar\n8. phone - nah\n9. location - It seems to be interesting\n10. rest_type - interesting\n11. dish_liked - mmmmm I think not\n12. Cuisines - yeeees\n12. approx_cost - jejejejej\n13. reviews_list - Maybe we could try something with NLP.\n14. menu_item - NLP? I dont know\n15. listed_in (typ3) - Yes\n16. listed_in (city) - YEEEESSSS\n\nIf we check the info about location and we compare it with listed_in, we can see than in location there are some null values. Then, I think I could remove location and let just listed_in(city). What do you think?\n\nSo, we will remove next columns: url, address, phone, location, dish_liked\n\nlets work!"},{"metadata":{"trusted":true},"cell_type":"code","source":"semiclean = [\"url\", \"address\", \"phone\", \"location\", \"dish_liked\"]\ndf_semiclean = df.drop(semiclean, axis = 1)\ndf_semiclean.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Jmmmm some null values in rest, what should we do? I can think in two different options:\n\n - Easy: remove null values\n - Not so easy: to predict these values.\n \nI will start removing these values."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean = df_semiclean.dropna()\ndf_clean.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rates = list()\nfor fila in df_clean.rate:\n    aux = fila[:3]\n    rates.append(aux)\n#df_clean = df_clean.drop([\"rate\"], axis = 1)\ndf_clean = df_clean.assign(rate = rates)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clean.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we start analyzing in a visual way the data. How? we will start comparing the following fields:\n \n - Rates Vs. Prices (Maybe restaurant boss has increased prices due to good rates)\n - Votes Vs. cuisines (Maybe we can get some food trend, who knows?)\n - online_order Vs Prices\n - historic of prices\n - Distribution of prices per city\n \nBut before lets to analyze data trying to find some patterns and studying how these are distributed\nLets start with that to see if we can get some conclusions."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of rates and prices\n\nimport plotly.plotly as py\nimport plotly.graph_objs as go\nimport plotly.offline as ply\nply.init_notebook_mode(connected=True)\n\n\nrate = go.Histogram(x=df_clean[\"rate\"],\n                   opacity=0.75,\n                   name = \"Rate Values\",\n                   )\n\nprice = go.Histogram(x=df_clean[\"approx_cost(for two people)\"],\n                   opacity=0.75,\n                   name = \"Price Values\",\n                   )\n\nlayout = go.Layout(barmode='overlay',\n                   title='Histogram',\n                   xaxis=dict(title='Values'),\n                   yaxis=dict(\n                        title='yaxis title',\n                    ),\n                  )\n\ndata = [rate]\nfig = go.Figure(data=data, layout=layout)                   \nply.iplot(fig)\n\ndata = [price]\nfig = go.Figure(data=data, layout=layout)                   \nply.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace = [go.Scattergl(\n                    x = df_clean[\"rate\"],\n                    y = df_clean[\"approx_cost(for two people)\"],\n                    mode = \"markers\"\n                    )]\nply.iplot(trace)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Votes Vs. Cusines**"},{"metadata":{"trusted":true},"cell_type":"code","source":"cuisines_ = np.unique(df_clean.cuisines)\ncounter = list()\nfor i in cuisines_:\n    aux = len(df_clean.index[df_clean[\"cuisines\"]==i])\n    counter.append(aux)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_count = pd.DataFrame({\"Q\": counter}, index = cuisines_)\ndf_count.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cuisin = [go.Histogram(x=df_count[\"Q\"],\n                   opacity=0.75,\n                   name = \"Cusine counter\",\n                   text = df_count.index,\n                   )]\n\nfig = go.Figure(data=cuisin)                   \nply.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see in the image below that here is accomplished the pareto principle: https://en.wikipedia.org/wiki/Pareto_principle\nThus, next cuisines are the most repeated along india:\n\n - African, Burguer\n - African, Burger, Desserts, Beverages, Fast food\n - American\n \nNext cuisines finally refer to allmost every kind of dishes. Now, thinking (a bit, not to much) it is not efficient to find a relation between kind of cuisines and prices. So next action will be deploy how many restaurantes there are in India per city.\n "},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_ = np.unique(df_clean[\"listed_in(city)\"])\ncounter = list()\nfor i in cities_:\n    aux = len(df_clean.index[df_clean[\"listed_in(city)\"]==i])\n    counter.append(aux)\n\ndf_city = pd.DataFrame({\"Q\": counter}, index = cities_)\ndf_city.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace = [go.Pie(labels=df_city.index, values=df_city[\"Q\"])]\n\nply.iplot(trace)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}