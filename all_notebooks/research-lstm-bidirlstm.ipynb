{"cells":[{"metadata":{},"cell_type":"markdown","source":"## LSTM on Log-Return/MSFT"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\n\nimport os\nos.listdir()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summary=pd.read_csv('/kaggle/input/us-historical-stock-prices-with-earnings-data/dataset_summary.csv')\nprices=pd.read_csv('/kaggle/input/us-historical-stock-prices-with-earnings-data/stocks_latest/stock_prices_latest.csv')\nearnings=pd.read_csv('/kaggle/input/us-historical-stock-prices-with-earnings-data/stocks_latest/earnings_latest.csv')\ndividends=pd.read_csv('/kaggle/input/us-historical-stock-prices-with-earnings-data/stocks_latest/dividends_latest.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Print out schemas of EQTY "},{"metadata":{"trusted":true},"cell_type":"code","source":"## prices\nprices.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## earnings\nearnings.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## dividends\ndividends.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"masterQuote=prices.merge(dividends,on=['symbol','date'],how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"masterQuote=masterQuote.fillna(0.0)\ntickerCount=pd.DataFrame(masterQuote.groupby(['symbol']).count())\ntickerCount=tickerCount.reset_index()\ntickerCount=tickerCount[['symbol','date']]\nqualified=tickerCount[tickerCount['date']>250]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Use MSFT as an example"},{"metadata":{"trusted":true},"cell_type":"code","source":"msft=masterQuote[masterQuote['symbol']=='MSFT']\nmsft=msft.sort_values(by=['date'],ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"msft=msft[['close_adjusted','volume','split_coefficient','dividend']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Calc log-return\n#### & Visualizations"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nhistQuote=msft['close_adjusted'].tolist()\nplt.plot(histQuote)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logRet=np.log(np.array(histQuote[1:])/np.array(histQuote[:-1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(logRet)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"paddedLogRet=[0]+list(logRet)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"msft['logRet']=paddedLogRet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logvolume=np.log(msft['volume'].tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"msft['logVolume']=logvolume","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def makeBatch():\n    tp=msft\n    trainXs=[]\n    trainYs=[]\n    tempTrain=[]\n    for i in range(tp.shape[0]-1500-40):\n        tempTrain=np.array(tp.iloc[i+0:i+40,2:6])\n        trainXs.append(tempTrain)\n        trainYs.append([tp['logRet'].tolist()[i+40]])\n    return np.array(trainXs,dtype='float32'),np.array(trainYs,dtype='float32')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xs,Ys=makeBatch()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Last 1500 as test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.reset_default_graph()\nnum_hidden = 64\n\ndata = tf.placeholder(tf.float32, [None,40,4]) \ntarget = tf.placeholder(tf.float32, [None,1])\n## LSTM\ncell = tf.nn.rnn_cell.LSTMCell(num_hidden,activation='tanh',initializer=tf.random_normal_initializer())\nval, state = tf.nn.dynamic_rnn(cell, data, dtype=tf.float32)\nval = tf.transpose(val, [1, 0, 2])\nlast = tf.gather(val, int(val.get_shape()[0]) - 1)\n## Dense 1\nweight = tf.Variable(tf.truncated_normal([num_hidden, 16]))\nbias = tf.Variable(tf.constant(0.1, shape=[16]))\nprediction1=tf.matmul(last, weight) + bias\n## Dense 2\nweight1 = tf.Variable(tf.truncated_normal([16,1]))\nbias1 = tf.Variable(tf.constant(0.1, shape=[1]))\nprediction = tf.matmul(prediction1, weight1) + bias1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mse = tf.reduce_sum(tf.keras.losses.MSE(prediction,target))\noptimizer = tf.train.AdamOptimizer(0.003).minimize(mse)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"init=tf.global_variables_initializer()\nsess=tf.Session()\nsess.run(init)\nXs,Ys=makeBatch()\nbatch_size=64\nfor i in range(200):\n    ptr = 0\n    for j in range(int(Xs.shape[0]/batch_size)-1):\n        inp, out = Xs[j*batch_size:j*batch_size+batch_size], Ys[j*batch_size:j*batch_size+batch_size]\n        train=sess.run(optimizer,{data: inp, target: out})\n    loss=sess.run(mse,{data: inp, target: out})\n    if (i+1)%100==0:\n        print(\"Epoch - \"+str(i)+\": the loss is: \" +str(loss))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predList=[]\nactualList =[]\n\nfor j in range(int(Xs.shape[0]/batch_size)-1):\n    inp, out = Xs[j*batch_size:j*batch_size+batch_size], Ys[j*batch_size:j*batch_size+batch_size]\n    predTemp=sess.run(prediction,{data: inp})\n    cellTemp=sess.run(val,{data:inp})\n    actualList+=list(out)\n    predList+=list(predTemp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predReturn=[x[0] for x in predList]\nactualReturn=[x[0] for x in actualList]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(predReturn[:30],color='red')\nplt.plot(actualReturn[:30],color='blue')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Test\ndef makeBatchTest():\n    tp=msft\n    trainXs=[]\n    trainYs=[]\n    tempTrain=[]\n    for i in range(tp.shape[0]-1500-40,tp.shape[0]-40-1):\n        tempTrain=np.array(tp.iloc[i+0:i+40,2:6])\n        trainXs.append(tempTrain)\n        trainYs.append([tp['logRet'].tolist()[i+40]])\n    return np.array(trainXs,dtype='float32'),np.array(trainYs,dtype='float32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predList=[]\nactualList =[]\nXs,Ys=makeBatchTest()\nfor j in range(int(Xs.shape[0]/batch_size)-1):\n    inp, out = Xs[j*batch_size:j*batch_size+batch_size], Ys[j*batch_size:j*batch_size+batch_size]\n    predTemp=sess.run(prediction,{data: inp})\n    cellTemp=sess.run(val,{data:inp})\n    actualList+=list(out)\n    predList+=list(predTemp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predReturn=[x[0] for x in predList]\nactualReturn=[x[0] for x in actualList]\nplt.plot(predReturn[:30],color='red')\nplt.plot(actualReturn[:30],color='blue')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot actual quotes instead of log-return"},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nactual_Price=msft['close_adjusted'].tolist()\npredictChunk=actual_Price[-1500:]\npredSeed=actual_Price[-1501]\ngeneratedQuote=[]\nfor logret in predReturn:\n    generatedQuote.append(predSeed*math.exp(logret))\n    predSeed=predSeed*math.exp(logret)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(generatedQuote)\nplt.plot(predictChunk)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Smooth enough but not so good for long term prediction"},{"metadata":{},"cell_type":"markdown","source":"## Lets make it Bi-directional"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ntf.reset_default_graph()\nnum_hidden = 64\n\ndata = tf.placeholder(tf.float32, [None,40,4]) \ntarget = tf.placeholder(tf.float32, [None,1])\n## LSTM\ncellfw = tf.nn.rnn_cell.LSTMCell(num_hidden,activation='tanh',initializer=tf.random_normal_initializer())\ncellbw = tf.nn.rnn_cell.LSTMCell(num_hidden,activation='tanh',initializer=tf.random_normal_initializer())\n\nlstm_fw_multicell = tf.nn.rnn_cell.MultiRNNCell([cellfw])\nlstm_bw_multicell = tf.nn.rnn_cell.MultiRNNCell([cellbw])\n\nvalAll, state= tf.nn.bidirectional_dynamic_rnn(lstm_fw_multicell, lstm_bw_multicell, data, dtype=tf.float32)\nout_fw, out_bw = valAll\noutput = tf.concat([out_fw, out_bw], axis=-1)\n#val, state = tf.nn.dynamic_rnn(cell, data, dtype=tf.float32)\nval = tf.transpose(output , [1, 0, 2])\nlast = tf.gather(val, int(val.get_shape()[0]) - 1)\n## Dense 1\nweight = tf.Variable(tf.truncated_normal([num_hidden*2, 16]))\nbias = tf.Variable(tf.constant(0.1, shape=[16]))\nprediction1=tf.matmul(last, weight) + bias\n## Dense 2\nweight1 = tf.Variable(tf.truncated_normal([16,1]))\nbias1 = tf.Variable(tf.constant(0.1, shape=[1]))\nprediction = tf.matmul(prediction1, weight1) + bias1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mse = tf.reduce_sum(tf.keras.losses.MSE(prediction,target))\noptimizer = tf.train.AdamOptimizer(0.003).minimize(mse)\ninit=tf.global_variables_initializer()\nsess=tf.Session()\nsess.run(init)\nXs,Ys=makeBatch()\nbatch_size=64\nfor i in range(200):\n    ptr = 0\n    for j in range(int(Xs.shape[0]/batch_size)-1):\n        inp, out = Xs[j*batch_size:j*batch_size+batch_size], Ys[j*batch_size:j*batch_size+batch_size]\n        train=sess.run(optimizer,{data: inp, target: out})\n    loss=sess.run(mse,{data: inp, target: out})\n    if (i+1)%100==0:\n        print(\"Epoch - \"+str(i)+\": the loss is: \" +str(loss))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predList=[]\nactualList =[]\n\nfor j in range(int(Xs.shape[0]/batch_size)-1):\n    inp, out = Xs[j*batch_size:j*batch_size+batch_size], Ys[j*batch_size:j*batch_size+batch_size]\n    predTemp=sess.run(prediction,{data: inp})\n    cellTemp=sess.run(val,{data:inp})\n    actualList+=list(out)\n    predList+=list(predTemp)\npredReturn=[x[0] for x in predList]\nactualReturn=[x[0] for x in actualList]\nplt.plot(predReturn[:30],color='red')\nplt.plot(actualReturn[:30],color='blue')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Test\ndef makeBatchTest():\n    tp=msft\n    trainXs=[]\n    trainYs=[]\n    tempTrain=[]\n    for i in range(tp.shape[0]-1500-40,tp.shape[0]-40-1):\n        tempTrain=np.array(tp.iloc[i+0:i+40,2:6])\n        trainXs.append(tempTrain)\n        trainYs.append([tp['logRet'].tolist()[i+40]])\n    return np.array(trainXs,dtype='float32'),np.array(trainYs,dtype='float32')\npredList=[]\nactualList =[]\nXs,Ys=makeBatchTest()\nfor j in range(int(Xs.shape[0]/batch_size)-1):\n    inp, out = Xs[j*batch_size:j*batch_size+batch_size], Ys[j*batch_size:j*batch_size+batch_size]\n    predTemp=sess.run(prediction,{data: inp})\n    cellTemp=sess.run(val,{data:inp})\n    actualList+=list(out)\n    predList+=list(predTemp)\npredReturn=[x[0] for x in predList]\nactualReturn=[x[0] for x in actualList]\nplt.plot(predReturn[:30],color='red')\nplt.plot(actualReturn[:30],color='blue')\nplt.show()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nactual_Price=msft['close_adjusted'].tolist()\npredictChunk=actual_Price[-1500:]\npredSeed=actual_Price[-1501]\ngeneratedQuote=[]\nfor logret in predReturn:\n    generatedQuote.append(predSeed*math.exp(logret))\n    predSeed=predSeed*math.exp(logret)\nplt.plot(generatedQuote)\nplt.plot(predictChunk)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"}},"nbformat":4,"nbformat_minor":1}