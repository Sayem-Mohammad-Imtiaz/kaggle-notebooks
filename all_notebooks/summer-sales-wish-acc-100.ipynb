{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from plotly.offline import iplot, init_notebook_mode\n\nimport cufflinks as cf\nimport plotly.graph_objs as go\n# import chart_studio.plotly as py\n\ninit_notebook_mode(connected=True)\ncf.go_offline(connected=True)\n\n# Set global theme\ncf.set_config_file(world_readable=True, theme='ggplot')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Info\n\n## Context\n\nStudying top products requires more than just product listings. You also need to know what sells well and what does not.\n\n## Content\n\nThis dataset contains product listings as well as products ratings and sales performance, which you would not find in other datasets.\n\nWith this, you can finally start to look for correlations and patterns regarding the success of a product and the various components.\n\n## Inspiration\n\nHow about trying to validate the established idea of human sensitiveness to price drops ? (discounted price compared to original retail_price)\n\nYou may look for top categories of products so that you know what sells best\n\nDo bad products sell ? \n\nHow about the relationship between the quality of a product (ratings) and its success ? \n\nDoes the price factor into this ?\n\n\n\n## Infos on Columns\n\n1. title : Title for localized for european countries. May be the same as title_orig if the seller did not offer a translation.\n\n2. title_orig : Original english title of the product.\n\n3. price : price for the buyer\n\n4. retail_price : Retail price, or reference price in other stores/places. Used by the seller to indicate a regular value or the price before discount.\n\n5. currency_buyer : currency of the prices\n\n6. units_sold : Number of units sold. Lower bound approximation by steps\n\n7. uses_ad_boosts : Whether the seller paid to boost his product within the platform (highlighting, better placement or whatever).\n\n8. rating : Mean product rating.\n\n9. rating_count : Total number of ratings of the product\n\n10. rating_five_count  : Number of 5-star ratings (there are also similar rating columns for four, three .. stars)\n\n11. badges_count : Number of badges the product or the seller have.\n\n12. badge_local_product : A badge that denotes the product is a local product. Conditions may vary (being produced locally, or something else).  Some people may prefer buying local products rather than. 1 means Yes, has the badge. \n\n13. badge_product_quality : Badge awarded when many buyers consistently gave good evaluations 1 means Yes, has the badge\n\n14. badge_fast_shipping : Badge awarded when this product's order is consistently shipped rapidly\n\n15. tags : tags set by the seller\n\n16. product_color : Product's main color\n\n17. product_variation_size_id : One of the available size variation for this product\n\n18. product_variation_inventory : Inventory the seller has. Max allowed quantity is 50\n\n19. shipping_option_price : shipping price\n\n20. shipping_is_express : whether the shipping is express or not. 1 for True\n\n21. countries_shipped_to : Number of countries this product is shipped to. Sellers may choose to limit where they ship a product to\n\n22. inventory_total : Total inventory for all the product's variations (size/color variations for instance)\n\n23. has_urgency_banner : whether there was an urgency banner with an urgency\n\n24. merchant_rating : merchant's rating\n\n*Note: Not all the columns are present in the above description.*\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/summer-products-and-sales-in-ecommerce-wish/summer-products-with-rating-and-performance_2020-08.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"uniuqe_categories = pd.read_csv(\"/kaggle/input/summer-products-and-sales-in-ecommerce-wish/unique-categories.csv\")\nuniuqe_categories_count = pd.read_csv(\"/kaggle/input/summer-products-and-sales-in-ecommerce-wish/unique-categories.sorted-by-count.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Explorations","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Merchant Columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.loc[:,df.columns.str.startswith(\"merchant\")].columns.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"lets drop everything related to merchent except *merchant_id, merchant_rating_count,and merchant_ratings*.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['merchant_has_profile_picture', 'merchant_profile_picture','merchant_title' ,'merchant_name', 'merchant_info_subtitle'], inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Null Columns ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[:,df.isnull().sum()>0].columns\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Theme column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.theme.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Theme column has only one value *summer*, so its no-use for analysis or model prediction. Lets drop this column.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('theme', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Title and Title_orig column\n\nTitle and title_orig columns share same value, for our case, lets use the one with english tilte i.e. title_orig and drop title column.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(\"title\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Urgency Text and Urgency Banner\n\nBoth columns have null values, and in very large number so lets drop them.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf.drop(['urgency_text','has_urgency_banner'], inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fill the rest of null-columns by value \"unknown\".","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.fillna(value=\"unknown\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Currency Column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.currency_buyer.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since the data was only taken from France, currency is only in euros. Lets remember that and drop the columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('currency_buyer', inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Crawl Month","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.crawl_month.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looke like crawl month is only from August, lets drop this column too.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('crawl_month', inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Badges Columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[:,df.columns.str.startswith('badge')].columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets convert **'badge_local_product', 'badge_product_quality', 'badge_fast_shipping'** into categorical values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['badge_local_product', 'badge_product_quality','badge_fast_shipping']] = df[['badge_local_product', 'badge_product_quality','badge_fast_shipping']].astype(str)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA \n\nlets do some explorations via visualizations","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Origin Country","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_df = df.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Rename country columns for clear meaning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_df.origin_country = eda_df.origin_country.str.replace( 'CN',\"China\" )\neda_df.origin_country = eda_df.origin_country.str.replace( \"US\",\"United States of America\" )\neda_df.origin_country = eda_df.origin_country.str.replace( \"unknown\",\"unknown\" )\neda_df.origin_country = eda_df.origin_country.str.replace( \"VE\",\"Venezuela\" )\neda_df.origin_country = eda_df.origin_country.str.replace( 'GB',\"Great Britain\" )\neda_df.origin_country = eda_df.origin_country.str.replace( 'SG',\"Singapore\" )\neda_df.origin_country = eda_df.origin_country.str.replace( 'AT',\"Austria\" )\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = eda_df.origin_country.value_counts(normalize=True).index.values\n\nvalues  = eda_df.origin_country.value_counts().values\n\n# Create Pie Chart\n\nfig = go.Figure()\nfig.add_trace(go.Pie(labels=labels, values=values))\nfig.update_layout(title=\"Country of Origin of Product in Wish\", legend_title=\"Countries\", template=\"plotly_dark\")\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seems the products mostly originate from China.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets create so called discounts column by subtracting the price from  retail_price\n\neda_df['discounted_price'] = eda_df['retail_price'] - eda_df['price']\nprices_by_country = eda_df[['price','discounted_price','retail_price','origin_country']].groupby('origin_country').mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\n\nfig.add_trace(go.Bar(x=prices_by_country.index.values, y=prices_by_country.price, name=\"Price\"))\nfig.add_trace(go.Scatter(x=prices_by_country.index.values, y=prices_by_country.discounted_price, name=\"Discounted Price\"))\nfig.add_trace(go.Bar(x=prices_by_country.index.values, y=prices_by_country.retail_price, name=\"Retail Price\"))\nfig.update_layout(title=\"Prices Categories By Country\", xaxis_title=\"Countries\", yaxis_title=\"Avg Discount Prices\", template=\"plotly_dark\", legend_title=\"Legend\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The graph, displpays that theres a heavy discounts on prodcuts from Venezuela as displayed by red line by avg of around 27 euros. \n\nSurprisingly, from the period of July,2020, when the data was taken, selling prices are higher than retail prices in countries like **Austria, GB and Singapore**. China where most of the product in the data is coming from is sold on average of around 8.5 euros with discounts on average of around 14 euros.\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Prices In China ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_df[eda_df.origin_country==\"China\"]['price'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"About 75% of products coming from China are near 10 euros.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"layout=dict(title=\"Selling Price Ranges In China\", xaxis_title=\"Prices\", yaxis_title=\"Frequency\",)\neda_df[eda_df.origin_country==\"China\"]['price'].iplot(kind=\"hist\", bins=50 , layout=layout)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_df[eda_df.origin_country==\"China\"]['retail_price'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"layout=dict(title=\"Original Price Ranges In China\", xaxis_title=\"Prices\", yaxis_title=\"Frequency\",)\neda_df[eda_df.origin_country==\"China\"]['retail_price'].iplot(kind=\"hist\", layout=layout)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Shipping Options and Prices","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_df.loc[:,eda_df.columns.str.startswith(\"shipping\")].columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_df['shipping_option_name'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Livraison standard** is quite populuar option for shipping. Lets check the prices of the company.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nlivrasion_prices = eda_df[eda_df.shipping_option_name =='Livraison standard']['shipping_option_price'].value_counts().index.values\nlivrasion_prices_frquency = eda_df[eda_df.shipping_option_name =='Livraison standard']['shipping_option_price'].value_counts().values\n\nfig = go.Figure()\nfig.add_trace(go.Pie(labels=livrasion_prices, values=livrasion_prices_frquency))\nfig.update_layout(title=\"Livrasion Standard Prices\", legend_title=\"Prices In Euros\", template=\"plotly_dark\")\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most customers choose shipping options from 1-3 euros. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_df['shipping_is_express'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Almost all the shipping is not express","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Products and Sales\n\nLets try and make a small df thats related to product and their sales.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"product_cat_columns = eda_df.loc[:,eda_df.columns.str.startswith(\"product\")].columns.values\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_df[product_cat_columns].info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_df[product_cat_columns].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets drop links ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['product_picture','product_url'], inplace=True, axis=1)\neda_df.drop(['product_picture','product_url'], inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_df_products = eda_df[['tags', 'price', 'units_sold', 'rating','rating_count', 'product_id','badges_count', 'badge_product_quality']].copy().sort_values(['units_sold','badges_count'], ascending=False)\n\neda_df_products_by_id = eda_df_products.set_index('product_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_df_products_by_id.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If u look at the top sold products and their respective badge count then it does not seem there's a positive correlation, however, the units_sold is not clear on months, product relase dates, and so on..","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The top 6 products sold are 100k while others are at 50k, so thats a massive difference. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Top 10 products sold for women\neda_df_products.loc[eda_df_products.tags.str.contains('[Ww]omen')].head(10).index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Top 10 products in general\neda_df_products.head(10).index ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The index is same for both in general and women products, so top buyers are ladies or for ladies in wish.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Due to huge variation in units plotting without normalizing was not quite helpful.So, lets first normalize and then plot.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\neda_df_products_by_id_norm = eda_df_products_by_id.copy()\neda_df_products_by_id_norm.iloc[:,1:] = scaler.fit_transform(eda_df_products_by_id_norm.iloc[:,1:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\n\nfig.add_trace(go.Bar(x=eda_df_products_by_id_norm.head(20).index.values,y=eda_df_products_by_id_norm.head(20).units_sold,name=\"Units Sold\"  ))\nfig.add_trace(go.Scatter(x=eda_df_products_by_id_norm.head(20).index.values,y=eda_df_products_by_id_norm.head(20).price, mode=\"lines+markers\", name=\"Price\" ))\nfig.add_trace(go.Scatter(x=eda_df_products_by_id_norm.head(20).index.values,y=eda_df_products_by_id_norm.head(20).rating_count,mode=\"lines+markers\",name=\"Rating Counts\"  ))\nfig.add_trace(go.Scatter(x=eda_df_products_by_id_norm.head(20).index.values,y=eda_df_products_by_id_norm.head(20).rating,mode=\"lines+markers\",name=\"Avg. Rating\"  ))\n\nfig.update_layout(title=\"Top 20 Products Sold\", legend_title=\"Features\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_df_products_by_id.head(20).describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eda_df_products_by_id.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From plot and description, 75%  of the prodcut's cost less than 10 euros and products have average ratings of 3.8.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Discounts, Ratings and Sales","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We'll first select some columns seems more relevant to the context. After that lets apply binning of every 1k units sold to get a better grasp of proper range of sale and then analyse it. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dis_rat_slaes = eda_df[['rating', 'product_id', 'units_sold', 'price','discounted_price']]\ndis_rat_slaes.set_index('product_id').head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bins_per_1k= [i for i in range(0,101001,1000)]\nlabels_bins_per_1k = [str(vals)[:-3]+\"k's\" for vals in bins_per_1k[1:]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bins_per_1k_units = pd.cut(dis_rat_slaes.units_sold,bins_per_1k, labels=labels_bins_per_1k )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dis_rat_slaes['bins_per_1k_units'] = bins_per_1k_units","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dis_rat_slaes.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dis_rat_slaes_per_1k_units_sold = dis_rat_slaes.groupby('bins_per_1k_units').agg('mean')\n\ndis_rat_slaes_per_1k_units_sold","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"lets drop the NAN columns since they are not very helpful.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dis_rat_slaes_per_1k_units_sold.dropna(how='all', inplace=True, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dis_rat_slaes_per_1k_units_sold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plots\n\nfig = go.Figure()\n\n\nfig.add_trace(go.Bar(x=dis_rat_slaes_per_1k_units_sold.index.values,y=dis_rat_slaes_per_1k_units_sold.price, name=\"Price\" ))\nfig.add_trace(go.Scatter(x=dis_rat_slaes_per_1k_units_sold.index.values,y=dis_rat_slaes_per_1k_units_sold.discounted_price,mode=\"lines+markers\",name=\"Discounted Price\"  ))\nfig.add_trace(go.Bar(x=dis_rat_slaes_per_1k_units_sold.index.values,y=dis_rat_slaes_per_1k_units_sold.rating,name=\"Avg. Rating\"  ))\n\nfig.update_layout(title=\"Product Sales Per 1k Bins\", legend_title=\"Features\", xaxis_title=\"Units Sold\", yaxis_title=\"Avg Values per 1000\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some important information like product's age on website, release date and so on are not available on data. Hence, assuming or ignoring those facts, it seems higher the discount price more likely is the sale of product to be higher. \n\nOn average of 1000 (missing k's in xaxis were null, i.e no units sold in that range.), the avg, customer rating has not changed much, ranging around 3.8 mostly.\n\nWhile as for price, item's sold from 50k-100k are cheaper  than lesser sold items on average by 2 euros.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Correlation Heatmap","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def customized_heatmap(corr_df):\n    corr_df =corr_df.iloc[1:,:-1].copy()  \n\n    \n    # Get only half portion of corr_df to avoid repitition, so create mask    \n    mask = np.triu(np.ones_like(corr_df), k=1)\n    \n     \n    # plot a heatmap of the values\n    plt.figure(figsize=(20,14))\n    plt.title(\"Heatmap Corrleation\")\n    ax = sns.heatmap(corr_df, vmin=-1, vmax=1, cbar=False,\n                     cmap='rainbow', mask=mask, annot=True)\n    \n    # format the text in the plot to make it easier to read\n    for text in ax.texts:\n        t = float(text.get_text())\n        if -0.4 < t < 0.4:\n\n#         if -0.5 < t < 0.5:\n            text.set_text('')        \n        else:\n            text.set_text(round(t, 2))\n        text.set_fontsize('x-large')\n    plt.xticks( size='x-large')\n    plt.yticks(rotation=0, size='x-large')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install dython","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import dython to check correlations\nfrom dython.nominal import associations\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assoc = associations(eda_df,plot=False)\ncorr_eda_df_dython = assoc['corr']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customized_heatmap(corr_eda_df_dython)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess_df = eda_df.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets first deal with colinear columns ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Ratings\n\nRatings column as shown in Heatmaps are highly colinear with each other as expected, but since \"rating\" column is average of several star rating column,lets drop one star to five star column and since we are using rating column to predict, lets convert the average rating column to a category with low, mediumn and high ratings divided according to following threshold.\n\n<2.5 = Low, 2.5 <= medium < 3.75, >3.75 = high ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess_df.loc[:,preprocess_df.columns.str.startswith(\"rating\")].columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess_df.drop([ 'rating_five_count', 'rating_four_count','rating_three_count','rating_two_count', 'rating_one_count'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def five_rating_to_level_rating(val):\n    if val<2.5:\n        return \"low\"\n    elif 2.5>= val <3.75:\n        return \"medium\"\n    else:\n        return \"high\"\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings = preprocess_df.rating.apply(five_rating_to_level_rating)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"More on the dealing with class imbalances later below.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\npreprocess_df.rating = ratings","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## IDs\n\nColumns with ids will mislead our algorithms so lets drop them","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess_df.drop(['merchant_id', 'product_id'],axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Origin Country, Shipping Names\n\nThese columns have about one value dominating about 98%. Moreover have very low correlation threshold. lets drop these two columns.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess_df.drop(['origin_country', 'shipping_option_name'],axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess_df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tags \n\nLets refine tags column ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets check the proportion of top 20 tags count \n(uniuqe_categories_count['count'].head(20).sum() / uniuqe_categories_count['count'].sum())*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since top 20 tags are 41% of total tags lets repalce make bag of words string from those top 20 tagsb\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bag_of_words =uniuqe_categories_count.keyword.head(20).str.lower().tolist()\n# bag_of_words_reg_pattern =[\"\\\\b{}\\\\b\".format(word) for word in bag_of_words]\n# bag_of_words_reg_pattern_str =  \"|\".join(bag_of_words_reg_pattern)\n\nbag_of_words","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. First replace uppercases with lowercases\n2. Create separate columns with top 20 tags we created earlier. Then drop tags columns, also title_orig","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for word in bag_of_words:\n    # First check if str contains the word\n    #If yes converto to 1 , if no convert to 0\n    # Again convert 1 and 0 into strings for dummy variables later.\n    \n    preprocess_df[\"tag_\"+word] = preprocess_df.tags.str.lower().str.contains(word).astype(int).astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess_df.drop(['title_orig','tags'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Product Color\n\nThe product color has positive correlation with inventory total and shipping price but this correlation does not makes sense. Lets not use this coloumn for prediction.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess_df.drop('product_color', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Discounted Price column has been created from the retial_price and price column so, lets not use the column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess_df.drop('discounted_price', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Classification","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df = preprocess_df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import DecisionTreeClassifier as DC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df_dummified = pd.get_dummies(final_df, drop_first=True)\nfinal_df_dummified['rating'] = final_df['rating']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dealing With Dependent Class Imbalances","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dependent_classes_labels= preprocess_df.rating.value_counts().index.values\ndependent_classes_values = preprocess_df.rating.value_counts().values\nfig = go.Figure()\nfig.add_trace(go.Pie(labels=dependent_classes_labels, values=dependent_classes_values))\nfig.update_layout(title=\"Imbalances in Dependent Classes\", legend_title=\"Target Classes\", template=\"plotly_dark\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One of the classes is highly dominant. This can cause model to be biased. Hence, lets try to fix this issue using Oversampling. I am doint it at last becuase SMOTE needs all ints or dummified data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = final_df_dummified.loc[:,final_df_dummified.columns!='rating']\ny= final_df_dummified['rating']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sm = SMOTE(sampling_strategy= 'not majority', random_state=101,k_neighbors=2)\n\nX_res,y_res = sm.fit_resample(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_res.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, the classes are balanced.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Split ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_res,y_res,random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_holdout, X_test_final, y_holdout, y_test_final = train_test_split(X_test, y_test,random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe = Pipeline([('scaler', StandardScaler()), ('rf', RandomForestClassifier())])\n\npipe2 = Pipeline([('scaler_2', StandardScaler()), ('dc', DC())])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets calculate their time as well.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_start = time.time()\npipe.fit(X_train,y_train)\nrf_end = time.time()\neval_time_rf = rf_end -rf_start\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dc_start = time.time()\npipe2.fit(X_train,y_train)\ndc_end = time.time()\neval_time_dc = dc_end -dc_start\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_start_pred = time.time()\npipe.predict(X_test)\nrf_end_pred = time.time()\neval_time_rf_pred = rf_end_pred -rf_start_pred\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dc_start_pred = time.time()\npipe2.predict(X_test)\ndc_end_pred = time.time()\neval_time_dc_pred = dc_end_pred -dc_start_pred\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy For Random forest on Validation Set: {}.\".format(pipe.score(X_holdout,y_holdout)*100) )\n\nprint(\"Accuracy For Decision tree on Validation Set: {}.\".format(pipe2.score(X_holdout,y_holdout)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy For Random forest on Test Set: {}.\".format(pipe.score(X_test_final,y_test_final)*100) )\n\nprint(\"Accuracy For Decision tree on Test Set : {}.\".format(pipe2.score(X_test_final,y_test_final)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total time taken by RF to fit the model: {:.2f} sec\".format(eval_time_rf))\nprint(\"Total time taken by Decision Tree to fit the model: {:.2f} sec\".format(eval_time_dc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total time taken by RF to predict the test set: {:.2f} sec\".format(eval_time_rf_pred))\nprint(\"Total time taken by Decision Tree to predict the test set: {:.2f} sec\".format(eval_time_dc_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Decision Tree seems to be doing better than Random Forest both in accuracy and time taken.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}