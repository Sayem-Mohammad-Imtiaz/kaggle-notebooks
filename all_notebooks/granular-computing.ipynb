{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport itertools\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nprint(\"Imported depending packages\")","metadata":{"_uuid":"4abff0ee-2109-470b-b140-767b9b2b8522","_cell_guid":"366862f4-8036-4ce2-af4c-8d2832ea6dfa","_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 决策信息系统\n\n- 条件属性\n- 决策属性","metadata":{}},{"cell_type":"markdown","source":"## 导入数据集\n\n通过 pandas 导入数据集","metadata":{}},{"cell_type":"code","source":"dataset = pd.read_csv(\"../input/iris/Iris.csv\")\ndataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 使用 min-max 标准化","metadata":{}},{"cell_type":"code","source":"dataset = (dataset - dataset.min()) / (dataset.max() - dataset.min())\ndataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 使用二分法进行数据处理\n\n简单的二分法，取当前 dataset 中每列中最大值和最小值相加的一半作为基准，大于基准的数据设为1，小于基准的数据设为0,同时将数据类型设置为int","metadata":{}},{"cell_type":"code","source":"for column in dataset:\n    max = dataset[column].max()\n    min = dataset[column].min()\n    base = (max + min)/2\n    print(max, min, base)\n    big = dataset[column] >= base\n    small = dataset[column] < base\n    dataset[column] = dataset[column].astype(\"int\")\n    dataset.loc[big, column] = 1\n    dataset.loc[small, column] = 0\n    \ndataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 使用 One hot 处理数据","metadata":{}},{"cell_type":"code","source":"for column in [\"Species\"]:\n    oneHot = pd.get_dummies(dataset[column], prefix=column)\n    dataset = dataset.join(oneHot)\n    dataset = dataset.drop(column, axis = 1)\n    \ndataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 使用模拟退火进行多元优化","metadata":{}},{"cell_type":"code","source":"big = dataset.iloc[:, 0] > 0.5\nbig","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 损失函数\n\ndef lossFun(p):\n    data = dataset.copy()\n    for index, base in enumerate(p):\n        big = data.iloc[:, index] >= base\n        small = data.iloc[:, index] < base\n        data.iloc[:, index] = data.iloc[:, index].astype(\"int\")\n        data.iloc[big, index] = 1\n        data.iloc[small, index] = 0\n#     print(data)\n    rate = coordinatedRate(data)\n    return 1 - rate\nlossFun([1,2,3])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom sko.GA import GA\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nga = GA(\n    func = lossFun,\n    n_dim = dataset.shape[1],\n    size_pop = 50,\n    max_iter = 800,\n    lb = np.zeros(dataset.shape[1], int),\n    ub = np.ones(dataset.shape[1], int),\n    precision = 1e-7\n)\n\nga.to(device = device)\nbest_x, best_y = ga.run()\nprint('best_x:', best_x, '\\n', 'best_y:', best_y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 坐标下降法","metadata":{}},{"cell_type":"code","source":"dataProcessed = dataset.copy()\n# Doing some pre-processing for the dataset here","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseList = np.ones(data.shape[1], int)*0.5\nfor column in baseList:\n    max = 0\n    maxBase = 0\n    for base in np.arange(0.1,1,0.1):\n        data = dataProcessed.copy()\n        big = data[column] >= base\n        small = data[column] < base\n        data[column] = data[column].astype(\"int\")\n        data.loc[big, column] = 1\n        data.loc[small, column] = 0\n        rate = coordinatedRate(data)\n        if rate > max:\n            max = rate\n            maxBase = base\n    print(\"For \", column, \" maxBase \", maxBase)\n    print(\"==========\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nnp.ones(dataset.shape[1], int)*0.5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.arange(0.1,1,0.1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 判断是否粒协调","metadata":{}},{"cell_type":"code","source":"def isCoordinated(row, attrdataset, decidataset):\n    xaa = []\n    xdd = []\n#     print(attrdataset)\n#     print(decidataset)\n    for index in attrdataset.index:\n        isAddxaa = True\n        for column in attrdataset:\n            if attrdataset.loc[index, column] == 0 and attrdataset.loc[row, column] == 1:\n                isAddxaa = False\n        if isAddxaa:\n            xaa.append(index)\n#     print(xaa)\n        \n    for index in decidataset.index:\n        isAddxdd = True\n        for column in decidataset:\n            if decidataset.loc[index, column] == 0 and decidataset.loc[row, column] == 1:\n                isAddxdd = False\n        if isAddxdd:\n            xdd.append(index)\n#     print(xdd)  \n    if contain(xdd, xaa):\n        return True\n    return False\n            \n    \ndef contain(array1, array2):\n    for x in array2:\n        if x not in array1:\n            return False\n    return True\n\nprint(isCoordinated(1, dataset.iloc[:, 1:5], dataset.iloc[:, 5:-1]))\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 计算粒协调的比例","metadata":{}},{"cell_type":"code","source":"def coordinatedRate(dataset):\n    trueNum = 0\n    falseNum = 0\n    isTrue = []\n    for index in dataset.index:\n        if isCoordinated(index, dataset.iloc[:, 1:-3], dataset.iloc[:, -3:]):\n            trueNum += 1\n            isTrue.append(True)\n        else:\n            falseNum += 1\n            isTrue.append(False)\n    rate = trueNum / (trueNum + falseNum)\n    return rate\nprint(coordinatedRate(dataset))\n# print(isTrue)\n# coordinatedDataset = dataset[]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"coordinatedDataset = dataset[isTrue]\ncoordinatedDataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for column in dataset:\n    print(column)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 粒协调决策形式背景的属性约简\n\n> 「粒协调决策形式背景的属性约简与规则融合」算法 1\n\n- Input：*F=(U, A, I, D, G)*\n- Output：*B*\n\n### 算法\n\n1. 已知 *F* 为粒协调形式背景\n2. 构造 *F* 的辨识矩阵\n3. 提取辨识矩阵中的所有集合\n4. 去重并删除空集\n5. 删除存在包含关系的集合\n6. 对剩余集合求笛卡尔积\n7. 输出 *B* 即为该形式背景的粒约简\n\n## 例子\n\n对于 *F=(U, A, I, D, G)*\n\n| **U** | a1 | a2 | a3 | a4 | a5 | a6 | a7 | a8 | d |\n|---|----|----|----|----|----|----|----|----|---|\n| **x1** | 1 | − | − | − | − | 1 | − | − | 1 |\n| **x2** | 1 | − | − | − | − | 1 | 1 | - | 1 |\n| **x3** | 1 | 1 | − | − | − | 1 | 1 | - | 1 |\n| **x4** | - | 1 | − | − | 1 | 1 | 1 | 1 | 3 |\n| **x5** | 1 | − | 1 | − | 1 | - | - | - | 2 |\n| **x6** | 1 | 1 | 1 | − | 1 | - | - | - | 2 |\n| **x7** | - | 1 | 1 | 1 | - | - | - | - | 3 |\n\n*U = {x1, x2, x3, x4, x5, x6, x7}*\n\n*A = {a1,a2,a3,a4,a5,a6,a7,a8}*","metadata":{}},{"cell_type":"code","source":"# 初始化上面的例子\n\nu = np.array([\"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\"])\na = np.array([\"a1\", \"a2\", \"a3\", \"a4\", \"a5\", \"a6\", \"a7\", \"a8\"])\nd = np.array([\"d\"])\ni = np.array([[1, 0, 0, 0, 0, 1, 0, 0, 1],\n              [1, 0, 0, 0, 0, 1, 1, 0, 1],\n              [1, 1, 0, 0, 0, 1, 1, 0, 1],\n              [0, 1, 0, 0, 1, 1, 1, 1, 3],\n              [1, 0, 1, 0, 1, 0, 0, 0, 2],\n              [1, 1, 1, 0, 1, 0, 0, 0, 2],\n              [0, 1, 1, 1, 0, 0, 0, 0, 3],\n             ])\nprint(u,a,d,i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 构造辨识矩阵\ndiscernMat = []\nfor xa in range(0, len(u)):\n    dRow = []\n    for xb in range(0, len(u)):\n        dBlock = []\n        for attr in range(0, len(a)):\n            if i[xa][attr] == 1 and i[xb][attr] != 1 and i[xb][8] != i[xa][8]:\n                dBlock.append(a[attr])\n        dRow.append(dBlock)\n    discernMat.append(dRow)\n\nprint(discernMat)\ndMat = discernMat\n\ndef contain(array1, array2):\n    for x in array2:\n        if x not in array1:\n            return False\n    return True\n\ndList = []\nfor y in dMat:\n    for x in y:\n        if x not in dList:\n            dList.append(x)\ndList.remove([])\nprint()\nprint(dList)\n\nremoveList = []\nfor aList in dList:\n    for aListCompare in dList:\n        if aListCompare != aList:\n            if contain(aListCompare,aList):\n                if aListCompare not in removeList:\n                    removeList.append(aListCompare)\nfor q in removeList:\n    dList.remove(q)\nprint(dList)\nprint(\"粒约简：\")\nfor item in itertools.product(*dList):\n    print(item)\n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}