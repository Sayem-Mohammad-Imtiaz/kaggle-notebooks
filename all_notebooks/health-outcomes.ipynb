{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Table of Contents\n\n\n* [Importing libraries](#importing-libraries)\n* [Loading Data](#loading-data)\n\n"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"importing-libraries\"></a>\n## Importing Libraries\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport os\nfrom os import listdir\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding out all the files that we can analyse and list them for loading and further exploration. \narr = os.listdir('/kaggle/input/healthcare-analytics/Train')\nprint(arr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"loading-data\"></a>\n## Loading Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n#Loading all the files for further explorations.\ntrain_df = pd.read_csv('/kaggle/input/healthcare-analytics/Train/Train.csv')\nfirst_health_df = pd.read_csv('/kaggle/input/healthcare-analytics/Train/First_Health_Camp_Attended.csv')\nsecond_health_df = pd.read_csv('/kaggle/input/healthcare-analytics/Train/Second_Health_Camp_Attended.csv')\nthird_health_df = pd.read_csv('/kaggle/input/healthcare-analytics/Train/Third_Health_Camp_Attended.csv')\nhealth_camp_detail_df = pd.read_csv('/kaggle/input/healthcare-analytics/Train/Health_Camp_Detail.csv')\npatient_profile_df = pd.read_csv('/kaggle/input/healthcare-analytics/Train/Patient_Profile.csv')\ntest_init = pd.read_csv('/kaggle/input/healthcare-analytics/Train/test.csv')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Analyzing the First Health Camp data"},{"metadata":{"trusted":true},"cell_type":"code","source":"first_health_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Analyzing the Second Health Camp data"},{"metadata":{"trusted":true},"cell_type":"code","source":"second_health_df.sort_values(['Health Score'], ascending = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Analyzing the Third Health Camp data "},{"metadata":{"trusted":true},"cell_type":"code","source":"third_health_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"third_health_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"third_health_df.sort_values(['Number_of_stall_visited'], ascending = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_outcome_third = third_health_df[third_health_df['Number_of_stall_visited'] > 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All the positive outcomes from the third health camp are stored in the positive_outcome_third table below - we know that a positive outcome constitutes a number of stalls visited bigger than 11 - so thats how we create this table:"},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_outcome_third","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Finding the pairs of Patient_ID and Health_camp_ID with positive outcomes that figure out in camps 1, 2 or 3 and then creating a data frame where we store them"},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_1 = first_health_df.drop([\"Donation\", 'Health_Score', 'Unnamed: 4'], axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_2 = second_health_df.drop(['Health Score'], axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_3 = positive_outcome_third.drop(['Number_of_stall_visited', 'Last_Stall_Visited_Number'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Concatenating first 2 columns of each of the above 3 databases into one positive outcome:"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"positive_outcomes = pd.concat([positive_1, positive_2, positive_3], axis = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We observe that a patient can attend more than one data camp, or none. The challenge is to observe for each camp, each of the patients whether in the train or test data set has a positive or negative outcome. For that we will have find a way to asses if for each pair in the train set if the outcome was positive or not. Once we have the table that contains all the positive outcomes observed - we can use it to find out if each pair (patient_ID, Health_Camp_ID) in the train set has a positive or negative outlook. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#create tuple column with (Patient_ID, Health_Camp_ID) - we see we have 20534 positive outcomes.\npositive_outcomes['patient_camp'] = list(zip(positive_outcomes.Patient_ID, positive_outcomes.Health_Camp_ID))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_outcomes.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['patient_camp_train'] = list(zip(train_df.Patient_ID, train_df.Health_Camp_ID))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_list = list(positive_outcomes.patient_camp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(positive_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Details of the Healts Camps"},{"metadata":{"trusted":true},"cell_type":"code","source":"health_camp_detail_df.info","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Patient Profiles"},{"metadata":{"trusted":true},"cell_type":"code","source":"patient_profile_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"patient_profile_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We aim to create function that will provide us with a list of camps with positive outcomes atendeded by each patient - and we have the data already stored in the positive_outcomes table:"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"positive_outcomes.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we have 20534 patients and camps touples that qualify as - positive outcomes:\nlen(positive_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_list[:3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#accessing only the camp portion of a tuple:\npositive_list[0][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# how many unique patients we have that have positive outcomes?\nunique_patient_ID_with_positive = list(positive_outcomes.Patient_ID.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_patient_ID_with_positive[:3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we have only 11069 patients with positive outcomes:\nlen(unique_patient_ID_with_positive)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a function that shows all camps with positive outcome attended by a patient:","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def camps(patient):\n    camps = []\n    i = 0\n    while i < 20533:\n        if positive_list[i][0] == patient:\n            camps.append(positive_list[i][1])\n        i += 1\n    return camps\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below started to create a dictionary of camps for each patient - this still does not work - figure out why - I assume for all the null results for the camp function - need to define that better?\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#patient_camps_attended = { 'patient_id': patient_profile_df.Patient_ID,\n#                          'camps': camps(patient_profile_df.Patient_ID)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"camps(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Will create a function that takes 2 parameters - camp and patient - so it  tests if a patient and camp couple is succesfull. If the camp function of the patient is null - we return 0 as it is unsuccesful. But - if the patient did indeed attend a succesful camp - we test to see if this specific camp in the function is in the patients list of camps: \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef outcome(patient, camp):\n    if len(camps(patient)) == 0:\n        return 0\n    \n    elif camp in camps(patient):\n        return 1 \n    else:\n        return 0\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outcome(485679, 6555)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outcome(485679, 6578)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We create a list where we check the outcome for each Patient_ID, Health_Camp_ID in the train dataframe:"},{"metadata":{"trusted":true},"cell_type":"code","source":"outcomes = []\nfor patient_camp_tuple in train_df.patient_camp_train:\n    outcomes.append(outcome(patient_camp_tuple[0], patient_camp_tuple[1])) \noutcomes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(outcomes,columns=['Outcome'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(df.Outcome)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(train_df.Var1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new = pd.concat((train_df, df), axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new.Outcome.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new.Outcome[10014]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new.Outcome.sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Analyzing the Train and Test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_init.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_init.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Preping and Spliting the data ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separate features and labels\nX = new.drop([\"Patient_ID\", \"Health_Camp_ID\",\"Registration_Date\", \"Outcome\", \"patient_camp_train\"], axis = 1)\ny = df\n#y = new.drop([\"Patient_ID\", \"Health_Camp_ID\",\"Registration_Date\",\"patient_camp_train\", \"Var1\", \"Var2\", \"Var3\", \"Var4\", \"Var5\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Analyzing the variables used as features for the model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\n%matplotlib inline\n\nfeatures = ['Var1','Var2','Var3','Var4','Var5']\nfor col in features:\n    new.boxplot(column=col, by='Outcome', figsize=(6,6))\n    plt.title(col)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split data 70%-30% into training set and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n\nprint ('Training cases: %d\\nTest cases: %d' % (X_train.size, X_test.size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train the model\nfrom sklearn.linear_model import LogisticRegression\n\n# Set regularization rate\nreg = 0.01\n\n# train a logistic regression model on the training set\nmodel = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train.values.ravel())\n                                                            \n                                                        \nprint (model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(X_test)\nprint('Predicted labels: ', predictions)\nprint('Actual labels:    ' ,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions.sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.Outcome.sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\nprint('Accuracy: ', accuracy_score(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score\n\nprint(\"Overall Precision:\",precision_score(y_test, predictions))\nprint(\"Overall Recall:\",recall_score(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ROC AUC score, confusion matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\n# Print the confusion matrix\ncm = confusion_matrix(y_test, predictions)\nprint (cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_scores = model.predict_proba(X_test)\nprint(y_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# calculate ROC curve\nfpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n\n# plot ROC curve\nfig = plt.figure(figsize=(6, 6))\n# Plot the diagonal 50% line\nplt.plot([0, 1], [0, 1], 'k--')\n# Plot the FPR and TPR achieved by our model\nplt.plot(fpr, tpr)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\nauc = roc_auc_score(y_test,y_scores[:,1])\nprint('AUC: ' + str(auc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model above has a very poor ROC score - barely better than 0.5. :et try to normalize the data and see if that will improve a bit the outcome:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train the model\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, PowerTransformer\nfrom sklearn.linear_model import LogisticRegression\nimport numpy as np\n\n# Define preprocessing for numeric columns (normalize them so they're on the same scale)\nnumeric_features = [0,1,2,3,4]\nnumeric_transformer = Pipeline(steps=[\n    ('scaler', PowerTransformer())])\n\n# Combine preprocessing steps\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features)])\n\n# Create preprocessing and training pipeline\npipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                           ('logregressor', LogisticRegression(C=1/reg, solver=\"liblinear\"))])\n\n\n# fit the pipeline to train a logistic regression model on the training set\nmodel_pipe = pipeline.fit(X_train, (y_train.values.ravel()))\nprint (model_pipe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get predictions from test data\npredictions_pipe = model_pipe.predict(X_test)\n\n# Get evaluation metrics\ncm = confusion_matrix(y_test, predictions_pipe)\nprint ('Confusion Matrix:\\n',cm, '\\n')\nprint('Accuracy:', accuracy_score(y_test, predictions_pipe))\nprint(\"Overall Precision:\",precision_score(y_test, predictions_pipe))\nprint(\"Overall Recall:\",recall_score(y_test, predictions_pipe))\nauc = roc_auc_score(y_test,y_scores[:,1])\nprint('AUC: ' + str(auc))\n\n# calculate ROC curve\ny_scores = model_pipe.predict_proba(X_test)\nfpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n\n# plot ROC curve\nfig = plt.figure(figsize=(6, 6))\n# Plot the diagonal 50% line\nplt.plot([0, 1], [0, 1], 'k--')\n# Plot the FPR and TPR achieved by our model\nplt.plot(fpr, tpr)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Didnt improve at all - trying Random Forest:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# Create preprocessing and training pipeline\npipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                           ('logregressor', RandomForestClassifier(n_estimators=100))])\n\n# fit the pipeline to train a random forest model on the training set\nmodel = pipeline.fit(X_train, (y_train.values.ravel()))\nprint (model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(X_test)\ncm = confusion_matrix(y_test, predictions)\nprint ('Confusion Matrix:\\n',cm, '\\n')\nprint('Accuracy:', accuracy_score(y_test, predictions))\nprint(\"Overall Precision:\",precision_score(y_test, predictions))\nprint(\"Overall Recall:\",recall_score(y_test, predictions))\nauc = roc_auc_score(y_test,y_scores[:,1])\nprint('\\nAUC: ' + str(auc))\n\n# calculate ROC curve\ny_scores = model.predict_proba(X_test)\nfpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n\n# plot ROC curve\nfig = plt.figure(figsize=(6, 6))\n# Plot the diagonal 50% line\nplt.plot([0, 1], [0, 1], 'k--')\n# Plot the FPR and TPR achieved by our model\nplt.plot(fpr, tpr)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets try and see how our model performs on the test data - although with this AUC I wont be submitting anything."},{"metadata":{"trusted":true},"cell_type":"code","source":"test_init.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_test = test_init.drop([\"Patient_ID\", 'Health_Camp_ID', \"Registration_Date\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create a column for tuples of the Patient_ID, Health_Camp_ID:"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_init['patient_camp_train'] = list(zip(test_init.Patient_ID, test_init.Health_Camp_ID))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_test = model.predict(X_test_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outcomes_test = pd.DataFrame(predictions_test, columns = [\"Outcome\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outcomes_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_for_output = test_init.drop([\"Registration_Date\", \"Var1\", \"Var2\", \"Var3\", \"Var4\", \"Var5\", \"patient_camp_train\"], axis = 1)\ntest_for_output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df = pd.concat([test_for_output, outcomes_test], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df.to_csv(\"Output.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testing_output_csv = pd.read_csv('/kaggle/working/Output.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testing_output_csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}