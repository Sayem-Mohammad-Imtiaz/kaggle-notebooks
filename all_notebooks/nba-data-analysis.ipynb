{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/nba-players-data/all_seasons.csv').drop('Unnamed: 0',axis=1)\ndf","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking for null values\ndf.dropna(inplace=True)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_season_wise = df.set_index('season')\n\n#Set undrafted to null\nUndrafted= df_season_wise[df_season_wise['draft_year']=='Undrafted']\ndf_season_wise['draft_year']=df_season_wise['draft_year'].replace('Undrafted',np.NaN) \ndf_season_wise['draft_round']=df_season_wise['draft_round'].replace('Undrafted',np.NaN)\ndf_season_wise['draft_number']=df_season_wise['draft_number'].replace('Undrafted',np.NaN)\ndf_season_wise","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n#selecting columns required for analysis\ncol_need=['age','player_height','player_weight','gp','pts','reb','ast','net_rating','oreb_pct','dreb_pct','usg_pct','ts_pct','ast_pct']\nana_df=df[col_need]\nana_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking for duplicate values; False=> NO duplicated values\nana_df.duplicated().values.any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#co-relation matrix showing correlation between features\nana_df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualizing relation between features\npd.plotting.scatter_matrix(ana_df,figsize=(20,20),alpha=0.5);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#better visualization\nimport seaborn as sns\nsns.pairplot(ana_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting all other features correlation with net_rating\nfig,((ax1,ax2,ax3,ax4),(ax5,ax6,ax7,ax8),(ax9,ax10,ax11,ax12))=plt.subplots(3,4,figsize=(30,10))\nax=[ax1,ax2,ax3,ax4,ax5,ax6,ax7,ax8,ax9,ax10,ax11,ax12]\nk=0\n\nfor col in ana_df.columns:\n    if col!='net_rating':\n        ax[k].scatter(ana_df[col],ana_df['net_rating'])\n        ax[k].set_xlabel(col)\n        ax[k].set_ylabel(\"net_rating\")\n        k=k+1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predicting net rating dependence on different individual features \n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\n\nX=['age','player_height','player_weight','gp','pts','reb','ast','oreb_pct','dreb_pct','usg_pct','ts_pct','ast_pct']\ny=['net_rating']\n\nl=[]\nfor x in X:\n    m=np.array(ana_df[x])\n    n=np.array(ana_df[y])\n    X_train,X_test,y_train,y_test=train_test_split(m.reshape(-1,1),n.reshape(-1,1),random_state=0)\n    model=LinearRegression().fit(X_train,y_train)\n    print(model.score(X_train,y_train),'  ',model.score(X_test,y_test))\n    l.append((model.score(X_test,y_test),x))\n    \n# returns max model score of the feature that best predicts the net rating of the player\nmax(l)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Multiple Linear Regression\n#Polynomial Regression\n#Decision Tree Regressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Multiple Linear Regression\nfrom sklearn.metrics import r2_score\nX_m=['age','player_height','player_weight','gp','pts','reb','ast','oreb_pct','dreb_pct','usg_pct','ts_pct','ast_pct']\ny_m=['net_rating']\n\nXm_train,Xm_test,ym_train,ym_test=train_test_split(ana_df[X_m],ana_df[y_m])\n\nmul_model=LinearRegression().fit(Xm_train,ym_train)\nprint('training multiple feature model score:',mul_model.score(Xm_train,ym_train),'\\ntesting multiple feature model score:',mul_model.score(Xm_test,ym_test),\n      '\\ntraining multiple feature model r2 score:',r2_score(ym_train,mul_model.predict(Xm_train)),'\\ntesting multiple feature model r2 score:',r2_score(ym_test,mul_model.predict(Xm_test)))\n\n#cross validation\nfrom sklearn.model_selection import cross_val_score\ncv_score=cross_val_score(mul_model,ana_df[X_m],ana_df[y_m])\nprint('cross validation score:',cv_score)\nprint('mean cross validation score:',np.mean(cv_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Polynomial Regression\nfrom sklearn.preprocessing import PolynomialFeatures\n\npoly_X_m=PolynomialFeatures(degree=2).fit_transform(ana_df[X_m])\ny_m=['net_rating']\n\npoly_X_train,poly_X_test,y_trainn,y_testt=train_test_split(poly_X_m,ana_df[y_m])\n\npoly_model= LinearRegression().fit(poly_X_train,y_trainn)\n\nprint('training polynomial model score:',poly_model.score(poly_X_train,y_trainn),'\\ntesting polynomial model score:',poly_model.score(poly_X_test,y_testt),\n      '\\ntraining polynomial model r2 score:',r2_score(y_trainn,poly_model.predict(poly_X_train)),'\\ntesting polynomial model r2 score:',r2_score(y_testt,poly_model.predict(poly_X_test)))\n\n#cross validation\ncv_score=cross_val_score(poly_model,poly_X_m,ana_df[y_m])\nprint('cross validation score:',cv_score)\nprint('mean cross validation score:',np.mean(cv_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Decision Tree Regressor\nfrom sklearn.tree import DecisionTreeRegressor\n\ntree_model=  DecisionTreeRegressor(max_depth=1).fit(Xm_train,ym_train)\n\nprint('training decision tree model score:',tree_model.score(Xm_train,ym_train),'\\ntesting decision tree model score:',tree_model.score(Xm_test,ym_test),\n      '\\ntraining decision tree model r2 score:',r2_score(ym_train,tree_model.predict(Xm_train)),'\\ntesting decision tree model r2 score:',r2_score(ym_test,tree_model.predict(Xm_test)))\n\n#cross validation\ncv_score=cross_val_score(tree_model,ana_df[X_m],ana_df[y_m])\nprint('cross validation score:',cv_score)\nprint('mean cross validation score:',np.mean(cv_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#KNN Regression\nfrom sklearn.neighbors import KNeighborsRegressor\nknn_model=KNeighborsRegressor(n_neighbors=1000).fit(Xm_train,ym_train)\nprint('training knn model score:',knn_model.score(Xm_train,ym_train),'\\ntesting knn model score:',knn_model.score(Xm_test,ym_test),\n      '\\ntraining knn model r2 score:',r2_score(ym_train,knn_model.predict(Xm_train)),'\\ntesting knn model r2 score:',r2_score(ym_test,knn_model.predict(Xm_test)))\n\n#cross validation\ncv_score=cross_val_score(knn_model,ana_df[X_m],ana_df[y_m])\nprint('cross validation score:',cv_score)\nprint('mean cross validation score:',np.mean(cv_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Hence, for this dataset, predicting the net_rating of a player depending on features available in dataset, best model is: \n#Polynomial Regression accompanied by linear regression\n#However","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking outliers in Measure of the player's shooting efficiency \nplt.figure()\n_=plt.boxplot(ana_df['ts_pct'],whis='range')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking outliers in Average number of rebounds grabbed\nplt.figure()\n_=plt.boxplot(ana_df['reb'],whis='range')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#How does height and weight of a player can be used to predict his shooting efficiency\nfrom sklearn.metrics import r2_score\nfrom mpl_toolkits.mplot3d import Axes3D\n%matplotlib notebook\n\ncol_shoot=['player_height','player_weight','ts_pct']\ndf_shoot= ana_df[col_shoot]\n\nX_sht=['player_height','player_weight']\ny_sht=['ts_pct']\n\nX_sht_train,X_sht_test,y_sht_train,y_sht_test= train_test_split(df_shoot[X_sht],df_shoot[y_sht])\n\n#Simple Linear Regression model\nlinear_model_sht=LinearRegression().fit(X_sht_train,y_sht_train)\nprint('training_set score:',linear_model_sht.score(X_sht_train,y_sht_train),'\\ntest_set score:',linear_model_sht.score(X_sht_test,y_sht_test),\n      '\\ntraining_set r2_score:',r2_score(y_sht_train,linear_model_sht.predict(X_sht_train)),'\\ntest_set r2_score:',r2_score(y_sht_test,linear_model_sht.predict(X_sht_test)))\npredict=linear_model_sht.predict(X_sht_test)\nplt.figure(figsize=(10,10))\nplt.subplot(411)\nsns.scatterplot(df_shoot['player_height'],df_shoot['player_weight'],alpha=0.5)\n\nplt.subplot(412)\nsns.scatterplot(df_shoot['player_height'],df_shoot['ts_pct'],alpha=0.5)\nplt.plot(X_sht_test,linear_model_sht.predict(X_sht_test))\nplt.legend(['height','weight'])\nplt.subplot(413)\nsns.scatterplot(df_shoot['player_weight'],df_shoot['ts_pct'],alpha=0.5)\n\nplt.plot(X_sht_test,linear_model_sht.predict(X_sht_test))\nplt.legend(['height','weight'])\nsns.pairplot(df_shoot)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Ridge Regression model\nfrom sklearn.linear_model import Ridge\nridge_model_sht=Ridge(alpha=709999).fit(X_sht_train,y_sht_train)\nprint('training_set score:',ridge_model_sht.score(X_sht_train,y_sht_train),'\\ntest_set score:',ridge_model_sht.score(X_sht_test,y_sht_test),\n      '\\ntraining_set r2_score:',r2_score(y_sht_train,ridge_model_sht.predict(X_sht_train)),'\\ntest_set r2_score:',r2_score(y_sht_test,ridge_model_sht.predict(X_sht_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#How does height and weight of a player can be used to predict whether he'll be able to take rebound\nfrom sklearn.metrics import r2_score\nfrom mpl_toolkits.mplot3d import Axes3D\n%matplotlib notebook\n\ncol_rebound=['player_height','player_weight','reb']\ndf_rebound= ana_df[col_rebound]\n\nX_reb=['player_height','player_weight']\ny_reb=['reb']\n\nX_reb_train,X_reb_test,y_reb_train,y_reb_test= train_test_split(df_rebound[X_reb],df_rebound[y_reb])\n\n#Simple Linear Regression model\nlinear_model_reb=LinearRegression().fit(X_reb_train,y_reb_train)\nprint('training_set score:',linear_model_reb.score(X_reb_train,y_reb_train),'\\ntest_set score:',linear_model_reb.score(X_reb_test,y_reb_test),\n      '\\ntraining_set r2_score:',r2_score(y_reb_train,linear_model_reb.predict(X_reb_train)),'\\ntest_set r2_score:',r2_score(y_reb_test,linear_model_reb.predict(X_reb_test)))\nplt.subplot(311)\nplt.scatter(df_rebound['player_height'],df_rebound['player_weight'],alpha=0.5)\nplt.subplot(312)\nplt.scatter(df_rebound['player_height'],df_rebound['reb'],alpha=0.5)\nplt.subplot(313)\nplt.scatter(df_rebound['player_weight'],df_rebound['reb'],alpha=0.5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Ridge Regression model\nfrom sklearn.linear_model import Ridge\nridge_model_reb=Ridge(alpha=10).fit(X_reb_train,y_reb_train)\nprint('training_set score:',ridge_model_reb.score(X_reb_train,y_reb_train),'\\ntest_set score:',ridge_model_reb.score(X_reb_test,y_reb_test),\n      '\\ntraining_set r2_score:',r2_score(y_reb_train,ridge_model_reb.predict(X_reb_train)),'\\ntest_set r2_score:',r2_score(y_reb_test,ridge_model_reb.predict(X_reb_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}