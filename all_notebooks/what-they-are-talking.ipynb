{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"5d481597-62cc-844c-16b8-0e09931e79a7"},"source":"Data Pre-Processing and Overview\n--------------------------------\n\n\n 1.  removing re-tweets\n 2. removing short messages (less then 4 words)\n 3. replacing @<user> with REF\n 4. replacing any url with URL\n 5. replacing any date with DATE\n 6. replacing any time with TIME\n 7. replace digits with NUM\n 8. extracting  most frequent features using word analyzer, char analyzer and tokenizing,steming, stop words removing. Something like WordCloud but with more details"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ad80558c-5e76-6a1b-1325-cda16b76a583"},"outputs":[],"source":"import pandas as pd\nfrom pandas import Series,DataFrame\nimport numpy as np\n\n\n\n\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.stem.porter import PorterStemmer\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve, auc,precision_score, accuracy_score, recall_score, f1_score\nfrom scipy import interp\n\n#Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"408c0533-df7c-343c-1215-45dffa5ea0b3"},"outputs":[],"source":"#data\ndf_rd=pd.read_csv('../input/AllTweets.csv')\ndf_rd.drop(df_rd[df_rd.author=='various'].index, inplace=True)\ndf_rd.drop(df_rd[df_rd.author=='FiveThirtyEight'].index, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"511ad0c6-02ed-de21-e619-3fa5e1ccc09c"},"outputs":[],"source":"df_rd.drop(df_rd[df_rd.retweet==True].index, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"08755e55-9517-39ff-a466-e796061f12d3"},"outputs":[],"source":"df_rd['length'] = df_rd[\"text\"].apply(len)\ndf_rd['num_of_words'] = df_rd[\"text\"].str.split().apply(len)"},{"cell_type":"markdown","metadata":{"_cell_guid":"6a166f7a-2413-d2f8-ee03-81d3cab51a9d"},"source":"Kim Kardashian used to tweet more short words in sentences, Adam Savage less words in short sentences and NASA histogram is not skew. (It's an agency not a person).  "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"75450102-74e7-1424-77eb-3a51341c9594"},"outputs":[],"source":"df_rd.hist(column='num_of_words', by='author', bins=100)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6d967ba6-b661-504c-c50d-a319b045346c"},"outputs":[],"source":"df_rd.hist(column='length', by='author', bins=20,figsize=(10,4))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1a4ce6af-603c-4bd6-5c4b-6f16b8ef0fc5"},"outputs":[],"source":"df_rd.drop(df_rd[df_rd.num_of_words<4].index, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e54cc7fe-4a12-9886-5dd3-653044dfb42f"},"outputs":[],"source":"df_rd[\"text\"].replace(r\"http\\S+\", \"URL\", regex=True,inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2a9b25bb-aaa8-b0b6-daa6-89cad564cd69"},"outputs":[],"source":"df_rd[\"text\"].replace(r\"@\\S+\", \"REF\", regex=True ,inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f7006f70-eb0c-cef3-48b0-719f24d35286"},"outputs":[],"source":"df_rd[\"text\"].replace(r\"(\\d{1,2})[/.-](\\d{1,2})[/.-](\\d{2,4})+\", \"DATE\", regex=True,inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c0f9161b-e8a2-d1c2-c2fe-4e25775621d9"},"outputs":[],"source":"df_rd[\"text\"].replace(r\"(\\d{1,2})[/:](\\d{2})[/:](\\d{2})?(am|pm)+\", \"TIME\", regex=True,inplace=True)\ndf_rd[\"text\"].replace(r\"(\\d{1,2})[/:](\\d{2})?(am|pm)+\", \"TIME\", regex=True,inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"558c96fc-65d0-e74a-8b82-3e1d4a1bcfc5"},"outputs":[],"source":"df_rd[\"text\"].replace(r\"\\d+\", \"NUM\", regex=True,inplace=True)"},{"cell_type":"markdown","metadata":{"_cell_guid":"0ef551d6-b429-8998-f90b-5e2131817894"},"source":"Most popular features using word ngrams (1 - 5) and standard set of english stop words\n------------------------------------------------------------------------"},{"cell_type":"markdown","metadata":{"_cell_guid":"43c3e58e-765e-082c-10d7-fa67e2ed0848"},"source":" - \"pic twitter com\" and \"url twitter com\" are the most popular ngrams for all authors. I remove them via stop words list later\n - The exercise also reveals other words which need to be added to the stop word list\n - It's rare when you can see something unique per author in first 5  ngrams A little bit better with first 10 3-ngrams and 5-ngrams\n - I compile the list of most popular unique words per author. First 5 can say a lot\nLike \"lol\" and \"birthday\" for Kim Kardashian or RichardDawkins for Richard Dawkins (looks like he used to add a lot of links to its own site or other resources where his name is mentioned)\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"95e16cb9-ba43-4bee-6fc0-951c5bdc5a36"},"outputs":[],"source":"df_features=pd.DataFrame()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7914038f-6598-637a-7bc9-079c7678b40c"},"outputs":[],"source":"for a in df_rd.author.unique():\n    v = CountVectorizer(analyzer='word',stop_words='english',ngram_range=(1, 5))\n    ngrams = v.fit_transform(df_rd[df_rd['author'] == a]['text'])\n    df=pd.DataFrame(\n    {'FeaturesNames': v.get_feature_names(),\n     'Counts': list(ngrams.sum(axis=0).flat),\n     'Author': a\n    })\n    #\n    df['num_of_words'] = df[\"FeaturesNames\"].str.split().apply(len)\n    #\n    df1=df.loc[(df['num_of_words']==1)].sort_values('Counts', ascending=False)[['Author','Counts','FeaturesNames']].head(100)\n    df1.rename(columns={'Counts':'Counts1','FeaturesNames':'Features1'}, inplace=True)\n    df1.reset_index(inplace=True)\n    #\n    df3=df.loc[(df['num_of_words']==3)].sort_values('Counts', ascending=False)[['Counts','FeaturesNames']].head(100)\n    df3.rename(columns={'Counts':'Counts3','FeaturesNames':'Features3'}, inplace=True)\n    df3.reset_index(inplace=True)\n    #\n    df5=df.loc[(df['num_of_words']==5)].sort_values('Counts', ascending=False)[['Counts','FeaturesNames']].head(100)\n    df5.rename(columns={'Counts':'Counts5','FeaturesNames':'Features5'}, inplace=True)\n    df5.reset_index(inplace=True)\n    #\n    df_result = pd.concat([df1,df3,df5], axis=1)\n    #\n    df_features=df_features.append(df_result,ignore_index=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"724111ad-9152-2a68-fcd7-73076843468e"},"outputs":[],"source":"df_features.drop('index', axis=1, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"df90edff-3523-5e5d-4a55-e658ed28a56d"},"outputs":[],"source":"df_features.loc[(df_features['Author'] == 'NASA')].head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a89d80c5-db61-a89a-072b-daf0a7bedcb0"},"outputs":[],"source":"df_features[~df_features.Features1.isin(df_features[df_features['Author'] != 'NASA'].Features1)].sort_values('Counts1', ascending=False).ix[:,['Author','Counts1','Features1']].head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"963e9278-b984-11fb-fda3-c8c096aae8dc"},"outputs":[],"source":"df_features.loc[(df_features['Author'] == 'AdamSavage')].head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"945c7dbf-6cb6-415d-306c-4a586d7df972"},"outputs":[],"source":"df_features[~df_features.Features1.isin(df_features[df_features['Author'] != 'AdamSavage'].Features1)].sort_values('Counts1', ascending=False).ix[:,['Author','Counts1','Features1']].head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e4b96512-31b9-00f1-320a-7ad27c3fee35"},"outputs":[],"source":"df_features.loc[(df_features['Author'] == 'BarackObama')].head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cc55c0e1-2d09-0874-672e-46e248c5d278"},"outputs":[],"source":"df_features[~df_features.Features1.isin(df_features[df_features['Author'] != 'BarackObama'].Features1)].sort_values('Counts1', ascending=False).ix[:,['Author','Counts1','Features1']].head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dc4fbf58-e400-17e4-ac53-e461ebf4bd23"},"outputs":[],"source":"df_features.loc[(df_features['Author'] == 'DonaldTrump')].head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"697d3764-7c9d-272d-b9ca-998223dd53aa"},"outputs":[],"source":"df_features[~df_features.Features1.isin(df_features[df_features['Author'] != 'DonaldTrump'].Features1)].sort_values('Counts1', ascending=False).ix[:,['Author','Counts1','Features1']].head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b4f3bd45-c853-f27d-9d81-bb1f0c5f04dc"},"outputs":[],"source":"df_features.loc[(df_features['Author'] == 'HillaryClinton')].head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b80a09d5-d711-cd32-9e56-68f6a7e982d3"},"outputs":[],"source":"df_features[~df_features.Features1.isin(df_features[df_features['Author'] != 'HillaryClinton'].Features1)].sort_values('Counts1', ascending=False).ix[:,['Author','Counts1','Features1']].head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f06e8452-b36a-ec58-9695-90ce6769079c"},"outputs":[],"source":"df_features.loc[(df_features['Author'] == 'KimKardashian')].head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ead2e655-9aac-b25d-d7ca-7251753d6c8f"},"outputs":[],"source":"df_features[~df_features.Features1.isin(df_features[df_features['Author'] != 'KimKardashian'].Features1)].sort_values('Counts1', ascending=False).ix[:,['Author','Counts1','Features1']].head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1053746c-aee1-a4ae-b7eb-077b84e86600"},"outputs":[],"source":"df_features.loc[(df_features['Author'] == 'ScottKelly')].head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"25090763-97b4-4af8-e8f3-7a0609247ed4"},"outputs":[],"source":"df_features[~df_features.Features1.isin(df_features[df_features['Author'] != 'ScottKelly'].Features1)].sort_values('Counts1', ascending=False).ix[:,['Author','Counts1','Features1']].head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e8d41978-5759-7dbe-9478-a3806ef848a8"},"outputs":[],"source":"df_features.loc[(df_features['Author'] == 'RichardDawkins')].head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1685ea7c-1f32-fbb4-8f9c-f3096361ef03"},"outputs":[],"source":"df_features[~df_features.Features1.isin(df_features[df_features['Author'] != 'RichardDawkins'].Features1)].sort_values('Counts1', ascending=False).ix[:,['Author','Counts1','Features1']].head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"85e67100-45e9-f915-c037-364cba8bc345"},"outputs":[],"source":"df_features.loc[(df_features['Author'] == 'deGrasseTyson')].head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"eda8786a-db55-10bc-7903-6c3a2e9aa0bf"},"outputs":[],"source":"df_features[~df_features.Features1.isin(df_features[df_features['Author'] != 'deGrasseTyson'].Features1)].sort_values('Counts1', ascending=False).ix[:,['Author','Counts1','Features1']].head(5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"817196c9-1166-8ac2-2238-f364bd5d9998"},"outputs":[],"source":"def text_process(text):\n    \"\"\"\n    Takes in a string of text, then performs the following:\n    1. Tokenizes and removes punctuation\n    2. Removes  stopwords\n    3. Stems\n    4. Returns a list of the cleaned text\n    \"\"\"\n\n    # tokenizing\n    tokenizer = RegexpTokenizer(r'\\w+')\n    text_processed=tokenizer.tokenize(text)\n    \n    # removing any stopwords\n    stoplist = stopwords.words('english')\n    stoplist.append('twitter')\n    stoplist.append('pic')\n    stoplist.append('com')\n    stoplist.append('net')\n    stoplist.append('gov')\n    stoplist.append('tv')\n    stoplist.append('www')\n    stoplist.append('twitter')\n    stoplist.append('num')\n    stoplist.append('date')\n    stoplist.append('time')\n    stoplist.append('url')\n    stoplist.append('ref')\n\n    stoplist.append('nasa')\n    stoplist.append('adam')\n    stoplist.append('savage')\n    stoplist.append('barack')\n    stoplist.append('obama')\n    stoplist.append('donald')\n    stoplist.append('trump')\n    stoplist.append('hillary')\n    stoplist.append('clinton')\n    stoplist.append('kim')\n    stoplist.append('kardashian')\n    stoplist.append('kardashian')\n    stoplist.append('de')\n    stoplist.append('grasse')\n    stoplist.append('tyson')\n    stoplist.append('scott')\n    stoplist.append('kelly')\n    stoplist.append('richard')\n    stoplist.append('dawkins')\n    stoplist.append('adamsavage')\n    stoplist.append('barackobama')\n    stoplist.append('donaldtrump')\n    stoplist.append('hillaryclinton')\n    stoplist.append('kimkardashian')\n    stoplist.append('degrassetyson')\n    stoplist.append('scottkelly')\n    stoplist.append('richarddawkins')\n    stoplist.append('kourtney')\n    text_processed = [word.lower() for word in text_processed if word.lower() not in stoplist]\n    \n    # steming\n    porter_stemmer = PorterStemmer()\n    \n    text_processed = [porter_stemmer.stem(word) for word in text_processed]\n    \n\n    return text_processed"},{"cell_type":"markdown","metadata":{"_cell_guid":"2411867f-ab0d-2024-f5b5-ec9604077840"},"source":"Most popular features after tokenizing, removing stop words and steming\n------------------------------------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0075c846-027a-c8f4-2ac0-55e9ac2b5272"},"outputs":[],"source":"df_features=pd.DataFrame()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a35195e8-a1dc-6b4a-d113-548fc88d8b91"},"outputs":[],"source":"for a in df_rd.author.unique():\n    v = CountVectorizer(tokenizer=text_process,ngram_range=(1, 5))\n    ngrams = v.fit_transform(df_rd[df_rd['author'] == a]['text'])\n    df=pd.DataFrame(\n    {'FeaturesNames': v.get_feature_names(),\n     'Counts': list(ngrams.sum(axis=0).flat),\n     'Author': a\n    })\n    #\n    df['num_of_words'] = df[\"FeaturesNames\"].str.split().apply(len)\n    #\n    df1=df.loc[(df['num_of_words']==1)].sort_values('Counts', ascending=False)[['Author','Counts','FeaturesNames']].head()\n    df1.rename(columns={'Counts':'Counts1','FeaturesNames':'Features1'}, inplace=True)\n    df1.reset_index(inplace=True)\n    #\n    df3=df.loc[(df['num_of_words']==3)].sort_values('Counts', ascending=False)[['Counts','FeaturesNames']].head()\n    df3.rename(columns={'Counts':'Counts3','FeaturesNames':'Features3'}, inplace=True)\n    df3.reset_index(inplace=True)\n    #\n    df5=df.loc[(df['num_of_words']==5)].sort_values('Counts', ascending=False)[['Counts','FeaturesNames']].head()\n    df5.rename(columns={'Counts':'Counts5','FeaturesNames':'Features5'}, inplace=True)\n    df5.reset_index(inplace=True)\n    #\n    df_result = pd.concat([df1,df3,df5], axis=1)\n    #\n    df_features=df_features.append(df_result,ignore_index=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a3f5ba43-17cf-46e6-6de5-774482fecc95"},"outputs":[],"source":"df_features.drop('index', axis=1, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"77cdabc6-2d25-3273-d6a7-f606c2ceea16"},"outputs":[],"source":"df_features.loc[(df_features['Author'] == 'NASA')]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3e0ceee4-382b-b98e-7ee8-5aaddd778ae9"},"outputs":[],"source":"df_features.loc[(df_features['Author'] == 'AdamSavage')]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"34894d58-c40a-b468-9704-0311cdfc785b"},"outputs":[],"source":"df_features.loc[(df_features['Author'] == 'BarackObama')]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dd34352b-5f82-9c52-7ef2-5794251de36c"},"outputs":[],"source":"df_features.loc[(df_features['Author'] == 'DonaldTrump')]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b7c11e3b-db8b-e220-6bf1-275e0696f6a4"},"outputs":[],"source":"df_features.loc[(df_features['Author'] == 'HillaryClinton')]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fb63c3b6-21e9-140d-cfde-4c7f37348e1f"},"outputs":[],"source":"df_features.loc[(df_features['Author'] == 'KimKardashian')]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3dab0c8a-62f2-08a9-d8b0-74822ebae6ce"},"outputs":[],"source":"df_features.loc[(df_features['Author'] == 'ScottKelly')]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"da625909-ab52-a85d-edb2-873d4d324f22"},"outputs":[],"source":"df_features.loc[(df_features['Author'] == 'RichardDawkins')]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"62d265ed-c8e7-ef90-4f6f-82bdb1cfa7ee"},"outputs":[],"source":"df_features.loc[(df_features['Author'] == 'deGrasseTyson')]"},{"cell_type":"markdown","metadata":{"_cell_guid":"a17226e6-ef00-8ca1-0455-d678f9bc558a"},"source":"Let's try char  3-grams\n----------------------------------"},{"cell_type":"markdown","metadata":{"_cell_guid":"e8efaed1-726b-2616-0f59-8e12f02da192"},"source":"I list unique char 3-grams for each author (not appearing in the \nset of any other author) You can see \"lol\" and \"!!\" only for Kim Kardashian The rest of 3-grams not so self explainable but maybe useful for classification "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"eb98bf37-c9b6-938c-ed00-c30d1d12468c"},"outputs":[],"source":"df_features=pd.DataFrame()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"eb6ce277-28cb-4feb-835a-5c5c2e1c50f8"},"outputs":[],"source":"for a in df_rd.author.unique():\n    v = CountVectorizer(analyzer='char_wb',max_features=2000,ngram_range=(3, 3))\n    ngrams = v.fit_transform(df_rd[df_rd['author'] == a]['text'])\n    df=pd.DataFrame(\n    {'FeaturesNames': v.get_feature_names(),\n     'Counts': list(ngrams.sum(axis=0).flat),\n     'Author': a\n    })\n    #\n    df_features=df_features.append(df,ignore_index=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1d11f395-e84e-bbde-5fe2-0429e9d1f184"},"outputs":[],"source":"df_features[~df_features.FeaturesNames.isin(df_features[df_features['Author'] != 'NASA'].FeaturesNames)].sort_values('Counts', ascending=False).head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c8ae0c0e-9513-ad6c-d7f4-4f01e5bd8650"},"outputs":[],"source":"df_features[~df_features.FeaturesNames.isin(df_features[df_features['Author'] != 'AdamSavage'].FeaturesNames)].sort_values('Counts', ascending=False).head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dafb04b7-3dbd-1e7b-fd74-afd7f3ba0019"},"outputs":[],"source":"df_features[~df_features.FeaturesNames.isin(df_features[df_features['Author'] != 'BarackObama'].FeaturesNames)].sort_values('Counts', ascending=False).head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a1db10d0-690d-61de-30e6-6964d6927d9b"},"outputs":[],"source":"df_features[~df_features.FeaturesNames.isin(df_features[df_features['Author'] != 'DonaldTrump'].FeaturesNames)].sort_values('Counts', ascending=False).head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e9357cae-9ba6-4f70-dcbe-98c2209c45d5"},"outputs":[],"source":"df_features[~df_features.FeaturesNames.isin(df_features[df_features['Author'] != 'HillaryClinton'].FeaturesNames)].sort_values('Counts', ascending=False).head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0d9575ff-eea4-26d6-6bad-dde6498aac74"},"outputs":[],"source":"df_features[~df_features.FeaturesNames.isin(df_features[df_features['Author'] != 'KimKardashian'].FeaturesNames)].sort_values('Counts', ascending=False).head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"27159daa-4cbc-4130-de0e-a41797ec77e9"},"outputs":[],"source":"df_features[~df_features.FeaturesNames.isin(df_features[df_features['Author'] != 'ScottKelly'].FeaturesNames)].sort_values('Counts', ascending=False).head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"471ffd62-814b-11f5-04ce-a41d0489a376"},"outputs":[],"source":"df_features[~df_features.FeaturesNames.isin(df_features[df_features['Author'] != 'RichardDawkins'].FeaturesNames)].sort_values('Counts', ascending=False).head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"21917738-1063-67a3-44ca-6a30aeec6e4e"},"outputs":[],"source":"df_features[~df_features.FeaturesNames.isin(df_features[df_features['Author'] != 'deGrasseTyson'].FeaturesNames)].sort_values('Counts', ascending=False).head(10)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}