{"cells":[{"metadata":{"_uuid":"c9f40d255e943a2d9fe538fdfd71298b484955a9"},"cell_type":"markdown","source":"## Introduction:\n\n> Kickstarter is an American public-benefit corporation[2] based in Brooklyn, New York, that maintains a global crowdfunding platform focused on creativity and merchandising.[3] The company's stated mission is to \"help bring creative projects to life\".[4] Kickstarter has reportedly received more than $1.9 billion in pledges from 9.4 million backers to fund 257,000 creative projects, such as films, music, stage shows, comics, journalism, video games, technology and food-related projects.[5]\nPeople who back Kickstarter projects are offered tangible rewards or experiences in exchange for their pledges.[6] This model traces its roots to subscription model of arts patronage, where artists would go directly to their audiences to fund their work.[7][Wikipedia](https://en.wikipedia.org/wiki/Kickstarter)\n\nSo, with the help of the crawlers of [webrobots](https://webrobots.io/kickstarter-datasets/), we got all the data from the run along 2017 kickstater projects and keep just those written in english and finished either as \"successful\" or \"failed\", and two columns:\n\n- the one with the blurb or short description of the project [text]\n- the one with the final state: \"successful\" if the project got the money goal in time or \"failed\" if don't [factor]"},{"metadata":{"_uuid":"c00980fef6b428da8e16c68af312c593aa46ded5"},"cell_type":"markdown","source":"## Getting and preprocessing data:"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\ndata = pd.read_csv(\"../input/df_text_eng.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ca0dd1edf7f52941ad775d5fedaa095b5a44d9b1"},"cell_type":"markdown","source":"Here we organize the dataframe more and make colum for mapping the {'successful':1,'failed':0}"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"del data['Unnamed: 0'] \nfrom io import StringIO\ndata['state_id'] = data['state'].factorize()[0]\nstate_id_df = data[['state', 'state_id']].drop_duplicates().sort_values('state_id')\nstate_to_id = dict(state_id_df.values)\nid_to_state = dict(state_id_df[['state_id', 'state']].values)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"54f49806db7afba8bf33e0b23df0f537a7b466b0"},"cell_type":"markdown","source":"I want to check if there is impalanced class "},{"metadata":{"trusted":true,"_uuid":"a6fcf593047f0123270564b4bfd0fadfbc09be74"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig = plt.figure(figsize=(8,6))\ndata.groupby('state').blurb.count().plot.bar(ylim=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81ca59c78466cd4b70af92ef97a41e1c57861fd1","collapsed":true},"cell_type":"markdown","source":"seems that there is no problem here"},{"metadata":{"_uuid":"81ab40ff8a1649494f0fe881b95cff658f94491e"},"cell_type":"markdown","source":"Now lets clean the text for training , i see no need to delete the stopwords so i will just remove punctuations"},{"metadata":{"trusted":true,"_uuid":"c61d33ecc4435ac6eb6465889d92b8448d2a3b43","collapsed":true},"cell_type":"code","source":"import re\ndef clean(text):\n    text = str(text)\n    text = re.findall(r'\\w+', text)\n    return ' '.join(text)\ndata['blurb'] = data['blurb'].apply(lambda x: clean(x))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d4ecccc910d2cce8c9f30de8307dfe1f9c87c7fb"},"cell_type":"markdown","source":"## Text Representation"},{"metadata":{"_uuid":"278187c272d4781ac08c1a463621ec85cdd3b9a2"},"cell_type":"markdown","source":"Now for text representation i will use tfidf model"},{"metadata":{"trusted":true,"_uuid":"8efa1707784d279d086d522ae0a2a8fd1828ab03"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nx_train, x_test, y_train, y_test = train_test_split(data['blurb'], data['state'], train_size=0.8)\nvectorizer = TfidfVectorizer().fit(x_train)\nx_train_v = vectorizer.transform(x_train)\nx_test_v  = vectorizer.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"21eb00b46216af28f0dfca143fe0845e23486f03"},"cell_type":"markdown","source":"## Training "},{"metadata":{"_uuid":"8e3ea123142a759f83484e5863cb1ff3aa1b3b2c"},"cell_type":"markdown","source":"I will try multiple algorthims and see what gives better accuracy"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b99e0057ea0f6d0733fe77e8d97529dc30fe9794"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import classification_report\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score\nfrom time import time\nentries = []\ndef train():\n    models = {\n        \"LogisticRegression\": LogisticRegression(),\n        \"SGDClassifier\": SGDClassifier(),\n        \"Multinomial\":MultinomialNB(),\n        \"LinearSVC\": LinearSVC(),\n    }\n    for model in models:\n        print(\"training model\"+model)\n        start = time()\n        models[model].fit(x_train_v, y_train)\n        end = time()\n        print(\"trained in {} secs\".format(end-start))\n        y_pred = models[model].predict(x_test_v)\n        entries.append((model,accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ee003a23b6b23ec642a61ab66cdc86c1c976b98"},"cell_type":"code","source":"train()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c916b8d375337b68bab9dedce2b6e078226ea82b"},"cell_type":"markdown","source":"> #### lets Visualize the accuracies"},{"metadata":{"trusted":true,"_uuid":"62459b5e0acea795b845a1f1324f9234b9138eab","collapsed":true},"cell_type":"code","source":"cv_df = pd.DataFrame(entries, columns=['model_name','accuracy'])\nimport seaborn as sns\nsns.boxplot(x='model_name', y='accuracy', data=cv_df)\nsns.stripplot(x='model_name', y='accuracy', data=cv_df, \n              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61a955feb8b863da46c087f39abf90bf3645e6f0"},"cell_type":"markdown","source":"Ok,it seems that LogisticRegression did the job."},{"metadata":{"_uuid":"f3279835345575cf4aabbf9fb98a314d098564d7"},"cell_type":"markdown","source":"## Evaluation:\nnow lets look at the confusion matrix, and show the discrepancies between predicted and actual labels."},{"metadata":{"trusted":true,"_uuid":"2fb642d5853309d32241dd71ba926ee2e3aad6c4","collapsed":true},"cell_type":"code","source":"model = LogisticRegression()\nmodel.fit(x_train_v, y_train)\ny_pred = model.predict(x_test_v)\nfrom sklearn.metrics import confusion_matrix\n\nconf_mat = confusion_matrix(y_test, y_pred)\nfig, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(conf_mat, annot=True, fmt='d',\n            xticklabels=state_id_df.state.values, yticklabels=state_id_df.state.values)\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce7b0ad2fd839dc32487d95306f2bbbd842a2876","collapsed":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}