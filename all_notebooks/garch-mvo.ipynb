{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Install and call packages"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip3 install arch\n!pip install yfinance\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.graphics.tsaplots as sgt\nimport statsmodels.tsa.stattools as sts\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom scipy.stats.distributions import chi2 \nfrom arch import arch_model\nfrom math import sqrt\nimport seaborn as sns\nsns.set()\nimport scipy.optimize as sco\nimport matplotlib.pyplot as plt\nimport datetime as dt\nimport yfinance as yf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Define GARCH function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def GARCH_predict(symbol_list, start, end, interval): \n    \n    #download data and calculate returns\n    data = yf.download(symbol_list, start, end, interval = interval)\n    ret = data.pct_change()['Adj Close']\n    ret = ret.dropna()\n    \n    #create list to store predicted variance and volatility\n    variance_list = []\n    vol_list = []\n    \n    for symbol in symbol_list:\n        \n        model = arch_model(ret[symbol], \n                            mean = \"Constant\",\n                            vol = \"GARCH\", \n                            dist = 'normal', \n                            p = 1, q = 1, \n                            rescale = False) \n       \n        result = model.fit(update_freq = 5, disp = 'off')\n        forecast = result.forecast()\n        \n        predict_var = (forecast.variance.iloc[-1]).iloc[0]\n        variance_list.append(predict_var)\n        vol_list.append(np.sqrt(predict_var))\n        \n        # It's optional to print other statistical result\n        # print(result.plot())\n        # print(result.summary())\n        # print(forecast.mean)\n\n    df = pd.DataFrame(columns = symbol_list, index = ['predicted var','predicted vol'])\n    df.loc['predicted var'] = variance_list\n    df.loc['predicted vol'] = vol_list\n    \n    # The function returns a DataFrame containing predicted variance and volatility values.\n    return(df)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Define Basic MVO Framework"},{"metadata":{"trusted":true},"cell_type":"code","source":"def neg_sharpe_ratio(weights, mean_returns, cov_matrix, risk_free_rate):\n    \n    # Recall portfolio_annualised_performance(weights, mean_returns, cov_matrix) returns portfolio standard deviation and portfolio return\n    p_var = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n    p_ret = np.sum(mean_returns*weights)\n    return -(p_ret - risk_free_rate/52) / p_var\n\ndef max_sharpe_ratio(mean_returns, cov_matrix, risk_free_rate):\n    num_assets = len(mean_returns)\n    args = (mean_returns, cov_matrix, risk_free_rate)\n    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n    bound = (0,0.25)\n    bounds = tuple(bound for asset in range(num_assets))\n    \n    result = sco.minimize(neg_sharpe_ratio, num_assets*[1./num_assets,], args=args,\n                        method='SLSQP', bounds=bounds, constraints=constraints)\n    return result\n\ndef MVO_result(df,mean_returns, cov_matrix, risk_free_rate):    \n\n    max_sharpe = max_sharpe_ratio(mean_returns, cov_matrix, risk_free_rate)\n    print (\"-\"*80)\n    print (\"Maximum Sharpe Ratio Portfolio Allocation\\n\")\n    print (max_sharpe)\n    \n    weights = max_sharpe['x']\n    rp = np.sum(mean_returns*weights)\n    sdp = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n    \n    \n    max_sharpe_allocation = pd.DataFrame(max_sharpe.x,index=df.columns,columns=['allocation'])\n    max_sharpe_allocation.allocation = [round(i*100,2)for i in max_sharpe_allocation.allocation]\n    max_sharpe_allocation = max_sharpe_allocation.T\n    \n    print (\"-\"*80)\n    print (\"Weekly Return:\", round(rp,5))\n    print (\"Weekly Volatility:\", round(sdp,5))\n    print (\"Max Weekly Sharpe Ratio:\", (rp - (risk_free_rate/52))/sdp)\n    print (\"\\n\")\n    print (max_sharpe_allocation)\n    return max_sharpe.x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Seclet Stocks Based on Valuation Matrix Score"},{"metadata":{},"cell_type":"markdown","source":"The FactSet-sourced file contains valuation scores for SP500 composition stocks, categorized by industry. I re-grouped the data by narrowing industry types down to 9 types only: Financials, Chemicals, Tech, Utilities, Air, F&B, Oil, Services and Others. The criteria used in my trading is to select the stocks with best combined score in each industry"},{"metadata":{"trusted":true},"cell_type":"code","source":"# upload stock score data scv file (downloaded from FactSet)\nstock = pd.read_csv('../input/stock-valuation-score/Scoring the SP 500 - Valuation and Sales Growth.csv', na_values=['#N/A'])\n\n# set index by symbol\nstock = stock.set_index('Symbol')\n\n# look for the max score within each industry\nstock['score_max'] = stock.groupby(['Industry'])['Combined Score'].transform(max)\n\n# select stocks with industry max score \nselection = stock[stock['Combined Score']>=stock['score_max']*0.99]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Call Functions to Calculate Allocation for chozen stocks"},{"metadata":{"trusted":true},"cell_type":"code","source":"# input parameters\nsymbol_list = selection.index.tolist()\nend = dt.datetime.now()\nstart = end - dt.timedelta(140)\ninterval = \"1wk\"\n\n# download data\nreturns = yf.download(symbol_list, start, end, interval = interval).pct_change()['Adj Close'].dropna()\nmean_returns = returns.mean()\ncov_matrix = returns.cov()\nrisk_free_rate = 0.12 / 100\n\n# print optimal allocation using historical covarianc matrix\nallocation_hist = MVO_result(returns, mean_returns, cov_matrix, risk_free_rate)\nprint('MVO result by historical covariance matrix')\n\n# replace diagonal elements of cov matrix by GARCH-predicted variance.\nGARCH_var = GARCH_predict(symbol_list, start, end, interval)\nadjust_cov_matrix = cov_matrix.copy()\nfor symbols in symbol_list:\n    adjust_cov_matrix[symbols][symbols] = GARCH_var[symbols][0]\n\n# print optimal allocation using GARCH covariance matrix\nallocation_GARCH = MVO_result(returns, mean_returns, adjust_cov_matrix, risk_free_rate)\nprint('MVO result by GARCH-based covariance matrix')\n\n# print the shrinkage allocation\nprint('-'*80)\nprint('MVO shrinkage result')\nprint(0.5*allocation_hist + 0.5*allocation_GARCH)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Reference\n* https://campus.datacamp.com/courses/garch-models-in-python/garch-model-fundamentals?ex=9\n* https://stackoverflow.com/questions/59884917/forecasting-volatility-using-garch-in-python-arch-package\n* https://stackoverflow.com/questions/15705630/get-the-rows-which-have-the-max-count-in-groups-using-groupby\n* Professor Lee's BootCamp Videos"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}