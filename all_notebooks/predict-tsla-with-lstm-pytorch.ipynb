{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom matplotlib import pyplot as plt\n\nfrom torch import nn\nimport torch.utils.data","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"tsla_df = pd.read_csv('/kaggle/input/tesla-stock-data-from-2010-to-2020/TSLA.csv', index_col='Date', parse_dates=['Date'])\ntsla_df = tsla_df[['Open', 'High', 'Low', 'Volume', 'Close']]\nprint(tsla_df.info())\nprint(tsla_df.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data(df, seq_len, out_feature=5, train_ratio=0.8, is_test=False):\n    scaler = StandardScaler()\n    scaler.fit(df)\n\n    train_norm = scaler.transform(df)\n    data = []\n    for index in range(len(train_norm) - seq_len):\n        # create all possible sequences\n        data.append(train_norm[index:index + seq_len])\n\n    data = np.array(data)\n\n    train_len = len(data) if is_test else int(train_ratio * len(data))\n\n    # train_x are sequences of seq_len-1 days. Features of each day are OPEN, CLOSE, HIGH, LOW, VOLUME\n    # train_y is CLOSE price of day seq_len\n    # shape is (n_data, n_sequence, features)\n    train_x = data[:train_len, :-1, :]\n    train_y = data[:train_len, -1, -out_feature:]\n\n    val_x = data[train_len:, :-1, :]\n    val_y = data[train_len:, -1, -out_feature:]\n\n    return train_x, train_y, val_x, val_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seq_len = 100\nbatch_size = 128\nn_epoch = 50\nn_feature = 5\nout_feature = 1\n\ntrain_df = tsla_df.loc[:'2018']\ntest_df = tsla_df.loc['2019':]\n\ntrain_x, train_y, val_x, val_y = load_data(train_df, seq_len, out_feature=out_feature)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = torch.from_numpy(train_x).float().cuda()\ntrain_y = torch.from_numpy(train_y).float().cuda()\nval_x = torch.from_numpy(val_x).float().cuda()\nval_y = torch.from_numpy(val_y).float().cuda()\n\ntrain = torch.utils.data.TensorDataset(train_x, train_y)\nval = torch.utils.data.TensorDataset(val_x, val_y)\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train,\n                                               batch_size=batch_size,\n                                               shuffle=True, drop_last=True)\n\nval_loader = torch.utils.data.DataLoader(dataset=val,\n                                             batch_size=1,\n                                             shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class StockRNN(nn.Module):\n\n    def __init__(self, n_feature=5, out_feature=5, n_hidden=256, n_layers=2, drop_prob=0.5):\n        super().__init__()\n        self.drop_prob = drop_prob\n        self.n_layers = n_layers\n        self.n_hidden = n_hidden\n        self.n_feature = n_feature\n\n        self.lstm = nn.LSTM(self.n_feature, self.n_hidden, self.n_layers, dropout=self.drop_prob, batch_first=True)\n\n        self.dropout = nn.Dropout(drop_prob)\n\n        self.fc = nn.Linear(n_hidden, out_feature)\n\n    def forward(self, x, hidden):\n        # x.shape (batch, seq_len, n_features)\n        l_out, l_hidden = self.lstm(x, hidden)\n\n        # out.shape (batch, seq_len, n_hidden*direction)\n        out = self.dropout(l_out)\n\n        # out.shape (batch, out_feature)\n        out = self.fc(out[:, -1, :])\n\n        # return the final output and the hidden state\n        return out, l_hidden\n\n    def init_hidden(self, batch_size):\n        weight = next(self.parameters()).data\n\n        hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n        return hidden","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = StockRNN(n_feature=n_feature, out_feature=out_feature)\nnet.cuda()\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(net.parameters())\nval_loss_list = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(n_epoch):\n\n    for i, (x, y) in enumerate(train_loader):\n        output, hidden = net(x, net.init_hidden(batch_size))\n        loss = criterion(output, y)\n\n        net.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    net.eval()\n    val_loss_sum = 0\n    for i, (x, y) in enumerate(val_loader):\n        with torch.no_grad():\n            output, hidden = net(x, net.init_hidden(1))\n            val_loss = criterion(output, y)\n            val_loss_sum += val_loss.item()\n\n    val_loss_list.append(val_loss_sum/len(val_loader))\n    print('End of Epoch ', epoch, 'Val loss: ', val_loss_sum/len(val_loader))\n    net.train()\n\nplt.plot(val_loss_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_df.shape\ntest_x, test_y, _, _ = load_data(test_df, seq_len, out_feature=out_feature, is_test=True)\n\ntest_x = torch.from_numpy(test_x).float().cuda()\ntest_y = torch.from_numpy(test_y).float().cuda()\n\ntest = torch.utils.data.TensorDataset(test_x, test_y)\n\ntest_loader = torch.utils.data.DataLoader(dataset=test, batch_size=1, shuffle=False)\n\nnet.eval()\ntest_predict = []\nfor i, (x, y) in enumerate(test_loader):\n    with torch.no_grad():\n        output, hidden = net(x, net.init_hidden(1))\n    test_predict.append(output[:, -1])\n\nplt.plot(test_y[:, -1].cpu().numpy(), label='GT')\nplt.plot(test_predict, label='Predict')\nplt.legend()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}