{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndef process(x):\n    processed_tweet = re.sub(r'\\W', ' ', str(x))\n    processed_tweet = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_tweet)\n    processed_tweet = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_tweet) \n    processed_tweet= re.sub(r'\\s+', ' ', processed_tweet, flags=re.I)\n    processed_tweet = re.sub(r'^b\\s+', '', processed_tweet)\n    processed_tweet = processed_tweet.lower()\n    return processed_tweet\ndata.review=data.review.apply(process)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk.stem import PorterStemmer,LancasterStemmer\nstemming =PorterStemmer()\ndef identify_tokens(row):\n    tokens = nltk.word_tokenize(row)\n    token_words = [w for w in tokens if w.isalpha()]\n    return token_words\ndef stem_list(row):\n    stemmed_list = [stemming.stem(word) for word in row]\n    return (stemmed_list)\ndef rejoin_words(row):\n    joined_words = ( \" \".join(row))\n    return joined_words\ndata.review=data.review.apply(identify_tokens)\ndata.review=data.review.apply(stem_list)\ndata.review=data.review.apply(rejoin_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\ntk=Tokenizer(num_words=10000,oov_token='oov<>')\ntk.fit_on_texts(data.review)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_dict=tk.word_index\ntext_token=tk.texts_to_sequences(data.review)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pad=pad_sequences(text_token,maxlen=100,padding='post')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nla=LabelEncoder()\nlabels=la.fit_transform(data.review)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels=np.array(labels)\npad=np.array(pad)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_class=len(np.unique(labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nxr,xt,yr,yt=train_test_split(pad,labels,test_size=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nyr=keras.utils.to_categorical(yr,num_class)\nyt=keras.utils.to_categorical(yt,num_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Embedding,GlobalAvgPool1D,Dense,Dropout\nfrom keras.models import Sequential","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=Sequential()\nmodel.add(Embedding(10000,10,input_length=100))\nmodel.add(GlobalAvgPool1D())\nmodel.add(Dense(500,activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(num_class,activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=model.fit(xr,yr,epochs=2,batch_size=128)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfigure=plt.figure(figsize=(15,15))\nax=figure.add_subplot(121)\nax.plot(history.history['accuracy'])\nax.legend(['Training Accuracy'])\nbx=figure.add_subplot(122)\nbx.plot(history.history['loss'])\nbx.legend(['Training Loss'])\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}