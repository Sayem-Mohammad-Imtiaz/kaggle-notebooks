{"cells":[{"metadata":{},"cell_type":"markdown","source":"各位同学大家好，现将kernel重写。\n\n2019年12月3日"},{"metadata":{},"cell_type":"markdown","source":"Step 1: 准备数据。\n    添加右上角 “+ Add data”\n    将google landmark recognition dataset加进去。分别是：\n        （a）google_landmarks_2019_64x64_part1\n         (b) google_landmarks_2019_64x64_part2"},{"metadata":{},"cell_type":"markdown","source":"Step 2: 观察添加的数据（通过Kernel下面的console）。"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(os.getcwd())\nprint('number {:d}'.format(4))\n\n# os.walk('/kaggle/input/Fashion MNIST') 有空格 错误的文件路径写法\nfor dirname, _, filenames in os.walk('/kaggle/input/fashionmnist'):\n# for dirname, _, filenames in os.walk('/kaggle/input/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Step 3: 依赖项和超参设置"},{"metadata":{"trusted":true},"cell_type":"code","source":"#!/usr/bin/env python\nimport multiprocessing\nimport os\nimport time\n\nimport numpy as np\nimport pandas as pd\n\nfrom typing import Any, Optional, Tuple\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.backends.cudnn as cudnn\n\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\nfrom sklearn.preprocessing import LabelEncoder\nfrom PIL import Image\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IN_KERNEL = os.environ.get('KAGGLE_WORKING_DIR') is not None\n# 每一个类别的样本数目至少是50\nMIN_SAMPLES_PER_CLASS = 50\nBATCH_SIZE = 512\nLEARNING_RATE = 1e-3\nLR_STEP = 1          # epoch\nLR_FACTOR = 0.5\nNUM_WORKERS = multiprocessing.cpu_count()\n# 需要大家改\n# MAX_STEPS_PER_EPOCH = 15000\nMAX_STEPS_PER_EPOCH = 15 \nNUM_EPOCHS = 2\n# 每几个iteration显示loss\nLOG_FREQ = 5\n# 这是什么意思？？？？\nNUM_TOP_PREDICTS = 20","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 整体设计思路介绍\n    \n### define dataset\nlandmark_recog:\n    __init__(root, path, transform)\n    __get_item():\n    \ntrain_dataloader = Dataloader(dataset, 'train')\n\n### define model, loss, optimizer\nuse resenet-50\n\n### train_epoch \nfor i, (input, target) in enumerate(train_dataloader):\n\n    output = model(input)\n    loss = criterion(output, target)\n    loss.zero()\n    optimizer.backward()\n    loss.update()\n    \n    ## show progress\n    # 不需要大家写这里\n    \n### test_epoch\n    torch.with_no_grad():\n        for i, (input, target) in enumerate(test_dataloader):\n            xxxx\n            \n        # compute accuracy here\n        xxxx\n\n### main function\nif __file__ == 'main':\n\n    xxxx\n    dataloader = xx\n    model = xx\n    for i in range(MAX_EPOCH):\n        train_epoch\n        test_epoch\n        \n    save_result_to_csv('result_my_own.csv')\n    print('done')\n            "},{"metadata":{},"cell_type":"markdown","source":"### 具体define dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"class LandmarkDataset(torch.utils.data.Dataset):\n    def __init__(self, dataframe, mode):\n        print(f'creating data loader - {mode}')\n        assert mode in ['train', 'val', 'test']\n        \n        self.df = dataframe   # 从 ‘train.csv’文件 读好的数据\n        self.mode = mode\n        transforms_list = []\n\n        if self.mode == 'train':\n            transforms_list = [\n                transforms.RandomHorizontalFlip(),\n                transforms.RandomChoice([\n                    transforms.RandomResizedCrop(64),\n                    transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),\n                    transforms.RandomAffine(degrees=15, translate=(0.2, 0.2),\n                                            scale=(0.8, 1.2), shear=15,\n                                            resample=Image.BILINEAR)\n                ])\n            ]\n\n        transforms_list.extend([\n            transforms.ToTensor(),\n            # 这些数值 可能是landmark_Recognition 上根据image 算出来的 / 也可能是iamgenet数据\n            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                  std=[0.229, 0.224, 0.225]),\n        ])\n        self.transforms = transforms.Compose(transforms_list)\n    \n    def __getitem__(self, index):\n        ''' Returns: tuple (sample, target) '''\n        # df 是dataframe, csv文件， train.csv, 是由数据库本身提供的。\n        filename = self.df.id.values[index]   # 45465656.jpg\n\n        part = 1 if self.mode == 'test' or filename[0] in '01234567' else 2\n        directory = 'test' if self.mode == 'test' else 'train_' + filename[0]\n        sample = Image.open(f'../input/google-landmarks-2019-64x64-part{part}/{directory}/{self.mode}_64/{filename}.jpg')\n        assert sample.mode == 'RGB'\n\n        image = self.transforms(sample)\n\n        if self.mode == 'test':\n            return image\n        elif self.mode == 'train':\n            # image and target\n            return image, self.df.landmark_id.values[index]\n\n    def __len__(self):\n        return self.df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### define dataloader"},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data():\n    # 这个我也不知道 就抄过来吧。\n    torch.multiprocessing.set_sharing_strategy('file_system')\n    cudnn.benchmark = True\n\n    # only use classes which have at least MIN_SAMPLES_PER_CLASS samples\n    print('loading data...')\n    df = pd.read_csv('../input/google-landmarks-2019-64x64-part1/train.csv')\n    df.drop(columns='url', inplace=True)\n\n    counts = df.landmark_id.value_counts()\n    selected_classes = counts[counts >= MIN_SAMPLES_PER_CLASS].index\n    num_classes = selected_classes.shape[0]\n    print('# of classes with at least {:d} samples: {:d}'.format(MIN_SAMPLES_PER_CLASS, num_classes))\n\n    train_df = df.loc[df.landmark_id.isin(selected_classes)].copy()\n    print('train_df', train_df.shape)\n\n    test_df = pd.read_csv('../input/google-landmarks-2019-64x64-part1/test.csv', dtype=str)\n    test_df.drop(columns='url', inplace=True)\n    print('test_df', test_df.shape)\n\n    # filter non-existing test images\n    exists = lambda img: os.path.exists(f'../input/google-landmarks-2019-64x64-part1/test/test_64/{img}.jpg')\n    test_df = test_df.loc[test_df.id.apply(exists)].copy()\n    print('test_df after filtering', test_df.shape)\n    assert test_df.shape[0] > 112000\n\n    label_encoder = LabelEncoder()\n    label_encoder.fit(train_df.landmark_id.values)\n    print('found classes', len(label_encoder.classes_))\n    assert len(label_encoder.classes_) == num_classes\n\n    train_df.landmark_id = label_encoder.transform(train_df.landmark_id)\n\n    # 下面这些都是标准pytorch语法\n    train_dataset = LandmarkDataset(train_df, mode='train')\n    test_dataset = LandmarkDataset(test_df, mode='test')\n\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n                              shuffle=True, num_workers=NUM_WORKERS, drop_last=True)\n\n    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n                             shuffle=False, num_workers=NUM_WORKERS)\n\n    return train_loader, test_loader, label_encoder, num_classes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 评价函数"},{"metadata":{"trusted":true},"cell_type":"code","source":"class AverageMeter:\n    ''' Computes and stores the average and current value '''\n    def __init__(self) -> None:\n        self.reset()\n\n    def reset(self) -> None:\n        self.val = 0.0\n        self.avg = 0.0\n        self.sum = 0.0\n        self.count = 0\n\n    def update(self, val: float, n: int = 1) -> None:\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def GAP(predicts: torch.Tensor, confs: torch.Tensor, targets: torch.Tensor) -> float:\n    ''' Simplified GAP@1 metric: only one prediction per sample is supported '''\n    assert len(predicts.shape) == 1\n    assert len(confs.shape) == 1\n    assert len(targets.shape) == 1\n    assert predicts.shape == confs.shape and confs.shape == targets.shape\n\n    _, indices = torch.sort(confs, descending=True)\n\n    confs = confs.cpu().numpy()\n    predicts = predicts[indices].cpu().numpy()\n    targets = targets[indices].cpu().numpy()\n\n    res, true_pos = 0.0, 0\n\n    for i, (c, p, t) in enumerate(zip(confs, predicts, targets)):\n        rel = int(p == t)\n        true_pos += rel\n\n        res += true_pos / (i + 1) * rel\n\n    res /= targets.shape[0] \n    return res\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 子函数：train"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(train_loader, model, criterion, optimizer,\n          epoch, lr_scheduler):\n    print(f'epoch {epoch}')\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    avg_score = AverageMeter()\n\n    model.train()\n    num_steps = min(len(train_loader), MAX_STEPS_PER_EPOCH)  # 是 20\n    print(f'total batches: {num_steps}')\n\n    end = time.time()\n    lr_str = ''\n\n    for i, (input_, target) in enumerate(train_loader):\n        if i >= num_steps:\n            break\n\n        output = model(input_.cuda())\n        loss = criterion(output, target.cuda())\n\n        confs, predicts = torch.max(output.detach(), dim=1)\n        avg_score.update(GAP(predicts, confs, target))\n\n        losses.update(loss.data.item(), input_.size(0))\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % LOG_FREQ == 0:\n            print(f'{epoch} [{i}/{num_steps}]\\t'\n                        f'time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n                        f'loss {losses.val:.4f} ({losses.avg:.4f})\\t'\n                        f'GAP {avg_score.val:.4f} ({avg_score.avg:.4f})'\n                        + lr_str)\n            \n    print(f' * average GAP(accuray/error) on train {avg_score.avg:.4f}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 子函数：test"},{"metadata":{"trusted":true},"cell_type":"code","source":"def inference(data_loader: Any, model: Any) -> Tuple[torch.Tensor, torch.Tensor,\n                                                     Optional[torch.Tensor]]:\n    ''' Returns predictions and targets, if any. '''\n    model.eval()\n    activation = nn.Softmax(dim=1)\n    all_predicts, all_confs, all_targets = [], [], []\n\n    with torch.no_grad():\n        for i, data in enumerate(tqdm(data_loader, disable=IN_KERNEL)):\n            if data_loader.dataset.mode != 'test':\n                input_, target = data\n            else:\n                input_, target = data, None\n\n            output = model(input_.cuda())\n            output = activation(output)\n\n            confs, predicts = torch.topk(output, NUM_TOP_PREDICTS)\n            all_confs.append(confs)\n            all_predicts.append(predicts)\n\n            if target is not None:\n                all_targets.append(target)\n\n    predicts = torch.cat(all_predicts)\n    confs = torch.cat(all_confs)\n    targets = torch.cat(all_targets) if len(all_targets) else None\n\n    return predicts, confs, targets","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 生成结果"},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_submission(test_loader: Any, model: Any, label_encoder: Any) -> np.ndarray:\n    \n    # 坑：\"-\" 中间横线，不是下划线！！！\n    sample_sub = pd.read_csv('../input/julyonline-landmark/haha_sample_submission.csv')\n\n    predicts_gpu, confs_gpu, _ = inference(test_loader, model)\n    predicts, confs = predicts_gpu.cpu().numpy(), confs_gpu.cpu().numpy()\n\n    labels = [label_encoder.inverse_transform(pred) for pred in predicts]\n    print('labels')\n    print(np.array(labels))\n    print('confs')\n    print(np.array(confs))\n\n    sub = test_loader.dataset.df\n    def concat(label: np.ndarray, conf: np.ndarray) -> str:\n        return ' '.join([f'{L} {c}' for L, c in zip(label, conf)])\n    sub['landmarks'] = [concat(label, conf) for label, conf in zip(labels, confs)]\n\n    sample_sub = sample_sub.set_index('id')\n    sub = sub.set_index('id')\n    sample_sub.update(sub)\n\n    sample_sub.to_csv('july_today_Dec_3_NEW.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 主函数"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 数据\ntrain_loader, test_loader, label_encoder, num_classes = load_data()\n\nmodel = torchvision.models.resnet50(pretrained=False)\n# 要事先浏览resnet-50 每一层的名字，才知道 有 \"avg_pool\"\nmodel.avg_pool = nn.AdaptiveAvgPool2d(1)\nmodel.fc = nn.Linear(model.fc.in_features, num_classes)  # 1.8w 类的个数\nmodel.cuda()   # 送到GPU中\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=LR_STEP,\n                                               gamma=LR_FACTOR)\n\nfor epoch in range(1, NUM_EPOCHS + 1):\n    print('-' * 50)\n    train(train_loader, model, criterion, optimizer, epoch, lr_scheduler)\n    lr_scheduler.step()\n\nprint('inference mode')\ngenerate_submission(test_loader, model, label_encoder)\nprint('done')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}