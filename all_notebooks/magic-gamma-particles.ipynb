{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Dependencies"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport pandas_profiling as pp\nimport matplotlib.pyplot as plt\nfrom colorama import Fore, Style\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/magic-gamma-telescope-dataset/telescope_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.profile_report(\n    title='Profiling Report for the MAGIC Telescope Dataset'\n).to_notebook_iframe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df.drop(['class'], axis=1)\ny = df['class']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(x)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\ny = le.fit_transform(y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train-Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nx_train, x_test = scaler.fit_transform(x_train), scaler.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Building and Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracies = {}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(\n    n_estimators=100, \n    criterion='entropy', \n    random_state=0\n)\nmodel.fit(x_train, y_train)\n\ny_pred = model.predict(x_test)\nsns.heatmap(confusion_matrix(y_test, y_pred), cmap='YlGnBu', annot=True)\nplt.show()\naccuracies['RandomForest'] = accuracy_score(y_test, y_pred) * 100\nprint(f\"Accuracy: {accuracies['RandomForest']:.2f}%\\n\")\nprint(classification_report(y_test, y_pred, target_names=['gamma', 'hadron']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\n\nmodel = SGDClassifier(random_state=0)\nmodel.fit(x_train, y_train)\n\ny_pred = model.predict(x_test)\nsns.heatmap(confusion_matrix(y_test, y_pred), cmap='YlGnBu', annot=True)\nplt.show()\naccuracies['LogReg'] = accuracy_score(y_test, y_pred) * 100\nprint(f\"Accuracy: {accuracies['LogReg']:.2f}%\\n\")\nprint(classification_report(y_test, y_pred, target_names=['gamma', 'hadron']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Support Vector Machine"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\nmodel = SVC(C=57, random_state=0)\nmodel.fit(x_train, y_train)\n\ny_pred = model.predict(x_test)\nsns.heatmap(confusion_matrix(y_test, y_pred), cmap='YlGnBu', annot=True)\nplt.show()\naccuracies['SVM'] = accuracy_score(y_test, y_pred) * 100\nprint(f\"Accuracy: {accuracies['SVM']:.2f}%\\n\")\nprint(classification_report(y_test, y_pred, target_names=['gamma', 'hadron']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier(criterion='entropy', random_state=0)\nmodel.fit(x_train, y_train)\ny_pred = model.predict(x_test)\nsns.heatmap(confusion_matrix(y_test, y_pred), cmap='YlGnBu', annot=True)\nplt.show()\naccuracies['DT'] = accuracy_score(y_test, y_pred) * 100\nprint(f\"Accuracy: {accuracies['DT']:.2f}%\\n\")\nprint(classification_report(y_test, y_pred, target_names=['gamma', 'hadron']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(256, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(256, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(2, activation='sigmoid'),\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_nn, x_cv_nn, y_train_nn, y_cv_nn = train_test_split(x_train, y_train, test_size=0.25, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 6\nhistory = model.fit(\n    x_train_nn, y_train_nn, epochs=num_epochs, \n    validation_data=(x_cv_nn, y_cv_nn),\n    steps_per_epoch=x_train.shape[0] // num_epochs,\n    callbacks=[\n        tf.keras.callbacks.ReduceLROnPlateau(patience=2, verbose=2)\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_train = history.history['loss']\nloss_validation = history.history['val_loss']\nepochs = range(1, num_epochs + 1)\nplt.plot(epochs, loss_train, 'g', label='Training')\nplt.plot(epochs, loss_validation, 'b', label='Validation')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_train = history.history['accuracy']\nacc_validation = history.history['val_accuracy']\nepochs = range(1, num_epochs + 1)\nplt.plot(epochs, acc_train, 'g', label='Training')\nplt.plot(epochs, acc_validation, 'b', label='Validation')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(x_test)\ny_pred = [np.argmax(y) for y in y_pred]\nsns.heatmap(confusion_matrix(y_test, y_pred), cmap='YlGnBu', annot=True)\nplt.show()\naccuracies['NN'] = accuracy_score(y_test, y_pred) * 100\nprint(f\"Accuracy: {accuracies['NN']:.2f}%\\n\")\nprint(classification_report(y_test, y_pred, target_names=['gamma', 'hadron']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.barplot(list(accuracies.keys()), list(accuracies.values()))\nfor p in ax.patches:\n    ax.annotate(\n        f'{p.get_height():2.2f}%', \n        (p.get_x() + p.get_width() / 2., p.get_height()), \n        ha = 'center', va = 'center', \n        xytext = (0, -20), textcoords = 'offset points'\n    )\nplt.xlabel('Models')\nplt.ylabel('Accuracy')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion"},{"metadata":{},"cell_type":"markdown","source":"Tree-based Classification Models tend to perform better on the dataset."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}