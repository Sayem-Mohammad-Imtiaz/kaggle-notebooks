{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center>Online Retail Clustering</center>\n\n### Agenda : \nWe are required to cluster the customers using different attributes shared in the data\n### Data used : \nWe have used the data to define the frequency of purchase, recency of purchase and amount of purchase to cluster the customers\n\n### This notebook has been created after multiple iteration:<br>\n1. Iteration 1 : Implemented the K means algorithm using python\n2. Iteration 2 : Created other data attributes which may help in Clustering\n3. Iteration 3 : Scaled the data to improve the clustering technique\n4. Iteration 4 : Lastly, realised there are anomalies and so implemented IQR to eliminate iteration\n","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport datetime","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reading dataframe","metadata":{}},{"cell_type":"code","source":"# Pulling invoice data\ndf_retail = pd.read_csv(\"/kaggle/input/online-retail-customer-clustering/OnlineRetail.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_retail.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Null value treatment","metadata":{}},{"cell_type":"code","source":"df_retail.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Number of na in customer id =' ,df_retail['CustomerID'].isna().sum())\nprint('Number of null in customer id =' ,df_retail['CustomerID'].isnull().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_retail.dropna(inplace=True)\ndf_retail.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating attributes for clustering","metadata":{}},{"cell_type":"code","source":"# First attribute : Total amount paid\ndf_retail['Amount'] = df_retail['Quantity'] * df_retail['UnitPrice']\ndf_amount = df_retail.groupby(['CustomerID'],as_index=False)[\"Amount\"].sum()\ndf_amount.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Second attribute : Purchase recency\n\n# UDF to convert string to datetime\ndef convertDate(x):\n    conv_date = datetime.datetime.strptime(x, '%d-%m-%Y %H:%M')\n    return conv_date","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# UDF to split date and pick out recent purchase days \ndef splitDate(y):\n    y = str(y)\n    num_days = y.split()[0]\n    num_days = int(num_days)\n    return num_days","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_retail['InvoiceDate'] = df_retail.loc[:,'InvoiceDate'].apply(convertDate)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_date = df_retail['InvoiceDate'].max()\ndf_retail['Recent_purchase_days'] = max_date - df_retail['InvoiceDate']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_retail['Recent_purchase_days'] = df_retail['Recent_purchase_days'].apply(splitDate)\ndf_rec_purch = df_retail.groupby(['CustomerID'],as_index=False)[\"Recent_purchase_days\"].min()\ndf_rec_purch.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Attribute : Frequency of purchase\ndf_purchase_freq = df_retail.groupby(['CustomerID'],as_index=False)[\"InvoiceNo\"].count()\ndf_purchase_freq.rename(columns={'CustomerID':'CustomerID','InvoiceNo':'PurchaseCount'},inplace=True)\ndf_purchase_freq.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Analytical data set for the clustering model","metadata":{}},{"cell_type":"code","source":"df_amt_purch = df_amount.merge(df_rec_purch,how='left',on=['CustomerID'])\ndf_model_inp = df_amt_purch.merge(df_purchase_freq,how='left',on=['CustomerID'])\ndf_model_inp.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Anomaly detection","metadata":{}},{"cell_type":"code","source":"# UDF to determine outliers in data for all the columns\ndef viewDistribution(df):\n    sns.boxplot(data=df)\n    plt.xticks(rotation=90)\n    plt.show","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# INSIGHTS: There are outliers in amount and frequency column\ndf_anomaly = df_model_inp.iloc[:,1:4]\nviewDistribution(df_anomaly)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# UDF to remove outlier\ndef remove_outlier_IQR(df):\n    Q1=df.quantile(0.25)\n    Q3=df.quantile(0.75)\n    IQR=Q3-Q1\n    df_final=df[~((df<(Q1-1.5*IQR)) | (df>(Q3+1.5*IQR)))]\n    return df_final","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removed the anomalies in all the columns\ndf_IQR = remove_outlier_IQR(df_anomaly)\ndf_IQR.fillna(0,inplace=True)\nviewDistribution(df_IQR)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Performing scaling on the analytical data set","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n# define standard scaler\nscaler = StandardScaler()\n# transform data\ndf_scalar = scaler.fit_transform(df_IQR)\n\ndf_scalar1 = pd.DataFrame(df_scalar)\ndf_scalar1.columns = ['Amount' , 'Frequency' , 'Recency']\ndf_scalar1.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Mathematical implementation of K means clustering techinique\n1.Pick K points as the initial centroids from the data set, either randomly or the first K.<br>\n2.Find the Euclidean distance of each point in the data set with the identified K points — cluster centroids.<br>\n3.Assign each data point to the closest centroid using the distance found in the previous step.<br>\n4.Find the new centroid by taking the average of the points in each cluster group.<br>\n5.Repeat iteration till the centroids don’t change.<br>\n","metadata":{}},{"cell_type":"code","source":"# Defining centroids\nk = 5\n\n# Filtering the columns required for clustering\ndata = df_IQR.iloc[:,0:3]\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Storing the sample dataframe to determine the number of centroids\nk_means = (data.sample(k, replace=False))    # store current means\nk_means2 = pd.DataFrame()                    # store previous means\nclusters = pd.DataFrame()    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"while not k_means2.equals(k_means):\n    # distance matrix (euclidean distance)\n    cluster_count = 0\n    for idx, k_mean in k_means.iterrows():\n        clusters[cluster_count] = (data[k_means.columns] - np.array(k_mean)).pow(2).sum(1).pow(0.5)\n        cluster_count += 1\n\n    # update cluster\n    data['MDCluster'] = clusters.idxmin(axis=1)\n\n    # store previous cluster\n    k_means2 = k_means\n    k_means = pd.DataFrame()\n    k_means_frame = data.groupby('MDCluster').agg(np.mean)\n    k_means[k_means_frame.columns] = k_means_frame[k_means_frame.columns]","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plotting clusters ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nsns.scatterplot(x=data['Amount'] ,y=data['Recent_purchase_days'] , hue = data['MDCluster'], palette = sns.color_palette('hls',5))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nsns.scatterplot(x=data['Amount'] ,y=data['PurchaseCount'] , hue = data['MDCluster'], palette = sns.color_palette('hls',5))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nsns.scatterplot(x=data['Recent_purchase_days'] ,y=data['PurchaseCount'] , hue = data['MDCluster'], palette = sns.color_palette('hls',5))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}