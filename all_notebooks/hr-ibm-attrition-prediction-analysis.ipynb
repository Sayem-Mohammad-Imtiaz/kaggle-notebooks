{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Goal**\n\nMy goal for this notebook is to showcase two different approaches to predicting attrition responses based on a pre-generated dataset developed by IBM. The dataset specifically has a column denoting responses to whether an employee feels they are attritioned. The dataset then has a corresponding number of other categories to measure other data. \n\nThe classification models that will be utilized are the Neural Network classifier implemented by the Multi Layer Perceptron algorithm and the other model will be the Random Forest classifier. Both models are implemented using the by scikit-learn libraries. All categories other than the Attrition category will be used as independent variables to help train the models to accurately predict the dependent variable.    "},{"metadata":{},"cell_type":"markdown","source":"**Importing Libraries**\n\nMultiple packages and libraries will be utilized to help process the data, create the model, and display the results in several visualizations. The main modeling library is scikit-learn which is the sklearn package that will be utilized to preprocess the data and to create/train/test the model. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# HR Employee Attrition Predictor\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport graphviz\nimport seaborn as sns\nimport sklearn.metrics as metrics\nimport plotly.graph_objs as go\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n \nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.compose import ColumnTransformer, make_column_transformer\nfrom matplotlib.colors import ListedColormap\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Graphing ROC Curve**\n\nFunction that graphs the ROC Curve based on the y test values vs the model predicted y test values. The ROC curve or the AUC ROC Curve (Area under the Curve Receiver Operating Characteristics) evaluates the classification models' performance. It explains how accurately the model is able to predict the various classification classes. \n\nSource:\n- https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5"},{"metadata":{"trusted":true},"cell_type":"code","source":"def graphROCCurve(y_test, y_pred):    \n    fpr = {}\n    tpr = {}\n    roc_auc = {}\n    \n    # Compute micro-average ROC curve and ROC area\n    fpr, tpr, _ = metrics.roc_curve(y_test, y_pred, pos_label=\"Yes\")\n    roc_auc = metrics.auc(fpr, tpr)\n    \n    plt.figure()\n    lw = 2\n    plt.plot(fpr, tpr, color='darkorange',\n             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic')\n    plt.legend(loc=\"lower right\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Graphing important features for Random Forest Classifier**\n\nThis method deals with graphing the output of calling the random forest classifier's features importance attribute. The attribute details what features within the set of independent variables that were provided made an impact in the model's ability to classify the class.\n\nSource:\n- https://towardsdatascience.com/running-random-forests-inspect-the-feature-importances-with-this-code-2b00dd72b92e"},{"metadata":{"trusted":true},"cell_type":"code","source":"def graphFeaturesImportant(rf_classifier, features):\n    trace = go.Scatter(\n        y = features, \n        x = dataset.columns.values, mode = \"markers\",\n        marker = dict(\n            sizemode = \"diameter\", sizeref=1, size=13, \n            color=features, colorscale=\"Portland\",\n            showscale=True\n        ),\n        text = dataset.columns.values\n    )\n    data = [trace]\n\n    layout = go.Layout(\n        autosize = True,\n        title = \"Random Forest Feature Importance\",\n        hovermode = \"closest\",\n        xaxis = dict(\n            ticklen=5, showgrid=True, zeroline=True, showline=True\n        ),\n        yaxis = dict(\n            title=\"Feature Importance\", showgrid=True, zeroline=True,\n            ticklen=5, gridwidth=2\n        ),\n        showlegend=False\n    )\n    \n    fig = go.Figure(data=data, layout=layout)\n    py.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Defining the Neural Network Model**\n\nThe Multi-layer Perceptron algorithm is a supervised learning algorithm that follows the concept of a neural network. In a neural network a list of feature variables are passed in via the input layer to calculate weights that will allow it to be aggregated to satisfy the activation function and ultimately be sent out via the output layer. \n\nIn between are varying layers of hidden layers that are utilized to learn and adjust the weights to better fit the values to the expected output. Here in this app I am creating a multi-layer perceptron with 13 nodes in the hidden layer and I am using the Stochastic gradient-based optimizer to optimize the neural network as it backpropagates to better scale and fit the data.  \n\nSource:\n- https://scikit-learn.org/stable/modules/neural_networks_supervised.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"# developing the Multi Layer Perceptron Neural Network\ndef creatingNeuralNetworkPredictor(X_train, y_train, X_test, y_test, preprocess):\n    print(\"\\nNeural Network Classifier Section\")\n    print(\"---------------------------------\")\n    \n    # initialize the Multi Layer Perceptron Neural Network \n    mlp_classifier = MLPClassifier(solver=\"adam\", alpha=1e-5, max_iter=500,\n                               hidden_layer_sizes=(13, 13, 13))\n    \n    # hook up the preprocess step with the classifier params and create the pipeline\n    model = make_pipeline(preprocess, mlp_classifier)\n    \n    # fitting the Multi Layer Perceptron to the training set\n    model.fit(X_train, y_train)\n    \n    print(\"Training set Score: \", model.score(X_train, y_train))\n    print(\"Testing set Score: \", model.score(X_test, y_test))    \n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Defining the Random Forest Classifier**\n\nCreating a random forest classifier model along with training and testing it. A random forest classifier leverages a number of decision trees and aggregates their prediction values to find the best value given multiple iterations of sub-sampling the training data. \n\nIt uses averaging to improve the prediction accuracy and to control over-fitting. Several parameters were utilized to configure the random forest classifier:\n\n- n_estimators: Number of trees in the forest.\n- n_jobs: The number of jobs to run in parallel for both fit and predict.\n\nSource:\n- https://towardsdatascience.com/understanding-random-forest-58381e0602d2"},{"metadata":{"trusted":true},"cell_type":"code","source":"# developing the Random Forest Classifier\ndef creatingRandomForestPredictor(X_train, y_train, X_test, y_test, preprocess):\n    print(\"\\nRandom Forest Classifier Section\")\n    print(\"---------------------------------\")\n    \n    # initialize the Multi Layer Perceptron Neural Network \n    random_forest_classifier = RandomForestClassifier(**{'n_jobs': -1,\n        'n_estimators': 800\n    })\n    \n    # hook up the preprocess step with the classifier params and create the pipeline\n    model = make_pipeline(preprocess, random_forest_classifier)\n    \n    # fitting Random Forest to the training set\n    model.fit(X_train, y_train)\n    \n    print(\"Training set Score: \", model.score(X_train, y_train))\n    print(\"Testing set Score: \", model.score(X_test, y_test))    \n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing the fictionally generated data that was retrieved from Kaggle.\n\nhttps://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing the data\ndataset = pd.read_csv(\"../input/WA_Fn-UseC_-HR-Employee-Attrition.csv\")\ndataset = dataset.drop([\"YearsWithCurrManager\"], axis=1)\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Setting up preprocess steps using the sklearn feature of Pipelines. Main tasks include the following: \n\n- Separating the independent variables from the dependent variable of Attrition.  \n- Separating numerical columns from columns that have string values. \n- Used OneHotEncoder method and library to encode string values of a category into numeric array like integers that can be used to represent the categorical values in a discrete manner.\n- Used SimpleImputer to complete missing or null values within a column. \n- Used StandardScaler to standardize the features by removing mean and scaling to unit variance. Often times when features don't look more like each other, it can throw off the estimators. \n\nSource:\n- https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n- https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"# using ColumnTransformer only approach\ntransformed_data = dataset.loc[:, dataset.columns != \"Attrition\"]\nX = transformed_data.values\ny = dataset.Attrition.values\n\nnumerical_features = transformed_data.dtypes == \"int64\"\ncategorical_features = ~numerical_features\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n\npreprocess = make_column_transformer(\n    (OneHotEncoder(), categorical_features),\n    (make_pipeline(SimpleImputer(), StandardScaler()), numerical_features)\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Provided initial analysis of the data including column names, any null values within the data, and total responses per Attrition values."},{"metadata":{"trusted":true},"cell_type":"code","source":"# outputting data summary\nprint(\"Summary Info About the Dataset\")\nprint(\"Does category contain null values?\")\nprint(dataset.isnull().any(), \"\\n\")\nprint(\"Said Yes to Attrition: \", y[(y == \"Yes\")].size)\nprint(\"Said No to Attrition:  \", y[(y == \"No\")].size)\nprint(\"Total responses:       \", y.size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training and Testing the Neural Network Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"nn_model = creatingNeuralNetworkPredictor(X_train, y_train, X_test, y_test, preprocess)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Analyzing the Model - Accuracy, Classification Report, ROC Curve, Confusion Matrix, and Features Importance**\n\nSome notable measurements include the following:\n- Accuracy score of the prediction represented in a percentage value. \n- Classification Report \n    - Metrics\n        - Precision: Ratio that dictates the ability of the classifier not to label as positive if a sample is negative. \n        - Recall: Ratio that dictates the ability of the classifier to find all positive samples.\n        - F1-Score or F-beta score is the weighted harmonic of the precision and recall.\n        - Support is the number of occurrences of each class. \n    - Labels - other than the values of each class in the dependent variable\n        - Macro Average: Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n        - Weighted Average: Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall.\n        - Zero One Loss: Measurement that measures the entire set of labels to make sure it is correctly predicted, otherwise the loss for the sample will be one. The best performance is therefore a 0.\n        - Log Loss: Calculates for a list of actual of valid values, how much of a probability in the accuracy of the prediction was for each of the labels.   \n- ROC Curve\n    - As discussed before the ROC curve or the AUC ROC Curve (Area under the Curve Receiver Operating Characteristics) evaluates the classification models' performance. \n    - It explains how accurately the model is able to predict the various classification classes.\n    - The macro average is used since there are only two classes for classification (Yes or No). It will treat each metric independently and take an average resulting in the classes having equal weight.\n- Confusion Matrix\n    - Chart and calculations that measures the number of true positives, true negatives, false positives, and false negatives between the prediction and test values.\n\nSource:\n- https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62        \n- https://markhneedham.com/blog/2016/09/14/scikit-learn-first-steps-with-log_loss/        \n- https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n- https://scikit-learn.org/stable/modules/generated/sklearn.metrics.zero_one_loss.html"},{"metadata":{},"cell_type":"markdown","source":"**Analyzing the Neural Network Model - Accuracy**\n- The overall prediction accuracy of the model is fairly high at classifying the Attrition values. \n- However, a break down of the classification labels shows that the model has a higher accuracy rate with accurately predicting No versus Yes. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting the Test set results\nnn_y_pred = nn_model.predict(X_test)\n\n# output results\nnn_y_pred_prob = nn_model.predict_proba(X_test)[:, 1]\n\nprint(\"Accuracy Score of Prediction : \", metrics.accuracy_score(y_test, nn_y_pred) * 100)\nprint(\"\\nClassification Report\")\nprint(metrics.classification_report(y_test, nn_y_pred))\nprint(\"Zero One Loss: \", metrics.zero_one_loss(y_test, nn_y_pred))\nprint(\"Log Loss:      \", metrics.log_loss(y_test, nn_y_pred_prob))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Analyzing the Neural Network Model - ROC Curve**\n- Visually we can tell that since the ROC curve is nearer to the middle of lining up with the y-axis and the x-axis with a slop of nearly 1 for both that the model scores at a good range in the ROC score. "},{"metadata":{"trusted":true},"cell_type":"code","source":"graphROCCurve(y_test, nn_y_pred_prob)\nprint(\"ROC AUC Score: \", metrics.roc_auc_score(y_test, nn_y_pred_prob, average=\"macro\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Analyzing the Neural Network Model - Confusion Matrix**\n- The confusion matrix breaks down the expected responses and how the predictions lined up. \n- We can see that most of the responses were No and we accurately predicted that. While for the Yes responses we fared worse with over half of the responses being predicted as No when they should have been Yes."},{"metadata":{"trusted":true},"cell_type":"code","source":"nn_cm = metrics.confusion_matrix(y_test, nn_y_pred)\nsns.heatmap(nn_cm)\nprint(\"\\nConfusion Matrix\")\nprint(pd.crosstab(y_test.ravel(), nn_y_pred.ravel(), rownames=['True'], colnames=['Predicted'], margins=True))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training and Testing the Random Forest Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model = creatingRandomForestPredictor(X_train, y_train, X_test, y_test, preprocess)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true},"cell_type":"markdown","source":"**Analyzing the Random Forest Model - Accuracy**\n- We can see that the Random Forest model had a prediction accuracy of that is comparable to that of the neural network. \n- Additionally, for the Yes responses the random forest approach fared better as a whole with that type of response scoring at a higher rate of precision, but was more dispersed in the other categories. "},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Predicting the Test set results\nrf_y_pred = rf_model.predict(X_test)\n\n# output results\nrf_y_pred_prob = rf_model.predict_proba(X_test)[:, 1]\nprint(\"Accuracy Score of Prediction : \", metrics.accuracy_score(y_test, rf_y_pred) * 100)\nprint(\"\\nClassification Report\")\nprint(metrics.classification_report(y_test, rf_y_pred))\nprint(\"Zero One Loss: \", metrics.zero_one_loss(y_test, rf_y_pred))\nprint(\"Log Loss:      \", metrics.log_loss(y_test, rf_y_pred_prob))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Analyzing the Random Forest Model - ROC Curve**\n- The ROC curve meanwhile showcased the random forest model did a little better than that of the neural network model. \n- With the ROC score we can see the curve moving closer to that of the main slope line of 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"graphROCCurve(y_test, rf_y_pred_prob)\nprint(\"ROC AUC Score: \", metrics.roc_auc_score(y_test, rf_y_pred_prob, average=\"macro\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Analyzing the Random Forest Model - Confusion Matrix**\n- The confusion matrix showcases that the random forest model fared better in the Yes label category as it was able to predict more accurately positive predictions for Yes responses. \n- It did more about the same rate of success for No responses as the neural network model."},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_cm = metrics.confusion_matrix(y_test, rf_y_pred)\nprint(\"\\nConfusion Matrix\")\nprint(pd.crosstab(y_test.ravel(), rf_y_pred.ravel(), rownames=['True'], colnames=['Predicted'], margins=True))\nsns.heatmap(rf_cm, center=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true},"cell_type":"markdown","source":"As demonstrated above, both types of machine learning models can be utilized to accurately predict the attrition rate given the independent variables provided. I, also, found using the Pipelines approach provided by scikit-learn a great way to preprocess/transform the data. It was a more organized way of coordinating what columns needed to be changed without drilling manually into each column. \n\nHope you enjoy it as well :)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}