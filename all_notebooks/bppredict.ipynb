{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def numpy_ewma_vectorized_v2(data, window):\n\n    alpha = 2 /(window + 1.0)\n    alpha_rev = 1-alpha\n    n = data.shape[0]\n\n    pows = alpha_rev**(np.arange(n+1))\n\n    scale_arr = 1/pows[:-1]\n    offset = data[0]*pows[1:]\n    pw0 = alpha*alpha_rev**(n-1)\n\n    mult = data*pw0*scale_arr\n    cumsums = mult.cumsum()\n    out = offset + cumsums*scale_arr[::-1]\n    return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(dataListM10[20000]))\ndata = dataListM10[1]\nwaveletname = 'db5'\n\nplt.plot(data)\nplt.show()\n\nfig, axarr = plt.subplots(nrows=3, ncols=2, figsize=(18,18))\n# for ii in range(3):\nii = 0\ncoeff_d = pywt.swt(data, waveletname, level = 3)\n\n# print(len(coeff_d))\n# for i in range(3):\n#     print(len(coeff_d[i]))\n#     print(coeff_d[i])\n\nfor ii in range(3):    \n    axarr[ii, 0].plot(coeff_d[ii][0], 'r')\n    axarr[ii, 1].plot(coeff_d[ii][1], 'g')\n\n    #     if ii == 0:\n    #         axarr[ii, 0].set_title(\"Approximation coefficients\", fontsize=14)\n    #         axarr[ii, 1].set_title(\"Detail coefficients\", fontsize=14)\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from google.cloud import bigquery\n# client = bigquery.Client()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"print(os.listdir('../input'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.io\nmat1 = scipy.io.loadmat('../input/part_1.mat')\n# print(mat1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.signal import find_peaks\nfrom scipy.signal import resample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize(arr):\n    return (arr- np.min(arr))/(np.max(arr) - np.min(arr))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testMat = scipy.io.loadmat('../input/part_{}.mat'.format(1))['p']\ntempMat = testMat[0, 0]\nmean = np.mean(tempMat[0, 0])\nstd = np.std(testMat[0, 0])\nmeanStd = mean/std\nprint(mean, \" hahaha \", std, \"lalala\", meanStd)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tempSize = 125\ndataTest = []\nfor i in range(1000):\n    tempMat = testMat[0, i]\n    tempLength = tempMat.shape[1]\n    for j in range((int)(tempLength/tempSize)):\n        tempPpg = tempMat[0, j*tempSize:(j+1)*tempSize]\n        dataTest.append(tempPpg)\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test(aTest, meanStd):\n    tempSum = 0\n    mean = np.mean(aTest)\n    std = np.std(aTest)\n    for i in range(125):\n        tempSum += np.power((aTest[i] - mean/std), 3)\n    return tempSum/125","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(dataTest))\nnumAb = 0\nfor j in range(10):\n    tempSum = 0\n    aTest = dataTest[j*1200]\n    res = test(aTest, meanStd)\n    numAb += 1\n    plt.plot(aTest)\n    plt.show()\n    print(res)\n\nprint(numAb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.io\ndataListM10 = []\ntarget = []\nsize = 1000\nfor k in range(0):\n    testMat = scipy.io.loadmat('../input/part_{}.mat'.format(k+1))['p']\n    for i in range(1000):\n        tempMat = testMat[0, i]\n        tempLength = tempMat.shape[1]\n        tempMat[0, :] = normalize(tempMat[0, :])\n#         tempMat[2, :] = normalize(tempMat[2, :])\n        for j in range((int)(tempLength/size)):\n            tempPpg = tempMat[0, j*size:(j+1)*size]\n#             tempPpg = tempMat[0, j*size:(j+1)*size].reshape(18, 18)\n\n#             tempEcg = tempMat[2, j*size:(j+1)*size].reshape(18, 18)\n            tempBp = tempMat[1, j*size:(j+1)*size]\n#             dataListM10.append(np.r_[tempPpg, tempEcg].reshape(32, 32))\n            dataListM10.append(tempPpg)\n            target.append(tempBp)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tempSize = 125\ndataTest = []\ntestMat = scipy.io.loadmat('../input/part_{}.mat'.format(1))['p']\nfor i in range(1000):\n    tempMat = testMat[0, i]\n    tempLength = tempMat.shape[1]\n    for j in range((int)(tempLength/tempSize)):\n        tempPpg = tempMat[0, j*tempSize:(j+1)*tempSize]\n        dataTest.append(tempPpg)\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(dataTest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(dataTest[2])\nplt.show()\n\ntempSum = 0\naTest = dataTest[2]\n\nmean = np.mean(testMat[0, 0])\nstd = np.std(testMat[0, 0])\nmeanStd = mean/std\n\n\nprint(mean, \" hahaha \", std, \"lalala\", meanStd)\nfor j in range(25):\n    tempSum = 0\n    aTest = dataTest[j]\n    for i in range(125):\n        tempSum += np.power((aTest[i] - meanStd), 3)\n    res = tempSum/125\n    plt.plot(aTest)\n    plt.show()\n    print(res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tempSize = 125\ndataTest0 = []\ntestMat0 = scipy.io.loadmat('../input/part_{}.mat'.format(12))['p']\nfor i in range(0):\n    tempMat = testMat0[0, i]\n    tempLength = tempMat.shape[1]\n    for j in range((int)(tempLength/tempSize)):\n        tempPpg = tempMat[0, j*tempSize:(j+1)*tempSize]\n        dataTest0.append(tempPpg)\nprint(len(dataTest0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in range(1000):\n#     print(testMat0[0,i].shape)\n# for i in range(1000):\n#     plt.plot(testMat0[0, i][0, 0:125])\n#     plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean = np.mean(testMat[0, 0])\nstd = np.std(testMat[0, 0])\nmeanStd = mean/std\nprint(testMat0[0,0].shape)\nprint(len(dataTest0))\nnumAb = 0\nfor j in range(0):\n    tempSum = 0\n    aTest = dataTest0[j*1200]\n    if test(aTest, meanStd) == False:\n#     for i in range(125):\n#         tempSum += np.power((aTest[i] - meanStd), 3)\n#     res = tempSum/125\n#     if (res > 4 or res < 2):\n        numAb += 1\n        plt.plot(aTest)\n        plt.show()\n        print(res)\n\nprint(numAb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(dataListM10))\nprint(len(target))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.plot(target[500000])\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data as td\nimport torchvision as tv\nfrom torch.autograd import Variable\n\nfrom torch.utils.data import DataLoader\nimport torch.nn.init as torch_init\n\nfrom PIL import Image\n# import nntools as nt\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if torch.cuda.is_available:\n    device = torch.device(\"cuda\")\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class dataSetABP(td.Dataset):\n    def __init__(self, dataList, target, M=32, mode = 'train'):\n        super(td.Dataset, self).__init__()\n        self.mode = mode\n        self.dataList = dataList\n        self.target = target\n        self.M = M\n        self.trainLength = int(0.8*len(self.dataList))\n        self.valLength = int(0.1*len(self.dataList))\n    def __len__(self):\n        if self.mode == 'train':\n            return int(0.8*len(self.dataList))\n        else:\n            return int(0.1*len(self.dataList))\n    def __getitem__(self, idx):\n\n        if self.mode == 'train': # np.expand_dims(x, axis=1)\n            return torch.from_numpy(np.expand_dims(self.dataList[idx], axis=0)).type(torch.FloatTensor), torch.from_numpy(self.target[idx]).type(torch.FloatTensor)\n#             idxStart = idx*self.M # \n#             return torch.from_numpy(np.stack(self.dataList[idxStart:idxStart+self.M])).type(torch.FloatTensor), torch.from_numpy(np.stack(self.target[idxStart:idxStart+self.M])).type(torch.FloatTensor)\n        elif self.mode == 'val':\n            return torch.from_numpy(np.expand_dims(self.dataList[idx+self.trainLength], axis=0)).type(torch.FloatTensor), torch.from_numpy(self.target[idx+self.trainLength]).type(torch.FloatTensor)\n#             idxStart = (idx+self.trainLength)*self.M\n#             return torch.from_numpy(np.stack(self.dataList[idxStart:idxStart+self.M])).type(torch.FloatTensor), torch.from_numpy(np.stack(self.target[idxStart:idxStart+self.M])).type(torch.FloatTensor)\n        else:\n            return torch.from_numpy(np.expand_dims(self.dataList[idx+self.trainLength+self.valLength], axis=0)).type(torch.FloatTensor), torch.from_numpy(self.target[idx+self.trainLength+self.valLength]).type(torch.FloatTensor)\n#             idxStart = (idx+self.trainLength+self.valLength)*self.M\n#             return torch.from_numpy(np.stack(self.dataList[idxStart:idxStart+self.M])).type(torch.FloatTensor), torch.from_numpy(np.stack(self.target[idxStart:idxStart+self.M])).type(torch.FloatTensor)\n\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# trainSet = dataSetABP(dataListM10, target, M=32, mode = 'train')\n# valSet = dataSetABP(dataListM10, target, M=32, mode = 'val')\n# testSet = dataSetABP(dataListM10, target, M=32, mode = 'test')\ntrainLoader = DataLoader(dataSetABP(dataListM10, target, M=32, mode = 'train'), batch_size = 128, shuffle = True, pin_memory = True, drop_last = True)\nvalLoader = DataLoader(dataSetABP(dataListM10, target, M=32, mode = 'val'), batch_size = 128, shuffle = False, pin_memory = True, drop_last = True)\ntestLoader = DataLoader(dataSetABP(dataListM10, target, M=32, mode = 'test'), batch_size = 128, shuffle = True, pin_memory = True, drop_last = True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for ppgEcg, target0 in enumerate(trainLoader):\n    \n#     print(ppgEcg.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Resnet18Transfer(nn.Module):\n    def __init__(self, num_classes, fine_tuning=True):\n        super(Resnet18Transfer, self).__init__() \n        resnet = tv.models.resnet18(pretrained=False) \n        for param in resnet.parameters():\n            param.requires_grad = fine_tuning\n            self.conv1 = torch.nn.Conv2d(1, 64, kernel_size = 7)\n            self.bn1 = resnet.bn1\n            self.relu = resnet.relu\n            self.maxpool = resnet.maxpool\n            self.layer1 = resnet.layer1\n            self.layer2 = resnet.layer2\n            self.layer3 = resnet.layer3\n            self.layer4 = resnet.layer4\n            self.avgpool = resnet.avgpool\n            num_ftrs = resnet.fc.in_features\n            self.fc = nn.Linear(num_ftrs, num_classes) \n            \n    def forward(self, x):\n        h = self.conv1(x)\n        h = self.bn1(h)\n        h = self.relu(h)\n        h = self.maxpool(h)\n        h = self.layer1(h)\n        h = self.layer2(h)\n        h = self.layer3(h)\n        h = self.layer4(h)\n        h = self.avgpool(h) \n        h = h.view(-1, 512) \n        y = self.fc(h) \n        return y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Resnet18Transfer(size).to(device)\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = annLstm(M = 32).to(device)\n# criterion = torch.nn.MSELoss()\n# optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def validation(model, valLoader):\n    with torch.no_grad():\n        mean_loss = 0\n        for j, [ppgEcg, target0] in enumerate(valLoader):\n            ppgEcg, target0 = ppgEcg.to(device), target0.to(device)\n            outputs = model(ppgEcg)\n            outputs = torch.squeeze(outputs, dim = 0)\n            loss = criterion(outputs, target0)\n            mean_loss += loss.item()\n        return mean_loss / len(valLoader)\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # optimizer = torch.optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\ntimeIter = 0\ntempLoss = 0\n# hidden = model.init_hidden()\nfor i in range(timeIter):\n    print(\"i\", i)\n    if i > 0:\n        for g in optimizer.param_groups:\n            g['lr'] = 0.0001\n    for j, [ppgEcg, target0] in enumerate(trainLoader):\n#         print(\"hello j = \", j)\n        ppgEcg, target0 = ppgEcg.to(device), target0.to(device)\n        optimizer.zero_grad()\n        outputs = model(ppgEcg)\n        outputs = torch.squeeze(outputs, dim = 0)\n#         target0 = target0.view(-1, 256)\n#         print(outputs.size())\n#         print(target0.detach().size())\n#         print(\"target \", target[0])\n#         print(\"outputs\", outputs[0])\n        loss = criterion(outputs, target0)\n        loss.backward()\n        optimizer.step()\n        tempLoss += loss.item()\n        if j % 500 == 0 and j != 0:\n            print(\"j\", j, tempLoss/500)\n            valLoss = validation(model, valLoader)\n            print(\"val \", valLoss)\n#             print(\"target \", target0[:5])\n#             print(\"outputs\", outputs[:5])\n#             print(model.fc1.weight[:5, :5])\n            tempLoss = 0.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for j, [ppgEcg, target0] in enumerate(testLoader):\n        ppgEcg, target0 = ppgEcg.to(device), target0.to(device)\n        print(ppgEcg.size())\n        optimizer.zero_grad()\n        outputs = model(ppgEcg)\n#         outputs = torch.squeeze(outputs, dim = 0)\n        if j == 3:\n            break;\n            \ntestNum = size\n\nground_truth = target0.detach().cpu().numpy()\nprediction = outputs.detach().cpu().numpy()\n\nprint(ground_truth.shape)\n\ntestCase = 10\nfor i in range(12):\n    plt.figure(figsize=(20,10))\n    plt.plot(ground_truth[i+20, :testNum], label = \"ground\")\n    plt.plot(prediction[i+20, :testNum], label = \"prediction\")\n    plt.legend(fontsize=20)\n    plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}