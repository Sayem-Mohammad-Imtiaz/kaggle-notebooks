{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install dataprep","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import libraries","metadata":{}},{"cell_type":"code","source":"from dataprep.eda import plot\nfrom dataprep.eda import plot_correlation\nfrom dataprep.eda import plot_missing","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"houses = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/train.csv\")\nhouses.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"houses_test = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/test.csv\")\nhouses_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"houses.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are total 1460 tuples, each tuple contains 80 features and 1 target value.","metadata":{}},{"cell_type":"code","source":"houses_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Variable identification","metadata":{}},{"cell_type":"code","source":"plot(houses)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Overview of the data","metadata":{}},{"cell_type":"markdown","source":"We could get the following information: \n- Variable-Variable name * Type-There are 43 categorical columns and 38 numerical columns. \n- Missing value-How many missing values each column contains. For instance, Fence contains 80.8% * 1460 = 1180 missing tuples. Usually, some model does not allow the input data contains missing value such as SVM, we have to clean the data before we utilize it.\n- Target Value-The distribution of target value (SalePrice). According to the distribution of the target value, we could get the information that the target value is numerical and the distribution of the target value conforms to the norm distribution. Thus, we are not confronted with imbalanced classes problem. It is really great. \n- Guess-According to the columns’ name, we reckon GrLivArea, YearBuilt and OverallQual are likely to be correlated to the target value (SalePrice).","metadata":{}},{"cell_type":"markdown","source":"# Correlation in data","metadata":{}},{"cell_type":"code","source":"plot_correlation(houses, \"SalePrice\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_correlation(houses, \"SalePrice\", value_range=[0.5, 1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- OverallQual, GrLivArea, GarageCars, GarageArea, TotalBsmtSF, 1stFlrSF, FullBath, TotRmsAbvGrd, YearBuilt, YearRemodAdd have more than 0.5 Pearson correlation with SalePrice.\n\n- OverallQual, GrLivArea, GarageCars, YearBuilt, GarageArea, FullBath, TotalBsmtSF, GarageYrBlt, 1stFlrSF, YearRemodAdd, TotRmsAbvGrd and Fireplaces have more than 0.5 Spearman correlation with SalePrice.\n\n- OverallQual, GarageCars, GrLivArea and FullBath have more than 0.5 KendallTau correlation with SalePrice.\n\n- EnclosedPorch and KitchenAbvGr have little negative correlation with target variable.\n\nThese can prove to be important features to predict SalePrice.","metadata":{}},{"cell_type":"markdown","source":"# Heatmap","metadata":{}},{"cell_type":"code","source":"plot_correlation(houses)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# In summary\nIn my opinion, this heatmap is the best way to get a quick overview of features’ relationships.\n\n- At first sight, there are two red colored squares that get my attention. The first one refers to the ‘TotalBsmtSF’ and ‘1stFlrSF’ variables, and the second one refers to the ‘GarageX’ variables. Both cases show how significant the correlation is between these variables. Actually, this correlation is so strong that it can indicate a situation of multicollinearity. If we think about these variables, we can conclude that they give almost the same information so multicollinearity really occurs. Heatmaps are great to detect this kind of situations and in problems dominated by feature selection, like ours, they are an essential tool.\n\n- Another thing that got my attention was the ‘SalePrice’ correlations. We can see our well-known ‘GrLivArea’, ‘TotalBsmtSF’, and ‘OverallQual’, but we can also see many other variables that should be taken into account. That’s what we will do next.","metadata":{}},{"cell_type":"code","source":"plot_correlation(houses[[\"SalePrice\",\"OverallQual\",\"GrLivArea\",\"GarageCars\",\n                  \"GarageArea\",\"GarageYrBlt\",\"TotalBsmtSF\",\"1stFlrSF\",\"FullBath\",\n                  \"TotRmsAbvGrd\",\"YearBuilt\",\"YearRemodAdd\"]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we saw above there are few feature which shows high multicollinearity from heatmap. Lets focus on red squares on diagonal line and few on the sides.\n\n- SalePrice and OverallQual\n\n- GarageArea and GarageCars\n\n- TotalBsmtSF and 1stFlrSF\n\n- GrLiveArea and TotRmsAbvGrd\n\n- YearBulit and GarageYrBlt\n\nWe have to create a single feature from them before we use them as predictors.","metadata":{}},{"cell_type":"code","source":"plot_correlation(houses, value_range=[0.5, 1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_correlation(houses, k=30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Attribute Pair Correlation\n\n- 7 (GarageArea, GarageCars) 0.882475\n\n- 11 (GarageYrBlt, YearBuilt) 0.825667\n\n- 15 (GrLivArea, TotRmsAbvGrd) 0.825489\n\n- 18 (1stFlrSF, TotalBsmtSF) 0.819530\n\n- 19 (2ndFlrSF, GrLivArea) 0.687501\n\n- 9 (BedroomAbvGr, TotRmsAbvGrd) 0.676620\n\n- 0 (BsmtFinSF1, BsmtFullBath) 0.649212\n\n- 2 (GarageYrBlt, YearRemodAdd) 0.642277\n\n- 24 (FullBath, GrLivArea) 0.630012\n\n- 8 (2ndFlrSF, TotRmsAbvGrd) 0.616423\n\n- 1 (2ndFlrSF, HalfBath) 0.609707\n\n- 4 (GarageCars, OverallQual) 0.600671\n\n- 16 (GrLivArea, OverallQual) 0.593007\n\n- 23 (YearBuilt, YearRemodAdd) 0.592855\n\n- 22 (GarageCars, GarageYrBlt) 0.588920\n\n- 12 (OverallQual, YearBuilt) 0.572323\n\n- 5 (1stFlrSF, GrLivArea) 0.566024\n\n- 25 (GarageArea, GarageYrBlt) 0.564567\n\n- 6 (GarageArea, OverallQual) 0.562022\n\n- 17 (FullBath, TotRmsAbvGrd) 0.554784\n\n- 13 (OverallQual, YearRemodAdd) 0.550684\n\n- 14 (FullBath, OverallQual) 0.550600\n\n- 3 (GarageYrBlt, OverallQual) 0.547766\n\n- 10 (GarageCars, YearBuilt) 0.537850\n\n- 27 (OverallQual, TotalBsmtSF) 0.537808\n\n- 20 (BsmtFinSF1, TotalBsmtSF) 0.522396\n\n- 21 (BedroomAbvGr, GrLivArea) 0.521270\n\n- 26 (2ndFlrSF, BedroomAbvGr) 0.502901\n\nThis shows multicollinearity. In regression, “multicollinearity” refers to features that are correlated with other features. Multicollinearity occurs when your model includes multiple factors that are correlated not just to your target variable, but also to each other.\n\nProblem:\n\nMulticollinearity increases the standard errors of the coefficients. That means, multicollinearity makes some variables statistically insignificant when they should be significant.\n\nTo avoid this we can do 3 things:\n\nCompletely remove those variables Make new feature by adding them or by some other operation. Use PCA, which will reduce feature set to small number of non-collinear features.","metadata":{}},{"cell_type":"markdown","source":"# Univariate Analysis","metadata":{}},{"cell_type":"markdown","source":"How 1 single variable is distributed in numeric range. What is statistical summary of it. Is it positively skewed or negatively.","metadata":{}},{"cell_type":"code","source":"plot(houses, \"SalePrice\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pivotal Features","metadata":{}},{"cell_type":"code","source":"plot_correlation(houses, \"OverallQual\", \"SalePrice\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot(houses, \"OverallQual\", \"SalePrice\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot(houses, \"GarageCars\", \"SalePrice\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot(houses, \"Fireplaces\", \"SalePrice\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot(houses, \"GrLivArea\", \"SalePrice\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot(houses, \"TotalBsmtSF\", \"SalePrice\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot(houses, \"YearBuilt\", \"SalePrice\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# In summary\nBased on the above analysis, we can conclude that:\n\n‘GrLivArea’ and ‘TotalBsmtSF’ seem to be linearly related with ‘SalePrice’. Both relationships are positive, which means that as one variable increases, the other also increases. In the case of ‘TotalBsmtSF’, we can see that the slope of the linear relationship is particularly high. ‘OverallQual’ and ‘YearBuilt’ also seem to be related with ‘SalePrice’. The relationship seems to be stronger in the case of ‘OverallQual’, where the box plot shows how sales prices increase with the overall quality. We just analysed four variables, but there are many other that we should analyse. The trick here seems to be the choice of the right features (feature selection) and not the definition of complex relationships between them (feature engineering).\n\nThat said, let’s separate the wheat from the chaff.","metadata":{}},{"cell_type":"markdown","source":"# Missing Value Imputation\nMissing values in the training data set can affect prediction or classification of a model negatively.\n\nAlso some machine learning algorithms can’t accept missing data eg. SVM, Neural Network.\n\nBut filling missing values with mean/median/mode or using another predictive model to predict missing values is also a prediction which may not be 100% accurate, instead you can use models like Decision Trees and Random Forest which handle missing values very well.","metadata":{}},{"cell_type":"code","source":"plot_missing(houses)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"basement_cols=['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','BsmtFinSF1','BsmtFinSF2']\nhouses[basement_cols][houses['BsmtQual'].isnull()==True].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All categorical variables contains NAN whereas continuous ones have 0. So that means there is no basement for those houses. we can replace it with ‘None’.","metadata":{}},{"cell_type":"code","source":"for col in basement_cols:\n    if 'FinSF'not in col:\n        houses[col] = houses[col].fillna('None')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"houses[\"FireplaceQu\"] = houses[\"FireplaceQu\"].fillna('None')\npd.crosstab(houses.Fireplaces, houses.FireplaceQu)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"garage_cols=['GarageType','GarageQual','GarageCond','GarageYrBlt','GarageFinish','GarageCars','GarageArea']\nhouses[garage_cols][houses['GarageType'].isnull()==True].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All garage related features are missing values in same rows. that means we can replace categorical variables with None and continuous ones with 0.","metadata":{}},{"cell_type":"code","source":"for col in garage_cols:\n    if houses[col].dtype==np.object:\n        houses[col] = houses[col].fillna('None')\n    else:\n        houses[col] = houses[col].fillna(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from dataprep.eda import create_report\nreport = create_report(houses, title='My Report')\nreport","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}