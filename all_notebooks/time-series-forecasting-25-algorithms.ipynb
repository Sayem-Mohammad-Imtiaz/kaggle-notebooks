{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## *If found useful, please leave an Upvote* üëç","metadata":{}},{"cell_type":"code","source":"import os\nfrom IPython.display import Image\nImage(filename=\"../input/front-image/Statisical-cash-forecasting-methods-1.png\", width= 1200, height=800)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T16:27:08.537828Z","iopub.execute_input":"2021-05-27T16:27:08.538139Z","iopub.status.idle":"2021-05-27T16:27:08.562383Z","shell.execute_reply.started":"2021-05-27T16:27:08.53811Z","shell.execute_reply":"2021-05-27T16:27:08.561614Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom datetime import datetime, timedelta\nfrom tqdm import tqdm \n \n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-27T16:12:35.177221Z","iopub.execute_input":"2021-05-27T16:12:35.177513Z","iopub.status.idle":"2021-05-27T16:12:35.20097Z","shell.execute_reply.started":"2021-05-27T16:12:35.177441Z","shell.execute_reply":"2021-05-27T16:12:35.200071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Install PyCaret","metadata":{}},{"cell_type":"code","source":"# PyCaret might not be installed. Below commands would install PyCaret and import necessary regression models\n!pip install pycaret\nfrom pycaret.regression import *","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:22:30.302386Z","iopub.execute_input":"2021-05-27T11:22:30.302711Z","iopub.status.idle":"2021-05-27T11:23:26.018211Z","shell.execute_reply.started":"2021-05-27T11:22:30.302681Z","shell.execute_reply":"2021-05-27T11:23:26.017234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read Data\ndata = pd.read_csv('/kaggle/input/retail-analysis-with-walmart-data/Walmart_Store_sales.csv')","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:23:53.696842Z","iopub.execute_input":"2021-05-27T11:23:53.697164Z","iopub.status.idle":"2021-05-27T11:23:53.73386Z","shell.execute_reply.started":"2021-05-27T11:23:53.697133Z","shell.execute_reply":"2021-05-27T11:23:53.73309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Properties\ndata.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:23:54.46802Z","iopub.execute_input":"2021-05-27T11:23:54.46836Z","iopub.status.idle":"2021-05-27T11:23:54.484535Z","shell.execute_reply.started":"2021-05-27T11:23:54.468327Z","shell.execute_reply":"2021-05-27T11:23:54.483582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:23:55.771769Z","iopub.execute_input":"2021-05-27T11:23:55.772111Z","iopub.status.idle":"2021-05-27T11:23:55.777839Z","shell.execute_reply.started":"2021-05-27T11:23:55.772079Z","shell.execute_reply":"2021-05-27T11:23:55.776953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:23:56.292589Z","iopub.execute_input":"2021-05-27T11:23:56.292924Z","iopub.status.idle":"2021-05-27T11:23:56.305088Z","shell.execute_reply.started":"2021-05-27T11:23:56.292895Z","shell.execute_reply":"2021-05-27T11:23:56.304341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting all columns to Upper Case \ndata.columns = [_c.upper() for _c in data.columns]","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:23:57.601017Z","iopub.execute_input":"2021-05-27T11:23:57.601353Z","iopub.status.idle":"2021-05-27T11:23:57.605653Z","shell.execute_reply.started":"2021-05-27T11:23:57.601323Z","shell.execute_reply":"2021-05-27T11:23:57.604753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting datatype of Date to DateTime and creating a month column\ndata['DATE'] = pd.to_datetime(data['DATE'])\ndata.loc[:,'MONTH'] = data['DATE'].dt.month\n","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:23:58.236902Z","iopub.execute_input":"2021-05-27T11:23:58.237225Z","iopub.status.idle":"2021-05-27T11:23:58.251202Z","shell.execute_reply.started":"2021-05-27T11:23:58.237196Z","shell.execute_reply":"2021-05-27T11:23:58.250151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:23:59.555123Z","iopub.execute_input":"2021-05-27T11:23:59.555482Z","iopub.status.idle":"2021-05-27T11:23:59.575716Z","shell.execute_reply.started":"2021-05-27T11:23:59.55545Z","shell.execute_reply":"2021-05-27T11:23:59.575056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Creating train and test data dictionaries","metadata":{}},{"cell_type":"code","source":"train_dict = {}\ntest_dict = {}\n\nunique_stores = list(data['STORE'].unique())\n\nfor i in unique_stores:\n    train_dict[i] = data.loc[data['STORE'] == i].copy()\n    train_dict[i].sort_values(by = 'DATE', inplace = True)\n    train_dict[i].reset_index(inplace = True, drop = True)\n    test_dict[i] = train_dict[i].iloc[-6:,:].copy()\n    train_dict[i] = train_dict[i].iloc[0:len(train_dict[i])-6,:]\n    test_dict[i].reset_index(inplace = True, drop = True)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:24:01.011596Z","iopub.execute_input":"2021-05-27T11:24:01.011921Z","iopub.status.idle":"2021-05-27T11:24:01.089116Z","shell.execute_reply.started":"2021-05-27T11:24:01.011891Z","shell.execute_reply":"2021-05-27T11:24:01.088365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Setup PyCaret and Run Multiple Regression Models for each Store","metadata":{}},{"cell_type":"code","source":"# Executing PyCaret and Saving the output\noutput_dict = {}\nall_results = []\nfinal_model = {}\nfor i in tqdm(unique_stores):\n    \n    df_subset = train_dict[i]\n    \n    # initialize setup from pycaret.regression\n    s = setup(df_subset, target = 'WEEKLY_SALES', train_size = 0.95,\n              data_split_shuffle = False, fold_strategy = 'timeseries', fold = 3,\n              ignore_features = ['DATE', 'STORE'],\n              numeric_features = ['TEMPERATURE', 'FUEL_PRICE', 'CPI', 'UNEMPLOYMENT'],\n              categorical_features = ['MONTH', 'HOLIDAY_FLAG'],\n              silent = True, verbose = False, session_id = 123)\n    \n    # compare all models and select best one based on MAE\n    best_model = compare_models(sort = 'MAE', verbose=False)\n    \n    # capture the compare result grid and store best model in list\n    p = pull().iloc[0:1]\n    p['time_series'] = str(i)\n    all_results.append(p)\n    \n    # finalize model i.e. fit on entire data including test set\n    f = finalize_model(best_model)\n    \n    # attach final model to a dictionary\n    final_model[i] = f\n    \n    # Predict\n    score_df = test_dict[i].drop('WEEKLY_SALES', axis = 1)\n    p = predict_model(f, data=score_df)\n    test_dict[i].loc[:,'FORECASTED_SALES'] = p['Label']","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:25:18.182946Z","iopub.execute_input":"2021-05-27T11:25:18.183282Z","iopub.status.idle":"2021-05-27T11:34:29.474435Z","shell.execute_reply.started":"2021-05-27T11:25:18.183238Z","shell.execute_reply":"2021-05-27T11:34:29.473458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Check Different best performing models for each store","metadata":{}},{"cell_type":"code","source":"# Checking Models used for Each Store \nconcat_results = pd.concat(all_results,axis=0)\nconcat_results","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:37:28.816987Z","iopub.execute_input":"2021-05-27T11:37:28.817368Z","iopub.status.idle":"2021-05-27T11:37:28.882723Z","shell.execute_reply.started":"2021-05-27T11:37:28.817335Z","shell.execute_reply":"2021-05-27T11:37:28.880337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Plotting","metadata":{}},{"cell_type":"code","source":"# Plotting Result of any Store 17 randomly\nimport plotly.express as px\ndf = test_dict[17][['DATE', 'WEEKLY_SALES', 'FORECASTED_SALES']]\nfig = px.line(df, x=\"DATE\", y=df.columns,\n              title='Weekly Sales')\nfig.update_xaxes(\n    dtick=\"M1\",\n    tickformat=\"%b\\n%Y\")\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T11:44:39.709022Z","iopub.execute_input":"2021-05-27T11:44:39.709354Z","iopub.status.idle":"2021-05-27T11:44:39.78329Z","shell.execute_reply.started":"2021-05-27T11:44:39.709322Z","shell.execute_reply":"2021-05-27T11:44:39.7824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### This could be used as a baseline model to further check for trend, seasonality in the data and account for it","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}