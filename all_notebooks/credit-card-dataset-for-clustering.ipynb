{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Introduction: Business Goal & Problem Definition\n\nIF YOU LIKE IT OR IF IT HELPS YOU SOMEHOW, COULD YOU PLEASE UPVOTE? THANK YOU VERY MUCH!!!\n\nThe goal of this project is to identify, study and analyze credit card holder´s clusters, so the business can have a better understanding of its customers segmentations and adapt different marketing strategies to each of them, increasing its revenue and market share. For that we´ll use the Credit Card Dataset for Clustering dataset available in Kaggle, containing 9000 active credit card holders. Each customer has the following attributes:\n\n* CUSTID : Identification of Credit Card holder (Categorical)\n* BALANCE : Balance amount left in their account to make purchases (\n* BALANCEFREQUENCY : How frequently the Balance is updated, score between 0 and 1 (1 = frequently updated, 0 = not frequently updated)\n* PURCHASES : Amount of purchases made from account\n* ONEOFFPURCHASES : Maximum purchase amount done in one-go\n* INSTALLMENTSPURCHASES : Amount of purchase done in installment\n* CASHADVANCE : Cash in advance given by the user\n* PURCHASESFREQUENCY : How frequently the Purchases are being made, score between 0 and 1 (1 = frequently purchased, 0 = not frequently purchased)\n* ONEOFFPURCHASESFREQUENCY : How frequently Purchases are happening in one-go (1 = frequently purchased, 0 = not frequently purchased)\n* PURCHASESINSTALLMENTSFREQUENCY : How frequently purchases in installments are being done (1 = frequently done, 0 = not frequently done)\n* CASHADVANCEFREQUENCY : How frequently the cash in advance being paid\n* CASHADVANCETRX : Number of Transactions made with \"Cash in Advanced\"\n* PURCHASESTRX : Numbe of purchase transactions made\n* CREDITLIMIT : Limit of Credit Card for user\n* PAYMENTS : Amount of Payment done by user\n* MINIMUM_PAYMENTS : Minimum amount of payments made by user\n* PRCFULLPAYMENT : Percent of full payment paid by user\n* TENURE : Tenure of credit card service for user"},{"metadata":{},"cell_type":"markdown","source":"# 2. Importing Basic Libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import io\nimport openpyxl\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Data Collection"},{"metadata":{"trusted":true},"cell_type":"code","source":"cc_ds = pd.read_csv('../input/ccdata/CC GENERAL.csv', encoding='latin1', sep=\",\")\n\ncc_ds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Data Preliminary Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking a dataset sample\n\npd.set_option(\"display.max_rows\", 100)\npd.set_option(\"display.max_columns\", 100)\npd.options.display.float_format=\"{:,.2f}\".format\ncc_ds.sample(n=10, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking dataset info by feature\n\ncc_ds.info(verbose=True, null_counts=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the existence of zeros in rows\n\n(cc_ds==0).sum(axis=0).to_excel(\"zeros_per_feature.xlsx\")\n(cc_ds==0).sum(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the existence of duplicated rows\n\ncc_ds.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking basic statistical data by feature\n\ncc_ds.describe(include=\"all\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Data Cleaning\n\n    We´ll perform the following:\n    \n    \n    1. Treat missing values:\n        1.1 CREDIT_LIMIT: replace by mean\n        2.2 MINIMUM_PAYMENTS: replace by mean\n        \n    \n    2. Remove outliers:\n        2.1 PURCHASES: 49039.57 (index 550): replace by mean\n        2.2 INSTALLMENTS_PURCHASES 22500 (index 5260): replace by mean\n        2.3 CASH_ADVANCE 47137.21176 (index 2159): replace by mean\n        2.4 MINIMUM_PAYMENTS: 76406.20752 (index 4376): replace by mean"},{"metadata":{"trusted":true},"cell_type":"code","source":"#1\n\ncc_ds[\"CREDIT_LIMIT\"].fillna(cc_ds[\"CREDIT_LIMIT\"].mean(), inplace=True)\ncc_ds[\"MINIMUM_PAYMENTS\"].fillna(cc_ds[\"MINIMUM_PAYMENTS\"].mean(), inplace=True)\n\n#2\n\ncc_ds.loc[550, \"PURCHASES\"] = cc_ds[\"PURCHASES\"].mean()\ncc_ds.loc[5260, \"INSTALLMENTS_PURCHASES\"] = cc_ds[\"INSTALLMENTS_PURCHASES\"].mean()\ncc_ds.loc[2159, \"CASH_ADVANCE\"] = cc_ds[\"CASH_ADVANCE\"].mean()\ncc_ds.loc[4376, \"MINIMUM_PAYMENTS\"] = cc_ds[\"MINIMUM_PAYMENTS\"].mean()\n\ncc_ds.to_excel(\"cc_ds_clean.xlsx\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Data Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting Numerical Variables\n\nfig, ax = plt.subplots(1, 3)\nfig.suptitle(\"BALANCE Distribution\", fontsize=15)\nsns.distplot(cc_ds[\"BALANCE\"], ax=ax[0])\nsns.boxplot(cc_ds[\"BALANCE\"], ax=ax[1])\nsns.violinplot(cc_ds[\"BALANCE\"], ax=ax[2])\n\nfig, ax = plt.subplots(1, 3)\nfig.suptitle(\"BALANCE_FREQUENCY Distribution\", fontsize=15)\nsns.distplot(cc_ds[\"BALANCE_FREQUENCY\"], ax=ax[0])\nsns.boxplot(cc_ds[\"BALANCE_FREQUENCY\"], ax=ax[1])\nsns.violinplot(cc_ds[\"BALANCE_FREQUENCY\"], ax=ax[2])\n\nfig, ax = plt.subplots(1, 3)\nfig.suptitle(\"PURCHASES Distribution\", fontsize=15)\nsns.distplot(cc_ds[\"PURCHASES\"], ax=ax[0])\nsns.boxplot(cc_ds[\"PURCHASES\"], ax=ax[1])\nsns.violinplot(cc_ds[\"PURCHASES\"], ax=ax[2])\n\nfig, ax = plt.subplots(1, 3)\nfig.suptitle(\"ONEOFF_PURCHASES Distribution\", fontsize=15)\nsns.distplot(cc_ds[\"ONEOFF_PURCHASES\"], ax=ax[0])\nsns.boxplot(cc_ds[\"ONEOFF_PURCHASES\"], ax=ax[1])\nsns.violinplot(cc_ds[\"ONEOFF_PURCHASES\"], ax=ax[2])\n\nfig, ax = plt.subplots(1, 3)\nfig.suptitle(\"INSTALLMENTS_PURCHASES Distribution\", fontsize=15)\nsns.distplot(cc_ds[\"INSTALLMENTS_PURCHASES\"], ax=ax[0])\nsns.boxplot(cc_ds[\"INSTALLMENTS_PURCHASES\"], ax=ax[1])\nsns.violinplot(cc_ds[\"INSTALLMENTS_PURCHASES\"], ax=ax[2])\n\nfig, ax = plt.subplots(1, 3)\nfig.suptitle(\"CASH_ADVANCE Distribution\", fontsize=15)\nsns.distplot(cc_ds[\"CASH_ADVANCE\"], ax=ax[0])\nsns.boxplot(cc_ds[\"CASH_ADVANCE\"], ax=ax[1])\nsns.violinplot(cc_ds[\"CASH_ADVANCE\"], ax=ax[2])\n\nfig, ax = plt.subplots(1, 3)\nfig.suptitle(\"PURCHASES_FREQUENCY Distribution\", fontsize=15)\nsns.distplot(cc_ds[\"PURCHASES_FREQUENCY\"], ax=ax[0])\nsns.boxplot(cc_ds[\"PURCHASES_FREQUENCY\"], ax=ax[1])\nsns.violinplot(cc_ds[\"PURCHASES_FREQUENCY\"], ax=ax[2])\n\nfig, ax = plt.subplots(1, 3)\nfig.suptitle(\"ONEOFF_PURCHASES_FREQUENCY Distribution\", fontsize=15)\nsns.distplot(cc_ds[\"ONEOFF_PURCHASES_FREQUENCY\"], ax=ax[0])\nsns.boxplot(cc_ds[\"ONEOFF_PURCHASES_FREQUENCY\"], ax=ax[1])\nsns.violinplot(cc_ds[\"ONEOFF_PURCHASES_FREQUENCY\"], ax=ax[2])\n\nfig, ax = plt.subplots(1, 3)\nfig.suptitle(\"PURCHASES_INSTALLMENTS_FREQUENCY Distribution\", fontsize=15)\nsns.distplot(cc_ds[\"PURCHASES_INSTALLMENTS_FREQUENCY\"], ax=ax[0])\nsns.boxplot(cc_ds[\"PURCHASES_INSTALLMENTS_FREQUENCY\"], ax=ax[1])\nsns.violinplot(cc_ds[\"PURCHASES_INSTALLMENTS_FREQUENCY\"], ax=ax[2])\n\nfig, ax = plt.subplots(1, 3)\nfig.suptitle(\"CASH_ADVANCE_FREQUENCY Distribution\", fontsize=15)\nsns.distplot(cc_ds[\"CASH_ADVANCE_FREQUENCY\"], ax=ax[0])\nsns.boxplot(cc_ds[\"CASH_ADVANCE_FREQUENCY\"], ax=ax[1])\nsns.violinplot(cc_ds[\"CASH_ADVANCE_FREQUENCY\"], ax=ax[2])\n\nfig, ax = plt.subplots(1, 3)\nfig.suptitle(\"CASH_ADVANCE_TRX Distribution\", fontsize=15)\nsns.distplot(cc_ds[\"CASH_ADVANCE_TRX\"], ax=ax[0])\nsns.boxplot(cc_ds[\"CASH_ADVANCE_TRX\"], ax=ax[1])\nsns.violinplot(cc_ds[\"CASH_ADVANCE_TRX\"], ax=ax[2])\n\nfig, ax = plt.subplots(1, 3)\nfig.suptitle(\"PURCHASES_TRX Distribution\", fontsize=15)\nsns.distplot(cc_ds[\"PURCHASES_TRX\"], ax=ax[0])\nsns.boxplot(cc_ds[\"PURCHASES_TRX\"], ax=ax[1])\nsns.violinplot(cc_ds[\"PURCHASES_TRX\"], ax=ax[2])\n\nfig, ax = plt.subplots(1, 3)\nfig.suptitle(\"CREDIT_LIMIT Distribution\", fontsize=15)\nsns.distplot(cc_ds[\"CREDIT_LIMIT\"], ax=ax[0])\nsns.boxplot(cc_ds[\"CREDIT_LIMIT\"], ax=ax[1])\nsns.violinplot(cc_ds[\"CREDIT_LIMIT\"], ax=ax[2])\n\nfig, ax = plt.subplots(1, 3)\nfig.suptitle(\"PAYMENTS Distribution\", fontsize=15)\nsns.distplot(cc_ds[\"PAYMENTS\"], ax=ax[0])\nsns.boxplot(cc_ds[\"PAYMENTS\"], ax=ax[1])\nsns.violinplot(cc_ds[\"PAYMENTS\"], ax=ax[2])\n\nfig, ax = plt.subplots(1, 3)\nfig.suptitle(\"MINIMUM_PAYMENTS Distribution\", fontsize=15)\nsns.distplot(cc_ds[\"MINIMUM_PAYMENTS\"], ax=ax[0])\nsns.boxplot(cc_ds[\"MINIMUM_PAYMENTS\"], ax=ax[1])\nsns.violinplot(cc_ds[\"MINIMUM_PAYMENTS\"], ax=ax[2])\n\nfig, ax = plt.subplots(1, 3)\nfig.suptitle(\"PRC_FULL_PAYMENT Distribution\", fontsize=15)\nsns.distplot(cc_ds[\"PRC_FULL_PAYMENT\"], ax=ax[0])\nsns.boxplot(cc_ds[\"PRC_FULL_PAYMENT\"], ax=ax[1])\nsns.violinplot(cc_ds[\"PRC_FULL_PAYMENT\"], ax=ax[2])\n\n# fig, ax = plt.subplots(1, 3)\n# fig.suptitle(\"TENURE Distribution\", fontsize=15)\n# sns.distplot(cc_ds[\"TENURE\"], ax=ax[0])\n# sns.boxplot(cc_ds[\"TENURE\"], ax=ax[1])\n# sns.violinplot(cc_ds[\"TENURE\"], ax=ax[2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Correlations Analysis & Features Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Deleting not relevant and original categorical columns\n\ncc_ds2 = cc_ds.drop([\"CUST_ID\"], axis=1)\n\n# #Plotting a Heatmap\n\n# fig, ax = plt.subplots(1, figsize=(25,25))\n# sns.heatmap(cc_ds2.corr(), annot=True, fmt=\",.2f\")\n# plt.title(\"Heatmap Correlation\", fontsize=20)\n# plt.tick_params(labelsize=12)\n# plt.xticks(rotation=90)\n# plt.yticks(rotation=45)\n\n# #Plotting a Pairplot\n\n# sns.pairplot(cc_ds2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 8. Data Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining Xs\n\nX_orig = cc_ds\nX = cc_ds2\n\n#Scaling all features\n\nfrom sklearn.preprocessing import MinMaxScaler\nsc_X = MinMaxScaler()\nX_scaled = sc_X.fit_transform(X)\nX_scaled = pd.DataFrame(X_scaled)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 9. Machine Learning Algorithms Implementation & Assessment"},{"metadata":{},"cell_type":"markdown","source":"# 9.1.1 K-means"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a K-means model and checking its Metrics\n\nfrom sklearn.cluster import KMeans\n\n#Applying the Elbow Method to calculate distortion for a range of number of cluster\n\ndistortions = []\nfor i in range(1, 21):\n    km = KMeans(n_clusters=i, init=\"random\", n_init=10, max_iter=300, tol=1e-04, random_state=0)\n    km.fit(X_scaled)\n    distortions.append(km.inertia_)\n\n#Plotting\n\nplt.plot(range(1, 21), distortions, marker=\"o\")\nplt.xlabel(\"Number of clusters\")\nplt.ylabel(\"Distortion\")\nplt.show()\n\n#Applying the Silhouette Method to interpret and validate of consistency within clusters of data\n\nfrom sklearn.metrics import silhouette_score\nsilhouette_coefficients = []\nfor j in range(2, 21):\n    km = KMeans(n_clusters=j, init=\"random\", n_init=10, max_iter=300, tol=1e-04, random_state=0)\n    km.fit(X_scaled)\n    score = silhouette_score(X_scaled, km.labels_)\n    silhouette_coefficients.append(score)\n\n#Plotting\n\nplt.style.use(\"fivethirtyeight\")\nplt.plot(range(2, 21), silhouette_coefficients)\nplt.xticks(range(2, 21))\nplt.xlabel(\"Number of Clusters\")\nplt.ylabel(\"Silhouette Coefficient\")\nplt.show()\n\n#Choosing number of clusters\n\nn_clusters = 2\nprint('Estimated number of clusters: %d' % n_clusters)\nkm = KMeans(n_clusters=n_clusters)\nkm.fit(X_scaled)\nprint(\"Silhouette Coefficient: %0.3f\" % silhouette_score(X_scaled, km.fit(X_scaled).labels_))\n\n#Plotting chosen number of clusters\n\nfrom yellowbrick.cluster import silhouette_visualizer\nsilhouette_visualizer(KMeans(n_clusters=n_clusters, random_state=0), X_scaled)\n\n#Visualizing clusters in the dataset\nX_orig = pd.DataFrame(X_orig)\nX_orig[\"cluster\"] = km.labels_\nX_orig.to_excel(\"model_km.xlsx\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 9.1.2 Clusters exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Cluster 0\")\nX_orig.query(\"cluster == 0\").describe(include=\"all\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Cluster 1\")\nX_orig.query(\"cluster == 1\").describe(include=\"all\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting Numerical Variables\n\nfig, ax = plt.subplots(1, len(X_orig[\"cluster\"].unique()))\nfig.suptitle(\"BALANCE Distribution\", fontsize=15)\nsns.distplot(X_orig.query(\"cluster == 0\")[\"BALANCE\"], label = \"Cluster 0\", ax=ax[0])\nsns.distplot(X_orig.query(\"cluster == 1\")[\"BALANCE\"], label = \"Cluster 1\", ax=ax[1])\n\nfig, ax = plt.subplots(1, len(X_orig[\"cluster\"].unique()))\nfig.suptitle(\"BALANCE_FREQUENCY Distribution\", fontsize=15)\n# sns.distplot(X_orig.query(\"cluster == 0\")[\"BALANCE_FREQUENCY\"], label = \"Cluster 0\", ax=ax[0])\n# sns.distplot(X_orig.query(\"cluster == 1\")[\"BALANCE_FREQUENCY\"], label = \"Cluster 1\", ax=ax[1])\n\nfig, ax = plt.subplots(1, len(X_orig[\"cluster\"].unique()))\nfig.suptitle(\"PURCHASES Distribution\", fontsize=15)\nsns.distplot(X_orig.query(\"cluster == 0\")[\"PURCHASES\"], label = \"Cluster 0\", ax=ax[0])\nsns.distplot(X_orig.query(\"cluster == 1\")[\"PURCHASES\"], label = \"Cluster 1\", ax=ax[1])\n\nfig, ax = plt.subplots(1, len(X_orig[\"cluster\"].unique()))\nfig.suptitle(\"ONEOFF_PURCHASES Distribution\", fontsize=15)\nsns.distplot(X_orig.query(\"cluster == 0\")[\"ONEOFF_PURCHASES\"], label = \"Cluster 0\", ax=ax[0])\nsns.distplot(X_orig.query(\"cluster == 1\")[\"ONEOFF_PURCHASES\"], label = \"Cluster 1\", ax=ax[1])\n\nfig, ax = plt.subplots(1, len(X_orig[\"cluster\"].unique()))\nfig.suptitle(\"INSTALLMENTS_PURCHASES Distribution\", fontsize=15)\nsns.distplot(X_orig.query(\"cluster == 0\")[\"INSTALLMENTS_PURCHASES\"], label = \"Cluster 0\", ax=ax[0])\nsns.distplot(X_orig.query(\"cluster == 1\")[\"INSTALLMENTS_PURCHASES\"], label = \"Cluster 1\", ax=ax[1])\n\nfig, ax = plt.subplots(1, len(X_orig[\"cluster\"].unique()))\nfig.suptitle(\"CASH_ADVANCE Distribution\", fontsize=15)\nsns.distplot(X_orig.query(\"cluster == 0\")[\"CASH_ADVANCE\"], label = \"Cluster 0\", ax=ax[0])\nsns.distplot(X_orig.query(\"cluster == 1\")[\"CASH_ADVANCE\"], label = \"Cluster 1\", ax=ax[1])\n\nfig, ax = plt.subplots(1, len(X_orig[\"cluster\"].unique()))\nfig.suptitle(\"PURCHASES_FREQUENCY Distribution\", fontsize=15)\nsns.distplot(X_orig.query(\"cluster == 0\")[\"PURCHASES_FREQUENCY\"], label = \"Cluster 0\", ax=ax[0])\nsns.distplot(X_orig.query(\"cluster == 1\")[\"PURCHASES_FREQUENCY\"], label = \"Cluster 1\", ax=ax[1])\n\nfig, ax = plt.subplots(1, len(X_orig[\"cluster\"].unique()))\nfig.suptitle(\"ONEOFF_PURCHASES_FREQUENCY Distribution\", fontsize=15)\nsns.distplot(X_orig.query(\"cluster == 0\")[\"ONEOFF_PURCHASES_FREQUENCY\"], label = \"Cluster 0\", ax=ax[0])\nsns.distplot(X_orig.query(\"cluster == 1\")[\"ONEOFF_PURCHASES_FREQUENCY\"], label = \"Cluster 1\", ax=ax[1])\n\nfig, ax = plt.subplots(1, len(X_orig[\"cluster\"].unique()))\nfig.suptitle(\"PURCHASES_INSTALLMENTS_FREQUENCY Distribution\", fontsize=15)\nsns.distplot(X_orig.query(\"cluster == 0\")[\"PURCHASES_INSTALLMENTS_FREQUENCY\"], label = \"Cluster 0\", ax=ax[0])\nsns.distplot(X_orig.query(\"cluster == 1\")[\"PURCHASES_INSTALLMENTS_FREQUENCY\"], label = \"Cluster 1\", ax=ax[1])\n\nfig, ax = plt.subplots(1, len(X_orig[\"cluster\"].unique()))\nfig.suptitle(\"CASH_ADVANCE_FREQUENCY Distribution\", fontsize=15)\nsns.distplot(X_orig.query(\"cluster == 0\")[\"CASH_ADVANCE_FREQUENCY\"], label = \"Cluster 0\", ax=ax[0])\nsns.distplot(X_orig.query(\"cluster == 1\")[\"CASH_ADVANCE_FREQUENCY\"], label = \"Cluster 1\", ax=ax[1])\n\nfig, ax = plt.subplots(1, len(X_orig[\"cluster\"].unique()))\nfig.suptitle(\"CASH_ADVANCE_TRX Distribution\", fontsize=15)\nsns.distplot(X_orig.query(\"cluster == 0\")[\"CASH_ADVANCE_TRX\"], label = \"Cluster 0\", ax=ax[0])\nsns.distplot(X_orig.query(\"cluster == 1\")[\"CASH_ADVANCE_TRX\"], label = \"Cluster 1\", ax=ax[1])\n\nfig, ax = plt.subplots(1, len(X_orig[\"cluster\"].unique()))\nfig.suptitle(\"PURCHASES_TRX Distribution\", fontsize=15)\nsns.distplot(X_orig.query(\"cluster == 0\")[\"PURCHASES_TRX\"], label = \"Cluster 0\", ax=ax[0])\nsns.distplot(X_orig.query(\"cluster == 1\")[\"PURCHASES_TRX\"], label = \"Cluster 1\", ax=ax[1])\n\nfig, ax = plt.subplots(1, len(X_orig[\"cluster\"].unique()))\nfig.suptitle(\"CREDIT_LIMIT Distribution\", fontsize=15)\nsns.distplot(X_orig.query(\"cluster == 0\")[\"CREDIT_LIMIT\"], label = \"Cluster 0\", ax=ax[0])\nsns.distplot(X_orig.query(\"cluster == 1\")[\"CREDIT_LIMIT\"], label = \"Cluster 1\", ax=ax[1])\n\nfig, ax = plt.subplots(1, len(X_orig[\"cluster\"].unique()))\nfig.suptitle(\"PAYMENTS Distribution\", fontsize=15)\nsns.distplot(X_orig.query(\"cluster == 0\")[\"PAYMENTS\"], label = \"Cluster 0\", ax=ax[0])\nsns.distplot(X_orig.query(\"cluster == 1\")[\"PAYMENTS\"], label = \"Cluster 1\", ax=ax[1])\n\nfig, ax = plt.subplots(1, len(X_orig[\"cluster\"].unique()))\nfig.suptitle(\"MINIMUM_PAYMENTS Distribution\", fontsize=15)\nsns.distplot(X_orig.query(\"cluster == 0\")[\"MINIMUM_PAYMENTS\"], label = \"Cluster 0\", ax=ax[0])\nsns.distplot(X_orig.query(\"cluster == 1\")[\"MINIMUM_PAYMENTS\"], label = \"Cluster 1\", ax=ax[1])\n\nfig, ax = plt.subplots(1, len(X_orig[\"cluster\"].unique()))\nfig.suptitle(\"PRC_FULL_PAYMENT Distribution\", fontsize=15)\n# sns.distplot(X_orig.query(\"cluster == 0\")[\"PRC_FULL_PAYMENT\"], label = \"Cluster 0\", ax=ax[0])\nsns.distplot(X_orig.query(\"cluster == 1\")[\"PRC_FULL_PAYMENT\"], label = \"Cluster 1\", ax=ax[1])\n\nfig, ax = plt.subplots(1, len(X_orig[\"cluster\"].unique()))\nfig.suptitle(\"TENURE Distribution\", fontsize=15)\n# sns.distplot(X_orig.query(\"cluster == 0\")[\"TENURE\"], label = \"Cluster 0\", ax=ax[0])\n# sns.distplot(X_orig.query(\"cluster == 1\")[\"TENURE\"], label = \"Cluster 1\", ax=ax[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #Plotting scatter graph per pair features\n\n# #Mapping every individual cluster to a color\n\n# colors = ['goldenrod', 'olive', 'navy']\n\n# vectorizer = np.vectorize(lambda x: colors[x % len(colors)])\n\n# #Plotting\n\n# for i in range(0, X_scaled.shape[1]):\n#     for j in range(1, X_scaled.shape[1]):\n#         plt.scatter(X_scaled.iloc[:,i], X_scaled.iloc[:,j])\n#         plt.xlabel(X.columns[i])\n#         plt.ylabel(X.columns[j])\n#         plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 9.2 DBSCAN"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a DBSCAN model and checking its Metrics\n#OBS: we´re exploring DBSCAN only as a study exercise in this project - we´ll adopt K-Means\n\nfrom sklearn.neighbors import NearestNeighbors\n\n#We can calculate the distance from each point to its closest neighbour using the NearestNeighbors. The point itself is included in n_neighbors. The kneighbors method returns two arrays, one which contains the distance to the closest n_neighbors points and the other which contains the index for each of those points\n\nneigh = NearestNeighbors(n_neighbors=2)\nnbrs = neigh.fit(X_scaled)\ndistances, indices = nbrs.kneighbors(X_scaled)\n\n#Soring and plotting results\n\ndistances = np.sort(distances, axis=0)\ndistances = distances[:,1]\nplt.plot(distances)\nplt.xlabel(\"Distances to the closest n_neighbors\")\nplt.ylabel(\"eps\")\nplt.show()\n\nfrom sklearn.cluster import DBSCAN\n\n#Selecting the best eps (the optimal value for epsilon will be found at the point of maximum curvature)\n\ndbs = DBSCAN(eps=0.3)\ndbs.fit(X_scaled)\n\n#The labels_ property contains the list of clusters and their respective points\n\nclusters = dbs.labels_\n\nfrom sklearn import metrics\n\n#Number of clusters in labels, ignoring noise (outlier) (-1) if present\n\nn_clusters = len(set(clusters)) - (1 if -1 in clusters else 0)\nn_noise_ = list(clusters).count(-1)\nprint('Estimated number of clusters: %d' % n_clusters)\nprint('Estimated number of noise points: %d' % n_noise_)\nprint(\"Silhouette Coefficient: %0.3f\" % metrics.silhouette_score(X_scaled, clusters))\n\n#Visualizing clusters in the dataset\nX_orig = pd.DataFrame(X_orig)\nX_orig[\"cluster\"] = dbs.labels_\nX_orig.to_excel(\"model_dbs.xlsx\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 10. Conclusions\n\nIF YOU LIKE IT OR IF IT HELPS YOU SOMEHOW, COULD YOU PLEASE UPVOTE? THANK YOU VERY MUCH!!!\n\nIn this exercise we went through all the process from collecting data, exploring features and distributions, treating data, understanding correlations, selecting relevant features, data modelling and presenting a clustering model, indicating groups of customers with similarities to explored, as explained below, so the credit card company can have a better understanding of its customers segmentations and adapt different marketing strategies to each of them, bringing more revenue and market share to the business.\n\nFirst group of clients: the first group is composed by the more conservative customers. Those customers, when compared to the second group, have a 20% higher Balance, 82% lower purchases amount, 74% lower one off purchase amount and 93% lower installment purchase. At the same time, they have a 138% higher cash in advance. Those clients, although represent the minority, need to be kept, as they´re good payers and have their finances under control, but also they have the potential to grow when the right products are offered to them.\n\nSecond group of clients: the second group represents 85% of the purchases, and unlike the first group, although they have a lower balance, they have much higher purchases rates and lower cash in advance given. This group is more dynamic, has a more inconstant behavior, is the core for the business and can be constantly incentivized on new products, having the caution on their payment capacity."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}