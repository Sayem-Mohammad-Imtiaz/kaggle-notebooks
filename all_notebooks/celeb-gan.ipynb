{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tqdm import tqdm\nimport numpy as np\nimport pandas as pd\nimport os\nimport PIL.Image\nfrom matplotlib import pyplot as plt\nfrom keras import Input\nfrom keras.layers import Dense, Reshape, LeakyReLU, Conv2D, Conv2DTranspose, Flatten, Dropout\nfrom keras.models import Model\nfrom keras.optimizers import RMSprop\nfrom keras.utils.vis_utils import model_to_dot\n\n\nPIC_DIR = '../input/celeba-dataset/img_align_celeba/img_align_celeba/'\nIMAGES_COUNT = 10000\nORIG_WIDTH = 178\nORIG_HEIGHT = 208\ndiff = (ORIG_HEIGHT - ORIG_WIDTH) // 2\nWIDTH = 128\nHEIGHT = 128\ncrop_rect = (0, diff, ORIG_WIDTH, ORIG_HEIGHT - diff)\nimages = []\nfor pic_file in tqdm(os.listdir(PIC_DIR)[:IMAGES_COUNT]):\n    pic = PIL.Image.open(PIC_DIR + pic_file).crop(crop_rect)\n    pic.thumbnail((WIDTH, HEIGHT), PIL.Image.ANTIALIAS)\n    images.append(np.uint8(pic)) #Normalize the images\nimages = np.array(images) / 255\nimages.shape #print first 25 images\nplt.figure(1, figsize=(10, 10))\nfor i in range(25):\n    plt.subplot(5, 5, i+1)\n    plt.imshow(images[i])\n    plt.axis('off')\nplt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-23T10:41:03.934167Z","iopub.execute_input":"2021-07-23T10:41:03.935007Z","iopub.status.idle":"2021-07-23T10:41:36.244684Z","shell.execute_reply.started":"2021-07-23T10:41:03.934958Z","shell.execute_reply":"2021-07-23T10:41:36.243922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create generator\nLATENT_DIM = 32\nCHANNELS = 3\ndef create_generator():\n    gen_input = Input(shape=(LATENT_DIM, ))\n    \n    x = Dense(128 * 16 * 16)(gen_input)\n    x = LeakyReLU()(x)\n    x = Reshape((16, 16, 128))(x)\n    \n    x = Conv2D(256, 5, padding='same')(x)\n    x = LeakyReLU()(x)\n    \n    x = Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n    x = LeakyReLU()(x)\n    \n    x = Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n    x = LeakyReLU()(x)\n    \n    x = Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n    x = LeakyReLU()(x)\n    \n    x = Conv2D(512, 5, padding='same')(x)\n    x = LeakyReLU()(x)\n    x = Conv2D(512, 5, padding='same')(x)\n    x = LeakyReLU()(x)\n    x = Conv2D(CHANNELS, 7, activation='tanh', padding='same')(x)\n    \n    generator = Model(gen_input, x)\n    return generator","metadata":{"execution":{"iopub.status.busy":"2021-07-23T10:41:36.2461Z","iopub.execute_input":"2021-07-23T10:41:36.246513Z","iopub.status.idle":"2021-07-23T10:41:36.256842Z","shell.execute_reply.started":"2021-07-23T10:41:36.246481Z","shell.execute_reply":"2021-07-23T10:41:36.256072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create discriminator\ndef create_discriminator():\n    disc_input = Input(shape=(HEIGHT, WIDTH, CHANNELS))\n    \n    x = Conv2D(256, 3)(disc_input)\n    x = LeakyReLU()(x)\n    \n    x = Conv2D(256, 4, strides=2)(x)\n    x = LeakyReLU()(x)\n    \n    x = Conv2D(256, 4, strides=2)(x)\n    x = LeakyReLU()(x)\n    \n    x = Conv2D(256, 4, strides=2)(x)\n    x = LeakyReLU()(x)\n    \n    x = Conv2D(256, 4, strides=2)(x)\n    x = LeakyReLU()(x)\n    \n    x = Flatten()(x)\n    x = Dropout(0.4)(x)\n    \n    x = Dense(1, activation='sigmoid')(x)\n    discriminator = Model(disc_input, x)\n    \n    optimizer = RMSprop(\n        lr=.0001,\n        clipvalue=1.0,\n        decay=1e-8\n    )\n    \n    discriminator.compile(\n        optimizer=optimizer,\n        loss='binary_crossentropy'\n    )\n    \n    return discriminator","metadata":{"execution":{"iopub.status.busy":"2021-07-23T10:41:36.258358Z","iopub.execute_input":"2021-07-23T10:41:36.258952Z","iopub.status.idle":"2021-07-23T10:41:36.445665Z","shell.execute_reply.started":"2021-07-23T10:41:36.258763Z","shell.execute_reply":"2021-07-23T10:41:36.444678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = create_generator()\ndiscriminator = create_discriminator()\ndiscriminator.trainable = False\ngan_input = Input(shape=(LATENT_DIM, ))\ngan_output = discriminator(generator(gan_input))\ngan = Model(gan_input, gan_output)#Adversarial Model\noptimizer = RMSprop(lr=.0001, clipvalue=1.0, decay=1e-8)\ngan.compile(optimizer=optimizer, loss='binary_crossentropy')","metadata":{"execution":{"iopub.status.busy":"2021-07-23T10:41:36.447645Z","iopub.execute_input":"2021-07-23T10:41:36.448093Z","iopub.status.idle":"2021-07-23T10:41:36.674162Z","shell.execute_reply.started":"2021-07-23T10:41:36.448032Z","shell.execute_reply":"2021-07-23T10:41:36.673298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\niters = 10000\nbatch_size = 16\nRES_DIR = 'res2'\nFILE_PATH = '%s/generated_%d.png'\nif not os.path.isdir(RES_DIR):\n    os.mkdir(RES_DIR)\nCONTROL_SIZE_SQRT = 6\ncontrol_vectors = np.random.normal(size=(CONTROL_SIZE_SQRT**2, LATENT_DIM)) / 2\nstart = 0\nd_losses = []\na_losses = []\nimages_saved = 0\nfor step in range(iters):\n    start_time = time.time()\n    latent_vectors = np.random.normal(size=(batch_size, LATENT_DIM))\n    generated = generator.predict(latent_vectors)\n    \n    real = images[start:start + batch_size]\n    combined_images = np.concatenate([generated, real])\n    \n    labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n    labels += .05 * np.random.random(labels.shape)\n    \n    d_loss = discriminator.train_on_batch(combined_images, labels)\n    d_losses.append(d_loss)\n    \n    latent_vectors = np.random.normal(size=(batch_size, LATENT_DIM))\n    misleading_targets = np.zeros((batch_size, 1))\n    \n    a_loss = gan.train_on_batch(latent_vectors, misleading_targets)\n    a_losses.append(a_loss)\n    \n    start += batch_size\n    if start > images.shape[0] - batch_size:\n        start = 0\n    \n    if step % 50 == 49:\n        gan.save_weights('gan.h5')\n        \n        print('%d/%d: d_loss: %.4f,  a_loss: %.4f.  (%.1f sec)' % (step + 1, iters, d_loss, a_loss, time.time() - start_time))\n        \n        control_image = np.zeros((WIDTH * CONTROL_SIZE_SQRT, HEIGHT * CONTROL_SIZE_SQRT, CHANNELS))\n        control_generated = generator.predict(control_vectors)\n        for i in range(CONTROL_SIZE_SQRT ** 2):\n            x_off = i % CONTROL_SIZE_SQRT\n            y_off = i // CONTROL_SIZE_SQRT\n            control_image[x_off * WIDTH:(x_off + 1) * WIDTH, y_off * HEIGHT:(y_off + 1) * HEIGHT, :] = control_generated[i, :, :, :]\n        im = PIL.Image.fromarray(np.uint8(control_image * 255))\n        im.save(FILE_PATH % (RES_DIR, images_saved))\n        images_saved += 1","metadata":{"execution":{"iopub.status.busy":"2021-07-23T10:41:36.675416Z","iopub.execute_input":"2021-07-23T10:41:36.675906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(1, figsize=(12, 8))\nplt.subplot(121)\nplt.plot(d_losses, color='red')\nplt.xlabel('epochs')\nplt.ylabel('discriminant losses')\nplt.subplot(122)\nplt.plot(a_losses)\nplt.xlabel('epochs')\nplt.ylabel('adversary losses')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import imageio\nimport shutil\nimages_to_gif = []\nfor filename in os.listdir(RES_DIR):\n    images_to_gif.append(imageio.imread(RES_DIR + '/' + filename))\nimageio.mimsave('trainnig_visual.gif', images_to_gif)\nshutil.rmtree(RES_DIR)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}