{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os.path\nimport numpy as np\nimport cv2\nimport pickle\nimport sys\nimport os\nimport csv\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.layers.core import Flatten, Dense\nfrom PIL import Image\nimport pandas as pd\n\nimport seaborn as sns\nfrom keras.preprocessing.image import load_img, img_to_array\nimport matplotlib.pyplot as plt\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Useful function to read data files\ndef createFileList(Mydir, format='.jpg'):\n    i=0\n    fileList = []\n    for breed in os.listdir(Mydir) :\n        counts =len(os.listdir(Mydir + breed))\n        if counts >= 4000 and counts < 50000:\n            i+=1\n            for name in os.listdir(Mydir + breed):\n                if name.endswith(format):\n                    fullName = os.path.join(\"../input/cat-breeds-dataset/\" + \"images/\" , breed, name)\n                    #print(fullName)\n                    fileList.append(fullName)\n    return fileList, i\n\n\n# load the original image\nbreeds = (\"../input/cat-breeds-dataset/\" + \"images/\")\nmyFileList, i = createFileList(breeds)\nprint(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# initialize the data and labels\ndata   = []\nlabels = []\n\n# loop over the input images\nfor image_file in myFileList:\n\n    # Load the image\n    image = cv2.imread(image_file, cv2.IMREAD_UNCHANGED)\n   \n    # Resize the image so it fits in a 300x300 pixel box\n    dim = (300, 300)\n    image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n    \n    # Grab the name of the label based on the folder it was in\n    label = image_file.split(os.path.sep)[-2]\n    \n    # Add the  image and it's label to our training data\n    data.append(image)\n    labels.append(label)\n    \nprint(\"finished\")\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = np.array(data, dtype=\"float\") / 255.0\nlabels = np.array(labels)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.shape(data))\nprint(np.shape(labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Split the training data into separate train and test sets\n(X_train, X_test, Y_train, Y_test) = train_test_split(data, labels, test_size=0.25, random_state=0)\n\n# Convert the labels (letters) into one-hot encodings that Keras can work with\nlb = LabelBinarizer().fit(Y_train)\nY_train = lb.transform(Y_train)\nY_test = lb.transform(Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build the neural network!\nmodel = Sequential()\n\n# First convolutional layer with max pooling\nmodel.add(Conv2D(32, (5, 5), padding=\"same\", activation=\"relu\", \n                input_shape=(300,300,3)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n#Dropout to avoid overfitting\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n#Flatten output of conv\nmodel.add(Flatten())\n\n#Fully Connected layer\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\n\n# Output layer with 32 nodes (one for each possible letter/number we predict)\nmodel.add(Dense(4, activation=\"softmax\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ask Keras to build the TensorFlow model behind the scenes\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Train the neural network\nmodel.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=86, epochs=30, verbose=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n# compile model\nopt = SGD(lr=0.001, momentum=0.9)\nmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\nmodel.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=86, epochs=30, verbose=1)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}