{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import minmax_scale, normalize\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading our dataset\ndf = pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')\n\ndisplay(df)\nprint(df.info())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Our target/dependent variable is 'Outcome' here, and all the other variables are independant variables\n# We'll clean some of our independent variables, replacing the 0's in the features with their mean.\ncols_with_zero = ['Glucose','BloodPressure','SkinThickness','Insulin','BMI']\nfor col in cols_with_zero:\n    df[col] = df[col].replace(0, np.NaN)\n    mean = int(df[col].mean(skipna= True))\n    df[col] = df[col].replace(np.NaN, mean)\n\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's split our data into two sets, one with only dependent variable and the other with the independent variables\n\nx = df.iloc[:,0:8]\ny = df.iloc[:,8]\n\n# splitting our data into Training & Testing data sets in the ratio of 8:2 for both dependent and independent variables\nx_train,x_test, y_train,y_test = train_test_split(x,y, test_size= 0.2, random_state= 123)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's standardize our data to transform the data into equal scale range\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.fit_transform(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Identifying the value of the k-NearestNeighbors we need.\nmath.sqrt(len(y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's train our model on the Training datasets using k-NearestNeighbors (k-NN) algorithm\nclassifier = KNeighborsClassifier(n_neighbors= 11, p= 2, metric= 'euclidean')\nclassifier.fit(x_train,y_train)\n\n# Using our trained model to predict the values for our Testing dataset\ny_pred = classifier.predict(x_test)\n\n# Calculating the metrics for our classification model and the accuracy for the predicted values\ncm1= confusion_matrix(y_test, y_pred)\nprint(cm1)\nprint(f1_score(y_test,y_pred))\nprint(accuracy_score(y_test,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We have got a f1_score of 73%, and an accuracy of 81%, implementing that it's not a very good model but a sustainable one which is workable.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}