{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Univariate time series prediction \n\nThis notebook is an example of how you can use observation data. We will try to forecast a univariate time series, the temperature at one ground station, using Recurrent Neural Networks (RNNs)."},{"metadata":{},"cell_type":"markdown","source":"# Note\n\n<font size=\"4.5\">To use <span style=\"color:blue\">**Cartopy**</span>, a library to plot data with basemaps (see cells below), it is necessary to <span style=\"color:red\">activate the internet connection</span> of that notebook (in edit mode, you can find on the right column, in the *Settings* section, a row entitled *Internet*, put the slider bar on **on**).  </font>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport time\n\nimport tensorflow as tf\nfrom sklearn.metrics import mean_absolute_error\n\nimport matplotlib.pyplot as plt\n\n# Map plotting library\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\n\n# Input data files are available in the \"../input/\" directory.\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Quick data exploration\nThis first part will help you explore quickly the observation data we will use in this example. To get more details about the entire observation data, check the *open_ground_stations* notebook, or navigate to https://meteofrance.github.io/meteonet/data/ground-observations/. Here, we will use 3 years of observation data for the temperature parameter and measured in the North West quarter of France. "},{"metadata":{},"cell_type":"markdown","source":"### Loading the data[](http://)"},{"metadata":{"trusted":true},"cell_type":"code","source":"param = 't'  # parameter to study, here the temperature \nzone = 'NW'  # zone to study \npath = '/kaggle/input/meteonet/NW_Ground_Stations/NW_Ground_Stations/NW_Ground_Stations_'  # path to the data \ncols = ['number_sta','lat','lon','date',param]    # columns we need in the array\n\ndf = pd.concat([pd.read_csv(path + '2016.csv',usecols = cols, parse_dates=['date'],infer_datetime_format=True),\n                pd.read_csv(path + '2017.csv',usecols = cols, parse_dates=['date'],infer_datetime_format=True),\n                pd.read_csv(path + '2018.csv',usecols = cols,parse_dates=['date'],infer_datetime_format=True)], axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's get a look at our data !"},{"metadata":{"trusted":true},"cell_type":"code","source":"display(df.head())\ndisplay(df.tail())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check the data availability \nWe have 3 years of data, but we might need to check that the data is available during this entire period for a given station.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"for id_sta in np.unique(df['number_sta'])[0:3]:\n    print('Station number:',id_sta)    \n    uni_data = df[(df['number_sta'] == id_sta)][{param,'date'}]\n    uni_data = uni_data[uni_data[param].notnull()]\n    if (uni_data.empty == False):\n        t = [t.year for t in uni_data['date']]\n        print('Parameter ',param,' available for the following years : ',np.unique(t))\n    else:\n        print('Param ',param,' missing') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot the map of temperature for a given date"},{"metadata":{"trusted":true},"cell_type":"code","source":"date = '2016-01-01T06:00:00'\nd_sub = df[df['date'] == date]\nplt.figure()\nplt.scatter(d_sub['lon'], d_sub['lat'], c=d_sub[param], cmap='jet')\nplt.xlabel('Longitude (째E)')\nplt.ylabel('Latitude (째N)')\nplt.title(date)\nplt.colorbar().set_label('Temperature (K)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's add the map to our plot with Cartopy !"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Coordinates of studied area boundaries (in 째N and 째E)\nlllat = 46.25  #lower left latitude\nurlat = 51.896  #upper right latitude\nlllon = -5.842  #lower left longitude\nurlon = 2  #upper right longitude\nextent = [lllon, urlon, lllat, urlat]\n\nfig = plt.figure(figsize=(9,5))\n\n# Select projection\nax = plt.axes(projection=ccrs.PlateCarree())\n\n# Plot the data\nplt.scatter(d_sub['lon'], d_sub['lat'], c=d_sub[param], cmap='jet')\nplt.colorbar().set_label('Temperature (K)')\nplt.title(date)\n\nax.coastlines(resolution='50m', linewidth=1)\nax.add_feature(cfeature.BORDERS.with_scale('50m'))\n\n# Adjust the plot to the area we defined \n#/!\\# this line causes a bug of the kaggle notebook and clears all the memory. That is why this line is commented and so\n# the plot is not completely adjusted to the data\n#ax.set_extent(extent)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you wonder why some data points are in the middle of the sea, they were measured on small islands ;)\n\n### Plot the evolution of the temperature at one station"},{"metadata":{"trusted":true},"cell_type":"code","source":"number_sta = 29277001\nuni_data = df[(df['number_sta'] == number_sta)][param]\nuni_data.index = df[(df['number_sta'] == number_sta)]['date']\n\nplt.figure(figsize=(10,5))\nplt.ylabel('Temperature (K)')\nplt.title('Temperature evolution of the station '+str(number_sta))\nuni_data.plot(subplots=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the temperature is rising and falling with the different seasons. "},{"metadata":{},"cell_type":"markdown","source":"## Time series prediction\n\nLet's come back to our example of univariate time series prediction ! We will start by preprocessing the data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#replace nan values by the mean \nuni_data_mean = np.nanmean(uni_data)\nuni_data = np.nan_to_num(uni_data,nan=uni_data_mean)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training and validation datasets\n\nLet's start by splitting the dataset into a training and a validation dataset. \nIt is also important to rescale the data before training our neural network. Standardization is a common way of doing this rescaling by subtracting the mean and dividing by the standard deviation of the feature."},{"metadata":{"trusted":true},"cell_type":"code","source":"coeff_train = 0.7  #proportion of the dataset in the training set\nTRAIN_SPLIT = round(uni_data.shape[0]*coeff_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's now create the data for the univariate model. Our model will take as input an array of consecutive values of size `input_size` and will use this 'past' information to infer the  maximum 'future' value of the parameter on a given period, which is a new array of size `target_size`.\n\nWe choose that the model will be given the last 24h recorded temperature observations (`input_size`=24x10, the data time step is 6min, so we have 10 observations per hour) and learn to predict the maximum temperature at the next 24 hours (`target_size`=240)."},{"metadata":{"trusted":true},"cell_type":"code","source":"def univariate_data(x_data, start_index, end_index,input_size ,target_size):\n    data = []\n    labels = []\n    \n    start_index = start_index + input_size\n    if end_index is None:\n        end_index = len(x_data) - target_size\n\n    for i in range(start_index, end_index):\n        # Reshape data from (input_size,) to (input_size, 1)\n        data.append(np.expand_dims(x_data[(i-input_size):i], axis=1))\n        labels.append(np.max(x_data[i:i+target_size]))\n    return np.array(data), np.array(labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's compute the training and validation set:"},{"metadata":{"trusted":true},"cell_type":"code","source":"univariate_past_history = 240\nunivariate_future_target = 240\n\nx_train,y_train = univariate_data(uni_data, 0,TRAIN_SPLIT,univariate_past_history,univariate_future_target)\nx_val,y_val = univariate_data(uni_data, TRAIN_SPLIT, None,univariate_past_history,univariate_future_target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's standardize the data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_mean = np.mean(x_train)\nx_train_std = np.std(x_train)\n\ny_train_mean = np.mean(y_train)\ny_train_std = np.std(y_train)\n\n#Let's standardize the data:\nx_data_train = (x_train-x_train_mean)/x_train_std\nx_data_val = (x_val-x_train_mean)/x_train_std\ny_data_train = (y_train-y_train_mean)/y_train_std\ny_data_val = (y_val-y_train_mean)/y_train_std","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print ('Single window of past history, first elements')\nprint (x_data_train[0][0:10])\nprint ('\\n Target ',param,' to predict')\nprint (y_data_train[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Single example of the preprocessed dataset\n\nNow that the data has been created, let's take a look at a single example. The information given to the network is given in blue, and it must predict the value at the red cross."},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_time_steps(length):\n  return list(range(-length, 0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_plot(ind, plot_data, delta):\n    labels = ['History : x', 'True Future : y']\n    marker = ['.-', 'rx', 'go']\n    time_steps = create_time_steps(plot_data[0].shape[0])\n    if delta:\n        future = delta\n    else:\n        future = 0\n\n    plt.figure()  \n    plt.title('Sample example '+str(ind))\n    for i, x in enumerate(plot_data):\n        if i:\n            plt.plot(future, plot_data[i], marker[i], markersize=10,\n               label=labels[i])\n        else:\n            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n    plt.legend()\n    plt.xlim([time_steps[0], (future+5)*2])\n    plt.xlabel('Time-Step')\n    plt.ylabel('Standardized temperature')\n    plt.show()\n\nind = 0\nshow_plot(ind,[x_data_train[ind], y_data_train[ind]], 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Baseline\n\nBefore proceeding to train a model, let's first set a simple baseline. Given an input point, the baseline predicts the next point to be the maximum value of the last 24 hours. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def baseline(history):\n    return np.max(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_baseline(ind, plot_data, delta):\n    labels = ['History : x', 'True Future : y','Baseline : Max(History)']\n    marker = ['.-', 'rx', 'go']\n    time_steps = create_time_steps(plot_data[0].shape[0])\n    if delta:\n        future = delta\n    else:\n        future = 0\n\n    plt.figure()  \n    plt.title('Sample example '+str(ind))\n    for i, x in enumerate(plot_data):\n        if i:\n            plt.plot(future, plot_data[i], marker[i], markersize=10,\n               label=labels[i])\n        else:\n            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n    plt.legend()\n    plt.xlim([time_steps[0], (future+5)*2])\n    plt.xlabel('Time-Step')\n    plt.ylabel('Standardized temperature')\n    plt.show()\n\nind = 240\nshow_baseline(ind,[x_data_train[ind], y_data_train[ind], baseline(x_data_train[ind])], 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see if you can beat this baseline using a recurrent neural network."},{"metadata":{},"cell_type":"markdown","source":"## Recurrent neural network"},{"metadata":{},"cell_type":"markdown","source":"A Recurrent Neural Network (RNN) is a type of neural network well-suited to time series data. RNNs process a time series step-by-step, maintaining an internal state summarizing the information they've seen so far. In this notebook, you will use a specialized RNN layer called Long Short Term Memory (LSTM)."},{"metadata":{},"cell_type":"markdown","source":"First we set the seed to ensure the reproducibility of the experiment:"},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.random.set_seed(13)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's now use `tf.data` to shuffle, batch, and cache the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 256\nBUFFER_SIZE = 10000\n\ntrain_univariate = tf.data.Dataset.from_tensor_slices((x_data_train, y_data_train))\ntrain_univariate = train_univariate.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n\nval_univariate = tf.data.Dataset.from_tensor_slices((x_data_val, y_data_val))\nval_univariate = val_univariate.batch(BATCH_SIZE).repeat()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following visualisation should help you understand how the data is represented after batching:"},{"metadata":{},"cell_type":"markdown","source":"![](https://www.tensorflow.org/tutorials/structured_data/images/time_series.png)"},{"metadata":{},"cell_type":"markdown","source":"You will see the LSTM requires the input shape of the data it is being given."},{"metadata":{"trusted":true},"cell_type":"code","source":"simple_lstm_model = tf.keras.models.Sequential([\n    tf.keras.layers.LSTM(8, input_shape=x_data_train.shape[-2:]),\n    tf.keras.layers.Dense(1)\n])\n\nsimple_lstm_model.compile(optimizer='adam', loss='mae')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's make a sample prediction, to check the output of the model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"for x,y in val_univariate.take(1):\n    print(simple_lstm_model.predict(x).shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's train the model now. "},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 5\nSTEPS_PER_EPOCH = (x_data_train.shape[0]/BATCH_SIZE//1)+1\nVAL_STEPS = (x_data_val.shape[0]/BATCH_SIZE//1)+1\n\nsimple_lstm_model.fit(train_univariate, epochs=EPOCHS,\n                      steps_per_epoch=STEPS_PER_EPOCH,\n                      validation_data=val_univariate, validation_steps = VAL_STEPS)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predict using the simple LSTM model\n\nNow that you have trained your simple LSTM, let's try and make a few predictions."},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_result(index, plot_data, delta):\n    labels = ['History : x', 'True Future : y', 'Prediction','Baseline : Max(History)']\n    marker = ['.-', 'rx', 'go','go']\n    colors = ['blue','red','green','darkblue']\n    time_steps = create_time_steps(plot_data[0].shape[0])\n    if delta:\n        future = delta\n    else:\n        future = 0\n\n    plt.figure()  \n    plt.title('Sample example '+str(ind))\n    for i, x in enumerate(plot_data):\n        if i:\n            plt.plot(future, plot_data[i], marker[i], markersize=10,\n               label=labels[i], color = colors[i])\n        else:\n            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i], color = colors[i])\n    plt.legend()\n    plt.xlim([time_steps[0], (future+5)*2])\n    plt.xlabel('Time-Step')\n    plt.ylabel('Standardized temperature')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ind = 0\nfor x, y in val_univariate.take(3):\n    y_true=[]\n    y_true.append(y[ind].numpy())\n    basel=[]\n    basel.append(baseline(x[ind].numpy()))\n    print('mae baseline',mean_absolute_error(y_true,basel))\n    print('mae LSTM',mean_absolute_error(y_true,simple_lstm_model.predict(x)[ind]))\n    plot = show_result(ind,[x[ind].numpy(), y[ind].numpy(),simple_lstm_model.predict(x)[ind],baseline(x[ind].numpy())], 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This looks better than the baseline. \n\nNow that you have seen some basics, let's go ahead, play with the data, propose your own methods ! "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}