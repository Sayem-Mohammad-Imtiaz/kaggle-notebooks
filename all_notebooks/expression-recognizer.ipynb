{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport torch\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import io, datasets, transforms\nfrom tqdm.notebook import tqdm\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-01T11:13:11.202615Z","iopub.execute_input":"2021-07-01T11:13:11.202995Z","iopub.status.idle":"2021-07-01T11:13:12.500066Z","shell.execute_reply.started":"2021-07-01T11:13:11.202908Z","shell.execute_reply":"2021-07-01T11:13:12.499235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#enable cuda\nuse_cuda = torch.cuda.is_available()\nif use_cuda:\n    device = torch.device('cuda')\n    loader_kwargs = {'num_workers': 1, 'pin_memory': True}\nelse:\n    device = torch.device('cpu')\n    loader_kwargs = {}\n    \nprint(device)","metadata":{"execution":{"iopub.status.busy":"2021-07-01T11:13:19.768669Z","iopub.execute_input":"2021-07-01T11:13:19.769009Z","iopub.status.idle":"2021-07-01T11:13:19.83806Z","shell.execute_reply.started":"2021-07-01T11:13:19.768975Z","shell.execute_reply":"2021-07-01T11:13:19.837294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ExpressionDataset(Dataset):\n    \"\"\"Binomial expression dataset\"\"\"\n    \n    def __init__(self, csv_file, root_dir):\n        self.labels = pd.read_csv(csv_file)\n        self.root_dir = root_dir\n        \n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        \n        img_name = os.path.join(self.root_dir, self.labels.iloc[idx,0])\n        img = io.read_image(img_name).float()\n        exprtype, ans = self.labels.iloc[idx,1:]\n        exprtype_int = 0\n        if exprtype == \"infix\":\n            exprtype_int = 1\n        elif exprtype == \"postfix\":\n            exprtype_int = 2\n        return [img, exprtype_int, ans+9]\n\ndataset = ExpressionDataset(csv_file='../input/soml-hackathon/SoML/SoML-50/annotations.csv', root_dir='../input/soml-hackathon/SoML/SoML-50/data')\nplt.imshow(dataset[10][0].squeeze())","metadata":{"execution":{"iopub.status.busy":"2021-07-01T11:13:23.40473Z","iopub.execute_input":"2021-07-01T11:13:23.40508Z","iopub.status.idle":"2021-07-01T11:13:23.659606Z","shell.execute_reply.started":"2021-07-01T11:13:23.405047Z","shell.execute_reply":"2021-07-01T11:13:23.658859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set, test_set, validation_set = torch.utils.data.random_split(dataset, [40000,5000,5000])\n\ntrain_loader = DataLoader(train_set, batch_size=50, shuffle=True)\ntest_loader = DataLoader(test_set, batch_size=50, shuffle=True)\nvalidation_loader = DataLoader(validation_set, batch_size=50, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-01T11:13:26.571469Z","iopub.execute_input":"2021-07-01T11:13:26.571803Z","iopub.status.idle":"2021-07-01T11:13:26.588297Z","shell.execute_reply.started":"2021-07-01T11:13:26.571753Z","shell.execute_reply":"2021-07-01T11:13:26.587514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ExpressionTypeNetwork(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.conv1 = nn.Conv2d(1, 10, kernel_size = 8)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size = 4)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(1900, 100)\n        self.fc2 = nn.Linear(100, 3)\n\n#        self.input_layer = torch.nn.Linear(128*384, 192)\n        #self.hl1 = torch.nn.Linear(384, 14*3)\n#        self.hl2 = torch.nn.Linear(192, 3)\n#        self.relu = torch.nn.ReLU()\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 6))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 3))\n#        print(x.shape)\n        x = torch.flatten(x,1)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training = self.training)\n        x = self.fc2(x)\n        return x\n        \n#        x = self.input_layer(x)\n#        x = self.relu(x)\n#        x = self.hl2(x)\n#        x = self.relu(x)\n#        x = self.hl2(x)\n\n#        return x\n    \n    def acc(self, loader):\n        total = 0\n        correct = 0\n        \n        with torch.no_grad(): \n            for images, types, answers in loader:\n                images, types = images.to(device), types.to(device)\n                batch_size = images.shape[0]\n#                images = images.reshape(batch_size, (128//4)*(384//4))\n                output = self(images)\n\n                predicted = torch.argmax(output, dim=1)\n                correct += torch.sum(types == predicted)\n                total += batch_size\n        \n        return correct/total","metadata":{"execution":{"iopub.status.busy":"2021-07-01T11:16:01.708505Z","iopub.execute_input":"2021-07-01T11:16:01.708834Z","iopub.status.idle":"2021-07-01T11:16:01.718928Z","shell.execute_reply.started":"2021-07-01T11:16:01.708799Z","shell.execute_reply":"2021-07-01T11:16:01.718024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type_net = ExpressionTypeNetwork().to(device)\nlossfn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(type_net.parameters(), lr=0.001)\n\ntype_net.eval()\nprint(f\"Accuracy: {type_net.acc(validation_loader)}\")\nfor epoch in range(10):\n    avg_loss = 0\n    num_iters = 0\n    type_net.train()\n    for images, types, answers in tqdm(train_loader):\n        images, types = images.to(device), types.to(device)\n        optimizer.zero_grad()\n        batch_size = images.shape[0]\n#        images = images.reshape(batch_size, 128*384)\n        output = type_net(images)\n        loss = lossfn(output, types)\n        \n        loss.backward()\n        optimizer.step()\n\n        avg_loss += loss.item()\n        num_iters += 1\n    \n    type_net.eval()\n    print(f\"Loss: {avg_loss/num_iters}\")\n    print(f\"Accuracy: {type_net.acc(validation_loader)}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-01T11:16:02.921741Z","iopub.execute_input":"2021-07-01T11:16:02.922142Z","iopub.status.idle":"2021-07-01T11:33:33.287439Z","shell.execute_reply.started":"2021-07-01T11:16:02.922107Z","shell.execute_reply":"2021-07-01T11:33:33.286497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(type_net.state_dict(), '/kaggle/working/type_net_dict')","metadata":{"execution":{"iopub.status.busy":"2021-07-01T11:46:49.698473Z","iopub.execute_input":"2021-07-01T11:46:49.698818Z","iopub.status.idle":"2021-07-01T11:46:49.711575Z","shell.execute_reply.started":"2021-07-01T11:46:49.698765Z","shell.execute_reply":"2021-07-01T11:46:49.7108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}