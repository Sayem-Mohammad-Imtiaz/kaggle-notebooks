{"cells":[{"metadata":{"_uuid":"4da915e69e8efe272b5f1307ad4c14029bc13b2e"},"cell_type":"markdown","source":"The aim of this kernal is to discover what is the active research area in this institute by using basic language processing to count the number of each token appearing and identify the most frquent type of cancer. The analysis then go on to explore the impact factor of each publication to see which area of research is more impactful."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%%capture\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom nltk.corpus import stopwords#to filter out stop words to scale down the data \nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer \nfrom sklearn.linear_model import LogisticRegression\n#the last two are used for NLP \nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n#this is for ipython to display all the results of cell\nimport os\nprint(os.listdir(\"../input\"))\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"raw = pd.read_csv('../input/publications-from-roswell-park-cancer-institute-beginning-2006.csv')\nraw.columns #show what informations are available\nraw.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5199ee3748dd1b462ed1ec7e4c24630b86309d7e"},"cell_type":"code","source":"%%capture\n#see what each column contain\nfor feature in list(raw.columns):\n    print(feature + str(raw[feature].unique()) + '\\n')\n'''\nyear: looks fine, can be used\ntype: can be used, there is a 967-9753 can take out\njournal name: could be useful\ntitle: essential for my purpose\narthor: maybe can use\njournal volume: definitely can drop\nissue number: also useless\nrange: could be used to calculate the length of the paper\nISSN: useless\npeer reviewed: important?\nImpact: the most important prediction here\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"467f73584bf92461a17d7cb27e7f84cf8e889945"},"cell_type":"code","source":"#first stage cleaning: dropping the stuff definitely irrelevant to analysis\nDF = raw.drop(['ISSN', 'Journal Issue Number', 'Journal Volume'], axis = 1)\nDF = DF[DF['Publication Type']!='967-9753']\nDF.head()\nDF['Publication Type'].unique()#no more 967-963","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"467f73584bf92461a17d7cb27e7f84cf8e889945"},"cell_type":"code","source":"DF['Year Published'].value_counts().plot(kind='bar');\n#see the number of journals each year\n#2018 doesn't really count but we still see a gradual decrease","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0141f3193270409295ebb1bc0558d53f1618bb29","scrolled":false},"cell_type":"code","source":"%%capture\n#from here, if the analysis has to do with impact score, use DF_impact, unless use DF as there are more data\n#some are non-rated so replace the string: 'Not Rated' with nan\nDF['Impact Factor'] = DF['Impact Factor'].replace(to_replace = 'Not Rated',value=np.nan)\n#ignore the data without rating\nDF_impact = DF[DF['Impact Factor'].notnull()]\n#covert the score/year from string to a number\nDF_impact['Impact Factor'] = DF_impact['Impact Factor'].astype('float64')\nDF_impact['Year Published'] = DF_impact['Year Published'].astype('int64')\n#ignore years from 2015 since impact score shouldn't be calculated before three years after prublication\nDF_impact = DF_impact[DF_impact['Year Published'].apply(lambda x: x <=2015)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da40d3b4a35e2e7fbe312c413e5e7d169e3edfb2"},"cell_type":"code","source":"#check the most impactful publication \nDF_impact.sort_values(by=['Impact Factor'], ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"6485769665f778582a50bc2af2f215e2fccf6f6e"},"cell_type":"code","source":"#trying to combine all the titles from all the articles\ncombined_long =''\n#adding them\nfor _ in DF['Publication Title']:\n    combined_long+=_\n    #combined_long+=' '.join(list(set(_.split(' '))))\n#filtered=' '.join([words for words in combined_long.split(\" \") if words not in uninformation_words])\n\n#build a bag of words for each title with NLP toolbox\n#second one is more robust and will be used from now on\ncount_vectorizer = CountVectorizer(lowercase=True)\ntfidf_vectorizer = TfidfVectorizer(lowercase=True)\n#build bag of words with the vectorizer\nbag_of_words = count_vectorizer.fit_transform([combined_long])\nbag_of_words2 = tfidf_vectorizer.fit_transform([combined_long])\n#get name of the feature i.e. the key words\nfeature_names = count_vectorizer.get_feature_names()\nfeature_names2 = tfidf_vectorizer.get_feature_names()\n#the words we don't want\ncustomed_uselesswords=set(['cancer','study','cell','cells','analysis','tumor','risk','phase','human','group',\n                           'advanced','expression','thearpy','treatment','patients','non','based','survival'\n                          'small','gene','trial','results','novel'])\nuninformation_words = customed_uselesswords|set(stopwords.words('english')) \nuninformation_words=list(uninformation_words&set(feature_names))\n#convert our results for the bag of words into a data frame for the normal method\nBoW=pd.DataFrame(bag_of_words.toarray(), columns = feature_names)\nBoW= BoW.transpose()\nBoW.columns = BoW.columns.astype(str)\nBoW.columns = ['counts']\n#filter the less important ones(less frequent)\nBoW = BoW.drop(uninformation_words).loc[BoW['counts']>200].sort_values(by=['counts'], ascending=False)\n#same thing for the more robust method\nBoW2=pd.DataFrame(bag_of_words2.toarray(), columns = feature_names2)\nBoW2= BoW2.transpose()\nBoW2.columns = BoW2.columns.astype(str)\nBoW2.columns = ['frequency']\nBoW2 = BoW2.drop(uninformation_words).loc[BoW2['frequency']>0.015].sort_values(by=['frequency'], ascending=False)    \nBagWords=BoW2\n\nBoW.plot.bar();\nBoW2.plot.bar();\n\n#the two happened to be the same ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ed1a14da6d0caa8155ef030642f9f6281ca4b64"},"cell_type":"code","source":"BagWords.head(20)\n#we can pick out the main cancer research area to invertigate: breast, prostate, ovarian, carcinoma, lung, leukemia,lymphoma,myeloid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"496e562f6bc1778755cd247a4dd628e4fd14d505"},"cell_type":"code","source":"%%capture\n#next stage will be to investigate how the key words of cancer has raised popularity \ngrouped_df = DF_impact.groupby(['Year Published'])\n\nfor key, item in grouped_df:\n    print(grouped_df.get_group(key), \"\\n\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc83e2023292c0f8121d910e425e62b88c1ca339"},"cell_type":"code","source":"#define a class contain the methods for the type of cancer we're focusing on\n\nclass cancer():\n    #initiate the cancer type such that we have a data frame that doesn't contain the type of cancer we interesested\n    def __init__(self,cancer_type):\n        self.cancer_type=cancer_type\n        self.df = DF[DF['Publication Title'].apply(lambda x: self.cancer_type in x)]\n        self.df_i = DF_impact[DF_impact['Publication Title'].apply(lambda x: self.cancer_type in x)]\n    #define the method for the verious things we might be interested from the data\n    def summary(self,h,t):\n        def counts_year(t):\n            self.f_y = self.df.groupby('Year Published')['Publication Title'].count()\n            self.f_y.plot.bar(title=self.cancer_type, ax=ax[t], rot =0);\n        def impact_year(t):\n            self.i_y = self.df_i.groupby('Year Published')['Impact Factor'].agg('mean')\n            self.i_y.plot.bar(title=self.cancer_type, ax=ax[t], rot =0);\n        def average_impact():\n            return self.df_i['Impact Factor'].mean() \n        def correlation():\n            self.f_y = self.df_i.groupby('Year Published')['Publication Title'].count()\n            self.i_y = self.df_i.groupby('Year Published')['Impact Factor'].agg('mean')\n            return self.f_y.corr(self.i_y)\n        def box(t):\n            self.df_i[self.df_i['Year Published'] == int(t)+2006].boxplot(column=['Impact Factor'], ax=ax[t])\n        def box_year():\n            self.df_i.groupby('Year Published')['Impact Factor'].agg('mean').plot(kind='line', ax = ax);\n            self.df_i.boxplot(column = ['Impact Factor'], by = 'Year Published', ax=ax,  rot=0 );\n           \n        if h=='f':#the publication counts by year\n            counts_year(t)\n        elif h=='i':#the average impact factor by year\n            impact_year(t)\n        elif h=='a':#find the average impact score for each type of cancer\n            return average_impact()\n        elif h=='c':#find the correlation between publication number and impact factor\n            return correlation()\n        elif h=='b':#the distribution of impact factor score by year\n            box(t)\n        elif h=='b_y':#the distribution of impact factor score by year\n            box_year()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c04a66372189d379177ab0073bf3833f3aac2dc"},"cell_type":"code","source":"#the most frequently appeared type of cancer in this order\nall_cancer = ['breast', 'prostate', 'ovarian', 'carcinoma', 'lung', 'leukemia', 'lymphoma', 'myeloid']\n#define a function that tells us the cancer and its associate information\ndef find_summary(Cancer, s, t):\n    _ = cancer(Cancer)\n    return _.summary(s,t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c04a66372189d379177ab0073bf3833f3aac2dc","scrolled":true},"cell_type":"code","source":"#find the average impact score according to year by cancer\nfig, ax = plt.subplots(8,1,figsize=(20,20))\nplt.subplots_adjust(hspace=1)\nfor i in range(8):\n    find_summary(all_cancer[i],'i',i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7de227636b3a8fc13a7b945304c351c388c147c"},"cell_type":"code","source":"#find the publication counts according to year by cancer\nfig, ax = plt.subplots(8,1,figsize=(20,20))\nplt.subplots_adjust(hspace=1)\nfor i in range(8):\n    find_summary(all_cancer[i],'f',i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79bc8a3ee94c3cf904fc6b28d2a2a10c15a88b62"},"cell_type":"code","source":"#find the distribution of impact score with boxplot for breast cancer from 2006 to 2015(left to right)\nfig, ax = plt.subplots(1,10,figsize=(20,5))\nfor i in range(10):\n    find_summary('breast','b',i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2abd94d6ea64d6529441014f36b67a57840bc16"},"cell_type":"code","source":"fig, ax = plt.subplots(1,1,figsize=(20,20))\nfind_summary('breast','b_y',2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a35d582d72a16d48a88fb0f15ab97f122517f808"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}