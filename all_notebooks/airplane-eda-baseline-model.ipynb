{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Load packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd                                                  # to import csv and for data manipulation\nimport matplotlib.pyplot as plt                                      # to plot graph\nimport seaborn as sns                                                # for intractve graphs\nimport numpy as np                                                   # for linear algebra\nimport datetime                                                      # to deal with date and time\n%matplotlib inline\nfrom sklearn.preprocessing import StandardScaler                     # for preprocessing the data\nfrom sklearn.ensemble import RandomForestClassifier                  # Random forest classifier\nfrom sklearn.tree import DecisionTreeClassifier                      # for Decision Tree classifier\nfrom sklearn.svm import SVC                                          # for SVM classification\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nfrom sklearn.model_selection import GridSearchCV                     # for tunnig hyper parameter it will use all combination of given parameters\nfrom sklearn.model_selection import RandomizedSearchCV               # same for tunning hyper parameter but will use random combinations of parameters\nfrom sklearn.metrics import confusion_matrix,recall_score,precision_recall_curve,auc,roc_curve,roc_auc_score,classification_report\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.utils import resample\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Read data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/airplane-accidents-severity-dataset/train.csv')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/airplane-accidents-severity-dataset/test.csv')\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.read_csv('/kaggle/input/airplane-accidents-severity-dataset/sample_submission.csv')\nsub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_df['Severity'].nunique())\nprint(train_df['Severity'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The total number of Rows in Train dataset is : \", train_df.shape[0])\nprint(\"The total number of Rows in Test dataset is : \", test_df.shape[0])\nprint(\"The total number of Rows in both Train and Test dataset is : \", train_df.shape[0]+test_df.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Structure, Features and DataTypes"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Univariate Analysis"},{"metadata":{},"cell_type":"markdown","source":"We will first look at the target variable, i.e., Severity. As it is a categorical variable, let us look at its frequency table, percentage distribution and bar plot. Frequency table of a variable will give us the count of each category in that variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Severity'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalise can be set to true to print the proportions instead of Numbers.\ntrain_df['Severity'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here there is no class imbalance problem . Hence we can proceed further without addressing any class imbalance issues"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Severity'].value_counts().plot.bar(figsize=(4,4),title='Severity - Split for Train Dataset')\nplt.xlabel('Severity')\nplt.ylabel('Count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now lets visualize each variable separately. Different types of variables are Categorical, ordinal and numerical.\n\nCategorical features: These features have categories (Accident_Type_Code, 'Violations')\n\nOrdinal features: Variables in categorical features having some order involved \n\nNumerical features: These features have numerical values ('Safety_Score', 'Days_Since_Inspection', 'Total_Safety_Complaints', 'Control_Metric', 'Turbulence_In_gforces',\n       'Cabin_Temperature',  'Max_Elevation',\n        'Adverse_Weather_Metric')\n\nTarget variable : 'Severity'\n\nLetâ€™s visualize the categorical and ordinal features first."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1)\nplt.subplot(121)\ntrain_df['Accident_Type_Code'].value_counts(normalize=True).plot.bar(figsize=(24,6), fontsize = 15.0)\nplt.title('Accident_Type_Code', fontweight=\"bold\", fontsize = 22.0)\nplt.ylabel('Count %', fontsize = 20.0)\n\nplt.subplot(122)\ntrain_df['Violations'].value_counts(normalize=True).plot.bar(figsize=(24,6), fontsize = 15.0)\nplt.title('Violations', fontweight=\"bold\", fontsize = 22.0)\nplt.ylabel('Count %', fontsize = 20.0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's visualize the Numerical Attributes"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['Safety_Score', 'Days_Since_Inspection', 'Total_Safety_Complaints', 'Control_Metric']\nfor col in cols:    \n    plt.figure(1)\n    plt.subplot(121)\n    sns.distplot(train_df[col])\n\n    plt.subplot(122)\n    train_df[col].plot.box(figsize=(16,5))\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['Turbulence_In_gforces',\n       'Cabin_Temperature',  'Max_Elevation',\n        'Adverse_Weather_Metric']\nfor col in cols:    \n    plt.figure(1)\n    plt.subplot(121)\n    sns.distplot(train_df[col])\n\n    plt.subplot(122)\n    train_df[col].plot.box(figsize=(16,5))\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation between numerical variables\nnum_cols_data = (train_df[['Safety_Score', 'Days_Since_Inspection', 'Total_Safety_Complaints',\n                        'Control_Metric', 'Turbulence_In_gforces',\n                       'Cabin_Temperature',  'Max_Elevation',\n                        'Adverse_Weather_Metric'                       \n                       ]])\nmatrix = num_cols_data.corr()\nf, ax = plt.subplots(figsize=(20, 10))\nsns.heatmap(matrix, vmax=.8, square=True, cmap=\"BuPu\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Missing Values Treatment"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check missing values\ntrain_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no missing values in dataset\n"},{"metadata":{},"cell_type":"markdown","source":"### Bivariate Analysis"},{"metadata":{},"cell_type":"markdown","source":"#### Categorical Independent Variable vs Target Variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"Accident_Type_Code=pd.crosstab(train_df['Accident_Type_Code'],train_df['Severity'])\nViolations=pd.crosstab(train_df['Violations'],train_df['Severity'])\n\n\nAccident_Type_Code.div(Accident_Type_Code.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(6,6))\nViolations.div(Violations.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(6,6))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Numerical Independent Variable vs Target Variable"},{"metadata":{},"cell_type":"markdown","source":"We will try to find the meanvalues vs Target vs "},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['Safety_Score', 'Days_Since_Inspection', 'Total_Safety_Complaints',\n                        'Control_Metric', 'Turbulence_In_gforces',\n                       'Cabin_Temperature',  'Max_Elevation',\n                        'Adverse_Weather_Metric']\n\ntrain_df.groupby('Severity')['Safety_Score'].mean().plot.bar()\n\nplt.ylabel('Mean_Safety_Score')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cols = ['Safety_Score', 'Days_Since_Inspection', 'Total_Safety_Complaints',\n#                         'Control_Metric', 'Turbulence_In_gforces',\n#                        'Cabin_Temperature',  'Max_Elevation',\n#                         'Adverse_Weather_Metric']\nplt.figure(1)\nplt.subplot(121)\ntrain_df.groupby('Severity')['Safety_Score'].mean().plot.bar(figsize=(18,6), fontsize = 15.0)\nplt.title('Severity', fontweight=\"bold\", fontsize = 22.0)\nplt.ylabel('Mean_Days_Safety_Score', fontsize = 20.0)\n\nplt.subplot(122)\ntrain_df.groupby('Severity')['Days_Since_Inspection'].mean().plot.bar(figsize=(18,6), fontsize = 15.0)\nplt.title('Severity', fontweight=\"bold\", fontsize = 22.0)\nplt.ylabel('Mean_Days_Since_Inspection', fontsize = 20.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1)\nplt.subplot(121)\ntrain_df.groupby('Severity')['Total_Safety_Complaints'].mean().plot.bar(figsize=(18,6), fontsize = 15.0)\nplt.title('Severity', fontweight=\"bold\", fontsize = 22.0)\nplt.ylabel('Mean_Days_Total_Safety_Complaints', fontsize = 12.0)\n\nplt.subplot(122)\ntrain_df.groupby('Severity')['Control_Metric'].mean().plot.bar(figsize=(18,6), fontsize = 15.0)\nplt.title('Severity', fontweight=\"bold\", fontsize = 22.0)\nplt.ylabel('Mean_Days_Control_Metric', fontsize = 12.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1)\nplt.subplot(121)\ntrain_df.groupby('Severity')['Turbulence_In_gforces'].mean().plot.bar(figsize=(18,6), fontsize = 15.0)\nplt.title('Severity', fontweight=\"bold\", fontsize = 22.0)\nplt.ylabel('Mean_Days_Turbulence_In_gforces', fontsize = 12.0)\n\nplt.subplot(122)\ntrain_df.groupby('Severity')['Cabin_Temperature'].mean().plot.bar(figsize=(18,6), fontsize = 15.0)\nplt.title('Severity', fontweight=\"bold\", fontsize = 22.0)\nplt.ylabel('Mean_Days_Cabin_Temperature', fontsize = 12.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 'Max_Elevation',  'Adverse_Weather_Metric'\nplt.figure(1)\nplt.subplot(121)\ntrain_df.groupby('Severity')['Max_Elevation'].mean().plot.bar(figsize=(18,6), fontsize = 15.0)\nplt.title('Severity', fontweight=\"bold\", fontsize = 22.0)\nplt.ylabel('Mean_Days_Max_Elevation', fontsize = 12.0)\n\nplt.subplot(122)\ntrain_df.groupby('Severity')['Adverse_Weather_Metric'].mean().plot.bar(figsize=(18,6), fontsize = 15.0)\nplt.title('Severity', fontweight=\"bold\", fontsize = 22.0)\nplt.ylabel('Mean_Days_Adverse_Weather_Metric', fontsize = 12.0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Baseline model"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['Safety_Score', 'Days_Since_Inspection', 'Total_Safety_Complaints',\n       'Control_Metric', 'Turbulence_In_gforces', 'Cabin_Temperature',\n       'Accident_Type_Code', 'Max_Elevation', 'Violations',\n       'Adverse_Weather_Metric']\nlabels = train_df['Severity']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_df.drop(['Accident_ID','Severity'],axis=1)\ny = train_df['Severity']\n\ntest_X = test_df.drop(['Accident_ID'],axis=1)\n# TODO: Shuffle and split the data into training and testing subsets\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=100)\n\n# Success\nprint (\"Training and testing split was successful.\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nmodel_log = LogisticRegression()\nmodel_log.fit(X_train, y_train)\npred_cv = model_log.predict(X_valid)\naccuracy_score(y_valid,pred_cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix = confusion_matrix( y_valid,pred_cv)\nprint(\"the recall for this model is :\",confusion_matrix[1,1]/(confusion_matrix[1,1]+confusion_matrix[1,0]))\n\nfig= plt.figure(figsize=(6,3))# to plot the graph\nprint(\"TP\",confusion_matrix[1,1,]) \nprint(\"TN\",confusion_matrix[0,0]) \nprint(\"FP\",confusion_matrix[0,1]) \nprint(\"FN\",confusion_matrix[1,0])\nsns.heatmap(confusion_matrix,cmap=\"coolwarm_r\",annot=True,linewidths=0.5)\nplt.title(\"Confusion_matrix\")\nplt.xlabel(\"Predicted_class\")\nplt.ylabel(\"Real class\")\nplt.show()\nprint(confusion_matrix)\nprint(\"\\n--------------------Classification Report------------------------------------\")\nprint(classification_report(y_valid, pred_cv)) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Model Building - RandomForestClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\nmodel_rf.fit(X_train, y_train)\npred_cv = model_rf.predict(X_valid)\naccuracy_score(y_valid,pred_cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_test = model_rf.predict(test_X)\npred_test = pd.DataFrame(pred_test)\npred_test.columns = ['Severity']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_test.head()\nprint(len(pred_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances=pd.Series(model_rf.feature_importances_, index=X.columns).sort_values()\nimportances.plot(kind='barh', figsize=(20,20))\nplt.xlabel('Importance of Attributes - Score')\nplt.ylabel('Attribute Name')\nplt.title(\"Attribute Importance by RandomForest Application\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = test_df[['Accident_ID']]\n# # Fill the target variable with the predictions\nsub_df['Severity'] = pred_test['Severity']\n# # # Converting the submission file to csv format\nsub_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}