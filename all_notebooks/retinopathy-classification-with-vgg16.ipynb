{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport cv2\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.preprocessing.image import img_to_array, load_img\nfrom keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dense\nfrom keras.applications.vgg16 import VGG16\nfrom keras.utils.np_utils import to_categorical\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First, the images must be converted into a form that can be inputed into a neural network. We also need to shuffle and split the data into training and test sets."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"base_dir = '/kaggle/input/diabetic-retinopathy-224x224-gaussian-filtered/gaussian_filtered_images/gaussian_filtered_images/'\n\ndata = []\nlabels = []\n\n# Walk through all the images and convert them to arrays to be fed into the network\n\nfor subdir, dirs, files in os.walk(base_dir):\n    for file in files:\n        if file.endswith('.pkl') is False:\n            filepath = subdir + os.sep + file\n            image = load_img(filepath, target_size=(224,224))\n            # image = cv2.resize(image, (122,122))\n            image = img_to_array(image)\n            data.append(image)\n        \n            label = filepath.split(os.path.sep)[-2]\n            labels.append(label)\n        \n        else:\n            continue\n\ndata = np.stack(data)\ndata /= 255.0\nlabels = np.array(labels)\nprint(np.unique(labels))\n\n# Shuffle the image data and labels in unison \nX = data\ny = labels\n\nle = LabelEncoder()\n\ny = le.fit_transform(y)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will construct a model and see if we can classify the data. I trained the entire VGG16 model to the data. A basic visualization of model performance will also be provided."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate the trained model and set all layers to be trainable\ntrained_model = VGG16(input_shape=(224,224,3), include_top=False)\n\nfor layer in trained_model.layers:\n    layer.trainable = True\n\n# Construct the model and compile\nmod1 = Flatten()\nmod_final = Dense(5, activation='softmax')\n\nmodel = Sequential([trained_model, mod1, mod_final])\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Fit the model to the data and validate\nhistory = model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=15)\n\n# Plot the model results using seaborn and matplotlib\nsns.set(style='darkgrid')\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}