{"cells":[{"metadata":{"id":"OYqaFlsVy0Ab"},"cell_type":"markdown","source":"# Given that someone likes certain animes, which other animes this person might like?\n\nLet's start by importing the needed datasets and modules\n\n","execution_count":null},{"metadata":{"id":"HqXUkC02bt52","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.cluster import KMeans\nfrom sklearn.cluster import OPTICS","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","id":"1ctO152fy0Ac","trusted":true},"cell_type":"code","source":"anime_original = pd.read_csv('../input/anime-recommendations-database/anime.csv')\nrating_original = pd.read_csv('../input/anime-recommendations-database/rating.csv')","execution_count":null,"outputs":[]},{"metadata":{"id":"9n98ZA5Ny0Af","trusted":true},"cell_type":"code","source":"anime = anime_original.copy()\nrating = rating_original.copy()","execution_count":null,"outputs":[]},{"metadata":{"id":"UxY-euFSy0Ai"},"cell_type":"markdown","source":"# Machine Learning recomendation system\n### For this task we will use a colaborative system, in which we'll make recomendations based on the rating data of similar users.\nNote that there are values of -1 in the rating column. This means that the user watched the film but didn't rate it. We'll choose to drop these values in this aproach. In another approach we may choose to input some values as the -1 rating is a significant proportion of the rating column, almost 15%","execution_count":null},{"metadata":{"id":"wsGxbbuyy0Aj","outputId":"3a7a0d10-f8c4-49ef-8145-f046daa0bbd4","trusted":true},"cell_type":"code","source":"condition = rating.loc[rating.rating == -1,:].index\nrating.drop(condition,inplace=True)\nrating","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"id":"plj69ckdy0Am","outputId":"fff3a162-f275-477d-bdb8-10b28cbf8e47","trusted":true},"cell_type":"code","source":"# Creating an array with the Id's of the rated animes\nanime_id_list = np.unique(rating.anime_id.values)\nanime_id_list","execution_count":null,"outputs":[]},{"metadata":{"id":"DrForgCUy0Aq"},"cell_type":"markdown","source":"## Creation of the ratings matrix \n\n### We'll create a matrix such that the ij element of the matrix will be equal to the rating given by user \"i\" to the anime \"j\". Whenever the user didn't rate the anime the entry will be assigned to 0.\n\nThere is a simples way to accomplish this task. The .pivot( ) method does exactly that, but unfortunately our dataset is huge so we don't have enough memory to make the calculations.\n\nTo solve this problem, I came up with a function that leads to the same result but as a Sparse Matrix so we don't have to store all the values in memory!","execution_count":null},{"metadata":{"id":"CeD1yGZ5cmqp","trusted":true},"cell_type":"code","source":"from scipy.sparse import csr_matrix\nfrom pandas.api.types import CategoricalDtype\n\nuser_c = CategoricalDtype(sorted(rating.user_id.unique()), ordered=True)\nanime_c = CategoricalDtype(sorted(rating.anime_id.unique()), ordered=True)\n\nrow = rating.user_id.astype(user_c).cat.codes\ncol = rating.anime_id.astype(anime_c).cat.codes\nsparse_matrix = csr_matrix((rating[\"rating\"], (row, col)), \\\n                           shape=(user_c.categories.size, anime_c.categories.size))","execution_count":null,"outputs":[]},{"metadata":{"id":"Up6iBN-Jy0Aq","trusted":true},"cell_type":"code","source":"### Importing the sparse matrix previously calculated\nimport scipy.sparse\nX_sparse = scipy.sparse.load_npz(\"../input/user-matrix/sparse_matrix.npz\")","execution_count":null,"outputs":[]},{"metadata":{"id":"uTrK6tDgy0Au"},"cell_type":"markdown","source":"\n\n\n### The matrix is sparse because there are a ton of animes and obviously, most users didn't watch most of them","execution_count":null},{"metadata":{"id":"jfaIeDBUy0Au","outputId":"dcee18cd-a9f6-4823-a44d-64411db2fcf1","trusted":true},"cell_type":"code","source":"#Less than 1% of the entries belong to given ratings\nsparcity = (X_sparse.nonzero()[0].shape[0])/(X_sparse.shape[0]*X_sparse.shape[1])\nsparcity*100","execution_count":null,"outputs":[]},{"metadata":{"id":"ujtPG17vy0Ax"},"cell_type":"markdown","source":"## In this approach, we'll use matrix factorization in order to predict all the entries which weren't assigned by the users, then we'll group similar users to finally give predictions about a new user\nI've written a Gradient Descent algorithm to return two matrices P and Q such that their product approximates our original sparse matrix only at the entries that the users have given their ratings (non zero entries). This way the algorithm will learn the intrinsic taste of a user and will (hopefully!) generalize to the animes that weren't rated by the users. ","execution_count":null},{"metadata":{"id":"1-hBBjSHy0Ay","trusted":true},"cell_type":"code","source":"def Gradient_Descent(X):\n    X_sparse = X/np.max(X)           # normalizing values\n    print(X_sparse)\n    n_factors = 100\n    n_steps =  500                # optimized\n    alpha = 0.01                   # optimized\n    \n    #initializing the vectors randomly:\n    p = np.random.normal(0, .01, (X_sparse.shape[0], n_factors))\n    q = np.random.normal(0, .01, (n_factors, X_sparse.shape[1]))      # changed so as to follow matrix multiplication rule\n    \n    for k in range(0,n_steps):\n        for (i,j) in zip(X_sparse.nonzero()[0],X_sparse.nonzero()[1]):\n            err = X_sparse[i,j] - np.dot(p[i, :],q[:, j])              # multiply whole row and column\n            p[i, :] = p[i, :] + alpha*q[:, j]*err                      # update whole row and column\n            q[:, j] = q[:, j] + alpha*p[i, :]*err                      # update whole row and column\n    print(np.dot(p, q)) \n    p = p*np.sqrt(np.max(X))                         # matrix multiplication rule for normalized values\n    q = q*np.sqrt(np.max(X))                         # matrix multiplication rule for normalized values\n    return (p,q)   ","execution_count":null,"outputs":[]},{"metadata":{"id":"W7yDrZ_Ly0A0","trusted":true},"cell_type":"code","source":"#p,q = Gradient_Descent(X_sparse)","execution_count":null,"outputs":[]},{"metadata":{"id":"gypo7lEby0A3","outputId":"7c965013-e287-4183-96b0-d748dc16f1f5","trusted":true},"cell_type":"code","source":"#Loading both of the arrays\nimport numpy as np\np = np.load(\"../input/user-matrix/P_100.npy\")\nq = np.load(\"../input/user-matrix/Q_100.npy\")\nu = np.dot(p,q)\nu","execution_count":null,"outputs":[]},{"metadata":{"id":"LCmb4D-1CG-G","outputId":"d7ad4d03-decb-4372-a9b5-0c3a25011066","trusted":true},"cell_type":"code","source":"u.mean()","execution_count":null,"outputs":[]},{"metadata":{"id":"we3S6g7Si6nH"},"cell_type":"markdown","source":"### Great! Now we have a matrix with all the entries filled . We'll treat both the assigned values and the user-given values the same way without any distinction.\n\nThere is a problem, though... \n\nLet's see what the values of a well-known anime are. In this case let's take FullMetal Alchemist.","execution_count":null},{"metadata":{"id":"dLku4CgRlM3Z","outputId":"5fb3806c-f1b9-40b0-c911-c8c741d48af9","trusted":true},"cell_type":"code","source":"anime.loc[anime.name == 'Fullmetal Alchemist: Brotherhood']","execution_count":null,"outputs":[]},{"metadata":{"id":"olUC2cKkll20","outputId":"df570d6d-0e44-4a43-832e-29be6bfec985","trusted":true},"cell_type":"code","source":"np.where(anime_id_list == 5114 )","execution_count":null,"outputs":[]},{"metadata":{"id":"fhpFPm7Zltps","outputId":"885a9d97-601b-4f56-ddcd-0c5ce70277f9","trusted":true},"cell_type":"code","source":"print('The mean is: ',u[:,3936].mean())\nprint('The standard deviation is: ',u[:,3936].std())","execution_count":null,"outputs":[]},{"metadata":{"id":"UJ9KIilgl35h"},"cell_type":"markdown","source":"Some animes have means greater than 9 (with low standard deviation). That means that the algorithm will consistently choose these animes as top recomendations just because their overall scores are so high (as we will see when I show the full algorithm).\n\nTo solve this, I chose to reduce the values of the animes with mean greater than 9 and greater than 8 by using a weighted mean with those values and the mean of all the animes to give a chance for the lower rated ones to compete. Of course we need to reduce the ratings of the >9-mean animes more than the >8 animes.\n","execution_count":null},{"metadata":{"id":"mnxwaV2m4F_7","trusted":true},"cell_type":"code","source":"#function to reduce the ratings of the best rated anime\ndef squeezing_top_values(u):\n  p1 = 9        # paremeter to reduce the greater than 9-mean animes\n  p2 = 200      # paremeter to reduce the greater than 8 and lower than 9 mean animes\n  index1 = np.where(u.mean(axis=0)>9)\n  index2 = np.where((u.mean(axis=0)>8) & (u.mean(axis=0)<9))\n  k = u.mean()\n  for i in index1:\n    u[:,i] = (u[:,i]*p1 + k)/(p1+1)\n  for i in index2:\n    u[:,i] = (u[:,i]*p2 + k)/(p2+1)\n  return u\n\n\nu = squeezing_top_values(u)    \n","execution_count":null,"outputs":[]},{"metadata":{"id":"NTzKsNorm90-","outputId":"814385fb-4ee8-4481-a974-7adfb81e7e8a","trusted":true},"cell_type":"code","source":"# Now we have:\nprint('The mean now is: ',u[:,3936].mean())\nprint('The standard deviation now is: ',u[:,3936].std())\n\n#That's better!","execution_count":null,"outputs":[]},{"metadata":{"id":"FMGCyJwJy0A9"},"cell_type":"markdown","source":"### Let's assign the user input to a vector\n","execution_count":null},{"metadata":{"id":"8MFRsQyHy0A-","trusted":true},"cell_type":"code","source":"''' This function takes the names and the ratings of the animes given \nby the new user and transforms them to the correct form such that the algorithm\nwill understand\n'''\n\ndef user_input_scores(array):\n    a = []\n    scores = []\n    for i in range(0,len(array)):\n        a.append(anime.loc[anime.name == array[i][0]].anime_id.values[0]) \n    a = np.array(a)\n    \n    for i in range(0,len(anime_id_list) - len(array)):\n        scores.append(0)\n    \n    for i in range(0,len(a)):\n        index = np.where(anime_id_list == a[i])[0][0]\n        scores.insert(index,array[i][1])\n    scores = np.array(scores)\n    return scores\n","execution_count":null,"outputs":[]},{"metadata":{"id":"VYiC0_DboNKE"},"cell_type":"markdown","source":"### I've written a few customized lists of well known animes to test if the given recomendations make sense.","execution_count":null},{"metadata":{"id":"ysvh_RRN85M9","trusted":true},"cell_type":"code","source":"# shonen\ny1 = [('Death Note',8),('Naruto',10),('Hunter x Hunter (2011)',9)]\n# sports\ny2 = [('Haikyuu!!',10),('Diamond no Ace',10)]\n\n# Slice of Life\ny3 = [('Toradora!',10),('Mob Psycho 100',10),('Suzumiya Haruhi no Yuuutsu',9)]\n\n# Mecha\ny4 = [('Code Geass: Hangyaku no Lelouch',10),('Neon Genesis Evangelion',10),('Guilty Crown',9)]\n\n# Music\ny5 = [('Shigatsu wa Kimi no Uso',9),('K-On!',10)]\n\n#Kids\ny6 = [('Pokemon',10),('Digimon Adventure',10)]","execution_count":null,"outputs":[]},{"metadata":{"id":"7mqi6KuNy0BA"},"cell_type":"markdown","source":"### Finally, below are all the functions needed to finish the recomendation process. The way that the recomendations will be given is as follows:\n\nFirst, we'll use the KMeans algorithm to Cluster our users and see in which group our new user will be assigned to. To understand this in a high level you could think that the clustering will divide the users between the ones who like more shonen, the ones who like more sports animes and so on...\n\nThen, we'll know the similar users with our new user.\n\n Based on that we'll take the mean of all the animes ratings of those viewers and the recomended shows will be the ones with the highest means, simple isn't it?\n\n\n","execution_count":null},{"metadata":{"id":"TsVWudufsT4E","trusted":true},"cell_type":"code","source":"#Function to determine the positions of the animes that the user has seen:\n\ndef position_seen_animes(y):\n  scores = user_input_scores(y)\n  position = np.where(scores!=0)[0]\n  return position\n\n# Function to create an array from the users matrix with only the animes the new user has seen\n\ndef user_scores_seen_animes(X,y):\n  positions = position_seen_animes(y)\n  return X[:,positions]\n\n#Function to apply Kmeans algorithm to get similar viewers\n\ndef similar_users_position(X,y):\n  \n  n_clusters = 8 ### The best number after exhaustive tests\n\n  X_transformed = user_scores_seen_animes(X,y)\n  y_transformed = user_input_scores(y)[position_seen_animes(y)].reshape(1,-1)\n  kmeans = KMeans(n_clusters = n_clusters).fit(X_transformed)\n  group = kmeans.predict(y_transformed)\n    \n  (array_labels,n_labels) = np.unique(kmeans.labels_,return_counts = True) #test to see if the clustering was well done\n  #print(n_labels,group) -- test to see if the clustering was well done\n  similar_user_position = np.where(kmeans.labels_ == group)[0]\n  return similar_user_position\n\n\n#Function to take the mean scores of the similar users in order to rank the animes\n\ndef mean_scores(X,y):\n  similar_users_scores = []\n  \n  index = similar_users_position(X,y) #similar users positions on the user matrix\n  scores = np.zeros(len(anime_id_list)) #inicializing \n\n  for i in index:\n    similar_users_scores.append(X[i])\n\n  similar_users_scores = np.array(similar_users_scores)\n\n  mean_scores = similar_users_scores.sum(axis = 0)/similar_users_scores.shape[0] # Getting the mean_scores\n\n  return mean_scores\n\n#Function to determine the positions of the best rated shows\n\ndef best_rated_shows(X,y):\n  mean_marks = mean_scores(X,y)\n  index = np.flip(anime_id_list[np.argsort(mean_marks)[-10:]]) ### Choose how many recommendations will be displayed\n  return index\n\n#Function to determine the names of the best rated shows\n\ndef names_best_rated_shows(X,y):\n  index = best_rated_shows(X,y)\n  print('The best recommendations for you are:\\n')\n  for i in index:\n        print(anime.loc[anime.anime_id == i,['name']].values[0][0])\n        print('')\n\n\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"ooDtlyr7PD9R"},"cell_type":"markdown","source":"## We're good to go to use our algorithm! Let's print the recommendations for different types of users!","execution_count":null},{"metadata":{"id":"1rwv13Mk2lQN","outputId":"1112c385-a21d-4ca5-f62a-764538c49137","trusted":true},"cell_type":"code","source":"# Shonen\nr1 = names_best_rated_shows(u,y1)","execution_count":null,"outputs":[]},{"metadata":{"id":"CbnDjnd1ma2Q","outputId":"5fb7d511-b26a-4bfc-9968-e9318e6ddb8a","trusted":true},"cell_type":"code","source":"# Sport\nr2 = names_best_rated_shows(u,y2)","execution_count":null,"outputs":[]},{"metadata":{"id":"uJll19OcnISd","outputId":"11daee08-1c48-4d63-a372-0ca569914067","trusted":true},"cell_type":"code","source":"# Slice of life\nr3 = names_best_rated_shows(u,y3)","execution_count":null,"outputs":[]},{"metadata":{"id":"tq8cjtCKSM14","outputId":"5834d099-ec0c-478c-aabb-ee96c828537e","trusted":true},"cell_type":"code","source":"# Mecha\nr4 = names_best_rated_shows(u,y4) ","execution_count":null,"outputs":[]},{"metadata":{"id":"hdmq4sraSbSb","outputId":"a0b937c9-b1cb-4bf8-c69f-c35e4726278e","trusted":true},"cell_type":"code","source":"# Music\nr5 = names_best_rated_shows(u,y5)","execution_count":null,"outputs":[]},{"metadata":{"id":"waZWiJMxSseb","outputId":"49714c87-a436-4a37-d863-7ec9f4524e47","trusted":true},"cell_type":"code","source":"# Kids\nr6 = names_best_rated_shows(u,y6)","execution_count":null,"outputs":[]},{"metadata":{"id":"ozruxzTTVtIu"},"cell_type":"markdown","source":"### Considerations and Future Work\n\n* The algorithm is quite sensitive to changes in the scores entered by the user and works best with few animes (1-3) and high scores (>8)\n\n* The algorithm could improve if other factors are considered, such as the genre and the watched but not rated animes\n\n### Thanks a lot for your time reading this Notebook! Feel free to message me!","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}