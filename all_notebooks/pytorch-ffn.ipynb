{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Imports","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.preprocessing import scale\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Regression","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Loading into dataframe","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/appliances-energy-prediction/KAG_energydata_complete.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Little EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['Appliances'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train, Test, Val split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(labels='date', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = train_test_split(df, test_size=0.3, shuffle=True, random_state=42)\ntest, val = train_test_split(df, test_size=0.5, shuffle=True, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preparing Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, df):\n        self.X = torch.tensor(scale(df.drop(labels='Appliances', axis=1)).astype(np.float32)).to(device)\n        self.y = torch.tensor(df['Appliances'].values.astype(np.float32)).to(device)\n        \n    def __len__(self):\n        return len(self.y)\n    \n    def __getitem__(self, index):\n        return {'X': self.X[index], 'y': self.y[index]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainD = CustomDataset(train.reset_index(drop=True))\ntestD = CustomDataset(test.reset_index(drop=True))\nvalD = CustomDataset(val.reset_index(drop=True))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dataloaders","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"trainDL = DataLoader(trainD, batch_size=32, shuffle=True, num_workers=2)\ntestDL = DataLoader(testD, batch_size=32, num_workers=2)\nvalDL = DataLoader(valD, batch_size=32, num_workers=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feed Forward Network","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class FeedForwardNet(nn.Module):\n    def __init__(self):\n        super(FeedForwardNet, self).__init__()\n        self.input_layer = nn.Linear(27, 80)\n        self.hidden1 = nn.Linear(80, 40)\n        nn.init.xavier_uniform_(self.hidden1.weight)\n        self.sigmoid = nn.Sigmoid()\n        self.dropout = nn.Dropout()\n        self.batchnorm1 = nn.BatchNorm1d(40)\n        self.hidden2 = nn.Linear(40, 12)\n        self.output = nn.Linear(12, 1)\n        \n    def forward(self, x):\n        x = self.input_layer(x)\n        x = self.batchnorm1(self.sigmoid(self.hidden1(x)))\n        x = self.dropout(self.sigmoid(self.hidden2(x)))\n        x = self.output(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = FeedForwardNet()\nmodel = model.to(device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loss Function & Optimizer","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_function = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def trainer(epochs, trainDL, valDL, model, loss_function, optimizer):\n    for epoch in range(epochs):\n        for i, data in enumerate(trainDL):\n            model.train()\n            output = model(data['X'])\n            t_loss = loss_function(output, data['y'].view(-1, 1))\n            optimizer.zero_grad()\n            t_loss.backward()\n            optimizer.step()\n            \n            v_loss = 0\n            with torch.no_grad():\n                model.eval()\n                for j, data in enumerate(valDL):\n                    loss = loss_function(model(data['X']), data['y'].view(-1, 1))\n                    v_loss += loss.item()\n            print(f\"Epoch: {epoch+1}, Batch: {i+1}, Training Loss: {str(round(t_loss.item(), 2))}, Validation Loss: {str(round(v_loss/j, 2))}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainer(5, trainDL, valDL, model, loss_function, optimizer)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def tester(testDL, model, loss_function):\n    model.eval()\n    total_loss = 0\n    for i, data in enumerate(testDL):\n        loss = loss_function(model(data['X']), data['y'].view(-1, 1))\n        total_loss += loss.item()\n    print(f\"Total Loss: {total_loss/i}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### To Improve Accuracy\n\n0. Initial Accuracy = 9482.92\n1. Standardize dataset (mean 0, standard deviation = 1) = 8597.80\n2. Activation function for Non-Linearity (tanh, sigmoid, RELU) = slow convergence\n3. Dropout = slower processing speed, slower convergence\n4. Batch Normalization = Faster convergence. Order = neuron layer -> activation -> batchnorm\n5. Weight Initialization\n6. Adjust Hyperparameters (like learning rate, epochs, optimizer parameters)\n\nNOTE: Don't put Dropout and Batch Normalization together\n\nSlower convergence doesn't mean it's bad. Maybe it's more regularized, so less overfitting","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Classification","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Loading into DataFrame","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/diabetes/diabetes.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Little EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train, Test, Val split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = train_test_split(df, test_size=0.2, shuffle=True, random_state=42)\ntest, val = train_test_split(test, test_size=0.5, shuffle=True, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preparing Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, df):\n        self.X = torch.tensor(scale(df.drop(labels='Outcome', axis=1)).astype(np.float32)).to(device)\n        self.y = torch.tensor(df['Outcome'].values, dtype=torch.long).to(device)\n        \n    def __len__(self):\n        return len(self.y)\n    \n    def __getitem__(self, index):\n        return {'X': self.X[index], 'y': self.y[index]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainD = CustomDataset(train.reset_index(drop=True))\ntestD = CustomDataset(test.reset_index(drop=True))\nvalD = CustomDataset(val.reset_index(drop=True))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### DataLoaders","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"trainDL = DataLoader(trainD, batch_size=16, shuffle=True)\nvalDL = DataLoader(valD, batch_size=16)\ntestDL = DataLoader(testD, batch_size=16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feed Forward Network","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class FFN(nn.Module):\n    def __init__(self):\n        super(FFN, self).__init__()\n        self.input = nn.Linear(8, 20)\n        self.hidden1 = nn.Linear(20, 6)\n        nn.init.xavier_uniform_(self.hidden1.weight)\n        self.sigmoid = nn.Sigmoid()\n        self.batchnorm = nn.BatchNorm1d(6)\n        self.output = nn.Linear(6, 2)\n        \n    def forward(self, x):\n        x = self.input(x)\n        x = self.batchnorm(self.sigmoid(self.hidden1(x)))\n        x = self.output(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = FFN()\nmodel = model.to(device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loss function & Optimizer","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_function = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def trainer(epochs, trainDL, valDL, model, optimizer, loss_function):\n    for epoch in range(epochs):\n        for i, data in enumerate(trainDL):\n            model.train()\n            output = model(data['X'])\n            t_loss = loss_function(output, data['y'])\n            optimizer.zero_grad()\n            t_loss.backward()\n            optimizer.step()\n            \n            with torch.no_grad():\n                v_loss = 0\n                model.eval()\n                for j, data in enumerate(valDL):\n                    loss = loss_function(model(data['X']), data['y'])\n                    v_loss += loss.item()\n            print(f\"Epoch: {epoch+1}, Batch: {i+1}, Training Loss: {str(round(t_loss.item(), 2))}, Validation Loss: {str(round(v_loss/j, 2))}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainer(10, trainDL, valDL, model, optimizer, loss_function)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def tester(model, testDL):\n    model.eval()\n    total = 0\n    correct = 0\n    for i, data in enumerate(testDL):\n        output = model(data['X'])\n        values, indices = torch.max(output.data, 1)\n        total += data['y'].size(0)\n        correct += (indices == data['y']).sum().item()\n    print(f\"Accuracy: {(correct/total)*100}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tester(model, testDL)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}