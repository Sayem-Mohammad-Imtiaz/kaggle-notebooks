{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nplt.style.use(\"seaborn-whitegrid\")\n\nimport seaborn as sns\nfrom collections import Counter\n\n\nfrom keras.layers.core import Dense, Activation, Dropout\nfrom keras.layers.recurrent import LSTM\nfrom keras.models import Sequential\nimport time\nfrom sklearn.preprocessing import MinMaxScaler\nfrom numpy import newaxis\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tcs_df = pd.read_csv('/kaggle/input/tcs-stock-data/TCS.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tcs_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tcs_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tcs_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tcs_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tcs_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tcs_df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.heatmap(tcs_df.corr(), cmap=\"YlGnBu\", annot= True,)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set()\n# plt.figure(figsize = (8, 5))\nplt.title('High Stockprice Distribution')\nsns.distplot(tcs_df['High'], color='orange')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set()\n# plt.figure(figsize = (8, 5))\nplt.title('Low Stockprice Distribution')\nsns.distplot(tcs_df['Low'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tcs_stock_volume = tcs_df.Volume.values.astype('float32')\ntcs_stock_volume = tcs_stock_volume.reshape(504, 1)\ntcs_stock_volume.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nplt.title('Volume History')\nplt.plot(tcs_df['Volume'])\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Volume Price USD ($)', fontsize=18)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nplt.title('Close Price History')\nplt.plot(tcs_df['Close'])\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Close Price USD ($)', fontsize=18)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tcs_df.hist(figsize=(12, 12));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tcs_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tcs_df_new=tcs_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ma_day = [10, 20, 50]\n\nfor ma in ma_day:\n    column_name = f\"MA for {ma} days\"\n    tcs_df_new[column_name] = tcs_df_new['Close'].rolling(ma).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tcs_df_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(2,2)\nfig.set_figheight(8)\nfig.set_figwidth(15)\n\ntcs_df_new[['Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[0,0])\n#axes[0,0].set_title('TCS')\n\nfig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tcs_df['Daily Return'] = tcs_df['Close'].pct_change()\n\n# Then we'll plot the daily return percentage\nfig, axes = plt.subplots(nrows=2, ncols=2)\nfig.set_figheight(8)\nfig.set_figwidth(15)\n\ntcs_df['Daily Return'].plot(ax=axes[0,0], legend=True, linestyle='--', marker='o')\naxes[0,0].set_title('TCS')\n\nfig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Comparing Google to itself should show a perfectly linear relationship\nsns.jointplot('Close', 'Close', tcs_df, kind='scatter', color='seagreen')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(tcs_df, kind='reg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a new dataframe with only the 'Close column \ndata = tcs_df.filter(['Close'])\n# Convert the dataframe to a numpy array\ndataset = data.values\n# Get the number of rows to train the model on\ntraining_data_len = int(np.ceil( len(dataset) * .95 ))\n\ntraining_data_len","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range=(0,1))\nscaled_data = scaler.fit_transform(dataset)\n\nscaled_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the training data set \n# Create the scaled training data set\ntrain_data = scaled_data[0:int(training_data_len), :]\n# Split the data into x_train and y_train data sets\nx_train = []\ny_train = []\n\nfor i in range(60, len(train_data)):\n    x_train.append(train_data[i-60:i, 0])\n    y_train.append(train_data[i, 0])\n    if i<= 61:\n        print(x_train)\n        print(y_train)\n        print()\n        \n# Convert the x_train and y_train to numpy arrays \nx_train, y_train = np.array(x_train), np.array(y_train)\n\n# Reshape the data\nx_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n# x_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, LSTM\n\n# Build the LSTM model\nmodel = Sequential()\nmodel.add(LSTM(128, return_sequences=True, input_shape= (x_train.shape[1], 1)))\nmodel.add(LSTM(64, return_sequences=False))\nmodel.add(Dense(25))\nmodel.add(Dense(1))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# Train the model\nmodel.fit(x_train, y_train, batch_size=1, epochs=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the testing data set\n# Create a new array containing scaled values from index 1543 to 2002 \ntest_data = scaled_data[training_data_len - 60: , :]\n# Create the data sets x_test and y_test\nx_test = []\ny_test = dataset[training_data_len:, :]\nfor i in range(60, len(test_data)):\n    x_test.append(test_data[i-60:i, 0])\n    \n# Convert the data to a numpy array\nx_test = np.array(x_test)\n\n# Reshape the data\nx_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))\n\n# Get the models predicted price values \npredictions = model.predict(x_test)\npredictions = scaler.inverse_transform(predictions)\n\n# Get the root mean squared error (RMSE)\nrmse = np.sqrt(np.mean(((predictions - y_test) ** 2)))\nrmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the data\ntrain = data[:training_data_len]\nvalid = data[training_data_len:]\nvalid['Predictions'] = predictions\n# Visualize the data\nplt.figure(figsize=(16,8))\nplt.title('Model')\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Close Price USD ($)', fontsize=18)\nplt.plot(train['Close'])\nplt.plot(valid[['Close', 'Predictions']])\nplt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}