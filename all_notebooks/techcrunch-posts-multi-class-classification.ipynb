{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"8a7c8523-2ab0-8937-4c56-d7650b91a1fc"},"source":"In this notebook I search the best classifier and its parameters for posts multi-class classifications based on authorship attributes"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1a12924b-89df-82f7-8b0b-92443009d411"},"outputs":[],"source":"import pandas as pd\nfrom pandas import Series,DataFrame\nimport numpy as np"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b2fd0057-0555-56e7-c1db-f8680d8c2ba2"},"outputs":[],"source":"#data\ndf=pd.read_csv('../input/techcrunch_posts.csv')"},{"cell_type":"markdown","metadata":{"_cell_guid":"f6476422-bd65-da07-2e0a-5bd825fe2e13"},"source":"The experiment is very time consuming due to the size of of the data set. That's why I choose only 4 authors as an example and only 200 posts per author. The more posts the higher score. You can review  [here][1] the same analysis for 2000 posts and compare results. The score is higher but the rank of classifiers is the same.\n\n\n  [1]: https://github.com/KaterynaD/TechcrunchPostsMulticlassPostsClassification/blob/master/TechCrunch%2BPosts%2B%25282000%2529%2BMulti-class%2BClassification%2B.ipynb"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a9e8cbe0-419e-82f4-1f97-f42c94ff3bc2"},"outputs":[],"source":"pd.DataFrame(df.groupby('authors').size().rename('counts')).sort_values('counts', ascending=False).head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8eae1801-1b3a-dc39-d4db-53327f921e07"},"outputs":[],"source":"authors=['Sarah Perez','Anthony Ha','Darrell Etherington','Jordan Crook']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d4e5c86e-fbcc-b7bd-cf1a-26ac9d86f50e"},"outputs":[],"source":"df=df[df['authors'].isin(authors)].ix[:,['authors','content']]\ndf.rename(columns={'authors':'author'}, inplace=True)\nlen(df)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"332f715c-bc52-982d-bc2f-a26c2e9ca576"},"outputs":[],"source":"import random\nfrom sklearn.model_selection import train_test_split\n#200 random sample rows for each author\ndf_new=pd.DataFrame()\nposts_train=pd.DataFrame()\nposts_test=pd.DataFrame()\nauthor_train=pd.DataFrame()\nauthor_test=pd.DataFrame()\nfor a in df.author.unique():\n    rows = random.sample(list(df[df['author']==a].index), 200)\n    df_temp = df.ix[rows]\n    df_new=df_new.append(df_temp,ignore_index=True)    \n    X_train, X_test, Y_train, Y_test = train_test_split(df_temp.ix[:,['content']], df_temp.ix[:,['author']], test_size=0.3, random_state=42)\n    posts_train=posts_train.append(X_train, verify_integrity=False)\n    posts_test=posts_test.append(X_test, verify_integrity=False)\n    author_train=author_train.append(Y_train, verify_integrity=False)\n    author_test=author_test.append(Y_test, verify_integrity=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"430c6636-1cf7-48c4-3188-4846cbaecf69"},"source":"Train set:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a6da5237-c76e-6c9e-06ab-847d4b11cbde"},"outputs":[],"source":"print (len(posts_train),len(author_train))"},{"cell_type":"markdown","metadata":{"_cell_guid":"926ad8d1-6bd2-ff8a-b4e3-3c4836a1907a"},"source":"Test set:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"29fea3d3-7d1c-eeac-b64e-fc0580f094e3"},"outputs":[],"source":"print(len(posts_test),len(author_test))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fc2de7fb-aca4-e93c-f25e-353b84270259"},"outputs":[],"source":"from nltk.tokenize import RegexpTokenizer\nfrom nltk.stem.porter import PorterStemmer\ndef text_process(text):\n    \"\"\"\n    Takes in a string of text, then performs the following:\n    1. Tokenizes and removes punctuation\n    3. Stems\n    4. Returns a list of the cleaned text\n    \"\"\"\n\n    # tokenizing\n    tokenizer = RegexpTokenizer(r'\\w+')\n    text_processed=tokenizer.tokenize(text)\n    \n    \n    # steming\n    porter_stemmer = PorterStemmer()\n    \n    text_processed = [porter_stemmer.stem(word) for word in text_processed]\n    \n\n    return text_processed"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9bb4fbb4-7be0-4d1c-a5e8-0b2036c917d2"},"outputs":[],"source":"ScoreSummaryByModelParams=list()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a1178997-c15d-a09b-31fa-6833d91e9085"},"outputs":[],"source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7e5e8366-6fd3-e466-24ee-b39e839dea5e"},"outputs":[],"source":"def ModelParamsEvaluation (f_union,model,params,comment):\n    pipeline = Pipeline([\n    # Extract the text & text_coded\n    # Use FeatureUnion to combine the features from different vectorizers\n    ('union', f_union),\n    # Use a  classifier on the combined features\n    ('clf', model)\n    ])\n    grid_search = GridSearchCV(estimator=pipeline, param_grid=params, verbose=1)\n    grid_search.fit(posts_train['content'], author_train['author'])\n    #best score\n    print(\"Best score: %0.3f\" % grid_search.best_score_)\n    print(\"Best parameters set:\")\n    best_parameters = grid_search.best_estimator_.get_params()\n    for param_name in sorted(params.keys()):\n        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n        ScoreSummaryByModelParams.append([comment,grid_search.best_score_,\"\\t%s: %r\" % (param_name, best_parameters[param_name])])    "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"100df8ca-7235-4b10-4a43-54a49bb69ada"},"outputs":[],"source":"f2_union=FeatureUnion(\n        transformer_list=[\n            # Pipeline for pulling char features  from the text\n            ('char', Pipeline([\n                ('tfidf',     TfidfVectorizer(analyzer='char',ngram_range=(3, 3))),\n            ])),\n            # Pipeline for pulling stememd word features from the text\n            ('text', Pipeline([\n                ('tfidf',    TfidfVectorizer(analyzer='word',tokenizer= text_process,ngram_range=(1, 1))),\n            ])),        \n\n        ],\n\n    )"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2f54d0b1-6b30-5e40-914b-201ad6a276e4"},"outputs":[],"source":"from sklearn.svm import LinearSVC\n#LinearSVC\np = {'clf__C': (1,0.1,0.01,0.001,0.0001)}\nModelParamsEvaluation(f2_union,LinearSVC(),p,'LinearSVC')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"97f73ccd-fb04-418e-d93a-5c34f46a54e8"},"outputs":[],"source":"from sklearn.svm import SVC\np = {'clf__C': (1,0.1,0.01,0.001,0.0001)}\nModelParamsEvaluation(f2_union,SVC(kernel='linear'),p,'SVC, linear kernel')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f0824915-cebd-97e6-d046-77c6e508fb51"},"outputs":[],"source":"from sklearn.linear_model import SGDClassifier\np = {'clf__alpha': (0.01,0.001,0.0001,0.00001, 0.000001),\n    'clf__penalty': ('l1','l2', 'elasticnet')}\nModelParamsEvaluation (f2_union,SGDClassifier(),p,'SGD Classifier')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6d9dd98c-a832-8102-ef37-06f11db47619"},"outputs":[],"source":"from sklearn.naive_bayes import BernoulliNB\np = {'clf__alpha': (1,0.1,0.01,0.001,0.0001,0)}\nModelParamsEvaluation(f2_union,BernoulliNB(),p,'Bernoulli Naive Bayes')"},{"cell_type":"markdown","metadata":{"_cell_guid":"a3c6d48e-3b7e-8aa2-cd0d-23d06c0d8461"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b3bfdb54-6fb1-91de-3dd4-f671e7d3b3a1"},"outputs":[],"source":"df_ScoreSummaryByModelParams=DataFrame(ScoreSummaryByModelParams,columns=['Method','BestScore','BestParameter'])\ndf_ScoreSummaryByModelParams.sort_values(['BestScore'],ascending=False,inplace=True)\ndf_ScoreSummaryByModelParams"},{"cell_type":"markdown","metadata":{"_cell_guid":"066ba3e4-fc47-4720-8616-870ec70d398a"},"source":"The best method is LinearSVC(C=1). The worse is BernoulliNB(alpha=0.1). There is a difference between binary and multi-class classifications. Bernoulli Naive Bayes has the same or better scores then LinearSVC etc\nSVC with the linear kernel shows worse result then LinearSVC. This is also different from binary classification. LinearSVC uses \"one-vs-rest\" (default) and SVC uses \"one-vs-one\" for multi-class. And SGDClassifier uses \"one-vs-all\" for multi-class classification"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d09d1329-d1de-de2c-b110-c3703f9f1d34"},"outputs":[],"source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8150dff6-8154-57ff-982d-2404925bd7db"},"outputs":[],"source":"ScoreSummaryByVector = list()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"38c5681d-c606-6b1c-bba1-8717a5c26a3d"},"outputs":[],"source":"def PredictionEvaluation(author_test_b,author_predicted_b,target_names,comment):\n    Accuracy=accuracy_score(author_test_b,author_predicted_b)\n    Recall=recall_score(author_test_b, author_predicted_b, labels=[0,1,2,3], average='macro')\n    Precision=precision_score(author_test_b, author_predicted_b, labels=[0,1,2,3], average='macro')\n    F1=f1_score(author_test_b, author_predicted_b, labels=[0,1,2,3], average='macro')\n    ScoreSummaryByVector.append([Accuracy,Recall,Precision,F1,comment])\n    print(classification_report(author_test_b, author_predicted_b, target_names=target_names))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cc03a30c-e9e1-4f3d-10f8-f74a902f9f83"},"outputs":[],"source":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport itertools"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5375eb8e-a8d6-559e-cec8-7fb4483163d6"},"outputs":[],"source":"#http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6967cca9-a8ae-7583-27e1-f347fe2fb0c9"},"outputs":[],"source":"def ModelRun (f_union,model):\n    pipeline = Pipeline([\n    # Extract the text & text_coded\n    # Use FeatureUnion to combine the features from different vectorizers\n    ('union', f_union),\n    # Use a  classifier on the combined features\n    ('clf', model)\n    ])\n    \n    pipeline.fit(posts_train['content'], author_train['author'])\n    \n    author_predicted = pipeline.predict(posts_test['content'])\n    \n    feature_names=list()\n    for p in (pipeline.get_params()['union'].transformer_list):\n        fn=(p[0],pipeline.get_params()['union'].get_params()[p[0]].get_params()['tfidf'].get_feature_names())\n        feature_names.append(fn)\n    df_fn=pd.DataFrame()\n    for fn in feature_names:\n        df_fn= df_fn.append(pd.DataFrame(\n        {'FeatureType': fn[0],\n         'Feature': fn[1]\n        }),\n        ignore_index=True)    \n    \n    from sklearn.preprocessing import LabelBinarizer\n    lb = LabelBinarizer()\n    author_test_b = lb.fit_transform(author_test['author'])\n    author_predicted_b  = lb.fit_transform(author_predicted)\n    return (df_fn,pipeline.get_params()['clf'],author_predicted,author_predicted_b, author_test_b)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c3f1a41f-4e9e-a079-9ffe-fe4fb67036da"},"outputs":[],"source":"(feature_names,clf,author_predicted,author_predicted_b, author_test_b)=ModelRun(f2_union,BernoulliNB(alpha=0.0001))\ntarget_names=clf.classes_"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c09ba21d-97b2-b806-7b53-119efc979a3c"},"outputs":[],"source":"PredictionEvaluation(author_predicted_b, author_test_b,target_names,'BernoulliNB(alpha=0.0001)')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9ec328c6-fd44-bdfc-f84c-6fbacfade4ac"},"outputs":[],"source":"plot_confusion_matrix(confusion_matrix(author_test['author'], author_predicted), target_names,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d54830c8-07a7-f508-c1f3-270b959e1590"},"outputs":[],"source":"(feature_names,clf,author_predicted,author_predicted_b, author_test_b)=ModelRun(f2_union,LinearSVC(C=1))\ntarget_names=clf.classes_"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c0ef8432-edcc-18c7-ad38-4455c6a26b2a"},"outputs":[],"source":"PredictionEvaluation(author_predicted_b, author_test_b,target_names,'LinearSVC(C=1)')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"27648561-5fc9-84f0-a889-ac174f25a510"},"outputs":[],"source":"plot_confusion_matrix(confusion_matrix(author_test['author'], author_predicted), target_names,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d55c4ab9-813b-bb84-b55a-0e2d517f219a"},"outputs":[],"source":"df_ScoreSummaryByVector=DataFrame(ScoreSummaryByVector,columns=['Precision','Accuracy','Recall','F1','Comment'])\ndf_ScoreSummaryByVector.sort_values(['F1'],ascending=False,inplace=True)\ndf_ScoreSummaryByVector"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}