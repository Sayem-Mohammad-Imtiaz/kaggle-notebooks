{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style('darkgrid')\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/sf-employee-compensation/employee-compensation.csv')\ndf = df.sample(frac=1).reset_index(drop=True) # shuffle data so train and test can have same categorical variables\ndf = df[:50000]\nprint(df.shape)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Exploration ###"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['Department', 'Job'], axis=1, inplace=True) # 'Department' and 'Job' are basically duplicates for 'Department Code' and 'Job Code'\n\n## aggregators for 'Total Compensation', get near perfect prediction accuracy if include all of them ##\n## keep benefit columns only ##\n# 'Salaries' + 'Overtime' + 'Other Salaries' = 'Total Salary' \n# 'Retirement' + 'Health and Dental' + 'Other Benefits' = 'Total Benefits'\n# 'Total Salary' + 'Total Benefits' = 'Total Compensation'\ndf.drop(['Salaries', 'Overtime', 'Other Salaries', 'Total Salary', 'Total Benefits'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.boxplot(x=\"Year Type\", y=\"Total Compensation\", data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Year doesn't really provide any insight on Total Compensation."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nax = sns.boxplot(x=\"Organization Group\", y=\"Total Compensation\", data=df)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Public Protection has the highest average salaries, sitting nicely at $120,000. \n\nGeneral City Responsibilities and Culture & Recreation seem to be the worst with the average sitting slightly above $0."},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing Setup"},{"metadata":{"trusted":true},"cell_type":"code","source":"object_cols = [col for col in df.columns if df[col].dtype == object]\nnum_cols = [col for col in df.columns if df[col].dtype in [float, int]]\n\nnum_cols.remove('Total Compensation') # y-variable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"object_col_cnts = {col: df[col].nunique() for col in object_cols}\nobject_col_cnts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\n\nX_cols = [col for col in df.columns if col != 'Total Compensation'] # remove output variable\n\nX = df[X_cols]\ny = df['Total Compensation']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n\n## Remove cols from X_train and X_test where categorical values not contained in train and test set ##\nbad_lbl_cols = [col for col in object_cols if list(set(X_train[col]) - set(X_test[col]))]\nbad_lbl_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_cols = [col for col in X_cols if col not in bad_lbl_cols]\nX_train = X_train.drop(bad_lbl_cols, axis=1)\nX_test = X_test.drop(bad_lbl_cols, axis=1)\nobject_cols = [x for x in object_cols if x not in bad_lbl_cols]\nobject_cols","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One hot encode 'Year Type' and 'Organization Group' since there aren't many unique values. However, convert the rest using Label Encoding. "},{"metadata":{"trusted":true},"cell_type":"code","source":"OH_cols = [k for k,v in object_col_cnts.items() if v <= 10] # only OHE variables w/ less than 10 unique values per column\nLE_cols = list(set(object_cols) - set(OH_cols))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Build Pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer, OrdinalEncoder \nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n\nnumerical_transformer = SimpleImputer(missing_values=np.nan, strategy='mean')\n\n# two steps: \n# (1) Fill in missing values using SimpleImputer\n# (2) One Hot Encode the variables, creating new columns for each unique type\nOH_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n                                 ('one_hot', OneHotEncoder(handle_unknown='ignore', sparse=False)) # ignore errors when calling 'transform', sparse=False returns np.array\n])\n\n# Same as OH_transformer except using LabelEncoder instead --> high-cardinality columns\nLE_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n                                 ('lbl_enc', OrdinalEncoder())\n])\n\n# Bundle preprocessing for numerical and two categorical groups data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, num_cols),\n        ('oh', OH_transformer, OH_cols),\n        ('le', LE_transformer, LE_cols),\n    ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import GradientBoostingRegressor\n\n# list of models to evaluate\nmodels = {'Random Forest': RandomForestRegressor(n_estimators=100, random_state=0),\n          'KNN': KNeighborsRegressor(),\n          'Linear Regression': LinearRegression(),\n          'Gradient Boost': GradientBoostingRegressor(random_state=0)\n         }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\n\nmodel_mse = {}\nmodel_adj_r2 = {}\n\nfor name, model in models.items():\n    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n                           ('regressor', model)])\n    pipe.fit(X_train, y_train)   \n    y_pred = pipe.predict(X_test)\n\n    model_adj_r2[name] = round(pipe.score(X_test, y_test), 3)\n    model_mse[name] = mean_absolute_error(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_adj_r2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_mse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"By just including the 3 individual benefit columns, many of the models perform very well. We can safely assume benefits are a strong predictors of Total Compensation. [](http://)"},{"metadata":{},"cell_type":"markdown","source":"### Pipe #2\n\nNext let's try removing all of the benefits columns and see how the model performs."},{"metadata":{"trusted":true},"cell_type":"code","source":"benefit_cols = ['Retirement', 'Health and Dental', 'Other Benefits']\ndf.drop(benefit_cols, axis=1, inplace=True)\n\n# object cols stay the same\nnum_cols = [col for col in num_cols if col not in benefit_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\n\nX_cols = [col for col in df.columns if col not in (benefit_cols + ['Total Compensation'])] # remove output variable\n\nX = df[X_cols]\ny = df['Total Compensation']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n\n# still need to check for values in train set not in test set\nbad_lbl_cols = [col for col in object_cols if list(set(X_train[col]) - set(X_test[col]))]\nbad_lbl_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_cols = [col for col in X_cols if col not in bad_lbl_cols]\nX_train = X_train.drop(bad_lbl_cols, axis=1)\nX_test = X_test.drop(bad_lbl_cols, axis=1)\nobject_cols = [x for x in object_cols if x not in bad_lbl_cols]\nobject_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"OH_cols = [k for k,v in object_col_cnts.items() if v <= 10] # only OHE variables w/ less than 10 unique values per column\nLE_cols = list(set(object_cols) - set(OH_cols))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer, OrdinalEncoder \nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n\nnumerical_transformer = SimpleImputer(missing_values=np.nan, strategy='mean')\n\n# two steps: \n# (1) Fill in missing values using SimpleImputer\n# (2) One Hot Encode the variables, creating new columns for each unique type\nOH_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n                                 ('one_hot', OneHotEncoder(handle_unknown='ignore', sparse=False)) # ignore errors when calling 'transform', sparse=False returns np.array\n])\n\n# Same as OH_transformer except using LabelEncoder instead --> high-cardinality columns\nLE_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n                                 ('lbl_enc', OrdinalEncoder())\n])\n\n# Bundle preprocessing for numerical and two categorical groups data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, num_cols),\n        ('oh', OH_transformer, OH_cols),\n        ('le', LE_transformer, LE_cols),\n    ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\n\nmodel_mse = {}\nmodel_adj_r2 = {}\n\nfor name, model in models.items():\n    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n                           ('regressor', model)])\n    pipe.fit(X_train, y_train)   \n    y_pred = pipe.predict(X_test)\n\n    model_adj_r2[name] = round(pipe.score(X_test, y_test), 3)\n    model_mse[name] = mean_absolute_error(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_adj_r2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_mse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Without including the 3 Benefit columns, the model's accuracy plummets. RF still does alright sitting at slightly above 50%."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}