{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Here we will take a closer look at the feature selection on the example of the Bike Rentals dataset.\nData source and description:\n\nhttp://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset\n\n# Plan:\n1. Data exploration.\n2. Random forest model.\n3. Feature importance understanding and selection.\n\n# References:\n - https://arxiv.org/pdf/1309.6392.pdf\n - Friedman, Jerome H. “Greedy function approximation: A gradient boosting machine.” Annals of statistics (2001): 1189-1232.↩\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.inspection import plot_partial_dependence\nimport pdpbox\nfrom pdpbox import pdp, get_dataset, info_plots\nimport xgboost as xgb\nfrom sklearn.model_selection import ParameterGrid\nfrom tqdm import tqdm\n\nnp.random.seed(1)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"hour = pd.read_csv(\"../input/bike-sharing-dataset/hour.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# First, we will make a data exploration."},{"metadata":{"trusted":true},"cell_type":"code","source":"hour.head(6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hour.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plottong data.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hour['season'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hour['yr'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hour['mnth'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hour['hr'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hour['holiday'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hour['weekday'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hour['workingday'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hour['weathersit'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nplt.plot(hour['temp'], '.')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.distplot(hour['temp'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nplt.plot(hour['atemp'], '.')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.distplot(hour['atemp'])\n# are they related?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nplt.plot(hour['hum'][:200], '.')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.distplot(hour['hum'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nplt.plot(hour['windspeed'], '.')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.distplot(hour['windspeed'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nplt.plot(hour['casual'], '.')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.distplot(hour['casual'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nplt.plot(hour['registered'], '.')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.distplot(hour['registered'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nplt.plot(hour['cnt'], '.')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.distplot(hour['cnt'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exclude casual and registered and use cnt as target.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of days since the 01.01.2011 (the first day in the dataset). \n# This feature was introduced to take account of the trend over time.\n\nhour['date'] = pd.to_datetime(hour['dteday'])\n\nbasedate = pd.Timestamp('2011-01-01')\nhour['days_since'] = hour['date'].apply(lambda x: (x - basedate).days)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nplt.plot(hour['hum'], hour['days_since'], '.')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.regplot(x=hour[\"temp\"], y=hour[\"cnt\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.jointplot(x=hour[\"temp\"], y=hour[\"cnt\"], kind='scatter')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.regplot(x=hour[\"atemp\"], y=hour[\"cnt\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Temp and atemp show clear influence on cnt."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.regplot(x=hour[\"hum\"], y=hour[\"cnt\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.regplot(x=hour[\"days_since\"], y=hour[\"cnt\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For categorial features.\nplt.figure(figsize=(12, 6))\nsns.violinplot(x=\"season\", y=\"cnt\", data=hour, palette=\"muted\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.boxplot(x=\"season\", y=\"cnt\", data=hour)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.violinplot(x=\"yr\", y=\"cnt\", data=hour, palette=\"muted\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.violinplot(x=\"mnth\", y=\"cnt\", data=hour, palette=\"muted\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.violinplot(x=\"hr\", y=\"cnt\", data=hour, palette=\"muted\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.boxplot(x=\"hr\", y=\"cnt\", data=hour)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.violinplot(x=\"holiday\", y=\"cnt\", data=hour, palette=\"muted\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.violinplot(x=\"weekday\", y=\"cnt\", data=hour, palette=\"muted\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.violinplot(x=\"workingday\", y=\"cnt\", data=hour, palette=\"muted\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.violinplot(x=\"weathersit\", y=\"cnt\", data=hour, palette=\"muted\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cyclical features. Hour, weekday and month. It is usefull for NN algorhitms. Tree algos are robust without it.\n\ndef encode_cyclical(data, col_name, max_val):\n    data[col_name + '_sin'] = np.sin(2 * np.pi * data[col_name] / max_val)\n    data[col_name + '_cos'] = np.cos(2 * np.pi * data[col_name] / max_val)\n    return data\n\n\nhour = encode_cyclical(hour, 'hr', 24)\nhour = encode_cyclical(hour, 'mnth', 12)\nhour = encode_cyclical(hour, 'weekday', 7)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['season', 'yr', 'mnth', 'hr', 'holiday',\n            'weekday', 'workingday', 'weathersit', 'temp', 'atemp',\n            'hum', 'windspeed', 'days_since']\n\nX, y = hour[features], hour['cnt']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Since the features are far from linear we will try a simple tree algorhitm first namely Random Forest."},{"metadata":{"trusted":true},"cell_type":"code","source":"def rand_forest_model(X, y):\n    rmse_arr = []\n    \n    kf = KFold(n_splits=5, random_state=1, shuffle=True)\n\n    for n, (train_index, val_index) in enumerate(kf.split(X, y)):\n        print(f'fold: {n}')\n        train_X = X.iloc[train_index].values\n        val_X = X.iloc[val_index].values\n        train_y = y[train_index].values\n        val_y = y[val_index].values\n        \n        regr = RandomForestRegressor(max_depth=20, n_estimators=140, random_state=0)\n        regr.fit(train_X, train_y)\n        # print(regr.feature_importances_)\n\n        y_pred = regr.predict(val_X)\n        \n        # Predicted values should be non negative.\n        y_pred[y_pred < 0] = 0\n        \n        rmse = np.sqrt(mean_squared_error(val_y, y_pred))\n        rmse_arr.append(rmse)\n        \n    print('RMSE list:', rmse_arr)\n    print('RMSE AVG:', np.mean(rmse_arr))\n    return {'rmse_arr': rmse_arr, 'y_pred': y_pred, 'y_val': val_y, 'train_X': train_X, 'model': regr}\n\n\nres = rand_forest_model(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pot predicitons.\nplt.figure(figsize=(12, 6))\nplt.plot(res['y_pred'], '.', label='pred')\nplt.plot(res['y_val'], '.', label='original')\nplt.legend()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting absolute deviation.\nplt.figure(figsize=(12, 6))\nplt.plot(np.abs(res['y_pred'] - res['y_val']), '.')\nplt.title('Deviation from val.')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Here, we analyze feature influence on the result (feature importance)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluating features importance for RFregressor model.\n# res['model'].feature_importances_\nplt.figure(figsize=(12, 6))\nsns.barplot(x=res['model'].feature_importances_, y=features)\nplt.title('Feature importances')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Partial dependence plots."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_partial_dependence(estimator=res['model'], X=res['train_X'], features=[(0, 2), 2], feature_names=features) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_partial_dependence(estimator=res['model'], X=res['train_X'], features=[0, 1], feature_names=features) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_partial_dependence(estimator=res['model'], X=res['train_X'], features=[2, 3], feature_names=features) \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can a see strong dependance on \"hour\", obviously people rent more during day than night and at specific hours."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_partial_dependence(estimator=res['model'], X=res['train_X'], features=[4, 5], feature_names=features) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Weekday plays a significant role."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_partial_dependence(estimator=res['model'], X=res['train_X'], features=[6, 7], feature_names=features) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Weather situation has hight variation in PDP, means high dependance. Working day plays smaller role."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_partial_dependence(estimator=res['model'], X=res['train_X'], features=[8, 9], feature_names=features) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Temperature plays a big role, no surprise when its cold its not pleasant to bike. These two features might depend on each other (check it later)."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.corrcoef(hour[\"temp\"], hour[\"atemp\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.regplot(x=hour[\"temp\"], y=hour[\"atemp\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Temp or atemp can be excluded (one of them)."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_partial_dependence(estimator=res['model'], X=res['train_X'], features=[10, 11], feature_names=features) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here humidity plays a big role."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_partial_dependence(estimator=res['model'], X=res['train_X'], features=[12], feature_names=features) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems this feature captures trend in rentals."},{"metadata":{},"cell_type":"markdown","source":"Now we are going to exclude couple of important features and not important and understand its influence on the resulting score."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Excluding holiday, \"not very important\" feature.\nfeatures = ['season', 'yr', 'mnth', 'hr',\n            'weekday', 'workingday', 'weathersit', 'temp', 'atemp',\n            'hum', 'windspeed', 'days_since']\n\nX, y = hour[features], hour['cnt']\n\nrand_forest_model(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RMSE changes not much."},{"metadata":{"trusted":true},"cell_type":"code","source":"# excluding atemp, \"not very important\" feature.\nfeatures = ['season', 'yr', 'mnth', 'hr', 'holiday',\n            'weekday', 'workingday', 'weathersit', 'temp', 'atemp',\n            'hum', 'windspeed', 'days_since']\n\nX, y = hour[features], hour['cnt']\n\nrand_forest_model(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As expected removing atemp changes RMSE not much (almost the same value)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Excluding hour, \"very important\" feature.\nfeatures = ['season', 'yr', 'mnth', 'holiday',\n            'weekday', 'workingday', 'weathersit', 'temp', 'atemp',\n            'hum', 'windspeed', 'days_since']\n\nX, y = hour[features], hour['cnt']\n\nrand_forest_model(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RMSE rises a lot. So the hour is obviously an important feature."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets try to remove days_since feature.\nfeatures = ['season', 'yr', 'mnth', 'hr', 'holiday',\n            'weekday', 'workingday', 'weathersit', 'temp',\n            'hum', 'windspeed']\n\nX, y = hour[features], hour['cnt']\n\nrand_forest_model(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Days since is an importnt feature."},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['season', 'yr', 'mnth', 'hr', 'holiday',\n            'weekday', 'workingday', 'weathersit', 'temp',\n            'hum', 'windspeed']\n\nrmse_ft_arr = []\n\nfor n in range(len(features)):\n    print(f'step {n}')\n    features = ['season', 'yr', 'mnth', 'hr', 'holiday',\n            'weekday', 'workingday', 'weathersit', 'temp',\n            'hum', 'windspeed']\n    features.remove(features[n])\n    X, y = hour[features], hour['cnt']\n\n    res1 = rand_forest_model(X, y)\n\n    rmse_ft_arr.append(np.mean(res1['rmse_arr']))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['season', 'yr', 'mnth', 'hr', 'holiday',\n            'weekday', 'workingday', 'weathersit', 'temp',\n            'hum', 'windspeed']\n\nplt.figure(figsize=(12, 6))\nsns.barplot(x=rmse_ft_arr, y=features)\nplt.title('RMSE vs removed feature.')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ICE plots."},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['season', 'yr', 'mnth', 'hr', 'holiday',\n            'weekday', 'workingday', 'weathersit', 'temp', 'atemp',\n            'hum', 'windspeed', 'days_since']\n\ndata_df = pd.DataFrame(res['train_X'], columns=features)\n\npdp_hr = pdp.pdp_isolate(\n    model=res['model'], dataset=data_df, model_features=features, feature='hr', num_grid_points=200\n)\n\nfig, axes = pdp.pdp_plot(pdp_hr, 'hr', plot_lines=True, frac_to_plot=400)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_partial_dependence(estimator=res['model'], X=res['train_X'], features=[3], feature_names=features, grid_resolution=200) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGB Model."},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['season', 'yr', 'mnth', 'hr', 'holiday',\n            'weekday', 'workingday', 'weathersit', 'temp',\n            'hum', 'windspeed', 'days_since']\n\nX, y = hour[features], hour['cnt']\n\npars = {\n    'learning_rate': 0.1,\n    'max_depth': 12,\n    'objective': 'reg:squarederror',\n    'eval_metric': 'rmse',\n    'gamma': 0.25,\n    'n_estimators': 280\n}\n\ndef xgb_model(X, y, pars):    \n    rmse_arr = []\n    \n    kf = KFold(n_splits=5, random_state=1, shuffle=True)\n\n    for n, (train_index, val_index) in enumerate(kf.split(X, y)):\n#         print(f'fold: {n}')\n        \n        train_X = X.iloc[train_index]\n        val_X = X.iloc[val_index]\n        train_y = y[train_index]\n        val_y = y[val_index]\n        \n        xgb_train = xgb.DMatrix(train_X, label=train_y)\n        xgb_eval = xgb.DMatrix(val_X, label=val_y)\n        \n        xgb_model = xgb.train(pars,\n              xgb_train,\n              num_boost_round=800,\n              evals=[(xgb_train, 'train'), (xgb_eval, 'val')],\n              verbose_eval=False,\n              early_stopping_rounds=30\n             )\n    \n        y_pred = xgb_model.predict(xgb.DMatrix(val_X))\n\n        rmse = np.sqrt(mean_squared_error(val_y, y_pred))\n        rmse_arr.append(rmse)\n        \n    print('RMSE list:', rmse_arr)\n    print('RMSE AVG:', np.mean(rmse_arr))\n    return {'rmse_arr': rmse_arr, 'y_pred': y_pred, 'y_val': val_y, 'train_X': train_X, 'model': xgb_model}\n\n\nfeatures = ['season', 'yr', 'mnth', 'hr', 'holiday',\n            'weekday', 'workingday', 'weathersit',\n            'temp', 'hum', 'windspeed', 'days_since']\n\nX, y = hour[features], hour['cnt']\n\nres = xgb_model(X, y, pars)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple hyperparameters tuning.\nreference:\n\nhttps://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"par_grid = {\n    \"max_depth\": [3, 6, 7, 8, 9],\n    \"min_child_weight\": [0.5, 1, 3],\n    \"gamma\": [0.25, 0.5, 0.8, 0.9, 1.1],\n    \"n_estimators\": [60, 80, 100, 140]\n#     \"learning_rate\": [0.05, 0.15, 0.25, 0.30],\n#     \"colsample_bytree\": [0.3, 0.4, 0.5, 0.7, 0.9],\n#     \"etha\": [0.01, 0.5, 0.1, 0.2],\n#     \"subsample\": [0.5, 0.7, 1.0],\n#     \"lambda\": [0.5, 1.0, 2.0]\n}\n\nrmse_avg_min = 1e10\nmin_pars = None\n\n\nprint('total:', len(ParameterGrid(par_grid)))\nfor n, par in enumerate(ParameterGrid(par_grid)):\n    print(f'step {n}')\n    \n    model_pars = {\n        'objective': 'reg:squarederror',\n        'eval_metric': 'rmse',\n    }\n    \n    for k, v in par.items():\n        model_pars[k] = v \n    \n    res = xgb_model(X, y, model_pars)\n    \n    rmse_avg = np.mean(res['rmse_arr'])\n    \n    if rmse_avg < rmse_avg_min:\n        rmse_avg_min = rmse_avg\n        min_pars = par\n\n        \nprint(f'Best AVG RMSE: {rmse_avg_min}')\nprint('Best parameters:', min_pars)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Usually if one instance of the model is trained slowly, it could take a lot of time to find optimal hyperparameters in one kernel. This procedure can be done with several cores via \"lazy paralelism\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'With tunned parameters:', min_pars)\nprint('xgb model gives:')\nres = xgb_model(X, y, min_pars)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The average RMSE with xgb is smaler than with random forest."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nplt.plot(np.abs(res['y_pred'] - res['y_val']), '.')\nplt.title('Abs deviation from validation set.')\nplt.ylabel('Rentals')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}