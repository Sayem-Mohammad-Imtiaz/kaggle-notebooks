{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Import libraries needed in this notebook","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib as mpl\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"load the dataset","metadata":{}},{"cell_type":"code","source":"data_diabetes = pd.read_csv('../input/pima-indians-diabetes-database/diabetes.csv')\ndata_diabetes.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Overview of attributes","metadata":{}},{"cell_type":"code","source":"data_diabetes.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_diabetes.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Notice that the attributes - Glucose, BloodPressure, SkinThickness, Insulin and BMI are having a minimum value of 0. This value can not be valid under any circumstance.","metadata":{}},{"cell_type":"markdown","source":"Replacing 0 values with NAN","metadata":{}},{"cell_type":"code","source":"data_diabetes[['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']] = data_diabetes[['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']].replace(0, np.nan)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_diabetes.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_diabetes.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Histograms of all the continuous attributes(minus the target variable outcome)","metadata":{}},{"cell_type":"code","source":"plot = data_diabetes.hist(figsize=(20,20))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can now replace the np.nan values with the median values of the attributes.","metadata":{}},{"cell_type":"code","source":"data_diabetes['Glucose'].fillna(data_diabetes['Glucose'].median(), inplace=True)\ndata_diabetes['Insulin'].fillna(data_diabetes['Insulin'].median(), inplace=True)\ndata_diabetes['BMI'].fillna(data_diabetes['BMI'].median(), inplace=True)\ndata_diabetes['BloodPressure'].fillna(data_diabetes['BloodPressure'].median(), inplace=True)\ndata_diabetes['SkinThickness'].fillna(data_diabetes['SkinThickness'].median(), inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_diabetes.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Zero and null values have now been imputed","metadata":{}},{"cell_type":"code","source":"plot= sns.countplot(data=data_diabetes, x='Outcome')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Around 250 patients in the dataset were found to have diabetes while 500 were not.","metadata":{}},{"cell_type":"markdown","source":"Correlation between different attributes","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplot= sns.heatmap(data=data_diabetes.corr(), annot=True, cmap='YlOrBr')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preparing data for models","metadata":{}},{"cell_type":"markdown","source":"Scaling of data","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness','Insulin','BMI', 'DiabetesPedigreeFunction', 'Age']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_data_to_scale = data_diabetes[features]\n\nX_data_scaled = scaler.fit_transform(X_data_to_scale)\n\nX_data_scaled = pd.DataFrame(X_data_scaled)\n\nX_data_scaled.columns = features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_data_scaled.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = data_diabetes['Outcome']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using a logistic regression model","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.linear_model import LogisticRegression","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logit_model = LogisticRegression()\npredictions_logit = cross_val_predict(logit_model, X_data_scaled, y, cv=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y, predictions_logit)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"precision_score(y, predictions_logit)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recall_score(y, predictions_logit)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_score(y, predictions_logit)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conf_matrix =  confusion_matrix(y, predictions_logit)\nplot= sns.heatmap(data=conf_matrix, annot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\nroc_auc_score(y, predictions_logit)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using a Random forest classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"forest_clf = RandomForestClassifier()\npredictions_forest = cross_val_predict(forest_clf, X_data_scaled, y, cv=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y, predictions_forest)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"precision_score(y, predictions_forest)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recall_score(y, predictions_forest)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_score(y, predictions_forest)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conf_matrix_forest =  confusion_matrix(y, predictions_forest)\nplot= sns.heatmap(data=conf_matrix_forest, annot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_auc_score(y, predictions_forest)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using a k-nearest neighbors classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_data_scaled, y, test_size=0.3, random_state=42, stratify=y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_scores = []\ntest_scores = []\n\nfor i in range(1, 15):\n    knn_clf = KNeighborsClassifier(i)\n    knn_clf.fit(X_train, y_train)\n\n    train_scores.append(knn_clf.score(X_train, y_train))\n    test_scores.append(knn_clf.score(X_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_score = max(train_scores)\nmax_ind = [i for i in range(len(train_scores)) if train_scores[i]==max_score][0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Best knn score is {} when k is {}'.format(max_score, max_ind+1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_test_score = max(test_scores)\nmax_ind_test = [i for i in range(len(test_scores)) if test_scores[i]==max_test_score][0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Best knn score is {} when k is {}'.format(max_test_score, max_ind_test+1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\np = sns.lineplot(y=train_scores, x=[i for i in range(1,15)], marker='*',label='Train Score')\np = sns.lineplot(y=test_scores,  x=[i for i in range(1,15)],  marker='o',label='Test Score')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We get the best results with a knn classifier when the value of k is set to 11","metadata":{}},{"cell_type":"markdown","source":"k-fold cross validation on knn","metadata":{}},{"cell_type":"code","source":"knn_optimal = KNeighborsClassifier(11)\npredictions_knn = cross_val_predict(knn_clf, X_data_scaled, y, cv=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y, predictions_knn)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"precision_score(y, predictions_knn)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recall_score(y, predictions_knn)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_score(y, predictions_knn)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conf_matrix_knn =  confusion_matrix(y, predictions_knn)\nplot= sns.heatmap(data=conf_matrix_knn, annot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_auc_score(y, predictions_knn)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ROC_AOC curve comparison of all the models","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_curve\n\nfpr_logit, tpr_logit, thresholds_logit = roc_curve(y, predictions_logit)\nfpr_forest, tpr_forest, thresholds_forest = roc_curve(y, predictions_forest)\nfpr_knn, tpr_knn, thresholds_knn = roc_curve(y, predictions_knn)\n\nplt.figure(figsize=(10,6))\nplt.plot(fpr_logit, tpr_logit, linewidth=2, color='b')\nplt.plot(fpr_forest, tpr_forest, linewidth=2, color='g')\nplt.plot(fpr_knn, tpr_knn, linewidth=2, color='r')\nplt.plot([0,1], [0,1], 'k--')\nplt.axis([0,1,0,1])\nplt.legend(['Logistic Regression', 'Random Forest', 'KNN'])\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observations\n\n- Surprisingly, our random forest and knn classifiers didn't perform any better than the baseline logistic regression model.\n\n- The three models have similar roc_aoc and f1_scores on cross validation testing.\n\n- KNN has a lower recall score(0.50) meaning that its overall ability of predicting diabetic patients is prety low.\n\n- Performance can be improved marginally by using GridSearchCV to tweak model parameters.\n\n- Also, a Support Vector Classifier can be used and the performance should be similar if not better.","metadata":{}}]}