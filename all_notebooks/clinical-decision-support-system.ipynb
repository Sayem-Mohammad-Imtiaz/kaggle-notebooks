{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#imported important libraries\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#reading the dataset\ndf = pd.read_csv('../input/Training.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#They are 4920 rows, 133 columns\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#seeing any null values are there with descending format\ndf.isnull().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#looking how much percent each diseases having\ndf['prognosis'].value_counts(normalize = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#as we can see each no. diseases having the same percentage through bar chart\ndf['prognosis'].value_counts(normalize = True).plot.bar()\nplt.subplots_adjust(left = 0.9, right = 2 , top = 2, bottom = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking if there are any other data types\ndf.dtypes.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Analyzing each symptoms/variable\nfor x in range(df.shape[1]):\n    plt.subplot(7,22,x+1)\n    plt.subplots_adjust(left = 0.5, right = 16 , top = 10, bottom = 0.5)\n    sns.countplot(df[df.columns[x]]).set_title(df.columns[x],fontsize=23)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the relationship between the variables by applying the correlation \ncorr = df.corr()\nmask = np.array(corr)\nmask[np.tril_indices_from(mask)] = False\nplt.subplots_adjust(left = 0.5, right = 16 , top = 20, bottom = 0.5)\nsns.heatmap(corr, mask=mask,vmax=.9, square=True,annot=True, cmap=\"YlGnBu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#took two high correlation variables and analysing if it is satisfying null hypothesis or alternate hypothesis\npd.crosstab(df['cold_hands_and_feets'],df['weight_gain'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#imported the chi square contingency\nfrom scipy.stats import chi2_contingency","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#as p value is  0.0  which is less than 0.05 then they are actually different from each other which satisfy the alternate hypothesis \nchi2_contingency(pd.crosstab(df['cold_hands_and_feets'],df['weight_gain']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#seperated the independent and dependent values to repective variables \nx = df.drop(['prognosis'],axis =1)\ny = df['prognosis']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#divided into testing and training\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#imported naive_baye algorithm\nfrom sklearn.naive_bayes import MultinomialNB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fitted the model\nmnb = MultinomialNB()\nmnb = mnb.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = mnb.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_pred,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#by cross validating we got mean also 100%\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(mnb, x_test, y_test, cv=3)\nprint (scores)\nprint (scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_diseases = y_test.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for the cross checking purpose i want to see if predicted values and actual values are same else it gives me worng prediction \nfor i in range(0, len(real_diseases)):\n    if y_pred[i] == real_diseases[i]:\n        print ('Pred: {0} Actual:{1}'.format(y_pred[i], real_diseases[i]))\n    else:\n        print('worng prediction')\n        print ('Pred: {0} Actual:{1}'.format(y_pred[i], real_diseases[i]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#imported Kfold\nfrom sklearn.model_selection import KFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Function to run multiple algorithms with different K values of KFold.\ndef evaluate(train_data,kmax,algo):\n    test_scores = {}\n    train_scores = {}\n    for i in range(2,kmax,2):\n        kf = KFold(n_splits = i)\n        sum_train = 0\n        sum_test = 0\n        data = df\n        for train,test in kf.split(data):\n            train_data = data.iloc[train,:]\n            test_data = data.iloc[test,:]\n            x_train = train_data.drop([\"prognosis\"],axis=1)\n            y_train = train_data['prognosis']\n            x_test = test_data.drop([\"prognosis\"],axis=1)\n            y_test = test_data[\"prognosis\"]\n            algo_model = algo.fit(x_train,y_train)\n            sum_train += algo_model.score(x_train,y_train)\n            y_pred = algo_model.predict(x_test)\n            sum_test += accuracy_score(y_test,y_pred)\n        average_test = sum_test/i\n        average_train = sum_train/i\n        test_scores[i] = average_test\n        train_scores[i] = average_train\n        print(\"kvalue: \",i)\n    return(train_scores,test_scores)   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\ngbm = GradientBoostingClassifier()\nnb = MultinomialNB()\nfrom sklearn.linear_model import LogisticRegression\nlog = LogisticRegression()\nfrom sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier(criterion='entropy',)\nfrom sklearn.ensemble import RandomForestClassifier\nran = RandomForestClassifier(n_estimators = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"algo_dict = {'l_o_g':log,'d_t':dt,'r_a_n':ran,'N_B' : nb}\nalgo_train_scores={}\nalgo_test_scores={}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#decision tree was found to be best fit with training score of 0.1 and testing score of 0.87 with k value of 2 in the k fold cross validation. All the other algorithm seems to be overfit.\nmax_kfold = 11\nfor algo_name in algo_dict.keys():\n    print(algo_name)\n    tr_score,tst_score = evaluate(df,max_kfold,algo_dict[algo_name])\n    algo_train_scores[algo_name] = tr_score\n    algo_test_scores[algo_name] = tst_score\nprint(algo_train_scores)\nprint(algo_test_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.DataFrame(algo_test_scores)\ndf_train = pd.DataFrame(algo_train_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.plot(grid = 1)\nplt.show()\nplt.grid()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#building the model at k value 2 \ntest_scores={}\ntrain_scores={}\nfor i in range(2,4,2):\n    kf = KFold(n_splits = i)\n    sum_train = 0\n    sum_test = 0\n    data = df\n    for train,test in kf.split(data):\n        train_data = data.iloc[train,:]\n        test_data = data.iloc[test,:]\n        x_train = train_data.drop([\"prognosis\"],axis=1)\n        y_train = train_data['prognosis']\n        x_test = test_data.drop([\"prognosis\"],axis=1)\n        y_test = test_data[\"prognosis\"]\n        algo_model = dt.fit(x_train,y_train)\n        sum_train += dt.score(x_train,y_train)\n        y_pred = dt.predict(x_test)\n        sum_test += accuracy_score(y_test,y_pred)\n    average_test = sum_test/i\n    average_train = sum_train/i\n    test_scores[i] = average_test\n    train_scores[i] = average_train\n    print(\"kvalue: \",i)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_scores)\nprint(test_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#saved the model \nfrom sklearn.externals import joblib\njoblib.dump(dt,'my_model_for_healthcare')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = list(range(2,134))\ni_name  = (input('Enter your name :'))\ni_age = (int(input('Enter your age:')))\nfor i in range(len(x.columns)):\n    print(str(i+1+1) + \":\", x.columns[i])\nchoices = input('Enter the Serial no.s which is your Symptoms are exist:  ')\nb = [int(x) for x in choices.split()]\ncount = 0\nwhile count < len(b):\n    item_to_replace =  b[count]\n    replacement_value = 1\n    indices_to_replace = [i for i,x in enumerate(a) if x==item_to_replace]\n    count += 1\n    for i in indices_to_replace:\n        a[i] = replacement_value\na = [0 if x !=1 else x for x in a]\ny_diagnosis = dt.predict([a])\ny_pred_2 = dt.predict_proba([a])\nprint(('Name of the infection = %s , confidence score of : = %s') %(y_diagnosis[0],y_pred_2.max()* 100),'%' )\nprint(('Name = %s , Age : = %s') %(i_name,i_age))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Need to incorporate adaptive questioning here. Please refer Webmd.com to understand the flow."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}