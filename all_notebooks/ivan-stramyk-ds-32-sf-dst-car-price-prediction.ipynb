{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Итоговое задание Ivan Stramyk по Проекту 6. Car Price prediction","metadata":{}},{"cell_type":"markdown","source":"## №1. Парсинг","metadata":{}},{"cell_type":"markdown","source":"##### Парсил объявления через колаб https://colab.research.google.com/drive/1UyKMfeF-DjK_gad25PEofaLhFir2b9uH?usp=sharing \nКод предоставляю ниже.\nСписок объявлений по маркам автомобилей состоянием на 02.04.2021","metadata":{}},{"cell_type":"code","source":"# Импорт используемых библиотек\nimport pandas as pd\nimport requests, json\nimport time\nimport traceback","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_dict = {'AC':3,'AMC':4,'AURUS':10,'Acura':145,'Adler':4,'Alfa Romeo':145,'Alpina':10,'Ariel':1,'Aro':7,'Asia':7,'Aston Martin':20,'Auburn':1,'Audi':11130,'Austin':2,\\\n               'BAIC':2,'BMW':16647,'BYD':125,'Bentley':173,'Borgward':1,'Brabus':2,'Brilliance':94,'Bugatti':1,'Buick':44,'CHERYEXEED':78,'Cadillac':692,'Chana':1,'ChangFeng':3,\\\n               'Changan':484,'Changhe':2,'Chery':3429,'Chevrolet':12926,'Chrysler':650,'Citroen':2421,'DKW':1,'DS':5,'DW Hower':18,'Dacia':43,'Dadi':5,'Daewoo':4992,'Daihatsu':373,\\\n               'Daimler':1,'Datsun':1219,'Delage':1,'Derways':14,'Dodge':771,'DongFeng':51,'Doninvest':23,'Eagle':3,'FAW':277,'FSO':2,'Ferrari':29,'Fiat':909,'Fisker':1,'Ford':12124,\\\n               'Foton':10,'GAC':10,'GMC':45,'Geely':2060,'Genesis':83,'Geo':8,'Great Wall':900,'Hafei':47,'Haima':99,'Hanomag':1,'Haval':1339,'Hawtai':10,'Heinkel':1,'Honda':5698,\\\n               'HuangHai':2,'Hudson':1,'Hummer':162,'Hyundai':23231,'Infiniti':1935,'Iran Khodro':79,'Isuzu':149,'JAC':80,'Jaguar':717,'Jeep':937,'Jinbei':7,'Kia':20809,'LADA (ВАЗ)':77398,\\\n               'LTI':1,'Lamborghini':16,'Lancia':33,'Land Rover':3476,'Landwind':3,'Lexus':3932,'Lifan':2209,'Ligier':1,'Lincoln':186,'Luxgen':23,'MG':19,'MINI':1042,'Mahindra':4,'Marussia':1,\\\n               'Maruti':1,'Maserati':97,'Maybach':11,'Mazda':8327,'McLaren':3,'Mercedes-Benz':21671,'Mercury':37,'Metrocab':1,'Mitsubishi':11276,'Mitsuoka':4,'Nissan':19415,'Oldsmobile':16,\\\n               'Opel':9582,'PUCH':7,'Packard':1,'Peugeot':4462,'Plymouth':21,'Pontiac':113,'Porsche':1590,'Proton':12,'RAM':32,'Ravon':291,'Renault':19025,'Renault Samsung':2,'Rolls-Royce':57,\\\n               'Rover':222,'SEAT':214,'Saab':271,'Saturn':33,'Scion':19,'Shanghai Maple':8,'ShuangHuan':2,'Simca':1,'Skoda':9601,'Smart':165,'SsangYong':1840,'Subaru':2436,'Suzuki':2940,'TATA':4,\\\n               'Talbot':1,'Tatra':4,'Tesla':152,'Tianma':2,'Tianye':10,'Toyota':24191,'Trabant':4,'Triumph':3,'Vauxhall':1,'Volkswagen':19792,'Volvo':3346,'Vortex':395,'Wanderer':5,'Wartburg':3,\\\n               'Willys':13,'Xin Kai':3,'Yulon':1,'ZX':15,'Zibar':1,'Zotye':85,'Автокам':1,'ГАЗ':4318,'Гоночный автомобиль':6,'ЗАЗ':1380,'ЗИЛ':7,'ЗиС':3,'ИЖ':626,'Канонир':1,'ЛуАЗ':299,'Москвич':671,\\\n               'СМЗ':21,'ТагАЗ':189,'УАЗ':5713}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# уберем модели с кол-вом объявлений ниже 300 и повысим регистр индексов \nlist_keys_to_delete = []\nfor mark in models_dict.keys():\n    if models_dict[mark] < 300:\n        list_keys_to_delete.append(mark)\n    \nfor key in list_keys_to_delete: del models_dict[key]\n\nfor mark in list(models_dict.keys()):\n    mark_up = mark.upper()\n    models_dict[mark_up]=models_dict.pop(mark)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Удалим отечественные модели\nfor key in ['LADA (ВАЗ)','ГАЗ','УАЗ', 'ЗАЗ', 'ИЖ', 'МОСКВИЧ']: del models_dict[key]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# исправим некоторые названия\nmodels_dict['GREAT_WALL']=models_dict.pop('GREAT WALL')\nmodels_dict['LAND_ROVER']=models_dict.pop('LAND ROVER')\nmodels_dict['MERCEDES']=models_dict.pop('MERCEDES-BENZ')\nmodels_dict['SSANG_YONG']=models_dict.pop('SSANGYONG')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# словарь с названиями моделей и количеством объявлений после фильтрации\n\nmodels_dict = {'AUDI': 11130,  'BMW': 16647,  'CADILLAC': 692,  'CHANGAN': 484,  'CHERY': 3429,  'CHEVROLET': 12926,  'CHRYSLER': 650,  'CITROEN': 2421,\n 'DAEWOO': 4992,  'DAIHATSU': 373,  'DATSUN': 1219,  'DODGE': 771,  'FIAT': 909,  'FORD': 12124,  'GEELY': 2060,  'HAVAL': 1339,  'HONDA': 5698,\n 'HYUNDAI': 23231,  'INFINITI': 1935,  'JAGUAR': 717,  'JEEP': 937,  'KIA': 20809,  'LEXUS': 3932,  'LIFAN': 2209,  'MINI': 1042,  'MAZDA': 8327,\n 'MITSUBISHI': 11276,  'NISSAN': 19415,  'OPEL': 9582,  'PEUGEOT': 4462,  'PORSCHE': 1590,  'RENAULT': 19025,  'SKODA': 9601,  'SUBARU': 2436, \n 'SUZUKI': 2940,  'TOYOTA': 24191,  'VOLKSWAGEN': 19792,  'VOLVO': 3346,  'VORTEX': 395,  'GREAT_WALL': 900,  'LAND_ROVER': 3476, 'MERCEDES': 21671,\n 'SSANG_YONG': 1840}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Парсить будем методом POST через JSON так как это довольно быстро и удобно.","metadata":{}},{"cell_type":"code","source":"# headers нашей сессии в браузере\nHEADERS = {\n    'Accept': '*/*',\n    'Accept-Encoding': 'gzip, deflate, br',\n    'Accept-Language': 'ru-RU,ru;q=0.8,en-US;q=0.5,en;q=0.3',\n    'Connection': 'keep-alive',\n    'Content-Length':'103',\n    'content-type':'application/json',\n    'Cookie':'autoru_gdpr=1; _csrf_token=0b9bfe638dd0b95a7c3ac9b3fd59d540eae8102094150176; autoru_sid=a%3Ag60697fdd20d5osjl7hjk5o65qso5f3m.bbec9e47fe6c357861dac8894dd324be%7C1617526749509.604800.Rmi4CAt4gY8VoAVCNf8yGA.WhKyb55vGRLnuhVwmAYw-WpbpGJhnU11ZIgNnQ0xwlQ; autoruuid=g60697fdd20d5osjl7hjk5o65qso5f3m.bbec9e47fe6c357861dac8894dd324be; suid=8b392ef0642f31eba6e490553b2a8876.aa730c703f9c9a4f5e66993fe8c916ea; from_lifetime=1617559952775; from=direct; yuidlt=1; yandexuid=8768961311617526753; cmtchd=MTYxNzUyNjc2MDU5Ng==; gdpr=0; cycada=p92JQFOQLJpa73XwSOM/xy61EE8dGReKfzAjoY3mt3A=; _ym_uid=1617526759299819712; _ym_d=1617559952; _ym_isad=2; mindboxDeviceUUID=ab564749-0f98-40b1-89d2-41b766a1c42d; directCrm-session=%7B%22deviceGuid%22%3A%22ab564749-0f98-40b1-89d2-41b766a1c42d%22%7D; _ga=GA1.2.1029486733.1617532156; _gid=GA1.2.1469364259.1617532156; tmr_reqNum=3; tmr_lvid=bf1506bfca36781b64ee3b80ce17ae53; tmr_lvidTS=1617532156060; X-Vertis-DC=vla',\n    'Host': 'auto.ru',\n    'Origin':'https://auto.ru',\n    'Referer':'https://auto.ru/',\n    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:87.0) Gecko/20100101 Firefox/87.0',\n    'x-client-app-version':'5f535b6dbd',\n    'x-client-date':'1617559954352',\n    'x-csrf-token':'0b9bfe638dd0b95a7c3ac9b3fd59d540eae8102094150176',\n    'x-page-request-id':'52e324b5b6813d1a9c9635b956cb5b85',\n    'x-requested-with':'fetch'\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"url = 'https://auto.ru/-/ajax/desktop/listing/' # урл на который отправляем запрос\n\ndf_list = [] # список для упаковки спаршенной информации\npage_dict = {} # словарь для записи моделей и страниц, на которых парсер остановился\n\nfor pages in range(1,100): # всего сайт показывает 99 страниц - проходимся по каждой странице\n    for model in models_dict: # проходимся по каждой модели из словаря\n        if models_dict[model] > (pages * 37): # проверяем есть ли вообще столько страниц по этой модели\n            time.sleep(1) # задержка между запросами, чтобы не блокировали наш IP\n            param = {\"catalog_filter\":[{\"mark\":model}],\"section\":\"all\",\"category\":\"cars\", \"page\": pages} # параметры запроса\n            try:\n                response = requests.post(url, data=json.dumps(param), headers = HEADERS) # запрашиваем данные\n                data = response.json()\n                if data['status'] == 'SUCCESS': # в случае успеха добавляем в наш список всю информацию по каждому объявлению отдельно\n                    for elem in data['offers']:\n                        try:\n                            df_list.append(elem)\n                        except:\n                            print(df_list)\n                        page_dict.update({model: pages}) # обновляем словарь со значением модели и страницы, которая была обработана   \n                    # сохраняем в отдельный файл после каждого успешного цикла\n                    pd.DataFrame([page_dict]).to_csv(r'pars_models.csv', index=False) # а также файл с названиями моделей и страниц, где парсер остановился\n            except:\n                print(data['status']) # в случае неудачи смотрим на статус\n                print(model,pages, traceback.format_exc()) # а также на модель, страницу и суть ошибки\n\npd.DataFrame(df_list).to_csv(r'autoru.csv', index=False) # сохраняем всё в файл (по факту делал в три итерации)\n!cp autoru.csv \"/content/drive/My Drive/Data Science/SF/auto.ru/\" # дополнительно копируем файл к себе в гугл диск","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## №2. Обрабатываем данные - формируем датафрейм с самыми необходимыми параметрами","metadata":{}},{"cell_type":"code","source":"df_t = pd.DataFrame(df_list) # создаем датафрейм из полученных спаршенных данных\ndf_t = df_t.drop_duplicates(subset=['id']) # удаляем дубликаты","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# создаем новый датафрейм с самыми необходимыми параметрами\ndf_tnew = pd.DataFrame()\n\ndf_tnew['bodyType'] = ''\ndf_tnew['brand'] = ''\ndf_tnew['color'] = df_t['color_hex']\ndf_tnew['complectation_dict'] = ''\ndf_tnew['description'] = df_t['description']\ndf_tnew['engineDisplacement'] = ''\ndf_tnew['enginePower'] = ''\ndf_tnew['equipment_dict'] = ''\ndf_tnew['fuelType'] = ''\ndf_tnew['mileage'] = ''\ndf_tnew['modelDate'] = ''\ndf_tnew['model_info'] = ''\ndf_tnew['model_name'] = ''\ndf_tnew['name'] = ''\ndf_tnew['numberOfDoors'] = ''\ndf_tnew['priceCurrency'] = 'RUB'\ndf_tnew['productionDate'] = ''\ndf_tnew['sell_id'] = df_t['saleId']\ndf_tnew['super_gen'] = ''\ndf_tnew['vehicleConfiguration'] = ''\ndf_tnew['vehicleTransmission'] = ''\ndf_tnew['vendor'] = ''\ndf_tnew['Владельцы'] = ''\ndf_tnew['ПТС'] = ''\ndf_tnew['Привод'] = ''\ndf_tnew['Руль'] = ''\ndf_tnew['id'] = df_t['id']\ndf_tnew['price'] = ''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Пишем функции, которые распарсят наши данные с формата JSON в удобный для нас табличный вид. Нужно сделать такие же столбцы как в test.csv, но с добавлений цены и id объявления для удаления дубликатов.","metadata":{}},{"cell_type":"code","source":"def first_level(df, new_df, column, parametr, new_parametr):\n    iterator = 0\n    for x in df[column]:\n        if x is not None:\n            try:\n                new_df[new_parametr][iterator] = eval(x)[parametr]\n            except:\n                new_df[new_parametr][iterator] = ''\n        iterator += 1\n        \ndef second_level(df, new_df, column, parametr_1, parametr_2, new_parametr):\n    iterator = 0\n    for x in df[column]:\n        if x is not None:\n            try:\n                new_df[new_parametr][iterator] = eval(x)[parametr_1][parametr_2]\n            except:\n                new_df[new_parametr][iterator] = ''\n        iterator += 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Выполняем под каждый параметр определенную функцию.","metadata":{}},{"cell_type":"code","source":"first_level(df_t, df_tnew, 'vehicle_info', 'complectation', 'complectation_dict')\nfirst_level(df_t, df_tnew, 'vehicle_info', 'equipment', 'equipment_dict')\nfirst_level(df_t, df_tnew, 'state', 'mileage', 'mileage')\nfirst_level(df_t, df_tnew, 'vehicle_info', 'model_info', 'model_info')\nfirst_level(df_t, df_tnew, 'documents', 'year', 'productionDate')\nfirst_level(df_t, df_tnew, 'vehicle_info', 'tech_param', 'super_gen')\nfirst_level(df_t, df_tnew, 'vehicle_info', 'vendor', 'vendor')\nfirst_level(df_t, df_tnew, 'documents', 'owners_number', 'Владельцы')\nfirst_level(df_t, df_tnew, 'documents', 'pts', 'ПТС')\nfirst_level(df_t, df_tnew, 'vehicle_info', 'steering_wheel', 'Руль')\nfirst_level(df_t, df_tnew, 'price_info', 'price', 'price')\nsecond_level(df_t, df_tnew, 'vehicle_info', 'configuration', 'human_name', 'bodyType')\nsecond_level(df_t, df_tnew, 'vehicle_info', 'mark_info', 'code', 'brand')\nsecond_level(df_t, df_tnew, 'vehicle_info', 'tech_param', 'human_name', 'engineDisplacement')\nsecond_level(df_t, df_tnew, 'vehicle_info', 'tech_param', 'power', 'enginePower')\nsecond_level(df_t, df_tnew, 'vehicle_info', 'super_gen', 'year_from', 'modelDate')\nsecond_level(df_t, df_tnew, 'vehicle_info', 'model_info', 'code', 'model_name')\nsecond_level(df_t, df_tnew, 'vehicle_info', 'tech_param', 'human_name', 'name')\nsecond_level(df_t, df_tnew, 'vehicle_info', 'configuration', 'doors_count', 'numberOfDoors')\nsecond_level(df_t, df_tnew, 'vehicle_info', 'tech_param', 'transmission', 'vehicleTransmission')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# пара ручных обработок для необычных методов обработки параметров\n\niterator = 0\nfor x in df_t['lk_summary']:\n    if x is not None:        \n        try:\n            df_tnew['fuelType'][iterator] = x.split(' ')[-1]\n        except:\n            df_tnew['fuelType'][iterator] = ''\n    iterator += 1\n    \niterator = 0\nfor x in df_t['lk_summary']:\n    if x is not None:        \n        try:\n            df_tnew['Привод'][iterator] = x.split(' ')[-2][:-1]\n        except:\n            df_tnew['Привод'][iterator] = ''\n    iterator += 1\n\niterator = 0\nfor x in df_tnew['engineDisplacement']:    \n    df_tnew['engineDisplacement'][iterator] = str(x[:3]) + ' LTR'\n    iterator += 1\n    \niterator = 0\nfor x in df_tnew['enginePower']:\n    df_tnew['enginePower'][iterator] = str(x) + ' N12'\n    iterator += 1\n\niterator = 0\nfor x in df_tnew['sell_id']:\n    df_tnew['sell_id'][iterator] = str(x[:10])\n    iterator += 1\n    \niterator = 0\nfor x in df_t['vehicle_info']:\n    if x is not None:\n        try:\n            df_tnew['vehicleConfiguration'][iterator] = \\\n            eval(x)['configuration']['body_type'] + ' ' + \\\n            eval(x)['tech_param']['transmission'] + ' ' + \\\n            eval(x)['tech_param']['human_name'][:3]\n        except:\n            df_tnew['vehicleConfiguration'][iterator] = ''\n    iterator += 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# исправляем название цветов\ncolor_dict = {'040001' : 'чёрный', 'FAFBFB' : 'белый', '97948F' : 'серый', 'CACECB' : 'серебристый', '0000CC' : 'синий', 'EE1D19' : 'красный', \\\n              '200204' : 'коричневый', '007F00' : 'зелёный', 'C49648' : 'бежевый', '22A0F8' : 'голубой', 'DEA522' : 'золотистый', '660099' : 'пурпурный', \\\n              'FF8649' : 'оранжевый', '4A2197' : 'фиолетовый', 'FFD600' : 'жёлтый', 'FFC0CB' : 'розовый'}\n\niterator = 0\nfor x in df_tnew['color']:\n    df_tnew['color'][iterator] = color_dict[x]    \n    iterator += 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df_tnew)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"В общем не плохо. Получилось спарсить таким образом 167 398 объявлений.Если поиграться с параметрами запроса (вводить разные модели, количество дней с появления объвления и другие), то за недельку можно собрать приличный датасет для анализа.","metadata":{}},{"cell_type":"code","source":"df_tnew.to_csv('train.csv') # сохраням наш финальный датафрейм в файл","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## №3. Подготовка данных и обучение","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport sys\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom tqdm.notebook import tqdm\nfrom catboost import CatBoostRegressor\n\nimport warnings\n#warnings.filterwarnings(\"ignore\")\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport re","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n!pip freeze > requirements.txt","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\nRANDOM_SEED = 42","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"VERSION    = 1\nDIR_TRAIN  = '../input/autoru/' # подключил к ноутбуку свой внешний датасет\nDIR_TEST   = '../input/sf-dst-car-price-prediction/'\nVAL_SIZE   = 0.33   # 33%\nN_FOLDS    = 5\n\n# CATBOOST\nITERATIONS = 2000\nLR         = 0.1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"!ls ../input/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(DIR_TRAIN+'train.csv') # мой подготовленный датасет для обучения модели\ntest = pd.read_csv(DIR_TEST+'test.csv')\nsample_submission = pd.read_csv(DIR_TEST+'sample_submission.csv')","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# убираем не нужные для модели признаки\ntest.drop(['Таможня', 'Состояние', 'car_url', 'image', 'parsing_unixtime', 'Владение', 'priceCurrency'], axis=1, inplace=True,)\ntrain.drop(['id', 'priceCurrency'], axis=1, inplace=True,)\n\n# убираем признаки которые еще не успели обработать,     \ntest.drop(['description', 'complectation_dict', 'equipment_dict', 'super_gen', 'model_info'], axis=1, inplace=True,)\ntrain.drop(['description', 'complectation_dict', 'equipment_dict', 'super_gen', 'model_info'], axis=1, inplace=True,)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# проверяем на пустые значения\ntest.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# смотрим самые популярные значения\ntest['ПТС'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# заполняем самым популярным значением пропущенные значения\ntest['ПТС'] = test['ПТС'].fillna(test['ПТС'].value_counts().index[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# проверяем пустые значения\ntrain.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Среди владельцев нету сильно популярного значения, но пропусков очень много - 17 тыс. это около 13%, поэтому лучше заполним пропуски нулями. Таким образом создадим ещё одно состояние для этого категориального признака.","metadata":{}},{"cell_type":"code","source":"train['Владельцы'].value_counts() # проверяем уникальные значения владельцев.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Владельцы'] = train['Владельцы'].fillna(0) # заполняем нулями пропуски","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Переводим Владельцы в строку, так как по сути это категориальный признак","metadata":{}},{"cell_type":"code","source":"train['Владельцы'] = train['Владельцы'].astype('str')\ntrain['numberOfDoors'] = train['numberOfDoors'].astype('str')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### В остальных случаях либо удаляем, либо заполняем самыми популярными значениями.","metadata":{}},{"cell_type":"code","source":"iterator = 0\nfor x in train.isna().sum():\n    col = train.isna().sum().index[iterator] # формируем название столбца\n    if x < 200:\n        train = train.dropna(subset=[col]) # всё что меньше 200 пропусков - удаляем всю строку\n    else:\n        train[col] = train[col].fillna(train[col].value_counts().index[0]) # где больше 200 пропусков - заполняем ячейки самыми популярными значениями\n    iterator += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Исследуем наши числовые признаки.","metadata":{}},{"cell_type":"code","source":"num_cols = ['mileage', 'modelDate', 'productionDate', 'price']\n\n# посмотрим на распределение числовых данных\nplt.figure(figsize=(20, 10))\niterator = 1\nfor i in num_cols:\n    plt.subplot(2, 2, iterator)\n    train[i].hist(bins=100)\n    plt.title(i)\n    iterator += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Видим явные перекосы. Посмотрим подробнее. ","metadata":{}},{"cell_type":"code","source":"for x in num_cols:\n    print(train[x].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Видим много нулевых значений в mileage. Крайне малое количество очень старых моделей и несколько крайне редких значений цены. \nПо скольку в mileage распределение достаточно нормальное, с небольшим смещением, заполним нулевые значения средним значением по выборке.\nВ modelDate и productionDate - удалим крайне старые модели.\nВ price удалим крайне дорогие модели.","metadata":{}},{"cell_type":"code","source":"train.loc[train['mileage'] == 0, 'mileage'] = train[train['mileage'] > 0]['mileage'].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# функция удаления выбросов\ndef remove_outlier(df_in, col_name):\n    q1 = df_in[col_name].quantile(0.25)\n    q3 = df_in[col_name].quantile(0.75)\n    iqr = q3-q1 #Interquartile range\n    fence_low  = q1-1.5*iqr\n    fence_high = q3+1.5*iqr\n    df_out = df_in.loc[(df_in[col_name] > fence_low) & (df_in[col_name] < fence_high)]\n    return df_out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# применяем функцию\ntrain = remove_outlier(train, 'modelDate')\ntrain = remove_outlier(train, 'productionDate')\ntrain = remove_outlier(train, 'price')\ntrain = remove_outlier(train, 'mileage')\ntrain = train.reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Чутка подсократили датасет, но количество выбросов по численных признаках явно стало меньше.","metadata":{}},{"cell_type":"code","source":"num_cols = ['mileage', 'modelDate', 'productionDate', 'price']\n\n# посмотрим на распределение числовых данных\nplt.figure(figsize=(20, 10))\niterator = 1\nfor i in num_cols:\n    plt.subplot(2, 2, iterator)\n    train[i].hist(bins=100)\n    plt.title(i)\n    iterator += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Смотрим на корреляцию, предполагая что дата выхода модели и производства автомобиля будет очень близка и сильно коррелировать между собой.","metadata":{}},{"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (15,10)\nsns.heatmap(train.drop(['price', 'Владельцы'], axis=1).corr(),)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ожидаемо, что productionDate и modelDate сильно коррелируют, но пока не будем удалять какую-то из них, так как регрессия лучше учится на обеих, чем на каждой по отдельности.\nСделаем пока пару OneHot признаков.","metadata":{}},{"cell_type":"code","source":"train_LR = train.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_LR = train_LR[train_LR['bodyType'].isin(train_LR['bodyType'].value_counts()[:10].index)]\ntrain_LR = train_LR.reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_LR = pd.get_dummies(train_LR, columns=['Владельцы', 'brand', 'vendor', 'bodyType'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['bodyType'].value_counts(ascending=True).plot(kind='barh')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# сократим мало популярные варианты bodyType\ntrain = train[train['bodyType'].isin(train['bodyType'].value_counts()[:10].index)]\ntrain = train.reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# есть явные мелкие значения, которые можно сократить\ntrain['engineDisplacement'].value_counts(ascending=True).plot(kind='barh')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# из-за ошибок попадаются не верные числа, а также есть не нужная приставка LTR - исправим это и сократим список этого категориального признака\nfor index, value in enumerate(train['engineDisplacement']):\n    train['engineDisplacement'][index] = re.sub(r'(\\d).*(\\d)(\\D*)', '\\\\1.\\\\2', value)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# сократим мало популярные варианты engineDisplacement\ntrain = train[train['engineDisplacement'].isin(train['engineDisplacement'].value_counts()[:30].index)]\ntrain = train.reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# попробуем перевести engineDisplacement в числовой признак\ntrain['engineDisplacement'].value_counts().index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"engineDisplacement_list = ['1.6', '2.0', '1.5', '1.4', '1.8', '3.0', '2.5', '2.4', '1.3', '1.2', '0.8', '3.5', '2.2', '1.7', '4.0', '2.3', '5.0', '3.6', '2.7', \\\n                           '1.0', '1.9', '4.4', '3.2', '2.8', '0.7']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train[train['engineDisplacement'].isin(engineDisplacement_list)]\ntrain = train.reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# из-за ошибок попадаются не верные числа, а также есть не нужная приставка LTR - исправим это и сократим список этого категориального признака\nfor index, value in enumerate(train['engineDisplacement']):\n    train['engineDisplacement'][index] = re.sub(r'(\\d).*(\\d)', '\\\\1\\\\2', value)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# есть явные мелкие значения, которые можно сократить\ntrain['enginePower'].value_counts(ascending=True).plot(kind='barh')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# сделаем из этого признака тоже числовой\nfor index, value in enumerate(train['enginePower']):\n    train['enginePower'][index] = re.sub(r'(\\d*)\\s(12)$', '\\\\1', value)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# есть явные мелкие значения, которые можно сократить\ntrain['vehicleConfiguration'].value_counts(ascending=True).plot(kind='barh')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['vehicleConfiguration'].value_counts()[:200].sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# сократим мало популярные варианты engineDisplacement\ntrain = train[train['vehicleConfiguration'].isin(train['vehicleConfiguration'].value_counts()[:200].index)]\ntrain = train.reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Переводим признаки из float в int (иначе catboost выдает ошибку)\ntrain_preproc = train.copy()\nfor feature in ['mileage', 'modelDate', 'productionDate', 'engineDisplacement', 'enginePower']:\n    train_preproc[feature]=train_preproc[feature].astype('int32')\n    \nX_sub = test.copy()\nfor feature in ['mileage', 'modelDate', 'productionDate']:\n    X_sub[feature]=X_sub[feature].astype('int32')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preproc_data(df_input):\n    '''includes several functions to pre-process the predictor data.'''\n    \n    df_output = df_input.copy()    \n        \n    # ################### Feature Engineering ####################################################\n    # тут ваш код на генерацию новых фитчей\n    \n    # заполняем самым популярным значением пропущенные значения\n    df_output['ПТС'] = df_output['ПТС'].fillna(df_output['ПТС'].value_counts().index[0])\n\n    df_output['Владельцы'] = df_output['Владельцы'].fillna(0) # заполняем нулями пропуски\n\n    df_output['Владельцы'] = df_output['Владельцы'].astype('str')\n    df_output['numberOfDoors'] = df_output['numberOfDoors'].astype('str')\n\n    iterator = 0\n    for x in df_output.isna().sum():\n        col = df_output.isna().sum().index[iterator] # формируем название столбца\n        if x < 200:\n            df_output = df_output.dropna(subset=[col]) # всё что меньше 200 пропусков - удаляем всю строку\n        else:\n            df_output[col] = df_output[col].fillna(df_output[col].value_counts().index[0]) # где больше 200 пропусков - заполняем ячейки самыми популярными значениями\n        iterator += 1\n    \n    # заполняем пропуски средним значением\n    df_output.loc[df_output['mileage'] == 0, 'mileage'] = df_output[df_output['mileage'] > 0]['mileage'].mean()\n\n    # функция удаления выбросов\n    def remove_outlier(df_in, col_name):\n        q1 = df_in[col_name].quantile(0.25)\n        q3 = df_in[col_name].quantile(0.75)\n        iqr = q3-q1 #Interquartile range\n        fence_low  = q1-1.5*iqr\n        fence_high = q3+1.5*iqr\n        df_out = df_in.loc[(df_in[col_name] > fence_low) & (df_in[col_name] < fence_high)]\n        return df_out\n\n    # применяем функцию\n    df_output = remove_outlier(df_output, 'modelDate')\n    df_output = remove_outlier(df_output, 'productionDate')\n    try:\n        df_output = remove_outlier(df_output, 'price')\n    except:\n        df_output = df_output\n    df_output = remove_outlier(df_output, 'mileage')\n    df_output = df_output.reset_index(drop=True)\n\n    # сократим мало популярные варианты bodyType\n    df_output = df_output[df_output['bodyType'].isin(df_output['bodyType'].value_counts()[:10].index)]\n    df_output = df_output.reset_index(drop=True)\n    \n    # сделаем из этого признака тоже числовой\n    for index, value in enumerate(df_output['enginePower']):\n        df_output['enginePower'][index] = re.sub(r'(\\d*).*(12)$', '\\\\1', value)\n\n    # сократим мало популярные варианты vehicleConfiguration\n    df_output = df_output[df_output['vehicleConfiguration'].isin(df_output['vehicleConfiguration'].value_counts()[:200].index)]\n    df_output = df_output.reset_index(drop=True)\n    \n    # ################### fix ############################################################## \n    # Переводим признаки из float в int (иначе catboost выдает ошибку)\n    for feature in ['mileage', 'modelDate', 'productionDate', 'enginePower']:\n        df_output[feature]=df_output[feature].astype('int32')\n    \n    return df_output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Для тестовой выборки пишем другую функцию обработки, по скольку в тренировочной выборке мы удаляем выбросы и другие мало популярные значения. В тестовой не будем этого делать.","metadata":{}},{"cell_type":"code","source":"def preproc_data_test(df_input):\n    '''includes several functions to pre-process the predictor data.'''\n    \n    df_output = df_input.copy()    \n        \n    # ################### Feature Engineering ####################################################\n    # тут ваш код на генерацию новых фитчей\n    \n    # заполняем самым популярным значением пропущенные значения\n    df_output['ПТС'] = df_output['ПТС'].fillna(df_output['ПТС'].value_counts().index[0])\n\n    df_output['Владельцы'] = df_output['Владельцы'].fillna(0) # заполняем нулями пропуски\n\n    df_output['Владельцы'] = df_output['Владельцы'].astype('str')\n    df_output['numberOfDoors'] = df_output['numberOfDoors'].astype('str')\n       \n    # заполняем пропуски средним значением\n    df_output.loc[df_output['mileage'] == 0, 'mileage'] = df_output[df_output['mileage'] > 0]['mileage'].mean()\n    \n    # сделаем из этого признака тоже числовой\n    for index, value in enumerate(df_output['enginePower']):\n        df_output['enginePower'][index] = re.sub(r'(\\d*).*(12)$', '\\\\1', value)\n    \n    # ################### fix ############################################################## \n    # Переводим признаки из float в int (иначе catboost выдает ошибку)\n    for feature in ['mileage', 'modelDate', 'productionDate', 'enginePower']:\n        df_output[feature]=df_output[feature].astype('int32')\n    \n    return df_output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_preproc = preproc_data(train)\nX_sub = preproc_data_test(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Случайный лес","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.datasets import load_boston\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_forest = RandomForestRegressor(random_state = RANDOM_SEED)\n\nX_RF = train_preproc[['mileage', 'modelDate', 'productionDate', 'enginePower']]\ny_RF = train_preproc.price.values\n\nX_RF_train, X_RF_test, y_RF_train, y_RF_test = train_test_split(X_RF, y_RF, test_size=0.3, random_state=RANDOM_SEED)\n\nscaler = StandardScaler()\nX_RF_train = scaler.fit_transform(X_RF_train)\nX_RF_test = scaler.transform(X_RF_test)\n\nrandom_forest.fit(X_RF_train, y_RF_train)\ny_RF_pred = random_forest.predict(X_RF_test)\n\nprint('MAPE: ', mape(y_RF_test, y_RF_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_forest_out_of_bag = RandomForestRegressor(oob_score=True,random_state = RANDOM_SEED)\n\nrandom_forest_out_of_bag.fit(X_RF_train, y_RF_train)\nprint('oob_score: ', random_forest_out_of_bag.oob_score_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Случайный лес дает вполне хороший результат МАРЕ = 0.104. Будем провобовать усреднить полученные результаты с CatBoost.","metadata":{}},{"cell_type":"markdown","source":"## Линейная регрессия","metadata":{}},{"cell_type":"markdown","source":"Пробовал делать линейную регрессию - результат слабый. MAPE около 0,49. Нет смысла усреднять с результатами CatBoost, где 0,11.","metadata":{}},{"cell_type":"code","source":"test_LR = test.copy()\n\ntest_LR = test_LR[test_LR['bodyType'].isin(test_LR['bodyType'].value_counts()[:10].index)]\ntest_LR = test_LR.reset_index(drop=True)\n\ntest_LR = pd.get_dummies(test_LR, columns=['Владельцы', 'brand', 'vendor', 'bodyType'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_LR = pd.get_dummies(train_LR, columns=['bodyType'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Опыты показали, что на качество линейной регрессии влияет разбиение OneHot признака \"Владельцы\", \"brand\", \"bodyType\". В то же время разбиение признака \"numberOfDoors\", \"color\", \"vehicleTransmission\" никак не повлияло на результат.\nТак же решил преобразовать \"engineDisplacement\" в числовой признак - удалось ещё немного улучшить регрессию.","metadata":{}},{"cell_type":"code","source":"train_preproc = train_LR.copy()\nfor feature in ['mileage', 'modelDate', 'productionDate']:\n    train_preproc[feature]=train_preproc[feature].astype('int32')\n    \nX_sub = test_LR.copy()\nfor feature in ['mileage', 'modelDate', 'productionDate']:\n    X_sub[feature]=X_sub[feature].astype('int32')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Пробовал нормализацию, результат не изменился.\nfrom sklearn import preprocessing\nimport pandas as pd\n\nscaler = preprocessing.MinMaxScaler()\n\nd = scaler.fit_transform(train_preproc[['mileage', 'modelDate','productionDate']])\n\nscaled_df = pd.DataFrame(d, columns=['mileage', 'modelDate','productionDate'])\nscaled_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_preproc[['mileage', 'modelDate','productionDate']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# разбиваем выборку на тестовую и обучающую\nfrom sklearn.model_selection import train_test_split\n\nX_LR = train_preproc[['mileage', 'modelDate', 'productionDate', 'Владельцы_0.0', 'Владельцы_1.0', 'Владельцы_2.0', 'Владельцы_3.0', 'Владельцы_4.0',\\\n                     'brand_AUDI', 'brand_BMW', 'brand_CADILLAC', 'brand_CHANGAN', 'brand_CHERY','brand_CHEVROLET', 'brand_CHRYSLER', 'brand_CITROEN', 'brand_DAEWOO',\\\n                       'brand_DAIHATSU', 'brand_DATSUN', 'brand_DODGE', 'brand_FIAT','brand_FORD', 'brand_GEELY', 'brand_GREAT_WALL', 'brand_HAVAL',\\\n                       'brand_HONDA', 'brand_HYUNDAI', 'brand_INFINITI', 'brand_JAGUAR','brand_JEEP', 'brand_KIA', 'brand_LAND_ROVER', 'brand_LEXUS',\\\n                       'brand_LIFAN', 'brand_MAZDA', 'brand_MERCEDES', 'brand_MINI','brand_MITSUBISHI', 'brand_NISSAN', 'brand_OPEL', 'brand_PEUGEOT',\\\n                       'brand_PORSCHE', 'brand_RENAULT', 'brand_SKODA', 'brand_SSANG_YONG','brand_SUBARU', 'brand_SUZUKI', 'brand_TOYOTA', 'brand_VOLKSWAGEN',\\\n                       'brand_VOLVO', 'brand_VORTEX', 'bodyType_Внедорожник 5 дв.', 'bodyType_Компактвэн', 'bodyType_Купе', 'bodyType_Лифтбек',\\\n                       'bodyType_Минивэн', 'bodyType_Седан', 'bodyType_Универсал 5 дв.', 'bodyType_Хэтчбек 3 дв.', 'bodyType_Хэтчбек 5 дв.','bodyType_Хэтчбек 5 дв. Stepway',\\\n                       'vendor_AMERICAN', 'vendor_CHINESE','vendor_EUROPEAN', 'vendor_JAPANESE', 'vendor_KOREAN','vendor_RUSSIAN'\n                     ]]\ny_LR = train_preproc.price.values\n\n# Теперь с помощью этой функции мы получаем независимые и зависимые переменные из обучающей \n# и тестовой выборки. Размер тестовой выборки задаем 0,3.\nX_LR_train, X_LR_test, y_LR_train, y_LR_test = train_test_split(X_LR, y_LR, test_size=VAL_SIZE, random_state=RANDOM_SEED)\n\n# Теперь обучим модель линейной регрессии:\nfrom sklearn.linear_model import LinearRegression\nLR_Model = LinearRegression() #Обозначаем, что наша модель - линейная регрессия\nLR_Model.fit(X_LR_train,y_LR_train) #обучаем модель на обучающих данных","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Теперь можем попробовать предсказать значения зависимой переменной для тестовой выборки:\ny_LR_pred = LR_Model.predict(X_LR_test)\ny_LR_pred\n\ndef mape(y_true, y_pred):\n    return np.mean(np.abs((y_pred-y_true)/y_true))\n\nprint(mape(y_LR_test, y_LR_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Изначально без каких либо предобработок линейная регрессия давала ужасный результат около 2. После удаления выбросов и заполнения нулевых значений результат МАРЕ уже 0,487. Движемся в нужном направлении!","metadata":{}},{"cell_type":"markdown","source":"## CatBoost","metadata":{}},{"cell_type":"code","source":"X = train_preproc.drop(['price'], axis=1,)\ny = train_preproc.price.values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=VAL_SIZE, shuffle=True, random_state=RANDOM_SEED)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Keep list of all categorical features in dataset to specify this for CatBoost\ncat_features_ids = np.where(X_train.apply(pd.Series.nunique) < 4500)[0].tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_features_ids","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_features_ids = [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fit","metadata":{}},{"cell_type":"code","source":"model = CatBoostRegressor(iterations = ITERATIONS,\n                          learning_rate = LR,\n                          random_seed = RANDOM_SEED,\n                          eval_metric='MAPE',\n                          custom_metric=['R2', 'MAE']\n                         )\nmodel.fit(X_train, y_train,\n         cat_features=cat_features_ids,\n         eval_set=(X_test, y_test),\n         verbose_eval=100,\n         use_best_model=True,\n         plot=True\n         )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_model('catboost_single_model_baseline.model')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CatBoost после всех преобразований дал 10,69%. Не плохо, учитывая минимум преобразований и еще огромный потенциал при работе с другими данными. К сожалению в рамках такого проекта времени нету, но если бы это была действительно важная задача - тут можно еще очень много признаков формировать из словарей, которые были удалены вначале и группировать уже существующие признаки.","metadata":{}},{"cell_type":"markdown","source":"## Усредним значения полученные с Случайного леса и CatBoost.","metadata":{}},{"cell_type":"code","source":"predict_submission_RF = random_forest.predict(X_sub[['mileage', 'modelDate', 'productionDate', 'enginePower']])\npredict_submission_CB = model.predict(X_sub)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_arr = np.array([predict_submission_RF, predict_submission_CB])\nprice = mean_arr.mean(axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"#predict_submission = model.predict(X_sub)\n#predict_submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission['price'] = price\nsample_submission.to_csv(f'submission_v{VERSION}.csv', index=False)\nsample_submission.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}