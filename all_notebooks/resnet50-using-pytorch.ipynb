{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# importing all the libraries we need\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport time\nimport random\nimport pandas as pd\nimport torch\nfrom torch import nn, cuda, optim\nfrom torchvision import models,transforms,datasets\nfrom torch.utils.data import DataLoader,random_split\nfrom PIL import Image\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Knowing the data \ndata_dir = '/kaggle/input/100-bird-species/175/'\nclasses = []\nimg_per_class = []\nfor folder in os.listdir(data_dir+'consolidated'):\n    classes.append(folder)\n    img_per_class.append(len(os.listdir(f'{data_dir}consolidated/{folder}')))\nnum_classes = len(classes)\ndf = pd.DataFrame({'Classes':classes, 'Examples':img_per_class})\ndf","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# i didn't run due to its size \nsamples = []\nnum_per_class = 1\nfor folder in range(num_per_class):\n    for species in os.listdir(data_dir+'consolidated'):\n        samples.append(os.path.join(f'{data_dir}consolidated/{species}',\n                                    random.choice(os.listdir(f'{data_dir}consolidated/{species}/'))))\n# plotting some images to know the data        \nplt.figure(figsize=(20,100))\nfor n in range(len(samples)):\n    plt.subplot(35,5,n+1)\n    plt.imshow(Image.open(samples[n]))\n    plt.title(classes[n])\n    plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading the model architecture\nmodel = models.resnet50(pretrained=True)\n\n# freezing all the parameters from training \nfor param in model.parameters():\n    param.require_grad = False\n    \n# adding a fc layer with relu activation and a dropout layer to prevent overfitting then output layer with num of classes\nmodel.fc = nn.Sequential(nn.Linear(model.fc.in_features,1024),\n                         nn.ReLU(),\n                         nn.Dropout(0.3),\n                         nn.Linear(1024,num_classes))\nmodel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# class Net(nn.Module):\n#     def __init__(self):\n#         super(Net, self).__init__()\n#         self.conv1 = nn.Conv2d(3, 32, 5, padding=2)\n#         self.bn1 = nn.BatchNorm2d(32)\n#         self.pool1 = nn.MaxPool2d(2,2)\n#         self.conv2 = nn.Conv2d(32,64,5, padding=2)\n#         self.bn2 = nn.BatchNorm2d(64)\n#         self.pool2 = nn.MaxPool2d(2,2)\n#         self.conv3 = nn.Conv2d(64,128,5, padding=2)\n#         self.bn3 = nn.BatchNorm2d(128)\n#         self.pool3 = nn.MaxPool2d(2,2)\n#         self.dropout1 = nn.Dropout(0.4)\n#         self.fc1 = nn.Linear(28*28*128,1024)\n#         self.dropout2 = nn.Dropout(0.4)\n#         self.fc2 = nn.Linear(1024,num_classes)\n        \n#     def forward(self,x):\n#         x = self.pool1(nn.functional.relu(self.bn1(self.conv1(x))))\n#         x = self.pool2(nn.functional.relu(self.bn2(self.conv2(x))))\n#         x = self.pool3(nn.functional.relu(self.bn3(self.conv3(x))))\n#         x = self.dropout1(x)\n#         x = x.view(x.size(0),-1)\n#         x = nn.functional.relu(self.fc1(x))\n#         x = self.dropout2(x)\n#         x = self.fc2(x)\n#         return x\n        \n# model = Net()        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda:0' if cuda.is_available() else 'cpu')\nmodel.to(device)\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# doing data augmentation \ntrain_transform = transforms.Compose([transforms.Resize((224,224)),transforms.RandomRotation(45),transforms.RandomHorizontalFlip(),\n                                      transforms.RandomVerticalFlip(),transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\nval_transform = transforms.Compose([transforms.Resize((224,224)),transforms.RandomRotation(45),transforms.RandomHorizontalFlip(),\n                                    transforms.RandomVerticalFlip(),transforms.ToTensor(),\n                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\ntest_transform = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor(),\n                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting the data into train/validation/test sets\ndata = datasets.ImageFolder(data_dir+'consolidated')\ntrain_size = int(len(data)*0.9)\nval_size = int((len(data)-train_size)*0.7)\ntest_size = int(len(data)-train_size-val_size)\ntrain_data,val_data,test_data = random_split(data,[train_size,val_size,test_size])\nprint(f'train size: {len(train_data)}\\nval size: {len(val_data)}\\ntest size: {len(test_data)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.dataset.transform = train_transform\nval_data.dataset.transform = val_transform\ntest_data.dataset.transform = test_transform\nbatch_size = 16\ntrain_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True)\nval_loader = DataLoader(val_data,batch_size=batch_size,shuffle=True)\ntest_loader = DataLoader(test_data,batch_size=batch_size,shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(),lr=0.0001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit(model,criterion,optimizer,num_epochs=10):\n    start = time.time()\n    best_model = model.state_dict()\n    best_acc = 0.0\n    train_loss_over_time = []\n    val_loss_over_time = []\n    train_acc_over_time = []\n    val_acc_over_time = []\n    \n    # each epoch has a training and validation phase\n    for epoch in range(num_epochs):\n        print(f'{epoch+1}/{num_epochs} epoch')\n        \n        for phase in ['train','val']:\n            \n            if phase == 'train':\n                data_loader = train_loader\n                model.train()                    # set the model to train mode\n            else:\n                data_loader = val_loader\n                model.eval()                    # set the model to evaluate mode\n                \n            running_loss = 0.0\n            running_corrects = 0.0\n            \n            # iterate over the data\n            for inputs,labels in data_loader:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                \n                # zero the parameter gradients\n                optimizer.zero_grad()\n                \n                # forward\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _,pred = torch.max(outputs,dim=1)\n                    loss = criterion(outputs,labels)\n                    \n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                \n                # calculating the loss and accuracy\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(pred == labels.data)\n                \n            if phase == 'train':\n                epoch_loss = running_loss/len(train_data)\n                train_loss_over_time.append(epoch_loss)\n                epoch_acc = running_corrects.double()/len(train_data)\n                train_acc_over_time.append(epoch_acc)\n            else:\n                epoch_loss = running_loss/len(val_data)\n                val_loss_over_time.append(epoch_loss)\n                epoch_acc = running_corrects.double()/len(val_data)\n                val_acc_over_time.append(epoch_acc)\n                \n            print(f'{phase} loss: {epoch_loss:.3f}, acc: {epoch_acc:.3f}')\n            \n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model = model.state_dict()\n                \n        print('-'*60)\n    \n    total_time = (time.time() - start)/60\n    print(f'training complete in: {total_time:.3f} min\\nbest accuracy: {best_acc:.3f}')\n    # load best model weights\n    model.load_state_dict(best_model)\n    loss = {'train':train_loss_over_time, 'val':val_loss_over_time}\n    acc = {'train':train_acc_over_time, 'val':val_acc_over_time}\n    return model,loss,acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training the model\n# trained for 5 epochs then for 3 epochs then 2\nepochs = 2\nhistory,loss,acc = fit(model,criterion,optimizer,num_epochs=epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting the loss and accuracy curve for each phase\ntrain_loss = loss['train']\nval_loss = loss['val']\ntrain_acc = acc['train']\nval_acc = acc['val']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(20,10))\n\nplt.subplot(1,2,1)\nplt.plot(epochs_range,train_loss,label='train_loss')\nplt.plot(epochs_range,val_loss,label='val_loss')\nplt.legend(loc=0)\nplt.title('Loss')\n\nplt.subplot(1,2,2)\nplt.plot(epochs_range,train_acc,label='train_acc')\nplt.plot(epochs_range,val_acc,label='val_acc')\nplt.legend(loc=0)\nplt.title('Accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# testing how good the model is\ndef evaluate(model,criterion):\n    model.eval()       # setting the model to evaluate mode\n    test_loss = 0.0\n    test_acc = 0.0\n    preds = []\n    labels_list = []\n    \n    for inputs,labels in test_loader:\n        \n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        # predicting\n        with torch.no_grad():\n            outputs = model(inputs)\n            loss = criterion(outputs,labels)\n            _,pred = torch.max(outputs,dim=1)\n            preds.append(pred)\n            labels_list.append(labels)\n        \n        # calculating the loss and accuracy \n        test_loss += loss.item()*inputs.size(0)        \n        correct = pred.eq(labels.data.view_as(pred))\n        accuracy = torch.mean(correct.type(torch.FloatTensor))\n        test_acc += accuracy.item() * inputs.size(0)\n    \n    # avreging the loss and accuracy\n    test_loss = test_loss/len(test_loader.dataset)\n    test_acc = test_acc / len(test_loader.dataset)\n        \n    print(\"test loss: {:.4f}  test acc: {:.4f}\".format(test_loss,test_acc))\n    return preds,labels_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# testing the model\npredictions,labels = evaluate(model,criterion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# the model's name\nmodel_name = 'model_resnet50.pt'\n# saving the best trained model\ntorch.save(model.state_dict(),model_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading the model to evaluate\nmodel.load_state_dict(torch.load('model_resnet50.pt'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicting on image from the web\nfrom urllib import request\nimg_urls = ['https://i2.wp.com/www.casablanca-nuernberg.de/wp-content/uploads/2018/09/albatross.jpg?w=660&ssl=1','https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcS2v3aWxgzOb-SWhtQRCk0KdAb9iY_RNe8UcETwBFhyafDW6oFg']\nimgs = []\npredictions = []\nfor img_url in img_urls:\n    img = Image.open(request.urlopen(img_url))\n    imgs.append(img)\n    img_transform = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor(),\n                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n    img = img_transform(img)\n    img = img.unsqueeze(0)\n    img = img.to(device)\n    model.eval()\n    outputs = model(img)\n    _,pred = torch.max(outputs,dim=1)\n    predictions.append(classes[pred])\n    \nplt.figure(figsize=(30,30))\nfor n in range(len(imgs)):\n    plt.subplot(8,8,n+1)\n    plt.imshow(imgs[n])\n    plt.title(\"Predicted: \"+predictions[n])\n    plt.axis('off')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":4}