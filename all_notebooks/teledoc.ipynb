{"cells":[{"metadata":{"id":"MPZoz6htj1Un","outputId":"96ddaf72-9560-45dc-821e-631c42b90244","trusted":true},"cell_type":"code","source":"import numpy as np # For numerical computation\nimport pandas as pd # Data manipulation\nimport seaborn as sns # plotting\nimport scipy.io # reading matlab files in python\nfrom scipy import signal #signal processing\nfrom scipy.fftpack import fft, dct #signal processing\n\nfrom sklearn.linear_model import LinearRegression #linear regression model\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import KFold, train_test_split # cross validation split\nfrom sklearn.metrics import mean_squared_error\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom matplotlib import pyplot as plt # For plotting graphs(Visualization)\n\nimport os # system-wide functions\nos.listdir('/kaggle/input/BloodPressureDataset')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# defining our evaluation error function\ndef rmse(y_true, y_pred):\n    \"\"\"Computes the Root Mean Squared Error (RMSE).\"\"\"\n    return np.sqrt(mean_squared_error(y_true, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_file = scipy.io.loadmat(f'../input/BloodPressureDataset/part_{1}.mat')\nsample_file.update(scipy.io.loadmat(f'../input/BloodPressureDataset/part_{2}.mat'))\nprint(f'sample_file Data type: {type(sample_file)}')\nprint(sample_file['p'].shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_file","execution_count":null,"outputs":[]},{"metadata":{"id":"eSz2jtgSKxES","trusted":true},"cell_type":"code","source":"# Loading a sample .mat file to understand the data dimensions\ntest_sample = scipy.io.loadmat(f'../input/BloodPressureDataset/part_{2}.mat')['p']\nprint(f'test_sample Data type: {type(test_sample)}')\nprint(f'test_sample shape/dimensions: {test_sample.shape}')","execution_count":null,"outputs":[]},{"metadata":{"id":"ROoUlWP0LKnX","outputId":"69e837b2-8ac5-4494-efe8-716eba75fd60","trusted":true},"cell_type":"code","source":"print(f\"Total Samples: {len(test_sample[0])}\")\nprint(f\"Number of readings in each sample(column): {len(test_sample[0][0])}\")\nprint(f\"Number of samples in each reading(ECG): {len(test_sample[0][0][2])}\")\n\ntemp_mat = test_sample[0, 999]\ntemp_length = temp_mat.shape[1]\nsample_size = 125\n\n\nprint(temp_length)\nprint((int)(temp_length/sample_size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sample.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_size = 125\nppg = []\nfor i in range(1000):\n    temp_mat = test_sample[0, i]\n    temp_length = temp_mat.shape[1]\n    for j in range((int)(temp_length/sample_size)):\n        temp_ppg = temp_mat[0, j*sample_size:(j+1)*sample_size]\n        ppg.append(temp_ppg)","execution_count":null,"outputs":[]},{"metadata":{"id":"EMzlCKipxTlT","trusted":true},"cell_type":"code","source":"ecg = []\nbp = []\nsbp = [] #Systolic Blood Pressure\ndbp = [] #Diastolic Blood Pressue\nsize = 125 #sample size\n\nfor i in range(1000):\n    temp_mat = test_sample[0, i]\n    temp_length = temp_mat.shape[1]\n    for j in range((int)(temp_length/sample_size)):\n        temp_ecg = temp_mat[2, j*size:(j+1)*size]\n        temp_bp = temp_mat[1, j*size:(j+1)*size]\n        \n        max_value = max(temp_bp)\n        min_value = min(temp_bp)\n        \n        sbp.append(max_value)\n        dbp.append(min_value)\n        ecg.append(temp_ecg)\n        bp.append(temp_bp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ppg, ecg, bp = np.array(ppg).reshape(-1,1), np.array(ecg).reshape(-1,1), np.array(bp).reshape(-1,1)\nsbp, dbp = np.array(sbp).reshape(-1,1), np.array(dbp).reshape(-1,1)\nprint(f'PPG_shape: {ppg.shape}\\n ECG_shape: {ecg.shape}\\n BP_shape: {bp.shape}')\nprint(f'Systolic-BP_shape: {sbp.shape},\\n Diastolic-BP_shape: {dbp.shape}')","execution_count":null,"outputs":[]},{"metadata":{"id":"nRjehDvyxVN7","outputId":"80b7614b-e1c5-457f-8fd5-40a0e18f2393","trusted":true},"cell_type":"code","source":"\nfig, ax = plt.subplots(3,1, figsize=(9,12), sharex=True)\n\nax[0].set_title('PPG graph', fontsize=16)\nax[0].set_ylabel('Signal Value')\nax[0].plot(ppg[:125])\n\nax[1].set_title('ECG graph', fontsize=16)\nax[1].set_ylabel('Signal Value')\nax[1].plot(ecg[:125])\n\nax[2].set_title('Blood Pressure (BP) graph', fontsize=16)\nax[2].set_ylabel('Signal Value')\nax[2].set_xlabel('Sample size')\nax[2].plot(bp[:125])","execution_count":null,"outputs":[]},{"metadata":{"id":"2jegyBKExWmf","outputId":"699b86e1-2462-48ea-d35e-bcf883a63411","trusted":true},"cell_type":"code","source":"\n\nplt.title('SBP vs DBP graph', fontsize=16)\nplt.ylabel('Signal Value')\nplt.plot(sbp[:125])\nplt.plot(dbp[:125])\nplt.legend(['SBP', 'DBP'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(ppg[:125].squeeze())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_corr = np.convolve(ppg[:125].squeeze(), bp[:125].squeeze(), mode='full')\n\nfig, ax = plt.subplots(3,1, figsize=(9,12), sharex=True)\n\nax[0].set_title('PPG graph', fontsize=16)\nax[0].set_ylabel('Signal Value')\nax[0].plot(ppg[:125])\n\nax[1].set_title('BP graph', fontsize=16)\nax[1].set_ylabel('Signal Value')\nax[1].plot(bp[:125])\n\nax[2].set_title('Cross-correlated resultant graph', fontsize=16)\nax[2].set_ylabel('Signal Value')\nax[2].set_xlabel('Sample size')\nax[2].plot(cross_corr[:125])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Computing the discrete cosine transform (DCT)\ncosine_transformed_array = dct(ppg)\nerror = rmse(bp.squeeze(), cosine_transformed_array.squeeze())\nprint(f'RMSE: {error}')","execution_count":null,"outputs":[]},{"metadata":{"id":"lYe0oujixYPb","outputId":"7849f9de-c0cf-4ea7-e7da-718d5a2cc948","trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(ppg, bp, test_size=0.30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folds = KFold(n_splits=5, shuffle=False)\nscores = []\nfor i, (train_index, val_index) in enumerate(folds.split(X_train, y_train)):\n    train_data, target = X_train[train_index], y_train[train_index]\n    validation_data, val_target = X_train[val_index], y_train[val_index]\n    \n    model = LinearRegression()\n    model.fit(train_data, target)\n    #model = RandomForestRegressor(n_estimators=50,max_depth=5, n_jobs=-1, random_state=42)\n    #model.fit(train_data[:100000], target[:100000].squeeze())  # training on few samples to save time.\n    val_predictions = model.predict(validation_data)\n    error = rmse(val_target, val_predictions)\n    scores.append(error)\n    print(f'Fold {i} RMSE: {error}')\nprint(f'Average RMSE over 5 folds: {np.mean(scores)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing train error.\nfig, ax = plt.subplots(1,2, figsize=(16,6))\nax[0].set_title(\"=======Training error=======\")\nax[0].set_xlabel('Number of folds')\nax[0].set_ylabel('Error values')\nax[0].plot(scores)\n\n# Visualize predicted BP and the True BP\nax[1].set_title(\"===True BP values Vs Predicted BP values===\")\nax[1].set_xlabel('Number of samples taken')\nax[1].set_ylabel('BP values')\nax[1].plot(val_target[:100]) #only plotting 100 samples\nax[1].plot(val_predictions[:100])\nax[1].legend(['True_BP', 'Predicted_BP'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting on the test set\ntest_predictions = model.predict(X_test[:1000000]) #predicting on the first 1million rows for speed.\ntest_error = rmse(y_test[:1000000], test_predictions)\nprint(f'Error on test set predictions: {test_error}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import optimizers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Model(input_dim, activation, num_class):\n    model = Sequential()\n\n    model.add(Dense(1024, input_dim = input_dim))\n    model.add(Activation(activation))\n    model.add(Dropout(0.5))\n\n    model.add(Dense(512)) \n    model.add(Activation(activation))\n    model.add(Dropout(0.5))\n\n    model.add(Dense(64))    \n    model.add(Activation(activation))\n    model.add(Dropout(0.25))\n\n    model.add(Dense(num_class))    \n    model.add(Activation('linear'))\n    \n    model.compile(loss='Huber',\n                  optimizer=optimizers.Adam(lr = 0.001),\n                  metrics=['MeanAbsoluteError']\n                 )\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_dim = X_train.shape[1]\nactivation = 'relu'\nclasses = 1\nmodel = Model(input_dim=input_dim, activation=activation, num_class=classes)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing the model\ntf.keras.utils.plot_model(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the model\nhistory = model.fit(X_train[:1000000], # using the first 1million rows for speed.\n                    y_train[:1000000].squeeze(),\n                    epochs=5,\n                    batch_size=128,\n                    verbose = 1\n                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test[:1000000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k=np.array([[0.58455523]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nn_predictions = model.predict(k)\nprint(nn_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights(\"1.ckpt\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a new model instance\ninput_dim = X_train.shape[1]\nactivation = 'relu'\nclasses = 1\nmodel = Model(input_dim=input_dim, activation=activation, num_class=classes)\n\n# Load the previously saved weights\nmodel.load_weights(\"1.ckpt\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nn_predictions = model.predict(k)\nnn_predictions ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading a sample .mat file to understand the data dimensions\nfor s in range(2,12):\n    # Create a new model instance\n    test_sample = scipy.io.loadmat('../input/BloodPressureDataset/part_{}.mat'.format(s+1))['p']\n    print(f'test_sample Data type: {type(test_sample)}')\n    print(f'test_sample shape/dimensions: {test_sample.shape}')\n    print(f\"Total Samples: {len(test_sample[0])}\")\n    print(f\"Number of readings in each sample(column): {len(test_sample[0][0])}\")\n    print(f\"Number of samples in each reading(ECG): {len(test_sample[0][0][2])}\")\n\n    temp_mat = test_sample[0, 999]\n    temp_length = temp_mat.shape[1]\n    sample_size = 125\n\n\n    print(temp_length)\n    print((int)(temp_length/sample_size))\n    sample_size = 125\n    ppg = []\n    for i in range(1000):\n        temp_mat = test_sample[0, i]\n        temp_length = temp_mat.shape[1]\n        for j in range((int)(temp_length/sample_size)):\n            temp_ppg = temp_mat[0, j*sample_size:(j+1)*sample_size]\n            ppg.append(temp_ppg)\n            ecg = []\n    bp = []\n    sbp = [] #Systolic Blood Pressure\n    dbp = [] #Diastolic Blood Pressue\n    size = 125 #sample size\n\n    for i in range(1000):\n        temp_mat = test_sample[0, i]\n        temp_length = temp_mat.shape[1]\n        for j in range((int)(temp_length/sample_size)):\n            temp_ecg = temp_mat[2, j*size:(j+1)*size]\n            temp_bp = temp_mat[1, j*size:(j+1)*size]\n\n            max_value = max(temp_bp)\n            min_value = min(temp_bp)\n\n            sbp.append(max_value)\n            dbp.append(min_value)\n            ecg.append(temp_ecg)\n            bp.append(temp_bp)\n\n\n    ppg, ecg, bp = np.array(ppg).reshape(-1,1), np.array(ecg).reshape(-1,1), np.array(bp).reshape(-1,1)\n    sbp, dbp = np.array(sbp).reshape(-1,1), np.array(dbp).reshape(-1,1)\n    print(f'PPG_shape: {ppg.shape}\\n ECG_shape: {ecg.shape}\\n BP_shape: {bp.shape}')\n    print(f'Systolic-BP_shape: {sbp.shape},\\n Diastolic-BP_shape: {dbp.shape}')\n\n\n\n    X_train, X_test, y_train, y_test = train_test_split(ppg, bp, test_size=0.30)\n    input_dim = X_train.shape[1]\n    activation = 'relu'\n    classes = 1\n    model = Model(input_dim=input_dim, activation=activation, num_class=classes)\n\n    # Load the previously saved weights\n    model.load_weights(\"{}.ckpt\".format(s))\n    history = model.fit(X_train[:1000000], # using the first 1million rows for speed.\n                        y_train[:1000000].squeeze(),\n                        epochs=5,\n                        batch_size=128,\n                        verbose = 1\n                       )\n    model.save_weights(\"{}.ckpt\".format(s+1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predicting on the test set using the nn(neural network) model\nnn_predictions = model.predict(X_test[:1000000])\nerror = rmse(y_test[:1000000], nn_predictions)\nprint(f'Neural Net RMSE: {error}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Train loss against mean_absolute_error')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.plot(history.history['loss'])\nplt.plot(history.history['mean_absolute_error'])\nplt.legend(['Loss', 'Mean_absolute_error'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize predicted BP and the True BP\nplt.title(\"===True BP values Vs Predicted BP values===\")\nplt.xlabel('Number of samples taken')\nplt.ylabel('BP values')\nplt.plot(y_test[:100]) #only plotting 100 samples\nplt.plot(nn_predictions[:100])\nplt.legend(['True_BP', 'Predicted_BP'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}