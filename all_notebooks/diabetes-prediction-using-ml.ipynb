{"cells":[{"metadata":{"_uuid":"b7c1b341b7ec00e2e67df1887bb62587a355d791"},"cell_type":"markdown","source":"# Introduction:\nThe challenge/goal of the project is to see how accurately we can predict weather a given patient has diabetes or not. Do we use all the features at our disposal ? or do we choose a subset to corelate with the 'Outcome' field? In this case it will be observed that removing certain features actually increase the accuracy of the prediction. In a previous [runbook](https://www.kaggle.com/arjunshenoymec/diabetes-prediction-using-svm) I attempted an approach of randomly removing variables (mostly based on intuition) to see which combination of features produced the maximum accuracy. The largest I could get was 77.47%.\n\nIn this runbook I am attempting a more organized approach based on statistical techniques to find out two things:\n* A way to methodically select the most appropriate features, such that the particular subset results in maximum accuracy.\n* To see if the accuracy of the models can be pushed beyond 77.4%. \n\n\n## Loading Libraries:\nAll the required import statements were put into this particular block along with the set of statements to initialize the dataset. "},{"metadata":{"trusted":true,"_uuid":"02dd4f85809b5ad72092fbad6e39babd8887b4c0","collapsed":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport os\nfrom matplotlib import pyplot as plt\nimport math\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\n\npatient_data = pd.read_csv(\"../input/diabetes.csv\")\nprint(patient_data.dtypes)\nprint(patient_data.head())\npatient_data.describe()    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bc19530b69f8394ebb63d28316187caa16258085"},"cell_type":"markdown","source":"## Removing NaNs:\nThe first step is to check if there are any columns with NaN values this can be done with the pandas isnull() function. If there are any depending on they type of data being stores you can use the fillna() function to replace NaN with some appropriate value (Typically median values are used for numeric data). "},{"metadata":{"trusted":true,"_uuid":"bab48b7fa8873efe8634ebf24b1a1920a8b07ccf","collapsed":true},"cell_type":"code","source":"print(patient_data.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aea13e10a096080ccc190e7ea10283cdebc7b3de"},"cell_type":"markdown","source":"## Univariate Analysis and Binning\nThe intention here is to obtain counts and observe distribution of the variables. I used count plots for variables having descrete values (such as number of Pregnancies) and KDE (\"kernel density estimation (KDE) is a non-parametric way to estimate the probability density function of a random variable\") plots for variables having continuous values (eg: Insulin, BloodPressure). \n\nAnother Step that I took here is to create 'Bucket' and 'Log' variables for those which I saw skewed distributions. I also created 'AgeGroup' since that would also be more effective in observing trends (if any) rather than looking at raw Age value. "},{"metadata":{"trusted":true,"_uuid":"4e0ee4eaa71473942d53d25cccfd05f58b921df3","collapsed":true},"cell_type":"code","source":"# Note down all Transformations/new column creations here for clarity\npatient_data['GlucoseBucket'] = patient_data['Glucose'].map(lambda i: math.ceil(i/10))\npatient_data['SkinThicknessBucket'] = patient_data['SkinThickness'].map(lambda i: int(i/10))\npatient_data['InsulinBucket'] = patient_data['Insulin'].map(lambda i: int(i/100))\npatient_data['InsulinLog'] = patient_data['Insulin'].map(lambda i: np.log(i) if i > 0 else 0)\npatient_data['DiabetesPedigreeFunctionLog'] = patient_data['DiabetesPedigreeFunction'].map(lambda i: np.log(i) if i > 0 else 0)\npatient_data['DiabetesPedigreeFunctionBucket'] = patient_data['DiabetesPedigreeFunction'].map(lambda i: math.ceil(10*i))\npatient_data['AgeGroup'] = patient_data['Age'].map(lambda i: int(i/10))\npatient_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f70dbffbc310b0f9f39e15469ca7021d42233602","collapsed":true},"cell_type":"code","source":"patient_data.loc[:,['Insulin','InsulinLog','InsulinBucket']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e8bd68405e0255d2bb5820f7e914b6d805b75747","collapsed":true},"cell_type":"code","source":"patient_data.loc[:,['AgeGroup','GlucoseBucket', 'SkinThicknessBucket', 'DiabetesPedigreeFunctionBucket','InsulinBucket']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a333cbed7d07013ebf135d081634b9077125783a","collapsed":true},"cell_type":"code","source":"patient_data.loc[:,['DiabetesPedigreeFunction','DiabetesPedigreeFunctionLog','DiabetesPedigreeFunctionBucket']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d7c9c550c4089f547a6c7db5480c7c34edfeee7","collapsed":true},"cell_type":"code","source":"fig, ax = plt.subplots (3,3, figsize=(30,16))\nsns.countplot(\"Pregnancies\", data=patient_data, ax=ax[0][0])\nax[0][0].set_title(\"Pregnancy Distribution\")\nsns.kdeplot(patient_data['Glucose'], ax=ax[0][1])\nax[0][1].set_title(\"glucose Concentration\")\nsns.kdeplot(patient_data['BloodPressure'], ax=ax[0][2])\nax[0][2].set_title(\"Blood Pressure\")\nsns.kdeplot(patient_data['SkinThickness'], ax=ax[1][0])\nax[1][0].set_title(\"Skin Thickness\")\nsns.kdeplot(patient_data['Insulin'], ax=ax[1][1])\nax[1][1].set_title(\"Insulin\")\nsns.countplot(patient_data['Insulin'].map(lambda i: int(i/100)), ax=ax[1][2])\nax[1][2].set_title(\"Insulin (log10 Transformation)\")\nsns.kdeplot(patient_data['DiabetesPedigreeFunction'], ax=ax[2][0])\nax[2][0].set_title('DiabetesPedigreeFunction')\nsns.kdeplot(patient_data['DiabetesPedigreeFunction'].map(lambda i: np.log(i) if i > 0 else 0), ax=ax[2][1])\nax[2][1].set_title('DiabetesPedigreeFunction Log Transformation')\nsns.kdeplot(patient_data['BMI'], ax=ax[2][2])\nax[2][2].set_title('BMI')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"63e9c00d0c2c57b5c89cc45d48c7201bebf91324"},"cell_type":"markdown","source":"Here it can be seen in the case of insulin that using the log of insulin does not help much as it produces a new challenge of a valley in the middle. \n\n### Correlation between Outcome and Age\nHere we are using the \"ageGroup\" parameter to see if there is any direct correlation between \"Age\" and \"Outcome\".\n[20-30): bucket 2\n[30-40): bucket 3"},{"metadata":{"trusted":true,"_uuid":"304122a3f5928f261ebff21034fc8a8cd5b7c302","collapsed":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,1, figsize=(10, 5))\nsns.countplot(patient_data['AgeGroup'], hue=patient_data['Outcome'], ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"03e7b19bd88d89d5d91ee094c3769a4bf50ce901"},"cell_type":"markdown","source":"## Bi Variate and MultiVariate  Analysis\n\nMy Initial Aim here is to find out if there is any direct correlation between the individual parameters and the \"Outcome\" variable. \n"},{"metadata":{"trusted":true,"_uuid":"37e515897f816ad5b371362b4a3726c79a601978","scrolled":false,"collapsed":true},"cell_type":"code","source":"fig, ax = plt.subplots (3,3, figsize=(30,16))\nsns.boxplot(x='Outcome', y='Glucose', data=patient_data, ax=ax[0][0])\nsns.boxplot(x='Outcome', y='BloodPressure', data=patient_data, ax=ax[0][1])\nsns.boxplot(x='Outcome', y='SkinThickness', data=patient_data, ax=ax[0][2])\nsns.boxplot(x='Outcome', y='InsulinLog', data=patient_data, ax=ax[2][1]) # insulin Diabetees dependency tough to depict\nsns.boxplot(x='Outcome', y='InsulinBucket', data=patient_data, ax=ax[1][0]) \nsns.boxplot(x='Outcome', y='DiabetesPedigreeFunctionLog', data=patient_data, ax=ax[1][1])\nsns.boxplot(x='Outcome', y='DiabetesPedigreeFunctionBucket', data=patient_data, ax=ax[1][2])\nsns.boxplot(x='Outcome', y='BMI', data=patient_data, ax=ax[2][2])\nsns.boxplot(x='Outcome', y='Pregnancies', data=patient_data, ax=ax[2][0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1b8f4bc85eca522c9b3241ca00898849cbc296ed"},"cell_type":"markdown","source":"The next thing I am trying here is to figure out how the different parameteres are related to each other by using the 'Outcome' variable as the third variable (or hue in terms of plotting terminology). In otherwords how much two variables are related for those who have diabetees vs their relation for those who don't have diabetees. "},{"metadata":{"trusted":true,"_uuid":"f60fe4234256e3579cfce63406248246ad16cb70","collapsed":true},"cell_type":"code","source":"fig, ax = plt.subplots (3,3, figsize=(40,20))\nsns.boxplot(x='Pregnancies', y='BMI', hue='Outcome', data=patient_data, ax=ax[0][0])\nax[0][0].set_title(\"Pregnancies Vs BMI Vs Outcome\")\nsns.boxplot(x='GlucoseBucket', y='InsulinBucket', hue='Outcome', data=patient_data, ax=ax[0][1])\nsns.boxplot(x='GlucoseBucket', y='DiabetesPedigreeFunctionLog', hue='Outcome', data=patient_data, ax=ax[0][2])\nsns.boxplot(x='Pregnancies', y='BMI', data=patient_data, ax=ax[1][0])\nsns.boxplot(y='GlucoseBucket', x='SkinThicknessBucket', hue='Outcome', data=patient_data, ax=ax[1][1])\nsns.boxplot(y='InsulinBucket', x='SkinThicknessBucket', hue='Outcome', data=patient_data, ax=ax[1][2])\nsns.boxplot(x='Outcome', y='GlucoseBucket', data=patient_data, ax=ax[2][0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d472fd028a65535df92e1505eda4c0b6e66fd4e8"},"cell_type":"markdown","source":"### Heatmaps\n\nIn a last attempt to see the correlation between different variables in the dataset, I use correlation heatmaps which tell how much the variables effect each other. "},{"metadata":{"trusted":true,"_uuid":"e7d14968fe0da1a5957b5613bdf0a4b15601a74a","collapsed":true},"cell_type":"code","source":"fig, ax = plt.subplots (1,1, figsize=(20,10))\nf = patient_data.loc[:,['Pregnancies','GlucoseBucket','AgeGroup','DiabetesPedigreeFunctionLog','InsulinBucket','SkinThicknessBucket','BMI','BloodPressure', 'Outcome']].corr()\nsns.heatmap(f, annot=True, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d6221b441e34a3f1d73df31c24e3ee5321721259","collapsed":true},"cell_type":"code","source":"sns.heatmap(patient_data.loc[:,['Insulin','InsulinLog','InsulinBucket','Outcome']].corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f16548e2bc26767aad129a7e849e4b4782de608","collapsed":true},"cell_type":"code","source":"fig, ax = plt.subplots (1,1, figsize=(10,5))\nsns.heatmap(patient_data.loc[:,['DiabetesPedigreeFunction','DiabetesPedigreeFunctionLog','DiabetesPedigreeFunctionBucket','Glucose', 'GlucoseBucket','Outcome']].corr(),annot=True, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e63a526d82602795d49e73dfc2dc0d36ba703976"},"cell_type":"markdown","source":"## Classification\n\n### Creating a \"Classifier\" \nInstead of creating multiple classifiers and writing similar parts of the code over and over again or passing variables into a series of loosely coupled functions, I am going with the Object Oriented approach of creating a generic \"Classifier\".\n\n**constructor:**\n* accepts any basic classifier instance, along with a name (just a string type for later reference) and the set of parameters associated with the classifier (can be ignored if needed). \n* creates a GridSearchCV instance of the classifier along with the parameter. \n* sets the accuracy to \"None\".\n\n**fit_and_train:**\n* Accepts the subset of the data to be used for training along with the indices of the features to be used for training (As I mentioned in the intro, adding all the variables might not result in the highest accuracy).\n* Performs the fit for the classifier. \n\n**get_accuracy:**\n* Accepts the test dataset along with the indices of the features to be used. \n* Returns the accuracy.\n\n**get_overall_accuracy:**\n* An extended version of get_accuracy, which performs kfold CV and passes data to **fit_and_train()** and **get_accuracy()** during each iteration. The mean accuracy obtained is set as \"accuracy\" of the Classifier object."},{"metadata":{"trusted":true,"_uuid":"7eb3c8c77c3b9436793745efe0ad38b4f071ebca","collapsed":true},"cell_type":"code","source":"'''\nFor reference \n0 Pregnancies                         int64\n1 Glucose                             int64\n2 BloodPressure                       int64\n3 SkinThickness                       int64\n4 Insulin                             int64\n5 BMI                               float64\n6 DiabetesPedigreeFunction          float64\n7 Age                                 int64\n8 Outcome                             int64\n9 GlucoseBucket                       int64\n10 SkinThicknessBucket                 int64\n11 InsulinBucket                       int64\n12 InsulinLog                        float64\n13 DiabetesPedigreeFunctionLog       float64\n14 DiabetesPedigreeFunctionBucket      int64\n15 AgeGroup                            int64\n'''\nprint(patient_data.dtypes)\nsplit_num = 8\ndefault_param_set = [1,2,4,5,6,7] # The mysterious feature set which when produced the highest accuracy i've personally seen for the dataset (77.47%)\n# Generic class that can be used for any specific classifier\nclass Classifier:\n    \n    def __init__(self, clf_type, name, params=None):\n        self.name = name\n        self.clf = GridSearchCV(clf_type, params)\n        self.params = params\n        self.accuracy = None #initialized as None \n        print('Initializing done for %s classifier' % (name))\n    \n    def fit_and_train(self, train, param_set=None):\n        print('Fitting and training dataset for %s' % (self.name))\n        labels = train.Outcome\n        if param_set:\n            features = pd.DataFrame(train.iloc[:, param_set])\n        else:\n            features = pd.DataFrame(train.iloc[:, default_param_set])\n        print('Feature initializing complete')\n        self.clf.fit(features, labels)\n        print('Fit complete')\n        \n    def get_accuracy(self, test, param_set=None):\n        print('Accuracy iteration for %s' % (self.name))\n        labels_test = test.Outcome\n        if param_set:\n            features_test = pd.DataFrame(test.iloc[:, param_set])\n        else:\n            features_test = pd.DataFrame(test.iloc[:, default_param_set])\n        pred = self.clf.predict(features_test)\n        print('prediction for test features complete')\n        return accuracy_score(pred, labels_test)\n    \n    def get_overall_accuracy(self, df, param_set=None):\n        kf = KFold(n_splits=split_num, random_state=42, shuffle=True)\n        scores = []\n        for train_index, test_index in kf.split(df):\n            train = df.iloc[train_index]\n            test = df.iloc[test_index]\n            self.fit_and_train(train, param_set)\n            scores.append(self.get_accuracy(test, param_set))\n        self.accuracy = float(sum(scores)/split_num)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a6599db050e48e6abac3ca1b1a2f080a3a9b68f6"},"cell_type":"markdown","source":"### Normalization \nOne final step I am performing here is to scale all the variables that are to be used. So that the influence of each of the variables is equal. I am using a custom function to do so rather than the inbuilt library version. "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7c7b7c48cce0dba43e039a471c42d6d96ed6e0eb"},"cell_type":"code","source":"max_pregn = patient_data.Pregnancies.max()\nmin_pregn = patient_data.Pregnancies.min()\nmax_glucose = patient_data.Glucose.max()\nmin_glucose = patient_data.Glucose.min()\nmax_bp = patient_data.BloodPressure.max()\nmin_bp = patient_data.BloodPressure.min()\nmax_dpf = patient_data.DiabetesPedigreeFunction.max()\nmin_dpf = patient_data.DiabetesPedigreeFunction.min()\nmax_ins = patient_data.Insulin.max()\nmin_ins = patient_data.Insulin.min()\nmax_bmi = patient_data.BMI.max()\nmin_bmi = patient_data.BMI.min()\nmax_age = patient_data.Age.max()\nmin_age = patient_data.Age.min()\nmax_st = patient_data.SkinThickness.max()\nmin_st = patient_data.SkinThickness.min()\nmax_glucose_bucket = patient_data.GlucoseBucket.max()\nmin_glucose_bucket = patient_data.GlucoseBucket.min()\nmax_st_bucket = patient_data.SkinThicknessBucket.max()\nmin_st_bucket = patient_data.SkinThicknessBucket.min()\nmax_insulin_bucket = patient_data.InsulinBucket.max()\nmin_insulin_bucket = patient_data.InsulinBucket.min()\nmax_dpf_bucket = patient_data.DiabetesPedigreeFunctionBucket.max()\nmin_dpf_bucket = patient_data.DiabetesPedigreeFunctionBucket.min()\nmax_age_group = patient_data.AgeGroup.max()\nmin_age_group = patient_data.AgeGroup.min()\n\ndef normalize(srs, max_pregn_val, min_pregn_val, max_glucose_val, min_glucose_val, max_bp_val, min_bp_val, max_dpf_val, min_dpf_val, max_ins_val, min_ins_val, max_bmi_val, min_bmi_val, max_age_val, min_age_val, max_st_val, min_st_val, max_glucose_bucket_val, min_glucose_bucket_val, max_st_bucket_val, min_st_bucket_val, max_insulin_bucket_val, min_insulin_bucket_val, max_dpf_bucket_val, min_dpf_bucket_val, max_age_group_val, min_age_group_val):\n    srs.Pregnancies = float((srs.Pregnancies-min_pregn_val)/(max_pregn_val-min_pregn_val))\n    srs.Glucose = float((srs.Glucose - min_glucose_val)/(max_glucose_val - min_glucose_val))\n    srs.BloodPressure = float((srs.BloodPressure - min_bp_val)/(max_bp_val - min_bp_val))\n    srs.DiabetesPedigreeFunction = float((srs.DiabetesPedigreeFunction - min_dpf_val)/(max_dpf_val - min_dpf_val))\n    srs.Insulin = float((srs.Insulin - min_ins_val)/(max_ins_val - min_ins_val))\n    srs.BMI = float((srs.BMI - min_bmi_val)/(max_bmi_val - min_bmi_val))\n    srs.Age = float((srs.Age - min_age_val)/(max_age_val - min_age_val))\n    srs.SkinThickness = float((srs.SkinThickness - min_st_val)/(max_st_val - min_st_val))\n    srs.GlucoseBucket = float((srs.GlucoseBucket - min_glucose_bucket_val)/(max_glucose_bucket_val - min_glucose_bucket_val))\n    srs.SkinThicknessBucket = float((srs.SkinThicknessBucket - min_st_bucket_val)/(max_st_bucket_val - min_st_bucket_val))\n    srs.InsulinBucket = float((srs.InsulinBucket - min_insulin_bucket_val)/(max_insulin_bucket_val - min_insulin_bucket_val))\n    srs.DiabetesPedigreeFunctionBucket = float((srs.DiabetesPedigreeFunctionBucket - min_dpf_bucket_val)/(max_dpf_bucket_val - min_dpf_bucket_val))\n    srs.AgeGroup = float((srs.AgeGroup - min_age_group_val)/(max_age_group_val - min_age_group_val))\n    return srs\n\npatient_data = patient_data.apply((lambda x: normalize(x, max_pregn, min_pregn, max_glucose, min_glucose, max_bp, min_bp, max_dpf, min_dpf, max_ins, min_ins, max_bmi, min_bmi, max_age, min_age, max_st, min_st, max_glucose_bucket, min_glucose_bucket, max_st_bucket, min_st_bucket, max_insulin_bucket, min_insulin_bucket, max_dpf_bucket, min_dpf_bucket, max_age_group, min_age_group)), axis='columns')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ea1b7bbd6eaa7250a833409efe2d0152023608e"},"cell_type":"markdown","source":"In the block below I Instantiate 3 \"Classifier\" of type  SVM,  DT and XGBoost respectively. \n\nIn my previous runbook I had only used an SVM to get an accuracy of 77.4%. I pass that same combination of features to get scores of the other classifiers to compare. After which I replace the feature set with the new \"engineered\" ones to see how the accuracy changes when we use modified features instead of the original ones. "},{"metadata":{"trusted":true,"_uuid":"f08ee98461a03abc30be93efb45a3761ce3ea797","collapsed":true},"cell_type":"code","source":"from sklearn import svm\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\n\nsvm_parameters = {'kernel':('linear', 'rbf', 'poly'), 'C':[1, 5, 10, 0.1], 'gamma': ['auto', 'scale']}\ndt_parameters = {'criterion': ('entropy', 'gini'), 'max_depth': range(1,25), 'min_samples_split': range(2,10)}\nxgb_parameters = {'booster': ['gbtree'], 'gamma': [0.1,0.5,0.2,0.3,0.4], 'n_estimators':[20], 'reg_alpha': range(1,10),'learning_rate': [0.1,0.5,0.2,0.3,0.4,0.6,1.0]}\n\n# Creating 'Classifier' instances\nsvc_classifier = Classifier(svm.SVC(), 'SVM', svm_parameters)\ndt_classifier = Classifier(DecisionTreeClassifier(), 'DecisionTree', dt_parameters)\nxgb_classifier = Classifier(XGBClassifier(), 'XGBoost', xgb_parameters)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06cdfc6d1da10f1a7f35734776c23bf167154275","collapsed":true},"cell_type":"code","source":"# obtaining scores on raw dataset (without normalization) with the original set of features being considered.\nsvc_classifier.get_overall_accuracy(patient_data)\nsvc_original_score = svc_classifier.accuracy\n\ndt_classifier.get_overall_accuracy(patient_data)\ndt_original_score = dt_classifier.accuracy\n\nxgb_classifier.get_overall_accuracy(patient_data)\nxgb_original_score = xgb_classifier.accuracy\nprint('Param set 0 complete')\n\nnew_param_set = [9,2,10,11,5,14,15] # The new 'engineered' features...\nsvc_classifier.get_overall_accuracy(patient_data, new_param_set)\nsvc_score_1 = svc_classifier.accuracy\n\ndt_classifier.get_overall_accuracy(patient_data, new_param_set)\ndt_score_1 = dt_classifier.accuracy\n\nxgb_classifier.get_overall_accuracy(patient_data, new_param_set)\nxgb_score_1 = xgb_classifier.accuracy\nprint('Param set 1 complete')\n\nnew_param_set = [9,2,11,5,14,15] # Removed SkinThicknessBucket \nsvc_classifier.get_overall_accuracy(patient_data, new_param_set)\nsvc_score_2 = svc_classifier.accuracy\n\ndt_classifier.get_overall_accuracy(patient_data, new_param_set)\ndt_score_2 = dt_classifier.accuracy\n\nxgb_classifier.get_overall_accuracy(patient_data, new_param_set)\nxgb_score_2 = xgb_classifier.accuracy\nprint('Param set 2 complete')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8513b9b0d812326537b6f42a03bbfee9db2cb1be"},"cell_type":"markdown","source":"A block to perform a graphical comparison of the accuracies. "},{"metadata":{"trusted":true,"_uuid":"90bf83e3c28460e6ec041d9b6123c3a750081564","collapsed":true},"cell_type":"code","source":"accuracy_df = pd.DataFrame({'score_0':[svc_original_score, dt_original_score, xgb_original_score], 'score_1':[svc_score_1, dt_score_1, xgb_score_1], 'score_2':[svc_score_2, dt_score_2, xgb_score_2], 'Classifiers': ['SVM', 'DecisionTree', 'XGBoost']})\nfig, ax = plt.subplots (3,1, figsize=(20,8))\nsns.barplot('score_0', 'Classifiers', data=accuracy_df, ax=ax[0])\nax[0].set_title('Accuracy comparison with param set 0')\nsns.barplot('score_1', 'Classifiers', data=accuracy_df, ax=ax[1])\nax[1].set_title('Accuracy comparison with param set 1')\nsns.barplot('score_2', 'Classifiers', data=accuracy_df, ax=ax[2])\nax[2].set_title('Accuracy comparison with param set 2')\naccuracy_df.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}