{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Stroke data basic EDA and predictions","metadata":{"papermill":{"duration":0.047738,"end_time":"2021-04-11T21:28:02.673147","exception":false,"start_time":"2021-04-11T21:28:02.625409","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Welcome!<br>\n&emsp;&emsp;In this notebook we will take a look at the dataset from Kaggle containing information about patients and whether they had stroke or not. We will do basic exploration of this dataset and try to predict if a new patient is likely to get a stroke or not.<br>\n&emsp;&emsp;In our predictions we will use Logistic Regression, Naive Bayes, K-Nearest Neighbours, Decision Tree and Linear Discriminant Analysis using Scikit-learn library.","metadata":{"papermill":{"duration":0.044888,"end_time":"2021-04-11T21:28:02.76319","exception":false,"start_time":"2021-04-11T21:28:02.718302","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Table of content:<br><br>\n    [1. The Data](#data)<br>\n    [2. The Vizualization](#viz)<br>\n    [3. The Preprocessing](#pre)<br>\n        &emsp;[3.1. Dummies](#dummies)<br>\n        &emsp;[3.2. Split](#split)<br>\n        &emsp;[3.3. Normalization](#norm)<br>\n        &emsp;[3.4. SMOTE](#smote)<br>\n    [4. The Models](#models)<br>\n    [5. Grid search](#grid)<br>","metadata":{"papermill":{"duration":0.045412,"end_time":"2021-04-11T21:28:02.85354","exception":false,"start_time":"2021-04-11T21:28:02.808128","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Libraries\n\nimport numpy as np\nimport pandas as pd\nfrom collections import Counter\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.metrics import classification_report, roc_curve, roc_auc_score, plot_roc_curve, \\\nprecision_score, recall_score, accuracy_score, f1_score, confusion_matrix, precision_recall_curve\n\nfrom imblearn.over_sampling import SMOTE\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set(rc={'figure.figsize':(10, 5)})\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"papermill":{"duration":2.010159,"end_time":"2021-04-11T21:28:04.908944","exception":false,"start_time":"2021-04-11T21:28:02.898785","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_data = pd.read_csv('../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')","metadata":{"papermill":{"duration":0.084284,"end_time":"2021-04-11T21:28:05.039759","exception":false,"start_time":"2021-04-11T21:28:04.955475","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The data\n<a id='data'></a>","metadata":{"papermill":{"duration":0.046737,"end_time":"2021-04-11T21:28:05.132231","exception":false,"start_time":"2021-04-11T21:28:05.085494","status":"completed"},"tags":[]}},{"cell_type":"code","source":"raw_data.head()","metadata":{"papermill":{"duration":0.088631,"end_time":"2021-04-11T21:28:05.26739","exception":false,"start_time":"2021-04-11T21:28:05.178759","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_data.shape","metadata":{"papermill":{"duration":0.05677,"end_time":"2021-04-11T21:28:05.370295","exception":false,"start_time":"2021-04-11T21:28:05.313525","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have 5110 entries in our dataset describing patient's age, health status, marital status, type of work, type of residence, wheter he smokes or not and had or did not a stroke.","metadata":{"papermill":{"duration":0.045923,"end_time":"2021-04-11T21:28:05.462951","exception":false,"start_time":"2021-04-11T21:28:05.417028","status":"completed"},"tags":[]}},{"cell_type":"code","source":"raw_data.describe()","metadata":{"papermill":{"duration":0.090676,"end_time":"2021-04-11T21:28:05.599716","exception":false,"start_time":"2021-04-11T21:28:05.50904","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_data.info()","metadata":{"papermill":{"duration":0.076809,"end_time":"2021-04-11T21:28:05.725557","exception":false,"start_time":"2021-04-11T21:28:05.648748","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_data.isna().sum()","metadata":{"papermill":{"duration":0.065384,"end_time":"2021-04-11T21:28:05.839768","exception":false,"start_time":"2021-04-11T21:28:05.774384","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Filling missing values in BMI column with mean:","metadata":{"papermill":{"duration":0.051552,"end_time":"2021-04-11T21:28:05.941771","exception":false,"start_time":"2021-04-11T21:28:05.890219","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df = raw_data.copy()\ndf.drop('id', axis=1, inplace=True)\ndf = df.fillna(df['bmi'].mean())\ndf.isna().sum()","metadata":{"papermill":{"duration":0.077665,"end_time":"2021-04-11T21:28:06.069767","exception":false,"start_time":"2021-04-11T21:28:05.992102","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Visualization\n<a id='viz'></a>","metadata":{"papermill":{"duration":0.051318,"end_time":"2021-04-11T21:28:06.173031","exception":false,"start_time":"2021-04-11T21:28:06.121713","status":"completed"},"tags":[]}},{"cell_type":"code","source":"plt.style.use('fivethirtyeight')\ng = sns.countplot(x=df['gender'], palette='plasma')\nfor p in g.patches:\n    g.annotate(format(p.get_height()), (p.get_x() + p.get_width() / 2., \\\n                                               p.get_height()), ha = 'center', va = 'center', \\\n                                               xytext = (0, 10), textcoords = 'offset points')\nplt.title('Gender distribution')\nplt.xlabel('Gender')\nplt.show()","metadata":{"papermill":{"duration":0.280562,"end_time":"2021-04-11T21:28:06.505189","exception":false,"start_time":"2021-04-11T21:28:06.224627","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Females are a majority in our dataset.","metadata":{"papermill":{"duration":0.049587,"end_time":"2021-04-11T21:28:06.604978","exception":false,"start_time":"2021-04-11T21:28:06.555391","status":"completed"},"tags":[]}},{"cell_type":"code","source":"plt.style.use('fivethirtyeight')\ng = sns.FacetGrid(df, col='stroke', hue='gender', palette='plasma', sharey=False)\ng.map(sns.histplot, \"age\", bins=30, kde=True)\nplt.legend()\ng.fig.set_size_inches(15, 5)","metadata":{"papermill":{"duration":1.242646,"end_time":"2021-04-11T21:28:07.897683","exception":false,"start_time":"2021-04-11T21:28:06.655037","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that stroke affects older people which was to be expected, although stroke occurs across every age group, including infants.","metadata":{"papermill":{"duration":0.055224,"end_time":"2021-04-11T21:28:08.006419","exception":false,"start_time":"2021-04-11T21:28:07.951195","status":"completed"},"tags":[]}},{"cell_type":"code","source":"plt.style.use('fivethirtyeight')\nplt.figure(figsize=(9, 4))\ng = sns.countplot(x=df['hypertension'], hue=df['stroke'], palette='Paired')\nfor p in g.patches:\n    g.annotate(format(p.get_height()), (p.get_x() + p.get_width() / 2., \\\n                                               p.get_height()), ha = 'center', va = 'center', \\\n                                               xytext = (0, 10), textcoords = 'offset points')\nplt.title('Stroke / Hypertension')\nplt.xlabel('Hypertension')\nplt.show()","metadata":{"papermill":{"duration":0.243587,"end_time":"2021-04-11T21:28:08.304145","exception":false,"start_time":"2021-04-11T21:28:08.060558","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Stroke occurs more often in cases of hypertansion (13%) comparing to patients without hypertension (4%).  ","metadata":{"papermill":{"duration":0.053982,"end_time":"2021-04-11T21:28:08.414075","exception":false,"start_time":"2021-04-11T21:28:08.360093","status":"completed"},"tags":[]}},{"cell_type":"code","source":"plt.style.use('fivethirtyeight')\nplt.figure(figsize=(9, 4))\ng = sns.countplot(x=df['heart_disease'], hue=df['stroke'], palette='Paired')\nfor p in g.patches:\n    g.annotate(format(p.get_height()), (p.get_x() + p.get_width() / 2., \\\n                                               p.get_height()), ha = 'center', va = 'center', \\\n                                               xytext = (0, 10), textcoords = 'offset points')\nplt.title('Stroke / Heart disease')\nplt.xlabel('Heart disease')\nplt.show()","metadata":{"papermill":{"duration":0.346114,"end_time":"2021-04-11T21:28:08.815007","exception":false,"start_time":"2021-04-11T21:28:08.468893","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Similarly to hypertension stroke occurs more oftes in cases of heart disease (17%) compared to absence of such (4%).","metadata":{"papermill":{"duration":0.054077,"end_time":"2021-04-11T21:28:08.922406","exception":false,"start_time":"2021-04-11T21:28:08.868329","status":"completed"},"tags":[]}},{"cell_type":"code","source":"plt.style.use('fivethirtyeight')\nplt.figure(figsize=(9, 4))\ng = sns.countplot(x=df['ever_married'], hue=df['stroke'], palette='Paired', order=['No', 'Yes'])\nfor p in g.patches:\n    g.annotate(format(p.get_height()), (p.get_x() + p.get_width() / 2., \n                                        p.get_height()), ha = 'center', va = 'center', \n                                        xytext = (0, 10), textcoords = 'offset points')\nplt.title('Married or not / Stroke')\nplt.xlabel('Married')\nplt.show()","metadata":{"papermill":{"duration":0.24991,"end_time":"2021-04-11T21:28:09.226121","exception":false,"start_time":"2021-04-11T21:28:08.976211","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Married people tend to be more affected by stroke.","metadata":{"papermill":{"duration":0.054428,"end_time":"2021-04-11T21:28:09.335014","exception":false,"start_time":"2021-04-11T21:28:09.280586","status":"completed"},"tags":[]}},{"cell_type":"code","source":"plt.style.use('fivethirtyeight')\nplt.figure(figsize=(9, 4))\ng = sns.countplot(x=df['work_type'], palette='Paired')\nfor p in g.patches:\n    g.annotate(format(p.get_height()), (p.get_x() + p.get_width() / 2., \\\n                                               p.get_height()), ha = 'center', va = 'center', \\\n                                               xytext = (0, 10), textcoords = 'offset points')\nplt.title('Work types')\nplt.xlabel('')\nplt.show()","metadata":{"papermill":{"duration":0.261733,"end_time":"2021-04-11T21:28:09.651188","exception":false,"start_time":"2021-04-11T21:28:09.389455","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most of people in our dataset works in a private companies.","metadata":{"papermill":{"duration":0.055746,"end_time":"2021-04-11T21:28:09.76319","exception":false,"start_time":"2021-04-11T21:28:09.707444","status":"completed"},"tags":[]}},{"cell_type":"code","source":"plt.style.use('fivethirtyeight')\nplt.figure(figsize=(9, 4))\ng = sns.countplot(x=df['work_type'], hue=df['stroke'], palette='magma')\nfor p in g.patches:\n    g.annotate(format(p.get_height()), (p.get_x() + p.get_width() / 2., \\\n                                               p.get_height()), ha = 'center', va = 'center', \\\n                                               xytext = (0, 10), textcoords = 'offset points')\nplt.title('Work type / Stroke')\nplt.xlabel('Work type')\nplt.show()","metadata":{"papermill":{"duration":0.326416,"end_time":"2021-04-11T21:28:10.145587","exception":false,"start_time":"2021-04-11T21:28:09.819171","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In our dataset stroke occurs more amongst self employed people (7%) rather than people working for private companies (5%) or government (5%).","metadata":{"papermill":{"duration":0.058718,"end_time":"2021-04-11T21:28:10.261586","exception":false,"start_time":"2021-04-11T21:28:10.202868","status":"completed"},"tags":[]}},{"cell_type":"code","source":"plt.style.use('fivethirtyeight')\nplt.figure(figsize=(9, 4))\ng = sns.countplot(x=df['Residence_type'], hue=df['stroke'], palette='Paired')\nfor p in g.patches:\n    g.annotate(format(p.get_height()), (p.get_x() + p.get_width() / 2., \\\n                                               p.get_height()), ha = 'center', va = 'center', \\\n                                               xytext = (0, 10), textcoords = 'offset points')\nplt.title('Residence type / Stroke')\nplt.xlabel('Residence type')\nplt.show()","metadata":{"papermill":{"duration":0.253363,"end_time":"2021-04-11T21:28:10.573495","exception":false,"start_time":"2021-04-11T21:28:10.320132","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Residence type seems to have very little impact.","metadata":{"papermill":{"duration":0.057859,"end_time":"2021-04-11T21:28:10.689767","exception":false,"start_time":"2021-04-11T21:28:10.631908","status":"completed"},"tags":[]}},{"cell_type":"code","source":"plt.style.use('fivethirtyeight')\nplt.figure(figsize=(12, 5))\nsns.histplot(x=df[\"avg_glucose_level\"], hue=df['gender'], bins=35, kde=True)\nplt.axvline(x=140, linewidth=2, color='r', ls='--')\nplt.axvline(x=70, linewidth=2, color='r', ls='--')\nplt.annotate('Normal sugar level', xy=(140, 351), arrowprops={'width': 2}, xytext=(85, 355), )\nplt.annotate('Normal sugar level', xy=(70, 351), arrowprops={'width': 2}, xytext=(85, 355), )\nplt.title('Glucose level / Gender')\nplt.xlabel('Avarage glucose level (mg/dl)')\nplt.show()","metadata":{"papermill":{"duration":0.761771,"end_time":"2021-04-11T21:28:11.509626","exception":false,"start_time":"2021-04-11T21:28:10.747855","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Glucose level should be interpreted individually for every person, but generally for a healthy pearson it should be between 70 and 140 mg/dl.","metadata":{"papermill":{"duration":0.059939,"end_time":"2021-04-11T21:28:11.630422","exception":false,"start_time":"2021-04-11T21:28:11.570483","status":"completed"},"tags":[]}},{"cell_type":"code","source":"plt.style.use('fivethirtyeight')\nplt.figure(figsize=(12, 7))\nsns.scatterplot(x='age', y='avg_glucose_level', data=df, hue='gender')\nplt.axhline(y=140, linewidth=2, color='g', ls='-')\nplt.ylabel('Glucose level')\nplt.xlabel('Age')\nplt.show()","metadata":{"papermill":{"duration":0.615779,"end_time":"2021-04-11T21:28:12.307443","exception":false,"start_time":"2021-04-11T21:28:11.691664","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df[df['avg_glucose_level'] > 140])","metadata":{"papermill":{"duration":0.083153,"end_time":"2021-04-11T21:28:12.461682","exception":false,"start_time":"2021-04-11T21:28:12.378529","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"821 of our patients can be classified as overweight judging by glucose level.","metadata":{"papermill":{"duration":0.071709,"end_time":"2021-04-11T21:28:12.604665","exception":false,"start_time":"2021-04-11T21:28:12.532956","status":"completed"},"tags":[]}},{"cell_type":"code","source":"plt.style.use('fivethirtyeight')\nplt.figure(figsize=(14, 6))\nsns.histplot(x=df[\"bmi\"], hue=df['stroke'], bins=35, kde=True)\nplt.axvline(x=18.5, linewidth=2, color='y', ls='--')\nplt.axvline(x=24.9, linewidth=2, color='y', ls='--')\nplt.annotate('Underweight', xy=(15, 180), arrowprops={'width': 2},  xytext=(7, 280), )\nplt.annotate('Normal BMI range', xy=(23, 680), arrowprops={'width': 2},  xytext=(31, 740), )\nplt.axvline(x=29.9, linewidth=2, color='r', ls='--')\nplt.annotate('Overweight', xy=(27, 600), arrowprops={'width': 2},  xytext=(32, 650), )\nplt.annotate('Obese', xy=(34, 520), arrowprops={'width': 2},  xytext=(38, 580), )\nplt.title('BMI/Stroke histogram')\nplt.xlabel('BMI')\nplt.show()","metadata":{"papermill":{"duration":0.724612,"end_time":"2021-04-11T21:28:13.400714","exception":false,"start_time":"2021-04-11T21:28:12.676102","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.style.use('fivethirtyeight')\nplt.figure(figsize=(12, 6))\nsns.histplot(x=df[\"bmi\"], hue=df['gender'], bins=35, kde=True)\nplt.axvline(x=18.5, linewidth=2, color='y', ls='--')\nplt.axvline(x=24.9, linewidth=2, color='r', ls='--')\nplt.annotate('Normal BMI range', xy=(23, 450), arrowprops={'width': 2},  xytext=(31, 490), )\nplt.title('BMI by gender')\nplt.xlabel('BMI')\nplt.show()","metadata":{"papermill":{"duration":0.729601,"end_time":"2021-04-11T21:28:14.204951","exception":false,"start_time":"2021-04-11T21:28:13.47535","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.style.use('fivethirtyeight')\nplt.figure(figsize=(12, 7))\nsns.scatterplot(x='age', y='bmi', data=df, hue='gender')\nplt.axhline(y=24.9, linewidth=2, color='g', ls='-')\nplt.axhline(y=18.5, linewidth=2, color='b', ls='-')\nplt.ylabel('BMI')\nplt.xlabel('Age')\nplt.show()","metadata":{"papermill":{"duration":0.570934,"end_time":"2021-04-11T21:28:14.868048","exception":false,"start_time":"2021-04-11T21:28:14.297114","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df[df['bmi']>25])","metadata":{"papermill":{"duration":0.092271,"end_time":"2021-04-11T21:28:15.042158","exception":false,"start_time":"2021-04-11T21:28:14.949887","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"BMI below 18,5 falls into underweight range (blue line on the scatter plot).<br>\nBMI in range 18.5 - 25 is considered normal.<br>\nBMI of 25.0 (green line on the scatter plot) to <30 falls within the overweight range and over 30 is a obesity range.\n\nAs we can see most of our patients may be classified as overweight.","metadata":{"papermill":{"duration":0.082943,"end_time":"2021-04-11T21:28:15.207069","exception":false,"start_time":"2021-04-11T21:28:15.124126","status":"completed"},"tags":[]}},{"cell_type":"code","source":"plt.style.use('fivethirtyeight')\nplt.figure(figsize=(12, 5))\ng = sns.countplot(x=df['smoking_status'], hue=df['stroke'], palette='Paired')\nfor p in g.patches:\n    g.annotate(format(p.get_height()), (p.get_x() + p.get_width() / 2., \\\n                                               p.get_height()), ha = 'center', va = 'center', \\\n                                               xytext = (0, 10), textcoords = 'offset points')\nplt.title('Smoking status / Stroke')\nplt.xlabel('Smoking status')\nplt.show()","metadata":{"papermill":{"duration":0.345532,"end_time":"2021-04-11T21:28:15.635588","exception":false,"start_time":"2021-04-11T21:28:15.290056","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Stroke occurences amongst smokers/non-smokers:<br>\nPeople that formerly smoked: 7%<br> Never smoked: 4%<br> Smokes 5%<br>\n<br>\nUnfortunatelly we can't interpret the 'Unknown' status so those numbers don't reflect the whole situation.","metadata":{"papermill":{"duration":0.083001,"end_time":"2021-04-11T21:28:15.801885","exception":false,"start_time":"2021-04-11T21:28:15.718884","status":"completed"},"tags":[]}},{"cell_type":"code","source":"plt.style.use('fivethirtyeight')\nplt.figure(figsize=(10, 5))\ng = sns.countplot(x=df['stroke'], palette='Paired')\nfor p in g.patches:\n    g.annotate(format(p.get_height()), (p.get_x() + p.get_width() / 2., \\\n                                               p.get_height()), ha = 'center', va = 'center', \\\n                                               xytext = (0, 10), textcoords = 'offset points')\nplt.title('Dataset stroke count')\nplt.xlabel('Stroke')\nplt.show()","metadata":{"papermill":{"duration":0.37679,"end_time":"2021-04-11T21:28:16.263233","exception":false,"start_time":"2021-04-11T21:28:15.886443","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Total number of stroke occurences in this dataset. As we can see most of our patients did not suffer from stroke.","metadata":{"papermill":{"duration":0.08526,"end_time":"2021-04-11T21:28:16.432433","exception":false,"start_time":"2021-04-11T21:28:16.347173","status":"completed"},"tags":[]}},{"cell_type":"code","source":"plt.style.use('fivethirtyeight')\nplt.figure(figsize=(10, 6))\nto_corr = df[['age', 'hypertension', 'heart_disease', 'avg_glucose_level', 'bmi', 'stroke']].corr()\nplt.style.use('fivethirtyeight')\nsns.heatmap(to_corr, cmap='Blues', annot=True)\nplt.show()","metadata":{"papermill":{"duration":0.512084,"end_time":"2021-04-11T21:28:17.032094","exception":false,"start_time":"2021-04-11T21:28:16.52001","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the plot above we can see that age and BMI are heavier corelated with stroke than other variables.","metadata":{"papermill":{"duration":0.087885,"end_time":"2021-04-11T21:28:17.205889","exception":false,"start_time":"2021-04-11T21:28:17.118004","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"This sums up our exploration, let's get into the modeling.\n***","metadata":{"papermill":{"duration":0.089135,"end_time":"2021-04-11T21:28:17.384331","exception":false,"start_time":"2021-04-11T21:28:17.295196","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Preprocessing\n<a id='pre'></a>","metadata":{"papermill":{"duration":0.088436,"end_time":"2021-04-11T21:28:17.560194","exception":false,"start_time":"2021-04-11T21:28:17.471758","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Dummies\n<a id='dummies'></a>","metadata":{"papermill":{"duration":0.088267,"end_time":"2021-04-11T21:28:17.736963","exception":false,"start_time":"2021-04-11T21:28:17.648696","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"It is always better to convert categorical variables into numeric format because machine learning algorithms can't interpret words. We will use Pandas 'get_dummies' method for that.<br><br> Our data before encoding:","metadata":{"papermill":{"duration":0.088266,"end_time":"2021-04-11T21:28:17.913256","exception":false,"start_time":"2021-04-11T21:28:17.82499","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df.head(3)","metadata":{"papermill":{"duration":0.111708,"end_time":"2021-04-11T21:28:18.112763","exception":false,"start_time":"2021-04-11T21:28:18.001055","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gender = pd.get_dummies(df['gender'], drop_first=True)\nmarried = pd.get_dummies(df['ever_married'], drop_first=True)\nwork = pd.get_dummies(df['work_type'])\nresidence = pd.get_dummies(df['Residence_type'], drop_first=True)\nsmoking = pd.get_dummies(df['smoking_status'])","metadata":{"papermill":{"duration":0.107342,"end_time":"2021-04-11T21:28:18.308293","exception":false,"start_time":"2021-04-11T21:28:18.200951","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_model = df.copy()\ndf_model.drop(['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status'], axis=1, inplace=True)\ndf_model = pd.concat([df_model, gender, married, work, residence, smoking], axis=1)\ndf_model.rename(columns={'Yes': 'Married'}, inplace=True)","metadata":{"papermill":{"duration":0.103863,"end_time":"2021-04-11T21:28:18.502047","exception":false,"start_time":"2021-04-11T21:28:18.398184","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data after encoding:","metadata":{"papermill":{"duration":0.089163,"end_time":"2021-04-11T21:28:18.767352","exception":false,"start_time":"2021-04-11T21:28:18.678189","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_model.head(3)","metadata":{"papermill":{"duration":0.1107,"end_time":"2021-04-11T21:28:18.967169","exception":false,"start_time":"2021-04-11T21:28:18.856469","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split\n \n<a id='split'></a>","metadata":{"papermill":{"duration":0.090244,"end_time":"2021-04-11T21:28:19.149866","exception":false,"start_time":"2021-04-11T21:28:19.059622","status":"completed"},"tags":[]}},{"cell_type":"code","source":"X = df_model.drop('stroke', axis=1)\ny = df_model['stroke']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=6)","metadata":{"papermill":{"duration":0.104639,"end_time":"2021-04-11T21:28:19.345048","exception":false,"start_time":"2021-04-11T21:28:19.240409","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Normalization\n<a id='norm'></a>","metadata":{"papermill":{"duration":0.091227,"end_time":"2021-04-11T21:28:19.525237","exception":false,"start_time":"2021-04-11T21:28:19.43401","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"The goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values. That helps machine learning algorithms to better understand dependencies between values.","metadata":{"papermill":{"duration":0.088617,"end_time":"2021-04-11T21:28:19.703226","exception":false,"start_time":"2021-04-11T21:28:19.614609","status":"completed"},"tags":[]}},{"cell_type":"code","source":"normalizer= MinMaxScaler()\n\nX_train = normalizer.fit_transform(X_train)\nX_test = normalizer.transform(X_test)","metadata":{"papermill":{"duration":0.108571,"end_time":"2021-04-11T21:28:19.903395","exception":false,"start_time":"2021-04-11T21:28:19.794824","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### SMOTE\n<a id='smote'></a>","metadata":{"papermill":{"duration":0.091611,"end_time":"2021-04-11T21:28:20.086357","exception":false,"start_time":"2021-04-11T21:28:19.994746","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Since we have unbalanced dataset we will use SMOTE (Synthetic Minority Oversampling TEchnique) to oversample the minority class (in our case '1', which is an occurence of stroke).\n\n*'SMOTE first selects a minority class instance a at random and finds its k nearest minority class neighbors. The synthetic instance is then created by choosing one of the k nearest neighbors b at random and connecting a and b to form a line segment in the feature space. The synthetic instances are generated as a convex combination of the two chosen instances a and b.'*\n\nSource: Imbalanced Learning: Foundations, Algorithms, and Applications, 2013.","metadata":{"papermill":{"duration":0.088606,"end_time":"2021-04-11T21:28:20.266773","exception":false,"start_time":"2021-04-11T21:28:20.178167","status":"completed"},"tags":[]}},{"cell_type":"code","source":"y_train.value_counts()","metadata":{"papermill":{"duration":0.101375,"end_time":"2021-04-11T21:28:20.459719","exception":false,"start_time":"2021-04-11T21:28:20.358344","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"smote = SMOTE(random_state=0)\nX_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)","metadata":{"papermill":{"duration":0.114497,"end_time":"2021-04-11T21:28:20.665114","exception":false,"start_time":"2021-04-11T21:28:20.550617","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_smote.value_counts()","metadata":{"papermill":{"duration":0.101886,"end_time":"2021-04-11T21:28:20.905117","exception":false,"start_time":"2021-04-11T21:28:20.803231","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Models\n<a id='models'></a>","metadata":{"papermill":{"duration":0.091972,"end_time":"2021-04-11T21:28:21.090181","exception":false,"start_time":"2021-04-11T21:28:20.998209","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"We create a list of models and loop through it fitting, training models on our data and printing the results. We will as well define a function that will help us visualize some aspects of the outcomes.<br>\nThe last step is to store the results in a dataframe to better compare the proedictions of our models side by side.","metadata":{"papermill":{"duration":0.090081,"end_time":"2021-04-11T21:28:21.280183","exception":false,"start_time":"2021-04-11T21:28:21.190102","status":"completed"},"tags":[]}},{"cell_type":"code","source":"models = [['Logistic Regression', LogisticRegression()], \n               ['Naive Bayes (GNB)', GaussianNB()], \n               ['K-Nearest Neighbours', KNeighborsClassifier()],\n               ['Decision Tree', DecisionTreeClassifier()], \n               ['LDA', LinearDiscriminantAnalysis()]]","metadata":{"papermill":{"duration":0.099651,"end_time":"2021-04-11T21:28:21.470116","exception":false,"start_time":"2021-04-11T21:28:21.370465","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def precision_recall_threshold_plot(precisions, recalls, thresholds):\n    plt.plot(thresholds, precisions[:-1], \"g--\", label=\"Precision\")\n    plt.plot(thresholds, recalls[:-1], \"b\", label=\"Recall\")\n    plt.xlabel(\"Threshold\")\n    plt.legend(loc=\"best\")\n    plt.title('Precision/Recall vs Threshold')\n    plt.ylim([0, 1])\n    plt.show()","metadata":{"papermill":{"duration":0.10011,"end_time":"2021-04-11T21:28:21.661361","exception":false,"start_time":"2021-04-11T21:28:21.561251","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = {}\n\nfor i in range(0, len(models)):\n    \n    clf = models[i][1]\n    clf.fit(X_train_smote, y_train_smote)\n    clf_pred = clf.predict(X_test)\n    clf_proba = clf.predict_proba(X_test)[:, 1]\n    \n    print(f'\\nResults for {clf}\\n')\n    print('Confusion matrix:\\n\\n', confusion_matrix(y_test, clf_pred), '\\n')\n    print('Classification report:\\n\\n', classification_report(y_test, clf_pred))\n    \n    plot_roc_curve(clf, X_test, y_test)\n    plt.plot([0, 1], [0, 1], 'r--')\n    plt.title(f'ROC curve for {clf}')\n    plt.show()\n    \n    precisions_clf, recalls_clf, thresholds_clf = precision_recall_curve(y_test, clf_proba)\n    precision_recall_threshold_plot(precisions_clf, recalls_clf, thresholds_clf)\n    \n    scores = cross_val_score(clf, X_train_smote, y_train_smote, cv=10)\n    Accuracy = round(accuracy_score(y_test, clf_pred)*100, 2)\n    Precision = round(precision_score(y_test, clf_pred), 2)\n    Recall = round(recall_score(y_test, clf_pred), 2)\n    F1_Score = round(f1_score(y_test, clf_pred), 2)\n    Cross_Validation_mean_score = round(scores.mean(), 2)\n    ROC_AUC_score = round(roc_auc_score(y_test, clf_proba), 2)\n    \n    results[clf] = [Accuracy, Precision, Recall, F1_Score, Cross_Validation_mean_score, ROC_AUC_score]","metadata":{"papermill":{"duration":8.018324,"end_time":"2021-04-11T21:28:29.770667","exception":false,"start_time":"2021-04-11T21:28:21.752343","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's interpret the results!<br>\n&emsp;&emsp;Confusion matrix allows us to visualize the performance of our algorithms. All correct predictions are located in the diagonal of the table (top left - bottom right), so it is easy to visually inspect the table for prediction errors, as they will be represented by values outside the diagonal.<br> &emsp;&emsp;A **true positive** (top left) is an outcome where the model correctly predicts the positive class (stroke in our case). Similarly, a **true negative** (bottom right) is an outcome where the model correctly predicts the negative class (no stroke).<br>\n&emsp;&emsp;A **false positive** (top right) is an outcome where the model incorrectly predicts the positive class (which in our case is predicting the stroke when in reality there is none). And a **false negative** (bottom left) is an outcome where the model incorrectly predicts the negative class (predicting no stroke when in fact there is one).<br>\nNext we have the classification raport.<br>\n&emsp;&emsp;In most cases the higher the accuracy the better but in our example I would take in consideration **recall** (true positive rate) as well because it tells us what proportion of actual positives was identified correctly. It is better to tell a person that he/she will probably get a stroke (and maybe proceed with some further analysis or correcting the lifestyle) than assure the patient that he/she will most probably not get a stroke (when in fact he might).<br>\n&emsp;&emsp;Next we have a **ROC curve** plot (ROC - receiver operating characteristic). This graph is showing us the performance of a classification model at all classification thresholds. The plot shows True Positive Rate vs False Positive Rate at different classification thresholds. **Threshold** is the value from which the model classifies an item as positive. Lowering the classification threshold classifies more items as positive, thus increasing both False Positives and True Positives<br>\n&emsp;&emsp;The last plot is showing how precision and recall changes at given threshold. **Precision** is defined as the fraction of the examples which are actually positive among all the examples which we predicted positive. ROC curves is more usefull with a equal numbers of observations for each class and Precision-Recall plot should be use in a case of class imbalance (which would be our case if we wouldn't oversampled with SMOTE)","metadata":{"papermill":{"duration":0.108842,"end_time":"2021-04-11T21:28:30.04546","exception":false,"start_time":"2021-04-11T21:28:29.936618","status":"completed"},"tags":[]}},{"cell_type":"code","source":"results_df = pd.DataFrame.from_dict(results, orient='index', columns=['Accuracy', 'Precision', 'Recall', 'F1 Score', \n                                                                      'CV mean score', 'ROC AUC score'])","metadata":{"papermill":{"duration":0.11815,"end_time":"2021-04-11T21:28:30.272105","exception":false,"start_time":"2021-04-11T21:28:30.153955","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_df.sort_values(by=['Accuracy', 'Recall'], ascending=False)","metadata":{"papermill":{"duration":0.133081,"end_time":"2021-04-11T21:28:30.515496","exception":false,"start_time":"2021-04-11T21:28:30.382415","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the table above we put our results side by side and sorted by accuracy and recall. We can see that Decision tree classifier has the best accuracy but very low recall. ","metadata":{"papermill":{"duration":0.10779,"end_time":"2021-04-11T21:28:30.732378","exception":false,"start_time":"2021-04-11T21:28:30.624588","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Grid Search\n<a id='grid'></a>","metadata":{"papermill":{"duration":0.10836,"end_time":"2021-04-11T21:28:30.949774","exception":false,"start_time":"2021-04-11T21:28:30.841414","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Using GridSearchCV from Scikit-learn libraries we can loop through predefined hyperparameters and fit our models on the training set. That helps us chose the best parameters for our predictions.","metadata":{"papermill":{"duration":0.112975,"end_time":"2021-04-11T21:28:31.171908","exception":false,"start_time":"2021-04-11T21:28:31.058933","status":"completed"},"tags":[]}},{"cell_type":"code","source":"models_grid = [(LogisticRegression(),[{'C': [0.25, 0.5, 0.75, 1], 'penalty': ['l1', 'l2', 'elasticnet']}]), \n       (KNeighborsClassifier(),[{'n_neighbors': range(5, 11), 'metric': ['euclidean', 'manhattan', \n                                                                         'minkowski', 'chebyshev', 'mahalanobis']}]), \n       (LinearDiscriminantAnalysis(),[{'solver' : ['svd', 'lsqr', 'eigen']}]), \n       (GaussianNB(),[{'var_smoothing': [1e-09]}]),  \n       (DecisionTreeClassifier(),[{'criterion': ['gini','entropy'], 'splitter': ['best', 'random']}])]","metadata":{"papermill":{"duration":0.119905,"end_time":"2021-04-11T21:28:31.401196","exception":false,"start_time":"2021-04-11T21:28:31.281291","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for clf, par in models_grid:\n    \n    scoring = ['accuracy','recall']\n    grid = GridSearchCV(estimator=clf, param_grid=par, scoring=scoring, refit='accuracy', cv=10)\n    grid.fit(X_train_smote, y_train_smote)\n    best_score = grid.best_score_\n    best_param = grid.best_params_\n    print(f'Classifier: {clf}')\n    print(f'Best Accuracy : {best_score:.2%}')\n    print('Best Parameters : ', best_param)\n    print('\\n********************************\\n')","metadata":{"papermill":{"duration":51.191463,"end_time":"2021-04-11T21:29:22.702239","exception":false,"start_time":"2021-04-11T21:28:31.510776","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"K-Nearest Neighbours and Decision Tree Clasifier got the highest accuracy and we got the best parameters to retrain those models when needed.<br> I hope you enjoyed this notebook.\n<br>\nThank you.","metadata":{"papermill":{"duration":0.110048,"end_time":"2021-04-11T21:29:22.924196","exception":false,"start_time":"2021-04-11T21:29:22.814148","status":"completed"},"tags":[]}}]}