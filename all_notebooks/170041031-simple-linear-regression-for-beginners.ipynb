{"cells":[{"metadata":{},"cell_type":"markdown","source":"This is a very simple tutorial intended for the beginners to understand and implement Simple Linear Regression from the scratch. \n\n\n\n<font color='blue'> Simple Linear Regression </font> is a great first machine learning algorithm to implement as it requires you to estimate properties from your training dataset, but is simple enough for beginners to understand. Linear regression is a prediction method that is more than 200 years old. In this tutorial, you will discover how to implement the simple linear regression algorithm from scratch in Python.\n\nAfter completing this tutorial you will know:<br>\n&#9632; How to estimate statistical quantities from training data.<br>\n&#9632; How to estimate linear regression coefficients from data.<br>\n&#9632; How to make predictions using linear regression for new data.<br>\n\n\nLinear regression assumes a **linear or straight line relationship between the input variables (X) and the single output variable (y).** More specifically, that output (y) can be calculated from a linear combination of the input variables (X). When there is a single input variable, the method is referred to as a simple linear regression.\n\nIn simple linear regression we can use statistics on the training data to estimate the coefficients required by the model to make predictions on new data.\n\nThe line for a simple linear regression model can be written as:\n\n$$ y = b_0 + b_1 * x $$\nwhere $b_0$ and $b_1$ are the coefficients we must estimate from the training data. Once the coefficients are known, we can use this equation to estimate output values for $y$ given new input examples of $x$. It requires that you calculate statistical properties from the data such as **mean, variance** and **covariance.**\n\n\nIf somehow this notebook helps you, please do <font color='red'> UPVOTE </font>"},{"metadata":{},"cell_type":"markdown","source":"## <font color = 'blue'> Swedish Insurance Dataset</font>\nWe will use a real dataset to demonstrate simple linear regression. The dataset is called the **“Auto Insurance in Sweden”** dataset and involves **<font color='blue'> predicting the total payment for all the claims in thousands of Swedish Kronor (y) given the total number of claims (x). </font>**\n\nThis means that for a new number of claims (x) we will be able to predict the total payment of claims (y)."},{"metadata":{},"cell_type":"markdown","source":"Let's load some basic python libraries that we will need over the course of this tutorial. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# library for manipulating the csv data\nimport pandas as pd\n\n# library for scientific calculations on numbers + linear algebra\nimport numpy as np\nimport math\n\n# library for regular plot visualizations\nimport matplotlib.pyplot as plt\n\n#library for responsive visualizations\nimport plotly.express as px\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/auto-insurance-in-sweden/swedish_insurance.csv')\ndata.sort_values('X', inplace= True)\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data.head(10)\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Manipulating the data (Task) \nThe data has been manipulated to see the effect of outliers on the prediction model. It was seen that the MSE rises with the following manipulations. But overall, the line of best fit remains pretty much the same as before.\n\nThe manipulations have been commented out so as to show the MSE for the data that has been provided."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Manipulating Data to create some outliers\n\n# data.loc[data.X==61,'Y'] = 450\n# data.loc[data.X==40,'Y'] = 50\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's have a look at the data itself. You can either use `matplotlib.pyplot` or `plotly` for visualization. The latter one produces responsive visualizations. Try hovering over the points on the graph to see the actual values."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(x = data['X'], y=data['Y'])\nfig.update_layout(title = 'Swedish Automobiles Data', title_x=0.5, xaxis_title= \"Number of Claims\", yaxis_title=\"Payment in Claims\", height = 500, width = 700)\nfig.update_xaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\nfig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**This tutorial is broken down into five parts:<br>**\n&#9832; Calculate Mean and Variance.<br>\n&#9832; Calculate Covariance.<br>\n&#9832; Estimate Coefficients.<br>\n&#9832; Make Predictions.<br>\n&#9832; Visual Comparison for Correctness.<br>\nThese steps will give you the foundation you need to implement and train simple linear regression models for your own prediction problems."},{"metadata":{},"cell_type":"markdown","source":"### 1. Calculate Mean and Variance.\nAs said earlier, simple linear regression uses mean and variance of the given data. We will use `numpy` builtin functions to calculate them. "},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_x = np.mean(data['X'])\nmean_y = np.mean(data['Y'])\n\nvar_x = np.var(data['X'])\nvar_y = np.var(data['Y'])\n\n\nprint('x stats: mean= %.3f   variance= %.3f' % (mean_x, var_x))\nprint('y stats: mean= %.3f   variance= %.3f' % (mean_y, var_y))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Calculate Covariance.\nThe covariance of two groups of numbers describes how those numbers change together. Covariance is a generalization of correlation. Correlation describes the relationship between two groups of numbers, whereas covariance can describe the relationship between two or more groups of numbers. It is calculated by the following formula. \n$$ Cov(X,Y) = \\frac{\\sum{(X_i - \\overline{X})}{(Y_j - \\overline{Y})}}{n} $$\n\nYou can simply implement it by yourself or use builtin function `numpy.cov()`\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate covariance between x and y\ndef covariance(x, y):\n    mean_x = np.mean(x)\n    mean_y = np.mean(y)\n    covar = 0.0\n    for i in range(len(x)):\n        covar += (x[i] - mean_x) * (y[i] - mean_y)\n    return covar/len(x)\ncovar_xy = covariance(data['X'], data['Y'])\nprint(f'Cov(X,Y): {covar_xy}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Estimate Coefficients\nWe must estimate the values for two coefficients in simple linear regression."},{"metadata":{"trusted":true},"cell_type":"code","source":"b1 = covar_xy / var_x\nb0 = mean_y - b1 * mean_x\n\nprint(f'Coefficents:\\n b0: {b0}  b1: {b1} ')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. Make Predictions\nThe simple linear regression model is a line defined by coefficients estimated from training data. Once the coefficients are estimated, we can use them to make predictions. The equation to make predictions with a simple linear regression model is as follows:\n$$ \\hat{y} = b_0 + b_1 * x $$"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Taking the values from the dataframe and sorting only X for the ease of plotting line later on\nx = data['X'].values.copy()\nx.sort()\nprint(f'x: {x}')\n\n# Predicting the new data based on calculated coeffiecents. \ny_hat = b0 + b1 * x\nprint(f'y_hat: {y_hat}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5. Visual Comparison for Correctness "},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x=data['X'], y=data['Y'], name='train', mode='markers', marker_color='rgba(152, 0, 0, .8)'))\nfig.add_trace(go.Scatter(x=x, y=y_hat, name='prediction', mode='lines+markers', marker_color='rgba(0, 152, 0, .8)'))\n\nfig.update_layout(title = f'Swedish Automobiles Data\\n (visual comparison for correctness)',title_x=0.5, xaxis_title= \"Number of Claims\", yaxis_title=\"Payment in Claims\", height = 500, width = 800)\nfig.update_xaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\nfig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Writing the MSE function (Task)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def MSE():\n    y = data['Y'].values\n    \n    size = y.size\n    \n    diff = np.subtract(y,y_hat)\n    squared_diff = np.square(diff)\n    sum_of_squared_diff = np.sum(squared_diff)\n    \n    mse = sum_of_squared_diff / size\n    return mse\n    \n\n\nmse = MSE()\nprint(mse)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Observations\n* Manipulating the data to create some outliers resulted in a higher value of MSE.\n* But overall, the line of best fit remained pretty much the same.\n* It is easy to see how linear regression would be done for multiple features. A new variable will be required for each feature, which will also have a coefficient called the parameter. \n* Suppose, if there were two features (say, x1 and x2) in the above problem, then the linear regression model would be as follows :\n$$ \\hat{y} = b_0 + b_1 * x1 + b_2 * x2 $$\n\n* Finally, the more data we have, the better and more accurate our predictions will be.\n"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Where To Go From Here \n* <font color=\"red\">Can you find out the squared error of the predictions???</font>\n* Extend the same problem for multiple input features. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}