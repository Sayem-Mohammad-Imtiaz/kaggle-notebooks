{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9512fc5a9e924cb815799619bba91791b71c84a"},"cell_type":"markdown","source":"## Importing Dataset"},{"metadata":{"trusted":true,"_uuid":"0812ced7ee33c4cbd78c8df12d24cfc60397313c"},"cell_type":"code","source":"dataset = pd.read_csv(\"../input/spam.csv\",encoding='latin-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2560d425808da9b18de2790f04aff002bcdc644"},"cell_type":"code","source":"##Checking the head\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06226bd6865d939eeae6982ca7ea73a6d2c7d976"},"cell_type":"code","source":"dataset.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23527dd88e75ff1fd9fe789176324e0ae919bfbe"},"cell_type":"code","source":"dataset.groupby('v1').describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f54aadb244acd0f90ad1ac1232449ae7c6f0a22"},"cell_type":"code","source":"dataset['length'] = dataset['v2'].apply(len)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cfa6bd74588b799247cbd8d278f999b5eb9e060c"},"cell_type":"markdown","source":"# Data Visualization"},{"metadata":{"trusted":true,"_uuid":"a5170070eec063c2504a300cb0f043b08f86d9e0"},"cell_type":"code","source":"dataset['length'].plot(bins=50, kind='hist') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a46a287aa027aa5dca3e12c91402cc954218095f"},"cell_type":"code","source":"dataset.length.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b70b43862b1c7ef844ff1e86c30f7881e9bced1e"},"cell_type":"code","source":"dataset[dataset['length'] == 910]['v2'].iloc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"336bde2b8afa57be96bc8a5d31e7a8651105a408"},"cell_type":"code","source":"dataset.hist(column='length', by='v1', bins=50,figsize=(12,4))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"332010d67698106b00c23959f371a8e8ee01866a"},"cell_type":"markdown","source":"**Dropping the last four columns,because that three columns don't have any values and length column doesn't have any values useful to build to a model**"},{"metadata":{"trusted":true,"_uuid":"68e2315fa20bd8884541418c8b6a5970d6958b5b"},"cell_type":"code","source":"dataset.drop(labels = ['Unnamed: 2','Unnamed: 3','Unnamed: 4','length'],axis = 1,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a5450e55098dbd826b65dba033e339fac976047"},"cell_type":"code","source":"import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac8172501e16413058ae5cf043378cadaa00044a"},"cell_type":"markdown","source":"1.  **Here we  are creating corpus,we are using re package to remove punctuation and special characters. **\n\n2. **We are converting all characters in the corpus into lower case**\n\n3. **Then we are splitting a message into words to remove stop words and to perform stemming**\n\n4.  **And then we are removing stopwords and we are performing stemming while removing stopwords,the word which is not a stop word will be converted to its root form.For example loved will be converted to love.This process is called stemming**\n\n5. **After this we are joining the words in the list again  to form a message without any stopwords and all words will be present in its root form**\n\n6. **After all this step we are appending refined message into  corpus**"},{"metadata":{"trusted":true,"_uuid":"99144b6e5896d9f9776a668429f0e759471d52b4"},"cell_type":"code","source":"portstemmer = PorterStemmer()\ncorpus = []\nfor i in range (0,len(dataset)):\n    mess = re.sub('[^a-zA-Z]',repl = ' ',string = dataset['v2'][i])\n    mess.lower()\n    mess = mess.split()\n    mess = [portstemmer.stem(word) for word in mess if word not in set(stopwords.words('english'))]\n    mess = ' '.join(mess)\n    corpus.append(mess)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed9d5fa74406cf9cfd536600d3273b0ef3a6d1ff"},"cell_type":"code","source":"corpus[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5213c8cfcfebb866d4cd2b459ae662869b5edea"},"cell_type":"code","source":"len(corpus)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"39363396b3f21cec7407d9473d5e90a79600d4a7"},"cell_type":"markdown","source":"#### In this step we are vectorizing the words,We are creating sparse matrix here"},{"metadata":{"trusted":true,"_uuid":"7f2be2388562b748132bfea04f4385d2ba3ae994"},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f47e782972a8b67f5dac60ccd138a43ff3d7a8d0"},"cell_type":"code","source":"countvectorizer = CountVectorizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9fe572c7cb534e79878f724de652f4d97eae2c68"},"cell_type":"code","source":"x = countvectorizer.fit_transform(corpus).toarray() #Independent Variable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a023d2566950217875caa6fbf849b5f91a2e34a9"},"cell_type":"code","source":"y = dataset['v1'].values #Dependent Variable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d6327c27523221eef5b56a6dac22c72c7228c0f9"},"cell_type":"code","source":"x.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a5b5869090faf19c4cb6ca3ab8e0e233a476942"},"cell_type":"markdown","source":"#### Creating training and test set"},{"metadata":{"trusted":true,"_uuid":"693c6f7fdf30b4a4cb635e8b0c6de53b2d947a8c"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"94ff83b2d7fe246aa6832ec0e33cec6001930f2c"},"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"20a88d3e7f700b85afc9cd2861167116e10acee8"},"cell_type":"markdown","source":"## Using MultinomialNB to classify the message"},{"metadata":{"trusted":true,"_uuid":"bdbc807632d5470690216f206ef68ab8f018d27a"},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da7e5fc6e44ee90554e501bf2735d3df5e7ae489"},"cell_type":"code","source":"multinomialnb = MultinomialNB()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8fd75cbfd2c929f4a43350b4495974f865c09ab"},"cell_type":"code","source":"multinomialnb.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1674e4dafd392161b8e0de6e15b597504b76f016"},"cell_type":"code","source":"y_pred = multinomialnb.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b71e5a76010777930e36f20bda35cfb07f40dc6d"},"cell_type":"code","source":"y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0036d2430b7007b762108cbe11cf9052e6207b1f"},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6173e0fa8845d0a9efbf95b4c806d5d4808c0f62"},"cell_type":"markdown","source":"## Classification Report"},{"metadata":{"trusted":true,"_uuid":"b7ba34b1d379cec3943171898ca1c775f1d8e3f6"},"cell_type":"code","source":"print(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe196f3510d0203e0c507cf23c2628e4875a0915"},"cell_type":"markdown","source":"## Confusion Matrix"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"0750ca26ef5c7476f3685e8e2e4e8219b1b945f3"},"cell_type":"code","source":"confusion_matrix(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a75dad619d373762c7ac45c9a3b9eb6756f756c2"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c8c083e37d691ef886ae5089ab769c6244acd637"},"cell_type":"markdown","source":"## Accuracy Score"},{"metadata":{"trusted":true,"_uuid":"41ec723a1b7ef401cc998486633d948c5b2bb327"},"cell_type":"code","source":"accuracy_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24b0aeb66708a1d12de433615f30d7eba0a24a60"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}