{"cells":[{"metadata":{"_uuid":"2221d9ce0419513808069487a0bbb7a240bfa6db"},"cell_type":"markdown","source":"# Project Air Quality\n\n### Domain Name: Environment Air quality\n\n### Abstract: \n\nContains the responses of a gas multisensor device deployed on the field in an Italian city. Hourly responses averages are recorded along with gas concentrations references from a certified analyzer.\n\n### Dataset: Air quality of an Italian city \n(https://archive.ics.uci.edu/ml/datasets/Air+quality)\n\nThe dataset contains 9358 instances of hourly averaged responses from an array of 5 metal oxide chemical sensors embedded in an Air Quality Chemical Multisensor Device. The device was located on the field in a significantly polluted area, at road level, within an Italian city. Data were recorded from March 2004 to February 2005 (one year) representing the longest freely available recordings of on field deployed air quality chemical sensor devices responses. Ground Truth hourly averaged concentrations for CO, Non Metanic Hydrocarbons, Benzene, Total Nitrogen Oxides (NOx) and Nitrogen Dioxide (NO2) and were provided by a co-located reference certified analyzer. \n\nEvidences of cross-sensitivities as well as both concept and sensor drifts are present as described in De Vito et al., Sens. And Act. B, Vol. 129,2,2008 (citation required) eventually affecting sensors concentration estimation capabilities. Missing values are tagged with -200 value.\n\n**Attributes of the dataset are:**\n\n|Sl No|\t|Attribute|\t|Description|\n|-|\t|-|\t|-|\n|0|\t|Date|\t|Date (DD/MM/YYYY) |\n|1|\t|Time|\t|Time (HH.MM.SS) |\n|2|\t|CO(GT)|\t|True hourly averaged concentration CO in mg/m^3 (reference analyzer) |\n|3|\t|PT08.S1(CO)|\t|PT08.S1 (tin oxide) hourly averaged sensor response (nominally CO targeted)|\n|4|\t|NMHC(GT)|\t|True hourly averaged overall Non Metanic HydroCarbons concentration in microg/m^3 (reference analyzer)|\n|5|\t|C6H6(GT)|\t|True hourly averaged Benzene concentration in microg/m^3 (reference analyzer) |\n|6|\t|PT08.S2(NMHC)|\t|PT08.S2 (titania) hourly averaged sensor response (nominally NMHC targeted) |\n|7|\t|NOx(GT)|\t|True hourly averaged NOx concentration in ppb (reference analyzer) |\n|8|\t|PT08.S3(NOx)|\t|PT08.S3 (tungsten oxide) hourly averaged sensor response (nominally NOx targeted) |\n|9|\t|NO2(GT)|\t|True hourly averaged NO2 concentration in microg/m^3 (reference analyzer) |\n|10|\t|PT08.S4(NO2)|\t|PT08.S4 (tungsten oxide) hourly averaged sensor response (nominally NO2 targeted) |\n|11|\t|PT08.S5(O3)|\t|PT08.S5 (indium oxide) hourly averaged sensor response (nominally O3 targeted) |\n|12|\t|T|\t|Temperature in Â°C |\n|13|\t|RH|\t|Relative Humidity (%) |\n|14|\t|AH|\t|AH Absolute Humidity|\n\n\n### Problem:\n\nHumans are very sensitive to humidity, as the skin relies on the air to get rid of moisture. The process of sweating is your body's attempt to keep cool and maintain its current temperature. If the air is at 100-percent relative humidity, sweat will not evaporate into the air. As a result, we feel much hotter than the actual temperature when the relative humidity is high. If the relative humidity is low, we can feel much cooler than the actual temperature because our sweat evaporates easily, cooling us off. For example, if the air temperature e is 75 degrees Fahrenheit (24 degrees Celsius) and the relative humidity is zero percent, the air temperature feels like 69 degrees Fahrenheit (21 C) to our bodies. If the air temperature is 75 degrees Fahrenheit (24 C) and the relative humidity is 100 percent, we feel like it's 80 degrees (27 C) out. \n\n### Objective:\n\nSo we will **predict the Relative Humidity** of a given point of time based on the all other attributes affecting the change in RH.\n"},{"metadata":{"_uuid":"32af863b96dea6b55e2edb2ef9efd3b7700eeb47"},"cell_type":"markdown","source":"### <u>Content:<u>\n\n[1) Load data](#load_data)\n\n[2) Basic statistics](#stat)\n\n[3) Data Cleaning](#hr)\n    \n[4) Co-relation between variables](#corr)\n\n[5) Influence of features on output-RH](#lin)\n\n[6) Baseline Linear Regression](#LR)\n\n[6a) Conclusion of Baseline Linear Regression](#LRcon)\n\n[7) Feature Engineering and testing model](#FE)\n\n[7a) Conclusion of Feature Engineering and testing](#FEcon)\n\n[8) Decision Tree Regression ](#DT)\n\n[9) Random Forest Regression](#RF)\n\n[10) Support Vector Machine](#SVM)\n\n[11) Conclusion](#conclusion)\n"},{"metadata":{"trusted":true,"_uuid":"3fb7e3274cdb7252c5434d45e35b5db673d83a1f","collapsed":true},"cell_type":"code","source":"#Import packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom matplotlib.pylab import rcParams\nimport seaborn as sns\nrcParams['figure.figsize']=10,8","execution_count":19,"outputs":[]},{"metadata":{"collapsed":true,"_kg_hide-input":true,"trusted":true,"_uuid":"066768b191e34810169218cfde69514f663c3f5f"},"cell_type":"code","source":"#Local path\nlocal_path='../input/'","execution_count":20,"outputs":[]},{"metadata":{"_uuid":"dba61c61e778a17f4fc311b7e207268a0068c262"},"cell_type":"markdown","source":"#### 1) Load data<a name=\"load_data\"></a>"},{"metadata":{"trusted":true,"_uuid":"f3336d998053e4d1e6bc2760a7b5ed3a65b525be","collapsed":true},"cell_type":"code","source":"#define header\ncol=['DATE','TIME','CO_GT','PT08_S1_CO','NMHC_GT','C6H6_GT','PT08_S2_NMHC',\n     'NOX_GT','PT08_S3_NOX','NO2_GT','PT08_S4_NO2','PT08_S5_O3','T','RH','AH']\n\n#define number of columns from csv\nuse=list(np.arange(len(col)))\n\n#read the data from csv\ndf_air=pd.read_csv(local_path+'AirQualityUCI.csv',header=None,skiprows=1,names=col,na_filter=True,\n                   na_values=-200,usecols=use)\ndf_air.head()","execution_count":21,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81dd92618371e28fe750c7a2df93115a368f6827","collapsed":true},"cell_type":"code","source":"#See the end records of dataframe\ndf_air.tail()","execution_count":22,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b2d9d7360f167bb682326d368c544cec164fd87f","collapsed":true},"cell_type":"code","source":"df_air.dtypes","execution_count":23,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"631434c504c9386b38aa2b4868046dc68da4f8da","collapsed":true},"cell_type":"code","source":"#drop end rows with NaN values\ndf_air.dropna(how='all',inplace=True)\n#drop RH NAN rows\ndf_air.dropna(thresh=10,axis=0,inplace=True)","execution_count":24,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"992b21b43492dae04aaf6218e6bd04253cb280a7","collapsed":true},"cell_type":"code","source":"df_air.shape","execution_count":25,"outputs":[]},{"metadata":{"_uuid":"11cfab56463119e89386f321ae32a8f4ddba59d2"},"cell_type":"markdown","source":"#### 2) Basic statistics<a name=\"stat\"></a>"},{"metadata":{"trusted":true,"_uuid":"ea0865fdc8a2076e90f2f817c6af255cc3090630","collapsed":true},"cell_type":"code","source":"df_air.describe()","execution_count":26,"outputs":[]},{"metadata":{"_uuid":"fe4cf230d2c14cbbcef7e26ebbb249777cfa7cb3"},"cell_type":"markdown","source":"#### 3) Data Cleaning<a name=\"hr\"></a>"},{"metadata":{"trusted":true,"_uuid":"0bec75167ae46be9682010443ee73362e5794f8d","collapsed":true},"cell_type":"code","source":"#Split hour from time into new column\ndf_air['HOUR']=df_air['TIME'].apply(lambda x: int(x.split(':')[0]))\ndf_air.HOUR.head()","execution_count":27,"outputs":[]},{"metadata":{"_uuid":"b1407b610322a53bdebc1a3e780ddf6f39576672"},"cell_type":"markdown","source":"##### How many missing values now?"},{"metadata":{"trusted":true,"_uuid":"82434c01f32fbdfcce4cd5ffa11420bfa3c6d0a5","collapsed":true},"cell_type":"code","source":"print('Count of missing values:\\n',df_air.shape[0]-df_air.count())","execution_count":28,"outputs":[]},{"metadata":{"_uuid":"9d1a542166144081d9ed6137aabfc876dd60c78c"},"cell_type":"markdown","source":"##### Fill missing value strategy\n\n-CO_GT, NOX_GT, NO2_GT will be filled by monthly average of that particular hour\n\n-NHHC_GT will be dropped as it has 90% missing data"},{"metadata":{"trusted":true,"_uuid":"ca1b7224f6881bbc382ce8507d27ed51e12de709","collapsed":true},"cell_type":"code","source":"df_air['DATE']=pd.to_datetime(df_air.DATE, format='%m/%d/%Y')   #Format date column","execution_count":29,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91de63e7fd5b6404b437ed995f3071f9b57b76f7","collapsed":true},"cell_type":"code","source":"# set the index as date\ndf_air.set_index('DATE',inplace=True)","execution_count":30,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3dd1ffa6086d61b5e0b8535647eb896656f247d8","collapsed":true},"cell_type":"code","source":"df_air['MONTH']=df_air.index.month     #Create month column (Run once)\ndf_air.reset_index(inplace=True)\n#df_air.head()","execution_count":31,"outputs":[]},{"metadata":{"_uuid":"77ebd67e6a32310fcc8f7943c538cd7c7f0ebd63"},"cell_type":"markdown","source":"##### Drop column NMHC_GT; it has 90% missing data"},{"metadata":{"trusted":true,"_uuid":"000a361345a4469fc300d883a1275876793100d0","collapsed":true},"cell_type":"code","source":"df_air.drop('NMHC_GT',axis=1,inplace=True)    #drop col","execution_count":32,"outputs":[]},{"metadata":{"_uuid":"59d7d8a65eb3a4f6d9c26793723cfaedfe3b0880"},"cell_type":"markdown","source":"##### Fill NaN values with monthly average of particular hour"},{"metadata":{"trusted":true,"_uuid":"f00bc5da96c4db8d2d23a704fa45321cfeaeb682","collapsed":true},"cell_type":"code","source":"df_air['CO_GT']=df_air['CO_GT'].fillna(df_air.groupby(['MONTH','HOUR'])['CO_GT'].transform('mean'))\ndf_air['NOX_GT']=df_air['NOX_GT'].fillna(df_air.groupby(['MONTH','HOUR'])['NOX_GT'].transform('mean'))\ndf_air['NO2_GT']=df_air['NO2_GT'].fillna(df_air.groupby(['MONTH','HOUR'])['NO2_GT'].transform('mean'))","execution_count":33,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0b5243ab00b71b52fa0a102e317a6d9c64d9f97","collapsed":true},"cell_type":"code","source":"print('Left out missing value:',df_air.shape[0]-df_air.count() )","execution_count":34,"outputs":[]},{"metadata":{"_uuid":"29977bdc1801f76e3d3c3dd2a769c62d6da5732f"},"cell_type":"markdown","source":"##### Fill left out NaaN values with hourly average value"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"07f1ae983958da0bf9af2294836a865c8bb69f5c"},"cell_type":"code","source":"df_air['CO_GT']=df_air['CO_GT'].fillna(df_air.groupby(['HOUR'])['CO_GT'].transform('mean'))\ndf_air['NOX_GT']=df_air['NOX_GT'].fillna(df_air.groupby(['HOUR'])['NOX_GT'].transform('mean'))\ndf_air['NO2_GT']=df_air['NO2_GT'].fillna(df_air.groupby(['HOUR'])['NO2_GT'].transform('mean'))","execution_count":35,"outputs":[]},{"metadata":{"_uuid":"a390f0e9e8b4950475913663213bcd833f8cbeb6"},"cell_type":"markdown","source":"#### 4) Understand co-relation between variables<a name=\"corr\"></a>"},{"metadata":{"hideCode":false,"trusted":true,"_uuid":"6f66b54be3ee221420ba23c9f218451680ac2f41","collapsed":true},"cell_type":"code","source":"#Use heatmap to see corelation between variables\nsns.heatmap(df_air.corr(),annot=True,cmap='viridis')\nplt.title('Heatmap of co-relation between variables',fontsize=16)\nplt.show()","execution_count":36,"outputs":[]},{"metadata":{"_uuid":"0fe8d6fcdfaaa654c94beedbb693a04ddadf536e"},"cell_type":"markdown","source":"#### 5) Try to understand degree of linearity between RH output and other input features<a name=\"lin\"></a>"},{"metadata":{"hideCode":false,"scrolled":true,"trusted":true,"_uuid":"2d6bdaf849efada7176e4fd3d13ca7eb5f1fa484","collapsed":true},"cell_type":"code","source":"#plot all X-features against output variable RH\ncol_=df_air.columns.tolist()[2:]\nfor i in df_air.columns.tolist()[2:]:\n    sns.lmplot(x=i,y='RH',data=df_air,markers='.')","execution_count":37,"outputs":[]},{"metadata":{"_uuid":"bdea423dd5a6909235b58e471b4400c6b13cce25"},"cell_type":"markdown","source":"### 6) Linear Regression<a name=\"LR\"></a>"},{"metadata":{"trusted":true,"_uuid":"18a2075d29238b5d89d6676b731bf7ced805c2ec","collapsed":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler         #import normalisation package\nfrom sklearn.model_selection import train_test_split      #import train test split\nfrom sklearn.linear_model import LinearRegression         #import linear regression package\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error   #import mean squared error and mean absolute error","execution_count":38,"outputs":[]},{"metadata":{"_uuid":"a8cfe7db69f4cbaa5c07e56de9aae8eb79f7fb5f"},"cell_type":"markdown","source":"##### Define Feature (X) and Target (y)"},{"metadata":{"trusted":true,"_uuid":"37cb056fb7da95fa970bf47375b9fae7d2324bb2","collapsed":true},"cell_type":"code","source":"X=df_air[col_].drop('RH',1)     #X-input features\ny=df_air['RH']                    #y-input features","execution_count":39,"outputs":[]},{"metadata":{"_uuid":"7231f2173db0d89b411e0f97766f690a8a2820ff"},"cell_type":"markdown","source":"##### Normalize Feature variable"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"e962d38ebed67ad1c22620367a0d86dc6bde59bc"},"cell_type":"code","source":"ss=StandardScaler()     #initiatilise","execution_count":40,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15952593f56d59f728e9ad930267b25ff8a573cc","collapsed":true},"cell_type":"code","source":"X_std=ss.fit_transform(X)     #apply stardardisation","execution_count":41,"outputs":[]},{"metadata":{"_uuid":"44530f9871590d84d917d8823110e38ff24fb56b"},"cell_type":"markdown","source":"##### Train test split"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"5c807208b968db8fd484a7fb94cc01bc85ba9278"},"cell_type":"code","source":"#split the data into train and test with test size and 30% and train size as 70%\nX_train, X_test, y_train, y_test=train_test_split(X_std,y,test_size=0.3, random_state=42)","execution_count":42,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6da09964d8a20171a1cf8fb0b4ecd2d25bf582ba","collapsed":true},"cell_type":"code","source":"print('Training data size:',X_train.shape)\nprint('Test data size:',X_test.shape)","execution_count":43,"outputs":[]},{"metadata":{"_uuid":"45bb5e52af895a267c874a8dd18ac6cd6ad98f22"},"cell_type":"markdown","source":"##### Train the model"},{"metadata":{"trusted":true,"_uuid":"159571147e44944d8b92f804e1e3a8a6fda0784e","collapsed":true},"cell_type":"code","source":"lr=LinearRegression()\nlr_model=lr.fit(X_train,y_train)          #fit the linear model on train data","execution_count":44,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc5bf141431b1bc0e87c6ec4355ed13d74ad733b","collapsed":true},"cell_type":"code","source":"print('Intercept:',lr_model.intercept_)\nprint('--------------------------------')\nprint('Slope:')\nlist(zip(X.columns.tolist(),lr_model.coef_))","execution_count":45,"outputs":[]},{"metadata":{"_uuid":"cfe82bdd6c51b1889300ff8f5281a9badb62e80a"},"cell_type":"markdown","source":"##### Prediction"},{"metadata":{"trusted":true,"_uuid":"9eb76c8a7d964fcc3e0975de450921802d8468e4","collapsed":true},"cell_type":"code","source":"y_pred=lr_model.predict(X_test)                      #predict using the model\nrmse=np.sqrt(mean_squared_error(y_test,y_pred))      #calculate rmse\nprint('Baseline RMSE of model:',rmse)","execution_count":46,"outputs":[]},{"metadata":{"_uuid":"e0b12a8d38da8d0994b1169be384e3992e3c1280"},"cell_type":"markdown","source":"#### <u>6a) Conclusion of baseline linear regression model:<a name=\"LRcon\"></a>\n\nThis means that we can predict RH using all the features together with **RMSE as 6.01**. Let us call it as baseline model."},{"metadata":{"_uuid":"6b97f6943c00521d768fd9e225dcaa6d4ed5ad29"},"cell_type":"markdown","source":"### 7) Feature engineering and testing model:<a name=\"FE\"></a>\n\nTry with multiple feature combination and see if RMSE is improving"},{"metadata":{"_uuid":"fc53443f0abbb1bb8f932b4e76939088a62b0c7a"},"cell_type":"markdown","source":"##### Build RMSE function"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"b917e0c10ce602ff97e72786b1f9fa9a05a99e63"},"cell_type":"code","source":"# write function to measure RMSE\ndef train_test_RMSE(feature):\n    X=df_air[feature]\n    y=df_air['RH']\n    X_std_one=ss.fit_transform(X)\n    X_trainR,X_testR,y_trainR,y_testR=train_test_split(X_std_one,y,test_size=0.3,random_state=42)\n    lr_model_one=lr.fit(X_trainR,y_trainR)\n    y_predR=lr_model_one.predict(X_testR)\n    return np.sqrt(mean_squared_error(y_testR,y_predR))","execution_count":47,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1b4f81132b6dc1a86095dc0ef363ef71c9aeeb8","collapsed":true},"cell_type":"code","source":"col_.remove('RH')        #remove output","execution_count":48,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3fcd6877c683d5335f94e6fa44190f33bdec2fb","collapsed":true},"cell_type":"code","source":"print('List of features:',col_)    #print list of features","execution_count":49,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2df7fa42452f0d987f988ca4b0c64a7b32d7b939","collapsed":true},"cell_type":"code","source":"print('RMSE with Features as',col_[0:2],train_test_RMSE(col_[0:2]))\nprint('-------------------------')\nprint('RMSE with Features as',col_[0:6],train_test_RMSE(col_[0:6]))\nprint('-------------------------')\nprint('RMSE with Features as',col_[0:9],train_test_RMSE(col_[0:9]))\nprint('-------------------------')\nprint('RMSE with Features as',col_[1:5],train_test_RMSE(col_[2:9]))\nprint('-------------------------')\nprint('RMSE with Features as',col_[0:11],train_test_RMSE(col_[0:11]))\nprint('-------------------------')\nprint('RMSE with Features as',col_[1:12],train_test_RMSE(col_[1:12]))\nprint('-------------------------')\nprint('RMSE with Features as',col_[0:13],train_test_RMSE(col_[0:13]))","execution_count":50,"outputs":[]},{"metadata":{"_uuid":"7d434585b7284b2e87a49a69eb7394ff7b0fe23c"},"cell_type":"markdown","source":"#### <u>7a) Conclusion of Feature Engineering and testing:<a name=\"FEcon\"></a>\n\nAfter this experiment it looks that baseline model is performing best"},{"metadata":{"_uuid":"c9b4dd7c82bf372612fdb301c7ed59dbf93781d7"},"cell_type":"markdown","source":"### 8) Decision Tree Regression<a name=\"DT\"></a>\n\nLet us try to apply Decision tree regression technique and see if any improvement happens"},{"metadata":{"trusted":true,"_uuid":"4ece8c66fa537470bc165472221ea3eb7fc371ac","collapsed":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor         #Decision tree regression model\nfrom sklearn.cross_validation import cross_val_score    #import cross validation score package\nfrom sklearn.model_selection import GridSearchCV        #import grid search cv\ndt_one_reg=DecisionTreeRegressor()","execution_count":51,"outputs":[]},{"metadata":{"_uuid":"0cd00140f7405c5d213fd37af8776867b40b98ee"},"cell_type":"markdown","source":"##### Fit the DT model and predict:"},{"metadata":{"trusted":true,"_uuid":"e521980e8e0c531358cbd0871709268feb382df1","collapsed":true},"cell_type":"code","source":"dt_model=dt_one_reg.fit(X_train,y_train)         #fit the model\ny_pred_dtone=dt_model.predict(X_test)            #predict","execution_count":52,"outputs":[]},{"metadata":{"_uuid":"48f647b2e5e46d5bad3988bf0475ef0bc7237013"},"cell_type":"markdown","source":"##### RMSE of RH prediction"},{"metadata":{"trusted":true,"_uuid":"8746927d99271c2ddda379c45a4aef3035e997ab","collapsed":true},"cell_type":"code","source":"#calculate RMSE\nprint('RMSE of Decision Tree Regression:',np.sqrt(mean_squared_error(y_pred_dtone,y_test)))","execution_count":53,"outputs":[]},{"metadata":{"_uuid":"eaa340d761a6f2eeddb8982912f2e1f304019562"},"cell_type":"markdown","source":"#### <u>Conclusion:<u>(Decision Tree Regression)\n\nWhen decision tree regression has been applied we observe significant improvement of **RMSE value to 1.36**"},{"metadata":{"_uuid":"4904dbd6ee5dfcddc63d1d580c15586195b9b5c9"},"cell_type":"markdown","source":"### 9) Random Forest Regression<a name=\"RF\"></a>\n\nLet us apply Random Forest regression and measure RMSE"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"15cdc478bbd1d46d4e576e84e878df5be1b850c9"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor           #import random forest regressor\nrf_reg=RandomForestRegressor()","execution_count":54,"outputs":[]},{"metadata":{"_uuid":"0a943435d37f60e8281ca0360283b37cb0669813"},"cell_type":"markdown","source":"##### Fit the RF model and predict"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"64b4eb02c2bca90f571a5782499f48de0245b965"},"cell_type":"code","source":"rf_model=rf_reg.fit(X_train,y_train)         #fit model   \ny_pred_rf=rf_model.predict(X_test)           #predict","execution_count":55,"outputs":[]},{"metadata":{"_uuid":"bfcd4f1a0ff4136bcecfe113a890d517ef198183"},"cell_type":"markdown","source":"##### RMSE of RH prediction"},{"metadata":{"trusted":true,"_uuid":"7d2c6f2b866fdc699dd10608a094132e7b2621b6","collapsed":true},"cell_type":"code","source":"#Calculate RMSE\nprint('RMSE of predicted RH in RF model:',np.sqrt(mean_squared_error(y_test,y_pred_rf)))","execution_count":56,"outputs":[]},{"metadata":{"_uuid":"be1732d23226a6134376336680d3fc18514324d1"},"cell_type":"markdown","source":"##### Lets try to improve on baseline RF model"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"36b4737670e2c8e3a4363b19e01c4e92eb9bab0d"},"cell_type":"code","source":"#define rf parameters\nrf_params={'n_estimators':[10,20],'max_depth':[8,10],'max_leaf_nodes':[70,90]}\n#define rf grid search\nrf_grid=GridSearchCV(rf_reg,rf_params,cv=10)","execution_count":57,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d31104659e78c45aded09b884ca55c7dbec27cf","collapsed":true},"cell_type":"code","source":"rf_model_two=rf_grid.fit(X_train,y_train)     #fit the model wtih all grid parameters","execution_count":58,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"767fdb0cd4c89a52bcb8ba0f433a9a6eeb22651c"},"cell_type":"code","source":"y_pred_rf_two=rf_model_two.predict(X_test)        #predict","execution_count":59,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a56923a2a9049104c7f82a588c03296d369b2404","collapsed":true},"cell_type":"code","source":"#Calculate RMSE\nprint('RMSE using RF grid search method',np.sqrt(mean_squared_error(y_test,y_pred_rf_two)))  ","execution_count":60,"outputs":[]},{"metadata":{"_uuid":"b5f0b96cc0e6a21fbf588ecb622795f91d57deb9"},"cell_type":"markdown","source":"#### <u>Conclusion: Random Forest\n\nApplying Random Forest regression the predicted **RMSE has improved to 0.86**, the default RF algorithm is giving better RMSE value than grid search applied different parameters."},{"metadata":{"collapsed":true,"_uuid":"ce39a28c254a8e5c8e8db100563e501e10aa9559"},"cell_type":"markdown","source":"### 10) Support Vector Machine<a name=\"SVM\"></a>"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"b24920e6ee1a7682ba3465c08be7d52f5c073693"},"cell_type":"code","source":"from sklearn.svm import SVR           #import support vector regressor\nsv_reg=SVR()","execution_count":61,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6c218855ebd20d406fdfc66e51433da0ad523d0","collapsed":true},"cell_type":"code","source":"sv_model=sv_reg.fit(X_train,y_train)    #train the model","execution_count":62,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e3e8a01443490300741c887770814f7b84c6925","collapsed":true},"cell_type":"code","source":"y_pred_sv=sv_model.predict(X_test)         #predict","execution_count":63,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7a0dbe11cf0d0dc153cb0e83f6659652aa2df1d","collapsed":true},"cell_type":"code","source":"#Calculate RMSE of SVR\nprint('RMSE of SVR model:',np.sqrt(mean_squared_error(y_test,y_pred_sv)))","execution_count":64,"outputs":[]},{"metadata":{"_uuid":"c7c7f98858b5f4bdaf0a53139127847fbe90a614"},"cell_type":"markdown","source":"## Conclusion:<a name=\"conclusion\"></a>\n\nFor designing the model for predicting RH, I have applied Linear Regression, Decision Tree, Random Forest, Support Vector Machine. When tested on test data below are RMSE obtained from different algorithms:\n\n**RMSE:** \n\n-Linear Regression: 6.01\n\n-Decision Tree: 1.36\n\n**-Random Forest: 0.86**\n\n-Support Vector Machine: 3.89\n\n<u>Hence Random Forest algorithm is selected for the prediction of RH using the features.</u>\n\n**Future:** \nGoing forward, I would like to try if applying PCA and using day of the month and month of the year as variable, whether model RMSE of prediction gives a better result."},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"e55db017a391107c5c6eb4ad8d486811f8e9d288"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"latex_envs":{"LaTeX_envs_menu_present":false,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false}},"nbformat":4,"nbformat_minor":1}