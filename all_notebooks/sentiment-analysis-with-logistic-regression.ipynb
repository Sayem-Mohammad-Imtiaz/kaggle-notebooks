{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Amazon reviews : Sentiment analysis"},{"metadata":{},"cell_type":"markdown","source":"<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Data-Analysis\" data-toc-modified-id=\"Data-Analysis-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Top-10-most-reviewed-products\" data-toc-modified-id=\"Top-10-most-reviewed-products-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Top 10 most reviewed products</a></span></li><li><span><a href=\"#Top-10-best-brand\" data-toc-modified-id=\"Top-10-best-brand-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Top 10 best brand</a></span></li><li><span><a href=\"#Top-10-worst-products\" data-toc-modified-id=\"Top-10-worst-products-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Top 10 worst products</a></span></li><li><span><a href=\"#Best-budget-product\" data-toc-modified-id=\"Best-budget-product-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Best budget product</a></span></li><li><span><a href=\"#Best-high-end-product\" data-toc-modified-id=\"Best-high-end-product-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Best high end product</a></span></li><li><span><a href=\"#Price-vs-Rating-distribution\" data-toc-modified-id=\"Price-vs-Rating-distribution-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Price vs Rating distribution</a></span></li></ul></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Feature-extraction-from-text\" data-toc-modified-id=\"Feature-extraction-from-text-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Feature extraction from text</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tfidf\" data-toc-modified-id=\"Tfidf-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Tfidf</a></span></li></ul></li><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Logistic Regression</a></span></li><li><span><a href=\"#n-grams\" data-toc-modified-id=\"n-grams-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>n-grams</a></span></li></ul></li></ul></div>"},{"metadata":{},"cell_type":"markdown","source":"## Introduction\nAbout this Dataset\nContext\n\nPromptCloud extracted 400 thousand reviews of unlocked mobile phones sold on Amazon.com to find out insights with respect to reviews, ratings, price and their relationships.\nContent\n\nGiven below are the fields:\n\n    Product Title\n    Brand\n    Price\n    Rating\n    Review text\n    Number of people who found the review helpful\n\nData was acquired in December, 2016 by the crawlers build to deliver our data extraction services.\nInitial Analysis\n\nIt can be accessed here: http://www.kdnuggets.com/2017/01/data-mining-amazon-mobile-phone-reviews-interesting-insights.html"},{"metadata":{},"cell_type":"markdown","source":"The goal of this notebook is to predict wheter a review is positive or negative using Logistic Regression, MLP and NN"},{"metadata":{},"cell_type":"markdown","source":"**Data preparation**\n\nFirst read the dataset in panda dataframe. We are interseted in positive and negative reviews only. No such column exist in dataframe.\n\nTo create the column we will remove neutral rating i.e. 3. After that values those are below 3 will be treated negative review and above 3 will be treated as positive review."},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\n\nplt.style.use('fivethirtyeight')\n\n# Read in the data\ndf = pd.read_csv('../input/amazon-reviews-unlocked-mobile-phones/Amazon_Unlocked_Mobile.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"### Top 10 most reviewed products"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmostreviewd = (df.set_index('Product Name').groupby(level=0)['Reviews']\n    .agg(['count'])).sort_values(['count'], ascending=False)[:10]\n\n\n\nplt.figure(figsize=(12, 8))\nsns.barplot(mostreviewd.reset_index().index, y=mostreviewd['count'], hue=mostreviewd.index.str[:50] + '...', dodge=False)\nplt.ylim(1000,)\nplt.xticks([]);\nplt.ylabel('Reviews count')\nplt.title('Top 10 most reviewed products');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Top 10 best brand"},{"metadata":{"trusted":true},"cell_type":"code","source":"bestbrand = (df[df['Rating'] > 3].set_index('Brand Name').groupby(level=0)['Reviews'].\n    agg(['count'])).sort_values(['count'], ascending=False)[:10]\n\nplt.figure(figsize=(12, 8))\nsns.barplot(bestbrand.index, y=bestbrand['count'], hue=bestbrand.index, dodge=False)\nplt.legend([])\nplt.ylabel('Positive reviews count')\nplt.title('Top 10 best brand');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Top 10 worst products"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter out rating above 3 and get the review count\nworstproduct = (df[df['Rating'] < 3].set_index('Product Name').groupby(level=0)['Reviews'].\n    agg(['count'])).sort_values(['count'], ascending=False)[:10]\n\nplt.figure(figsize=(12, 8))\nsns.barplot(worstproduct.reset_index().index, y=worstproduct['count'], hue=worstproduct.index.str[:50] + '...', dodge=False)\nplt.ylim(250,)\nplt.xticks([]);\nplt.ylabel('Negative reviews count')\nplt.title('Top 10 worst products');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Best budget product"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Best budget product\nbudget = (df[(df['Rating'] > 3) & (df['Price'] < 500)].set_index('Product Name').groupby(level=0)['Price'].\n    agg(['count'])).sort_values(['count'], ascending=False)[:10]\n\ngrouped = df.set_index('Product Name').loc[budget.index].groupby(level=0)\n\nprice = pd.Series(index = budget.index)\nfor name, group in grouped:\n    price.loc[name] = group.Price.iloc[0] \n    \nbudget['Price'] = price\nbudget.reset_index(inplace=True)\n\nplt.figure(figsize=(12, 8))\nsns.barplot(x='Price', y='count', dodge=False, hue='Product Name', data=budget, palette=sns.color_palette(\"cubehelix\", 12))\nplt.ylim(750,)\nplt.ylabel('Positive reviews count')\nplt.title('Best budget products under $500');\n# Put the legend out of the figure\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Best high end product"},{"metadata":{"trusted":true},"cell_type":"code","source":"highend = (df[(df['Rating'] > 3) & (df['Price'] > 900)].set_index('Product Name').groupby(level=0)['Price'].\n    agg(['count'])).sort_values(['count'], ascending=False)[:10]\n\ngrouped = df.set_index('Product Name').loc[highend.index].groupby(level=0)\n\nprice = pd.Series(index = budget.index)\nfor name, group in grouped:\n    price.loc[name] = group.Price.iloc[0] \n    \nhighend['Price'] = price\nhighend.reset_index(inplace=True)\n\nplt.figure(figsize=(8, 8))\nsns.barplot(x='Price', y='count', dodge=False, hue='Product Name', data=highend, palette=sns.color_palette(\"cubehelix\", 12))\nplt.ylabel('Positive reviews count')\nplt.title('Best high end products under $2000');\n# Put the legend out of the figure\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Price vs Rating distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.violinplot(x=\"Rating\", y=\"Price\", data=df)\nplt.title('Price vs Rating distribution');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop missing values\ndf.dropna(inplace=True)\n\n# Remove any 'neutral' ratings equal to 3\ndf = df[df['Rating'] != 3]\n\n# Encode 4s and 5s as 1 (rated positively)\n# Encode 1s and 2s as 0 (rated poorly)\ndf['Positively Rated'] = np.where(df['Rating'] > 3, 1, 0)\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see most of the reviews are positive."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get training and test data from dataset. \nfrom sklearn.model_selection import train_test_split\n\n# Split data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(df['Reviews'], \n                                                    df['Positively Rated'], \n                                                    random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature extraction from text\nThe main and only feature for this model is **Review**. We will be parsing review and train the model. Finally, model should be able to predict whether review is positive or negative.\n\n* Feature : Reviews\n* Target : Positively Rated\n\n#### Tfidf\n\nConvert a collection of raw documents to a matrix of TF-IDF features. https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 5\nvect = TfidfVectorizer(min_df=5).fit(X_train)\nlen(vect.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"TfidfVectorizer created 17951 features from review text. Now we can feed this features to out model. Lets see top features extracted by TfidfVectorizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_vectorized = vect.transform(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_names = np.array(vect.get_feature_names())\n\nsorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\n\nprint('Smallest tfidf:\\n{}\\n'.format(feature_names[sorted_tfidf_index[:10]]))\nprint('Largest tfidf: \\n{}'.format(feature_names[sorted_tfidf_index[:-11:-1]]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\n\nX_train_vectorized = vect.transform(X_train)\n\nmodel = LogisticRegression(solver='saga')\nmodel.fit(X_train_vectorized, y_train)\n\npredictions = model.predict(vect.transform(X_test))\n\nprint('AUC: ', roc_auc_score(y_test, model.decision_function(vect.transform(X_test))))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our model's roc score is very good. Below are the lists of words from Logistic Regression model coefficiants "},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_coef_index = model.coef_[0].argsort()\n\nprint('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\nprint('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\n\ndef PlotWordCloud(words, title):\n    wordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white' \n                ).generate(words) \n                                                           \n    # plot the WordCloud image                        \n    plt.figure(figsize = (10, 10), facecolor = None) \n    plt.imshow(wordcloud) \n    plt.axis(\"off\") \n    plt.tight_layout(pad = 0) \n    plt.title(title, fontsize=50)\n\n    plt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"negative = ''\nfor word in feature_names[sorted_coef_index[:100]]:\n    negative += word + ' '\nPlotWordCloud(negative, 'Most negative words')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positive = ''\nfor word in feature_names[sorted_coef_index[:-101:-1]]:\n    positive += word + ' '    \nPlotWordCloud(positive, 'Most positive words')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model is wroking as expected. Lets try to give it some difficult reviews"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.predict(vect.transform(['not an issue, phone is working',\n                                    'an issue, phone is not working'])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you can notice that our model is predicting both the reviews as negative. It is only considering single word. Now lets make it understand two word combination."},{"metadata":{},"cell_type":"markdown","source":"### n-grams"},{"metadata":{"trusted":true},"cell_type":"code","source":"# extracting 1-grams and 2-grams\nvect = TfidfVectorizer(min_df=5, ngram_range=(1,2)).fit(X_train)\n\nX_train_vectorized = vect.transform(X_train)\n\nlen(vect.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The features count reached to whopping 198917 from 17951. Lets train the model again with new features"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression(solver='saga')\nmodel.fit(X_train_vectorized, y_train)\n\npredictions = model.predict(vect.transform(X_test))\n\nprint('AUC: ', roc_auc_score(y_test, model.decision_function(vect.transform(X_test))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_names = np.array(vect.get_feature_names())\n\nsorted_coef_index = model.coef_[0].argsort()\n\nprint('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\nprint('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.predict(vect.transform(['not an issue, phone is working',\n                                    'an issue, phone is not working'])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thats exactly we want our model should predict. It is now able to diffrentiate reviews based on tow words combination."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}