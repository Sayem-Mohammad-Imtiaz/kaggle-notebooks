{"cells":[{"metadata":{},"cell_type":"markdown","source":"Reference : https://machinelearningmastery.com/how-to-develop-convolutional-neural-network-models-for-time-series-forecasting/"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nfrom numpy import array\nimport torch\nimport gc\nimport torch.nn as nn\nfrom tqdm import tqdm_notebook as tqdm\nfrom torch.utils.data import Dataset,DataLoader","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"solar_power = pd.read_csv('/kaggle/input/solarpanelspower/PV_Elec_Gas2.csv').rename(columns={'Unnamed: 0':'timestamp'}).set_index('timestamp')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Train & Valid split(Almost 8.5:1.5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set = solar_power[:'2018-10-31']\nvalid_set = solar_power['2018-11-01':'2019-11-18']\nprint('Proportion of train_set : {:.2f}%'.format(len(train_set)/len(solar_power)))\nprint('Proportion of valid_set : {:.2f}%'.format(len(valid_set)/len(solar_power)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_sequence(sequence, n_steps):\n    x, y = list(), list()\n    for i in range(len(sequence)):\n        \n        end_ix = i + n_steps\n        \n        if end_ix > len(sequence)-1:\n            break\n        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n        x.append(seq_x)\n        y.append(seq_y)\n    return array(x), array(y)\n\nraw_seq = [10,20,30,40,50,60,70,80,90]\nn_steps = 3\ntrain_x,train_y = split_sequence(train_set.Elec_kW.values,n_steps)\nvalid_x,valid_y = split_sequence(valid_set.Elec_kW.values,n_steps)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Build CNN Forecast Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ElecDataset(Dataset):\n    def __init__(self,feature,target):\n        self.feature = feature\n        self.target = target\n    \n    def __len__(self):\n        return len(self.feature)\n    \n    def __getitem__(self,idx):\n        item = self.feature[idx]\n        label = self.target[idx]\n        \n        return item,label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CNN_ForecastNet(nn.Module):\n    def __init__(self):\n        super(CNN_ForecastNet,self).__init__()\n        self.conv1d = nn.Conv1d(3,64,kernel_size=1)\n        self.relu = nn.ReLU(inplace=True)\n        self.fc1 = nn.Linear(64*2,50)\n        self.fc2 = nn.Linear(50,1)\n        \n    def forward(self,x):\n        x = self.conv1d(x)\n        x = self.relu(x)\n        x = x.view(-1)\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = CNN_ForecastNet().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\ncriterion = nn.MSELoss()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Do I have to think autocorrelation when setting batch_size? \nMaybe Batch_size is important, and It is related with autocorrelation I guess."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = ElecDataset(train_x.reshape(train_x.shape[0],train_x.shape[1],1),train_y)\nvalid = ElecDataset(valid_x.reshape(valid_x.shape[0],valid_x.shape[1],1),valid_y)\ntrain_loader = torch.utils.data.DataLoader(train,batch_size=2,shuffle=False)\nvalid_loader = torch.utils.data.DataLoader(train,batch_size=2,shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_losses = []\nvalid_losses = []\ndef Train():\n    \n    running_loss = .0\n    \n    model.train()\n    \n    for idx, (inputs,labels) in enumerate(train_loader):\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        optimizer.zero_grad()\n        preds = model(inputs.float())\n        loss = criterion(preds,labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss\n        \n    train_loss = running_loss/len(train_loader)\n    train_losses.append(train_loss.detach().numpy())\n    \n    print(f'train_loss {train_loss}')\n    \ndef Valid():\n    running_loss = .0\n    \n    model.eval()\n    \n    with torch.no_grad():\n        for idx, (inputs, labels) in enumerate(valid_loader):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            optimizer.zero_grad()\n            preds = model(inputs.float())\n            loss = criterion(preds,labels)\n            running_loss += loss\n            \n        valid_loss = running_loss/len(valid_loader)\n        valid_losses.append(valid_loss.detach().numpy())\n        print(f'valid_loss {valid_loss}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 200\nfor epoch in range(epochs):\n    print('epochs {}/{}'.format(epoch+1,epochs))\n    Train()\n    Valid()\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(train_losses,label='train_loss')\nplt.plot(valid_losses,label='valid_loss')\nplt.title('MSE Loss')\nplt.ylim(0, 100)\nplt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_x , target_y = split_sequence(train_set.Elec_kW.values,n_steps)\ninputs = target_x.reshape(target_x.shape[0],target_x.shape[1],1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.eval()\nprediction = []\nbatch_size = 2\niterations =  int(inputs.shape[0]/2)\n\nfor i in range(iterations):\n    preds = model(torch.tensor(inputs[batch_size*i:batch_size*(i+1)]).float())\n    prediction.append(preds.detach().numpy())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Prediction Result"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2,figsize=(11,4))\nax[0].set_title('predicted one')\nax[0].plot(prediction)\nax[1].set_title('real one')\nax[1].plot(target_y)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}