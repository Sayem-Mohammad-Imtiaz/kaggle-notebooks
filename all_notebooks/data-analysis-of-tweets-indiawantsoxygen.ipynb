{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing the dataset\ndataset= pd.read_csv(\"../input/indianeedsoxygen-tweets/IndiaWantsOxygen.csv\")\n#Manipulations will be done on copy of original data\ndataPrep=dataset.copy()\n#Ckecking number of null values\ndataPrep.isnull().sum(axis=0)\n#Checking first five rows\ndataPrep.head()\n#Checking dataTypes\ndataPrep.dtypes\n#checking number of rows and columns\ndataPrep.shape\n#removing all rows which donot have user_name\ndataPrep=dataPrep.dropna(subset=['user_name'],axis=0)\n#removing time of user creation as it is useless\ndataPrep=dataPrep.drop(['user_created'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"len(dataPrep.user_name.unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#top locations from where people tweeted\nlocation_wise_tweets=dataPrep.user_location.value_counts().head(25)\nprint(location_wise_tweets)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nplt.figure(figsize= (10,7))\nsns.set_style(\"whitegrid\")\nax= sns.barplot(location_wise_tweets.values,location_wise_tweets.index)\nax.set_xlabel(\"No of tweets\")\nax.set_ylabel(\"Locations\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndataPrep['date'] = pd.to_datetime(dataPrep['date'])\n\ndataPrep['onlyDate'] = dataPrep['date'].dt.date\n\ndataPrep['onlyTime'] = dataPrep['date'].dt.time\n# dataPrep.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"date_wise_tweets=dataPrep.onlyDate.value_counts().head(25)\nprint(date_wise_tweets)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting date wise tweets\nfig = plt.figure(figsize=(10, 10))\nplt.plot(date_wise_tweets.index, date_wise_tweets.values)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Location wise tweets for a particular date.\ndf = dataPrep.groupby(['user_location','onlyDate']).size()\nprint(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#top sources from which they tweeted\nsource_wise_tweets=dataPrep.source.value_counts().head(25)\nprint(source_wise_tweets)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting source wise tweets\nfig = plt.figure(figsize=(10, 10))\nplt.xticks(rotation=90)\nplt.plot(source_wise_tweets.index, source_wise_tweets.values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#verified and non verified user counts\nuser_verified=dataPrep.user_verified.value_counts()\nprint(user_verified)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating a pie chart\n# Creating plot\nfig = plt.figure(figsize =(10, 7))\nplt.pie(user_verified.values, labels = user_verified.index,autopct='%1.2f')\n  \n# show plot\nplt.show()\n#98.79% are unverified users while 1.21% are verified users","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#number ofverified and unverified tweets\ndf = dataPrep.groupby(['user_verified']).size()\nprint(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}