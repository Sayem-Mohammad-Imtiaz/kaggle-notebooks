{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing the Required Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelBinarizer\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndata = pd.read_csv('/kaggle/input/star-type-classification/Stars.csv')\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Missing Value Analysis","metadata":{}},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### No Missing Values in the Data","metadata":{}},{"cell_type":"markdown","source":"## Duplicates Analysis","metadata":{}},{"cell_type":"code","source":"data[data.duplicated()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### No Duplicate Values present","metadata":{}},{"cell_type":"markdown","source":"## Feature Analysis","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(2, 2,figsize=(15,15))\naxs[0, 0].boxplot(data['Temperature'])\naxs[0, 0].set_title('Temperature')\naxs[0, 1].boxplot(data['R'], 'tab:orange')\naxs[0, 1].set_title('Radius')\naxs[1, 0].boxplot(data['A_M'], 'tab:green')\naxs[1, 0].set_title('Absolute Magnitutde')\naxs[1, 1].boxplot(data['L'], 'tab:red')\naxs[1, 1].set_title('Luminosity')\n\nfor ax in axs.flat:\n    ax.set(xlabel='x-label', ylabel='y-label')\n\n# Hide x labels and tick labels for top plots and y ticks for right plots.\nfor ax in axs.flat:\n    ax.label_outer()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Star Color Analysis","metadata":{}},{"cell_type":"code","source":"a= pd.DataFrame(data['Color'].value_counts())\nplt.figure(figsize=(8,6))\nsns.barplot(a['Color'], a.index, palette= 'Spectral')\nplt.title(\"Star Color Analysis\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 112 stars have Red color & 56 stars have Blue color","metadata":{}},{"cell_type":"markdown","source":"## Star Spectral Class Analysis","metadata":{}},{"cell_type":"code","source":"a= pd.DataFrame(data['Spectral_Class'].value_counts())\nplt.figure(figsize=(8,6))\nsns.barplot(a['Spectral_Class'], a.index, palette= 'rainbow')\nplt.title(\"Star Spectral Class Analysis\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 111 Stars belong to \"M\" Spectral Class, making it the most dominant class in the sample","metadata":{}},{"cell_type":"markdown","source":"## Star Type Analysis","metadata":{}},{"cell_type":"code","source":"a =pd.DataFrame(data['Type'].value_counts())\nplt.figure(figsize=(10,8))\nplt.pie(a['Type'],labels=a.index,autopct='%1.1f%%')\nplt.title(\"Percentage Distribution of Star Type\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### It is seen that the comprises of equal distribution of Star Types","metadata":{}},{"cell_type":"markdown","source":"## Correlation Analysis","metadata":{}},{"cell_type":"code","source":"matrix= data.corr()\nmask = np.zeros_like(matrix, dtype=np.bool)\nmask[np.triu_indices_from(mask)]= True\n\n\nplt.figure(figsize=(11,6))\nsns.heatmap(matrix,annot=True,cmap='viridis',annot_kws = {'size': 10},mask=mask)\nplt.title(\"Correlation Analysis\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- There is a Moderate Positive Correlation between Luminosity-Temperature and Star Type-Temperature\n- Moderately High Positive Correlation is seen between Lumionsity-Radius, Luminosity-Star Type & Radius- Star Type\n- Moderately High Negatively Correlation is seen between Lumionsity-Magnitude & Radius-Magnitude\n- Strong Negative Correlation is seen between Magnitude & Star Type","metadata":{}},{"cell_type":"markdown","source":"## Star Classification Analysis","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nx1=LabelEncoder()  \ndata['Spectral_Class']= x1.fit_transform(data['Spectral_Class'])\ndata['Color']= x1.fit_transform(data['Color'])\n\nY= data[['Type']]\nX= data.drop(['Type'], axis=1)\n\nx_train, x_test, y_train, y_test= train_test_split(X, Y, test_size=0.2, random_state=0, stratify=Y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Logistic Regression","metadata":{}},{"cell_type":"code","source":"LogReg= LogisticRegression()\nLogReg= LogReg.fit(x_train,y_train)\ny_pred= LogReg.predict(x_test)\nprint(\"Accuracy Score: \",metrics.accuracy_score(y_pred,y_test))\ncm= confusion_matrix(y_test,y_pred)\nprint(\"Confusion Matrix: \",cm,sep='\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n    lb = LabelBinarizer()\n    lb.fit(y_test)\n    y_test = lb.transform(y_test)\n    y_pred = lb.transform(y_pred)\n    return roc_auc_score(y_test, y_pred, average=average)\n\n\nLogReg= multiclass_roc_auc_score(y_test,y_pred)\nLogReg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### KNN ","metadata":{}},{"cell_type":"code","source":"knn= KNeighborsClassifier(n_neighbors=5)\nknn.fit(x_train,y_train)\n\ny_pred= knn.predict(x_test)\nprint(\"Accuracy Score: \",metrics.accuracy_score(y_pred,y_test))\n\ncm= confusion_matrix(y_test,y_pred)\nprint(\"Confusion Matrix: \",cm,sep='\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KNN=multiclass_roc_auc_score(y_test,y_pred)\nKNN","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Decision Tree","metadata":{}},{"cell_type":"code","source":"dtc= DecisionTreeClassifier(criterion=\"entropy\")\ndtc.fit(x_train,y_train)\n\ny_pred= dtc.predict(x_test)\nprint(\"Accuracy Score: \",metrics.accuracy_score(y_pred,y_test))\n\ncm= confusion_matrix(y_test,y_pred)\nprint(\"Confusion Matrix: \",cm,sep='\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DT=multiclass_roc_auc_score(y_test,y_pred)\nDT","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest","metadata":{}},{"cell_type":"code","source":"rf= RandomForestClassifier(n_estimators=100,random_state=0)\nrf.fit(x_train,y_train)\n\ny_pred= rf.predict(x_test)\nprint(\"Accuracy Score RandomForest: \",metrics.accuracy_score(y_test,y_pred))\n\ncm= confusion_matrix(y_test,y_pred)\nprint(\"Confusion Matrix: \",cm,sep='\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RF= multiclass_roc_auc_score(y_test,y_pred)\nRF","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ada Boost Classifier","metadata":{}},{"cell_type":"code","source":"ada= AdaBoostClassifier(n_estimators=200,random_state=0)\nada.fit(x_train,y_train)\n\ny_pred= ada.predict(x_test)\nprint(\"Accuracy Score of AdaBoost Classifier: \",metrics.accuracy_score(y_test,y_pred))\n\ncm= confusion_matrix(y_test,y_pred)\nprint(\"Confusion Matrix: \",cm,sep='\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AB= multiclass_roc_auc_score(y_test,y_pred)\nAB","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Gradient Boost Classifiier","metadata":{}},{"cell_type":"code","source":"gradient= GradientBoostingClassifier(n_estimators=200,random_state=0,max_depth=2)\ngradient.fit(x_train,y_train)\n\ny_pred= gradient.predict(x_test)\nprint(\"Accuracy Score of GradientBoost Classifier: \",metrics.accuracy_score(y_test,y_pred))\n\ncm= confusion_matrix(y_test,y_pred)\nprint(\"Confusion Matrix: \",cm,sep='\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GB= multiclass_roc_auc_score(y_test,y_pred)\nGB","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Comparison","metadata":{}},{"cell_type":"code","source":"mc= pd.DataFrame([LogReg,KNN,DT,RF,AB,GB],['Logistic Regression','KNN Classifier','Decision Tree','Random Forest','Ada-Boost','Gradient Boost'])\nmc.columns=['ROC_AUC']\nmc\n\nplt.figure(figsize=(11,6))\nsns.barplot(mc.index,mc.ROC_AUC,palette='rainbow')\nplt.title('ML Model Comparison')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### It is seen that Random Forest, Decision Tree & Gradient Boost Classifiers give the best Classification Performance","metadata":{}}]}