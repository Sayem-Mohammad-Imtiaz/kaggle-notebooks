{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Introdução - Dataset HMEQ\n\nA base contém dados de 5.960 empréstimos concedidos por uma determinada empresa. A variável resposta, a qual tentaremos prever, será (BAD), que é binária, em que é informado se o cliente é adimplente ou não nos pagamentos do crédito obtido. \n\nPara cada linha da base, temos as seguintes variáveis:\n\n* BAD - 1 = Cliente não pagou o empréstimo ou está seriamente inadimplente; 0 = Cliente com pagamentos em dia;\n* CLAge\t- Tempo da linha de crédito mais antiga em meses;\n* CLNo - Quantidade de linhas de credito\n* DebtInc - A proporção dívida / renda (DTI)  - Mede a quantidade de renda que uma pessoa ou organização gera para atender a uma dívida\n* Delinq - Quantidade de linhas de crédito inadimplente\n* Derog\t - Quantidade de Relatórios depreciativos\n* Job - Categoria Profissional\n* Loan - Montante do empréstimo solicitado\n* MortDue\t-  Valor Devido da Hipoteca Existente\n* nInq\t- Número de pedidos de crédito recentes\n* Reason - DebtCon = Renegociação de dívidas; HomeImp = Melhorias em casa\n* Value - Valor da Garantia Oferecida\n* YoJ -\tAnos de trabalho no emprego atual\n\n"},{"metadata":{},"cell_type":"markdown","source":"# Análise Exploratória\n\nA partir de agora, faremos algumas análises na base para entender melhor a variável resposta - BAD. Assim, tentaremos identificar possíveis correlações entre as variáveis preditoras e a variável resposta;\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Carregando o Arquivo\n\ndf = pd.read_csv('/kaggle/input/hmeq-data/hmeq.csv')\n\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizando qtde e tipos\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualizando os valores do DataFrame\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Estatística Descritiva dos Empréstimos Obtidos"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Empréstimos Adimplentes\ndf[df['BAD']==0].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Emprestimos Inadimplentes\ndf[df['BAD']==1].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Em relação as estatíticas descritivas acima, podemos verificar:\n\n\nO valor do empréstimo solicitado(LOAN), a hipoteca(MORTDUE) e a garantia subjacente são estatisticamente consistentes para os empréstimos PAGOS e que resultaram em PADRÃO. Isso sugere que essas variáveis podem não fornecer um poder de discriminação significativo para separar as duas classes.\n\nAinda, é possível verificar que a média de tempo no emprego (YOJ) e menor nos empréstimos inadimplentes em relação aos adimplentes. Da mesma forma, temos que o número de relatórios ruins(DEROG), o tempo de credito mais antigo (CLAGE), número de linhas de crédito inadimplentes(DLINQ)  e o número de solicitações de empréstimos, possuem influencia na variável resposta (BAD)."},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfig, axs = plt.subplots(1,2,figsize=(14,7))\nsns.countplot(x='BAD',data=df,ax=axs[0])\naxs[0].set_title(\"Frequência do Status de Pagamento\")\ndf.BAD.value_counts().plot(x=None,y=None, kind='pie', ax=axs[1],autopct='%1.2f%%')\naxs[1].set_title(\"Porcentagem de Pagamento\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Análise Gráfica\n\nEm uma análise inicial da base, é possível perceber que há mais de 80% de emprestimos adimplentes (BAD=0)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tipo de emprego X Pagou emprestimo\nsns.catplot(x='JOB', hue='BAD', data=df, kind='count')\n#Motivo Emprestimo X Pagou emprestimo\nsns.catplot(x='REASON', hue='BAD', data=df, kind='count')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Análise Gráfica\n\n1. É possível observar influência do tipo de trabalho da pessoal na relação com a situação do empréstimo. Assim, pode-se afirmar que a proporção de emprétimos inandimplentes é maior entre os vendedores;\n\n2. Da mesma forma, os emprestimos solicitados para renegociação de dividas tem maior inadiplemento."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Relação PAGOU x VALOR EMPRESTIMO + REASON\nsns.catplot(x='BAD', y='LOAN', hue='REASON', data=df, height=7, aspect=.8).set(title=\"Valor X Situação do Emprestimo e Razão\")\nsns.catplot(x='BAD', y='LOAN', hue='JOB', data=df, height=7, aspect=.8).set(title=\"Valor X Situação do Emprestimo e Trabalho\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Relação do Trabalho X Tempo de Trabalho e Situação do Emprestimo\nplt.figure(figsize=(15,5))\nsns.violinplot(x='JOB', y='YOJ', hue='BAD',split=True, inner=\"quart\", data=df)  \n# Relação do Trabalho X Tempo do Emprestimo Mais Antigo e Situação do Emprestimo\nplt.figure(figsize=(15,5))\nsns.violinplot(x='JOB', y='CLAGE', hue='BAD',split=True, inner=\"quart\",data=df)   \n# Relação do Trabalho X Valor da Hipoteca e Situação do Emprestimo\nplt.figure(figsize=(15,5))\nsns.violinplot(x='JOB', y='MORTDUE', hue='BAD', split=True, inner=\"quart\",data=df)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tratando Valores Nulos da Base"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analisando campos Nulos\ndf.isna().sum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Analisando os registros com mais da metade de valores nulos das YOJ a DEBTINC\ndf[df.iloc[:,6:].isnull().all(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Excluidno do dataFrame dados com 7 ou mais colunas com valores nulos\ndf = df.dropna(axis=0,thresh=df.shape[1]-6)\ndf[df.iloc[:,6:].isnull().all(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analisando campos Nulos\ndf.isna().sum(), df.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Analisando colunas REASON do Tipo Object\ndf['REASON'].value_counts(),print(\"Nulos Campo REASON:\", df['REASON'].isna().sum())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Analisando colunas JOB do Tipo Object\ndf['JOB'].value_counts(),print(\"Nulos Campo JOB:\", df['JOB'].isna().sum())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Criando categoria Dummie para coluna REASON e JOB\n\ndumies_reason=pd.get_dummies(df['REASON'],prefix='REASON')\ndf = df.merge(dumies_reason,left_index=True, right_index=True)\ndumies_job=pd.get_dummies(df['JOB'],prefix='JOB')\ndf = df.merge(dumies_job,left_index=True, right_index=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preenchendo campos nulos que restaram com 0\ndf.fillna(0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum(), df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlação das variáveis numéricas\nplt.figure(figsize= (15, 15))\n\nsns.heatmap(df.corr(), square=True, annot=True, linewidth=0.5)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Análise da Matrix de Correlação\n\nVariáveis relacionadas ao histórico de crédito (DELINQ, DEROG, NINQ) tem mais correlação com a situação do empréstimo (BAD), sugerindo que essas serão as variáveis mais relevantes nos modelos de previsão.\n\nPor outro lado, o valor do empréstimo solicitado, bem como a garantia oferecida sugerem não possuir relação com o pagamento ou não do empréstimo. "},{"metadata":{},"cell_type":"markdown","source":"# Modelos de Predição\n\nA partir de agora, após a análise exploratória da base, utilizaremos alguns modelos de aprendizado de máquina para tentar prever a situação do empréstimo, adimplente (BAD=0) ou inadimplente (BAD=1). \n\nAssim, utilizaremos alguns dos modelos aprendidos na disciplina de ***Data Mining e Machine Learning II***: \n* *Ramdon Forest* (***RF***)\n* *Gradient Boosting* (***GBM***)\n* *XGBoost* (***XGB***)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dividindo o DataFrame\nfrom sklearn.model_selection import train_test_split\n\n# Treino e teste\ntrain, test = train_test_split(df, test_size=0.199, random_state=42)\n\n# Veificando o tanho dos DataFrames\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# definindo colunas de entrada para a predição\nfeats = [c for c in df.columns if c not in ['BAD','JOB', 'REASON']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bibliotecas RandomForest\nfrom sklearn.ensemble import RandomForestClassifier\n# Bibliotecas GBM\nfrom sklearn.ensemble import GradientBoostingClassifier\n# Trabalhando com XGBoost\nfrom xgboost import XGBClassifier\n\n#Validação do Modelo, Acurácia\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import accuracy_score\n\n# importando a bilbioteca para plotar o gráfico de Matriz de Confusão\nimport scikitplot as skplt\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest\n\nPara obter melhor acurárica, o algoritimo de RF vai criar diversas árvores de decisão (parâmetro n_estimators) e chegar ao resultado final com base no resultado de cada árvore criada. A idéia básica é separar o conjunto de dados diversas vezes e para cada sub-conjunto treinar um novo regressor/classificador. Os diferentes regressores/classificadores irão produzir resultados diferentes, e o resultado final será determinado com base nessas regressões/classificações."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Trabalhando com Random Forest\n\nrf = RandomForestClassifier(n_estimators=200, min_samples_split=5, oob_score=True,max_depth=4, random_state=42)\nrf.fit(train[feats], train['BAD'])\nrf_predict=rf.predict(test[feats])\nrf_accuracy=accuracy_score(test['BAD'], rf_predict)\nrf_scores = cross_val_score(rf, test[feats], rf_predict, n_jobs=-1, cv=5)\nrf_model_f1=cross_validate(rf, test[feats] ,rf_predict, scoring='f1',n_jobs=-1, cv=5)\ntemp = pd.Series([rf_accuracy, rf_scores.mean(), rf_model_f1['test_score'].mean()], index=['ACCURACY', 'K-FOLD', 'F1'])\nval_model_rf = pd.DataFrame(temp, columns=['Resultado_RF'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importancia das Variáveis - Modelo Random Forest\npd.Series(rf.feature_importances_, index=feats).sort_values().plot.barh()\n\n#Matrix de Confusão - Modelo Random Forest\nskplt.metrics.plot_confusion_matrix(test['BAD'] ,rf_predict, normalize=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Validação Modelo Random Forest\n\nval_model_rf.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Resultados Random Forest\n\nA variável mais importante para o modelo foi a capacidade de pagamento (DEBTINC), seguida pelo número de linhas inadimplentes(DELINQ) e o valor da garantia (VALUE).\n\nQuanto ao resultado da matriz de confusão, o modelo gerado previu de forma equivocada **1%** dos resultados para **adimplente**, ou seja, **falsos positivos**. Entretanto, ao se analisar os **falsos negativos** gerados foi de **55%** das previsões para **inadimplente**.\n\n"},{"metadata":{},"cell_type":"markdown","source":"## Gradient Boosting\nGBM é um método de boosting, construído em cima de regressores/classificadores fracos. A idéia é adicionar um regressor/classificador de cada vez, então o próximo regressor/classificador é treinado para melhorar o resultado atingido até o momento ('soma de resultados'). Ao contrário do RF, que treina cada regressor/classificador de forma independente, no GBM eles são treinados em conjunto, um ligado ao outro."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trabalhando com GBM\n\ngbm = GradientBoostingClassifier(n_estimators=200, learning_rate=1.0, max_depth=1, random_state=42)\ngbm.fit(train[feats], train['BAD'])\ngbm_predict=gbm.predict(test[feats])\ngbm_accuracy = accuracy_score(test['BAD'], gbm_predict)\ngbm_scores = cross_val_score(gbm, test[feats], gbm_predict, n_jobs=-1, cv=5)\ngbm_model_f1=cross_validate(gbm, test[feats] ,gbm_predict, scoring='f1',n_jobs=-1, cv=5)\n\ntemp = pd.Series([gbm_accuracy, gbm_scores.mean(), gbm_model_f1['test_score'].mean()], index=['ACCURACY', 'K-FOLD', 'F1'])\nval_model_gbm = pd.DataFrame(temp, columns=['Resultado_GBM'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importancia das Variáveis - GBM\npd.Series(gbm.feature_importances_, index=feats).sort_values().plot.barh()\n#Matrix de Confusão - Modelo GBM\nskplt.metrics.plot_confusion_matrix(test['BAD'] ,gbm_predict, normalize=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Validação Modelo GBM\n\nval_model_gbm.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Resultados **GBM**\n\nA variável mais importante para o modelo foi a capacidade de pagamento (DEBTINC), seguida pelo número de linhas inadimplentes(DELINQ)\ne o valor da garantia (VALUE).\n\nQuanto ao resultado da matriz de confusão, o modelo gerado previu de forma equivocada em **3%** dos resultados para **adimplente**, ou seja, \n**falsos positivos**. Entretanto, ao se analisar os **falsos negativos** gerados foi de **29%** das previsões para **inadimplente**, um pouco melhor que os resultados **RF**.\n"},{"metadata":{},"cell_type":"markdown","source":"## XGBoost\nXGB é uma implementação específica do GBM, dita melhor e mais rápida que a implementação padrão do scikit-learn. Tanto o GBM quanto o XGB precisam de maior trabalho de interpretação dos dados e tunning do modelo."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trabalhando com XGBoost\nfrom xgboost import XGBClassifier\nxgb = XGBClassifier(n_estimators=200, learning_rate=0.09, random_state=42)\nxgb.fit(train[feats], train['BAD'])\nxgb_predict=xgb.predict(test[feats])\nxgb_accuracy=accuracy_score(test['BAD'], xgb_predict)\nxgb_model_f1=cross_validate(xgb, test[feats] ,xgb_predict, scoring='f1',n_jobs=-1, cv=5)\nxgb_scores = cross_val_score(xgb, test[feats], xgb_predict, n_jobs=-1, cv=5)\n\ntemp = pd.Series([xgb_accuracy, xgb_scores.mean(), xgb_model_f1['test_score'].mean()], index=['ACCURACY', 'K-FOLD', 'F1'])\nval_model_xgb = pd.DataFrame(temp, columns=['Resultado_XGB'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importancia das Variáveis - XGB\npd.Series(xgb.feature_importances_, index=feats).sort_values().plot.barh()\n#Matrix de Confusão - Modelo XGB\nskplt.metrics.plot_confusion_matrix(test['BAD'] ,xgb_predict, normalize=True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Validação Modelo XGB\n\nval_model_xgb.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Resultados XGB\n\nA variável mais importante para o modelo foi a capacidade de pagamento (DEBTINC), seguida pelo número de linhas inadimplentes(DELINQ) e a quantidade de Relatórios ruins do solicitante. Diferente dos demais modelos testastos (GBM e RF), as variáveis dummies tiveram maior importância para o modelo.\n\nQuanto ao resultado da matriz de confusão, o modelo gerado previu de forma equivocada em 3% dos resultados para adimplente, ou seja, falsos positivos. Entretanto, ao se analisar os falsos negativos gerados foi de 22% das previsões para inadimplente, o melhor resultado para os três modelos."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compilação dos Resultados da Cross Validation dos modelos utilizados\n\nfinal_result = pd.concat([val_model_rf,val_model_gbm,val_model_xgb],axis=1)\n\nfinal_result.head().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusão \n\nA tabela acima, demostra o desempenho dos modelos considerados no estudo. O modelos que tiveram melhores desempenhos foram o **GBM e XGB**. Contudo, o XGB foi o que menos apresentou a menor quantidade de falsos negativos, por isso a maior acurácia do modelo. Já o **GBM** teve os melhores indices de cross validation se comparado ao resultado dos demais modelos.\n\nAssim, pelo melhor resultado na validação através do K-Fold e pelo F1, o modelo GBM teria melhor desempenho na previsibilidade dos resultados.\n\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}