{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read and preprocess data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataset = pd.read_csv(\"../input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv\")\ndataset.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting predictors and target\nx = dataset.drop(columns=[\"DEATH_EVENT\"])\ny = dataset[\"DEATH_EVENT\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scaling input\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nscaler.fit(x)\n\nx = scaler.fit_transform(x)\n\n# Splitting into train/test\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n\nprint(\"x_train Shape : \", x_train.shape)\nprint(\"x_test Shape  : \", x_test.shape)\nprint(\"y_train Shape : \", y_train.shape)\nprint(\"y_test Shape  : \", y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model building","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model building\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n\nnn_model = MLPClassifier(random_state=0)\nnn_model.fit(x_train, y_train)\n\ny_pred = nn_model.predict(x_test)\n\nprint(\"Accuracy score  : {:.4f}\".format(accuracy_score(y_pred, y_test)))\nprint(\"Precision score : {:.4f}\".format(precision_score(y_pred, y_test)))\nprint(\"Recall score    : {:.4f}\".format(recall_score(y_pred, y_test)))\nprint(\"F1 score        : {:.4f}\".format(f1_score(y_pred, y_test)))\nprint(\"AUC ROC score   : {:.4f}\".format(roc_auc_score(y_pred, y_test)))\nprint(\"\\n\", classification_report(y_pred, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Parameters tuning with Grid search (using AUC ROC as scoring method)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nactivation_fn = [\"identity\", \"relu\", \"logistic\", \"tanh\"] # activation function\nsolver = [\"lbfgs\", \"adam\", \"sgd\"] # optimizer\nalpha = [0.0001, 0.05] # Ridge regression's alpha\nlearning_rate = list(['constant','adaptive'])\nhidden_layer_sizes = list([(50,50,50), (50,100,50), (100,)]) # different sizes of hidden layers\n\n\nparam_grid = dict(\n    activation = activation_fn,\n    solver = solver,\n    alpha = alpha,\n    learning_rate = learning_rate,\n    hidden_layer_sizes = hidden_layer_sizes\n)\n\nmlp = MLPClassifier(max_iter=100)\nclf = GridSearchCV(mlp, param_grid=param_grid, \n                   cv=10, \n                   scoring='roc_auc',\n                   n_jobs=-1, verbose=2\n                  )\nclf.fit(x_train, y_train)\nclf.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using the tuned parameters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mlpc_final = MLPClassifier(activation = 'tanh',\n                           alpha = 0.05,\n                           hidden_layer_sizes = (50, 50, 50),\n                           learning_rate = 'adaptive',\n                           solver = 'adam',\n                           random_state = 0\n                          )\nmlpc_final.fit(x_train, y_train)\ny_pred = mlpc_final.predict(x_test)\n\nprint(\"Accuracy score  : {:.4f}\".format(accuracy_score(y_pred, y_test)))\nprint(\"Precision score : {:.4f}\".format(precision_score(y_pred, y_test)))\nprint(\"Recall score    : {:.4f}\".format(recall_score(y_pred, y_test)))\nprint(\"F1 score        : {:.4f}\".format(f1_score(y_pred, y_test)))\nprint(\"AUC ROC score   : {:.4f}\".format(roc_auc_score(y_pred, y_test)))\nprint(\"\\n\", classification_report(y_pred, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visuallizing confusion matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_pred, y_test)\n\nsns.heatmap((cm/np.sum(cm) * 100),\n            annot = True,\n            fmt = \".2f\",\n            cmap = \"Greens\"\n           )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using boostrap sampling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import resample\n\nall_accuracy_scores = []\n\nfor i in range(0, 101): # repeat bootstrap sampling 100 times\n    x_boot = resample(dataset, replace=True)\n    oob = dataset[~dataset.apply(tuple,1).isin(x_boot.apply(tuple,1))]\n    \n    mlpc_boot = MLPClassifier(activation = 'tanh',\n                              alpha = 0.05,\n                              hidden_layer_sizes = (50, 50, 50),\n                              learning_rate = 'adaptive',\n                              solver = 'adam',\n                              random_state = 0\n                             )\n    mlpc_boot.fit(x_boot.drop(columns=[\"DEATH_EVENT\"]), x_boot[\"DEATH_EVENT\"])\n    boot_pred = mlpc_boot.predict(oob.drop(columns=[\"DEATH_EVENT\"]))\n    \n    all_accuracy_scores.append(accuracy_score(boot_pred, oob[\"DEATH_EVENT\"]))\n\nprint(\"Mean accuracy score  : {:.4f}\".format(np.mean(all_accuracy_scores)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using SMOTE method (over sampling)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nsms = SMOTE(random_state=0)\n\nx_res, y_res = sms.fit_sample(x, y)\nx_train, x_test, y_train, y_test = train_test_split(x_res, y_res, test_size=0.2, random_state=42)\n\nprint(\"x_train Shape : \", x_train.shape)\nprint(\"x_test Shape  : \", x_test.shape)\nprint(\"y_train Shape : \", y_train.shape)\nprint(\"y_test Shape  : \", y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mlpc_model = MLPClassifier(activation=\"relu\",\n                            alpha=0.05,\n                            hidden_layer_sizes= (100,),\n                            learning_rate= 'adaptive',\n                            solver= 'adam',\n                            random_state=42)\nmlpc_model.fit(x_train, y_train)\ny_pred = mlpc_model.predict(x_test)\n\nprint('Accuracy Score: {:.4f}'.format(accuracy_score(y_test, y_pred)))\nprint('SVC f1-score  : {:.4f}'.format(f1_score(y_pred, y_test)))\nprint('SVC precision : {:.4f}'.format(precision_score(y_pred, y_test)))\nprint('SVC recall    : {:.4f}'.format(recall_score(y_pred, y_test)))\nprint(\"\\n\",classification_report(y_pred, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_pred, y_test)\n\nsns.heatmap((cm/np.sum(cm) * 100),\n            annot = True,\n            fmt = \".2f\",\n            cmap = \"Oranges\"\n           )","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}