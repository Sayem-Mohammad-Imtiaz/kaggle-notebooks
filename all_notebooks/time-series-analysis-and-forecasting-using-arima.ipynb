{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Time Series Analysis and Forecasting Using ARIMA**\n\n**What is a Time Series Problem:**\n\nIn the field of machine learning and data science, most of the real life problems are based on upon the prediction of future\nwhich is totally oblivious to us such as stock market prediction, future sales prediction and so on. Time series problem is \nbasically the prediction of such problems using variuos machine learning tools. Time series problem is tackled efficently when first it is analyzed properly and according to that observation suitable algorithm is used.\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/portland-oregon-avg-rider-monthly-data/portland-oregon-average-monthly-.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns=[\"month\",\"average_monthly_ridership\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['average_monthly_ridership'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can see above anamolous data, which is the lastone."},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.drop(df.index[df['average_monthly_ridership']==' n=114'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Assign int into average_monthly_ridership column\n* assign datetime to month column"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['average_monthly_ridership'] = df['average_monthly_ridership'].astype(np.int32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['month'] = pd.to_datetime(df['month'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Time Series Analysis:**\n\nterminology which is frequently used in this problem domain.\n\n**Trend** : as a name suggests trend depicts the variation in the output as time increases. it is often nonlinear. sometimes\nwe will refer to trend as \"changing direction\" when it might go from an increasing trend to decreasing trend.\n\n**Level**: it is basically depicts baseline value for the time series.\n\n**Seasonal**: As its name depicts it shows the repeated pattern over time. in layman terms, it shows the seasonal variation of data \nover time.\n\n**Noise** : it basically external noises that vary the data randomly.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normal line plot so we can see data variation \ndf.plot.line(x='month',y='average_monthly_ridership')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* we can observe that average number of riders is increasing most of time"},{"metadata":{},"cell_type":"markdown","source":"**Plotting Monthly Variation of Dataset**\n\nit gives us idea about seasonal variation of our dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#only store month\nmon = df1['month']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(mon.shape)\nprint(mon.head(2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp=pd.DatetimeIndex(mon)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp.dtype","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DatetimeIndex.html\n\nRepresented internally as int64, and which can be boxed to Timestamp objects that are subclasses of datetime and carry metadata."},{"metadata":{"trusted":true},"cell_type":"code","source":"temp.month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp.year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"month = pd.Series(temp.month)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(month.dtype)\nprint(month.head(2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=df1.drop(['month'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=df1.join(month)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='month',y='average_monthly_ridership',data=df1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well this looks tough to decode. Not a typical box plot. one can infer that data is too sparse for this graph to represent any\npattern. hence it cannot represents monthly variation effectively. we can "},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.plot.scatter(x='month',y='average_monthly_ridership')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can see here the yearly variation of data in this plot. to understand this curve more effectively first look at the \nevery row from bottom to top and see each year's variation. to understand yearly variation take a look at each column \nrepresenting a month.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2=df[['average_monthly_ridership']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Trend Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.rolling(6).mean().plot(figsize=(20,10),linewidth=5,fontsize=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"rolling window:\nchoosing rollowing window size, the number of consecutive observations per rolling window. the size of the rolling window will\ndepend on the sample size, time , and periodicity of the data. in general, you can use a shorting rolling window size for data \ncollect in short intervals, and a larger size for data collected in longer intervals. longer rolling window sizes tend to yield \nsmoother rolling window eastimates than shorter sizes.\n\nhttps://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.rolling.html"},{"metadata":{},"cell_type":"markdown","source":"For trend analysis, we use smoothing techniques. in stastics smoothing a dataset means to create an approximating function \nthat attempts to capture important patterens in the data, while leaving out noise or other fine scale structures phenomena. in \nsmoothing, the data points of a signal are modified so individual points are reduced, and points that are lower than the adjacent \npoints ae increased leading to a smoother signal. we implement smoothing by taking moving averages. Exponential Smoothing average is frequently used to compute smoothed function. here i used the rolling method which is inbuilt in pandas and freuently used for smoothing."},{"metadata":{},"cell_type":"markdown","source":"## **Seasonability Analysis**"},{"metadata":{},"cell_type":"markdown","source":"Two most famous seasonality analysis algorithms are:\n\n* Discrete difference of object\n* Periodicity and Autocorrelation "},{"metadata":{},"cell_type":"markdown","source":"## Discrete Difference of Object"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.diff(periods =4).plot(figsize=(20,10), linewidth=5,fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.diff.html\n\n## Periodicity and Autocorrelation"},{"metadata":{},"cell_type":"markdown","source":"Auto correlation is the most famous way to understand seasonal variation till now. we can calculate the correlation for \ntime series observations with observations with time steps, called lags. because the correlation of the time series observation is\ncalculated with values of the same series at previous times, this is called a serial correlation or auto correlation.\n\nharizontal axis represents time lags "},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.plotting.autocorrelation_plot(df['average_monthly_ridership'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.plotting.lag_plot(df['average_monthly_ridership'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above curve represents the relation between current time stepp and its previous time step"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.set_index('month')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying Seasonal ARIMA model to forcast the data \nimport statsmodels.api as sm\nmod = sm.tsa.SARIMAX(df['average_monthly_ridership'], trend='n', order=(0,1,0), seasonal_order=(1,1,1,12))\nresults = mod.fit()\nprint(results.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**To check your code**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['forecast'] = results.predict(start = 102, end= 120, dynamic= True)  \ndf[['average_monthly_ridership', 'forecast']].plot(figsize=(12, 8))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**To generate future forcasts**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def forcasting_future_months(df, no_of_months):\n    df_perdict = df.reset_index()\n    mon = df_perdict['month']\n    mon = mon + pd.DateOffset(months = no_of_months)\n    future_dates = mon[-no_of_months -1:]\n    df_perdict = df_perdict.set_index('month')\n    future = pd.DataFrame(index=future_dates, columns= df_perdict.columns)\n    df_perdict = pd.concat([df_perdict, future])\n    df_perdict['forecast'] = results.predict(start = 114, end = 125, dynamic= True)  \n    df_perdict[['average_monthly_ridership', 'forecast']].iloc[-no_of_months - 12:].plot(figsize=(12, 8))\n    plt.show()\n    return df_perdict[-no_of_months:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted = forcasting_future_months(df,10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}