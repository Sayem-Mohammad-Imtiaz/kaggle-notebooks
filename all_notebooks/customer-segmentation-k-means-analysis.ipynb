{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Customer Segmentation - K-Means Analysis"},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://images.unsplash.com/photo-1511120096-e7744308d1d2?ixlib=rb-1.2.1&auto=format&fit=crop&w=1950&q=80\" style=\"height:500px\">"},{"metadata":{},"cell_type":"markdown","source":"Photo by [Dieter de Vroomen](https://unsplash.com/@dieterdevroomen)"},{"metadata":{},"cell_type":"markdown","source":"## Context\nThis data set is created only for the learning purpose of the customer segmentation concepts , also known as market basket analysis . I will demonstrate this by using unsupervised ML technique (KMeans Clustering Algorithm) in the simplest form.\n\n## Content\nYou are owing a supermarket mall and through membership cards , you have some basic data about your customers like Customer ID, age, gender, annual income and spending score. Spending Score is something you assign to the customer based on your defined parameters like customer behavior and purchasing data.\n\nProblem Statement You own the mall and want to understand the customers like who can be easily converge Target Customers so that the sense can be given to marketing team and plan the strategy accordingly.\n\n## Inspiration\n* How to achieve customer segmentation using machine learning algorithm (KMeans Clustering) in Python in simplest way. \n* Who are your target customers with whom you can start marketing strategy easy to converse\n* How the marketing strategy works in real world"},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Libraries imports and first insight"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First let's explore the dataset first"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(r'../input/Mall_Customers.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The features are quite explicit."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No need to clean the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Data exploration and visualization"},{"metadata":{},"cell_type":"markdown","source":"Plot pairwise relationships between features in a dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1, figsize=(16,10))\nsns.pairplot(data=df, hue='Gender')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Number of male vs female"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1, figsize=(4,4))\nsns.countplot(x='Gender', data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distribution of numerical features (Age, Annual income & Spending score)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1, figsize=(16,4))\nn = 0 \nfor x in ['Age', 'Annual Income (k$)', 'Spending Score (1-100)']:\n    n += 1\n    plt.subplot(1, 3, n)\n    plt.subplots_adjust(hspace=0.5 , wspace=0.5)\n    sns.distplot(df[x] , bins=10)\n    plt.title('Distplot of {}'.format(x))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Clustering using K- means"},{"metadata":{},"cell_type":"markdown","source":"## ML model"},{"metadata":{},"cell_type":"markdown","source":"__Concept__\n\nK-means clustering is one of the simplest and popular unsupervised machine learning algorithms.\n\nTypically, unsupervised algorithms make inferences from datasets using only input vectors without referring to known, or labelled, outcomes.\n\nA cluster refers to a collection of data points aggregated together because of certain similarities.\n\nYou’ll define a target number k, which refers to the number of centroids you need in the dataset. A centroid is the imaginary or real location representing the center of the cluster.\n\nEvery data point is allocated to each of the clusters through reducing the in-cluster sum of squares.\n\nIn other words, the K-means algorithm identifies k number of centroids, and then allocates every data point to the nearest cluster, while keeping the centroids as small as possible.\n\nThe ‘means’ in the K-means refers to averaging of the data; that is, finding the centroid.\n\n__How the K-means algorithm works__\n\nTo process the learning data, the K-means algorithm in data mining starts with a first group of randomly selected centroids, which are used as the beginning points for every cluster, and then performs iterative (repetitive) calculations to optimize the positions of the centroids\n\nIt halts creating and optimizing clusters when either:\n\nThe centroids have stabilized — there is no change in their values because the clustering has been successful.\nThe defined number of iterations has been achieved.\n\n__Optimal K: the elbow method__\n\nHow many clusters would you choose ?\n\n\nA common, empirical method, is the elbow method. You plot the mean distance of every point toward its cluster center, as a function of the number of clusters.\n\nSometimes the plot has an arm shape, and the elbow would be the optimal K.\n\n<img src=\"input/elbow.png\" style=\"height:300px\">\n\nWarning: this method does not apply all the time: sometimes you don't have a clear elbow! In any case, you have to check on the data how is the clustering and make sure it makes sense."},{"metadata":{},"cell_type":"markdown","source":"## Application in this use-case"},{"metadata":{},"cell_type":"markdown","source":"Let's perform clustering (optimizing K with the elbow method). In order to simplify the problem, we start by keeping only the two last columns as features."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.iloc[:, -2:]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"km_inertias, km_scores = [], []\n\nfor k in range(2, 11):\n    km = KMeans(n_clusters=k).fit(X)\n    km_inertias.append(km.inertia_)\n    km_scores.append(silhouette_score(X, km.labels_))\n    \nsns.lineplot(range(2, 11), km_inertias)\nplt.title('elbow graph / inertia depending on k')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"sns.lineplot(range(2, 11), km_scores)\nplt.title('scores depending on k')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's apply K-means on more than 2 features."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.iloc[:, -3:]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"km_inertias, km_scores = [], []\n\nfor k in range(2, 11):\n    km = KMeans(n_clusters=k).fit(X)\n    km_inertias.append(km.inertia_)\n    km_scores.append(silhouette_score(X, km.labels_))\n    \nsns.lineplot(range(2, 11), km_inertias)\nplt.title('elbow graph / inertia depending on k')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(range(2, 11), km_scores)\nplt.title('scores depending on k')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"km = KMeans(n_clusters=5).fit(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# K-Means visualization on pair of 2 features\nplt.figure(figsize=(10, 6))\nsns.scatterplot(X.iloc[:, 1], X.iloc[:, 2], hue=km.labels_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# K-Means visualization on another pair of 2 features\nplt.figure(figsize=(10, 6))\nsns.scatterplot(X.iloc[:, 0], X.iloc[:, 1], hue=km.labels_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"code_folding":[],"trusted":true},"cell_type":"code","source":"# K-Means visualization on the last pair of 2 features\nplt.figure(figsize=(10, 6))\nsns.scatterplot(X.iloc[:, 0], X.iloc[:, 2], hue=km.labels_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization  of the clusters in a 3D scatter plot."},{"metadata":{"trusted":true},"cell_type":"code","source":"from mpl_toolkits.mplot3d import Axes3D\n\nfig = plt.figure(figsize=(8,8))\nax = Axes3D(fig)\n\nxs = X.iloc[:, 0]\nys = X.iloc[:, 1]\nzs = X.iloc[:, 2]\nax.scatter(xs, ys, zs, s=50, alpha=0.6, c=km.labels_)\n\nax.set_xlabel('Age')\nax.set_ylabel('Annual income')\nax.set_zlabel('Spending score')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This Clustering Analysis gives us a very clear insight about the different segments of the customers in the Mall. There are clearly 5 segments of Customers based on their Annual Income and Spending Score which are reportedly the best factors/attributes to determine the segments of a customer in a Mall."},{"metadata":{},"cell_type":"markdown","source":"## Definition of customers profiles corresponding to each clusters"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Profiles of customers\nX['label'] = km.labels_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.label.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for k in range(5):\n    print(f'cluster nb : {k}')\n    print(X[X.label == k].describe().iloc[[0, 1, 3, 7], :-1])\n    print('\\n\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X[X.label == 1].describe().iloc[[0, 1, 3, 7], :-1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The generated \"Clusters of Customers\" plot shows the distribution of the 5 clusters. A sensible interpretation for the mall customer segments can be:\n\n* Cluster 1. Customers with medium annual income and medium annual spend\n* Cluster 2. Customers with high annual income and high annual spend\n* Cluster 3. Customers with low annual income and low annual spend\n* Cluster 4. Customers with high annual income but low annual spend\n* Cluster 5. Customers low annual income but high annual spend\n\nHaving a better understanding of the customers segments, a company could make better and more informed decisions. An example, there are customers with high annual income but low spending score. A more strategic and targeted marketing approach could lift their interest and make them become higher spenders. The focus should also be on the \"loyal\" customers and maintain their satisfaction.\n\nWe have thus seen, how we could arrive at meaningful insights and recommendations by using clustering algorithms to generate customer segments. For the sake of simplicity, the dataset used only 2 variables — income and spend. In a typical business scenario, there could be several variables which could possibly generate much more realistic and business-specific insights."},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# Credits"},{"metadata":{},"cell_type":"markdown","source":"* [From Udemy's Machine Learning A-Z course](https://github.com/SteffiPeTaffy/machineLearningAZ/blob/master/Machine%20Learning%20A-Z%20Template%20Folder/Part%204%20-%20Clustering/Section%2025%20-%20Hierarchical%20Clustering/Mall_Customers.csv)\n* Few tips for the dataviz are the idea of [kushal1996](https://www.kaggle.com/kushal1996/) and for the final analysis [ioannismesionis](https://www.kaggle.com/ioannismesionis/)\n* Explanations of the k-means model by [towardsdatascience](https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1) and [Vivadata](https://vivadata.org/)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":1}