{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Cleaning & adjusting geolocated data for regressor house rent estimators"},{"metadata":{},"cell_type":"markdown","source":"*Table of contents*\n\n1. [Data import, analysis and initial feature selection](#divaifs)\n2. [Datetime conversion and currency conversion](#dcarva)\n3. [Variations of training dataframes (real value adjustments (by inflation)?)](#ptd)\n4. [<font color=\"red\">Adjustment by inflation</font>](#abi)\n5. [Data export](#de)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport datetime\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data import, visualization and initial feature selection <a id=\"divaifs\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/argentina-venta-de-propiedades/ar_properties.csv\",index_col=\"id\").dropna(subset=[\"price\",\"currency\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_alq_ar = df[(df[\"operation_type\"]==\"Alquiler\") & (df[\"l1\"]==\"Argentina\")]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_alq_ar.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## First feature selection  \nImportant features: lat, lon, rooms, bathrooms, surface_covered, ¿surface total? (correlated to covered), price period, property type, currency.  \n\nWe picked lat/lon because we'll perform predictions with a KNN algorithm. This information is more than enough to drop all of the rest location-related columns. The advantage of this is that if we instead pick the labeled categorical locations we will end up unnecesarily creating hundreds of new columns when converting categoricals to numerical values. Bedrooms are not important since this info is very highly correlated to rooms and bathrooms and Argentines do not value it as a metric (domain specific knowledge)."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_alq_ar[df_alq_ar[\"currency\"]==\"USD\"]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [\"created_on\",\"lat\", \"lon\", \"rooms\", \n\"bathrooms\", \"surface_covered\", \"surface_total\", \"price_period\", \"property_type\",\"price\", \"currency\"]\ndf_alq_ar_reducido = df_alq_ar[features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_alq_ar_reducido.isnull().sum()/df_alq_ar_reducido.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Different dataframes to be tested:  \n0. \"created_on\",\"lat\", \"lon\", \"rooms\", \"bathrooms\", \"surface_covered\", \"surface_total\", \"price_period\", \"property_type\" (drop missing surfaces, impute for the mean in everything else) \n1. \"created_on\",\"lat\", \"lon\", \"rooms\", \"bathrooms\", \"surface_covered\", \"surface_total\", \"price_period\", \"property_type\"  \n2. \"created_on\",\"lat\", \"lon\", \"rooms\", \"bathrooms\", \"surface_covered\", \"price_period\", \"property_type\"(drop lat/lon missing, imputation on the mean for rooms, bathrooms and surface)\n3. \"created_on\",\"lat\", \"lon\", \"rooms\", \"bathrooms\", \"surface_covered\", \"price_period\", \"property_type\"(drop lat/lon &rooms missing, imputation on the mean for bathrooms)\n4. \"created_on\",\"lat\", \"lon\", \"rooms\", \"bathrooms\", \"price_period\", \"property_type\" (drop lat/lon missing)  "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_alq_ar_reducido[\"price_period\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Todos los alquileres son mensuales y es costumbre que así lo sea en Ar, por eso voy a imputar los valores faltantes de \"price_period\" por mensual. Esto es lo mismo que directamente tirar la columna."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_alq_ar_reducido = df_alq_ar_reducido.drop(\"price_period\",axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_alq_ar_reducido.info(verbose=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sólo tenemos una columna no-numérica y es el tipo de propiedad... Que además no tiene datos faltantes en absoluto lo cual viene muy bien."},{"metadata":{},"cell_type":"markdown","source":"# Datetime conversion and real value adjustments <a id=\"dcarva\"></a>"},{"metadata":{},"cell_type":"markdown","source":"## We'll:\n    1. Convert to datetime\n    2. Sort by date\n    3. replace column for \"months away from last one registered\" (pick a better name)\nThe reason for this is that we may want to adjust by domain inflation all of the prices, so that all of the rent values are updated."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_alq_ar_reducido.loc[:,\"created_on\"] = pd.to_datetime(df_alq_ar_reducido[\"created_on\"],format=\"%Y-%m-%d\")\ndf_alq_ar_reducido = df_alq_ar_reducido.sort_values(\"created_on\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_alq_ar_reducido","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min_date = df_alq_ar_reducido[\"created_on\"][0]\nmax_date = df_alq_ar_reducido[\"created_on\"].tail(1)[0]\nprint(\"First recorded date: \", min_date, \"Last recorded date: \", max_date)\nyear_diff_to_end = df_alq_ar_reducido[\"created_on\"].apply(lambda x: x.year)-max_date.year\nmonth_diff_to_end = df_alq_ar_reducido[\"created_on\"].apply(lambda x: x.month) - max_date.month\n\nmonth_diff = month_diff_to_end + year_diff_to_end * 12\nprint(\"Month differences to last date: \\n\", month_diff.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_alq_ar_reducido[\"created_on\"]=-month_diff","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_alq_ar_reducido = df_alq_ar_reducido.rename(columns={\"created_on\":\"mo_dist_to_last\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index_inDollars = (df_alq_ar_reducido[\"currency\"]==\"USD\")\ndf_alq_ar_reducido.loc[index_inDollars, \"price\"] = df_alq_ar_reducido.loc[index_inDollars,\"price\"]*150\ndf_alq_ar_reducido = df_alq_ar_reducido.rename(columns={\"currency\":\"original_currency\"})\ndf_alq_ar_reducido = df_alq_ar_reducido[(df_alq_ar_reducido[\"original_currency\"]==\"ARS\") | (df_alq_ar_reducido[\"original_currency\"]==\"USD\") ]\ndf_alq_ar_reducido[\"original_currency\"][(df_alq_ar_reducido[\"original_currency\"]==\"USD\")] = 1\ndf_alq_ar_reducido[\"original_currency\"][(df_alq_ar_reducido[\"original_currency\"]==\"ARS\")] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_alq_ar_reducido[\"original_currency\"] = df_alq_ar_reducido[\"original_currency\"].astype(\"int\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_alq_ar_reducido[df_alq_ar_reducido[\"original_currency\"]==\"USD\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_alq_ar_reducido[df_alq_ar_reducido[\"mo_dist_to_last\"]<3]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Variations of training dataframes <a id=\"ptd\"></a>\n\nDifferent dataframes to be tested:  \nA: Only last 3 months\n\nB: All months considered\n\n0. \"mo_dist_to_last\",\"lat\", \"lon\", \"original_currency\",\"rooms\", \"bathrooms\", \"surface_covered\", \"surface_total\", \"property_type\" (drop missing surfaces & lat/lon, impute for the mean in everything else) \n1. \"mo_dist_to_last\",\"lat\", \"lon\", \"original_currency\", \"rooms\", \"bathrooms\", \"surface_covered\", \"surface_total\", \"property_type\" (drop lat, lon and surface total misising, impute covered, rooms andbathrooms)\n2. \"mo_dist_to_last\",\"lat\", \"lon\", \"original_currency\", \"rooms\", \"bathrooms\", \"surface_covered\", \"property_type\"(drop lat/lon and surface missing, imputation on the mean for rooms and bathrooms)\n3. \"mo_dist_to_last\",\"lat\", \"lon\", \"original_currency\", \"rooms\", \"bathrooms\", \"surface_covered\", \"property_type\"(drop lat/lon, rooms and surface missing, imputation on the median for bathrooms)\n4. \"mo_dist_to_last\",\"lat\", \"lon\", \"original_currency\", \"rooms\", \"bathrooms\", \"property_type\" (drop lat/lon and rooms missing, impute missing bathrooms for the median)\n5. \"mo_dist_to_last\",\"lat\", \"lon\", \"original_currency\", \"rooms\", \"bathrooms\", \"property_type\" (drop lat/lon, rooms and bathrooms missing)\n\n\n<font color=\"red\">Idea de ajuste de precios: convertir todo a dolares del mes al que pertenecen y multiplicar por valor actual del dolar paralelo</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_alq_ar_reducido.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll rename the dataframe to make it more simple..."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_alq_ar_reducido[\"original_currency\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_alq_ar_reducido.dropna(subset=[\"lat\", \"lon\", \"surface_covered\"]).isnull().sum()/df_alq_ar_reducido.dropna(subset=[\"lat\", \"lon\", \"rooms\", \"bathrooms\"]).shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df0 = df_alq_ar_reducido[[\"mo_dist_to_last\",\"lat\", \"lon\", \"rooms\", \"bathrooms\",\"surface_covered\",\"surface_total\",\"original_currency\", \"property_type\",\"price\"]]\ndf1 = df0\ndf2 = df_alq_ar_reducido[[\"mo_dist_to_last\",\"lat\", \"lon\", \"rooms\", \"bathrooms\",\"surface_covered\",\"original_currency\", \"property_type\",\"price\"]]\ndf3 = df2\ndf4 = df_alq_ar_reducido[[\"mo_dist_to_last\",\"lat\", \"lon\", \"rooms\", \"bathrooms\",\"original_currency\", \"property_type\",\"price\"]]\ndf5 = df4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\ndef potentialTrainingDataGenerator(df, colsToDrop, colsToImpute, categoricalCols, nMonthsConsidered):\n    \"\"\"Given a dataframe with missing values on some rows, remove the rows or impute them as indicated by the parameters, \n    then return the data ready to be used for training\"\"\"\n    ##Drop rows with missing...\n    df = df.dropna(subset=colsToDrop)\n    df = df[df[\"mo_dist_to_last\"]<nMonthsConsidered]\n    ## Split into train and test for posterior imputation\n    X = df.drop(columns=[\"price\"])\n    y = df[\"price\"]\n    X_train, X_test, y_train, y_test = train_test_split(X, y)\n    ## Encode\n    encoder = OneHotEncoder(handle_unknown=\"ignore\",sparse=False)\n    X_train_encoded_cat = pd.DataFrame(encoder.fit_transform(X_train[categoricalCols]))\n    X_test_encoded_cat = pd.DataFrame(encoder.transform(X_test[categoricalCols]))\n    ## recover indexes\n    X_train_encoded_cat.index = X_train[categoricalCols].index\n    X_test_encoded_cat.index = X_test[categoricalCols].index\n    \n    ## reinsert encoded\n    X_train = X_train.drop(categoricalCols, axis=1)\n    X_test = X_test.drop(categoricalCols, axis=1)\n    \n    X_train = pd.concat([X_train, X_train_encoded_cat], axis=1)\n    X_test = pd.concat([X_test, X_test_encoded_cat], axis=1)\n    ## impute missing values for the median\n    imputer = SimpleImputer(strategy='median')\n    \n    X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), index = X_train.index)\n    X_test_imputed = pd.DataFrame(imputer.transform(X_test), index = X_test.index)\n    \n    X_train_imputed.columns = X_train.columns\n    X_test_imputed.columns = X_train.columns\n    \n    return X_train_imputed, X_test_imputed, y_train, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_5a, X_test_5a, y_train_5a, y_test_5a = potentialTrainingDataGenerator(df5, [\"lat\", \"lon\", \"rooms\",\"bathrooms\"], [], [\"property_type\"], 3)\n\nX_train_5b, X_test_5b, y_train_5b, y_test_5b = potentialTrainingDataGenerator(df5, [\"lat\", \"lon\", \"rooms\", \"bathrooms\"], [], [\"property_type\"], 14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_5a","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_4a, X_test_4a, y_train_4a, y_test_4a = potentialTrainingDataGenerator(df4, [\"lat\", \"lon\", \"rooms\"], [\"bathrooms\"], [\"property_type\"], 3)\n\nX_train_4b, X_test_4b, y_train_4b, y_test_4b = potentialTrainingDataGenerator(df4, [\"lat\", \"lon\", \"rooms\"], [\"bathrooms\"], [\"property_type\"], 14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_3a, X_test_3a, y_train_3a, y_test_3a = potentialTrainingDataGenerator(df3, [\"lat\", \"lon\", \"rooms\", \"surface_covered\"], [\"bathrooms\"], [\"property_type\"], 3)\n\nX_train_3b, X_test_3b, y_train_3b, y_test_3b = potentialTrainingDataGenerator(df3, [\"lat\", \"lon\", \"rooms\", \"surface_covered\"], [\"bathrooms\"], [\"property_type\"], 14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_2a, X_test_2a, y_train_2a, y_test_2a = potentialTrainingDataGenerator(df2, [\"lat\", \"lon\", \"surface_covered\"], [\"bathrooms\",\"rooms\"], [\"property_type\"], 3)\n\nX_train_2b, X_test_2b, y_train_2b, y_test_2b = potentialTrainingDataGenerator(df2, [\"lat\", \"lon\", \"surface_covered\"], [\"bathrooms\", \"rooms\"], [\"property_type\"], 14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_1a, X_test_1a, y_train_1a, y_test_1a = potentialTrainingDataGenerator(df1, [\"lat\", \"lon\",\"surface_total\"], [\"bathrooms\",\"rooms\",\"surface_covered\"], [\"property_type\"], 3)\n\nX_train_1b, X_test_1b, y_train_1b, y_test_1b = potentialTrainingDataGenerator(df1, [\"lat\", \"lon\", \"surface_total\"], [\"bathrooms\", \"rooms\",\"surface_covered\"], [\"property_type\"], 14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_1a","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_0a, X_test_0a, y_train_0a, y_test_0a = potentialTrainingDataGenerator(df0, [\"lat\", \"lon\", \"surface_covered\",\"surface_total\"], [\"bathrooms\",\"rooms\"], [\"property_type\"], 3)\n\nX_train_0b, X_test_0b, y_train_0b, y_test_0b = potentialTrainingDataGenerator(df0, [\"lat\", \"lon\", \"surface_covered\",\"surface_total\"], [\"bathrooms\", \"rooms\"], [\"property_type\"], 14)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"0. \"mo_dist_to_last\",\"lat\", \"lon\", \"original_currency\",\"rooms\", \"bathrooms\", \"surface_covered\", \"surface_total\", \"property_type\" (drop missing surfaces & lat/lon, impute for the mean in everything else) \n1. \"mo_dist_to_last\",\"lat\", \"lon\", \"original_currency\", \"rooms\", \"bathrooms\", \"surface_covered\", \"surface_total\", \"property_type\" (drop lat, lon and surface total misising, impute covered, rooms andbathrooms)"},{"metadata":{},"cell_type":"markdown","source":"# Adjustment by inflation <a id=\"abi\"></a>"},{"metadata":{},"cell_type":"markdown","source":"This wasn't yet done because I'll assume that the model can detect inflationary patterns from the \"mo_dist_to_last\" column\n\nidea:\n1. map locations to regions\n2. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# def adjustByInflation(df):\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data export <a id=\"de\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cero_a = [(X_train_0a,\"X_train_0a\"), (X_test_0a,\"X_test_0a\"), (y_train_0a,\"y_train_0a\"), (y_test_0a,\"y_test_0a\")]\none_a = [(X_train_1a,\"X_train_1a\"), (X_test_1a,\"X_test_1a\"), (y_train_1a,\"y_train_1a\"), (y_test_1a,\"y_test_1a\")]\ntwo_a = [(X_train_2a,\"X_train_2a\"), (X_test_2a,\"X_test_2a\"), (y_train_2a,\"y_train_2a\"), (y_test_2a,\"y_test_2a\")]\nthree_a = [(X_train_3a,\"X_train_3a\"), (X_test_3a,\"X_test_3a\"), (y_train_3a,\"y_train_3a\"), (y_test_3a,\"y_test_3a\")]\nfour_a = [(X_train_4a,\"X_train_4a\"), (X_test_4a,\"X_test_4a\"), (y_train_4a,\"y_train_4a\"), (y_test_4a,\"y_test_4a\")]\nfive_a = [(X_train_5a,\"X_train_5a\"), (X_test_5a,\"X_test_5a\"), (y_train_5a,\"y_train_5a\"), (y_test_5a,\"y_test_5a\")]\nA = [cero_a,one_a,two_a,three_a,four_a,five_a]\ncero_b = [(X_train_0b,\"X_train_0b\"), (X_test_0b,\"X_test_0b\"), (y_train_0b,\"y_train_0b\"), (y_test_0b,\"y_test_0b\")]\none_b = [(X_train_1b,\"X_train_1b\"), (X_test_1b,\"X_test_1b\"), (y_train_1b,\"y_train_1b\"), (y_test_1b,\"y_test_1b\")]\ntwo_b = [(X_train_2b,\"X_train_2b\"), (X_test_2b,\"X_test_2b\"), (y_train_2b,\"y_train_2b\"), (y_test_2b,\"y_test_2b\")]\nthree_b = [(X_train_3b,\"X_train_3b\"), (X_test_3b,\"X_test_3b\"), (y_train_3b,\"y_train_3b\"), (y_test_3b,\"y_test_3b\")]\nfour_b = [(X_train_4b,\"X_train_4b\"), (X_test_4b,\"X_test_4b\"), (y_train_4b,\"y_train_4b\"), (y_test_4b,\"y_test_4b\")]\nfive_b = [(X_train_5b,\"X_train_5b\"), (X_test_5b,\"X_test_5b\"), (y_train_5b,\"y_train_5b\"), (y_test_5b,\"y_test_5b\")]\nB = [cero_b,one_b,two_b,three_b,four_b,five_b]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for k in A:\n    for i in k:\n        i[0].to_csv(i[1]+\".csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}