{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Diabetes Predicition Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Importing all the relevent libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Setting the style for all the plots thats we will be analysing ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style('whitegrid')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing the data in a dataframe","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/diabetes-dataset/diabetes2.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking the first 5 rows of the data: We have 8 independent columns and 1 dependent column in the dataset","execution_count":null},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking types of the features : All columns are numerical in natures with no missing values ","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating a pairplot to see the distribution of all features and comparing them","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check for null values: There is no null values ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can also see though the heamap below that there is no missing value, in case there were it will be highlighed by yellow color corresponsing to features","execution_count":null},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"sns.heatmap(data.isnull(),yticklabels=False,cbar=False,cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distibution of BMI: Normal","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"sns.distplot(data['BMI'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distribution of SkinThickness: Bimodel and skewed towards right","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"sns.distplot(data['SkinThickness'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distribtion of diabetes cases: 0 - No Diabetes | 1 - Diabetes\nWe can see from the below countplot that our data is not balance which also means we will give more importance to Precision, Recall or F-Value over Accuracy in this case ","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"sns.countplot(data['Outcome'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"COrrelation Matrix: All features have some what significant correlation with outcome and also does not look like a case of multicollinearity","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(data.corr(), cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Divide the dataset into Train and test","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In this case we have 70% of the data to be considered as Training and remaining 30% will used for testing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.drop('Outcome', axis = 1)\ny= data['Outcome']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating Logistic regression object and fitting/traing the model ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lm = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"lm.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predicting the outcome based on test dataset and storing in the variable ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = lm.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking confusing matrix and classification report in order to see how will our model performed on the test datatset","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Accounding to these matrics, our model is around 75% successful in predicting the outcome ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Standardizing the dataset","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We noticed that columns have different range for all independent features are different so we will try to run regression after standarizing the dataset and see if it can improve the model performance","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Importing StandardScaler and creating an object of it","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Standardizing the independent features ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler.fit(data.drop('Outcome',axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_features = scaler.transform(data.drop('Outcome',axis=1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking the standard dataframe","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df_feat = pd.DataFrame(scaled_features,columns=data.columns[:-1])\ndf_feat.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df_feat.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Spliting the dataframe into test and train dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"S_X_train, S_X_test, S_y_train, S_y_test = train_test_split(scaled_features,data['Outcome'],\n                                                    test_size=0.30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"slm = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training the model ","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"slm.fit(S_X_train, S_y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predicting based on trained model and storing the outcome in the variable ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = slm.predict(S_X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking confusing matrix and classification report in order to see how will our model performed on the test datatset","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Accounding to these matrics, our model is around 75% successful in predicting the outcome so in this case standardization has not been able to significantly chnage the performance of the model but is a good practice to standized the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(S_y_test, predict)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(classification_report(S_y_test, predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In the dataset, I tried to predict the occurance of diabetes based on 8 independent variable like BMI, SkinThickeness, Glucose level and other.\nI used logistic regresion and conclude that this model is ~ 75% times successfully predicting wheather the patient has diabetes or not","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}