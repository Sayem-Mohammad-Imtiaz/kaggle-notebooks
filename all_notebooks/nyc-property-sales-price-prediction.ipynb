{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#1 - Import libraries\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set(color_codes=True)\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.linear_model import LinearRegression\nimport math\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true},"cell_type":"code","source":"#2 - Load file into dataframe\ndf = pd.read_csv(\"../input/nyc-rolling-sales.csv\")\n\n#Overview of data\n#Find no. of rows & cols\nprint(df.shape, \"\\n\")\n#Show col names and datatypes\nprint(df.dtypes, \"\\n\")\n#Show no. of None values\nprint(df.isna().sum(), \"\\n\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b294664d440b3d20ab5cb966056c26d80f17199"},"cell_type":"code","source":"#3 - Write functions for data exploration\n\n#Function for plotting histograms:\ndef PlotHist(col, color='b'):\n    col.plot.hist(grid=True, bins=12, rwidth=0.9,\n                      color=color)\n    plt.title('Value distribution: ' + col.name)\n    plt.xlabel(col.name)\n    plt.ylabel('Frequency')\n    plt.grid(axis='y', alpha=0.75)\n    plt.show();\n    \n#Calculate step for y-ticks\ndef CalcMax(max_val):\n    mag = len(str(round(max_val))) - 1\n    #power of ten - pot\n    PoT = 10 ** mag \n    rounded = math.ceil(max_val/PoT) * PoT\n    return rounded;\n\n#Function for selecting categories\ndef AssignCat(col, num_cats=5):\n    if len(col.value_counts().keys()) < num_cats:\n        num_cats = len(col.value_counts().keys())\n    cats =  pd.DataFrame(col.value_counts().nlargest(num_cats - 1))\n    cats['row_num'] = [str(x+1) for x in range(len(cats))]\n    cats['name'] = cats.index.values\n    col = pd.DataFrame({'val': col.values})\n    col = pd.merge(col, cats, how='left', left_on='val', right_on='name')\n    col['new'] = col['row_num'].fillna(str(num_cats))\n    return col['new'].values;\n \n#Function for plotting bar charts:\ndef PlotBar(col, color='b'):\n    means = {}\n    for i in col.unique():\n        means.update({i : np.exp(df['Price'][df[col.name]== i]).mean()})   \n    plt.bar(range(len(means)), list(means.values()), align='center', \\\n            color=color)\n    plt.xticks(range(len(means)), sorted(list(means.keys())))\n    #Get largest value\n    maximum = CalcMax(max(means.values()))\n    s = maximum / 5\n    y_labels = [\"{:,}\".format(x) for x in np.arange(0,maximum, step=s)]\n    plt.yticks(np.arange(0,maximum, step=s),y_labels)\n    plt.title('Avg. Price per ' + col.name)\n    plt.xlabel(col.name)\n    plt.ylabel('Price')\n    plt.show(); \n    \n#Function for creating scatter plots:\ndef PlotScatter(col, show='none'):\n    plt.title('Price - ' + col.name)\n    plt.xlabel(col.name)\n    plt.ylabel('Price log')\n    if show == 'mlp':\n        plt.scatter(col,(df['Price']))\n        plt.show()\n    elif show == 'sns': \n        sns.regplot(x=col.name, y='Price', data=df, x_jitter=.5)\n        plt.show()\n    else: print(col.name +': No plot shown to reduce processing time');\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0215e298e1d089feb0ebd9551d0e75bbb91db0ea"},"cell_type":"code","source":"#4 - Analyse dependent variable\n\n#Check for unusual values\ndf['Price'] = sorted(df['SALE PRICE'])\n#print(df.Price.head(10))\n#Some values which represent missing values: '-'\n#Convert to int\ndf['Price'] = pd.to_numeric(df['SALE PRICE'], errors='coerce')\n#remove Nan values\ndf = df[df['Price'].isnull()==0]\ndf['Price'] = df['Price'].astype(int)\n# Show distribution before transformation\nPlotHist(df['Price'],'c')\n\n#Remove records with price = 0 - Anomalies\ndf = df[df['Price'] != 0]\n\ndf['Price'] = df['Price'].apply(np.log)\n\nprint(df['SALE PRICE'].describe(), \"\\n\")\nprice_avg = df['Price'].mean()\nprint('Average Price (log): ' + \"{:,}\".format(round(price_avg)), \"\\n\")\nprice_stdev = np.std(df['Price'])\nprint('Std. Dev. of Price (log): ' + \"{:,}\".format(round(price_stdev)), \"\\n\")\n\n#Remove outliers: 3 stdevs from mean\ndf =  df[df['Price'] >= price_avg - price_stdev * 3]\ndf =  df[df['Price'] <= price_avg + price_stdev * 3]\n\n#Plot again:\nPlotHist(df['Price'], 'c')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e20e284f76e542f4cfc15c691f1f23965b17d5de"},"cell_type":"code","source":"#5 - Explore independent variables\n\n                                #1. Borough\nprint('BOROUGH - Value Counts')\nprint(df.BOROUGH.value_counts(), \"\\n\")\nPlotBar(df['BOROUGH'],'g')\n\n#Convert to dummies\nborough = pd.get_dummies(df['BOROUGH'], prefix='borough')\ndf = pd.concat([df, borough], axis=1)\n\n# May use this feature in multiple regression due to significant price difference\n\n                            #2. Neighborhood\n#print('NEIGHBORHOOD - Value Counts')\n#print(df.NEIGHBORHOOD.value_counts(), \"\\n\")\n# Probably not useful: too many distinct, non-numeric values\n\n                        #3. Building Class Category\n#Since there are too many categories, we only take the first 4 categories \n#and group the rest into one\ndf['building_category'] = AssignCat(df['BUILDING CLASS CATEGORY'])\n\nPlotBar(df['building_category'],'r')\n\n#Convert to dummies\nbuild_cat = pd.get_dummies(df['building_category'], prefix='bc')\ndf = pd.concat([df, build_cat], axis=1)\n\n                        #4.A Tax Class Category\nprint('Tax Class - Value Counts')\nprint(df['TAX CLASS AT PRESENT'].value_counts(), \"\\n\")\n#Only use 3 most common classes\ndf['tax_class'] = AssignCat(df['TAX CLASS AT PRESENT'])\n\nPlotBar(df['tax_class'],'gray')\n\n#Convert to dummies\ntax_class = pd.get_dummies(df['tax_class'], prefix='tc')\ndf = pd.concat([df, tax_class], axis=1)\n\n                        #4.B Tax class at time of sale\nprint('Tax Class at Sale - Value Counts')\nprint(df['TAX CLASS AT TIME OF SALE'].value_counts(), \"\\n\")\n#Only use 3 most common classes\ndf['tc_at_sale'] = AssignCat(df['TAX CLASS AT TIME OF SALE'])\n  \n\nPlotBar(df['tax_class'],'black')\n\ntc_present = pd.get_dummies(df['tc_at_sale'], prefix='tcs')\ndf = pd.concat([df, tc_present], axis=1)\n\n#Different systems - unclear which is better\n\n                            #5. Block\n#print('Block - Value Counts')\n#print(df['BLOCK'].value_counts(), \"\\n\")\n#Too many distinct values, no category with significant % of counts\n\n                            #6. Lot\n#print('Lot - Value Counts')\n#print(df['LOT'].value_counts(), \"\\n\")\n#Too many distinct values, no category with significant % of counts\n\n                        #7. Ease-ment\nprint('Ease-ment - Value Counts')\nprint(df['EASE-MENT'].value_counts(), \"\\n\")\n#Same as ID - no use\n\n                #8A - Building class at present\n#print('Building Class Present - Value Counts')\n#print(df['BUILDING CLASS AT PRESENT'].value_counts(), \"\\n\")\n#Only use 3 most common classes\ndf['bcp'] = AssignCat(df['BUILDING CLASS AT PRESENT'])\n\nPlotBar(df['bcp'],color='y')\n\n                    #8B - Building class at time of sale\n\n\ndf['bcs'] = AssignCat(df['BUILDING CLASS AT TIME OF SALE'])\n\nPlotBar(df['bcs'],color='coral')\n\n#Almost the same as Building Class at Present - use at Sale which is more meaningful\n\nbcs = pd.get_dummies(df['bcs'], prefix='bcs')\ndf = pd.concat([df, bcs], axis=1)\n\n                        #9. Address\n#Too specifig - unlikely to be useful\n\n                    #10. Apartment no.\n#print('Apartment No. - Value Counts')\n#print(df['APARTMENT NUMBER'].value_counts(), \"\\n\")\n#Too many different values \n\n                    #11. Zip code\n#print('ZIP Code - Value Counts')\n#print(df['ZIP CODE'].value_counts(), \"\\n\")\n#Too many different values \n\n\n                    #12. Residential units\n#print('RESIDENTIAL UNITS - Value Counts')\n#print(df['RESIDENTIAL UNITS'].value_counts(), \"\\n\")\ndf['res_unit_log'] = df['RESIDENTIAL UNITS'].apply(lambda x: 0 if x == 0 \\\n                                              else np.log(x)) \nPlotScatter(df['res_unit_log'])\n\n                        #13. Commercial units\ndf['com_unit_log'] = df['COMMERCIAL UNITS'].apply(lambda x: 0 if x == 0 \\\n                                              else np.log(x)) \nPlotScatter(df['com_unit_log'])\n\n                        #14. Total units\ndf['tot_unit_log'] = df['TOTAL UNITS'].apply(lambda x: 0 if x == 0 \\\n                                              else np.log(x)) \nPlotScatter(df['tot_unit_log'])\n\n                        #15. Land square ft\n#Impute mean for missing and values\ndf['land'] =  pd.to_numeric(df['LAND SQUARE FEET'], errors='coerce')\n#use median for 0 and nulls\nland_median = df['land'][df['land']!=0].median()\ndf['land'] = df['land'].fillna(land_median)\ndf['land'] = df['land'].apply(lambda x: x if x > 0 \\\n                                          else land_median)\ndf['land_log'] = np.log(df['land'])\nPlotScatter(df['land_log'])\n\n                            #16. Gross square ft\ndf['gross_sqft'] =  pd.to_numeric(df['GROSS SQUARE FEET'], errors='coerce')\n#use median for 0 and nulls\ngross_sqft_median = df['gross_sqft'][df['gross_sqft']!=0].median()\ndf['gross_sqft'] = df['gross_sqft'].fillna(gross_sqft_median)\ndf['gross_sqft'] = df['gross_sqft'].apply(lambda x: x if x > 0 \\\n                                          else gross_sqft_median)\ndf['gross_sqft_log'] = np.log(df['gross_sqft'])\nPlotScatter(df['gross_sqft'])\n\n                            #17. Year built\ndf['year'] = df['YEAR BUILT']\n#Impute median where year = 0\nyear_median = df['year'][df['year'] != 0].median()\n#Date cannot before 1764\ndf['year'] = df['year'].apply(lambda x: x if x >= 1764 else year_median )\nPlotHist(df['year'], 'orange')\nPlotScatter(df['year'])\n\n#Unclear if relationship between year and price\n\n\n                        #18. Sale date\ndf['date'] = pd.to_datetime(df['SALE DATE'], format = '%Y-%m-%d %H:%M:%S') \n\nsale_dates =  sorted(set(df['date']))\n\ndate_means = []\nfor i in sale_dates:\n    date_means.append(np.exp(df['Price'][df['date']== i]).mean())\n    \nplt.plot(sale_dates,date_means)\nplt.title('Price - Sale Date')\nplt.xlabel('Date')\nplt.ylabel('Price')\nplt.show()\n#Apparently no clear relationship\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"997312e7c5a0cb93d121448ebe1faf27627c22ce"},"cell_type":"code","source":"#6 - Split dataset into train and test\n\n#potential features\nX= df[['borough_1','borough_2','borough_3','borough_4','borough_5', \\\n       'bc_1','bc_2','bc_3','bc_4','bc_5','tc_1','tc_3','tc_4',\\\n       'tcs_3','tcs_1','tcs_2','bcs_5','bcs_1', \\\n       'bcs_3','bcs_4','res_unit_log','com_unit_log','tot_unit_log',\\\n       'land_log','gross_sqft_log','year']]\nY = df['Price']\nX_train, X_test, Y_train, Y_test = \\\n   train_test_split(X, Y, test_size=0.3, random_state=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff1ffaa0ada44abff639e05b88d777772b16678b"},"cell_type":"code","source":"#7 - Build regression model\n\nTrain = {}\nTest = {}\nmodel_no = 1\n\ndef RunRegression(model_number, model):\n    print('Model no. ' + str([model_number]), \"\\n\" )\n    Train[model_number] = X_train[model]\n    Test[model_number]= X_test[model]                        \n    reg = LinearRegression().fit(Train[model_number], Y_train)\n    score = reg.score(Test[model_number], Y_test)\n    print('Model using variables: '+ str(list(Train[model_number])))\n    print('R^2 Score: ' + str(score), \"\\n\" )\n    coefficients = reg.coef_\n    print('Coefficients: ' +str(coefficients), \"\\n\" )  \n    global model_no\n    model_no = model_number + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3eb73e143045d7c12b3fb9491f017cdba9ed8d87"},"cell_type":"code","source":"#8 - Test and evaluate different models\n\n#First model: only BOROUGH  \nmodel =  ['borough_1','borough_2','borough_3','borough_4','borough_5']\n\nRunRegression(model_no, model)\n\n#Second model: BOROUGH and land  \nmodel = ['borough_1','borough_2','borough_3','borough_4','borough_5','land_log']\n\nRunRegression(model_no, model)\n#Total R^2 increased\n\n#Third model: BOROUGH and Gross_sqft  \nmodel = ['borough_1','borough_2','borough_3','borough_4','borough_5',\\\n         'gross_sqft_log']\nRunRegression(model_no, model)\n#Total R^2 increased compared to land\n\n#Fourth model: BOROUGH, Gross_sqft, Res_Unit \nmodel = ['borough_1','borough_2','borough_3','borough_4','borough_5',\\\n         'gross_sqft_log','res_unit_log']\nRunRegression(model_no, model)\n#Total R^2 not significantly increased\n\n#Fifth model: BOROUGH, Gross_sqft, Com_Unit \nmodel = ['borough_1','borough_2','borough_3','borough_4','borough_5',\\\n         'gross_sqft_log','com_unit_log']\nRunRegression(model_no, model)\n#Total R^2 reduced\n\n#Sixth model: BOROUGH, Gross_sqft, Tot_Unit \nmodel = ['borough_1','borough_2','borough_3','borough_4','borough_5',\\\n         'gross_sqft_log','tot_unit_log']\nRunRegression(model_no, model)\n\n#Total R^2 higher than res_units or com_units\n\n#Seventh model: BOROUGH, Gross_sqft, Tot_Unit, TaxClass \nmodel = ['borough_1','borough_2','borough_3','borough_4','borough_5',\\\n         'gross_sqft_log','tot_unit_log','tc_3','tc_1','tc_3','tc_4']\nRunRegression(model_no, model)\n#Total R^2 slightly increased\n\n#Next model: BOROUGH, Gross_sqft, Tot_Unit, TaxClass at Sale \nmodel = ['borough_1','borough_2','borough_3','borough_4','borough_5',\\\n         'gross_sqft_log','tot_unit_log','tcs_3','tcs_1','tcs_2']\nRunRegression(model_no, model)\n#Total R^2 slightly lower\n\n#Next model: BOROUGH, Gross_sqft, Tot_Unit, TaxClass present, TaxClass at Sale \nmodel = ['borough_1','borough_2','borough_3','borough_4','borough_5',\\\n         'gross_sqft_log','tot_unit_log','tc_1','tc_3','tc_4',\\\n         'tcs_3','tcs_1','tcs_2']\nRunRegression(model_no, model)\n#Total R^2 only slightly higher than without tax class at sale\n\n\"\"\"Next model: BOROUGH, Gross_sqft, Tot_Unit, TaxClass present, \nBuildingCat at Sale\"\"\" \nmodel = ['borough_1','borough_2','borough_3','borough_4','borough_5',\\\n         'gross_sqft_log','tot_unit_log','tc_1','tc_3','tc_4',\\\n         'bc_1','bc_2','bc_3','bc_4','bc_5']\nRunRegression(model_no, model)\n#Total R^2 slightly increased","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}