{"cells":[{"metadata":{},"cell_type":"markdown","source":"##### Please upvote if you like this kernel representation!"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv(\"../input/retail-analysis-with-walmart-data/Walmart_Store_sales.csv\")\ndata.head() #Fetches default first 5 rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#basic Functions\ndata.isnull().sum() #Null value check","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1. Which store has maximum sales ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"max_sales = data.groupby('Store')['Weekly_Sales'].sum()\nmax_sales.idxmax()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting the max sales in the Bar chart\nplt.figure(figsize=(15,5))\nsns.barplot(x=data.Store, y = data.Weekly_Sales)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Store 20 has maximum Sales"},{"metadata":{},"cell_type":"markdown","source":"### 2. Which store has maximum standard deviation i.e., the sales vary a lot. Also, find out the coefficient of mean to standard deviation."},{"metadata":{"trusted":true},"cell_type":"code","source":"# maximum Standard deviation\nmax_std = data.groupby('Store')['Weekly_Sales'].std()\nmax_std.idxmax()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# maximum coefficient of variation\nmax_cov = ((data.groupby('Store')['Weekly_Sales'].std())/(data.groupby('Store')['Weekly_Sales'].mean()))*100\nmax_cov.idxmax()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting the max sales in the Bar chart\nstores = data.groupby('Store')\nstore_35 = stores.get_group(35)\nplt.figure(figsize=(10,5))\nsns.distplot(store_35.Weekly_Sales, color='green', label='Weekly Sales for Store 35')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Analysis- It is rightly skewed graph which is giving the intutions that sales are centred around 800000 for weekly sales for store 35."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Identify Outliers in weekly_sales for store 35\nsns.boxplot(store_35.Weekly_Sales, color='cyan') #less outliers","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Store 14 has maximum standard deviation and store 35 has maximum Coefficient of Variance."},{"metadata":{},"cell_type":"markdown","source":"### 3. Which store/s has good quarterly growth rate in Q3’2012 ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Grouping data by year and month\ngrowth = data.copy()\ngrowth['Date'] = pd.to_datetime(growth.Date,format='%d-%m-%Y')\ngrowth['Year'] = growth['Date'].dt.year\ngrowth['Month'] = growth['Date'].dt.month\ngrowth","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Group data with year = 2012\ngrowth_rate = growth.groupby('Year')\ngrowth_rate_2012 = growth_rate.get_group(2012)\ngrowth_rate_2012.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting data for 4 quaters for year 2012\n\ngrowth_rate_2012_Quaters = growth_rate_2012.groupby('Month')\ngrowth_rate_2012_Q1_1 = growth_rate_2012_Quaters.get_group(1)\ngrowth_rate_2012_Q1_2 = growth_rate_2012_Quaters.get_group(2)\ngrowth_rate_2012_Q1_3 = growth_rate_2012_Quaters.get_group(3)\n\nQuater_1 = growth_rate_2012_Q1_1.append(growth_rate_2012_Q1_2)\nQuater_1 = Quater_1.append(growth_rate_2012_Q1_3) #Q1 data of 2012\ndisplay(Quater_1.head())  \n\ngrowth_rate_2012_Q2_4 = growth_rate_2012_Quaters.get_group(4)\ngrowth_rate_2012_Q2_5 = growth_rate_2012_Quaters.get_group(5)\ngrowth_rate_2012_Q2_6 = growth_rate_2012_Quaters.get_group(6)\n\nQuater_2 = growth_rate_2012_Q2_4.append(growth_rate_2012_Q2_5)\nQuater_2 = Quater_2.append(growth_rate_2012_Q2_6)  #Q2 data of 2012\ndisplay(Quater_2.head())\n\ngrowth_rate_2012_Q3_7 = growth_rate_2012_Quaters.get_group(7)\ngrowth_rate_2012_Q3_8 = growth_rate_2012_Quaters.get_group(8)\ngrowth_rate_2012_Q3_9 = growth_rate_2012_Quaters.get_group(9)\nQuater_3 = growth_rate_2012_Q3_7.append(growth_rate_2012_Q3_8)\nQuater_3 = Quater_3.append(growth_rate_2012_Q3_9)  #Q3 data of 2012\ndisplay(Quater_3.head())\n\n# Q4 data of 2012\ngrowth_rate_2012_Q4_10 = growth_rate_2012_Quaters.get_group(10)\nQuater_4 = growth_rate_2012_Q4_10\ndisplay(Quater_4.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Grouping the data \"Store\" wise each Quarter\n\ndf2 = pd.DataFrame(Quater_1.groupby('Store')['Weekly_Sales'].sum())\n\ndf2[\"Quater1_Sales\"] = pd.DataFrame(Quater_1.groupby('Store')['Weekly_Sales'].sum())\ndf2[\"Quater2_Sales\"] = pd.DataFrame(Quater_2.groupby('Store')['Weekly_Sales'].sum())\ndf2[\"Quater3_Sales\"] = pd.DataFrame(Quater_3.groupby('Store')['Weekly_Sales'].sum())\ndf2[\"Quater4_Sales\"] = pd.DataFrame(Quater_4.groupby('Store')['Weekly_Sales'].sum())\ndf2.drop('Weekly_Sales', axis = 1, inplace = True)\ndf2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Growth rate formula- ((Present value — Past value )/Past value )*100\n\ndf2['Q3 - Q2'] = df2['Quater3_Sales'] - df2['Quater2_Sales']\ndf2['Overall Growth Rate in 2012 Q3 %'] = (df2['Q3 - Q2']/df2['Quater2_Sales'])*100\n\ndf2['Overall Growth Rate in 2012 Q3 %'].idxmax() # Store which has good growth in Q3-2012","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the data in Bar chart\nplt.figure(figsize=(15,5))\nsns.barplot(x=df2.index, y = 'Overall Growth Rate in 2012 Q3 %', data = df2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Store 7 has good growth in Q3-2012"},{"metadata":{},"cell_type":"markdown","source":"### 4. Some holidays have a negative impact on sales. Find out holidays which have higher sales than the mean sales in non-holiday season for all stores together."},{"metadata":{"trusted":true},"cell_type":"code","source":"#finding the mean sales of non holiday and holiday \ndata.groupby('Holiday_Flag')['Weekly_Sales'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Marking the holiday dates \ndata['Date'] = pd.to_datetime(data['Date'])\n\nChristmas1 = pd.Timestamp(2010,12,31)\nChristmas2 = pd.Timestamp(2011,12,30)\nChristmas3 = pd.Timestamp(2012,12,28)\nChristmas4 = pd.Timestamp(2013,12,27)\n\nThanksgiving1=pd.Timestamp(2010,11,26)\nThanksgiving2=pd.Timestamp(2011,11,25)\nThanksgiving3=pd.Timestamp(2012,11,23)\nThanksgiving4=pd.Timestamp(2013,11,29)\n\nLabourDay1=pd.Timestamp(2010,9,10)\nLabourDay2=pd.Timestamp(2011,9,9)\nLabourDay3=pd.Timestamp(2012,9,7)\nLabourDay4=pd.Timestamp(2013,9,6)\n\nSuperBowl1=pd.Timestamp(2010,2,12)\nSuperBowl2=pd.Timestamp(2011,2,11)\nSuperBowl3=pd.Timestamp(2012,2,10)\nSuperBowl4=pd.Timestamp(2013,2,8)\n\n#Calculating the mean sales during the holidays\nChristmas_mean_sales=data[(data['Date'] == Christmas1) | (data['Date'] == Christmas2) | (data['Date'] == Christmas3) | (data['Date'] == Christmas4)]\nThanksgiving_mean_sales=data[(data['Date'] == Thanksgiving1) | (data['Date'] == Thanksgiving2) | (data['Date'] == Thanksgiving3) | (data['Date'] == Thanksgiving4)]\nLabourDay_mean_sales=data[(data['Date'] == LabourDay1) | (data['Date'] == LabourDay2) | (data['Date'] == LabourDay3) | (data['Date'] == LabourDay4)]\nSuperBowl_mean_sales=data[(data['Date'] == SuperBowl1) | (data['Date'] == SuperBowl2) | (data['Date'] == SuperBowl3) | (data['Date'] == SuperBowl4)]\nChristmas_mean_sales\n\nlist_of_mean_sales = {'Christmas_mean_sales' : round(Christmas_mean_sales['Weekly_Sales'].mean(),2),\n'Thanksgiving_mean_sales': round(Thanksgiving_mean_sales['Weekly_Sales'].mean(),2),\n'LabourDay_mean_sales' : round(LabourDay_mean_sales['Weekly_Sales'].mean(),2),\n'SuperBowl_mean_sales':round(SuperBowl_mean_sales['Weekly_Sales'].mean(),2),\n'Non holiday weekly sales' : round(data[data['Holiday_Flag'] == 0 ]['Weekly_Sales'].mean(),2)}\nlist_of_mean_sales\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\"Thanksgiving Day\" has much high sale than mean sales in Non-Holiday season."},{"metadata":{},"cell_type":"markdown","source":"### 5. Provide a monthly and semester view of sales in units and give insights"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Monthly sales \nmonthly = data.groupby(pd.Grouper(key='Date', freq='1M')).sum() # groupby each 1 month\nmonthly=monthly.reset_index()\nfig, ax = plt.subplots(figsize=(10,5))\nX = monthly['Date']\nY = monthly['Weekly_Sales']\nplt.plot(X,Y)\nplt.title('Month Wise Sales')\nplt.xlabel('Monthly')\nplt.ylabel('Weekly_Sales')\n\n# Analysis- highest sum of sales is recorded in between jan-2011 to march-2011.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Semester Sales \nSemester = data.groupby(pd.Grouper(key='Date', freq='6M')).sum()\nSemester = Semester.reset_index()\nfig, ax = plt.subplots(figsize=(10,5))\nX = Semester['Date']\nY = Semester['Weekly_Sales']\nplt.plot(X,Y)\nplt.title('Semester Wise Sales')\nplt.xlabel('Semester')\nplt.ylabel('Weekly_Sales')\n\n# ANalysis- sales are lowest in beginning of 1st sem of 2010 and 1st sem of 2013","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  For Store 1 – Build  prediction models to forecast demand\n\nLinear Regression – Utilize variables like date and restructure dates as 1 for 5 Feb 2010 (starting from the earliest date in order). Hypothesize if CPI, unemployment, and fuel price have any impact on sales."},{"metadata":{"trusted":true},"cell_type":"code","source":"hypothesis = growth.groupby('Store')[['Fuel_Price','Unemployment', 'CPI','Weekly_Sales', 'Holiday_Flag']]\nfactors  = hypothesis.get_group(1) #Filter by Store 1\nday_arr = [1]\nfor i in range (1,len(factors)):\n    day_arr.append(i*7)\n    \nfactors['Day'] = day_arr.copy()\nfactors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(factors.corr(), annot = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Few variables which are positive and have value greater than zero are correlated with Weekly_Sales. We can also see CPI and Holiday_Flag is fairly strongly correlated to Weekly_Sales. Holiday_Flag = 1 means it's holiday_week we have sales more than the non_holiday_weeks."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lmplot(x='Fuel_Price', y = 'Unemployment', data = factors)\n#plt.figure()\nsns.lmplot(x='CPI', y = 'Unemployment', data = factors)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As the Fuel_price and Cpi goes high, rate of Unemployment Fairly Decreases (shown above in Line Regression plot)."},{"metadata":{},"cell_type":"markdown","source":"### Hypothesis Testing - CPI"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\nttest,pval = stats.ttest_rel(factors['Weekly_Sales'],factors['CPI'])\nsns.distplot(factors.CPI)\nplt.figure()\nprint(pval)\nif pval<0.05:\n    print(\"reject null hypothesis\")\nelse:\n    print(\"accept null hypothesis\")\n    \nsns.scatterplot(x='CPI', y = 'Weekly_Sales', data = factors, hue = 'Holiday_Flag')\n#plt.figure()\nsns.lmplot(x='CPI', y = 'Weekly_Sales', data = factors, hue = 'Holiday_Flag')\n#plt.figure()\nsns.lineplot(x='CPI', y = 'Weekly_Sales', data = factors)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1) Earlier, we rejected the null hypothesis saying that ther is no relationship between Weekly_sales and CPI. But we found there is a positive corrlation between CPI and Weekly_sales as shown in the above graphs.\n\n2) The CPI is not normally distributed and line regression plot is showing how CPI is varying with Weekly_Sales on days of Holidays and non holiday weeks."},{"metadata":{},"cell_type":"markdown","source":"### Hypothesis Testing - Fuel_Price"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\nttest,pval = stats.ttest_rel(factors['Weekly_Sales'],factors['Fuel_Price'])\nsns.distplot(factors.Fuel_Price)\nplt.figure()\nprint(pval)\nif pval<0.05:\n    print(\"reject null hypothesis\")\nelse:\n    print(\"accept null hypothesis\")\n    \nsns.scatterplot(x='Fuel_Price', y = 'Weekly_Sales', data = factors, hue = 'Holiday_Flag')\n#plt.figure()\nsns.lmplot(x='Fuel_Price', y = 'Weekly_Sales', data = factors, hue = 'Holiday_Flag')\n#plt.figure()\nsns.lineplot(x='Fuel_Price', y = 'Weekly_Sales', data = factors)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are more number of Sales when the Fuel_Price are higher and also we can see more Sales during Holiday_Weeks when fuel_prices were fairly low. So its not clear to say on what factors Fuel_price has a direct dependency on Sales."},{"metadata":{},"cell_type":"markdown","source":"### Hypothesis Testing - Uneployment"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\nttest,pval = stats.ttest_rel(factors['Weekly_Sales'],factors['Unemployment'])\nsns.distplot(factors.Unemployment)\nplt.figure()\nprint(pval)\nif pval<0.05:\n    print(\"reject null hypothesis\")\nelse:\n    print(\"accept null hypothesis\")\n    \nsns.scatterplot(x='Unemployment', y = 'Weekly_Sales', data = factors, hue = 'Holiday_Flag')\n#plt.figure()\nsns.lmplot(x='Unemployment', y = 'Weekly_Sales', data = factors, hue = 'Holiday_Flag')\n#plt.figure()\nsns.lineplot(x='Unemployment', y = 'Weekly_Sales', data = factors)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see as the rate of unemployment increases, people only buy during holiday seasons, as there are only few outliers present for weekly_sales and which are on the day of Holiday. Speaking of which people only buy necessary products and try to save more. Hence rejecting the null hypothesis was appropriate."},{"metadata":{},"cell_type":"markdown","source":"### Plotting the Weekly_sales for store 1 (Day wise)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.barplot(x='Day', y = 'Weekly_Sales', data = factors.head(50), hue = 'Holiday_Flag')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can infer during the days of holidays, there is comparatively more sales for store1."},{"metadata":{},"cell_type":"markdown","source":"## Thank you!!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}