{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Notebook - Table of Contents\n\n\n1. [**Basic Data Analysis**](#1.-Basic-Data-Analysis)  \n    1.1 [**Importing the necessary libraries & loading the data**](#1.1-Importing-the-necessary-libraries-&-loading-the-data)    \n    1.2 [**Basic statistics - Number of products, subcategories & gender**](#1.2-Basic-statistics---Number-of-products,-subcategories-&-gender)      \n    1.3 [**Frequency of each gender**](#1.3-Frequency-of-each-gender)      \n    1.4 [**Distribution of products gender-wise**](#1.4-Distribution-of-products-gender-wise)     \n2. [**Data Preparation**](#2.-Data-Preparation) \n3. [**Feature extraction using ResNet**](#3.-Feature-extraction-using-ResNet)  \n4. [**Computing the Euclidean distance and recommending similar products**](#4.-Computing-the-Euclidean-distance-and-recommending-similar-products)                         \n    4.1 [**Loading the extracted features**](#4.1-Loading-the-extracted-features)  \n    4.2 [**Distance computation and Recommendation**](#4.2-Distance-computation-and-Recommendation)  \n5. [**Deploying the solution**](#5.-Deploying-the-solution)  "},{"metadata":{},"cell_type":"markdown","source":"### Basic Data Analysis\n\n#### 1.1 Importing the necessary libraries & loading the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras import applications\nfrom sklearn.metrics import pairwise_distances\nimport requests\nfrom PIL import Image\nimport pickle\nfrom datetime import datetime\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\nimport plotly.figure_factory as ff\nimport plotly.graph_objects as go\nimport plotly.express as px\n#import streamlit as st\n#use the below library while displaying the images in jupyter notebook\nfrom IPython.display import display, Image\n\nfashion_df = pd.read_csv(\"/kaggle/input/fashion-images/data/fashion.csv\")\nfashion_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 1.2 Basic statistics - Number of products, subcategories & gender"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total number of products : \", fashion_df.shape[0])\nprint(\"Total number of unique subcategories : \", fashion_df[\"SubCategory\"].nunique())\nprint(\"Total number of unique gender types : \", fashion_df[\"Gender\"].nunique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 1.3 Frequency of each gender"},{"metadata":{"trusted":true},"cell_type":"code","source":"fashion_df[\"Gender\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 1.4 Distribution of products gender-wise"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot = sns.countplot(fashion_df[\"Gender\"])\nplt.title(\"Distribution of articles gender-wise\")\nplt.xlabel(\"Gender type\")\nplt.ylabel(\"Number of products\")\nplot.set_xticklabels(plot.get_xticklabels())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Data Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"apparel_boys = fashion_df[fashion_df[\"Gender\"]==\"Boys\"]\napparel_girls = fashion_df[fashion_df[\"Gender\"]==\"Girls\"]\nfootwear_men = fashion_df[fashion_df[\"Gender\"]==\"Men\"]\nfootwear_women = fashion_df[fashion_df[\"Gender\"]==\"Women\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Feature extraction using ResNet\n\n**For Gender - Men**"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_width, img_height = 224, 224\n\n#top_model_weights_path = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\ntrain_data_dir = \"/kaggle/input/fashion-images/data/Footwear/Men/Images/\"\n\nnb_train_samples = 811\nepochs = 50\nbatch_size = 1\n\ndef extract_features():\n    Itemcodes = []\n    datagen = ImageDataGenerator(rescale=1. / 255)\n    model = applications.ResNet50(include_top=False, weights='imagenet')\n    generator = datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_width, img_height),\n        batch_size=batch_size,\n        class_mode=None,\n        shuffle=False)\n    for i in generator.filenames:\n        Itemcodes.append(i[(i.find(\"/\")+1):i.find(\".\")])\n    extracted_features = model.predict_generator(generator, nb_train_samples // batch_size)\n    extracted_features = extracted_features.reshape((811, 100352))\n    \n    np.save(open('./Men_ResNet_features.npy', 'wb'), extracted_features)\n    np.save(open('./Men_ResNet_feature_product_ids.npy', 'wb'), np.array(Itemcodes))\n    \na = datetime.now()\nextract_features()\nprint(\"Time taken in feature extraction\", datetime.now()-a)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. Computing the Euclidean distance and recommending similar products\n\n#### 4.1 Loading the extracted features"},{"metadata":{"trusted":true},"cell_type":"code","source":"extracted_features = np.load('/kaggle/working/Men_ResNet_features.npy')\nProductids = np.load('/kaggle/working/Men_ResNet_feature_product_ids.npy')\nmen = footwear_men.copy()\n#men = pd.read_csv('./footwear_men.csv')\ndf_Productids = list(men['ProductId'])\nProductids = list(Productids)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4.2 Distance computation and Recommendation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_similar_products_cnn(product_id, num_results):\n    doc_id = Productids.index(product_id)\n    pairwise_dist = pairwise_distances(extracted_features, extracted_features[doc_id].reshape(1,-1))\n    indices = np.argsort(pairwise_dist.flatten())[0:num_results]\n    pdists  = np.sort(pairwise_dist.flatten())[0:num_results]\n    print(\"=\"*20, \"input product image\", \"=\"*20)\n    ip_row = men[['ImageURL','ProductTitle']].loc[men['ProductId']==int(Productids[indices[0]])]\n    #print(ip_row.head())\n    for indx, row in ip_row.iterrows():\n        display(Image(url=row['ImageURL'], width = 224, height = 224,embed=True))\n        print('Product Title: ', row['ProductTitle'])\n    print(\"\\n\",\"=\"*20, \"Recommended products\", \"=\"*20)\n    for i in range(1,len(indices)):\n        rows = men[['ImageURL','ProductTitle']].loc[men['ProductId']==int(Productids[indices[i]])]\n        for indx, row in rows.iterrows():\n            display(Image(url=row['ImageURL'], width = 224, height = 224,embed=True))\n            print('Product Title: ', row['ProductTitle'])\n            print('Euclidean Distance from input image:', pdists[i])\n\nget_similar_products_cnn('13683', 5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**NOTE** - The above feature extraction process can be repeated for other genders (Women, Boys and Girls) as well. So let's extract for each one by one.\n\n**For Gender - Women**"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_width, img_height = 224, 224\n\n\n#top_model_weights_path = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\ntrain_data_dir = \"/kaggle/input/fashion-images/data/Footwear/Women/Images/\"\n\nnb_train_samples = 769\nepochs = 50\nbatch_size = 1\n\ndef extract_features():\n    Itemcodes = []\n    datagen = ImageDataGenerator(rescale=1. / 255)\n    model = applications.ResNet50(include_top=False, weights='imagenet')\n    generator = datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_width, img_height),\n        batch_size=batch_size,\n        class_mode=None,\n        shuffle=False)\n    for i in generator.filenames:\n        Itemcodes.append(i[(i.find(\"/\")+1):i.find(\".\")])\n    extracted_features = model.predict_generator(generator, nb_train_samples // batch_size)\n    extracted_features = extracted_features.reshape((769, 100352))\n    \n    np.save(open('./Women_ResNet_features.npy', 'wb'), extracted_features)\n    np.save(open('./Women_ResNet_feature_product_ids.npy', 'wb'), np.array(Itemcodes))\n    \na = datetime.now()\nextract_features()\nprint(\"Time taken in feature extraction\", datetime.now()-a)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**For Gender - Boys**"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_width, img_height = 224, 224\n\n\n#top_model_weights_path = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\ntrain_data_dir = \"/kaggle/input/fashion-images/data/Apparel/Boys/Images\"\n\nnb_train_samples = 759\nepochs = 50\nbatch_size = 1\n\ndef extract_features():\n    Itemcodes = []\n    datagen = ImageDataGenerator(rescale=1. / 255)\n    model = applications.ResNet50(include_top=False, weights='imagenet')\n    generator = datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_width, img_height),\n        batch_size=batch_size,\n        class_mode=None,\n        shuffle=False)\n    for i in generator.filenames:\n        Itemcodes.append(i[(i.find(\"/\")+1):i.find(\".\")])\n    extracted_features = model.predict_generator(generator, nb_train_samples // batch_size)\n    extracted_features = extracted_features.reshape((759, 100352))\n    \n    np.save(open('./Boys_ResNet_features.npy', 'wb'), extracted_features)\n    np.save(open('./Boys_ResNet_feature_product_ids.npy', 'wb'), np.array(Itemcodes))\n    \na = datetime.now()\nextract_features()\nprint(\"Time taken in feature extraction\", datetime.now()-a)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**For Gender - Girls**"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_width, img_height = 224, 224\n\n\n#top_model_weights_path = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\ntrain_data_dir = \"/kaggle/input/fashion-images/data/Apparel/Girls/Images\"\n\nnb_train_samples = 567\nepochs = 50\nbatch_size = 1\n\ndef extract_features():\n    Itemcodes = []\n    datagen = ImageDataGenerator(rescale=1. / 255)\n    model = applications.ResNet50(include_top=False, weights='imagenet')\n    generator = datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_width, img_height),\n        batch_size=batch_size,\n        class_mode=None,\n        shuffle=False)\n    for i in generator.filenames:\n        Itemcodes.append(i[(i.find(\"/\")+1):i.find(\".\")])\n    extracted_features = model.predict_generator(generator, nb_train_samples // batch_size)\n    extracted_features = extracted_features.reshape((567, 100352))\n    \n    np.save(open('./Girls_ResNet_features.npy', 'wb'), extracted_features)\n    np.save(open('./Girls_ResNet_feature_product_ids.npy', 'wb'), np.array(Itemcodes))\n    \na = datetime.now()\nextract_features()\nprint(\"Time taken in feature extraction\", datetime.now()-a)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5. Deploying the solution"},{"metadata":{"trusted":true},"cell_type":"code","source":"boys_extracted_features = np.load('/kaggle/working/Boys_ResNet_features.npy')\nboys_Productids = np.load('/kaggle/working/Boys_ResNet_feature_product_ids.npy')\ngirls_extracted_features = np.load('/kaggle/working/Girls_ResNet_features.npy')\ngirls_Productids = np.load('/kaggle/working/Girls_ResNet_feature_product_ids.npy')\nmen_extracted_features = np.load('/kaggle/working/Men_ResNet_features.npy')\nmen_Productids = np.load('/kaggle/working/Men_ResNet_feature_product_ids.npy')\nwomen_extracted_features = np.load('/kaggle/working/Women_ResNet_features.npy')\nwomen_Productids = np.load('/kaggle/working/Women_ResNet_feature_product_ids.npy')\nfashion_df[\"ProductId\"] = fashion_df[\"ProductId\"].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_similar_products_cnn(product_id, num_results):\n    if(fashion_df[fashion_df['ProductId']==product_id]['Gender'].values[0]==\"Boys\"):\n        extracted_features = boys_extracted_features\n        Productids = boys_Productids\n    elif(fashion_df[fashion_df['ProductId']==product_id]['Gender'].values[0]==\"Girls\"):\n        extracted_features = girls_extracted_features\n        Productids = girls_Productids\n    elif(fashion_df[fashion_df['ProductId']==product_id]['Gender'].values[0]==\"Men\"):\n        extracted_features = men_extracted_features\n        Productids = men_Productids\n    elif(fashion_df[fashion_df['ProductId']==product_id]['Gender'].values[0]==\"Women\"):\n        extracted_features = women_extracted_features\n        Productids = women_Productids\n    Productids = list(Productids)\n    doc_id = Productids.index(product_id)\n    pairwise_dist = pairwise_distances(extracted_features, extracted_features[doc_id].reshape(1,-1))\n    indices = np.argsort(pairwise_dist.flatten())[0:num_results]\n    pdists  = np.sort(pairwise_dist.flatten())[0:num_results]\n    print(\"=\"*20, \"input product details\", \"=\"*20)\n    ip_row = fashion_df[['ImageURL','ProductTitle']].loc[fashion_df['ProductId']==Productids[indices[0]]]\n    for indx, row in ip_row.iterrows():\n        display(Image(url=row['ImageURL'], width = 224, height = 224,embed=True))\n        print('Product Title: ', row['ProductTitle'])\n    print(\"\\n\",\"=\"*20, \"Recommended products\", \"=\"*20)\n    for i in range(1,len(indices)):\n        rows = fashion_df[['ImageURL','ProductTitle']].loc[fashion_df['ProductId']==Productids[indices[i]]]\n        for indx, row in rows.iterrows():\n            display(Image(url=row['ImageURL'], width = 224, height = 224,embed=True))\n            print('Product Title: ', row['ProductTitle'])\n            print('Euclidean Distance from input image:', pdists[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_similar_products_cnn('21030', 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_similar_products_cnn('18181', 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_similar_products_cnn('37633', 5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Tip** - The solution can be deployed using ***streamlit***.\n\nThe complete deployment code can be downloaded from [here](https://drive.google.com/file/d/123XGxKvRY7sk2pnTmVOyLp9FH-iFL5oN/view)."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}