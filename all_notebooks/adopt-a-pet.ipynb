{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <u><center>Adopt a Pet</center></u>\n<center>Authored by: Pratham Tripathi</center>\n\n## <u>Aim:</u> \nTo predict which pet is accurate when prerequisites are given (like length,Breadth etc). \n\n## <u>Approach:</u>\nThe Approach was Supervised Machine Learning Classification model. Here, we used some basic algorithms like K- Nearest Neighbors, Decision Tree Classifier.\n### 1. <u>K-Nearest-Neighbors (KNN) :</u> \nThe k-nearest neighbors algorithm (k-NN) is a non-parametric method proposed by Thomas Cover used for classification and regression.[1] In both cases, the input consists of the k closest training examples in the feature space. The output depends on whether k-NN is used for classification or regression:\n\n- In kNN classification, the output is a class membership. An object is classified by a plurality vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). If k = 1, then the object is simply assigned to the class of that single nearest neighbor.\n- In kNN regression, the output is the property value for the object. This value is the average of the values of k nearest neighbors.\n\n### 2. <u>Decision Tree :</u> \nA decision tree is a flowchart-like structure in which each internal node represents a “test” on an attribute (e.g. whether a coin flip comes up heads or tails), each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Importing Required Libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import itertools\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import NullFormatter\nimport pylab as py\nimport matplotlib.ticker as ticker\nfrom sklearn import preprocessing\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pydotplus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import collections\nimport pydotplus\nimport matplotlib.image as mpimg","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading Data for Model and Prediction","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/hackerearth-ml-challenge-pet-adoption/train.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv(\"../input/hackerearth-ml-challenge-pet-adoption/test.csv\")\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cleaning The Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.dropna()\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['breed_category'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature and Target Sets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df[['length(m)', 'height(cm)',\"X1\",\"X2\"]]\nX[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df[\"pet_category\"]\ny[0:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pre-Processing Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Spliting Data for Testing and Training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3, random_state = 123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Training Set: \",X_train.shape,y_train.shape)\nprint(\"Testing Set: \",X_test.shape,y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# K-nearest Neighbor Algorithm","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nk = 9\nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\nneigh","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction and Evaluation of KNN Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_hat = neigh.predict(X_test)\ny_hat[0:5]\nnp.unique(y_hat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nprint(\"Accuracy Score is : \", metrics.accuracy_score(y_test,y_hat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ks = 10\nmean_acc = np.zeros((ks - 1))\nstd_acc = np.zeros((ks - 1))\nconfusion_matrix = []\n\nfor n in range(1,ks):\n    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n    yhat = neigh.predict(X_test)\n    mean_acc[n-1] = metrics.accuracy_score(y_test,yhat)\n    std_acc[n-1] = np.std(yhat == y_test)/np.sqrt(yhat.shape[0])\n    \nmean_acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(1,ks),mean_acc,'g')\nplt.fill_between(range(1,ks),mean_acc - 1*std_acc,mean_acc + 1*std_acc,alpha = 1)\nplt.legend([\"Accuracy\", \"+/- 3xstd\"])\nplt.tight_layout()\nprint(\"The best accuracy for the model is :\",mean_acc.max(),\"With k=\",mean_acc.argmax()+1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"PetTree = DecisionTreeClassifier(criterion =\"entropy\", max_depth = 5)\nPetTree.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction and Evaluation of Decision Tree","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"yhat1 = PetTree.predict(X_test) \nprint(yhat1[0:5])\nprint(y_test[0:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy Score is : \", metrics.accuracy_score(y_test,yhat1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction of test.csv\n\n<p>Since <u>Decision Tree</u> has a better Accuracy here than the KNN model, we are going to choose it as our main model for prediction.</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Xtest = test_data[['length(m)', 'height(cm)', 'X1', 'X2']]\nXtest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Main Prediction using Decision Tree","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = PetTree.predict(Xtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_feature_names = ['length(m)', 'height(cm)', 'X1', 'X2']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualization of The Decision Tree","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize data\ndot_data = tree.export_graphviz(PetTree,\n                                feature_names=data_feature_names,\n                                out_file=None,\n                                filled=True,\n                                rounded=True)\ngraph = pydotplus.graph_from_dot_data(dot_data)\n\ncolors = ('turquoise', 'orange')\nedges = collections.defaultdict(list)\n\nfor edge in graph.get_edge_list():\n    edges[edge.get_source()].append(int(edge.get_destination()))\n\nfor edge in edges:\n    edges[edge].sort()    \n    for i in range(2):\n        dest = graph.get_node(str(edges[edge][i]))[0]\n        dest.set_fillcolor(colors[i])\nfilename = \"tree.png\"\ngraph.write_png(filename)\nimg = mpimg.imread(filename)\nplt.figure(figsize=(100,200))\nplt.imshow(img,interpolation = 'nearest')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final Output in a csv file","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame({'PetId': test_data.pet_id, 'Pet Category': pred})\noutput.to_csv('Output.csv', index=False)\nprint(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}