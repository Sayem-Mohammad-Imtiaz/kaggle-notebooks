{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/mushroom-classification/mushrooms.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's now replace all the columns in our data with their respective dummies. The loop below will do that.(I have replaced all except the 'class' feature because it has only 2 values and it won't make any difference even if we dont replace it.)"},{"metadata":{"trusted":true},"cell_type":"code","source":"for cols in data.columns:\n    if cols != 'class':\n        temp = pd.get_dummies(data[cols],drop_first=True)\n        data.drop(cols,axis=1,inplace=True)\n        data = pd.concat([data,temp],axis=1)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Great! Now let's split our data for validation and use random forest classifier to predict our mushroom class."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = data.drop('class',axis=1)\ny = data['class']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(n_estimators=100)\nrfc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc_pred = rfc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,rfc_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_test,rfc_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nprint(accuracy_score(y_test,rfc_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"WHAT!!! 100% precision in our model! I honestly didn't think that just making dummies would make so much difference. I guess it could be just coincidence, but still it is 100%. Honestly I thought that I would just try to get a brief idea about the model after the first trial and then maybe move onto something more like PCA. But I guess I'll just stop here.(XD) Do let me know what you think about this in the comments and also leave an upvote.\n# Thanks!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}