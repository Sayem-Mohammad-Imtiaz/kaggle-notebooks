{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Part I: Departmental and Policy Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"Goal: Calculate correlation between numPolicies and numkillings and calculate correlation per policy with numkillings.\n\nStep 1: Read and clean data. This is using US census data from mappingpoliceviolence.com and policy data from Campaign Zero. The MPV data was already in a CSV, but the CZ dataset wasn't. This required converting it using Optical Character Recognition Software, and then formatting that into the same CSV file as the MPV data. After that, I put all the column names and row names into a dictionary to make queries easier."},{"metadata":{"trusted":false},"cell_type":"code","source":"import csv\nimport numpy as np\n\n#read CSV\nwith open('policydept.csv') as csvfile:\n    csvthing = csv.reader(csvfile, delimiter=',')\n    total=0\n    count=0\n    readCSV=[]\n    for row in csvthing:\n        readCSV.append(row)\n\n    #dictify row 1\n    querydict={}\n    labels=readCSV[0]\n    for el in labels:\n        name=el\n        querydict[name]=count\n        count=count+1\n    count=0\n\n    #dictify column 1\n    deptdict={}\n    for row in readCSV:\n        if row[0]!='City':\n            dept=row[0]\n            deptdict[dept]=count\n            count=count+1\n    count=0\n    \n    print(deptdict)\n    print(querydict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Correlation with Number of Policies"},{"metadata":{},"cell_type":"markdown","source":"Getting data from the CSV file about policies, police homicide rates, and disparities."},{"metadata":{"trusted":false},"cell_type":"code","source":"nps=[]\nrates=[]\nratebs=[]\ndisps=[]\nfor dept in deptdict.keys():\n    print('dept is', dept)\n    i=deptdict[dept]+1\n    j=querydict['numPolicies']\n    nP=int(readCSV[i][j])\n    nps.append(nP)\n    print('numPolicies is', nP)\n    j=querydict['killingsPerMillion']\n    rate=float(readCSV[i][j])\n    rates.append(rate)\n    rateb=float(readCSV[i][querydict['Avg Annual Police Homicide Rate for Black People']])\n    ratebs.append(rateb)\n    print('police homicide rate is', rate)\n    disp=float(readCSV[i][querydict['Black-White Disparity']])+float(readCSV[i][querydict['Hispanic-White Disparity']])\n    disps.append(disp)\n    print('racial disparity is ',disp)\n    print()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As shown below there isn't the greatest negative correlation between number of policies and rate of killings. This could be due to varied crime rates and implementation of policies. I decided it might be better to look at individual policies"},{"metadata":{"trusted":false},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.style as style\nstyle.use('fivethirtyeight')\n\nplt.scatter(nps,ratebs)\nprint(np.corrcoef(nps,ratebs)[0][1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at individual policies still didn't show the most correlation either. This made me realize that there was an even bigger problem."},{"metadata":{"trusted":false},"cell_type":"code","source":"for j in range(32,41):\n    policys=[]\n    print(readCSV[0][j])\n    for dept in deptdict.keys():\n        i=deptdict[dept]+1\n        nP=int(readCSV[i][j])\n        policys.append(nP)\n    plt.scatter(policys,ratebs)\n    print('correlation:',np.corrcoef(policys,ratebs)[0][1])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I then restricted to similar cities to avoid noise due to differing factors. I thought it would be ideal to compare a city to itself before the policy but I didn't have that data so I had to use similar cities. As shown below, this effectively revealed that policies really did correlate to lower rates of police homicide."},{"metadata":{"trusted":false},"cell_type":"code","source":"def lookAtCities(bigcities,s):\n    ratesrestricted=[]\n    for dept in bigcities:\n        i=deptdict[dept]+1\n        query='Avg Annual Police Homicide Rate'+s\n        j=querydict[query]\n        rate=float(readCSV[i][j])\n        ratesrestricted.append(rate)\n    for j in range(32,40):\n        policys=[]\n        print(readCSV[0][j])\n        for dept in bigcities:\n            i=deptdict[dept]+1\n            nP=int(readCSV[i][j])\n            policys.append(nP)\n        print('correlation:',np.corrcoef(policys,ratesrestricted)[0][1])\n\n#comparing similar cities yield higher negative correlation for most policies\nprint('Looking at rate of black homicides')\nlookAtCities(['Los Angeles','San Francisco','Philadelphia','Orlando'],' for Black People')\nlookAtCities(['New Orleans','Baton Rouge','Orlando'],' for Black People')\nprint()\nprint('Looking at rate of white homicides')\nlookAtCities(['Los Angeles','San Francisco','Philadelphia','Orlando'],'')\nlookAtCities(['New Orleans','Baton Rouge','Orlando'],'')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, I thought that maybe bucketing homicide rates based on number of policies might reveal some larger trend since I saw a graphic indicating so published by Campaign Zero, who provided the policies dataset. After doing this I realized they slightly painted the picture brighter than it was by drawing the below graph in a distorted way. It probably would have been better for them to compare similar cities to get the trend they were looking for."},{"metadata":{"trusted":false},"cell_type":"code","source":"import numpy as np\nlabels=['0 to 1','2','3','4+']\nlabelsn=[0,1,2,3]\nlowest=0\nok=0\nbetter=0\nbest=0\nfor row in readCSV:\n    if row[0]!='City':\n        nP=int(row[40])\n        k=float(row[42])\n        if nP<2:\n            lowest=lowest+k\n        elif nP==2:\n            ok=ok+k\n        elif nP==3:\n            better=better+k\n        elif nP>4:\n            best=best+k\nkillings=[lowest,ok,better,best]\nplt.plot(labels,killings)\nprint('correlation:',np.corrcoef(labelsn,killings)[0][1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part II: State Specific Data Analysis"},{"metadata":{"trusted":false},"cell_type":"code","source":"import csv\n#can use rate of death estimates to estimate p-values?\n\n#read csv\nwith open('states.csv') as csvfile:\n    csvthing = csv.reader(csvfile, delimiter=',')\n    total=0\n    count=0\n    readCSV=[]\n    for row in csvthing:\n        readCSV.append(row)\n\n    #dictify row 1\n    querydict={}\n    labels=readCSV[0]\n    for el in labels:\n        name=el\n        querydict[name]=count\n        count=count+1\n    count=0\n\n    #dictify column 1\n    statedict={}\n    for row in readCSV:\n        if row[0]!='State':\n            state=row[0]\n            statedict[state]=count\n            count=count+1\n    count=0\n    \n    print(statedict)\n    print(querydict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ex.1 Alabama"},{"metadata":{},"cell_type":"markdown","source":"We can look at the state of Alabama as an example before algorithmically analyzing all of the states. I used bayesian probability to derive how to calculate the rate of police homicide given race in a given state. The derivation of this (and thus all following formulas) is shown on my github using Bayes theoerem. Then using this probability and assuming a Poisson distribution(a probability distribution where something happens at a rate) I calculated the rate of homicide. This revealed significant racial disparities. Also if these numbers sound very large, it's important to remember these homicides include armed victims."},{"metadata":{"trusted":false},"cell_type":"code","source":"pb1=float(readCSV[statedict['Alabama']+1][6])/float(readCSV[statedict['Alabama']+1][2].replace(',',''))\nprint('the probability that someone is killed by an officer given theyre black is',pb1)\n#calculating lambda=p*n\nprint('the rate of killing per 100k is thus',(pb1*100000))\nrate1=pb1*100000\n\nwhitepop=float(readCSV[statedict['Alabama']+1][17])*int(readCSV[statedict['Alabama']+1][1].replace(',', ''))\npb2=float(readCSV[statedict['Alabama']+1][11])/(whitepop)\nprint('the probability that someone is killed by an officer given theyre white is',pb2)\n#calculating lambda=p*n\nprint('the rate of killing per 100k is thus',pb2*100000)\nrate2=pb2*100000\n\npb3=(float(readCSV[statedict['Alabama']+1][6])+float(readCSV[statedict['Alabama']+1][7])\n    +float(readCSV[statedict['Alabama']+1][8])+float(readCSV[statedict['Alabama']+1][9])\n    +float(readCSV[statedict['Alabama']+1][10]))/(int(readCSV[statedict['Alabama']+1][1].replace(',', ''))-whitepop)\nprint('the probability that someone is killed by an officer given theyre not white is',pb3)\n#calculating lambda=p*n\nprint('the rate of killing per 100k is thus',pb3*100000)\nrate3=pb3*100000\n\nbwdisparity =rate1-rate2\nprint('the black-white disparity is ',bwdisparity)\n\ndisparity=rate3-rate2\nprint('the disparity is ',disparity)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ex.2 Iterating Through States"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"disparities=[]\nfor state in statedict.keys():\n    print(\"\")\n    pb1=float(readCSV[statedict[state]+1][6])/float(readCSV[statedict[state]+1][2].replace(',', ''))\n    print('the probability that someone is killed by an officer in',state,'given theyre black is',pb1)\n    rate1=pb1*100000\n    print('the rate of killing per 100k is thus',rate1)\n    \n    whitepop=float(readCSV[statedict[state]+1][17])*int(readCSV[statedict[state]+1][1].replace(',', ''))\n    pb2=float(readCSV[statedict[state]+1][11])/(whitepop)\n    print('the probability that someone is killed by an officer',state,'given theyre white is',pb2)\n    rate2=pb2*100000\n    print('the rate of killing per 100k is thus',rate2)\n    \n    pb3=(float(readCSV[statedict[state]+1][6])+float(readCSV[statedict[state]+1][7])\n    +float(readCSV[statedict[state]+1][8])+float(readCSV[statedict[state]+1][9])\n    +float(readCSV[statedict[state]+1][10]))/(int(readCSV[statedict[state]+1][1].replace(',', ''))-whitepop)\n    print('the probability that someone is killed by an officer given theyre not white is',pb3)\n    print('the rate of killing per 100k is thus',pb3*100000)\n    rate3=pb3*100000\n    \n    bwdisparity =rate1-rate2\n    print('the black-white disparity is ',bwdisparity)\n    disparity=rate3-rate2\n    disparities.append(disparity)\n    print('the disparity is ',disparity)\n    print(\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"avg=np.sum(disparities)/len(disparities)\nprint('national disparity is',avg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part III: Aggregate Data and Joint Sampling"},{"metadata":{"trusted":false},"cell_type":"code","source":"with open('aggregate.csv') as csvfile:\n    csvthing = csv.reader(csvfile, delimiter=',')\n    total=0\n    count=0\n    readCSV=[]\n    for row in csvthing:\n        readCSV.append(row)\n        \n#dictify row 1\n    querydict={}\n    labels=readCSV[0]\n    for el in labels:\n        name=el\n        querydict[name]=count\n        count=count+1\n    count=0\n\n    print(querydict)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"n=1000000\nwcount=0\nfor row in readCSV:\n        if row[3]=='White' or row[3]=='white':\n            wcount=wcount+1\n            \nbcount=0\nfor row in readCSV:\n        if row[3]=='Black' or row[3]=='black':\n            bcount=bcount+1\n\nncount=0\nfor row in readCSV:\n        if row[3]=='Unknown Race' or row[3]=='?':\n            ncount=ncount+1\ntcount=len(readCSV)-1\n\n#prob of police homicide\nprobPoliceHomicide= tcount/327000000 #P(H)\nratePoliceHomicide=n*probPoliceHomicide \n\n#prob of police homicide involving someone white\nprobWHomicide= wcount/327000000 #P(W,H)\nrateWHomicide=n*probWHomicide\nprobHomicidegW=probWHomicide/(0.607) #P(H|W)\nrateHomicidegW=n*probHomicidegW\n\n#prob of shooting someone black\nprobBHomicide= bcount/327000000 #P(B,H)\nrateBHomicide=n*probBHomicide\nprobHomicidegB=probBHomicide/(0.14) #P(B|H)\nrateHomicidegB=n*probHomicidegB\n\nprint(rateHomicidegW,'police homicides of white people per million in America')\nprint(rateHomicidegB,'police homicides of black people per million in America')\n\n\n#prob of police homicide involving someone black and unarmed\nucount=0\nfor row in readCSV:\n    if row[18]=='Unarmed' or row[18]=='unarmed':\n        ucount=ucount+1\nprobUH=ucount/327000000\n\nprobHgU=probUH/probPoliceHomicide\n\nucount=0\nfor row in readCSV:\n    if (row[18]=='Unarmed' or row[18]=='unarmed') and (row[3]=='Black' or row[3]=='black'):\n        ucount=ucount+1\nprobBUH=ucount/327000000\n\nprobBgUH=probBUH/probHgU\n\nucount=0\nfor row in readCSV:\n    if row[18]=='Armed' or row[18]=='Allegedly Armed':\n        ucount=ucount+1\nprobAH=ucount/327000000\n\nucount=0\nfor row in readCSV:\n    if (row[18]=='Armed' or row[18]=='Allegedly Armed') and (row[3]=='Black' or row[3]=='black'):\n        ucount=ucount+1\nprobBAH=ucount/327000000\n\nprobHgA=probAH/probPoliceHomicide\nprobBgAH=probBAH/probHgA\n\nprobB=.14\nprobU=.99 # approximated, 3 million Americans carry guns daily, more probably carry occasionally/illegally\n#this data obviously doesn't exist, so i had to make a generous guess\n\nprobBgU=probB*probU\n\nprobHgBU=(probBgUH*probHgU)/probBgU\nprint('probability of a police homicide, given a black unarmed victim is',probHgBU)\nprint(probHgBU*1000000,'homicides per million')\n\n\n#prob of police homicide involving someone white and unarmed\nucount=0\nfor row in readCSV:\n    if (row[18]=='Unarmed' or row[18]=='unarmed') and (row[3]=='White' or row[3]=='white'):\n        ucount=ucount+1\nprobWUH=ucount/327000000\n\nprobWgUH=probWUH/probHgU\n\nucount=0\nfor row in readCSV:\n    if (row[18]=='Armed' or row[18]=='Allegedly Armed') and (row[3]=='White' or row[3]=='white'):\n        ucount=ucount+1\nprobWAH=ucount/327000000\n\nprobWgAH=probWAH/probHgA\n\nprobW=.613\n\nprobWgU=probW*probU\n\nprobHgWU=(probWgUH*probHgU)/probWgU\nprint('probability of a police homicide, given a white unarmed victim is',probHgWU)\nprint(probHgWU*1000000,'homicides per million')\n\nprint('the disparity is now even larger as the rate of murder is around 4 times larger for unarmed black people')\n\nprobHgB=probHomicidegB #rewriting variable names for clarity later on\nprobHgW=probHomicidegW\nprobHgBA=probHgB-probHgBU # since probHgB=probHgBU+probHgBA (armed and unarmed are mutually exclusive+exhaustive)\nprobHgWA=probHgW-probHgWU # above\n\ndef probHomicide(b,w,u):\n    if u==1:\n        if b==1:\n            return probHgBU\n        elif w==1:\n            return probHgWU\n        else:\n            return probHgU\n    else:\n        if b==1:\n            return probHgBA\n        elif w==1:\n            return probHgWA\n        else:\n            return probHgA","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can visualize these distributions to show how large the disparity is (black is red, white is blue):"},{"metadata":{"trusted":false},"cell_type":"code","source":"from scipy.stats import poisson\n\nw=poisson(3.27)\nb=poisson(15)\narr=[]\nfor num in range(-5,35):\n    arr.append(w.pmf(num))\nprob1 = w.pmf(5)\nplt.grid(True)\nplt.ylabel('Probability ')\nplt.xlabel('# of Annual Homicides of Unarmed People')\nplt.title('Probability Distribution Curve')\nplt.plot(arr, linewidth=2.0)\n\narr2=[]\nfor num in range(-5,35):\n    arr2.append(b.pmf(num))\nprob2 = b.pmf(12)\nplt.grid(True)\nplt.plot(arr2, linewidth=2.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#calculating multivariable probabilities\ncounter=0\nfor row in readCSV:\n    if (\"Charged\" in str(row[14])) or (\"indicted\" in str(row[14])) or (\"Murder\" in str(row[14])) or (\"Criminal\" in str(row[14])) or (\"Convicted\" in str(row[14])):\n        counter=counter+1\npCH=counter/327000000\nprobCgH=pCH/probPoliceHomicide\nprint(probCgH, 'is the probability that an officer is charged with homicide given a police homicide')\n\n#assumes homicide occurs, since makeSample only runs this if homicide=1\nfor row in readCSV:\n    c=(\"Charged\" in str(row[14])) or (\"indicted\" in str(row[14])) or (\"Murder\" in str(row[14])) or (\"Criminal\" in str(row[14])) or (\"Convicted\" in str(row[14]))\n    if c and (row[3]=='Black' or row[3]=='black') and (row[18]=='Unarmed' or row[18]=='unarmed'):\n        counter=counter+1\nprobCBUH=counter/327000000\n\nfor row in readCSV:\n    c=(\"Charged\" in str(row[14])) or (\"indicted\" in str(row[14])) or (\"Murder\" in str(row[14])) or (\"Criminal\" in str(row[14])) or (\"Convicted\" in str(row[14]))\n    if c and (row[3]=='White' or row[3]=='white') and (row[18]=='Unarmed' or row[18]=='unarmed'):\n        counter=counter+1\nprobCWUH=counter/327000000\n\nfor row in readCSV:\n    c=(\"Charged\" in str(row[14])) or (\"indicted\" in str(row[14])) or (\"Murder\" in str(row[14])) or (\"Criminal\" in str(row[14])) or (\"Convicted\" in str(row[14]))\n    if c and (row[18]=='Unarmed' or row[18]=='unarmed'):\n        counter=counter+1\nprobCUH=counter/327000000\n\nfor row in readCSV:\n    c=(\"Charged\" in str(row[14])) or (\"indicted\" in str(row[14])) or (\"Murder\" in str(row[14])) or (\"Criminal\" in str(row[14])) or (\"Convicted\" in str(row[14]))\n    if c and (row[3]=='Black' or row[3]=='black') and (row[18]=='Allegedly Armed' or row[18]=='Armed'):\n        counter=counter+1\nprobCBAH=counter/327000000\n\nfor row in readCSV:\n    c=(\"Charged\" in str(row[14])) or (\"indicted\" in str(row[14])) or (\"Murder\" in str(row[14])) or (\"Criminal\" in str(row[14])) or (\"Convicted\" in str(row[14]))\n    if c and (row[3]=='White' or row[3]=='white') and (row[18]=='Allegedly Armed' or row[18]=='Armed'):\n        counter=counter+1\nprobCWAH=counter/327000000\n\nfor row in readCSV:\n    c=(\"Charged\" in str(row[14])) or (\"indicted\" in str(row[14])) or (\"Murder\" in str(row[14])) or (\"Criminal\" in str(row[14])) or (\"Convicted\" in str(row[14]))\n    if c and (row[18]=='Allegedly Armed' or row[18]=='Armed'):\n        counter=counter+1\nprobCAH=counter/327000000\n\n#using bayes rule, g means given\nprobCgBUH=probCBUH/(probBUH)\nprobCgWUH=probCWUH/(probWUH)\nprobCgUH=probCUH/probUH\n\n#using bayes rule, g means given\nprobCgBAH=probCBAH/(probBAH)\nprobCgWAH=probCWAH/(probWAH)\nprobCgAH=probCAH/probAH\n\n#again assumes homicide occurs, since makeSample only runs this if homicide=1\ndef probCharges(black,white,unarmed):\n    counter=0\n    if unarmed==1:\n        #P(C|B=1,W=0,U=1,H)=P(C,B=1,W=0,U=1)/P(B=1,W=0,U=1,H)\n        if black==1:\n            return probCgBUH\n        #P(C,B=0,W=1,U=1,H)/P(B=0,W=1,U=1,H)\n        elif white==1:\n            return probCgWUH\n        #P(C,B=0,W=0,U=1,H)/P(B=0,W=0,U=1,H)\n        else:\n            return probCgUH\n    else:\n        #P(C,B=1,W=0,U=0,H)/P(B=1,W=0,U=0,H)\n        if black==1:\n            return probCgBAH\n        #P(C,B=0,W=1,U=0,H)/P(B=0,W=1,U=0,H)\n        elif white==1:\n            return probCgWAH\n        #P(C,B=0,W=0,U=0,H)/P(B=0,W=0,U=0,H)\n        else:\n            return probCgAH","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(probCgBUH, 'is the probability of an officer being charged given they shot someone black and unarmed')\nprint(probCgWUH, 'is the probability of an officer being charged given they shot someone white and unarmed')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#prob conviction\ncounter=0\nfor row in readCSV:\n    if (\"Murder\" in str(row[14])) or (\"Criminal\" in str(row[14])) or (\"Convicted\" in str(row[14])):\n        counter=counter+1\npVH=counter/327000000\nprobVgH=pVH/probPoliceHomicide\nprint(probVgH, 'is the probability that an officer is convicted of homicide given a homicide')\n\n#assumes homicide occurs, since makeSample only runs this if homicide=1\nfor row in readCSV:\n    c=(\"Murder\" in str(row[14])) or (\"Criminal\" in str(row[14])) or (\"Convicted\" in str(row[14]))\n    if c and (row[3]=='Black' or row[3]=='black') and (row[18]=='Unarmed' or row[18]=='unarmed'):\n        counter=counter+1\nprobVCBUH=counter/327000000\n\nfor row in readCSV:\n    c=(\"Murder\" in str(row[14])) or (\"Criminal\" in str(row[14])) or (\"Convicted\" in str(row[14]))\n    if c and (row[3]=='White' or row[3]=='white') and (row[18]=='Unarmed' or row[18]=='unarmed'):\n        counter=counter+1\nprobVCWUH=counter/327000000\n\nfor row in readCSV:\n    c=(\"Murder\" in str(row[14])) or (\"Criminal\" in str(row[14])) or (\"Convicted\" in str(row[14]))\n    if c and (row[18]=='Unarmed' or row[18]=='unarmed'):\n        counter=counter+1\nprobVCUH=counter/327000000\n\nfor row in readCSV:\n    c=(\"Murder\" in str(row[14])) or (\"Criminal\" in str(row[14])) or (\"Convicted\" in str(row[14]))\n    if c and (row[3]=='Black' or row[3]=='black') and (row[18]=='Allegedly Armed' or row[18]=='Armed'):\n        counter=counter+1\nprobVCBAH=counter/327000000\n\nfor row in readCSV:\n    c=(\"Murder\" in str(row[14])) or (\"Criminal\" in str(row[14])) or (\"Convicted\" in str(row[14]))\n    if c and (row[3]=='White' or row[3]=='white') and (row[18]=='Allegedly Armed' or row[18]=='Armed'):\n        counter=counter+1\nprobVCWAH=counter/327000000\n\nfor row in readCSV:\n    c=(\"Murder\" in str(row[14])) or (\"Criminal\" in str(row[14])) or (\"Convicted\" in str(row[14]))\n    if c and (row[18]=='Allegedly Armed' or row[18]=='Armed'):\n        counter=counter+1\nprobVCAH=counter/327000000\n\n#using bayes rule, g means given\nprobVgCBUH=probVCBUH/(probCBUH)\nprobVgCWUH=probVCWUH/(probCWUH)\nprobVgCUH=probVCUH/probUH\n\n#using bayes rule, g means given\nprobVgCBAH=probVCBAH/(probCBAH)\nprobVgCWAH=probVCWAH/(probCWAH)\nprobVgCAH=probVCAH/probCAH\n\n#again assumes homicide occurs, since makeSample only runs this if homicide=1\ndef probConviction(black,white,unarmed):\n    counter=0\n    if unarmed==1:\n        #P(C|B=1,W=0,U=1,H)=P(C,B=1,W=0,U=1,H)/P(B=1,W=0,U=1,H)\n        if black==1:\n            return probVgCBUH\n        #P(C|B=0,W=1,U=1,H)=P(C,B=0,W=1,U=1,H)/P(B=0,W=1,U=1,H)\n        elif white==1:\n            return probVgCWUH\n        #P(C|U=1,H)=P(C,U=1,H)/P(U=1,H)\n        else:\n            return probVgCUH\n    else:\n        #P(C,B=1,W=0,U=0,H)/P(B=1,W=0,U=0,H)\n        if black==1:\n            return probVgCBAH\n        #P(C,B=0,W=1,U=0,H)/P(B=0,W=1,U=0,H)\n        elif white==1:\n            return probVgCWAH\n        #P(C,U=0,H)/P(U=0,H)\n        else:\n            return probVgCAH","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(probVgCBUH, 'is the probability of an officer being convicted given they are charged for shooting someone black and unarmed')\nprint(probVgCWUH, 'is the probability of an officer being convicted given they are charged for shooting someone white and unarmed')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It becomes very difficult to model with different parameters after the addition of the charges event, so we need some way to model this Bayesian network of events. Joint sampling works well."},{"metadata":{"trusted":false},"cell_type":"code","source":"import random\n\n# joint sampling \ndef bern(p):\n    event = random.random() < p\n    if event: return 1\n    else: return 0\n    \ndef makeSample():\n    observation=[]\n    unarmed = bern(0.99)\n    white=bern(.613)\n    if white!=1:\n        black = bern(0.14/(1-0.613)) #P(B|not-white)=P(B,non-white)/P(non-white)=P(B)/P(non-white)\n    else:\n        black=0\n    homicide=bern(probHomicide(black,white,unarmed))\n    if homicide==1:\n        charges=bern(probCharges(black,white,unarmed))\n    else:\n        charges=0\n    if charges==1:\n        conviction=probConviction(black,white,unarmed)\n    else:\n        conviction=0\n    observation = [unarmed,black,white,homicide,charges,conviction]\n    return observation\n    \ndef makeSamples(n):\n    samples=[]\n    for i in range(n):\n        samples.append(makeSample())\n    return samples        \n\nsamples=makeSamples(32700000) #1/10 of the US population","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def probSample(a,an): #P(a=an)\n    counter=0\n    for s in samples:\n        if (s[a]==an):\n            counter=counter+1\n    count = counter\n    total=len(samples)\n    return count/total\n\ndef probSample1(a,b,an,bn): #P(a=an|b=bn)\n    keptsamples = []\n    for s in samples:\n        if (s[b]==bn):\n            keptsamples.append(s)\n    total = len(keptsamples)\n    count=0\n    for s in keptsamples:\n        if s[a]==an:\n            count=count+1\n    return count/total\n\ndef probSample2(a,b,c,an,bn,cn): #P(a=an|b=bn,c=cn)\n    keptsamples = []\n    for s in samples:\n        if (s[b]==bn and s[c]==cn):\n            keptsamples.append(s)\n    total = len(keptsamples)\n    count=0\n    for s in keptsamples:\n        if s[a]==an:\n            count=count+1\n    return count/total\n\ndef probSample3(a,b,c,d,an,bn,cn,dn): #P(a|b,c,d)\n    keptsamples = []\n    for s in samples:\n        if (s[b]==bn and s[c]==cn and s[d]==dn):\n            keptsamples.append(s)\n    total = len(keptsamples)\n    count=0\n    for s in keptsamples:\n        if s[a]==an:\n            count=count+1\n    return count/total","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Initially running this below cell gave only a 5% white population because i didn't realize that there should be arrows between black and white in my Bayesian network (since these random variables obviously affect each other). After fixing that, I adjusted my makeSamples() method using Bayes theorem as shown above and then the proportions started to make sense with actual US census data."},{"metadata":{"trusted":false},"cell_type":"code","source":"print('portion of sample that is black',probSample(1,1))\nprint('portion of sample that is white',probSample(2,1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The joint sampled model mimics the close, but regardless disparate, rates of officers getting charged when they shoot unarmed people. The fact that there are 0 convictions is unfamiliar though. However, probably due to the smaller sample size than the actual population of the US and the ridiculously small amount of officers that get convicted, with a sample with a size of 1/10th the US' population, it makes sense that no one gets convicted. Doing the math out, I realized that this made sense so there was no issue with my algorithm."},{"metadata":{"trusted":false},"cell_type":"code","source":"print('probability of charges given police homicide of an unarmed black person is ',probSample3(4,1,3,0,1,1,1,1))\nprint('probability of charges given police homicide of an unarmed white person is ',probSample3(4,2,3,0,1,1,1,1))\nprint('probability of conviction',probSample(5,1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The joint sampled model also shows a 4x disparity between white and black people so it succeeds in approximating disparities in the US."},{"metadata":{"trusted":false},"cell_type":"code","source":"p1=probSample2(3,1,0,1,1,1)\np2=probSample2(3,2,0,1,1,1)\nprint('probability of a police homicide of an unarmed black person is ',p1)\nprint('thus the rate per million is', p1*1000000)\nprint('probability of a police homicide of an unarmed white person is ',p2)\nprint('thus the rate per million is', p2*1000000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# FUTURE WORK"},{"metadata":{},"cell_type":"markdown","source":"# P-values?"},{"metadata":{"trusted":false},"cell_type":"code","source":"# we can now calcualte p-values for a national disparity?\n# that would require two generated samples of b/w populations\n# and drawing out \nimport random\ndef pvalue(universalSample,hopes):\n    s=universalSample\n    n=wcount\n    m=tcount-wcount\n    count=0\n    for i in range(10000):\n        r1=random.choices(s,k=n)\n        sum1=0\n        for i in r1:\n            sum1=sum1+int(i)\n        r2=random.choices(s,k=m)\n        sum2=0\n        for i in r2:\n            sum2=sum2+int(i)\n        rate1=sum1/float(n)\n        rate2=sum2/float(m)\n        ratediff=abs(rate1-rate2)\n        if ratediff>hopes:\n            count=count+1\n    return count/10000\n\nprint(pvalue(np.ones(tcount),13.214192025732315))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating a GUI for a Probability Calculator"},{"metadata":{"trusted":true},"cell_type":"code","source":"import PySimpleGUI as sg\n\nlayout = [ [sg.Txt('Enter values to calculate')],      \n           [sg.In(size=(8,1), key='numerator')],      \n           [sg.Txt('_'  * 10)],      \n           [sg.In(size=(8,1), key='denominator')],      \n           [sg.Txt('', size=(8,1), key='output')  ],      \n           [sg.Button('Calculate', bind_return_key=True)]]\n\nwindow = sg.Window('Math', layout)\n\nwhile True:      \n    event, values = window.Read()\n\n    if event is not None:      \n        try:      \n            numerator = float(values['numerator'])      \n            denominator = float(values['denominator'])      \n            calc = numerator / denominator      \n        except:      \n            calc = 'Invalid'\n\n        window.Element('output').Update(calc)      \n    else:      \n        break","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}