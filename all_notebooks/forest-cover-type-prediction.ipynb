{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# Task for Today\n***\n Predict the type of forest cover based on ecological data (Human influences are excluded within the features as much as possible)\n Treat the imbalance between output classes and fit it to Logistic Regression Model."},{"metadata":{},"cell_type":"markdown","source":"## Set Up"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install seaborn --upgrade\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/forest-cover-type-dataset/covtype.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Indexing the Class Labels from 0 rather than 1\ndata.Cover_Type = data.Cover_Type - 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Cover_Type.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize the Imbalanced Data: Class Distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap = sns.color_palette('Set2', as_cmap=True)(data.Cover_Type.unique()) # get color map from sns and initialize 7 values from it\n\nplt.figure(figsize=(8,8))\nplt.pie(\n    data.Cover_Type.value_counts().values,\n    colors=cmap,\n    labels=data.Cover_Type.value_counts().keys(),\n    autopct='%.2f%%',\n)\nplt.title(\"Forest Cover Type Distribution\")\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Some Helper Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_and_scale(df):\n    df= df.copy()\n    \n    # Split df in X and y\n    y = df.Cover_Type.copy()\n    X = df.drop('Cover_Type', axis=1).copy()\n    \n    # Train Test Split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=123)\n    \n    # Scale X \n    sc = StandardScaler()\n    sc.fit(X_train)\n    \n    # Transform fcn returns numpy array -> Turn back into dataframe\n    X_train = pd.DataFrame(sc.transform(X_train), columns=X_train.columns)\n    X_test = pd.DataFrame(sc.transform(X_test), columns=X_test.columns)\n    \n    return X_train, X_test, y_train, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate_model(model, class_balance, X_test, y_test):\n    model_acc = model.score(X_test, y_test)\n    print(\"Accuracy ({}): {:.2f}%\".format(class_balance, model_acc*100))\n    \n    y_pred = model.predict(X_test)\n    \n    cm = confusion_matrix(y_test, y_pred)\n    clr = classification_report(y_test, y_pred)\n    \n    plt.figure(figsize=(8,8))\n    sns.heatmap(cm, annot=True, fmt='g', vmin=0, cbar=False, cmap='Blues')\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.title('Confusion Matrix Heatmap')\n    plt.show()\n    \n    print('Classification Report: \\n ------------------------------- \\n', clr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training with Imbalanced Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"imbalanced_data = data.copy()\n\nX_train, X_test, y_train, y_test = split_and_scale(imbalanced_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = LogisticRegression()\nmodel1.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate_model(model1, 'Imbalaced Data', X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training with UnderSampled Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"undersampled_data = data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"undersampled_data.Cover_Type.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min_class_size = min(undersampled_data.Cover_Type.value_counts().values)\nprint(\"Size of smallest class: \", min_class_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Undersample all the majority classes\nclass_subsets = [undersampled_data.query('Cover_Type == ' + str(i)) for i in range(7)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# All Classes will be downsized using below\nfor i in range(7):\n    class_subsets[i] = class_subsets[i].sample(min_class_size, random_state=123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combine all Subsets (row-wise), Shuffle the data using sample fcn, Reset the index and drop the old index\nundersampled_data = pd.concat(class_subsets, axis=0).sample(frac=1.0, random_state=123).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"undersampled_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"undersampled_data.Cover_Type.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = split_and_scale(undersampled_data)\n\nmodel2 = LogisticRegression()\nmodel2.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate_model(model2, 'Undersampled', X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ## Training with OverSampled Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"oversampled_data = data.copy()\n\nmax_class_size = max(oversampled_data.Cover_Type.value_counts().values)\nmax_class_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make all subsets of Classes match the oversampled size\nclass_subsets_ov = [oversampled_data.query('Cover_Type == ' + str(i)) for i in range(7)]\n\nfor i in range(7):\n    class_subsets_ov[i] = class_subsets_ov[i].sample(max_class_size, replace=True, random_state=123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"oversampled_data = pd.concat(class_subsets_ov, axis = 0).sample(frac=1).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oversampled_data.Cover_Type.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = split_and_scale(oversampled_data)\n\nmodel3 = LogisticRegression()\nmodel3.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate_model(model3, \"Oversampled\", X_test, y_test)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}