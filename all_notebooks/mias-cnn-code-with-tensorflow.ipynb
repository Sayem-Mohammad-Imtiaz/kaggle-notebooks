{"cells":[{"metadata":{"_cell_guid":"57bf31bc-10bf-4237-819a-c9af271f141e","_kg_hide-output":true,"_uuid":"f2437f2e8b7c2e9d0707de220c34865d8856876e","scrolled":false,"trusted":true},"cell_type":"code","source":"!tar -xzf ../input/mias-mammography/all-mias.tar.gz","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"17255e58-0449-430c-b174-973235e117ae","_uuid":"5e71d826ed9b1a814d18e864d4adc5192f41a8a7","trusted":true},"cell_type":"code","source":"!mkdir images","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"40e1cb18-f123-46dd-915c-ffc65d6549d1","_uuid":"a0334a952b29beb62aafd60f12724dd2f43eaf58","collapsed":true,"trusted":true},"cell_type":"code","source":"!mv ./*.pgm ./images/","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"35ed1884-a9d8-4a8f-8d07-e5ccee300ed7","_uuid":"3ab554e7190b1442795003aff7746229ddd7a541","trusted":true},"cell_type":"code","source":"!ls ./images/","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"5e2c9ff2-34d6-47a6-b9bb-a8862c42f536","_uuid":"4612d2ea3127049bb54b42d97860c88e7ed8e1ac","trusted":true},"cell_type":"code","source":"\nfrom __future__ import print_function\nimport numpy as np\nimport os , re\nimport sys\nimport sys\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom tensorflow.examples.tutorials.mnist import input_data\n#print(mnist.test.images.size())\n\ndef read_pgm(filename, byteorder='>'):\n  with open(filename, 'rb') as f:\n    buffer = f.read()\n  try:\n    header, width, height, maxval = re.search(\n  b\"(^P5\\s(?:\\s*#.*[\\r\\n])*\"\n  b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n  b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n  b\"(\\d+)\\s(?:\\s*#.*[\\r\\n]\\s)*)\", buffer).groups()\n  except AttributeError:\n    raise ValueError(\"Not a raw PGM file: '%s'\" % filename)\n  return np.frombuffer(buffer,\n         dtype='u1' if int(maxval) < 256 else byteorder+'u2',\n         count=int(width)*int(height),\n         offset=len(header)\n        ).reshape((int(height)*int(width)))\n\ndef import_images(image_dir, num_images):\n  images_tensor = np.zeros((num_images, 1024*1024))\n  i = 0\n  for dirName, subdirList, fileList in os.walk(image_dir):\n    for fname in fileList:\n      if fname.endswith(\".pgm\"):\n        images_tensor[i] = read_pgm(image_dir+fname, byteorder='<')\n        i += 1\n\n  # Create a tensor for the labels\n  labels_tensor = np.zeros(num_images,dtype=np.int32)\n  f = open(\"../input/onelabels/1.txt\", 'r')\n  i=0;\n\n  for line in f:\n    image_num = i\n    labels_tensor[image_num] = int(line[0]) - 1\n    i+=1;\n    #print(\"image \"+str(i)+ \" saved \");\n\n  out = np.zeros((num_images, 7))\n  out[np.arange(num_images), labels_tensor] = 1\n  return images_tensor, out\n\n\nimages , labels = import_images(\"./images/\" ,322)\nbb=images[0]\nb=np.reshape(bb, (1024, 1024))\nplt.imshow(b, interpolation='nearest')\nplt.show()\nsys.exit()\n\n","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"2365b97a-cf64-416c-b814-04e2d2735f73","_uuid":"f42e6b96ef6121890693265e8df0fc86006c3a21","collapsed":true,"trusted":true},"cell_type":"code","source":"!mkdir ./new","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"bcc7de6d-533c-47a9-b9ee-2afc689a8115","_uuid":"630285eb825853d3b7d90d0d9f878133661dd95e","trusted":true},"cell_type":"code","source":"!pip install Pillow","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"b53b9f6f-4ba5-4536-b580-7c235d06f790","_uuid":"51802836ddbbb5305b34208cd6e148c889a92dd8","collapsed":true,"trusted":true},"cell_type":"code","source":"from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport sys\nfrom PIL import Image\nimport numpy as np\nimport re\nimport numpy\nimport os\nfrom random import randint\n\nf = open(\"../input/rtc-data/rtc.txt\", 'r')\nmax_right=0;\nmin_right=1025\nmax_top=0;\nmin_top=1025;\nmax_radius=0;\nradius=125;\ni = 0\nbad = [30 , 72 , 91 , 99 , 104 , 110 , 126 , 130 , 186 , 211 , 236 , 271 , 267 , 270 , 290 , 312]\nfor line in f:\n  # The first value in the line is the database ID\n  # some values are duplicated so we have to use this as the key\n  image_num = int(line.split()[0].replace(\"mdb\", \"\").replace(\".pgm\", \"\"))\n  if image_num in bad :\n    continue\n  image_name = line.split()[0] \n  a =    int(line.split()[1])\n  b=    int(line.split()[2])\n  c= 125\n  \n\n\n\n  im = Image.open(\"./images/\"+image_name)\n  \n  #print(im.size)\n  left = a-c\n  top =1024-b-c\n  Right = a+c\n  bottom = 1024-b+c\n  #print(image_name,left,Right,top,bottom)\n  image=im.crop((left, top, Right, bottom))\n  ninety=image.rotate(90)\n  oneeighty=image.rotate(180)\n  twoseventy=image.rotate(270)\n  image.save(\"./new/\" + str(i) + \".pgm\")\n  i+=1\n  ninety.save(\"./new/\" + str(i)+ \".pgm\")\n  i+=1;\n  oneeighty.save(\"./new/\"+ str(i)+ \".pgm\")\n  i+=1\n  twoseventy.save(\"./new/\"+ str(i)+ \".pgm\")\n  i+=1","execution_count":14,"outputs":[]},{"metadata":{"_cell_guid":"43f771f9-50d9-437d-a1e4-8f7ff02db72f","_uuid":"45bab992add5df3409ec12fac638822cf03fe57a","scrolled":false,"trusted":true},"cell_type":"code","source":"!ls ./new/","execution_count":15,"outputs":[]},{"metadata":{"_cell_guid":"adf08a0d-0b2e-4a6a-b586-11189b3a67fd","_uuid":"111d0962ad62aa73881da92ce90e84679734c992","trusted":true},"cell_type":"code","source":"from __future__ import print_function\nimport sys,os\nimport re\nfrom tensorflow.examples.tutorials.mnist import input_data\n#mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n\nimport tensorflow as tf\nimport numpy as np\ndef read_pgm(filename, byteorder='>'):\n  with open(filename, 'rb') as f:\n    buffer = f.read()\n  try:\n    header, width, height, maxval = re.search(\n  b\"(^P5\\s(?:\\s*#.*[\\r\\n])*\"\n  b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n  b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n  b\"(\\d+)\\s(?:\\s*#.*[\\r\\n]\\s)*)\", buffer).groups()\n  except AttributeError:\n    raise ValueError(\"Not a raw PGM file: '%s'\" % filename)\n  return np.frombuffer(buffer,\n         dtype='u1' if int(maxval) < 256 else byteorder+'u2',\n         count=int(width)*int(height),\n         offset=len(header)\n        ).reshape((int(height)*int(width)))\n\ndef import_images(image_dir, num_images):\n  images_tensor = np.zeros((num_images, 250*250))\n  i = 0\n  for dirName, subdirList, fileList in os.walk(image_dir):\n    for fname in fileList:\n      if fname.endswith(\".pgm\"):\n        images_tensor[i] = read_pgm(image_dir+fname, byteorder='<')\n        i += 1\n\n  # Create a tensor for the labels\n  labels_tensor = np.zeros(num_images,dtype=np.int32)\n  f = open(\"../input/alllabels2501256/labels2.txt\", 'r')\n  i=0;\n\n  for line in f:\n    image_num = i\n    labels_tensor[image_num] = int(line[0]) - 1\n    i+=1;\n    #print(\"image \"+str(i)+ \" saved \");\n\n  out = np.zeros((num_images, 7))\n  out[np.arange(num_images), labels_tensor] = 1\n  return images_tensor, out\n\n\nimages , labels = import_images(\"./new/\" , 1256)\n\ntest_image , test_labels =images,labels\n\n\n\ndef weight_variable(shape):\n  initial = tf.truncated_normal(shape, stddev=0.1)\n  return tf.Variable(initial)\n\ndef bias_variable(shape):\n  initial = tf.constant(0.1, shape=shape)\n  return tf.Variable(initial)\n\ndef conv2d(x, W):\n  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n\ndef max_pool_2x2(x):\n  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n                        strides=[1, 2, 2, 1], padding='SAME')\n\n# Input layer\nx  = tf.placeholder(tf.float32, [None, 250*250], name='x')\ny_ = tf.placeholder(tf.float32, [None, 7],  name='y_')\nx_image = tf.reshape(x, [-1, 250, 250, 1])\n\n# Convolutional layer 1\nW_conv1 = weight_variable([5, 5, 1, 32])\nb_conv1 = bias_variable([32])\n\nh_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\nh_pool1 = max_pool_2x2(h_conv1)\n\n# Convolutional layer 2\nW_conv2 = weight_variable([5, 5, 32, 64])\nb_conv2 = bias_variable([64])\n\nh_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\nh_pool2 = max_pool_2x2(h_conv2)\n\n# Fully connected layer 1\nh_pool2_flat = tf.reshape(h_pool2, [-1, 63*63*64])\n\nW_fc1 = weight_variable([63*63* 64, 1024])\nb_fc1 = bias_variable([1024])\n\nh_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n\n# Dropout\nkeep_prob  = tf.placeholder(tf.float32)\nh_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n\n# Fully connected layer 2 (Output layer)\nW_fc2 = weight_variable([1024, 7])\nb_fc2 = bias_variable([7])\n\ny = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2, name='y')\n\n# Evaluation functions\ncross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n\ncorrect_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n\n# Training algorithm\ntrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n\n# Training steps\nwith tf.Session() as sess:\n  sess.run(tf.initialize_all_variables())\n'''\n  max_steps = 120\n  for step in range(max_steps):\n    batch_xs, batch_ys = [images[step]],[labels[step]]\n    if (step % 100) == 0:\n      print(step, sess.run(accuracy, feed_dict={x: test_image, y_: test_labels, keep_prob: 1.0}))\n    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys, keep_prob: 0.5})\n  print(max_steps, sess.run(accuracy, feed_dict={x: test_image, y_: test_labels, keep_prob: 1.0}))\n'''","execution_count":5,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89d2bf9eff0e4b11cbebdf09e5e74ca23d644243"},"cell_type":"code","source":"!ls ./new/ | wc -l","execution_count":2,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}