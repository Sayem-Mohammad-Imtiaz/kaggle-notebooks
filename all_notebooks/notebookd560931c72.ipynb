{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"* > # EE226 - Coding 2\n## Streaming algorithm & Locality Sensitive Hashing","metadata":{}},{"cell_type":"markdown","source":"### Streaming: DGIM","metadata":{}},{"cell_type":"markdown","source":"DGIM is an efficient algorithm in processing large streams. When it's infeasible to store the flowing binary stream, DGIM can estimate the number of 1-bits in the window. In this coding, you're given the *stream_data.txt* (binary stream), and you need to implement the DGIM algorithm to count the number of 1-bits. Write code and ask the problems below.","metadata":{}},{"cell_type":"markdown","source":"### Your task","metadata":{}},{"cell_type":"markdown","source":"1. Set the window size to 1000, and count the number of 1-bits in the current window.","metadata":{}},{"cell_type":"code","source":"# Your code here, you can add cells if necessary\nimport math\nimport time\nstart_t = time.process_time()\n\nfilename = \"../input/coding2/stream_data.txt\"\n\ncontainer = {}\nwindowsize = 1000\ntimestamp = 0\nupdateinterval = 1000# no larger than the windowsize\nupdateindex = 0\n\nkeysnum = int(math.log(windowsize, 2)) + 1\nkeylist = list()\n# initialize the container\nfor i in range(keysnum):\n    key = int(math.pow(2, i))\n    keylist.append(key)\n    container[key] = list()\n\ndef UpdateContainer(inputdict, klist, numkeys):\n    for key in klist:\n        if len(inputdict[key]) > 2:\n            inputdict[key].pop(0)\n            tstamp = inputdict[key].pop(0)\n            if key != klist[-1]:\n                inputdict[key * 2].append(tstamp)\n        else:\n            break\n\ndef OutputResult(inputdict, klist, wsize):\n    cnt = 0\n    firststamp = 0\n    for key in klist:\n        if len(inputdict[key]) > 0:\n            firststamp = inputdict[key][0]\n        #for tstamp in inputdict[key]:\n            #print (\"size of bucket: %d, timestamp: %d\" % (key, tstamp))\n    for key in klist:\n        for tstamp in inputdict[key]:\n            if tstamp != firststamp:\n                cnt += key\n            else:\n                cnt += 0.5 * key\n    print (\"Estimated number of ones in the last %d bits: %d\" % (wsize, cnt))\n\nwith open(filename, 'r') as sfile:\n    while True:\n        char = sfile.read(1)\n        if not char:# no more input\n            break\n        timestamp = (timestamp + 1) % windowsize\n        for k in container.keys():\n            for itemstamp in container[k]:\n                if itemstamp == timestamp:# remove record which is out of the window\n                    container[k].remove(itemstamp)\n        if char == \"1\":# add it to the container\n            container[1].append(timestamp)\n            UpdateContainer(container, keylist, keysnum)\n        updateindex = (updateindex + 1) % updateinterval\n        if updateindex == 0:\n            OutputResult(container, keylist, windowsize)\n            \nend_t = time.process_time()\n#统计运行时间\nprint (\"run time: %s Seconds\" % (end_t-start_t))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Write a function that accurately counts the number of 1-bits in the current window, and compare the difference between its running time and space and the DGIM algorithm.","metadata":{}},{"cell_type":"code","source":"# Your code here, you can add cells if necessary\nimport math\nimport time\nstart_t = time.process_time()\nfilename = \"../input/coding2/stream_data.txt\"\n\ncontainer = []\nwindowsize = 1000\nupdateinterval = 1000# no larger than the windowsize\nupdateindex = 0\n\ndef OutputResult(inputlist, wsize):\n    cnt = 0\n    for char in inputlist:\n        if char==\"1\":\n            cnt += 1\n    print (\"Accurate number of ones in the last %d bits: %d\" % (wsize, cnt))\n\nwith open(filename, 'r') as sfile:\n    while True:\n        char = sfile.read(1)\n        if not char:# no more input\n            break\n        container.append(char)\n        if len(container) > windowsize:\n            container.pop(0)\n        updateindex = (updateindex + 1) % updateinterval\n        if updateindex == 0:\n            OutputResult(container, windowsize)\n            \nend_t = time.process_time()\n#统计运行时间\nprint (\"run time: %s Seconds\" % (end_t-start_t))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Locality Sensitive Hashing","metadata":{}},{"cell_type":"markdown","source":"The locality sensitive hashing (LSH) algorithm is efficient in near-duplicate document detection. In this coding, you're given the *docs_for_lsh.csv*, where the documents are processed into set of k-shingles (k = 8, 9, 10). *docs_for_lsh.csv* contains 201 columns, where column 'doc_id' represents the unique id of each document, and from column '0' to column '199', each column represents a unique shingle. If a document contains a shingle ordered with **i**, then the corresponding row will have value 1 in column **'i'**, otherwise it's 0. You need to implement the LSH algorithm and ask the problems below.","metadata":{}},{"cell_type":"markdown","source":"### Your task","metadata":{}},{"cell_type":"markdown","source":"Use minhash algoirthm to create signature of each document, and find 'the most similar' documents under Jaccard similarity. \nParameters you need to determine:\n1) Length of signature (number of distinct minhash functions) *n*. Recommanded value: n > 20.\n\n2) Number of bands that divide the signature matrix *b*. Recommanded value: b > n // 10.","metadata":{}},{"cell_type":"code","source":"# Your code here, you can add cells if necessary\nimport numpy as np\nimport linecache\nimport random\nimport itertools\nfilename = \"../input/coding2/docs_for_lsh.csv\"\n\nn=100\nb=20\nr=int(n/b)\ncolu=200\nrow = -1\nfor count, line in enumerate(open(filename, \"rU\")):\n    pass\n    row += 1\nmatrix = np.ones([n,colu])*(-1)\n#计算签名矩阵\nfor k in range(n):\n    seqSet = [i for i in range(row)]\n    count = 0\n    while len(seqSet) > 0:\n        # choose a row of matrix randomly\n        randomSeq = random.choice(seqSet)\n        read = linecache.getline(filename,randomSeq+1)\n        for i in range(colu):\n            if read[i+1] != '0' and matrix[k][i] == -1:\n                matrix[k][i] = randomSeq\n                count += 1\n        if count == colu:\n            break\n        seqSet.remove(randomSeq)\nrelation = np.zeros([colu,colu])\n#Banding\npower=np.array([[10**30,10**24,10**12,10**6,1]])\nfor k in range(b):\n    bucket = {}\n    for i in range(colu):\n        key = np.dot(power,matrix[k*r:k*r+5,i])\n        key=key[0]\n        if key not in bucket:\n            bucket[key] = []\n        bucket[key].append(i)\n    #hash相撞的文件之间连一条边\n    for key in bucket:\n        if len(bucket[key]) > 1:\n            rel = list(itertools.permutations(bucket[key], 2))\n            for point in rel:\n                relation[point] += 1\nprint(\"不同文件相似程度（数值代表两不同文件hash相撞次数，越大越相似）\\n\",relation)\nrelation = np.triu(relation,0)\nsim = np.where(relation==np.max(relation))\nprint(\"最相似文件对：\\n\",list(zip(*sim)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Problem: For document 0 (the one with id '0'), list the **30** most similar document ids (except document 0 itself). You can valid your results with the [sklearn.metrics.jaccard_score()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.jaccard_score.html) function.\n\nTips: You can adjust your parameters to hash the documents with similarity *s > 0.8* into the same bucket.","metadata":{}},{"cell_type":"code","source":"# Your code here, you can add cells if necessary\nindex = relation[0,:].argsort()[-30:][::-1]\nprint(\"与doc0的相撞次数：\",relation[0,:])\nprint(\"与doc0最接近的30个文件：\",index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}