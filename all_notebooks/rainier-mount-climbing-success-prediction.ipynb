{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h3>Intro</h3>\n\nThe problem that underlies this project is stated here:<br>\nhttps://www.kaggle.com/codersree/mount-rainier-weather-and-climbing-data\n\n<b>Briefly:</b><br>\nWe'll go through the EDA and build a prediction model that predicts the Success Rate of climbing, using weather data, at the end.<br>\nEnjoy the reading."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import essential libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib as mpl\n\n# Set my favourite matplotlib style\n\nmpl.style.use('ggplot')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define a parsing function and the date format to detect\n\ndateparse = lambda x: pd.datetime.strptime(x, '%m/%d/%Y')\n\n# Load and parse a Date column simultaneously\n\ndf = pd.read_csv('../input/clmbwth/climbing_statistics.csv', parse_dates=['Date'], date_parser=dateparse)\ndf.sort_values('Date').head(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now, load Rainier_Weather dataset and parse a Date column as previously\n\nwth = pd.read_csv('../input/clmbwth/Rainier_Weather.csv', parse_dates=['Date'], date_parser=dateparse)\nwth.sort_values('Date').head(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wth.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At this stage, we'll skip dataset structure analysis and will back to it several cells later."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge climbing and weather datasets on the Date columns\n\ndfm = df.merge(wth, on='Date')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Then, sort Date values ascending and reset index\n\ndfm.sort_values('Date', inplace=True)\ndfm.reset_index(drop=True, inplace=True)\ndfm.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, let's look into the data we've got:"},{"metadata":{"trusted":true},"cell_type":"code","source":"dfm.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dataset is complete, without NaNs, all features have proper types"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets see histograms for all numeric features\n\ndf_countable = dfm._get_numeric_data()\ndf_countable.hist(bins = 50, figsize=(20,15))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now plot a correlation matrix:\n\ncorr = df_countable.corr()\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nf, ax = plt.subplots(figsize=(10, 9))\n\ncmap = sns.diverging_palette(210, 5, as_cmap=True)\n\nsns.heatmap(corr, mask=mask, cmap=cmap, vmin=-1, vmax=1, center=0,\n            square=True, linewidths=.1, cbar_kws={\"shrink\": .8})\nplt.title('Correlation Matrix for the combined dataset')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfm.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>What we can notice from the table above and the correlation matrix:</b>\n1. 'Success Percentage' feature has an unexpected value of 14.2%, this is clearly an outlier (because '<b>Success Percentage</b>'  $\\subseteq [0, 1]$). To preserve observations, I prefer to fix it the following way: where the values > 1, we'll make them = 1. Additionally, all succeeded attempts we'll make = number of attempts where they exceed.<br>\n\n2. There is a strong correlation between 'Succeeded' and 'Success Percentage' (logically), so we'll drop 'Succeeded' column.<br>\n3. 'Battery Voltage AVG' indicated the battary voltage and seems to be backward correlated with 'Temperature AVG'. Nevertheless, we'll keep this column."},{"metadata":{},"cell_type":"markdown","source":"The cells below are all for the decisions we made previously:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's first rename the target feature column (for convenience purpose only):\n\ndfm.rename(columns={'Success Percentage' : 'SuccPerc'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bring 'Succeeded' to be equal 'Attempted' where 'Succeeded' > 'Attempted'\n\ndfm.loc[dfm['Succeeded'] > dfm['Attempted'], 'Succeeded'] = dfm['Attempted']\n\n# Now, locate the outliers and bring them to 1.\n\ndfm.loc[dfm['SuccPerc'] > 1, 'SuccPerc'] = 1\ndfm['SuccPerc'] = dfm['SuccPerc'].round(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For now, I'm going to keep all the columns and see how efficient the model could be. "},{"metadata":{},"cell_type":"markdown","source":"Some additional EDA using Time Series:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set Date as index\n\nts = dfm.set_index('Date')\n\n# Sort it\n\nts.sort_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The records about climbing successfulness from %s to %s' % (dfm.Date.dt.date.min(), dfm.Date.dt.date.max()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Brief observation:\n\nts['SuccPerc'].plot(style='k.', figsize = (12,7))\n\nplt.title('Climbing success rate distribution')\nplt.ylabel('Success Percentage')\nplt.yticks(np.linspace(0,1,21))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we see that a <b>climbing season</b> starts roughly in <b>March</b> and ends in <b>October</b>. So, let's consider only this interval"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set the range\n\nts_mo = ts['2015-03-01':'2015-10-01']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_mo.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tiseries Multiplotting\n\ncols_plot = ['Temperature AVG', 'Wind Speed Daily AVG', 'Relative Humidity AVG', 'Wind Direction AVG','Solare Radiation AVG', 'SuccPerc']\n\n\naxes = ts_mo[cols_plot].plot(marker='.', alpha=0.5, linestyle='None', figsize=(15, 10), subplots=True)\n\nfor i, ax in enumerate(axes):\n    ax.title.set_text('Time Series Data from {} to {}'.format(str(ts_mo.index.date.min()), str(ts_mo.index.date.max())))\n    break\n\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can notice here, Wind Direction has strong correlation with Relative Humidity. The same is for Wind Speed.<br>\nAnother point to make is that <b>SuccPerc</b> $\\subseteq [0] \\cup [0.5, 1]$ for the most cases."},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.catplot(x = 'Route', data=dfm, aspect=1.5, kind=\"count\", color=\"r\")\ng.set_xticklabels(rotation=90)\nplt.title('Number of records for the each route')\nplt.annotate('The most popular route',\n             xy=(3,1250),\n             rotation=0,\n             va='bottom',\n             ha='left',\n            )\n\nplt.annotate('',\n             xy=(0.5, 1250),\n             xytext=(3, 1270),\n             xycoords='data',\n             arrowprops=dict(arrowstyle='fancy ,head_length=0.4,head_width=0.4,tail_width=0.2',\n                             connectionstyle='arc3', \n                             color='xkcd:red', \n                             lw=2\n                            ))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Combine \"Fuhrer's Finger\" and \"Fuhrers Finger\""},{"metadata":{"trusted":true},"cell_type":"code","source":"dfm.Route.replace(\"Fuhrer's Finger\", \"Fuhrers Finger\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Before we continue, I want to make an important note:</b>\n\nAll <b>Regression models</b> I tried to build showed very poor accuracy ~10%. That is why all further predictions will be based on <b>Classification</b> models."},{"metadata":{},"cell_type":"markdown","source":"The main idea of my further exploration is that each route has its own features such as its difficulty, the way wind blows there and many others.<br>\nThat is why I'm going to consider each route separately.<br>\nThe case where the model was be based on all routes' observations was also examined and the average accuracy score was 58%.<br> I hope it will be higher after we split the dataset on routes."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create dummies for the routes\n\ndummy_r = pd.get_dummies(dfm['Route'])\n\n# Concatenate dummies to the dfm\n\ndfd = pd.concat([dfm,dummy_r], axis=1).drop('Route', axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Another important decision here is binning. We will try to predict three variants of success criterion: Low, Medium, High."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create bins [0,35%] , [35%,65%], [65%, 100%]\n\nbins = [0,0.35,0.65,1]\n\n# Give names to the bins\n\ngroup_names = ['Low', 'Medium', 'High']\n\n# Add SuccBinned column to the dataset\n\ndfd['SuccBinned'] = pd.cut(dfd['SuccPerc'], bins, labels=group_names, include_lowest=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the amount of the each bin\ndfd.SuccBinned.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import libraries for RandomForest models development, accuracy evaluation and train/test/split procedure\n\nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we walk through each route and create a data frame with the corresponding name.\n\nroutes = dfd.columns.to_list()[10:-1]\n\n# Initialize an empty list to add all generated data frames' names\n\nnew_list = []\n\n# Main assigning loop:\n\nfor r in routes:\n    rn = r.lower()\n    rn = rn.replace(' ', '').replace('-', '_').replace(\"'\", '') # We also want to bring the df names to more safe view\n    \n    globals()['df_' + rn] = dfd.loc[dfd[r] == 1] # Generate dataframe\n    globals()['df_' + rn].drop(routes, axis=1, inplace=True) # Drop unnecessary columns\n    \n    new_list.append('df_' + rn) # Add the name to the list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the list\n\npd.DataFrame(data= {'list of df names' : new_list}).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the df created\n\ndf_disappointmentcleaver.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Everything looks awesome so far. Now let's go straight forward and build a classification model based on RandomForest algorithm without tuning, as is."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a function that trains a RF model and returns its accuracy, based on testing dataset. \n# We do not consider dataframes with a number of observations <= 5\n\ndef rf_training(df):\n    if len(df) > 5:\n        temp = df.drop(['Succeeded', 'SuccPerc'], axis=1) \n        x_tr, x_tst, y_tr, y_tst = train_test_split(temp.iloc[:,1:-1], temp['SuccBinned'], test_size=0.2, random_state=1)\n\n        rfc = RandomForestClassifier(n_estimators = 100)\n        rfc.fit(x_tr,y_tr)\n        yhat = rfc.predict(x_tst)\n        return metrics.accuracy_score(y_tst, yhat)\n    \n    else:\n        return -1\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize a dictionary where we'll add information about the route and a base model's accuracy built for it \n# Its view: {'route' : accuracy}\n\ndic = {}\n\n# Fill the dictionary\n\nfor i,v in enumerate(new_list):\n    dic[v] = rf_training(globals()[v])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create df from the dictionary\n\nsuccess = pd.DataFrame(dic, index=['before tuning'])\n\n# Filter models that have less than 6 observations\n\nsuccess = success.T.loc[success.T['before tuning'] != -1]\n\n# Show the df\n\nsuccess","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These are the values of models' accuracy for each route (before tuning)"},{"metadata":{},"cell_type":"markdown","source":"The next step is attempt to improve the accuracy, changing models' parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"# The tuning function\n\ndef rf_tuning(df, mode = 'p'):\n    \n# Create train and test sets\n    temp = df.drop(['Succeeded', 'SuccPerc'], axis=1) \n    x_tr, x_tst, y_tr, y_tst = train_test_split(temp.iloc[:,1:-1], temp['SuccBinned'], test_size=0.2, random_state=1)\n    \n#     Tune min_samples_leaf   \n    a = {}\n    samp = []\n    for sam in range(2,25):            \n        rfc = RandomForestClassifier(n_estimators = 100,\n                                n_jobs = -1,\n                                max_features = \"auto\",\n                                random_state = 1,\n                                min_samples_leaf=sam)\n        rfc.fit(x_tr,y_tr)\n        yhat = rfc.predict(x_tst)\n        a[sam] = metrics.accuracy_score(y_tst, yhat)\n        samp.append(metrics.accuracy_score(y_tst, yhat))\n        \n    for s, val in a.items():   \n        if val == max(samp):\n            max_sam = s\n            \n#     Tune n_estimators        \n    b = {}\n    est = []\n    for tr in range(100,2000,100):\n        rfc = RandomForestClassifier(n_estimators = tr,\n                                n_jobs = -1,\n                                max_features = \"auto\",\n                                random_state = 888,\n                                min_samples_leaf = max_sam)\n        rfc.fit(x_tr,y_tr)\n        yhat = rfc.predict(x_tst)\n        b[tr] = metrics.accuracy_score(y_tst, yhat)\n        est.append(metrics.accuracy_score(y_tst, yhat))\n    \n    for e, val in b.items():   \n        if val == max(est):\n            max_est = e\n            \n#     Tune max_features      \n    results3 = []\n    mf_opt=[\"auto\", None, \"sqrt\", \"log2\", 0.9, 0.2]\n    for max_f in mf_opt:\n        rfc = RandomForestClassifier(n_estimators = max_est,\n                                n_jobs = -1,\n                                max_features = max_f,\n                                random_state = 888,\n                                min_samples_leaf=max_sam)\n        rfc.fit(x_tr,y_tr)\n        yhat = rfc.predict(x_tst)\n        results3.append(metrics.accuracy_score(y_tst, yhat))\n        \n#     Return best accuracy, df's leght and model's parameters\n    if mode == 'p':\n        return max(results3), len(temp), [max_est, max_sam, max_f]\n    elif mode == 't':\n        return rfc, x_tr.columns\n    else:\n        pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize a dictionary for tuned models\n\ndic1 = {}\n\n# Initialize number of samples in the df\n\ndic_samples = {}\n\n# Initialize a dictionary for model's parameters\n\ndic_bparams = {}\n\n# Fill the tuned dictionary\n\nfor r in success.index.to_list():\n    dic1[r], dic_samples[r], dic_bparams[r] = rf_tuning(globals()[r], 'p')   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now it's time to combine it to a single data frame"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert dicts to dfs\n\ntuned = pd.DataFrame(dic1, index=['after tuning'])\nnsamples = pd.DataFrame(dic_samples, index=['df_size'])\n\ntuned = tuned.T\nnsamples = nsamples.T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge all columns into a single dataframe\n\ncompare = success.merge(tuned, left_index = True, right_index = True)\ncompare['improvement'] = (compare['after tuning'] - compare['before tuning'])\ncompare = compare.merge(nsamples, left_index = True, right_index = True)\n\ncompare['num_est'] = 0\ncompare['min_samp_leaf'] = 0\ncompare['max_features'] = 0\n\n# Unpack parameters lists\n\nk=0\nfor key,value in dic_bparams.items():\n    for j in range(len(dic_bparams[key])):\n        compare.iloc[k,-3+j] = value[j]\n    k+=1\ncompare","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The next step was to try to improve the accuracy of the most popular route - \"Disappointment Cleaver\". Unfortunately, any further attempts to improve the accuracy was failed. Neither changing the model nor using a GridSearch technique led to success."},{"metadata":{"trusted":true},"cell_type":"code","source":"mod, col = rf_tuning(globals()['df_disappointmentcleaver'], 't')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's observe feature importances\n\nt = {}\nfor f, v in zip(col.values,mod.feature_importances_):\n    t[f] = v\n    \n\ntd = pd.DataFrame(t, index=['Imp. values']).T.sort_values('Imp. values')\ntd.plot(kind='bar', figsize=(12,7))\n\nfor i, v in enumerate(td['Imp. values']):\n    plt.annotate('{0:0.2f}%'.format(v*100), xy=(i, v+0.005), ha='center', color='black')\n    \nplt.ylim(0,0.3)\nplt.title('Feature Importances')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Overall, we see that all features contribute to prediction performance."},{"metadata":{},"cell_type":"markdown","source":"Here are some EDA I conducted when tried to get some insights on the \"Disappointment Cleaver\" dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now let's plot and observe the frequency of attempts per day\n\nplt.figure(figsize=(12,7))\n\nplt.title(\"Disappointment Cleaver. Number of attempts frequency\")\nplt.annotate('',\n             xy=(3.1, 345),\n             xytext=(6.9, 300),\n             xycoords='data',\n             arrowprops=dict(arrowstyle='fancy ,head_length=0.4,head_width=0.4,tail_width=0.2',\n                             connectionstyle='arc3', \n                             color='xkcd:red', \n                             lw=2\n                            ))\nplt.annotate('',\n             xy=(10.9, 360),\n             xytext=(7.1, 300),\n             xycoords='data',\n             arrowprops=dict(arrowstyle='fancy ,head_length=0.4,head_width=0.4,tail_width=0.2',\n                             connectionstyle='arc3', \n                             color='xkcd:red', \n                             lw=2\n                            ))\n\nplt.annotate('Most popular: 2 and 12 attempts per day',\n             xy=(7,280),\n             rotation=0,\n             va='bottom',\n             ha='center',)\n\nsns.distplot(df_disappointmentcleaver.Attempted,  bins=11, kde=False, rug=True);\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_disappointmentcleaver.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Another way to look at the data: PairGrid."},{"metadata":{"trusted":true},"cell_type":"code","source":"tp = df_disappointmentcleaver.drop(['Succeeded', 'Battery Voltage AVG'], axis=1)\ng = sns.PairGrid(tp, hue='SuccBinned',\n                 palette='Set2',\n                 hue_order=['Low', 'Medium', 'High'], hue_kws = {\"marker\": [\"o\", \"s\", \"D\"]})\n\ng.map_diag(plt.hist)\ng.map_offdiag(plt.scatter)\ng.add_legend();\n\ndel(tp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,7))\nax = sns.violinplot(x=\"SuccBinned\", y='Wind Speed Daily AVG', data=df_disappointmentcleaver, inner=None)\nax = sns.swarmplot(x='SuccBinned', y='Wind Speed Daily AVG', data=df_disappointmentcleaver)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,7))\nax = sns.violinplot(x=\"SuccBinned\", y=\"Temperature AVG\", data=df_disappointmentcleaver, inner=None)\nax = sns.swarmplot(x='SuccBinned', y='Temperature AVG', data=df_disappointmentcleaver)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Conclusoin</h3>\n\nTo conclude, the prediction model I've managed to build has 60% accuracy. This is quite risky to use it in a real-world.<br>\nTo my mind, this is mainly because of lack of observations and the vast influence of the individual groups' climbing experience. This results to cases when the equal features' values point to different outcomes. Unfortunately, there is no data about how skilled the attempted groups were."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}