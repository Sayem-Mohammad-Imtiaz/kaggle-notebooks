{"cells":[{"metadata":{"_uuid":"d8ebb79f-6a72-437d-bf99-647213ea7c00","_cell_guid":"dd708ed0-074e-421a-b66b-7b27e6b822ab","trusted":true},"cell_type":"code","source":"---\ntitle: \"Trabajo final Master - Ntic/UCM\"\nauthor: \"Leonardo Valverde Badilla\"\ndate: \"14 de febrero del 2021\"\noutput: html_document\n---\n\n#### **Índice**\n\n1. [Introducción](#id1)\n2. [Descripción del problema](#id2)\n3. [Análisis Exploratorio](#id3)\n4. [Dummies](#id4)\n5. [Estandarización](#id5)\n6. [Selección de variables](#id6)\n7. [Modelización](#id7)\n7. [Ensamblado](#id8)\n\n<div id='id1' />\n\n#### **Introducción**\nNtic Master y la Universidad Complutense de Madrid tienen el master en \"Big data and business analytics\" donde el trabajo final del master es sobre \"Credit Card Customers\", el cual el gerente del banco está molesto porque cada vez más clientes abandonan sus servicios de tarjetas de crédito. Él desea predecir  quién va a abandonar la tarjeta de crédito para que de manera proactiva le puedan ofrecer un mejor servicio a los clientes, así puedan cambiar de opinión y no abandonen el banco.\n\nLa fuente de los datos se obtuvo de Kaggle: https://www.kaggle.com/sakshigoyal7/credit-card-customers\n\n<div id='id2' />\n\n#### **Descripción del problema**\n\nComo se mencionó en el encabezado, el banco está reportando un mayor abandono de los clientes de la tarjeta de crédito y el gerente desea predecir el abandono de cada cliente para mejorarle los servicios y no abandone el banco.\n\nEn conclusión, se deben conocer las características de los clientes que abandonan los servicios de la tarjeta de crédito para que no aumente este KPI dentro de la organización, esto puede afectar otros indicadores como rentabilidad, mala imagen por servicio, entre otros.\n\n```{r, warning=FALSE, echo=FALSE,message=FALSE}\nlibrary(doParallel)\nregisterDoParallel(makeCluster(6))\n```\n\n<div id='id3' />\n\n#### **Análisis Exploratorio**\n\nSe carga la base y se presenta una pequeña parte de las 10.217 observaciones y 21 variables:\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\nsetwd(\"C:/Users/lvalverde/Documents/UCM/TFM\")\nbase <- read.csv(\"Credit_Card_Customers.csv\")\n\ndim(base)\n\nlibrary(kableExtra)\nkable(base[1:5,2:9]) %>%\n  kable_styling(\"striped\", full_width = F)\n```\n\nEl formato de las 21 variables se resumen de la siguiente manera:\n\n* **ID**: ClientNum (El número de cliente)\n* **Target**: Attrition_Flag (Variable Objetivo)\n* **Character**: \n  + Gender (Género: Femenino y Masculino)\n  + Education level (Nivel de educación)\n  + Marital Status (Estado civil)\n  + Income Category (Categoría de ingreso)\n  + Card Category (Categoría de la tarjeta de crédito)\n* **Numérico**: \n  + Age (Edad)\n  + Dependent Count (Cantidad de dependientes)\n  + Month on book (Periodo de relación con el banco)\n  + Total Relationship Count (Cantidad de productos que posee el cliente)\n  + Months Inactive 12 mon (Número de meses inactivos en los últimos 12 meses)\n  + Contacts Count 12 mon (Cantidad de contactos en los U12M)\n  + Credit Limit (Límite de crédito)\n  + Total Revolving Bal (Saldo giratorio de la tarjeta de crédito)\n  + Avg Open To Buy (Línea de crédito para compras (Prom. U12M))\n  + Total Amt Chng Q4 Q1 (Cambio en el monto de transacción)\n  + Total Trans Amt (Monto total de transacciones U12M)\n  + Total Trans Ct (Cantidad total de transacciones U12M)\n  + Total Ct Chng Q4 Q1 (Cambio en lacantidad de transacciones)\n  + Avg Utilization Ratio (Índice de utilización promedio de la tarjeta)\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\nlibrary(ggplot2)\nlibrary(dfexplore)\ndfplot(base[,c(3:21)], title = \"Credit Card Customers\")\n```\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\nbase$Attrition_Flag <- as.factor(base$Attrition_Flag)\nbase$Gender <- as.factor(base$Gender)\nbase$Education_Level <- as.factor(base$Education_Level)\nbase$Marital_Status <- as.factor(base$Marital_Status)\nbase$Income_Category <- as.factor(base$Income_Category)\nbase$Card_Category <- as.factor(base$Card_Category)\n```\n\nLa función \"Summary\" nos permite  ver el resumen estadístico de las variables donde podemos analizar lo siguiente: \n\n- Las variables \"Education level\", \"Martital Status\" y \"Income_Category\" tienen datos desconocidos, es decir, podríamos sustituirlos por missings para validar el porcentaje de nulos y saber qué validación podemos aplicar en estas tres variables.\n\n- Se reportan valores máximos con gran diferencia entre la media en las variables numéricas de \"Avg Open To Buy\", \"Credit Limit\", \"Total Amt Chng Q4_Q1\", \"Total Amt Chng Q4_Q1\" y \"Total Trans Amt\", por lo que se pueden realizar boxplots para identificar outliers.\n  \n- Se debe sustituir los \"Unknown\" por missings para después hacer las validaciones correspondientes de los nulos ya que no son una categoría dentro de cada variable.\n\n```{r, echo=FALSE, warning=FALSE, message=FALSE}\nsummary(base)\n```\nCon respecto a los valores máximos anteriores, se procede a validar las 4 variables numéricas para saber si se reportan valores atípicos, y se evidencia outliers principalmente en Total Ct Ching Q4-Q1 donde a partir de 3 ya que esto podría introducir un sesgo.\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\npar(bty='n', mfrow=c(2,2))\nboxplot(base$Total_Ct_Chng_Q4_Q1, main = \"Boxplot Total Ct Ching Q4-Q1\")\nboxplot(base$Avg_Open_To_Buy, main = \"Boxplot Avg Open to buy\")\nboxplot(base$Total_Trans_Amt, main = \"Boxplot Total Trans Amt\")\nboxplot(base$Credit_Limit, main = \"Boxplot Credit Limit\")\n```\n\nSe procede a sustituir los outliers de \"Total CT Chng Q4-Q1\" y los valores \"Unkhown\" para evitar un sesgo de los datos, y se recodifica la variable objetivo para ser \"Yes\" o \"No\".\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\nbase$Total_Ct_Chng_Q4_Q1 <- replace(base$Total_Ct_Chng_Q4_Q1, which((base$Total_Ct_Chng_Q4_Q1 >= 3)), NA)\nbase$Education_Level <- replace(base$Education_Level, which((base$Education_Level == \"Unknown\")), NA)\nbase$Marital_Status <- replace(base$Marital_Status, which((base$Marital_Status == \"Unknown\")), NA)\nbase$Income_Category <- replace(base$Income_Category, which((base$Income_Category == \"Unknown\")), NA)\nbase$Attrition_Flag <- ifelse(base$Attrition_Flag==\"Attrited Customer\",\"Yes\",\"No\")\nbase$Attrition_Flag <- as.factor(base$Attrition_Flag)\nsummary(base[,c(2,6:8,20)])\n```\n\nSe hace un análisis de algunas de las variables numéricas:\n\n- El promedio de uso de la tarjeta de crédito se destaca porque la mayoría de los clientes están por debajo del 10%.\n- El mayor rango de edad de los clientes está entre 40 a 50 años.\n- La cantidad de meses inactivos en el último año es entre 1 a 3 meses.\n- Existen más clientes con un límite de crédito inferior a los 5 mil dólares.\n\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\npar(mfrow=c(2,3))\n\nhist(base$Credit_Limit, col = heat.colors(20),\n     xlab = \"Límite crédito\", ylab = \"Cantidad Clientes\", main = \"Clientes por límite de crédito\")\n\nhist(base$Customer_Age, col = \"green\",\n     xlab = \"Edad\", ylab = \"Cantidad Clientes\", main = \"Edad de los clientes\")\n\nhist(base$Total_Trans_Ct, col = colorRampPalette(c('blue', 'red'))(15),\n     xlab = \"Cantidad transacciones\", ylab = \"Cantidad Clientes\", main = \"Total de transacciones del último año\")\n\nhist(base$Months_Inactive_12_mon, col = \"darkblue\",\n     xlab = \"Meses inactivos\", ylab = \"Cantidad Clientes\", main = \"Meses inactivos en el último año\")\n\nhist(base$Total_Relationship_Count, col = 'darkgreen', border = \"white\",\n     xlab = \"Cantidad productos\", ylab = \"Cantidad Clientes\", main = \"Cantidad productos del cliente\")\n\nhist(base$Avg_Utilization_Ratio, col = terrain.colors(20),\n     xlab = \"Utilización tarjeta\", ylab = \"Cantidad Clientes\", main = \"Promedio del uso de la tarjeta\")\n```\n\nSe valida la cantidad de missings donde se evidencia que de las 21 variables, 4 poseen missings, donde la variable \"Education Level\" es la que posee más missings donde el 15% de las observaciones son nulos.\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\nlibrary(naniar)\ngg_miss_var(base)\n```\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\nrow.names(base) <- base$CLIENTNUM\nbase2 <- base[,-1]\n```\n\nSe procede a imputar las variables con missings ya que si se eliminan de la base de datos, se exluye el 30% de las observaciones, así que la recomendación es imputarlos con la moda de cada atributo. Por lo que queda de la siguiente manera:\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\nlibrary(psych)\nbase2$prop_missings<-apply(is.na(base2),1,mean)\nsummary(base2$prop_missings)\n```\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\nlistclass <- c(\"Gender\", \"Marital_Status\", \"Education_Level\", \"Income_Category\", \"Card_Category\")\nlistnumeric <- c(\"Customer_Age\", \"Dependent_count\", \"Months_on_book\", \"Total_Relationship_Count\", \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\", \"Credit_Limit\", \"Total_Revolving_Bal\", \"Avg_Open_To_Buy\", \"Total_Amt_Chng_Q4_Q1\", \"Total_Trans_Amt\", \"Total_Trans_Ct\", \"Total_Ct_Chng_Q4_Q1\", \"Avg_Utilization_Ratio\")\nvardep <- \"Attrition_Flag\"\n```\n\n\n```{r, echo=FALSE, warning=FALSE, message=FALSE}\n#Missing de variables numericas\ntablamis1<-as.data.frame(sapply(base2[,listnumeric],function(x) sum(is.na(x))))\nnames(tablamis1)[1]<-\"nmiss\"\n\n#Missing de variables categoricas\ntablamis2<-as.data.frame(sapply(base2[,listclass],function(x) sum(is.na(x))))\nnames(tablamis2)[1]<-\"nmiss\"\n\n#Missing total\ntablatotal<-as.data.frame(rbind(tablamis2,tablamis1))\ntablatotal2 <- subset(tablatotal, tablatotal>0)\n```\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\nfactores<-names(Filter(is.factor, base2))\ntablamis<-as.data.frame(sapply(base2[,factores],function(x) sum(is.na(x))))\nnames(tablamis)[1]<-\"nmiss\"\n\ntablatotal<-as.data.frame(tablamis)\ntablatotal2 <- subset(tablatotal, tablatotal$nmiss>0)\n\ntablatotal2$nombrevar<-row.names(tablatotal2)\nlista<-tablatotal2[which(tablatotal2$nmiss>0),]\nlistamisimp<-dput(lista$nombrevar)\n\nlista2<-intersect(listamisimp, factores)\n\nMode <- function(x){\n  a = table(x)\n  return(names(a[which.max(a)]))\n}\n\nmoda_categorica <- as.data.frame(sapply(base2[,lista2],function(x) ifelse(is.na(x),Mode(x),x)))\n```\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\nbase2$Education_Level[is.na(base2$Education_Level)] <- \"Graduate\"\nbase2$Marital_Status[is.na(base2$Marital_Status)] <- \"Married\"\nbase2$Income_Category[is.na(base2$Income_Category)] <- \"Less than $40K\"\nsummary(base2[,c(5:7)])\n```\n\n\n| Atributo | Observaciones | Moda |\n|------- |------------- |--------- |\n| Education_Level | 1519 | \tGraduate |\n| Marital_Status | 749 | Married |\n| Income_Category | 1112 | Less than $40K |\n\n\nAntes de realizar los dummies, necesitamos eliminar las observaciones con Missings donde al realizar este ejercicio únicamente estaríamos elimnando los 6 observaciones.\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\nbase3<-na.omit(base2,(!is.na(base2)))\ndim(base3)\ntexto <- paste(\"Total de observaciones eliminadas:\", (nrow(base2)-nrow(base3)),sep = \" \")\ntexto\nbase4 <- base3[,-21]\n```\n\n<div id='id4' />\n\n#### **Dummies**\n\nEL siguiente paso es crear dummies para poder realizar el estudio de variables y definir las más importantes, donde este paso nos generó 15 atributos nuevos ya que se hizo únicamente para variables categóricas. \n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\nlibrary(dummies)\nbase5<-dummy.data.frame(base4, listclass, sep = \".\")\ndim(base5)\n\ntexto2 <- paste(\"El modelo generó\", (ncol(base5)-ncol(base4)), \"nuevos atributos\",sep = \" \")\ntexto2\n```\n\nDespués de realizar los dummies, se valida la participación de los atributos generados, esto para definir si dejamos todos los dummies o no, ejemplo: Género se dividió en 2 (Género.F y Género.M) por lo que si dejamos Género.F entonces si trae un cero se puede definir como masculino (Ya que no existe otro género dentro de la base).\n\n**Nota**: Únicamente se va a realizar una pequeña comprobación de lo anterior, ya que es preferible usar técnicas de Machine Learning que nos indica la importancia de las variables.\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\npar(mfrow=c(2,2))\nbarplot(table(base4$Education_Level), col = terrain.colors(10))\nbarplot(table(base4$Marital_Status), col = heat.colors(5))\nbarplot(table(base4$Income_Category), col = terrain.colors(15))\nbarplot(table(base4$Card_Category), col = \"darkblue\")\n```\n\n**Education Level**: El 45.9% de las observaciones son \"Graduate\", sin embargo, podríamos excluir únicamente los atributos \"Doctorate\" y \"Post-Graduate\" ya que solo el 5% de los clientes poseen estos grados académicos.\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\nlibrary(htmlTable)\n\neducacion_college <- as.data.frame(round((prop.table(table(base5$Education_Level.College))*100),1))\nnames(educacion_college) <- c(\"Categoria\", \"College\")\neducacion_doctorate <- as.data.frame(round((prop.table(table(base5$Education_Level.Doctorate))*100),1))\nnames(educacion_doctorate) <- c(\"Categoria\", \"Doctorate\")\neducacion_graduate <- as.data.frame(round((prop.table(table(base5$Education_Level.Graduate))*100),1))\nnames(educacion_graduate) <- c(\"Categoria\", \"Graduate\")\neducacion_hs <- as.data.frame(round((prop.table(table(base5$`Education_Level.High School`))*100),1))\nnames(educacion_hs) <- c(\"Categoria\", \"High_School\")\neducacion_post <- as.data.frame(round((prop.table(table(base5$`Education_Level.Post-Graduate`))*100),1))\nnames(educacion_post) <- c(\"Categoria\", \"Post-Graduate\")\neducacion_uneducated <- as.data.frame(round((prop.table(table(base5$Education_Level.Uneducated))*100),1))\nnames(educacion_uneducated) <- c(\"Categoria\", \"Uneducated\")\n\nfreq_education <- merge(educacion_college, educacion_doctorate)\nfreq_education2 <- merge(freq_education, educacion_graduate)\nfreq_education3 <- merge(freq_education2, educacion_hs)\nfreq_education4 <- merge(freq_education3, educacion_post)\nfreq_education5 <- merge(freq_education4, educacion_uneducated)\n\nhtmlTable(head(freq_education5),\n          caption = \"Education Level\",\n          tfoot = \"0 corresponde a 'No' y 1 a 'Si'\")\n```\n\n**Marital Status**: El 53.7% de los clientes están casados, por lo que podemos dejar únicamente este estado ya que \"Divorciado\" tiene poca participación, por lo que si no está casado entonces podría estar soltero o divorciado.\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\ncasado <- as.data.frame(round((prop.table(table(base5$Marital_Status.Married))*100),1))\nnames(casado) <- c(\"Categoria\", \"Casado\")\nsoltero <- as.data.frame(round((prop.table(table(base5$Marital_Status.Single))*100),1))\nnames(soltero) <- c(\"Categoria\", \"Soltero\")\ndivorciado <- as.data.frame(round((prop.table(table(base5$Marital_Status.Divorced))*100),1))\nnames(divorciado) <- c(\"Categoria\", \"Divorciado\")\n\nfreq_estadocivil <- merge(casado, divorciado)\nfreq_estadocivil2 <- merge(freq_estadocivil, soltero)\n\nhtmlTable(head(freq_estadocivil2),\n          caption = \"Marial Status\",\n          tfoot = \"0 corresponde a 'No' y 1 a 'Si'\")\n```\n\n**Income Category**: El 46.1% reporta un ingreso inferior a los 40 mil anuales, sin embargo, hay poca participación en las demás categorías con mayor a 120 mil ya que es el 7.2%.\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\ninferior40 <- as.data.frame(round((prop.table(table(base5$`Income_Category.Less than $40K`))*100),1))\nnames(inferior40) <- c(\"Categoria\", \"Less than 40K\")\nincome_40a60 <- as.data.frame(round((prop.table(table(base5$`Income_Category.$40K - $60K`))*100),1))\nnames(income_40a60) <- c(\"Categoria\", \"$40K - $60K\")\nincome_60a80 <- as.data.frame(round((prop.table(table(base5$`Income_Category.$60K - $80K`))*100),1))\nnames(income_60a80) <- c(\"Categoria\", \"$60K - $80K\")\nincome_80a120 <- as.data.frame(round((prop.table(table(base5$`Income_Category.$80K - $120K`))*100),1))\nnames(income_80a120) <- c(\"Categoria\", \"$80K - $120K\")\nincome_120 <- as.data.frame(round((prop.table(table(base5$`Income_Category.$120K +`))*100),1))\nnames(income_120) <- c(\"Categoria\", \"$120K +\")\n\nfreq_income <- merge(inferior40, income_40a60)\nfreq_income2 <- merge(freq_income, income_60a80)\nfreq_income3 <- merge(freq_income2, income_80a120)\nfreq_income4 <- merge(freq_income3, income_120)\n\nhtmlTable(head(freq_income4),\n          caption = \"Income Category\",\n          tfoot = \"0 corresponde a 'No' y 1 a 'Si'\")\n```\n\n**Card Category**: El 93.2% de los clientes poseen tareta de crédito Blue, por lo que es preferible dejar únicamente esta categoría.\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\nblue <- as.data.frame(round((prop.table(table(base5$Card_Category.Blue))*100),1))\nnames(blue) <- c(\"Categoría\", \"Blue\")\ngold <- as.data.frame(round((prop.table(table(base5$Card_Category.Gold))*100),1))\nnames(gold) <- c(\"Categoría\", \"Gold\")\nplatinum <- as.data.frame(round((prop.table(table(base5$Card_Category.Platinum))*100),1))\nnames(platinum) <- c(\"Categoría\", \"Platinum\")\nsilver <- as.data.frame(round((prop.table(table(base5$Card_Category.Silver))*100),1))\nnames(silver) <- c(\"Categoría\", \"Silver\")\n\nfreq_card <- merge(blue, gold)\nfreq_card2 <- merge(freq_card, platinum)\nfreq_card3 <- merge(freq_card2, silver)\n\nhtmlTable(head(freq_card3),\n          caption = \"Card Category\",\n          tfoot = \"0 corresponde a 'No' y 1 a 'Sí'\")\n```\n\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\nlistclass <- c(\"Gender.F\", \"Education_Level.College\", \"Education_Level.Doctorate\",\"Education_Level.Graduate\",\"Education_Level.High School\",\"Education_Level.Post-Graduate\", \"Education_Level.Uneducated\",\"Marital_Status.Divorced\",\"Marital_Status.Married\",\"Marital_Status.Single\",\"Income_Category.$120K +\",\"Income_Category.$40K - $60K\",\"Income_Category.$60K - $80K\",\"Income_Category.$80K - $120K\",\"Income_Category.Less than $40K\",\"Card_Category.Blue\",\"Card_Category.Gold\",\"Card_Category.Platinum\",\"Card_Category.Silver\")\nlistnumeric <- c(\"Customer_Age\", \"Dependent_count\", \"Months_on_book\", \"Total_Relationship_Count\", \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\", \"Credit_Limit\", \"Total_Revolving_Bal\", \"Avg_Open_To_Buy\", \"Total_Amt_Chng_Q4_Q1\", \"Total_Trans_Amt\", \"Total_Trans_Ct\", \"Total_Ct_Chng_Q4_Q1\", \"Avg_Utilization_Ratio\")\nvardep <- \"Attrition_Flag\"\n```\n\n\n<div id='id5' />\n\n#### **Estandarización**\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\nlibrary(MASS)\n# Calculo medias y dtipica de datos y estandarizo (solo las continuas)\nmeans <-apply(base5[,listnumeric],2,mean)\nsds<-sapply(base5[,listnumeric],sd)\n\n# Estandarizo solo las continuas y uno con las categoricas\nbase6<-scale(base5[,listnumeric], center = means, scale = sds)\nnumerocont<-which(colnames(base5)%in%listnumeric)\nbase7<-cbind(base6,base5[,-numerocont])\nbase7[1:5,1:4]\n```\n\n<div id='id6' />\n\n#### **Selección de variables**\n\nSe van a realizar 3 validaciones para la selección de variables, las cuales nos permiten identificar cuáles son las más predictivas. \n\n**Stepwise**: Stepwise va a ser la primera validación que vamos a realizar mediante una regresión y sus significancia estadística para agregar o eliminar posibles variables en el modelo final.\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\nfull<-glm(factor(Attrition_Flag)~.,data=base7,family = binomial(link=\"logit\"))\nnull<-glm(factor(Attrition_Flag)~1,data=base7,family = binomial(link=\"logit\"))\n```\n\n| Selección de variables de Stepwise (Top 12) |\n|------- |------------- |--------- |\n| Dependent_count | Months_Inactive_12_mon | \tTotal_Relationship_Count |\n| Contacts_Count_12_mon | Gender.F | Total_Trans_Amt |\n| Total_Revolving_Bal | Total_Trans_Ct | Total_Ct_Chng_Q4_Q1 |\n| Credit_Limit  | Marital_Status.Married  |  |\n\n**Step Repetida**: \n\nEsta función que permitede ste 20 nodos y un decay de 0.1\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\nsteprepetidobinaria<- function(data=data,vardep=\"vardep\",\n  listconti=\"listconti\",\n sinicio=12345,sfinal=12359,porcen=0.8,criterio=\"BIC\")\n {\nlibrary(MASS)\nlibrary(dplyr)\nresultados<-data.frame(c())\ndata<-data[,c(listconti,vardep)]\nformu1<-formula(paste(\"factor(\",vardep,\")~.\",sep=\"\"))\nformu2<-formula(paste(\"factor(\",vardep,\")~1\",sep=\"\"))\nlistamodelos<-list()\nfor (semilla in sinicio:sfinal)\n{\nset.seed(semilla)\nsample <- sample.int(n = nrow(data),\n size = floor(porcen*nrow(data)), replace = F)\ntrain <- data[sample, ]\ntest  <- data[-sample, ]\nfull<-glm(formu1,data=train,family = binomial(link=\"logit\"))\nnull<-glm(formu2,data=train,family = binomial(link=\"logit\"))\nif  (criterio=='AIC')\n  {\n  selec1<-stepAIC(null,scope=list(upper=full),\n   direction=\"both\",family = binomial(link=\"logit\"),trace=FALSE)\n  } \nelse   if  (criterio=='BIC')\n  {\n k1=log(nrow(train))\n selec1<-stepAIC(null,scope=list(upper=full),\n  direction=\"both\",family = binomial(link=\"logit\"),k=k1,trace=FALSE)\n  }\nvec<-(names(selec1[[1]]))\nif (length(vec)!=1)\n{\n# CAMBIOS\ncosa<-as.data.frame(table(vec))\ncosa<-as.data.frame(t(cosa))\ncolnames(cosa)<-vec\n# 1) creo un vector con todas las variables input y ceros\n# 2) voy aÃ±adiendo\ncosa<-cosa[2,,drop=FALSE]\ncosa<-cosa[,-(1),drop=FALSE]\ncosa<- data.frame(lapply(cosa, function(x) as.numeric(as.character(x))))\ncosa$id<-semilla\n}\nif (length(vec)==1)\n{\ncosa<-data.frame()\ncosa[1,\"id\"]<-semilla\ncosa$id<-as.integer(cosa$id)\n}\nvectormodelo<-list(names(cosa),semilla)\nlistamodelos<-append(listamodelos,vectormodelo)  \nif (semilla==sinicio)\n{\nlistamod<-cosa\n}\n\nelse if (semilla!=sinicio)\n{\n listamod<-suppressMessages(full_join(cosa,listamod,by = NULL, copy =TRUE))\n}\n}\nlistamod[is.na(listamod)] <- 0\nnom<-names(listamod)\nlistamod$modelo<-\"\"\nfor (i in 1:nrow(listamod))\n{\n listamod[i,c(\"modelo\")]<-\"\"\n listamod[i,c(\"contador\")]=0\n\n  for (vari in nom)\n  { \n   if (listamod[i,vari]==1)\n   {\n   listamod[i,c(\"modelo\")]<-paste(listamod[i,c(\"modelo\")],vari,collapse=\"\",sep=\"+\")\n   listamod[i,c(\"contador\")]=listamod[i,c(\"contador\")]+1\n   }\n  \n   }\n\n}\n \nlistamod$modelo<-substring(listamod$modelo, 2)\ntablamod<-as.data.frame(table(listamod$modelo))\nnames(tablamod)<-c(\"modelo\",\"Freq\")\ntablamod<-tablamod[order(-tablamod$Freq,tablamod$modelo),]\nnuevo<-listamod[,c(\"modelo\",\"id\",\"contador\")]\nuni<-full_join(tablamod,nuevo,by =\"modelo\", copy =TRUE)\nuni= uni[!duplicated(uni$modelo),]\nuni$semilla<-semilla\nli1<-list()\n# str(listamodelos)\nfor (i in 1:nrow(uni))\n{\n for (j in 1:length(listamodelos))\n {\n    if (uni[i,c(\"id\")]==listamodelos[j][[1]])\n  {\n   k<-as.vector(listamodelos[j-1][[1]])\n   length(k)<-length(k)-1\n   li1<-c(li1,list(k))\n   j=length(listamodelos)\n  }\n } \n\n}\n\n uni$semilla<-NULL\n uni$id<-NULL\n return(list(uni,li1))\n\n}\n```\n\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\ndata<-base7\nlistconti<-c(\"Customer_Age\", \"Dependent_count\", \"Months_on_book\", \"Total_Relationship_Count\",\n\"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\", \"Credit_Limit\", \n\"Total_Revolving_Bal\", \"Avg_Open_To_Buy\", \"Total_Amt_Chng_Q4_Q1\", \n\"Total_Trans_Amt\", \"Total_Trans_Ct\", \"Total_Ct_Chng_Q4_Q1\", \"Avg_Utilization_Ratio\", \n\"Gender.F\", \"Gender.M\", \"Education_Level.College\", \n\"Education_Level.Doctorate\", \"Education_Level.Graduate\", \"Education_Level.High School\", \n\"Education_Level.Post-Graduate\", \"Education_Level.Uneducated\", \n\"Marital_Status.Divorced\", \"Marital_Status.Married\", \"Marital_Status.Single\", \n\"Income_Category.$120K +\", \"Income_Category.$40K - $60K\", \"Income_Category.$60K - $80K\", \n\"Income_Category.$80K - $120K\", \"Income_Category.Less than $40K\", \n\"Card_Category.Blue\", \"Card_Category.Gold\", \"Card_Category.Platinum\", \n\"Card_Category.Silver\")\n\nlista<-steprepetidobinaria(data=data,\n                           vardep=vardep,listconti=listconti,sinicio=12345,\n                           sfinal=12395,porcen=0.8,criterio=\"BIC\")\n```\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\ntabla<-lista[[1]]\ndput(lista[[2]][[1]])\ndput(lista[[2]][[2]])\n\n# Vamos a quedarnos con estos modelos\nmod1<-c(\"Total_Trans_Ct\", \"Total_Revolving_Bal\", \"Total_Relationship_Count\", \"Total_Ct_Chng_Q4_Q1\", \"Total_Trans_Amt\", \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\", \"Gender.F\", \"Marital_Status.Married\", \n\"Dependent_count\")\n\ncontrol<-trainControl(method = \"repeatedcv\",number=4,repeats = 5,\n                      classProbs=TRUE,savePredictions = \"all\") \n\navnnetgrid <-expand.grid(size=c(5,10,15,20),\n                         decay=c(0.01,0.1,0.001),bag=FALSE)\n\nredavnnet<- train(Attrition_Flag~ Total_Trans_Ct+Total_Revolving_Bal+Total_Relationship_Count+ Total_Ct_Chng_Q4_Q1+ Total_Trans_Amt+ Months_Inactive_12_mon+Contacts_Count_12_mon+Gender.F+Marital_Status.Married+Dependent_count,\n                  data=data,\n                  method=\"avNNet\",linout = FALSE,maxit=100,\n                  trControl=control,tuneGrid=avnnetgrid,\n                  repeats=5)\nredavnnet\n```\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\nlibrary(plyr)\ndetach(package:plyr)\nlibrary(dummies)\nlibrary(MASS)\nlibrary(reshape)\nlibrary(caret)\nlibrary(dplyr)\nlibrary(pROC)\n\n# CRUZADA LOGISTICA\n\ncruzadalogistica <- function(data=data,vardep=NULL,\n listconti=NULL,listclass=NULL,grupos=4,sinicio=1234,repe=5)\n{\n \nif (any(listclass==c(\"\"))==FALSE)\n    {\n   for (i in 1:dim(array(listclass))) {\n    numindi<-which(names(data)==listclass[[i]])\n    data[,numindi]<-as.character(data[,numindi])\n    data[,numindi]<-as.factor(data[,numindi])\n   }\n  }   \n  \n  data[,vardep]<-as.factor(data[,vardep])\n  \n  # Creo la formula para la logistica\n  \n  if (any(listclass==c(\"\"))==FALSE)\n  {\n   koko<-c(listconti,listclass)\n  }  else   {\n   koko<-c(listconti)\n  }\n \n  modelo<-paste(koko,sep=\"\",collapse=\"+\")\n  formu<-formula(paste(vardep,\"~\",modelo,sep=\"\"))\n  \n  formu \n  # Preparo caret   \n  \n  set.seed(sinicio)\n  control<-trainControl(method = \"repeatedcv\",number=grupos,repeats=repe,\n   savePredictions = \"all\",classProbs=TRUE) \n  \n  # Aplico caret y construyo modelo\n  \n  regresion <- train(formu,data=data,\n   trControl=control,method=\"glm\",family = binomial(link=\"logit\"))                  \n  preditest<-regresion$pred\n  \n  preditest$prueba<-strsplit(preditest$Resample,\"[.]\")\n  preditest$Fold <- sapply(preditest$prueba, \"[\", 1)\n  preditest$Rep <- sapply(preditest$prueba, \"[\", 2)\n  preditest$prueba<-NULL\n  \n  tasafallos<-function(x,y) {\n   confu<-confusionMatrix(x,y)\n   tasa<-confu[[3]][1]\n   return(tasa)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n   tabla<-table(preditest$Rep)\nlistarep<-c(names(tabla))\nmedias<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\ntasa=1-tasafallos(paso1$pred,paso1$obs)  \nmedias<-rbind(medias,tasa)\n}\nnames(medias)<-\"tasa\"\n\n  # CalculamoS AUC  por cada RepeticiÃ³n de cv \n  # Definimnos funciÃ³n\n  \n  auc<-function(x,y) {\n   curvaroc<-roc(response=x,predictor=y)\n   auc<-curvaroc$auc\n   return(auc)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n  \n   mediasbis<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\nauc=auc(paso1$obs,paso1$Yes)\nmediasbis<-rbind(mediasbis,auc)\n}\nnames(mediasbis)<-\"auc\"\n\n  # Unimos la info de auc y de tasafallos\n  \n  medias$auc<-mediasbis$auc\n  return(medias)\n  \n }\n\n# CRUZADA avNNet\n\ncruzadaavnnetbin<-\n function(data=data,vardep=\"vardep\",\n  listconti=\"listconti\",listclass=\"listclass\",grupos=4,sinicio=1234,repe=5,\n  size=c(5),decay=c(0.01),repeticiones=5,itera=100,trace=TRUE)\n { \n  \n  # PreparaciÃ³n del archivo\n  \n  # b)pasar las categÃ³ricas a dummies\n  \nif (any(listclass==c(\"\"))==FALSE)\n  {\n   databis<-data[,c(vardep,listconti,listclass)]\n   databis<- dummy.data.frame(databis, listclass, sep = \".\")\n  }  else   {\n   databis<-data[,c(vardep,listconti)]\n  }\n  \n  # c)estandarizar las variables continuas\n  \n  # Calculo medias y dtipica de datos y estandarizo (solo las continuas)\n  \n  means <-apply(databis[,listconti],2,mean)\n  sds<-sapply(databis[,listconti],sd)\n  \n  # Estandarizo solo las continuas y uno con las categoricas\n  \n  datacon<-scale(databis[,listconti], center = means, scale = sds)\n  numerocont<-which(colnames(databis)%in%listconti)\n  databis<-cbind(datacon,databis[,-numerocont,drop=FALSE ])\n  \n  databis[,vardep]<-as.factor(databis[,vardep])\n  \n  formu<-formula(paste(vardep,\"~.\",sep=\"\"))\n  \n  # Preparo caret   \n  \n  set.seed(sinicio)\n  control<-trainControl(method = \"repeatedcv\",number=grupos,repeats=repe,\n   savePredictions = \"all\",classProbs=TRUE) \n  \n  # Aplico caret y construyo modelo\n  \n  avnnetgrid <-  expand.grid(size=size,decay=decay,bag=FALSE)\n  \n  avnnet<- train(formu,data=databis,\n   method=\"avNNet\",linout = FALSE,maxit=itera,repeats=repeticiones,\n   trControl=control,tuneGrid=avnnetgrid,trace=trace)\n  \n  print(avnnet$results)\n  \n  preditest<-avnnet$pred\n  \n  preditest$prueba<-strsplit(preditest$Resample,\"[.]\")\n  preditest$Fold <- sapply(preditest$prueba, \"[\", 1)\n  preditest$Rep <- sapply(preditest$prueba, \"[\", 2)\n  preditest$prueba<-NULL\n  \n  tasafallos<-function(x,y) {\n   confu<-confusionMatrix(x,y)\n   tasa<-confu[[3]][1]\n   return(tasa)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n\n   tabla<-table(preditest$Rep)\nlistarep<-c(names(tabla))\nmedias<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\ntasa=1-tasafallos(paso1$pred,paso1$obs)  \nmedias<-rbind(medias,tasa)\n}\nnames(medias)<-\"tasa\"\n\n  # CalculamoS AUC  por cada RepeticiÃ³n de cv \n  # Definimnos funciÃ³n\n  \n  auc<-function(x,y) {\n   curvaroc<-roc(response=x,predictor=y)\n   auc<-curvaroc$auc\n   return(auc)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n  \n   mediasbis<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\nauc=auc(paso1$obs,paso1$Yes)\nmediasbis<-rbind(mediasbis,auc)\n}\nnames(mediasbis)<-\"auc\"\n  \n  # Unimos la info de auc y de tasafallos\n  \n  medias$auc<-mediasbis$auc\n  \n  return(medias)\n  \n }\n```\n\n```{r, message=FALSE, echo=FALSE, warning=FALSE}\nmedias1<-cruzadalogistica(data=data,\n                          vardep=\"Attrition_Flag\",\n                          listconti=c(\"Total_Trans_Ct\", \"Total_Revolving_Bal\", \"Total_Relationship_Count\", \"Total_Ct_Chng_Q4_Q1\", \"Total_Trans_Amt\", \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\", \"Gender.F\", \"Marital_Status.Married\", \"Dependent_count\"),\n                          listclass=c(\"\"), grupos=4,sinicio=1234,repe=5)\nmedias1$modelo=\"Logistica1\"\n\nmedias2<-cruzadaavnnetbin(data=data,\n                          vardep=\"Attrition_Flag\",listconti=c(\"Total_Trans_Ct\", \"Total_Revolving_Bal\", \"Total_Relationship_Count\", \"Total_Ct_Chng_Q4_Q1\", \"Total_Trans_Amt\", \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\", \"Gender.F\", \"Marital_Status.Married\", \"Dependent_count\"),\n                          listclass=c(\"\"),grupos=4,sinicio=1234,repe=5,\n                          size=c(20),decay=c(0.1),repeticiones=5,itera=200)\nmedias2$modelo=\"avnnet1\"\n\nunion1<-rbind(medias1,medias2)\npar(cex.axis=0.8,mfrow=c(1,2))\nboxplot(data=union1,tasa~modelo,main=\"TASA FALLOS\",col=\"pink\")\nboxplot(data=union1,auc~modelo,main=\"AUC\",col=\"pink\")\n```\n\n| Selección de variables Step Repetido Binario |\n|------- |------------- |--------- |\n| Total_Trans_Ct | Total_Trans_Amt | \tTotal_Revolving_Bal |\n| Total_Ct_Chng_Q4_Q1 | Months_Inactive_12_mon | Contacts_Count_12_mon |\n| Gender.F | Total_Relationship_Count | Marital_Status.Married |\n| Dependent_count |  |  |\n\n\n**Árbol de decisiones**: El split que se está usando para el árbol es \"Gini\" ya que entre mayor es el valor entonces mayor es su homogenidad, y explicando un poco el árbol, la variable que predomina es \"Total Trans Ct\", es decir, la cantidad de transacciones en el último año donde el 84% que sí tiene entonces valida el monto de transacciones el mismo periodo y si es inferior a -0.44 entonces el 16% se tiene que revisar el saldo giratorio de la tarjeta.\n\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\nlibrary(rpart.plot)\narbol1 <- rpart(factor(Attrition_Flag) ~., data = base7,\n                minbucket =30,method = \"class\",parms=list(split=\"gini\"))\nrpart.plot(arbol1,extra=105,nn=TRUE,tweak=0.7)\n```\n\n| Selección de variables del Árbol de decisión |\n|------- |------------- |\n| Total_Trans_Ct | Total_Trans_Amt |\n| Total_Ct_Chng_Q4_Q1 | Total_Revolving_Bal |\n| Customer_Age | Total_Relationship_Count |\n\n\n\n**Selección Variables Final**: \n\nDe acuerdo con el análisis que se realizó con la selección de variables mediante los 3 métodos y en resumen se lograron identificar 10 variables predictivas en el Stepwise, StepRepetido y Árbol.\n\n| Selección de variables Final |\n|------- |------------- |--------- |\n| Total_Trans_Ct | Total_Revolving_Bal | Gender.F\t |\n| Total_Trans_Amt | Months_Inactive_12_mon | Contacts_Count_12_mon |\n| Total_Ct_Chng_Q4_Q1 | Total_Relationship_Count | Marital_Status.Married |\n| Dependent_count |  |  |\n\nEs decir, las variables del cuadro anterior serán usadas en los modelos de Machine Learning para la predicción de los clientes que van a abandonar el banco y no continuar más con la tarjeta de crédito. \n\n<div id='id7' />\n\n#### **Modelización**\n\n**Regresión Logística**\n\nComenzamos la modelización con la Regresión logística y las 10 variables que seleccionamos en el paso anterior. \n\n```{r, warning=FALSE, echo=FALSE, message=FALSE}\nregisterDoParallel(makeCluster(7))\n```\n\n```{r, warning=FALSE, echo=FALSE, message=FALSE}\n#LOGISTICA\nlogistica<- train(Attrition_Flag~Total_Trans_Ct+Total_Revolving_Bal+Gender.F+Total_Trans_Amt+Months_Inactive_12_mon+Contacts_Count_12_mon+Total_Ct_Chng_Q4_Q1+Total_Relationship_Count+Marital_Status.Married+Dependent_count,data=data,\n             method=\"glm\",trControl=control)\n\n#Matriz de confusión\nsal<-logistica$pred\nsalconfu<-confusionMatrix(sal$pred,sal$obs)\n\n#AUC\ncurvaroc<-roc(response=sal$obs,predictor=sal$Yes)\nauc<-curvaroc$auc\n```\n\nEl resultado del modelo es el siguiente: \n\n|Accuracy  | Sensitivity | Specificity | AUC |\n|------- |------------- |--------- |--------- |\n| 90.45% | 96.59% | 58.39% | 92.3% |\n\nEl resultado es positivo ya que los cuatro indicadores tienen un buen porcentaje, sin embargo, la Especificidad se puede mejorar para que el porcentaje de aciertos sea mayor.\n\n\n**Redes Neuronales**\n\nLa red neuronal se está realizando con un parámetros de 5 a 20 nodos y un decay entre 0.001 a 0.1, incluso se establece un maxit de 100 y se define un linout \"False\" por ser una variable dependiente dinaria. \n\n```{r, warning=FALSE, echo=FALSE, message=FALSE}\navnnetgrid_modelo <-expand.grid(size=c(5,10,15,20),\n                         decay=c(0.01,0.1,0.001),bag=FALSE)\n\nredavnnet_modelo<- train(Attrition_Flag~Total_Trans_Ct+Total_Revolving_Bal+Gender.F+Total_Trans_Amt+Months_Inactive_12_mon+Contacts_Count_12_mon+Total_Ct_Chng_Q4_Q1+Total_Relationship_Count+Marital_Status.Married+Dependent_count,\n                  data=data,method=\"avNNet\",linout = FALSE,maxit=100,\n                  trControl=control,tuneGrid=avnnetgrid_modelo, repeats=5)\n\nsal_red<-redavnnet_modelo$pred\nsal_red_confu<-confusionMatrix(sal_red$pred,sal_red$obs)\n\ncurvaroc<-roc(response=sal_red$obs,predictor=sal_red$Yes)\nauc<-curvaroc$auc\nplot(roc(response=sal_red$obs,predictor=sal_red$Yes))\n\n```\n\n\nEl resultado de Redes neuronales es el siguiente: \n\n|Accuracy  | Sensitivity | Specificity | AUC |\n|------- |------------- |--------- |--------- |\n| 94.4% | 98.28% | 74.1% | 97.2% |\n\nEste modelo mejoró más sus indicadores en comparación a Regresión logística, sin embargo, debemos hacer un comparativo final con todos los modelos. De igual manera los parámetros que recomienda son 20 nodos y decay de 0.1.\n\n**Gradient Boosting**\n\nOtra técnica de aprendizaje es Gradient boosting, el mismo usa diferentes parámetros como Shrinkage, número de nodos, cantidad de árboles y depth, y en el ejercicio vamos a aplicar nuevamente la Validación Cruzada Repetitiva y un rango de parámetros para que el modelo recomiende los parámetros que mayor Accuracy y otros indicadores que debemos considerar para saber si el modelo es predictivo.\n\n```{r, warning=FALSE, echo=FALSE, message=FALSE}\ngbmgrid<-expand.grid(shrinkage=c(0.1,0.05,0.03,0.01,0.001),\n                     n.minobsinnode=c(5,10,20),\n                     n.trees=c(100,300,500),\n                     interaction.depth=c(2))\ngbm<- train(factor(Attrition_Flag)~Total_Trans_Ct+Total_Revolving_Bal+Gender.F+Total_Trans_Amt+Months_Inactive_12_mon+Contacts_Count_12_mon+Total_Ct_Chng_Q4_Q1+Total_Relationship_Count+Marital_Status.Married+Dependent_count,data=data,\n            method=\"gbm\",trControl=control,tuneGrid=gbmgrid,\n            distribution=\"bernoulli\", bag.fraction=1,verbose=FALSE)\nplot(gbm)\n```\n\nDe acuerdo con el modelo anterior donde tenía varios parámetros, se genera el modelo con las recomendaciones del anterior, es decir, 500 árboles, 2 iteracciones, 10 nodos y 0.1 de shrinkage. Sin embargo, el nodo de 5 parece tener el mismo Accuracy entonces es preferible usar el que tenga menos nodos. \n\nAdemás, las variables más importantes son las relacionadas a las transacciones de la tarjeta de crédito como:\n\n```{r, warning=FALSE, echo=FALSE, message=FALSE}\ngbmgrid_validacion<-expand.grid(shrinkage=c(0.1),\n                     n.minobsinnode=c(10),\n                     n.trees=c(500),\n                     interaction.depth=c(2))\ngbm_validacion<- train(factor(Attrition_Flag)~Total_Trans_Ct+Total_Revolving_Bal+Gender.F+Total_Trans_Amt+Months_Inactive_12_mon+Contacts_Count_12_mon+Total_Ct_Chng_Q4_Q1+Total_Relationship_Count+Marital_Status.Married+Dependent_count,data=data,\n            method=\"gbm\",trControl=control,tuneGrid=gbmgrid_validacion,\n            distribution=\"bernoulli\", bag.fraction=1,verbose=FALSE)\n\n# IMPORTANCIA DE VARIABLES\npar(cex=1.3)\npar(cex=1.5,las=2, mfrow=c(2,2))\nbarplot(tabla$rel.inf,names.arg=row.names(tabla))\n\nsal_gbm<-gbm_validacion$pred\nsal_gbm_confu<-confusionMatrix(sal_gbm$pred,sal_gbm$obs)\n```\n\n\n```{r, warning=FALSE, echo=FALSE, message=FALSE}\nlibrary(plyr)\ndetach(package:plyr)\nlibrary(dummies)\nlibrary(MASS)\nlibrary(reshape)\nlibrary(caret)\nlibrary(dplyr)\nlibrary(pROC)\n\n\ncruzadagbmbin<-\n function(data=data,vardep=\"vardep\",\n  listconti=\"listconti\",listclass=\"listclass\",\n  grupos=4,sinicio=1234,repe=5,\n  n.minobsinnode=20,shrinkage=0.1,n.trees=100,interaction.depth=2)\n { \n  \n  # PreparaciÃ³n del archivo\n  \n  # b)pasar las categÃ³ricas a dummies\n  \nif (any(listclass==c(\"\"))==FALSE)\n  {\n   databis<-data[,c(vardep,listconti,listclass)]\n   databis<- dummy.data.frame(databis, listclass, sep = \".\")\n  }  else   {\n   databis<-data[,c(vardep,listconti)]\n  }\n  \n  # c)estandarizar las variables continuas\n  \n  # Calculo medias y dtipica de datos y estandarizo (solo las continuas)\n  \n  means <-apply(databis[,listconti],2,mean)\n  sds<-sapply(databis[,listconti],sd)\n  \n  # Estandarizo solo las continuas y uno con las categoricas\n  \n  datacon<-scale(databis[,listconti], center = means, scale = sds)\n  numerocont<-which(colnames(databis)%in%listconti)\n  databis<-cbind(datacon,databis[,-numerocont,drop=FALSE ])\n  \n  databis[,vardep]<-as.factor(databis[,vardep])\n  \n  formu<-formula(paste(\"factor(\",vardep,\")~.\",sep=\"\"))\n  \n  # Preparo caret   \n  \n  set.seed(sinicio)\n  control<-trainControl(method = \"repeatedcv\",number=grupos,repeats=repe,\n   savePredictions = \"all\",classProbs=TRUE) \n  \n  # Aplico caret y construyo modelo\n  \n  \n  \n   gbmgrid <-expand.grid(n.minobsinnode=n.minobsinnode,\n    shrinkage=shrinkage,n.trees=n.trees,\n    interaction.depth=interaction.depth)\n  \n  gbm<- train(formu,data=databis,\n   method=\"gbm\",trControl=control,\n   tuneGrid=gbmgrid,distribution=\"bernoulli\",verbose=FALSE)\n  \n  print(gbm$results)\n  \n  preditest<-gbm$pred\n  \n  \n  preditest$prueba<-strsplit(preditest$Resample,\"[.]\")\n  preditest$Fold <- sapply(preditest$prueba, \"[\", 1)\n  preditest$Rep <- sapply(preditest$prueba, \"[\", 2)\n  preditest$prueba<-NULL\n  \n  tasafallos<-function(x,y) {\n   confu<-confusionMatrix(x,y)\n   tasa<-confu[[3]][1]\n   return(tasa)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n  \n  \n   \n   tabla<-table(preditest$Rep)\nlistarep<-c(names(tabla))\nmedias<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\ntasa=1-tasafallos(paso1$pred,paso1$obs)  \nmedias<-rbind(medias,tasa)\n}\nnames(medias)<-\"tasa\"\n\n  \n  # CalculamoS AUC  por cada RepeticiÃ³n de cv \n  # Definimnos funciÃ³n\n  \n  auc<-function(x,y) {\n   curvaroc<-roc(response=x,predictor=y)\n   auc<-curvaroc$auc\n   return(auc)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n  \n  \n   \n   mediasbis<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\nauc=auc(paso1$obs,paso1$Yes)\nmediasbis<-rbind(mediasbis,auc)\n}\nnames(mediasbis)<-\"auc\"\n\n  \n  # Unimos la info de auc y de tasafallos\n  \n  medias$auc<-mediasbis$auc\n  \n  return(medias)\n  \n }\n```\n\n\n```{r, warning=FALSE, echo=FALSE, message=FALSE}\nmedias_boosting1<-cruzadagbmbin(data=data, vardep=\"Attrition_Flag\",\n                                listconti=c(\"Total_Trans_Ct\", \"Total_Revolving_Bal\", \"Total_Relationship_Count\", \"Total_Ct_Chng_Q4_Q1\", \"Total_Trans_Amt\", \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\", \"Gender.F\", \"Marital_Status.Married\", \"Dependent_count\"),\n                                listclass=c(\"\"),\n                                grupos=4,sinicio=1234,repe=5,\n                                n.minobsinnode=10,shrinkage=0.1,n.trees=200,interaction.depth=2)\n\nmedias_boosting1$modelo=\"gbm1\"\n\nmedias_boosting2<-cruzadagbmbin(data=data, vardep=\"Attrition_Flag\",\n                                listconti=c(\"Total_Trans_Ct\", \"Total_Revolving_Bal\", \"Total_Relationship_Count\", \"Total_Ct_Chng_Q4_Q1\", \"Total_Trans_Amt\", \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\", \"Gender.F\", \"Marital_Status.Married\", \"Dependent_count\"),\n                                listclass=c(\"\"),\n                                grupos=4,sinicio=1234,repe=5,\n                                n.minobsinnode=10,shrinkage=0.1,n.trees=300,interaction.depth=2)\n\nmedias_boosting2$modelo=\"gbm2\"\n\nmedias_boosting3<-cruzadagbmbin(data=data, vardep=\"Attrition_Flag\",\n                                listconti=c(\"Total_Trans_Ct\", \"Total_Revolving_Bal\", \"Total_Relationship_Count\", \"Total_Ct_Chng_Q4_Q1\", \"Total_Trans_Amt\", \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\", \"Gender.F\", \"Marital_Status.Married\", \"Dependent_count\"),\n                                listclass=c(\"\"),\n                                grupos=4,sinicio=1234,repe=5,\n                                n.minobsinnode=10,shrinkage=0.1,n.trees=400,interaction.depth=2)\n\nmedias_boosting3$modelo=\"gbm3\"\n\nmedias_boosting4<-cruzadagbmbin(data=data, vardep=\"Attrition_Flag\",\n                                listconti=c(\"Total_Trans_Ct\", \"Total_Revolving_Bal\", \"Total_Relationship_Count\", \"Total_Ct_Chng_Q4_Q1\", \"Total_Trans_Amt\", \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\", \"Gender.F\", \"Marital_Status.Married\", \"Dependent_count\"),\n                                listclass=c(\"\"),\n                                grupos=4,sinicio=1234,repe=5,\n                                n.minobsinnode=10,shrinkage=0.1,n.trees=500,interaction.depth=2)\n\nmedias_boosting4$modelo=\"gbm4\"\n\nunion_boosting<-rbind(medias_boosting1,medias_boosting2,medias_boosting3,medias_boosting4)\n\npar(cex.axis=0.8)\nboxplot(data=union_boosting,tasa~modelo,main=\"TASA FALLOS\",col=\"pink\")\nboxplot(data=union_boosting,auc~modelo,main=\"AUC\",col=\"pink\")\n\ncurvaroc<-roc(response=sal_gbm$obs,predictor=sal_gbm$Yes)\nauc<-curvaroc$auc\nplot(roc(response=sal_red$obs,predictor=sal_red$Yes))\n```\n\nEn resumen G. Boosting ha dado un importante resultado predictivo ya que la precisión es de un 96%.\n\n|Accuracy  | Sensitivity | Specificity | AUC |\n|------- |------------- |--------- |--------- |\n| 96.2% | 98.28% | 84.2% | 98.4% |\n\n\n**Bagging**\n\nEl método de bagging es donde los algoritmos simples son usados en paralelo, es decir, el error se puede reducir al promediar las salidas del modelo. Además, Bagging es conocido también por ser familia de Random Forest, solamente que este usa en mtry el número de variables. \n\nEn este modelo vamos a usar los parámetros del número de árboles que siempre se recomiendan entre 100 a 200 ya que después de eso es estable el resultado con un número mayor de árboles.\n\n```{r, warning=FALSE, echo=FALSE, message=FALSE}\nlibrary(plyr)\ndetach(package:plyr)\nlibrary(dummies)\nlibrary(MASS)\nlibrary(reshape)\nlibrary(caret)\nlibrary(dplyr)\nlibrary(pROC)\n\ncruzadagbmbin<-\n function(data=data,vardep=\"vardep\",\n  listconti=\"listconti\",listclass=\"listclass\",\n  grupos=4,sinicio=1234,repe=5,\n  n.minobsinnode=20,shrinkage=0.1,n.trees=100,interaction.depth=2)\n { \n  # PreparaciÃ³n del archivo\n  # b)pasar las categÃ³ricas a dummies\nif (any(listclass==c(\"\"))==FALSE)\n  {\n   databis<-data[,c(vardep,listconti,listclass)]\n   databis<- dummy.data.frame(databis, listclass, sep = \".\")\n  }  else   {\n   databis<-data[,c(vardep,listconti)]\n  }\n  # c)estandarizar las variables continuas\n  # Calculo medias y dtipica de datos y estandarizo (solo las continuas)\n  means <-apply(databis[,listconti],2,mean)\n  sds<-sapply(databis[,listconti],sd)\n  # Estandarizo solo las continuas y uno con las categoricas\n  datacon<-scale(databis[,listconti], center = means, scale = sds)\n  numerocont<-which(colnames(databis)%in%listconti)\n  databis<-cbind(datacon,databis[,-numerocont,drop=FALSE ])\n  databis[,vardep]<-as.factor(databis[,vardep])\n  formu<-formula(paste(\"factor(\",vardep,\")~.\",sep=\"\"))\n  # Preparo caret   \n  set.seed(sinicio)\n  control<-trainControl(method = \"repeatedcv\",number=grupos,repeats=repe,\n   savePredictions = \"all\",classProbs=TRUE) \n  \n  # Aplico caret y construyo modelo\n   gbmgrid <-expand.grid(n.minobsinnode=n.minobsinnode,\n    shrinkage=shrinkage,n.trees=n.trees,\n    interaction.depth=interaction.depth)\n  \n  gbm<- train(formu,data=databis,\n   method=\"gbm\",trControl=control,\n   tuneGrid=gbmgrid,distribution=\"bernoulli\",verbose=FALSE)\n  print(gbm$results)\n  preditest<-gbm$pred\n  preditest$prueba<-strsplit(preditest$Resample,\"[.]\")\n  preditest$Fold <- sapply(preditest$prueba, \"[\", 1)\n  preditest$Rep <- sapply(preditest$prueba, \"[\", 2)\n  preditest$prueba<-NULL\n  \n  tasafallos<-function(x,y) {\n   confu<-confusionMatrix(x,y)\n   tasa<-confu[[3]][1]\n   return(tasa)\n  }\n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n   tabla<-table(preditest$Rep)\nlistarep<-c(names(tabla))\nmedias<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\ntasa=1-tasafallos(paso1$pred,paso1$obs)  \nmedias<-rbind(medias,tasa)\n}\nnames(medias)<-\"tasa\"\n  # CalculamoS AUC  por cada RepeticiÃ³n de cv \n  # Definimnos funciÃ³n\n  auc<-function(x,y) {\n   curvaroc<-roc(response=x,predictor=y)\n   auc<-curvaroc$auc\n   return(auc)\n  }\n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n   mediasbis<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\nauc=auc(paso1$obs,paso1$Yes)\nmediasbis<-rbind(mediasbis,auc)\n}\nnames(mediasbis)<-\"auc\"\n  # Unimos la info de auc y de tasafallos\n  medias$auc<-mediasbis$auc\n  return(medias)\n }\n\n\ncruzadaarbolbin<-\n function(data=data,vardep=\"vardep\",\n  listconti=\"listconti\",listclass=\"listclass\",\n  grupos=4,sinicio=1234,repe=5,\n  cp=c(0),minbucket =20)\n { \n  # PreparaciÃ³n del archivo\n  # b)pasar las categÃ³ricas a dummies\nif (any(listclass==c(\"\"))==FALSE)\n  {\n   databis<-data[,c(vardep,listconti,listclass)]\n   databis<- dummy.data.frame(databis, listclass, sep = \".\")\n  }  else   {\n   databis<-data[,c(vardep,listconti)]\n  }\n  \n  # c)estandarizar las variables continuas\n  \n  # Calculo medias y dtipica de datos y estandarizo (solo las continuas)\n  means <-apply(databis[,listconti],2,mean)\n  sds<-sapply(databis[,listconti],sd)\n  \n  # Estandarizo solo las continuas y uno con las categoricas\n  datacon<-scale(databis[,listconti], center = means, scale = sds)\n  numerocont<-which(colnames(databis)%in%listconti)\n  databis<-cbind(datacon,databis[,-numerocont,drop=FALSE ])\n  databis[,vardep]<-as.factor(databis[,vardep])\n  formu<-formula(paste(\"factor(\",vardep,\")~.\",sep=\"\"))\n  \n  # Preparo caret   \n  set.seed(sinicio)\n  control<-trainControl(method = \"repeatedcv\",number=grupos,repeats=repe,\n   savePredictions = \"all\",classProbs=TRUE) \n  \n  # Aplico caret y construyo modelo\n  arbolgrid <-  expand.grid(cp=cp)\n  arbol<- train(formu,data=databis,\n   method=\"rpart\",trControl=control,\n   tuneGrid=arbolgrid,minbucket=minbucket)\n  print(arbol$results)\n  preditest<-arbol$pred\n  preditest$prueba<-strsplit(preditest$Resample,\"[.]\")\n  preditest$Fold <- sapply(preditest$prueba, \"[\", 1)\n  preditest$Rep <- sapply(preditest$prueba, \"[\", 2)\n  preditest$prueba<-NULL\n  tasafallos<-function(x,y) {\n   confu<-confusionMatrix(x,y)\n   tasa<-confu[[3]][1]\n   return(tasa)\n  }\n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n   tabla<-table(preditest$Rep)\nlistarep<-c(names(tabla))\nmedias<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\ntasa=1-tasafallos(paso1$pred,paso1$obs)  \nmedias<-rbind(medias,tasa)\n}\nnames(medias)<-\"tasa\"\n  # CalculamoS AUC  por cada RepeticiÃ³n de cv \n  # Definimnos funciÃ³n\n  auc<-function(x,y) {\n   curvaroc<-roc(response=x,predictor=y)\n   auc<-curvaroc$auc\n   return(auc)\n  }\n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n   mediasbis<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\nauc=auc(paso1$obs,paso1$Yes)\nmediasbis<-rbind(mediasbis,auc)\n}\nnames(mediasbis)<-\"auc\"\n  # Unimos la info de auc y de tasafallos\n  medias$auc<-mediasbis$auc\n  return(medias)\n }\n\n\ncruzadarfbin<-\n function(data=data,vardep=\"vardep\",\n  listconti=\"listconti\",listclass=\"listclass\",\n  grupos=4,sinicio=1234,repe=5,nodesize=20,\n  mtry=2,ntree=50,replace=TRUE,sampsize=1)\n { \n  # if  (sampsize==1)\n  # {\n  #  sampsize=floor(nrow(data)/(grupos-1))\n  # }\n  # PreparaciÃ³n del archivo\n  # b)pasar las categÃ³ricas a dummies\nif (any(listclass==c(\"\"))==FALSE)\n  {\n   databis<-data[,c(vardep,listconti,listclass)]\n   databis<- dummy.data.frame(databis, listclass, sep = \".\")\n  }  else   {\n   databis<-data[,c(vardep,listconti)]\n  }\n  \n  # c)estandarizar las variables continuas\n  \n  # Calculo medias y dtipica de datos y estandarizo (solo las continuas)\n  means <-apply(databis[,listconti],2,mean)\n  sds<-sapply(databis[,listconti],sd)\n  \n  # Estandarizo solo las continuas y uno con las categoricas\n  datacon<-scale(databis[,listconti], center = means, scale = sds)\n  numerocont<-which(colnames(databis)%in%listconti)\n  databis<-cbind(datacon,databis[,-numerocont,drop=FALSE ])\n  databis[,vardep]<-as.factor(databis[,vardep])\n  formu<-formula(paste(\"factor(\",vardep,\")~.\",sep=\"\"))\n  \n  # Preparo caret   \n  set.seed(sinicio)\n  control<-trainControl(method = \"repeatedcv\",number=grupos,repeats=repe,\n   savePredictions = \"all\",classProbs=TRUE) \n  \n  # Aplico caret y construyo modelo\n  rfgrid <-expand.grid(mtry=mtry)\n\n  if  (sampsize==1)\n  {\n    rf<- train(formu,data=databis,\n   method=\"rf\",trControl=control,\n   tuneGrid=rfgrid,nodesize=nodesize,replace=replace,ntree=ntree)\n  }\n  \nelse  if  (sampsize!=1)\n  {\n    rf<- train(formu,data=databis,\n   method=\"rf\",trControl=control,\n   tuneGrid=rfgrid,nodesize=nodesize,replace=replace,sampsize=sampsize,\n   ntree=ntree)\n }\n  print(rf$results)\n  preditest<-rf$pred\n  preditest$prueba<-strsplit(preditest$Resample,\"[.]\")\n  preditest$Fold <- sapply(preditest$prueba, \"[\", 1)\n  preditest$Rep <- sapply(preditest$prueba, \"[\", 2)\n  preditest$prueba<-NULL\n  tasafallos<-function(x,y) {\n   confu<-confusionMatrix(x,y)\n   tasa<-confu[[3]][1]\n   return(tasa)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n   tabla<-table(preditest$Rep)\nlistarep<-c(names(tabla))\nmedias<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\ntasa=1-tasafallos(paso1$pred,paso1$obs)  \nmedias<-rbind(medias,tasa)\n}\nnames(medias)<-\"tasa\"\n  \n  # CalculamoS AUC  por cada RepeticiÃ³n de cv \n  # Definimnos funciÃ³n\n  auc<-function(x,y) {\n   curvaroc<-roc(response=x,predictor=y)\n   auc<-curvaroc$auc\n   return(auc)\n  }\n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n   mediasbis<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\nauc=auc(paso1$obs,paso1$Yes)\nmediasbis<-rbind(mediasbis,auc)\n}\nnames(mediasbis)<-\"auc\"\n  # Unimos la info de auc y de tasafallos\n  medias$auc<-mediasbis$auc\n  return(medias)\n }\n\n```\n\nTambién se van a realizar diferentes variaciones en los parámetros para ver cómo se comporta el modelo como tal, y el resultado de las 5 pruebas es el Bagging número 4 ya que posee la menor tasa de fallos y posee un alto porcentaje de AUC, sin embargo, está por debajo del Accuracy de Boosting por un 1 punto porcentual.\n\nLos parámetros de este cuarto prueba es: \"rupos=4,sinicio=1234,repe=5,nodesize=10, mtry=10,ntree=200,replace=TRUE,sampsize=900\", con respecto al último punto se usó el 8.8% del tamaño de la base.\n\n```{r, warning=FALSE, echo=FALSE, message=FALSE}\nlibrary(randomForest)\nrfgrid<-expand.grid(mtry=c(10))\n\nset.seed(12345)\n\nrf_bagging<- train(data=data,\n           factor(Attrition_Flag)~Total_Trans_Ct+Total_Revolving_Bal+Gender.F+Total_Trans_Amt+Months_Inactive_12_mon+Contacts_Count_12_mon+Total_Ct_Chng_Q4_Q1+Total_Relationship_Count+Marital_Status.Married+Dependent_count,\n           method=\"rf\",trControl=control,tuneGrid=rfgrid,\n           linout = FALSE,ntree=200,nodesize=10,replace=TRUE)\n\n# PARA PLOTEAR EL ERROR OOB A MEDIDA QUE AVANZAN LAS ITERACIONES\n# SE USA DIRECTAMENTE EL PAQUETE randomForest\n\nrfbis_bagging<-randomForest(factor(Attrition_Flag)~Total_Trans_Ct+Total_Revolving_Bal+Gender.F+Total_Trans_Amt+Months_Inactive_12_mon+Contacts_Count_12_mon+Total_Ct_Chng_Q4_Q1+Total_Relationship_Count+Marital_Status.Married+Dependent_count,\n                    data=data,\n                    mtry=10,ntree=200,sampsize=500,nodesize=10,replace=TRUE)\n\nsal_bagging<-rf_bagging$pred\nsal_bagging_confu<-confusionMatrix(sal_bagging$pred,sal_bagging$obs)\n\n#Medias bagging\nmedias_bagging1<-cruzadarfbin(data=data, vardep=\"Attrition_Flag\",\n                              listconti=c(\"Total_Trans_Ct\", \"Total_Revolving_Bal\", \"Total_Relationship_Count\", \"Total_Ct_Chng_Q4_Q1\", \"Total_Trans_Amt\", \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\", \"Gender.F\", \"Marital_Status.Married\", \"Dependent_count\"),\n            listclass=c(\"\"),grupos=4,sinicio=1234,repe=5,nodesize=10,\n            mtry=10,ntree=100,replace=TRUE,sampsize=500)\n\nmedias_bagging1$modelo=\"bagging1\"\n\nmedias_bagging2<-cruzadarfbin(data=data, vardep=\"Attrition_Flag\",\n                              listconti=c(\"Total_Trans_Ct\", \"Total_Revolving_Bal\", \"Total_Relationship_Count\", \"Total_Ct_Chng_Q4_Q1\", \"Total_Trans_Amt\", \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\", \"Gender.F\", \"Marital_Status.Married\", \"Dependent_count\"),\n                              listclass=c(\"\"),grupos=4,sinicio=1234,repe=5,nodesize=10,\n                              mtry=10,ntree=100,replace=TRUE,sampsize=700)\n\nmedias_bagging2$modelo=\"bagging2\"\n\nmedias_bagging3<-cruzadarfbin(data=data, vardep=\"Attrition_Flag\",\n                              listconti=c(\"Total_Trans_Ct\", \"Total_Revolving_Bal\", \"Total_Relationship_Count\", \"Total_Ct_Chng_Q4_Q1\", \"Total_Trans_Amt\", \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\", \"Gender.F\", \"Marital_Status.Married\", \"Dependent_count\"),\n                              listclass=c(\"\"),grupos=4,sinicio=1234,repe=5,nodesize=10,\n                              mtry=10,ntree=200,replace=TRUE,sampsize=800)\n\nmedias_bagging3$modelo=\"bagging3\"\n\nmedias_bagging4<-cruzadarfbin(data=data, vardep=\"Attrition_Flag\",\n                              listconti=c(\"Total_Trans_Ct\", \"Total_Revolving_Bal\", \"Total_Relationship_Count\", \"Total_Ct_Chng_Q4_Q1\", \"Total_Trans_Amt\", \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\", \"Gender.F\", \"Marital_Status.Married\", \"Dependent_count\"),\n                              listclass=c(\"\"),grupos=4,sinicio=1234,repe=5,nodesize=10,\n                              mtry=10,ntree=200,replace=TRUE,sampsize=900)\n\nmedias_bagging4$modelo=\"bagging4\"\n\nmedias_bagging5<-cruzadarfbin(data=data, vardep=\"Attrition_Flag\",\n                              listconti=c(\"Total_Trans_Ct\", \"Total_Revolving_Bal\", \"Total_Relationship_Count\", \"Total_Ct_Chng_Q4_Q1\", \"Total_Trans_Amt\", \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\", \"Gender.F\", \"Marital_Status.Married\", \"Dependent_count\"),\n                              listclass=c(\"\"),grupos=4,sinicio=1234,repe=5,nodesize=10,\n                              mtry=10,ntree=100,replace=TRUE,sampsize=1000)\n\nmedias_bagging5$modelo=\"bagging5\"\n\nunion_bagging<-rbind(medias_bagging1,medias_bagging2,medias_bagging3,medias_bagging4,medias_bagging5)\n\npar(cex.axis=0.8)\nboxplot(data=union_bagging,tasa~modelo,main=\"TASA FALLOS\",col=\"pink\")\nboxplot(data=union_bagging,auc~modelo,main=\"AUC\",col=\"pink\")\n```\n\n\n**RANDOM FOREST**\n\nLos bosques aleatorios es otro modelo conocido en Machine Learning por su predicitivdad, lo cual hace que el modelo tenga estabilidad y es similar a Bagging pero en este caso usa \"Mtry\" usa todo el número de variables en cada partición de cada árbol.\n\nSe recomienda usar un número de árboles pequeño (100 a 200) pero en este caso vamos a probar el modelo con un árbol de 500 pero un número mayor hace que el modelo tarde más en ejecutarse por el algoritmo que aplica y va a tener casi que el mismo resultado. En el siguiente gráfico se va a poder visualizar el número de árboles que ya se estabilizan apartir del 300 a 500.\n\n```{r, warning=FALSE, echo=FALSE, message=FALSE}\nrfgrid_random<-expand.grid(mtry=c(3,4,5,6,7,8,9,10))\n\nrf_random<- train(factor(Attrition_Flag)~Total_Trans_Ct+Total_Revolving_Bal+Gender.F+Total_Trans_Amt+Months_Inactive_12_mon+Contacts_Count_12_mon+Total_Ct_Chng_Q4_Q1+Total_Relationship_Count+Marital_Status.Married+Dependent_count,data=data,\n           method=\"rf\",trControl=control,tuneGrid=rfgrid_random,\n           linout = FALSE,ntree=500,nodesize=10,replace=TRUE,\n           importance=TRUE)\n\n#El modelo anterior recomienda mtry=4\nrfbis_random<-randomForest(factor(Attrition_Flag)~Total_Trans_Ct+Total_Revolving_Bal+Gender.F+Total_Trans_Amt+Months_Inactive_12_mon+Contacts_Count_12_mon+Total_Ct_Chng_Q4_Q1+Total_Relationship_Count+Marital_Status.Married+Dependent_count,\n                    data=data,\n                    mtry=4,ntree=500,nodesize=10,replace=TRUE)\n\nplot(rfbis_random$err.rate[,1])\n\nsal_random<-rf_random$pred\nsal_random_confu<-confusionMatrix(sal_random$pred,sal_random$obs)\n```\n\nEn Random Forest también se va a realizar el estudio de medias, es decir, se van a probar varios modelos para que compitan entre sí teniendo diferentes parámetros, y así conocer el mejor para el modelo.\n\nEl resultado del mejor Random es de 98% de AUC y una tasa de error del 4.9%, teniendo en cuenta estos parámetros: Wgrupos=4,sinicio=1234,repe=5,nodesize=10, mtry=4,ntree=500,replace=TRUE,sampsize=1000\".  \n\n```{r, warning=FALSE, echo=FALSE, message=FALSE}\n#Medias Random Forest\n\nmedias_random1 <- cruzadarfbin(data=data, \n                      vardep=\"Attrition_Flag\",listconti=c(\"Total_Trans_Ct\", \"Total_Revolving_Bal\", \"Total_Relationship_Count\", \"Total_Ct_Chng_Q4_Q1\", \"Total_Trans_Amt\", \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\", \"Gender.F\", \"Marital_Status.Married\", \"Dependent_count\"),\n                      listclass=c(\"\"),\n                      grupos=4,sinicio=1234,repe=5,nodesize=10,\n                      mtry=4,ntree=200,replace=TRUE,sampsize=400)\n\nmedias_random1$modelo=\"Random1\"\n\nmedias_random2 <- cruzadarfbin(data=data, \n                               vardep=\"Attrition_Flag\",listconti=c(\"Total_Trans_Ct\", \"Total_Revolving_Bal\", \"Total_Relationship_Count\", \"Total_Ct_Chng_Q4_Q1\", \"Total_Trans_Amt\", \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\", \"Gender.F\", \"Marital_Status.Married\", \"Dependent_count\"),\n                               listclass=c(\"\"),\n                               grupos=4,sinicio=1234,repe=5,nodesize=10,\n                               mtry=4,ntree=300,replace=TRUE,sampsize=600)\n\nmedias_random2$modelo=\"Random2\"\n\nmedias_random3 <- cruzadarfbin(data=data, \n                               vardep=\"Attrition_Flag\",listconti=c(\"Total_Trans_Ct\", \"Total_Revolving_Bal\", \"Total_Relationship_Count\", \"Total_Ct_Chng_Q4_Q1\", \"Total_Trans_Amt\", \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\", \"Gender.F\", \"Marital_Status.Married\", \"Dependent_count\"),\n                               listclass=c(\"\"),\n                               grupos=4,sinicio=1234,repe=5,nodesize=10,\n                               mtry=4,ntree=400,replace=TRUE,sampsize=800)\n\nmedias_random3$modelo=\"Random3\"\n\n\nmedias_random4 <- cruzadarfbin(data=data, \n                               vardep=\"Attrition_Flag\",listconti=c(\"Total_Trans_Ct\", \"Total_Revolving_Bal\", \"Total_Relationship_Count\", \"Total_Ct_Chng_Q4_Q1\", \"Total_Trans_Amt\", \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\", \"Gender.F\", \"Marital_Status.Married\", \"Dependent_count\"),\n                               listclass=c(\"\"),\n                               grupos=4,sinicio=1234,repe=5,nodesize=10,\n                               mtry=4,ntree=500,replace=TRUE,sampsize=1000)\n\nmedias_random4$modelo=\"Random4\"\nmedias_random4\n\ncurvaroc<-roc(response=sal_random$obs,predictor=sal_random$Yes)\nauc<-curvaroc$auc\n\nunion_random<-rbind(medias_random1,medias_random2,medias_random3,medias_random4)\n\npar(cex.axis=0.8, mfrow=c(1,2))\nboxplot(data=union_random,tasa~modelo,main=\"TASA FALLOS\",col=\"pink\")\nboxplot(data=union_random,auc~modelo,main=\"AUC\",col=\"pink\")\n\n```\n\n\n**SVM**\n\nEste algoritmo es un aprendizaje supervisado y existen varios métodos pero en este estudio vamos a realizar el Lineal y el Radial, y no se realizó el Polynomial porque el resultado de la precisión del modelo fue baja.\n\n```{r, warning=FALSE, echo=FALSE, message=FALSE}\nSVMgrid<-expand.grid(C=c(0.01,0.05,0.1,0.2,0.5,1,2,5,10))\n\nSVM<- train(data=data,factor(Attrition_Flag)~Total_Trans_Ct+Total_Revolving_Bal+Gender.F+Total_Trans_Amt+Months_Inactive_12_mon+Contacts_Count_12_mon+Total_Ct_Chng_Q4_Q1+Total_Relationship_Count+Marital_Status.Married+Dependent_count,\n            method=\"svmLinear\",trControl=control,\n            tuneGrid=SVMgrid,verbose=FALSE)\nSVM$results\n\nsal_svm<-SVM$pred\nsal_svm_confu<-confusionMatrix(sal_svm$pred,sal_svm$obs)\nsal_svm_confu\n\n\ncurvaroc<-roc(response=sal_svm$obs,predictor=sal_svm$Yes)\nauc<-curvaroc$auc\nauc\nplot(roc(response=sal_svm$obs,predictor=sal_svm$Yes))\n\n```\n\n|Accuracy  | Sensitivity | Specificity | AUC |\n|------- |------------- |--------- |--------- |\n| 90.54% | 96.71% | 58.32% | 91.8% |\n\n\n```{r, warning=FALSE, echo=FALSE, message=FALSE}\n#  SVM RBF\nSVMgrid<-expand.grid(C=c(0.5,1,2,5),\n                     sigma=c(0.0001,0.005,0.01,0.05))\n\nSVM_radial<- train(data=data,factor(Attrition_Flag)~Total_Trans_Ct+Total_Revolving_Bal+Gender.F+Total_Trans_Amt+Months_Inactive_12_mon+Contacts_Count_12_mon+Total_Ct_Chng_Q4_Q1+Total_Relationship_Count+Marital_Status.Married+Dependent_count,\n            method=\"svmRadial\",trControl=control,\n            tuneGrid=SVMgrid,verbose=FALSE)\n\nSVM_radial$results\n\nsal_svm_radial<-SVM_radial$pred\nsal_svmradial_confu<-confusionMatrix(sal_svm_radial$pred,sal_svm_radial$obs)\nsal_svmradial_confu\n\n\ncurvaroc<-roc(response=sal_svm_radial$obs,predictor=sal_svm_radial$Yes)\nauc<-curvaroc$auc\nauc\nplot(roc(response=sal_svm_radial$obs,predictor=sal_svm_radial$Yes))\n\ndat_radial<-as.data.frame(SVM_radial$results)\n\nggplot(dat_radial, aes(x=factor(C), y=Accuracy, \n                color=factor(sigma)))+ \n  geom_point(position=position_dodge(width=0.5),size=3)\n```\n|Accuracy  | Sensitivity | Specificity | AUC |\n|------- |------------- |--------- |--------- |\n| 91.5% | 96.3% | 66.76% | 93.5% |\n\nLos dos modelos de SVM no tuvieron un gran desempeño en el resultado, ya que fueron los modelos que menor porcentaje de Accuracy ya que se vio afectado por la Especificidad que no sobrepasaron el 70%.\n\n<div id='id8' />\n\n**Ensamblado**\n\nEl ensamble de modelos ayuda al rendimiento de los modelos de Machine Learning, principalmente para mejorar su precisión, mediante una combinación de predicciones de varios modelos donde promedio el error y produce una mejor predicción.\n\n```{r, warning=FALSE, echo=FALSE, message=FALSE}\nlibrary(corrplot)\nlibrary(ggplot2)\n\narchivo<-data\n\nvardep<-\"Attrition_Flag\"\nlistconti<-c(\"Total_Trans_Ct\", \"Total_Revolving_Bal\", \"Total_Relationship_Count\", \"Total_Ct_Chng_Q4_Q1\", \"Total_Trans_Amt\", \"Months_Inactive_12_mon\", \"Contacts_Count_12_mon\", \"Gender.F\", \"Marital_Status.Married\", \"Dependent_count\")\nlistclass<-c(\"\")\ngrupos<-4\nsinicio<-1234\nrepe<-5\n\n\n# APLICACION CRUZADAS PARA ENSAMBLAR\nmedias1<-cruzadalogistica(data=archivo,\n                          vardep=vardep,listconti=listconti,\n                          listclass=listclass,grupos=grupos,sinicio=sinicio,repe=repe)\n\nmedias1bis<-as.data.frame(medias1[1])\nmedias1bis$modelo<-\"Logistica\"\npredi1<-as.data.frame(medias1[[2]])\npredi1$logi<-predi1$Yes\n```\n\n```{r, warning=FALSE, echo=FALSE, message=FALSE}\nlibrary(plyr)\ndetach(package:plyr)\nlibrary(dummies)\nlibrary(MASS)\nlibrary(reshape)\nlibrary(caret)\nlibrary(dplyr)\nlibrary(pROC)\n\n\n# *********************************\n# CRUZADA LOGISTICA\n# ********************************* \n\ncruzadalogistica <- function(data=data,vardep=NULL,\n listconti=NULL,listclass=NULL,grupos=4,sinicio=1234,repe=5)\n{\n\n  if (any(listclass==c(\"\"))==FALSE)\n  {\n   for (i in 1:dim(array(listclass))) {\n    numindi<-which(names(data)==listclass[[i]])\n    data[,numindi]<-as.character(data[,numindi])\n    data[,numindi]<-as.factor(data[,numindi])\n   }\n  }   \n  \n  data[,vardep]<-as.factor(data[,vardep])\n  \n  # Creo la formula para la logistica\n  \nif (any(listclass==c(\"\"))==FALSE)\n  {\n   koko<-c(listconti,listclass)\n  }  else   {\n   koko<-c(listconti)\n  }\n \n  modelo<-paste(koko,sep=\"\",collapse=\"+\")\n  formu<-formula(paste(vardep,\"~\",modelo,sep=\"\"))\n  \n  formu \n  # Preparo caret   \n  \n  set.seed(sinicio)\n  control<-trainControl(method = \"repeatedcv\",number=grupos,repeats=repe,\n   savePredictions = \"all\",classProbs=TRUE) \n  \n  # Aplico caret y construyo modelo\n  \n  regresion <- train(formu,data=data,\n   trControl=control,method=\"glm\",family = binomial(link=\"logit\"))                  \n  preditest<-regresion$pred\n  \n  preditest$prueba<-strsplit(preditest$Resample,\"[.]\")\n  preditest$Fold <- sapply(preditest$prueba, \"[\", 1)\n  preditest$Rep <- sapply(preditest$prueba, \"[\", 2)\n  preditest$prueba<-NULL\n  \n  tasafallos<-function(x,y) {\n   confu<-confusionMatrix(x,y)\n   tasa<-confu[[3]][1]\n   return(tasa)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n  \n  \n   \n   tabla<-table(preditest$Rep)\nlistarep<-c(names(tabla))\nmedias<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\ntasa=1-tasafallos(paso1$pred,paso1$obs)  \nmedias<-rbind(medias,tasa)\n}\nnames(medias)<-\"tasa\"\n\n  \n  # CalculamoS AUC  por cada RepeticiÃ³n de cv \n  # Definimnos funciÃ³n\n  \n  auc<-function(x,y) {\n   curvaroc<-roc(response=x,predictor=y)\n   auc<-curvaroc$auc\n   return(auc)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n  \n  \n   \n   mediasbis<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\nauc=auc(paso1$obs,paso1$Yes)\nmediasbis<-rbind(mediasbis,auc)\n}\nnames(mediasbis)<-\"auc\"\n\n  \n  # Unimos la info de auc y de tasafallos\n  \n  medias$auc<-mediasbis$auc\n  \n return(list(medias,preditest))\n  \n }\n\n\n\n\n# *********************************\n# CRUZADA avNNet\n# **************\n\ncruzadaavnnetbin<-\n function(data=data,vardep=\"vardep\",\n  listconti=\"listconti\",listclass=\"listclass\",grupos=4,sinicio=1234,repe=5,\n  size=c(5),decay=c(0.01),repeticiones=5,itera=100,trace=FALSE)\n { \n  \n  # PreparaciÃ³n del archivo\n  \n  # b)pasar las categÃ³ricas a dummies\n  \nif (any(listclass==c(\"\"))==FALSE)\n  {\n   databis<-data[,c(vardep,listconti,listclass)]\n   databis<- dummy.data.frame(databis, listclass, sep = \".\")\n  }  else   {\n   databis<-data[,c(vardep,listconti)]\n  }\n  \n  # c)estandarizar las variables continuas\n  \n  # Calculo medias y dtipica de datos y estandarizo (solo las continuas)\n  \n  means <-apply(databis[,listconti],2,mean)\n  sds<-sapply(databis[,listconti],sd)\n  \n  # Estandarizo solo las continuas y uno con las categoricas\n  \n  datacon<-scale(databis[,listconti], center = means, scale = sds)\n  numerocont<-which(colnames(databis)%in%listconti)\n  databis<-cbind(datacon,databis[,-numerocont,drop=FALSE ])\n  \n  databis[,vardep]<-as.factor(databis[,vardep])\n  \n  formu<-formula(paste(vardep,\"~.\",sep=\"\"))\n  \n  # Preparo caret   \n  \n  set.seed(sinicio)\n  control<-trainControl(method = \"repeatedcv\",number=grupos,repeats=repe,\n   savePredictions = \"all\",classProbs=TRUE) \n  \n  # Aplico caret y construyo modelo\n  \n  avnnetgrid <-  expand.grid(size=size,decay=decay,bag=FALSE)\n  \n  avnnet<- train(formu,data=databis,\n   method=\"avNNet\",linout = FALSE,maxit=itera,repeats=repeticiones,\n   trControl=control,tuneGrid=avnnetgrid,trace=trace)\n  \n  print(avnnet$results)\n  \n  preditest<-avnnet$pred\n  \n  preditest$prueba<-strsplit(preditest$Resample,\"[.]\")\n  preditest$Fold <- sapply(preditest$prueba, \"[\", 1)\n  preditest$Rep <- sapply(preditest$prueba, \"[\", 2)\n  preditest$prueba<-NULL\n  \n  tasafallos<-function(x,y) {\n   confu<-confusionMatrix(x,y)\n   tasa<-confu[[3]][1]\n   return(tasa)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n  \n  \n   \n   tabla<-table(preditest$Rep)\nlistarep<-c(names(tabla))\nmedias<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\ntasa=1-tasafallos(paso1$pred,paso1$obs)  \nmedias<-rbind(medias,tasa)\n}\nnames(medias)<-\"tasa\"\n\n  \n  # CalculamoS AUC  por cada RepeticiÃ³n de cv \n  # Definimnos funciÃ³n\n  \n  auc<-function(x,y) {\n   curvaroc<-roc(response=x,predictor=y)\n   auc<-curvaroc$auc\n   return(auc)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n  \n  \n   \n   mediasbis<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\nauc=auc(paso1$obs,paso1$Yes)\nmediasbis<-rbind(mediasbis,auc)\n}\nnames(mediasbis)<-\"auc\"\n\n  \n  # Unimos la info de auc y de tasafallos\n  \n  medias$auc<-mediasbis$auc\n  \n   return(list(medias,preditest))\n  \n }\n\n\n# *********************************\n# CRUZADA Random Forest\n# ******************************\n\n\ncruzadarfbin<-\n function(data=data,vardep=\"vardep\",\n  listconti=\"listconti\",listclass=\"listclass\",\n  grupos=4,sinicio=1234,repe=5,nodesize=20,\n  mtry=2,ntree=50,replace=TRUE,sampsize=1)\n { \n  \n  \n  # PreparaciÃ³n del archivo\n  \n  # b)pasar las categÃ³ricas a dummies\n  \nif (any(listclass==c(\"\"))==FALSE)\n  {\n   databis<-data[,c(vardep,listconti,listclass)]\n   databis<- dummy.data.frame(databis, listclass, sep = \".\")\n  }  else   {\n   databis<-data[,c(vardep,listconti)]\n  }\n  \n  # c)estandarizar las variables continuas\n  \n  # Calculo medias y dtipica de datos y estandarizo (solo las continuas)\n  \n  means <-apply(databis[,listconti],2,mean)\n  sds<-sapply(databis[,listconti],sd)\n  \n  # Estandarizo solo las continuas y uno con las categoricas\n  \n  datacon<-scale(databis[,listconti], center = means, scale = sds)\n  numerocont<-which(colnames(databis)%in%listconti)\n  databis<-cbind(datacon,databis[,-numerocont,drop=FALSE ])\n  \n  databis[,vardep]<-as.factor(databis[,vardep])\n  \n  formu<-formula(paste(\"factor(\",vardep,\")~.\",sep=\"\"))\n  \n  # Preparo caret   \n  \n  set.seed(sinicio)\n  control<-trainControl(method = \"repeatedcv\",number=grupos,repeats=repe,\n   savePredictions = \"all\",classProbs=TRUE) \n  \n  # Aplico caret y construyo modelo\n  \n  rfgrid <-expand.grid(mtry=mtry)\n  \n      if  (sampsize==1)\n  {\n    rf<- train(formu,data=databis,\n   method=\"rf\",trControl=control,\n   tuneGrid=rfgrid,nodesize=nodesize,replace=replace,ntree=ntree)\n  }\n  \nelse  if  (sampsize!=1)\n  {\n    rf<- train(formu,data=databis,\n   method=\"rf\",trControl=control,\n   tuneGrid=rfgrid,nodesize=nodesize,replace=replace,sampsize=sampsize,\n   ntree=ntree)\n }\n  \n  print(rf$results)\n  \n  preditest<-rf$pred\n  \n  preditest$prueba<-strsplit(preditest$Resample,\"[.]\")\n  preditest$Fold <- sapply(preditest$prueba, \"[\", 1)\n  preditest$Rep <- sapply(preditest$prueba, \"[\", 2)\n  preditest$prueba<-NULL\n  \n  tasafallos<-function(x,y) {\n   confu<-confusionMatrix(x,y)\n   tasa<-confu[[3]][1]\n   return(tasa)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n  \n  \n   \n   tabla<-table(preditest$Rep)\nlistarep<-c(names(tabla))\nmedias<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\ntasa=1-tasafallos(paso1$pred,paso1$obs)  \nmedias<-rbind(medias,tasa)\n}\nnames(medias)<-\"tasa\"\n\n  \n  # CalculamoS AUC  por cada RepeticiÃ³n de cv \n  # Definimnos funciÃ³n\n  \n  auc<-function(x,y) {\n   curvaroc<-roc(response=x,predictor=y)\n   auc<-curvaroc$auc\n   return(auc)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n  \n  \n   \n   mediasbis<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\nauc=auc(paso1$obs,paso1$Yes)\nmediasbis<-rbind(mediasbis,auc)\n}\nnames(mediasbis)<-\"auc\"\n\n  \n  # Unimos la info de auc y de tasafallos\n  \n  medias$auc<-mediasbis$auc\n  \n   return(list(medias,preditest))\n  \n }\n\n# ***************************************************************\n# gbm : parÃ¡metros\n\n# \n#     Number of Boosting Iterations (n.trees, numeric)\n#     Max Tree Depth (max.depth, numeric)\n#     Shrinkage (shrinkage, numeric)\n#     Min. Terminal Node Size (n.minobsinnode, numeric)\n#    \n# ***************************************************************\n\n\n\ncruzadagbmbin<-\n function(data=data,vardep=\"vardep\",\n  listconti=\"listconti\",listclass=\"listclass\",\n  grupos=4,sinicio=1234,repe=5,\n  n.minobsinnode=20,shrinkage=0.1,n.trees=100,interaction.depth=2)\n { \n  \n  # PreparaciÃ³n del archivo\n  \n  # b)pasar las categÃ³ricas a dummies\n  \nif (any(listclass==c(\"\"))==FALSE)\n  {\n   databis<-data[,c(vardep,listconti,listclass)]\n   databis<- dummy.data.frame(databis, listclass, sep = \".\")\n  }  else   {\n   databis<-data[,c(vardep,listconti)]\n  }\n  \n  # c)estandarizar las variables continuas\n  \n  # Calculo medias y dtipica de datos y estandarizo (solo las continuas)\n  \n  means <-apply(databis[,listconti],2,mean)\n  sds<-sapply(databis[,listconti],sd)\n  \n  # Estandarizo solo las continuas y uno con las categoricas\n  \n  datacon<-scale(databis[,listconti], center = means, scale = sds)\n  numerocont<-which(colnames(databis)%in%listconti)\n  databis<-cbind(datacon,databis[,-numerocont,drop=FALSE ])\n  \n  databis[,vardep]<-as.factor(databis[,vardep])\n  \n  formu<-formula(paste(\"factor(\",vardep,\")~.\",sep=\"\"))\n  \n  # Preparo caret   \n  \n  set.seed(sinicio)\n  control<-trainControl(method = \"repeatedcv\",number=grupos,repeats=repe,\n   savePredictions = \"all\",classProbs=TRUE) \n  \n  # Aplico caret y construyo modelo\n  \n  \n  \n   gbmgrid <-expand.grid(n.minobsinnode=n.minobsinnode,\n    shrinkage=shrinkage,n.trees=n.trees,\n    interaction.depth=interaction.depth)\n  \n  gbm<- train(formu,data=databis,\n   method=\"gbm\",trControl=control,\n   tuneGrid=gbmgrid,distribution=\"bernoulli\",verbose=FALSE)\n  \n  print(gbm$results)\n  \n  preditest<-gbm$pred\n  \n  \n  preditest$prueba<-strsplit(preditest$Resample,\"[.]\")\n  preditest$Fold <- sapply(preditest$prueba, \"[\", 1)\n  preditest$Rep <- sapply(preditest$prueba, \"[\", 2)\n  preditest$prueba<-NULL\n  \n  tasafallos<-function(x,y) {\n   confu<-confusionMatrix(x,y)\n   tasa<-confu[[3]][1]\n   return(tasa)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n  \n  \n   \n   tabla<-table(preditest$Rep)\nlistarep<-c(names(tabla))\nmedias<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\ntasa=1-tasafallos(paso1$pred,paso1$obs)  \nmedias<-rbind(medias,tasa)\n}\nnames(medias)<-\"tasa\"\n\n  \n  # CalculamoS AUC  por cada RepeticiÃ³n de cv \n  # Definimnos funciÃ³n\n  \n  auc<-function(x,y) {\n   curvaroc<-roc(response=x,predictor=y)\n   auc<-curvaroc$auc\n   return(auc)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n  \n  \n   \n   mediasbis<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\nauc=auc(paso1$obs,paso1$Yes)\nmediasbis<-rbind(mediasbis,auc)\n}\nnames(mediasbis)<-\"auc\"\n\n  \n  # Unimos la info de auc y de tasafallos\n  \n  medias$auc<-mediasbis$auc\n  \n   return(list(medias,preditest))\n  \n }\n \n\n# ***************************************************************\n# xgboost: parÃ¡metros\n\n   # nrounds (# Boosting Iterations)\n    # max_depth (Max Tree Depth)\n    # eta (Shrinkage)\n    # gamma (Minimum Loss Reduction)\n    # colsample_bytree (Subsample Ratio of Columns)\n    # min_child_weight (Minimum Sum of Instance Weight)\n    # subsample (Subsample Percentage)\n#    \n# PONER linout = FALSE\n# ***************************************************************\n\ncruzadaxgbmbin<-\n function(data=data,vardep=\"vardep\",\n  listconti=\"listconti\",listclass=\"listclass\",\n  grupos=4,sinicio=1234,repe=5,\n  min_child_weight=20,eta=0.1,nrounds=100,max_depth=2,\n  gamma=0,colsample_bytree=1,subsample=1,alpha=0,lambda=0,lambda_bias=0)\n { \n  \n  # PreparaciÃ³n del archivo\n  \n  # b)pasar las categÃ³ricas a dummies\n  \nif (any(listclass==c(\"\"))==FALSE)\n  {\n   databis<-data[,c(vardep,listconti,listclass)]\n   databis<- dummy.data.frame(databis, listclass, sep = \".\")\n  }  else   {\n   databis<-data[,c(vardep,listconti)]\n  }\n  \n  # c)estandarizar las variables continuas\n  \n  # Calculo medias y dtipica de datos y estandarizo (solo las continuas)\n  \n  means <-apply(databis[,listconti],2,mean)\n  sds<-sapply(databis[,listconti],sd)\n  \n  # Estandarizo solo las continuas y uno con las categoricas\n  \n  datacon<-scale(databis[,listconti], center = means, scale = sds)\n  numerocont<-which(colnames(databis)%in%listconti)\n  databis<-cbind(datacon,databis[,-numerocont,drop=FALSE ])\n  \n  databis[,vardep]<-as.factor(databis[,vardep])\n  \n  formu<-formula(paste(\"factor(\",vardep,\")~.\",sep=\"\"))\n  \n  # Preparo caret   \n  \n  set.seed(sinicio)\n  control<-trainControl(method = \"repeatedcv\",number=grupos,repeats=repe,\n   savePredictions = \"all\",classProbs=TRUE) \n  \n  # Aplico caret y construyo modelo\n  \n  xgbmgrid <-expand.grid( min_child_weight=min_child_weight,\n  eta=eta,nrounds=nrounds,max_depth=max_depth,\n  gamma=gamma,colsample_bytree=colsample_bytree,subsample=subsample)\n  \n  xgbm<- train(formu,data=databis,\n   method=\"xgbTree\",trControl=control,\n   tuneGrid=xgbmgrid,objective = \"binary:logistic\",verbose=FALSE,\n   alpha=alpha,lambda=lambda,lambda_bias=lambda_bias)\n  \n  print(xgbm$results)\n  \n  preditest<-xgbm$pred\n  \n  \n  preditest$prueba<-strsplit(preditest$Resample,\"[.]\")\n  preditest$Fold <- sapply(preditest$prueba, \"[\", 1)\n  preditest$Rep <- sapply(preditest$prueba, \"[\", 2)\n  preditest$prueba<-NULL\n  \n  tasafallos<-function(x,y) {\n   confu<-confusionMatrix(x,y)\n   tasa<-confu[[3]][1]\n   return(tasa)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n  \n  \n   \n   tabla<-table(preditest$Rep)\nlistarep<-c(names(tabla))\nmedias<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\ntasa=1-tasafallos(paso1$pred,paso1$obs)  \nmedias<-rbind(medias,tasa)\n}\nnames(medias)<-\"tasa\"\n\n  \n  # CalculamoS AUC  por cada RepeticiÃ³n de cv \n  # Definimnos funciÃ³n\n  \n  auc<-function(x,y) {\n   curvaroc<-roc(response=x,predictor=y)\n   auc<-curvaroc$auc\n   return(auc)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n  \n  \n   \n   mediasbis<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\nauc=auc(paso1$obs,paso1$Yes)\nmediasbis<-rbind(mediasbis,auc)\n}\nnames(mediasbis)<-\"auc\"\n\n  \n  # Unimos la info de auc y de tasafallos\n  \n  medias$auc<-mediasbis$auc\n  \n   return(list(medias,preditest))\n  \n }\n \n\n\n# ***************************************************************\n# svmLinear: parÃ¡metros\n\n# Cost (C, numeric)     \n\n# PONER linout = FALSE\n# ***************************************************************\n\n\ncruzadaSVMbin<-\n function(data=data,vardep=\"vardep\",\n  listconti=\"listconti\",listclass=\"listclass\",\n  grupos=4,sinicio=1234,repe=5,\n  C=1,replace=TRUE)\n { \n  \n  # PreparaciÃ³n del archivo\n  \n  # b)pasar las categÃ³ricas a dummies\n  \nif (any(listclass==c(\"\"))==FALSE)\n  {\n   databis<-data[,c(vardep,listconti,listclass)]\n   databis<- dummy.data.frame(databis, listclass, sep = \".\")\n  }  else   {\n   databis<-data[,c(vardep,listconti)]\n  }\n  \n  # c)estandarizar las variables continuas\n  \n  # Calculo medias y dtipica de datos y estandarizo (solo las continuas)\n  \n  means <-apply(databis[,listconti],2,mean)\n  sds<-sapply(databis[,listconti],sd)\n  \n  # Estandarizo solo las continuas y uno con las categoricas\n  \n  datacon<-scale(databis[,listconti], center = means, scale = sds)\n  numerocont<-which(colnames(databis)%in%listconti)\n  databis<-cbind(datacon,databis[,-numerocont,drop=FALSE ])\n  \n  databis[,vardep]<-as.factor(databis[,vardep])\n  \n  formu<-formula(paste(\"factor(\",vardep,\")~.\",sep=\"\"))\n  \n  # Preparo caret   \n  \n  set.seed(sinicio)\n  control<-trainControl(method = \"repeatedcv\",number=grupos,repeats=repe,\n   savePredictions = \"all\",classProbs=TRUE) \n  \n  # Aplico caret y construyo modelo\n  \n  SVMgrid <-expand.grid(C=C)\n  \n  SVM<- train(formu,data=databis,\n   method=\"svmLinear\",trControl=control,\n   tuneGrid=SVMgrid,replace=replace)\n  \n  print(SVM$results)\n  \n  preditest<-SVM$pred\n  \n  preditest$prueba<-strsplit(preditest$Resample,\"[.]\")\n  preditest$Fold <- sapply(preditest$prueba, \"[\", 1)\n  preditest$Rep <- sapply(preditest$prueba, \"[\", 2)\n  preditest$prueba<-NULL\n  \n  tasafallos<-function(x,y) {\n   confu<-confusionMatrix(x,y)\n   tasa<-confu[[3]][1]\n   return(tasa)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n  \n  \n   \n   tabla<-table(preditest$Rep)\nlistarep<-c(names(tabla))\nmedias<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\ntasa=1-tasafallos(paso1$pred,paso1$obs)  \nmedias<-rbind(medias,tasa)\n}\nnames(medias)<-\"tasa\"\n\n  \n  # CalculamoS AUC  por cada RepeticiÃ³n de cv \n  # Definimnos funciÃ³n\n  \n  auc<-function(x,y) {\n   curvaroc<-roc(response=x,predictor=y)\n   auc<-curvaroc$auc\n   return(auc)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n  \n  \n   \n   mediasbis<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\nauc=auc(paso1$obs,paso1$Yes)\nmediasbis<-rbind(mediasbis,auc)\n}\nnames(mediasbis)<-\"auc\"\n\n  \n  # Unimos la info de auc y de tasafallos\n  \n  medias$auc<-mediasbis$auc\n  \n   return(list(medias,preditest))\n  \n }\n\n\n\n\n\ncruzadaSVMbinPoly<-\n function(data=data,vardep=\"vardep\",\n  listconti=\"listconti\",listclass=\"listclass\",\n  grupos=4,sinicio=1234,repe=5,\n  C=1,degree=2,scale=1)\n { \n  \n  # PreparaciÃ³n del archivo\n  \n  # b)pasar las categÃ³ricas a dummies\n  \nif (any(listclass==c(\"\"))==FALSE)\n  {\n   databis<-data[,c(vardep,listconti,listclass)]\n   databis<- dummy.data.frame(databis, listclass, sep = \".\")\n  }  else   {\n   databis<-data[,c(vardep,listconti)]\n  }\n  \n  # c)estandarizar las variables continuas\n  \n  # Calculo medias y dtipica de datos y estandarizo (solo las continuas)\n  \n  means <-apply(databis[,listconti],2,mean)\n  sds<-sapply(databis[,listconti],sd)\n  \n  # Estandarizo solo las continuas y uno con las categoricas\n  \n  datacon<-scale(databis[,listconti], center = means, scale = sds)\n  numerocont<-which(colnames(databis)%in%listconti)\n  databis<-cbind(datacon,databis[,-numerocont,drop=FALSE ])\n  \n  databis[,vardep]<-as.factor(databis[,vardep])\n  \n  formu<-formula(paste(\"factor(\",vardep,\")~.\",sep=\"\"))\n  \n  # Preparo caret   \n  \n  set.seed(sinicio)\n  control<-trainControl(method = \"repeatedcv\",number=grupos,repeats=repe,\n   savePredictions = \"all\",classProbs=TRUE) \n  \n  # Aplico caret y construyo modelo\n  \n  SVMgrid <-expand.grid(C=C,degree=degree,scale=scale)\n  \n  SVM<- train(formu,data=databis,\n   method=\"svmPoly\",trControl=control,\n   tuneGrid=SVMgrid,replace=replace)\n  \n  print(SVM$results)\n  \n  preditest<-SVM$pred\n  \n  preditest$prueba<-strsplit(preditest$Resample,\"[.]\")\n  preditest$Fold <- sapply(preditest$prueba, \"[\", 1)\n  preditest$Rep <- sapply(preditest$prueba, \"[\", 2)\n  preditest$prueba<-NULL\n  \n  tasafallos<-function(x,y) {\n   confu<-confusionMatrix(x,y)\n   tasa<-confu[[3]][1]\n   return(tasa)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n  \n  \n   \n   tabla<-table(preditest$Rep)\nlistarep<-c(names(tabla))\nmedias<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\ntasa=1-tasafallos(paso1$pred,paso1$obs)  \nmedias<-rbind(medias,tasa)\n}\nnames(medias)<-\"tasa\"\n\n  \n  # CalculamoS AUC  por cada RepeticiÃ³n de cv \n  # Definimnos funciÃ³n\n  \n  auc<-function(x,y) {\n   curvaroc<-roc(response=x,predictor=y)\n   auc<-curvaroc$auc\n   return(auc)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n  \n  \n   \n   mediasbis<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\nauc=auc(paso1$obs,paso1$Yes)\nmediasbis<-rbind(mediasbis,auc)\n}\nnames(mediasbis)<-\"auc\"\n\n  \n  # Unimos la info de auc y de tasafallos\n  \n  medias$auc<-mediasbis$auc\n  \n   return(list(medias,preditest))\n  \n }\n\n\n\n# ***************************************************************\n# svmRadial: parÃ¡metros\n\n    # Sigma (sigma, numeric)\n    # Cost (C, numeric)\n\n# PONER linout = FALSE\n# ***************************************************************\n\n\n\ncruzadaSVMbinRBF<-\n function(data=data,vardep=\"vardep\",\n  listconti=\"listconti\",listclass=\"listclass\",\n  grupos=4,sinicio=1234,repe=5,\n  C=1,sigma=1)\n { \n  \n  # PreparaciÃ³n del archivo\n  \n  # b)pasar las categÃ³ricas a dummies\n  \nif (any(listclass==c(\"\"))==FALSE)\n  {\n   databis<-data[,c(vardep,listconti,listclass)]\n   databis<- dummy.data.frame(databis, listclass, sep = \".\")\n  }  else   {\n   databis<-data[,c(vardep,listconti)]\n  }\n  \n  # c)estandarizar las variables continuas\n  \n  # Calculo medias y dtipica de datos y estandarizo (solo las continuas)\n  \n  means <-apply(databis[,listconti],2,mean)\n  sds<-sapply(databis[,listconti],sd)\n  \n  # Estandarizo solo las continuas y uno con las categoricas\n  \n  datacon<-scale(databis[,listconti], center = means, scale = sds)\n  numerocont<-which(colnames(databis)%in%listconti)\n  databis<-cbind(datacon,databis[,-numerocont,drop=FALSE ])\n  \n  databis[,vardep]<-as.factor(databis[,vardep])\n  \n  formu<-formula(paste(\"factor(\",vardep,\")~.\",sep=\"\"))\n  \n  # Preparo caret   \n  \n  set.seed(sinicio)\n  control<-trainControl(method = \"repeatedcv\",number=grupos,repeats=repe,\n   savePredictions = \"all\",classProbs=TRUE) \n  \n  # Aplico caret y construyo modelo\n  \n  SVMgrid <-expand.grid(C=C,sigma=sigma)\n  \n  SVM<- train(formu,data=databis,\n   method=\"svmRadial\",trControl=control,\n   tuneGrid=SVMgrid,replace=replace)\n  \n  print(SVM$results)\n  \n  preditest<-SVM$pred\n  \n  preditest$prueba<-strsplit(preditest$Resample,\"[.]\")\n  preditest$Fold <- sapply(preditest$prueba, \"[\", 1)\n  preditest$Rep <- sapply(preditest$prueba, \"[\", 2)\n  preditest$prueba<-NULL\n  \n  tasafallos<-function(x,y) {\n   confu<-confusionMatrix(x,y)\n   tasa<-confu[[3]][1]\n   return(tasa)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n  \n  \n   \n   tabla<-table(preditest$Rep)\nlistarep<-c(names(tabla))\nmedias<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\ntasa=1-tasafallos(paso1$pred,paso1$obs)  \nmedias<-rbind(medias,tasa)\n}\nnames(medias)<-\"tasa\"\n\n  \n  # CalculamoS AUC  por cada RepeticiÃ³n de cv \n  # Definimnos funciÃ³n\n  \n  auc<-function(x,y) {\n   curvaroc<-roc(response=x,predictor=y)\n   auc<-curvaroc$auc\n   return(auc)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n  \n  \n   \n   mediasbis<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\nauc=auc(paso1$obs,paso1$Yes)\nmediasbis<-rbind(mediasbis,auc)\n}\nnames(mediasbis)<-\"auc\"\n\n  \n  # Unimos la info de auc y de tasafallos\n  \n  medias$auc<-mediasbis$auc\n  \n   return(list(medias,preditest))\n  \n }\n\n```\n\n\n```{r, warning=FALSE, echo=FALSE, message=FALSE}\nmedias2<-cruzadaavnnetbin(data=archivo,\n                          vardep=vardep,listconti=listconti,\n                          listclass=listclass,grupos=grupos,sinicio=sinicio,repe=repe,\n                          size=c(5),decay=c(0.1),repeticiones=5,itera=100)\n\nmedias2bis<-as.data.frame(medias2[1])\nmedias2bis$modelo<-\"avnnet\"\npredi2<-as.data.frame(medias2[2])\npredi2$avnnet<-predi2$Yes\n```\n\n\n```{r, warning=FALSE, echo=FALSE, message=FALSE}\nmedias3<-cruzadarfbin(data=archivo,\n                      vardep=vardep,listconti=listconti,\n                      listclass=listclass,grupos=grupos,sinicio=sinicio,repe=repe,\n                      mtry=4,ntree=500,nodesize=10,replace=TRUE)\n\nmedias3bis<-as.data.frame(medias3[1])\nmedias3bis$modelo<-\"rf\"\npredi3<-as.data.frame(medias3[2])\npredi3$rf<-predi3$Yes\n```\n\n\n```{r, warning=FALSE, echo=FALSE, message=FALSE}\nmedias4<-cruzadagbmbin(data=archivo,\n                       vardep=vardep,listconti=listconti,\n                       listclass=listclass,grupos=grupos,sinicio=sinicio,repe=repe,\n                       n.minobsinnode=20,shrinkage=0.1,n.trees=500,interaction.depth=2)\n\nmedias4bis<-as.data.frame(medias4[1])\nmedias4bis$modelo<-\"gbm\"\npredi4<-as.data.frame(medias4[2])\npredi4$gbm<-predi4$Yes\n```\n\n```{r, warning=FALSE, echo=FALSE, message=FALSE}\nmedias5<-cruzadarfbin(data=archivo,\n                        vardep=vardep,listconti=listconti,\n                        listclass=listclass,grupos=grupos,sinicio=sinicio,repe=repe,\n                      nodesize=10,mtry=10,ntree=200,replace=TRUE)\n\nmedias5bis<-as.data.frame(medias5[1])\nmedias5bis$modelo<-\"bagging\"\npredi5<-as.data.frame(medias5[2])\npredi5$bagging<-predi5$Yes\n```\n\n\n```{r, warning=FALSE, echo=FALSE, message=FALSE}\ncruzadaSVMbin<-\n function(data=data,vardep=\"vardep\",\n  listconti=\"listconti\",listclass=\"listclass\",\n  grupos=4,sinicio=1234,repe=5,\n  C=1,replace=TRUE)\n { \n  \n  # PreparaciÃ³n del archivo\n  \n  # b)pasar las categÃ³ricas a dummies\n  \nif (any(listclass==c(\"\"))==FALSE)\n  {\n   databis<-data[,c(vardep,listconti,listclass)]\n   databis<- dummy.data.frame(databis, listclass, sep = \".\")\n  }  else   {\n   databis<-data[,c(vardep,listconti)]\n  }\n  \n  # c)estandarizar las variables continuas\n  \n  # Calculo medias y dtipica de datos y estandarizo (solo las continuas)\n  \n  means <-apply(databis[,listconti],2,mean)\n  sds<-sapply(databis[,listconti],sd)\n  \n  # Estandarizo solo las continuas y uno con las categoricas\n  \n  datacon<-scale(databis[,listconti], center = means, scale = sds)\n  numerocont<-which(colnames(databis)%in%listconti)\n  databis<-cbind(datacon,databis[,-numerocont,drop=FALSE ])\n  \n  databis[,vardep]<-as.factor(databis[,vardep])\n  \n  formu<-formula(paste(\"factor(\",vardep,\")~.\",sep=\"\"))\n  \n  # Preparo caret   \n  \n  set.seed(sinicio)\n  control<-trainControl(method = \"repeatedcv\",number=grupos,repeats=repe,\n   savePredictions = \"all\",classProbs=TRUE) \n  \n  # Aplico caret y construyo modelo\n  \n  SVMgrid <-expand.grid(C=C)\n  \n  SVM<- train(formu,data=databis,\n   method=\"svmLinear\",trControl=control,\n   tuneGrid=SVMgrid,replace=replace)\n  \n  print(SVM$results)\n  \n  preditest<-SVM$pred\n  \n  preditest$prueba<-strsplit(preditest$Resample,\"[.]\")\n  preditest$Fold <- sapply(preditest$prueba, \"[\", 1)\n  preditest$Rep <- sapply(preditest$prueba, \"[\", 2)\n  preditest$prueba<-NULL\n  \n  tasafallos<-function(x,y) {\n   confu<-confusionMatrix(x,y)\n   tasa<-confu[[3]][1]\n   return(tasa)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n  \n  \n   \n   tabla<-table(preditest$Rep)\nlistarep<-c(names(tabla))\nmedias<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\ntasa=1-tasafallos(paso1$pred,paso1$obs)  \nmedias<-rbind(medias,tasa)\n}\nnames(medias)<-\"tasa\"\n\n  \n  # CalculamoS AUC  por cada RepeticiÃ³n de cv \n  # Definimnos funciÃ³n\n  \n  auc<-function(x,y) {\n   curvaroc<-roc(response=x,predictor=y)\n   auc<-curvaroc$auc\n   return(auc)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n  \n  \n   \n   mediasbis<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\nauc=auc(paso1$obs,paso1$Yes)\nmediasbis<-rbind(mediasbis,auc)\n}\nnames(mediasbis)<-\"auc\"\n\n  \n  # Unimos la info de auc y de tasafallos\n  \n  medias$auc<-mediasbis$auc\n  \n  return(medias)\n  \n }\n\n```\n\n```{r, warning=FALSE, echo=FALSE, message=FALSE}\nmedias6<-cruzadaSVMbin(data=archivo,\n                       vardep=vardep,listconti=listconti,\n                       listclass=listclass,grupos=grupos,\n                       sinicio=sinicio,repe=repe,C=0.05)\n\nmedias6bis<-as.data.frame(medias6[1])\nmedias6bis$modelo<-\"svmLinear\"\npredi6<-as.data.frame(medias6[2])\npredi6$svmLinear<-\"svmLinear\"\n```\n\n```{r, warning=FALSE, echo=FALSE, message=FALSE}\ncruzadaSVMbinRBF<-\n function(data=data,vardep=\"vardep\",\n  listconti=\"listconti\",listclass=\"listclass\",\n  grupos=4,sinicio=1234,repe=5,\n  C=1,sigma=1)\n { \n  \n  # PreparaciÃ³n del archivo\n  \n  # b)pasar las categÃ³ricas a dummies\n  \nif (any(listclass==c(\"\"))==FALSE)\n  {\n   databis<-data[,c(vardep,listconti,listclass)]\n   databis<- dummy.data.frame(databis, listclass, sep = \".\")\n  }  else   {\n   databis<-data[,c(vardep,listconti)]\n  }\n  \n  # c)estandarizar las variables continuas\n  \n  # Calculo medias y dtipica de datos y estandarizo (solo las continuas)\n  \n  means <-apply(databis[,listconti],2,mean)\n  sds<-sapply(databis[,listconti],sd)\n  \n  # Estandarizo solo las continuas y uno con las categoricas\n  \n  datacon<-scale(databis[,listconti], center = means, scale = sds)\n  numerocont<-which(colnames(databis)%in%listconti)\n  databis<-cbind(datacon,databis[,-numerocont,drop=FALSE ])\n  \n  databis[,vardep]<-as.factor(databis[,vardep])\n  \n  formu<-formula(paste(\"factor(\",vardep,\")~.\",sep=\"\"))\n  \n  # Preparo caret   \n  \n  set.seed(sinicio)\n  control<-trainControl(method = \"repeatedcv\",number=grupos,repeats=repe,\n   savePredictions = \"all\",classProbs=TRUE) \n  \n  # Aplico caret y construyo modelo\n  \n  SVMgrid <-expand.grid(C=C,sigma=sigma)\n  \n  SVM<- train(formu,data=databis,\n   method=\"svmRadial\",trControl=control,\n   tuneGrid=SVMgrid,replace=replace)\n  \n  print(SVM$results)\n  \n  preditest<-SVM$pred\n  \n  preditest$prueba<-strsplit(preditest$Resample,\"[.]\")\n  preditest$Fold <- sapply(preditest$prueba, \"[\", 1)\n  preditest$Rep <- sapply(preditest$prueba, \"[\", 2)\n  preditest$prueba<-NULL\n  \n  tasafallos<-function(x,y) {\n   confu<-confusionMatrix(x,y)\n   tasa<-confu[[3]][1]\n   return(tasa)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n  \n  \n   \n   tabla<-table(preditest$Rep)\nlistarep<-c(names(tabla))\nmedias<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\ntasa=1-tasafallos(paso1$pred,paso1$obs)  \nmedias<-rbind(medias,tasa)\n}\nnames(medias)<-\"tasa\"\n\n  \n  # CalculamoS AUC  por cada RepeticiÃ³n de cv \n  # Definimnos funciÃ³n\n  \n  auc<-function(x,y) {\n   curvaroc<-roc(response=x,predictor=y)\n   auc<-curvaroc$auc\n   return(auc)\n  }\n  \n  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n\n  \n  \n   \n   mediasbis<-data.frame()\nfor (repi in listarep) {\npaso1<-preditest[which(preditest$Rep==repi),]\nauc=auc(paso1$obs,paso1$Yes)\nmediasbis<-rbind(mediasbis,auc)\n}\nnames(mediasbis)<-\"auc\"\n\n  \n  # Unimos la info de auc y de tasafallos\n  \n  medias$auc<-mediasbis$auc\n  \n  return(medias)\n  \n }\n```\n\n\n```{r,warning=FALSE, echo=FALSE, message=FALSE}\nmedias7<-cruzadaSVMbinRBF(data=archivo,\n                          vardep=vardep,listconti=listconti,\n                          listclass=listclass,grupos=grupos,\n                          sinicio=sinicio,repe=repe,\n                          C=10,sigma=0.05)\n\nmedias7bis<-as.data.frame(medias7[1])\nmedias7bis$modelo<-\"svmRadial\"\npredi7<-as.data.frame(medias7bis[2])\npredi7$svmRadial<-predi7$Yes\n```\n\n```{r,warning=FALSE, echo=FALSE, message=FALSE}\nunion_todos<-rbind(medias1bis,medias2bis,\n              medias3bis,medias4bis,medias5bis,medias6bis,medias7bis)\n\n\npar(cex.axis=0.8)\nboxplot(data=union_todos,tasa~modelo,col=\"pink\",main='TASA FALLOS')\nboxplot(data=union_todos,auc~modelo,col=\"pink\",main='AUC')\n\n# CONSTRUCCION DE TODOS LOS ENSAMBLADOS\n# SE UTILIZARON LOS ARCHIVOS SURGIDOS DE LAS FUNCIONES LLAMADOS predi1,...\n\nunipredi<-cbind(predi1,predi2,predi3,predi4,predi5,predi6,predi7)\n\n# Esto es para eliminar columnas duplicadas\nunipredi<- unipredi[, !duplicated(colnames(unipredi))]\n\n# Construccion de ensamblados, cambiar al gusto\n\nunipredi$predi9<-(unipredi$logi+unipredi$avnnet)/2\nunipredi$predi10<-(unipredi$logi+unipredi$rf)/2\nunipredi$predi11<-(unipredi$logi+unipredi$gbm)/2\nunipredi$predi12<-(unipredi$logi+unipredi$bagging)/2\nunipredi$predi16<-(unipredi$avnnet+unipredi$rf)/2\nunipredi$predi17<-(unipredi$avnnet+unipredi$gbm)/2\nunipredi$predi18<-(unipredi$avnnet+unipredi$bagging)/2\nunipredi$predi22<-(unipredi$rf+unipredi$gbm)/2\nunipredi$predi23<-(unipredi$rf+unipredi$bagging)/2\nunipredi$predi27<-(unipredi$gbm+unipredi$bagging)/2\nunipredi$predi31<-(unipredi$logi+unipredi$avnnet+unipredi$rf)/3\nunipredi$predi32<-(unipredi$logi+unipredi$avnnet+unipredi$gbm)/3\nunipredi$predi33<-(unipredi$logi+unipredi$avnnet+unipredi$bagging)/3\nunipredi$predi37<-(unipredi$logi+unipredi$rf+unipredi$gbm)/3\nunipredi$predi38<-(unipredi$logi+unipredi$rf+unipredi$bagging)/3\nunipredi$predi42<-(unipredi$logi+unipredi$gbm+unipredi$bagging)/3\nunipredi$predi51<-(unipredi$rf+unipredi$gbm+unipredi$logi)/3\nunipredi$predi54<-(unipredi$rf+unipredi$bagging+unipredi$gbm)/3\nunipredi$predi56<-(unipredi$rf+unipredi$avnnet+unipredi$gbm)/3\nunipredi$predi57<-(unipredi$rf+unipredi$avnnet+unipredi$bagging)/3\nunipredi$predi59<-(unipredi$rf+unipredi$avnnet+unipredi$gbm)/3\nunipredi$predi62<-(unipredi$avnnet+unipredi$gbm+unipredi$logi)/3\nunipredi$predi70<-(unipredi$logi+unipredi$gbm+unipredi$avnnet)/3\nunipredi$predi71<-(unipredi$logi+unipredi$rf+unipredi$avnnet)/3\nunipredi$predi64<-(unipredi$logi+unipredi$rf+unipredi$gbm+unipredi$avnnet)/4\nunipredi$predi65<-(unipredi$logi+unipredi$rf+unipredi$bagging+unipredi$avnnet)/4\nunipredi$predi66<-(unipredi$logi+unipredi$rf+unipredi$bagging+unipredi$avnnet)/4\nunipredi$predi68<-(unipredi$logi+unipredi$rf+unipredi$bagging+unipredi$avnnet+unipredi$gbm)/5\n\n# Listado de modelos a considerar, cambiar al gusto\n\ndput(names(unipredi))\n\nlistado<-c(\"logi\",\"avnnet\",\"rf\",\"gbm\",\"bagging\",\"predi9\", \"predi10\", \n\"predi11\", \"predi12\", \"predi17\", \"predi16\", \"predi18\", \"predi22\", \n\"predi23\", \"predi27\", \"predi31\", \"predi32\", \"predi33\", \"predi37\", \n\"predi38\", \"predi42\", \"predi51\", \"predi54\", \"predi56\", \"predi57\", \n\"predi59\", \"predi62\", \"predi70\", \"predi71\", \"predi64\", \"predi65\", \n\"predi66\", \"predi68\")\n\n# Cambio a Yes, No, todas las predicciones\n\n# Defino funcion tasafallos\n\ntasafallos<-function(x,y) {\n  confu<-confusionMatrix(x,y)\n  tasa<-confu[[3]][1]\n  return(tasa)\n}\n\nauc<-function(x,y) {\n  curvaroc<-roc(response=x,predictor=y)\n  auc<-curvaroc$auc\n  return(auc)\n}\n\n# Se obtiene el numero de repeticiones CV y se calculan las medias por repe en\n# el data frame medias0\n\nrepeticiones<-nlevels(factor(unipredi$Rep))\nunipredi$Rep<-as.factor(unipredi$Rep)\nunipredi$Rep<-as.numeric(unipredi$Rep)\n\n\nmedias0<-data.frame(c())\nfor (prediccion in listado)\n{\n  unipredi$proba<-unipredi[,prediccion]\n  unipredi[,prediccion]<-ifelse(unipredi[,prediccion]>0.5,\"Yes\",\"No\")\n  for (repe in 1:repeticiones)\n  {\n    paso <- unipredi[(unipredi$Rep==repe),]\n    pre<-factor(paso[,prediccion])\n    archi<-paso[,c(\"proba\",\"obs\")]\n    archi<-archi[order(archi$proba),]\n    obs<-paso[,c(\"obs\")]\n    tasa=1-tasafallos(pre,obs)\n    t<-as.data.frame(tasa)\n    t$modelo<-prediccion\n    auc<-auc(archi$obs,archi$proba)\n    t$auc<-auc\n    medias0<-rbind(medias0,t)\n  }\n}\n\n\n# Finalmente boxplot\n\npar(cex.axis=0.5,las=2)\nboxplot(data=medias0,tasa~modelo,col=\"pink\",main=\"TASA FALLOS\")\n\n# Para AUC se utiliza la variable auc del archivo medias0\n\nboxplot(data=medias0,auc~modelo,col=\"pink\",main=\"AUC\")\n\n# PRESENTACION TABLA MEDIAS\n\ntablamedias<-medias0 %>%\n  group_by(modelo) %>%\n  summarize(tasa=mean(tasa))     \n\ntablamedias<-tablamedias[order(tablamedias$tasa),]\ntablamedias\n\n# ORDEN DEL FACTOR MODELO POR LAS MEDIAS EN TASA\n# PARA EL GRAFICO\n\nmedias0$modelo <- with(medias0,\n                       reorder(modelo,tasa, mean))\npar(cex.axis=0.7,las=2)\nboxplot(data=medias0,tasa~modelo,col=\"pink\", main='TASA FALLOS')\n\n# ************************************\n# PARA AUC\n# ************************************\n\n# PRESENTACION TABLA MEDIAS\n\ntablamedias2<-medias0 %>%\n  group_by(modelo) %>%\n  summarize(auc=mean(auc))     \n\ntablamedias2<-tablamedias2[order(-tablamedias2$auc),]\ntablamedias2\n\n# ORDENACIÃN DEL FACTOR MODELO POR LAS MEDIAS EN AUC\n# PARA EL GRAFICO\n\nmedias0$modelo <- with(medias0,\n                       reorder(modelo,auc, mean))\npar(cex.axis=0.7,las=2)\nboxplot(data=medias0,auc~modelo,col=\"pink\", main='AUC')\n\n```\n\nDespués de validar el ensamblado, la predicción que más se rescata es \"Predi22\", la cual es una combinación entre el modelo de Random Forest y Gradient Boosting, es decir, los dos mejores modelos que hemos generado ya que ambos tenían una precisión por encima del 95%.\n\nEn conclusión, podemos definir lo siguiente:\n\n- Las características del cliente que más predominan en la selección de variables y modelo son las del comportamiento que tiene el cliente con la tarjeta, es decir, su uso en transacciones, monto, periodo de no uso, entre otros, ya que no se reportaron variables sociodemográficas o socioeconómicas significativas en el modelo predictivo.\n\n- El ensamblado ayudó a generar una mejor precisión en el modelo con un 98%, lo cual es un gran resultado para predecir quién es el cliente que puede abandonar el banco y así proactivamente mejorar los servicios o aplicar algunas estrategia para que cambie de opinión.\n\n- Los modelos más predictivos fueron Gradient Boosting, Random Forest y Bagging ya que estuvieron por encima del 95% de Accuracy, por eso el resultado tan positivo entre en el ensamblado por la combinación de dos grandes modelos.\n\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n```","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}