{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport sklearn\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read monthly and yearly data\nmth = pd.read_csv(\"../input/housing-in-london/housing_in_london_monthly_variables.csv\")\nyr = pd.read_csv(\"../input/housing-in-london/housing_in_london_yearly_variables.csv\")\n\n#set date as index for both df and delete date column (non-index)\n\nyr = yr.set_index(pd.to_datetime(yr['date']))\nmth = mth.set_index(pd.to_datetime(mth['date']))\ndel yr['date'] \ndel mth['date']\n\n# Extract London data from both dataframes. All london boroughs are marked with borough_flag = 1\nldn_yr = yr[yr['borough_flag']==1]\ndel ldn_yr['borough_flag']\nldn_mth = mth[mth['borough_flag']==1]\ndel ldn_mth['borough_flag']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Take a look at the data\n\nldn_mth.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ldn_yr.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Considering the null values present in the data-set********\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(ldn_yr.isnull().sum())\nprint('\\n')\nprint(ldn_mth.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"We proceed to group the data by area, and impute the missing values by the average value from that area. This is to ensure we don't have any null values present in dataset, since they will not fit in our algorithm."},{"metadata":{"trusted":true},"cell_type":"code","source":"ldn_yr.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that there are object columns in our dataset, which we need to convert into float/int values."},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert str values in recycling_pct to int\n\nldn_yr['recycling_pct'] = [pd.to_numeric(x, errors='coerce') for x in ldn_yr['recycling_pct']]   \n\n# Now, since our column \"code\" consists of entries like 'E09000001', \n# we'll replace the value \"E\" with \"nothing\", so that our object datatype will be converted into a float\nldn_yr['code'] = [float(x.replace('E', '')) for x in ldn_yr['code']]\n\n#mean_salary column has integers stored as strings, and also contains some '#'s. \n#By setting errors='coerce',we replace # with nan and then impute the nans.\n\nldn_yr['mean_salary'] = [pd.to_numeric(x, errors='coerce') for x in ldn_yr['mean_salary']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ldn_yr.loc[:,('life_satisfaction')] = ldn_yr.groupby('area')['life_satisfaction'].transform(lambda x: x.fillna(x.mean()))\n\n# notice city of london does not have any life_satisfaction data, so we will impute using overall mean\n\nldn_yr.loc[:, ('life_satisfaction')] = ldn_yr.loc[:, ('life_satisfaction')].fillna(ldn_yr.loc[:, ('life_satisfaction')].mean())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# repeating the imputation on other int/float columns by their group mean.\n\nldn_yr['area_size'] = ldn_yr.groupby('area').area_size.transform(lambda x: x.fillna(x.mean()))\n\nldn_yr['number_of_jobs'] = ldn_yr.groupby('area').number_of_jobs.transform(lambda x: x.fillna(x.mean()))\nldn_yr['no_of_houses'] = ldn_yr.groupby('area').no_of_houses.transform(lambda x: x.fillna(x.mean()))\n\nldn_yr['population_size'] = ldn_yr.groupby('area').population_size.transform(lambda x: x.fillna(x.mean()))\nldn_yr['median_salary'] = ldn_yr.groupby('area').median_salary.transform(lambda x: x.fillna(x.mean()))\nldn_yr['recycling_pct'] = ldn_yr.groupby('area').recycling_pct.transform(lambda x: x.fillna(x.mean()))\nldn_yr['mean_salary'] = ldn_yr.mean_salary.fillna(ldn_yr.mean_salary.mean())\n\nldn_yr.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now replace each area with a unique integer using factorize\nldn_yr.loc[:,'area'] = pd.factorize(ldn_yr.area)[0].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ldn_yr.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Incorporating monthly data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# By taking average over months of a year we incorporate monthly data into our yearly data.\nldn_mth = mth[mth['borough_flag']==1]\ndel ldn_mth['borough_flag']\ncols = ldn_mth.groupby('area').resample('Y').mean()[4:-1]\n\ncols = cols.reset_index()\n\n# factorize the areas in the columns from monthly data. Notice that the boroughs are identical\n# so factorize() will assign the same integer to the same area in both dataframes.\ncols.loc[:,'area'] = pd.factorize(cols.reset_index().area)[0].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting multiindex for both dataframes to merge\nldn_yr = ldn_yr.reset_index().set_index(['date', 'area'])\n\nimport datetime\n\ncols.date = ([(x - datetime.timedelta(30)) for x in cols.date])\ncols = cols.set_index(['date', 'area'])\ncols = cols.sort_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now merge the dataframes."},{"metadata":{"trusted":true},"cell_type":"code","source":"ldn_yr_plus = pd.merge(ldn_yr, cols, how = 'left', on = ['date','area'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#imputing missing values in no_of_crimes\nldn_yr_plus.no_of_crimes = ldn_yr_plus.groupby('area').transform(lambda x: x.fillna(x.mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ldn_yr_plus.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## House price prediction"},{"metadata":{},"cell_type":"markdown","source":"Taking our features into X, while taking our target features into y, for prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = ldn_yr_plus.reset_index()[['area', 'median_salary', 'life_satisfaction', 'population_size', 'mean_salary', 'number_of_jobs', 'no_of_houses', 'area_size', 'no_of_crimes', 'houses_sold']]\ny = ldn_yr_plus[['average_price']]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Spliting the Dataset into train and test."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.15,random_state=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nmodel=DecisionTreeRegressor(random_state=0,min_samples_split=3)\nmodel.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction=(model.predict(X_test).astype(int))\nprint(\"predictions:\",prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score\nr2_score(prediction,y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}