{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Stroke Prediction"},{"metadata":{},"cell_type":"markdown","source":"1. Importing Libraries"},{"metadata":{"trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Setting visualisation parameters\nsns.set_style('darkgrid')\ncmap = sns.cm.mako_r\n\n%matplotlib inline\n\n# Preventing warnings from libraries especially scikit learn\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Importing data and viewing basic details"},{"metadata":{"trusted":false},"cell_type":"code","source":"stroke = pd.read_csv('../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"stroke.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Viewing the shape of the data in (row, column) format\nstroke.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"stroke.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. Preprocessing Data before exploration"},{"metadata":{"trusted":false},"cell_type":"code","source":"stroke.drop(columns=['id']).describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Using **round()** to round off age.\n\n\n2. Setting values to NaN where BMI is less than 12 and greater than 60. We were told in the dataset that these values should be considered **outliers** and therefore should not be considered when building a model.\n\n\n3. We will sort the dataframe based on **gender** and then on **age** and use **forward filling** to fill out those missing BMI values."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Round off age values\nstroke['age'] = stroke['age'].apply(lambda x : round(x))\n\n# BMI to NaN\nstroke['bmi'] = stroke['bmi'].apply(lambda bmi_value: bmi_value if 12 < bmi_value < 60 else np.nan)\n\n# Sorting dataframe based on gender then on age and using forward fill-ffill() to fill NaN value for BMI\nstroke.sort_values(['gender', 'age'], inplace = True)\nstroke.reset_index(drop=True, inplace=True)\nstroke['bmi'].ffill(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"stroke.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have now converted our age column to int64 and have no missing values in our bmi column"},{"metadata":{},"cell_type":"markdown","source":"4. Exploratory data analysis"},{"metadata":{},"cell_type":"markdown","source":"1. Check if the data is balanced\n\n\n2. Plotting various graphs to check for any relation between each column\n\n    - Age vs BMI\n    - BMI vs AVG glucose level\n    - Percentage of people who had a stroke in each category"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Checking if the data is balanced\nxs = stroke['stroke'].value_counts().index\nys = stroke['stroke'].value_counts().values\n\nax = sns.barplot(xs, ys)\nax.set_xlabel(\"Stroke\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see from the plot, the data is not balanced, this will result in a badly fitted model. To resolve this issue, we need to use SMOTE to balance the data. This will be done before fitting the model."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Age vs BMI\nplt.figure(figsize = (12,8))\nax = sns.scatterplot(x=\"bmi\", y=\"age\", alpha=0.4, data=stroke[stroke['stroke']==0])\nsns.scatterplot(x = \"bmi\", y=\"age\", alpha=1, data=stroke[stroke['stroke']==1], ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above Age vs BMI plot we can clearly see that when people attain an age of 40 or greater, the chances of having a stroke increases. After age 60, it tends to increase even more. Furthermore, people with a BMI of over 20-25 have shown a greatly increased chance of having a stroke.\n\nSo, from this plot we can conclude that people who are aged over 40 and have a BMI of over 20-25 have a grater probability of having a stroke."},{"metadata":{"trusted":false},"cell_type":"code","source":"# AVG Glucose level vs BMI with hue = stroke\nplt.figure(figsize = (12,8))\nax = sns.scatterplot(x=\"bmi\", y=\"avg_glucose_level\", alpha=0.4, data=stroke[stroke['stroke']==0])\nsns.scatterplot(x=\"bmi\", y=\"avg_glucose_level\", alpha=1, data=stroke[stroke['stroke']==1], ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Percentage of people\ndef plot_percent_of_stroke_in_each_category(df, column, axis):\n    x_axis = []\n    y_axis = []\n    \n    unique_values = df[column].unique()\n    \n    for value in unique_values:\n        stroke_yes = len(df[(df[column] == value) & (df['stroke'] ==1)])\n        total = len(df[df[column] == value])\n        percentage = (stroke_yes/total) * 100\n        x_axis.append(value)\n        y_axis.append(percentage)\n        \n    sns.barplot(x_axis, y_axis, ax=axis)\n    \ncolumns = ['gender', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n\nfig, axes = plt.subplots(4, 2, figsize=(16,18))\naxes[3, 1].remove()\n\nplot_percent_of_stroke_in_each_category(stroke, 'gender', axes[0,0])\naxes[0,0].set_xlabel(\"Gender\")\naxes[0,0].set_ylabel(\"Percentage\")\n\nplot_percent_of_stroke_in_each_category(stroke, 'hypertension', axes[0,1])\naxes[0,1].set_xlabel(\"Hypertension\")\n\nplot_percent_of_stroke_in_each_category(stroke, 'heart_disease', axes[1,0])\naxes[1,0].set_xlabel(\"Heart Disease\")\naxes[1,0].set_ylabel(\"Percentage\")\n\nplot_percent_of_stroke_in_each_category(stroke, 'ever_married', axes[1,1])\naxes[1,1].set_xlabel(\"Ever Married\")\n\n\nplot_percent_of_stroke_in_each_category(stroke, 'work_type', axes[2,0])\naxes[2,0].set_xlabel(\"Work Type\")\naxes[2,0].set_ylabel(\"Percentage\")\n\nplot_percent_of_stroke_in_each_category(stroke, 'Residence_type', axes[2,1])\naxes[2,1].set_xlabel(\"Residence Type\")\n\nplot_percent_of_stroke_in_each_category(stroke, 'smoking_status', axes[3,0])\naxes[3,0].set_xlabel(\"Smoking Status\")\naxes[3,0].set_ylabel(\"Percentage\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Insights drawn from above plots**\n\n1. Both genders have around a 5% chance\n\n\n2. People with a history of hypertension and heart disease have shown an increased percentage of encountering a stroke with around a 12.5% chance and 16.5% chance respectively.\n\n\n3. Married/Divorced people have a 6.5% chance of a stroke.\n\n\n4. Self Employed people have a higher chance compared to private and government jobs. Stress induced?\n\n\n5. Rural and urban residency doesn't seem to show much of a difference.\n\n\n6. Former smokers have higher chance compared to people who have never smoked or currently smoke."},{"metadata":{},"cell_type":"markdown","source":"**5. Preparing the data for prediction**"},{"metadata":{},"cell_type":"markdown","source":"1. Converting the categorical columns into numerical by mapping each category to an integer value using **map()** on pandas series object"},{"metadata":{},"cell_type":"markdown","source":"2. As we saw earlier, the data is imbalanced. To make it balanced we will use a technique called SMOTE (Synthetic minority oversampling technique). There are other techniques available such as NearMiss algorithm.\n\n\n\n3. Splitting the data into training and testing samples."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Converting categorical data to numerical\n\ngender_dict = {'Male': 0, 'Female': 1, 'Other': 2}\never_married_dict = {'No': 0, 'Yes': 1}\nwork_type_dict = {'children': 0, 'Never_worked': 1, 'Govt_job': 2, 'Private': 3, 'Self-employed': 4}\nresidence_type_dict = {'Rural': 0, 'Urban': 1}\nsmoking_status_dict = {'Unknown': 0, 'never smoked': 1, 'formerly smoked':2, 'smokes': 3}\n\nstroke['gender'] = stroke['gender'].map(gender_dict)\nstroke['ever_married'] = stroke['ever_married'].map(ever_married_dict)\nstroke['work_type'] = stroke['work_type'].map(work_type_dict)\nstroke['Residence_type'] = stroke['Residence_type'].map(residence_type_dict)\nstroke['smoking_status'] = stroke['smoking_status'].map(smoking_status_dict)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Splitting into features and value to be predicted\nX = stroke.drop(columns=['id', 'stroke'])\ny = stroke['stroke']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2)\n\nsns.barplot(x=['0', '1'], y =[sum(y == 0), sum(y == 1)], ax = ax1)\nax1.set_title(\"Before Oversampling\")\nax1.set_xlabel('Stroke')\n\n#Using SMOTE to balance the Data\nfrom imblearn.over_sampling import SMOTE\n\nsm = SMOTE(random_state = 2) \nX, y = sm.fit_resample(X, y) \n\nsns.barplot(x=['0', '1'], y =[sum(y == 0), sum(y == 1)], ax = ax2)\nax2.set_title(\"After Oversampling\")\nax2.set_xlabel('Stroke')\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Splitting data into train and test\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=40)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**6. Creating a model for stroke prediction**"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Importing neccessary libraries\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, plot_confusion_matrix\n\npipeline = make_pipeline(StandardScaler(), RandomForestClassifier())\npipeline.fit(X_train, y_train)\nprediction = pipeline.predict(X_test)\n\nprint(f\"Accuracy Score : {round(accuracy_score(y_test, prediction) * 100, 2)}%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(classification_report(y_test, prediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plot_confusion_matrix(pipeline, X_test, y_test, cmap=cmap)\nplt.grid(False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}