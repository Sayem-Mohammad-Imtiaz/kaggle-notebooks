{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport datetime\nimport geopandas","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/etsy-shops/raw_shops.csv\")\ndf = df.drop_duplicates() # to remove duplicates in case of scrapy run several times","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(columns=['number_of_admirers','date_of_last_review_left'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def update_nan(value):\n    if value == '-':\n        return np.nan\n    if value == '':\n        return np.nan\n    return value\n\ndf = df.applymap(update_nan)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_join_date(seller_join_date):\n    pattern = '^On Etsy since ([0-9]+)$'\n    res = re.match(pattern, seller_join_date)\n    return res.group(1)\n    return seller_join_date\n    \ndef clean_number_of_sales(number_of_sales):\n    pattern = '^([0-9]+) Sale'\n    res = re.match(pattern, number_of_sales)\n    return res.group(1)\n\ndef clean_number_of_reviews(number_of_reviews):\n    pattern = '^\\(([0-9]+)\\)$'\n    res = re.match(pattern, number_of_reviews)\n    if res:\n        return res.group(1)\n    return np.nan\n\ndf['seller_join_date'] = df['seller_join_date'].map(clean_join_date, na_action='ignore')\ndf['number_of_sales'] = df['number_of_sales'].map(clean_number_of_sales, na_action='ignore')\ndf['number_of_reviews'] = df['number_of_reviews'].map(clean_number_of_reviews, na_action='ignore')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['average_review_score'] == '0'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0 actually means that Etsy just does not show the it - so make it NaN as well\ndf.loc[ (df['average_review_score'] == '0'), 'average_review_score'] = np.nan\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('shops.csv', index=False) #this is the same shops.csv from the input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def parse_location(location):\n    splitted = location.split(\",\")\n    if len(splitted) == 3:\n        return (splitted[0].strip(), splitted[2].strip())\n    elif len(splitted) == 2:\n        return (splitted[0].strip(), splitted[1].strip())\n    return (np.nan, splitted[0].strip())\n    \ndef get_town(location):\n    (town, country) = parse_location(location)\n    return town\n\ndef get_country(location):\n    (town, country) = parse_location(location)\n    return country\n\ndf['seller_town'] = df['seller_location'].map(get_town, na_action='ignore')\ndf['seller_country'] = df['seller_location'].map(get_country, na_action='ignore')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('shops_add.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## prepare geocodes\nwc = pd.read_csv(\"../input/world-cities/worldcities.csv\") # taken from https://www.kaggle.com/juanmah/world-cities\nwc = wc[['city', 'country', 'lat', 'lng']]\nwc['index'] = wc['city'] + \", \" + wc['country']\nwc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get geocodes for States\n\n# commented, as asking Nominatim takes some time\n# states = geocodes[ geocodes['seller_country'] == 'United States']['seller_town'].drop_duplicates().dropna()\n# states_geo = geopandas.tools.geocode(states.to_list(), provider='nominatim', user_agent=\"snowwlex-app\")\n# states_df = pd.DataFrame({\n#     'state_name' : states.to_list(),\n#     'lng' : states_geo['geometry'].apply(lambda p: p.x),\n#     'lat' : states_geo['geometry'].apply(lambda p: p.y)\n# })\n# states_df.to_csv('states_geocodes.csv', index=False)\n\n# so just load\nstates_df = pd.read_csv(\"../input/us-states-geocodes-by-nominatim-api/states_geocodes.csv\")\nstates_df['index'] = states_df['state_name'] + \", United States\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#combine World Cities with States-specific data:\n# as for US, it's state what is specified as 'city'\ngeo_locations = wc[ wc['country'] != 'United States' ][['index', 'lat', 'lng']].append(states_df[['index', 'lat', 'lng']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"locations = df[['seller_location', 'seller_country', 'seller_town']].drop_duplicates().dropna(subset=['seller_location'])\nlocations.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"locations[ locations['seller_country'] == 'United States'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Uniting the United Kingdom\nlocations.loc[(locations['seller_country'] == 'England'), 'seller_country'] = 'United Kingdom'\nlocations.loc[(locations['seller_country'] == 'Wales'), 'seller_country'] = 'United Kingdom'\nlocations.loc[(locations['seller_country'] == 'Scotland'), 'seller_country'] = 'United Kingdom'\nlocations.loc[(locations['seller_country'] == 'Northern Ireland'), 'seller_country'] = 'United Kingdom'\n\nlocations['index'] = locations['seller_town'] + \", \" + locations['seller_country']\nlocations.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"locations_joined = locations.set_index('index').join(geo_locations.set_index('index'), how='inner')\nlocations_joined[ locations_joined['seller_country'] == 'United Kingdom'].sample(n=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"locations_joined[ locations_joined['seller_country'] == 'United States'].sample(n=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"locations_joined[ locations_joined['seller_country'] == 'United States']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_locations = locations_joined.reset_index()[['seller_location', 'lng', 'lat']]\nall_locations.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_locations.to_csv('all_locations.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}