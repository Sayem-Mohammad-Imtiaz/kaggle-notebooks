{"cells":[{"metadata":{"_uuid":"48a4fd84-95dd-4e3e-9089-44b6309c9d15","_cell_guid":"26dfbf24-3bfe-44b2-b368-ad41c3aac3e1","trusted":true},"cell_type":"markdown","source":"<html>\n     <body>\n         <p><font size=\"6\" color=\"white\">Sign Language MNIST with CNN in Tensorflow 2.0 & Image Aumentation.</font></p>\n     </body>     ![tensorflow](https://www.gstatic.com/devrel-devsite/v0bcab1972c3b1579b82e221c810ad3eb061cbd75c8520328bda82087ceb07528/tensorflow/images/lockup.svg)"},{"metadata":{"_uuid":"ed6b79c5-8fc5-43e8-a1c8-4d02d52ad4a8","_cell_guid":"e4f88673-f9fb-41ed-b0ad-b052d7758008","trusted":true},"cell_type":"markdown","source":"The idea of this notebook it to predict Sign language competion using TF 2.0 (keras) and Data augmentation"},{"metadata":{"_uuid":"600f23a4-bbe5-4643-b34a-125a765efe80","_cell_guid":"35fb1485-deb7-46fb-82ca-3f87dcac5dce","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport numpy as np\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport pandas as pd\n\nprint(tf.__version__)\nprint(os.listdir('../input/'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05163e6f-ac00-435d-930b-c3afe266df77","_cell_guid":"0c9f2e9f-b0fa-458f-868e-f06d49a3cf5e","trusted":true},"cell_type":"markdown","source":"##  Define the Directory and Files"},{"metadata":{"_uuid":"7d732e28-4f7f-4f9a-8e61-27953c1caa4c","_cell_guid":"5a1e0d65-767b-4837-85ab-f04a46082871","trusted":true},"cell_type":"code","source":"name_file_train = 'sign_mnist_train.csv'\nname_file_test ='sign_mnist_test.csv'\ndirectory = '../input/sign-language-mnist/'\n\nfile_train = os.path.join(directory,name_file_train)\nfile_test = os.path.join(directory, name_file_test)\n\nprint(directory)\nprint(file_train)\nprint(file_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5dfa87e4-d6c3-4f49-983a-a9fbe9611164","_cell_guid":"5b3b0288-d37e-4bf5-9a18-970ab7b20d0c","trusted":true},"cell_type":"markdown","source":"### Get_data function\n It is function that recieve the filename path and **return two objets**.\n 1.  training images\n 2.  label images\n \nThe task it was to created:\n 1. a dataframe from file using pandas library\n 2. isolate the column label.\n 3. Get the array images\n 4. Transform the list on np.array and gives them it a 28 to 28 shape for each line\n"},{"metadata":{"_uuid":"e1ccaf29-09df-4cce-9179-2456511ede17","_cell_guid":"fcb258e9-41c4-4e28-9df8-a752e1fe8e8c","trusted":true},"cell_type":"code","source":"def get_data(filename):\n    df = pd.read_csv(filename, header=0)\n    labels= np.array(df.iloc[:,0].values)\n    imgs = df.iloc[:,1:].values\n    data = []\n    for img in imgs:\n        tmp =np.array( np.array_split(img,28))\n        data.append(tmp)\n    \n    data = np.array(data).astype('float')    \n    return data, labels\n\ntraining_images, training_labels = get_data(file_train)\ntesting_images, testing_labels = get_data(file_test)\n\nprint(training_images.shape)\nprint(training_labels.shape)\nprint(testing_images.shape)\nprint(testing_labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea6098ba-c9fa-4cfe-891c-34218df5690e","_cell_guid":"f7e2c7a8-da32-4c79-a587-f30826d0679c","trusted":true},"cell_type":"markdown","source":"### Expand Dimension\n\n We define the Matrix on Training and Label. We need to include the color channel (a new dimension) and the because is black and white the value of the channel it is one."},{"metadata":{"_uuid":"db0116ac-422b-43d1-b6eb-b23e89513962","_cell_guid":"c31a9e6b-d90b-452e-981e-b02274f6d525","trusted":true},"cell_type":"code","source":"training_images = np.expand_dims(training_images,axis=3)\ntesting_images = np.expand_dims(testing_images,axis=3)\n\nprint(training_images.shape)\nprint(testing_images.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2eb03b4f-33d2-47e2-8249-a97c8c54d3a0","_cell_guid":"e6ffed47-dc14-4ebb-86a5-58c670e94e43","trusted":true},"cell_type":"markdown","source":"### Image Generation\n\n We use the ImageDataGenerator, this class not override the information of the folder. Only expand the information on memory. \n We rotate, shift and zoom. And we fill the picture on the transformation with the neares picture."},{"metadata":{"_uuid":"7aff5ebb-edd6-47a0-af29-1fafea58852f","_cell_guid":"e9b421a7-70b1-447b-8f52-8507d71d84d2","trusted":true},"cell_type":"code","source":"# Create an ImageDataGenerator \n# and do Image Augmentation\ntrain_datagen = ImageDataGenerator(\n    rescale=1.0/255.0,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2, \n    horizontal_flip=True,\n    fill_mode='nearest'\n    )\n\nvalidation_datagen = ImageDataGenerator(\n    rescale=1.0/255.0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2131e73f-da00-4ca0-8046-54872d5bbfa5","_cell_guid":"7116a52a-94b5-4e08-95d5-01a032abbc32","trusted":true},"cell_type":"markdown","source":"### Sequential Model\n We create 3 convolutional layers each oneÂ´s with their on MaxPooling. Before to create the Dense Layer we Dropout a twenty percent to avoid overfitting"},{"metadata":{"_uuid":"922e3d4e-3fe0-41bd-b5eb-64a18c853d77","_cell_guid":"1bbf469a-0b6c-4461-b9b1-48071e418871","trusted":true},"cell_type":"code","source":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32,(3,3), activation='relu', input_shape=(28,28,1)),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Conv2D(64,(3,3), activation='relu'),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Conv2D(128,(3,3), activation='relu'),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(1024, activation='relu'),\n    tf.keras.layers.Dense(26, activation='softmax')    \n])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b28e5f56-7a3a-4b2d-8517-47b0910996b1","_cell_guid":"2cc28e12-e4d1-49cc-b599-d57ffa793f9c","trusted":true},"cell_type":"markdown","source":"### Model Compilation and Monitoring variables\n The compilation that we use is 'adam' or we can consider other that work we momentun. (not GD)"},{"metadata":{"_uuid":"b0b43214-933f-480c-934a-ab5b74a7c964","_cell_guid":"f8081814-ce7a-411e-8087-9610e98b41ab","trusted":true},"cell_type":"code","source":"# Compile Model. \nmodel.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Train the Model\nhistory = model.fit_generator(\n    train_datagen.flow(training_images,training_labels,batch_size=32),\n    steps_per_epoch=len(training_images)/32,\n    epochs=50,\n    validation_data=validation_datagen.flow(testing_images, testing_labels, batch_size=32),\n    validation_steps=len(testing_images)/32\n                             )\n\nmodel.evaluate(testing_images, testing_labels)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d1b49f50-f6ca-4e01-b390-cfe73746049b","_cell_guid":"62f8c586-7bb2-4b78-9f57-a65655413ef9","trusted":true},"cell_type":"markdown","source":"### visualization\n We visualize the training and validation history"},{"metadata":{"_uuid":"36851958-08d5-4f87-b60e-e2443bde7d11","_cell_guid":"6aa4b39f-154e-4a9d-ac4b-9269404a7795","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}