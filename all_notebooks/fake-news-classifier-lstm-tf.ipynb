{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import Libs"},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sb\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport tensorflow\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense ,LSTM ,Embedding , Dropout\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk import word_tokenize , sent_tokenize\nimport re\nimport string\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score , confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/traindata/train.csv')\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Drop NaN"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(inplace = True)\ndf.reset_index(inplace =True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Since , there are 20k records , Training a LSTM model took me around 2hr with CPU , So here am going to cut short it to 8k"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.sample(frac = 1).reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.head(8000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df[['title' , 'author' , 'text']]\ny = df['label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.shape , y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tensorflow.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preprocessing\nimport time\ns = time.time()\ncorpus = []\nfor i in range(len(x)):\n    if i+1 % 100 == 0:\n        print(i)\n    \n    text = re.sub('[^a-zA-Z]' , \" \", x['text'][i])\n    text = text.lower()\n    text = text.split()\n    \n    word = [words for words in text if words not in stopwords.words('english') ]\n    word = \" \".join(word) \n    corpus.append(word)\nprint('done')\nprint((time.time() - s)*1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#one hot\nvoc_size =6000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one_hot_sentence = [one_hot(words , voc_size) for words in corpus]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one_hot_sentence[:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to make fixed length\nmax_length_of_sent = 50\nembedding_sent = pad_sequences(one_hot_sentence,padding='pre' , maxlen=max_length_of_sent)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_sent[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(embedding_sent[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(embedding_sent)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(x) , len(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_feature_size = 256\n#after taking input , how much should be length of feature vector after passing into model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#make model\nmodel = Sequential()\nmodel.add(Embedding(voc_size , embedding_feature_size , input_length = max_length_of_sent ))\nmodel.add(LSTM(256 , return_sequences = True))\nmodel.add(Dropout(0.4))\nmodel.add(LSTM(128))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(1 , activation = 'sigmoid'))\nmodel.compile(loss = 'binary_crossentropy',metrics = ['accuracy'],optimizer = 'adam')\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array(embedding_sent)\nY = np.array(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape , y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train , x_test , y_train , y_test = train_test_split(X ,Y,test_size = 0.25 , random_state =100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train\nhistory = model.fit(x_train , y_train , validation_data = (x_test , y_test) , epochs =10 , batch_size= 128)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['accuracy'] , label = 'train_acc')\nplt.plot(history.history['val_accuracy'] , label = 'val_acc')\nplt.legend()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'] , label = 'train_loss')\nplt.plot(history.history['val_loss'] , label ='val_loss')\nplt.legend()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict_classes(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_pred , y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_pred, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## We get 85 % accuracy just for 10 epochs !"},{"metadata":{},"cell_type":"markdown","source":"# User's input"},{"metadata":{"trusted":true},"cell_type":"code","source":"user_inp = 'There were many forest fire and Trump was seen dancing there :)'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preprocessing\nimport time\ns = time.time()\ncorpus = []\n\ntext = re.sub('[^a-zA-Z]' , \" \", user_inp)\ntext = text.lower()\ntext = text.split()\n\nword = [words for words in text if words not in stopwords.words('english') ]\nword = \" \".join(word) \ncorpus.append(word)\nprint('done')\nprint((time.time() - s)*1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_one_hot = [one_hot(words , voc_size) for words in corpus]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_one_hot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to make fixed length\nmax_length_of_sent = 50\nembedding_sent_user = pad_sequences(user_one_hot,padding='pre' , maxlen=max_length_of_sent)\nembedding_sent_user","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check = np.array(embedding_sent_user)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.predict_classes(check)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1 - Represent Fake , Model working fine :)"},{"metadata":{},"cell_type":"markdown","source":"## If you find this notebook useful , please upvote and leave a comment ! Thank you :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}