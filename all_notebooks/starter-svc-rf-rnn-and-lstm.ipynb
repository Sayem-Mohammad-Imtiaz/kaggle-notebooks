{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/full_dataset.csv',sep=';')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## importing everything that we're going to need!\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Embedding, SpatialDropout1D, LSTM, SimpleRNN\nfrom keras.layers.wrappers import Bidirectional\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.utils import to_categorical\n\nfrom gensim import corpora\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def replace_tags(list_of_tokens: list) -> list:\n    \n    treated_tokens = []\n    for token in list_of_tokens:\n        if token == '?':\n            treated_tokens.append('<QST_MARK>')\n        elif token == '!':\n            treated_tokens.append('<EXC_MARK>')\n        else:\n            treated_tokens.append(token)\n            \n    return treated_tokens \n\ndef pad_sequence(list_of_treated_tokens: list, max_len: int) -> list:\n    \n    actual_len = len(list_of_treated_tokens)\n    if actual_len < max_len:\n        padded_list = ['<PAD>' for _ in range(max_len-actual_len)] + list_of_treated_tokens\n    elif actual_len > max_len:\n        padded_list = list_of_treated_tokens[:max_len]\n    else:\n        padded_list = list_of_treated_tokens\n        \n    return padded_list\n    \ndef pre_processing(text: str) -> str:\n    text = re.sub('([!?])',r' \\1 ',text)\n    text = text.lower().split()\n    \n    ## adding tokens\n    list_with_tokens = replace_tags(text)\n    \n    ## padding the sentence\n    padded_list = pad_sequence(list_with_tokens,max_len=30)\n       \n    return padded_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## applying pre_processing\n\ndf['text_tratado'] = df.title.apply(pre_processing)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## encoding using a simple bow model\n\nencoder = corpora.Dictionary(df.text_tratado)\n\nx = np.array([encoder.doc2idx(s) for s in df.text_tratado])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## defining y\ny = df.label\ny_ann = to_categorical(y.map({'python':0,'java':1,'R':2,'javascript':3,'php':4}),5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## train test\n\nx_train,x_valid,y_train,y_valid = train_test_split(x,y_ann,test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVC and RandomForestClassifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_val_score(SVC(),x,y,cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_val_score(RandomForestClassifier(500),x,y,cv=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bidirectional LSTM and RNN","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## defining the model\n\nmodel = Sequential()\nmodel.add(Embedding(x.shape[1],64))\nmodel.add(SpatialDropout1D(0.2))\nmodel.add(Bidirectional(LSTM(256, dropout=0.2)))\nmodel.add(Dense(32,activation= 'relu'))\nmodel.add(Dense(16,activation= 'relu'))\nmodel.add(Dense(8,activation= 'relu'))\nmodel.add(Dense(5, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_train,y_train,batch_size = 32, epochs = 10, validation_data = (x_valid,y_valid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = Sequential()\nmodel2.add(Embedding(x.shape[1],64))\nmodel2.add(SpatialDropout1D(0.2))\nmodel2.add(SimpleRNN(256, dropout=0.2))\nmodel2.add(Dense(32,activation= 'relu'))\nmodel2.add(Dense(16,activation= 'relu'))\nmodel2.add(Dense(8,activation= 'relu'))\nmodel2.add(Dense(5, activation='softmax'))\n\nmodel2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel2.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.fit(x_train,y_train,batch_size = 32, epochs = 10, validation_data = (x_valid,y_valid))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}