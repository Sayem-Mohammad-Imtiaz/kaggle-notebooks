{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read Data."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\nmpl.rcParams['figure.figsize'] = (15, 7)\nmpl.rcParams['axes.grid'] = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mpl.rcParams['figure.figsize'] = (20, 7)\nmpl.rcParams['axes.grid'] = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/sunspots/Sunspots.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see from info, Date column is stored as object i.e. string data type . Date column must be converted into datatime format which makes it easier for working with date and time data.There is an unnecessary column named 'Unnamed :0' which has to be removed.\n\n* df['Date']=pd.to_datetime(df['Date']) <-- can be used to convert a column to into datetime data type column\n* pd.drop can be used for dropping the unnnecesary column\n* Here, I am using 'usecols' argument inside pd.read_csv for selecting only required column.\n* 'parse_date', & 'date_parser' arguments for converting Date column into datetime data type.\n* inside 'parse_data, we have to pass the column to be conveted into datetime, here, it is 'Date' column.\n* 'dateparse' function below is requied which is basically converting any argument passed to it into datetime data type . This is given to * 'data_parser' inside pd.read_csv.\n* check the documentation of pd.read_csv, there are more than 15 arguments, which can be used to perform many operations while importing the data itself."},{"metadata":{"trusted":true},"cell_type":"code","source":"from dateutil.parser import parse\ndateparse=lambda dates:parse(dates)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/sunspots/Sunspots.csv',usecols=['Date','Monthly Mean Total Sunspot Number'],parse_dates=['Date'],date_parser=dateparse)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info() ## Checking the info again : data type of Date column --> has conveted into datetime","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_non_index=df.copy() # Making a copy of initial data.Both will be used as required\n# The 'df_non_index' dataframe is used for some exploratory data analysis  \n# Later we will convert Date colum as index in  'df' dataframe.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Profit of datetime formated data:\n\n* You can do lot of date and time related operations easily without doing string opeations.\n* Here month is seprated and kept in another column named month so easily\n* Afeter that year is seperated and used."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_non_index['Month']=df_non_index.Date.dt.month\ndf_non_index.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The following code is extracting the each year of the decade, for example in string '1749' last character i.e. (3rd positional) is year 9 of that decade, which has been extracded and kept in another column named 'nth_year.\n* for '1748' it wil be year 8.\n* But for '1750' it will be year '0' which has to be 10. Thus .replace('0','10') is applied and finally converted back into intger by type casting."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_non_index['nth_year'] =[int(str(i)[3]) for i in (df_non_index.Date.dt.year)] # Note this is list comprehension \ndf_non_index['nth_year'].replace(0,10,inplace=True)\ndf_non_index.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plotting the data using seaborn boxplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(3, 1, figsize=(20,15), dpi= 80)\nsns.boxplot(x='Date', y='Monthly Mean Total Sunspot Number', data=df_non_index, ax=axes[0])\nsns.boxplot(x='Month', y='Monthly Mean Total Sunspot Number', data=df_non_index,ax = axes[1])\nsns.boxplot(x='nth_year', y='Monthly Mean Total Sunspot Number', data=df_non_index,ax = axes[2])\n# Set Title\naxes[0].set_title('Year-wise Box Plot\\n(The Trend)', fontsize=14); \naxes[1].set_title('Month-wise Box Plot\\n(The Seasonality)', fontsize=14)\naxes[2].set_title('nth_year_each_decade\\n(The Seasonality)', fontsize=14)\nfig.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Eplanation of above plot:\n\n* The distribution of data is almost same in each month with few outliers\n* The distribution of data among each year of the decades are not same .\n## Returing back to dataframe 'df' and Making Date column as index\n\n* Once we make Date column as index,it is very easy to slice the data based on index (i.e. date) and even plotting in pandas with datetime column as index is easy."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.set_index('Date')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.plot(grid=True) # plots in pandas itself take index as x axis, here it is datetime and y axis is  'Monthly Mean Total Sunspot Number'\n#  This plot is same to that of previous first box plot (that was a scatter plot, here it dots are joined )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The data is too to large to see it in a one graph, there are 3235 monthly entries from date 1749-01-31 to 2018-07-31.\n\n* One way to slice the data and visualise any particular time zone.\n* Plotly express provide slider and button to select particular time zone.\n* Checking both:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2018=df.loc['2000':'2010'] # Slicing all data from 2000 to 2010\ndf_2018.plot(figsize=(16,7),grid=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2018=df.loc['1900':'1920'] # Slicing all data from 1900 to 1910\ndf_2018.plot(figsize=(16,7),grid=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## plotly express"},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px  \nfig = px.line(df_non_index, x='Date', y='Monthly Mean Total Sunspot Number', title='Mean_Sunspot_Slider')\nfig.update_xaxes(rangeslider_visible=False)\nfig.show()\n## There is slider belwo the graph using which we can select any particular time zone","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Buttons options in plotly"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.line(df_non_index, x='Date', y='Monthly Mean Total Sunspot Number', title='Mean_Sunspot_Slider')\n\nfig.update_xaxes(\n    rangeslider_visible=False,\n    rangeselector=dict(\n        buttons=list([\n            dict(count=10, label=\"10y\", step=\"year\", stepmode=\"backward\"),\n            dict(count=20, label=\"20y\", step=\"year\", stepmode=\"backward\"),\n            dict(count=30, label=\"30y\", step=\"year\", stepmode=\"backward\"),\n            dict(count=40, label=\"40y\", step=\"year\", stepmode=\"backward\"),\n            dict(count=50, label=\"50y\", step=\"year\", stepmode=\"backward\"),\n            dict(step=\"all\")\n        ])\n    )\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_non_index.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Comparison of two consecutive 11 year: How to choose from where to where?\n* In above graph we can see the pattern is repeating after 11 year approx, choose the time to match any two reapeated pattern"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_11_1985=df_non_index[(df_non_index.Date.dt.year>=1985) & (df_non_index.Date.dt.year<1996)]\ndf_11_1996=df_non_index[(df_non_index.Date.dt.year>=1996) &(df_non_index.Date.dt.year<2007)]\n\nx=np.arange(1,len(df_11_1996['Date'])+1)\n\nplt.plot(x, df_11_1985['Monthly Mean Total Sunspot Number'],label='df_60_1998')\nplt.plot(x, df_11_1996['Monthly Mean Total Sunspot Number'],label='df_60_1958')\nplt.legend()\nplt.xlabel('Month')\nplt.ylabel('Monthly Mean Total Sunspot Number')\nplt.title('Comparison of Two consecutive 11 year')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lag plot\n\n* It helps to understand the autocorrelation lag, visualizing for few, normally lag greater than 4 is not useful.\n* As we increase the lag time, the correlation is decresing.\n* The data is correlated with its recet time lag upt 4/5 time lag."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(18,6))\nfig.subplots_adjust(hspace=0.4, wspace=0.2)\nax1=fig.add_subplot(2,2,1)\npd.plotting.lag_plot(df['Monthly Mean Total Sunspot Number'],lag=1)\nplt.title('Lag_1')\nax2=fig.add_subplot(2,2,2)\npd.plotting.lag_plot(df['Monthly Mean Total Sunspot Number'],lag=3)\nplt.title('Lag_3')\nax3=fig.add_subplot(2,2,3)\npd.plotting.lag_plot(df['Monthly Mean Total Sunspot Number'],lag=6)\nplt.title('Lag_6')\nax3=fig.add_subplot(2,2,4)\npd.plotting.lag_plot(df['Monthly Mean Total Sunspot Number'],lag=24)\nplt.title('Lag_24')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Checking the distribution by making histogram and kde plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(18,6))\nfig.subplots_adjust(hspace=0.4, wspace=0.2)\nax1=fig.add_subplot(1,2,1)\ndf['Monthly Mean Total Sunspot Number'].hist()\nplt.title('Histogram')\nax2=fig.add_subplot(1,2,2)\ndf['Monthly Mean Total Sunspot Number'].plot(kind='density')# kernel density plot\nplt.title('KDE')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Checking Stationarity of Time Series Data\n* From the plot of data we can see that the it is stationary, though we have to check it statistically. ### Check Stationarity of a Time Series\n\nA TS is said to be stationary if its statistical properties such as mean, variance remain constant over time. But why is it important? Most of the TS models work on the assumption that the TS is stationary. Intuitively, we can state that if a TS has a particular behaviour over time, there is a very high probability that it will follow the same in the future. Also, the theories related to stationary series are more mature and easier to implement as compared to non-stationary series.\n\nStationarity is defined using very strict criterion. However, for practical purposes we can assume the series to be stationary if it has constant statistical properties over time, ie. the following:\n\n* constant mean (For different time slots)\n* constant variance (For different time slots)\n* (Rolling mean/variance should be checked and should be constant)\n* an autocovariance that does not depend on time\n* Two test for stationarity: ADF & KPSS test\n\nhttps://www.statsmodels.org/stable/examples/notebooks/generated/stationarity_detrending_adf_kpss.html\n\n## Perform Augumented Dickey-Fuller test:\nDickey-Fuller Test: This is one of the statistical tests for checking stationarity. Here the null hypothesis is that the TS is non-stationary. The test results comprise of a Test Statistic and some Critical Values for difference confidence levels. If the ‘Test Statistic’ is less than the ‘Critical Value’, we can reject the null hypothesis and say that the series is stationary.\n\n* Null Hypothesis - Series is not stationary\n\n* Alternate Hypothesis - Series is stationary"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_series=df['Monthly Mean Total Sunspot Number']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Results of Dickey-Fuller Test:')\ndftest = adfuller(data_series, autolag='AIC')\ndfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\nfor key,value in dftest[4].items():\n    dfoutput['Critical Value (%s)'%key] = value\nprint(dfoutput)\nif dfoutput['Test Statistic'] < dfoutput['Critical Value (5%)']:  ## Comparing with 5% significant Level\n  print('Series is stationary')\nelse:\n  print('Series is not Stationary')\n## OR \nif dfoutput[1] > 0.05 :\n  print('Series is not Stationary')\nelse:\n  print('Series is Stationary')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## KPSS test for stationary: This another test\n* Null hypothesis - Series is stationary\n* Alternate hypothesis - Series is not stationary"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import kpss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stats, p, lags, critical_values = kpss(df['Monthly Mean Total Sunspot Number'], 'c',nlags='legacy')\n## pass --> 'ct' if there is trend component in data \n## pass --> 'c' if there is no trend component in data. In this case there is not trend in the data being stationary data.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Test Statistics: {stats}')\nprint(f'p-value: {p}')\nprint(f'Critial Values: {critical_values}')\n\nif p < 0.05 :\n  print('Series is not Stationary')\nelse:\n  print('Series is Stationary')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Note: For Non-Stationary data: First make it stationary**\n* Differencing, Taking log and Differencing, Decompostion in components and detrending are few techniques are used.\n# 3. Modelling Time Series\n**There are many ways to model a time series in order to make predictions.Few are discussed here:**\n* Different Moving Averages\n* Exponential Smoothing\n* ARIMA\n* SARIMA\n## Rolling Statistics:\nWe can plot the moving average or moving variance and see if it varies with time. By moving average/variance I mean that at any instant ‘t’, we’ll take the average/variance of the last year, i.e. last 12 months. But again this is more of a visual technique :\n\n**Rolling Average OR Simple moving average = (t + (t-1) + (t-2) + ... + (t-n)) / n**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Monthly Mean Total Sunspot Number'][:200].plot() # Checking for only first 200 data set\ndf['Monthly Mean Total Sunspot Number'][:200].rolling(3).mean().plot(label='rolling mean') ## rolling average with 3 time step also known as window\n#df['Monthly Mean Total Sunspot Number'][:200].rolling(3).std().plot(label='rolling std')\nplt.legend()\nplt.title('Rolling Mean & Standard Deviation')\n## df['Monthly Mean Total Sunspot Number'].rolling(12).mean().shift(1) # Rolling mean with shift\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Weighted moving average\n### Weighted moving average = (tweighting factor) + ((t-1)weighting factor-1) + ((t-n) * weighting factor-n)/n\n* This is similar as rolling average except, we multiply with weighting factor so that more weight is given to recent data.\n* this function is not availbele, we have to make our own"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Making a function for calculating weighted average which is passed through .apply()\ndef wma(weights): \n    def calc(x):\n        return (weights*x).mean()\n    return calc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Monthly Mean Total Sunspot Number'][:200].plot() # Checking for only first 200 data set\ndf['Monthly Mean Total Sunspot Number'][:200].rolling(3).apply(wma(np.array([0.5,1,1.5]))).plot(label='weighted mooving_averate')\n#  Here inside wma 3 weights are passed since we are taking 3 time step only as window.\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exponential moving average\\Exponential Smoothing\n\n\n* https://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average #### * Luckly there is a function for this in pandas."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Monthly Mean Total Sunspot Number'][:200].plot() # Checking for only first 200 data set\ndf['Monthly Mean Total Sunspot Number'][:200].ewm(span=3, adjust=False, min_periods=3).mean().plot(label='Exponential Weighted Average')\n## Here span=3 is provide thus α=2/(span+1) automatically calculated and applied\n## https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.ewm.html\nplt.title('Exponential Weighted M.A.')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Providing alpha for Smoothing"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Monthly Mean Total Sunspot Number'][:200].plot() # Checking for only first 200 data set\ndf['Monthly Mean Total Sunspot Number'][:200].ewm(alpha=0.7, adjust=False, min_periods=3).mean().plot(label='Exponential Smooting M A')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting All together and comparing"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_with_diff_avg=df[:200].copy()\ndf_with_diff_avg['Rolling mean']=df['Monthly Mean Total Sunspot Number'][:200].rolling(3).mean()\ndf_with_diff_avg['W_M_A']= df['Monthly Mean Total Sunspot Number'][:200].rolling(window=3).apply(wma(np.array([0.5,1,1.5])))\ndf_with_diff_avg['E_W_A']= df['Monthly Mean Total Sunspot Number'][:200].ewm(span=3, adjust=False, min_periods=0).mean()\ndf_with_diff_avg['E_S_M_A']= df['Monthly Mean Total Sunspot Number'][:200].ewm(alpha=0.7, adjust=False, min_periods=3).mean()\nprint(df_with_diff_avg.head())\n#df_with_diff_avg.set_index('Date', inplace=True)\ndf_with_diff_avg.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_with_diff_avg.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_with_diff_avg.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Making a function for comparing RMSE in all above modelling\n* We can see exponential smoothing Moving average has lowest RMSE.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def RMSE_CAL(df):\n      Rolling_Mean_RMSE=np.sqrt(np.sum((df.iloc[:,0]-df.iloc[:,1])**2))\n      W_M_A_RMSE=np.sqrt(np.sum((df.iloc[:,0]-df.iloc[:,2])**2))\n      E_W_A_RMSE=np.sqrt(np.sum((df.iloc[:,0]-df.iloc[:,3])**2))\n      E_S_M_A_RMSE=np.sqrt(np.sum((df.iloc[:,0]-df.iloc[:,4])**2))\n      return {\"Rolling_Mean_RMSE\":Rolling_Mean_RMSE,\"W_M_A_RMSE\":W_M_A_RMSE,\"E_W_A_RMSE\":E_W_A_RMSE,\"E_S_M_A_RMSE\":E_S_M_A_RMSE}\nRMSE_CAL(df_with_diff_avg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Decomposing a Time_Series Data"},{"metadata":{},"cell_type":"markdown","source":"****NOTE: This operation is not required for this data as it is stationary but while working with non-stationary data this step may required.****\n* Systematic: Components of the time series that have consistency or reocurrence and can be described and modeled as level,trend, seasonality.\n* Non-Systematic: Components of the time series that cannot be directly modeled is noise/residual.\nThese components are defined as follows:\n\n* Level: The average value in the series.\n* Trend: The increasing or decreasing value in the series.\n* Seasonality: The repeating short-term cycle in the series.\n* Noise: The random variation in the series.\n       \n       So a time series is thought to be an aggregate or combination of these four components. \n       All series have a level and noise. The trend and seasonality components are optional. \n       It is helpful to think of the components as combining either additively or multiplicatively as given by relation below:\n\n* y(t) = Level + Trend + Seasonality + Noise\n* y(t) = Level * Trend * Seasonality * Noise"},{"metadata":{},"cell_type":"markdown","source":"### Since our data is stationary we will use additive decomposition"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Additive decomposition\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nresult = seasonal_decompose(df['Monthly Mean Total Sunspot Number'], model=\"additive\",freq=11*12) # Data Trend is repeated after every 11 year,freq=11*12\nresult.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### checking the definition of decompostion for additive nature time series data\n* y(t) = Trend + Seasonality + Noise"},{"metadata":{"trusted":true},"cell_type":"code","source":"total_sum=result.trend+result.seasonal+result.resid\ntotal_sum[:100] # compare this result with original Sunspot data ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Monthly Mean Total Sunspot Number'][:100]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Detrended Data :\n* Since our data is additive in nature we are going to subtract the trend from observed value and get the detrended data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(result.observed-result.trend).plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Autocorrelation plot\n* We can assume the distribution of each variable fits a Gaussian (bell curve) distribution. If this is the case, we can use the Pearson’s correlation coefficient to summarize the correlation between the variables.\n\n* The Pearson’s correlation coefficient is a number between -1 and 1 that describes a negative or positive correlation respectively. A value of zero indicates no correlation.\n\n* We can calculate the correlation for time series observations with observations with previous time steps, called lags. Because the correlation of the time series observations is calculated with values of the same series at previous times, this is called a serial correlation, or an autocorrelation.\n\n* A plot of the autocorrelation of a time series by lag is called the AutoCorrelation Function, or the acronym ACF. This plot is sometimes called a correlogram or an autocorrelation plot.\n\n* This helps us to find if current value depends on previous values. In the plot you can observe that current value is dependent on previous 120-130 values. This can be around 10/11 years as it is monthly data."},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.plotting.autocorrelation_plot(df['Monthly Mean Total Sunspot Number']) ## for each month\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Monthly Mean Total Sunspot Number'].resample(\"1y\").mean() ## Resample based on 1 year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.plotting.autocorrelation_plot(df['Monthly Mean Total Sunspot Number'].resample(\"1y\").mean())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ACF and PACF plots:\n* Running the example creates a 2D plot showing the lag value along the x-axis and the correlation on the y-axis between -1 and 1.\n\n* Confidence intervals are drawn as a cone. By default, this is set to a 95% confidence interval, suggesting that correlation values outside of this code are very likely a correlation and not a statistical fluke.\n\n* acf: By looking at the plot we can improvise our understanding from above plot and say that present value depends on previous 25-30 values.\n\n* pacf plot further says that present value depends only on previous 5/6 values. All these plots help us narrow down thinking and make our model efficient."},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import acf, pacf\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Draw Plot\nplot_acf(df['Monthly Mean Total Sunspot Number'].tolist(), lags=20, ax=axes[0])\nplot_pacf(df['Monthly Mean Total Sunspot Number'].tolist(), lags=20, ax=axes[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Auto ARIMA"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pmdarima","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pmdarima as pm\nfrom pmdarima.model_selection import train_test_split\n\nmodel = pm.auto_arima(df['Monthly Mean Total Sunspot Number'], \n                        m=11, seasonal=True,\n                      start_p=0, start_q=0, max_order=4, test='adf',error_action='ignore',  \n                           suppress_warnings=True,\n                      stepwise=True, trace=True) \n ## actually we have to set m=11*12,but it take too much time and it doesnt matter much. Source Given below:\n # https://robjhyndman.com/hyndsight/longseasonality/\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split tha data into train and test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.reset_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=df[(df.Date.dt.year<1958)]\ntest=df[(df.Date.dt.year>=1958)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(df.Date.dt.year>=1958) & (df.Date.dt.year<1968)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1=df[(df.Date.dt.year>=1958) & (df.Date.dt.year<1968)]\nn=len(test1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train['Monthly Mean Total Sunspot Number'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast=model.predict(n_periods=n, return_conf_int=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast_df = pd.DataFrame(forecast[0],index = test1.index,columns=['Prediction'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.concat([df['Monthly Mean Total Sunspot Number'],forecast_df],axis=1).plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The result may not seem accurate but, note that time series forecasting is not reasonable for many time step ahead. It may be valid only for 1,2 or few more time step ahead in future.**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}