{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-14T02:18:24.970343Z","iopub.execute_input":"2021-06-14T02:18:24.970781Z","iopub.status.idle":"2021-06-14T02:18:24.990648Z","shell.execute_reply.started":"2021-06-14T02:18:24.97069Z","shell.execute_reply":"2021-06-14T02:18:24.989458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Import all Packages**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport keras\nfrom keras import backend as K\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom matplotlib import pyplot\nfrom statistics import mean\nimport glob\nimport os\nimport cv2\nimport sys","metadata":{"execution":{"iopub.status.busy":"2021-06-14T02:18:27.091715Z","iopub.execute_input":"2021-06-14T02:18:27.092047Z","iopub.status.idle":"2021-06-14T02:18:32.759712Z","shell.execute_reply.started":"2021-06-14T02:18:27.092019Z","shell.execute_reply":"2021-06-14T02:18:32.758784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Load the Dataset**","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"../input/letterrecognition-using-svm/letter-recognition.csv\",header=0)# header 0 means the first row is name of the coloumn \n\n \n# View sample data\ndata.head(10) ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T02:25:08.559449Z","iopub.execute_input":"2021-06-14T02:25:08.55993Z","iopub.status.idle":"2021-06-14T02:25:08.61322Z","shell.execute_reply.started":"2021-06-14T02:25:08.5599Z","shell.execute_reply":"2021-06-14T02:25:08.612334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['label'] = pd.factorize(data.letter)[0]","metadata":{"execution":{"iopub.status.busy":"2021-06-14T02:25:17.994975Z","iopub.execute_input":"2021-06-14T02:25:17.995313Z","iopub.status.idle":"2021-06-14T02:25:18.002505Z","shell.execute_reply.started":"2021-06-14T02:25:17.995283Z","shell.execute_reply":"2021-06-14T02:25:18.001349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T02:18:45.875334Z","iopub.execute_input":"2021-06-14T02:18:45.875682Z","iopub.status.idle":"2021-06-14T02:18:45.890856Z","shell.execute_reply.started":"2021-06-14T02:18:45.875653Z","shell.execute_reply":"2021-06-14T02:18:45.890045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del data[\"letter\"]","metadata":{"execution":{"iopub.status.busy":"2021-06-14T02:25:20.502751Z","iopub.execute_input":"2021-06-14T02:25:20.503095Z","iopub.status.idle":"2021-06-14T02:25:20.507641Z","shell.execute_reply.started":"2021-06-14T02:25:20.503058Z","shell.execute_reply":"2021-06-14T02:25:20.506746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T02:25:22.947194Z","iopub.execute_input":"2021-06-14T02:25:22.947804Z","iopub.status.idle":"2021-06-14T02:25:22.962093Z","shell.execute_reply.started":"2021-06-14T02:25:22.947767Z","shell.execute_reply":"2021-06-14T02:25:22.961238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##########################################################\n#SHARE TO TEST AND TRAIN DATA\n##########################################################\nx = data.iloc[:, :16]\ny = data['label'].tolist()\nprint(x)\n\n# Select 4000 rows data as a testing dataset\nx_test = x.iloc[0:3000, :].values.astype('float32') # all pixel values \ny_test = y[0:3000] # Select label for testing data\nx_train = x.iloc[3000:, :].values.astype('float32') # all pixel values \ny_train = y[3000:]\n\n# # Share test and train data\n# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T02:25:25.648558Z","iopub.execute_input":"2021-06-14T02:25:25.6491Z","iopub.status.idle":"2021-06-14T02:25:25.664747Z","shell.execute_reply.started":"2021-06-14T02:25:25.649053Z","shell.execute_reply":"2021-06-14T02:25:25.663594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2021-06-14T02:19:12.507219Z","iopub.execute_input":"2021-06-14T02:19:12.50762Z","iopub.status.idle":"2021-06-14T02:19:12.532439Z","shell.execute_reply.started":"2021-06-14T02:19:12.507585Z","shell.execute_reply":"2021-06-14T02:19:12.531423Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Reshape Dataset to Have a Single Channel**","metadata":{}},{"cell_type":"code","source":"x_train = x_train.reshape((x_train.shape[0], 4, 4, 1))\nx_test = x_test.reshape((x_test.shape[0], 4, 4, 1))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T02:25:32.446902Z","iopub.execute_input":"2021-06-14T02:25:32.447256Z","iopub.status.idle":"2021-06-14T02:25:32.454609Z","shell.execute_reply.started":"2021-06-14T02:25:32.447226Z","shell.execute_reply":"2021-06-14T02:25:32.453393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-14T02:25:39.727351Z","iopub.execute_input":"2021-06-14T02:25:39.727705Z","iopub.status.idle":"2021-06-14T02:25:39.732861Z","shell.execute_reply.started":"2021-06-14T02:25:39.727676Z","shell.execute_reply":"2021-06-14T02:25:39.732083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Normalize Input**","metadata":{}},{"cell_type":"code","source":"#x_train2 = x_train/255\n#x_test2 = x_test/255\nx_train2 = x_train/255 - 0.5\nx_test2 = x_test/255 - 0.5\n\n# Convert class labels to one-hot encoded\ny_train2 = keras.utils.to_categorical(y_train)\ny_test2 = keras.utils.to_categorical(y_test)\n\n# Print labels\ny_train2","metadata":{"execution":{"iopub.status.busy":"2021-06-14T02:25:43.00665Z","iopub.execute_input":"2021-06-14T02:25:43.007213Z","iopub.status.idle":"2021-06-14T02:25:43.020311Z","shell.execute_reply.started":"2021-06-14T02:25:43.007181Z","shell.execute_reply":"2021-06-14T02:25:43.019178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Import Necessary CNN Building Blocks**","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout\nfrom keras.layers.advanced_activations import LeakyReLU","metadata":{"execution":{"iopub.status.busy":"2021-06-14T02:25:46.070314Z","iopub.execute_input":"2021-06-14T02:25:46.070661Z","iopub.status.idle":"2021-06-14T02:25:46.074896Z","shell.execute_reply.started":"2021-06-14T02:25:46.070631Z","shell.execute_reply":"2021-06-14T02:25:46.074124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Define/Create CNN Architecture**","metadata":{}},{"cell_type":"code","source":"# Create a model function\ndef make_model():\n    model = Sequential()\n\n    model.add(Conv2D(filters = 16, kernel_size = (3, 3), padding='same', input_shape=(4, 4, 1)))\n    model.add(LeakyReLU(0.1))\n    model.add(Conv2D(filters = 32, kernel_size = (3, 3), padding='same'))\n    model.add(LeakyReLU(0.1))\n    \n    model.add(MaxPooling2D((2, 2)))\n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(filters = 32, kernel_size = (3, 3), padding='same'))\n    model.add(LeakyReLU(0.1))\n    model.add(Conv2D(filters = 64, kernel_size = (3, 3), padding='same'))\n    model.add(LeakyReLU(0.1))\n\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Dropout(0.25))\n    \n    model.add(Flatten())\n    \n    model.add(Dense(256))\n    model.add(LeakyReLU(0.1))\n\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(10))\n    model.add(Activation(\"softmax\"))\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-14T02:42:43.83897Z","iopub.execute_input":"2021-06-14T02:42:43.839345Z","iopub.status.idle":"2021-06-14T02:42:43.846104Z","shell.execute_reply.started":"2021-06-14T02:42:43.839309Z","shell.execute_reply":"2021-06-14T02:42:43.845041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Summarize a model\nmodel = make_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T02:42:47.251277Z","iopub.execute_input":"2021-06-14T02:42:47.251617Z","iopub.status.idle":"2021-06-14T02:42:47.280668Z","shell.execute_reply.started":"2021-06-14T02:42:47.251587Z","shell.execute_reply":"2021-06-14T02:42:47.279575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Define the loss function, the optimizer and the metrics**","metadata":{}},{"cell_type":"code","source":"INIT_LR = 5e-3 # Learning rate, is default schedule in all Keras Optimizers\nBATCH_SIZE = 32 # Batch size is a hyperparameter of gradient descent that controls the number of training samples\nEPOCHS = 80 # Number of epochs\n\n# Create object of deep learning model\nmodel = make_model()\n\n# Define the loss function, the optimizer and the metrics\nmodel.compile(\n    loss='categorical_crossentropy',  \n    optimizer=keras.optimizers.Adamax(lr=INIT_LR), \n    metrics=['accuracy']  # report accuracy during training\n)\n\n# Scheduler of learning rate (decay with epochs)\ndef lr_scheduler(epoch):\n    return INIT_LR * 0.9 ** epoch\n\n# Callback for printing of actual learning rate used by optimizer\nclass LrHistory(keras.callbacks.Callback):\n    def on_epoch_begin(self, epoch, logs={}):\n        print(\"Learning rate:\", K.get_value(model.optimizer.lr))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T02:42:50.614493Z","iopub.execute_input":"2021-06-14T02:42:50.614887Z","iopub.status.idle":"2021-06-14T02:42:50.651792Z","shell.execute_reply.started":"2021-06-14T02:42:50.614841Z","shell.execute_reply":"2021-06-14T02:42:50.650884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Fit the Deep Learning Mode**","metadata":{}},{"cell_type":"code","source":"import tensorflow_addons as tfa\ntqdm_callback = tfa.callbacks.TQDMProgressBar()\n\nmodel.fit(\n    x_train2, y_train2,  # Prepared data\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    callbacks=[keras.callbacks.LearningRateScheduler(lr_scheduler), \n               LrHistory(), \n               tqdm_callback],\n    shuffle=True,\n    verbose=0,\n    initial_epoch=0\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T02:42:56.163775Z","iopub.execute_input":"2021-06-14T02:42:56.164371Z","iopub.status.idle":"2021-06-14T02:42:56.334542Z","shell.execute_reply.started":"2021-06-14T02:42:56.16433Z","shell.execute_reply":"2021-06-14T02:42:56.332335Z"},"trusted":true},"execution_count":null,"outputs":[]}]}