{"cells":[{"metadata":{},"cell_type":"markdown","source":"#Situation Overview and Humanitarian Needs\n\nSenegal reported its first confirmed COVID-19 case on March 2. As of June 22, there were 5970 cases, 3953 fully recovered and 86 deceased persons with a significant increase in cases in the last weeks. 51 out of 79 health districts are now affected but with the highest concentration of cases in the regions of Dakar, Thiès, Diourbel and Sédhiou. The Senegalese government is leading the response and prevention work with support of key partners including UNICEF. Many preventive measures are in place including a state of national emergency, school closure, night curfew and closed borders. In mid-June the government lifted a few restrictions, such as the ban on inter-regional travel and the re-opening of some public spaces. Schools are expected to partially reopen on 25 June, starting with examination classes.\n\nRecently, the government shifted its treatment strategy of persons having tested positive to COVID-19. From treating all positive cases in hospitals, those with no or only light symptoms are now treated in other centres (mainly hotels). UNICEF provides technical support to the Ministry of Health in this process.\n\nA large delivery of personal protective equipment, thermometers, oxygen concentrators and hygiene items that recently arrived in the country by UNICEF is now being distributed to the regions most in need. They continue working closely with the Ministry of Education to prepare schools for the re-opening of exam classes (planned for 25 June) by providing for example hygiene supplies and handwashing stands.\n\nThey also continue supporting the return to families for the ‘talibés’ children in the daaras (coranic schools) within the coordinated initiative \"Zero street children in the context of COVID-19\". UNICEF contributed with food support to children in the daaras, continued to find alternative care to children without parental care and to provide psychosocial care to all vulnerable children. https://reliefweb.int/report/senegal/senegal-covid-19-situation-report-06-29-may-22-june-2020","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#Scouts du Senegal\n\n![](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcQKxvPPzXQpGL-PXzh781eq7-UC62jda-KYrw&usqp=CAU)m.facebook.com","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.offline as py\nimport plotly.express as px\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Senegal Uses U.S.-Donated Field Hospitals in Fight Against COVID-19 \n\nIn October 2019, the United States donated two deployable field hospitals to the Senegalese Armed Forces through the Africa Peacekeeping Rapid Response Partnership.  The $6.5 million dollar donation of the hospitals and associated medical training is designed to support the Senegalese military by offering heightened medical capacity in the field.  This investment is already paying dividends in the form of ensuring access to healthcare and treatment for the people of Senegal as one these hospitals, and the trained medical personnel, has been deployed to the Senegalese city of Touba to assist in the emergency response to the Covid-19 outbreak.\n\n![](https://d2v9ipibika81v.cloudfront.net/uploads/sites/209/cov1-1.jpg)https://sn.usembassy.gov/senegal-uses-u-s-donated-field-hospitals-in-fight-against-covid-19/","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.gridspec as gridspec\nfrom scipy.stats import skew\nfrom sklearn.preprocessing import RobustScaler,MinMaxScaler\nfrom scipy import stats\nimport matplotlib.style as style\nstyle.use('seaborn-colorblind')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df = pd.read_csv('../input/hackathon/task_2-owid_covid_data-21_June_2020.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"senegal = df[(df['location']=='Senegal')].reset_index(drop=True)\nsenegal.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of different type of amount\nfig , ax = plt.subplots(1,3,figsize = (12,5))\n\ntotal_cases = senegal.total_cases.values\ntotal_deaths = senegal.total_deaths.values\ntotal_cases_per_million = senegal.total_cases_per_million.values\n\nsns.distplot(total_cases , ax = ax[0] , color = 'blue').set_title('Senegal Covid19 Total Cases' , fontsize = 14)\nsns.distplot(total_deaths , ax = ax[1] , color = 'cyan').set_title('Senegal Covid19 Deaths' , fontsize = 14)\nsns.distplot(total_cases_per_million , ax = ax[2] , color = 'purple').set_title('Senegal Covid19 Cases per Milion' , fontsize = 14)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig , ((ax1,ax2),(ax3,ax4)) = plt.subplots(nrows = 2, ncols = 2, figsize = (14,6))\n\nsns.violinplot(x = 'total_cases' , y = 'new_cases' , data = senegal , ax = ax1 , palette = 'Set2')\nsns.violinplot(x = 'total_cases' , y = 'total_deaths' , data = senegal , ax = ax2 , palette = 'Set2')\nsns.boxplot(x = 'total_cases' , y = 'total_cases_per_million', data = senegal, ax = ax3 , palette = 'Set2')\nsns.boxplot(x = 'total_cases',y = 'new_cases_per_million', data = senegal, ax = ax4, palette = 'Set2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_r=0.6                # Remove Null value ratio more than n_r. For example 0.6 means if column null ratio more than %60 then remove column\ns_r=0.50               # If skewness more than %75 transform column to get normal distribution\nc_r=1                  # Remove correlated columns\nn_f= df.shape[1]  # n_f number of features. dataset.shape[1] means all columns. If you change it to 10, it will select 10 most correlated feature\nr_s=42                  # random seed","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Codes from Mehmet Sungur https://www.kaggle.com/medyasun/house-price-all-regressor-algorithms","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#Fill null values with Mode/Median (for categorical features -Mode and for numbers-Median)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cat=df.select_dtypes(\"object\")\nfor column in cat:\n    df[column].fillna(df[column].mode()[0], inplace=True)\n    #dataset[column].fillna(\"NA\", inplace=True)\n\n\nfl=df.select_dtypes([\"float64\",\"int64\"]).drop(\"total_cases\",axis=1)\nfor column in fl:\n    df[column].fillna(df[column].median(), inplace=True)\n    #dataset[column].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# categorical features\ncategorical_feat = [feature for feature in df.columns if df[feature].dtypes=='O']\nprint('Total categorical features: ', len(categorical_feat))\nprint('\\n',categorical_feat)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Label Encoding","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nencoder = preprocessing.LabelEncoder()\ndf[\"iso_code\"] = encoder.fit_transform(df[\"iso_code\"].fillna('Nan'))\ndf[\"continent\"] = encoder.fit_transform(df[\"continent\"].fillna('Nan'))\ndf[\"location\"] = encoder.fit_transform(df[\"location\"].fillna('Nan'))\ndf[\"date\"] = encoder.fit_transform(df[\"date\"].fillna('Nan'))\ndf[\"tests_units\"] = encoder.fit_transform(df[\"tests_units\"].fillna('Nan'))\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotting_3_chart(df, feature): \n    ## Creating a customized chart. and giving in figsize and everything. \n    fig = plt.figure(constrained_layout=True, figsize=(10,6))\n    ## crea,ting a grid of 3 cols and 3 rows. \n    grid = gridspec.GridSpec(ncols=3, nrows=3, figure=fig)\n    #gs = fig3.add_gridspec(3, 3)\n\n    ## Customizing the histogram grid. \n    ax1 = fig.add_subplot(grid[0, :2])\n    ## Set the title. \n    ax1.set_title('Histogram')\n    ## plot the histogram. \n    sns.distplot(df.loc[:,feature], norm_hist=True, ax = ax1)\n\n    # customizing the QQ_plot. \n    ax2 = fig.add_subplot(grid[1, :2])\n    ## Set the title. \n    ax2.set_title('QQ_plot')\n    ## Plotting the QQ_Plot. \n    stats.probplot(df.loc[:,feature], plot = ax2)\n\n    ## Customizing the Box Plot. \n    ax3 = fig.add_subplot(grid[:, 2])\n    ## Set title. \n    ax3.set_title('Box Plot')\n    ## Plotting the box plot. \n    sns.boxplot(df.loc[:,feature], orient='v', ax = ax3 );\n \n\nprint('Skewness: '+ str(df['total_cases'].skew())) \nprint(\"Kurtosis: \" + str(df['total_cases'].kurt()))\nplotting_3_chart(df, 'total_cases')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Target was skewed so we need to transformation. Mehmet used log but you try other transformation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#log transform the target:\ndf[\"total_cases\"] = np.log1p(df[\"total_cases\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Skewness: '+ str(df['total_cases'].skew()))   \nprint(\"Kurtosis: \" + str(df['total_cases'].kurt()))\nplotting_3_chart(df, 'total_cases')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Auto Detect Outliers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_o=df[df[\"total_cases\"].notnull()]\nfrom sklearn.neighbors import LocalOutlierFactor\ndef detect_outliers(x, y, top=5, plot=True):\n    lof = LocalOutlierFactor(n_neighbors=40, contamination=0.1)\n    x_ =np.array(x).reshape(-1,1)\n    preds = lof.fit_predict(x_)\n    lof_scr = lof.negative_outlier_factor_\n    out_idx = pd.Series(lof_scr).sort_values()[:top].index\n    if plot:\n        f, ax = plt.subplots(figsize=(9, 6))\n        plt.scatter(x=x, y=y, c=np.exp(lof_scr), cmap='RdBu')\n    return out_idx\n\nouts = detect_outliers(train_o['total_deaths'], train_o['total_cases'],top=5)\nouts\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"outs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Detect and Remove outliers","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"from collections import Counter\noutliers=outs\nall_outliers=[]\nnumeric_features = train_o.dtypes[train_o.dtypes != 'object'].index\nfor feature in numeric_features:\n    try:\n        outs = detect_outliers(train_o[feature], train_o['total_cases'],top=5, plot=False)\n    except:\n        continue\n    all_outliers.extend(outs)\n\nprint(Counter(all_outliers).most_common())\nfor i in outliers:\n    if i in all_outliers:\n        print(i)\ntrain_o = train_o.drop(train_o.index[outliers])\ntest_o=df[df[\"total_cases\"].isna()]\ndf =  pd.concat(objs=[train_o, test_o], axis=0,sort=False).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Check Skewness and fit transformations if needed.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.special import boxcox1p\nfrom scipy.stats import boxcox\nlam = 0.15\n\n#log transform skewed numeric features:\nnumeric_feats = df.dtypes[df.dtypes != \"object\"].index\n\nskewed_feats = df[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\nskewed_feats = skewed_feats[skewed_feats > s_r]\nskewed_feats = skewed_feats.index\n\ndf[skewed_feats] = boxcox1p(df[skewed_feats],lam)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Now we don't have any missing value","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df.columns[df.isnull().any()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Check Correlation between features and remove features with high correlations.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_heat=df[df[\"total_cases\"].notnull()]\ntrain_heat=train_heat.drop([\"total_deaths\"],axis=1)\nstyle.use('ggplot')\nsns.set_style('whitegrid')\nplt.subplots(figsize = (20,16))\n## Plotting heatmap. \n\n# Generate a mask for the upper triangle (taken from seaborn example gallery)\nmask = np.zeros_like(train_heat.corr(), dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n\nsns.heatmap(train_heat.corr(), \n            cmap=sns.diverging_palette(255, 133, l=60, n=7), \n            mask = mask, \n            annot=True, \n            center = 0, \n           );\n## Give title. \nplt.title(\"Heatmap of all the Features\", fontsize = 30);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Remove correlated features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_corr = train_heat.corr().abs()\ntarget_corr=df.corr()[\"total_cases\"].abs()\ntarget_corr=pd.DataFrame(target_corr)\ntarget_corr=target_corr.reset_index()\nfeature_corr_unstack= feature_corr.unstack()\ndf_fc=pd.DataFrame(feature_corr_unstack,columns=[\"corr\"])\ndf_fc=df_fc[(df_fc[\"corr\"]>=.80)&(df_fc[\"corr\"]<1)].sort_values(by=\"corr\",ascending=False)\ndf_dc=df_fc.reset_index()\n\n#df_dc=pd.melt(df_dc, id_vars=['corr'], var_name='Name')\ntarget_corr=df_dc.merge(target_corr, left_on='level_1', right_on='index',\n          suffixes=('_left', '_right'))\n\ncols=target_corr[\"level_0\"].values\n\ntarget_corr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Remove low features with low variances","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"all_features = df.keys()\n# Removing features.\ndf = df.drop(df.loc[:,(df==0).sum()>=(df.shape[0]*0.9994)],axis=1)\ndf = df.drop(df.loc[:,(df==1).sum()>=(df.shape[0]*0.9994)],axis=1) \n# Getting and printing the remaining features.\nremain_features = df.keys()\nremov_features = [st for st in all_features if st not in remain_features]\nprint(len(remov_features), 'features were removed:', remov_features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Create regression models and compare the accuracy to our best regressor.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train=df[df[\"total_cases\"].notnull()]\ntest=df[df[\"total_cases\"].isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k = n_f # if you change it 10 model uses most 10 correlated features\ncorrmat=abs(df.corr())\ncols = corrmat.nlargest(k, 'total_cases')['total_cases'].index\ntrain_x=df[cols].drop(\"total_cases\",axis=1)\ntrain_y=df[\"total_cases\"]\nX_test=test[cols].drop(\"total_cases\",axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Classic Train Test Split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(train_x, train_y, test_size=0.20, random_state=r_s)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Do you know all models names in sckitlearn? I learnt right now.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils.testing import all_estimators\nfrom sklearn import base\n\nestimators = all_estimators()\n\nfor name, class_ in estimators:\n    if issubclass(class_, base.RegressorMixin):\n       print(name+\"()\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(seed=r_s)\n\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error\nfrom sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor,AdaBoostRegressor,ExtraTreesRegressor,HistGradientBoostingRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import Ridge,RidgeCV,BayesianRidge,LinearRegression,Lasso,LassoCV,ElasticNet,RANSACRegressor,HuberRegressor,PassiveAggressiveRegressor,ElasticNetCV\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import VotingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.cross_decomposition import CCA\nfrom sklearn.neural_network import MLPRegressor\n\n\n\nmy_regressors=[ \n               ElasticNet(alpha=0.001,l1_ratio=0.70,max_iter=100,tol=0.01, random_state=r_s),\n               ElasticNetCV(l1_ratio=0.9,max_iter=100,tol=0.01,random_state=r_s),\n               CatBoostRegressor(logging_level='Silent',random_state=r_s),\n               GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, loss='huber',random_state =r_s),\n               LGBMRegressor(objective='regression', \n                                       num_leaves=4,\n                                       learning_rate=0.01, \n                                       n_estimators=5000,\n                                       max_bin=200, \n                                       bagging_fraction=0.75,\n                                       bagging_freq=5, \n                                       bagging_seed=7,\n                                       feature_fraction=0.2,\n                                       feature_fraction_seed=7,\n                                       verbose=-1,\n                                       random_state=r_s\n                                       ),\n               RandomForestRegressor(random_state=r_s),\n               AdaBoostRegressor(random_state=r_s),\n               ExtraTreesRegressor(random_state=r_s),\n               SVR(C= 20, epsilon= 0.008, gamma=0.0003),\n               Ridge(alpha=6),\n               RidgeCV(),\n               BayesianRidge(),\n               DecisionTreeRegressor(),\n               LinearRegression(),\n               KNeighborsRegressor(),\n               Lasso(alpha=0.00047,random_state=r_s),\n               LassoCV(),\n               KernelRidge(),\n               CCA(),\n               MLPRegressor(random_state=r_s),\n               HistGradientBoostingRegressor(random_state=r_s),\n               HuberRegressor(),\n               RANSACRegressor(random_state=r_s),\n               PassiveAggressiveRegressor(random_state=r_s)\n               #XGBRegressor(random_state=r_s)\n              ]\n\nregressors=[]\n\nfor my_regressor in my_regressors:\n    regressors.append(my_regressor)\n\n\nscores_val=[]\nscores_train=[]\nMAE=[]\nMSE=[]\nRMSE=[]\n\n\nfor regressor in regressors:\n    scores_val.append(regressor.fit(X_train,y_train).score(X_val,y_val))\n    scores_train.append(regressor.fit(X_train,y_train).score(X_train,y_train))\n    y_pred=regressor.predict(X_val)\n    MAE.append(mean_absolute_error(y_val,y_pred))\n    MSE.append(mean_squared_error(y_val,y_pred))\n    RMSE.append(np.sqrt(mean_squared_error(y_val,y_pred)))\n\n    \nresults=zip(scores_val,scores_train,MAE,MSE,RMSE)\nresults=list(results)\nresults_score_val=[item[0] for item in results]\nresults_score_train=[item[1] for item in results]\nresults_MAE=[item[2] for item in results]\nresults_MSE=[item[3] for item in results]\nresults_RMSE=[item[4] for item in results]\n\n\ndf_results=pd.DataFrame({\"Algorithms\":my_regressors,\"Training Score\":results_score_train,\"Validation Score\":results_score_val,\"MAE\":results_MAE,\"MSE\":results_MSE,\"RMSE\":results_RMSE})\ndf_results","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#There is No Missing Values, though the program returned the error above.","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"ls ../input/hackathon/task_1-google_search_txt_files_v2/SN/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Senegal = '../input/hackathon/task_1-google_search_txt_files_v2/SN/Senegal-fr-result-31.txt'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = open(Senegal, 'r',encoding='utf-8',\n                 errors='ignore').read()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(text[:2000])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df1 = pd.read_csv('../input/hackathon/task_2-BCG_world_atlas_data-bcg_strain-7July2020.csv', encoding='utf8')\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEN = df1[(df1['country_name']=='Senegal')].reset_index(drop=True)\nSEN.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,3, figsize = (20,6), sharex=True)\nsns.countplot(x='bcg_strain_original',data=SEN, palette=\"nipy_spectral\", ax=ax[0])\nsns.countplot(x='bcg_strain_id', palette=\"YlOrBr\", data=SEN,ax=ax[1])\nsns.countplot(x='bcg_policy_first_year_original', palette=\"flag\", data=SEN,ax=ax[2])\nax[0].title.set_text('Senegal BCG Original Strain')\nax[1].title.set_text('Senegal BCG Strain ID')\nax[2].title.set_text('Senegal BCG Policy 1st Year')\nplt.xticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#word cloud\nfrom wordcloud import WordCloud, ImageColorGenerator\ntext = \" \".join(str(each) for each in SEN.country_name)\n# Create and generate a word cloud image:\nwordcloud = WordCloud(max_words=200,colormap='Set2', background_color=\"black\").generate(text)\nplt.figure(figsize=(10,6))\nplt.figure(figsize=(15,10))\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='Bilinear')\nplt.axis(\"off\")\nplt.figure(1,figsize=(12, 12))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Das War's, Kaggle Notebook Runner: Marília Prata  @mpwolke ","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}