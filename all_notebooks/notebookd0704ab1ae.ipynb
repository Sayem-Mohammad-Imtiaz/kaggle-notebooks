{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-02T23:48:23.585143Z","iopub.execute_input":"2021-06-02T23:48:23.585581Z","iopub.status.idle":"2021-06-02T23:48:23.598229Z","shell.execute_reply.started":"2021-06-02T23:48:23.58548Z","shell.execute_reply":"2021-06-02T23:48:23.596677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. Read the dataset as a dataframe. Create a copy of your dataframe. Solve the rest of the questions using this dataframe copy.","metadata":{}},{"cell_type":"code","source":"a = pd.read_csv(\"../input/weather-dataset-rattle-package/weatherAUS.csv\")\na","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:23.600488Z","iopub.execute_input":"2021-06-02T23:48:23.600877Z","iopub.status.idle":"2021-06-02T23:48:24.43017Z","shell.execute_reply.started":"2021-06-02T23:48:23.600839Z","shell.execute_reply":"2021-06-02T23:48:24.428811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = a.copy()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:24.431702Z","iopub.execute_input":"2021-06-02T23:48:24.432104Z","iopub.status.idle":"2021-06-02T23:48:24.463677Z","shell.execute_reply.started":"2021-06-02T23:48:24.432067Z","shell.execute_reply":"2021-06-02T23:48:24.462091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:24.466119Z","iopub.execute_input":"2021-06-02T23:48:24.466659Z","iopub.status.idle":"2021-06-02T23:48:24.508555Z","shell.execute_reply.started":"2021-06-02T23:48:24.466605Z","shell.execute_reply":"2021-06-02T23:48:24.507358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Find out the describe and info attributes of the dataframe. Analyze these information and create a short write-up according to your findings.","metadata":{}},{"cell_type":"code","source":"df.describe().T","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:24.51004Z","iopub.execute_input":"2021-06-02T23:48:24.510377Z","iopub.status.idle":"2021-06-02T23:48:24.691949Z","shell.execute_reply.started":"2021-06-02T23:48:24.510341Z","shell.execute_reply":"2021-06-02T23:48:24.690511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Coment; Bu tabloda Avustralya'nın min. sıcaklık, max. sıcaklık, ruzgar hızı, nem, basinc vs. hava durumu ile ilgili bilgilerini görebiliriz. Ornegin min. sıcaklık -8.5 ve max. sıcaklık 48.1 derecedir.\n\nAyrıca mean ve %50 column degerlerine baktigimizda bunlarin birbirlerine yakin degerler olduklarini da goruruz. Bu da bize bu veri setinin normal bir dagilim gosterdigini ifade eder.","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:24.697694Z","iopub.execute_input":"2021-06-02T23:48:24.698114Z","iopub.status.idle":"2021-06-02T23:48:24.818227Z","shell.execute_reply.started":"2021-06-02T23:48:24.698079Z","shell.execute_reply":"2021-06-02T23:48:24.817362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Coment; df.info ile data tiplerini(ornegin yukarida float64(16), object(7)), kac tane column oldugunu(23) ve bunlarin isimlerini ve ne kadar non-null deger oldugunu gorebiliriz.","metadata":{}},{"cell_type":"markdown","source":"3. Find out the shape and size info of the dataset.","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:24.820666Z","iopub.execute_input":"2021-06-02T23:48:24.821124Z","iopub.status.idle":"2021-06-02T23:48:24.82797Z","shell.execute_reply.started":"2021-06-02T23:48:24.821092Z","shell.execute_reply":"2021-06-02T23:48:24.826783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.size","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:24.830354Z","iopub.execute_input":"2021-06-02T23:48:24.831676Z","iopub.status.idle":"2021-06-02T23:48:24.843359Z","shell.execute_reply.started":"2021-06-02T23:48:24.831606Z","shell.execute_reply":"2021-06-02T23:48:24.842245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"4. Find out the types values of the columns and save the result as a dataframe.","metadata":{}},{"cell_type":"code","source":"b = df.dtypes.to_frame(\"dtypes\").reset_index()\nb","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:24.844981Z","iopub.execute_input":"2021-06-02T23:48:24.845798Z","iopub.status.idle":"2021-06-02T23:48:24.870402Z","shell.execute_reply.started":"2021-06-02T23:48:24.845726Z","shell.execute_reply":"2021-06-02T23:48:24.869072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtypes = pd.DataFrame(df.dtypes,columns = [\"dtypes\"])\ndtypes","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:24.872305Z","iopub.execute_input":"2021-06-02T23:48:24.873638Z","iopub.status.idle":"2021-06-02T23:48:24.895887Z","shell.execute_reply.started":"2021-06-02T23:48:24.87356Z","shell.execute_reply":"2021-06-02T23:48:24.894688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"5. Find out the non-null counts of the columns and save the result as a dataframe.","metadata":{}},{"cell_type":"code","source":"not_null = pd.DataFrame(df.notnull().sum())\nnot_null","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:24.897339Z","iopub.execute_input":"2021-06-02T23:48:24.897805Z","iopub.status.idle":"2021-06-02T23:48:25.020812Z","shell.execute_reply.started":"2021-06-02T23:48:24.897772Z","shell.execute_reply":"2021-06-02T23:48:25.020092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"6. Find out the null counts of the columns and save the result as a dataframe.","metadata":{}},{"cell_type":"code","source":"non_null = pd.DataFrame(df.isnull().sum(), columns=[\"is_null\"])\nnon_null","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:25.021781Z","iopub.execute_input":"2021-06-02T23:48:25.022189Z","iopub.status.idle":"2021-06-02T23:48:25.12561Z","shell.execute_reply.started":"2021-06-02T23:48:25.022159Z","shell.execute_reply":"2021-06-02T23:48:25.124878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"7. Find out the unique counts of the columns and save the result as a dataframe.","metadata":{}},{"cell_type":"code","source":"nunique = df.nunique().to_frame(\"nunique\").reset_index()\nnunique","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:25.126795Z","iopub.execute_input":"2021-06-02T23:48:25.127091Z","iopub.status.idle":"2021-06-02T23:48:25.350464Z","shell.execute_reply.started":"2021-06-02T23:48:25.127062Z","shell.execute_reply":"2021-06-02T23:48:25.349519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"II. YOL","metadata":{}},{"cell_type":"code","source":"nunique = pd.DataFrame(df.nunique(), columns = [\"nunique\"])\nnunique","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:25.352031Z","iopub.execute_input":"2021-06-02T23:48:25.352344Z","iopub.status.idle":"2021-06-02T23:48:25.595929Z","shell.execute_reply.started":"2021-06-02T23:48:25.352315Z","shell.execute_reply":"2021-06-02T23:48:25.594626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"8. Merge the dataframes you created in questions 4-5-6-7.","metadata":{}},{"cell_type":"code","source":"c = pd.concat([dtypes,not_null,non_null, nunique], axis=1)\nc","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:25.597452Z","iopub.execute_input":"2021-06-02T23:48:25.597804Z","iopub.status.idle":"2021-06-02T23:48:25.616529Z","shell.execute_reply.started":"2021-06-02T23:48:25.597751Z","shell.execute_reply":"2021-06-02T23:48:25.615065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"9. Lowercase all column names.","metadata":{}},{"cell_type":"code","source":"df.columns = df.columns.str.lower()\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:25.618373Z","iopub.execute_input":"2021-06-02T23:48:25.61879Z","iopub.status.idle":"2021-06-02T23:48:25.66971Z","shell.execute_reply.started":"2021-06-02T23:48:25.618734Z","shell.execute_reply":"2021-06-02T23:48:25.668132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"10. Change all the No values to NoRain and all the Yes values to Rain in raintoday and raintomorrow columns.","metadata":{}},{"cell_type":"code","source":"df.raintoday.replace('No','NoRain',inplace = True)\ndf.raintoday.replace('Yes','Rain',inplace = True)\ndf.raintomorrow.replace('No','NoRain',inplace = True)\ndf.raintomorrow.replace('Yes','Rain',inplace = True)\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:25.671286Z","iopub.execute_input":"2021-06-02T23:48:25.671744Z","iopub.status.idle":"2021-06-02T23:48:25.76634Z","shell.execute_reply.started":"2021-06-02T23:48:25.671697Z","shell.execute_reply":"2021-06-02T23:48:25.764808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"11. Change the data type of \"date\" (object) column to datetime64 and reformat the date as DD/MM/YYYY.","metadata":{}},{"cell_type":"code","source":"df.date = pd.to_datetime(df.date)\ndf.date = df.date.dt.strftime('%d/%m/%Y')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:25.76793Z","iopub.execute_input":"2021-06-02T23:48:25.768299Z","iopub.status.idle":"2021-06-02T23:48:26.981264Z","shell.execute_reply.started":"2021-06-02T23:48:25.768257Z","shell.execute_reply":"2021-06-02T23:48:26.979994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:26.98316Z","iopub.execute_input":"2021-06-02T23:48:26.983514Z","iopub.status.idle":"2021-06-02T23:48:27.100057Z","shell.execute_reply.started":"2021-06-02T23:48:26.98348Z","shell.execute_reply":"2021-06-02T23:48:27.098684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"12. Create a new column called \"difference\", calculate the difference between maxtemp and mintemp columns for each row, and store the value in this new column.","metadata":{}},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:27.101898Z","iopub.execute_input":"2021-06-02T23:48:27.102282Z","iopub.status.idle":"2021-06-02T23:48:27.296348Z","shell.execute_reply.started":"2021-06-02T23:48:27.102245Z","shell.execute_reply":"2021-06-02T23:48:27.295283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"difference\"] = df[\"maxtemp\"] - df[\"mintemp\"]\ndf","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:27.297667Z","iopub.execute_input":"2021-06-02T23:48:27.298018Z","iopub.status.idle":"2021-06-02T23:48:27.518437Z","shell.execute_reply.started":"2021-06-02T23:48:27.297986Z","shell.execute_reply":"2021-06-02T23:48:27.517199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"13. Remove the evaporation and sunshine columns from the dataset permanently.","metadata":{}},{"cell_type":"code","source":"df.drop(\"evaporation\",axis = 1, inplace = True)\ndf.drop(\"sunshine\",axis = 1, inplace = True)\ndf","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:27.520209Z","iopub.execute_input":"2021-06-02T23:48:27.520656Z","iopub.status.idle":"2021-06-02T23:48:27.771803Z","shell.execute_reply.started":"2021-06-02T23:48:27.52061Z","shell.execute_reply":"2021-06-02T23:48:27.770925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"14. Find out the most rainy day for each city.","metadata":{}},{"cell_type":"code","source":"df_most_rainy_day = df.groupby(df.location)[\"rainfall\"].idxmax().to_frame(\"mostrainydays\")\nday = df_most_rainy_day.mostrainydays.to_list()\ndf.date[day]","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:27.77307Z","iopub.execute_input":"2021-06-02T23:48:27.773563Z","iopub.status.idle":"2021-06-02T23:48:27.806745Z","shell.execute_reply.started":"2021-06-02T23:48:27.773528Z","shell.execute_reply":"2021-06-02T23:48:27.805828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"15. Filter out all the data for the city 'Albury' and then sort according to maxtemp column.","metadata":{}},{"cell_type":"code","source":"df_Albury = df[df.location == \"Albury\"]\ndf_Albury","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:27.80896Z","iopub.execute_input":"2021-06-02T23:48:27.809461Z","iopub.status.idle":"2021-06-02T23:48:27.8949Z","shell.execute_reply.started":"2021-06-02T23:48:27.80941Z","shell.execute_reply":"2021-06-02T23:48:27.893601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_Albury.sort_values(by = \"maxtemp\")","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:27.896511Z","iopub.execute_input":"2021-06-02T23:48:27.897069Z","iopub.status.idle":"2021-06-02T23:48:27.9586Z","shell.execute_reply.started":"2021-06-02T23:48:27.897024Z","shell.execute_reply":"2021-06-02T23:48:27.957677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"II. YOL","metadata":{}},{"cell_type":"code","source":"df_Albury = df[df.location == \"Albury\"].sort_values(by = \"maxtemp\", ascending=False)\ndf_Albury","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:27.95991Z","iopub.execute_input":"2021-06-02T23:48:27.960433Z","iopub.status.idle":"2021-06-02T23:48:28.046333Z","shell.execute_reply.started":"2021-06-02T23:48:27.960397Z","shell.execute_reply":"2021-06-02T23:48:28.045037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"16. Find out the NaN counts for each column.","metadata":{}},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:28.048477Z","iopub.execute_input":"2021-06-02T23:48:28.048981Z","iopub.status.idle":"2021-06-02T23:48:28.158405Z","shell.execute_reply.started":"2021-06-02T23:48:28.048931Z","shell.execute_reply":"2021-06-02T23:48:28.156842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"II.YOL","metadata":{}},{"cell_type":"code","source":"NaN = df.isna().sum().to_frame(\"isNaN\").reset_index()\nNaN","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:28.160352Z","iopub.execute_input":"2021-06-02T23:48:28.160855Z","iopub.status.idle":"2021-06-02T23:48:28.27708Z","shell.execute_reply.started":"2021-06-02T23:48:28.1608Z","shell.execute_reply":"2021-06-02T23:48:28.275817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"17. Remove the rows with NaN values in \"windgustdir\" column from the dataframe permanently.","metadata":{}},{"cell_type":"code","source":"df.dropna(subset = [\"windgustdir\"],inplace = True)\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:28.278297Z","iopub.execute_input":"2021-06-02T23:48:28.278622Z","iopub.status.idle":"2021-06-02T23:48:28.36649Z","shell.execute_reply.started":"2021-06-02T23:48:28.278591Z","shell.execute_reply":"2021-06-02T23:48:28.364779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"18. Create a new dataframe, use \"Location\" column as the index of the dataframe, display the min, max, and median values of \"evaporation\" and \"sunshine\" columns in this dataframe.","metadata":{}},{"cell_type":"code","source":"df_2 = df.copy()  \nmin_val = df_2.groupby(\"Location\")[[\"Evaporation\",\"Sunshine\"]].min()\nmin_val","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_val = df_2.groupby('Location')[['Evaporation','Sunshine']].max()\nmax_val","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:28.442454Z","iopub.status.idle":"2021-06-02T23:48:28.443689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"median_value = new_df.groupby('Location')[['Evaporation','Sunshine']].median()\nmedian_val","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:28.444851Z","iopub.status.idle":"2021-06-02T23:48:28.445347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_min_max_median = pd.concat([min_val,max_val,median_val], axis = 1)\ndf_min_max_median","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:48:28.446728Z","iopub.status.idle":"2021-06-02T23:48:28.447359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"19. Find out the hottest day of \"Perth\". Example output: Timestamp('2015-01-05 00:00:00')","metadata":{}},{"cell_type":"code","source":"df_Albury = df[df.location == 'Perth'].sort_values(by='maxtemp', ascending=False)\ndf.date[df_Albury['maxtemp'].idxmax()]","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:50:23.169286Z","iopub.execute_input":"2021-06-02T23:50:23.170417Z","iopub.status.idle":"2021-06-02T23:50:23.208204Z","shell.execute_reply.started":"2021-06-02T23:50:23.170359Z","shell.execute_reply":"2021-06-02T23:50:23.206642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"20. Group your dataframe by location and find out the averages of all numeric values.","metadata":{}},{"cell_type":"code","source":"df.groupby('location').mean()","metadata":{"execution":{"iopub.status.busy":"2021-06-02T23:50:27.787652Z","iopub.execute_input":"2021-06-02T23:50:27.788282Z","iopub.status.idle":"2021-06-02T23:50:27.876182Z","shell.execute_reply.started":"2021-06-02T23:50:27.788239Z","shell.execute_reply":"2021-06-02T23:50:27.874659Z"},"trusted":true},"execution_count":null,"outputs":[]}]}