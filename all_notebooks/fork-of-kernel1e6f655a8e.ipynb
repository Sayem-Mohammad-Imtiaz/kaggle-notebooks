{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random\nimport math\n\nfrom matplotlib.ticker import NullFormatter\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n\nimport itertools","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                              normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve\n\ndef evaluate_model(y_test,predictions, probs):\n    \"\"\"Compare machine learning model to baseline performance.\n    Computes statistics and shows ROC curve.\"\"\"\n    \n    baseline = {}\n    \n    baseline['recall'] = recall_score(y_test, [1 for _ in range(len(y_test))])\n    baseline['precision'] = precision_score(y_test, [1 for _ in range(len(y_test))])\n    baseline['roc'] = 0.5\n    \n    results = {}\n    \n    results['recall'] = recall_score(y_test, predictions)\n    results['precision'] = precision_score(y_test, predictions)\n    results['roc'] = roc_auc_score(y_test, probs)\n    \n    # Calculate false positive rates and true positive rates\n    base_fpr, base_tpr, _ = roc_curve(y_test, [1 for _ in range(len(y_test))])\n    model_fpr, model_tpr, _ = roc_curve(y_test, probs)\n\n    plt.figure(figsize = (4, 3))\n    plt.rcParams['font.size'] = 10\n    \n    # Plot both curves\n    plt.plot(base_fpr, base_tpr, 'b', label = 'baseline')\n    plt.plot(model_fpr, model_tpr, 'r', label = 'model')\n    plt.legend();\n    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate'); plt.title('ROC Curves');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predictAndCreateConfusionMatrix(model,x_data,y_true,y_pred,y_probs,addTitle=''):\n    \n    #Confusion Matrix\n    cnf_matrix = confusion_matrix(y_true, y_pred, labels=[1,0])\n    np.set_printoptions(precision=2)\n\n    # Plot non-normalized confusion matrix\n    plt.figure(figsize = (6,4))\n    plot_confusion_matrix(cnf_matrix, classes=['1','0'],normalize= False,  title='Confusion Matrix: %s %s' % (type(model).__name__,addTitle))\n    plt.show()\n    \n    #Create ROC\n    AUC_rf = roc_auc_score(y_true, y_probs)\n    print(\"AUC for %s %s:\" % (type(model).__name__,addTitle))\n    print(AUC_rf)\n    evaluate_model(y_true,y_pred,y_probs)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cleanDataset(dfOrig, lsContVars, missingStrategy = 'DropNA', dropAge = 0, dropOutliers_low = .00, dropOutliers_high = 1.0):\n    print(\"\\nPrior to cleaning the original dataframe contains %d rows\" % len(dfOrig.index))\n    \n    #Minimum Age\n    if dropAge is not None:\n        lsIndexesAge = list(dfOrig[dfOrig['age'] <= dropAge].index)\n        print(\"There are %d indexes deleted for having an age of %d or less.\" % (len(lsIndexesAge),dropAge))\n        \n    #Drop Missing\n    lsMissingIndex = []\n    if missingStrategy:\n        lenBeforeMissing = len(dfOrig.index)\n        lsMissingDataHandling = missingDataHandling(dfOrig, missingStrategy, lsContVars)\n        dfOrig = lsMissingDataHandling[0]\n        lsMissingIndex = lsMissingDataHandling[1]\n        print(\"There are %d indexes deleted for having missing variables.\" % (lenBeforeMissing-len(dfOrig.index)))\n\n    #Clean Dataset for Outlier Detection\\\n    dfClean = dfOrig.loc[~dfOrig.index.isin(lsIndexesAge)]\n    lsIndexesClean = dfClean.index\n    print(\"The clean dataset now has %d rows before deleting outliers.\" % len(dfClean.index))\n\n    #Detect and store Outlier indexes\n    dfQuantile = dfClean.quantile([dropOutliers_low,dropOutliers_high])\n    \n    dfClean = dfClean.apply(lambda x: x[(x >= dfQuantile.loc[dropOutliers_low,x.name]) &\n                            (x <= dfQuantile.loc[dropOutliers_high,x.name])], axis = 0).dropna()\n    lsIndexesNonOutliers = dfClean.index\n    print(\"The clean dataset now has %d rows after deleting outliers.\\n\" % len(dfClean.index))\n    \n    lsIndexesOutliers = [ix for ix in lsIndexesClean if ix not in lsIndexesNonOutliers]\n    \n    return {'dfClean':dfClean,'lsIndexesAge':lsIndexesAge,'lsMissingIndex':lsMissingIndex,'lsIndexesOutliers':lsIndexesOutliers}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def missingDataHandling(dfOrig, missingStrategy, lsColImpute = []):\n\n    if len(lsColImpute) == 0:\n        lsColImpute = dfOrig.columns\n\n    if missingStrategy == \"DropNA\":\n        lsOrigIndex = list(dfOrig.index)\n        dfDropNA = dfOrig.dropna()\n        lsDropNAIndex = list(dfDropNA.index)\n        lsMissingIndex = list(set(lsOrigIndex) - set(lsDropNAIndex))\n        \n        return [dfDropNA, lsMissingIndex]\n\n    if missingStrategy == \"Mean\" or missingStrategy == \"Mode\":\n        dfDescribe = dfOrig.describe()\n\n        for col in lsColImpute:\n\n            valImpute = dfDescribe.loc[missingStrategy.lower(), col]\n\n            lsMissingIndex = pd.isna(dfOrig[col])\n\n            dfOrig.loc[lsMissingIndex,col] = valImpute\n\n    return [dfOrig, []]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def createVariables(dfModel, blExtraCont=True, blDiscrete=True, blInteraction=True):\n\n    #Continuous\n    if blExtraCont:\n        dfModel['NumberOfNonRealEstateCreditLines'] = dfModel['NumberOfOpenCreditLinesAndLoans']  - dfModel['NumberRealEstateLoansOrLines']\n        dfModel['TotalDebtIncome'] = dfModel['DebtRatio'] * dfModel['MonthlyIncome']\n        dfModel['NumberOfTimesPastDue'] = dfModel['NumberOfTime30-59DaysPastDueNotWorse'] + dfModel['NumberOfTime60-89DaysPastDueNotWorse'] + dfModel['NumberOfTimes90DaysLate']\n    \n    #Discretize Age\n    if blDiscrete:\n        dfModel.loc[:,'disc_age'] = '<29'\n\n        dfModel.loc[:,'age_21_29'] = 0\n        lsIx = dfModel.loc[(dfModel['age'] <= 29)].index\n        dfModel.loc[lsIx,'age_21_29'] = 1\n\n        dfModel.loc[:,'age_30_69'] = 0\n        lsIx = dfModel.loc[(dfModel['age'] >= 30) & (dfModel['age']<= 69)].index\n        dfModel.loc[lsIx,'age_30_69'] = 1\n        dfModel.loc[lsIx,'disc_age'] = '30_69'\n\n        dfModel.loc[:,'age_70_'] = 0\n        lsIx = dfModel.loc[(dfModel['age'] >= 70)].index\n        dfModel.loc[lsIx,'age_70_'] = 1\n        dfModel.loc[lsIx,'disc_age'] = '>70'\n\n        #Number Credit Lines\n        dfModel.loc[:,'disc_numcreditlines'] = '<4'\n        lsIx = dfModel.loc[(dfModel['NumberOfOpenCreditLinesAndLoans'] >=4)].index\n        dfModel.loc[lsIx,'disc_numcreditlines'] = '4+'\n\n        #Income\n        dfModel.loc[:,'disc_income'] = '<1000'\n\n        dfModel.loc[:,'income_0_1999'] = 0\n        lsIx = dfModel.loc[(dfModel['MonthlyIncome'] <= 1999)].index\n        dfModel.loc[lsIx,'income_0_1999'] = 1\n\n        dfModel.loc[:,'income_1999_13000'] = 0\n        lsIx = dfModel.loc[(dfModel['MonthlyIncome'] > 1999) & (dfModel['MonthlyIncome']<= 13000)].index\n        dfModel.loc[lsIx,'income_1999_13000'] = 1\n        dfModel.loc[lsIx,'disc_income'] = '1999_13000'\n\n        dfModel.loc[:,'income_13000_'] = 0\n        lsIx = dfModel.loc[(dfModel['MonthlyIncome'] > 13000)].index\n        dfModel.loc[lsIx,'income_13000_'] = 1\n        dfModel.loc[lsIx,'disc_income'] = '>13000'\n        \n        dfModel.loc[:,'DRgt0_MIeq0'] = 0\n        dfModel.loc[(dfModel['DebtRatio'] > 0) & (dfModel['MonthlyIncome'] == 0),'DRgt0_MIeq0'] = 1\n        \n        dfModel.loc[:,'NREgt0_MIeq0'] = 0\n        dfModel.loc[(dfModel['NumberRealEstateLoansOrLines'] == dfModel['NumberOfOpenCreditLinesAndLoans']),'NREgt0_MIeq0'] = 1\n        \n        dfModel.loc[:,'RUeq0_NREeq0_DRgt0'] = 0\n        dfModel.loc[(dfModel['RevolvingUtilizationOfUnsecuredLines'] == 0) & (dfModel['NumberRealEstateLoansOrLines'] == 0) & (dfModel['DebtRatio'] > 0),'RUeq0_NREeq0_DRgt0'] = 1\n    \n    #Interaction\n    if blInteraction:\n        dfModel['irc_age_21_29'] = dfModel['age_21_29'] * dfModel['age']\n        dfModel['irc_age_30_69'] = dfModel['age_30_69'] * dfModel['age']\n        dfModel['irc_age_70_'] = dfModel['age_70_'] * dfModel['age']\n\n        dfModel['irc_income_0_1999'] = dfModel['income_0_1999'] * dfModel['MonthlyIncome']\n        dfModel['irc_income_1999_13000'] = dfModel['income_1999_13000'] * dfModel['MonthlyIncome']\n    \n    print(dfModel.columns)\n    print(dfModel.dtypes)\n    \n    return dfModel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def transformData(dfModel,blNormalizeCont,x_var_cont,x_var_disc=[],x_var_intc=[]):\n    print(\"Transforming data...\")\n    #To Preserve Index\n    dfModel['Index'] = dfModel.index\n    #Continuous\n    x_cont = np.asarray(dfModel[x_var_cont])\n    if blNormalizeCont:\n        x_cont = preprocessing.StandardScaler().fit(x_cont).transform(x_cont)\n\n    #Add to full variable\n    x_full = x_cont#np.concatenate((x_full,x_cont),axis=1)\n    \n    #Add discrete\n    if len(x_var_disc) > 0:\n        x_disc = np.asarray(dfModel[x_var_disc])\n        x_full = np.concatenate((x_full,x_disc),axis=1)\n    \n    #Interaction\n    if len(x_var_intc) > 0:\n        x_intc = np.asarray(dfModel[x_var_intc])\n        x_full = np.concatenate((x_full,x_intc),axis=1)\n    \n    print(\"arrays:\")\n    print(type(x_full))\n    print(type(x_full[1]))\n    \n    #np.concatenate((x_full,np.asarray(dfModel['Index']))\n    print(x_full)\n    return x_full","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def createRandomDataFrameSplit(dfSplit, leftSplit=.5, randomSeed=4):\n    \n    lsIndex = list(dfSplit.index)\n    \n    #Shuffle\n    random.seed(randomSeed)\n    random.shuffle(lsIndex)\n\n    ixLeft = math.ceil(len(lsIndex)*(1-leftSplit))\n    \n    lsIndexLeft = lsIndex[:ixLeft+1]\n    lsIndexRight = lsIndex[ixLeft+1:]\n    \n    return {'dfLeft':dfSplit.loc[lsIndexLeft],'dfRight':dfSplit.loc[lsIndexRight]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def returnTrainTestSplit(dfModel, y_var, blNormalizeCont, x_var_cont, x_var_disc, x_var_intc, testSplit=.2, randomSeed=4):\n    lsRegressors = x_var_cont + x_var_disc + x_var_intc\n    \n    dictTrainTest = createRandomDataFrameSplit(dfModel,testSplit,randomSeed)\n    dfTrain = dictTrainTest['dfLeft']\n    dfTest = dictTrainTest['dfRight']\n    \n    x_train = transformData(dfTrain.loc[:,lsRegressors],blNormalizeCont,x_var_cont,x_var_disc,x_var_intc)\n    y_train = np.asarray(dfTrain[y_var])\n    x_test = transformData(dfTest.loc[:,lsRegressors],blNormalizeCont,x_var_cont,x_var_disc,x_var_intc)\n    y_test = np.asarray(dfTest[y_var])\n    \n    return x_train, x_test, y_train, y_test, dfTrain.index, dfTest.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def runModels(dfModel, y_var, x_var_cont, x_var_disc, x_var_intc, blNormalizeCont, test_split, randomSeed, blRunLogistic, blRunLogisticCV, blRunDecisionTree, blRunRandomForest, numTrees, blRunCV):\n    #Create arrays and define regressors\n    lsRegressors = x_var_cont + x_var_disc + x_var_intc\n    \n    dictModels = {}\n    \n    #Define train and test split\n    x_train, x_test, y_train, y_test, x_train_index, x_test_index = returnTrainTestSplit(dfModel, y_var, blNormalizeCont, x_var_cont, x_var_disc, x_var_intc, test_split, randomSeed)\n    print ('Train set:', x_train.shape,  y_train.shape)\n    print ('Test set:', x_test.shape,  y_test.shape)\n    \n    #Define Display Function\n    def displayModel(model):\n        nameModel = type(model).__name__\n        print(\"\\nDisplaying results for model %s:\\n\" % nameModel)\n        \n        y_pred_train = model.predict(x_train)\n        y_probs_train = model.predict_proba(x_train)[:,1]\n        y_pred_test = model.predict(x_test)\n        y_probs_test = model.predict_proba(x_test)[:,1]\n        \n        predictAndCreateConfusionMatrix(model,x_train,y_train,y_pred_train,y_probs_train,'Train')\n        predictAndCreateConfusionMatrix(model,x_test,y_test,y_pred_test,y_probs_test,'Test')\n        \n        dictModels[nameModel] = {'model': model,'pred_train_split' : y_pred_train, 'pred_test_split' : y_pred_test}\n        print('')\n    \n    #Run Logistic\n    if blRunLogistic:\n        model_LR = LogisticRegression(C=.01,solver='liblinear').fit(x_train,y_train)\n        print(model_LR)\n        from collections import OrderedDict\n        dictCoeff = OrderedDict()\n        inc = 0\n        for coef in lsRegressors:\n            dictCoeff[coef] = model_LR.coef_[0][inc]/(1-model_LR.coef_[0][inc])\n            print(coef + ': ' + str(dictCoeff[coef]))\n            inc+=1\n        \n        displayModel(model_LR)\n    \n    if blRunLogisticCV:\n        model_LRCV = LogisticRegressionCV(cv=10).fit(x_train,y_train)\n        \n        displayModel(model_LRCV)\n \n    #Run Decision Tree Classifier\n    if blRunDecisionTree:\n        model_clf = DecisionTreeClassifier()\n        model_clf = model_clf.fit(x_train,y_train)\n        \n        displayModel(model_clf)\n    \n    #Run Random Forest\n    if blRunRandomForest:\n        # Create the model with 100 trees\n        model_RF = RandomForestClassifier(n_estimators=numTrees, \n                                   bootstrap = True,\n                                   max_features = 'sqrt',random_state = randomSeed)\n        # Fit on training data\n        model_RF.fit(x_train,y_train)\n        \n        #Create Confusion Matrices\n        displayModel(model_RF)\n\n    if blRunCV:\n        # Hyperparameter grid\n        param_grid = {\n            'n_estimators': np.linspace(10, 200).astype(int),\n            'max_depth': [None] + list(np.linspace(3, 20).astype(int)),\n            'max_features': ['auto', 'sqrt', None] + list(np.arange(0.5, 1, 0.1)),\n            'max_leaf_nodes': [None] + list(np.linspace(10, 50, 500).astype(int)),\n            'min_samples_split': [2, 5, 10],\n            'bootstrap': [True, False]\n        }\n\n        # Estimator for use in random search\n        estimator = RandomForestClassifier()\n\n        # Create the random search model\n        model_CV = RandomizedSearchCV(estimator, param_grid, n_jobs = -1, \n                                scoring = 'roc_auc', cv = 3, \n                                n_iter = 10, verbose = 1, random_state=randomSeed)\n\n        # Fit \n        model_CV.fit(x_train, y_train)\n        \n        #Params and Best Model\n        model_CV.best_params_\n        model_CV_best = model_CV.best_estimator_\n        \n        displayModel(model_CV_best)\n    \n    dictRunModels = {}\n    dictRunModels['dictModels'] = dictModels\n    dictRunModels['train_index'] = x_train_index\n    dictRunModels['test_index'] = x_test_index\n    \n    print(\"Models returned:\")\n    print(dictRunModels['dictModels'].keys())\n    return dictRunModels\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def createResultFrame(model, cs_test, x_test, colID, lsMissingIndex):\n   \n    #Predict\n    predics_test = model.predict(x_test)\n    probs_test = model.predict_proba(x_test)\n    print(\"There were %d probabilities generated.\" % len(probs_test))\n\n    #Create Result Frame\n    namePredCol = colID +'_pred'\n    nameProbCol = colID +'_prob'\n    dfPred = pd.DataFrame(index=cs_test.index,columns=[namePredCol])                         \n    #dfResult[namePredCol] = 1\n    dfPred.loc[~dfPred.index.isin(lsMissingIndex),namePredCol] = predics_test\n    dfPred.loc[~dfPred.index.isin(lsMissingIndex),nameProbCol] = probs_test[:,1]\n    dfPred[nameProbCol] = dfPred[nameProbCol].astype(float)\n    dfPred[namePredCol] = dfPred[namePredCol].astype(float)\n\n    return dfPred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cleanTestDataSet(cs_test, x_var_cont, x_var_disc, x_var_intc, colID, missingStrategy, blNormalizeCont, outlier_low, outlier_high):\n    print(\"Cleaning test data set for predictions....\")\n        \n    #Drop ID\n    cs_test = cs_test.drop([colID], axis=1)\n    \n    #Get Clean Dict\n    dictClean = cleanDataset(cs_test, x_var_cont, missingStrategy, 0, outlier_low, outlier_high)\n    dfClean = dictClean['dfClean']\n    \n    lsMissingIndex = []\n    for nameMissing in dictClean.keys():\n        if nameMissing != 'dfClean':\n            lsMissingIndex += dictClean[nameMissing]\n    lsMissingIndex = list(set(lsMissingIndex))\n    print(\"Length Missing: %d/n\" % len(lsMissingIndex))\n    \n    #Create Variables\n    dfModel = createVariables(dfClean)\n    #print(dfModel.dtypes)\n    #print(dfModel.describe())\n    \n    x_test = transformData(dfModel, blNormalizeCont, x_var_cont, x_var_disc, x_var_intc)\n    \n    return [x_test,lsMissingIndex]\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def runProcess(cs_training, cs_test, y_col='SeriousDlqin2yrs',\n               x_var_cont=[], x_var_disc=[], x_var_intc=[], missingStrategy = 'DropNA', blNormalizeCont=True, \n               test_split = .2, randomSeed = 4, outlier_low = .02, outlier_high = .98,\n               blRunLogistic=True, blRunLogisticCV=True, blRunDecisionTree=True, blRunRandomForest=True, numTrees=100, blRunCV=True):\n    \n    #Get Clean Dict\n    dictClean = cleanDataset(cs_training, x_var_cont, missingStrategy, 0, outlier_low, outlier_high)\n    dfClean = dictClean['dfClean']\n    \n    #Create Variables\n    dfModel = createVariables(dfClean)\n    \n    dictRunModels = runModels(dfModel, y_col, x_var_cont, x_var_disc, x_var_intc, blNormalizeCont, \n                           test_split, randomSeed, blRunLogistic, blRunLogisticCV, blRunDecisionTree, blRunRandomForest, numTrees, blRunCV)\n    \n    #Create test data set and run predictions\n    lsCleanDataItems = cleanTestDataSet(cs_test, x_var_cont, x_var_disc, x_var_intc, y_col, missingStrategy, blNormalizeCont, outlier_low, outlier_high)\n    x_test = lsCleanDataItems[0]\n    lsMissingIndex = lsCleanDataItems[1]\n    \n    dictResults = {}\n    for model in dictRunModels['dictModels'].keys():\n        dfPredict = createResultFrame(dictRunModels['dictModels'][model]['model'],cs_test,x_test,y_col,lsMissingIndex)#x_var_cont,x_var_disc,x_var_intc,\n        dfResult = cs_test.merge(dfPredict,how='left',left_index=True,right_index=True)\n        dictResults[model] = dfResult\n    \n    lsIndexTrain = dictRunModels['train_index']\n    return {'dictRunModels':dictRunModels,'dictResults':dictResults,'dfTrain':dfModel.loc[lsIndexTrain,:],'dfTrainTest':dfModel.loc[~dfModel.index.isin(lsIndexTrain),:]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Run everything before here\ncs_test = pd.read_csv(\"../input/give-me-some-credit-dataset/cs-test.csv\")\ncs_training = pd.read_csv(\"../input/give-me-some-credit-dataset/cs-training.csv\")\nsampleEntry = pd.read_csv(\"../input/give-me-some-credit-dataset/sampleEntry.csv\")\ncs_training.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Define Regressors\nlsContinuous = ['RevolvingUtilizationOfUnsecuredLines', 'age', 'NumberOfTime30-59DaysPastDueNotWorse',\n                         'MonthlyIncome','NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate',#'DebtRatio',\n                         'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse',\n                         'NumberOfDependents']\nlsExtraContinuous = ['NumberOfNonRealEstateCreditLines','TotalDebtIncome','NumberOfTimesPastDue']\nlsInteraction = ['irc_age_21_29','irc_age_30_69','irc_age_70_','irc_income_0_1999','irc_income_1999_13000']\nlsDiscrete = ['DRgt0_MIeq0','NREgt0_MIeq0']#'age_21_29','age_70_','income_0_1999','income_13000_']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cs_test_debtratio0_monthinc0 = cs_test.loc[(cs_training['DebtRatio'] > 0) & (cs_training['MonthlyIncome'] == 0),]\ncs_training_debtratio0_monthinc0 = cs_training.loc[(cs_training['DebtRatio'] > 0) & (cs_training['MonthlyIncome'] == 0),]\ndictProcess_debtratio0_monthinc0 = runProcess(cs_training_debtratio0_monthinc0, cs_test_debtratio0_monthinc0, x_var_cont=lsContinuous, missingStrategy = \"Mean\", outlier_low = .005, outlier_high = .995, blRunDecisionTree=False, blRunRandomForest=False, blRunCV=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cs_test_NumRealeqNumOpenCredit = cs_test.loc[(cs_test['NumberRealEstateLoansOrLines'] == cs_test['NumberOfOpenCreditLinesAndLoans']),]\ncs_training_NumRealeqNumOpenCredit = cs_training.loc[(cs_training['NumberRealEstateLoansOrLines'] == cs_training['NumberOfOpenCreditLinesAndLoans']),]\ndictProcess_NumRealeqNumOpenCredit = runProcess(cs_training_NumRealeqNumOpenCredit, cs_test_NumRealeqNumOpenCredit, x_var_cont=lsContinuous, missingStrategy = \"Mean\", outlier_low = .005, outlier_high = .995, blRunDecisionTree=False, blRunRandomForest=False, blRunCV=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cs_test_NumRevolveeqNumReal = cs_test.loc[(cs_test['RevolvingUtilizationOfUnsecuredLines'] == 0) & (cs_test['NumberRealEstateLoansOrLines'] == 0) & (cs_test['DebtRatio'] > 0),]\ncs_training_NumRevolveeqNumReal = cs_training.loc[(cs_training['RevolvingUtilizationOfUnsecuredLines'] == 0) & (cs_training['NumberRealEstateLoansOrLines'] == 0) & (cs_training['DebtRatio'] > 0),]\ndictProcess_NumRevolveeqNumReal = runProcess(cs_training_NumRevolveeqNumReal, cs_test_NumRevolveeqNumReal, x_var_cont=lsContinuous, missingStrategy = \"Mean\", outlier_low = .005, outlier_high = .995, blRunDecisionTree=False, blRunRandomForest=False, blRunCV=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cs_training.loc[(cs_training['DebtRatio'] > 0) & (cs_training['MonthlyIncome'] == 0)].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cs_training.loc[(cs_training['DebtRatio'] >= 5000)].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cs_training.loc[(cs_training['NumberRealEstateLoansOrLines'] == cs_training['NumberOfOpenCreditLinesAndLoans'])].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cs_training.loc[ (cs_training['NumberRealEstateLoansOrLines'] == cs_training['NumberOfOpenCreditLinesAndLoans'])  & (cs_training['RevolvingUtilizationOfUnsecuredLines'] > 0)].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cs_training.loc[(cs_training['RevolvingUtilizationOfUnsecuredLines'] == 0) & (cs_training['NumberRealEstateLoansOrLines'] == 0) & (cs_training['DebtRatio'] > 0)].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dictProcess = runProcess(cs_training, cs_test, x_var_cont=lsContinuous, missingStrategy = \"Mean\", outlier_low = .002, outlier_high = .998, blRunDecisionTree=False, blRunRandomForest=False, blRunCV=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dictProcess = runProcess(cs_training, cs_test, x_var_cont=lsContinuous, x_var_disc=lsDiscrete, missingStrategy = \"Mean\", outlier_low = .002, outlier_high = .998, blRunDecisionTree=False, blRunRandomForest=False, blRunCV=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dictProcess.keys()\ndfTrain = dictProcess['dfTrain']\ndfTrainTest = dictProcess['dfTrainTest']\nlsLogisticPreds_train = dictProcess['dictRunModels']['dictModels']['LogisticRegression']['pred_train_split']\nlsLogisticPreds_traintest = dictProcess['dictRunModels']['dictModels']['LogisticRegression']['pred_test_split']\ndfTrain['SeriousDlqin2yrs_pred'] = lsLogisticPreds_train\ndfTrainTest['SeriousDlqin2yrs_pred'] = lsLogisticPreds_traintest\ndfTrain_Disagree = dfTrain.loc[(dfTrain['SeriousDlqin2yrs'] != dfTrain['SeriousDlqin2yrs_pred'])]\ndfTrainTest_Disagree = dfTrainTest.loc[(dfTrainTest['SeriousDlqin2yrs'] != dfTrainTest['SeriousDlqin2yrs_pred'])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfTrain.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfTrain_Disagree.describe()\n#dfTrain_Disagree.iloc[:50,]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfTrain_Disagree.loc[(dfTrain['SeriousDlqin2yrs']==1)].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfTrain_Disagree.loc[(dfTrain['SeriousDlqin2yrs']==0)].describe()\n#dfTrain_Disagree.loc[(dfTrain['SeriousDlqin2yrs']==0)].iloc[:50,]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfTrainTest.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfTrainTest_Disagree.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfResults_Logistic = dictProcess['dictResults']['LogisticRegression']\ndfResults_Logistic.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfResults_Logistic.loc[(pd.isnull(dfResults_Logistic['SeriousDlqin2yrs_pred'])),'SeriousDlqin2yrs_prob'] = .5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfSubmit = pd.DataFrame(columns=['Id','Probability'],index=dfResults_Logistic.index)\n\ndfSubmit['Id'] = [item for item in range(1,len(cs_test.index)+1)]\ndfSubmit['Probability'] = dfResults_Logistic['SeriousDlqin2yrs_prob']\n\ndfSubmit.iloc[2000:5000]\ndfSubmit.to_csv('GiveMeCredit_Sub3.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dictResult = runProcess(cs_training, cs_test, x_var_cont=lsContinuous, blRunDecisionTree=False, blRunRandomForest=True, blRunCV=False)","execution_count":null,"outputs":[]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python [conda root]","language":"python","name":"conda-root-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":4}