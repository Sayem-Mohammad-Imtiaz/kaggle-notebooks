{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_t = pd.read_csv('/kaggle/input/language-translation-englishfrench/eng_-french.csv')\n\ndf = train_t[0:100000]\n\nimport re\nenglish = []\nfrench = []\nfor i in df['English words/sentences']:\n    text = i.lower()\n    text = re.sub('[^a-zA-Z]',' ',text)\n    text = re.sub(' +',' ',text)\n    text = text[:-1]\n    english.append(text)\n\nfor j in df['French words/sentences']:\n    ftext =  j.lower()\n    ftext = (re.sub(\"[^a-zA-Z' àâäèéêëîïôœùûüÿçÀÂÄÈÉÊËÎÏÔŒÙÛÜŸÇ]\",' ',ftext))\n    ftext = re.sub(' +',' ',ftext)\n    ftext = ftext[:-1]\n    french.append(\"start_ \" + ftext + \" _end\")\n    \ncleaned_data = pd.DataFrame({'english':english,'french':french})\n\nenglish_words = []\nfrench_words = []\n\nfor i in cleaned_data['english']:\n    english_words.append(len(i.split()))\n\nfor j in cleaned_data['french']:\n    french_words.append(len(j.split()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sn\nimport matplotlib.pyplot as plt\n\nsn.countplot(english_words)\nplt.show()\n\nsn.countplot(x = french_words)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_len_english = max(english_words)\nmax_len_french = max(french_words)\n\nfrom sklearn.model_selection import train_test_split\nx_tr,x_val,y_tr,y_val=train_test_split(cleaned_data['english'],cleaned_data['french'],test_size=0.1,random_state=12,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nx_tokens = Tokenizer()\nx_tokens.fit_on_texts(x_tr)\n\nx_tr = x_tokens.texts_to_sequences(x_tr)\nx_val = x_tokens.texts_to_sequences(x_val)\n\nfrom keras.preprocessing.sequence import pad_sequences\nx_tr = pad_sequences(x_tr,maxlen = max_len_english,padding = 'post')\nx_val = pad_sequences(x_val,maxlen = max_len_english,padding = 'post')\n\n# +1 for padding \nx_voc_size   =  len(x_tokens.word_index) +1\n\n# y data\nfrom keras.preprocessing.text import Tokenizer\ny_tokens = Tokenizer()\ny_tokens.fit_on_texts(y_tr)\n\ny_tr = y_tokens.texts_to_sequences(y_tr)\ny_val = y_tokens.texts_to_sequences(y_val)\n\nfrom keras.preprocessing.sequence import pad_sequences\ny_tr = pad_sequences(y_tr,maxlen = max_len_french,padding = 'post')\ny_val = pad_sequences(y_val,maxlen = max_len_french,padding = 'post')\n\n# +1 for padding \ny_voc_size   =  len(y_tokens.word_index) +1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from attention import AttentionLayer\nfrom tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras import backend as K \nK.clear_session()\n\nlatent_dim = 300\n\nencoder_inputs = Input(shape=(max_len_english,))\n\nenc_emb =  Embedding(x_voc_size, latent_dim,trainable=True)(encoder_inputs)\n\nencoder_lstm1 = Bidirectional(LSTM(latent_dim,return_sequences=True,return_state=True))\nencoder_output1, forward_h1, forward_c1, backward_h1, backward_c1 = encoder_lstm1(enc_emb)\n\nencoder_lstm2 = Bidirectional(LSTM(latent_dim,return_sequences=True,return_state=True))\nencoder_output2, forward_h2, forward_c2, backward_h2, backward_c2 = encoder_lstm2(encoder_output1)\n\nencoder_lstm3 = Bidirectional(LSTM(latent_dim, return_state=True, return_sequences=True))\nencoder_outputs, forward_h3, forward_c3, backward_h3, backward_c3= encoder_lstm3(encoder_output2)\n\nstate_h = Concatenate()([forward_h3,backward_h3])\nstate_c = Concatenate()([forward_c3,backward_c3])\n\ndecoder_inputs = Input(shape=(None,))\n\ndec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True)\ndec_emb = dec_emb_layer(decoder_inputs)\n\ndecoder_lstm = LSTM(600, return_sequences=True, return_state=True)\ndecoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n\nattn_layer = AttentionLayer(name='attention_layer')\nattn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n\ndecoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n\ndecoder_dense =  TimeDistributed(Dense(y_voc_size, activation='softmax'))\ndecoder_out = decoder_dense(decoder_concat_input)\n\nmodel = Model([encoder_inputs, decoder_inputs], decoder_out)\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\nes = EarlyStopping(monitor='val_loss', mode='min')\nhistory=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot\npyplot.plot(history.history['loss'], label='train')\npyplot.plot(history.history['val_loss'], label='test')\npyplot.legend()\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reverse_target_word_index=y_tokens.index_word\nreverse_source_word_index=x_tokens.index_word\ntarget_word_index=y_tokens.word_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n\ndecoder_state_input_h = Input(shape=(600,))\ndecoder_state_input_c = Input(shape=(600,))\ndecoder_hidden_state_input = Input(shape=(max_len_english,600))\n\ndec_emb2= dec_emb_layer(decoder_inputs) \n\ndecoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n\nattn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\ndecoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n\ndecoder_outputs2 = decoder_dense(decoder_inf_concat) \n\ndecoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n    [decoder_outputs2] + [state_h2, state_c2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_sequence(input_seq):\n    e_out, e_h, e_c = encoder_model.predict(input_seq)\n\n    target_seq = np.zeros((1,1))\n    \n    target_seq[0, 0] = target_word_index['start']\n\n    stop_condition = False\n    decoded_sentence = ''\n    while not stop_condition:\n      \n        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_token = reverse_target_word_index[sampled_token_index]\n        \n        if(sampled_token!='end'):\n            decoded_sentence += ' '+sampled_token\n\n        if (sampled_token == 'end'  or len(decoded_sentence.split()) >= (max_len_french-1)):\n            stop_condition = True\n\n        target_seq = np.zeros((1,1))\n        target_seq[0, 0] = sampled_token_index\n        \n        e_h, e_c = h, c\n\n    return decoded_sentence","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seq2summary(input_seq):\n    newString=''\n    for i in input_seq:\n      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n        newString=newString+reverse_target_word_index[i]+' '\n    return newString\n\ndef seq2text(input_seq):\n    newString=''\n    for i in input_seq:\n      if(i!=0):\n        newString=newString+reverse_source_word_index[i]+' '\n    return newString\n\n\nfor i in range(11,20):\n  print(\"Review:\",seq2text(x_val[i]))\n  print(\"Original summary:\",seq2summary(y_val[i]))\n  print(\"Predicted summary:\",decode_sequence(x_val[i].reshape(1,max_len_english)))\n  print(\"\\n\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}