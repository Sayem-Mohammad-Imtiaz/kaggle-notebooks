{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Task Description\n\nDataset: Stroke Prediction Dataset\n\nKaggle: https://www.kaggle.com/fedesoriano/stroke-prediction-dataset","metadata":{}},{"cell_type":"code","source":"# %% === < Global Setting: Time and Seed > ===\nimport time\nimport numpy as np\nUTC_time = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime()) # Colab UTC time\nlocal_time = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime(time.time()+8*3600)) # Colab for UTC+8\nprint(\"UTC Time:\", UTC_time)\nprint(\"Local Time (UTC+8):\", local_time)\nseed = int(round(1000000*np.random.random()))\nseed = 2021\nprint(\"Seed:\", seed)\nnp.random.seed(seed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Importing and Preprocessing\n\nUsing Pandas to import data and doing preprocessing","metadata":{}},{"cell_type":"code","source":"# %% === < Importing the raw data > ===\nimport pandas as pd\ndata_raw = pd.read_csv('/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')\nprint(data_raw.shape)\ndata_raw.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %% === < Droping out the null data and useless variables > ===\ndata_raw[data_raw.isnull().any(axis=1)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data_raw[\"gender\"].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_raw[data_raw['gender']=='Other']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dropna = data_raw.dropna()\nprint(data_dropna.shape)\ndata_dropna = data_dropna.drop([3116])\nprint(data_dropna[\"gender\"].value_counts())\nprint(data_dropna.shape)\ndata_dropna = data_dropna.drop(columns=['id']) # dropout non-using column\nprint(data_dropna.shape)\ndata_dropna.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data preprocessing and Visualization\n\nUsing Pandas, Matplolib, Seaborn to prepare date for analysis and visualize","metadata":{}},{"cell_type":"code","source":"data_dropna[\"work_type\"] = data_dropna[\"work_type\"].astype('category')\ndata_dropna[\"smoking_status\"] = data_dropna[\"smoking_status\"].astype('category')\ndata_dropna[\"Residence_type\"] = data_dropna[\"Residence_type\"].astype('object')\ndata_dropna[\"hypertension\"] = data_dropna[\"hypertension\"].astype('object')\ndata_dropna[\"heart_disease\"] = data_dropna[\"heart_disease\"].astype('object')\ndata_dropna[\"stroke\"] = data_dropna[\"stroke\"].astype('int8')\nprint(data_dropna.dtypes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %% === < Showing correlations between variables > ===\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.rcParams['axes.titlesize'] = 16\nplt.rcParams['axes.labelsize'] = 14\nplt.rcParams['xtick.labelsize'] = 12\nplt.rcParams['ytick.labelsize'] = 12\nplt.rcParams['legend.fontsize'] = 12\n\nplt.figure(figsize=(8,6))\nsns.heatmap(data_dropna.corr(), cmap=\"coolwarm\", annot=True, vmin=-1, vmax=1, fmt='.2g')\nplt.title('Correlation of Continuous Variables')\n# plt.savefig(output_folder+'Correlation of Variables.png', dpi=300)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_conti = data_dropna.select_dtypes(include=['float64']).copy()\ndata_conti.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %% === < Drawing violinplots of continuous variables > ===\nfor idx,feature in enumerate(data_conti):\n  plt.figure(figsize=(8,6))\n  sns.violinplot(y = data_conti[feature], x = data_dropna['stroke'], palette=\"Set3\")\n  plt.title('Violinplot of %s'%feature)\n#   plt.savefig(output_folder+'Violinplot of %s.png'%feature, dpi=300)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_obj = data_dropna.select_dtypes(include=['object']).copy()\ndata_obj.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %% === < Drawing boxplots of catergorical variables > ===\nfor idx,feature in enumerate(data_obj):\n  plt.figure(figsize=(8,6))\n  sns.barplot(x = data_obj[feature], y = data_dropna['stroke'])\n  plt.title('Barplot of %s'%feature)\n#   plt.savefig(output_folder+'Barplot of %s.png'%feature, dpi=300)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data_obj[\"ever_married\"].value_counts())\nprint()\nprint(data_obj[\"gender\"].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleanup_vars = {\"ever_married\": {\"No\":0,\"Yes\":1},\n         \"gender\": {\"Male\":0,\"Female\":1}}\ndata_obj = data_obj.replace(cleanup_vars).astype('object')\ndata_obj.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabel_vars = [\"Residence_type\"]\ndata_obj[label_vars] = data_obj[label_vars].apply(LabelEncoder().fit_transform).astype('object')\ndata_obj.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_catg = data_dropna.select_dtypes(include=['category']).copy()\ndata_catg.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %% === < Drawing boxplots of catergorical variables > ===\nfor idx,feature in enumerate(data_catg):\n  plt.figure(figsize=(8,6))\n  sns.barplot(x = data_catg[feature], y = data_dropna['stroke'])\n  plt.title('Barplot of %s'%feature)\n#   plt.savefig(output_folder+'Barplot of %s.png'%feature, dpi=300)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### One-Hot-Encoding \n\nUsing one-hot-encoding (dummy coding) to sparse data\n\nFor preparing to train models\n\nReference:\n\n* https://medium.com/@PatHuang/%E5%88%9D%E5%AD%B8python%E6%89%8B%E8%A8%98-3-%E8%B3%87%E6%96%99%E5%89%8D%E8%99%95%E7%90%86-label-encoding-one-hot-encoding-85c983d63f87\n\n* https://www.kaggle.com/getting-started/27270\n\n* https://pbpython.com/categorical-encoding.html","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ndata_dummy = pd.get_dummies(data_catg)\ndata_dummy.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Rebuilding Data (concat)\n\nIf neccessary, droping out useless variables","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ndata = pd.concat([data_conti,data_obj,data_dummy,data_dropna[\"stroke\"]], axis=1)\nprint(data.shape)\ndata.head()\n# data.to_excel(output_folder+'Data_StatisticsDummy.xlsx',sheet_name='dummy') ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Balance\n\nUsing re-sampling method to balance different targets\n\nReference (Imbalanced-Learn):\n\n* https://imbalanced-learn.org/stable/index.html","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split # Import train_test_split function\n\ndropout_cols = ['stroke']\nX = data.drop(columns=dropout_cols) # Predictors\ny = data['stroke'] # Target variable\nprint('Shape of original dummy coding data X and y: ',X.shape,y.shape)\nprint()\n\n# === Spliting dataset into training set and test set\nX_train_raw, X_test, y_train_raw, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\nprint('Shape of testing data X and y: ',X_test.shape,y_test.shape)\nprint('Testing data - No stroke: %d'%y_test[y==0].shape)\nprint('Testing data - Yes stroke: %d'%y_test[y==1].shape)\nprint()\nprint('Shape of training data X and y: ',X_train_raw.shape,y_train_raw.shape)\nprint('Before over sampling - No stroke: %d'%y_train_raw[y==0].shape)\nprint('Before over sampling - Yes stroke: %d'%y_train_raw[y==1].shape)\nprint()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# === Over sampling to balance the different labels of data\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.over_sampling import ADASYN\nfrom imblearn.over_sampling import BorderlineSMOTE\nfrom imblearn.over_sampling import SVMSMOTE\n# from imblearn.over_sampling import SMOTENC\n\nresampling_method = BorderlineSMOTE\nX_train, y_train = resampling_method(sampling_strategy='not majority').fit_resample(X_train_raw,y_train_raw)\nprint('Shape of random over sampling dummy coding data X and y: ',X_train.shape,y_train.shape)\nprint('After over sampling - No stroke: %d'%y_train[y_train==0].shape)\nprint('After over sampling - Yes stroke: %d'%y_train[y_train==1].shape)\nprint()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Establishment and Evaluation\n\nUsing some classification algorithms to classify\n\nApplying some evaluation indexes to check the fitting results and predicted results","metadata":{}},{"cell_type":"code","source":"# %% === < Classifiers: Predicted Results and Confusion Matrices > ===\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.neural_network import MLPClassifier\n\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nfrom sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n\nclassifiers = [\n  LogisticRegression(),\n  KNeighborsClassifier(),\n  GaussianNB(),\n  SVC(probability=True), \n  DecisionTreeClassifier(), \n  QuadraticDiscriminantAnalysis(),\n  RandomForestClassifier(), \n  AdaBoostClassifier(),\n  MLPClassifier()\n  ]\n\nresult_table = pd.DataFrame(columns=['Classifiers','Accuracy','F1','Precision','Recall','fpr','tpr','AUC'])\n\nfor classifier in classifiers:\n  classifier_name = classifier.__class__.__name__\n  model = classifier.fit(X_train, y_train)\n  y_pred = model.predict(X_test)\n  y_score = model.predict_proba(X_test)[::,1]\n  # === Confusion Matrix\n  plt.figure(figsize=(8,7))\n  sns.heatmap(confusion_matrix(y_test,y_pred,normalize=None), annot=True, cmap='YlGnBu')\n  plt.ylabel('True label', fontsize=14)\n  plt.xlabel('Predicted label', fontsize=14)\n  plt.title('Confusion Matrix (%s)'%classifier_name, fontsize=14)\n#   plt.savefig(output_folder+'Confusion Matrix (%s).png'%classifier_name, dpi=300)\n  plt.show()\n  # === Normalized Confusion Matrix\n  plt.figure(figsize=(8,7))\n  sns.heatmap(confusion_matrix(y_test,y_pred,normalize='true'), annot=True, cmap='Blues', vmin=0, vmax=1)\n  plt.ylabel('True label')\n  plt.xlabel('Predicted label')\n  plt.title('Normalized Confusion Matrix (%s)'%classifier_name)\n#   plt.savefig(output_folder+'Normalized Confusion Matrix (%s).png'%classifier_name, dpi=300)\n  plt.show()\n  # === Result\n  accuracy = accuracy_score(y_test,y_pred)\n  f1 = f1_score(y_test,y_pred)\n  precision = precision_score(y_test,y_pred)\n  recall = recall_score(y_test,y_pred)\n  fpr, tpr, _ = roc_curve(y_test, y_score)\n  auc = roc_auc_score(y_test, y_score)\n  # === Table of Result\n  result_table = result_table.append({\n      'Classifiers':classifier_name,\n      'Accuracy':accuracy,\n      'F1':f1,\n      'Precision':precision,\n      'Recall':recall,\n      'fpr':fpr,\n      'tpr':tpr,\n      'AUC':auc\n      },\n    ignore_index=True\n    )\nresult_table.set_index('Classifiers', inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %% === < Predicted Results Output > ===\ndf_result = result_table[['Accuracy','F1','Precision','Recall']]\ndf_result = df_result.round(4)\nprint(df_result)\n# df_result.to_excel(output_folder+'Result_%s.xlsx'%local_time,sheet_name='result') ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %% === < ROC Curves to compare different models > ===\nimport numpy as np\n\nfig = plt.figure(figsize=(10,9))\n\nfor idx in result_table.index:\n  plt.plot(\n    result_table.loc[idx]['fpr'], \n    result_table.loc[idx]['tpr'], \n    label=\"{}, AUC={:.4f}\".format(idx, result_table.loc[idx]['AUC'])\n    )\n    \nplt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\nplt.xticks(np.arange(0.0, 1.1, step=0.1))\nplt.yticks(np.arange(0.0, 1.1, step=0.1))\nplt.xlabel(\"Flase Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title('Comparison of ROC Curves')\nplt.legend(prop={'size':12}, loc='lower right')\n# plt.savefig(output_folder+'ROC Curves %s.png'%local_time, dpi=300)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %% === < Finish Time > ===\nimport time\nUTC_time = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime()) # Colab UTC time\nlocal_time = time.strftime(\"%Y%m%d-%H%M%S\", time.localtime(time.time()+8*3600)) # Colab for UTC+8\nprint(\"UTC Time:\", UTC_time)\nprint(\"Local Time (UTC+8):\", local_time)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}