{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport os\nimport gc\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading in the data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data_fer = pd.read_csv('../input/fer2013/fer2013.csv')\ndata_fer.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral\nidx_to_emotion_fer = {0:\"Angry\", 1:\"Disgust\", 2:\"Fear\", 3:\"Happy\", 4:\"Sad\", 5:\"Surprise\", 6:\"Neutral\"}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_fer_train, y_fer_train = np.rollaxis(data_fer[data_fer.Usage == \"Training\"][[\"pixels\", \"emotion\"]].values, -1)\nX_fer_train = np.array([np.fromstring(x, dtype=\"uint8\", sep=\" \") for x in X_fer_train]).reshape((-1, 48, 48))\ny_fer_train = y_fer_train.astype('int8')\n\nX_fer_test_public, y_fer_test_public = np.rollaxis(data_fer[data_fer.Usage == \"PublicTest\"][[\"pixels\", \"emotion\"]].values, -1)\nX_fer_test_public = np.array([np.fromstring(x, dtype=\"uint8\", sep=\" \") for x in X_fer_test_public]).reshape((-1, 48, 48))\ny_fer_test_public = y_fer_test_public.astype('int8')\n\nX_fer_test_private, y_fer_test_private = np.rollaxis(data_fer[data_fer.Usage == \"PrivateTest\"][[\"pixels\", \"emotion\"]].values, -1)\nX_fer_test_private = np.array([np.fromstring(x, dtype=\"uint8\", sep=\" \") for x in X_fer_test_private]).reshape((-1, 48, 48))\ny_fer_test_private = y_fer_test_private.astype('int8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Flatten, Dense, Input, Dropout, Conv2D, MaxPool2D, BatchNormalization\nfrom keras.utils import to_categorical, plot_model\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data preprocessing and augmentation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE=128","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_fer_train.reshape((-1, 48, 48, 1))\nX_val = X_fer_test_public.reshape((-1, 48, 48, 1))\nX_test = X_fer_test_private.reshape((-1, 48, 48, 1))\ny_train = to_categorical(y_fer_train,7)\ny_val = to_categorical(y_fer_test_public,7)\ny_test = to_categorical(y_fer_test_private,7)\n\ntrain_datagen = ImageDataGenerator(\n    featurewise_center=False,\n    featurewise_std_normalization=False,\n    rotation_range=10,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=.1,\n    horizontal_flip=True,\n)\n\nval_datagen = ImageDataGenerator(\n    featurewise_center=False,\n    featurewise_std_normalization=False,\n)\n\ntrain_datagen.fit(X_train)\nval_datagen.fit(X_train)\n\ntrain_flow = train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)\nval_flow = val_datagen.flow(X_val, y_val, batch_size=BATCH_SIZE, shuffle=False)\ntest_flow = val_datagen.flow(X_test, y_test, batch_size=1, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"DROPOUT_RATE = 0.3\nCONV_ACTIVATION = \"relu\"\n\nimg_in = Input(shape=(48,48,1))\n\nX = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(img_in)\nX = BatchNormalization()(X)\nX = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\n\nX = MaxPool2D((2, 2), strides=(2, 2), padding='same')(X)\nX = Dropout(DROPOUT_RATE)(X)\n\n\nX = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\nX = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\nX = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\n\nX = MaxPool2D((2, 2), strides=(2, 2), padding='same')(X)\nX = Dropout(DROPOUT_RATE)(X)\n\nX = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\nX = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\nX = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\nX = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\n\nX = MaxPool2D((2, 2), strides=(2, 2), padding='same')(X)\nX = Dropout(DROPOUT_RATE)(X)\n\nX = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\nX = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\nX = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\nX = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\nX = MaxPool2D((2, 2), strides=(2, 2), padding='same')(X)\nX = Dropout(DROPOUT_RATE)(X)\n\nX = Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\nX = Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\nX = Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\nX = Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal', activation=CONV_ACTIVATION)(X)\nX = BatchNormalization()(X)\nX = MaxPool2D((2, 2), strides=(2, 2), padding='same')(X)\nX = Dropout(DROPOUT_RATE)(X)\n\nX = Flatten()(X)\nX = Dense(2048, activation=\"relu\")(X)\nX = Dropout(DROPOUT_RATE)(X)\nX = Dense(1024, activation=\"relu\")(X)\nX = Dropout(DROPOUT_RATE)(X)\nX = Dense(512, activation=\"relu\")(X)\nX = Dropout(DROPOUT_RATE)(X)\n\nout = Dense(7, activation='softmax')(X)\n\nmodel = Model(inputs=img_in, outputs=out)\nmodel.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['categorical_accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(model, show_shapes=True, show_layer_names=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_categorical_accuracy', mode='max', verbose=1, patience=20)\ncheckpoint_loss = ModelCheckpoint('best_loss_weights.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='min')\ncheckpoint_acc = ModelCheckpoint('best_accuracy_weights.h5', verbose=1, monitor='val_categorical_accuracy',save_best_only=True, mode='max')\nlr_reduce = ReduceLROnPlateau(monitor='val_categorical_accuracy', mode='max', factor=0.5, patience=5, min_lr=1e-7, cooldown=1, verbose=1)\n\nhistory = model.fit_generator(\n        train_flow, \n        steps_per_epoch= X_train.shape[0] // BATCH_SIZE,\n        epochs=150, \n        validation_data=val_flow,\n        validation_steps = X_val.shape[0] // BATCH_SIZE,\n        callbacks=[early_stopping, checkpoint_acc, checkpoint_loss, lr_reduce]\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n\n# summarize history for accuracy\nplt.plot(history.history['categorical_accuracy'])\nplt.plot(history.history['val_categorical_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model with the best loss","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('best_loss_weights.h5')\ny_pred = model.predict_generator(test_flow, steps=X_test.shape[0])\ny_pred_cat = np.argmax(y_pred, axis=1)\ny_true_cat = np.argmax(test_flow.y, axis=1)\nreport = classification_report(y_true_cat, y_pred_cat)\nprint(report)\n\nconf = confusion_matrix(y_true_cat, y_pred_cat, normalize=\"true\")\n\nlabels = idx_to_emotion_fer.values()\n_, ax = plt.subplots(figsize=(8, 6))\nax = sns.heatmap(conf, annot=True, cmap='YlGnBu', \n                 xticklabels=labels, \n                 yticklabels=labels)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model with the best accuracy","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# best acc\nmodel.load_weights('best_accuracy_weights.h5')\ny_pred = model.predict_generator(test_flow, steps=X_test.shape[0])\ny_pred_cat = np.argmax(y_pred, axis=1)\ny_true_cat = np.argmax(test_flow.y, axis=1)\nreport = classification_report(y_true_cat, y_pred_cat)\nprint(report)\n\nconf = confusion_matrix(y_true_cat, y_pred_cat, normalize=\"true\")\n\nlabels = idx_to_emotion_fer.values()\n_, ax = plt.subplots(figsize=(8, 6))\nax = sns.heatmap(conf, annot=True, cmap='YlGnBu', \n                 xticklabels=labels, \n                 yticklabels=labels)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}