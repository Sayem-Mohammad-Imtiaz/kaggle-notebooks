{"cells":[{"metadata":{},"cell_type":"markdown","source":"# CORD-19 QA Transformer Model\n\nThis notebook builds a CORD-19 extractive QA model based on the BERT-Small model. The model is designed to help extract structured information out of CORD-19 articles. \n\nThe following sections go through detailed steps in building these models, background information on each step and a link to pre-trained models on Hugging Face's website.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Install libraries and download build scripts","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Install latest transformers library\n!pip install transformers --upgrade\n\n# Language modeling\n!wget -P /tmp https://raw.githubusercontent.com/huggingface/transformers/master/examples/language-modeling/run_language_modeling.py\n\n# SQuAD 2.0\n!wget -P /tmp https://raw.githubusercontent.com/huggingface/transformers/master/examples/question-answering/run_squad.py\n!wget -P /tmp https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n!wget -P /tmp https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n\n# Remove wandb\n!pip uninstall -y wandb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Discussion\n\n[BERT-Small](https://huggingface.co/google/bert_uncased_L-6_H-512_A-8) was selected as the root model after testing various models ([BERT-Base](https://huggingface.co/bert-base-uncased), [ALBERT-base v2](https://huggingface.co/albert-base-v2), [SciBERT](https://huggingface.co/allenai/scibert_scivocab_uncased), [BioBERT](https://huggingface.co/monologg/biobert_v1.1_pubmed), [DistilBERT](https://huggingface.co/distilbert-base-uncased), [BERT-Tiny](https://huggingface.co/google/bert_uncased_L-2_H-128_A-2) and [BERT-Mini](https://huggingface.co/google/bert_uncased_L-4_H-256_A-4)).\n\nThe CORD-19 QA extractive model is primarily designed to execute subqueries against large lists of search results, therefore it needs to be performant. BERT-Base, ALBERT-base v2 and SciBERT all roughly had the same execution time. BERT-Tiny and BERT-Mini were much faster than BERT-Small but just couldn't reach a reasonable level of answering accuracy. DistilBERT was slower than BERT-Small.\n\nThe second part of model selection is whether to start with a general English language model or a medical/scientific model. My assumption going in was that models trained on medical data would be more accurate and perform better. But what I found was that BERT-Small performed better as I built out the CORD-19 QA dataset. My hypothesis behind this is that given my limited medical background, the way I constructed the questions to ask of the data was better suited to a general language model.\n\nOthers may find different results and it's easy to modify/test. Simply clone this notebook and change a single line in the code below to substitute an alternate model.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# bert-small-cord19\n\nThe file [cord19.txt](https://www.kaggle.com/davidmezzetti/cord19-qa?select=cord19.txt) is a partial export of sentences from the CORD-19 dataset, representing the best articles, ones with detected study designs. \n\nA pretrained model is available on Hugging Face's website: [bert-small-cord19](https://huggingface.co/NeuML/bert-small-cord19)","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false,"_kg_hide-output":true},"cell_type":"code","source":"!python /tmp/run_language_modeling.py \\\n    --model_type bert \\\n    --model_name_or_path google/bert_uncased_L-6_H-512_A-8 \\\n    --do_train \\\n    --mlm \\\n    --line_by_line \\\n    --block_size 512 \\\n    --train_data_file ../input/cord19-qa/cord19.txt \\\n    --per_gpu_train_batch_size 4 \\\n    --learning_rate 3e-5 \\\n    --num_train_epochs 3.0 \\\n    --output_dir bert-small-cord19 \\\n    --save_steps 0 \\\n    --overwrite_output_dir","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# bert-small-cord19-squad2\n\nThe next step takes the fine-tuned language model and trains it on SQuAD 2.0. SQuAD 2.0 is a better fit than 1.1 as it handled abstaining from answering a question, which is important for this dataset.\n\nA pretrained model is available on Hugging Face's website: [bert-small-cord19-squad2](https://huggingface.co/NeuML/bert-small-cord19-squad2)","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!python /tmp/run_squad.py \\\n    --model_type bert \\\n    --model_name_or_path bert-small-cord19 \\\n    --do_train \\\n    --do_eval \\\n    --do_lower_case \\\n    --version_2_with_negative \\\n    --train_file /tmp/train-v2.0.json \\\n    --predict_file /tmp/dev-v2.0.json \\\n    --per_gpu_train_batch_size 8 \\\n    --learning_rate 3e-5 \\\n    --num_train_epochs 3.0 \\\n    --max_seq_length 384 \\\n    --doc_stride 128 \\\n    --output_dir bert-small-cord19-squad2 \\\n    --save_steps 0 \\\n    --threads 2 \\\n    --overwrite_cache \\\n    --overwrite_output_dir","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# bert-small-cord19qa\n\nThe last step is taking the fine-tuned SQuAD 2.0 model and further fine-tuning it on [700+ CORD-19 specific QA pairs](https://www.kaggle.com/davidmezzetti/cord19-qa).\n\nA pretrained model is available on Hugging Face's website: [bert-small-cord19qa](https://huggingface.co/NeuML/bert-small-cord19qa)","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"!python /tmp/run_squad.py \\\n    --model_type bert \\\n    --model_name_or_path bert-small-cord19-squad2 \\\n    --do_train \\\n    --do_lower_case \\\n    --version_2_with_negative \\\n    --train_file ../input/cord19-qa/cord19-qa.json \\\n    --per_gpu_train_batch_size 8 \\\n    --learning_rate 5e-5 \\\n    --num_train_epochs 10.0 \\\n    --max_seq_length 384 \\\n    --doc_stride 128 \\\n    --output_dir bert-small-cord19qa \\\n    --save_steps 0 \\\n    --threads 2 \\\n    --overwrite_cache \\\n    --overwrite_output_dir","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# Remove large training cache files from output\n!rm -rf cached_*","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing the model\nTest the model with the following handful of question/context/answer groups","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\nimport string\nimport sys\n\nfrom transformers.pipelines import pipeline\n\n# Create NLP pipeline\nnlp = pipeline(\"question-answering\", model=\"bert-small-cord19qa\", tokenizer=\"bert-small-cord19qa\")\n\n# Init questions/contexts/answers\nquestions = [\"What containment method?\",\n             \"What weather factor?\",\n             \"What is the incubation period range?\",\n             \"What is model prediction?\",\n             \"What is cancer risk number?\"]\n\ncontexts = [\"With contact tracing, the proportion q of individuals exposed to the virus is quarantined.\",\n            \"Higher temperatures and higher RH (38 C, and >95% RH) have been found to reduce virus viability.\",\n            \"The average incubation period is 5-6 days, ranging from 1-14 days 6 .\",\n            \"Therefore, if person-to-person transmission persists from February, we predict the epidemic peak would occur in June.\",\n            \"cancer was associated with an increased risk for severe events (odds ratio, 5.34; 95% confidence interval [CI], 1.80 to 16.18; P = .0026),\"]\n\nanswers = [\"contact tracing\",\n           \"Higher temperatures and higher RH\",\n           \"5-6 days\",\n           \"epidemic peak would occur in June\",\n           \"odds ratio, 5.34\"]\n\n# Show results\nfor x, result in enumerate(nlp(question=questions, context=contexts)):\n    # Remove leading/trailing punctuation\n    result[\"answer\"] = result[\"answer\"].strip(string.punctuation)\n    print(result, answers[x])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}