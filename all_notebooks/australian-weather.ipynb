{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Requirements\n1. Dataset must contain more than 5 features and have more than 500 observations. ✔\n2. Analysis should only be based on ONE question ✔\n3. Program must use two different machine learning algorithms ✔\n4. \ni  Print out the original question that you are asking. ✔\nii  Visualise the data and prediction/classification if relevant. ✔\niii Print out the answer to the question obtained from both models. ✔\ni.v Print out the accuracy or error of the ML models. ✔\n5.  Mark-up cells a detailed explanation to why you picked the specific \nalgorithms. ✔\n6. comparison of the results obtained with both models and a reflection \nabout why you think one model is better over the other. ✔\n7. You code must be explained in comments as part of the code cells. ✔","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"Import all python functions, code comments here and throughout code to satisfy requirement 7","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.impute import SimpleImputer, KNNImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weather  = pd.read_csv(\"/kaggle/input/australia-weather/australia weather.csv\")  #Load the dataset using pandas read_csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Take a look at the dataframe information, we have 145460 entries, 0 to 145459, with total 23 columns, satisfies requirement 1","metadata":{}},{"cell_type":"code","source":"print(weather.info()) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets look at the data, the first 5 rows","metadata":{}},{"cell_type":"code","source":"weather.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is a lot of data, I will take a look at any correlations using pairplot and I will decide what columns to keep. I will do this before looking at the Nulls. This plot takes a lot of time to run.","metadata":{}},{"cell_type":"code","source":"sns.pairplot(weather)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"My question will be: Can we predict whether it will rain tomorrow based on this dataset? Satisfies requirement 2","metadata":{}},{"cell_type":"markdown","source":"Use two different machine learning algorithms to create two regression or classification models over the same dataset. With this aim in mind I will reduce my dataset to a manageable size therefore I will drop the following columns:","metadata":{}},{"cell_type":"code","source":"weather.pop('Date')\nweather.pop('Location')\nweather.pop('Rainfall')\nweather.pop('Evaporation')\nweather.pop('Sunshine')\nweather.pop('WindGustDir')\nweather.pop('WindDir9am')\nweather.pop('WindDir3pm')\nweather.pop('WindSpeed3pm')\nweather.pop('RainToday')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I will check how many nulls I have","metadata":{}},{"cell_type":"code","source":"weather.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I could use impute to replace the nulls but for the moment I will delete nulls as my dataset is large and I can afford to lose some data","metadata":{}},{"cell_type":"code","source":"weather  = weather.dropna(axis = 0, how ='any')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weather.isnull().values.any()  #I will check if all nulls are gone","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weather.head()  #I will take another look at the data now","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I will use 'RainTomorrow' as my target","metadata":{}},{"cell_type":"code","source":"y = weather.pop('RainTomorrow')\ny","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(weather.corr(), annot=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using train_test_split from sklearn.model_selection \nX_train, X_test, y_train, y_test = train_test_split(weather, y, test_size=0.2)\nX_train.shape, X_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I will use pipeline to create my models and compare results.\nAll my input data is numeric so I dont have to encode any columns.\nI have no Nan so I do not need to impute any input columns. My output however is categorical so I will use classifier in my pipeline.","metadata":{}},{"cell_type":"markdown","source":"1st Model - I will use standardscaler and KNeighbourClassifier (manhattan and euclidean with a selection of neighbours). Then I will use minmax scaler and compare. This will satisfy part of requirement 3","metadata":{}},{"cell_type":"code","source":"#here I set up for Standard scaler with kNN\nkNNpipeSS  = Pipeline(steps=[('scaler', StandardScaler()),\n                             ('classifier', KNeighborsClassifier())])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#here i set up for minmax scaler with knn\nkNNpipeMM  = Pipeline(steps=[('scaler', MinMaxScaler()),\n                             ('classifier', KNeighborsClassifier())])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#here I set my classifier metrics\nparam_grid = {'classifier__n_neighbors':[5,10,15,20], \n              'classifier__metric':['manhattan','euclidean']}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#use grid for knn and standard scaler\npipe_knn_ss = GridSearchCV(kNNpipeSS, param_grid, verbose = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#use grid for knn and minmax scaler\npipe_knn_mm = GridSearchCV(kNNpipeMM, param_grid, verbose = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fit the training data\npipe_knn_ss = pipe_knn_ss.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#the best combinations are:\npipe_knn_ss.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#the accuracy for this combination is:\ny_pred_gs = pipe_knn_ss.predict(X_test)\nprint(\"Accuracy for KNN and standard scaler are: \", pipe_knn_ss.score(X_test,y_test))\nprint('Can we predict the weather tomorrow? Yes, to {} accuracy'.format(pipe_knn_ss.score(X_test, y_test)) ) #satisfies req. 4.iii","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fit the training data for minmax scaler\npipe_knn_mm = pipe_knn_mm.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#the best combinations are:\npipe_knn_mm.best_params_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#the accuracy for this combination is:\ny_pred_gs = pipe_knn_mm.predict(X_test)\nprint(\"Accuracy for knn and min max scaler: \",pipe_knn_mm.score(X_test,y_test))\nprint('Can we predict the weather tomorrow? Yes, to {} accuracy'.format(pipe_knn_mm.score(X_test, y_test)) ) #satisfies req. 4.iii","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2nd Model - I will use standardscaler and DecisionTreeClassifier (entropy and gini). Then I will use minmax scaler and compare. This will satisfy part of requirement 3","metadata":{}},{"cell_type":"code","source":"# here I set up for Standard scaler with decision tree\ntreepipeSS  = Pipeline(steps=[('scaler', StandardScaler()),\n                             ('classifier', DecisionTreeClassifier())])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#here i set up for minmax scaler with decision tree\ntreepipeMM  = Pipeline(steps=[('scaler', MinMaxScaler()),\n                             ('classifier', DecisionTreeClassifier())])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#set classifier metrics\nparam_grid = {'classifier__criterion':['entropy', 'gini'],\n             'classifier__min_samples_split': range(2, 403, 10)\n             }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#use grid for decision tree and standard scaler\npipe_tree_SS = GridSearchCV(treepipeSS, param_grid, verbose = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#use grid for decision tree and minmax scaler\npipe_tree_MM = GridSearchCV(treepipeMM, param_grid, verbose = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fit train data for standard scaler\npipe_tree_SS = pipe_tree_SS.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#best combinations are\npipe_tree_SS.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#the accuracy for this combination is:\ny_pred_gs = pipe_tree_SS.predict(X_test)\nprint(\"Accuracy for decision tress standard scaler: \",pipe_tree_SS.score(X_test,y_test))\nprint('Can we predict the weather tomorrow? Yes, to {} accuracy'.format(pipe_tree_SS.score(X_test, y_test)) ) #satisfies req. 4.iii","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##fit train data for min max\npipe_tree_MM = pipe_tree_MM.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#best combinations are\npipe_tree_MM.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#the accuracy for this combination is:\ny_pred_gs = pipe_tree_MM.predict(X_test)\nprint(\"Accuracy for decision tress standard scaler: \",pipe_tree_MM.score(X_test,y_test))\nprint('Can we predict the weather tomorrow? Yes, to {} accuracy'.format(pipe_tree_SS.score(X_test, y_test)) ) #satisfies req. 4.iii","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### To satisfy requirement 4: All results are similar with KNN/standard scaler just ahead with a score of 0.844\nI will plot all the scores for a visual, this will satisfies requirement 6.","metadata":{}},{"cell_type":"code","source":"models_default_scores = {\n    'KNearest Neighbors' : pipe_knn_ss.score(X_test, y_test),\n    'Decision Tree' : pipe_tree_SS.score(X_test, y_test),\n    }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"default_models_compare = pd.DataFrame(models_default_scores, index=['accuracy'])\ndefault_models_compare.T.plot.bar()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The next stage would be to create a function instead of repeating steps for each model.\nAs I had a large dataset I could afford to lose some data as the purpose was to create a model. With more experience and time I would have done more preprocessing and dealt with the missing data differently.\n","metadata":{}}]}