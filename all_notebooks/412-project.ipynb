{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import nltk\nnltk.download('stopwords')\nnltk.download('averaged_perceptron_tagger')\nnltk.download('punkt')","metadata":{"id":"NIW-BmfP32Sk","outputId":"2c63369a-46e8-46c1-99fb-338a802e1c0c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nfrom nltk.corpus import stopwords\nimport string\nimport xgboost as xgb\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn import ensemble, metrics, model_selection, naive_bayes\nfrom nltk.tokenize import RegexpTokenizer\nimport nltk.stem as stm\nfrom nltk import WordNetLemmatizer, word_tokenize\nfrom gensim.models import Word2Vec\nfrom sklearn.linear_model import LogisticRegression\nfrom tqdm import tqdm\nimport re\nimport string\nfrom time import time\n\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.naive_bayes import BernoulliNB, MultinomialNB\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression\nfrom sklearn.calibration import CalibratedClassifierCV\n\nmodels = [('MultiNB', MultinomialNB(alpha=0.03)),\n          ('Calibrated MultiNB', CalibratedClassifierCV(\n              MultinomialNB(alpha=0.03), method='isotonic')),\n          ('Calibrated BernoulliNB', CalibratedClassifierCV(\n              BernoulliNB(alpha=0.03), method='isotonic')),\n          ('Calibrated Huber', CalibratedClassifierCV(\n              SGDClassifier(loss='modified_huber', alpha=1e-4,\n                            max_iter=10000, tol=1e-4), method='sigmoid')),\n          ('Logit', LogisticRegression(C=30))]\n\nstart_time = time()\ncolor = sns.color_palette()\ntqdm.pandas()\nalphabet = 'abcdefghijklmnopqrstuvwxyz'\n_punctuation = ['.', '..', '...', ',', ':', ';', '-', '*', '\"', '!', '?']\nembeddings_index = {}\nf = open(r'../input/glove840b300dtxt/glove.840B.300d.txt', encoding='utf8')\n\nfor line in f:\n  try:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], 'float32')\n    embeddings_index[word] = coefs\n  except:\n    continue\n\nf.close()\n\n\nprint('Found %s word vectors.' % len(embeddings_index))\n# get_ipython().magic(u'matplotlib inline')\n","metadata":{"id":"vZjyzmYuAfCy","outputId":"c0614991-980a-426b-ee19-04b718c1ee2c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\neng_stopwords = set(stopwords.words(\"english\"))         # for wipe out some common words that hava no help such as \"I\", \"you\", \"and\"\npd.options.mode.chained_assignment = None               # prevent raise an exception\nalpha_tokenizer = RegexpTokenizer('[A-Za-z]\\w+')\nlemmatizer = WordNetLemmatizer()\n\n\n## Read the train and test dataset and check the top few lines ##\ntrain_df = pd.read_csv(\"../input/412-dataset/newtrain.csv\")\ntest_df = pd.read_csv(\"../input/412-dataset/test.csv\")\nprint(\"Number of rows in train dataset : \",train_df.shape[0])\nprint(\"Number of rows in test dataset : \",test_df.shape[0])\n\n\n# In[31]:\n\n\ndef fraction_noun(row):\n    \"\"\"function to give us fraction of noun over total words \"\"\"\n    text = row['text']\n    text_splited = text.split(' ')\n    text_splited = [''.join(c for c in s if c not in string.punctuation) for s in text_splited]\n    text_splited = [s for s in text_splited if s]\n    word_count = text_splited.__len__()\n    pos_list = nltk.pos_tag(text_splited)\n    noun_count = len([w for w in pos_list if w[1] in ('NN','NNP','NNPS','NNS')])\n    return (noun_count/word_count)\n\ndef fraction_adj(row):\n    \"\"\"function to give us fraction of adjectives over total words in given text\"\"\"\n    text = row['text']\n    text_splited = text.split(' ')\n    text_splited = [''.join(c for c in s if c not in string.punctuation) for s in text_splited]\n    text_splited = [s for s in text_splited if s]\n    word_count = text_splited.__len__()\n    pos_list = nltk.pos_tag(text_splited)\n    adj_count = len([w for w in pos_list if w[1] in ('JJ','JJR','JJS')])\n    return (adj_count/word_count)\n\ndef fraction_verbs(row):\n    \"\"\"function to give us fraction of verbs over total words in given text\"\"\"\n    text = row['text']\n    text_splited = text.split(' ')\n    text_splited = [''.join(c for c in s if c not in string.punctuation) for s in text_splited]\n    text_splited = [s for s in text_splited if s]\n    word_count = text_splited.__len__()\n    pos_list = nltk.pos_tag(text_splited)\n    verbs_count = len([w for w in pos_list if w[1] in ('VB','VBD','VBG','VBN','VBP','VBZ')])\n    return (verbs_count/word_count)\n\ndef fraction_adverbs(row):\n    \"\"\"function to give us fraction of verbs over total words in given text\"\"\"\n    text = row['text']\n    text_splited = text.split(' ')\n    text_splited = [''.join(c for c in s if c not in string.punctuation) for s in text_splited]\n    text_splited = [s for s in text_splited if s]\n    word_count = text_splited.__len__()\n    pos_list = nltk.pos_tag(text_splited)\n    verbs_count = len([w for w in pos_list if w[1] in ('RB','RBR','RBS')])\n    return (verbs_count/word_count)\n\n\ndef clean_text(x):\n    x.lower()\n    for p in _punctuation:\n        x.replace(p, '')\n    return x\n\ndef sent2vec(s):\n    words = str(s).lower().encode('utf-8').decode('utf-8')\n    words = word_tokenize(words)\n    words = [w for w in words if not w in eng_stopwords]\n    words = [w for w in words if w.isalpha()]\n    M = []\n    for w in words:\n        try:\n            M.append(embeddings_index[w])\n        except:\n            continue\n    M = np.array(M)\n    v = M.sum(axis=0)\n    if type(v) != np.ndarray:\n        return np.zeros(300)\n    return v / np.sqrt((v ** 2).sum())\n\n\n# In[17]:\n\n\ntrain_df[\"num_words\"] = train_df[\"text\"].apply(lambda x: len(str(x).split()))\ntest_df[\"num_words\"] = test_df[\"text\"].apply(lambda x: len(str(x).split()))\n\n## Number of unique words in the text ##\ntrain_df[\"num_unique_words\"] = train_df[\"text\"].apply(lambda x: len(set(str(x).split())))\ntest_df[\"num_unique_words\"] = test_df[\"text\"].apply(lambda x: len(set(str(x).split())))\n\n## Number of characters in the text ##\ntrain_df[\"num_chars\"] = train_df[\"text\"].apply(lambda x: len(str(x)))\ntest_df[\"num_chars\"] = test_df[\"text\"].apply(lambda x: len(str(x)))\n\n## Number of stopwords in the text ##\ntrain_df[\"num_stopwords\"] = train_df[\"text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\ntest_df[\"num_stopwords\"] = test_df[\"text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n\n## Number of punctuations in the text ##\ntrain_df[\"num_punctuations\"] =train_df['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\ntest_df[\"num_punctuations\"] =test_df['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n\n## Number of title case words in the text ##\ntrain_df[\"num_words_upper\"] = train_df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\ntest_df[\"num_words_upper\"] = test_df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n\n## Number of title case words in the text ##\ntrain_df[\"num_words_title\"] = train_df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\ntest_df[\"num_words_title\"] = test_df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n\n## Average length of the words in the text ##\ntrain_df[\"mean_word_len\"] = train_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\ntest_df[\"mean_word_len\"] = test_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n\ntrain_df[\",\"] = train_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\",\")]))\ntest_df[\",\"] = test_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\",\")]))\n\ntrain_df[\";\"] = train_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\";\")]))\ntest_df[\";\"] = test_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\";\")]))\n\ntrain_df['\\\"'] = train_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split('\\\"')]))\ntest_df['\\\"'] = test_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split('\\\"')]))\n\ntrain_df[\"...\"] = train_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"...\")]))\ntest_df[\"...\"] = test_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"...\")]))\n\ntrain_df[\"?\"] = train_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"?\")]))\ntest_df[\"?\"] = test_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"?\")]))\n\ntrain_df[\"!\"] = train_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"!\")]))\ntest_df[\"!\"] = test_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"!\")]))\n\ntrain_df[\".\"] = train_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\".\")]))\ntest_df[\".\"] = test_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\".\")]))\n\ntrain_df[\":\"] = train_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\":\")]))\ntest_df[\":\"] = test_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\":\")]))\n\ntrain_df[\"*\"] = train_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"*\")]))\ntest_df[\"*\"] = test_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"*\")]))\n\ntrain_df[\"-\"] = train_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"-\")]))\ntest_df[\"-\"] = test_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"-\")]))\n\ntrain_df['fraction_noun'] = train_df.apply(lambda row: fraction_noun(row), axis =1)\ntest_df['fraction_noun'] = test_df.apply(lambda row: fraction_noun(row), axis =1)\n\ntrain_df['fraction_adj'] = train_df.apply(lambda row: fraction_adj(row), axis =1)\ntest_df['fraction_adj'] = test_df.apply(lambda row: fraction_adj(row), axis =1)\n\ntrain_df['fraction_verbs'] = train_df.apply(lambda row: fraction_verbs(row), axis =1)\ntest_df['fraction_verbs'] = test_df.apply(lambda row: fraction_verbs(row), axis =1)\n\n\nmost_words = ['strange', 'night', 'ancient', 'terrible', 'house', 'street', 'black', 'dark', 'city', 'remain', ''\n          'moon', 'west', 'told', 'looked', 'dreams', 'door', 'stone', 'half', 'left','found', 'course', 'observe',\n          'head', 'person', 'length', 'water', 'character', 'moment', 'manner', 'air', 'ider', 'speak', 'place',\n            'hand', 'matter', 'de', 'feet', 'body', 'means', 'doubt','raymond', 'perdita', 'adrian', 'fall', 'come',\n            'father', 'country', 'heart', 'idris', 'spirit', 'love', 'life', 'say', 'find', 'thing', 'long', 'dream',\n          'idris', 'tears', 'passed', 'nature', 'fear', 'human', 'voice', 'dear', 'words', 'great', 'little', 'see',\n          'the ', ' a ', 'appear', 'little', 'was ', 'one ', 'two ', 'three ', 'ten ', 'is ', 'are ', 'ed ', 'misery',\n            'however', ' to ', 'into', 'about ', 'th', 'er', 'ex', 'an ', 'ground', 'any', 'silence', 'wall', 'look'\n            , 'The ', 'I ', 'It ', 'He', 'Me', 'They ', 'She ', 'We ', 'You ', 'good', 'time', 'old', 'death', 'man']\n\n_punctuation = ['.', '..', '...', ',', ':', ';', '-', '*', '\"', '!', '?']\n\ntrain_df['text_cleaned'] = train_df['text'].apply(lambda x: clean_text(x))\ntest_df['text_cleaned'] = test_df['text'].apply(lambda x: clean_text(x))\n\nfor word in most_words:\n    train_df[word] = train_df[\"text_cleaned\"].str.count(word)\n    test_df[word] = test_df[\"text_cleaned\"].str.count(word)\n\nfor char in alphabet:\n    train_df['num_'+char] = train_df[\"text_cleaned\"].str.count(char)\n    test_df['num_'+char] = test_df[\"text_cleaned\"].str.count(char)\n\n\n# We can check the number of occurrence of each of the author to see if the classes are balanced.\n\n# In[36]:\n\n\n# train_df = train_df.drop(['fraction_adverbs'], axis=1)\n\n\nxtrain_glove = [sent2vec(x) for x in tqdm(train_df.text)]\nxtest_glove = [sent2vec(x) for x in tqdm(test_df.text)]\nxtrain_glove = np.array(xtrain_glove)\nxtest_glove = np.array(xtest_glove)\n# print xtrain_glove.shape, xtest_glove.shape\n\ntrain_df = pd.concat([train_df, pd.DataFrame(xtrain_glove)], axis=1)\ntest_df = pd.concat([test_df, pd.DataFrame(xtest_glove)], axis=1)\nprint(train_df.info())\n\n\n# This looks good. There is not much class imbalance. Let us print some lines of each of the authors to try and understand their writing style if possible.\n\n# In[37]:\n\n\nauthor_mapping_dict = {'EAP':0, 'HPL':1, 'MWS':2}\ntrain_y = train_df['author'].map(author_mapping_dict)\ntrain_id = train_df['id'].values\ntest_id = test_df['id'].values\n\n\ncols_to_drop = ['id', 'text', 'text_cleaned']\ntrain_X = train_df.drop(cols_to_drop+['author'], axis=1)\ntest_X = test_df.drop(cols_to_drop, axis=1)\n","metadata":{"id":"MNgsIS2xcr8S","outputId":"591ff0a8-d613-4862-d750-b750e3d1ff05","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sent2vec(s):\n    words = str(s).lower().encode('utf-8').decode('utf-8')\n    words = word_tokenize(words)\n    words = [w for w in words if not w in eng_stopwords]\n    words = [w for w in words if w.isalpha()]\n    M = []\n    for w in words:\n        try:\n            M.append(embeddings_index[w])\n        except:\n            continue\n    M = np.array(M)\n    v = M.sum(axis=0)\n    if type(v) != np.ndarray:\n        return np.zeros(300)\n    return v / np.sqrt((v ** 2).sum())\n\n\n# In[17]:\n\n\ntrain_df[\"num_words\"] = train_df[\"text\"].apply(lambda x: len(str(x).split()))\ntest_df[\"num_words\"] = test_df[\"text\"].apply(lambda x: len(str(x).split()))\n\n## Number of unique words in the text ##\ntrain_df[\"num_unique_words\"] = train_df[\"text\"].apply(lambda x: len(set(str(x).split())))\ntest_df[\"num_unique_words\"] = test_df[\"text\"].apply(lambda x: len(set(str(x).split())))\n\n## Number of characters in the text ##\ntrain_df[\"num_chars\"] = train_df[\"text\"].apply(lambda x: len(str(x)))\ntest_df[\"num_chars\"] = test_df[\"text\"].apply(lambda x: len(str(x)))\n\n## Number of stopwords in the text ##\ntrain_df[\"num_stopwords\"] = train_df[\"text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\ntest_df[\"num_stopwords\"] = test_df[\"text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n\n## Number of punctuations in the text ##\ntrain_df[\"num_punctuations\"] =train_df['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\ntest_df[\"num_punctuations\"] =test_df['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n\n## Number of title case words in the text ##\ntrain_df[\"num_words_upper\"] = train_df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\ntest_df[\"num_words_upper\"] = test_df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n\n## Number of title case words in the text ##\ntrain_df[\"num_words_title\"] = train_df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\ntest_df[\"num_words_title\"] = test_df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n\n## Average length of the words in the text ##\ntrain_df[\"mean_word_len\"] = train_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\ntest_df[\"mean_word_len\"] = test_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n\ntrain_df[\",\"] = train_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\",\")]))\ntest_df[\",\"] = test_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\",\")]))\n\ntrain_df[\";\"] = train_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\";\")]))\ntest_df[\";\"] = test_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\";\")]))\n\ntrain_df['\\\"'] = train_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split('\\\"')]))\ntest_df['\\\"'] = test_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split('\\\"')]))\n\ntrain_df[\"...\"] = train_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"...\")]))\ntest_df[\"...\"] = test_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"...\")]))\n\ntrain_df[\"?\"] = train_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"?\")]))\ntest_df[\"?\"] = test_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"?\")]))\n\ntrain_df[\"!\"] = train_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"!\")]))\ntest_df[\"!\"] = test_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"!\")]))\n\ntrain_df[\".\"] = train_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\".\")]))\ntest_df[\".\"] = test_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\".\")]))\n\ntrain_df[\":\"] = train_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\":\")]))\ntest_df[\":\"] = test_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\":\")]))\n\ntrain_df[\"*\"] = train_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"*\")]))\ntest_df[\"*\"] = test_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"*\")]))\n\ntrain_df[\"-\"] = train_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"-\")]))\ntest_df[\"-\"] = test_df[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split(\"-\")]))\n\ntrain_df['fraction_noun'] = train_df.apply(lambda row: fraction_noun(row), axis =1)\ntest_df['fraction_noun'] = test_df.apply(lambda row: fraction_noun(row), axis =1)\n\ntrain_df['fraction_adj'] = train_df.apply(lambda row: fraction_adj(row), axis =1)\ntest_df['fraction_adj'] = test_df.apply(lambda row: fraction_adj(row), axis =1)\n\ntrain_df['fraction_verbs'] = train_df.apply(lambda row: fraction_verbs(row), axis =1)\ntest_df['fraction_verbs'] = test_df.apply(lambda row: fraction_verbs(row), axis =1)\n\n\nmost_words = ['strange', 'night', 'ancient', 'terrible', 'house', 'street', 'black', 'dark', 'city', 'remain', ''\n          'moon', 'west', 'told', 'looked', 'dreams', 'door', 'stone', 'half', 'left','found', 'course', 'observe',\n          'head', 'person', 'length', 'water', 'character', 'moment', 'manner', 'air', 'ider', 'speak', 'place',\n            'hand', 'matter', 'de', 'feet', 'body', 'means', 'doubt','raymond', 'perdita', 'adrian', 'fall', 'come',\n            'father', 'country', 'heart', 'idris', 'spirit', 'love', 'life', 'say', 'find', 'thing', 'long', 'dream',\n          'idris', 'tears', 'passed', 'nature', 'fear', 'human', 'voice', 'dear', 'words', 'great', 'little', 'see',\n          'the ', ' a ', 'appear', 'little', 'was ', 'one ', 'two ', 'three ', 'ten ', 'is ', 'are ', 'ed ', 'misery',\n            'however', ' to ', 'into', 'about ', 'th', 'er', 'ex', 'an ', 'ground', 'any', 'silence', 'wall', 'look'\n            , 'The ', 'I ', 'It ', 'He', 'Me', 'They ', 'She ', 'We ', 'You ', 'good', 'time', 'old', 'death', 'man']\n\n_punctuation = ['.', '..', '...', ',', ':', ';', '-', '*', '\"', '!', '?']\n\ntrain_df['text_cleaned'] = train_df['text'].apply(lambda x: clean_text(x))\ntest_df['text_cleaned'] = test_df['text'].apply(lambda x: clean_text(x))\n\nfor word in most_words:\n    train_df[word] = train_df[\"text_cleaned\"].str.count(word)\n    test_df[word] = test_df[\"text_cleaned\"].str.count(word)\n\nfor char in alphabet:\n    train_df['num_'+char] = train_df[\"text_cleaned\"].str.count(char)\n    test_df['num_'+char] = test_df[\"text_cleaned\"].str.count(char)\n\n\n# We can check the number of occurrence of each of the author to see if the classes are balanced.\n\n# In[36]:\n\n\n# train_df = train_df.drop(['fraction_adverbs'], axis=1)\n\n\nxtrain_glove = [sent2vec(x) for x in tqdm(train_df.text)]\nxtest_glove = [sent2vec(x) for x in tqdm(test_df.text)]\nxtrain_glove = np.array(xtrain_glove)\nxtest_glove = np.array(xtest_glove)\n# print xtrain_glove.shape, xtest_glove.shape\n\ntrain_df = pd.concat([train_df, pd.DataFrame(xtrain_glove)], axis=1)\ntest_df = pd.concat([test_df, pd.DataFrame(xtest_glove)], axis=1)\nprint(train_df.info())\n\n\n# This looks good. There is not much class imbalance. Let us print some lines of each of the authors to try and understand their writing style if possible.\n\n# In[37]:\n\n\nauthor_mapping_dict = {'EAP':0, 'HPL':1, 'MWS':2}\ntrain_y = train_df['author'].map(author_mapping_dict)\ntrain_id = train_df['id'].values\ntest_id = test_df['id'].values\n\n\ncols_to_drop = ['id', 'text', 'text_cleaned']\ntrain_X = train_df.drop(cols_to_drop+['author'], axis=1)\ntest_X = test_df.drop(cols_to_drop, axis=1)\n","metadata":{"id":"hDIV_kkkCtXu","outputId":"a83d0fe5-f5fd-431b-d1f5-283ba1820671","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def runXGB(train_X, train_y, test_X, test_y=None, test_X2=None, seed_val=0, child=1, colsample=0.3):\n    param = {}\n    param['objective'] = 'multi:softprob'\n    param['eta'] = 0.1\n    param['max_depth'] = 3\n    param['silent'] = 1\n    param['num_class'] = 3\n    param['eval_metric'] = \"mlogloss\"\n    param['min_child_weight'] = child\n    param['subsample'] = 0.8\n    param['colsample_bytree'] = colsample\n    param['seed'] = seed_val\n    num_rounds = 2000\n\n    plst = list(param.items())\n    xgtrain = xgb.DMatrix(train_X, label=train_y)\n\n    if test_y is not None:\n        xgtest = xgb.DMatrix(test_X, label=test_y)\n        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=50, verbose_eval=20)\n    else:\n        xgtest = xgb.DMatrix(test_X)\n        model = xgb.train(plst, xgtrain, num_rounds)\n\n    pred_test_y = model.predict(xgtest, ntree_limit = model.best_ntree_limit)\n    if test_X2 is not None:\n        xgtest2 = xgb.DMatrix(test_X2)\n        pred_test_y2 = model.predict(xgtest2, ntree_limit = model.best_ntree_limit)\n    return pred_test_y, pred_test_y2, model\n\ndef runMNB(train_X, train_y, test_X, test_y, test_X2):\n    model = naive_bayes.MultinomialNB()\n    model.fit(train_X, train_y)\n    pred_test_y = model.predict_proba(test_X)\n    pred_test_y2 = model.predict_proba(test_X2)\n    return pred_test_y, pred_test_y2, model\n\ndef runBer(train_X, train_y, test_X, test_y, test_X2):\n    model = naive_bayes.BernoulliNB()\n    model.fit(train_X, train_y)\n    pred_test_y = model.predict_proba(test_X)\n    pred_test_y2 = model.predict_proba(test_X2)\n    return pred_test_y, pred_test_y2, model\n\n\n# Let us now plot some of our new variables to see of they will be helpful in predictions.\nvectorizer=TfidfVectorizer(token_pattern=r'\\w{1,}', sublinear_tf=True, ngram_range=(1,2))\nclf = VotingClassifier(models, voting='soft', weights=[2,3,3,1,1])\n\ntfidf_vec = CountVectorizer(analyzer='word', ngram_range=(1, 5))\ntfidf_vec.fit(train_df['text'].values.tolist() + test_df['text'].values.tolist())\ntrain_tfidf = tfidf_vec.transform(train_df['text'].values.tolist())\ntest_tfidf = tfidf_vec.transform(test_df['text'].values.tolist())\n\ncv_scores = []\npred_full_test = 0\npred_train = np.zeros([train_df.shape[0], 3])\nkf = model_selection.KFold(n_splits=10, shuffle=True, random_state=2017)\nfor dev_index, val_index in tqdm(kf.split(train_X)):\n    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\n    dev_y, val_y = train_y[dev_index], train_y[val_index]\n    #pred_val_y, pred_test_y, model = runMNB(dev_X, dev_y, val_X, val_y, test_tfidf)\n    clf.fit(dev_X, dev_y)\n    pred_val_y = clf.predict_proba(val_X)\n    pred_test_y = clf.predict_proba(test_tfidf)\n    pred_full_test = pred_full_test + pred_test_y\n    pred_train[val_index,:] = pred_val_y\n    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\nprint(\"Mean cv score : \", np.mean(cv_scores))\npred_full_test = pred_full_test / 10.\n\n# add the predictions as new features #\ntrain_df[\"nb_word2_eap\"] = pred_train[:,0]\ntrain_df[\"nb_word2_hpl\"] = pred_train[:,1]\ntrain_df[\"nb_word2_mws\"] = pred_train[:,2]\ntest_df[\"nb_word2_eap\"] = pred_full_test[:,0]\ntest_df[\"nb_word2_hpl\"] = pred_full_test[:,1]\ntest_df[\"nb_word2_mws\"] = pred_full_test[:,2]\n","metadata":{"id":"3_DC9C1qG1EV","outputId":"9d5a9479-a6ed-466f-bbfe-fb5b611f8341","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nvectorizer=TfidfVectorizer(token_pattern=r'\\w{1,}', sublinear_tf=True, ngram_range=(1,2))\nclf = VotingClassifier(models, voting='soft', weights=[2,3,3,1,1])\n\ntfidf_vec = CountVectorizer(analyzer='char_wb', ngram_range=(1, 5))\ntfidf_vec.fit(train_df['text'].values.tolist() + test_df['text'].values.tolist())\ntrain_tfidf = tfidf_vec.transform(train_df['text'].values.tolist())\ntest_tfidf = tfidf_vec.transform(test_df['text'].values.tolist())\n\ncv_scores = []\npred_full_test = 0\npred_train = np.zeros([train_df.shape[0], 3])\nkf = model_selection.KFold(n_splits=10, shuffle=True, random_state=2017)\nfor dev_index, val_index in kf.split(train_X):\n    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\n    dev_y, val_y = train_y[dev_index], train_y[val_index]\n    #pred_val_y, pred_test_y, model = runMNB(dev_X, dev_y, val_X, val_y, test_tfidf)\n    clf.fit(dev_X, dev_y)\n    pred_val_y = clf.predict_proba(val_X)\n    pred_test_y = clf.predict_proba(test_tfidf)\n    pred_full_test = pred_full_test + pred_test_y\n    pred_train[val_index,:] = pred_val_y\n    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\nprint(\"Mean cv score : \", np.mean(cv_scores))\npred_full_test = pred_full_test / 10.\n\n# add the predictions as new features #\ntrain_df[\"nb_c2_eap\"] = pred_train[:,0]\ntrain_df[\"nb_c2_hpl\"] = pred_train[:,1]\ntrain_df[\"nb_c2_mws\"] = pred_train[:,2]\ntest_df[\"nb_c2_eap\"] = pred_full_test[:,0]\ntest_df[\"nb_c2_hpl\"] = pred_full_test[:,1]\ntest_df[\"nb_c2_mws\"] = pred_full_test[:,2]\n\n\n# EAP seems slightly lesser number of words than MWS and HPL.\n\n# In[40]:\n\nvectorizer=TfidfVectorizer(token_pattern=r'\\w{1,}', sublinear_tf=True, ngram_range=(1,2))\nclf = VotingClassifier(models, voting='soft', weights=[2,3,3,1,1])\n\ntfidf_vec = CountVectorizer(analyzer='word', ngram_range=(1, 5))\ntfidf_vec.fit(train_df['text'].values.tolist() + test_df['text'].values.tolist())\ntrain_tfidf = tfidf_vec.transform(train_df['text'].values.tolist())\ntest_tfidf = tfidf_vec.transform(test_df['text'].values.tolist())\n\ncv_scores = []\npred_full_test = 0\npred_train = np.zeros([train_df.shape[0], 3])\nkf = model_selection.KFold(n_splits=10, shuffle=True, random_state=2017)\nfor dev_index, val_index in kf.split(train_X):\n    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\n    dev_y, val_y = train_y[dev_index], train_y[val_index]\n    #pred_val_y, pred_test_y, model = runBer(dev_X, dev_y, val_X, val_y, test_tfidf)\n    clf.fit(dev_X, dev_y)\n    pred_val_y = clf.predict_proba(val_X)\n    pred_test_y = clf.predict_proba(test_tfidf)\n    pred_full_test = pred_full_test + pred_test_y\n    pred_train[val_index,:] = pred_val_y\n    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\nprint(\"Mean cv score : \", np.mean(cv_scores))\npred_full_test = pred_full_test / 10.\n\n# add the predictions as new features #\ntrain_df[\"ber_word2_eap\"] = pred_train[:,0]\ntrain_df[\"ber_word2_hpl\"] = pred_train[:,1]\ntrain_df[\"ber_word2_mws\"] = pred_train[:,2]\ntest_df[\"ber_word2_eap\"] = pred_full_test[:,0]\ntest_df[\"ber_word2_hpl\"] = pred_full_test[:,1]\ntest_df[\"ber_word2_mws\"] = pred_full_test[:,2]\n\n\nvectorizer=TfidfVectorizer(token_pattern=r'\\w{1,}', sublinear_tf=True, ngram_range=(1,2))\nclf = VotingClassifier(models, voting='soft', weights=[3,2,3,1,1])\n\ntfidf_vec = CountVectorizer(analyzer='char_wb', ngram_range=(1, 5))\ntfidf_vec.fit(train_df['text'].values.tolist() + test_df['text'].values.tolist())\ntrain_tfidf = tfidf_vec.transform(train_df['text'].values.tolist())\ntest_tfidf = tfidf_vec.transform(test_df['text'].values.tolist())\n\ncv_scores = []\npred_full_test = 0\npred_train = np.zeros([train_df.shape[0], 3])\nkf = model_selection.KFold(n_splits=10, shuffle=True, random_state=2017)\nfor dev_index, val_index in kf.split(train_X):\n    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\n    dev_y, val_y = train_y[dev_index], train_y[val_index]\n    #pred_val_y, pred_test_y, model = runBer(dev_X, dev_y, val_X, val_y, test_tfidf)\n    clf.fit(dev_X, dev_y)\n    pred_val_y = clf.predict_proba(val_X)\n    pred_test_y = clf.predict_proba(test_tfidf)\n    pred_full_test = pred_full_test + pred_test_y\n    pred_train[val_index,:] = pred_val_y\n    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\nprint(\"Mean cv score : \", np.mean(cv_scores))\npred_full_test = pred_full_test / 10.\n\n# add the predictions as new features #\ntrain_df[\"ber_c2_eap\"] = pred_train[:,0]\ntrain_df[\"ber_c2_hpl\"] = pred_train[:,1]\ntrain_df[\"ber_c2_mws\"] = pred_train[:,2]\ntest_df[\"ber_c2_eap\"] = pred_full_test[:,0]\ntest_df[\"ber_c2_hpl\"] = pred_full_test[:,1]\ntest_df[\"ber_c2_mws\"] = pred_full_test[:,2]\n\n\n# This also seems to be somewhat useful. Now let us focus on creating some text based features.\n#\n# Let us first build a basic model to see how these meta features  are helping.\n\n# In[41]:\n\n\ntfidf_vec = TfidfVectorizer(stop_words='english', ngram_range=(1,3))\nfull_tfidf = tfidf_vec.fit_transform(train_df['text'].values.tolist() + test_df['text'].values.tolist())\ntrain_tfidf = tfidf_vec.transform(train_df['text'].values.tolist())\ntest_tfidf = tfidf_vec.transform(test_df['text'].values.tolist())\n\nn_comp = 20\nsvd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')\nsvd_obj.fit(full_tfidf)\ntrain_svd = pd.DataFrame(svd_obj.transform(train_tfidf))\ntest_svd = pd.DataFrame(svd_obj.transform(test_tfidf))\n\ntrain_svd.columns = ['svd_word_'+str(i) for i in range(n_comp)]\ntest_svd.columns = ['svd_word_'+str(i) for i in range(n_comp)]\ntrain_df = pd.concat([train_df, train_svd], axis=1)\ntest_df = pd.concat([test_df, test_svd], axis=1)\n\ndel full_tfidf, train_tfidf, test_tfidf, train_svd, test_svd\n\n\n# **Naive Bayes on Word Count Vectorizer:**\n\n# In[22]:\n\n\n### Fit transform the count vectorizer ###\nvectorizer=TfidfVectorizer(token_pattern=r'\\w{1,}', sublinear_tf=True, ngram_range=(1,2))\nclf = VotingClassifier(models, voting='soft', weights=[2,3,3,1,1])\n\ntfidf_vec = CountVectorizer(stop_words='english', ngram_range=(1,3))\ntfidf_vec.fit(train_df['text'].values.tolist() + test_df['text'].values.tolist())\ntrain_tfidf = tfidf_vec.transform(train_df['text'].values.tolist())\ntest_tfidf = tfidf_vec.transform(test_df['text'].values.tolist())\n\ncv_scores = []\npred_full_test = 0\npred_train = np.zeros([train_df.shape[0], 3])\nkf = model_selection.KFold(n_splits=10, shuffle=True, random_state=2017)\nfor dev_index, val_index in kf.split(train_X):\n    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\n    dev_y, val_y = train_y[dev_index], train_y[val_index]\n    #pred_val_y, pred_test_y, model = runMNB(dev_X, dev_y, val_X, val_y, test_tfidf)\n    clf.fit(dev_X, dev_y)\n    pred_val_y = clf.predict_proba(val_X)\n    pred_test_y = clf.predict_proba(test_tfidf)\n    pred_full_test = pred_full_test + pred_test_y\n    pred_train[val_index,:] = pred_val_y\n    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\nprint(\"Mean cv score : \", np.mean(cv_scores))\npred_full_test = pred_full_test / 10.\n\n# add the predictions as new features #\ntrain_df[\"nb_cvec_eap\"] = pred_train[:,0]\ntrain_df[\"nb_cvec_hpl\"] = pred_train[:,1]\ntrain_df[\"nb_cvec_mws\"] = pred_train[:,2]\ntest_df[\"nb_cvec_eap\"] = pred_full_test[:,0]\ntest_df[\"nb_cvec_hpl\"] = pred_full_test[:,1]\ntest_df[\"nb_cvec_mws\"] = pred_full_test[:,2]\n\n\n# We can train a simple XGBoost model.\n\n# In[42]:\n\n\n'''tfidf_vec = CountVectorizer(stop_words='english', ngram_range=(1,3))\ntfidf_vec.fit(train_df['text'].values.tolist() + test_df['text'].values.tolist())\ntrain_tfidf = tfidf_vec.transform(train_df['text'].values.tolist())\ntest_tfidf = tfidf_vec.transform(test_df['text'].values.tolist())\n'''\nvectorizer=TfidfVectorizer(token_pattern=r'\\w{1,}', sublinear_tf=True, ngram_range=(1,2))\nclf = VotingClassifier(models, voting='soft', weights=[3,2,3,1,1])\n\ncv_scores = []\npred_full_test = 0\npred_train = np.zeros([train_df.shape[0], 3])\nkf = model_selection.KFold(n_splits=10, shuffle=True, random_state=2017)\nfor dev_index, val_index in kf.split(train_X):\n    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\n    dev_y, val_y = train_y[dev_index], train_y[val_index]\n    #pred_val_y, pred_test_y, model = runBer(dev_X, dev_y, val_X, val_y, test_tfidf)\n    clf.fit(dev_X, dev_y)\n    pred_val_y = clf.predict_proba(val_X)\n    pred_test_y = clf.predict_proba(test_tfidf)\n    pred_full_test = pred_full_test + pred_test_y\n    pred_train[val_index,:] = pred_val_y\n    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\nprint(\"Mean cv score : \", np.mean(cv_scores))\npred_full_test = pred_full_test / 10.\n\n# add the predictions as new features #\ntrain_df[\"ber_cvec_eap\"] = pred_train[:,0]\ntrain_df[\"ber_cvec_hpl\"] = pred_train[:,1]\ntrain_df[\"ber_cvec_mws\"] = pred_train[:,2]\ntest_df[\"ber_cvec_eap\"] = pred_full_test[:,0]\ntest_df[\"ber_cvec_hpl\"] = pred_full_test[:,1]\ntest_df[\"ber_cvec_mws\"] = pred_full_test[:,2]\n\n\nvectorizer=TfidfVectorizer(token_pattern=r'\\w{1,}', sublinear_tf=True, ngram_range=(1,2))\nclf = VotingClassifier(models, voting='soft', weights=[2,3,3,1,1])\n\ntfidf_vec = CountVectorizer(ngram_range=(1,8), analyzer='char')\ntfidf_vec.fit(train_df['text'].values.tolist() + test_df['text'].values.tolist())\ntrain_tfidf = tfidf_vec.transform(train_df['text'].values.tolist())\ntest_tfidf = tfidf_vec.transform(test_df['text'].values.tolist())\n\ncv_scores = []\npred_full_test = 0\npred_train = np.zeros([train_df.shape[0], 3])\nkf = model_selection.KFold(n_splits=10, shuffle=True, random_state=2017)\nfor dev_index, val_index in kf.split(train_X):\n    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\n    dev_y, val_y = train_y[dev_index], train_y[val_index]\n    #pred_val_y, pred_test_y, model = runBer(dev_X, dev_y, val_X, val_y, test_tfidf)\n    clf.fit(dev_X, dev_y)\n    pred_val_y = clf.predict_proba(val_X)\n    pred_test_y = clf.predict_proba(test_tfidf)\n    pred_full_test = pred_full_test + pred_test_y\n    pred_train[val_index,:] = pred_val_y\n    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\nprint(\"Mean cv score : \", np.mean(cv_scores))\npred_full_test = pred_full_test / 10.\n\n# add the predictions as new features #\ntrain_df[\"ber_cvec_char_eap\"] = pred_train[:,0]\ntrain_df[\"ber_cvec_char_hpl\"] = pred_train[:,1]\ntrain_df[\"ber_cvec_char_mws\"] = pred_train[:,2]\ntest_df[\"ber_cvec_char_eap\"] = pred_full_test[:,0]\ntest_df[\"ber_cvec_char_hpl\"] = pred_full_test[:,1]\ntest_df[\"ber_cvec_char_mws\"] = pred_full_test[:,2]\n#----------------------------------------------------------------------------------------\n\n\n### Fit transform the tfidf vectorizer ###\n'''tfidf_vec = CountVectorizer(ngram_range=(1,8), analyzer='char')\ntfidf_vec.fit(train_df['text'].values.tolist() + test_df['text'].values.tolist())\ntrain_tfidf = tfidf_vec.transform(train_df['text'].values.tolist())\ntest_tfidf = tfidf_vec.transform(test_df['text'].values.tolist())\n'''\nvectorizer=TfidfVectorizer(token_pattern=r'\\w{1,}', sublinear_tf=True, ngram_range=(1,2))\nclf = VotingClassifier(models, voting='soft', weights=[3,2,3,1,1])\n\ncv_scores = []\npred_full_test = 0\npred_train = np.zeros([train_df.shape[0], 3])\nkf = model_selection.KFold(n_splits=10, shuffle=True, random_state=2017)\nfor dev_index, val_index in kf.split(train_X):\n    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\n    dev_y, val_y = train_y[dev_index], train_y[val_index]\n    #pred_val_y, pred_test_y, model = runMNB(dev_X, dev_y, val_X, val_y, test_tfidf)\n    clf.fit(dev_X, dev_y)\n    pred_val_y = clf.predict_proba(val_X)\n    pred_test_y = clf.predict_proba(test_tfidf)\n    pred_full_test = pred_full_test + pred_test_y\n    pred_train[val_index,:] = pred_val_y\n    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\nprint(\"Mean cv score : \", np.mean(cv_scores))\npred_full_test = pred_full_test / 10.\n\n# add the predictions as new features #\ntrain_df[\"nb_cvec_char_eap\"] = pred_train[:,0]\ntrain_df[\"nb_cvec_char_hpl\"] = pred_train[:,1]\ntrain_df[\"nb_cvec_char_mws\"] = pred_train[:,2]\ntest_df[\"nb_cvec_char_eap\"] = pred_full_test[:,0]\ntest_df[\"nb_cvec_char_hpl\"] = pred_full_test[:,1]\ntest_df[\"nb_cvec_char_mws\"] = pred_full_test[:,2]\n\n\n\n# The cross val score is very high and is 3.75. But this might add some different information than word level features and so let us use this for the final model as well.\n#\n# **Naive Bayes on Character Tfidf Vectorizer:**\n#\n# Let us also get the naive bayes predictions on the character tfidf vectorizer.\n\n# In[ ]:\n\n\n### Fit transform the tfidf vectorizer ###\nvectorizer=TfidfVectorizer(token_pattern=r'\\w{1,}', sublinear_tf=True, ngram_range=(1,2))\nclf = VotingClassifier(models, voting='soft', weights=[3,2,3,1,1])\n\ntfidf_vec = TfidfVectorizer(ngram_range=(1, 5), analyzer='char')\nfull_tfidf = tfidf_vec.fit_transform(train_df['text'].values.tolist() + test_df['text'].values.tolist())\ntrain_tfidf = tfidf_vec.transform(train_df['text'].values.tolist())\ntest_tfidf = tfidf_vec.transform(test_df['text'].values.tolist())\n\ncv_scores = []\npred_full_test = 0\npred_train = np.zeros([train_df.shape[0], 3])\nkf = model_selection.KFold(n_splits=10, shuffle=True, random_state=2017)\nfor dev_index, val_index in kf.split(train_X):\n    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\n    dev_y, val_y = train_y[dev_index], train_y[val_index]\n    #pred_val_y, pred_test_y, model = runMNB(dev_X, dev_y, val_X, val_y, test_tfidf)\n    clf.fit(dev_X, dev_y)\n    pred_val_y = clf.predict_proba(val_X)\n    pred_test_y = clf.predict_proba(test_tfidf)\n    pred_full_test = pred_full_test + pred_test_y\n    pred_train[val_index,:] = pred_val_y\n    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\nprint(\"Mean cv score : \", np.mean(cv_scores))\npred_full_test = pred_full_test / 10.\n\n# add the predictions as new features #\ntrain_df[\"nb_tfidf_char_eap\"] = pred_train[:,0]\ntrain_df[\"nb_tfidf_char_hpl\"] = pred_train[:,1]\ntrain_df[\"nb_tfidf_char_mws\"] = pred_train[:,2]\ntest_df[\"nb_tfidf_char_eap\"] = pred_full_test[:,0]\ntest_df[\"nb_tfidf_char_hpl\"] = pred_full_test[:,1]\ntest_df[\"nb_tfidf_char_mws\"] = pred_full_test[:,2]\n\n#111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n'''tfidf_vec = TfidfVectorizer(ngram_range=(1, 5), analyzer='char')\nfull_tfidf = tfidf_vec.fit_transform(train_df['text'].values.tolist() + test_df['text'].values.tolist())\ntrain_tfidf = tfidf_vec.transform(train_df['text'].values.tolist())\ntest_tfidf = tfidf_vec.transform(test_df['text'].values.tolist())\n'''\nvectorizer=TfidfVectorizer(token_pattern=r'\\w{1,}', sublinear_tf=True, ngram_range=(1,2))\nclf = VotingClassifier(models, voting='soft', weights=[2,3,3,1,1])\n\ncv_scores = []\npred_full_test = 0\npred_train = np.zeros([train_df.shape[0], 3])\nkf = model_selection.KFold(n_splits=10, shuffle=True, random_state=2017)\nfor dev_index, val_index in kf.split(train_X):\n    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\n    dev_y, val_y = train_y[dev_index], train_y[val_index]\n    #pred_val_y, pred_test_y, model = runBer(dev_X, dev_y, val_X, val_y, test_tfidf)\n    clf.fit(dev_X, dev_y)\n    pred_val_y = clf.predict_proba(val_X)\n    pred_test_y = clf.predict_proba(test_tfidf)\n    pred_full_test = pred_full_test + pred_test_y\n    pred_train[val_index,:] = pred_val_y\n    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\nprint(\"Mean cv score : \", np.mean(cv_scores))\npred_full_test = pred_full_test / 10.\n\n# add the predictions as new features #\ntrain_df[\"ber_tfidf_char_eap\"] = pred_train[:,0]\ntrain_df[\"ber_tfidf_char_hpl\"] = pred_train[:,1]\ntrain_df[\"ber_tfidf_char_mws\"] = pred_train[:,2]\ntest_df[\"ber_tfidf_char_eap\"] = pred_full_test[:,0]\ntest_df[\"ber_tfidf_char_hpl\"] = pred_full_test[:,1]\ntest_df[\"ber_tfidf_char_mws\"] = pred_full_test[:,2]\n\nvectorizer=TfidfVectorizer(token_pattern=r'\\w{1,}', sublinear_tf=True, ngram_range=(1,2))\nclf = VotingClassifier(models, voting='soft', weights=[2,3,3,1,1])\n\ntfidf_vec = TfidfVectorizer(ngram_range=(1,5), analyzer='word')\nfull_tfidf = tfidf_vec.fit_transform(train_df['text'].values.tolist() + test_df['text'].values.tolist())\ntrain_tfidf = tfidf_vec.transform(train_df['text'].values.tolist())\ntest_tfidf = tfidf_vec.transform(test_df['text'].values.tolist())\n\ncv_scores = []\npred_full_test = 0\npred_train = np.zeros([train_df.shape[0], 3])\nkf = model_selection.KFold(n_splits=10, shuffle=True, random_state=2017)\nfor dev_index, val_index in kf.split(train_X):\n    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\n    dev_y, val_y = train_y[dev_index], train_y[val_index]\n    #pred_val_y, pred_test_y, model = runBer(dev_X, dev_y, val_X, val_y, test_tfidf)\n    clf.fit(dev_X, dev_y)\n    pred_val_y = clf.predict_proba(val_X)\n    pred_test_y = clf.predict_proba(test_tfidf)\n    pred_full_test = pred_full_test + pred_test_y\n    pred_train[val_index,:] = pred_val_y\n    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\nprint(\"Mean cv score : \", np.mean(cv_scores))\npred_full_test = pred_full_test / 10.\n\n# add the predictions as new features #\ntrain_df[\"ber_tfidf2_char_eap\"] = pred_train[:,0]\ntrain_df[\"ber_tfidf2_char_hpl\"] = pred_train[:,1]\ntrain_df[\"ber_tfidf2_char_mws\"] = pred_train[:,2]\ntest_df[\"ber_tfidf2_char_eap\"] = pred_full_test[:,0]\ntest_df[\"ber_tfidf2_char_hpl\"] = pred_full_test[:,1]\ntest_df[\"ber_tfidf2_char_mws\"] = pred_full_test[:,2]\n#111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n\n#-------------------------------------------------------------------------------------\n'''tfidf_vec = TfidfVectorizer(ngram_range=(1,5), analyzer='word')\nfull_tfidf = tfidf_vec.fit_transform(train_df['text'].values.tolist() + test_df['text'].values.tolist())\ntrain_tfidf = tfidf_vec.transform(train_df['text'].values.tolist())\ntest_tfidf = tfidf_vec.transform(test_df['text'].values.tolist())\n'''\nvectorizer=TfidfVectorizer(token_pattern=r'\\w{1,}', sublinear_tf=True, ngram_range=(1,2))\nclf = VotingClassifier(models, voting='soft', weights=[3,2,3,1,1])\n\ncv_scores = []\npred_full_test = 0\npred_train = np.zeros([train_df.shape[0], 3])\nkf = model_selection.KFold(n_splits=10, shuffle=True, random_state=2017)\nfor dev_index, val_index in kf.split(train_X):\n    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\n    dev_y, val_y = train_y[dev_index], train_y[val_index]\n    #pred_val_y, pred_test_y, model = runMNB(dev_X, dev_y, val_X, val_y, test_tfidf)\n    clf.fit(dev_X, dev_y)\n    pred_val_y = clf.predict_proba(val_X)\n    pred_test_y = clf.predict_proba(test_tfidf)\n    pred_full_test = pred_full_test + pred_test_y\n    pred_train[val_index,:] = pred_val_y\n    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\nprint(\"Mean cv score : \", np.mean(cv_scores))\npred_full_test = pred_full_test / 10.\n\n# add the predictions as new features #\ntrain_df[\"nb_tfidf2_char_eap\"] = pred_train[:,0]\ntrain_df[\"nb_tfidf2_char_hpl\"] = pred_train[:,1]\ntrain_df[\"nb_tfidf2_char_mws\"] = pred_train[:,2]\ntest_df[\"nb_tfidf2_char_eap\"] = pred_full_test[:,0]\ntest_df[\"nb_tfidf2_char_hpl\"] = pred_full_test[:,1]\ntest_df[\"nb_tfidf2_char_mws\"] = pred_full_test[:,2]\n#-------------------------------------------------------------------------------------\n\n# **SVD on Character TFIDF:**\n#\n# We could also create svd features on character tfidf features and used them for modeling.\n\n# In[ ]:\n\n\nn_comp = 20\nsvd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')\nsvd_obj.fit(full_tfidf)\ntrain_svd = pd.DataFrame(svd_obj.transform(train_tfidf))\ntest_svd = pd.DataFrame(svd_obj.transform(test_tfidf))\n\ntrain_svd.columns = ['svd_char_'+str(i) for i in range(n_comp)]\ntest_svd.columns = ['svd_char_'+str(i) for i in range(n_comp)]\ntrain_df = pd.concat([train_df, train_svd], axis=1)\ntest_df = pd.concat([test_df, test_svd], axis=1)\n\ndel full_tfidf, train_tfidf, test_tfidf, train_svd, test_svd\n\n\n# For the sake of kernel run time, we can just check the first fold in the k-fold cross validation for the scores. Please remove the 'break' line while running in local.\n\n# In[45]:\n\n\n\n\n\n##############################################################\n\nvectorizer=TfidfVectorizer(token_pattern=r'\\w{1,}', sublinear_tf=True, ngram_range=(1,2))\nclf = VotingClassifier(models, voting='soft', weights=[3,3,3,1,1])\nX_train = vectorizer.fit_transform(train_df.text.values)\nauthors = ['MWS','EAP','HPL']\ny_train = train_df.author.apply(authors.index).values\nX_test = vectorizer.transform(test_df.text.values)\n\nkf = model_selection.KFold(n_splits=10, shuffle=True, random_state=2017)\ncv_scores = []\npred_full_test = 0\npred_train = np.zeros([train_df.shape[0], 3])\nfor dev_index, val_index in kf.split(X_train):\n    dev_X, val_X = X_train[dev_index], X_train[val_index]\n    dev_y, val_y = y_train[dev_index], y_train[val_index]\n    clf.fit(dev_X, dev_y)\n    pred_val_y = clf.predict_proba(val_X)\n    pred_full_test = pred_full_test + clf.predict_proba(X_test)\n    #pred_full_test = pred_full_test + pred_test_y\n    pred_train[val_index,:] = pred_val_y\n    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n    break\nprint(\"cv scores : \", cv_scores)\npred_full_test /= 10\n\ntrain_df[\"em_tfidf_eap\"] = pred_train[:,0]\ntrain_df[\"em_tfidf_hpl\"] = pred_train[:,1]\ntrain_df[\"em_tfidf_mws\"] = pred_train[:,2]\ntest_df[\"em_tfidf_eap\"] = pred_full_test[:,0]\ntest_df[\"em_tfidf_hpl\"] = pred_full_test[:,1]\ntest_df[\"em_tfidf_mws\"] = pred_full_test[:,2]\n##############################################################\n\ntrain_df.to_csv(\"train_26699.csv\", index=False)\ntest_df.to_csv(\"test_26699.csv\", index=False)\n\ncols_to_drop = ['id', 'text', 'text_cleaned']\ntrain_X = train_df.drop(cols_to_drop+['author'], axis=1)\ntest_X = test_df.drop(cols_to_drop, axis=1)\n\n\nkf = model_selection.KFold(n_splits=10, shuffle=True, random_state=2017)\ncv_scores = []\npred_full_test = 0\npred_train = np.zeros([train_df.shape[0], 3])\nfor dev_index, val_index in kf.split(train_X):\n    dev_X, val_X = train_X.loc[dev_index], train_X.loc[val_index]\n    dev_y, val_y = train_y[dev_index], train_y[val_index]\n    pred_val_y, pred_test_y, model = runXGB(dev_X, dev_y, val_X, val_y, test_X, seed_val=0, colsample=0.4)\n    pred_full_test = pred_full_test + pred_test_y\n    pred_train[val_index,:] = pred_val_y\n    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\nprint(\"cv scores : \", cv_scores)\nprint(sum(cv_scores) / 10)\npred_full_test = pred_full_test / 10.\n\nout_df = pd.DataFrame(pred_full_test)\nout_df.columns = ['EAP', 'HPL', 'MWS']\nout_df.insert(0, 'id', test_id)\nout_df.to_csv(\"submission.csv\", index=False)\n\nend_time = time()\nprint('totally time cost: %dm %.2fs' % ((end_time-start_time)/60, (end_time-start_time)%60))\n\n# We are getting a mlogloss of '0.987' using just the meta features. Not a bad score. Now let us see which of these features are important.\n\n# In[12]:\n\n\n### Plot the important variables ###\n'''\nfig, ax = plt.subplots(figsize=(12,12))\nxgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\nplt.show()\n'''\n\nfig, ax = plt.subplots(figsize=(120,120))\nxgb.plot_importance(model, max_num_features=500, height=0.8, ax=ax)\nfig.savefig('test.png', dpi=100)\n\n\n","metadata":{"id":"KRziprIRaJC9","outputId":"6d50a02d-f96b-43e7-99c2-897e6fdb471f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Naive bayes features are the top features as expected. Now let us get the confusion matrix to see the misclassification errors.\n\n# In[ ]:\n\n\nimport itertools\nfrom sklearn.metrics import confusion_matrix\n\n### From http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py #\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        #print(\"Normalized confusion matrix\")\n    #else:\n    #    print('Confusion matrix, without normalization')\n\n    #print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\ncnf_matrix = confusion_matrix(val_y, np.argmax(pred_val_y,axis=1))\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplt.figure(figsize=(8,8))\nplot_confusion_matrix(cnf_matrix, classes=['EAP', 'HPL', 'MWS'],\n                      title='Confusion matrix, without normalization')\nplt.show()\n'''\n\n# EAP and MWS seem to be misclassified more often than others. We could potentially create features which improves the predictions for this pair.\n#\n# **Next steps in this FE notebook:**\n# * Using word embedding based features\n# * Other meta features if any\n\n# **Ideas for further improvements:**\n# * Parameter tuning for tfidf and count vectorizer\n# * Parameter tuning for naive bayes and XGB models\n# * Ensembling / Stacking with other models\n\n#\n# **More to come. Stay tuned.!*","metadata":{"id":"uTI24fHxZZ_h","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"t1wuhN0cZa6e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"30Ll-eFKZbGl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"NbCHFxmeZbTR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"8pNHTzQxZbVY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"3MA1zeUtZbs7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip \"glove.840B.300d.zip\" -d \"glove.840B.300d.txt\"","metadata":{"id":"OAkphxdlVbDL","outputId":"247d1a43-6b40-4a9e-db06-2b9e2d1bd8ca","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n!pip install -U -q kaggle\n!mkdir -p ~/.kaggle\n!echo '{\"username\":\"shutingtao\",\"key\":\"4a9aca6f75a10aebd2de4229dcd1ee6b\"}' > ~/.kaggle/kaggle.json\n!chmod 600 ~/.kaggle/kaggle.json\n \n","metadata":{"id":"yDKeuOJPdJxf","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!kaggle -v","metadata":{"id":"3DwcYGE-1wGk","outputId":"87d1a62a-ebb6-414d-eecb-bb6f727c98db","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!kaggle competitions download spooky-author-identification","metadata":{"id":"xVZQlzFAuLXH","outputId":"180d8966-0993-44fe-df7f-7ba79ab6f274","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!kaggle competitions download quora-insincere-questions-classification","metadata":{"id":"9fYEnPbOvv6B","outputId":"84862a16-5e0b-4c9f-be66-75ad9e9dfe61","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python main.py","metadata":{"id":"Pigufiwncl1p","outputId":"0f6670ba-d0a0-469f-a018-f92c21326909","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"UcmrXaCuX_tg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"VGA2wOk3vF68"},"execution_count":null,"outputs":[]}]}