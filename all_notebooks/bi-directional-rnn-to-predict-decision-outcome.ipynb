{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\n%matplotlib inline\n\nfrom tensorflow.python.keras.preprocessing.text import Tokenizer\nfrom tensorflow.python.keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM, GRU, Bidirectional\nfrom keras.layers.embeddings import Embedding","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame()\ndf = pd.read_csv(\"../input/industrial-security-clearance-decisions-classified.csv\")\ndf_noblanks = df.loc[(df[\"digest\"].notnull()), (\"date\", \"digest\", \"keywords\", \"Favorable decision\", \"Decision upheld\")]\ndf_noblanks.dropna(subset = ['Favorable decision', 'Decision upheld'], inplace = True)\n\ndf_noblanks.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data consists of 5 columns\nDate - Date of the appeals hearing and decision\nDigest - Free text field describing the appeals decision\nKeywords - Identifes the type of guideline (such as Financial, Foreign Influence, security etc.) that the appeal relates to\nFavorable decision - Binary variable indicating the outcome of appeal i.e. favorable, which is ruled in favor of the party or unfavorable, which results in a rejection of security clearance\nDecision upheld - Binary variable indicating whether the decision made prior to appeal was upheld by the Appeals court of rejected. Yes indicates that the judge's decison was upheld, \"No\" indicates that the judge's decision was overturned"},{"metadata":{},"cell_type":"markdown","source":"**Exploring favorable decisions** - Visualization of the number of favorable and unfavorable decisions by year, the proportion of favorable and unfavorable decisions, and the percentage of favorable decisions by year"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Identify if any rows have unrecognizable date formats; this was a problem with the original data set but has already been cleaned up in this one\nbad_rows = pd.to_datetime(df_noblanks[\"date\"], errors = 'coerce').isnull()\nprint(np.where(bad_rows == True))\n\n#Group the favorable and unfavorable decisions by year\ndf_noblanks['date'] = pd.to_datetime(df_noblanks['date'])\nx = pd.DataFrame(df_noblanks.groupby([df_noblanks['date'].dt.year, 'Favorable decision'])\n                 ['Favorable decision'].agg({'count'}).reset_index())\nx_pos = x.loc[x['Favorable decision'] == 'Yes']\nx_neg = x.loc[x['Favorable decision'] == 'No']\nx_pos.loc[:, 'Pctg'] = np.divide(x_pos.loc[:, 'count'], np.add(x_pos.loc[:, 'count'], x_neg.loc[:, 'count']))\n\nfig = plt.figure(figsize = (15,4))\ncolors = ['limegreen', 'tomato']\n\n#Line chart for annual distribution of decisions - both favorable and unfavorable\nax1 = fig.add_subplot(121)\nax1.set(title = \"Annual distribution of decisions\", xlabel = \"Year\", ylabel = \"No. of decisions\")\nax1.plot(x_pos['date'], x_pos['count'], color = colors[0], linewidth = 2, label = \"Favourable decisions\")\nax1.plot(x_neg['date'], x_neg['count'], color = colors[1], linewidth = 2, label = \"Unfavourable decisions\")\nax1.legend()\n\n#Pie chart indicating the proportion of favorable to unfavorable decisions\nax2 = fig.add_subplot(122)\nax2.set(title = \"Percentage Unfavourable vs. Favourable decisions\")\nax2.pie((sum(x_pos['count']), sum(x_neg['count'])), explode = (0.1, 0), labels = (\"Favourable decisions\", \"Unfavourable decisions\"), autopct='%1.1f%%', shadow = True, colors = colors)\nax2.axis('equal')\n\n#Bar chart indicating the percentage of favorable decisions by year\nfig2 = plt.figure(figsize = (15,8))\nax = fig2.add_subplot(111)\nax.set(title = \"Percentage of favourable decisions\", xlabel = \"Year\", ylabel = \"Percentage favourable decisions\")\nax.bar(x_pos['date'], x_pos['Pctg'], color = colors[0], linewidth = 3)\n\nrects = ax.patches\nlabels = x_pos['Pctg']\n\nfor rect, label in zip(rects, labels):\n    ax.annotate(\n            '{:.1%}'.format(label),                      \n            (rect.get_x() + rect.get_width() / 2, rect.get_height()),         \n            xytext=(0, 5),          \n            textcoords=\"offset points\", \n            ha='center',                \n            va='bottom')    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's evident that majority of the cases heard by the Appeals court result in unfavorable decisions i.e. security clearance is rejected. **Almost 68% of cases heard are rejected**, which would reinforce the notion that the obtaining security clearance is a difficult task!\n\nFurther, from the first chart, it appears that the period from 2003 onwards has seen a marked increase in the number of appeals that the court is receiving. We find that with the increased volume of cases, the rate of **rejection has increased, spiking to 37.6% in 2014 and 2015**. Considering the increases volume and rate of rejection, it might be indicative of a more lenient process for appeals, where the court has been receiving more and more cases without merit.\n\nThe subsequent set of charts looks at **Exploring upheld decisions** - Visualization of the number upheld and overturned decisions by year, the proportion of upheld and overturned decisions, and the percentage of upheld decisions by year"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Group the upheld and overturned decisions by year\nx = pd.DataFrame(df_noblanks.groupby([df_noblanks['date'].dt.year, 'Decision upheld'])['Decision upheld'].agg({'count'}).reset_index())\nx_pos = x.loc[x['Decision upheld'] == 'Yes']\nx_neg = x.loc[x['Decision upheld'] == 'No']\nx_pos.loc[:, 'Pctg'] = np.divide(x_pos.loc[:, 'count'], np.add(x_pos.loc[:, 'count'], x_neg.loc[:, 'count']))\n\nfig = plt.figure(figsize = (15,4))\ncolors = ['springgreen', 'salmon']\n\n#Line chart for annual distribution of decisions - both upheld and overturned\nax1 = fig.add_subplot(121)\nax1.set(title = \"Annual distribution of decisions\", xlabel = \"Year\", ylabel = \"No. of decisions\")\nax1.plot(x_pos['date'], x_pos['count'], color = colors[0], linewidth = 2, label = \"Decisions upheld\")\nax1.plot(x_neg['date'], x_neg['count'], color = colors[1], linewidth = 2, label = \"Decision overturned\")\nax1.legend()\n\n#Pie chart indicating the proportion of upheld to overturned decisions\nax2 = fig.add_subplot(122)\nax2.set(title = \"Percentage Decisions upheld vs. overturned\")\nax2.pie((sum(x_pos['count']), sum(x_neg['count'])), explode = (0.1, 0), labels = (\"Decisions upheld\", \"Decisions overturned\"), autopct='%1.1f%%', shadow = True, colors = colors)\nax2.axis('equal')\n\n#Bar chart indicating the percentage of upheld decisions by year\nfig2 = plt.figure(figsize = (15,8))\nax = fig2.add_subplot(111)\nax.set(title = \"Percentage of decisions upheld\", xlabel = \"Year\", ylabel = \"Percentage decisions upheld\")\nax.bar(x_pos['date'], x_pos['Pctg'], color = colors[0], linewidth = 3)\n\nrects = ax.patches\nlabels = x_pos['Pctg']\n\nfor rect, label in zip(rects, labels):\n    ax.annotate(\n            '{:.1%}'.format(label),                      \n            (rect.get_x() + rect.get_width() / 2, rect.get_height()),         \n            xytext=(0, 5),          \n            textcoords=\"offset points\", \n            ha='center',                \n            va='bottom')       ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Almost 1 out of 3  cases heard by the Appeals court are upheld**. From a first glance at the numbers it seems like there might be a relation between the types of cases that are upheld and the decision iteself (favorable or unfavorable). **Decisions overturned spiked in 2014 and 2015 at 38%**, also the year in which the Appeals court received it's highest volume of cases. \n\nIt might be worth cross-tabulating overturned decisions with the outcome of the decision (favorable or unfavorable)."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Group upheld and favorable decisions\nx = pd.DataFrame(df_noblanks.groupby('Favorable decision')['Decision upheld'].agg({'count'}).reset_index())\nx.head()\n\noutcome = pd.Series(df_noblanks['Favorable decision'], name='Favorable decision')\nupheld = pd.Series(df_noblanks['Decision upheld'], name='Decision upheld')\ndf_confusion = pd.crosstab(outcome, upheld)\n\n#Cross tabulation (confusion matrix) of decisions upheld and favorable decisions\nfig3 = plt.figure(figsize = (15,4))\nax3 = fig3.add_subplot(111)\nax3.set(title = \"Cross tabulation of favourable decisions and decisions upheld\", \n        xlabel = 'Decision upheld', ylabel = 'Favorable decision', \n        xticks = np.arange(df_confusion.shape[1]), yticks = np.arange(df_confusion.shape[0]),\n        xticklabels = df_confusion.index.values, yticklabels = df_confusion.columns.values)\nax3.imshow(df_confusion, interpolation = 'nearest', cmap = plt.cm.Greens)\n\nthresh = df_confusion.values.max() / 2\nfor i in range(df_confusion.shape[0]):\n    for j in range(df_confusion.shape[1]):\n        ax3.text(j, i, df_confusion.iloc[i, j],\n                ha=\"center\", va=\"center\",\n                color=\"white\" if df_confusion.iloc[i, j] > thresh else \"black\")\nplt.show()\n        \nnum_initial_unfavorable_decisions = df_confusion.iloc[0,1] + df_confusion.iloc[1,0]\nprint(\"Number of decisions that were initially ruled upon unfavorably = \"\n      + str(num_initial_unfavorable_decisions))\nprint(\"Probability of an unfavorable decision being overturned in case it is appealed = \"\n     + \"{:.2%}\".format(df_confusion.iloc[1,0]/num_initial_unfavorable_decisions))\n\nnum_initial_favorable_decisions = df_confusion.iloc[0,0] + df_confusion.iloc[1,1]\nprint(\"Number of decisions that were initially ruled upon favorably = \"\n      + str(num_initial_favorable_decisions))\nprint(\"Probability of a favorable decision being overturned in case it is appealed = \"\n     + \"{:.2%}\".format(df_confusion.iloc[0,0]/num_initial_favorable_decisions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The cross-tabulation confirms that out of 7,264 (6,932 + 332) decisions overturned, **majority (95% - 6,932 out of 7,264) were initially rejected applications**, which were then appealed and overturned in favor of the party. Surprisingly, 5% of the appeals that were initially ruled upon positively were later overturned in the Appeals process and security clearance was rejected.\n\nSimilarly, out of 14,610 (14,508 + 102) cases that were upheld, **99% were unfavorable (security clearances were rejected)**. Out of 21,440 decisions that were initially rules upon unfavorably, one can take heart in knowing that **32.3% of such cases (roughly 1 out of 3) were overturned** and resulted in security clearance being granted.\n\nInterestingly, an initially favorable decision that goes to the Appeals court is **overturned 76.5% of the time!**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#X - Transcript of the decision as input\nX = df_noblanks.loc[:, (\"digest\")]\n\n#Y - Predicting the outcome of the decision and whether or not it will be upheld\nY = df_noblanks.loc[:, (\"Favorable decision\", \"Decision upheld\")]\n#Code the Yes/No values in Favorable and upheld decisions, our predicted values, to 1/0\nY = (Y.replace(to_replace = ['No', 'Yes'], value = [0, 1])).astype(int)\n\n#Split into training and test data\nX_train, X_test, Y_train, Y_test = train_test_split(X.values, Y.values, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will be using a bi-directional RNN to predict the outcome and whether or not the decision was upheld based on the text of the decision. With a forward RNN model, the accuracy achieved was only in the range of 60% - 70%. Bi-directional RNNs seem apt for this application, since the decision text involves several double negatives and indirect references."},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer_object = Tokenizer()\nX_train = X_train.flatten()\nX_test = X_test.flatten()\ntotal_decisions = np.concatenate((X_train, X_test))\ntokenizer_object.fit_on_texts(total_decisions)\n\n#Pad sequences\nmax_len = max([len(s.split()) for s in total_decisions])\n\n#Define vocab size\nvocab_size = len(tokenizer_object.word_index) + 1\n\n#Create sequences\nX_train_tokens = tokenizer_object.texts_to_sequences(X_train)\nX_test_tokens = tokenizer_object.texts_to_sequences(X_test)\n\nX_train_pad = pad_sequences(X_train_tokens, maxlen = max_len, padding = 'post')\nX_test_pad = pad_sequences(X_test_tokens, maxlen = max_len, padding = 'post')\n\n\n#Bi-directional RNN with embeddings being trained\nEMBEDDING_DIM = 50\nmodel = Sequential()\nmodel.add(Embedding(vocab_size, EMBEDDING_DIM, input_length = max_len))\nmodel.add(Bidirectional(GRU(units = 32, dropout = 0.15, recurrent_dropout = 0.15)))\nmodel.add(Dense(2, activation = 'sigmoid'))\n\nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\nhistory = model.fit(X_train_pad, Y_train, batch_size = 128, epochs = 10, validation_data = (X_test_pad, Y_test), verbose = 2)\n\n#Plotting  costs by iteration\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model achieves 98% accuracy on both the training and test sets."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}