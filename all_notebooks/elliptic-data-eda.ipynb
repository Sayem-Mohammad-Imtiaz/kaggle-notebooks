{"cells":[{"metadata":{},"cell_type":"markdown","source":"## General information\n\nIn this kernel I work with Elliptic Data Set. My aim is to explore the data and maybe to find some insights."},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!pip install -U vega_datasets notebook vega","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom tqdm import tqdm_notebook\npd.options.display.precision = 15\n\nimport time\nimport datetime\nimport gc\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom IPython.display import HTML\nimport json\nimport altair as alt\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nalt.renderers.enable('notebook')\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import altair as alt\nfrom altair.vega import v5\nfrom IPython.display import HTML\n\n# using ideas from this kernel: https://www.kaggle.com/notslush/altair-visualization-2018-stackoverflow-survey\ndef prepare_altair():\n    \"\"\"\n    Helper function to prepare altair for working.\n    \"\"\"\n\n    vega_url = 'https://cdn.jsdelivr.net/npm/vega@' + v5.SCHEMA_VERSION\n    vega_lib_url = 'https://cdn.jsdelivr.net/npm/vega-lib'\n    vega_lite_url = 'https://cdn.jsdelivr.net/npm/vega-lite@' + alt.SCHEMA_VERSION\n    vega_embed_url = 'https://cdn.jsdelivr.net/npm/vega-embed@3'\n    noext = \"?noext\"\n    \n    paths = {\n        'vega': vega_url + noext,\n        'vega-lib': vega_lib_url + noext,\n        'vega-lite': vega_lite_url + noext,\n        'vega-embed': vega_embed_url + noext\n    }\n    \n    workaround = f\"\"\"    requirejs.config({{\n        baseUrl: 'https://cdn.jsdelivr.net/npm/',\n        paths: {paths}\n    }});\n    \"\"\"\n    \n    return workaround\n    \n\ndef add_autoincrement(render_func):\n    # Keep track of unique <div/> IDs\n    cache = {}\n    def wrapped(chart, id=\"vega-chart\", autoincrement=True):\n        if autoincrement:\n            if id in cache:\n                counter = 1 + cache[id]\n                cache[id] = counter\n            else:\n                cache[id] = 0\n            actual_id = id if cache[id] == 0 else id + '-' + str(cache[id])\n        else:\n            if id not in cache:\n                cache[id] = 0\n            actual_id = id\n        return render_func(chart, id=actual_id)\n    # Cache will stay outside and \n    return wrapped\n           \n\n@add_autoincrement\ndef render(chart, id=\"vega-chart\"):\n    \"\"\"\n    Helper function to plot altair visualizations.\n    \"\"\"\n    chart_str = \"\"\"\n    <div id=\"{id}\"></div><script>\n    require([\"vega-embed\"], function(vg_embed) {{\n        const spec = {chart};     \n        vg_embed(\"#{id}\", spec, {{defaultStyle: true}}).catch(console.warn);\n        console.log(\"anything?\");\n    }});\n    console.log(\"really...anything?\");\n    </script>\n    \"\"\"\n    return HTML(\n        chart_str.format(\n            id=id,\n            chart=json.dumps(chart) if isinstance(chart, dict) else chart.to_json(indent=None)\n        )\n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have three files in this dataset. Let's load them."},{"metadata":{},"cell_type":"markdown","source":"## Data loading and overview"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_classes = pd.read_csv('/kaggle/input/elliptic_bitcoin_dataset/elliptic_bitcoin_dataset/elliptic_txs_classes.csv')\ndf_features = pd.read_csv('/kaggle/input/elliptic_bitcoin_dataset/elliptic_bitcoin_dataset/elliptic_txs_features.csv', header=None)\ndf_edgelist = pd.read_csv('/kaggle/input/elliptic_bitcoin_dataset/elliptic_bitcoin_dataset/elliptic_txs_edgelist.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have the following data:\n- 203769 transactions / graph nodes;\n- 234355 bitcoin flows / graph edges;\n- `elliptic_txs_edgelist.csv` contains graph edges information;\n- `elliptic_txs_classes.csv` contains information about legality of transactions;\n- `elliptic_txs_features.csv` contains information about transaction features;"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_classes['class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Class `1` means that transaction is illicit, '2' means that transaction is licit and most transaction aren't labeled."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_features.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The file with features is anonimyzed, it doesn't even have column names. Let's see what can be derived from the data description:\n- first column (with name `0`) is the transaction id;\n- column `1` represents timesteps for each node. These timestamps have an interval of ~2 weeks. Each timestamp contains connected component of transactions, which appeared on the blockchain within less than three hours between each other;\n- next 93 features show information about the transaction: number of inputs/outputs, transaction fee, output volume and aggregated figures such as average BTC received (spent) by the inputs/outputs and average number of incoming (outgoing) transactions associated with the inputs/outputs;\n- the remaining 72 features are aggregated features, obtained using transaction information one-hop backward/forward from the center node - giving the maximum, minimum, standard deviation and correlation coefficients of the neighbour transactions for the same information data (number of inputs/outputs, transaction fee, etc.)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# renaming columns\ndf_features.columns = ['id', 'time step'] + [f'trans_feat_{i}' for i in range(93)] + [f'agg_feat_{i}' for i in range(72)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## number of transactions and classes"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_features['time step'].value_counts().sort_index().plot();\nplt.title('Number of transactions in each time step');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Considering delta between time steps is 2 weeks, we have 98 weeks - almost 2 years. There were some up and down trends, but we can't see anything interesting on a simple plot. Let's split transactions by class."},{"metadata":{"trusted":true},"cell_type":"code","source":"# merge with classes\ndf_features = pd.merge(df_features, df_classes, left_on='id', right_on='txId', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 8))\ngrouped = df_features.groupby(['time step', 'class'])['id'].count().reset_index().rename(columns={'id': 'count'})\nsns.lineplot(x='time step', y='count', hue='class', data=grouped);\nplt.legend(loc=(1.0, 0.8));\nplt.title('Number of transactions in each time step by class');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can see that there were spikes in illicit transactions which usually happened when there was a generan increase on number of transactions."},{"metadata":{},"cell_type":"markdown","source":"## Examples of graphs"},{"metadata":{},"cell_type":"markdown","source":"Let's have a look at a graph at one time step. I'll plot a directed and an indirected graph."},{"metadata":{"trusted":true},"cell_type":"code","source":"bad_ids = df_features.loc[(df_features['time step'] == 37) & (df_features['class'] == '1'), 'id']\nshort_edges = df_edgelist.loc[df_edgelist['txId1'].isin(bad_ids)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"graph = nx.from_pandas_edgelist(short_edges, source = 'txId1', target = 'txId2', \n                                 create_using = nx.DiGraph())\npos = nx.spring_layout(graph)\nnx.draw(graph, cmap = plt.get_cmap('rainbow'), with_labels=True, pos=pos)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"graph1 = nx.from_pandas_edgelist(short_edges, source = 'txId1', target = 'txId2', \n                                 create_using = nx.Graph())\npos1 = nx.spring_layout(graph1)\nnx.draw(graph1, cmap = plt.get_cmap('rainbow'), with_labels=False, pos=pos1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"We can clearly see that some frauders worked alone and some worked in groups."},{"metadata":{},"cell_type":"markdown","source":"## features exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"# grouped = df_features.groupby(['time step', 'class'])['trans_feat_0'].mean().reset_index()\n# chart = alt.Chart(grouped).mark_line().encode(\n#     x=alt.X(\"time step:N\", axis=alt.Axis(title='Time step', labelAngle=315)),\n#     y=alt.Y('trans_feat_0:Q', axis=alt.Axis(title='Mean of trans_feat_0')),\n#     color = 'class:N',\n#     tooltip=['time step:O', 'trans_feat_0:Q', 'class:N']\n# ).properties(title=\"Average trans_feat_0 in each time step by type\", width=600).interactive()\n# chart","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 8))\ngrouped = df_features.groupby(['time step', 'class'])['trans_feat_0'].mean().reset_index()\nsns.lineplot(x='time step', y='trans_feat_0', hue='class', data=grouped);\nplt.legend(loc=(1.0, 0.8));\nplt.title('Average trans_feat_0 in each time step by type');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that this feature can efficiently separate illicit transactions from licit."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}