{"cells":[{"metadata":{},"cell_type":"markdown","source":"Reading classics [Deep Learning Models](https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/tree/master/pytorch_ipynb/)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Code Modules & Functions","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np,pandas as pd,pylab as pl\nimport h5py,torch\nfrom torchvision.datasets import MNIST as tmnist\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader as tdl\nfrom torch.utils.data import Dataset as tds\nimport torch.nn.functional as tnnf\nfrom sklearn.datasets import make_classification\nfrom IPython.core.magic import register_line_magic\ndev=torch.device(\"cuda:0\" if torch.cuda.is_available() \n                 else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_acc(model,data_loader,num_features):\n    correct_preds,num_examples=0,0    \n    for features,targets in data_loader:\n        features=features.view(-1,num_features).to(dev)\n        targets=targets.to(dev)\n        logits,probs=model(features)\n        _,pred_labels=torch.max(probs,1)\n        num_examples+=targets.size(0)\n        correct_preds+=(pred_labels==targets).sum()        \n    return correct_preds.float()/num_examples*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@register_line_magic\ndef print_acc(t):\n    if t=='test':\n        print('Test accuracy: %.4f%%'%\\\n        (model_acc(model,test_loader,num_features)))\n    if t=='train':\n        print('Train accuracy: %.4f%%'%\\\n        (model_acc(model,train_loader,num_features)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@register_line_magic\ndef print_acc2(t):\n    if t=='test':\n        print('Test accuracy: %.4f%%'%\\\n        (model_acc(model,test_loader2,num_features2)))\n    if t=='train':\n        print('Train accuracy: %.4f%%'%\\\n        (model_acc(model,train_loader2,num_features2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@register_line_magic\ndef train_run(epochs):\n    epochs=int(epochs)\n    for epoch in range(epochs):\n        for batch_ids,(features,targets) in enumerate(train_loader):        \n            features=features.view(-1,num_features).to(dev)\n            targets=targets.to(dev)\n            logits,probs=model(features)\n            cost=tnnf.cross_entropy(logits,targets)\n            optimizer.zero_grad(); cost.backward()\n            optimizer.step()\n            if not batch_ids%300:\n                print ('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f' \n                       %(epoch+1,epochs,batch_ids, \n                         len(train)//batch_size,cost))           \n        with torch.set_grad_enabled(False):\n            print('Epoch: %03d/%03d train accuracy: %.2f%%'%\\\n                  (epoch+1,epochs,model_acc(model,train_loader,\n                                            num_features)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@register_line_magic\ndef train_run2(epochs):\n    epochs=int(epochs)\n    for epoch in range(epochs):\n        for batch_ids,(features,targets) in enumerate(train_loader2):        \n            features=features.view(-1,num_features2).to(dev)\n            targets=targets.to(dev)\n            logits,probs=model(features)\n            cost=tnnf.cross_entropy(logits,targets.long())\n            optimizer.zero_grad(); cost.backward()\n            optimizer.step()\n            if not batch_ids%300:\n                print ('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f' \n                       %(epoch+1,epochs,batch_ids, \n                         len(train2)//batch_size2,cost))           \n        with torch.set_grad_enabled(False):\n            print('Epoch: %03d/%03d train accuracy: %.2f%%'%\\\n                  (epoch+1,epochs,model_acc(model,train_loader2,\n                                            num_features2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"random_seed=1; batch_size=64\ntrain=tmnist(root='data',train=True,download=True,\n            transform=transforms.ToTensor())\ntest=tmnist(root='data',train=False, \n            transform=transforms.ToTensor())\ntrain_loader=tdl(dataset=train,shuffle=True, \n                 batch_size=batch_size)\ntest_loader=tdl(dataset=test,shuffle=False, \n                batch_size=batch_size)\nfor images,labels in train_loader:  \n    print('Image dimensions: %s'%str(images.shape))\n    print('Label dimensions: %s'%str(labels.shape))\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpath='../input/classification-of-handwritten-letters/'\nf='LetterColorImages_123.h5'\nf=h5py.File(fpath+f,'r')\nkeys=list(f.keys()); print(keys)\nX=np.array(f[keys[1]],dtype='float32')/255\ny=np.array(f[keys[2]],dtype='int32')-1\nN=len(y); n=int(.2*N); batch_size=16\nshuffle_ids=np.arange(N)\nnp.random.RandomState(23).shuffle(shuffle_ids)\nX,y=X[shuffle_ids],y[shuffle_ids]\nX_test,X_train=X[:n],X[n:]\ny_test,y_train=y[:n],y[n:]\nX_train.shape,y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_seed=1; batch_size2=64\nclass TData(tds):\n    def __init__(self,X,y):   \n        self.X=torch.tensor(X,dtype=torch.float32)\n        self.y=torch.tensor(y,dtype=torch.int32)\n    def __getitem__(self,index):\n        train_img,train_lbl=self.X[index],self.y[index]\n        return train_img,train_lbl\n    def __len__(self):\n        return self.y.shape[0]\ntrain2=TData(X_train,y_train)\ntest2=TData(X_test,y_test)\ntrain_loader2=tdl(dataset=train2,batch_size=batch_size2,shuffle=True)\ntest_loader2=tdl(dataset=test2,batch_size=batch_size2,shuffle=False)\nfor images,labels in train_loader2:  \n    print('Image dimensions: %s'%str(images.shape))\n    print('Label dimensions: %s'%str(labels.shape))\n    break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## MLP","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_features=784; num_classes=10\nhidden1=512; hidden2=256; hidden3=128\nclass MLP(torch.nn.Module):\n    def __init__(self,num_features,num_classes):\n        super(MLP,self).__init__()\n        self.linear1=torch.nn.Linear(num_features,hidden1)\n        self.linear1.weight.detach().normal_(0.,.1)\n        self.linear1.bias.detach().zero_()\n        self.linear2=torch.nn.Linear(hidden1,hidden2)\n        self.linear2.weight.detach().normal_(0.,.1)\n        self.linear2.bias.detach().zero_()\n        self.linear3=torch.nn.Linear(hidden2,hidden3)\n        self.linear3.weight.detach().normal_(0.,.1)\n        self.linear3.bias.detach().zero_()\n        self.linear_out=torch.nn.Linear(hidden3,num_classes)\n        self.linear_out.weight.detach().normal_(0.,.1)\n        self.linear_out.bias.detach().zero_()        \n    def forward(self,x):\n        y=self.linear1(x); y=tnnf.relu(y)\n        y=self.linear2(y); y=tnnf.relu(y)\n        y=self.linear3(y); y=tnnf.relu(y)\n        logits=self.linear_out(y)\n        probs=tnnf.log_softmax(logits,dim=1)\n        return logits,probs   \ntorch.manual_seed(random_seed)\nmodel=MLP(num_features=num_features,\n          num_classes=num_classes)\nmodel=model.to(dev); learning_rate=.01\noptimizer=torch.optim.SGD(model.parameters(),lr=learning_rate) ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"%train_run 20","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%print_acc train\n%print_acc test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_features2=3072; num_classes2=33\nhidden1=1024; hidden2=256; hidden3=256\nclass MLP2(torch.nn.Module):\n    def __init__(self,num_features,num_classes):\n        super(MLP2,self).__init__()\n        self.linear1=torch.nn.Linear(num_features,hidden1)\n        self.linear1.weight.detach().normal_(0.,.1)\n        self.linear1.bias.detach().zero_()\n        self.linear2=torch.nn.Linear(hidden1,hidden2)\n        self.linear2.weight.detach().normal_(0.,.1)\n        self.linear2.bias.detach().zero_()\n        self.linear3=torch.nn.Linear(hidden2,hidden3)\n        self.linear3.weight.detach().normal_(0.,.1)\n        self.linear3.bias.detach().zero_()\n        self.linear_out=torch.nn.Linear(hidden3,num_classes)\n        self.linear_out.weight.detach().normal_(0.,.1)\n        self.linear_out.bias.detach().zero_()        \n    def forward(self,x):\n        y=self.linear1(x); y=tnnf.relu(y)\n        y=self.linear2(y); y=tnnf.relu(y)\n        y=self.linear3(y); y=tnnf.relu(y)\n        logits=self.linear_out(y)\n        probs=tnnf.log_softmax(logits,dim=1)\n        return logits,probs   \ntorch.manual_seed(random_seed)\nmodel=MLP2(num_features=num_features2,\n           num_classes=num_classes2)\nmodel=model.to(dev); learning_rate=.001\noptimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"%train_run2 30","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%print_acc2 train\n%print_acc2 test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## MLP with Dropouts","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_features=784; num_classes=10\nhidden1=1024; hidden2=256; hidden3=64\ndropout_prob=.1\nclass MLPD(torch.nn.Module):\n    def __init__(self,num_features,num_classes):\n        super(MLPD,self).__init__()\n        self.linear1=torch.nn.Linear(num_features,hidden1)\n        self.linear1.weight.detach().normal_(0.,.1)\n        self.linear1.bias.detach().zero_()\n        self.linear2=torch.nn.Linear(hidden1,hidden2)\n        self.linear2.weight.detach().normal_(0.,.1)\n        self.linear2.bias.detach().zero_()\n        self.linear3=torch.nn.Linear(hidden2,hidden3)\n        self.linear3.weight.detach().normal_(0.,.1)\n        self.linear3.bias.detach().zero_()\n        self.linear_out=torch.nn.Linear(hidden3,num_classes)\n        self.linear_out.weight.detach().normal_(0.,.1)\n        self.linear_out.bias.detach().zero_()        \n    def forward(self,x):\n        y=self.linear1(x); y=tnnf.relu(y)\n        y=tnnf.dropout(y,p=dropout_prob,\n                       training=self.training)\n        y=self.linear2(y); y=tnnf.relu(y)\n        y=tnnf.dropout(y,p=dropout_prob,\n                       training=self.training)\n        y=self.linear3(y); y=tnnf.relu(y)\n        logits=self.linear_out(y)\n        probs=tnnf.log_softmax(logits,dim=1)\n        return logits,probs   \ntorch.manual_seed(random_seed)\nmodel=MLPD(num_features=num_features,\n           num_classes=num_classes)\nmodel=model.to(dev); learning_rate=.01\noptimizer=torch.optim.SGD(model.parameters(),lr=learning_rate) ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"%train_run 20","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%print_acc train\n%print_acc test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_features2=3072; num_classes2=33\nhidden1=hidden2=1024; hidden3=hidden4=256\ndropout_prob2=.5\nclass MLPD2(torch.nn.Module):\n    def __init__(self,num_features,num_classes):\n        super(MLPD2,self).__init__()\n        self.linear1=torch.nn.Linear(num_features,hidden1)\n        self.linear1.weight.detach().normal_(0.,.1)\n        self.linear1.bias.detach().zero_()\n        self.linear2=torch.nn.Linear(hidden1,hidden2)\n        self.linear2.weight.detach().normal_(0.,.1)\n        self.linear2.bias.detach().zero_()\n        self.linear3=torch.nn.Linear(hidden2,hidden3)\n        self.linear3.weight.detach().normal_(0.,.1)\n        self.linear3.bias.detach().zero_()\n        self.linear4=torch.nn.Linear(hidden3,hidden4)\n        self.linear4.weight.detach().normal_(0.,.1)\n        self.linear4.bias.detach().zero_()\n        self.linear_out=torch.nn.Linear(hidden4,num_classes)\n        self.linear_out.weight.detach().normal_(0.,.1)\n        self.linear_out.bias.detach().zero_()        \n    def forward(self,x):\n        y=self.linear1(x); y=tnnf.relu(y)\n        y=self.linear2(y); y=tnnf.relu(y)\n        y=tnnf.dropout(y,p=dropout_prob2,\n                       training=self.training)\n        y=self.linear3(y); y=tnnf.relu(y)\n        y=self.linear4(y); y=tnnf.relu(y)\n        logits=self.linear_out(y)\n        probs=tnnf.log_softmax(logits,dim=1)\n        return logits,probs   \ntorch.manual_seed(random_seed)\nmodel=MLPD2(num_features=num_features2,\n            num_classes=num_classes2)\nmodel=model.to(dev); learning_rate=.005\noptimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"%train_run2 30","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%print_acc2 train\n%print_acc2 test","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}