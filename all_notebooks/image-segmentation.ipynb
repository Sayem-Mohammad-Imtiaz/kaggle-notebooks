{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom glob import glob\nfrom tqdm import tqdm\nimport cv2\nfrom skimage.transform import resize\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.backend\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Conv2D,Conv2DTranspose,BatchNormalization,Concatenate,ReLU,LeakyReLU,Add,Activation,Input,MaxPool2D\nfrom tensorflow.keras.layers import GlobalAveragePooling2D,AveragePooling2D,UpSampling2D","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '../input/semantic-segmentation-of-aerial-imagery/Semantic segmentation dataset'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_WIDTH = 224\nIMG_HEIGHT = 224\nIMG_CHANNELS = 3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ids = sorted(next(os.walk(path))[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = []\nmask=[]\nfor n,i in tqdm(enumerate(train_ids)):\n    a=os.listdir(path+'/'+i)\n    i_path=path+'/'+i+'/'+a[0]\n    m_path=path+'/'+i+'/'+a[1]\n    a=os.listdir(i_path)\n    b=os.listdir(m_path)\n    for j in a:\n        a=i_path+'/'+j\n        c=cv2.imread(i_path+'/'+j)\n        c=cv2.resize(c,(IMG_HEIGHT,IMG_WIDTH))\n        train.append(c)\n        b=a.replace(\"jpg\", \"png\")\n        b=b.replace('images','masks')\n        m=cv2.imread(b)\n        m=cv2.resize(m,(IMG_HEIGHT,IMG_WIDTH))\n        mask.append(m)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask = np.array(mask)\ntrain = np.array(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = tf.keras.layers.Input((224,224,3))\n\nc1 = tf.keras.layers.Conv2D(128,(3,3),activation='relu',padding='same')(inputs)\nc1 = BatchNormalization()(c1)\nc1 = tf.keras.layers.Conv2D(128,(3,3),activation='relu',padding='same')(c1)\nc1 = BatchNormalization()(c1)\np1 = tf.keras.layers.MaxPooling2D((2,2))(c1)\n\nc2 = tf.keras.layers.Conv2D(64,(3,3),activation='relu',padding='same')(p1)\nc2 = BatchNormalization()(c2)\nc2 = tf.keras.layers.Conv2D(64,(3,3),activation='relu',padding='same')(c2)\nc2 = BatchNormalization()(c2)\np2 = tf.keras.layers.MaxPooling2D((2,2))(c2)\n\nc3 = tf.keras.layers.Conv2D(128,(3,3),activation='relu',padding='same')(p2)\nc3 = BatchNormalization()(c3)\nc3 = tf.keras.layers.Conv2D(128,(3,3),activation='relu',padding='same')(c3)\nc3 = BatchNormalization()(c3)\np3 = tf.keras.layers.MaxPooling2D((2,2))(c3)\n\nc4 = tf.keras.layers.Conv2D(256,(3,3),activation='relu',padding='same')(p3)\nc4 = BatchNormalization()(c4)\nc4 = tf.keras.layers.Conv2D(256,(3,3),activation='relu',padding='same')(c4)\nc4 = BatchNormalization()(c4)\np4 = tf.keras.layers.MaxPooling2D((2,2))(c4)\n\n# c5 = tf.keras.layers.Conv2D(512,(3,3),activation='relu',padding='same')(p4)\n# c5 = BatchNormalization()(c5)\n# c5 = tf.keras.layers.Conv2D(512,(3,3),activation='relu',padding='same')(c5)\n# c5 = BatchNormalization()(c5)\n# p5 = tf.keras.layers.MaxPooling2D((2,2))(c5)\n\nc6 = tf.keras.layers.Conv2D(1024,(3,3),activation='relu',padding='same')(p4)\nc6 = BatchNormalization()(c6)\nc6 = tf.keras.layers.Conv2D(1024,(3,3),activation='relu',padding='same')(c6)\nc6 = BatchNormalization()(c6)\n\n# u7 = UpSampling2D((2, 2), interpolation=\"bilinear\")(c6)\n# c7 = Concatenate()([u7, c5])\n# c7 = tf.keras.layers.Conv2D(512,(3,3),activation='relu',padding='same')(c7)\n# c7 = BatchNormalization()(c7)\n# c7 = tf.keras.layers.Conv2D(512,(3,3),activation='relu',padding='same')(c7)\n# c7 = BatchNormalization()(c7)\n\nu8 = UpSampling2D((2, 2), interpolation=\"bilinear\")(c6)\nc8 = Concatenate()([u8, c4])\nc8 = tf.keras.layers.Conv2D(256,(3,3),activation='relu',padding='same')(c8)\nc8 = BatchNormalization()(c8)\nc8 = tf.keras.layers.Conv2D(256,(3,3),activation='relu',padding='same')(c8)\nc8 = BatchNormalization()(c8)\n\nu9 = UpSampling2D((2, 2), interpolation=\"bilinear\")(c8)\nc9 = Concatenate()([u9, c3])\nc9 = tf.keras.layers.Conv2D(128,(3,3),activation='relu',padding='same')(c9)\nc9 = BatchNormalization()(c9)\nc9 = tf.keras.layers.Conv2D(128,(3,3),activation='relu',padding='same')(c9)\nc9 = BatchNormalization()(c9)\n\nu10 = UpSampling2D((2, 2), interpolation=\"bilinear\")(c9)\nc10 = Concatenate()([u10, c2])\nc10 = tf.keras.layers.Conv2D(64,(3,3),activation='relu',padding='same')(c10)\nc10 = BatchNormalization()(c10)\nc10 = tf.keras.layers.Conv2D(64,(3,3),activation='relu',padding='same')(c10)\nc10 = BatchNormalization()(c10)\n\nu11 = UpSampling2D((2, 2), interpolation=\"bilinear\")(c10)\nc11 = Concatenate()([u11, c1])\nc11 = tf.keras.layers.Conv2D(128,(3,3),activation='relu',padding='same')(c11)\nc11 = BatchNormalization()(c11)\nc11 = tf.keras.layers.Conv2D(128,(3,3),activation='tanh',padding='same')(c11)\nc11 = BatchNormalization()(c11)\n\noutputs = Conv2D(3, 4, padding=\"same\", activation=\"softmax\")(c11)\nmodel = tf.keras.Model(inputs=[inputs],outputs=[outputs])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',loss='mean_squared_error',metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(train,mask, batch_size=5, epochs=100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_path='../input/semantic-segmentation-of-aerial-imagery/Semantic segmentation dataset/Tile 6/images/image_part_005.jpg'\ntest=cv2.imread(test_path)\ntest=cv2.resize(test,(224,224))\ntest1 = np.expand_dims(test,0)\ntt=model.predict(test1)\ntt=np.squeeze(tt)\n\nf, axarr = plt.subplots(1,1)\nplt.imshow(test)\nf, axarr = plt.subplots(1,1)\nplt.imshow(tt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}