{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Introduction to Statics."},{"metadata":{},"cell_type":"markdown","source":"Math and Statistics for Data Science are essential because these disciples form the basic foundation of all the Machine Learning Algorithms. In fact, Mathematics is behind everything around us, from shapes, patterns, and colors, to the count of petals in a flower. Mathematics is embedded in each and every aspect of our lives.\n\nSo, in this kernel we will try to cover and understand various math and Statistics topic which are required in Data Science. We will get brief discription of the topic and its implementation in Data Science using python. "},{"metadata":{},"cell_type":"markdown","source":"Here’s a list of topics I’ll be covering in this Math and Statistics for Data Science blog:\n\n* Introduction To Statistics\n* Terminologies In Statistics\n* Categories In Statistics\n* Descriptive Statistics In Python\n* Understanding Inferential Analysis\n\nThis topic we shall cover in another kernel.\n* Understanding Descriptive Analysis\n* Inferential Statistics In Python"},{"metadata":{},"cell_type":"markdown","source":"## Introduction To Statistics:\n   Statistics is process to work on any Data using math or descriptive way so that a meaningful \ntrend and information can be drawn from the given data. This process to draw information from \ndata can by done by applying mathematical operation.\n   Several Statistical functions, principles, and algorithms are implemented to analyze raw data, \nbuild a Statistical Model and infer or predict the result.\nThis topic cover all aspect of our day to daily life such as the Stock market, life sciences, weather, retail, insurance, and education are but to name a few.    "},{"metadata":{},"cell_type":"markdown","source":"## Terminologies in Statistics - Statistics for Data Science\n\nOne should be aware of a few key statistical terminologies while dealing with Statistics for Data Science. I’ve discussed these terminologies below:\n\n* The **population** is the set of sources from which data has to be collected.\n* A **Sample** is a subset of the Population\n* A **Variable** is any characteristics, number, or quantity that can be measured or counted. A variable may also be called a **data item**.\n* Also known as a **statistical model**, A statistical Parameter or population parameter is a quantity that indexes a family of probability distributions. For example, the mean, median, etc of a population.\nBefore we move any further and discuss the categories of Statistics, let’s look at the types of analysis.\n\nStatistics Analysis is also know as Quantitative Analysis. It is is the science of collecting and interpreting data with numbers and graphs to identify patterns and trends."},{"metadata":{},"cell_type":"markdown","source":"## Categories in Statistics\nThere are two main categories in Statistics, namely:\n\n* Descriptive Statistics\n* Inferential Statistics"},{"metadata":{},"cell_type":"markdown","source":"In This Kernel we will cover Inferencial Statics topics using Python on [Gapminder](https://www.kaggle.com/tklimonova/gapminder-datacamp-2007) Datasets. We will cover practical implementation of it using python.\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gapminder_filepath = \"../input/gapminder-datacamp-2007/gapminder_full.csv\"\ngapminder_data = pd.read_csv(gapminder_filepath)\ngapminder_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Intro Inferencial Statistics.\n\n    Inferential Statistics makes inferences and predictions about a population based on a sample of data taken from the population in question. \n    \nInferential statistics generalizes a large data set and applies probability to arrive at a conclusion. It allows you to infer parameters of the population based on sample stats and build models on it.\n\nSo, if want to know the alkaline level of water in particular region we will collect sample of water from various in Inferential Statistics, you will take a sample set of the class i.e water source. When the water are group into their category like lake, well pond, river, etc. In this method, you basically build a statistical model and expand it for the entire population in the water body.\n    "},{"metadata":{},"cell_type":"markdown","source":"## Understanding Inferential Analysis\n \n In inferential Analysis we use term as Hypothesis. If the current data satisfy the hypothesis condition then only the current data sample analysis hold true for entire data population. Statisticians use hypothesis testing to formally check whether the hypothesis is accepted or rejected. \n \n     Hypothesis testing is an Inferential Statistical technique used to determine whether there is enough evidence in a data sample to infer that a certain condition holds true for an entire population.\n     \nTo under the characteristics of a general population, we take a random sample and analyze the properties of the sample. We test whether or not the identified conclusion represents the population accurately and finally we interpret their results. Whether or not to accept the hypothesis depends upon the percentage value that we get from the hypothesis.\n\nA hypothesis is not simply a guess! It’s a statement of what you believe will happen based on the information you have gathered."},{"metadata":{},"cell_type":"markdown","source":"### Examples of If, Then Hypotheses\n\n* If you get at least 6 hours of sleep, you will do better on tests than if you get less sleep.\n* If you drop a ball, it will fall toward the ground.\n* If you drink coffee before going to bed, then it will take longer to fall asleep.\n* If you cover a wound with a bandage, then it will heal with less scarring.\n\nIn order for statisticians to come to a conclusion, they define what is known as a threshold value. Considering the above situation, if the threshold value is set to 5%, it would indicate that, if the probability of above experiment lies below 5%, then above experiment failed or we can say it is just statemnt with no Truth. But if the above experiment result probality are above the decided threshold value then the above all statement hold true for respective experiment.\n\nThe probability and hypothesis testing give rise to two important concepts, namely:\n\n**Null Hypothesis**: The result is no different from assumption.\n\n**Alternate Hypothesis**: Result disproves the assumption.\n\nTherefore, in our example, if the probability of an event occurring is less than 5%, then it is a biased event, hence it approves the alternate hypothesis."},{"metadata":{},"cell_type":"markdown","source":"## Inferential Statistics In Python:\n\nIn this demo, we’ll be using the gapminder data set to perform hypothesis testing. The gapminder data set contains a list of 142 countries, with their respective values for life expectancy, GDP per capita, and population, every five years, from 1952 to 2007."},{"metadata":{"trusted":true},"cell_type":"code","source":"gapminder_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped = gapminder_data.groupby('country')\n\ngroupd_1 = grouped['life_exp'].agg([np.sum, np.mean, np.std])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"groupd_2 = groupd_1[(groupd_1.index == 'South Africa') | (groupd_1.index == 'Ireland')] \n# groupd_1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## What is t-score?\n\nIt is one of the hypothesis test carried our between two group of same data sets. \nThe t score is a ratio between the difference between two groups and the difference within the groups. The larger the t score, the more difference there is between groups. The smaller the t score, the more similarity there is between groups. A t score of 3 means that the groups are three times as different from each other as they are within each other. When you run a t test, the bigger the t-value, the more likely it is that the results are repeatable.\n* A large t-score tells you that the groups are different.\n* A small t-score tells you that the groups are similar.\n\nFormula for t-test is as follows:\n\n$$t = \\frac{x1 - x2}{\\sqrt{s^2(^1/n1 + ^1/n2)}}$$\n\nwhere, n1 = n2 = degree of fredom of various data attributes,\n       s = standard deviation,\n       x1 = x2 = mean of two data attributes\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nsed = math.sqrt(groupd_1[groupd_1.index == 'South Africa']['std'][0]**2 + groupd_1[groupd_1.index == 'Ireland']['std'][0]**2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(groupd_1[groupd_1.index == 'South Africa']['mean'][0])\nprint(groupd_1[groupd_1.index == 'Ireland']['mean'][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t_test = abs(groupd_1[groupd_1.index == 'South Africa']['mean'][0] - groupd_1[groupd_1.index == 'Ireland']['mean'][0]) / sed","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number of degrees of freedom for the test is calculated as the sum of the observations in both samples, minus two."},{"metadata":{"trusted":true},"cell_type":"code","source":"# degree of freedom\nd_f = gapminder_data[gapminder_data['country'] == 'South Africa']['country'].count() + gapminder_data[gapminder_data['country'] == 'Ireland']['country'].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The critical value can be calculated using the percent point function (PPF) for a given significance level, such as 0.05 (95% confidence).\n\nThis function is available for the t distribution in SciPy, as follows:\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import t\n# calculated the critical value\nalpha = 0.05\ncv = t.ppf(1.0 - alpha, d_f)\ncv","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The p-value can be calculated using the cumulative distribution function on the t-distribution, again in SciPy."},{"metadata":{"trusted":true},"cell_type":"code","source":"p = (1 - t.cdf(abs(t_test), d_f)) * 2\np","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notice the mean in group Ireland and in South Africa, you can see that life expectancy almost differs by a scale of 20. Now we need to check if this difference in the value of life expectancy in South Africa and Ireland is actually valid and not just by pure chance. For this reason, the t-test is carried out.\n\nPay special attention to the p-value also known as the probability value. p-value is a very important measurement when it comes to ensuring the significance of a model. A model is said to be statistically significant only when the p-value is less than the pre-determined statistical significance level, which is ideally 0.05. As you can see from the output, the p value is 0.0077 which is an extremely small value.\n\nIn the summary of the model, notice another important parameter called the t-value. A larger t-value suggests that the alternate hypothesis is true and that the difference in life expectancy is not equal to zero by pure luck. Hence in our case, the null hypothesis is disapproved."},{"metadata":{},"cell_type":"markdown","source":"### Creating the function of finding T_test, degree of freedom, Critical Function."},{"metadata":{"trusted":true},"cell_type":"code","source":"def independent_ttest(mean_1, mean_2, std_1, std_2, alpha, df_1, df_2):\n # calculate means\n mean1, mean2 = mean_1, mean_2\n # calculate standard errors\n se1, se2 = std_1, std_2\n # standard error on the difference between the samples\n sed = math.sqrt(se1**2 + se2**2)\n # calculate the t statistic\n t_stat = (mean1 - mean2) / sed\n # degrees of freedom\n df = df_1 + df_2 - 2\n # calculate the critical value\n cv = t.ppf(1.0 - alpha, df)\n # calculate the p-value\n p = (1.0 - t.cdf(abs(t_stat), df)) * 2.0\n # return everything\n return abs(t_stat), df, cv, p","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha = 0.05\ncountry_1 = 'South Africa'\ncountry_2 = 'Ireland'\nmean_1 = groupd_1[groupd_1.index == country_1]['mean'][0]\nmean_2 = groupd_1[groupd_1.index == country_2]['mean'][0]\nstd_2 =  groupd_1[groupd_1.index == country_2]['std'][0]\nstd_1 = groupd_1[groupd_1.index == country_1]['std'][0]\ndf_1 = gapminder_data[gapminder_data['country'] == country_1]['country'].count()\ndf_2 = gapminder_data[gapminder_data['country'] == country_2]['country'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t_stat, df, cv, p = independent_ttest(mean_1, mean_2, std_1, std_2, alpha, df_1, df_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(t_stat)\nprint(df)\nprint(cv, p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gapminder_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### To conclude the demo, we’ll be plotting a graph for each continent, such that the graph shows how the life expectancy for each continent varies with the respective GDP per capita for that continent."},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\nsns.relplot(x=\"gdp_cap\", y=\"life_exp\", hue=\"country\", data=gapminder_data.iloc[0:500]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the above illustration, you can almost see a linear variance in the life expectancy for each continent with respect to the GDP per capita. This also shows how well the Python language can be used for Statistical Analysis.\n\nWith this, we come to the end of this kernel.\n\nThank you."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}