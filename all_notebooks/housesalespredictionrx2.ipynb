{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/housesalesprediction/kc_house_data.csv')\ndf['Current_Year'] = 2021\ndf['years_old'] = df['Current_Year'] - df['yr_built']\ndf.drop(['Current_Year'], axis = 1 , inplace = True)\ndf.drop(['yr_built'], axis = 1 , inplace = True)\ndf.drop(['id'], axis = 1 , inplace = True)\ndf.drop(['date'], axis = 1 , inplace = True)\n\ndf.shape\n# df.head()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To get a dataframe having only a particular value in a particular column \n# and the rest columns correspond to those values\n\n# Here the values are 0 and 1 ,and the column is waterfront\n\nx = df[df['waterfront'] == 1].index.tolist()\ny = df[df['waterfront'] == 0].index.tolist()\n# print(len(x))\n# print(len(y))\ndf.columns\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df1 is a DF having no rows in which bedrooms == 0\ndf1 = df[df['bedrooms'] != 0]\n\n# df2 is a DF having no rows in which bathrooms == 0\ndf2 = df1[df1['bathrooms'] != 0]\nprint(len(df2))\ndf2.shape\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fixing a possible typo \nprint(df2.loc[df2['bedrooms']== 33])\n15870","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fixed an anamoly having 33 bedrooms(considering it a typing error)\ndf2.at[15870,'bedrooms'] = 3\n# print(df2.loc[df2['price']== 640000])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(10,10))\ndf_corr = df2.drop(['lat','long','zipcode'], axis = 1)\ndf_corr = df_corr.corr()\nmask = np.triu(df_corr.corr())\nsns.heatmap(df_corr, annot=True, mask=mask, square=True, \n            fmt='.1g',  \n            vmin=-1, vmax=1, center= 0, cmap='coolwarm',\n            linewidths=3, linecolor='black',\n            cbar_kws= {'orientation': 'vertical'}) \n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The highest correlation between the target and the independent variables:\n\nsqft_living;\nsqft_above;\ngrade;\nsqft_living15.","metadata":{}},{"cell_type":"code","source":"z = df.loc[df['yr_renovated'] == 0]\nprint(z)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Most of the values in yr_renovated are 0s\nlist1 = []\nfor x in df2['yr_renovated']:\n    if x == 0:\n        list_.append(0)\n    else:\n        list_.append(1)\n        \ndf2['renovated'] = list1\ndf2.head()\n\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"z = df2.loc[df2['renovated'] == 0]\nprint(z)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.corr()\ndf2.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = plt.figure()\naxes1 = figure.add_axes([1.2, -3.9, 1, 1]) \nsns.regplot(x='lat', y='price', data=df2, color='royalblue', ax=axes1, scatter_kws={'s' : 10}, line_kws={'color': 'crimson', 'lw': 5})\naxes1.set_title('Price depending of latitude', fontsize=17)\naxes1.set_xlabel('lat', fontsize=14)\naxes1.set_ylabel('price', fontsize=14)\n\naxes2 = figure.add_axes([2.4, -3.9, 1, 1]) \nsns.regplot(x='long', y='price', data=df2, color='royalblue', ax=axes2, scatter_kws={'s' : 10}, line_kws={'color': 'crimson', 'lw': 5})\naxes2.set_title('Price depending of longitude', fontsize=17)\naxes2.set_xlabel('long', fontsize=14)\naxes2.set_ylabel('price', fontsize=14)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n\ncolumns = list(df2.columns)\nscaler = StandardScaler()\ndf_st = scaler.fit_transform(df2)\ndf_st = pd.DataFrame(data=df_st, columns=columns)\nprint(columns)\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf_st.drop(['lat'], axis = 1, inplace = True)\ndf_st.drop(['long'], axis = 1 , inplace = True)\ndf_st.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_st.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_st.mean(axis = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nx = df_st.drop(['price'], axis=1)\ny = df_st['price']\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\npoly = PolynomialFeatures(degree=2)\nx_train_poly = poly.fit_transform(x_train)\nx_test_poly = poly.fit_transform(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GridSearchCV\n\nparams1 = {}\nlinear = GridSearchCV(LinearRegression(),params1, cv = 5)\nlinear.fit(x_train, y_train)\ny_predict_linear = linear.predict(x_test)\nr_sq_linear = linear.score(x_test, y_test)\n\npoly = GridSearchCV(LinearRegression(), params1, cv = 5)\npoly.fit(x_train_poly, y_train)\ny_predict_poly = poly.predict(x_test_poly)\nr_sq_poly = poly.score(x_test_poly, y_test)\n\nparams2 = {'alpha':[0.001, 0.01, 0.1, 1, 10, 100]}\nridge = GridSearchCV(Ridge(), params2, cv=5)\nridge.fit(x_train_poly, y_train)\ny_predict_ridge = ridge.predict(x_test_poly)\nr_sq_ridge = ridge.score(x_test_poly, y_test)\n\nparams3 = {'alpha':[0.001, 0.01, 0.1, 1, 10, 100], 'l1_ratio':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\nelastic = GridSearchCV(ElasticNet(), params3, cv=5)\nelastic.fit(x_train_poly, y_train)\ny_predict_elastic = elastic.predict(x_test_poly)\nr_sq_elastic = elastic.score(x_test_poly, y_test)\n\n\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PowerTransformer\n\npipe = Pipeline((\n     ('pt',PowerTransformer()),\n     ('rf',RandomForestRegressor()),\n))\n\npipe.fit(x_train,y_train)\nrf_score=pipe.score(x_test,y_test)\nprint('Rf score :', rf_score)\n\n\n\nparams2 = {'alpha':[0.001, 0.01, 0.1, 1, 10, 100]}\nlasso = GridSearchCV(Lasso(), params2, cv=5)\nlasso.fit(x_train_poly, y_train)\ny_predict_lasso = lasso.predict(x_test_poly)\nr_sq_lasso = lasso.score(x_test_poly, y_test)\n\nmodels = ['RandomForest','Linear','Poly','Ridge','Lasso','Elastic']\nr_sq = [rf_score,r_sq_linear,r_sq_poly,r_sq_ridge,r_sq_lasso,r_sq_elastic]\nr_sq_table = pd.DataFrame({'Model' : models , 'r^2' : r_sq})\nr_sq_table.sort_values( by = 'r^2' , axis = 0 , ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}