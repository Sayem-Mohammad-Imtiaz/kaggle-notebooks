{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd,numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/googlestockpricing/Google.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(data.columns[2:],axis = 1)\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del data['High']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot\ndata.plot()\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport time\nimport math\nfrom matplotlib import pyplot\n\ntorch.manual_seed(0)\nnp.random.seed(0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_window = 100 # number of input steps\noutput_window = 1 # number of prediction steps\nbatch_size = 10 \ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n\n    def __init__(self, d_model, max_len=5000):\n        super(PositionalEncoding, self).__init__()       \n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0).transpose(0, 1)\n        #pe.requires_grad = False\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        return x + self.pe[:x.size(0), :]\n          ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TransAm(nn.Module):\n    def __init__(self,feature_size=250,num_layers=1,dropout=0.1):\n        super(TransAm, self).__init__()\n        self.model_type = 'Transformer'\n        \n        self.src_mask = None\n        self.pos_encoder = PositionalEncoding(feature_size)\n        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_size, nhead=10, dropout=dropout)\n        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)        \n        self.decoder = nn.Linear(feature_size,1)\n        self.init_weights()\n\n    def init_weights(self):\n        initrange = 0.1    \n        self.decoder.bias.data.zero_()\n        self.decoder.weight.data.uniform_(-initrange, initrange)\n\n    def forward(self,src):\n        if self.src_mask is None or self.src_mask.size(0) != len(src):\n            device = src.device\n            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n            self.src_mask = mask\n\n        src = self.pos_encoder(src)\n        output = self.transformer_encoder(src,self.src_mask)#, self.src_mask)\n        output = self.decoder(output)\n        return output\n    def _generate_square_subsequent_mask(self, sz):\n        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n        return mask\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_inout_sequences(input_data, tw):\n    inout_seq = []\n    L = len(input_data)\n    for i in range(L-tw):\n        train_seq = input_data[i:i+tw]\n        train_label = input_data[i+output_window:i+tw+output_window]\n        inout_seq.append((train_seq ,train_label))\n    return torch.FloatTensor(inout_seq)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_data(data):\n    # construct a littel toy dataset\n#     time        = np.arange(0, 400, 0.1)    \n#     amplitude   = np.sin(time) + np.sin(time*0.05) +np.sin(time*0.12) *np.random.normal(-0.2, 0.2, len(time))\n\n    \n    from sklearn.preprocessing import MinMaxScaler\n    \n    #loading weather data from a file\n    #from pandas import read_csv\n    #series = read_csv('daily-min-temperatures.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\n    \n    # looks like normalizing input values curtial for the model\n    scaler = MinMaxScaler(feature_range=(0, 1)) \n    amplitude = data.to_numpy()\n    amplitude = scaler.fit_transform(amplitude.reshape(-1, 1)).reshape(-1)\n    \n    \n    sampels = 2600\n    train_data = amplitude[:sampels]\n    test_data = amplitude[sampels:]\n\n    # convert our train data into a pytorch train tensor\n    #train_tensor = torch.FloatTensor(train_data).view(-1)\n    # todo: add comment.. \n    train_sequence = create_inout_sequences(train_data,input_window)\n    train_sequence = train_sequence[:-output_window] #todo: fix hack? -> din't think this trough, looks like the last n sequences are to short, so I just remove them. Hackety Hack.. \n\n    #test_data = torch.FloatTensor(test_data).view(-1) \n    test_data = create_inout_sequences(test_data,input_window)\n    test_data = train_sequence[:-output_window] #todo: fix hack?\n\n    return train_sequence.to(device),test_data.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_batch(source, i,batch_size):\n    seq_len = min(batch_size, len(source) - 1 - i)\n    data = source[i:i+seq_len]    \n    input = torch.stack(torch.stack([item[0] for item in data]).chunk(input_window,1)) # 1 is feature size\n    target = torch.stack(torch.stack([item[1] for item in data]).chunk(input_window,1))\n    return input, target\n\n\ndef train(train_data):\n    model.train() # Turn on the train mode \\o/\n    total_loss = 0.\n    start_time = time.time()\n\n    for batch, i in enumerate(range(0, len(train_data) - 1, batch_size)):\n        data, targets = get_batch(train_data, i,batch_size)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, targets)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.7)\n        optimizer.step()\n\n        total_loss += loss.item()\n        log_interval = int(len(train_data) / batch_size / 5)\n        if batch % log_interval == 0 and batch > 0:\n            cur_loss = total_loss / log_interval\n            elapsed = time.time() - start_time\n            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n                  'lr {:02.6f} | {:5.2f} ms | '\n                  'loss {:5.5f} | ppl {:8.2f}'.format(\n                    epoch, batch, len(train_data) // batch_size, scheduler.get_lr()[0],\n                    elapsed * 1000 / log_interval,\n                    cur_loss, math.exp(cur_loss)))\n            total_loss = 0\n            start_time = time.time()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_and_loss(eval_model, data_source,epoch):\n    eval_model.eval() \n    total_loss = 0.\n    test_result = torch.Tensor(0)    \n    truth = torch.Tensor(0)\n    with torch.no_grad():\n        for i in range(0, len(data_source) - 1):\n            data, target = get_batch(data_source, i,1)\n            output = eval_model(data)            \n            total_loss += criterion(output, target).item()\n            test_result = torch.cat((test_result, output[-1].view(-1).cpu()), 0)\n            truth = torch.cat((truth, target[-1].view(-1).cpu()), 0)\n            \n    #test_result = test_result.cpu().numpy() -> no need to detach stuff.. \n    len(test_result)\n\n    pyplot.plot(test_result,color=\"red\")\n    pyplot.plot(truth[:500],color=\"blue\")\n    pyplot.plot(test_result-truth,color=\"green\")\n    pyplot.grid(True, which='both')\n    pyplot.axhline(y=0, color='k')\n    pyplot.savefig('transformer-epoch%d.png'%epoch)\n    pyplot.close()\n    \n    return total_loss / i","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_future(eval_model, data_source,steps):\n    eval_model.eval() \n    total_loss = 0.\n    test_result = torch.Tensor(0)    \n    truth = torch.Tensor(0)\n    data, _ = get_batch(data_source, 0,1)\n    with torch.no_grad():\n        for i in range(0, steps):            \n            output = eval_model(data[-input_window:])                        \n            data = torch.cat((data, output[-1:]))\n            \n    data = data.cpu().view(-1)\n    \n    # I used this plot to visualize if the model pics up any long therm struccture within the data. \n    pyplot.plot(data,color=\"red\")       \n    pyplot.plot(data[:input_window],color=\"blue\")    \n    pyplot.grid(True, which='both')\n    pyplot.axhline(y=0, color='k')\n    pyplot.savefig('transformer-future%d.png'%steps)\n    pyplot.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(eval_model, data_source):\n    eval_model.eval() # Turn on the evaluation mode\n    total_loss = 0.\n    eval_batch_size = 1000\n    with torch.no_grad():\n        for i in range(0, len(data_source) - 1, eval_batch_size):\n            data, targets = get_batch(data_source, i,eval_batch_size)\n            output = eval_model(data)            \n            total_loss += len(data[0])* criterion(output, targets).cpu().item()\n    return total_loss / i","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data, val_data = get_data(data)\nmodel = TransAm().to(device)\n\ncriterion = nn.MSELoss()\nlr = 0.005 \n#optimizer = torch.optim.SGD(model.parameters(), lr=lr)\noptimizer = torch.optim.AdamW(model.parameters(), lr=lr)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n\nbest_val_loss = float(\"inf\")\nepochs = 10 # The number of epochs\nbest_model = None\n\nfor epoch in range(1, epochs + 1):\n    epoch_start_time = time.time()\n    train(train_data)\n    \n    if(epoch % 10 is 0):\n        val_loss = plot_and_loss(model, val_data,epoch)\n        predict_future(model, val_data,200)\n    else:\n        val_loss = evaluate(model, val_data)\n   \n    print('-' * 89)\n    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.5f} | valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n                                     val_loss, math.exp(val_loss)))\n    print('-' * 89)\n\n    #if val_loss < best_val_loss:\n    #    best_val_loss = val_loss\n    #    best_model = model\n\n    scheduler.step() \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls /kaggle/working","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = pyplot.imread('transformer-epoch10.png')\npyplot.imshow(img)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = pyplot.imread('transformer-future200.png')\npyplot.imshow(img)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}