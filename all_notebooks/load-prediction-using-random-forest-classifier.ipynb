{"cells":[{"metadata":{},"cell_type":"markdown","source":"### 1. Import Libraries "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Import Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/loan-prediction-problem-dataset/train_u6lujuX_CVtuZ9i.csv')\ndf_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv('../input/loan-prediction-problem-dataset/test_Y3wMUE5_7gLdaTN.csv')\ndf_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Check the information of the Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the result, we can see that there are several types of data. For prediction purpose, we wish to only use the **numerical** types of data, so we need to change the `object type` data into `numerical type`. Also, we can see that the number of data (rows) for each column is different. For `df_train` the rows for each column should have been 614 an for `df_test` is 367.\n\nThis following event indicates that there are **missing values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Knowing the statistical value of the data help us to know further to data transformation and analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"#print all of the data types and their unique values\nfor column in df_train.columns:\n  if df_train[column].dtype == object:\n    print(str(column) + ' : '+str(df_train[column].unique()))\n    print(df_train[column].value_counts())\n    print('_____________________________________________________________________')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see from the result above, IDs are different for each costumer. So, it's definitely not a predictor variable. You can drop it or just leave it as it is.\n\nAlso we can see for some columns there are `nan` or zero value. Let's check it out more"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get a count of the missing values for each column\ndf_train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are missing values in both dataset. For the train dataset, we should transform the **missing values** into some values, but for the test dataset I choose to drop **it** instead."},{"metadata":{},"cell_type":"markdown","source":"### 4. Handling Missing Values"},{"metadata":{},"cell_type":"markdown","source":"#### 4.1 Data Train"},{"metadata":{},"cell_type":"markdown","source":"* Missing Values of `Gender`, `Married`, `Self_Employed`\n    \n    using Mode"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Gender'] = df_train['Gender'].fillna(df_train['Gender'].mode())\ndf_train['Married'] = df_train['Married'].fillna(df_train['Married'].mode())\ndf_train['Self_Employed'] = df_train['Self_Employed'].fillna(df_train['Self_Employed'].mode())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Missing Values of `LoanAmount`\n\n    using Mean"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['LoanAmount'] = df_train['LoanAmount'].fillna(df_train['LoanAmount'].mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Missing Values of `Credit_History`\n    \n    using Median"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Credit_History'] = df_train['Credit_History'].fillna(df_train['Credit_History'].median())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Missing Values of `Dependents` and `Loan_Amount_Term`\n\n    Drop Missing Values\n   "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4.2 Data Test"},{"metadata":{},"cell_type":"markdown","source":"Drop Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4.3 Drop `Loan_ID`"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.drop('Loan_ID', inplace=True, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.drop('Loan_ID', inplace=True, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Check!**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5. Object type data mapping"},{"metadata":{},"cell_type":"markdown","source":"#### 5.1 Data Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.Gender = df_train.Gender.map({'Male':1, 'Female':0})\ndf_train.Married = df_train.Married.map({'Yes':1, 'No':0})\ndf_train.Education = df_train.Education.map({'Graduate':1, 'Not Graduate':0})\ndf_train.Self_Employed = df_train.Self_Employed.map({'Yes':1, 'No':0})\ndf_train.Dependents = df_train.Dependents.map({'0':0, '1':1, '2':2, '3+':3})\ndf_train.Property_Area = df_train.Property_Area.map({'Urban':1, 'Rural':0, 'Semiurban':2})\ndf_train.Loan_Status = df_train.Loan_Status.map({'Y':1, 'N':0})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.Gender = df_test.Gender.map({'Male':1, 'Female':0})\ndf_test.Married = df_test.Married.map({'Yes':1, 'No':0})\ndf_test.Education = df_test.Education.map({'Graduate':1, 'Not Graduate':0})\ndf_test.Self_Employed = df_test.Self_Employed.map({'Yes':1, 'No':0})\ndf_test.Dependents = df_test.Dependents.map({'0':0, '1':1, '2':2, '3+':3})\ndf_test.Property_Area = df_test.Property_Area.map({'Urban':1, 'Rural':0, 'Semiurban':2})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6. Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(2, 3, figsize=(20,10))\n\nfig.suptitle('Each Column Value Counts')\n\nsns.countplot(df_train['Gender'], hue = df_train['Loan_Status'], ax=axes[0, 0], palette='rainbow')\nsns.countplot(df_train['Married'], hue = df_train['Loan_Status'], ax=axes[0, 1], palette='rainbow')\nsns.countplot(df_train['Education'], hue = df_train['Loan_Status'], ax=axes[0, 2], palette='rainbow')\nsns.countplot(df_train['Self_Employed'], hue = df_train['Loan_Status'], ax=axes[1, 0], palette='rainbow')\nsns.countplot(df_train['Dependents'], hue = df_train['Loan_Status'], ax=axes[1, 1], palette='rainbow')\nsns.countplot(df_train['Property_Area'], hue = df_train['Loan_Status'], ax=axes[1, 2], palette='rainbow')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 7. Check Correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = df_train.corr()\ncorr.style.background_gradient(cmap='gist_earth_r').set_precision(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"from the result shown above,, we can see that `Credit_History` have a quite high positive correlation number (0.52). That means, our target (`Loan_Status`) is highly dependant with `Credit_History`"},{"metadata":{},"cell_type":"markdown","source":"### 8. Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 8.1 Train and Test Data Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_train.drop('Loan_Status', axis = 1)\ny = df_train['Loan_Status']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 8.2 Train and Validate Model using Random Forest Classifier\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"RF = RandomForestClassifier()\nRF.fit(X_train, y_train)\n\ny_predict = RF.predict(X_test)\n\n\n#Classification Report\nprint(classification_report(y_test, y_predict))\n\n# Accuracy score\nRF_score = accuracy_score(y_predict,y_test)\nprint(f\"Accurate {round(RF_score*100,2)}%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Loan_Status_Validation=pd.DataFrame({'y_test':y_test,'prediction':y_predict})\nLoan_Status_Validation","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 9. Make Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_predict = RF.predict(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Loan_Status_Prediction=pd.DataFrame({'y_test_predict':y_test_predict})\nLoan_Status_Prediction","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Done!**"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}