{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1><center>Over Sampling and its effects on Model Metrics</center></h1>","metadata":{"execution":{"iopub.status.busy":"2021-08-03T09:52:35.764623Z","iopub.execute_input":"2021-08-03T09:52:35.765053Z","iopub.status.idle":"2021-08-03T09:52:35.771532Z","shell.execute_reply.started":"2021-08-03T09:52:35.765015Z","shell.execute_reply":"2021-08-03T09:52:35.770157Z"}}},{"cell_type":"markdown","source":"We will try and explore the impact of sampling on Accuracy, Precision and Recall. \n\nWe will use 3 sampling techniques:\n* Over Sampling \n* Under Sampling\n* SMOTE(Synthetic Minority Over-sampling Technique)\n\nWe will see which one has the most impact on Metrics. We will also try and see when we need to use Sampling and if it really helps.\n\nHere, we are taking a simple dataset with 2 independent columns, no outliers and no null values.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-04T10:47:38.207755Z","iopub.execute_input":"2021-08-04T10:47:38.208129Z","iopub.status.idle":"2021-08-04T10:47:38.217152Z","shell.execute_reply.started":"2021-08-04T10:47:38.208082Z","shell.execute_reply":"2021-08-04T10:47:38.216053Z"}}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:48:04.695827Z","iopub.execute_input":"2021-08-06T02:48:04.696174Z","iopub.status.idle":"2021-08-06T02:48:04.700708Z","shell.execute_reply.started":"2021-08-06T02:48:04.696144Z","shell.execute_reply":"2021-08-06T02:48:04.699129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/social-network-ads/Social_Network_Ads.csv\")\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:48:04.715672Z","iopub.execute_input":"2021-08-06T02:48:04.717966Z","iopub.status.idle":"2021-08-06T02:48:04.733904Z","shell.execute_reply.started":"2021-08-06T02:48:04.71792Z","shell.execute_reply":"2021-08-06T02:48:04.733084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.Purchased.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:48:04.735279Z","iopub.execute_input":"2021-08-06T02:48:04.735869Z","iopub.status.idle":"2021-08-06T02:48:04.748029Z","shell.execute_reply.started":"2021-08-06T02:48:04.735824Z","shell.execute_reply":"2021-08-06T02:48:04.746846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:48:04.74996Z","iopub.execute_input":"2021-08-06T02:48:04.750418Z","iopub.status.idle":"2021-08-06T02:48:04.769635Z","shell.execute_reply.started":"2021-08-06T02:48:04.75037Z","shell.execute_reply":"2021-08-06T02:48:04.768553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's look at the importance of class imbalance","metadata":{}},{"cell_type":"code","source":"import seaborn as sns \nsns.distplot(data.EstimatedSalary)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:48:04.770854Z","iopub.execute_input":"2021-08-06T02:48:04.771129Z","iopub.status.idle":"2021-08-06T02:48:05.220119Z","shell.execute_reply.started":"2021-08-06T02:48:04.771101Z","shell.execute_reply":"2021-08-06T02:48:05.219141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(data.Age)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:48:05.221945Z","iopub.execute_input":"2021-08-06T02:48:05.222269Z","iopub.status.idle":"2021-08-06T02:48:05.423025Z","shell.execute_reply.started":"2021-08-06T02:48:05.222236Z","shell.execute_reply":"2021-08-06T02:48:05.421864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(data.EstimatedSalary)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:48:05.42643Z","iopub.execute_input":"2021-08-06T02:48:05.426805Z","iopub.status.idle":"2021-08-06T02:48:05.673133Z","shell.execute_reply.started":"2021-08-06T02:48:05.42677Z","shell.execute_reply":"2021-08-06T02:48:05.67197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX=data.drop(\"Purchased\",axis=1)\ny=data.Purchased\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=300)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:48:05.674719Z","iopub.execute_input":"2021-08-06T02:48:05.675086Z","iopub.status.idle":"2021-08-06T02:48:05.684974Z","shell.execute_reply.started":"2021-08-06T02:48:05.675052Z","shell.execute_reply":"2021-08-06T02:48:05.683979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samplingdf=pd.DataFrame(columns=[\"Model\",\"Sampling\",\"Accuracy\",\"Recall\",\"Precision\"])","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:48:05.686011Z","iopub.execute_input":"2021-08-06T02:48:05.686304Z","iopub.status.idle":"2021-08-06T02:48:05.70163Z","shell.execute_reply.started":"2021-08-06T02:48:05.686276Z","shell.execute_reply":"2021-08-06T02:48:05.700214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Model_pipeline(X_train,X_test,y_train,y_test,sampling,samplingdf):    \n    from sklearn.preprocessing import StandardScaler\n    scaler = StandardScaler()\n    X_trainstand=scaler.fit(X_train).transform(X_train)\n    X_teststand=scaler.transform(X_test)\n    #classification Metrics\n    def metrics(clf,model,sampling,samplingdf):\n        print(\"Model Type:\",model,sampling)\n        from sklearn.metrics import accuracy_score\n        from sklearn.metrics import recall_score\n        from sklearn.metrics import precision_score\n        y_pred_test = clf.predict(X_teststand)\n        print(\"Accuracy for Test set:\")\n        print(accuracy_score(y_test,y_pred_test)) \n        print(\"\\n\")\n        print(\"Recall for Test set:\")\n        print(recall_score(y_test,y_pred_test,pos_label=1))\n        print(\"\\n\")\n        print(\"Precision for Test set:\")\n        print(precision_score(y_test,y_pred_test,pos_label=1))\n        print(\"\\n\")\n        print(\"------------------------------------------------------------------------------\")\n        input1=pd.Series([model,sampling,accuracy_score(y_test,y_pred_test),\n                recall_score(y_test,y_pred_test,pos_label=1),precision_score(y_test,y_pred_test,pos_label=1)], index = samplingdf. columns)\n        samplingdf=samplingdf.append(input1,ignore_index=True)\n        return samplingdf\n    \n    from sklearn.linear_model import LogisticRegression\n    clf = LogisticRegression(random_state=0).fit(X_trainstand, y_train)\n    samplingdf=metrics(clf,\"Logistic Regression\",sampling,samplingdf)\n    \n    from sklearn.tree import DecisionTreeClassifier\n    clf = DecisionTreeClassifier(random_state=0).fit(X_trainstand,y_train)\n    samplingdf=metrics(clf,\"Decision Tree\",sampling,samplingdf)\n    \n    #GBM\n    from sklearn.ensemble import GradientBoostingClassifier\n    clf=GradientBoostingClassifier(random_state=0).fit(X_trainstand,y_train)\n    samplingdf=metrics(clf,\"Gradient Booster\",sampling,samplingdf)\n    \n    #RandomForest\n    from sklearn.ensemble import RandomForestClassifier\n    clf = RandomForestClassifier(random_state=0)\n    clf.fit(X_trainstand, y_train)\n    samplingdf=metrics(clf,\"Random Forest\",sampling,samplingdf)\n    \n    #XGBoost\n    from xgboost import XGBClassifier\n    XGB_model = XGBClassifier(learning_rate=0.05)\n    XGB_model.fit(X_trainstand, y_train)\n    samplingdf=metrics(clf,\"XGBoost\",sampling,samplingdf)\n    \n    #SVM\n    from sklearn.svm import SVC\n    clf = SVC(random_state=0)\n    clf.fit(X_trainstand, y_train)\n    samplingdf=metrics(clf,\"SVM normal\",sampling,samplingdf)\n    \n    #kernal SVM\n    from sklearn.svm import SVC\n    clf = SVC(kernel=\"rbf\")\n    clf.fit(X_trainstand, y_train)\n    samplingdf=metrics(clf,\"SVM Kernal\",sampling,samplingdf)\n    \n    return samplingdf","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:48:05.704412Z","iopub.execute_input":"2021-08-06T02:48:05.704798Z","iopub.status.idle":"2021-08-06T02:48:05.722147Z","shell.execute_reply.started":"2021-08-06T02:48:05.704747Z","shell.execute_reply":"2021-08-06T02:48:05.721164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samplingdf=Model_pipeline(X_train,X_test,y_train,y_test,\"No sampling\",samplingdf)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:48:05.723635Z","iopub.execute_input":"2021-08-06T02:48:05.723923Z","iopub.status.idle":"2021-08-06T02:48:06.293894Z","shell.execute_reply.started":"2021-08-06T02:48:05.723895Z","shell.execute_reply":"2021-08-06T02:48:06.292716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samplingdf","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:48:06.29564Z","iopub.execute_input":"2021-08-06T02:48:06.296077Z","iopub.status.idle":"2021-08-06T02:48:06.311092Z","shell.execute_reply.started":"2021-08-06T02:48:06.296029Z","shell.execute_reply":"2021-08-06T02:48:06.309904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Over Sampling","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import RandomOverSampler\nros = RandomOverSampler(random_state=0)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=300)\nX_train, y_train = ros.fit_resample(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:48:06.313088Z","iopub.execute_input":"2021-08-06T02:48:06.313603Z","iopub.status.idle":"2021-08-06T02:48:06.330428Z","shell.execute_reply.started":"2021-08-06T02:48:06.313555Z","shell.execute_reply":"2021-08-06T02:48:06.329395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samplingdf=Model_pipeline(X_train,X_test,y_train,y_test,\"Over sampling\",samplingdf)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:48:06.332279Z","iopub.execute_input":"2021-08-06T02:48:06.332695Z","iopub.status.idle":"2021-08-06T02:48:06.79618Z","shell.execute_reply.started":"2021-08-06T02:48:06.332652Z","shell.execute_reply":"2021-08-06T02:48:06.794925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Under sampling","metadata":{}},{"cell_type":"code","source":"from imblearn.under_sampling import ClusterCentroids\ncc = ClusterCentroids(random_state=0)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=300)\nX_train, y_train = cc.fit_resample(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:48:06.797828Z","iopub.execute_input":"2021-08-06T02:48:06.798291Z","iopub.status.idle":"2021-08-06T02:48:07.593245Z","shell.execute_reply.started":"2021-08-06T02:48:06.798244Z","shell.execute_reply":"2021-08-06T02:48:07.59208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samplingdf=Model_pipeline(X_train,X_test,y_train,y_test,\"Under sampling\",samplingdf)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:48:07.594704Z","iopub.execute_input":"2021-08-06T02:48:07.595294Z","iopub.status.idle":"2021-08-06T02:48:08.084113Z","shell.execute_reply.started":"2021-08-06T02:48:07.595249Z","shell.execute_reply":"2021-08-06T02:48:08.083395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SMOTE","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE \nsm = SMOTE(random_state=42)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=300)\nX_train, y_train = sm.fit_resample(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:48:08.085359Z","iopub.execute_input":"2021-08-06T02:48:08.085822Z","iopub.status.idle":"2021-08-06T02:48:08.100696Z","shell.execute_reply.started":"2021-08-06T02:48:08.085788Z","shell.execute_reply":"2021-08-06T02:48:08.099585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samplingdf=Model_pipeline(X_train,X_test,y_train,y_test,\"SMOTE\",samplingdf)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:48:08.102347Z","iopub.execute_input":"2021-08-06T02:48:08.102667Z","iopub.status.idle":"2021-08-06T02:48:08.597614Z","shell.execute_reply.started":"2021-08-06T02:48:08.102635Z","shell.execute_reply":"2021-08-06T02:48:08.596536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samplingdf","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:48:08.599116Z","iopub.execute_input":"2021-08-06T02:48:08.599438Z","iopub.status.idle":"2021-08-06T02:48:08.621529Z","shell.execute_reply.started":"2021-08-06T02:48:08.599405Z","shell.execute_reply":"2021-08-06T02:48:08.62058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samplingdf.sort_values(by=[\"Model\",\"Sampling\"])","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:48:08.622954Z","iopub.execute_input":"2021-08-06T02:48:08.623382Z","iopub.status.idle":"2021-08-06T02:48:08.649784Z","shell.execute_reply.started":"2021-08-06T02:48:08.623337Z","shell.execute_reply":"2021-08-06T02:48:08.648753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analysing the Results","metadata":{}},{"cell_type":"code","source":"samplingdf.groupby(\"Sampling\").mean()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:48:08.651102Z","iopub.execute_input":"2021-08-06T02:48:08.65144Z","iopub.status.idle":"2021-08-06T02:48:08.669878Z","shell.execute_reply.started":"2021-08-06T02:48:08.651406Z","shell.execute_reply":"2021-08-06T02:48:08.668823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns \n\nprint(sns.barplot(data=samplingdf.groupby(\"Sampling\").median().reset_index(),x=\"Sampling\",y=\"Accuracy\"))\n","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:48:08.673035Z","iopub.execute_input":"2021-08-06T02:48:08.67336Z","iopub.status.idle":"2021-08-06T02:48:08.840341Z","shell.execute_reply.started":"2021-08-06T02:48:08.673327Z","shell.execute_reply":"2021-08-06T02:48:08.839197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sns.barplot(data=samplingdf.groupby(\"Sampling\").median().reset_index(),x=\"Sampling\",y=\"Recall\"))","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:48:08.841879Z","iopub.execute_input":"2021-08-06T02:48:08.842186Z","iopub.status.idle":"2021-08-06T02:48:09.004279Z","shell.execute_reply.started":"2021-08-06T02:48:08.842155Z","shell.execute_reply":"2021-08-06T02:48:09.003115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sns.barplot(data=samplingdf.groupby(\"Sampling\").median().reset_index(),x=\"Sampling\",y=\"Precision\"))","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:48:09.005564Z","iopub.execute_input":"2021-08-06T02:48:09.005856Z","iopub.status.idle":"2021-08-06T02:48:09.18882Z","shell.execute_reply.started":"2021-08-06T02:48:09.005827Z","shell.execute_reply":"2021-08-06T02:48:09.187687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Considering the aggregate of all models, we can see that sampling does not have much of an effect on accuracy,with a barely 1% difference.\n\nHowever especially over sampling and SMOTE increase the recall considerably with over a 6% increase with SMOTE.\n\nBut we have to keep in mind that precision is effected significantly as we upscale with a reduction of more than 3-4%, this might not be important, for example a cancer prediction will depend on recall. however its important in applications such as youtube recommendations,etc. ","metadata":{}},{"cell_type":"markdown","source":"## Let's look at how it affects weak models","metadata":{}},{"cell_type":"code","source":"samplingdf[samplingdf.Model==\"Logistic Regression\"]","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:49:08.871941Z","iopub.execute_input":"2021-08-06T02:49:08.872325Z","iopub.status.idle":"2021-08-06T02:49:08.890236Z","shell.execute_reply.started":"2021-08-06T02:49:08.872279Z","shell.execute_reply":"2021-08-06T02:49:08.889056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(data=samplingdf[samplingdf.Model==\"Logistic Regression\"],x=\"Sampling\",y=\"Accuracy\")","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:49:09.673419Z","iopub.execute_input":"2021-08-06T02:49:09.673911Z","iopub.status.idle":"2021-08-06T02:49:09.819646Z","shell.execute_reply.started":"2021-08-06T02:49:09.673878Z","shell.execute_reply":"2021-08-06T02:49:09.818902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There doesn't seem to be much affect on accuracy with a 1%-2% increase due to oversampling, I would not consider this significant.","metadata":{}},{"cell_type":"code","source":"sns.barplot(data=samplingdf[samplingdf.Model==\"Logistic Regression\"],x=\"Sampling\",y=\"Recall\")","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:48:09.366836Z","iopub.execute_input":"2021-08-06T02:48:09.367247Z","iopub.status.idle":"2021-08-06T02:48:09.524082Z","shell.execute_reply.started":"2021-08-06T02:48:09.367202Z","shell.execute_reply":"2021-08-06T02:48:09.523351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Recall has increased immensly due to sampling with fair 40-45% increase, any sampling definately increases Recall. Over sampling and Under sampling seem to be giving the same recall ","metadata":{}},{"cell_type":"code","source":"sns.barplot(data=samplingdf[samplingdf.Model==\"Logistic Regression\"],x=\"Sampling\",y=\"Precision\")","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:48:09.525303Z","iopub.execute_input":"2021-08-06T02:48:09.525735Z","iopub.status.idle":"2021-08-06T02:48:09.703158Z","shell.execute_reply.started":"2021-08-06T02:48:09.525676Z","shell.execute_reply":"2021-08-06T02:48:09.702127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Precision has taken a hit with 10-12% decrease due to sampling.","metadata":{}},{"cell_type":"markdown","source":"## How about Strong Models?","metadata":{}},{"cell_type":"code","source":"samplingdf[samplingdf.Model==\"XGBoost\"]","metadata":{"execution":{"iopub.status.busy":"2021-08-06T03:00:48.186165Z","iopub.execute_input":"2021-08-06T03:00:48.186533Z","iopub.status.idle":"2021-08-06T03:00:48.200821Z","shell.execute_reply.started":"2021-08-06T03:00:48.1865Z","shell.execute_reply":"2021-08-06T03:00:48.199656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(data=samplingdf[samplingdf.Model==\"XGBoost\"],x=\"Sampling\",y=\"Accuracy\")","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:58:44.055904Z","iopub.execute_input":"2021-08-06T02:58:44.056258Z","iopub.status.idle":"2021-08-06T02:58:44.209409Z","shell.execute_reply.started":"2021-08-06T02:58:44.056227Z","shell.execute_reply":"2021-08-06T02:58:44.208587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(data=samplingdf[samplingdf.Model==\"XGBoost\"],x=\"Sampling\",y=\"Recall\")","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:59:04.968737Z","iopub.execute_input":"2021-08-06T02:59:04.969093Z","iopub.status.idle":"2021-08-06T02:59:05.12937Z","shell.execute_reply.started":"2021-08-06T02:59:04.969063Z","shell.execute_reply":"2021-08-06T02:59:05.128537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(data=samplingdf[samplingdf.Model==\"XGBoost\"],x=\"Sampling\",y=\"Precision\")","metadata":{"execution":{"iopub.status.busy":"2021-08-06T02:59:15.823055Z","iopub.execute_input":"2021-08-06T02:59:15.823555Z","iopub.status.idle":"2021-08-06T02:59:15.998991Z","shell.execute_reply.started":"2021-08-06T02:59:15.823522Z","shell.execute_reply":"2021-08-06T02:59:15.998263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above charts we see that for strong models:\n* Accuracy increases but barely and only when using SMOTE\n* Recall increases significantly,especially when using SMOTE\n* Precision decreases especially when under sampling, but the decrease is insignificant when using SMOTE","metadata":{}},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"markdown","source":"### From all the above I have come to a conclusion that sampling is extremely effective in increasing Recall, which is the popular metric among others. However, when precision is involved, the safest bet is not indulge in any Sampling. \n\n### I believe that the best sampling to use in any circumstance is SMOTE since its has the highest increase in recall in most cases and lowest decrease in precision.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}