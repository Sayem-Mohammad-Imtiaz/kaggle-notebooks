{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Hyderabad\nIf you are Indian or have stayed in India for sometime, probably you have heard about Hyderabadi Biryani, its one of hallmark dishes of country and city. We will use Zomato reviews from Hyderabad locality to see how the food market is doing in Nizam City.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Reading the files","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nhyd_rest=pd.read_csv('../input/zomato-restaurants-hyderabad/Restaurant names and Metadata.csv')\nhyd_rev=pd.read_csv('../input/zomato-restaurants-hyderabad/Restaurant reviews.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing the NLTK, Scikit libraries and features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer \nfrom nltk.stem import PorterStemmer, LancasterStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom textblob import TextBlob\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom IPython.display import Image\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA\nThe notebook will use bokeh and plotly to see ratings, reviews and cost relationships , will use NLTK,gensim, to convert text to vectors to find relatinonships between text. We will also see wordclouds ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## The Ratings distribution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"hyd_rev['Rating'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"38% reviews are 5 rated,23% are 4 rated stating that people do rate good food high.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### creating new variable review length to see if length of review impacts the ratings\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"hyd_rev['Review']=hyd_rev['Review'].astype(str)\nhyd_rev['Review_length'] = hyd_rev['Review'].apply(len)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Bokeh scatter plot for review length vs rating","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\nfig = px.scatter(hyd_rev, x=hyd_rev['Rating'], y=hyd_rev['Review_length'])\nfig.update_layout(title_text=\"Rating vs Review Length\")\nfig.update_xaxes(ticks=\"outside\", tickwidth=1, tickcolor='crimson',tickangle=45, ticklen=10)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The scatter plot confirms that length of review doesnt impact ratings","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Creating polarity variable to see sentiments in reviews(using textblob)\n\nPloarity analyzes the text ranges and search for words that express sentiments such as good or bad assignes a score to text in following manner: emotional negative (-2), rational negative (-1), neutral (0), rational positive (+1), and emotional positive (+2). In practice, neutral often means no opinion or sentiment expressed.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"hyd_rev['Polarity'] = hyd_rev['Review'].apply(lambda x: TextBlob(x).sentiment.polarity)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hyd_rev['Polarity'].plot(kind='hist', bins=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The graph shows us the majority of reviews are nuetral 0,probably sugesting mixture of bad and good words in reviews, also the number of positive reviews >0 are higher than negative reviews, more than 200 odd reviews have very high positive sentiments","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# wordclouds for all reviews, positive reviews and negative reviews\n\nI will create two datasets equal and above 3 rating for positive reviews and below 3 for negative reviews. Apart from stopwords i have removing common words used in restuarant business\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"stop_words = stopwords.words('english')\nprint(stop_words)\nrest_word=['order','restaurant','taste','ordered','good','food','table','place','one','also']\nrest_word","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nhyd_rev['Review']=hyd_rev['Review'].map(lambda x: re.sub('[,\\.!?]','', x))\nhyd_rev['Review']=hyd_rev['Review'].map(lambda x: x.lower())\nhyd_rev['Review']=hyd_rev['Review'].map(lambda x: x.split())\nhyd_rev['Review']=hyd_rev['Review'].apply(lambda x: [item for item in x if item not in stop_words])\nhyd_rev['Review']=hyd_rev['Review'].apply(lambda x: [item for item in x if item not in rest_word])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\nhyd_rev['Review']=hyd_rev['Review'].astype(str)\n\nps = PorterStemmer() \nhyd_rev['Review']=hyd_rev['Review'].map(lambda x: ps.stem(x))\nlong_string = ','.join(list(hyd_rev['Review'].values))\nlong_string\nwordcloud = WordCloud(background_color=\"white\", max_words=100, contour_width=3, contour_color='steelblue')\nwordcloud.generate(long_string)\nwordcloud.to_image()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ambience is key factor in food business, time, and variety in food is the key like starters , main course","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Creating two datasets for positive and negative reviews","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nhyd_rev['Rating']=pd.to_numeric(hyd_rev['Rating'],errors='coerce')\npos_rev = hyd_rev[hyd_rev.Rating>= 3]\nneg_rev = hyd_rev[hyd_rev.Rating< 3]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Positive reviews wordcloud","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"long_string = ','.join(list(pos_rev['Review'].values))\nlong_string\nwordcloud = WordCloud(background_color=\"white\", max_words=100, contour_width=3, contour_color='steelblue')\nwordcloud.generate(long_string)\nwordcloud.to_image()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Service,taste,time,starters are key to good review","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Negative reviews wordcloud","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"long_string = ','.join(list(neg_rev['Review'].values))\nlong_string\nwordcloud = WordCloud(background_color=\"white\", max_words=100, contour_width=3, contour_color='steelblue')\nwordcloud.generate(long_string)\nwordcloud.to_image()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Service , bad chicken , staff behavior, stale food are key reasons for neagtive reviews","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Creating word embeddings and t-SNE plot( for positive and negative reviews)\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Tsne works by taking a group of high-dimensional (100 dimensions via Word2Vec) vocabulary word feature vectors, then compresses them down to 2-dimensional x,y coordinate pairs. The idea is to keep similar words close together on the plane, while maximizing the distance between dissimilar words.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from gensim.models import word2vec\npos_rev = hyd_rev[hyd_rev.Rating>= 3]\nneg_rev = hyd_rev[hyd_rev.Rating< 3]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## plot for negative reviews","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_corpus(data):\n    \"Creates a list of lists containing words from each sentence\"\n    corpus = []\n    for col in ['Review']:\n        for sentence in data[col].iteritems():\n            word_list = sentence[1].split(\" \")\n            corpus.append(word_list)\n            \n    return corpus\n\ncorpus = build_corpus(neg_rev)        \ncorpus[0:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = word2vec.Word2Vec(corpus, size=100, window=20, min_count=200, workers=4)\nmodel\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tsne_plot(model):\n    \"Creates and TSNE model and plots it\"\n    labels = []\n    tokens = []\n\n    for word in model.wv.vocab:\n        tokens.append(model[word])\n        labels.append(word)\n    \n    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n    new_values = tsne_model.fit_transform(tokens)\n\n    x = []\n    y = []\n    for value in new_values:\n        x.append(value[0])\n        y.append(value[1])\n        \n    plt.figure(figsize=(16, 16)) \n    for i in range(len(x)):\n        plt.scatter(x[i],y[i])\n        plt.annotate(labels[i],\n                     xy=(x[i], y[i]),\n                     xytext=(5, 2),\n                     textcoords='offset points',\n                     ha='right',\n                     va='bottom')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tsne_plot(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The words close together for negative reviews : service,staff,time suggest these are key factors in negative reviews","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## plot for postive reviews","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_corpus(data):\n    \"Creates a list of lists containing words from each sentence\"\n    corpus = []\n    for col in ['Review']:\n        for sentence in data[col].iteritems():\n            word_list = sentence[1].split(\" \")\n            corpus.append(word_list)\n            \n    return corpus\n\ncorpus = build_corpus(pos_rev)        \ncorpus[0:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = word2vec.Word2Vec(corpus, size=100, window=20, min_count=200, workers=4)\nmodel\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tsne_plot(model):\n    \"Creates and TSNE model and plots it\"\n    labels = []\n    tokens = []\n\n    for word in model.wv.vocab:\n        tokens.append(model[word])\n        labels.append(word)\n    \n    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n    new_values = tsne_model.fit_transform(tokens)\n\n    x = []\n    y = []\n    for value in new_values:\n        x.append(value[0])\n        y.append(value[1])\n        \n    plt.figure(figsize=(16, 16)) \n    for i in range(len(x)):\n        plt.scatter(x[i],y[i])\n        plt.annotate(labels[i],\n                     xy=(x[i], y[i]),\n                     xytext=(5, 2),\n                     textcoords='offset points',\n                     ha='right',\n                     va='bottom')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tsne_plot(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we have lot many frequent occurences: Chicken items like biryani kebab , cheese , burger pizza , variety service staff music ambience are key too good reviews","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# POS tagging of negative rated reviews\n\nPOS tagging tags the text to grammar like if its is noun, pronoun, verb ,adjective etc are present in texts:\n\nThe complete lits of POS tags are in this website:\n\nhttps://pythonprogramming.net/part-of-speech-tagging-nltk-tutorial/","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.tag import pos_tag\nfrom nltk import pos_tag_sents","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating a loop that counts pos tags increments tag count of tags, then we plot the number pos tags frequency","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"neg_texts = neg_rev['Review'].str.split().map(pos_tag)\nneg_texts.head()\ndef count_tags(title_with_tags):\n    tag_count = {}\n    for word, tag in title_with_tags:\n        if tag in tag_count:\n            tag_count[tag] += 1\n        else:\n            tag_count[tag] = 1\n    return(tag_count)\nneg_texts.map(count_tags).head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neg_texts = pd.DataFrame(neg_texts)\nneg_texts['tag_counts'] = neg_texts['Review'].map(count_tags)\nneg_texts.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tag_set = list(set([tag for tags in neg_texts['tag_counts'] for tag in tags]))\nfor tag in tag_set:\n    neg_texts[tag] = neg_texts['tag_counts'].map(lambda x: x.get(tag, 0))\ntitle = 'Frequency of POS Tags in Negative Reviews'    \nneg_texts[tag_set].sum().sort_values().plot(kind='barh', logx=True, figsize=(12,8), title=title)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Topic Modeling using LDA\nWe will plot top 10 most occuring words. Topic modeling is  a process to automatically identify topics present in a text object and to assign text corpus to one category of topic.\n \nLDA is one of the methods to assign topic to texts. If observations are words collected into documents, it posits that each document is a mixture of a small number of topics and that each word's presence is attributable to one of the document's topics.\n\nSource: https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport seaborn as sns\ndef plot_10_most_common_words(count_data, count_vectorizer):\n    import matplotlib.pyplot as plt\n    words = count_vectorizer.get_feature_names()\n    total_counts = np.zeros(len(words))\n    for t in count_data:\n        total_counts+=t.toarray()[0]\n        count_dict = (zip(words, total_counts))\n    count_dict = sorted(count_dict, key=lambda x:x[1], reverse=True)[0:10]\n    words = [w[0] for w in count_dict]\n    counts = [w[1] for w in count_dict]\n    x_pos = np.arange(len(words)) \n    \n    plt.figure(2, figsize=(15, 15/1.6180))\n    plt.subplot(title='10 most common words in Negative reviews')\n    sns.set_context(\"notebook\", font_scale=1.25, rc={\"lines.linewidth\": 2.5})\n    sns.barplot(x_pos, counts, palette='husl')\n    plt.xticks(x_pos, words, rotation=90) \n    plt.xlabel('words')\n    plt.ylabel('counts')\n    plt.show()\ntext2=neg_rev['Review'].values\ncount_vectorizer = CountVectorizer(stop_words='english')\n\ncount_data = count_vectorizer.fit_transform(text2)\nplot_10_most_common_words(count_data, count_vectorizer)\n\n\nimport warnings\nwarnings.simplefilter(\"ignore\", DeprecationWarning)\n# Load the LDA model from sk-learn\nfrom sklearn.decomposition import LatentDirichletAllocation as LDA\n \n# Helper function\ndef print_topics(model, count_vectorizer, n_top_words):\n    words = count_vectorizer.get_feature_names()\n    for topic_idx, topic in enumerate(model.components_):\n        print(\"\\nTopic #%d:\" % topic_idx)\n        print(\" \".join([words[i]\n                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n        \n# Tweak the two parameters below\nnumber_topics = 10\nnumber_words = 10\n# Create and fit the LDA model\nlda = LDA(n_components=number_topics, n_jobs=-1)\nlda.fit(count_data)\n# Print the topics found by the LDA model\nprint(\"10 Topics found via LDA for negative reviews:\")\nprint_topics(lda, count_vectorizer, number_words)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Named Entity Recoginition in negative reviews\n\nNamed-entity recognition (NER) (also known as entity identification, entity chunking and entity extraction) is a subtask of information extraction that seeks to locate and classify named entities mentioned in unstructured text into pre-defined categories such as person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, etc.\n\nSource: https://en.wikipedia.org/wiki/Named-entity_recognition\n\nI will try to find negative reviews wherever they have date mentioned in specifically in the review","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import spacy\nfrom spacy import displacy\nfrom collections import Counter\nimport en_core_web_sm\nnlp = en_core_web_sm.load()\ndef extract_named_ents(text):    \n    return [ ent.label_ for ent in nlp(text).ents]  \nneg_rev['named_ents'] = neg_rev['Review'].apply(extract_named_ents)   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_ents=neg_rev[['named_ents','Review','Restaurant','Rating']]\ntext_ents['named_ents_new']=[','.join(map(str, l)) for l in text_ents['named_ents']]\ntext_ents","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATE_PROBLEM=text_ents['named_ents_new'] == 'DATE'\ntext_ents[DATE_PROBLEM]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Merging two datasets and Finding North Indian, Chinese and South Indian food options and ratings","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_rating=hyd_rev.groupby('Restaurant',as_index=False)['Rating'].mean()\nmerged=hyd_rest.merge(avg_rating, how='inner',left_on='Name',right_on='Restaurant')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged[\"North_indian\"]= merged[\"Cuisines\"].str.find(\"North Indian\")  \nmerged[\"Chinese\"]=merged[\"Cuisines\"].str.find(\"Chinese\")\nmerged[\"South_Indian\"]=merged[\"Cuisines\"].str.find(\"South Indian\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged.loc[merged['North_indian'] == -1, 'North_Indian_menu'] = 0\nmerged.loc[merged['North_indian'] > -1, 'North_Indian_menu'] = 1\nmerged.loc[merged['Chinese'] == -1, 'Chinese_menu'] = 0\nmerged.loc[merged['Chinese'] > -1, 'Chinese_menu'] = 1\nmerged.loc[merged['South_Indian'] == -1, 'South_Indian_menu'] = 0\nmerged.loc[merged['South_Indian'] > -1, 'South_Indian_menu'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"North=merged[merged['North_Indian_menu'] == 1]\nmean_rating_N=North.groupby(['Name','Cost'],as_index=False).Rating.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\nfig = px.bar(mean_rating_N, x=\"Name\", y=\"Cost\",color=\"Rating\")\nfig.update_xaxes(ticks=\"outside\", tickwidth=1, tickcolor='crimson',tickangle=45, ticklen=10)\nfig.update_layout(title_text=\"North Indian restaurant cost vs rating\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"South=merged[merged['South_Indian_menu'] == 1]\n\nmean_rating_S=South.groupby(['Name','Cost'],as_index=False).Rating.mean()\nfig = px.bar(mean_rating_S, x=\"Name\", y=\"Cost\",color=\"Rating\")\nfig.update_layout(title_text=\"South Indian restaurant cost vs rating\")\nfig.update_xaxes(ticks=\"outside\", tickwidth=1, tickcolor='crimson',tickangle=45, ticklen=10)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Chinese=merged[merged['Chinese_menu'] == 1]\nmean_rating_C=Chinese.groupby(['Name','Cost'],as_index=False).Rating.mean()\nfig = px.bar(mean_rating_C, x=\"Name\", y=\"Cost\",color=\"Rating\")\nfig.update_layout(title_text=\"Chinese restaurant cost vs rating\")\nfig.update_xaxes(ticks=\"outside\", tickwidth=1, tickcolor='crimson',tickangle=45, ticklen=10)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Kmeans - 2 cluster suggesting 1000INR for two is quality bechmark\n\nTried K means clustering which gives 2 clear clusters when we cluster restuarant based on rating and cost for two, if its above 1000 INR the rating are are never low barring one near average rating of Hyatt","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"merged['Cost']=merged['Cost'].str.replace(',', '').astype(float)\nmerged['Cost']=merged['Cost'].astype(float)\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=2, random_state=0).fit(merged[['Cost', 'Rating']])\nmerged['Name'] = kmeans.labels_\nwith plt.style.context('bmh', after_reset=True):\n    pal = sns.color_palette('Spectral', 7)\n    plt.figure(figsize = (8,6))\n    for i in range(2):\n        ix = merged.Name == i\n        plt.scatter(merged.loc[ix, 'Rating'], merged.loc[ix, 'Cost'], color = pal[i], label = str(i))\n        plt.text(merged.loc[i, 'Rating'], merged.loc[i, 'Cost'], str(i) + ': '+str(merged.loc[i, 'Name'].round(2)), fontsize = 14, color = 'brown')\n    plt.title('KMeans Hyderabad Restaurant for Cost and Rating')\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Multiple Cuisines gives higher ratings\n\nwe will plot : \n1.what type of cuisines are served most\n2.frequency of multiple cuisines restaurant\n3.rating vs multiple cuisines\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"merged['Cuisines'] = merged['Cuisines'].astype(str)\nmerged['fusion_num'] = merged['Cuisines'].apply(lambda x: len(x.split(',')))\n\nfrom collections import Counter\nlst_cuisine = set()\nCnt_cuisine = Counter()\nfor cu_lst in merged['Cuisines']:\n    cu_lst = cu_lst.split(',')\n    lst_cuisine.update([cu.strip() for cu in cu_lst])\n    for cu in cu_lst:\n        Cnt_cuisine[cu.strip()] += 1\n\ncnt = pd.DataFrame.from_dict(Cnt_cuisine, orient = 'index')\ncnt.sort_values(0, ascending = False, inplace = True)\n\n\ntmp_cnt = cnt.head(10)\ntmp_cnt.rename(columns = {0:'cnt'}, inplace = True)\nwith plt.style.context('bmh'):\n    f = plt.figure(figsize = (12, 8))\n    ax = plt.subplot2grid((2,2), (0,0))\n    sns.barplot(x = tmp_cnt.index, y = 'cnt', data = tmp_cnt, ax = ax, palette = sns.color_palette('Blues_d', 10))\n    ax.set_title('# Cuisine')\n    ax.tick_params(axis='x', rotation=70)\n    ax = plt.subplot2grid((2,2), (0,1))\n    sns.countplot(merged['fusion_num'], ax=ax, palette = sns.color_palette('Blues_d', merged.fusion_num.nunique()))\n    ax.set_title('# Cuisine Provided')\n    ax.set_ylabel('')\n\n    ax = plt.subplot2grid((2,2), (1,0), colspan = 2)\n    fusion_rate = merged[['fusion_num', 'Rating']].copy()\n    fusion_rate.loc[fusion_rate['fusion_num'] > 5,'fusion_num'] = 5\n    fusion_rate = fusion_rate.loc[fusion_rate.Rating != -1, :]\n    pal = sns.color_palette('Oranges', 11)\n    for i in range(1,6):\n        num_ix = fusion_rate['fusion_num'] == i\n        sns.distplot(fusion_rate.loc[num_ix, 'Rating'], color = pal[i*2], label = str(i), ax = ax)\n        ax.legend()\n        ax.set_title('Rating Distribution for fusion_number')\n\n    plt.subplots_adjust(wspace = 0.5, hspace = 0.8, top = 0.85)\n    plt.suptitle('Cuisine _ Rating')\n    plt.show()        \nprint('# Unique Cuisine: ', len(lst_cuisine))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Extracting total reviews from metadata column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"hyd_rev['total_reviews']=hyd_rev['Metadata'].str.extract('(\\d+)')\nhyd_rev","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3d plot for finding pattern between review length , rating and number of review","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\nfig = px.scatter_3d(hyd_rev, x='Review_length', y='total_reviews', z='Rating')\nfig.update_layout(title_text=\"Review Length vs Rating vs Number of Reviews \")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plot suggest that very lengthy reviews have either very high ratings or very ratings. Average reviews have very small length of review.Number of reviews do not show much impact on ratings","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Poeple who reviewed > 300 times, Their orders and ratings","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"reviewer_rating=hyd_rev.groupby(['Reviewer'],as_index=False).Rating.mean()\nmerged2=reviewer_rating.merge(hyd_rev[['Reviewer','total_reviews']],how='left',left_on='Reviewer',right_on='Reviewer')\nmerged2=merged2.drop_duplicates()\nmerged2['total_reviews']=merged2['total_reviews'].fillna(0)\nmerged2['total_reviews']=merged2['total_reviews'].astype(int)\nreveiwer_300=merged2[merged2['total_reviews']>300]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter_matrix(reveiwer_300,dimensions=[\"total_reviews\", \"Rating\"], color=\"Reviewer\")\nfig.update_layout(title_text=\"Total Reviews vs Ratings for 300+ reviewers \")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Two people in particular have rated every restuarant very poorly, while person who have most reviews gives average ratings to every restuarant.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Thanks for your time to review this lengthy notebook, its a long effort, your upvote will motivate me.\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}