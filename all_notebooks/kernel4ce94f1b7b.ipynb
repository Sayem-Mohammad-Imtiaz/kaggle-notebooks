{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/titanic/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split as tts\nimport re","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"# データをロード\ntest_dir = '/kaggle/input/titanic/test.csv'\ntrain_dir = '/kaggle/input/titanic/train.csv'\ngender_submission_dir = '/kaggle/input/titanic/gender_submission.csv'\ntitanic_test = pd.read_csv(test_dir, encoding='utf-8')\ntitanic_train = pd.read_csv(train_dir, encoding='utf-8')\ngender_submission = pd.read_csv(gender_submission_dir, encoding='utf-8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# データ可視化\nprint(titanic_train.describe())\nprint(titanic_train.sort_values('Age'))\n\n# 欠損値計算\nprint(titanic_train.isna().sum())\nprint('Test Data:\\n{}'.format(titanic_test.isna().sum()))\n\ntitanic_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 前処理\n\n# 欠損値を補完\ntrain_Mr = titanic_train[titanic_train['Name'].str.contains(' Mr. ')]\ntrain_Mrs = titanic_train[titanic_train['Name'].str.contains(' Mrs. ')]\ntrain_Miss = titanic_train[titanic_train['Name'].str.contains(' Miss. ')]\ntrain_Master = titanic_train[titanic_train['Name'].str.contains(' Master. ')]\ntest_Mr = titanic_test[titanic_test['Name'].str.contains(' Mr. ')]\ntest_Mrs = titanic_test[titanic_test['Name'].str.contains(' Mrs. ')]\ntest_Miss = titanic_test[titanic_test['Name'].str.contains(' Miss. ')]\ntest_Master = titanic_test[titanic_test['Name'].str.contains(' Master. ')]\n\n# 各平均値を求める\ntrain_mr_mean = int(train_Mr['Age'].dropna().mean())\ntrain_mrs_mean = int(train_Mrs['Age'].dropna().mean())\ntrain_miss_mean = int(train_Miss['Age'].dropna().mean())\ntrain_master_mean = int(train_Master['Age'].dropna().mean())\ntrain_all_median = int(titanic_train['Age'].dropna().median())\ntest_mr_mean = int(test_Mr['Age'].dropna().mean())\ntest_mrs_mean = int(test_Mrs['Age'].dropna().mean())\ntest_miss_mean = int(test_Miss['Age'].dropna().mean())\ntest_master_mean = int(test_Master['Age'].dropna().mean())\ntest_all_median = int(titanic_test['Age'].dropna().median())\n\n# 求めた平均値を使って欠損値を穴埋めする\ntitanic_train['Age'][train_Mr['Age']].fillna(train_mr_mean,inplace=True)\ntitanic_train['Age'][train_Mrs['Age']].fillna(train_mrs_mean, inplace=True)\ntitanic_train['Age'][train_Miss['Age']].fillna(train_miss_mean, inplace=True)\ntitanic_train['Age'][train_Master['Age']].fillna(train_master_mean, inplace=True)\ntitanic_train['Age'].fillna(train_all_median, inplace=True)\ntitanic_test['Age'][test_Mr['Age']].fillna(test_mr_mean,inplace=True)\ntitanic_test['Age'][test_Mrs['Age']].fillna(test_mrs_mean, inplace=True)\ntitanic_test['Age'][test_Miss['Age']].fillna(test_miss_mean, inplace=True)\ntitanic_test['Age'][test_Master['Age']].fillna(test_master_mean, inplace=True)\ntitanic_test['Age'].fillna(test_all_median, inplace=True)\n# print('train(Age) num of Nan %s' % titanic_train['Age'].isna().sum())\n# print('test(Age) num of Nan %s' % titanic_test['Age'].isna().sum())\n# print('Curent nan :\\n{}'.format(titanic_train.isna().sum()))\n\n# データのCabinを調査&整理\ncabin_bool = titanic_train['Cabin'].isna()\n\n# Cabinの欠損値をUに変更\ntitanic_train['Cabin'].fillna('U',inplace=True)\ntitanic_test['Cabin'].fillna('U', inplace=True)\n\n# Cabinを整理(train)\nprint(titanic_train['Cabin'].unique())\ntitanic_train_A = titanic_train[titanic_train['Cabin'].str.match('A')]\ntitanic_train_B = titanic_train[titanic_train['Cabin'].str.match('B')]\ntitanic_train_C = titanic_train[titanic_train['Cabin'].str.match('C')]\ntitanic_train_D = titanic_train[titanic_train['Cabin'].str.match('D')]\ntitanic_train_E = titanic_train[titanic_train['Cabin'].str.match('E')]\ntitanic_train_F = titanic_train[titanic_train['Cabin'].str.match('F\\d+')]\ntitanic_train_G = titanic_train[titanic_train['Cabin'].str.match('G')]\ntitanic_train_H = titanic_train[titanic_train['Cabin'].str.match('H')]\ntitanic_train_T = titanic_train[titanic_train['Cabin'].str.match('T')]\n\ntitanic_train.loc[titanic_train['Cabin'].str.match('A'),'Cabin'] = 'A'\ntitanic_train.loc[titanic_train['Cabin'].str.match('B'),'Cabin'] = 'B'\ntitanic_train.loc[titanic_train['Cabin'].str.match('C'),'Cabin'] = 'C'\ntitanic_train.loc[titanic_train['Cabin'].str.match('D'),'Cabin'] = 'D'\ntitanic_train.loc[titanic_train['Cabin'].str.match('E'),'Cabin'] = 'E'\ntitanic_train.loc[titanic_train['Cabin'].str.match('F\\d+'),'Cabin'] = 'F'\ntitanic_train.loc[titanic_train['Cabin'].str.match('\\w\\sE+'), 'Cabin'] = 'F'\ntitanic_train.loc[titanic_train['Cabin'].str.match('G'),'Cabin'] = 'G'\ntitanic_train.loc[titanic_train['Cabin'].str.match('\\w\\sG+'),'Cabin'] = 'G'\ntitanic_train.loc[titanic_train['Cabin'].str.match('H'),'Cabin'] = 'H'\ntitanic_train.loc[titanic_train['Cabin'].str.match('T'),'Cabin'] = 'U'\nprint('renamed titanic[Cabin]:\\n{}'.format(titanic_train['Cabin'].unique()))\n\n# test\nprint(titanic_test['Cabin'].unique())\ntitanic_test_A = titanic_test[titanic_test['Cabin'].str.match('A')]\ntitanic_test_B = titanic_test[titanic_test['Cabin'].str.match('B')]\ntitanic_test_C = titanic_test[titanic_test['Cabin'].str.match('C')]\ntitanic_test_D = titanic_test[titanic_test['Cabin'].str.match('D')]\ntitanic_test_E = titanic_test[titanic_test['Cabin'].str.match('E')]\ntitanic_test_F = titanic_test[titanic_test['Cabin'].str.match('F\\d+')]\ntitanic_test_G = titanic_test[titanic_test['Cabin'].str.match('G')]\ntitanic_test_H = titanic_test[titanic_test['Cabin'].str.match('H')]\ntitanic_test_T = titanic_test[titanic_test['Cabin'].str.match('T')]\n\ntitanic_test.loc[titanic_test['Cabin'].str.match('A'),'Cabin'] = 'A'\ntitanic_test.loc[titanic_test['Cabin'].str.match('B'),'Cabin'] = 'B'\ntitanic_test.loc[titanic_test['Cabin'].str.match('C'),'Cabin'] = 'C'\ntitanic_test.loc[titanic_test['Cabin'].str.match('D'),'Cabin'] = 'D'\ntitanic_test.loc[titanic_test['Cabin'].str.match('E'),'Cabin'] = 'E'\ntitanic_test.loc[titanic_test['Cabin'].str.match('F\\d+'),'Cabin'] = 'F'\ntitanic_test.loc[titanic_test['Cabin'].str.match('\\w\\sE+'), 'Cabin'] = 'F'\ntitanic_test.loc[titanic_test['Cabin'].str.match('G'),'Cabin'] = 'G'\ntitanic_test.loc[titanic_test['Cabin'].str.match('\\w\\sG+'),'Cabin'] = 'G'\ntitanic_test.loc[titanic_test['Cabin'].str.match('H'),'Cabin'] = 'H'\ntitanic_test.loc[titanic_test['Cabin'].str.match('T'),'Cabin'] = 'U'\nprint('renamed titanic[Cabin]:\\n{}'.format(titanic_test['Cabin'].unique()))\n\n# survivedとCabinとの関係を調査（死亡0）\ntitanic_train[titanic_train['Survived']==0]\n\n# Ticketの文字を正規表現で整理・分類\nnum_ticket = titanic_train[titanic_train['Ticket'].str.match('\\d+')]\nnum_ticket['Ticket'] = num_ticket['Ticket'].apply(lambda x : int(x))\nobj_ticket = titanic_train[titanic_train['Ticket'].str.match('[a-zA-Z]+')]\nobj_ticket_A = obj_ticket[obj_ticket['Ticket'].str.match('A.+')]\nobj_ticket_PC = obj_ticket[obj_ticket['Ticket'].str.match('PC.+')]\nobj_ticket_STON = obj_ticket[obj_ticket['Ticket'].str.match('STON.+')]\nobj_ticket_PP = obj_ticket[obj_ticket['Ticket'].str.match('PP.+')]\nobj_ticket_C = obj_ticket[obj_ticket['Ticket'].str.match('C\\s+')]\nobj_ticket_CA = obj_ticket[obj_ticket['Ticket'].str.match('C\\.+A\\.+')]\n\nnum_ticket_test = titanic_test[titanic_test['Ticket'].str.match('\\d+')]\nnum_ticket_test['Ticket'] = num_ticket_test['Ticket'].apply(lambda x : int(x))\nobj_ticket_test = titanic_test[titanic_test['Ticket'].str.match('[a-zA-Z]+')]\nobj_ticket_A_test = obj_ticket_test[obj_ticket_test['Ticket'].str.match('A.+')]\nobj_ticket_PC_test = obj_ticket_test[obj_ticket_test['Ticket'].str.match('PC.+')]\nobj_ticket_STON_test = obj_ticket_test[obj_ticket_test['Ticket'].str.match('STON.+')]\nobj_ticket_PP_test = obj_ticket_test[obj_ticket_test['Ticket'].str.match('PP.+')]\nobj_ticket_C_test = obj_ticket_test[obj_ticket_test['Ticket'].str.match('C\\s+')]\nobj_ticket_CA_test = obj_ticket_test[obj_ticket_test['Ticket'].str.match('C\\.+A\\.+')]\n\n# 正規表現で分けたデータを新しいラベルをつける(1-9)\nobj_ticket1 = obj_ticket.copy()\nobj_ticket['Ticket'] = '7'\nobj_ticket.loc[obj_ticket1['Ticket'].str.match('A.+'),'Ticket'] = '1'\nobj_ticket.loc[obj_ticket1['Ticket'].str.match('PC.+'), 'Ticket'] ='2'\nobj_ticket.loc[obj_ticket1['Ticket'].str.match('STON.+'), 'Ticket'] = '3'\nobj_ticket.loc[obj_ticket1['Ticket'].str.match('PP.+'), 'Ticket'] = '4'\nobj_ticket.loc[obj_ticket1['Ticket'].str.match('C\\s+'), 'Ticket'] = '5'\nobj_ticket.loc[obj_ticket1['Ticket'].str.match('C\\.+A\\.+'), 'Ticket'] = '6'\nnum_ticket1 = num_ticket.copy()\nnum_ticket.loc[num_ticket1['Ticket']  < 10000, 'Ticket'] = '8'\nnum_ticket.loc[(num_ticket1['Ticket'] >= 10000) & (num_ticket1['Ticket'] < 15000), 'Ticket'] = '9'\nnum_ticket.loc[(num_ticket1['Ticket'] >= 15000) & (num_ticket1['Ticket'] < 20000), 'Ticket'] = '10'\nnum_ticket.loc[(num_ticket1['Ticket'] >= 20000) & (num_ticket1['Ticket'] < 25000), 'Ticket'] = '11'\nnum_ticket.loc[(num_ticket1['Ticket'] >= 25000) & (num_ticket1['Ticket'] < 30000), 'Ticket'] = '12'\nnum_ticket.loc[num_ticket1['Ticket'] >= 30000, 'Ticket'] = '13'\ntrain = pd.concat([obj_ticket, num_ticket], axis=0)\n\nobj_ticket_test1 = obj_ticket_test.copy()\nobj_ticket_test['Ticket'] = '7'\nobj_ticket_test.loc[obj_ticket_test1['Ticket'].str.match('A.+'),'Ticket'] = '1'\nobj_ticket_test.loc[obj_ticket_test1['Ticket'].str.match('PC.+'), 'Ticket'] ='2'\nobj_ticket_test.loc[obj_ticket_test1['Ticket'].str.match('STON.+'), 'Ticket'] = '3'\nobj_ticket_test.loc[obj_ticket_test1['Ticket'].str.match('PP.+'), 'Ticket'] = '4'\nobj_ticket_test.loc[obj_ticket_test1['Ticket'].str.match('C\\s+'), 'Ticket'] = '5'\nobj_ticket_test.loc[obj_ticket_test1['Ticket'].str.match('C\\.+A\\.+'), 'Ticket'] = '6'\nnum_ticket_test1 = num_ticket_test.copy()\nnum_ticket_test.loc[num_ticket_test1['Ticket']  < 10000, 'Ticket'] = '8'\nnum_ticket_test.loc[(num_ticket_test1['Ticket'] >= 10000) & (num_ticket_test1['Ticket'] < 15000), 'Ticket'] = '9'\nnum_ticket_test.loc[(num_ticket_test1['Ticket'] >= 15000) & (num_ticket_test1['Ticket'] < 20000), 'Ticket'] = '10'\nnum_ticket_test.loc[(num_ticket_test1['Ticket'] >= 20000) & (num_ticket_test1['Ticket'] < 25000), 'Ticket'] = '11'\nnum_ticket_test.loc[(num_ticket_test1['Ticket'] >= 25000) & (num_ticket_test1['Ticket'] < 30000), 'Ticket'] = '12'\nnum_ticket_test.loc[num_ticket_test1['Ticket'] >= 30000, 'Ticket'] = '13'\ntest = pd.concat([obj_ticket_test, num_ticket_test], axis=0)\n\n# Embarkedの欠損値を削除\ntrain['Embarked'].fillna('S', inplace=True)  # 'S' is the most common symbol \ntest['Embarked'].fillna('S', inplace=True)\n\n# Test dataのFareの欠損値を中央値で補完\ntest['Fare'].fillna(test['Fare'].median(), inplace=True)\n\n# Data後で使うのでソート\ntrain.sort_values('PassengerId', inplace=True)\ntest.sort_values('PassengerId', inplace=True)\n\ntrain['Family'] = train['SibSp'] + train['Parch']\ntest['Family'] = test['SibSp'] + test['Parch']\n\n# ワンホットラベル化\ndef get_dummy(df):\n    df['Pclass'] = df['Pclass'].astype(np.str)\n    temp = pd.get_dummies(df, columns = ['Pclass','Sex', 'Ticket', 'Cabin', 'Embarked'],drop_first=False)\n    temp['PassengerId'] = df['PassengerId']\n    return temp\n\ntrain_dm = get_dummy(train)\ntest_dm = get_dummy(test)\n\n# いらない値を削除\ntrain_dm.drop(columns=['PassengerId', 'Name', 'Parch', 'SibSp'],inplace=True)\ntest_dm.drop(columns=['PassengerId', 'Name', 'Parch', 'SibSp'],inplace=True)\n\n# 訓練用データのtarget（死亡生存）を分ける\ntrain_target = train_dm['Survived']\ntrain_data = train_dm[train_dm.columns[train_dm.columns != 'Survived']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LightGBM勾配Boosting木で訓練\nimport lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\n\n# 交差検証\nskf = StratifiedKFold(n_splits=10,\n                      shuffle=True,\n                      random_state=0)\n\n# LightGBMモデルで訓練\nmodel = lgb.LGBMClassifier(silent=False)\n\n# GridSearchで検索するパラメーター\nparam_grid = {\"max_depth\": [2, 3, 5, 10],\n              \"learning_rate\" : [0.01, 0.05, 0.1],\n              \"num_leaves\": [10, 100, 300, 900],\n              \"n_estimators\": [100, 200, 500]\n             }\n\ngrid_result = GridSearchCV(estimator=model,\n                           param_grid=param_grid,\n                           scoring='balanced_accuracy',\n                           cv=skf,\n                           verbose=3,\n                           return_train_score=True,\n                           n_jobs=-1)\n\ngrid_result.fit(train_data, train_target)\n\n\n# LightGBM訓練 + 予測値\nX_train, X_val, y_train, y_val = tts(train_data, train_target,\n                                           shuffle=True,\n                                           stratify=train_target)\n\nlgb_train = lgb.Dataset(X_train, label=y_train)\nlgb_val = lgb.Dataset(X_val, label=y_val)\n\nlgb_param = {\n    'objective' : 'binary',\n    'metrics' : 'binary_logloss',\n}\n\n# 辞書結合（もしかするともっといい方法があるかも）\nparams = grid_result.best_params_\nparams.update(lgb_param)\n\nmodel = lgb.train(params,\n                  lgb_train,\n                  valid_sets=lgb_val,\n                  num_boost_round=10000,\n                  early_stopping_rounds=1000\n                  )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GridSearchCVのベストスコア（交差検証済み）\nscore = grid_result.best_score_\nprint('Best Score:{:.3f}'.format(score))\nprint('Best parametor :\\n{}'.format(grid_result.best_params_))\n\n# 予測値\ny_pred_proba = model.predict(test_dm,num_iteration=model.best_iteration)\ny_pred = (y_pred_proba > 0.5).astype(int)\nprint('prediction :\\n{}'.format(y_pred))\n\n# 提出用ファイルを作成&saving\ntest = titanic_test\ntest['Survived'] = y_pred.astype(int)\ntest[['PassengerId', 'Survived']].to_csv('submission.csv', encoding='utf-8', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 確認\nfor dirname, _, filenames in os.walk('./'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}