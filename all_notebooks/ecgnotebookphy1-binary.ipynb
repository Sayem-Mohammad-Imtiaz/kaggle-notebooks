{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# using Seaborne for hist\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dropout\nfrom tensorflow.keras.models import Model\n\nfrom sklearn.model_selection import train_test_split\n\nfrom numpy.random import seed\n\nsns.set(color_codes=True)\n%matplotlib inline\n\n# code for Tensorflow 2 !!!\nprint(tf.__version__)\nassert(tf.__version__ >= '2.')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"FILE_NAME = \"/kaggle/input/physionet2017ecg/physionet2017.csv\"\n\ndata = pd.read_csv(FILE_NAME)\n\n# shuffle the dataframe before splitting\ndata = data.sample(frac=1)\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's try first with binary classification (normal, not normal)\n\ndata.loc[data.label != 0, \"label\"] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['label'].hist();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.iloc[:, :2000]\nY = data.iloc[:, 2001]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.1, random_state=42)\n\nprint('X_train: ', X_train.shape)\nprint('X_valid: ', X_valid.shape)\n\n# need to trasnform to sort of image (2 dim tensor) for compatibility with input of CNN\nX_train = np.expand_dims(X_train, axis = 2)\n\nX_valid = np.expand_dims(X_valid, axis = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define the model\n\n# arcitecture inspired by keras.io\n\ndef build_model(input_shape):\n    # using Keras functional API\n    input_layer = keras.layers.Input(input_shape)\n\n    # kernel size changed from 3 to 5\n    conv0 = keras.layers.Conv1D(filters=32, kernel_size=5, padding=\"same\", activation = \"relu\")(input_layer)\n    # conv0 = keras.layers.BatchNormalization()(conv0)\n    conv0 = keras.layers.MaxPooling1D(pool_size=2)(conv0)\n    \n    conv1 = keras.layers.Conv1D(filters=32, kernel_size=5, padding=\"same\", activation=\"relu\")(conv0)\n    conv1 = keras.layers.MaxPooling1D(pool_size=2)(conv1)\n    \n    conv2 = keras.layers.Conv1D(filters=64, kernel_size=5, padding=\"same\", activation=\"relu\")(conv1)\n    conv2 = keras.layers.MaxPooling1D(pool_size=2)(conv2)\n    \n    conv3 = keras.layers.Conv1D(filters=64, kernel_size=5, padding=\"same\", activation=\"relu\")(conv2)\n    conv3 = keras.layers.MaxPooling1D(pool_size=2)(conv3)\n    \n    conv4 = keras.layers.Conv1D(filters=128, kernel_size=5, padding=\"same\", activation=\"relu\")(conv3)\n    conv4 = keras.layers.MaxPooling1D(pool_size=2)(conv4)\n    \n    conv5 = keras.layers.Conv1D(filters=128, kernel_size=5, padding=\"same\", activation=\"relu\")(conv4)\n    conv5 = keras.layers.MaxPooling1D(pool_size=2)(conv5)\n    conv5 = keras.layers.Dropout(0.5)(conv5)\n    \n    conv6 = keras.layers.Conv1D(filters=256, kernel_size=5, padding=\"same\", activation=\"relu\")(conv5)\n    conv6 = keras.layers.MaxPooling1D(pool_size=2)(conv6)\n    \n    conv7 = keras.layers.Conv1D(filters=256, kernel_size=5, padding=\"same\", activation=\"relu\")(conv6)\n    conv7 = keras.layers.MaxPooling1D(pool_size=2)(conv7)\n    conv7 = keras.layers.Dropout(0.5)(conv7)\n    \n    conv8 = keras.layers.Conv1D(filters=512, kernel_size=5, padding=\"same\", activation=\"relu\")(conv7)\n    conv8 = keras.layers.MaxPooling1D(pool_size=2)(conv8)\n    conv8 = keras.layers.Dropout(0.5)(conv8)\n    \n    conv9 = keras.layers.Conv1D(filters=512, kernel_size=5, padding=\"same\", activation=\"relu\")(conv8)\n    \n    gap = keras.layers.Flatten()(conv9)\n    dense1 = keras.layers.Dense(64, activation = \"relu\")(gap)\n    dense2 = keras.layers.Dropout(0.5)(dense1)\n    dense3 = keras.layers.Dense(32, activation = \"relu\")(dense2)\n    \n    output_layer = keras.layers.Dense(1, activation=\"sigmoid\")(dense3)\n\n    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed(1234)\ntf.random.set_seed(1234)\n\n\nmodel = build_model(input_shape=(2000, 1))\n\n# we need a smaller learning rate to have a smoother convergence\n# it is really important\nopt = keras.optimizers.Adam(learning_rate=0.00006)\n\nmc = tf.keras.callbacks.ModelCheckpoint(\n        'ecg5000.h5', monitor='val_loss', verbose=1, save_best_only=True,\n        save_weights_only=True, mode='min', save_freq='epoch')\n\nmodel.compile(\n    optimizer=opt,\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_EPOCHS = 100\nBATCH_SIZE = 128\nVAL_SPLIT = 0.2\nVERBOSE = 1\n\nimport time\n\nt_start = time.time()\n\n# y = X\nhistory = model.fit(X_train, y_train, batch_size = BATCH_SIZE, epochs = NUM_EPOCHS, validation_split = VAL_SPLIT, verbose = VERBOSE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize loss for the training\nplt.figure(figsize = (10,6))\nhist_loss = history.history['loss']\nhist_val_loss = history.history['val_loss']\n\nplt.plot(hist_loss, label='Training loss')\nplt.plot(hist_val_loss, label='Validation loss')\n\nplt.legend(loc='upper right')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize accuracy for the training\nplt.figure(figsize = (10,6))\nhist_loss = history.history['accuracy']\nhist_val_loss = history.history['val_accuracy']\n\nplt.plot(hist_loss, label='Training accuracy')\nplt.plot(hist_val_loss, label='Validation accuracy')\n\nplt.legend(loc='lower right')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, accuracy = model.evaluate(X_valid, y_valid)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}