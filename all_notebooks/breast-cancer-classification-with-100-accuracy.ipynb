{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Breast Cancer Classification","metadata":{}},{"cell_type":"markdown","source":"***Attribute Information:***\n\n* ID number\n \n* Diagnosis (M = malignant, B = benign)","metadata":{}},{"cell_type":"markdown","source":"***Ten real-valued features are computed for each cell nucleus:***\n* radius (mean of distances from center to points on the perimeter)\n* texture (standard deviation of gray-scale values)\n* perimeter\n* area\n* smoothness (local variation in radius lengths)\n* compactness (perimeter^2 / area - 1.0)\n* concavity (severity of concave portions of the contour)\n* concave points (number of concave portions of the contour)\n* symmetry\n* fractal dimension (\"coastline approximation\" - 1)","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-12T18:43:33.570964Z","iopub.execute_input":"2021-06-12T18:43:33.571495Z","iopub.status.idle":"2021-06-12T18:43:33.600189Z","shell.execute_reply.started":"2021-06-12T18:43:33.571357Z","shell.execute_reply":"2021-06-12T18:43:33.599166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing libraries\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport missingno as msno\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nplt.style.use('ggplot')","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:43:37.903662Z","iopub.execute_input":"2021-06-12T18:43:37.904008Z","iopub.status.idle":"2021-06-12T18:43:38.248383Z","shell.execute_reply.started":"2021-06-12T18:43:37.90398Z","shell.execute_reply":"2021-06-12T18:43:38.247496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the data:-\n\ndf = pd.read_csv('../input/breast-cancer-wisconsin-data/data.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:43:41.977115Z","iopub.execute_input":"2021-06-12T18:43:41.977463Z","iopub.status.idle":"2021-06-12T18:43:42.034211Z","shell.execute_reply.started":"2021-06-12T18:43:41.97743Z","shell.execute_reply":"2021-06-12T18:43:42.033115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data preprocessing:-","metadata":{}},{"cell_type":"code","source":"# View raw data:-\n\npd.set_option('max_columns',33)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:43:45.702416Z","iopub.execute_input":"2021-06-12T18:43:45.702775Z","iopub.status.idle":"2021-06-12T18:43:45.7372Z","shell.execute_reply.started":"2021-06-12T18:43:45.702741Z","shell.execute_reply":"2021-06-12T18:43:45.736258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dimension of the data:-\n\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:43:49.186827Z","iopub.execute_input":"2021-06-12T18:43:49.18716Z","iopub.status.idle":"2021-06-12T18:43:49.192755Z","shell.execute_reply.started":"2021-06-12T18:43:49.187127Z","shell.execute_reply":"2021-06-12T18:43:49.192028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> No. of rows and columns in the data is 569 and 33 respectvely.","metadata":{}},{"cell_type":"code","source":"# Data types:-\n\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:43:52.375471Z","iopub.execute_input":"2021-06-12T18:43:52.376005Z","iopub.status.idle":"2021-06-12T18:43:52.391111Z","shell.execute_reply.started":"2021-06-12T18:43:52.375957Z","shell.execute_reply":"2021-06-12T18:43:52.39036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking Null values using heatmap:-\n\nsns.heatmap(df.isnull())","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:43:56.44017Z","iopub.execute_input":"2021-06-12T18:43:56.440803Z","iopub.status.idle":"2021-06-12T18:43:56.823688Z","shell.execute_reply.started":"2021-06-12T18:43:56.440755Z","shell.execute_reply":"2021-06-12T18:43:56.822512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count the null values:-\n\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:44:00.515958Z","iopub.execute_input":"2021-06-12T18:44:00.516291Z","iopub.status.idle":"2021-06-12T18:44:00.525551Z","shell.execute_reply.started":"2021-06-12T18:44:00.516264Z","shell.execute_reply":"2021-06-12T18:44:00.524443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">As we can see that the last column Unnamed: 32 has all NaN value so we will drop this column.","metadata":{}},{"cell_type":"code","source":"# Droping Unnamed: 32 Column\n\ndf.drop('Unnamed: 32', axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:44:06.320621Z","iopub.execute_input":"2021-06-12T18:44:06.320945Z","iopub.status.idle":"2021-06-12T18:44:06.327087Z","shell.execute_reply.started":"2021-06-12T18:44:06.320915Z","shell.execute_reply":"2021-06-12T18:44:06.325854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find unique values in 'diagnosis' column:-\n\ndf.diagnosis.unique()","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:44:10.248056Z","iopub.execute_input":"2021-06-12T18:44:10.248408Z","iopub.status.idle":"2021-06-12T18:44:10.255136Z","shell.execute_reply.started":"2021-06-12T18:44:10.248375Z","shell.execute_reply":"2021-06-12T18:44:10.25416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replace 'M' with 1 and 'B' with 0 in column 'diagnosis':-\n\ndf['diagnosis'] = df['diagnosis'].apply(lambda val: 1 if val == 'M' else 0)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:44:13.415081Z","iopub.execute_input":"2021-06-12T18:44:13.415488Z","iopub.status.idle":"2021-06-12T18:44:13.421503Z","shell.execute_reply.started":"2021-06-12T18:44:13.415451Z","shell.execute_reply":"2021-06-12T18:44:13.420488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Again view raw data:-\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:44:18.637312Z","iopub.execute_input":"2021-06-12T18:44:18.637648Z","iopub.status.idle":"2021-06-12T18:44:18.67093Z","shell.execute_reply.started":"2021-06-12T18:44:18.637618Z","shell.execute_reply":"2021-06-12T18:44:18.669971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Describing the data / Statistical Data analysis:-\n\npd.set_option('precision',3)\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:44:22.111847Z","iopub.execute_input":"2021-06-12T18:44:22.112168Z","iopub.status.idle":"2021-06-12T18:44:22.206727Z","shell.execute_reply.started":"2021-06-12T18:44:22.112142Z","shell.execute_reply":"2021-06-12T18:44:22.205894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization:-","metadata":{}},{"cell_type":"code","source":"# Diagnosis Pie chart:-\n\nprint(df.diagnosis.value_counts())\ndf.diagnosis.value_counts().plot.pie();","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:44:26.29537Z","iopub.execute_input":"2021-06-12T18:44:26.295707Z","iopub.status.idle":"2021-06-12T18:44:26.384193Z","shell.execute_reply.started":"2021-06-12T18:44:26.29568Z","shell.execute_reply":"2021-06-12T18:44:26.383291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Heatmap:-\n\nplt.figure(figsize=(30,30))\nsns.heatmap(df.corr(),annot = True, cmap = 'Blues');","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:44:31.621709Z","iopub.execute_input":"2021-06-12T18:44:31.622045Z","iopub.status.idle":"2021-06-12T18:44:35.835679Z","shell.execute_reply.started":"2021-06-12T18:44:31.622014Z","shell.execute_reply":"2021-06-12T18:44:35.834896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# EDA:-\n\nplt.figure(figsize = (20, 15))\nplotnumber = 1\n\nfor column in df:\n    if plotnumber <= 30:\n        ax = plt.subplot(5, 6, plotnumber)\n        sns.distplot(df[column])\n        plt.xlabel(column)\n        \n    plotnumber += 1\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:44:41.906521Z","iopub.execute_input":"2021-06-12T18:44:41.907009Z","iopub.status.idle":"2021-06-12T18:44:47.588923Z","shell.execute_reply.started":"2021-06-12T18:44:41.906978Z","shell.execute_reply":"2021-06-12T18:44:47.585331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting Mean Columns\nm_col = ['diagnosis','radius_mean', 'texture_mean', 'perimeter_mean',\n       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']\n\n# Getting Se Columns\ns_col = ['diagnosis','radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n       'fractal_dimension_se']\n\n# Getting Worst column\nw_col = ['diagnosis','radius_worst', 'texture_worst',\n       'perimeter_worst', 'area_worst', 'smoothness_worst',\n       'compactness_worst', 'concavity_worst', 'concave points_worst',\n       'symmetry_worst', 'fractal_dimension_worst']","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:44:52.38525Z","iopub.execute_input":"2021-06-12T18:44:52.385613Z","iopub.status.idle":"2021-06-12T18:44:52.390467Z","shell.execute_reply.started":"2021-06-12T18:44:52.38558Z","shell.execute_reply":"2021-06-12T18:44:52.389613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Heatmap For Mean Columns:-\n\nplt.figure(figsize=(15,15))\nsns.heatmap(df[m_col].corr(),annot = True, cmap = 'Blues');","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:44:56.908969Z","iopub.execute_input":"2021-06-12T18:44:56.909462Z","iopub.status.idle":"2021-06-12T18:44:57.659831Z","shell.execute_reply.started":"2021-06-12T18:44:56.909427Z","shell.execute_reply":"2021-06-12T18:44:57.658792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pairplot for mean columns\n\nsns.pairplot(df[m_col],hue = 'diagnosis', palette='Blues');","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:45:02.522642Z","iopub.execute_input":"2021-06-12T18:45:02.522977Z","iopub.status.idle":"2021-06-12T18:45:27.313289Z","shell.execute_reply.started":"2021-06-12T18:45:02.522947Z","shell.execute_reply":"2021-06-12T18:45:27.312244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Heatmap for se columns\n\nplt.figure(figsize=(15,15))\nsns.heatmap(df[s_col].corr(),annot = True, cmap = 'Reds');","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:45:35.241162Z","iopub.execute_input":"2021-06-12T18:45:35.241668Z","iopub.status.idle":"2021-06-12T18:45:35.981247Z","shell.execute_reply.started":"2021-06-12T18:45:35.241632Z","shell.execute_reply":"2021-06-12T18:45:35.980274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pairplot for se columns\n\nsns.pairplot(df[m_col],hue = 'diagnosis', palette='Reds');","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:45:40.884987Z","iopub.execute_input":"2021-06-12T18:45:40.88549Z","iopub.status.idle":"2021-06-12T18:46:05.747222Z","shell.execute_reply.started":"2021-06-12T18:45:40.885439Z","shell.execute_reply":"2021-06-12T18:46:05.746285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Heatmap for Worst columns:-\n\nplt.figure(figsize=(15,15))\nsns.heatmap(df[w_col].corr(),annot = True, cmap = 'Greens');","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:46:07.375492Z","iopub.execute_input":"2021-06-12T18:46:07.375829Z","iopub.status.idle":"2021-06-12T18:46:08.124043Z","shell.execute_reply.started":"2021-06-12T18:46:07.375801Z","shell.execute_reply":"2021-06-12T18:46:08.123125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pairplot for worst columns:-\n\nsns.pairplot(df[w_col],hue = 'diagnosis', palette='Greens');","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:46:14.861812Z","iopub.execute_input":"2021-06-12T18:46:14.862172Z","iopub.status.idle":"2021-06-12T18:46:39.433503Z","shell.execute_reply.started":"2021-06-12T18:46:14.862139Z","shell.execute_reply":"2021-06-12T18:46:39.432453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# removing highly correlated features\n\ncorr_matrix = df.corr().abs() \n\nmask = np.triu(np.ones_like(corr_matrix, dtype = bool))\ntri_df = corr_matrix.mask(mask)\n\nto_drop = [x for x in tri_df.columns if any(tri_df[x] > 0.92)]\n\ndf = df.drop(to_drop, axis = 1)\n\nprint(f\"The reduced dataframe has {df.shape[1]} columns.\")","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:46:39.43511Z","iopub.execute_input":"2021-06-12T18:46:39.435473Z","iopub.status.idle":"2021-06-12T18:46:39.459505Z","shell.execute_reply.started":"2021-06-12T18:46:39.435436Z","shell.execute_reply":"2021-06-12T18:46:39.458601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> We can see that there are many columns which are very highly correlated which causes multicollinearity so we have to remove highly correlated features.","metadata":{}},{"cell_type":"markdown","source":"# Data Modelling:-","metadata":{}},{"cell_type":"code","source":"# Getting Features:-\n\nx = df.drop(columns = 'diagnosis')\n\n# Getting Predicting Value:-\n\ny = df['diagnosis']","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:46:39.460876Z","iopub.execute_input":"2021-06-12T18:46:39.46114Z","iopub.status.idle":"2021-06-12T18:46:39.466462Z","shell.execute_reply.started":"2021-06-12T18:46:39.461112Z","shell.execute_reply":"2021-06-12T18:46:39.465341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting data into training and testing data:-\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=1/9, random_state=252)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:46:39.467719Z","iopub.execute_input":"2021-06-12T18:46:39.467974Z","iopub.status.idle":"2021-06-12T18:46:39.541279Z","shell.execute_reply.started":"2021-06-12T18:46:39.467949Z","shell.execute_reply":"2021-06-12T18:46:39.540484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scaling data:-\n\nfrom sklearn.preprocessing import StandardScaler\nscale = StandardScaler()\nx_train = scale.fit_transform(x_train)\nx_test = scale.fit_transform(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:46:50.984493Z","iopub.execute_input":"2021-06-12T18:46:50.98482Z","iopub.status.idle":"2021-06-12T18:46:50.990785Z","shell.execute_reply.started":"2021-06-12T18:46:50.984791Z","shell.execute_reply":"2021-06-12T18:46:50.989925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating Classification Models:-","metadata":{}},{"cell_type":"code","source":"# Defining Models:-\n\ndef Classification_Models(x,y,xt,yt):\n    # Importing All LIberaries\n    from sklearn.metrics import accuracy_score\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n    from sklearn.naive_bayes import GaussianNB\n    from sklearn.tree import DecisionTreeClassifier\n    from sklearn.ensemble import RandomForestClassifier\n    from sklearn import svm\n    from sklearn.neighbors import KNeighborsClassifier\n\n    # Initializing models:-\n    \n    logisreg = LogisticRegression()\n    lda = LinearDiscriminantAnalysis()\n    gnb = GaussianNB()\n    dtc = DecisionTreeClassifier()\n    rfc = RandomForestClassifier()\n    svmodel = svm.SVC()\n    knnmodel = KNeighborsClassifier()\n    \n    # Fitting Models\n    logisreg.fit(x,y)\n    lda.fit(x,y)\n    gnb.fit(x,y)\n    dtc.fit(x,y)\n    rfc.fit(x,y)\n    svmodel.fit(x,y)\n    knnmodel.fit(x,y)\n    \n    # Getting Predicting Values:-\n    \n    logi_pred = logisreg.predict(xt)\n    lda_pred = lda.predict(xt)\n    gnb_pred = gnb.predict(xt)\n    dtc_pred = dtc.predict(xt)\n    rfc_pred = rfc.predict(xt)\n    svm_pred = svmodel.predict(xt)\n    knn_pred = knnmodel.predict(xt)\n    \n    # Getting Accuracy Score\n    acc_logisreg = accuracy_score(yt, logi_pred)\n    acc_lda = accuracy_score(yt, lda_pred)\n    acc_ganb = accuracy_score(yt, gnb_pred)\n    acc_dtree = accuracy_score(yt, dtc_pred)\n    acc_rf = accuracy_score(yt, rfc_pred)\n    acc_svc = accuracy_score(yt, svm_pred)\n    acc_knn = accuracy_score(yt, knn_pred)\n    \n    # MOdel Selection\n    models = pd.DataFrame({\n    'Model': ['Logistic Regression','Linear Discriminant Analysis','Naive Bayes', 'Decision Tree', 'Random Forest', 'Support Vector Machines', \n              'K - Nearest Neighbors'],\n    'Score': [acc_logisreg, acc_lda, acc_ganb, acc_dtree, acc_rf, acc_svc, acc_knn]})\n\n    print(models.sort_values(by='Score', ascending=False))\n    sns.barplot(x = models['Score'], y = models['Model'], palette='viridis');","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:46:55.925709Z","iopub.execute_input":"2021-06-12T18:46:55.926042Z","iopub.status.idle":"2021-06-12T18:46:55.93655Z","shell.execute_reply.started":"2021-06-12T18:46:55.926014Z","shell.execute_reply":"2021-06-12T18:46:55.935248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Classification_Models(x_train,y_train,x_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T18:47:01.346455Z","iopub.execute_input":"2021-06-12T18:47:01.346823Z","iopub.status.idle":"2021-06-12T18:47:01.928832Z","shell.execute_reply.started":"2021-06-12T18:47:01.34679Z","shell.execute_reply":"2021-06-12T18:47:01.927802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Logistic Regression, SVM, Random Forest and KNN were the best here with the accuracy of 100%.","metadata":{}},{"cell_type":"markdown","source":"# Please leave your feedbacks in the comment section. Thank you.....","metadata":{}},{"cell_type":"markdown","source":"# If you like my work, please do a upvote :)","metadata":{}}]}