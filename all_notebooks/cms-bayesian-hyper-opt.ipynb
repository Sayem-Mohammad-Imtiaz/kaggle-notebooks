{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install focal-loss==0.0.2","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport skopt\nimport gc\nimport time\nfrom skopt.space import Real, Integer, Categorical\nfrom skopt.utils import use_named_args\nfrom skopt import gp_minimize\nimport matplotlib.pyplot as plt\nfrom skopt.plots import plot_convergence,plot_objective,plot_evaluations\nimport warnings\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras import Model\nfrom focal_loss import BinaryFocalLoss\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.layers import Conv1D, Input, Dropout, BatchNormalization, MaxPooling1D, Flatten, Dense, GlobalMaxPooling1D\nfrom skopt import dump, load\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\n# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pT_classes(x):\n    if x<=25:\n        return 0\n    else:\n        return 1\n\ndf = pd.read_csv('../input/cmsdata/CMS_trigger.csv').drop(columns=['Unnamed: 0'])\ndf['No. of hits'] = df[['Mask_'+str(i) for i in range(12)]].sum(axis = 1)\ndf = df[df['No. of hits']<9].reset_index(drop=True)\ndf['1/pT'] = df['q/pt'].abs()\ndf['pT'] = 1/df['1/pT']\ndf['pT_classes'] = df['pT'].apply(pT_classes)\n\nfeatures = list(np.array([['Phi_'+str(i),'Theta_'+str(i)] for i in range(12)]).reshape((-1)))\nlabels_1 = ['1/pT']\nlabels_2 = ['BendingAngle_'+str(i) for i in [0,1,9,10,11]]\nlabels_3 = ['pT_classes']\nlabels_4 = ['PatternStraightness']\n\nscaler_1 = StandardScaler()\ndf[features] = scaler_1.fit_transform(df[features])\ndf[features] = df[features].fillna(0)\n\nscaler_2 = MinMaxScaler()\ndf[labels_2] = scaler_2.fit_transform(df[labels_2])\ndf[labels_2] = df[labels_2].fillna(0)\n\nscaler_3 = MinMaxScaler()\ndf[labels_4] = scaler_3.fit_transform(df[labels_4])\ndf[labels_4] = df[labels_4].fillna(0)\n\nfeatures = list(np.array([['Phi_'+str(i),'Theta_'+str(i), 'Mask_'+str(i)] for i in range(12)]).reshape((-1)))\n\ndf = df.sample(frac = 0.4).reset_index(drop = True)\ndf = df.iloc[:int((len(df)//1024)*1024)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = df[features].iloc[:int(len(df)*0.8)].to_numpy().reshape((-1,12,3))\nY1_train = df[labels_1].iloc[:int(len(df)*0.8)]\nY2_train = df[labels_2].iloc[:int(len(df)*0.8)]\nY3_train = df[labels_3].astype('float32').iloc[:int(len(df)*0.8)]\nY4_train = df[labels_4].iloc[:int(len(df)*0.8)]\n\nX_test = df[features].iloc[int(len(df)*0.8):].to_numpy().reshape((-1,12,3))\nY1_test = df[labels_1].iloc[int(len(df)*0.8):]\nY2_test = df[labels_2].iloc[int(len(df)*0.8):]\nY3_test = df[labels_3].astype('float32').iloc[int(len(df)*0.8):]\nY4_test = df[labels_4].iloc[int(len(df)*0.8):]\n\ndf = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, len(Y1_train), len(Y2_train), len(Y3_train), len(Y4_train), X_test.shape, len(Y1_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Real - Dropout, Focal loss weight, SkipFraction\n# Binary - Batchnorm, skipType\n# Integer - number of layers, number of filters, focal loss gamma, number of dense neurons","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"space  = [Real(0.0, 0.7, name='Dropout'),\n          Real(0.0, 1.0, name='FocalLossWeight'),\n          Real(0.0, 1.0, name='SkipFraction'),\n          Categorical([0,1], name = 'BatchNorm'),\n          Categorical([0,1], name = 'SkipType'),\n          Integer(2, 10, name='# Layers'),\n          Integer(16, 512, name='# Filters'),\n          Integer(0, 5, name='FocalLossGamma'),\n          Integer(128, 512, name='DenseNeurons'),\n         ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cnn(values = [0,1,0.5,1,1,5,16,2,128], X_train = X_train, Y1_train = Y1_train, Y2_train = Y2_train, Y3_train = Y3_train, Y4_train = Y4_train):\n    global strategy\n    dropout = values[0]\n    FocalLossWeight = values[1]\n    SkipFraction = values[2]\n    batchNorm = values[3]\n    SkipType = values[4]\n    Layers = values[5]\n    Filters = values[6]\n    Gamma = values[7]\n    DN = values[8]\n    \n    batch_size=1024* strategy.num_replicas_in_sync\n    path = \"model.h5\"\n    \n    with strategy.scope():\n        I = Input(shape=(12,3))\n        x = Conv1D(filters=Filters, kernel_size=3, activation='relu', padding='same')(I)\n        x_ = x\n        for i in range(Layers-1):\n            x = Dropout(dropout)(x)\n            if batchNorm==1:\n                x = BatchNormalization()(x)\n            x__ = Conv1D(filters=Filters, kernel_size=3, activation='relu', padding='same')(x)\n            if SkipType==1 and Layers*(1-SkipFraction)<=i:\n                x = tf.concat([x_, x__] ,axis = -1)\n                x_ = x__\n            elif SkipType==0 and Layers*(1-SkipFraction)<=i:\n                x = x_ + x__\n                x_ = x__\n            else:\n                x_ = x__\n                x = x__\n        x = GlobalMaxPooling1D()(x)\n        x1 = Dense(DN, activation='relu')(x)\n        O1 = Dense(1, activation='sigmoid')(x1)\n        x2 = Dense(DN, activation='relu')(x)\n        O2 = Dense(5, activation='sigmoid')(x2)\n        x3 = Dense(DN, activation='relu')(x)\n        O3 = Dense(1, activation='sigmoid')(x3)\n        x4 = Dense(DN, activation='relu')(x)\n        O4 = Dense(1, activation='sigmoid')(x4)\n\n        model = Model(inputs=I, outputs=[O1,O2, O3, O4])\n\n        checkpoint = ModelCheckpoint(path, monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n        early_stop = EarlyStopping(monitor='val_loss',patience=3,verbose=0)\n        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=0,verbose=0)\n\n        model.compile(optimizer = 'adam', loss=['mse','mse',BinaryFocalLoss(gamma=Gamma),'mse'],loss_weights = [1,1,1,FocalLossWeight] )\n    \n#     model.summary()\n#     print(X_train.shape, Y1_train.shape, Y2_train.shape, Y3_train.shape, Y4_train.shape )\n    model.fit(x = X_train, y = [Y1_train, Y2_train, Y3_train, Y4_train], batch_size=batch_size, epochs=40, verbose=0, validation_split=0.1, callbacks=[checkpoint,early_stop,reduce_lr])\n    \n    model.load_weights(path)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def score(true, preds):\n    true = 1/true\n    preds = 1/(preds+pow(10,-6))\n    S = []\n    count = 0\n    for i in range(150):\n        try:\n            S.append(mae(true[(true>i)&(true<=i+1)],preds[(true>i)&(true<=i+1)])/(i+0.5))\n        except:\n            count+=1\n            continue\n    print(count)\n    return sum(S)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def score(true, preds):\n#     true = 1/true\n#     preds = 1/(preds+pow(10,-6))\n#     return mae(true,preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iteration__ = 0\ndef objective(values = [0,1,0.5,1,1,5,16,2,128], X_test = X_test, Y1_test = Y1_test, Y2_test = Y3_test, Y3_test = Y3_test, Y4_test = Y4_test):\n    global iteration__\n    start = time.time()\n    iteration__ += 1\n    gc.collect()\n    model = cnn(values)\n    test_preds = model.predict(X_test)[0]\n    if len(set(list(test_preds.reshape((-1)))))==1:\n        model = cnn(values)\n        test_preds = model.predict(X_test)[0]\n    loss = score(Y1_test.to_numpy(), test_preds)\n    print(iteration__, \"iteration loss = \", loss)\n    print('Time-taken = ', time.time()-start)\n    print()\n    return loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# x0 = []\n# y0 = np.array([])\n# for i in range(1,-1,-1):\n#     res = load('../input/bayesian1/result'+str(i)+'.pkl')\n#     x0 = x0 + res.x_iters\n#     y0 = np.concatenate([y0,res.func_vals])\n    \n# for i in range(2):\n#     res = load('../input/bayesian3/result'+str(i)+'.pkl')\n#     x0 = x0 + res.x_iters\n#     y0 = np.concatenate([y0,res.func_vals])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# res_gp = gp_minimize(objective, space, n_calls=50, x0=x0, y0=y0, n_random_starts=5)\n\n# \"Best score=%.4f\" % res_gp.fun","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res_gp = gp_minimize(objective, space, n_calls=40, n_random_starts=20)\n\n\"Best score=%.4f\" % res_gp.fun","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x0 = res_gp.x_iters\ny0 = res_gp.func_vals\n\nfor i in sorted(y0):\n    print(i, x0[np.where(y0==i)[0][0]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dump(res_gp, 'result.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best parameters:\")\nprint(\"- Dropout=\",res_gp.x[0])\nprint(\"- FocalLossWeight=\",res_gp.x[1])\nprint(\"- SkipFraction=\",res_gp.x[2])\nprint(\"- BatchNorm=\",res_gp.x[3])\nprint(\"- SkipType=\",res_gp.x[4])\nprint(\"- # Layers=\",res_gp.x[5])\nprint(\"- # Filters=\",res_gp.x[6])\nprint(\"- FocalLossGamma=\",res_gp.x[7])\nprint(\"- DenseNeurons=\",res_gp.x[8])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_convergence(res_gp)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_objective(res_gp)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_evaluations(res_gp)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res_loaded = load('result.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res_loaded.fun","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}