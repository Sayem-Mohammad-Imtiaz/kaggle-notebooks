{"cells":[{"metadata":{"id":"Mc5b3SgM8mCU"},"cell_type":"markdown","source":"## German Traffic Signs Recognition"},{"metadata":{"id":"R-6VNEzm8is-"},"cell_type":"markdown","source":"### GTSRB Dataset\n\nThe German Traffic Sign Benchmark is a multi-class, single-image classification database which has 43 different traffic signs under various sizes and in different conditions and sizes. It is a large, life-like database It has about 39000 training set images and 12000 test set images"},{"metadata":{"id":"ryfFMQh9ecwT"},"cell_type":"markdown","source":"**Verify NVIDIA GPU**"},{"metadata":{"id":"U7ULKMxUhSb3","outputId":"fe2db135-0297-469d-8aad-d2c8bc8ae903","trusted":true},"cell_type":"code","source":"!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{"id":"EE4Rgoyn-Mxn"},"cell_type":"markdown","source":"Importing Pandas and Numpy libraries. Numpy is used for supporting large multi-dimensional arrays and matrices. Pandas is built on top of Numpy which is used for data manipulation and analysis"},{"metadata":{"id":"bXLv4lzdhOTv","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"id":"NS4kBDHEAkMV"},"cell_type":"markdown","source":"Loading traing datasets"},{"metadata":{"id":"kz5k2vSvjcFz","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/gtsrb-german-traffic-sign/Train.csv')\ndf_train['Path'] = df_train['Path'].str.lower()\ndf_train['ClassId'] = df_train['ClassId'].apply(str)","execution_count":null,"outputs":[]},{"metadata":{"id":"I6fBy9izhOT7","outputId":"4c0480c1-708c-4200-82cc-36df95c417c8","trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"qiLNo0nWhOT-","outputId":"3c41e19d-8a61-4a1a-d0d4-c7b26278f375","trusted":true},"cell_type":"code","source":"df_train.tail()","execution_count":null,"outputs":[]},{"metadata":{"id":"SfbxJFaUCxrG"},"cell_type":"markdown","source":"**One Hot Encoding**: It refers to splitting the column which contains numerical categorical data to many columns depending on the number of categories present in that column. Each column contains “0” or “1” corresponding to which column it has been placed."},{"metadata":{"id":"IFB0OLJ5hOUA","outputId":"09b8a7e2-a22b-4527-eb6a-0d57e0603bfd","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nohe = OneHotEncoder(dtype='int8', sparse=False) #Sparse matrix: Most of the elements are zero. int8: Byte (-128 to 127)\ny_train = ohe.fit_transform(df_train['ClassId'].values.reshape(-1,1)) #Reshape:To make sure the new shape must be compatible with the original shape","execution_count":null,"outputs":[]},{"metadata":{"id":"SfJgouDeKU22"},"cell_type":"markdown","source":"**Data Preprocessing**\nIt is a technique that is used to convert the raw data into a clean data set. Basically, it means making the data feasible for data analysis from the raw data. This may involve providing the dimensions of the images and Normalizing the images.\n\nNormalizing means bringing the images into the same scale (i.e. between 0 to 1) by dividing the RGB values by 255. Following is the formula of Normalization\n\n![alt text](data:image/png;base64,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)\n\nThe following Data Preprocessing is done for the training dataset"},{"metadata":{"id":"N9nIaCyhhOUC","outputId":"4a4082d7-680a-4dbd-ddd4-0d71722b723a","trusted":true},"cell_type":"code","source":"import keras\nfrom tqdm import tqdm\nfrom keras.preprocessing import image\ntrain_img = []                          # Creating a list\nfor i in tqdm(range(df_train.shape[0])):\n    img = image.load_img('../input/gtsrb-german-traffic-sign/' + df_train['Path'][i], target_size = (64, 64, 3)) #Loading the images and giving the dimensions to the image\n    img = image.img_to_array(img)  #For converting images to arrays\n    img = img/255 #Normalizing the images by bringing them into same scale by dividing the RGB values by 255\n    train_img.append(img)   #Storing the preprocessed images in the list\nX = np.array(train_img)","execution_count":null,"outputs":[]},{"metadata":{"id":"Fbor3YgGo2T5"},"cell_type":"markdown","source":"Check the input shape of the images"},{"metadata":{"id":"jdt-B7IjhOUF","outputId":"90a90c7f-d653-448a-84da-40f371867b60","trusted":true},"cell_type":"code","source":"X.shape #Check the shape of training images","execution_count":null,"outputs":[]},{"metadata":{"id":"whX05xtco8-_"},"cell_type":"markdown","source":"**Display Sample Images**\n\nThis can be done with the help of matplotlib library, which is also useful for plotting graphs and creating figures"},{"metadata":{"id":"TK7bHhBFhOUH","trusted":true},"cell_type":"code","source":"import matplotlib \nfrom matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"id":"SE9tyJ8ehOUJ","outputId":"03c84bae-c8c3-4005-8576-1e087b64db72","trusted":true},"cell_type":"code","source":"plt.imshow(X[3909])     #Checking a particular image","execution_count":null,"outputs":[]},{"metadata":{"id":"So3KQ63bN8zO"},"cell_type":"markdown","source":"Similarly apply Read the test dataset and apply Data Preprocessing "},{"metadata":{"id":"E4TjZhFHhOUM","trusted":true},"cell_type":"code","source":"df_test = pd.read_csv('../input/gtsrb-german-traffic-sign/Test.csv')\ndf_test['Path'] = df_test['Path'].str.lower()\ndf_test['ClassId'] = df_test['ClassId'].apply(str)","execution_count":null,"outputs":[]},{"metadata":{"id":"tOz1RIVohOUO","outputId":"48abf39c-e0a7-4ef9-88b3-f63753da88bc","trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"ygDm-cnAhOUQ","outputId":"6d2e55b7-9937-4358-ebac-33f86ca36d4c","trusted":true},"cell_type":"code","source":"df_test.tail()","execution_count":null,"outputs":[]},{"metadata":{"id":"Je7mSwzbhOUS","outputId":"ce7fc900-9ebf-425a-a3df-20b93ac5334d","trusted":true},"cell_type":"code","source":"test_img = []\nfor i in tqdm(range(df_test.shape[0])):\n    img = image.load_img('../input/gtsrb-german-traffic-sign/' + df_test['Path'][i], target_size = (64, 64, 3))\n    img = image.img_to_array(img)\n    img = img/255\n    test_img.append(img)\ny = np.array(test_img)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"id":"pRlpzjc5hOUU","outputId":"30a7c530-67ac-43c0-ab74-9e9506406978","trusted":true},"cell_type":"code","source":"y.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"gRvHndg1hOUX","outputId":"9ffc7760-e2e0-44f9-c33f-58851bf0c437","trusted":true},"cell_type":"code","source":"plt.imshow(y[1000])","execution_count":null,"outputs":[]},{"metadata":{"id":"IAXOTCkmONy6"},"cell_type":"markdown","source":"## Architecture of the model\n\nThe architecture of the model can be modified as per your requirement by changing number of hidden layers, activation functions and other hyperparameters.\n\nIn this case, Convolutional Neural network (CNN/ConvNet) Architecture is used. It is a class of Neural Networks that specializes in processing the data that has a grid like topology, such as an image. Since the dataset primarily consists of images, CNN architecure would be suitable here. Following image illustrates the CNN architecture \n\n\n![alt text](https://miro.medium.com/max/1569/1*XbuW8WuRrAY5pC4t-9DZAQ.jpeg)\n\n\nActivation function, as the name suggests, is the function which calculates the weighted sum & decides whether to activate a neuron or not. \nOne such activation function applied in the input layers is the 'ReLU' function.\n\n![alt text](https://miro.medium.com/max/446/1*oePAhrm74RNnNEolprmTaQ.png)\n\nHere, z = Wx + b\n\nAlso called 'Rectified Linear Unit', ReLU is used because of its 2 advantages: Sparsity and Reduced likelihood of Vanishing Gradient problem.\n\nIn the output layer, Softmax function is used. This function, will squeeze the outputs for each class between 0 & 1 & would also divide by the sum of its outputs. It gives a probability of input being in a particular class.\n\n\n\n"},{"metadata":{"id":"OkPz6nCcOjc0"},"cell_type":"markdown","source":"Keras is an Open Source Neural Network library written in Python that runs on top of Theano or Tensorflow. It is designed to be modular, fast and easy to use. Most of the libraries required to create the architecture of the model requires Keras. \n\nLoading the necessary libraries required for the architecture for the model"},{"metadata":{"id":"2s-MmPx-hOUZ","trusted":true},"cell_type":"code","source":"from keras.models import Sequential  #Helps to create models in a layer by layer architecture\nfrom keras.layers import Dense   #Layers which are connected to each other    \nfrom keras.layers import Conv2D #Convolution 2D: Class of Neural networks that specializes in processing data that has a grid like topology such as an image. Creates a kernel which is further connected wth the input layer\nfrom keras.layers import AveragePooling2D #For reducing the spatial size of the images progressiviely. Average value is taken\nfrom keras.layers import Flatten #For converting the data into a 1-dimensional array for inputting it to the next layer.\nfrom keras.layers import Dropout #For ignoring some of the neurons during the training phase\nfrom keras.layers import BatchNormalization #Normalizes the output of previous activation layer. Inceases stability in the network","execution_count":null,"outputs":[]},{"metadata":{"id":"90xiyru2tXxK"},"cell_type":"markdown","source":"Since the model is to be create in a layer by layer architechure, Sequential() is useful in this case"},{"metadata":{"id":"NPWb3bAvhOUc","outputId":"52b51523-cdc9-4e75-d6b7-49c1ad241d71","trusted":true},"cell_type":"code","source":"model = Sequential()","execution_count":null,"outputs":[]},{"metadata":{"id":"CC-Ytdr8uD2E"},"cell_type":"markdown","source":"Below the the layer by layer architecture of the model. It is a Convolutional model with the input shape of dimensions 64*64. \nActivation Functions"},{"metadata":{"id":"BX6s1JpRhOUf","outputId":"a3377bc0-7f51-4062-c11f-df5f5bb102b0","trusted":true},"cell_type":"code","source":"model.add(Conv2D(64, (3, 3), input_shape = (64, 64, 3), activation = 'relu', name = 'first')) #No. of filters: 64: Used for determining No. of kernels to convolve with the input volume.\nmodel.add(AveragePooling2D(pool_size = (2, 2))) \nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.30)) \n\nmodel.add(Conv2D(64, (3, 3), activation = 'relu'))  #Activation: For deciding whether the neuron is to be activated or not by calculating weighted sum.\nmodel.add(AveragePooling2D(pool_size = (2, 2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.30))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(128, activation='relu')) #Units: No. of neurons/cells in a layer. ReLU is preffered beacuse of its sparsity and reduced likelihood of vanishing gradient problem \nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(16, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\nmodel.add(Dense(43, activation='softmax', name = 'last')) #Output layer. ","execution_count":null,"outputs":[]},{"metadata":{"id":"-D-ZLnYuV5uJ"},"cell_type":"markdown","source":"**Compiling the model**\n\nmodel.compile compiles the loss function, optimizer and metrics.\n\n**Loss Function**: It calculates how poorly our model is performing. It is the function which calculates the difference between the actual output and the predicted output (also known as loss), is called loss function.\n\nHere categorical cross-entropy is used. Categorical crossentropy will compare the distribution of the predictions (the activations in the output layer, one for each class) with the true distribution, where the probability of the true class is set to 1 and 0 for the other classes. This is suitible for the model since it has multiple classes\n\n**Optimizers**: Optimizers are used to update weights and biases i.e. the internal parameters of a model to reduce the error.\nIn this case, 'Adam' optimizer is used. Adam or Adaptive Movement Estimation calculates the individual adaptive learning rate for each parameter from estimates of first and second moments of the gradients. It is computationally efficient and has very little memory requirement\n\n**Metrics**: A metric is a function that is used to judge the performance of the model\n\nAccuracy: Calculates how often predictions matches labels."},{"metadata":{"id":"TvMFRnE2nP2N","outputId":"4243cf48-4cd6-4d01-9657-6fed896a9112","trusted":true},"cell_type":"code","source":"model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy']) #CCE: For Multiclass problems","execution_count":null,"outputs":[]},{"metadata":{"id":"VjYdc8TsgKkm"},"cell_type":"markdown","source":"**Check the summary of the model**\n\nIt prints a summary representation of the model.\nIt lists out the Layers, shapes and number of parameters each layer consists of. It also tells the notal number of parameters in the model along with trainable and non-trainable parameters."},{"metadata":{"id":"MC1n553ChOUh","outputId":"6bcf56a4-c3fa-40d2-ea79-489741aea01e","trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"tIdwV7ZAtLM8"},"cell_type":"markdown","source":"Splitting Data into training and test sets\n\nWith the help of train_test_split, the dataset can be split into traning and test sets separately. "},{"metadata":{"id":"1Z2jGw8ihOUj","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split #For splitting data into training and test sets","execution_count":null,"outputs":[]},{"metadata":{"id":"7XUgwd7EnZV5","trusted":true},"cell_type":"code","source":"train_df, df_validate = train_test_split(df_train, test_size = 0.30, random_state = 42) #Test_Size: By default 0.25, random_state: for generating random integers when the code is run\ntrain_df = train_df.reset_index(drop = True) #reset_index: sets a list of integer ranging from 0 to length of data as index.\ndf_test = df_test.reset_index(drop = True)\ndf_validate = df_validate.reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{"id":"ZrjY-eDCtSPh"},"cell_type":"markdown","source":"Show the counts of each class"},{"metadata":{"id":"ZctfFCL-niLG","outputId":"d8e71ee9-43be-4e22-f1a4-80f19ee34507","trusted":true},"cell_type":"code","source":"train_df['ClassId'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"jdWPR0zrnrNP","outputId":"4f7b503d-48a4-43f4-c98e-0ff78360fca8","trusted":true},"cell_type":"code","source":"df_validate['ClassId'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"ElkO8CmWtZXX"},"cell_type":"markdown","source":"Plotting the value counts into bar graph (For representaion purposes)"},{"metadata":{"id":"53hvU471nwwv","outputId":"dc687d65-4b5e-4d0a-f3cf-03b08d3d471e","trusted":true},"cell_type":"code","source":"train_df['ClassId'].value_counts().plot.bar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"eAYism-hn2xE","outputId":"1532d840-d7a6-4681-9984-346529dc3fde","trusted":true},"cell_type":"code","source":"df_validate['ClassId'].value_counts().plot.bar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"rsPyYvzMALb0"},"cell_type":"markdown","source":"Building image generator for training and validation dataset\n\nImageDataGenerator is used for artificially increasing the variations of images in our data-set by using horizontal/vertical flips, rotations, variations in brightness of images, horizontal/vertical shifts etc.\nThis is done to generalize the data and imporve the performance by giving variations."},{"metadata":{"id":"ix3aEnObn9pf","trusted":true},"cell_type":"code","source":"train_total = train_df.shape[0] #Gives first component of dimensions 'train_df'\nvalidate_total = df_validate.shape[0]\nbatch_size = 64","execution_count":null,"outputs":[]},{"metadata":{"id":"2IwvqmpwoA9g","trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator #Importing library for Generation of images","execution_count":null,"outputs":[]},{"metadata":{"id":"UIJqkISxoUjU","trusted":true},"cell_type":"code","source":"train_data_generator = ImageDataGenerator(\n        rotation_range = 15,\n        rescale = 1./255,\n        shear_range = 0.2,\n        zoom_range = 0.2,\n        horizontal_flip = True\n    )","execution_count":null,"outputs":[]},{"metadata":{"id":"ubfZCe-aoX7g","outputId":"611ada7c-9f11-48be-d39c-317ed57b2873","trusted":true},"cell_type":"code","source":"train_gen = train_data_generator.flow_from_dataframe(\n        dataframe = train_df,\n        directory = '../input/gtsrb-german-traffic-sign/',\n        x_col = 'Path',\n        y_col = 'ClassId',\n        target_size = (64, 64),\n        batch_size = batch_size,\n        class_mode = 'categorical',\n    )","execution_count":null,"outputs":[]},{"metadata":{"id":"i8WIJ3Vh5HtE","trusted":true},"cell_type":"code","source":"validate_data_generator = ImageDataGenerator(\n        rotation_range = 15,\n        rescale = 1./255, #Scaling the value from 0 to 1 from 0-255\n        shear_range = 0.2,\n        zoom_range = 0.2,\n        horizontal_flip = True\n)","execution_count":null,"outputs":[]},{"metadata":{"id":"FiSQUjX35H4w","outputId":"bcc151f7-af1f-408c-8490-9b0fab04401a","trusted":true},"cell_type":"code","source":"validate_gen = validate_data_generator.flow_from_dataframe(\n        dataframe = df_validate,\n        directory = '../input/gtsrb-german-traffic-sign/',\n        x_col = 'Path',\n        y_col = 'ClassId',\n        target_size = (64, 64),\n        batch_size = batch_size,\n        class_mode = 'categorical'\n )","execution_count":null,"outputs":[]},{"metadata":{"id":"ATn5gdFZJAdm"},"cell_type":"markdown","source":"### Train the model\n\nfit_generator: It trains the model over fixed number of epochs(iterations on a dataset)\n\nIn this, Epochs refers to the one pass over entire data\nsteps_per_epoch refers to the one update of the parameters\n\nThis is applied on both, training data and validation data generated."},{"metadata":{"id":"rLD614mW5ID0","outputId":"bb1bd7f9-2588-4f15-caac-c6d821526116","trusted":true},"cell_type":"code","source":"history = model.fit_generator(\n        train_gen,  \n        epochs = 50,   #One pass over the entire data\n        steps_per_epoch = 150, #One update of the parameters\n        validation_data = validate_gen,\n        validation_steps = 50\n  )\n","execution_count":null,"outputs":[]},{"metadata":{"id":"YcfGX8ZwJ5NU"},"cell_type":"markdown","source":"### Plotting the results on a graph"},{"metadata":{"id":"n6wFvKYapIov","outputId":"a33c7ebe-3adc-4705-e7e7-8985cc8d8f0e","trusted":true},"cell_type":"code","source":"# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"FruRdWEsxG-B","outputId":"c55467ff-18bf-4fc7-ccc9-2e9dd2ec6f64","trusted":true},"cell_type":"code","source":"!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Final Wording**"},{"metadata":{},"cell_type":"markdown","source":"That's all!! Thank you very much for going through my code. I'm new to Deep learning and Kaggle. This will be my first subbmission in Kaggle. Kindly suggest me what can I do to improve this model or what can I do better in my code. Your suggestions are most welcome!!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}