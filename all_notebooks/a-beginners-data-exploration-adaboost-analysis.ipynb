{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#A Beginners data exploration on data classification\n#Feel free to comment any input i might missed or anything that could improve this kernel\n\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Store the data in a dataframe\ndf = pd.read_csv('/kaggle/input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Print head\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get the number of rows and columns\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Count the missing values\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#View statistics\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#count the number of employees that left or stayed\ndf['Attrition'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualize the above number\nplt.figure(figsize=(10, 6))\nsns.countplot(df['Attrition'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#If the model guessed no all the times whats the possibility to be correct\n#The model has to beat this number\nno_guessing = round((1233 - 237) / 1233, 3)\nprint(no_guessing)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Show the employee attrition by age\nplt.figure(figsize=(18, 8))\nsns.countplot(x='Age', hue='Attrition', data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove some useless columns\ndf = df.drop('Over18', axis=1)\ndf = df.drop('EmployeeNumber', axis=1)\ndf = df.drop('StandardHours', axis=1)\ndf = df.drop('EmployeeCount', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get the correlation\ndf.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualize the correlation\nplt.figure(figsize=(25, 10))\nsns.heatmap(df.corr(), annot=True, fmt='.0%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Transform non numerical to numerical\nfor column in df.columns:\n    if df[column].dtype == np.number:\n        continue\n    else:\n        df[column] = LabelEncoder().fit_transform(df[column])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Bring attrition column in the first Position\ncols = list(df.columns.values)\n#cols\ndf = df[['Attrition',\n 'Age',\n 'BusinessTravel',\n 'DailyRate',\n 'Department',\n 'DistanceFromHome',\n 'Education',\n 'EducationField',\n 'EnvironmentSatisfaction',\n 'Gender',\n 'HourlyRate',\n 'JobInvolvement',\n 'JobLevel',\n 'JobRole',\n 'JobSatisfaction',\n 'MaritalStatus',\n 'MonthlyIncome',\n 'MonthlyRate',\n 'NumCompaniesWorked',\n 'OverTime',\n 'PercentSalaryHike',\n 'PerformanceRating',\n 'RelationshipSatisfaction',\n 'StockOptionLevel',\n 'TotalWorkingYears',\n 'TrainingTimesLastYear',\n 'WorkLifeBalance',\n 'YearsAtCompany',\n 'YearsInCurrentRole',\n 'YearsSinceLastPromotion',\n 'YearsWithCurrManager']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split the data\nX = df.iloc[:, 1:df.shape[1]]\nY = df.iloc[:, 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split the data ( 75% training and 25% testing )\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets find out the best params setup for a balanced model\nn_estimators_range = list(range(10, 200, 10))\nlearning_rate_range = np.arange(0.1, 2, 0.1)\nalgorithm_options = ['SAMME', 'SAMME.R']\n\nABC = AdaBoostClassifier(random_state=0)\n\nparam_grid = dict(n_estimators=n_estimators_range, learning_rate=learning_rate_range, algorithm=algorithm_options)\n\ngrid = GridSearchCV(ABC, param_grid, scoring='roc_auc', n_jobs=-1)\ngrid.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Show the scores\nprint('The best params are: {}'.format(grid.best_params_))\nprint()\nprint('The best score is: {}'.format(grid.best_score_))\nprint()\nprint('The mean cross-validated score is: {}'.format(grid.score(X_test, Y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Use AdaBoost\nforest = AdaBoostClassifier(n_estimators=130, learning_rate=1.3, random_state=0, algorithm='SAMME')\nforest.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get the accuracy on the training data set\nround(forest.score(X_train, Y_train), 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Show the classification report\nprediction = forest.predict(X_test)\ntarget_names = ['TP + FP', 'TN + FN']\nprint(classification_report(Y_test, prediction, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Show the confusion matrix and accuracy score for the model on the test data\ncm = confusion_matrix(Y_test, forest.predict(X_test))\nTP = cm[0][0]\nFP = cm[0][1]\nFN = cm[1][0]\nTN = cm[1][1]\nprint()\nprint(cm)\nprint()\nprint('True positive is: {}'.format(TP))\nprint('False positive is: {}'.format(FP))\nprint('False negative is: {}'.format(FN))\nprint('True negative is: {}'.format(TN))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Model beeing correct guessing only no = {}'.format(no_guessing))\nprint('Model Testing Accuracy = {}'.format(round(forest.score(X_test, Y_test), 3)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Show the prediction score ( The ability of the model not to predict attrit for the employees that actually wont attrit)\nround(precision_score(Y_test, prediction), 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Show the recall score (What percentage of employees that end up attriting does the model succesfully find )\nround(recall_score(Y_test, prediction), 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Show the f1 score\nround(f1_score(Y_test, prediction), 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Inspect which feature contributes more to attrition\nfeat_importances = pd.Series(forest.feature_importances_, index=X.columns)\nplt.figure(figsize=(20, 10))\nfeat_importances.nlargest(20).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#As we see from the above plot the 2 variables that contribute more is 1: Monthly income, 2: Total working years\n\n\n#A Beginners data exploration on data classification\n#Feel free to comment any input i might missed or anything that could improve this kernel","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}