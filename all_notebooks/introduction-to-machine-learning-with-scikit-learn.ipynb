{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction to Machine Learning with Scikit Learn \n\n#### What is machine learning?\n\nThere are many ways to describe what is machine learning, you can find one at https://www.ibm.com/cloud/learn/machine-learning\n\n\nI like what Addreas Mueller described in the youtube video https://www.youtube.com/watch?v=4PXAztQtoTg:\n> Predictive Modeling 101: Make predictions of outcome of repeated events.\n> Machine learning is useful when the frequency of the repetitive envent is high, or the historical observations or data is large, and an individual mistake is not too costly \n\n> All models are wrong, but some are useful - George Box\n\nScikit Learn - Library of Machine Learning algorithms, built on top of Python, NumPy, SciPy, Cython https://scikit-learn.org/\n\nNow let's build a model using the KC house data set from https://www.kaggle.com/harlfoxem/housesalesprediction to predict house price\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n# np.set_printoptions(suppress=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Get the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/housesalesprediction/kc_house_data.csv')\nprint(f\"sample size = {df.shape[0]}\\nnumber of columns = {df.shape[1]}\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the data type and statistics"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory data analysis\n\nCheck the house price distributions"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(12,5))\nax1.hist(df['price']/1000000, bins=50)\nax2.hist(df['price']/1000000, bins=50)\nax2.set_xlim(0,2)\nax2.set_xlabel('price in millions')\nax3.boxplot(df['price']/1000000);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above plot we see the house price has a long tail with a few very expensive houses, but most house prices are below 2 million dollrs, we could remove the house sample with price over 2 millions which are outliers based on the statistic boxplot"},{"metadata":{"trusted":true},"cell_type":"code","source":"# the % house price over 2 millions\n(df['price'] > 2000000).mean() * 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So the houses which have price above 2 millions only count for less than 1% of all house data, we can simply remove them"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[df['price'] <= 2000000]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the correlations"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr().style.background_gradient(cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above correlation data may not display the color gird properly, as in github for example. Without color grid, it is hard to visualize the different correlations. So let's also plot the heatmap of correlations."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nfig.set_size_inches(15, 8)\nsns.heatmap(df.corr().round(4), annot=True, ax=ax);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the corralation related to house price "},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(df.corr()['price'].sort_values(ascending=False)).style.background_gradient(cmap='coolwarm')#.set_precision(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we see sqrt_living and sqrt_above has very high corrlation of 0.87. Let's visualize it below:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x='sqft_living', y='sqft_above', data=df);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"sqrt_living has the highest correlation price, so we can keep sqrt_living and remove the correlated sqrt_above from our feature when train model. Now let's visualize relationship between sqft_living and price"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x='sqft_living', y='price', data=df);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We also see that yr_built has a low correlation with price, which is a little counter intuitive, so let's plot the relationship between yr_built and price"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x='yr_built', y='price', data=df);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The result show that year built does not really have meaningful impact to price"},{"metadata":{},"cell_type":"markdown","source":"Plot the correlation between loaction and price"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(1,2, sharey=True)\nfig.set_size_inches(12,6)\nax[0].scatter(x='lat', y='price', data=df, alpha=0.2)\nax[1].scatter(x='long', y='price', data=df, alpha=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above it show that most expensive houses are located at above latitude of 47.5, so we can add a feature to denote if it is above 47.5 latitude, we then convert the value to 1 if it is True and to 0 if it is False, so it can be feed into model. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df['above_47.5_lat'] = (df['lat'] > 47.5).astype(int)\ndf['above_47.5_lat'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now lets compare its correlation with price:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['price', 'above_47.5_lat']].corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see the correlation increased from 0.362183 of \"lat\" to 0.4367 of out new feature \"above_47.5_lat\""},{"metadata":{},"cell_type":"markdown","source":"## Select features\n\nwhat feature(s) do we want to pick?\n\nLet's first do a simply model that only consider one feature of sqft_living. Then we will choose multiple features to to train model to compare model performance from the two approaches.\n\n1. Model with only one feature: sqft_living\n2. Model with mutiple features: we already see that sqrt_above is highly correlated with sqft_living so we exclude it from the feature, we will pick the features that has corr value above 0.2:\nsqft_living, grade, sqft_living15, bathrooms, lat, view, bedrooms, sqft_basement, floors\n3. Replace \"lat\" feature with re-engineered new feature of \"above_47.5_lat\"\n\nUncomment the below code to try both feature selection approaches"},{"metadata":{"trusted":true},"cell_type":"code","source":"# features = ['sqft_living']\nfeatures  = ['sqft_living', 'grade', 'sqft_living15', 'bathrooms','lat', 'view', 'bedrooms', 'sqft_basement', 'floors']\nfeatures  = ['sqft_living', 'grade', 'sqft_living15', 'bathrooms','above_47.5_lat', 'view', 'bedrooms', 'sqft_basement', 'floors']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get the training features as X"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df[features]#.to_numpy()\nprint(X.shape)\nX.iloc[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get the target labels as y. Here we have lower case y to denote it as vector, not matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df['price']#.to_numpy()\n# y = y[:, None]\ny.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split training and test data\n\nHere we choose 80/20 split where we use 80% of sample data to train model, and set aside 20% of sample to test the model prediction. We also set random_state so we can the same random sample for train and test for model evaluation later"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nx_train.shape, x_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Defind a linear regression model\n\nusing default hyper paramters https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n\nLinearRegression fits a linear model with coefficients w = (w1, …, wp) to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build a model with all default parameters\nmodel = LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fit/train the model\nWe can see how simple the scikit learn provided API is for train a model, simply call the fit method."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict price using the test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(x_test)\ny_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluate the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# coefficient of determination - how well observed outcomes are replicated by the model, with 1 be the perfect score, it can have negative score because the model can be arbitrarily worse\nprint('R squared = ', model.score(x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_absolute_error(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Ratio of mean absolute error to the mean true outcomes: ', mean_absolute_error(y_test, y_pred) / y_test.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the error distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.displot((y_pred - y_test).values, kde=True)\nplt.title('prediction error/residual distribution')\nplt.xlabel('prediction error')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see the prediction error is normal distributed with center around 0"},{"metadata":{},"cell_type":"markdown","source":"## Results:\n\nHere we see for single feature of sqrt_living, our model got R squared score of 0.465, and mean_absolute_error of 153402 which counts about 30% of the mean price\n\nWhen we increase to 9 features we achieved score of 0.657, which is a big improvment, and mean_absolute_error reduced to 115007 which now counts only about 22% of the mean price\n\nwe can further improve it by re-engineer the feature of lat into a new feature of above_47.5_lat, doing so we further improved score to 0.685, and reduced mean_absolute_error to 110659 which now counts only about 21% of the mean price"},{"metadata":{},"cell_type":"markdown","source":"## Look inside the model:  model parameters and how model predict price\n\nExamine the model coefficients/theta(1-n) and intercept/theta0"},{"metadata":{"trusted":true},"cell_type":"code","source":"theta = model.coef_\nprint(\"Model coefficents/theta(1-n):\\n\", theta)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"theta0 = model.intercept_\nprint('The model intercept/theta(0): ', theta0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How model predict the price? \n\nThe price is calculated as: $$h_{\\theta}(X)=\\theta_{0}+\\theta_{1}x_{1}+\\theta_{2}x_{2}+...+\\theta_{n}x_{n}$$ \n\nWhere $\\theta_{0}$ is the intercept, and $\\theta_{1}...\\theta_{n}$ are the coefficients. This can be calculated very efficiently using matrix multiplication of coefficients and X features, then plus the intercept scalar value as:\n\n```coefficients @ X + intercept``` \n\nNow let's calculate the prediction using the coefficients and intercept for the first test sample, it should match the first value from y_pred"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_input = x_test.head(1).values[0]\nprint('first test input is:\\n', test_input)\n\npredicted_price = theta @ test_input + theta0\nprint('\\nCalculated prediction is:\\t\\t\\t', predicted_price)\n\nprint('The first predicted model from y_pred is:\\t', y_pred[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot the predicted price and price against the input features\n\nLet's first build a dataframe with test features, target label, and prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = x_test.copy()\ndf_test['price'] = y_test\ndf_test.reset_index(inplace=True)\ndf_test['pred'] = y_pred.round()\ncolumns = features + ['price','pred']\ndf_test[columns]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot the target price/prediction against top (3) features"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_scatter(ax, by):\n    ax.scatter(df_test[by], df_test['price'], alpha=0.3, label='real_price')\n    ax.scatter(df_test[by], df_test['pred'], alpha=0.3, label='prediction')\n    ax.set_title('house price by ' + by)\n    ax.legend()\n\n# plot top n features\nn = 3 if len(features) > 3 else len(features)\nfig, ax = plt.subplots(1, n, sharey=True)\nfor i in range(n):\n    fig.set_size_inches(6*n,6)\n    if isinstance(ax, np.ndarray):\n        plot_scatter(ax[i], features[i])\n    else:\n        plot_scatter(ax, features[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Want to better understand the how the model gets trained and the mathematics behind it?\n\nIn this exercise we built a LinearRegression model to predice new outcomes based on the historical outcomes or events, for additional information on the linear regression model please refer to https://scikit-learn.org/stable/modules/linear_model.html\n\nTo better understand the mathematics behind the model, I highly recommend the popular machine learning course from coursera: https://www.coursera.org/learn/machine-learning"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}