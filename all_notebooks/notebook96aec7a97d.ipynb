{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\npd.set_option('display.max_columns', None)\n\n# Leitura do .csv usando a biblioteca do Python pandas\ndf = pd.read_csv(\"../input/aula-2-ia-dataset/CasasParaAlugar.csv\", index_col = 0)\n\n# FEATURES_ANALISAR = ['city', 'area', 'rooms', 'bathroom', 'parking spaces', 'floor', \n#                      'animal', 'furniture', 'hoa (R$)', 'rent amount (R$)', 'property tax (R$)', \n#                      'fire insurance (R$)', 'total (R$)']\n\n# df = df.loc[:, FEATURES_ANALISAR]\n# df\n\n# Tamanho do dataset\nprint(\"{} linhas\\n{} colunas/features.\".format(df.shape[0], df.shape[1]))\n\n################# Medição, deleção e imputação de dados ausentes ################# \n\n# # Funcao do Pandas usada para contar o numero de valores vazios de cada coluna\ndata = df.isna().sum(axis=0)\n\ny = list(range(df.shape[1]))\nx = data.values\n\n# Criamos uma figura\nfig, ax = plt.subplots(figsize=(8, 10))\n\n# Plota as barras\nax.barh(y=y, width=x)\n\n# Adiciona informações no gráfico\nax.set_yticks(y)\nax.set_yticklabels(df.columns.values)\nax.set_title(\"Quantidade de variáveis ausentes por coluna\")\nplt.show()\n\n\n######################### LIMPEZA DO DATASET #########################\n########### Imputação de dados por Regressão Linear (apenas para colunas numéricas) ########### \n\n# Criamos um dataframe com os dados das respectivas colunas:\n# 'area', 'rooms', 'bathroom', 'parking spaces', 'hoa (R$)', 'rent amount (R$)', 'property tax (R$)', 'fire insurance (R$)', 'total (R$)'\ndf_imput_regress = pd.concat([df['area'], df['rooms'], df['bathroom'], df['parking spaces'], df['hoa (R$)'], df['rent amount (R$)'], df['property tax (R$)'], df['fire insurance (R$)'], df['total (R$)']], axis=1)\ndf_imput_regress.head()\n\n## Aplicação da Regressão Linear ##\n\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\n# Criamos um objeto que fará a Imputação por Regressão\nimp_mean = IterativeImputer(random_state = 0)\n\n# Treinamos a regressão com os dados disponiveis\nimp_mean.fit(df_imput_regress.values)\n\n# Agora, faremos uma regressão nos mesmos dados usados no treinamento, para\n# gerar valores numéricos para substituir os valores ausentes de LotFrontage\nX = df_imput_regress.values\nregr_output = imp_mean.transform(X)\nregr_output\n\n## Substituição dos dados treinados para o dataset real:\n\ndf['area'] = regr_output[:, 0]\ndf['rooms'] = regr_output[:, 1]\ndf['bathroom'] = regr_output[:, 2]\ndf['parking spaces'] = regr_output[:, 3]\ndf['hoa (R$)'] = regr_output[:, 4]\ndf['rent amount (R$)'] = regr_output[:, 5]\ndf['property tax (R$)'] = regr_output[:, 6]\ndf['fire insurance (R$)'] = regr_output[:, 7]\ndf['total (R$)'] = regr_output[:, 8]\n\n# df\n\n## Confirmação que não restam mais valores nulos nas colunas\ndf['area'].isna().sum()\ndf['rooms'].isna().sum()\ndf['bathroom'].isna().sum()\ndf['parking spaces'].isna().sum()\ndf['hoa (R$)'].isna().sum()\ndf['rent amount (R$)'].isna().sum()\ndf['property tax (R$)'].isna().sum()\ndf['fire insurance (R$)'].isna().sum()\ndf['total (R$)'].isna().sum()\n\n########### Imputação de dados via maior frequência (apenas para colunas nominais) ########### \n# NominalCategorical = ['city', 'animal', 'furniture']\n\ndf['city'].value_counts()\ndf['animal'].value_counts()\ndf['furniture'].value_counts()\ndf['floor'].value_counts()\n\n\n#.fillna substitui o argumento nos dados ausentes\ndf['city'] = df['city'].fillna('São Paulo')\ndf['animal'] = df['animal'].fillna('acept')\ndf['furniture'] = df['furniture'].fillna('not furnished')\ndf['floor'] = df['floor'].fillna('1')\n\n# Substituindo o \"-\" na coluna floor por \"0\"\ndf['floor'] = df['floor'].str.replace('-','0')\n# df\n\n########### OUTLIERS ###########\n\nNominalCategorical = ['city', 'animal', 'furniture']\nOrdinalCategorical = ['floor'] \nNumeric = ['area', 'rooms', 'bathroom', 'parking spaces', 'hoa (R$)', 'rent amount (R$)', 'property tax (R$)', 'fire insurance (R$)', 'total (R$)']\n\n## Detecção visual\n\n####### TESTE 1\nselected_columns = Numeric + OrdinalCategorical\ndf[selected_columns].head()\n\nfig, ax = plt.subplots()\n\nax.scatter(x=df['rooms'], y=df['bathroom'])\nplt.show()\n\n###### TESTE 2\nselected_columns = Numeric + OrdinalCategorical\ndf[selected_columns].head()\n\nfig, ax = plt.subplots()\n\n# Valores acima de 50.000 seram excluídos \nax.scatter(x=df['property tax (R$)'], y=df['fire insurance (R$)'])\nplt.show()\n\nprint(\"Tamanho do dataset antes dos filtros: {}\".format(df.shape))\n\nmask = df['property tax (R$)'] < 50000\ndf = df[mask]\n\nprint(\"Tamanho do dataset depois dos filtros: {}\".format(df.shape))\n\n# df\n\n## FEATURE ENGINEERING -> SOMA DO RENT AMOUNT + PROPERTY TAX = coluna \"amount total rent\"\n\ndf['amount total rent'] = df['rent amount (R$)'] + df['property tax (R$)']\ndf[['amount total rent', 'rent amount (R$)', 'property tax (R$)']]\n\n## FEATURE SELECTION -> Descartar uma feature usando o teste f-regression\n\n# df\n\ncolunasSelecionadas = ['floor','area', 'rooms', 'bathroom', 'parking spaces', 'hoa (R$)', 'rent amount (R$)', 'property tax (R$)', 'fire insurance (R$)', 'total (R$)']\n\nx = df[colunasSelecionadas]\ny = df['total (R$)']\n\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.feature_selection import f_regression\n\n# k é o numero de features que NÃO serão jogadas foras. Vamos primeiro ver os resultados, depois eliminar alguma feature.\nk = x.shape[1]\n# Utilizamos um método do sklearn para isso, usando a estratégia Chi Squared.\nselector = SelectKBest(f_regression, k=k)\nx_new = selector.fit_transform(x, y)\n\n# Utilizo o log10 pois os valores são ou muito grandes, ou muito pequenos\nscores = -np.log10(selector.pvalues_)\n\nx_plot = list(range(len(scores)))\n\nfig, ax = plt.subplots(figsize=(8, 4))\nplt.bar(x_plot, scores)\nax.set_title(\"Score do método f-regression para Feature Selection\")\nax.set_xticks(x_plot)\nax.set_xticklabels(selected_columns, rotation=45)\nplt.show()\n\n## A feature \"area\" apresenta os menores resultados, e elimina-se a mesma do dataset\n\nprint(\"Tamanho do dataset antes dos filtros: {}\".format(df.shape))\n\n# df = df.drop(['area'], axis=1)\n\nprint(\"Tamanho do dataset depois dos filtros: {}\".format(df.shape))\n\n\n### FEATURE ENCODING ###\n# Furniture possui dois valores: \"furnished\" or \"not furnished\"\n\ndf['furniture'].value_counts()\n\ndf['furniture'].replace(to_replace='furnished', value=1, inplace=True)\ndf['furniture'].replace(to_replace='not furnished', value=0, inplace=True)\n\ndf['furniture'].value_counts()\n\n######## DATA SCALING #######\n\ncolunas = ['floor','area', 'rooms', 'bathroom', 'parking spaces', 'hoa (R$)', 'rent amount (R$)', 'property tax (R$)', 'fire insurance (R$)', 'total (R$)']\n\n\ndf[colunas].describe()\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ndata = df[colunas]\nscaler.fit(data)\n\n# Reescalonamos os dados\ndata_scaled = scaler.transform(data)\n\n# Criamos um dataframe para facilitar a visualização\ndata_scaled = pd.DataFrame(data_scaled)\n# \"Devolvemos\" os nomes das features e os índices para o dataframe\ndata_scaled.columns = colunas\ndata_scaled.index = df.index\n\ndata_scaled.describe()\n\ndf = df.drop(colunas, axis=1)\ndf = pd.concat([df, data_scaled], axis=1)\n\ndf\n\n\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-07T02:19:40.123064Z","iopub.execute_input":"2021-06-07T02:19:40.123422Z","iopub.status.idle":"2021-06-07T02:19:41.496717Z","shell.execute_reply.started":"2021-06-07T02:19:40.123389Z","shell.execute_reply":"2021-06-07T02:19:41.495937Z"},"trusted":true},"execution_count":null,"outputs":[]}]}