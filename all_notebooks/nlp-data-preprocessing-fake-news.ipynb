{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Necessary Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nimport re","metadata":{"execution":{"iopub.status.busy":"2021-07-31T11:32:58.347841Z","iopub.execute_input":"2021-07-31T11:32:58.348391Z","iopub.status.idle":"2021-07-31T11:32:58.355196Z","shell.execute_reply.started":"2021-07-31T11:32:58.348341Z","shell.execute_reply":"2021-07-31T11:32:58.353835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading fake and real news data from two different files\nfake_news = pd.read_csv(\"../input/fake-and-real-news-dataset/Fake.csv\")\nreal_news = pd.read_csv(\"../input/fake-and-real-news-dataset/True.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-07-31T11:32:58.356975Z","iopub.execute_input":"2021-07-31T11:32:58.357358Z","iopub.status.idle":"2021-07-31T11:32:59.8957Z","shell.execute_reply.started":"2021-07-31T11:32:58.357325Z","shell.execute_reply":"2021-07-31T11:32:59.894543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setting Label for Fake and Real Newa\n","metadata":{}},{"cell_type":"code","source":"# Considering 0 for fake news and 1 for real news\nfake_news[\"label\"] = 0\nreal_news[\"label\"] = 1","metadata":{"execution":{"iopub.status.busy":"2021-07-31T11:32:59.89745Z","iopub.execute_input":"2021-07-31T11:32:59.897794Z","iopub.status.idle":"2021-07-31T11:32:59.905027Z","shell.execute_reply.started":"2021-07-31T11:32:59.897761Z","shell.execute_reply":"2021-07-31T11:32:59.90397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking Data Distribution","metadata":{}},{"cell_type":"code","source":"fig = plt.figure()\nax = fig.add_axes([0,0,1,1])\ncats = ['Fake', 'Real']\nsamples = [fake_news.shape[0],real_news.shape[0]]\nax.bar(cats,samples)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-31T11:32:59.906901Z","iopub.execute_input":"2021-07-31T11:32:59.907556Z","iopub.status.idle":"2021-07-31T11:33:00.028426Z","shell.execute_reply.started":"2021-07-31T11:32:59.907415Z","shell.execute_reply":"2021-07-31T11:33:00.027198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration (Fake News)","metadata":{}},{"cell_type":"code","source":"fake_news_words = pd.Series(' '.join(fake_news['text']).split())\n\nwordcloud = WordCloud(width = 1000, height = 500).generate(' '.join(fake_news_words))\nplt.figure(figsize=(15,8))\nplt.imshow(wordcloud)\nplt.title(\"Most Frequent Words Used in Fake News\")\nplt.axis(\"off\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-31T11:33:00.029819Z","iopub.execute_input":"2021-07-31T11:33:00.030166Z","iopub.status.idle":"2021-07-31T11:33:00.033608Z","shell.execute_reply.started":"2021-07-31T11:33:00.030132Z","shell.execute_reply":"2021-07-31T11:33:00.032833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration (Real News)","metadata":{}},{"cell_type":"code","source":"real_news_words = pd.Series(' '.join(real_news['text']).split())\n\nwordcloud = WordCloud(width = 1000, height = 500).generate(' '.join(real_news_words))\nplt.figure(figsize=(15,8))\nplt.imshow(wordcloud)\nplt.title(\"Most Frequent Words Used in Real News\")\nplt.axis(\"off\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-31T11:33:00.034579Z","iopub.execute_input":"2021-07-31T11:33:00.034864Z","iopub.status.idle":"2021-07-31T11:33:00.048674Z","shell.execute_reply.started":"2021-07-31T11:33:00.034836Z","shell.execute_reply":"2021-07-31T11:33:00.047625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Combining Two different CSV Files","metadata":{}},{"cell_type":"code","source":"# Combining fake and real data together as they are in seperate file\ndata = pd.concat([fake_news,real_news], axis=0,ignore_index = True)\n\n# Shuffling The Dataset after combining fake and real news\ndata = shuffle(data)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T11:33:00.050083Z","iopub.execute_input":"2021-07-31T11:33:00.050537Z","iopub.status.idle":"2021-07-31T11:33:00.083471Z","shell.execute_reply.started":"2021-07-31T11:33:00.050489Z","shell.execute_reply":"2021-07-31T11:33:00.082465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration (Links & Tags)","metadata":{}},{"cell_type":"code","source":"all_text_data = np.array(data['text'])\n\nall_urls = []\nfor i in tqdm(range(0,data.shape[0])):\n    r = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n    urls = r.findall(all_text_data[i])\n    all_urls = all_urls + urls\n\nprint('Total URLS: ', len(all_urls),'\\n\\n')\n    \n\nall_tags = []\nfor i in tqdm(range(0,data.shape[0])):\n    r = re.compile('<.*?>')\n    tags = r.findall(all_text_data[i])\n    all_tags = all_tags + tags\n    \nprint('Total Tags: ', len(all_tags))","metadata":{"execution":{"iopub.status.busy":"2021-07-31T11:33:00.08708Z","iopub.execute_input":"2021-07-31T11:33:00.08767Z","iopub.status.idle":"2021-07-31T11:33:00.947687Z","shell.execute_reply.started":"2021-07-31T11:33:00.087619Z","shell.execute_reply":"2021-07-31T11:33:00.946617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking Null or Missing Values","metadata":{}},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-31T11:33:00.949159Z","iopub.execute_input":"2021-07-31T11:33:00.949478Z","iopub.status.idle":"2021-07-31T11:33:00.984353Z","shell.execute_reply.started":"2021-07-31T11:33:00.949447Z","shell.execute_reply":"2021-07-31T11:33:00.983255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dropping unnecessary columns","metadata":{}},{"cell_type":"code","source":"# Dropping unnecessary columns from dataset\ndata.drop([\"title\",\"subject\",\"date\"], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T11:33:00.985854Z","iopub.execute_input":"2021-07-31T11:33:00.986219Z","iopub.status.idle":"2021-07-31T11:33:00.998983Z","shell.execute_reply.started":"2021-07-31T11:33:00.986187Z","shell.execute_reply":"2021-07-31T11:33:00.998116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating Dependent and Independent variables","metadata":{}},{"cell_type":"code","source":"X = np.array(data['text'])\ny = np.array(data[\"label\"])","metadata":{"execution":{"iopub.status.busy":"2021-07-31T11:33:01.017703Z","iopub.execute_input":"2021-07-31T11:33:01.018627Z","iopub.status.idle":"2021-07-31T11:33:01.048845Z","shell.execute_reply.started":"2021-07-31T11:33:01.018568Z","shell.execute_reply":"2021-07-31T11:33:01.047394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper Functions for Data Preprocessing","metadata":{}},{"cell_type":"code","source":"!pip install beautifulsoup4\nfrom bs4 import BeautifulSoup\n# \ndef remove_tags(html):\n    # parse html content\n    soup = BeautifulSoup(html, \"html.parser\")\n  \n    for data in soup(['style', 'script']):\n        # Remove tags\n        data.decompose()\n    # return data by retrieving the tag content\n    return ' '.join(soup.stripped_strings)\n\ndef remove_link_from(text):\n    URLless_string = re.sub(r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}     /)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»“”‘’]))', '', text)\n    return URLless_string","metadata":{"execution":{"iopub.status.busy":"2021-07-31T11:33:01.050772Z","iopub.execute_input":"2021-07-31T11:33:01.05112Z","iopub.status.idle":"2021-07-31T11:33:08.277854Z","shell.execute_reply.started":"2021-07-31T11:33:01.051089Z","shell.execute_reply":"2021-07-31T11:33:08.276499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"ps = PorterStemmer()\ncorpus=[]\n\nfor i in tqdm(range(0,len(X))):\n    #Data Cleaning only considerin the alphabets\n    review = re.sub(\"[^a-zA-Z]\",\" \",X[i])\n    \n    #Lowering the cases\n    review = review.lower()\n    \n    #Removing Links from texts\n    review = remove_link_from(review)\n    \n    #Removing tags from texts\n    review = remove_tags(review)\n    \n    #Splitting sentence into words\n    review = review.split()\n    \n    #Stemming\n    #Stropwords removing\n    review = [ps.stem(word) for word in review if word not in stopwords.words(\"english\")]\n    \n    #Joining the words again\n    review = ' '.join(review)\n    corpus.append(review)\n    \nX = corpus","metadata":{"execution":{"iopub.status.busy":"2021-07-31T11:33:08.280208Z","iopub.execute_input":"2021-07-31T11:33:08.280578Z","iopub.status.idle":"2021-07-31T11:33:20.015221Z","shell.execute_reply.started":"2021-07-31T11:33:08.280543Z","shell.execute_reply":"2021-07-31T11:33:20.014015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving Preprocessed Data","metadata":{}},{"cell_type":"code","source":"processed_data = {\"text\": X, \"label\": y}\nprocessed_df = pd.DataFrame(processed_data)\nprocessed_df.to_csv('preprocessed-combined-dataset.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-31T11:38:10.040106Z","iopub.execute_input":"2021-07-31T11:38:10.040487Z","iopub.status.idle":"2021-07-31T11:38:10.06268Z","shell.execute_reply.started":"2021-07-31T11:38:10.040454Z","shell.execute_reply":"2021-07-31T11:38:10.061246Z"},"trusted":true},"execution_count":null,"outputs":[]}]}