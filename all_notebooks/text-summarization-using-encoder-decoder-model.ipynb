{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport re\nimport unicodedata\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tqdm import tqdm\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, TimeDistributed, Layer\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BASE_DIR = '../input/news-summary'\nSTART_TOKEN = '<start> '\nEND_TOKEN = ' <end>'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!ls {BASE_DIR}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_data():\n    \"\"\"Read the data.\"\"\"\n    news1_df = pd.read_csv('../input/news-summary/news_summary.csv', encoding='latin-1', usecols=['headlines', 'text'])\n    news2_df = pd.read_csv('../input/news-summary/news_summary_more.csv', encoding='latin-1')\n    \n    return pd.concat([news1_df, news2_df], axis=0).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df = read_data()\nfull_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_head(limit=5):\n    for idx in range(limit):\n        print(f'TITLE: {full_df[\"headlines\"][idx]}\\nTEXT: {full_df[\"text\"][idx]}\\n')\nprint_head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(text):\n    \"\"\"Preprocess the given text.\"\"\"\n    \n    # Encode to ascii\n    text = ''.join(\n        c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn'\n    )\n    \n    # To lowercase\n    text = text.lower()\n\n    text = re.sub(\"(\\\\t)\", ' ', text)  #remove escape charecters\n    text = re.sub(\"(\\\\r)\", ' ', text)\n    text = re.sub(\"(\\\\n)\", ' ', text)\n    text = re.sub(\"(__+)\", ' ', text)   #remove _ if it occors more than one time consecutively\n    text = re.sub(\"(--+)\", ' ', text)   #remove - if it occors more than one time consecutively\n    text = re.sub(\"(~~+)\", ' ', text)   #remove ~ if it occors more than one time consecutively\n    text = re.sub(\"(\\+\\++)\", ' ', text)   #remove + if it occors more than one time consecutively\n    text = re.sub(\"(\\.\\.+)\", ' ', text)   #remove . if it occors more than one time consecutively\n    text = re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", ' ', text) #remove <>()|&©ø\"',;?~*!\n    text = re.sub(\"(mailto:)\", ' ', text)  #remove mailto:\n    text = re.sub(r\"(\\\\x9\\d)\", ' ', text)  #remove \\x9* in text\n    text = re.sub(\"([iI][nN][cC]\\d+)\", 'INC_NUM', text)  #replace INC nums to INC_NUM\n    text = re.sub(\"([cC][mM]\\d+)|([cC][hH][gG]\\d+)\", 'CM_NUM', text)  #replace CM# and CHG# to CM_NUM\n    text = re.sub(\"(\\.\\s+)\", ' ', text)  #remove full stop at end of words(not between)\n    text = re.sub(\"(\\-\\s+)\", ' ', text)  #remove - at end of words(not between)\n    text = re.sub(\"(\\:\\s+)\", ' ', text)  #remove : at end of words(not between)\n    text = re.sub(\"(\\s+.\\s+)\", ' ', text)  #remove any single charecters hanging between 2 spaces\n\n    #Replace any url as such https://abc.xyz.net/browse/sdf-5327 ====> abc.xyz.net\n    try:\n        url = re.search(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)', text)\n        repl_url = url.group(3)\n        text = re.sub(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)',repl_url, text)\n    except:\n        pass #there might be emails with no url in them\n\n    text = re.sub(\"(\\s+)\",' ',text) #remove multiple spaces\n    text = re.sub(\"(\\s+.\\s+)\", ' ', text) #remove any single charecters hanging between 2 spaces\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfull_df['headlines'] = full_df['headlines'].apply(preprocess)\nfull_df['text'] = full_df['text'].apply(preprocess)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# After preprocessing\nprint_head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Max length analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"text_lens = full_df['text'].str.split().apply(len)\nheadline_lens = full_df['headlines'].str.split().apply(len)\n\nplt.figure(figsize=(12, 6))\n\nplt.subplot(1, 2, 1)\nsns.distplot(headline_lens)\nplt.title('Headlines length distribution')\n\nplt.subplot(1, 2, 2)\nsns.distplot(text_lens)\nplt.title('Text length distribution')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking mean lengths\nprint(f'Mean headline length: {headline_lens.mean()}')\nprint(f'Mean text length: {text_lens.mean()}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check how much % of headlines have 0-15 words\nprint(f\"Headlines having length in range [0, 15]: {len(headline_lens[headline_lens <= 15])/len(headline_lens)}\")\n\n# Check how much % of text have 0-62 words\nprint(f\"Text having length in range [0, 62]: {len(text_lens[text_lens <= 62])/len(text_lens)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_TEXT_SEQ_LEN = 62\nMAX_HEADLINE_SEQ_LEN = 15","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df['headlines_input'] = START_TOKEN + full_df['headlines']\nfull_df['headlines_output'] = full_df['headlines'] + END_TOKEN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df = full_df.drop(['headlines'], axis=1)\nfull_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test = train_test_split(full_df, test_size=0.1)\n\nX_train = X_train.reset_index(drop=True)\nX_test = X_test.reset_index(drop=True)\n\nprint(X_train.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train['headlines_input'][0], X_train['headlines_output'][0] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_preparation(X_train, X_test):\n    \"\"\"Tokenize and pad the given text.\"\"\"\n    \n    # Fit tokenizers\n    text_tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n    text_tokenizer.fit_on_texts(X_train['text'])\n\n    X_train['headlines_input'][0] = X_train['headlines_input'][0] + END_TOKEN\n    headline_tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n    headline_tokenizer.fit_on_texts(X_train['headlines_input'])\n    \n    # Pad sequences\n    text_train = pad_sequences(text_tokenizer.texts_to_sequences(X_train['text']), maxlen=MAX_TEXT_SEQ_LEN, padding='post', truncating='post')\n    text_test = pad_sequences(text_tokenizer.texts_to_sequences(X_test['text']), maxlen=MAX_TEXT_SEQ_LEN, padding='post', truncating='post')\n\n    headline_train_input = pad_sequences(headline_tokenizer.texts_to_sequences(X_train['headlines_input']), maxlen=MAX_HEADLINE_SEQ_LEN, padding='post', truncating='post')\n    headline_train_output = pad_sequences(headline_tokenizer.texts_to_sequences(X_train['headlines_output']), maxlen=MAX_HEADLINE_SEQ_LEN, padding='post', truncating='post')\n    headline_test_input = pad_sequences(headline_tokenizer.texts_to_sequences(X_test['headlines_input']), maxlen=MAX_HEADLINE_SEQ_LEN, padding='post', truncating='post')\n    headline_test_output = pad_sequences(headline_tokenizer.texts_to_sequences(X_test['headlines_output']), maxlen=MAX_HEADLINE_SEQ_LEN, padding='post', truncating='post')\n\n    return {\n        'text_tokenizer': text_tokenizer,\n        'headline_tokenizer': headline_tokenizer,\n        'text_train': text_train,\n        'text_test': text_test,\n        'headline_train_input': headline_train_input,\n        'headline_train_output': headline_train_output,\n        'headline_test_input': headline_test_input,\n        'headline_test_output': headline_test_output\n    }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndata = data_preparation(X_train, X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_vocab_size = len(data['text_tokenizer'].word_index) + 1\nheadline_vocab_size = len(data['headline_tokenizer'].word_index) + 1\n\nprint(f'Text vocab size: {text_vocab_size}')\nprint(f'Headline vocab size: {headline_vocab_size}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating Pretrained Embedding Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"EMBEDDING_DIM = 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nembeddings_index = dict()\nf = open(f'../input/glove6b/glove.6B.{EMBEDDING_DIM}d.txt')\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1: ], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\n\nprint(f'Found {len(embeddings_index)} word vectors.')\n\nheadline_embedding_matrix = np.zeros((headline_vocab_size, EMBEDDING_DIM))\nfor word, i in data['headline_tokenizer'].word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        headline_embedding_matrix[i] = embedding_vector\n\ntext_embedding_matrix = np.zeros((text_vocab_size, EMBEDDING_DIM))\nfor word, i in data['text_tokenizer'].word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        text_embedding_matrix[i] = embedding_vector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Shape of headline embedding matrix: {headline_embedding_matrix.shape}')\nprint(f'Shape of text embedding matrix: {text_embedding_matrix.shape}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Encoder(Layer):\n    def __init__(self, name):\n        super().__init__(name=name)\n        \n        self.embedding = Embedding(input_dim=text_vocab_size, output_dim=EMBEDDING_DIM, weights=[text_embedding_matrix], input_length=MAX_TEXT_SEQ_LEN, trainable=True, name='encoder_embedding')\n        # Store encoder hidden state and cell state for decoder input. Hidden state is the output of last timestamp,\n        # which represents the entire input sequence using a single vector.\n        self.lstm = LSTM(units=128, return_sequences=True, return_state=True, name='encoder_lstm')\n\n    def call(self, x):\n        x = self.embedding(x)\n        self.lstm_output, self.lstm_hidden, self.lstm_cell = self.lstm(x)\n        return self.lstm_output, self.lstm_hidden, self.lstm_cell\n    \n    def get_states(self):\n        return self.lstm_hidden, self.lstm_cell\n\nclass Decoder(Layer):\n    def __init__(self, name):\n        super().__init__(name=name)\n        \n        self.embedding = Embedding(input_dim=headline_vocab_size, output_dim=EMBEDDING_DIM, trainable=True, weights=[headline_embedding_matrix], input_length=None, name='decoder_embedding')\n        self.lstm = LSTM(units=128, return_sequences=True, return_state=True, name='decoder_lstm')\n    \n    \n    def call(self, x, lstm_hidden, lstm_cell):\n        x = self.embedding(x)\n        lstm_output, lstm_hidden, lstm_cell = self.lstm(x, initial_state=[lstm_hidden, lstm_cell])\n        return lstm_output, lstm_hidden, lstm_cell\n\nclass EncoderDecoder(Model):\n    def __init__(self):\n        super().__init__()\n        self.encoder = Encoder(name='encoder')\n        self.decoder = Decoder(name='decoder')\n        self.decoder_dense = TimeDistributed(Dense(units=headline_vocab_size, activation='softmax'), name='decoder_dense')\n    \n    \n    def call(self, x):\n        text, summary = x\n        _, hidden_state, cell_state = self.encoder(text)\n        out, hidden_state, cell_state = self.decoder(summary, hidden_state, cell_state)\n        return self.decoder_dense(out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = EncoderDecoder()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = Adam(learning_rate=0.002)\nmodel.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.2,\n    patience=3,\n    verbose=1\n)\n\n# Train the model\nhistory = model.fit(\n    [data['text_train'], data['headline_train_input']],\n    data['headline_train_output'],\n    batch_size=512,\n    epochs=100,\n    validation_data=([data['text_test'], data['headline_test_input']], data['headline_test_output']),\n    callbacks=[reduce_lr]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot(history):\n    plt.figure(figsize=(12, 6))\n    plt.style.use('ggplot')\n    plt.subplot(1, 2, 1)\n    plt.plot(np.arange(0, len(history.history['loss'])), history.history['loss'], label='train_loss')\n    plt.plot(np.arange(0, len(history.history['val_loss'])), history.history['val_loss'], label='validation_loss')\n\n    plt.title('Epochs vs. Loss')\n    plt.xlabel('Epoch #')\n    plt.ylabel('Loss')\n    plt.legend(loc='upper right')\n\n    plt.style.use('ggplot')\n    plt.subplot(1, 2, 2)\n    plt.plot(np.arange(0, len(history.history['accuracy'])), history.history['accuracy'], label='train_accuracy')\n    plt.plot(np.arange(0, len(history.history['val_accuracy'])), history.history['val_accuracy'], label='validation_accuracy')\n\n    plt.title('Epochs vs. Accuracy')\n    plt.xlabel('Epoch #')\n    plt.ylabel('Loss')\n    plt.legend(loc='lower right')\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Inference using Seq2Seq model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inspecting model layers\nfor idx, layer in enumerate(model.layers):\n    print(f'{idx} => {layer.name}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We first have to encode the input sequence using encoder, so that the encoder output state can be used by decoder to generate text summary (news headline in this case)."},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data['headline_tokenizer'].word_index.items())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index_to_word_text, index_to_word_headline  = {}, {}\n\nfor key, val in data['text_tokenizer'].word_index.items():\n    index_to_word_text[val] = key\n\nfor key, val in data['headline_tokenizer'].word_index.items():\n    index_to_word_headline[val] = key\n    \nindex_to_word_text[0] = '<pad>'\nindex_to_word_headline[0] = '<pad>'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example text to summarize\nsample_text = data['text_test'][0]\nsample_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fun_text = np.vectorize(lambda x: index_to_word_text[x])\nfun_headline = np.vectorize(lambda x: index_to_word_headline[x])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fun_text(sample_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_decoder_input = data['headline_test_input'][0]\nsample_decoder_input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fun_headline(sample_decoder_input)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def summarize(long_text):\n    long_text = long_text.reshape(1, -1)\n    out, hidden_state, cell_state = model.get_layer('encoder')(long_text)\n    summary = []\n    \n    output = np.array([1]).reshape(1, -1)\n    while True:\n        output, hidden_state, cell_state = model.get_layer('decoder')(output, hidden_state, cell_state)\n        output = np.argmax(model.get_layer('decoder_dense')(output), axis=-1)\n        pred = index_to_word_headline[int(output)]\n    \n        if pred == '<end>' or len(summary) >= MAX_HEADLINE_SEQ_LEN:\n            break\n        \n        summary.append(pred)\n\n    return ' '.join(summary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx in range(100, 200, 1):\n    predicted = summarize(data['text_test'][idx])\n    actual = ' '.join([word for word in fun_headline(data['headline_test_output'][idx]) if word not in ['<pad>', '<end>']])\n\n    print(f'GENERATED: {predicted}\\n\\nACTUAL: {actual}\\n\\nACTUAL TEXT: {\" \".join([word for word in fun_text(data[\"text_test\"][idx]) if word not in [\"<pad>\", \"<end>\"]])}\\n')\n    print('='*128)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}