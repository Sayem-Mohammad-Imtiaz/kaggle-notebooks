{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Adapted to be run for Sweden Data set case numbers\n# Note: AKNOWLEDGMENT taking the model of COVID-19 data with SIR model from Lisphilar Kaggle\n# AKNOWLEDGE OTHER PEOPLE'S WORK TO AVOID INTELLECTUAL PLAGIARISM\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nfrom datetime import datetime\ntime_format = \"%d%b%Y %H:%M\"\ndatetime.now().strftime(time_format)\nfrom datetime import timedelta\nfrom dateutil.relativedelta import relativedelta\nimport os\nfrom pprint import pprint\nimport warnings\nfrom fbprophet import Prophet\nfrom fbprophet.plot import add_changepoints_to_plot\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport matplotlib\nfrom matplotlib.ticker import ScalarFormatter\n%matplotlib inline\nimport numpy as np\nimport optuna\noptuna.logging.disable_default_handler()\nimport pandas as pd\nimport dask.dataframe as dd\npd.plotting.register_matplotlib_converters()\nimport seaborn as sns\nfrom scipy.integrate import solve_ivp\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\npd.set_option(\"display.max_colwidth\", 1000)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"population_raw = pd.read_csv(\n    \"/kaggle/input/covid19-global-forecasting-locations-population/locations_population.csv\"\n)\ndf = population_raw.copy()\ndf = df.rename({\"Province.State\": \"Province\", \"Country.Region\": \"Country\"}, axis=1)\ncols = [\"Country\", \"Province\", \"Population\"]\ndf = df.loc[:, cols].fillna(\"-\")\ndf.loc[df[\"Country\"] == df[\"Province\"], \"Province\"] = \"-\"\n# Add total records\n_total_df = df.loc[df[\"Province\"] != \"-\", :].groupby(\"Country\").sum()\n_total_df = _total_df.reset_index().assign(Province=\"-\")\ndf = pd.concat([df, _total_df], axis=0, sort=True)\ndf = df.drop_duplicates(subset=[\"Country\", \"Province\"], keep=\"first\")\n# Global\nglobal_value = df.loc[df[\"Province\"] == \"-\", \"Population\"].sum()\ndf = df.append(pd.Series([\"Global\", \"-\", global_value], index=cols), ignore_index=True)\n# Global except China\nchina_value = df.loc[(df[\"Country\"] == \"China\") & (df[\"Province\"] == \"-\"), \"Population\"].sum()\ndf = df.append(pd.Series([\"Except China\", \"-\", china_value - global_value], index=cols), ignore_index=True)\n# Sorting\ndf = df.sort_values(\"Population\", ascending=False).reset_index(drop=True)\ndf = df.loc[:, cols]\npopulation_df = df.copy()\npopulation_df.head()\ndf = population_df.loc[population_df[\"Province\"] == \"-\", :]\npopulation_dict = df.set_index(\"Country\").to_dict()[\"Population\"]\npopulation_dict\npyramid_csv_list = list()\nfor dirname, _, filenames in os.walk(\"/kaggle/input/population-pyramid-2019/\"):\n    for filename in filenames:\n        name = os.path.join(dirname, filename)\n        df = pd.read_csv(name)\n        df[\"Country\"], df[\"Year\"], _ = filename.replace(\".\", \"-\").split(\"-\")\n        pyramid_csv_list.append(df)\npyramid_raw = pd.concat(pyramid_csv_list, sort=True)\npyramid_raw.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pyramid_raw.copy()\ndf[\"Country\"] = df[\"Country\"].replace(\n    {\n        \"United States of America\": \"US\",\n        \"United Kingdom\": \"UK\",\n    }\n)\n# Global (WORLD)\n_male = [\n    349432556, 342927576, 331497486, 316642222, 308286775, 306059387, 309236984,\n    276447037, 249389688, 241232876, 222609691, 192215395, 157180267, 128939392,\n    87185982, 54754941, 33648953, 15756942, 5327866, 1077791, 124144\n]\n_female = [\n    328509234, 321511867, 309769906, 295553758, 289100903, 288632766, 296293748,\n    268371754, 244399176, 238133281, 223162982, 195633743, 164961323, 140704320,\n    101491347, 69026831, 48281201, 26429329, 11352182, 3055845, 449279\n]\n_df = pd.DataFrame(\n    {\n        \"Age\": df[\"Age\"].unique(),\n        \"Country\": \"Global\",\n        \"F\": _female,\n        \"M\": _male,\n        \"Year\": 2019\n    }\n)\ndf = pd.concat([df, _df], axis=0, ignore_index=True, sort=True)\ndf[\"Population\"] = df[\"F\"] + df[\"M\"]\n# Arrange\ndf = df.pivot_table(\n    index=\"Age\", columns=[\"Country\"], values=\"Population\", aggfunc=\"last\"\n)\ndf = df.astype(np.int64).reset_index().rename({\"Age\": \"Age_bin\"}, axis=1)\nseries = df[\"Age_bin\"].str.replace(\"+\", \"-122\")\ndf[[\"Age_first\", \"Age_last\"]] = series.str.split(\"-\", expand=True).astype(np.int64)\ndf = df.drop(\"Age_bin\", axis=1)\nseries = df[\"Age_last\"]\ndf = df.apply(lambda x: x[:-2] / (x[-1] - x[-2] + 1), axis=1)\ndf[\"Age\"] = series\ndf = pd.merge(df, pd.DataFrame({\"Age\": np.arange(0, 123, 1)}), on=\"Age\", how=\"right\", sort=True)\ndf = df.fillna(method=\"bfill\").astype(np.int64)\ndf = df.set_index(\"Age\")\npyramid_df = df.copy()\npyramid_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# @marcoferrante estimation\n_period_of_life_list = [\n    \"nursery\", \"nursery school\", \"elementary school\", \"middle school\",\n    \"high school\", \"university/work\", \"work\", \"work\", \"work\", \"work\",\n    \"retired\", \"retired\", \"retired\"\n]\ndf = pd.DataFrame(\n    {\n        \"Age_first\": [0, 3, 6, 11, 14, 19, 26, 36, 46, 56, 66, 76, 86],\n        \"Age_last\": [2, 5, 10, 13, 18, 25, 35, 45, 55, 65, 75, 85, 95],\n        \"Period_of_life\": _period_of_life_list,\n        \"Days\": [3, 5, 6, 6, 7, 7, 6, 5, 5, 5, 4, 3, 2]\n    }\n)\n# Adjustment by author\ndf[\"Types\"] = df[\"Period_of_life\"].replace(\n    {\n        \"nursery\": \"school\",\n        \"nursery school\": \"school\",\n        \"elementary school\": \"school\",\n        \"middle school\": \"school\",\n        \"high school\": \"school\",\n        \"university/work\": \"school/work\"\n    }\n)\ndf[\"School\"] = df[[\"Types\", \"Days\"]].apply(lambda x: x[1] if \"school\" in x[0] else 0, axis=1)\ndf[\"Office\"] = df[[\"Types\", \"Days\"]].apply(lambda x: x[1] if \"work\" in x[0] else 0, axis=1)\ndf[\"Others\"] = df[\"Days\"] - df[[\"School\", \"Office\"]].sum(axis=1)\ndf.loc[df[\"Others\"] < 0, \"Others\"] = 0\ndf.loc[df.index[1:5], \"School\"] -= 1\ndf.loc[df.index[1:5], \"Others\"] += 1\ndf.loc[df.index[5], [\"School\", \"Office\", \"Others\"]] = [3, 3, 1]\ndf[[\"School\", \"Office\", \"Others\"]] = df[[\"Days\", \"School\", \"Office\", \"Others\"]].apply(\n    lambda x: x[1:] / sum(x[1:]) * x[0], axis=1\n).astype(np.int64)\ndf.loc[df.index[6:10], \"Others\"] += 1\ndf = df.drop([\"Days\", \"Types\"], axis=1)\n# Show dataset\n_out_df = df.copy()\n_out_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pyramid_df.cumsum()\ncountries = df.columns[:]\ndf = pd.merge(_out_df, df, left_on=\"Age_last\", right_on=\"Age\", how=\"left\")\n_first = df.loc[df.index[0], countries]\ndf[countries] = df[countries].diff()\ndf.loc[df.index[0], countries] = _first\ndf[countries] = df[countries].apply(lambda x: x / x.sum(), axis=0)\nout_df = df.copy()\nout_df\n\ndef go_out(country, out_df=out_df):\n    \"\"\"\n    Return the estimated number of days people usually go out.\n    @country <str>: coutry name\n    @out_df <pd.DataFrame>: template dataframe\n    \"\"\"\n    df = out_df.copy()\n    try:\n        series = df[country]\n    except KeyError:\n        raise KeyError(f\"Population pyramid data of {country} is not defined!\")\n    df = df.iloc[:, :6]\n    df[\"Portion\"] = series\n    return df\n\ngo_out(\"Global\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def line_plot(df, title, ylabel=\"Cases\", h=None, v=None,\n              xlim=(None, None), ylim=(0, None), math_scale=True, y_logscale=False, y_integer=False):\n    \"\"\"\n    Show chlonological change of the data.\n    \"\"\"\n    ax = df.plot()\n    if math_scale:\n        ax.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n        ax.ticklabel_format(style=\"sci\",  axis=\"y\",scilimits=(0, 0))\n    if y_logscale:\n        ax.set_yscale(\"log\")\n    if y_integer:\n        fmt = matplotlib.ticker.ScalarFormatter(useOffset=False)\n        fmt.set_scientific(False)\n        ax.yaxis.set_major_formatter(fmt)\n    ax.set_title(title)\n    ax.set_xlabel(None)\n    ax.set_ylabel(ylabel)\n    ax.set_xlim(*xlim)\n    ax.set_ylim(*ylim)\n    ax.legend(bbox_to_anchor=(1.02, 0), loc=\"lower left\", borderaxespad=0)\n    if h is not None:\n        ax.axhline(y=h, color=\"black\", linestyle=\"--\")\n    if v is not None:\n        if not isinstance(v, list):\n            v = [v]\n        for value in v:\n            ax.axvline(x=value, color=\"black\", linestyle=\"--\")\n    plt.tight_layout()\n    plt.show()\n    \ndef select_area(ncov_df, group=\"Date\", places=None, areas=None, excluded_places=None,\n                start_date=None, end_date=None, date_format=\"%d%b%Y\"):\n    \"\"\"\n    Select the records of the palces.\n    @ncov_df <pd.DataFrame>: the clean data\n    @group <str or None>: group-by the group, or not perform (None)\n    @area or @places:\n        if ncov_df has Country and Province column,\n            @places <list[tuple(<str/None>, <str/None>)]: the list of places\n                - if the list is None, all data will be used\n                - (str, str): both of country and province are specified\n                - (str, None): only country is specified\n                - (None, str) or (None, None): Error\n        if ncov_df has Area column,\n            @areas <list[str]>: the list of area names\n                - if the list is None, all data will be used\n                - eg. Japan\n                - eg. US/California\n    @excluded_places <list[tuple(<str/None>, <str/None>)]: the list of excluded places\n        - if the list is None, all data in the \"places\" will be used\n        - (str, str): both of country and province are specified\n        - (str, None): only country is specified\n        - (None, str) or (None, None): Error\n    @start_date <str>: the start date or None\n    @end_date <str>: the start date or None\n    @date_format <str>: format of @start_date and @end_date\n    @return <pd.DataFrame>: index and columns are as same as @ncov_df\n    \"\"\"\n    # Select the target records\n    df = ncov_df.copy()\n    if (places is not None) or (excluded_places is not None):\n        c_series = df[\"Country\"]\n        p_series = df[\"Province\"]\n        if places is not None:\n            df = pd.DataFrame(columns=ncov_df.columns)\n            for (c, p) in places:\n                if c is None:\n                    raise Exception(\"places: Country must be specified!\")\n                if p is None:\n                    new_df = ncov_df.loc[c_series == c, :]\n                else:\n                    new_df = ncov_df.loc[(c_series == c) & (p_series == p), :]\n                df = pd.concat([df, new_df], axis=0)\n        if excluded_places is not None:\n            for (c, p) in excluded_places:\n                if c is None:\n                    raise Exception(\"excluded_places: Country must be specified!\")\n                if p is None:\n                    df = df.loc[c_series != c, :]\n                else:\n                    c_df = df.loc[(c_series == c) & (p_series != p), :]\n                    other_df = df.loc[c_series != c, :]\n                    df = pd.concat([c_df, other_df], axis=0)\n    if areas is not None:\n        df = df.loc[df[\"Area\"].isin(areas), :]\n    if group is not None:\n        df = df.groupby(group).sum().reset_index()\n    # Range of date\n    if start_date is not None:\n        df = df.loc[df[\"Date\"] >= datetime.strptime(start_date, date_format), :]\n    if end_date is not None:\n        df = df.loc[df[\"Date\"] <= datetime.strptime(end_date, date_format), :]\n    # Only use the records with Confirmed > 0\n    try:\n        df = df.loc[df[\"Confirmed\"] > 0, :]\n    except KeyError:\n        pass\n    # Aleart empty\n    if df.empty:\n        raise Exception(\"The output dataframe is empty!\")\n    return df\n\ndef create_target_df(ncov_df, total_population,\n                     confirmed=\"Confirmed\", recovered=\"Recovered\", fatal=\"Deaths\", **kwargs):\n    \"\"\"\n    Select the records of the places, calculate the number of susceptible people,\n     and calculate the elapsed time [day] from the start date of the target dataframe.\n    @ncov_df <pd.DataFrame>: the clean data\n    @total_population <int>: total population in the places\n    column names in @ncov_df:\n        @confirmed <str>: column name of the number of confirmed cases\n        @recovered <str>: column name of the number of recovered cases\n        @fatal <str>: column name of the number of fatal cases\n    @kwargs: keword arguments of select_area()\n    @return <tuple(2 objects)>:\n        - 1. first_date <pd.Timestamp>: the first date of the selected records\n        - 2. target_df <pd.DataFrame>:\n            - column T: elapsed time [min] from the start date of the dataset\n            - column Susceptible: the number of patients who are in the palces but not infected/recovered/died\n            - column Infected: the number of infected cases\n            - column Recovered: the number of recovered cases\n            - column Deaths: the number of death cases\n    \"\"\"\n    # Select the target records\n    df = select_area(ncov_df, **kwargs)\n    first_date = df.loc[df.index[0], \"Date\"]\n    # column T\n    df[\"T\"] = ((df[\"Date\"] - first_date).dt.total_seconds() / 60).astype(int)\n    # coluns except T\n    cols = [confirmed, recovered, fatal]\n    if not set(cols).issubset(set(df.columns)):\n        raise KeyError(f\"ncov_df must have {', '.join(cols)} column!\")\n    df[\"Susceptible\"] = total_population - df[confirmed]\n    df[\"Infected\"] = df[confirmed] - df[recovered] - df[fatal]\n    df[\"Recovered\"] = df[recovered]\n    df[\"Fatal\"] = df.loc[:, fatal]\n    response_variables = [\"Susceptible\", \"Infected\", \"Recovered\", \"Fatal\"]\n    # Return\n    target_df = df.loc[:, [\"T\", *response_variables]]\n    return (first_date, target_df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def simulation(model, initials, step_n, **params):\n    \"\"\"\n    Solve ODE of the model.\n    @model <ModelBase>: the model\n    @initials <tuple[float]>: the initial values\n    @step_n <int>: the number of steps\n    @params: the paramerters of the model\n    \"\"\"\n    tstart, dt, tend = 0, 1, step_n\n    sol = solve_ivp(\n        fun=model(**params),\n        t_span=[tstart, tend],\n        y0=np.array(initials, dtype=np.float64),\n        t_eval=np.arange(tstart, tend + dt, dt),\n        dense_output=True\n    )\n    t_df = pd.Series(data=sol[\"t\"], name=\"t\")\n    y_df = pd.DataFrame(data=sol[\"y\"].T.copy(), columns=model.VARIABLES)\n    sim_df = pd.concat([t_df, y_df], axis=1)\n    return sim_df\n\nclass ModelBase(object):\n    NAME = \"Model\"\n    VARIABLES = [\"x\"]\n    PRIORITIES = np.array([1])\n    QUANTILE_RANGE = [0.3, 0.7]\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        \"\"\"\n        Define parameters without tau. This function should be overwritten.\n        @train_df_divided <pd.DataFrame>:\n            - column: t and non-dimensional variables\n        @q_range <list[float, float]>: quantile rage of the parameters calculated by the data\n        @return <dict[name]=(min, max):\n            @min <float>: min value\n            @max <float>: max value\n        \"\"\"\n        param_dict = dict()\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        \"\"\"\n        Calculate the variables of the model.\n        This function should be overwritten.\n        @df <pd.DataFrame>\n        @return <pd.DataFrame>\n        \"\"\"\n        return df\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        \"\"\"\n        Calculate measurable variables using the variables of the model.\n        This function should be overwritten.\n        @df <pd.DataFrame>\n        @return <pd.DataFrame>\n        \"\"\"\n        return df\n\n    @classmethod\n    def create_dataset(cls, ncov_df, total_population, **kwargs):\n        \"\"\"\n        Create dataset with the model-specific varibles.\n        The variables will be divided by total population.\n        The column names (not include T) will be lower letters.\n        **kwargs: See the function named create_target_df()\n        @return <tuple(objects)>:\n            - start_date <pd.Timestamp>\n            - initials <tuple(float)>: the initial values\n            - Tend <int>: the last value of T\n            - df <pd.DataFrame>: the dataset\n        \"\"\"\n        start_date, target_df = create_target_df(ncov_df, total_population, **kwargs)\n        df = cls.calc_variables(target_df).set_index(\"T\") / total_population\n        df.columns = [n.lower() for n in df.columns]\n        initials = df.iloc[0, :].values\n        df = df.reset_index()\n        Tend = df.iloc[-1, 0]\n        return (start_date, initials, Tend, df)\n\n    def calc_r0(self):\n        \"\"\"\n        Calculate R0. This function should be overwritten.\n        \"\"\"\n        return None\n\n    def calc_days_dict(self, tau):\n        \"\"\"\n        Calculate 1/beta [day] etc.\n        This function should be overwritten.\n        @param tau <int>: tau value [hour]\n        \"\"\"\n        return dict()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SIR MODEL**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SIR(ModelBase):\n    NAME = \"SIR\"\n    VARIABLES = [\"x\", \"y\", \"z\"]\n    PRIORITIES = np.array([1, 1, 1])\n\n    def __init__(self, rho, sigma):\n        super().__init__()\n        self.rho = rho\n        self.sigma = sigma\n\n    def __call__(self, t, X):\n        # x, y, z = [X[i] for i in range(len(self.VARIABLES))]\n        # dxdt = - self.rho * x * y\n        # dydt = self.rho * x * y - self.sigma * y\n        # dzdt = self.sigma * y\n        dxdt = - self.rho * X[0] * X[1]\n        dydt = self.rho * X[0] * X[1] - self.sigma * X[1]\n        dzdt = self.sigma * X[1]\n        return np.array([dxdt, dydt, dzdt])\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        param_dict = super().param_dict()\n        q_range = super().QUANTILE_RANGE[:] if q_range is None else q_range\n        if train_df_divided is not None:\n            df = train_df_divided.copy()\n            # rho = - (dx/dt) / x / y\n            rho_series = 0 - df[\"x\"].diff() / df[\"t\"].diff() / df[\"x\"] / df[\"y\"]\n            param_dict[\"rho\"] = rho_series.quantile(q_range)\n            # sigma = (dz/dt) / y\n            sigma_series = df[\"z\"].diff() / df[\"t\"].diff() / df[\"y\"]\n            param_dict[\"sigma\"] = sigma_series.quantile(q_range)\n            return param_dict\n        param_dict[\"rho\"] = (0, 1)\n        param_dict[\"sigma\"] = (0, 1)\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        df[\"X\"] = df[\"Susceptible\"]\n        df[\"Y\"] = df[\"Infected\"]\n        df[\"Z\"] = df[\"Recovered\"] + df[\"Fatal\"]\n        return df.loc[:, [\"T\", \"X\", \"Y\", \"Z\"]]\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        df[\"Susceptible\"] = df[\"X\"]\n        df[\"Infected\"] = df[\"Y\"]\n        df[\"Recovered/Deaths\"] = df[\"Z\"]\n        return df\n\n    def calc_r0(self):\n        if self.sigma == 0:\n            return np.nan\n        r0 = self.rho / self.sigma\n        return round(r0, 2)\n\n    def calc_days_dict(self, tau):\n        _dict = dict()\n        _dict[\"1/beta [day]\"] = int(tau / 24 / 60 / self.rho)\n        _dict[\"1/gamma [day]\"] = int(tau / 24 / 60 / self.sigma)\n        return _dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SIR-D MODEL**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SIRD(ModelBase):\n    NAME = \"SIR-D\"\n    VARIABLES = [\"x\", \"y\", \"z\", \"w\"]\n    PRIORITIES = np.array([1, 10, 10, 2])\n\n    def __init__(self, kappa, rho, sigma):\n        super().__init__()\n        self.kappa = kappa\n        self.rho = rho\n        self.sigma = sigma\n\n    def __call__(self, t, X):\n        # x, y, z, w = [X[i] for i in range(len(self.VARIABLES))]\n        # dxdt = - self.rho * x * y\n        # dydt = self.rho * x * y - (self.sigma + self.kappa) * y\n        # dzdt = self.sigma * y\n        # dwdt = self.kappa * y\n        dxdt = - self.rho * X[0] * X[1]\n        dydt = self.rho * X[0] * X[1] - (self.sigma + self.kappa) * X[1]\n        dzdt = self.sigma * X[1]\n        dwdt = self.kappa * X[1]\n        return np.array([dxdt, dydt, dzdt, dwdt])\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        param_dict = super().param_dict()\n        q_range = super().QUANTILE_RANGE[:] if q_range is None else q_range\n        if train_df_divided is not None:\n            df = train_df_divided.copy()\n            # kappa = (dw/dt) / y\n            kappa_series = df[\"w\"].diff() / df[\"t\"].diff() / df[\"y\"]\n            param_dict[\"kappa\"] = kappa_series.quantile(q_range)\n            # rho = - (dx/dt) / x / y\n            rho_series = 0 - df[\"x\"].diff() / df[\"t\"].diff() / df[\"x\"] / df[\"y\"]\n            param_dict[\"rho\"] = rho_series.quantile(q_range)\n            # sigma = (dz/dt) / y\n            sigma_series = df[\"z\"].diff() / df[\"t\"].diff() / df[\"y\"]\n            param_dict[\"sigma\"] = sigma_series.quantile(q_range)\n            return param_dict\n        param_dict[\"kappa\"] = (0, 1)\n        param_dict[\"rho\"] = (0, 1)\n        param_dict[\"sigma\"] = (0, 1)\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        df[\"X\"] = df[\"Susceptible\"]\n        df[\"Y\"] = df[\"Infected\"]\n        df[\"Z\"] = df[\"Recovered\"]\n        df[\"W\"] = df[\"Fatal\"]\n        return df.loc[:, [\"T\", \"X\", \"Y\", \"Z\", \"W\"]]\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        df[\"Susceptible\"] = df[\"X\"]\n        df[\"Infected\"] = df[\"Y\"]\n        df[\"Recovered\"] = df[\"Z\"]\n        df[\"Deaths\"] = df[\"W\"]\n        return df\n\n    def calc_r0(self):\n        try:\n            r0 = self.rho / (self.sigma + self.kappa)\n        except ZeroDivisionError:\n            return np.nan\n        return round(r0, 2)\n\n\n    def calc_days_dict(self, tau):\n        _dict = dict()\n        if self.kappa == 0:\n            _dict[\"1/alpha2 [day]\"] = 0\n        else:\n            _dict[\"1/alpha2 [day]\"] = int(tau / 24 / 60 / self.kappa)\n        _dict[\"1/beta [day]\"] = int(tau / 24 / 60 / self.rho)\n        if self.sigma == 0:\n            _dict[\"1/gamma [day]\"] = 0\n        else:\n            _dict[\"1/gamma [day]\"] = int(tau / 24 / 60 / self.sigma)\n        return _dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SIR-F MODEL**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SIRF(ModelBase):\n    NAME = \"SIR-F\"\n    VARIABLES = [\"x\", \"y\", \"z\", \"w\"]\n    PRIORITIES = np.array([1, 10, 10, 2])\n\n    def __init__(self, theta, kappa, rho, sigma):\n        super().__init__()\n        self.theta = theta\n        self.kappa = kappa\n        self.rho = rho\n        self.sigma = sigma\n\n    def __call__(self, t, X):\n        # x, y, z, w = [X[i] for i in range(len(self.VARIABLES))]\n        # dxdt = - self.rho * x * y\n        # dydt = self.rho * (1 - self.theta) * x * y - (self.sigma + self.kappa) * y\n        # dzdt = self.sigma * y\n        # dwdt = self.rho * self.theta * x * y + self.kappa * y\n        dxdt = - self.rho * X[0] * X[1]\n        dydt = self.rho * (1 - self.theta) * X[0] * X[1] - (self.sigma + self.kappa) * X[1]\n        dzdt = self.sigma * X[1]\n        dwdt = self.rho * self.theta * X[0] * X[1] + self.kappa * X[1]\n        return np.array([dxdt, dydt, dzdt, dwdt])\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        param_dict = super().param_dict()\n        q_range = super().QUANTILE_RANGE[:] if q_range is None else q_range\n        param_dict[\"theta\"] = (0, 1)\n        param_dict[\"kappa\"] = (0, 1)\n        if train_df_divided is not None:\n            df = train_df_divided.copy()\n            # rho = - (dx/dt) / x / y\n            rho_series = 0 - df[\"x\"].diff() / df[\"t\"].diff() / df[\"x\"] / df[\"y\"]\n            param_dict[\"rho\"] = rho_series.quantile(q_range)\n            # sigma = (dz/dt) / y\n            sigma_series = df[\"z\"].diff() / df[\"t\"].diff() / df[\"y\"]\n            param_dict[\"sigma\"] = sigma_series.quantile(q_range)\n            return param_dict\n        param_dict[\"rho\"] = (0, 1)\n        param_dict[\"sigma\"] = (0, 1)\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        df[\"X\"] = df[\"Susceptible\"]\n        df[\"Y\"] = df[\"Infected\"]\n        df[\"Z\"] = df[\"Recovered\"]\n        df[\"W\"] = df[\"Fatal\"]\n        return df.loc[:, [\"T\", \"X\", \"Y\", \"Z\", \"W\"]]\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        df[\"Susceptible\"] = df[\"X\"]\n        df[\"Infected\"] = df[\"Y\"]\n        df[\"Recovered\"] = df[\"Z\"]\n        df[\"Fatal\"] = df[\"W\"]\n        return df\n\n    def calc_r0(self):\n        try:\n            r0 = self.rho * (1 - self.theta) / (self.sigma + self.kappa)\n        except ZeroDivisionError:\n            return np.nan\n        return round(r0, 2)\n\n    def calc_days_dict(self, tau):\n        _dict = dict()\n        _dict[\"alpha1 [-]\"] = round(self.theta, 3)\n        if self.kappa == 0:\n            _dict[\"1/alpha2 [day]\"] = 0\n        else:\n            _dict[\"1/alpha2 [day]\"] = int(tau / 24 / 60 / self.kappa)\n        _dict[\"1/beta [day]\"] = int(tau / 24 / 60 / self.rho)\n        if self.sigma == 0:\n            _dict[\"1/gamma [day]\"] = 0\n        else:\n            _dict[\"1/gamma [day]\"] = int(tau / 24 / 60 / self.sigma)\n        return _dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****"},{"metadata":{},"cell_type":"markdown","source":"**SEWIRF MODEL**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SEWIRF(ModelBase):\n    NAME = \"SEWIR-F\"\n    VARIABLES = [\"x1\", \"x2\", \"x3\", \"y\", \"z\", \"w\"]\n    PRIORITIES = np.array([0, 0, 0, 10, 10, 2])\n\n    def __init__(self, theta, kappa, rho1, rho2, rho3, sigma):\n        super().__init__()\n        self.theta = theta\n        self.kappa = kappa\n        self.rho1 = rho1\n        self.rho2 = rho2\n        self.rho3 = rho3\n        self.sigma = sigma\n\n    def __call__(self, t, X):\n        # x1, x2, x3, y, z, w = [X[i] for i in range(len(self.VARIABLES))]\n        # dx1dt = - self.rho1 * x1 * (x3 + y)\n        # dx2dt = self.rho1 * x1 * (x3 + y) - self.rho2 * x2\n        # dx3dt = self.rho2 * x2 - self.rho3 * x3\n        # dydt = self.rho3 * (1 - self.theta) * x3 - (self.sigma + self.kappa) * y\n        # dzdt = self.sigma * y\n        # dwdt = self.rho3 * self.theta * x3 + self.kappa * y\n        dx1dt = - self.rho1 * X[0] * (X[2] + X[3])\n        dx2dt = self.rho1 * X[0] * (X[2] + X[3]) - self.rho2 * X[1]\n        dx3dt = self.rho2 * X[1] - self.rho3 * X[2]\n        dydt = self.rho3 * (1 - self.theta) * X[2] - (self.sigma + self.kappa) * X[3]\n        dzdt = self.sigma * X[3]\n        dwdt = self.rho3 * self.theta * X[2] + self.kappa * X[3]\n        return np.array([dx1dt, dx2dt, dx3dt, dydt, dzdt, dwdt])\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        param_dict = super().param_dict()\n        q_range = super().QUANTILE_RANGE[:] if q_range is None else q_range\n        param_dict[\"theta\"] = (0, 1)\n        param_dict[\"kappa\"] = (0, 1)\n        param_dict[\"rho1\"] = (0, 1)\n        param_dict[\"rho2\"] = (0, 1)\n        param_dict[\"rho3\"] = (0, 1)\n        if train_df_divided is not None:\n            df = train_df_divided.copy()\n            # sigma = (dz/dt) / y\n            sigma_series = df[\"z\"].diff() / df[\"t\"].diff() / df[\"y\"]\n            param_dict[\"sigma\"] = sigma_series.quantile(q_range)\n            return param_dict\n        param_dict[\"sigma\"] = (0, 1)\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        df[\"X1\"] = df[\"Susceptible\"]\n        df[\"X2\"] = 0\n        df[\"X3\"] = 0\n        df[\"Y\"] = df[\"Infected\"]\n        df[\"Z\"] = df[\"Recovered\"]\n        df[\"W\"] = df[\"Fatal\"]\n        return df.loc[:, [\"T\", \"X1\", \"X2\", \"X3\", \"Y\", \"Z\", \"W\"]]\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        df[\"Susceptible\"] = df[\"X1\"]\n        df[\"Infected\"] = df[\"Y\"]\n        df[\"Recovered\"] = df[\"Z\"]\n        df[\"Fatal\"] = df[\"W\"]\n        df[\"Exposed\"] = df[\"X2\"]\n        df[\"Waiting\"] = df[\"X3\"]\n        return df\n\n    def calc_r0(self):\n        try:\n            r0 = self.rho1 * (1 - self.theta) / (self.sigma + self.kappa)\n        except ZeroDivisionError:\n            return np.nan\n        return round(r0, 2)\n\n    def calc_days_dict(self, tau):\n        _dict = dict()\n        _dict[\"alpha1 [-]\"] = round(self.theta, 3)\n        if self.kappa == 0:\n            _dict[\"1/alpha2 [day]\"] = 0\n        else:\n            _dict[\"1/alpha2 [day]\"] = int(tau / 24 / 60 / self.kappa)\n        _dict[\"1/beta1 [day]\"] = int(tau / 24 / 60 / self.rho1)\n        _dict[\"1/beta2 [day]\"] = int(tau / 24 / 60 / self.rho2)\n        _dict[\"1/beta3 [day]\"] = int(tau / 24 / 60 / self.rho3)\n        if self.sigma == 0:\n            _dict[\"1/gamma [day]\"] = 0\n        else:\n            _dict[\"1/gamma [day]\"] = int(tau / 24 / 60 / self.sigma)\n        return _dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SIR-FV MODEL**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SIRFV(ModelBase):\n    NAME = \"SIR-FV\"\n    VARIABLES = [\"x\", \"y\", \"z\", \"w\"]\n    PRIORITIES = np.array([1, 10, 10, 2])\n\n    def __init__(self, theta, kappa, rho, sigma, omega=None, n=None, v_per_day=None):\n        \"\"\"\n        (n and v_per_day) or omega must be applied.\n        @n <float or int>: total population\n        @v_par_day <float or int>: vacctinated persons per day\n        \"\"\"\n        super().__init__()\n        self.theta = theta\n        self.kappa = kappa\n        self.rho = rho\n        self.sigma = sigma\n        if omega is None:\n            try:\n                self.omega = float(v_per_day) / float(n)\n            except TypeError:\n                s = \"Neither (n and va_per_day) nor omega must be applied!\"\n                raise TypeError(s)\n        else:\n            self.omega = float(omega)\n\n    def __call__(self, t, X):\n        # x, y, z, w = [X[i] for i in range(len(self.VARIABLES))]\n        # x with vacctination\n        dxdt = - self.rho * X[0] * X[1] - self.omega\n        dxdt = 0 - X[0] if X[0] + dxdt < 0 else dxdt\n        # y, z, w\n        dydt = self.rho * (1 - self.theta) * X[0] * X[1] - (self.sigma + self.kappa) * X[1]\n        dzdt = self.sigma * X[1]\n        dwdt = self.rho * self.theta * X[0] * X[1] + self.kappa * X[1]\n        return np.array([dxdt, dydt, dzdt, dwdt])\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        param_dict = super().param_dict()\n        q_range = super().QUANTILE_RANGE[:] if q_range is None else q_range\n        param_dict[\"theta\"] = (0, 1)\n        param_dict[\"kappa\"] = (0, 1)\n        param_dict[\"omega\"] = (0, 1)\n        if train_df_divided is not None:\n            df = train_df_divided.copy()\n            # rho = - (dx/dt) / x / y\n            rho_series = 0 - df[\"x\"].diff() / df[\"t\"].diff() / df[\"x\"] / df[\"y\"]\n            param_dict[\"rho\"] = rho_series.quantile(q_range)\n            # sigma = (dz/dt) / y\n            sigma_series = df[\"z\"].diff() / df[\"t\"].diff() / df[\"y\"]\n            param_dict[\"sigma\"] = sigma_series.quantile(q_range)\n            return param_dict\n        param_dict[\"rho\"] = (0, 1)\n        param_dict[\"sigma\"] = (0, 1)\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        df[\"X\"] = df[\"Susceptible\"]\n        df[\"Y\"] = df[\"Infected\"]\n        df[\"Z\"] = df[\"Recovered\"]\n        df[\"W\"] = df[\"Fatal\"]\n        return df.loc[:, [\"T\", \"X\", \"Y\", \"Z\", \"W\"]]\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        df[\"Susceptible\"] = df[\"X\"]\n        df[\"Infected\"] = df[\"Y\"]\n        df[\"Recovered\"] = df[\"Z\"]\n        df[\"Fatal\"] = df[\"W\"]\n        df[\"Immuned\"] = 1 - df[[\"X\", \"Y\", \"Z\", \"W\"]].sum(axis=1)\n        return df\n\n    def calc_r0(self):\n        try:\n            r0 = self.rho * (1 - self.theta) / (self.sigma + self.kappa)\n        except ZeroDivisionError:\n            return np.nan\n        return round(r0, 2)\n\n    def calc_days_dict(self, tau):\n        _dict = dict()\n        _dict[\"alpha1 [-]\"] = round(self.theta, 3)\n        if self.kappa == 0:\n            _dict[\"1/alpha2 [day]\"] = 0\n        else:\n            _dict[\"1/alpha2 [day]\"] = int(tau / 24 / 60 / self.kappa)\n        _dict[\"1/beta [day]\"] = int(tau / 24 / 60 / self.rho)\n        if self.sigma == 0:\n            _dict[\"1/gamma [day]\"] = 0\n        else:\n            _dict[\"1/gamma [day]\"] = int(tau / 24 / 60 / self.sigma)\n        return _dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Estimator**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Estimator(object):\n    def __init__(self, model, ncov_df, total_population, name=None, places=None, areas=None,\n                 excluded_places=None, start_date=None, end_date=None, date_format=\"%d%b%Y\", **params):\n        \"\"\"\n        Set training data.\n        @model <ModelBase>: the model\n        @name <str>: name of the area\n        @params: fixed parameter of the model\n        @the other params: See the function named create_target_df()\n        \"\"\"\n        # Fixed parameters\n        self.fixed_param_dict = params.copy()\n        # Register the dataset arranged for the model\n        dataset = model.create_dataset(\n            ncov_df, total_population, places=places, areas=areas,\n            excluded_places=excluded_places,\n            start_date=start_date, end_date=end_date, date_format=date_format\n        )\n        self.start_time, self.initials, self.Tend, self.train_df = dataset\n        self.total_population = total_population\n        self.name = name\n        self.model = model\n        self.param_dict = dict()\n        self.study = None\n        self.optimize_df = None\n\n    def run(self, n_trials=500):\n        \"\"\"\n        Try estimation (optimization of parameters and tau).\n        @n_trials <int>: the number of trials\n        \"\"\"\n        if self.study is None:\n            self.study = optuna.create_study(direction=\"minimize\")\n        self.study.optimize(\n            lambda x: self.objective(x),\n            n_trials=n_trials,\n            n_jobs=-1\n        )\n        param_dict = self.study.best_params.copy()\n        param_dict.update(self.fixed_param_dict)\n        param_dict[\"R0\"] = self.calc_r0()\n        param_dict[\"score\"] = self.score()\n        param_dict.update(self.calc_days_dict())\n        self.param_dict = param_dict.copy()\n        return param_dict\n\n    def history_df(self):\n        \"\"\"\n        Return the hsitory of optimization.\n        @return <pd.DataFrame>\n        \"\"\"\n        optimize_df = self.study.trials_dataframe()\n        optimize_df[\"time[s]\"] = optimize_df[\"datetime_complete\"] - \\\n            optimize_df[\"datetime_start\"]\n        optimize_df[\"time[s]\"] = optimize_df[\"time[s]\"].dt.total_seconds()\n        self.optimize_df = optimize_df.drop(\n            [\"datetime_complete\", \"datetime_start\", \"system_attrs__number\"], axis=1)\n        return self.optimize_df.sort_values(\"value\", ascending=True)\n\n    def history_graph(self):\n        \"\"\"\n        Show the history of parameter search using pair-plot.\n        \"\"\"\n        if self.optimize_df is None:\n            self.history_df()\n        df = self.optimize_df.copy()\n        sns.pairplot(df.loc[:, df.columns.str.startswith(\n            \"params_\")], diag_kind=\"kde\", markers=\"+\")\n        plt.show()\n\n    def objective(self, trial):\n        # Time\n        try:\n            tau = self.fixed_param_dict[\"tau\"]\n        except KeyError:\n            tau = trial.suggest_int(\"tau\", 1, 1440)\n        train_df_divided = self.train_df.copy()\n        train_df_divided[\"t\"] = (train_df_divided[\"T\"] / tau).astype(np.int64)\n        # Parameters\n        param_dict = self.model.param_dict(train_df_divided)\n        p_dict = {\"tau\": None}\n        p_dict.update(\n            {\n                k: trial.suggest_uniform(k, *v)\n                for (k, v) in param_dict.items()\n            }\n        )\n        p_dict.update(self.fixed_param_dict)\n        p_dict.pop(\"tau\")\n        # Simulation\n        t_end = train_df_divided.loc[train_df_divided.index[-1], \"t\"]\n        sim_df = simulation(self.model, self.initials, step_n=t_end, **p_dict)\n        return self.error_f(train_df_divided, sim_df)\n\n    def error_f(self, train_df_divided, sim_df):\n        \"\"\"\n        We need to minimize the difference of the observed values and estimated values.\n        This function calculate the difference of the estimated value and obsereved value.\n        \"\"\"\n        n = self.total_population\n        df = pd.merge(train_df_divided, sim_df, on=\"t\", suffixes=(\"_observed\", \"_estimated\"))\n        diffs = [\n            # Weighted Average: the recent data is more important\n            p * np.average(\n                abs(df[f\"{v}_observed\"] - df[f\"{v}_estimated\"]) / (df[f\"{v}_observed\"] * n + 1),\n                weights=df[\"t\"]\n            )\n            for (p, v) in zip(self.model.PRIORITIES, self.model.VARIABLES)\n        ]\n        return sum(diffs) * n\n\n    def compare_df(self):\n        \"\"\"\n        Show the taining data and simulated data in one dataframe.\n\n        \"\"\"\n        est_dict = self.study.best_params.copy()\n        est_dict.update(self.fixed_param_dict)\n        tau = est_dict[\"tau\"]\n        est_dict.pop(\"tau\")\n        observed_df = self.train_df.drop(\"T\", axis=1)\n        observed_df[\"t\"] = (self.train_df[\"T\"] / tau).astype(int)\n        t_end = observed_df.loc[observed_df.index[-1], \"t\"]\n        sim_df = simulation(self.model, self.initials, step_n=t_end, **est_dict)\n        df = pd.merge(observed_df, sim_df, on=\"t\", suffixes=(\"_observed\", \"_estimated\"))\n        df = df.set_index(\"t\")\n        return df\n\n    def compare_graph(self):\n        \"\"\"\n        Compare obsereved and estimated values in graphs.\n        \"\"\"\n        df = self.compare_df()\n        use_variables = [\n            v for (i, (p, v)) in enumerate(zip(self.model.PRIORITIES, self.model.VARIABLES))\n            if p != 0 and i != 0\n        ]\n        val_len = len(use_variables) + 1\n        fig, axes = plt.subplots(\n            ncols=1, nrows=val_len, figsize=(9, 6 * val_len / 2))\n        for (ax, v) in zip(axes.ravel()[1:], use_variables):\n            df[[f\"{v}_observed\", f\"{v}_estimated\"]].plot.line(\n                ax=ax, ylim=(0, None), sharex=True,\n                title=f\"{self.model.NAME}: Comparison of observed/estimated {v}(t)\"\n            )\n            ax.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n            ax.ticklabel_format(style=\"sci\",  axis=\"y\", scilimits=(0, 0))\n            ax.legend(bbox_to_anchor=(1.02, 0),\n                      loc=\"lower left\", borderaxespad=0)\n        for v in use_variables:\n            df[f\"{v}_diff\"] = df[f\"{v}_observed\"] - df[f\"{v}_estimated\"]\n            df[f\"{v}_diff\"].plot.line(\n                ax=axes.ravel()[0], sharex=True,\n                title=f\"{self.model.NAME}: observed - estimated\"\n            )\n        axes.ravel()[0].axhline(y=0, color=\"black\", linestyle=\"--\")\n        axes.ravel()[0].yaxis.set_major_formatter(\n            ScalarFormatter(useMathText=True))\n        axes.ravel()[0].ticklabel_format(\n            style=\"sci\",  axis=\"y\", scilimits=(0, 0))\n        axes.ravel()[0].legend(bbox_to_anchor=(1.02, 0),\n                               loc=\"lower left\", borderaxespad=0)\n        fig.tight_layout()\n        fig.show()\n\n    def calc_r0(self):\n        \"\"\"\n        Calculate R0.\n        \"\"\"\n        est_dict = self.study.best_params.copy()\n        est_dict.update(self.fixed_param_dict)\n        est_dict.pop(\"tau\")\n        model_instance = self.model(**est_dict)\n        return model_instance.calc_r0()\n\n    def calc_days_dict(self):\n        \"\"\"\n        Calculate 1/beta etc.\n        \"\"\"\n        est_dict = self.study.best_params.copy()\n        est_dict.update(self.fixed_param_dict)\n        tau = est_dict[\"tau\"]\n        est_dict.pop(\"tau\")\n        model_instance = self.model(**est_dict)\n        return model_instance.calc_days_dict(tau)\n\n    def predict_df(self, step_n):\n        \"\"\"\n        Predict the values in the future.\n        @step_n <int>: the number of steps\n        @return <pd.DataFrame>: predicted data for measurable variables.\n        \"\"\"\n        est_dict = self.study.best_params.copy()\n        est_dict.update(self.fixed_param_dict)\n        tau = est_dict[\"tau\"]\n        est_dict.pop(\"tau\")\n        df = simulation(self.model, self.initials, step_n=step_n, **est_dict)\n        df[\"Time\"] = (\n            df[\"t\"] * tau).apply(lambda x: timedelta(minutes=x)) + self.start_time\n        df = df.set_index(\"Time\").drop(\"t\", axis=1)\n        df = (df * self.total_population).astype(np.int64)\n        upper_cols = [n.upper() for n in df.columns]\n        df.columns = upper_cols\n        df = self.model.calc_variables_reverse(df).drop(upper_cols, axis=1)\n        return df\n\n    def predict_graph(self, step_n, name=None, excluded_cols=None):\n        \"\"\"\n        Predict the values in the future and create a figure.\n        @step_n <int>: the number of steps\n        @name <str>: name of the area\n        @excluded_cols <list[str]>: the excluded columns in the figure\n        \"\"\"\n        if self.name is not None:\n            name = self.name\n        else:\n            name = str() if name is None else name\n        df = self.predict_df(step_n=step_n)\n        if excluded_cols is not None:\n            df = df.drop(excluded_cols, axis=1)\n        r0 = self.param_dict[\"R0\"]\n        title = f\"Prediction in {name} with {self.model.NAME} model: R0 = {r0}\"\n        line_plot(df, title, v=datetime.today(), h=self.total_population)\n\n    def rmsle(self, compare_df):\n        \"\"\"\n        Return the value of RMSLE.\n        @param compare_df <pd.DataFrame>\n        \"\"\"\n        df = compare_df.set_index(\"t\") * self.total_population\n        score = 0\n        for (priority, v) in zip(self.model.PRIORITIES, self.model.VARIABLES):\n            if priority == 0:\n                continue\n            observed, estimated = df[f\"{v}_observed\"], df[f\"{v}_estimated\"]\n            diff = (np.log(observed + 1) - np.log(estimated + 1))\n            score += (diff ** 2).sum()\n        rmsle = np.sqrt(score / len(df))\n        return rmsle\n\n    def score(self):\n        \"\"\"\n        Return the value of RMSLE.\n        \"\"\"\n        rmsle = self.rmsle(self.compare_df().reset_index(\"t\"))\n        return rmsle\n\n    def info(self):\n        \"\"\"\n        Return Estimater information.\n        @return <tupple[object]>:\n            - <ModelBase>: model\n            - <dict[str]=str>: name, total_population, start_time, tau\n            - <dict[str]=float>: values of parameters of model\n        \"\"\"\n        param_dict = self.study.best_params.copy()\n        param_dict.update(self.fixed_param_dict)\n        info_dict = {\n            \"name\": self.name,\n            \"total_population\": self.total_population,\n            \"start_time\": self.start_time,\n            \"tau\": param_dict[\"tau\"],\n            \"initials\": self.initials\n        }\n        param_dict.pop(\"tau\")\n        return (self.model, info_dict, param_dict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Predictor**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Predicter(object):\n    \"\"\"\n    Predict the future using models.\n    \"\"\"\n    def __init__(self, name, total_population, start_time, tau, initials, date_format=\"%d%b%Y\"):\n        \"\"\"\n        @name <str>: place name\n        @total_population <int>: total population\n        @start_time <datatime>: the start time\n        @tau <int>: tau value (time step)\n        @initials <list/tupple/np.array[float]>: initial values of the first model\n        @date_format <str>: date format to display in figures\n        \"\"\"\n        self.name = name\n        self.total_population = total_population\n        self.start_time = start_time\n        self.tau = tau\n        self.date_format = date_format\n        # Un-fixed\n        self.last_time = start_time\n        self.axvlines = list()\n        self.initials = initials\n        self.df = pd.DataFrame()\n        self.title_list = list()\n        self.reverse_f = lambda x: x\n\n    def add(self, model, end_day_n=None, count_from_last=False, vline=True, **param_dict):\n        \"\"\"\n        @model <ModelBase>: the epidemic model\n        @end_day_n <int/None>: day number of the end date (0, 1, 2,...), or None (now)\n            - if @count_from_last <bool> is True, start point will be the last date registered to Predicter\n        @vline <bool>: if True, vertical line will be shown at the end date\n        @**param_dict <dict>: keyword arguments of the model\n        \"\"\"\n        # Validate day nubber, and calculate step number\n        if end_day_n is None:\n            end_time = datetime.now()\n        else:\n            if count_from_last:\n                end_time = self.last_time + timedelta(days=end_day_n)\n            else:\n                end_time = self.start_time + timedelta(days=end_day_n)\n        if end_time <= self.last_time:\n            raise Exception(f\"Model on {end_time.strftime(self.date_format)} has been registered!\")\n        step_n = int((end_time - self.last_time).total_seconds() / 60 / self.tau)\n        self.last_time = end_time\n        # Perform simulation\n        new_df = simulation(model, self.initials, step_n=step_n, **param_dict)\n        new_df[\"t\"] = new_df[\"t\"] + len(self.df)\n        self.df = pd.concat([self.df, new_df.iloc[1:, :]], axis=0).fillna(0)\n        self.initials = new_df.set_index(\"t\").iloc[-1, :]\n        # For title\n        if vline:\n            self.axvlines.append(end_time)\n            r0 = model(**param_dict).calc_r0()\n            self.title_list.append(\n                f\"{model.NAME}({r0}, -{end_time.strftime(self.date_format)})\"\n            )\n        # Update reverse function (X, Y,.. to Susceptible, Infected,...)\n        self.reverse_f = model.calc_variables_reverse\n        return self\n\n    def restore_df(self):\n        \"\"\"\n        Return the dimentional simulated data.\n        @return <pd.DataFrame>\n        \"\"\"\n        df = self.df.copy()\n        df[\"Time\"] = self.start_time + df[\"t\"].apply(lambda x: timedelta(minutes=x * self.tau))\n        df = df.drop(\"t\", axis=1).set_index(\"Time\") * self.total_population\n        df = df.astype(np.int64)\n        upper_cols = [n.upper() for n in df.columns]\n        df.columns = upper_cols\n        df = self.reverse_f(df).drop(upper_cols, axis=1)\n        return df\n\n    def restore_graph(self, drop_cols=None, **kwargs):\n        \"\"\"\n        Show the dimentional simulate data as a figure.\n        @drop_cols <list[str]>: the columns not to be shown\n        @kwargs: keyword arguments of line_plot() function\n        \"\"\"\n        df = self.restore_df()\n        if drop_cols is not None:\n            df = df.drop(drop_cols, axis=1)\n        axvlines = [datetime.now(), *self.axvlines] if len(self.axvlines) == 1 else self.axvlines[:]\n        line_plot(\n            df,\n            title=f\"{self.name}: {', '.join(self.title_list)}\",\n            v=axvlines[:-1],\n            h=self.total_population,\n            **kwargs\n        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw = pd.read_csv(\"/kaggle/input/novel-corona-virus-2019-dataset/covid_19_data.csv\")\nraw.tail()\npd.DataFrame(raw.isnull().sum()).T\n\", \".join(raw[\"Country/Region\"].unique().tolist())\npprint(raw.loc[raw[\"Country/Region\"] == \"Others\", \"Province/State\"].unique().tolist(), compact=True)\ndata_cols = [\"Infected\", \"Deaths\", \"Recovered\"]\ndata_cols_all = [\"Confirmed\", \"Infected\", \"Deaths\", \"Recovered\"]\nrate_cols = [\"Fatal per Confirmed\", \"Recovered per Confirmed\", \"Fatal per (Fatal or Recovered)\"]\nvariable_dict = {\"Susceptible\": \"S\", \"Infected\": \"I\", \"Recovered\": \"R\", \"Deaths\": \"D\"}\ndf = raw.rename({\"ObservationDate\": \"Date\", \"Province/State\": \"Province\"}, axis=1)\ndf[\"Date\"] = pd.to_datetime(df[\"Date\"])\ndf[\"Country\"] = df[\"Country/Region\"].replace(\n    {\n        \"Mainland China\": \"China\",\n        \"Hong Kong SAR\": \"Hong Kong\",\n        \"Taipei and environs\": \"Taiwan\",\n        \"Iran (Islamic Republic of)\": \"Iran\",\n        \"Republic of Korea\": \"South Korea\",\n        \"Republic of Ireland\": \"Ireland\",\n        \"Macao SAR\": \"Macau\",\n        \"Russian Federation\": \"Russia\",\n        \"Republic of Moldova\": \"Moldova\",\n        \"Taiwan*\": \"Taiwan\",\n        \"Cruise Ship\": \"Others\",\n        \"United Kingdom\": \"UK\",\n        \"Viet Nam\": \"Vietnam\",\n        \"Czechia\": \"Czech Republic\",\n        \"St. Martin\": \"Saint Martin\",\n        \"Cote d'Ivoire\": \"Ivory Coast\",\n        \"('St. Martin',)\": \"Saint Martin\",\n        \"Congo (Kinshasa)\": \"Congo\",\n    }\n)\ndf[\"Province\"] = df[\"Province\"].fillna(\"-\").replace(\n    {\n        \"Cruise Ship\": \"Diamond Princess\",\n        \"Diamond Princess cruise ship\": \"Diamond Princess\"\n    }\n)\ndf.loc[df[\"Country\"] == \"Diamond Princess\", [\"Country\", \"Province\"]] = [\"Others\", \"Diamond Princess\"]\ndf[\"Infected\"] = df[\"Confirmed\"] - df[\"Deaths\"] - df[\"Recovered\"]\ndf[data_cols_all] = df[data_cols_all].astype(np.int64)\nncov_df_ungrouped = df.loc[:, [\"Date\", \"Country\", \"Province\", *data_cols_all]]\nncov_df_ungrouped.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ncov_df_ungrouped.info()\nncov_df_ungrouped.describe(include=\"all\").fillna(\"-\")\npd.DataFrame(ncov_df_ungrouped.isnull().sum()).T\n\", \".join(ncov_df_ungrouped[\"Country\"].unique().tolist())\ntotal_df = ncov_df_ungrouped.groupby(\"Date\").sum()\ntotal_df[rate_cols[0]] = total_df[\"Deaths\"] / total_df[data_cols].sum(axis=1)\ntotal_df[rate_cols[1]] = total_df[\"Recovered\"] / total_df[data_cols].sum(axis=1)\ntotal_df[rate_cols[2]] = total_df[\"Deaths\"] / (total_df[\"Deaths\"] + total_df[\"Recovered\"])\ntotal_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f\"{(total_df.index.max() - total_df.index.min()).days} days have passed from the date of the first record.\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"line_plot(total_df[data_cols], \"Total number of cases over time\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linelist_open_raw = pd.read_csv(\"/kaggle/input/novel-corona-virus-2019-dataset/COVID19_open_line_list.csv\")\nlinelist_open_raw.info()\ndf = linelist_open_raw.loc[:, ~linelist_open_raw.columns.str.startswith(\"Unnamed:\")]\ndf = df.dropna(axis=0, how=\"all\")\ndf = df.drop(\n    [\n        # Unnecessary in this notebook\n        \"ID\", \"wuhan(0)_not_wuhan(1)\", \"admin3\", \"admin2\", \"admin1\", \"country_new\", \"admin_id\",\n        \"data_moderator_initials\", \"source\", \"location\", \"lives_in_Wuhan\", \"notes_for_discussion\",\n        \"sequence_available\", \"reported_market_exposure\",\n        # Maybe useful, but un-used\n        \"city\", \"latitude\", \"longitude\", \"geo_resolution\", \"additional_information\",\n        \"travel_history_dates\", \"travel_history_location\", \n    ],\n    axis=1\n)\n# Personal\nage = linelist_open_raw[\"age\"].str.split(\"-\", expand=True)\nage[0] = pd.to_numeric(age[0], errors=\"coerce\")\nage[1] = pd.to_numeric(age[1], errors=\"coerce\")\ndf[\"Age\"] = age.mean(axis=1)\ndf[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].median()).astype(np.int64)\ndf[\"Sex\"] = df[\"sex\"].fillna(\"-\").str.replace(\"4000\", \"-\").str.capitalize()\n# Place\ndf[\"Country\"] = df[\"country\"].fillna(\"-\")\ndf[\"Province\"] = df[\"province\"].fillna(\"-\")\n# Onset Date\nseries = df[\"date_onset_symptoms\"].str.replace(\"end of December 2019\", \"31.12.2019\").replace(\"-25.02.2020\", \"25.02.2020\")\nseries = series.replace(\"20.02.220\", \"20.02.2020\").replace(\"none\", np.NaN).replace(\"10.01.2020 - 22.01.2020\", np.NaN)\ndf[\"Onset_date\"] = pd.to_datetime(series)\n# Hospitalized date\nseries = df[\"date_admission_hospital\"].replace(\"18.01.2020 - 23.01.2020\", np.NaN)\ndf[\"Hospitalized_date\"] = pd.to_datetime(series)\n# Confirmed date\nseries = df[\"date_confirmation\"].replace(\"25.02.2020-26.02.2020\", np.NaN)\ndf[\"Confirmed_date\"] = pd.to_datetime(series)\n# Symptoms/events\ndf[\"Symptoms\"] = df[\"symptoms\"].fillna(\"-\").str.lower()\n# Underlying disease\ndf[\"Underlying_disease\"] = df[[\"chronic_disease_binary\", \"chronic_disease\"]].apply(\n    lambda x: \"No\" if x[0] == 0 else x[1] if x[1] is not np.NaN else \"-\",\n    axis=1\n).str.strip(\";\").str.replace(\"; \", \",\").str.replace(\", \", \",\")\n# Outcome\ndf[\"Outcome\"] = df[\"outcome\"].replace(\n    {\n        \"discharge\": \"discharged\", \"Discharged\": \"discharged\", \"death\": \"died\",\n        \"critical condition, intubated as of 14.02.2020\": \"severe\",\n        \"treated in an intensive care unit (14.02.2020)\": \"severe\", \"05.02.2020\": \"-\",\n        \"Symptoms only improved with cough. Currently hospitalized for follow-up.\": \"stable\"\n    }\n).fillna(\"-\")\nseries = df[\"date_death_or_discharge\"].replace(\"discharge\", np.NaN)\ndf[\"Closed_date\"] = pd.to_datetime(series)\n# Show\nuse_cols = [\n    \"Age\", \"Sex\", \"Country\", \"Province\", \"Onset_date\", \"Hospitalized_date\", \"Confirmed_date\", \n    \"Symptoms\", \"Underlying_disease\", \"Outcome\", \"Closed_date\"\n]\nopen_linelist_df = df.loc[:, use_cols]\nopen_linelist_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linelist_raw = pd.read_csv(\"/kaggle/input/novel-corona-virus-2019-dataset/COVID19_line_list_data.csv\")\nlinelist_raw.info()\nlinelist_raw.head()\ndf = linelist_raw.loc[:, ~linelist_raw.columns.str.startswith(\"Unnamed:\")]\ndf = df.drop([\"id\", \"case_in_country\", \"summary\", \"source\", \"link\"], axis=1)\n# Date\ncase_date_dict = {\n    \"reporting date\": \"Confirmed_date\",\n    \"exposure_start\": \"Exposed_date\",\n    \"exposure_end\": \"Quarantined_date\",\n    \"hosp_visit_date\": \"Hospitalized_date\",\n    \"symptom_onset\": \"Onset_date\",\n    \"death\": \"Deaths_date\",\n    \"recovered\": \"Recovered_date\"    \n}\ndf[\"death\"] = df[\"death\"].replace({\"0\": \"\", \"1\": \"\"})\ndf[\"recovered\"] = df[\"recovered\"].replace({\"0\": \"\", \"1\": \"\", \"12/30/1899\": \"12/30/2019\"})\nfor (col, _) in case_date_dict.items():\n    df[col] = pd.to_datetime(df[col])\ndf = df.rename(case_date_dict, axis=1)\n# Location\ndf[\"Country\"] = df[\"country\"].fillna(\"-\")\ndf[\"Province\"] = df[\"location\"].fillna(\"-\")\ndf[\"Province\"] = df[[\"Country\", \"Province\"]].apply(lambda x: \"-\" if x[0] == x[1] else x[1], axis=1)\n# Personal\ndf[\"Gender\"] = df[\"gender\"].fillna(\"-\").str.capitalize()\ndf[\"Age\"] = df[\"age\"].fillna(df[\"age\"].median()).astype(np.int64) ## Fill in NA with median\ndf[\"From_Wuhan\"] = df[\"from Wuhan\"]\ndf[\"To_Wuhan\"] = df[\"visiting Wuhan\"]\n# Medical\ndf[\"Events\"] = df[\"symptom\"].fillna(\"-\")\n# Order of columns\nlinelist_df = df.loc[\n    :,\n    [\n        \"Country\", \"Province\",\n        \"Exposed_date\", \"Onset_date\", \"Hospitalized_date\", \"Confirmed_date\", \"Quarantined_date\", \"Deaths_date\", \"Recovered_date\",\n        \"Events\",\n        \"Gender\", \"Age\", \"From_Wuhan\", \"To_Wuhan\"\n    ]\n]\nlinelist_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linelist_df.info()\nlinelist_df.describe(include=\"all\").fillna(\"-\")\nperiod_df = select_area(linelist_df, group=None)\nperiod_df = period_df.loc[:, [\"Exposed_date\", \"Onset_date\", \"Confirmed_date\"]]\nperiod_df[\"Latent [min]\"] = (period_df[\"Onset_date\"] - period_df[\"Exposed_date\"]).dt.total_seconds() / 60\nperiod_df[\"Waiting [min]\"] = (period_df[\"Confirmed_date\"] - period_df[\"Onset_date\"]).dt.total_seconds() / 60\nperiod_df[\"Latent [day]\"] = period_df[\"Latent [min]\"] / 60 / 24\nperiod_df[\"Waiting [day]\"] = period_df[\"Waiting [min]\"] / 60 / 24\nperiod_df[\"Latent + Waiting [day]\"] = period_df[\"Latent [day]\"] + period_df[\"Waiting [day]\"]\nperiod_df.dropna(axis=0).tail()\ncols = [\"Latent [day]\", \"Waiting [day]\", \"Latent + Waiting [day]\"]\nperiod_df[cols].plot.kde()\nplt.title(\"Kernel density estimation of latent period and waiting time for confirmation [day]\")\nplt.show()\nperiod_df[cols].describe().T\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sweden_raw = pd.read_csv(\n    \"/kaggle/input/novel-corona-virus-2019-dataset/covid_19_data.csv\"\n)\nsweden_raw.head()\ndf = sweden_raw.copy()\ndf = df.drop([\"Country/Region\",\"Last Update\"], axis=1)\ndf.columns = [col.capitalize().replace(\" \", \"_\") for col in df.columns]\ndf[\"Observationdate\"] = pd.to_datetime(df[\"Observationdate\"])\ndf[\"Province/state\"] = df[\"Province/state\"].fillna(\"-\")\nsweden_df = df.copy()\nsweden_df.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Calculate growth factor\nWhere  C  is the number of confirmed cases\nGrowth Factor = ΔCn/ΔCn-1\n**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = ncov_df_ungrouped.pivot_table(\n    index=\"Date\", columns=\"Country\", values=\"Confirmed\", aggfunc=\"sum\"\n).fillna(method=\"ffill\").fillna(0)\n# Growth factor: (delta Number_n) / (delta Number_n)\ndf = df.diff() / df.diff().shift(freq=\"D\")\ndf = df.replace(np.inf, np.nan).fillna(1)\n# Rolling mean (window: 7 days)\ndf = df.rolling(7).mean()\ndf = df.iloc[6:-1, :]\n# round: 0.1\ngrowth_value_df = df.round(1)\ngrowth_value_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = growth_value_df.copy()\ndf = df.iloc[-7:, :].T\nday_cols = df.columns.strftime(\"%d%b%Y\")\ndf.columns = day_cols\n# Grouping\nmore_col, less_col = \"GF > 1 [straight days]\", \"GF < 1 [straight days]\"\ndf[more_col] = (growth_value_df > 1).iloc[::-1].cumprod().sum(axis=0)\ndf[less_col] = (growth_value_df < 1).iloc[::-1].cumprod().sum(axis=0)\ndf[\"Group\"] = df[[more_col, less_col]].apply(\n    lambda x: \"Outbreaking\" if x[0] >= 7 else \"Stopping\" if x[1] >= 7 else \"Crossroad\",\n    axis=1\n)\n# Sorting\ndf = df.loc[:, [\"Group\", more_col, less_col, *day_cols]]\ndf = df.sort_values([\"Group\", more_col, less_col], ascending=False)\ngrowth_df = df.copy()\ngrowth_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.merge(ncov_df_ungrouped, growth_df[\"Group\"].reset_index(), on=\"Country\")\nncov_df = df.loc[:, [\"Date\", \"Group\", *ncov_df_ungrouped.columns[1:]]]\nncov_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pprint(growth_df.loc[growth_df[\"Group\"] == \"Outbreaking\", :].index.tolist(), compact=True)\ngrowth_df.loc[growth_df[\"Group\"] == \"Outbreaking\", :].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = ncov_df.loc[ncov_df[\"Group\"] == \"Outbreaking\", [\"Date\", *data_cols]].groupby(\"Date\").sum()\nline_plot(df, \"Group 1 (Outbreaking): Cases over time\", y_integer=True)\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"critical_country_start = \"23Mar2020\"\ncritical_country = \"Sweden\"\ntrain_dataset = SIR.create_dataset(\n    ncov_df, population_dict[critical_country], excluded_places=[(critical_country, None)],\n    start_date=critical_country_start\n)\ntrain_start_date, train_initials, train_Tend, train_df = train_dataset\npprint([train_start_date.strftime(\"%d%b%Y\"), train_initials, train_Tend])\ntrain_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"line_plot(\n    train_df.set_index(\"T\").drop(\"x\", axis=1),\n    \"Training data: y(T), z(T)\", math_scale=False, ylabel=\"\"\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eg_r0, eg_rho = (2.5, 0.2)\neg_sigma = eg_rho / eg_r0\n(eg_rho, eg_sigma)\n\neg_df = simulation(SIR, train_initials, step_n=200, rho=eg_rho, sigma=eg_sigma)\neg_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"line_plot(\n    eg_df.set_index(\"t\"),\n    title=r\"SIR: $R_0$={0} ($\\rho$={1}, $\\sigma$={2})\".format(eg_r0, eg_rho, eg_sigma),\n    ylabel=\"\",\n    h=1\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set the example conditions\neg_tau = 1440\neg_start_date = ncov_df[\"Date\"].min()\neg_total_population = 1000000\n# Create dataset in the format of ncov_df\neg_ori_df = pd.DataFrame(\n    {\n        \"Date\": (eg_df[\"t\"] * eg_tau).apply(lambda x: timedelta(minutes=x)) + eg_start_date,\n        \"Country\": \"Example\",\n        \"Province\": \"Example\"\n    }\n)\neg_ori_df[\"Infected\"] = (eg_df[\"y\"] * eg_total_population).astype(np.int64)\neg_ori_df[\"Deaths\"] = (eg_df[\"z\"] * eg_total_population * 0.02).astype(np.int64)\neg_ori_df[\"Recovered\"] = (eg_df[\"z\"] * eg_total_population * 0.98).astype(np.int64)\neg_ori_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sirf_estimator = Estimator(\n    SIRF, ncov_df, population_dict[critical_country],\n    name=critical_country, places=[(critical_country, None)],\n    start_date=critical_country_start\n)\nsirf_dict = sirf_estimator.run()\nsirf_estimator.history_df().head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sirf_estimator.history_graph()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame.from_dict({\"SIR-F\": sirf_dict}, orient=\"index\").fillna(\"-\")\nsirf_estimator.compare_graph()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sirf_estimator.predict_graph(step_n=300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = sirf_estimator.predict_df(300)\ndf.loc[datetime.today():, [\"Infected\", \"Recovered\", \"Fatal\"]].head(25).style.background_gradient(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"period_df = select_area(linelist_df, group=None)\nperiod_df = period_df.loc[:, [\"Exposed_date\", \"Onset_date\", \"Confirmed_date\"]]\nperiod_df[\"Latent [min]\"] = (period_df[\"Onset_date\"] - period_df[\"Exposed_date\"]).dt.total_seconds() / 60\nperiod_df[\"Waiting [min]\"] = (period_df[\"Confirmed_date\"] - period_df[\"Onset_date\"]).dt.total_seconds() / 60\nperiod_df[\"Latent [day]\"] = period_df[\"Latent [min]\"] / 60 / 24\nperiod_df[\"Waiting [day]\"] = period_df[\"Waiting [min]\"] / 60 / 24\nperiod_df[\"Latent + Waiting [day]\"] = period_df[\"Latent [day]\"] + period_df[\"Waiting [day]\"]\nperiod_df.dropna(axis=0).tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = [\"Latent [day]\", \"Waiting [day]\", \"Latent + Waiting [day]\"]\nperiod_df[cols].plot.kde()\nplt.title(\"Kernel density estimation of latent period and waiting time for confirmation [day]\")\nplt.show()\nperiod_df[cols].describe().T\nlatent_period = period_df[\"Latent [min]\"].median()\nwaiting_time = period_df[\"Waiting [min]\"].median()\nlatent_waiting_day = period_df[\"Latent + Waiting [day]\"].median()\ntau = sirf_estimator.info()[1][\"tau\"]\nrho2, rho3 = tau / latent_period, tau / waiting_time\n(rho2, rho3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sewirf_estimator = Estimator(\n    SEWIRF, ncov_df, population_dict[critical_country],\n    name=critical_country, excluded_places=[(critical_country, None)],\n    start_date=critical_country_start,\n    tau=tau, rho2=rho2, rho3=rho3\n)\nsewirf_dict = sewirf_estimator.run()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sewirf_estimator.compare_graph()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame.from_dict({\"SIR-F\": sirf_dict, \"SEWIR-F\": sewirf_dict}, orient=\"index\").fillna(\"-\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"first_model, info_dict, param_dict = sewirf_estimator.info()\npredicter = Predicter(**info_dict)\npredicter.add(SEWIRF, end_day_n=None, vline=False, **param_dict)\npredicter.add(SEWIRF, end_day_n=7, count_from_last=True, **param_dict)\npredicter.restore_graph(drop_cols=[\"Susceptible\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = predicter.restore_df()\ndf.loc[datetime.today():, [\"Exposed\", \"Waiting\", \"Infected\", \"Recovered\", \"Fatal\"]].style.background_gradient(axis=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicter = Predicter(**info_dict)\npredicter.add(SEWIRF, end_day_n=200, count_from_last=False, **param_dict)\npredicter.restore_graph(drop_cols=None)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}