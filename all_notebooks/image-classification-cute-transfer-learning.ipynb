{"cells":[{"metadata":{},"cell_type":"markdown","source":"# This is Image Classification for Cute"},{"metadata":{},"cell_type":"markdown","source":"Get the current working directory"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['image-classification', 'vgg16-weights']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH=os.getcwd()\nprint(PATH)","execution_count":2,"outputs":[{"output_type":"stream","text":"/kaggle/working\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH=\"../input/image-classification/image/Image/10_categories\"","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(PATH))","execution_count":4,"outputs":[{"output_type":"stream","text":"['car_side', 'watch', 'bonsai', 'grand_piano', 'BACKGROUND_Google', 'airplanes', 'Faces_easy', 'Motorbikes', 'Leopards', 'Faces']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_rows=224\nimg_cols=224\nnum_channel=3\n\nnum_epoch=3\nbatch_size=32\n\nimg_data_list=[]\nclasses_names_list=[]\ndata_dir_list=os.listdir(PATH)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\n\nfor dataset in data_dir_list:\n    classes_names_list.append(dataset) \n    print ('Loading images from {} folder\\n'.format(dataset)) \n    img_list=os.listdir(PATH+'/'+ dataset)\n    for img in img_list:\n        input_img=cv2.imread(PATH + '/'+ dataset + '/'+ img )\n        input_img_resize=cv2.resize(input_img,(img_rows, img_cols))\n        img_data_list.append(input_img_resize)","execution_count":6,"outputs":[{"output_type":"stream","text":"Loading images from car_side folder\n\nLoading images from watch folder\n\nLoading images from bonsai folder\n\nLoading images from grand_piano folder\n\nLoading images from BACKGROUND_Google folder\n\nLoading images from airplanes folder\n\nLoading images from Faces_easy folder\n\nLoading images from Motorbikes folder\n\nLoading images from Leopards folder\n\nLoading images from Faces folder\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = len(classes_names_list)\nprint(num_classes)","execution_count":7,"outputs":[{"output_type":"stream","text":"10\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\nimg_data = np.array(img_data_list)\nimg_data = img_data.astype('float32')\nimg_data /= 255","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_of_samples = img_data.shape[0]\ninput_shape = img_data[0].shape","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (img_data.shape)\nprint(num_of_samples)\nprint(input_shape)","execution_count":10,"outputs":[{"output_type":"stream","text":"(3725, 224, 224, 3)\n3725\n(224, 224, 3)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = np.ones((num_of_samples,), dtype='int64')\n\nclasses[0:239]=0\nclasses[239:367]=1\nclasses[367:490]=2\nclasses[490:690]=3\nclasses[690:1490]=4\nclasses[1490:1958]=5\nclasses[1958:2393]=6\nclasses[2393:2828]=7\nclasses[2828:3626]=8\nclasses[3626:]=9\n","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\n\nclasses = to_categorical(classes, num_classes)","execution_count":12,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classes.shape)\nprint(classes)\n","execution_count":13,"outputs":[{"output_type":"stream","text":"(3725, 10)\n[[1. 0. 0. ... 0. 0. 0.]\n [1. 0. 0. ... 0. 0. 0.]\n [1. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 1.]\n [0. 0. 0. ... 0. 0. 1.]\n [0. 0. 0. ... 0. 0. 1.]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import shuffle\n\nX, Y = shuffle(img_data, classes, random_state=2)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=2)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.shape","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"(745, 10)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D","execution_count":17,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))","execution_count":18,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=[\"accuracy\"])","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epoch=12","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ndata_gen = ImageDataGenerator(\n    rotation_range=20,\n    shear_range=0.5, \n    zoom_range=0.4, \n    rescale=1./255,\n    vertical_flip=True, \n    validation_split=0.2,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True) ","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#TRN_AUGMENTED = os.path.join(PATH  , 'Trn_Augmented_Images')\n#TST_AUGMENTED = os.path.join(PATH  , 'Tst_Augmented_Images')","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = data_gen.flow_from_directory(\n        PATH,\n        target_size=(img_rows, img_cols), \n        batch_size=batch_size,\n        class_mode='categorical',\n        color_mode='rgb', \n        shuffle=True)\n\n #       save_to_dir=TRN_AUGMENTED, \n #       save_prefix='TrainAugmented', \n #       save_format='png', \n #       subset=\"training\")","execution_count":23,"outputs":[{"output_type":"stream","text":"Found 3724 images belonging to 10 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator.class_indices","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"{'BACKGROUND_Google': 0,\n 'Faces': 1,\n 'Faces_easy': 2,\n 'Leopards': 3,\n 'Motorbikes': 4,\n 'airplanes': 5,\n 'bonsai': 6,\n 'car_side': 7,\n 'grand_piano': 8,\n 'watch': 9}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generator = data_gen.flow_from_directory(\n        PATH,\n        target_size=(img_rows, img_cols),\n        batch_size=32,\n        class_mode='categorical',\n        color_mode='rgb', \n        shuffle=True, \n        seed=None)\n\n#        save_to_dir=TST_AUGMENTED, \n#        save_prefix='TestAugmented', \n#        save_format='png',\n#        subset=\"validation\")","execution_count":25,"outputs":[{"output_type":"stream","text":"Found 3724 images belonging to 10 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generator.class_indices","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"{'BACKGROUND_Google': 0,\n 'Faces': 1,\n 'Faces_easy': 2,\n 'Leopards': 3,\n 'Motorbikes': 4,\n 'airplanes': 5,\n 'bonsai': 6,\n 'car_side': 7,\n 'grand_piano': 8,\n 'watch': 9}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(train_generator, epochs=num_epoch, validation_data=test_generator,steps_per_epoch = len(X_train)/batch_size,validation_steps=len(X_test)/batch_size)","execution_count":27,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/12\n94/93 [==============================] - 56s 597ms/step - loss: 2.1697 - acc: 0.2839 - val_loss: 1.8436 - val_acc: 0.4531\nEpoch 2/12\n94/93 [==============================] - 49s 518ms/step - loss: 1.6486 - acc: 0.4511 - val_loss: 1.3899 - val_acc: 0.5872\nEpoch 3/12\n94/93 [==============================] - 49s 519ms/step - loss: 1.4037 - acc: 0.5307 - val_loss: 1.0928 - val_acc: 0.6289\nEpoch 4/12\n94/93 [==============================] - 48s 514ms/step - loss: 1.2986 - acc: 0.5644 - val_loss: 0.9301 - val_acc: 0.6680\nEpoch 5/12\n94/93 [==============================] - 48s 508ms/step - loss: 1.1947 - acc: 0.5985 - val_loss: 1.0107 - val_acc: 0.6471\nEpoch 6/12\n94/93 [==============================] - 48s 516ms/step - loss: 1.1591 - acc: 0.6320 - val_loss: 0.9284 - val_acc: 0.7070\nEpoch 7/12\n94/93 [==============================] - 48s 513ms/step - loss: 1.1161 - acc: 0.6363 - val_loss: 0.8062 - val_acc: 0.7161\nEpoch 8/12\n94/93 [==============================] - 48s 506ms/step - loss: 1.0611 - acc: 0.6540 - val_loss: 0.7926 - val_acc: 0.7253\nEpoch 9/12\n94/93 [==============================] - 48s 507ms/step - loss: 1.0800 - acc: 0.6334 - val_loss: 0.7997 - val_acc: 0.7240\nEpoch 10/12\n94/93 [==============================] - 48s 506ms/step - loss: 1.0021 - acc: 0.6517 - val_loss: 0.7760 - val_acc: 0.7299\nEpoch 11/12\n94/93 [==============================] - 48s 514ms/step - loss: 1.0162 - acc: 0.6596 - val_loss: 0.7908 - val_acc: 0.7227\nEpoch 12/12\n94/93 [==============================] - 49s 521ms/step - loss: 1.0189 - acc: 0.6576 - val_loss: 0.9338 - val_acc: 0.6979\n","name":"stdout"},{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"<keras.callbacks.History at 0x7f71a993ec88>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate_generator(train_generator,steps = len(X_train)/batch_size,verbose=1)","execution_count":28,"outputs":[{"output_type":"stream","text":"94/93 [==============================] - 40s 428ms/step\n","name":"stdout"},{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"[0.9613352602265446, 0.7028112450597117]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred = model.predict(X_test)\nprint(Y_pred)\nY_train_result = model.predict(X_train)\nprint(Y_train_result)","execution_count":29,"outputs":[{"output_type":"stream","text":"[[2.2713083e-01 8.0612898e-02 4.3078926e-03 ... 6.4196871e-03\n  3.2189243e-02 2.4310574e-01]\n [2.3544773e-01 3.5610878e-01 3.8375934e-03 ... 5.6239096e-03\n  1.1530529e-02 1.2669747e-01]\n [2.1850845e-01 2.9675609e-02 1.6193866e-03 ... 3.5028593e-03\n  1.8292662e-02 3.2964915e-01]\n ...\n [1.0514811e-01 5.6129828e-02 1.0421747e-02 ... 3.6626149e-04\n  2.2161307e-02 1.8632211e-01]\n [5.4655021e-01 4.3969404e-02 6.6151371e-04 ... 3.1659788e-08\n  3.5682222e-06 4.0849230e-01]\n [8.2392665e-04 2.8876022e-07 2.3655806e-09 ... 1.0115013e-08\n  5.7426252e-04 2.6890347e-03]]\n[[2.49625318e-05 1.53155572e-10 3.59275123e-14 ... 3.67045424e-13\n  4.60792171e-06 8.58438652e-05]\n [3.46100181e-02 2.39063259e-02 1.56059302e-03 ... 6.68716490e-01\n  1.87495002e-03 2.75037140e-02]\n [1.31479442e-01 5.18393063e-06 2.37264430e-07 ... 6.63837341e-07\n  2.38967245e-03 6.44101024e-01]\n ...\n [2.01428175e-01 3.43344808e-02 4.49256942e-04 ... 8.00235488e-04\n  1.10783977e-02 1.19015664e-01]\n [4.03131053e-05 5.66541085e-11 9.68192608e-14 ... 2.26117207e-13\n  2.20949823e-05 3.45898065e-04]\n [8.22510421e-02 7.00569665e-03 8.78059014e-04 ... 7.71066220e-03\n  4.14376669e-02 1.46307036e-01]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = np.argmax(Y_pred, axis=1)\nprint(y_pred)\ny_train_result = np.argmax(Y_train_result, axis=1)\nprint(y_train_result)","execution_count":30,"outputs":[{"output_type":"stream","text":"[4 1 4 4 4 4 4 2 4 5 4 4 0 4 4 4 4 0 4 4 5 5 4 5 4 5 0 4 5 5 4 5 4 4 5 4 4\n 5 0 4 4 4 4 4 4 4 4 4 3 0 4 4 4 4 4 4 0 4 4 4 0 4 0 4 5 5 0 4 4 0 4 0 4 5\n 5 5 0 5 0 0 4 4 4 4 1 4 4 4 9 4 0 4 4 5 4 4 5 5 4 4 5 4 5 0 4 4 4 5 4 4 4\n 4 4 5 4 4 4 0 4 4 1 4 4 4 4 7 4 5 5 4 4 5 5 4 4 1 4 4 9 0 4 4 4 4 0 7 4 5\n 4 4 4 4 4 4 4 4 0 4 4 4 4 4 4 5 4 4 4 5 0 4 4 4 4 5 4 4 1 4 4 4 0 4 0 4 4\n 4 4 0 4 4 5 4 4 4 0 5 4 4 1 4 4 4 5 4 4 4 4 5 5 5 4 5 4 5 5 4 4 4 4 5 2 9\n 4 4 4 4 4 4 4 4 4 3 9 4 4 5 4 7 0 0 5 7 5 4 1 7 4 4 4 5 0 4 4 4 4 4 0 4 4\n 4 0 5 4 4 0 4 4 4 4 4 4 4 4 5 4 4 4 4 4 4 5 4 5 0 4 4 4 9 7 5 4 5 4 4 4 4\n 5 5 4 4 4 0 5 5 4 4 4 9 4 4 4 4 7 4 5 4 4 4 4 1 4 4 5 0 4 4 4 4 4 4 3 4 4\n 5 4 4 4 4 4 4 0 4 4 9 0 4 5 4 0 1 5 4 4 0 4 5 4 7 4 4 4 4 4 4 5 4 4 4 4 0\n 5 4 1 4 4 5 4 5 5 5 4 4 5 4 4 4 4 4 0 4 0 4 1 4 0 5 0 4 7 9 4 0 4 0 4 5 4\n 4 2 4 4 4 4 4 4 4 4 1 4 4 4 5 4 4 4 9 1 4 4 5 0 5 4 4 7 4 4 2 4 4 0 5 4 5\n 2 4 5 4 4 4 4 4 5 0 4 5 4 4 4 4 0 0 4 4 5 4 5 4 0 5 4 4 4 4 0 0 0 4 0 4 9\n 4 7 4 0 1 4 4 5 4 5 0 0 4 4 4 4 4 2 0 4 5 5 4 3 0 4 4 0 5 4 4 4 5 4 4 1 4\n 4 4 0 5 4 5 4 7 5 5 0 4 4 5 1 9 4 4 1 4 4 5 4 4 4 9 4 0 4 0 0 4 4 4 4 5 7\n 0 4 5 4 5 0 0 4 5 4 4 4 0 4 0 4 0 4 4 0 4 4 4 0 4 4 4 4 0 0 4 4 0 4 4 9 4\n 4 0 9 4 7 4 4 4 4 4 4 4 4 4 0 4 0 4 0 4 4 4 4 4 4 0 5 9 4 4 2 4 4 5 4 0 4\n 4 5 4 4 7 5 4 4 4 4 4 4 4 4 7 5 4 4 0 9 1 4 4 0 9 0 4 0 9 4 4 4 5 9 4 0 4\n 4 4 4 4 4 4 4 0 4 0 0 4 0 4 0 4 4 4 4 4 4 4 4 1 5 4 4 4 4 4 4 0 4 4 5 5 5\n 4 0 5 4 4 4 5 1 0 4 4 4 0 4 4 4 4 1 5 4 0 0 4 4 4 0 4 4 0 4 0 4 4 4 4 5 5\n 4 4 4 0 4]\n[4 7 9 ... 4 4 4]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report,accuracy_score\n","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ny_true=np.argmax(y_test,axis=1)\ny_true_train=np.argmax(y_train,axis=1)\n","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_pred,y_true))\nprint(classification_report(y_train_result,y_true_train))\nprint(\"test accuracy = \",accuracy_score(y_pred,y_true))\nprint(\"validation accuracy = \",accuracy_score(y_train_result,y_true_train))","execution_count":33,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       0.05      0.03      0.04       103\n           1       0.00      0.00      0.00        21\n           2       0.00      0.00      0.00         7\n           3       0.02      0.25      0.04         4\n           4       0.34      0.11      0.16       463\n           5       0.47      0.42      0.44       112\n           6       0.00      0.00      0.00         0\n           7       0.00      0.00      0.00        16\n           8       0.00      0.00      0.00         0\n           9       0.00      0.00      0.00        19\n\n   micro avg       0.13      0.13      0.13       745\n   macro avg       0.09      0.08      0.07       745\nweighted avg       0.29      0.13      0.17       745\n\n              precision    recall  f1-score   support\n\n           0       0.07      0.03      0.04       399\n           1       0.00      0.00      0.00        94\n           2       0.00      0.00      0.00        34\n           3       0.01      0.08      0.01        13\n           4       0.39      0.14      0.20      1867\n           5       0.45      0.39      0.42       430\n           6       0.00      0.00      0.00        13\n           7       0.00      0.00      0.00        45\n           8       0.00      0.00      0.00         0\n           9       0.03      0.02      0.02        85\n\n   micro avg       0.15      0.15      0.15      2980\n   macro avg       0.09      0.07      0.07      2980\nweighted avg       0.32      0.15      0.19      2980\n\ntest accuracy =  0.1342281879194631\nvalidation accuracy =  0.14731543624161073\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from IPython.display import Image\n#Image(filename='vgg16.png')","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Input, Dense","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Custom_vgg_model_1\n#Training the classifier alone\nimage_input = Input(shape=(img_rows, img_cols, num_channel))","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications.vgg16 import VGG16\n\nprint(os.listdir(\"../input/vgg16-weights\"))","execution_count":37,"outputs":[{"output_type":"stream","text":"['vgg16_weights_tf_dim_ordering_tf_kernels.h5']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import applications\nmodel = VGG16(input_tensor=image_input, include_top=True, weights='../input/vgg16-weights/vgg16_weights_tf_dim_ordering_tf_kernels.h5', )","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_layer = model.get_layer('fc2').output\nout = Dense(num_classes, activation='softmax', name='output')(last_layer)","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Model\n\ncustom_vgg_model = Model(image_input, out)\ncustom_vgg_model.summary()","execution_count":40,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 224, 224, 3)       0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 25088)             0         \n_________________________________________________________________\nfc1 (Dense)                  (None, 4096)              102764544 \n_________________________________________________________________\nfc2 (Dense)                  (None, 4096)              16781312  \n_________________________________________________________________\noutput (Dense)               (None, 10)                40970     \n=================================================================\nTotal params: 134,301,514\nTrainable params: 134,301,514\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in custom_vgg_model.layers[:-1]:\n    layer.trainable = False","execution_count":41,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"custom_vgg_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epoch = 100\ncustom_vgg_model.fit(X_train, y_train, batch_size=512, epochs=num_epoch, verbose=1, validation_data=(X_test, y_test))","execution_count":43,"outputs":[{"output_type":"stream","text":"Train on 2980 samples, validate on 745 samples\nEpoch 1/100\n2980/2980 [==============================] - 25s 8ms/sample - loss: 2.5915 - acc: 0.1893 - val_loss: 2.1935 - val_acc: 0.3611\nEpoch 2/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 2.0670 - acc: 0.2990 - val_loss: 1.7988 - val_acc: 0.4000\nEpoch 3/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 1.7491 - acc: 0.4775 - val_loss: 1.5573 - val_acc: 0.4295\nEpoch 4/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 1.5026 - acc: 0.5121 - val_loss: 1.4651 - val_acc: 0.5195\nEpoch 5/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 1.3825 - acc: 0.5362 - val_loss: 1.3093 - val_acc: 0.5651\nEpoch 6/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 1.3076 - acc: 0.5443 - val_loss: 1.2614 - val_acc: 0.5638\nEpoch 7/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 1.2256 - acc: 0.5876 - val_loss: 1.2089 - val_acc: 0.5718\nEpoch 8/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 1.1698 - acc: 0.5983 - val_loss: 1.1372 - val_acc: 0.5946\nEpoch 9/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 1.1292 - acc: 0.6104 - val_loss: 1.1374 - val_acc: 0.5933\nEpoch 10/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 1.0918 - acc: 0.6128 - val_loss: 1.0783 - val_acc: 0.6094\nEpoch 11/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 1.0569 - acc: 0.6245 - val_loss: 1.0514 - val_acc: 0.6107\nEpoch 12/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 1.0312 - acc: 0.6235 - val_loss: 1.0572 - val_acc: 0.6121\nEpoch 13/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 1.0162 - acc: 0.6225 - val_loss: 1.0118 - val_acc: 0.6161\nEpoch 14/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.9907 - acc: 0.6305 - val_loss: 1.0033 - val_acc: 0.5987\nEpoch 15/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.9754 - acc: 0.6346 - val_loss: 0.9801 - val_acc: 0.6322\nEpoch 16/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.9558 - acc: 0.6399 - val_loss: 0.9729 - val_acc: 0.6188\nEpoch 17/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.9385 - acc: 0.6326 - val_loss: 0.9657 - val_acc: 0.6215\nEpoch 18/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.9278 - acc: 0.6460 - val_loss: 0.9350 - val_acc: 0.6349\nEpoch 19/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.9196 - acc: 0.6433 - val_loss: 0.9269 - val_acc: 0.6376\nEpoch 20/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.9050 - acc: 0.6480 - val_loss: 0.9481 - val_acc: 0.6215\nEpoch 21/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.8922 - acc: 0.6490 - val_loss: 0.9468 - val_acc: 0.6081\nEpoch 22/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.8965 - acc: 0.6450 - val_loss: 0.9075 - val_acc: 0.6349\nEpoch 23/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.8710 - acc: 0.6470 - val_loss: 0.9020 - val_acc: 0.6268\nEpoch 24/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.8583 - acc: 0.6654 - val_loss: 0.8838 - val_acc: 0.6416\nEpoch 25/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.8513 - acc: 0.6584 - val_loss: 0.8871 - val_acc: 0.6349\nEpoch 26/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.8440 - acc: 0.6661 - val_loss: 0.8923 - val_acc: 0.6121\nEpoch 27/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.8418 - acc: 0.6617 - val_loss: 0.8800 - val_acc: 0.6188\nEpoch 28/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.8325 - acc: 0.6597 - val_loss: 0.8773 - val_acc: 0.6201\nEpoch 29/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.8257 - acc: 0.6604 - val_loss: 0.8746 - val_acc: 0.6389\nEpoch 30/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.8143 - acc: 0.6644 - val_loss: 0.8683 - val_acc: 0.6188\nEpoch 31/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.8216 - acc: 0.6574 - val_loss: 0.8836 - val_acc: 0.6362\nEpoch 32/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.8209 - acc: 0.6631 - val_loss: 0.8668 - val_acc: 0.6403\nEpoch 33/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.8141 - acc: 0.6534 - val_loss: 0.8834 - val_acc: 0.6349\nEpoch 34/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.8026 - acc: 0.6701 - val_loss: 0.8428 - val_acc: 0.6470\nEpoch 35/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7867 - acc: 0.6805 - val_loss: 0.8478 - val_acc: 0.6376\nEpoch 36/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7813 - acc: 0.6728 - val_loss: 0.8319 - val_acc: 0.6268\nEpoch 37/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7767 - acc: 0.6742 - val_loss: 0.8376 - val_acc: 0.6349\nEpoch 38/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7744 - acc: 0.6779 - val_loss: 0.8404 - val_acc: 0.6188\nEpoch 39/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7751 - acc: 0.6792 - val_loss: 0.8608 - val_acc: 0.6161\nEpoch 40/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7668 - acc: 0.6742 - val_loss: 0.8257 - val_acc: 0.6282\nEpoch 41/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7655 - acc: 0.6775 - val_loss: 0.8252 - val_acc: 0.6416\nEpoch 42/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7668 - acc: 0.6795 - val_loss: 0.8542 - val_acc: 0.6282\nEpoch 43/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7780 - acc: 0.6698 - val_loss: 0.8590 - val_acc: 0.6336\nEpoch 44/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7776 - acc: 0.6735 - val_loss: 0.8520 - val_acc: 0.6201\nEpoch 45/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7591 - acc: 0.6755 - val_loss: 0.8217 - val_acc: 0.6336\nEpoch 46/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7540 - acc: 0.6899 - val_loss: 0.8385 - val_acc: 0.6376\nEpoch 47/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7373 - acc: 0.6846 - val_loss: 0.8289 - val_acc: 0.6255\nEpoch 48/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7337 - acc: 0.6869 - val_loss: 0.8134 - val_acc: 0.6430\nEpoch 49/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7330 - acc: 0.6899 - val_loss: 0.8272 - val_acc: 0.6309\nEpoch 50/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7300 - acc: 0.6889 - val_loss: 0.8029 - val_acc: 0.6443\nEpoch 51/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7367 - acc: 0.6839 - val_loss: 0.8049 - val_acc: 0.6456\nEpoch 52/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7232 - acc: 0.6953 - val_loss: 0.8081 - val_acc: 0.6322\nEpoch 53/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7167 - acc: 0.7003 - val_loss: 0.8103 - val_acc: 0.6470\nEpoch 54/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7131 - acc: 0.6963 - val_loss: 0.8200 - val_acc: 0.6255\nEpoch 55/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7132 - acc: 0.6950 - val_loss: 0.8172 - val_acc: 0.6456\nEpoch 56/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7139 - acc: 0.6906 - val_loss: 0.8103 - val_acc: 0.6322\nEpoch 57/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7118 - acc: 0.7003 - val_loss: 0.8080 - val_acc: 0.6349\nEpoch 58/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7091 - acc: 0.6960 - val_loss: 0.7947 - val_acc: 0.6362\nEpoch 59/100\n","name":"stdout"},{"output_type":"stream","text":"2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6979 - acc: 0.7017 - val_loss: 0.7923 - val_acc: 0.6403\nEpoch 60/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6980 - acc: 0.7070 - val_loss: 0.8255 - val_acc: 0.6322\nEpoch 61/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7161 - acc: 0.6953 - val_loss: 0.7999 - val_acc: 0.6134\nEpoch 62/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7200 - acc: 0.6862 - val_loss: 0.8140 - val_acc: 0.6282\nEpoch 63/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.7118 - acc: 0.6980 - val_loss: 0.8013 - val_acc: 0.6081\nEpoch 64/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6961 - acc: 0.6997 - val_loss: 0.8112 - val_acc: 0.6309\nEpoch 65/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6935 - acc: 0.7000 - val_loss: 0.8168 - val_acc: 0.6268\nEpoch 66/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6905 - acc: 0.7084 - val_loss: 0.7937 - val_acc: 0.6443\nEpoch 67/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6921 - acc: 0.7003 - val_loss: 0.7925 - val_acc: 0.6336\nEpoch 68/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6930 - acc: 0.7017 - val_loss: 0.7889 - val_acc: 0.6403\nEpoch 69/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6857 - acc: 0.7060 - val_loss: 0.7910 - val_acc: 0.6403\nEpoch 70/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6884 - acc: 0.7070 - val_loss: 0.7996 - val_acc: 0.6255\nEpoch 71/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6848 - acc: 0.7060 - val_loss: 0.7922 - val_acc: 0.6403\nEpoch 72/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6756 - acc: 0.7060 - val_loss: 0.7891 - val_acc: 0.6255\nEpoch 73/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6746 - acc: 0.7164 - val_loss: 0.7856 - val_acc: 0.6523\nEpoch 74/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6793 - acc: 0.7047 - val_loss: 0.7920 - val_acc: 0.6362\nEpoch 75/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6720 - acc: 0.7034 - val_loss: 0.7885 - val_acc: 0.6443\nEpoch 76/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6700 - acc: 0.7185 - val_loss: 0.7880 - val_acc: 0.6349\nEpoch 77/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6657 - acc: 0.7091 - val_loss: 0.7912 - val_acc: 0.6456\nEpoch 78/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6640 - acc: 0.7117 - val_loss: 0.8169 - val_acc: 0.6215\nEpoch 79/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6656 - acc: 0.7104 - val_loss: 0.8221 - val_acc: 0.6121\nEpoch 80/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6667 - acc: 0.7154 - val_loss: 0.7832 - val_acc: 0.6403\nEpoch 81/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6559 - acc: 0.7218 - val_loss: 0.7836 - val_acc: 0.6322\nEpoch 82/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6598 - acc: 0.7151 - val_loss: 0.8337 - val_acc: 0.6322\nEpoch 83/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6709 - acc: 0.7077 - val_loss: 0.7949 - val_acc: 0.6443\nEpoch 84/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6671 - acc: 0.7138 - val_loss: 0.7888 - val_acc: 0.6336\nEpoch 85/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6563 - acc: 0.7178 - val_loss: 0.7899 - val_acc: 0.6470\nEpoch 86/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6521 - acc: 0.7148 - val_loss: 0.8187 - val_acc: 0.6282\nEpoch 87/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6563 - acc: 0.7114 - val_loss: 0.7870 - val_acc: 0.6456\nEpoch 88/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6538 - acc: 0.7060 - val_loss: 0.8214 - val_acc: 0.6389\nEpoch 89/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6541 - acc: 0.7205 - val_loss: 0.8022 - val_acc: 0.6067\nEpoch 90/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6517 - acc: 0.7148 - val_loss: 0.8102 - val_acc: 0.6242\nEpoch 91/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6539 - acc: 0.7235 - val_loss: 0.7778 - val_acc: 0.6282\nEpoch 92/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6522 - acc: 0.7171 - val_loss: 0.7922 - val_acc: 0.6483\nEpoch 93/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6619 - acc: 0.7121 - val_loss: 0.7899 - val_acc: 0.6282\nEpoch 94/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6530 - acc: 0.7094 - val_loss: 0.7910 - val_acc: 0.6470\nEpoch 95/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6446 - acc: 0.7221 - val_loss: 0.8007 - val_acc: 0.6228\nEpoch 96/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6375 - acc: 0.7205 - val_loss: 0.7855 - val_acc: 0.6201\nEpoch 97/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6371 - acc: 0.7232 - val_loss: 0.7960 - val_acc: 0.6054\nEpoch 98/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6435 - acc: 0.7138 - val_loss: 0.8060 - val_acc: 0.5987\nEpoch 99/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6430 - acc: 0.7144 - val_loss: 0.7725 - val_acc: 0.6376\nEpoch 100/100\n2980/2980 [==============================] - 12s 4ms/sample - loss: 0.6256 - acc: 0.7268 - val_loss: 0.7804 - val_acc: 0.6443\n","name":"stdout"},{"output_type":"execute_result","execution_count":43,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f71a9348dd8>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\n\ncustom_vgg_model.save('Image_Class_Cute5.h5')","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(loss, accuracy) = custom_vgg_model.evaluate(X_train, y_train, batch_size=batch_size, verbose=1)\n\nprint(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss, accuracy * 100))","execution_count":45,"outputs":[{"output_type":"stream","text":"2980/2980 [==============================] - 9s 3ms/sample - loss: 0.6288 - acc: 0.7262\n[INFO] loss=0.6288, accuracy: 72.6174%\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train_pred = custom_vgg_model.predict(X_test)","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = np.argmax(Y_train_pred, axis=1)\nprint(y_train_pred)","execution_count":47,"outputs":[{"output_type":"stream","text":"[8 8 1 0 8 8 2 6 7 8 7 7 3 4 6 7 7 4 7 7 4 4 4 4 6 4 4 0 4 5 7 4 6 7 4 7 6\n 4 8 4 4 6 7 7 7 4 0 4 4 4 0 6 7 4 4 7 8 2 8 7 4 7 0 4 8 4 6 6 6 4 9 8 7 4\n 4 4 8 4 3 4 0 0 4 0 8 8 6 2 8 3 4 4 6 4 0 7 4 4 7 7 8 3 4 4 8 7 6 4 8 6 6\n 1 6 8 7 4 7 6 7 0 8 7 8 8 4 0 7 6 4 4 1 4 4 7 4 8 7 7 8 1 0 6 0 7 1 0 7 4\n 7 0 4 0 6 4 6 6 6 1 6 4 6 4 8 4 7 7 4 4 4 4 3 3 4 4 4 6 6 7 4 7 4 6 4 7 0\n 2 7 9 7 8 1 4 8 3 2 4 0 6 9 4 3 0 5 8 4 8 8 4 8 4 8 4 8 4 4 7 7 8 6 8 6 0\n 2 3 7 8 7 4 6 6 0 5 0 2 7 4 6 0 8 4 5 0 2 2 8 4 7 6 6 4 4 7 8 9 0 4 4 4 7\n 8 4 4 4 3 2 0 8 0 8 6 7 4 7 4 8 4 7 6 0 7 5 7 4 4 7 6 8 2 0 8 7 6 7 7 8 7\n 4 8 3 0 7 4 4 8 1 7 0 2 7 0 8 4 0 0 4 8 7 7 2 5 8 5 4 4 4 1 4 8 0 4 4 3 7\n 4 4 8 7 7 2 3 6 1 6 4 4 6 4 7 4 8 4 2 7 4 7 4 7 4 3 3 8 7 3 8 5 8 7 4 0 4\n 4 7 6 2 7 8 8 5 8 4 7 7 4 0 7 8 7 4 2 4 4 8 8 7 4 4 0 8 3 8 4 4 7 3 8 4 4\n 8 6 7 2 2 3 1 7 7 8 8 0 7 8 4 4 4 8 0 8 8 8 4 6 4 8 1 0 7 5 6 7 4 6 6 2 4\n 6 0 4 4 8 4 7 7 4 4 2 4 6 8 0 7 9 2 3 2 4 7 4 8 4 4 3 7 4 8 8 4 3 4 4 7 6\n 6 0 8 4 6 6 7 4 8 1 4 4 6 4 8 7 7 6 4 8 5 4 6 4 4 7 7 8 4 4 7 4 4 0 8 8 4\n 8 7 1 4 7 4 4 0 4 4 4 1 7 8 8 1 8 7 8 7 8 4 7 5 0 9 6 4 8 4 9 7 8 7 6 5 0\n 8 4 4 7 4 6 4 8 8 8 8 7 0 8 4 6 8 0 4 8 7 4 8 9 4 2 0 8 4 4 4 8 4 6 4 6 8\n 4 4 8 7 0 6 7 8 4 6 2 6 4 7 4 8 2 8 4 5 8 0 7 3 6 4 4 2 2 7 6 7 7 4 6 5 4\n 4 4 7 8 0 4 4 6 0 8 7 8 6 0 0 4 6 8 4 6 6 0 8 4 0 4 7 4 9 6 4 3 4 0 6 6 0\n 7 8 7 4 6 4 6 4 7 4 8 1 8 8 9 0 2 4 8 4 6 7 6 6 4 6 8 7 8 9 8 4 0 8 8 8 4\n 7 4 4 8 4 8 4 6 4 4 7 3 4 8 4 4 4 8 5 8 4 4 4 6 7 4 6 7 6 4 4 8 4 8 7 4 4\n 7 4 4 6 7]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,accuracy_score\nprint(\"test accuracy = \",accuracy_score(y_train_pred ,np.argmax(y_test, axis=1),))\n#print(\"test accuracy = \",accuracy_score(y_pred,y_true))","execution_count":48,"outputs":[{"output_type":"stream","text":"test accuracy =  0.6442953020134228\n","name":"stdout"}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}