{"cells":[{"metadata":{"_cell_guid":"da75225e-2736-4441-b7b8-a4ec70837961","_uuid":"4f00c27c343030acca6da9d515db45c9df3befc3"},"cell_type":"markdown","source":"**DML Use Case**"},{"metadata":{"scrolled":true,"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input\"))\n\nimport pandas as pd, numpy as np, time\nfrom sklearn.model_selection import train_test_split\n\ndata = pd.read_csv(\"../input/flights.csv\",low_memory=False)\ndata = data.sample(frac = 0.1, random_state=10)\n\ndata = data[[\"MONTH\",\"DAY\",\"DAY_OF_WEEK\",\"AIRLINE\",\"FLIGHT_NUMBER\",\"DESTINATION_AIRPORT\",\n                 \"ORIGIN_AIRPORT\",\"AIR_TIME\", \"DEPARTURE_TIME\",\"DISTANCE\",\"ARRIVAL_DELAY\"]]\ndata.dropna(inplace=True)\n\ndata[\"ARRIVAL_DELAY\"] = (data[\"ARRIVAL_DELAY\"]>10)*1\n\ncols = [\"AIRLINE\",\"FLIGHT_NUMBER\",\"DESTINATION_AIRPORT\",\"ORIGIN_AIRPORT\"]\nfor item in cols:\n    data[item] = data[item].astype(\"category\").cat.codes +1\n\ntrain, test, y_train, y_test = train_test_split(data.drop([\"ARRIVAL_DELAY\"], axis=1), data[\"ARRIVAL_DELAY\"],random_state=10, test_size=0.25)\n#print(train[0:20])\n# Any results you write to the current directory are saved as output.","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"8fd1d271-23c5-4f18-8d3a-afb0b7065ec9","_uuid":"1ed08c7736d9c4494f7d85b1214520d3a95312e5"},"cell_type":"markdown","source":"**AdaBoost**"},{"metadata":{"_cell_guid":"3a729937-3509-4bd7-a6c1-91f01fe03461","_uuid":"6d3dd21a4b3d67a8d5bc3d6bf4dfb8c56528c08c","trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\n\ndef auc(m, train, test): \n    return (metrics.roc_auc_score(y_train,m.predict_proba(train)[:,1]),\n                            metrics.roc_auc_score(y_test,m.predict_proba(test)[:,1]))\n\ndt_stump = DecisionTreeClassifier(max_depth=1, min_samples_leaf=1)\nn_estimators = 400\n# A learning rate of 1. may not be optimal for both SAMME and SAMME.R\nlearning_rate = 1.\n\nada_real = AdaBoostClassifier(\n    base_estimator=dt_stump,\n    learning_rate=learning_rate,\n    n_estimators=n_estimators,\n    algorithm=\"SAMME.R\")\n\nada_real.fit(train, y_train)\n\nauc(ada_real, train, test)\n","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"43dc1b45-6593-41c5-9ffe-d2e9fe4cb86c","_uuid":"3cf5db34ed8a61ef30980ac12cfb61704e0773aa"},"cell_type":"markdown","source":"**XGBoost**"},{"metadata":{"_cell_guid":"5f713c72-b875-4290-a741-23c38855c3a2","_uuid":"a704623f7488f382c0541d711cf8e017ff521a88","trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn import metrics\n\ndef auc(m, train, test): \n    return (metrics.roc_auc_score(y_train,m.predict_proba(train)[:,1]),\n                            metrics.roc_auc_score(y_test,m.predict_proba(test)[:,1]))\n\n# Parameter Tuning\nmodel = xgb.XGBClassifier()\nparam_dist = {\"max_depth\": [10,30,50],\n              \"min_child_weight\" : [1,3,6],\n              \"n_estimators\": [200],\n              \"learning_rate\": [0.05, 0.1,0.16],}\n# grid_search = GridSearchCV(model, param_grid=param_dist, cv = 3, \n#                                    verbose=10, n_jobs=-1)\n# grid_search.fit(train, y_train)\n\n# grid_search.best_estimator_\n\nmodel = xgb.XGBClassifier(max_depth=50, min_child_weight=1,  n_estimators=200,\n                          n_jobs=-1 , verbose=1,learning_rate=0.16)\nmodel.fit(train,y_train)\n\nauc(model, train, test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8c71fc4e-6b7c-4969-a4a3-7958677a04ba","_uuid":"795d2f34580861fb37c87927dd80da0d86103387"},"cell_type":"markdown","source":"**Light GBM**"},{"metadata":{"scrolled":true,"_cell_guid":"b1061225-bcd4-470e-bbf8-8526fdfcb4b2","_uuid":"01228ba96563d5cdec9639b4a07b98fa3cb25de4","trusted":false,"collapsed":true},"cell_type":"code","source":"\nimport lightgbm as lgb\nfrom sklearn import metrics\n\ndef auc2(m, train, test): \n    return (metrics.roc_auc_score(y_train,m.predict(train)),\n                            metrics.roc_auc_score(y_test,m.predict(test)))\n\nlg = lgb.LGBMClassifier(silent=False)\nparam_dist = {\"max_depth\": [25,50, 75],\n              \"learning_rate\" : [0.01,0.05,0.1],\n              \"num_leaves\": [300,900,1200],\n              \"n_estimators\": [200]\n             }\n# grid_search = GridSearchCV(lg, n_jobs=-1, param_grid=param_dist, cv = 3, scoring=\"roc_auc\", verbose=5)\n# grid_search.fit(train,y_train)\n# grid_search.best_estimator_\n\nd_train = lgb.Dataset(train, label=y_train)\nparams = {\"max_depth\": 50, \"learning_rate\" : 0.1, \"num_leaves\": 900,  \"n_estimators\": 300}\n\n# Without Categorical Features\nmodel2 = lgb.train(params, d_train)\nauc2(model2, train, test)\n\n# #With Catgeorical Features\n# cate_features_name = [\"MONTH\",\"DAY\",\"DAY_OF_WEEK\",\"AIRLINE\",\"DESTINATION_AIRPORT\",\n#                  \"ORIGIN_AIRPORT\"]\n# model2 = lgb.train(params, d_train, categorical_feature = cate_features_name)\n# auc2(model2, train, test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9851759d-b880-407b-a25c-1da87fb478ef","_uuid":"98ff2d649a3f10d5adf59034ffb72a42a730d586"},"cell_type":"markdown","source":"**CatBoost**"},{"metadata":{"_cell_guid":"c6d61428-4529-4210-92ff-9a3d494990ba","_uuid":"804cd130650fd9df874e4ae5fbc637e3ef863576","trusted":false,"collapsed":true},"cell_type":"code","source":"import catboost as cb\nfrom sklearn import metrics\ncat_features_index = [0,1,2,3,4,5,6]\n\ndef auc(m, train, test): \n    return (metrics.roc_auc_score(y_train,m.predict_proba(train)[:,1]),\n                            metrics.roc_auc_score(y_test,m.predict_proba(test)[:,1]))\n\nparams = {'depth': [4, 7, 10],\n          'learning_rate' : [0.03, 0.1, 0.15],\n         'l2_leaf_reg': [1,4,9],\n         'iterations': [300]}\n# cb = cb.CatBoostClassifier()\n# cb_model = GridSearchCV(cb, params, scoring=\"roc_auc\", cv = 3)\n# cb_model.fit(train, y_train)\n\n#Without Categorical features\nclf = cb.CatBoostClassifier(eval_metric=\"AUC\", depth=10, iterations= 500, l2_leaf_reg= 9, learning_rate= 0.15)\nclf.fit(train,y_train)\nauc(clf, train, test)\n\n#With Categorical features\nclf = cb.CatBoostClassifier(eval_metric=\"AUC\",one_hot_max_size=31, \n                            depth=10, iterations= 500, l2_leaf_reg= 9, learning_rate= 0.15)\nclf.fit(train,y_train, cat_features= cat_features_index)\nauc(clf, train, test)","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}