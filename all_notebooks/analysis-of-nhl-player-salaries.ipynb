{"cells":[{"metadata":{"_uuid":"2d09b5b38f9f44fe335960cd6cd01b37ff6cc97a"},"cell_type":"markdown","source":"# NHL Analytics Analysis\n\nThis is a brief analysis of NHL player salaries and some regression modeling using Light GBM as well as statistical analysis using statsmodels.\n\nSince the data set is not a time based series we dont have to worry too much about serial correlation or heteroskedasticity.\n\nThe features of the data set are explained on the Kaggle page.\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv', encoding = \"ISO-8859-1\")\ntrain.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"72a708d445b0c69d06337c52b817705fc1fa4a3e"},"cell_type":"markdown","source":"## Clean Up"},{"metadata":{"trusted":true,"_uuid":"91f0639d4940d42c51c6633168cf1fc31137378c"},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bf5b0401c8c3ccfe3ac79ad3e9ce5c79d137ebaf"},"cell_type":"markdown","source":"So there is 73 float features, 71 int, and 10 objects."},{"metadata":{"trusted":true,"_uuid":"617f3a0c6e84e9d4cb33ccf793cbb2c9eaf76ba0"},"cell_type":"code","source":"obj_cols = train.select_dtypes('object')\nobj_cols.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a83bba147033331b5ad4df492e3dd48732db9058"},"cell_type":"markdown","source":"It looks like these are mostly straight forward and we will dig into them in a second but lets take care of the **Born** column."},{"metadata":{"trusted":true,"_uuid":"aff4ed13b18ffd8d718158cb1b76958e67a5d829"},"cell_type":"code","source":"obj_cols.drop('Born',axis=1,inplace=True)\ntrain['Born'] = pd.to_datetime(train.Born)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3fc6266bd94f3eac9430c432beba624782a6322"},"cell_type":"code","source":"train.Born.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fed57184b6b6ff9ac110c29ba5e0a95191a5a024"},"cell_type":"markdown","source":"Now its into date time format and out of the object cols."},{"metadata":{"trusted":true,"_uuid":"9f5aba2c2470cea158c0b1c3b3748f460517dd04"},"cell_type":"code","source":"for c in obj_cols.columns:\n    print('Obj Col: ', c, '   Number of Unqiue Values ->', len(obj_cols[c].value_counts()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ac1148f6f871a669b080cad1184b11f8918e7b0"},"cell_type":"code","source":"373+37+18+16+2+573+308+18+68","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d46dc574801dc6c3fe983d6828ec4fca5bc166a"},"cell_type":"markdown","source":"If we dummied this out, we would get approximately an addition 1413 columns, minus the original 9.\n\nWe probably wouldnt need the first names though. It would be more interesting to keep the last names given some of hockey's family tradition.\n\nThere is something strange about the team category though since there is apparently 68 unique values...and currently only 31 hockey teams."},{"metadata":{"_uuid":"db07476a8d5d75563cfe0ec5b646749c5971d8e3"},"cell_type":"markdown","source":"## A Little Exploration"},{"metadata":{"_uuid":"f7342a62d77c2df4ced962cf2847f71c9e38b37a"},"cell_type":"markdown","source":"Lets take a look at the distribution of hockey players Countries relative to this data set."},{"metadata":{"trusted":true,"_uuid":"fba46bef8fa4b92438da2bbc632b8c690c85375d"},"cell_type":"code","source":"fig, ax=plt.subplots(1,2,figsize=(18,10))\nobj_cols['Cntry'].value_counts().sort_values().plot(kind='barh',ax=ax[0]) \nax[0].set_title(\"Counts of Hockey Players by Country\");\nobj_cols['Cntry'].value_counts().plot(kind='pie', autopct='%.2f', shadow=True,ax=ax[1]);\nax[1].set_title(\"Distribution of Hockey Players by Country\");\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae310e4b0b8ed73ec3c825dc9e418f08b76a6ad2"},"cell_type":"markdown","source":"Canada, USA, Sweden, Russia, Czekoslovakia, Finlad, etc."},{"metadata":{"trusted":true,"_uuid":"1ff1b95920dc86507404a8f3ae1d50cff999b74b"},"cell_type":"code","source":"fig, ax=plt.subplots(1,1,figsize=(12,8))\nobj_cols['Team'].value_counts().plot(kind='bar',ax=ax);\nplt.title('Counts of Team Values');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c97354725ff4a638ff51867bee01417e648d141"},"cell_type":"markdown","source":"So now we see what going on with the team values, there are actually some players who split teams so these are accounted for in this data set as well."},{"metadata":{"_uuid":"9c28961f8a58c0632ca7bcc52b00d26c052346de"},"cell_type":"markdown","source":"## Salary\n\nLets take a gander at whats going on with our target."},{"metadata":{"trusted":true,"_uuid":"b86060727c92660477beb03f848db588a6351742"},"cell_type":"code","source":"train.Salary.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"640698a946b3df91e90eda72fc9623f52ff530aa"},"cell_type":"code","source":"fig, ax=plt.subplots(1,1,figsize=(12,8))\ntrain.Salary.plot(kind='hist',ax=ax, bins=20);\nplt.title(\"Distribution of Salaries\");\nplt.xlabel('Dollars');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c028a1ea8a271e0c3702295255b35a86c051985"},"cell_type":"markdown","source":"There are a lot of salalries less than a million.\n\nThis will very likely skew our data when we try to model it.\n\nLets take a look at salaries above a million."},{"metadata":{"trusted":true,"_uuid":"c9a7cf48f33e35f61857c33822842e01f47d9ab7"},"cell_type":"code","source":"sal_gtmil = train[train.Salary >= 1e7]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6131a51192edda58e4cf5cc2a4e6509eb11d64dc"},"cell_type":"code","source":"sal_gtmil.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"938b0499df61ca9d7e5a2d45463911131eb6cf15"},"cell_type":"markdown","source":"Right here we see some big names in this set. This set also only appears to be 7 items long."},{"metadata":{"_uuid":"697a746187619e7890b3b07b57593abb4b7cbd73"},"cell_type":"markdown","source":"## Model\n\nMy thoughts with this are to dummy out most of the objects variables and using light gbm."},{"metadata":{"trusted":true,"_uuid":"3510908c33a4c9526883d765b52dc6318d52f013"},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f3e19ae73d5a930242513602270e4352b2f24905"},"cell_type":"markdown","source":"We had done some cleaning above but were going to create a function that handles it to work out the test data as well.\n\nAdditionally, we found out that the test and train splits arent evenly split so we need to go back and merge the data first."},{"metadata":{"trusted":true,"_uuid":"7429b9feb8e14646df811f77a794159ba5a963db"},"cell_type":"code","source":"def data_clean(x):\n    ## Were going to change Born to date time\n    x['Born'] = pd.to_datetime(x.Born, yearfirst=True)\n    x['dowBorn'] = x.Born.dt.dayofweek\n    x[\"doyBorn\"] = x.Born.dt.dayofyear\n    x[\"monBorn\"] = x.Born.dt.month\n    x['yrBorn'] = x.Born.dt.year\n    ## Drop Pr/St due to NaNs from other countries and First Name\n    x.drop(['Pr/St','First Name'], axis=1, inplace=True)\n    ocols = ['City', 'Cntry', 'Nat', 'Last Name', 'Position', 'Team']\n    for oc in ocols:\n        temp = pd.get_dummies(x[oc])\n        x = x.join(temp, rsuffix=str('_'+oc))\n    x['Hand'] = pd.factorize(x.Hand)[0]\n    x.drop(ocols, axis=1, inplace=True)\n    x.drop(['Born'],axis=1,inplace=True)\n    return x\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d4b69b5c3cf4daaa67b9f9e440acd1ef8b2e4911"},"cell_type":"code","source":"try:\n    del train, x0, xc, test\nexcept:\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"366c57ed218f0a22f66b782b79466700f41d838b"},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv', encoding=\"ISO-8859-1\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"925fc6c8ade3b3825c289720b5e884b58e4bace5"},"cell_type":"code","source":"test = pd.read_csv('../input/test.csv', encoding=\"ISO-8859-1\")\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f27f57e123abb93da83075d1c9a0b37a76de62cf"},"cell_type":"code","source":"full = train.merge(test, how='outer')\nprint(train.shape, test.shape, full.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a336c89b4a7cbc73404dbca6f2216d9c88dedce"},"cell_type":"code","source":"y = np.log(full.Salary.dropna())\nfull0 = full.drop(['Salary'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1067990f24569090b2a77428f391c14646e96d0"},"cell_type":"code","source":"fig, ax=plt.subplots(1,1,figsize=(10,6))\ny.plot(ax=ax);\nplt.title(\"Ln Salary\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db61aa1762f6f4c204545d2c189af7d8177c25d2"},"cell_type":"code","source":"obj_cols.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9daa51147b6525414e2755e1e9da70f9bd534bcf"},"cell_type":"code","source":"full_c = data_clean(full0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ca0905554cf053afadf4e4c30e6ad385af78447"},"cell_type":"code","source":"print(full0.shape, full_c.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d169736c7f474d8ce57934270e6c219ff03cda82"},"cell_type":"code","source":"full_c.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f6a898821f83b7d43b0e45bf7a3536ac4a8bce4d"},"cell_type":"code","source":"ss = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"200c3b4f8acad06af4ca651edaa13ac4d234041f"},"cell_type":"code","source":"full_cs = ss.fit_transform(full_c)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"88b228fb21a77e0b090adb5fbc7dbe547ce94591"},"cell_type":"markdown","source":"This cell below splits on the shape indices we have a few cells up."},{"metadata":{"trusted":true,"_uuid":"0363eaaeb05585d33f844a35aa7a4e8dfed9d10f"},"cell_type":"code","source":"train_c = full_cs[:612]\ntest_c = full_cs[612:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a11f396bd1fde96d1b89d2a9475d30129c9e8fe5"},"cell_type":"code","source":"print(train_c.shape, y.shape, test_c.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"539ecd4884641a1e102d08367eabdfbeb404c00c"},"cell_type":"code","source":"type(y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1277dc483a36e790d44b5525bcc50946bd428ef1"},"cell_type":"markdown","source":"### LGB Model"},{"metadata":{"trusted":true,"_uuid":"f8e332cd8673af5bad9e057cefe355ad9a0bf05c","scrolled":false},"cell_type":"code","source":"folds = 3\nlgbm_params = {\n    \"max_depth\": -1,\n    \"num_leaves\": 1000,\n    \"learning_rate\": 0.01,\n    \"n_estimators\": 1000,\n    \"objective\":'regression',\n    'min_data_in_leaf':64,\n    'feature_fraction': 0.8,\n    'colsample_bytree':0.8,\n    \"metric\":['mae','mse'],\n    \"boosting_type\": \"gbdt\",\n    \"n_jobs\": -1,\n    \"reg_lambda\": 0.9,\n    \"random_state\": 123\n}\npreds = 0\nfor f in range(folds):\n    xt, xv, yt, yv = train_test_split(train_c, y.values, test_size=0.2, random_state=((f+1)*123))\n    \n    xtd = lgb.Dataset(xt, label=yt)\n    xvd = lgb.Dataset(xv, label=yv)\n    mod = lgb.train(params=lgbm_params, train_set=xtd, \n                    num_boost_round=1000, valid_sets=xvd, valid_names=['valset'],\n                    early_stopping_rounds=20, verbose_eval=20)\n    \n    preds += mod.predict(test_c)\n    \npreds = preds/folds\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a1c760ecc709aaf0badc7a0d35673b22feea8bac"},"cell_type":"markdown","source":"## Actual Test Data"},{"metadata":{"trusted":true,"_uuid":"085651d40d52b2fc9d32dc9097e36e571be85bac"},"cell_type":"code","source":"acts = pd.read_csv('../input/test_salaries.csv', encoding=\"ISO-8859-1\")\nacts['preds'] = np.exp(preds)\nacts.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10adc7aba8c19b6d27cd058173f2e90b1073ed1a"},"cell_type":"code","source":"import matplotlib\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb30de64025cede305bae871bc794c8acfbfd174"},"cell_type":"code","source":"fig, ax=plt.subplots(1,1,figsize=(12,8))\nacts.plot(ax=ax, style=['b-','r-']);\nplt.title(\"Comparison of Preds and Actuals\");\nplt.ylabel('$');\nax.get_yaxis().set_major_formatter(\n    matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55afb3873c0d2dde1eaa4f492b0e6ab3c10d4c97"},"cell_type":"markdown","source":"Based on the items above, it appears we missed a lot of the outliers which is something we would need to grab with perhaps a quantile regression."},{"metadata":{"trusted":true,"_uuid":"18af1f8991f06f81842dbe6ea5cd0656f6d94329"},"cell_type":"code","source":"mse = mean_squared_error(np.log(acts.Salary), np.log(acts.preds))\nmae = mean_absolute_error(np.log(acts.Salary), np.log(acts.preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"149d234f67e6baafdfed0b54942295cc45efb014"},"cell_type":"code","source":"print(\"Ln Level Mean Squared Error :\", mse)\nprint(\"Ln Level Mean Absolute Error :\", mae)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"838f3253dc49a9ad07b9971320aad1707b54b2a2"},"cell_type":"code","source":"fi_df = pd.DataFrame( 100*mod.feature_importance()/mod.feature_importance().max(), \n                      index=full_c.columns, #mod.feature_name(),\n                      columns =['importance'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d031485f6991ff53512eb0cbb989ed225a509c7e"},"cell_type":"code","source":"fig, ax=plt.subplots(1,1,figsize=(12,8))\nfi_df.sort_values(by='importance',ascending=True).iloc[-20:].plot(kind='barh', color='C0', ax=ax)\nplt.title(\"Normalized Feature Importances\");","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6f731a9674da1986a558445a6d7eeb2cad94587b"},"cell_type":"markdown","source":"Top Features are:\n- Draft Year\n- Where the player was drafted over-all.\n- Year Born\n- Time On Ice / Games Played\n- Time On Ice (TOI/GP.l)\n- Draft Round\n- PLayers Avg Gane Score\n- Percentage of all opposing shot attempts blocked by this player\n- Expected goals (weighted shots) for this individual, which is shot attempts weighted by shot location\n- Day Of Year Born\n\n\nTime On Ice per GP doesnt seem so unusual as you would pay the ones who were better more and if theyre better, then they get paid more.\n\nThe Percentage of opposing shot attempts blocked is kinda of wild! Selke Trophy much?\n"},{"metadata":{"trusted":true,"_uuid":"f3bf729ac39d069cfd703d441f6ffd020b7214b7"},"cell_type":"code","source":"import statsmodels.api as sma","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c00dab3bb96d310d1561a17526e8e1654cada7a8"},"cell_type":"markdown","source":"For regressions I like to take the top couple effects from the Decision Tree and model it using statsmodels to get a better idea of the stastitical soundness of the model."},{"metadata":{"trusted":true,"_uuid":"08ae7ddf078609239f7564a12546f13461e0735a"},"cell_type":"code","source":"top10 = fi_df.sort_values(by='importance',ascending=True).iloc[-10:].index\ntop10\n\nexog = pd.DataFrame(test_c, columns=full_c.columns)[list(top10)].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"598e5e15f0e909d7f19ac754ddca54dd85fdce8a"},"cell_type":"code","source":"ols = sma.OLS(exog=exog, endog=acts.Salary)\nols_fit = ols.fit()\nprint(ols_fit.summary())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"750b0ea765c262b2e5329d92e10b3a6525cd226c"},"cell_type":"markdown","source":"According to the OLS, Draft Round and Block Shot % and Overall draft Position are not that statistically significant for this model.\n\nThe model has a good R squared.\n"},{"metadata":{"trusted":true,"_uuid":"434c73c2db1cc5e20543cd80614b9d1f2d6e3b19"},"cell_type":"code","source":"ols_preds = ols_fit.predict()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0ef77ee4afe3719435fbfcb97c8a63fef495784"},"cell_type":"code","source":"fig, ax=plt.subplots(1,1,figsize=(12,8))\nacts.Salary.plot(ax=ax, color='C1');\nax.plot(ols_preds, color='C0');\nplt.title(\"Comparison of StatsModels Preds and Actuals\");\nplt.ylabel('$');\nplt.legend(['salary actual','ols preds']);\nax.get_yaxis().set_major_formatter(\n    matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"147ff108dd4e69e2c7bd46dc49fb0845a2518060"},"cell_type":"markdown","source":"In this instance, we were able to predict negative values which doesnt make sense and would have to be cut off at 0."},{"metadata":{"trusted":true,"_uuid":"35c922bce24ebdbb8894eae4ca899de57c129d31"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}