{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport tensorflow as tf\nimport keras\nimport glob\nimport cv2\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd \nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport random\nimport os\nimport shutil\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/aptos-20152019-preprocessed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path='../input/aptos-20152019-preprocessed'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(path+'/trainData.csv')\n\nimage = load_img(path+\"/trainImgs/trainImgs/44e951e45dca.png\")\n\nplt.imshow(image)\nimage.mode","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.head())\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.hist(bins=50,figsize=(10,5))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout, GaussianNoise, GaussianDropout\nfrom keras.layers import Flatten, BatchNormalization\nfrom keras.layers.convolutional import Conv2D, SeparableConv2D, AveragePooling2D\nfrom keras.constraints import maxnorm\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras import backend as K\nfrom keras import regularizers, optimizers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain['diagnosis'] =  train['diagnosis'].astype(str)\ntrain['diagnosis'] =  train['diagnosis'].astype('string')\ntrain['id_code'] =  train['id_code'].astype(str)+'.png'\nX=train['id_code']\nY=train['diagnosis']\nY","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,)\nprint(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndatagen=ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2,\n    vertical_flip=True,\n    horizontal_flip=True)\n\nimage_size=100\nbatch_size=40\ntrain_gen=datagen.flow_from_dataframe(\n    dataframe=train,\n    directory=path+\"/trainImgs/trainImgs\",\n    x_col=\"id_code\",\n    y_col=\"diagnosis\",\n    batch_size=batch_size,\n    shuffle=True,\n    class_mode=\"categorical\",\n    target_size=(image_size,image_size),\n    subset='training')\n\ntest_gen=datagen.flow_from_dataframe(\n    dataframe=train,\n    directory=path+\"/trainImgs/trainImgs\",\n    x_col=\"id_code\",\n    y_col=\"diagnosis\",\n    batch_size=batch_size,\n    shuffle=True,\n    class_mode=\"categorical\", \n    target_size=(image_size,image_size),\n    subset='validation')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train['diagnosis']\nfrom keras.utils import np_utils\ny_train = np_utils.to_categorical(y_train)\nnum_classes = y_train.shape[1]\ny_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    # create model\n    model = Sequential()\n    #model.add(Reshape((x_train.shape[0],),))\n    #model.add(GaussianDropout(0.3,input_shape=[96,96,3]))\n    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',activation ='relu', input_shape = (100,100,3)))\n    model.add(GaussianDropout(0.3))\n    model.add(Conv2D(64, (5, 5), activation='relu', kernel_constraint=maxnorm(3)))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Conv2D(96, (5, 5), activation='relu'))\n    \n    model.add(Dropout(0.2))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n    model.add(Dense(50, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax', kernel_regularizer=regularizers.l2(0.0001)\n                   ,activity_regularizer=regularizers.l1(0.01)))\n    # Compile model\n    model.compile(loss='categorical_crossentropy', optimizer=optimizers.adam(lr=0.0001, amsgrad=True), metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model2():\n    model = Sequential()\n    model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same',activation ='relu', input_shape = (image_size,image_size,3)))\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu',kernel_constraint=maxnorm(3)))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n    \n    #kernel_constraint=maxnorm(3)\n    model.add(Conv2D(filters =64, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n    model.add(Dropout(0.3))\n    model.add(Conv2D(filters = 92, kernel_size = (3,3),padding = 'Same',activation ='relu',kernel_constraint=maxnorm(3)))\n    model.add(BatchNormalization())\n    model.add(AveragePooling2D(pool_size=(2,2), strides=(2,2))) #avrage before the last layer\n    \n    model.add(Dropout(0.2))\n    model.add(Flatten())\n    model.add(Dense(50, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dense(5, activation = \"softmax\",kernel_regularizer=regularizers.l2(0.0001),activity_regularizer=regularizers.l1(0.01)))\n    #,kernel_regularizer=regularizers.l2(0.0001),activity_regularizer=regularizers.l1(0.005)\n    model.compile(loss='categorical_crossentropy', optimizer=optimizers.adam(lr=0.0001, amsgrad=True), metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model3():\n    # create model\n    \n    model = Sequential()\n\n    model.add(Conv2D(filters = 30, kernel_size = (5, 5), input_shape = (100, 100, 3), activation = 'relu'))\n    model.add(Conv2D(filters = 30, kernel_size = (3, 3), activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size = (2, 2)))\n    model.add(Dropout(0.2))\n    \n    model.add(Conv2D(filters = 46, kernel_size = (3, 3), activation = 'relu',kernel_constraint=maxnorm(3)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters = 46, kernel_size = (3, 3), activation = 'relu',kernel_constraint=maxnorm(3)))\n    model.add(BatchNormalization())\n    model.add(AveragePooling2D(pool_size=(2,2), strides=(2,2))) \n    model.add(Dropout(0.2))\n\n    model.add(Flatten())\n    model.add(BatchNormalization())\n    model.add(Dense(64, activation = 'relu'))\n    model.add(Dense(32, activation = 'relu'))\n\n    model.add(Dense(5, activation = 'softmax'))\n    #kernel_regularizer=regularizers.l2(0.0001),activity_regularizer=regularizers.l1(0.01)\n    model.compile(loss = 'categorical_crossentropy', optimizer = optimizers.adam(lr=0.00006, amsgrad=True), metrics = ['categorical_accuracy'])\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ModelCheckpoint\nes= EarlyStopping(monitor='val_loss', mode ='min', verbose = 1, patience = 20)\nmc = ModelCheckpoint('model.h5', monitor='val_loss', save_best_only = True, mode ='min', verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model22=model.fit_generator(generator=train_gen,              \n                                    steps_per_epoch=len(train_gen),\n                                    validation_data=test_gen,                    \n                                    validation_steps=len(test_gen),\n                                    epochs=20,\n                                    callbacks = [es,mc], \n                                    use_multiprocessing = True,\n                                    verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(model22.history['accuracy'])\nplt.plot(model22.history['val_accuracy'])\nplt.title('accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndatagen=ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2,\n    vertical_flip=True,\n    horizontal_flip=True)\n\nexample_df = train.sample(n=1).reset_index(drop=True)\nimage_size=100\nexample_generator = datagen.flow_from_dataframe(\n    example_df, \n    path+\"/trainImgs/trainImgs\", \n    x_col='id_code',\n    y_col='diagnosis',\n     batch_size=batch_size,\n    shuffle=True,\n    target_size=(image_size,image_size),\n    class_mode='categorical',\n    \n)\nplt.figure(figsize=(12, 12))\nfor i in range(0, 15):\n    plt.subplot(5, 3, i+1)\n    for X_batch, Y_batch in example_generator:\n        image = X_batch[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}