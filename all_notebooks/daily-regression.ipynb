{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n!pip install -q git+https://github.com/tensorflow/docs\n\nimport matplotlib.pyplot as plt\nimport tensorflow.compat.v2 as tf\nimport tensorflow_docs as tfdocs\nimport tensorflow_docs.modeling\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nDIVIDER = 100000\n\ndf = pd.read_csv('/kaggle/input/us-border-crossing-data/Border_Crossing_Entry_Data.csv')\n\nCATEGORICAL_COLUMNS = ['Port Name', 'State', 'Border', 'Date', 'Measure']\n\nNUMERIC_COLUMNS = ['Port Code']\n\ntrain_label = df['Value']\ntrain_data = df.drop('Value', axis=1)\n\nfor feature_name in CATEGORICAL_COLUMNS:\n  dist_labels = []\n\n  vocabulary = train_data[feature_name].unique()\n  for item in vocabulary:\n    dist_labels.append(item)\n\n  train_data[feature_name] = train_data[feature_name].map(lambda x: dist_labels.index(x))\n\ntrain_stats = train_data.describe().transpose()\n\ndef norm_train(x):\n  return (x - train_stats['mean']) / train_stats['std']\n\ntrain_data = norm_train(train_data)\ntrain_label = train_label / DIVIDER","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def build_model():\n  model = keras.Sequential([\n    layers.Dense(128, activation='relu', input_dim=train_data.shape[1]),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(1)\n  ])\n\n  optimizer = tf.keras.optimizers.RMSprop(0.001)\n\n  model.compile(loss='mse',\n                optimizer=optimizer,\n                metrics=['mae', 'mse'])\n  return model\n\nmodel = build_model()\n\nmodel.summary()\n\nx_train,x_test,y_train,y_test = train_test_split(train_data, train_label, test_size=0.20)\n\nEPOCHS = 1000\n\nearly_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n\nhistory = model.fit(\n  x_train, y_train,\n  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n  callbacks=[early_stop, tfdocs.modeling.EpochDots()])\n\n\ntest_predictions = model.predict(x_test).flatten()\n\na = plt.axes(aspect='equal')\nplt.scatter(y_test, test_predictions)\nplt.xlabel('True Values [COUNTS]')\nplt.ylabel('Predictions [COUNTS]')\nlims = [0, 50]\nplt.xlim(lims)\nplt.ylim(lims)\n_ = plt.plot(lims, lims)\n\nplt.show()\n\nerror = test_predictions - y_test\nplt.hist(error, bins = 25)\nplt.xlabel(\"Prediction Error [COUNTS]\")\n_ = plt.ylabel(\"Count\")\n\nplt.show()\n\nnorm_error = (test_predictions - y_test) * DIVIDER\nprint(norm_error.describe())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}