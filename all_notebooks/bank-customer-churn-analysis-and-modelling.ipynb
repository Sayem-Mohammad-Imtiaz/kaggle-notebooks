{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, make_scorer, recall_score, roc_auc_score\nfrom xgboost import XGBClassifier, plot_importance\nfrom pdpbox import pdp, get_dataset, info_plots\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset is from kaggle [data](https://www.kaggle.com/santoshd3/bank-customers)   ","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/bank-customers/Churn Modeling.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see there are no missing values. The datatypes are all good. ","metadata":{}},{"cell_type":"code","source":"print(df.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(df.columns[[0,1]], axis=1, inplace=True)\n\nunique_vals = {}\nprint('Unique values for each feature:\\n')\nfor column in df.columns:\n    unique_vals[column]=df[column].unique()\n    print(len(unique_vals[column]), 'unique values of ', column)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No replicated CustomerId. Numbers of unique values of Gender, HasCrCard, IsActiveMember, Exited are legit.","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(4, 3, figsize=(15,15))\nsns.histplot(ax=axes[0, 0], data=df, x=\"CreditScore\", hue=\"Exited\", multiple=\"stack\")\nsns.histplot(ax=axes[0, 1], data=df, x='Age', hue=\"Exited\", multiple=\"stack\")\nsns.histplot(ax=axes[0, 2], data=df, x='Tenure', hue=\"Exited\", multiple=\"stack\")\nsns.histplot(ax=axes[1, 0], data=df, x='Balance', hue=\"Exited\", multiple=\"stack\")\nsns.histplot(ax=axes[1, 1], data=df, x='NumOfProducts', hue=\"Exited\", multiple=\"stack\")\nsns.histplot(ax=axes[1, 2], data=df, x='EstimatedSalary', hue=\"Exited\", multiple=\"stack\")\nsns.histplot(ax=axes[2, 0], data=df, x='Geography', hue=\"Exited\", multiple=\"stack\")\nsns.histplot(ax=axes[2, 1], data=df, x='Gender', hue=\"Exited\", multiple=\"stack\")\nsns.histplot(ax=axes[2, 2], data=df, x='HasCrCard', hue=\"Exited\", multiple=\"stack\")\nsns.histplot(ax=axes[3, 0], data=df, x='IsActiveMember', hue=\"Exited\", multiple=\"stack\")","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see generally, customers from the following groups are more likely to exit: \n1. Over the age of 40.\n2. From Germany.\n3. Female.\n\nCustomers from the following groups are less likely to exit: \n1. Having 2 products.\n2. Active members. ","metadata":{}},{"cell_type":"code","source":"cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary', 'Exited']\nsns.pairplot(df[cols], hue='Exited', kind='hist', height=2)\nplt.show();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encode the categorical features\ncat_features = ['Geography', 'Gender']\nohe = OneHotEncoder(sparse=False, dtype='int64', drop='if_binary')\ncat_encoded = ohe.fit_transform(df[cat_features])\ncolumn_name = ohe.get_feature_names(cat_features)\nohe_frame =  pd.DataFrame(cat_encoded, columns= column_name)\ndf = pd.concat([df.select_dtypes(exclude='object'), ohe_frame], axis=1)\n#df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corrmatrix = df.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nax = sns.heatmap(corrmatrix, vmax=.8, square=True, annot=True, cmap=\"YlGnBu\")","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Something interesting: Balance of customers from different countries varies a lot. ","metadata":{}},{"cell_type":"code","source":"X = df.drop(['Exited'], axis=1)\ny = df['Exited']\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=4)\n\nparam_grid = {'max_depth':range(3,15),'criterion':['gini','entropy']}\nrf = RandomForestClassifier(random_state=4)\nmodel_rf = GridSearchCV(rf, param_grid=param_grid)\nmodel_rf.fit(X_train, y_train)\npred_test = model_rf.predict(X_test)\nprint('Classification Report of RandomForestClassifier: \\n', classification_report(y_test, pred_test))\n#scores = cross_val_score(model_rf, X, y, scoring='roc_auc')\n#roc_auc_score(y_test, model_rf.predict_proba(X_test)[:, 1], average='weighted')\n#print ('cross validation score of RandomForestClassifier: %.8f'%scores.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see the recall is not good, meaning a lot of false negatives. Let's try to improve that if we don't want to miss potentially positive cases. ","metadata":{}},{"cell_type":"code","source":"rf1 = model_rf.best_estimator_\nimportances1 = rf1.feature_importances_\nfeature_importances = pd.Series(importances1, index=X.columns)\nfeature_importances.nlargest(12).plot(kind='barh')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf2 = RandomForestClassifier(random_state=4, class_weight={0:1,1:5})\n# For imbalanced sample: less 'Exited'=1 present, give 'Exited'=1 more weight. \nscorer = make_scorer(recall_score)\nmodel_rf2 = GridSearchCV(rf2, param_grid=param_grid, scoring=scorer)\nmodel_rf2.fit(X_train, y_train)\npred_test = model_rf2.predict(X_test)\nprint('Classification Report of RandomForestClassifier: \\n', classification_report(y_test, pred_test))","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems we achieve a good recall though the accuracy is relatively low. We need to tune the model according to our business objectives, like intervening before the exiting happens. In such cases, we may be willing to sacrifice accuracy for recall.","metadata":{}},{"cell_type":"code","source":"best_rf = model_rf2.best_estimator_\nimportances = best_rf.feature_importances_\nfeature_importances = pd.Series(importances, index=X.columns)\nfeature_importances.nlargest(12).plot(kind='barh')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for target_feature in ['Age', 'NumOfProducts', 'IsActiveMember']:\n    pdp_i = pdp.pdp_isolate(model=best_rf, dataset=X, model_features=X.columns, feature=target_feature)\n    pdp.pdp_plot(pdp_i, target_feature, figsize=(8,5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's try another model:","metadata":{}},{"cell_type":"code","source":"xgb = XGBClassifier()\n\"\"\"\nparam_grid = {'learning_rate': [0.01, 0.05], \n#        'min_child_weight': [1, 5],\n#        'subsample': [0.6, 0.8],\n#        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [5, 8],\n#        'n_estimators': [100, 500]\n        }\n\nmodel_xgb = GridSearchCV(estimator=xgb, param_grid=param_grid, scoring='roc_auc')\n\"\"\"\nxgb.fit(X_train, y_train)\npred_test = xgb.predict(X_test)\nprint('Classification Report of XGBClassifier: \\n', classification_report(y_test, pred_test))\n#scores = cross_val_score(model_xgb, X, y, scoring='roc_auc')\n#print ('cross validation score of XGBClassifier: %.8f'%scores.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb = XGBClassifier(scale_pos_weight=5)\nxgb.fit(X_train, y_train)\npred_test = xgb.predict(X_test)\nprint('Classification Report of XGBClassifier: \\n', classification_report(y_test, pred_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_importance(xgb)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}