{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install seaborn\n# !pip install sklearn\n# !pip install --user scikit-learn\n# !pip install matplotlib\n# !pip install nltk","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport string\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import MultinomialNB\nfrom collections import Counter\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import GridSearchCV\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/sms-spam-collection-dataset/spam.csv')\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop([\"Unnamed: 2\",\"Unnamed: 3\",\"Unnamed: 4\"],axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns = [\"class\",\"message\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['length'] = [len(d) for d in data.message]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.groupby('class').describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x=data['class'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(x=data[\"class\"],y=data[\"length\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop([\"length\"],axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform_message(message):\n    message_not_punc = [] # Message without punctuation\n    i = 0\n    for punctuation in message:\n        if punctuation not in string.punctuation:\n            message_not_punc.append(punctuation)\n    # Join words again to form the string.\n    message_not_punc = ''.join(message_not_punc) \n\n    # Remove any stopwords for message_not_punc, but first we should     \n    # to transform this into the list.\n    message_clean = list(message_not_punc.split(\" \"))\n    while i <= len(message_clean):\n        for mess in message_clean:\n            if mess.lower()  in stopwords.words('english'):\n                message_clean.remove(mess)\n        i =i +1\n    return  message_clean","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['message'].apply(transform_message)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorization = CountVectorizer(analyzer=transform_message)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = vectorization.fit(data[\"message\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_transform = X.transform(data[\"message\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_transform)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidf_transformer = TfidfTransformer().fit(X_transform)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_tfidf = tfidf_transformer.transform(X_transform)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_tfidf.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(data['message'], data['class'], test_size=0.3,random_state = 50, stratify=data['class'])  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train,y_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bow = CountVectorizer(stop_words='english')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the bag of words on the training docs\nbow.fit(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = bow.transform(X_train)\nX_test = bow.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train,X_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Naive Bayes Classifier","metadata":{}},{"cell_type":"code","source":"naive_bayes = MultinomialNB()\nnaive_bayes.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Accuracy : {accuracy_score(y_test, naive_bayes.predict(X_test)):.3f}')\nprint(f'Precision : {precision_score(y_test, naive_bayes.predict(X_test), pos_label=\"spam\"):.3f}')\nprint(f'Recall : {recall_score(y_test, naive_bayes.predict(X_test), pos_label=\"spam\"):.3f}')\nprint(f'F1-Score : {f1_score(y_test, naive_bayes.predict(X_test), pos_label=\"spam\"):.3f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = naive_bayes.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (classification_report(y_test, predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Support Vector Machine Classifier","metadata":{}},{"cell_type":"code","source":"svm_clf = SVC(kernel='linear').fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Accuracy : {accuracy_score(y_test, svm_clf.predict(X_test)):.3f}')\nprint(f'Precision : {precision_score(y_test, svm_clf.predict(X_test), pos_label=\"spam\"):.3f}')\nprint(f'Recall : {recall_score(y_test, svm_clf.predict(X_test), pos_label=\"spam\"):.3f}')\nprint(f'F1-Score : {f1_score(y_test, svm_clf.predict(X_test), pos_label=\"spam\"):.3f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm_predictions = svm_clf.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (classification_report(y_test, svm_predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}