{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, LogisticRegression\nfrom sklearn.metrics import (\n                mean_absolute_error, \n                mean_squared_error,\n                median_absolute_error,\n                max_error,\n                r2_score,\n                completeness_score,\n                fowlkes_mallows_score,\n                homogeneity_score,\n                v_measure_score )\nfrom sklearn.cluster import KMeans\nfrom sklearn.manifold import TSNE\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Inicial verificação dos dados \n__________\nComo não há valores vazios, podemos não nos preocupar com valores nulos e tratamentos desses dados.\n\nPara aprendizado supervisionado foi escolhido o atributo/coluna 'preço' (price) para tentar prever os seus dados através de aprendizado supervisionado.\n\nLogo dado o CEP, tipo de propriedade e quantidade de quarto tentar prever qual será seu preço.\n_________\nPosteriormente, será feito o contrário será colocado a coluna preço e tentará descobrir se é casa ou é \"unit\".  \n____________\nCEP será desconsiderado depois, para mais testes, uma vez que CEP não está por bairro e sim algo mais detalhado, tornando mais dificil seu uso.\nE feito o teste para descobrir o preço e o tipo de imóvel.\n\n\n"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/property-sales/raw_sales.csv')\n\nprint(df.head())\nprint(df.isna().sum())\nprint(df.info())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Análise atemporal**\n______________\nBuscou-se usar somentes os dados mais recentes, desde de 2019, para que o não ficasse muito grande. E assim, perde-se a temporalidade dos dados, na verdade usa-se os dados de forma atemporal."},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf_recente = df[(df['datesold'] > '2017-01-01 00:00:00')]\n# drop da mesma\ndf_recente=df_recente.drop('datesold',axis=1)\n\nprint(df_recente.head())\nprint(df_recente.info())\n\nprint(df_recente.price.count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.countplot(x=\"bedrooms\", data=df_recente)\nfor p in ax.patches:\n    ax.annotate('{}'.format(p.get_height()), (p.get_x()+0.15, p.get_height()+1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = sns.swarmplot(x='propertyType', y='price', data=df_recente)\n\n\n# Label the axes\n_ = plt.xlabel('Tipo de propriedade')\n_ = plt.ylabel('Preço')\n\n\n# Show the plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = sns.swarmplot(x='bedrooms', y='price', data=df_recente)\n\n\n# Label the axes\n_ = plt.xlabel('Quartos')\n_ = plt.ylabel('Preço')\n\n\n# Show the plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Aprendizado supervisionado\n\nNessa parte, irá salvar a coluna de interesse e usa-lá para treinos e ver qual modelo melhor se adapta.\nSeparar em treino e teste.\nPor costume teste terá 20% do dataset.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_recente['propertyType'].replace('unit', 0,inplace=True)\ndf_recente['propertyType'].replace('house', 1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecao da coluna a ser treinada\npreco = df_recente.price\n# drop da mesma\ndf1=df_recente.drop('price',axis=1)\nprint(df1.info())\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(df1, preco, test_size = 0.2)\n\ndef mean_absolute_percentage_error(y_true, y_pred): \n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Métodos de treino\n\nSerão usados métodos de regressão. Buscando de sklearn alguns modelos usados como regressão linear, logit, lasso, Ridge (disponíveis na biblioteca sklearn).\n\n### Métricas usadas\n\nSerão as que são usadas comumente para métodos de regressão:\n\n* Max Error \n\nRepresenta o valor máximo de erro entre o predito e o gabarito (true_value). Ou seja, max (|Y_predito - Gabarito|)\n\n* Mean Absolute Error \n\nErro médio absoluto, o nome já é explicativo: Soma-se o total de erros e divide-se pelo número de amostras. logo :\n $ \\frac{\\sum (Y_{predito} - Y_{gabarito})}{n_{amostras}} $\n\n* Mean Squared Error \n\nErro médio quadrático tem como base o erro médio absoluto, mas ao invés de pegar o valor absoluto, usa-se o valor quadrático desta diferença. logo :\n $ \\frac{\\sum \\sqrt{(Y_{predito} - Y_{gabarito})^{2}}}{n_{amostras}} $\n\n* Median Absolute Error\n\nNesse caso, pega-se os erros e se ordena e encontrar a tendência central do mesmo. Ou seja, as amostras em $X[\\frac{n}{2}]$ ou $X\\frac{[\\frac{n}{2}] + X[\\frac{n}{2} + 1]}{2}$\n\n* Mean Absolute Percentage Error\n\nMAPE é a soma dos erros absolutos individuais divididos pela demanda (cada período separadamente).\n$  MAPE = \\frac{1}{n} \\sum \\frac{Y_{Predito} - Y_{gabarito}}{Y_{gabarito}} $"},{"metadata":{"trusted":true},"cell_type":"code","source":"modeloRegrLinear =  LinearRegression().fit(train_X, train_y)\ny_pred =  modeloRegrLinear.predict(val_X)\nmodeloRidge = Ridge().fit(train_X, train_y)\ny_predRidge =  modeloRidge.predict(val_X)\nmodeloLasso = Lasso().fit(train_X, train_y)\ny_predLasso =  modeloLasso.predict(val_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Regressão linear \\n\\t\\t\\t\\t Acurácia treino: \", modeloRegrLinear.score(train_X,train_y),\n     \"\\n\\t\\t\\t\\t Acurácia validação: \", modeloRegrLinear.score(val_X,val_y),\n     \"\\n\\t\\t\\t\\t Erro médio absoluto: \", mean_absolute_error(val_y,y_pred),\n      \"\\n\\t\\t\\t\\t Erro Percentual médio absoluto: \", mean_absolute_percentage_error(val_y,y_pred),\n     \"\\n\\t\\t\\t\\t Erro médio quadrático: \", mean_squared_error(val_y,y_pred),\n      \"\\n\\t\\t\\t\\t Erro mediano absoluto: \", median_absolute_error(val_y,y_pred),\n      \"\\n\\t\\t\\t\\t Máximo erro: \", max_error(val_y,y_pred),\n      \"\\n\\t\\t\\t\\t R2 score: \", r2_score(val_y,y_pred)\n         )\nprint(\"Regressão Ridge \\n\\t\\t\\t\\t Acurácia treino: \", modeloRidge.score(train_X,train_y),\n     \"\\n\\t\\t\\t\\t Acurácia validação: \", modeloRidge.score(val_X,val_y),\n     \"\\n\\t\\t\\t\\t Erro médio absoluto: \", mean_absolute_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t Erro Percentual médio absoluto: \", mean_absolute_percentage_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t Erro médio quadrático: \", mean_squared_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t Erro mediano absoluto: \", median_absolute_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t Máximo erro: \", max_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t R2 score: \", r2_score(val_y,y_predRidge))\n\nprint(\"Regressão Lasso \\n\\t\\t\\t\\t Acurácia treino: \", modeloLasso.score(train_X,train_y),\n     \"\\n\\t\\t\\t\\t Acurácia validação: \", modeloLasso.score(val_X,val_y),\n     \"\\n\\t\\t\\t\\t Erro médio absoluto: \", mean_absolute_error(val_y,y_predLasso),\n     \"\\n\\t\\t\\t\\t Erro Percentual médio absoluto: \", mean_absolute_percentage_error(val_y,y_predLasso),\n     \"\\n\\t\\t\\t\\t Erro médio quadrático: \", mean_squared_error(val_y,y_predLasso),\n     \"\\n\\t\\t\\t\\t Erro mediano absoluto: \", median_absolute_error(val_y,y_predLasso),\n     \"\\n\\t\\t\\t\\t Máximo erro: \", max_error(val_y,y_predLasso),\n      \"\\n\\t\\t\\t\\t R2 score: \", r2_score(val_y,y_predLasso))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Aprendendo o tipo de imóvel\n\nAo invés de tentar aprender o preço do imóvel tentar descobrir o imóvel se é unidade ou apartamento."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecao da coluna a ser treinada\ntipo = df_recente.propertyType\n# drop da mesma\ndf2=df_recente.drop('propertyType',axis=1)\nprint(df1.info())\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(df2, tipo, random_state = 1,test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modeloRegrLinear =  LinearRegression().fit(train_X, train_y)\ny_pred =  modeloRegrLinear.predict(val_X)\n\nmodeloRidge = Ridge().fit(train_X, train_y)\ny_predRidge =  modeloRidge.predict(val_X)\n\nmodeloLogRegression = LogisticRegression().fit(train_X,train_y)\ny_predLog =  modeloLogRegression.predict(val_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Regressão linear \\n\\t\\t\\t\\t Acurácia treino: \", modeloRegrLinear.score(train_X,train_y),\n     \"\\n\\t\\t\\t\\t Acurácia validação: \", modeloRegrLinear.score(val_X,val_y),\n     \"\\n\\t\\t\\t\\t Erro médio absoluto: \", mean_absolute_error(val_y,y_pred),\n     \"\\n\\t\\t\\t\\t Erro Percentual médio absoluto: \", mean_absolute_percentage_error(val_y,y_pred),      \n     \"\\n\\t\\t\\t\\t Erro médio quadrático: \", mean_squared_error(val_y,y_pred),\n     \"\\n\\t\\t\\t\\t Erro mediano absoluto: \", median_absolute_error(val_y,y_pred),\n     \"\\n\\t\\t\\t\\t Máximo erro: \", max_error(val_y,y_pred),\n      \"\\n\\t\\t\\t\\t R2 score: \", r2_score(val_y,y_pred)\n         )\nprint(\"Regressão Ridge \\n\\t\\t\\t\\t Acurácia treino: \", modeloRidge.score(train_X,train_y),\n     \"\\n\\t\\t\\t\\t Acurácia validação: \", modeloRidge.score(val_X,val_y),\n     \"\\n\\t\\t\\t\\t Erro médio absoluto: \", mean_absolute_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t Erro Percentual médio absoluto: \", mean_absolute_percentage_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t Erro médio quadrático: \", mean_squared_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t Erro mediano absoluto: \", median_absolute_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t Máximo erro: \", max_error(val_y,y_predRidge),\n      \"\\n\\t\\t\\t\\t R2 score: \", r2_score(val_y,y_predRidge))\n\nprint(\"Regressão Regressão Logística \\n\\t\\t\\t\\t Acurácia treino: \", modeloLogRegression.score(train_X,train_y),\n     \"\\n\\t\\t\\t\\t Acurácia validação: \", modeloLogRegression.score(val_X,val_y),\n     \"\\n\\t\\t\\t\\t Erro médio absoluto: \", mean_absolute_error(val_y,y_predLog),\n     \"\\n\\t\\t\\t\\t Erro Percentual médio absoluto: \", mean_absolute_percentage_error(val_y,y_predLog),\n     \"\\n\\t\\t\\t\\t Erro médio quadrático: \", mean_squared_error(val_y,y_predLog),\n     \"\\n\\t\\t\\t\\t Erro mediano absoluto: \", median_absolute_error(val_y,y_predLog),\n     \"\\n\\t\\t\\t\\t Máximo erro: \", max_error(val_y,y_predLog),\n      \"\\n\\t\\t\\t\\t R2 score: \", r2_score(val_y,y_predLog))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Removendo o CEP (PostCode)\n\nAgora, removeremos o PostCode e faremos os mesmos modelos e métricas. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_recente_semCEP=df_recente.drop('postcode',axis=1)\n# Selecao da coluna a ser treinada\npreco_semCEP = df_recente_semCEP.price\n# drop da mesma\ndf1_semCEP=df_recente_semCEP.drop('price',axis=1)\nprint(df1_semCEP.info())\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(df1_semCEP, preco_semCEP, test_size = 0.2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modeloRegrLinear =  LinearRegression().fit(train_X, train_y)\ny_pred =  modeloRegrLinear.predict(val_X)\n\nmodeloRidge = Ridge().fit(train_X, train_y)\ny_predRidge =  modeloRidge.predict(val_X)\n\nmodeloLasso = Lasso().fit(train_X, train_y)\ny_predLasso =  modeloLasso.predict(val_X)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Regressão linear \\n\\t\\t\\t\\t Acurácia treino: \", modeloRegrLinear.score(train_X,train_y),\n     \"\\n\\t\\t\\t\\t Acurácia validação: \", modeloRegrLinear.score(val_X,val_y),\n     \"\\n\\t\\t\\t\\t Erro médio absoluto: \", mean_absolute_error(val_y,y_pred),\n     \"\\n\\t\\t\\t\\t Erro Percentual médio absoluto: \", mean_absolute_percentage_error(val_y,y_pred),\n      \"\\n\\t\\t\\t\\t Erro médio quadrático: \", mean_squared_error(val_y,y_pred),\n      \"\\n\\t\\t\\t\\t Erro mediano absoluto: \", median_absolute_error(val_y,y_pred),\n      \"\\n\\t\\t\\t\\t Máximo erro: \", max_error(val_y,y_pred),\n      \"\\n\\t\\t\\t\\t R2 score: \", r2_score(val_y,y_pred)\n         )\nprint(\"Regressão Ridge \\n\\t\\t\\t\\t Acurácia treino: \", modeloRidge.score(train_X,train_y),\n     \"\\n\\t\\t\\t\\t Acurácia validação: \", modeloRidge.score(val_X,val_y),\n     \"\\n\\t\\t\\t\\t Erro médio absoluto: \", mean_absolute_error(val_y,y_predRidge),      \n     \"\\n\\t\\t\\t\\t Erro Percentual médio absoluto: \", mean_absolute_percentage_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t Erro médio quadrático: \", mean_squared_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t Erro mediano absoluto: \", median_absolute_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t Máximo erro: \", max_error(val_y,y_predRidge),\n      \"\\n\\t\\t\\t\\t R2 score: \", r2_score(val_y,y_predRidge))\n\nprint(\"Regressão Lasso \\n\\t\\t\\t\\t Acurácia treino: \", modeloLasso.score(train_X,train_y),\n     \"\\n\\t\\t\\t\\t Acurácia validação: \", modeloLasso.score(val_X,val_y),\n     \"\\n\\t\\t\\t\\t Erro médio absoluto: \", mean_absolute_error(val_y,y_predLasso),\n     \"\\n\\t\\t\\t\\t Erro Percentual médio absoluto: \", mean_absolute_percentage_error(val_y,y_predLasso),\n     \"\\n\\t\\t\\t\\t Erro médio quadrático: \", mean_squared_error(val_y,y_predLasso),\n     \"\\n\\t\\t\\t\\t Erro mediano absoluto: \", median_absolute_error(val_y,y_predLasso),\n    \"\\n\\t\\t\\t\\t Máximo erro: \", max_error(val_y,y_predLasso),\n      \"\\n\\t\\t\\t\\t R2 score: \", r2_score(val_y,y_predLasso))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecao da coluna a ser treinada\ntipo_semCEP = df_recente_semCEP.propertyType\n# drop da mesma\ndf2_semCEP=df_recente_semCEP.drop('propertyType',axis=1)\nprint(df2_semCEP.info())\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(df2_semCEP, tipo_semCEP, random_state = 1,test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modeloRegrLinear =  LinearRegression().fit(train_X, train_y)\ny_pred =  modeloRegrLinear.predict(val_X)\n\nmodeloRidge = Ridge().fit(train_X, train_y)\ny_predRidge =  modeloRidge.predict(val_X)\n\nmodeloLogRegression = LogisticRegression().fit(train_X,train_y)\ny_predLog =  modeloLogRegression.predict(val_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Regressão linear \\n\\t\\t\\t\\t Acurácia treino: \", modeloRegrLinear.score(train_X,train_y),\n     \"\\n\\t\\t\\t\\t Acurácia validação: \", modeloRegrLinear.score(val_X,val_y),\n     \"\\n\\t\\t\\t\\t Erro médio absoluto: \", mean_absolute_error(val_y,y_pred),\n     \"\\n\\t\\t\\t\\t Erro Percentual médio absoluto: \", mean_absolute_percentage_error(val_y,y_pred),\n     \"\\n\\t\\t\\t\\t Erro médio quadrático: \", mean_squared_error(val_y,y_pred),\n     \"\\n\\t\\t\\t\\t Erro mediano absoluto: \", median_absolute_error(val_y,y_pred),\n     \"\\n\\t\\t\\t\\t Máximo erro: \", max_error(val_y,y_pred),\n      \"\\n\\t\\t\\t\\t R2 score: \", r2_score(val_y,y_pred)\n         )\nprint(\"Regressão Ridge \\n\\t\\t\\t\\t Acurácia treino: \", modeloRidge.score(train_X,train_y),\n     \"\\n\\t\\t\\t\\t Acurácia validação: \", modeloRidge.score(val_X,val_y),\n     \"\\n\\t\\t\\t\\t Erro médio absoluto: \", mean_absolute_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t Erro Percentual médio absoluto: \", mean_absolute_percentage_error(val_y,y_predRidge),\n      \"\\n\\t\\t\\t\\t Erro médio quadrático: \", mean_squared_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t Erro mediano absoluto: \", median_absolute_error(val_y,y_predRidge),\n     \"\\n\\t\\t\\t\\t Máximo erro: \", max_error(val_y,y_predRidge),\n      \"\\n\\t\\t\\t\\t R2 score: \", r2_score(val_y,y_predRidge))\n\nprint(\"Regressão Regressão Logística \\n\\t\\t\\t\\t Acurácia treino: \", modeloLogRegression.score(train_X,train_y),\n     \"\\n\\t\\t\\t\\t Acurácia validação: \", modeloLogRegression.score(val_X,val_y),\n     \"\\n\\t\\t\\t\\t Erro médio absoluto: \", mean_absolute_error(val_y,y_predLog),\n     \"\\n\\t\\t\\t\\t Erro Percentual médio absoluto: \", mean_absolute_percentage_error(val_y,y_predLog),\n     \"\\n\\t\\t\\t\\t Erro médio quadrático: \", mean_squared_error(val_y,y_predLog),\n     \"\\n\\t\\t\\t\\t Erro mediano absoluto: \", median_absolute_error(val_y,y_predLog),\n     \"\\n\\t\\t\\t\\t Máximo erro: \", max_error(val_y,y_predLog),\n      \"\\n\\t\\t\\t\\t R2 score: \", r2_score(val_y,y_predLog))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__________________________\n"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"zoo2 = pd.read_csv(\"../input/zoo-animals-extended-dataset/zoo2.csv\")\nzoo3 = pd.read_csv(\"../input/zoo-animals-extended-dataset/zoo3.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Aprendizado não supervisionado\n______________\n\nPara esse caso escolheu-se um dataset contendo animais de um zoologico de São Paulo.\n\nEssa tabela contêm o nome de cada bixo e seu ID.  Composto por 16 atributos que dizem se é ou não é.\n\n* animal_name animal id (unique for each instance)\n* hairif -- se tem cabelo\n* feathersif -- se tem penas\n* eggsif -- se poe ovos\n* milkif -- se dá leite\n* airborne -- se voa\n* aquaticif -- se é aquático\n* predatorif -- se é predador\n* toothedif -- se tem dentes\n* backboneif -- se tem ossos\n* breathesif -- se \"respira ar\"\n* venomousif -- se é venosos\n* finsif -- se tem barbatana\n* legsnumber -- numeros de pernas: {0,2,4,5,6,8}\n* tailif -- se tem pescoço\n* domesticif -- se é doméstico\n* catsizeif -- tamanho referente em unidades de gato\n* class_typea -- classe pertecente. \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# peeking at the dataset\nprint(zoo3.head())\n#Descriptive stats of the variables in data\nprint(zoo3.describe())\n# verificando se dados nulos\nprint(zoo3.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"animal_name = zoo3.animal_name\nclass_t = zoo3.class_type\nzoo3_Km = zoo3.drop(columns=['animal_name','class_type'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 8))\n\nwcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n    kmeans.fit(zoo3_Km)\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1, 11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Número de Clusters')\nplt.ylabel('Coeficiente de Silhueta')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Número de cluster\n\nDados as colunas que contêm dados sobre os animais catolagados.\n\nTentaremos dividir em 6 grupos:\n* Mamíferos\n* Insetos\n* Reptéis \n* anfíbios\n* Aves \n* Peixes "},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters=6, random_state = 0)\nkmeans.fit(zoo3_Km)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = kmeans.predict(zoo3_Km)\ncentroides = kmeans.cluster_centers_\nown_labels = np.array(['Mamíferos', 'Reptéis e Anfíbios', 'Aves', 'Peixe'])\nprint(\"Labels: \\n\", labels);\nprint(\"Centroides: \\n\", centroides);\n\nprint(animal_name)\n\ndummy_data3 = {\n        'nome': animal_name,\n        'labels': labels}\ndf_label = pd.DataFrame(dummy_data3, columns = ['nome', 'labels'])\ngroup = df_label.groupby('labels')\n\n#df_label.to_csv('labels.csv')\nlabels_true = [1,1,3,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,5,5,5,5,5,5,5,5,3,3,\n3,3,3,3,3,3,0,0,0,0,0,0,4,4,4,4,4,4,3,4,4]\n\nprint(group.count())\n\nfor key, item in group:\n    print(group.get_group(key), \"\\n\\n\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tsne_out = TSNE(n_components=2,  n_iter=1000, init='pca').fit_transform(zoo3_Km)\nplt.figure(figsize=(13,7))\nplt.scatter(tsne_out[:,0], tsne_out[:,1], c=kmeans.labels_,cmap='cividis');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Por fim, obteve-se 6 grupos conforme abaixo:\n\n### Label 0 - Anfíbios\n\n* 40                  jabuti       0 (estranho ao ninho)\n* 41            jacare-coroa       0 (estranho ao ninho)\n* 45                 tracaja       0 (OK)\n* 55  perereca-de-alcatrazes       0 (OK)\n* 56          ra-flecha-azul       0 (OK)\n* 57              ra-pimenta       0 (OK)\n* 58    sapo-barriga-de-fogo       0 (OK)\n* 59             sapo-cururu       0 (OK)\n* 60          sapo-de-chifre       0 (OK)\n\n### Label 1 - Mamíferos\n* 0                anta       1 (OK)\n* 1            ariranha       1 (OK)\n* 3               bugio       1 (OK)\n* 4    cachorro-vinagre       1 (OK)\n* 5           chimpanze       1 (OK)\n* 6       gato-maracaja       1 (OK)\n* 7         jaguatirica       1 (OK)\n* 8          lobo-guara       1 (OK)\n* 9       macaco-aranha       1 (OK)\n* 10   macaco-barrigudo       1 (OK)\n* 11  mico-leao-dourado       1 (OK)\n* 12     mono-carvoeiro       1 (OK)\n* 13       onca-pintada       1 (OK)\n* 14        orangotango       1 (OK)\n* 15          peixe-boi       1 (OK)\n* 16           queixada       1 (OK)\n* 17  tamandua-bandeira       1 (OK)\n* 18     urso-de-oculos       1  (OK)\n\n### Label 2 - Aves\n* 9         aguia-cinzenta       2 (OK)\n* 20         aracari-banana       2 (OK)\n* 21             arara-azul       2 (OK)\n* 22          arara-caninde       2 (OK)\n* 23                  chaua       2 (OK)\n* 24                    ema       2 (OK)\n* 25           gaviao-pombo       2 (OK)\n* 26                  guara       2 (OK)\n* 27                 harpia       2 (OK)\n* 28               jacurutu       2 (OK)\n* 29              jacutinga       2 (OK)\n* 30        jandaia-amarela       2 (OK)\n* 31                 macuco       2 (OK)\n* 32             murucututu       2 (OK)\n* 33                  mutum       2 (OK)\n* 34  papagaio-de-cara-roxa       2 (OK)\n* 35         pato-de-crista       2 (OK)\n* 36                   pavo       2 (OK)\n* 37   tucano-de-bico-preto       2 (OK)\n* 38              urubu-rei       2  (OK)\n\n### Label 3 - Peixes\n* 47                     baiacu       3 (OK)\n* 48      cascudinho-de-caverna       3 (OK)\n* 49                    lambari       3 (OK)\n* 50                   matrinxa       3 (OK)\n* 51                   pirarucu       3 (OK)\n* 52                 raia-chita       3 (OK)\n* 53                   tambaqui       3 (OK)\n* 54             tubarao-raposa       3 (OK)\n* 67  caracol-da-mata-atlantica       3 (OK)\n\n### Label 4 - Insetos\n* 61         abelha       4 (OK)\n* 62       joaninha       4 (OK)\n* 63       mariposa       4 (OK)\n* 64      pirilampo       4 (OK)\n* 65          vespa       4 (OK)\n* 66      bicho-pau       4 (OK)\n* 68  caranguejeira       4 (OK)\n* 69    sauva-limao       4 (OK)\n\n### Label 5 - Reptéis\n* 2   boto-cor-de-rosa       5 (Estranho ao ninho)\n* 39        cobra-cipo       5 (Ok)\n* 42    jararaca-ilhoa       5 (Ok)\n* 43            jiboia       5 (Ok)\n* 44            sucuri       5 (Ok)\n* 46    urutu-cruzeiro       5  (Ok)\n"},{"metadata":{},"cell_type":"markdown","source":"# Métricas\n__________\n\n* Completude\n\nRefere-se como os membros de um clusters foram preditos para um mesmo cluster (não necessariamente o cluster correto mas agrupados juntos). Calcula-se usando a entropia dos eventos. \n\n$completude = 1 - \\frac{H(Predito|Correto)}{H(Correto)}$\n\n* Homogenidade \n\nCada classe (cluster correto) contem membros  de um mesmo cluster predito, pode se imaginar como o inverso de completude. O que não implica em $Completude + Homogenidade = 1 $.  Logo, é a razão de um membro de uma classe dada ser assinalado ao mesmo cluster.\nMas temos que $ Completude(Predito, Gabarito) == Homogenidade(Gabarito, Predito) $\n\n* V-measure\n\nÉ a média harmônica de homogenidade e completude.\n\nDado que : Completude = c e Homogenidade = h\n\n$V_{Measure} = (1 + \\beta) \\frac{h \\times c}{\\beta \\times h + c}$\n\n* Acurácia fowlkes\n\nÉ definido como a média geométrica entre precisão e recall:\n\n$Fowlkes = \\frac{Verdadeiro_{Positivo}}{ \\sqrt{((Verdadeiro_{Positivo} + Falso_{Positivo}) * (Verdadeiro_{Positivo} + Falso_{Negativo} ))}}$"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Métricas da Cluster \\n\\t\\t\\t\\t Completude: \", completeness_score(labels_true,labels),\n     \"\\n\\t\\t\\t\\t Acurácia fowlkes: \", fowlkes_mallows_score(labels_true,labels),\n     \"\\n\\t\\t\\t\\t Homogenidade: \", homogeneity_score(labels_true,labels),\n     \"\\n\\t\\t\\t\\t V-measure: \", v_measure_score(labels_true,labels) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Aumentando número de cluster para 7\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans2 = KMeans(n_clusters=7, random_state = 0)\nkmeans2.fit(zoo3_Km)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels2 = kmeans2.predict(zoo3_Km)\ncentroides2 = kmeans2.cluster_centers_\nprint(\"Labels: \\n\", labels2);\nprint(\"Centroides: \\n\", centroides2);\n\ndummy_data3 = {\n        'nome': animal_name,\n        'labels': labels2}\ndf_label = pd.DataFrame(dummy_data3, columns = ['nome', 'labels'])\ngroup2 = df_label.groupby('labels')\n\nprint(group2.count())\n\nfor key, item in group2:\n    print(group2.get_group(key), \"\\n\\n\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tsne_out = TSNE(n_components=2,  n_iter=1000, init='pca').fit_transform(zoo3_Km)\nplt.figure(figsize=(13,7))\nplt.scatter(tsne_out[:,0], tsne_out[:,1], c=kmeans2.labels_,cmap='coolwarm');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Métricas da Cluster \\n\\t\\t\\t\\t Completude: \", completeness_score(class_t,labels2),\n     \"\\n\\t\\t\\t\\t Acurácia fowlkes: \", fowlkes_mallows_score(class_t,labels2),\n     \"\\n\\t\\t\\t\\t Homogenidade: \", homogeneity_score(class_t,labels2),\n     \"\\n\\t\\t\\t\\t V-measure: \", v_measure_score(class_t,labels2) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-------------------------------\n\n# Aprendizado por reforço - Racing King\n------------------------------\n\n\nO dataset escolhido é um jogo de Xadrez, na verdade uma variante do jogo de xadrez denominada Corrida dos Reis. Contendo um etapa de treino e outra de validação.\nFoi escolhido esse dataset pois reforço envolve caminhos bons que te levam a vitória e caminhos ruins que te levam a derrota.\n\n"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"racing_king_train = pd.read_csv(\"../input/racingkings/racing_king_train.csv\")\nracing_king_validate = pd.read_csv(\"../input/racingkings/racing_king_validate.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(racing_king_train.head())\nprint((racing_king_train.info()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nesse dataset há duas colunas\n\n* fen -- fen é o estado atual do jogo e assim por dizer como estão posicionadas as peças suas e do oponente.\n\n* score -- é a pontuação da aquela \"snapshot\" do jogo X(fen) = score.\n\n\nLogo, a ideia seria ir reforçando o aprendizado mostrando que tal jogada é de pouco valor e outro é de maior pontuação podendo direcionar as jogadas do bot.\n________________\n\n## Métricas de aprendizado por reforço\n\n* Regret -> Uma métrica que diz quantas jogadas \"nesse caso do xadrez\" seriam economizadas. Ou seja, as vantagens que se levaria se tomasse o caminho ótimo.\n\n\n* Reability -> confiabilidade, quanto aquela conhecimento realmente levou ao sucesso, ou se for ruim quanto levou ao fracasso.\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}