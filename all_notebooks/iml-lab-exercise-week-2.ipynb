{"cells":[{"metadata":{},"cell_type":"markdown","source":"#  **Simple and Multiple Linear Regression**\nLab Exercises - Week 2\n\n----------"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport scipy\nimport matplotlib.pyplot as plt\nfrom sklearn import linear_model as ln\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Introduction to Numpy:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Declaring an array\narr = np.array([[1,2,3],[4,5,6]])\n\nprint(\"Array dimensions:\\n\", arr.shape)\nprint(\"Array previous:\\n\", arr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to generate a Matrix with all values as 1:\nidentityMatrix = np.ones((2,2))\nprint(\"Identity Matrix:\\n\", identityMatrix)\n\n#Function to stack so as to make a single Matrix horizontally:\nx = np.hstack((identityMatrix,arr))\nprint(\"Stacking Arrays:\\n\", x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dot Product\na = np.array([[7,8],[9,10]])\nb = np.array([[11,12],[13,14]])\nprint(np.dot(a,b))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transpose\nmat = np.array([[7,8],[9,10],[11,12],[13,14]])\n\nprint(\"Original Matrix:\\n\", mat)\nprint(\"Transpose Matrix:\\n\", np.transpose(mat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to calculate the inverse of a matrix\nmat = np.array([[7,8],[9,10]])\nprint(\"Matrix Inverse:\\n\", np.linalg.inv(mat))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Simple Linear Regression using Numpy"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = np.array([[1.55],[0.42],[1.29],[0.73],[0.76],[-1.09],[1.41],[-0.32]])\nz = np.array([[1.13],[-0.73],[0.12],[0.52],[-0.54],[-1.15],[0.20],[-1.09]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generating regression coefficients\nid = np.ones((8,1))\nx = np.hstack((id,z))\nbeta = (np.dot(np.dot(np.linalg.inv(np.dot(x.transpose(),x)),x.transpose()),y))\nprint(beta)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Result - Calculation\nyp1 = beta[0] + beta[1]*z\nprint(np.hstack((z,y,yp1)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Simple Linear Regression using Scikit-Learn:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input DataFrame\nd = pd.DataFrame(np.hstack((z,y)))\nd.columns = [\"x1\",\"y\"]\nprint(d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Linear Regression - model fitting\nmodel = ln.LinearRegression()\nresults = model.fit(z,y)\nprint(model.intercept_, model.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Result: Scikit - Learn\nyp2 = model.predict(z)\nprint(yp2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Linear Regression representation using scatter plot\nplt.title(\"Scatter Plot Representation\",fontsize=16)\nplt.scatter(z,y)\nplt.plot(z,yp2, color=\"red\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction for new values\nx1new = pd.DataFrame(np.hstack(np.array([[1],[0],[-0.12],[0.52]])))\nx1new.columns = [\"x1\"]\nyp2new = model.predict(x1new)\nprint(yp2new)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Multiple Linear Regression using Numpy functions:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input DataFrame\ny = np.array([[1.55],[0.42],[1.29],[0.73],[0.76],[-1.09],[1.41],[-0.32]])\nx1 = np.array([[1.13],[-0.73],[0.12],[0.52],[-0.54],[-1.15],[0.20],[-1.09]])\nx2 = np.array([[1],[0],[1],[1],[0],[1],[0],[1]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id = np.ones((8,1))\nx = np.hstack((id, x1, x2))\nprint(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating Regression Coefficients\nbeta = (np.dot(np.dot(np.linalg.inv(np.dot(x.transpose(),x)),x.transpose()),y))\nprint(beta)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Result - Calculation\nyp1 = beta[0] + beta[1]*x1 + beta[2]*x2\nprint(np.hstack((x,y,yp1)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. Multiple Linear Regression using Scikit-Learn:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input DataFrame\nd = pd.DataFrame(np.hstack((x1,x2,y)))\nd.columns = [\"x1\",\"x2\",\"y\"]\nprint(d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Multiple Linear Regression - Model Fitting\ninputDF = d[[\"x1\",\"x2\"]]\nmodel = ln.LinearRegression()\nresult = model.fit(inputDF, y)\n\nprint(model.intercept_, model.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Result: Scikit - Learn\nyp2 = model.predict(inputDF)\nyp2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction for new values\nx1new = pd.DataFrame(np.hstack((np.array([[1],[0],[-0.12],[0.52]]),np.array([[1],[-1],[2],[0.7]]))))\nx1new.columns = [\"x1\",\"x2\"]\nyp2new = model.predict(x1new)\nprint(np.hstack((x1new,yp2new)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Voilà! This is the end of the lab session for week 2.** <br>\nDo not forget to commit your notebook and set the access to private. Share the notebook with Prof. Karim (Kaggle id: karimshaikh) and Manish Varma (Kaggle id: manishvarma)."},{"metadata":{},"cell_type":"markdown","source":"## 7. Exercise Questions:\nQ1. Using **survey.csv**, build simple linear regression based model using \"Height\" as a dependent variable and \"Wrhnd\" as independent variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/survey.csv\")\n#df.head()\n#df = df.rename(index=str,columns = (\"Wr.Hnd\":\"WrHnd\"))\ndf = df[['Wr.Hnd', 'Height']]\nprint(df.head())\nprint(\"------------------------------\")\nprint(df.isnull().values.any())\nprint(df.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking for Null/Nan Values\ndf = df.dropna()\nprint(\"Check for NaN/Null values:\\n\", df.isnull().values.any())\nprint(\"Number of NaN/Null values:\\n\", df.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Simple Linear Regression\ninputDF = df[[\"Wr.Hnd\"]]\noutcomeDF = df[[\"Height\"]]\nmodel = ln.LinearRegression()\nresults = model.fit(inputDF, outcomeDF)\n\nprint(model.intercept_, model.coef_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Q2. Using **check.csv** build a multiple linear regression based model using \"Price\" as a dependent variable and \"Bidders\" and \"Age\" as independent variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/clock.csv\")\nprint(df.head())\nprint(\"------------------------------------------------------------------------------\")\nprint(\"Check for NaN/Null values:\\n\", df.isnull().values.any())\nprint(\"Number of NaN/Null values:\\n\", df.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Multiple Linear Regression \ninputDF = df[[\"Bidders\",\"Age\"]]\noutcomeDF = df[[\"Price\"]]\nmodel = ln.LinearRegression()\nresults = model.fit(inputDF, outcomeDF)\n\nprint(model.intercept_, model.coef_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Voilà! This is the end of the lab session for week 2.\nDo not forget to commit your notebook and set the access to private. Share the notebook with Prof. Karim (Kaggle id: karimshaikh) and Manish Varma (Kaggle id: manishvarma)."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}