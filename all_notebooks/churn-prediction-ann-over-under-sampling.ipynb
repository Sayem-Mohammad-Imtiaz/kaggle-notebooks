{"cells":[{"metadata":{},"cell_type":"markdown","source":"Using the [dataset](https://www.kaggle.com/shivan118/churn-modeling-dataset) I'm going to use approaches to predict data that come from a unbalance dataset."},{"metadata":{},"cell_type":"markdown","source":"Using the nb_black formatter."},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install nb_black -q","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%load_ext nb_black","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing dataset and mini-EAD"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np  # linear algebra\nimport pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport os\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\n\ndata = pd.read_csv(\"/kaggle/input/churn-modeling-dataset/Churn_Modelling.csv\").drop(\n    [\"RowNumber\", \"CustomerId\", \"Surname\"], axis=1\n)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To plot numerical column\ndef plot_hist(data, column):\n    fig = px.histogram(data, x=column, color=\"Exited\")\n    fig.show()\n    fig = ff.create_table(pd.DataFrame(data[column].describe()).T)\n    fig.show()\n\n\n# To plot categorical column\ndef plot_count(data, column):\n    df = data.groupby(column)[\"Exited\"].value_counts()\n    df = pd.DataFrame(df)\n    df.columns = [\"Count\"]\n    df.reset_index(inplace=True)\n    fig = px.bar(df, x=column, y=\"Count\", color=\"Exited\", text=\"Count\", barmode=\"group\")\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data porfile\n\n- There is 10 columns;\n- No missing values;\n- Exited column is the target;\n\n### Columns meaning\n- CreditScore: Customer score in financial context;\n- Geography: Represets the customer contry;\n- Gender: Just customer's sex;\n- Age: Just Age;\n- Tenure: How much time as customer;\n- Balance: How much money in the bank;\n- NumOfProducts: How much products the customer uses;\n- HasCrCard: Does have the customer a credit card?\n- IsActiveMember: Is the customer an active member?\n- EstimetedSalary: How much is the customer salary?\n- Exited: Client churn flag\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EAD\n\n### CreditScore"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_hist(data, \"CreditScore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Geography"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count(data, \"Geography\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gender           "},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count(data, \"Gender\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Age"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_hist(data, \"Age\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tenure"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_hist(data, \"Tenure\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Balance          "},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_hist(data, \"Balance\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## NumOfProducts"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_hist(data, \"NumOfProducts\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## HasCrCard"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_hist(data, \"HasCrCard\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## IsActiveMember"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_hist(data, \"IsActiveMember\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EstimatedSalary"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_hist(data, \"EstimatedSalary\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data formatation\n\n- StandardScaler -> Standardize features by removing the mean and scaling to unit variance The standard score of a sample x is calculated as: z = (x - u) / s.\n\n- LabelEncoder -> Encode target labels with value between 0 and n_classes-1.\n\n- OneHotEncoder -> Encode categorical features as a one-hot numeric array.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n\nenc = OneHotEncoder(handle_unknown=\"ignore\")\nstander_scaler = StandardScaler()\nlabel_encoder = LabelEncoder()\n\nX = np.concatenate(\n    (\n        ## OneHotEncoder\n        enc.fit_transform(data[[\"Geography\"]]).toarray(),\n        ## Stander Scaler\n        stander_scaler.fit_transform(\n            data[\n                [\n                    \"CreditScore\",\n                    \"Age\",\n                    \"Tenure\",\n                    \"Balance\",\n                    \"NumOfProducts\",\n                    \"EstimatedSalary\",\n                ]\n            ]\n        ),\n        ## LabelEncoder\n        label_encoder.fit_transform(data[[\"Gender\"]]).reshape(-1, 1),\n        ## No formatation\n        data[[\"HasCrCard\", \"IsActiveMember\"]].values,\n    ),\n    axis=1,\n)\n\ny = data.Exited.values\nX.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Geting the name of our new columns after transformed..."},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = (\n    [el for el in enc.categories_[0]]\n    + [\"CreditScore\", \"Age\", \"Tenure\", \"Balance\", \"NumOfProducts\", \"EstimatedSalary\",]\n    + [\"Gender\"]\n    + [\"HasCrCard\", \"IsActiveMember\"]\n    + [\"Exited\"]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Correlation Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\ntable = pd.DataFrame(np.concatenate([X, y.reshape(-1, 1)], axis=1))\ntable.columns = columns\ntable = table.corr()\nwith sns.axes_style(\"white\"):\n    mask = np.zeros_like(table)\n    mask[np.triu_indices_from(mask)] = True\n    plt.figure(figsize=(10, 10))\n    sns.heatmap(\n        round(table, 2),\n        cmap=\"Reds\",\n        mask=mask,\n        vmax=table.max().max(),\n        vmin=table.min().min(),\n        linewidths=0.5,\n        annot=True,\n        annot_kws={\"size\": 12},\n    ).set_title(\"Correlation Matrix App behavior dataset\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train ANN"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Conv2D\nimport keras\n\n\ndef get_model():\n    return Sequential(\n        [\n            Dense(units=200, input_dim=12, activation=\"relu\"),\n            Dense(150, activation=\"relu\"),\n            Dropout(0.2),\n            Dense(100, activation=\"relu\"),\n            Dense(100, activation=\"relu\"),\n            Dropout(0.2),\n            Dense(100, activation=\"relu\"),\n            Dense(100, activation=\"relu\"),\n            Dense(100, activation=\"relu\"),\n            Dropout(0.2),\n            Dense(100, activation=\"relu\"),\n            Dense(1, activation=\"sigmoid\"),\n        ]\n    )\n\n\ndef train_ann(X, y):\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.1, random_state=42\n    )\n\n    model = get_model()\n\n    model.compile(\n        optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"mse\", \"accuracy\"],\n    )\n\n    # Trainig and returning back the results.\n    history = model.fit(\n        X_train,\n        y_train,\n        batch_size=10,\n        epochs=50,\n        verbose=0,\n        validation_data=(X_test, y_test),\n    )\n    loss, mse, acc = model.evaluate(X_test, y_test, verbose=0)\n    fig = ff.create_table(\n        pd.DataFrame([(loss, mse, acc)], columns=[\"Loss\", \"MSE\", \"Accuracy\"]),\n    )\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Over-sampling\n\n## SMOTE\nClass to perform over-sampling using SMOTE.\n\nThis object is an implementation of SMOTE - Synthetic Minority Over-sampling Technique as presented in [R001eabbe5dd7-1](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html#r001eabbe5dd7-1).\n\nRead more in the User Guide.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nX, y = SMOTE(random_state=42).fit_resample(X, y)\n\ntrain_ann(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## RandomOverSampler\n\nClass to perform random over-sampling.\n\nObject to over-sample the minority class(es) by picking samples at random with replacement.\n\nRead more in the [User Guide](https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html#random-over-sampler)."},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import RandomOverSampler\n\nX, y = RandomOverSampler(random_state=42).fit_resample(X, y)\n\ntrain_ann(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## BorderlineSMOTE\n\nOver-sampling using Borderline SMOTE.\n\nThis algorithm is a variant of the original SMOTE algorithm proposed in [R63962efaf197-2](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.BorderlineSMOTE.html#r63962efaf197-2). Borderline samples will be detected and used to generate new synthetic samples."},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import BorderlineSMOTE\n\nX, y = BorderlineSMOTE(random_state=42).fit_resample(X, y)\n\ntrain_ann(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ADASYN\nPerform over-sampling using Adaptive Synthetic (ADASYN) sampling approach for imbalanced datasets.\n\nRead more in the [User Guide](https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html#smote-adasyn)."},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import ADASYN\n\nX, y = ADASYN(random_state=42).fit_resample(X, y)\n\ntrain_ann(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## KMeansSMOTE\nApply a KMeans clustering before to over-sample using SMOTE.\n\nThis is an implementation of the algorithm described in [Rea5937a049dc-1](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.KMeansSMOTE.html#rea5937a049dc-1).\n\nRead more in the User Guide."},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import KMeansSMOTE\n\nX, y = KMeansSMOTE(random_state=42).fit_resample(X, y)\n\ntrain_ann(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVMSMOTE\nOver-sampling using SVM-SMOTE.\n\nVariant of SMOTE algorithm which use an SVM algorithm to detect sample to use for generating new synthetic samples as proposed in [R88acb9955f91-2](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SVMSMOTE.html#r88acb9955f91-2).\n\nRead more in the [User Guide](https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html#smote-adasyn)."},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SVMSMOTE\n\nX, y = SVMSMOTE(random_state=42).fit_resample(X, y)\n\ntrain_ann(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Under-Sampling\n\n## ClusterCentroids\nPerform under-sampling by generating centroids based on clustering methods.\n\nMethod that under samples the majority class by replacing a cluster of majority samples by the cluster centroid of a KMeans algorithm. This algorithm keeps N majority samples by fitting the KMeans algorithm with N cluster to the majority class and using the coordinates of the N cluster centroids as the new majority samples."},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.under_sampling import ClusterCentroids\n\nX, y = ClusterCentroids(random_state=42).fit_resample(X, y)\n\ntrain_ann(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## AllKNN\n\nClass to perform under-sampling based on the AllKNN method.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.under_sampling import AllKNN\n\nX, y = AllKNN().fit_resample(X, y)\n\ntrain_ann(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## NeighbourhoodCleaningRule\n\nClass performing under-sampling based on the neighbourhood cleaning rule.\n\nRead more in the [User Guide](https://imbalanced-learn.readthedocs.io/en/stable/under_sampling.html#condensed-nearest-neighbors).\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.under_sampling import NeighbourhoodCleaningRule\n\nX, y = NeighbourhoodCleaningRule().fit_resample(X, y)\n\ntrain_ann(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## RandomUnderSampler\nClass to perform random under-sampling.\n\nUnder-sample the majority class(es) by randomly picking samples with or without replacement.\n\nRead more in the [User Guide](https://imbalanced-learn.readthedocs.io/en/stable/under_sampling.html#controlled-under-sampling)."},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler\n\nX, y = RandomUnderSampler().fit_resample(X, y)\n\ntrain_ann(X, y)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}