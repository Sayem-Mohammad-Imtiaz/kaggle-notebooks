{"cells":[{"metadata":{},"cell_type":"markdown","source":"# My Music Preferences Based on Spotify Data\nFor my assignment I decided to explore Spotify API and collect the data about my own music preferences. \nI first obtain the data set, which contains all tracks from all artists, who's tracks I liked. Then I rearrange that dataset from quite complex JSON form to plain data frame. Finally I make couple of charts based on cleansed data.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#install needed packages\n!pip install spotipy\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sys\nimport spotipy\nimport spotipy.util as util\nimport json\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nspotify_client_id = user_secrets.get_secret(\"spotify_client_id\")\nspotify_client_secret = user_secrets.get_secret(\"spotify_client_secret\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Retrieval\nThe following two snippets of code obtain data from Spotify API.\nThis code is not requried for the rest of the notebook to work, as the dataset is saved as json file, but I am leaving it here just to demonstrate the logic behind data retrieval.\nThe first snippet will ***not*** work on Kaggle. It performs OAuth2 authenitication of spotify user, which involves opening browser window on local machine. You can't do in from inside of Docker container, at least I didn't find a way. Instad I run the first snippet on my local machine, generate the token and then paste the token to the second snippet.\nThe second snippet obtains user's top 50 tracks and then gets all tracks from the artists featured in top 50. Resulting data is stored as a json file.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"collapsed":true},"cell_type":"code","source":"# This script obtains user authorization token. Run it on local machine, paste the resulting token to the following code block\n\n#define neccessary level of API permissions\nscope = 'user-library-read user-top-read'\n\n#define user id (this is mine and it is associated with my API credentials stored in secrets)\nuser_id='12175561893'\n\n#obtain authorization token\ntoken = util.prompt_for_user_token(user_id,\n                           scope,\n                           client_id=spotify_client_id,\n                           client_secret=spotify_client_secret,\n                           redirect_uri='http://localhost:8080')\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# This code does the following:\n# 1. Obtains 50 of my favorite tracks\n# 2. Determines artists for each of those tracks\n# 3. Obtains all albums of those artists\n# 4. Obtains information about all songs from all those albums. The list is saved as a json file as the first half of the data set\n# 5. Obtains audio features for each of these songs and saves them as the second half of the data set\n#-------------\nTo prevent this code from accidential running (it takes forever to execute) this line is left uncommented. Comment it before the code is run\n#-------------\ntoken = 'BQCr_uNdj4N_sxq8I-oVXT6yePDWUdRY2Fns8zEtAjoASfx7W13dgNjq-YzyYqnN_3B3zKKqJF6VYcBNl4sF-_aKg78iiYbc_YcC8bi-uRpvCfMTgRpbLJ5SR8kw2Vjn5FlJ46Q-dS4Nzsi6vlcSiHGyKNubqOJbvME'\n#constuct API handler\nsp = spotipy.Spotify(auth=token)\n\n#get my favorite tracks\nfav_tracks = sp.current_user_top_tracks(limit=50, time_range='long_term')\n\n#pull artists from my favorite tracks\nartist_list = []\nfor track in fav_tracks['items']:\n    for artist in track['artists']:\n        artist_list.append(artist['id'])\n\n#pull all albums by all artists from my favorite tracks\nalbum_list=[]\nfor artist in artist_list:\n    albums = sp.artist_albums(artist)\n    for album in albums['items']:\n        album_list.append(album['id'])\n\n#Pull all tracks for all albums by all artists from my favorite tracks\n#This is our dataset. Unlike the previous steps we need more that not just list of IDs, so we are going to use dictionary\nfinal_track_list={}\nfor album in album_list:\n    album_tracks = sp.album_tracks(album)\n    for track in album_tracks['items']:\n        final_track_list[track['id']]=track #this is general track information\n        final_track_list[track['id']]['audio_features']=sp.audio_features(track['id']) #this is track analysis\n\n#Finally, save resulting data structure as json\njson.dump(final_track_list,fp=open('final_track_list.json','w'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Cleansing\nWe start by opening the file and flattening the structure. We also get rid of the columns, that are not interesting to us[](http://)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#opening json file\nftl = pd.json_normalize(json.load(fp=open('/kaggle/input/final_track_list.json','r')).values())\n#exploding internal structures to columns for artists and audio features\nfinal_dataset=ftl.explode('artists').explode('audio_features')\n#one more level of nesting\nart = pd.json_normalize(final_dataset['artists'])\nfeat = pd.json_normalize(final_dataset['audio_features'])\nart.index = final_dataset.index\nfeat.index = final_dataset.index\n#adding new columns to final dataset and dropping the garbage\ngarbage=['href', 'uri', 'external_urls.spotify', 'artists', 'available_markets', \n         'audio_features', 'preview_url', 'type','audio.analysis_url', \n         'audio.duration_ms','artist.href','artist.type','artist.uri',\n         'artist.external_urls.spotify', 'audio.type', 'audio.id', 'audio.uri',\n         'audio.track_href', 'artist.id']\nfinal_dataset=pd.concat([final_dataset,feat.add_prefix('audio.')], axis=1)\nfinal_dataset=pd.concat([final_dataset,art.add_prefix('artist.')], axis=1).drop(columns=garbage)\nfinal_dataset.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Visualization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's summon the forces of matplot\nimport matplotlib.pyplot as plt\n\n#for vissualization purposes we want to get rid of extra rows caused by exploding the lists (such as when there are multiple artists for a track)\ncharts = final_dataset.groupby(['id']).mean()\ndef audio_key(key):\n    all_keys=['C', 'C#', 'D','D#','E','F','F#','G','G#','A','A#','B']\n    return all_keys[key]\ndef audio_meter(sig):\n    all_sigs=['Unknown','1/1','1/2','3/4','4/4','5/8']\n    if sig>len(all_sigs)-1: return 'Unknown'\n    else: return all_sigs[sig]\n\nplt.style.use('seaborn-poster')\ncharts['audio.time_signature'].apply(audio_meter).value_counts().plot(kind='barh', title='Musical Meter of Tracks in The Dataset')\n#plt.scatter(final_dataset['audio.key'],final_dataset['audio.tempo'], alpha=0.5, c='Purple') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see prevalent music metre is 4/4","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"charts['audio.key'].apply(audio_key).value_counts().sort_index().plot(kind='bar', use_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"While there are no obvious favorite keys, some of them are certainly out of favor: D# is far less popular, than G or A.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"charts['audio.tempo'].hist(bins=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"charts['audio.tempo'].value_counts(bins=200).nlargest(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most popular tempo is 120 BPM with other populars being below and above by 10, 20, 30 bpm. I would speculate this is more common for electronic, or electronically produced music, where you would just turn the knob to change BPM. \"Natural\" tempos usually align to x2 or x3. Only 128 bpm made it to top 10.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"charts.plot(kind='scatter',x='audio.tempo',y='audio.energy')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is how the track energy changes with tempo. Without doing too much stats we can see that lower tempo may correspond to both low and high level of energy, while higher tempos almost always mean high-energy music","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"charts.plot(kind='scatter',x='audio.tempo',y='audio.danceability')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, track suitability for dancing is associated with some moderate tempos in vicinity of 120 BPM. This is kinda expected from the perspective of physics (ability to keep up with tempo decreases with increase of body mass), but also it could be a reason for 120 BPM popularity.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}