{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-27T08:56:10.704799Z","iopub.execute_input":"2021-08-27T08:56:10.705138Z","iopub.status.idle":"2021-08-27T08:56:11.522432Z","shell.execute_reply.started":"2021-08-27T08:56:10.705104Z","shell.execute_reply":"2021-08-27T08:56:11.521509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]\ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor=\"gpu_predictor\")\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-27T08:10:26.907145Z","iopub.execute_input":"2021-08-27T08:10:26.907512Z","iopub.status.idle":"2021-08-27T08:10:49.21607Z","shell.execute_reply.started":"2021-08-27T08:10:26.90748Z","shell.execute_reply":"2021-08-27T08:10:49.215188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* 0 0.7245705537554137\n* 1 0.7242510333821858\n* 2 0.7270667092065692\n* 3 0.7268359229595335\n* 4 0.7257178555909586\n* 0.7256884149789322 0.0011430674400777338","metadata":{}},{"cell_type":"code","source":"# standardization\ndf = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]\nnumerical_cols = [col for col in useful_features if col.startswith(\"cont\")]\ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    scaler = preprocessing.StandardScaler()\n    xtrain[numerical_cols] = scaler.fit_transform(xtrain[numerical_cols])\n    xvalid[numerical_cols] = scaler.transform(xvalid[numerical_cols])\n    xtest[numerical_cols] = scaler.transform(xtest[numerical_cols])\n    \n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor=\"gpu_predictor\")\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-27T07:48:03.673626Z","iopub.execute_input":"2021-08-27T07:48:03.673881Z","iopub.status.idle":"2021-08-27T07:48:26.052345Z","shell.execute_reply.started":"2021-08-27T07:48:03.673855Z","shell.execute_reply":"2021-08-27T07:48:26.05091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* standardization\n* 0 0.7241755479182882\n* 1 0.7241138968948254\n* 2 0.7267386816038165\n* 3 0.7268357864120136\n* 4 0.725667388462628\n* 0.7255062602583143 0.001185068397378747","metadata":{}},{"cell_type":"code","source":"# log transformation\ndf = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]\nnumerical_cols = [col for col in useful_features if col.startswith(\"cont\")]\ndf_test = df_test[useful_features]\n\nfor col in numerical_cols:\n    df[col] = np.log1p(df[col])\n    df_test[col] = np.log1p(df_test[col])\n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor=\"gpu_predictor\")\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-27T07:47:41.211532Z","iopub.execute_input":"2021-08-27T07:47:41.211861Z","iopub.status.idle":"2021-08-27T07:48:03.672048Z","shell.execute_reply.started":"2021-08-27T07:47:41.211826Z","shell.execute_reply":"2021-08-27T07:48:03.671067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* log transformation\n* 0 0.7245867071148808\n* 1 0.7242518770698644\n* 2 0.7269464580617742\n* 3 0.7267203050271116\n* 4 0.7255892005274619\n* 0.7256189095602186 0.001087249680887288","metadata":{}},{"cell_type":"code","source":"# polynomial features\ndf = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]\nnumerical_cols = [col for col in useful_features if col.startswith(\"cont\")]\ndf_test = df_test[useful_features]\n\npoly = preprocessing.PolynomialFeatures(degree=3, interaction_only=True, include_bias=False)\ntrain_poly = poly.fit_transform(df[numerical_cols])\ntest_poly = poly.fit_transform(df_test[numerical_cols])\n\ndf_poly = pd.DataFrame(train_poly, columns=[f\"poly_{i}\" for i in range(train_poly.shape[1])])\ndf_test_poly = pd.DataFrame(test_poly, columns=[f\"poly_{i}\" for i in range(test_poly.shape[1])])\n\ndf = pd.concat([df, df_poly], axis=1)\ndf_test = pd.concat([df_test, df_test_poly], axis=1)\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]\ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor=\"gpu_predictor\")\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-27T07:46:25.861005Z","iopub.execute_input":"2021-08-27T07:46:25.861332Z","iopub.status.idle":"2021-08-27T07:47:41.209991Z","shell.execute_reply.started":"2021-08-27T07:46:25.861301Z","shell.execute_reply":"2021-08-27T07:47:41.208515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* polynomial features\n* 0 0.729073179900137\n* 1 0.7286941123028183\n* 2 0.7302315824391516\n* 3 0.7304305210608322\n* 4 0.7297044930462646\n* 0.7296267777498406 0.0006624450323974544","metadata":{}},{"cell_type":"code","source":"# for col in numerical_cols:\n#     bin_col = pd.cut(df[col], bins = 4,labels=False, right=False)\n#     bin_col = bin_col.to_dict()\n#     df.loc[:, f\"bin_{col}\"] = df.index.map(bin_col)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2021-08-27T07:36:35.812225Z","iopub.execute_input":"2021-08-27T07:36:35.812572Z","iopub.status.idle":"2021-08-27T07:36:35.819045Z","shell.execute_reply.started":"2021-08-27T07:36:35.812541Z","shell.execute_reply":"2021-08-27T07:36:35.818206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# binning the numerical features\n# pd.cut\ndf = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]\nnumerical_cols = [col for col in useful_features if col.startswith(\"cont\")]\ndf_test = df_test[useful_features]\n\n#bining the variables++\nfor col in numerical_cols:\n    for fold in range(5):\n        xvalid = df[df.kfold == fold].reset_index(drop=True)\n        bin_col = pd.cut(xvalid[col], bins = 4,labels=False, right=False)\n        bin_col = bin_col.to_dict()\n        xvalid.loc[:, f\"cat_bin_{col}\"] = xvalid.index.map(bin_col)\n\nfor col in numerical_cols:\n    bin_col = pd.cut(df_test[col], bins = 4,labels=False, right=False)\n    bin_col = bin_col.to_dict()\n    df_test.loc[:, f\"cat_bin_{col}\"] = df_test.index.map(bin_col)\n\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if col.startswith(\"cat\")]\nnumerical_cols = [col for col in useful_features if col.startswith(\"cont\")]\ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor=\"gpu_predictor\")\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\nprint(np.mean(scores), np.std(scores))\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-27T07:38:51.857109Z","iopub.execute_input":"2021-08-27T07:38:51.857461Z","iopub.status.idle":"2021-08-27T07:39:23.610861Z","shell.execute_reply.started":"2021-08-27T07:38:51.857428Z","shell.execute_reply":"2021-08-27T07:39:23.609942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# binning the numerical features\n# pd.cut\ndf = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]\nnumerical_cols = [col for col in useful_features if col.startswith(\"cont\")]\ndf_test = df_test[useful_features]\n\n#bining the variables++\nfor col in numerical_cols:\n    bin_col = pd.cut(df[col], bins = 4,labels=False, right=False)\n    bin_col = bin_col.to_dict()\n    df.loc[:, f\"cat_bin_{col}\"] = df.index.map(bin_col)\n\nfor col in numerical_cols:\n    bin_col = pd.cut(df_test[col], bins = 4,labels=False, right=False)\n    bin_col = bin_col.to_dict()\n    df_test.loc[:, f\"cat_bin_{col}\"] = df_test.index.map(bin_col)\n\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if col.startswith(\"cat\")]\nnumerical_cols = [col for col in useful_features if col.startswith(\"cont\")]\ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor=\"gpu_predictor\")\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\nprint(np.mean(scores), np.std(scores))\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-27T07:45:04.176117Z","iopub.execute_input":"2021-08-27T07:45:04.176471Z","iopub.status.idle":"2021-08-27T07:45:50.686949Z","shell.execute_reply.started":"2021-08-27T07:45:04.176438Z","shell.execute_reply":"2021-08-27T07:45:50.686072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* binning the numerical features and ordinary\n* 0 0.7244715259084568\n* 1 0.7247714725802955\n* 2 0.7263946453260414\n* 3 0.726903777621419\n* 4 0.7249883367633758\n* 0.7255059516399177 0.0009613651944672863","metadata":{}},{"cell_type":"code","source":"# binning the numerical features + OHE\n# pd.cut\ndf = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]\nnumerical_cols = [col for col in useful_features if col.startswith(\"cont\")]\ndf_test = df_test[useful_features]\n\n#bining the variables++\nfor col in numerical_cols:\n    bin_col = pd.cut(df[col], bins = 4,labels=False, right=False)\n    bin_col = bin_col.to_dict()\n    df.loc[:, f\"cat_bin_{col}\"] = df.index.map(bin_col)\n\nfor col in numerical_cols:\n    bin_col = pd.cut(df_test[col], bins = 4,labels=False, right=False)\n    bin_col = bin_col.to_dict()\n    df_test.loc[:, f\"cat_bin_{col}\"] = df_test.index.map(bin_col)\n\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if col.startswith(\"cat\")]\nnumerical_cols = [col for col in useful_features if col.startswith(\"cont\")]\ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ohe = preprocessing.OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n    xtrain_ohe = ohe.fit_transform(xtrain[object_cols])\n    xvalid_ohe = ohe.transform(xvalid[object_cols])\n    xtest_ohe = ohe.transform(xtest[object_cols])\n    \n    xtrain_ohe = pd.DataFrame(xtrain_ohe, columns=[f\"ohe_{i}\" for i in range(xtrain_ohe.shape[1])])\n    xvalid_ohe = pd.DataFrame(xvalid_ohe, columns=[f\"ohe_{i}\" for i in range(xvalid_ohe.shape[1])])\n    xtest_ohe = pd.DataFrame(xtest_ohe, columns=[f\"ohe_{i}\" for i in range(xtest_ohe.shape[1])])\n    \n    xtrain = pd.concat([xtrain, xtrain_ohe], axis=1)\n    xvalid = pd.concat([xvalid, xvalid_ohe], axis=1)\n    xtest = pd.concat([xtest, xtest_ohe], axis=1)\n    \n    xtrain = xtrain.drop(object_cols, axis=1)\n    xvalid = xvalid.drop(object_cols, axis=1)\n    xtest = xtest.drop(object_cols, axis=1)\n    \n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor=\"gpu_predictor\")\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\nprint(np.mean(scores), np.std(scores))\n","metadata":{"execution":{"iopub.status.busy":"2021-08-27T09:08:32.427425Z","iopub.execute_input":"2021-08-27T09:08:32.427869Z","iopub.status.idle":"2021-08-27T09:09:13.59705Z","shell.execute_reply.started":"2021-08-27T09:08:32.427829Z","shell.execute_reply":"2021-08-27T09:09:13.596016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* binning the numerical features + OHE\n* 0 0.7246528139817886\n* 1 0.7243188344102082\n* 2 0.7268415459695178\n* 3 0.7263439289970397\n* 4 0.7256872231245289\n* 0.7255688692966167 0.0009629304895589322\n","metadata":{}},{"cell_type":"code","source":"# One-hot encoding\ndf = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]\ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ohe = preprocessing.OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n    xtrain_ohe = ohe.fit_transform(xtrain[object_cols])\n    xvalid_ohe = ohe.transform(xvalid[object_cols])\n    xtest_ohe = ohe.transform(xtest[object_cols])\n    \n    xtrain_ohe = pd.DataFrame(xtrain_ohe, columns=[f\"ohe_{i}\" for i in range(xtrain_ohe.shape[1])])\n    xvalid_ohe = pd.DataFrame(xvalid_ohe, columns=[f\"ohe_{i}\" for i in range(xvalid_ohe.shape[1])])\n    xtest_ohe = pd.DataFrame(xtest_ohe, columns=[f\"ohe_{i}\" for i in range(xtest_ohe.shape[1])])\n    \n    xtrain = pd.concat([xtrain, xtrain_ohe], axis=1)\n    xvalid = pd.concat([xvalid, xvalid_ohe], axis=1)\n    xtest = pd.concat([xtest, xtest_ohe], axis=1)\n    \n    # this part is missing in the video:\n    xtrain = xtrain.drop(object_cols, axis=1)\n    xvalid = xvalid.drop(object_cols, axis=1)\n    xtest = xtest.drop(object_cols, axis=1)\n    # missing part ends\n    \n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor=\"gpu_predictor\")\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-27T07:40:56.902609Z","iopub.execute_input":"2021-08-27T07:40:56.902944Z","iopub.status.idle":"2021-08-27T07:41:19.475151Z","shell.execute_reply.started":"2021-08-27T07:40:56.902914Z","shell.execute_reply":"2021-08-27T07:41:19.474263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* One-hot encoding\n* 0 0.7244255014738967\n* 1 0.7245139958781214\n* 2 0.7264465446086561\n* 3 0.7264028943362871\n* 4 0.7257096926265366\n* 0.7254997257846996 0.0008811227736574191","metadata":{}},{"cell_type":"code","source":"# one hot encoding of categorical variables + standarization of ohe & numerical\ndf = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]\ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ohe = preprocessing.OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n    xtrain_ohe = ohe.fit_transform(xtrain[object_cols])\n    xvalid_ohe = ohe.transform(xvalid[object_cols])\n    xtest_ohe = ohe.transform(xtest[object_cols])\n    \n    xtrain_ohe = pd.DataFrame(xtrain_ohe, columns=[f\"cont_ohe_{i}\" for i in range(xtrain_ohe.shape[1])])\n    xvalid_ohe = pd.DataFrame(xvalid_ohe, columns=[f\"cont_ohe_{i}\" for i in range(xvalid_ohe.shape[1])])\n    xtest_ohe = pd.DataFrame(xtest_ohe, columns=[f\"cont_ohe_{i}\" for i in range(xtest_ohe.shape[1])])\n    \n    xtrain = pd.concat([xtrain, xtrain_ohe], axis=1)\n    xvalid = pd.concat([xvalid, xvalid_ohe], axis=1)\n    xtest = pd.concat([xtest, xtest_ohe], axis=1)\n        \n    # this part is missing in the video:\n    xtrain = xtrain.drop(object_cols, axis=1)\n    xvalid = xvalid.drop(object_cols, axis=1)\n    xtest = xtest.drop(object_cols, axis=1)\n    # missing part ends\n    numerical_cols = [col for col in useful_features if col.startswith(\"cont\")]\n    scaler = preprocessing.StandardScaler()\n    xtrain[numerical_cols] = scaler.fit_transform(xtrain[numerical_cols])\n    xvalid[numerical_cols] = scaler.transform(xvalid[numerical_cols])\n    xtest[numerical_cols] = scaler.transform(xtest[numerical_cols])\n    \n    \n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor=\"gpu_predictor\")\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-27T08:00:10.248296Z","iopub.execute_input":"2021-08-27T08:00:10.248647Z","iopub.status.idle":"2021-08-27T08:00:33.095879Z","shell.execute_reply.started":"2021-08-27T08:00:10.248616Z","shell.execute_reply":"2021-08-27T08:00:33.094958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"one hot encoding of categorical variables + standarization of ohe & numerical\n* 0 0.7244324833714519\n* 1 0.7245329062537117\n* 2 0.7262739942272469\n* 3 0.7264029729278617\n* 4 0.7260672928259383\n* 0.7255419299212421 0.0008720458471300098","metadata":{}},{"cell_type":"code","source":"# # combine categorical columns\n# # cat1_cat2\n# # df[cat1] + \"_\" + df[cat2]\n# df = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\n# df_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\n# sample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\n# useful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\n# object_cols = [col for col in useful_features if 'cat' in col]\n# df_test = df_test[useful_features]\n\n# for i in range(0, len(object_cols)-2, 1):\n#     for l in range(i+1, len(object_cols)-1, 1):\n#         col = df[object_cols[i]] + \"_\" + df[object_cols[l]]\n#         df.loc[:, f\"cat{i}_cat{l}\"] = df.index.map(col)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-27T08:40:34.431591Z","iopub.execute_input":"2021-08-27T08:40:34.431914Z","iopub.status.idle":"2021-08-27T08:40:39.312555Z","shell.execute_reply.started":"2021-08-27T08:40:34.431882Z","shell.execute_reply":"2021-08-27T08:40:39.311697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# combine categorical columns\n# cat1_cat2\n# df[cat1] + \"_\" + df[cat2]\ndf = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\ndf_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\nsample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]\ndf_test = df_test[useful_features]\n\nfor i in range(0, len(object_cols)-2, 1):\n    for l in range(i+1, len(object_cols)-1, 1):\n        col = df[object_cols[i]] + \"_\" + df[object_cols[l]]\n        df.loc[:, f\"cat{i}_cat{l}\"] = df.index.map(col)\n        \nfor i in range(0, len(object_cols)-2, 1):\n    for l in range(i+1, len(object_cols)-1, 1):\n        col = df_test[object_cols[i]] + \"_\" + df_test[object_cols[l]]\n        df_test.loc[:, f\"cat{i}_cat{l}\"] = df_test.index.map(col)\n\n\nuseful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if 'cat' in col]\ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ohe = preprocessing.OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n    xtrain_ohe = ohe.fit_transform(xtrain[object_cols])\n    xvalid_ohe = ohe.transform(xvalid[object_cols])\n    xtest_ohe = ohe.transform(xtest[object_cols])\n    \n    xtrain_ohe = pd.DataFrame(xtrain_ohe, columns=[f\"ohe_{i}\" for i in range(xtrain_ohe.shape[1])])\n    xvalid_ohe = pd.DataFrame(xvalid_ohe, columns=[f\"ohe_{i}\" for i in range(xvalid_ohe.shape[1])])\n    xtest_ohe = pd.DataFrame(xtest_ohe, columns=[f\"ohe_{i}\" for i in range(xtest_ohe.shape[1])])\n    \n    xtrain = pd.concat([xtrain, xtrain_ohe], axis=1)\n    xvalid = pd.concat([xvalid, xvalid_ohe], axis=1)\n    xtest = pd.concat([xtest, xtest_ohe], axis=1)\n    \n    xtrain = xtrain.drop(object_cols, axis=1)\n    xvalid = xvalid.drop(object_cols, axis=1)\n    xtest = xtest.drop(object_cols, axis=1)\n    \n    model = XGBRegressor(random_state=fold, tree_method='gpu_hist', gpu_id=0, predictor=\"gpu_predictor\")\n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-27T08:56:56.286656Z","iopub.execute_input":"2021-08-27T08:56:56.287012Z","iopub.status.idle":"2021-08-27T08:59:52.682154Z","shell.execute_reply.started":"2021-08-27T08:56:56.286981Z","shell.execute_reply":"2021-08-27T08:59:52.676961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* 0 0.724260954293362\n* 1 0.7244463921778946\n* 2 0.7264497617913407\n* 3 0.7266519905763227\n* 4 0.725542787749717\n* 0.7254703773177275 0.0009871065524215002","metadata":{}},{"cell_type":"markdown","source":"* combine categorical columns\n0.7254703773177275 0.0009871065524215002\n* one hot encoding of categorical variables + standarization of ohe & numerical\n0.7255419299212421 0.0008720458471300098\n* one hot encoding\n0.7254997257846996 0.0008811227736574191","metadata":{}}]}