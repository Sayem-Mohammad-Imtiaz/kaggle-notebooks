{"cells":[{"metadata":{},"cell_type":"markdown","source":"## **Keras-Implementation of Attention-UNet for Pneumothorax Segmentation**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.compat.v1 import ConfigProto\nfrom tensorflow.compat.v1 import InteractiveSession\n\nconfig = ConfigProto()\nconfig.gpu_options.allow_growth = True \nsession = InteractiveSession(config=config)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load Packages","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport cv2 \nimport sys \nimport random\nimport warnings\nimport numpy as np\nimport pandas as pd  \nfrom time import time \nimport matplotlib.pyplot as plt \nfrom tqdm import tqdm \nfrom itertools import chain \nfrom skimage.io import imread, imshow, imread_collection, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label \n\nimport tensorflow as tf \nfrom tensorflow.keras.layers import Input, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, Concatenate, Activation, Add, multiply, add, concatenate, LeakyReLU, ZeroPadding2D, UpSampling2D, BatchNormalization\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom tensorflow.keras import backend as K \n\nfrom sklearn.metrics import classification_report, confusion_matrix\n%matplotlib inline \n\nIMG_HEIGHT = 128\nIMG_WIDTH = 128\nIMG_CHANNEL = 3\nIMG_PATH = '../input/pneumothorax-chest-xray-images-and-masks/siim-acr-pneumothorax/png_images'\nMASK_PATH = '../input/pneumothorax-chest-xray-images-and-masks/siim-acr-pneumothorax/png_masks'\n\nwarnings.filterwarnings('ignore', category=UserWarning, module='skimage')\nseed = 42 \nrandom.seed = seed\nnp.random.seed = seed","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing\nload tabular data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/pneumothorax-chest-xray-images-and-masks/siim-acr-pneumothorax/stage_1_train_images.csv')\ntest_df = pd.read_csv('../input/pneumothorax-chest-xray-images-and-masks/siim-acr-pneumothorax/stage_1_test_images.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mask only images that have label of 1 (pneumothorax detected). We use this data for train segmentation model later.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_pneumo = train_df[train_df['has_pneumo'] == 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Resizing images and its mask to 128 x 128, also add label to ensure we only put data that have label of  1 (it has pneumothorax). Resizing images to smaller dimention will help reduce background that contains pretty large number of 0 values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Getting and Resizing Train Images, Train Mask, and Adding Label ...\\n\\n\")\n\n# Create X_train, Y_train, and Label\nX_train_seg = np.zeros((len(train_df_pneumo), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL), dtype=np.uint8)\nY_train_seg = np.zeros((len(train_df_pneumo), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\nLabel_seg = np.zeros(len(train_df_pneumo), dtype=np.uint8)\n\nimg_data = list(train_df_pneumo.T.to_dict().values())\n\nfor i, data_row in tqdm(enumerate(img_data), total=len(img_data)):\n    \n    patientImage = data_row['new_filename']\n    imageLabel  = data_row['has_pneumo']\n\n    imagePath = os.path.join(IMG_PATH, patientImage)\n    lungImage = imread(imagePath)\n    lungImage = np.expand_dims(resize(lungImage, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True), axis=-1)\n    \n    X_train_seg[i] = lungImage\n\n    Label_seg[i] = imageLabel\n\n    maskPath = os.path.join(MASK_PATH, patientImage)\n    maskImage = imread(maskPath)\n    maskImage = np.expand_dims(resize(maskImage, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True), axis=-1)\n\n    Y_train_seg[i] = maskImage\n\nprint('\\n\\nProcess ... C O M P L E T E')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualize the data and its mask. The picture show to us that all the images only contains label of 1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Illustrate the train images and masks\nplt.figure(figsize=(20, 16))\nx, y = 12, 4\nfor i in range(y):\n    for j in range(x):\n        plt.subplot(y*2, x, i*2*x+j+1)\n        pos = i*120 + j*10\n        plt.imshow(X_train_seg[pos], cmap=plt.cm.bone)\n        plt.title('Image #{}'.format(pos))\n        plt.axis('off')\n        plt.subplot(y*2, x, (i*2+1)*x+j+1)\n\n        plt.imshow(np.squeeze(Y_train_seg[pos]), cmap='gray_r')\n        plt.title('Mask #{}\\nLabel: {}'.format(pos, Label_seg[pos]))\n        plt.axis('off')\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create IOU score, Dice Coef, and Dice Coef Loss","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def iou_score(y_pred, y_true, smooth=1):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    union = K.sum(y_true, -1) + K.sum(y_pred, -1) - intersection\n    iou = (intersection + smooth)/(union + smooth)\n    return iou\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## About the Model\nhere is a link about attention-unet paper : https://arxiv.org/abs/1804.03999 <br>\nmedium : https://medium.com/@sh.tsang/review-attention-u-net-learning-where-to-look-for-the-pancreas-biomedical-image-segmentation-e5f4699daf9f <br>\ngithub : https://github.com/lixiaolei1982/Keras-Implementation-of-U-Net-R2U-Net-Attention-U-Net-Attention-R2U-Net.-","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Build Attention Block","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def AttnBlock2D(x, g, inter_channel, data_format='channels_first'):\n\n    theta_x = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(x)\n\n    phi_g = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(g)\n\n    f = Activation('relu')(add([theta_x, phi_g]))\n\n    psi_f = Conv2D(1, [1, 1], strides=[1, 1], data_format=data_format)(f)\n\n    rate = Activation('sigmoid')(psi_f)\n\n    att_x = multiply([x, rate])\n\n    return att_x\n\n\ndef attention_up_and_concate(down_layer, layer, data_format='channels_first'):\n    \n    if data_format == 'channels_first':\n        in_channel = down_layer.get_shape().as_list()[1]\n    else:\n        in_channel = down_layer.get_shape().as_list()[3]\n    \n    up = UpSampling2D(size=(2, 2), data_format=data_format)(down_layer)\n    layer = AttnBlock2D(x=layer, g=up, inter_channel=in_channel // 4, data_format=data_format)\n\n    if data_format == 'channels_first':\n        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=1))\n    else:\n        my_concat = Lambda(lambda x: K.concatenate([x[0], x[3]], axis=3))\n    \n    concate = my_concat([up, layer])\n    return concate","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Attention-UNet","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Attention U-Net \ndef att_unet(img_w, img_h, n_label, data_format='channels_first'):\n    inputs = Input((IMG_CHANNEL, img_w, img_h))\n    x = inputs\n    depth = 4\n    features = 32\n    skips = []\n    for i in range(depth):\n\n        # ENCODER\n        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n        x = Dropout(0.2)(x)\n        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n        skips.append(x)\n        x = MaxPooling2D((2, 2), data_format='channels_first')(x)\n        features = features * 2\n\n    # BOTTLENECK\n    x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n    x = Dropout(0.2)(x)\n    x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n\n    # DECODER\n    for i in reversed(range(depth)):\n        features = features // 2\n        x = attention_up_and_concate(x, skips[i], data_format=data_format)\n        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n        x = Dropout(0.2)(x)\n        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n    \n    conv6 = Conv2D(n_label, (1, 1), padding='same', data_format=data_format)(x)\n    conv7 = Activation('sigmoid')(conv6)\n    \n    model = Model(inputs=inputs, outputs=conv7)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = att_unet(IMG_WIDTH, IMG_HEIGHT, n_label=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=[dice_coef_loss, iou_score]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We must change dimension to first channel format to train","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_seg = np.rollaxis(X_train_seg, 3, 1)\nY_train_seg = np.rollaxis(Y_train_seg, 3, 1)\nprint(X_train_seg.shape)\nprint(Y_train_seg.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stop = EarlyStopping(\n    monitor='val_loss',\n    min_delta=0,\n    patience=5,\n    restore_best_weights=True,\n    verbose=1\n)\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.25, min_delta=1e-10 ,patience=3, \n                                   verbose=1, mode='auto')\n\ncallbacks = [reduceLROnPlat]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train the Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 80\nmodel.fit(X_train_seg, Y_train_seg, validation_split=0.1, batch_size=16, epochs=epochs, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_seg = np.rollaxis(X_train_seg, 3, 1)\nY_train_seg = np.rollaxis(Y_train_seg, 3, 1)\nprint(X_train_seg.shape)\nprint(Y_train_seg.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict \npredict using some images in train data to ensure how well our model draw a segmentation compare to ground truth mask","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# The first 90% used for training\npred_train = model.predict(X_train_seg[:int(X_train_seg.shape[0]*0.9)].astype(np.float16), verbose=1)\n# The last 10% used for validation\npred_val = model.predict(X_train_seg[int(X_train_seg.shape[0]*0.9):].astype(np.float16), verbose=1)\n\n# pred_test = model.predict(X_test, verbose=1)\n\n# Thresholds prediction\npred_train_threshold = (pred_train > 0.40).astype(np.float16)\npred_val_threshold = (pred_val > 0.40).astype(np.float16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To visualize we change to last channel format ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# CHANGE TO CHANNEL LAST \nX_train_seg = np.rollaxis(X_train_seg, 3, 1)\nX_train_seg = np.rollaxis(X_train_seg, 3, 2)\n\nY_train_seg  = np.rollaxis(Y_train_seg, 3, 1)\nY_train_seg = np.rollaxis(Y_train_seg, 3, 2)\n\npred_train_threshold = np.rollaxis(pred_train_threshold, 3, 1)\npred_train_threshold = np.rollaxis(pred_train_threshold, 3, 2)\n\npred_val_threshold = np.rollaxis(pred_val_threshold, 3, 1)\npred_val_threshold = np.rollaxis(pred_val_threshold, 3, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Showing our predicted masks on our training data\nix = random.randint(0, 682)\nplt.figure(figsize=(20, 28))\n\n# Our original training image\nplt.subplot(131)\nimshow(X_train_seg[ix])\nplt.title('Image')\n\n# Our original combined mask\nplt.subplot(132)\nimshow(np.squeeze(Y_train_seg[ix]), cmap='gray_r')\nplt.title('Mask')\n\n# The mask of our model U-Net prediction\nplt.subplot(133)\nimshow(np.squeeze(pred_train_threshold[ix] > 0.40), cmap='gray_r')\nplt.title('Prediction')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Showing our predicted masks on our training data\nix = random.randint(602, 668)\nplt.figure(figsize=(20, 28))\n\n# Our original training image\nplt.subplot(121)\nimshow(X_train_seg[ix])\nplt.title('Image')\n\n# The mask of our model U-Net prediction\nplt.subplot(122)\nix = ix - 603\nimshow(np.squeeze(pred_val_threshold[ix] > 0.40), cmap='gray_r')\nplt.title('Prediction')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Last, maybe you can tuning the model so it will perform better than i do 😊. Good Luck!!!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}