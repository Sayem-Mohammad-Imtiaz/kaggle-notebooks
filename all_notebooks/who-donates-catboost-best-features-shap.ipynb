{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Data loading","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\npd.reset_option('^display.', silent=True)\n\n# Load data\nX_train = pd.read_csv(\"/kaggle/input/donorsprediction/Raw_Data_for_train_test.csv\")\nX_test = pd.read_csv(\"/kaggle/input/donorsprediction/Predict_donor.csv\")\n\n# Split target and predictors\ny_train = X_train['TARGET_B']\nnum_train = len(X_train)\nX_train.drop(['TARGET_B'], axis=1, inplace=True)\ndf = pd.concat([X_train, X_test], ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Short EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show the columns types\ndf.dtypes.value_counts()\ncategorical_columns = df.select_dtypes('object').columns\nprint(len(df.columns)-len(df.select_dtypes('object').columns),'numerical columns:')\nprint([i for i in list(df.columns) if i not in list(df.select_dtypes('object').columns)], '\\n')\nprint(len(df.select_dtypes('object').columns),'categorical columns:')\nprint(list(df.select_dtypes('object').columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature encoding","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('mode.chained_assignment', None)\n\n# Delete unused variables CONTROL_NUMBER and TARGET_D\ndf = df.drop(['CONTROL_NUMBER', 'TARGET_D'], axis=1)\n\n# Fill missing values for age with median\nages = df.groupby(['DONOR_GENDER']).DONOR_AGE\nf = lambda x: x.fillna(x.median())\ndf.DONOR_AGE = ages.transform(f)\n\n# Fill missing values for income group with median\nincome = df.groupby(['DONOR_AGE', 'DONOR_GENDER']).INCOME_GROUP\nf = lambda x: x.fillna(x.median())\ndf.INCOME_GROUP = income.transform(f)\ndf.INCOME_GROUP = df.INCOME_GROUP.fillna(4)\n\n# Use zero for missing SES values\ndf.SES[df.SES == '?'] = 0\n\n# Use zero missing cluster\ndf.CLUSTER_CODE[df.CLUSTER_CODE == '.'] = 0\n\n# Use mean value S for missing URBANICITY\ndf.URBANICITY[df.URBANICITY == '?'] = 'S'\n\n# Fill missing values for wealth rating with median\nwealth = df.groupby(['DONOR_AGE', 'INCOME_GROUP']).WEALTH_RATING\nf = lambda x: x.fillna(x.median())\ndf.WEALTH_RATING = wealth.transform(f)\ndf.WEALTH_RATING = df.WEALTH_RATING.fillna(5)\n\n# Use mean value for missing MONTHS_SINCE_LAST_PROM_RESP\ndf.MONTHS_SINCE_LAST_PROM_RESP[df.MONTHS_SINCE_LAST_PROM_RESP.isnull()] = 19\n\n# Save indices of categorial features\ncategorical_features_indices = np.where(df.dtypes == 'object')[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train/test split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the df into train and test set\nX_train = df.iloc[:num_train,:]\nX_test = df.iloc[num_train:,:]\n\n# Make a training and validation set\nfrom sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, train_size=0.75, stratify=y_train, random_state=0)\n\n# Calculate pos weight\npos_weight = sum(y_train.values == 0)/sum(y_train.values == 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import catboost\nparams = {\"iterations\": 10000,\n          \"learning_rate\": 0.1,\n          \"scale_pos_weight\": pos_weight,\n          \"eval_metric\": 'AUC',\n          \"custom_loss\": 'Accuracy',\n          \"loss_function\": \"Logloss\",\n          \"boosting_type\": 'Ordered',\n          'od_type': 'Iter',\n          'od_wait': 30,\n          \"use_best_model\": True,\n          \"logging_level\": 'Verbose',\n          \"random_seed\": 0\n}\n\ntrain_pool = catboost.Pool(X_train, y_train, cat_features=categorical_features_indices)\nvalid_pool = catboost.Pool(X_valid, y_valid, cat_features=categorical_features_indices)\n\nmodel = catboost.CatBoostClassifier(**params)\nmodel.fit(train_pool, eval_set=valid_pool, plot=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\nfrom sklearn.metrics import precision_score, recall_score\nfrom catboost.utils import get_roc_curve, select_threshold\n\ndef plot_roc_curve(fpr, tpr, label=None):\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], 'k--')\n\ny_pred = model.predict(X_valid)\nprint(f\"Confusion Matrix:\\n {confusion_matrix(y_valid, y_pred)}\\n\")\nprint(f\"Classification Report:\\n {classification_report(y_valid, y_pred)}\\n\")\n\ny_pred = model.predict(X_valid)\nprint(f\"Accuracy on validation set: {accuracy_score(y_valid, y_pred)}\")\nprint(f\"Precision on validation set: {precision_score(y_valid, y_pred)}\")\nprint(f\"Recall on validation set: {recall_score(y_valid, y_pred)}\")\n\nfpr_train, tpr_train, _ = get_roc_curve(model, train_pool)\nfpr_valid, tpr_valid, _ = get_roc_curve(model, valid_pool)\n\nplt.figure(figsize=(8,6))\nplot_roc_curve(fpr_train, tpr_train, \"Training ROC\")\nplot_roc_curve(fpr_valid, tpr_valid, \"Validation ROC\")\nplt.legend(loc=\"lower right\")\nplt.title(\"ROC plot\")\nplt.ylabel(\"TPR\")\nplt.xlabel(\"FPR\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature importance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.get_feature_importance(train_pool, fstr_type=catboost.EFstrType.FeatureImportance, prettified=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = model.get_feature_importance(train_pool, fstr_type=catboost.EFstrType.FeatureImportance)\nindices = np.argsort(importances)[::-1]\nplt.figure(figsize=(12,12))\nplt.title('Feature importance for CatBoost classifier')\nplt.barh(X_train.columns[indices][::-1], importances[indices][::-1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature interactions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"interactions = model.get_feature_importance(train_pool, fstr_type=catboost.EFstrType.Interaction)\nfeature_interaction = [[X_train.columns[interaction[0]], X_train.columns[interaction[1]], interaction[2]] for interaction in interactions]\nfeature_interaction_df = pd.DataFrame(feature_interaction, columns=['feature1', 'feature2', 'interaction_strength'])\nfeature_interaction_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Series(index=zip(feature_interaction_df['feature1'], feature_interaction_df['feature2']), data=feature_interaction_df['interaction_strength'].values, name='interaction_strength').head(10)[::-1].plot(kind='barh', figsize=(12,12))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SHAP Values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import shap\nshap_values = model.get_feature_importance(train_pool, fstr_type=catboost.EFstrType.ShapValues)\nshap.initjs()\nshap.summary_plot(shap_values[:, :-1], X_train, feature_names=X_train.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.summary_plot(shap_values[:, :-1], X_train, feature_names=X_train.columns.tolist(), plot_type=\"bar\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_preds = model.predict(X_test)\ny_test_probas = model.predict_proba(X_test)\n\nprint(f\"20 first predictions on test set: {y_test_preds[:20]}\")\nprint(f\"20 first probability dists: {y_test_probas[:20]}\")\nprint(f\"Number of predicated donors: {np.sum(y_test_preds == 1)}\")\nprint(f\"Number of predicated non-donors: {np.sum(y_test_preds == 0)}\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}