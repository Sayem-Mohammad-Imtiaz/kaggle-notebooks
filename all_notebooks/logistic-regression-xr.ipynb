{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt # plotting\nfrom sklearn.neural_network import MLPClassifier \nfrom sklearn.linear_model import LogisticRegression\n#from mpl_toolkits.mplot3d import Axes3D\n#from sklearn.preprocessing import StandardScaler\n#from sklearn.model_selection import train_test_split\n\n\ndata = pd.read_csv('../input/bank.csv',sep=',',header='infer')\ndata = data.drop(['day','poutcome','contact'],axis=1)\n\ndef binaryType_(data):\n    \n    data.y.replace(('yes', 'no'), (1, 0), inplace=True)\n    data.default.replace(('yes','no'),(1,0),inplace=True)\n    data.housing.replace(('yes','no'),(1,0),inplace=True)\n    data.loan.replace(('yes','no'),(1,0),inplace=True)\n    data.marital.replace(('married','single','divorced'),(1,2,3),inplace=True)\n    #data.contact.replace(('telephone','cellular','unknown'),(1,2,3),inplace=True)\n    #data.putcome.replace(('other','failure','success','unknown'),(1,2,3,4),inplace=True)\n    data.month.replace(('jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec'),(1,2,3,4,5,6,7,8,9,10,11,12),inplace=True)\n    data.education.replace(('primary','secondary','tertiary','unknown'),(1,2,3,4),inplace=True)\n    data.job.replace(('technician','services','retired','blue-collar','entrepreneur','admin.','housemaid','student','self-employed','management','unemployed','unknown'),(1,2,3,4,5,6,7,8,9,10,11,12),inplace=True )\n    return data\n\ndata = binaryType_(data)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution graphs (histogram/bar graph) of column data\ndef plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n    nunique = df.nunique()\n    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n    nRow, nCol = df.shape\n    columnNames = list(df)\n    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow\n    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n    for i in range(min(nCol, nGraphShown)):\n        plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n        columnDf = df.iloc[:, i]\n        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n            valueCounts = columnDf.value_counts()\n            valueCounts.plot.bar()\n        else:\n            columnDf.hist()\n        plt.ylabel('counts')\n        plt.xticks(rotation = 90)\n        plt.title(f'{columnNames[i]} (column {i})')\n    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt # plotting\n\n# === Γραφική αναπαράσταση των χαρακτηριστικών.\n\nplt.style.use('seaborn-whitegrid')\n\n# να σβήσω και το in[2]\n#plotPerColumnDistribution(data, 15, 5) \n#plotPerColumnDistribution(data, 20, 5)\n#plotPerColumnDistribution(data, 10, 10)\n\ndata.hist(bins=20, figsize=(14,10), color='#E14906')\nplt.show()\n\nplt.hist((data.y),bins=20)\nplt.show()\n\nplt.hist((data.duration),bins=100)\nplt.show()\n\nplt.hist((data.age),bins=10) \nplt.show()\n\nplt.hist((data.balance),bins=10) \nplt.show()\n\n# Μετρητής των y σε 0 και 1\ndata['y'].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import classification_report\n\ndef evaluate_classifier_performance(df_train_class, predicted_train, predicted_prob_train, df_test_class, predicted_test, predicted_prob_test, roc_y_n):\n    ### Confusion Matrix\n    confusion_matrix_train = confusion_matrix(df_train_class, predicted_train)\n    confusion_matrix_test = confusion_matrix(df_test_class, predicted_test)\n    print (\"\\nTraining Confusion Matrix:\\n \", confusion_matrix_train)\n    print (\"\\nTesting Confusion Matrix:\\n \", confusion_matrix_test)\n    \n    # Testing Confusion Matrix graph\n    import pylab as pl\n    cm = confusion_matrix(y_test, predicted_test)\n    pl.matshow(cm)\n    pl.title('Testing Confusion matrix of the classifier')\n    pl.colorbar()\n    pl.show()\n    \n    ### Accuracy score\n    score_train = accuracy_score(df_train_class, predicted_train)\n    score_test = accuracy_score(df_test_class, predicted_test)\n    print (\"\\nTraining Accuracy Score: \", score_train)\n    print (\"\\nTesting Accuracy Score: \", score_test)\n       \n    ### Precision, Recall  \n    precision_train = precision_score(df_train_class, predicted_train)\n    precision_test = precision_score(df_test_class, predicted_test)\n    print (\"\\nTraining Precision: \", precision_train)\n    print (\"\\nTesting Precision: \", precision_test)\n    \n    recall_train = recall_score(df_train_class, predicted_train)\n    recall_test = recall_score(df_test_class, predicted_test)\n    print (\"\\nTraining Recall: \", recall_train)\n    print (\"\\nTesting Recall: \", recall_test)\n    \n    ### Classification Report\n    print (\"\\nTrain Classification Report: \\n\",classification_report(df_train_class, predicted_train))\n    print (\"\\nTest Classification Report: \\n\",classification_report(df_test_class, predicted_test))\n\n    ### F1 Score\n    f1score_train = f1_score(df_train_class, predicted_train)#, average='weighted')\n    f1score_test = f1_score(df_test_class, predicted_test)#, average='weighted')\n    print (\"\\nTraining F1score: \", f1score_train)\n    print (\"\\nTesting F1score: \", f1score_test)\n    \n    f1score_train = f1_score(df_train_class, predicted_train, average='weighted')\n    f1score_test = f1_score(df_test_class, predicted_test, average='weighted')\n    print (\"\\nTraining Weigted F1score: \", f1score_train)\n    print (\"\\nTesting Weighted F1score: \", f1score_test)\n    \n    ### ROC-AUC\n    if roc_y_n == 'y':\n        fpr, tpr, threshold = roc_curve(df_train_class, predicted_prob_train[:,1])\n        roc_auc_train = auc(fpr, tpr)\n        print (\"\\nTraining AUC for ROC: \",roc_auc_train)\n        plt.figure()\n        plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc_train)\n        plt.plot([0, 1], [0, 1],'r--')\n        plt.xlim([0, 1])\n        plt.ylim([0, 1])\n        plt.ylabel('True Positive Rate')\n        plt.xlabel('False Positive Rate')\n        plt.legend(loc = 'lower right')\n        plt.title('Training - Receiver Operating Characteristic')\n        \n        fpr, tpr, threshold = roc_curve(df_test_class, predicted_prob_test[:,1])\n        roc_auc_test = auc(fpr, tpr)\n        print (\"\\nTesting AUC for ROC: \",roc_auc_test)\n        plt.figure()\n        plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc_test)\n        plt.plot([0, 1], [0, 1],'r--')\n        plt.xlim([0, 1])\n        plt.ylim([0, 1])\n        plt.ylabel('True Positive Rate')\n        plt.xlabel('False Positive Rate')\n        plt.legend(loc = 'lower right')\n        plt.title('Testing - Receiver Operating Characteristic')\n        \n        return(df_train_class, predicted_train, predicted_prob_train, df_test_class, predicted_test, predicted_prob_test, roc_y_n);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt \nimport seaborn as sns \nimport pandas as pd \nimport numpy as np\nimport time\n\nfrom sklearn.neural_network import MLPClassifier \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\n\n# create training and testing vars\nX_train, X_test, y_train, y_test = train_test_split(data, data.y, test_size=0.2)\nprint (X_train.shape, y_train.shape)\nprint (X_test.shape, y_test.shape)\n\nX_train['y'].value_counts()\n# ============================\n#X_train.info()\n\ndf_train = X_train\ndf_test = X_test\n\ndf_train_class = pd.DataFrame(df_train['y'])    \ndf_train_features = df_train.loc[:, df_train.columns != 'y']\n\ndf_test_class = pd.DataFrame(df_test['y'])\ndf_test_features = df_test.loc[:, df_test.columns != 'y']\n\n\nprint(\"  ### Logistic Regression  \")\nt_start = time.clock()\nLR = LogisticRegression()\nLR.fit(df_train_features, df_train_class)\n\nlog_scores = cross_val_score(LR, X_train, y_train, cv=3)\nlog_reg_mean = log_scores.mean()\nprint(\"Crossval Mean Scores :\" , log_reg_mean)\n\npredicted_train = LR.predict(df_train_features)\npredicted_test = LR.predict(df_test_features)\n\npredicted_prob_train = LR.predict_proba(df_train_features)\npredicted_prob_test = LR.predict_proba(df_test_features)\n\nevaluate_classifier_performance(df_train_class, predicted_train, predicted_prob_train, df_test_class, predicted_test, predicted_prob_test, 'y')\n\nprint(\"Crossval Mean Scores :\" , log_reg_mean)\n\nt_end = time.clock()\nt_diff = t_end - t_start\nprint(\"Trained in {f:.2f} sec\".format(f=t_diff))\n\nprint(\"  ###  Τέλος Logistic Regression  \")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}