{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Preprocessing","metadata":{}},{"cell_type":"markdown","source":"Import relevant packages","metadata":{}},{"cell_type":"code","source":"#import relevant packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, mean_squared_error","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#read in data\ndf = pd.read_csv(\"../input/austin-311/austin_311.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#quick initial look at the dataset\nprint(df.shape)\ndf.head()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"'SR Number' is a unique identifier for every column, so it would not be very useful when making predictions. 'SR Location' is just a combination of other columns, as is '(Latitude, Longitude)'. 'Street Number' also did not seem useful for this analysis. I removed these columns.","metadata":{}},{"cell_type":"code","source":"df = df[[\"SR Description\", \"Method Received\", \"SR Status\", \"Street Name\", \"City\", \"Zip Code\", \"County\", \\\n    \"Latitude Coordinate\", \"Longitude Coordinate\", \"Council District\", \"Created Date\", \"Closed Date\"]]\nprint(df.shape)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Removing rows with incomplete data.","metadata":{}},{"cell_type":"code","source":"df.isna().sum()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.dropna()\nprint(df.shape)\ndf.head()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note that the total number of rows has dropped from 912301 to 850918. Total number of columns dropped from 16 to 12.","metadata":{}},{"cell_type":"code","source":"print(np.unique(df['City']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Look at all the different spellings for Austin! Typos and differences like this are common in manually entered datasets. Let's try to fix this by replacing the mistyped values with a standard version.","metadata":{}},{"cell_type":"code","source":"austin_spellings =  ['ATX', 'AUST', 'AUSTIN', 'AUSTIN 5 ETJ', 'AUSTUN', 'AUsti', 'AUstin', 'Au', \\\n 'AuStin', 'Aus', 'Ausitn', 'Aust', 'AustIn', 'AustiN', 'Austin', 'Austin, TX', \\\n 'Austin.', 'Austn', 'Austtin', 'a', 'aUSTIN', 'aus', 'ausitn', 'austi', 'austibn', 'austin', 'austin `', 'austn']\n\nfor i in austin_spellings:\n    df['City'].replace({i:\"AUSTIN\"}, inplace = True)\n\ndf['City'].replace({'Del Valle': 'DEL VALLE', 'Del valle': 'DEL VALLE', 'del valle': 'DEL VALLE'}, inplace = True)\n\ndf['City'] = df['City'].apply(lambda x: x.upper())\n\nprint(df.shape)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Zip Code'] = df['Zip Code'].apply(lambda x: int(x))\ndf['Council District'] = df['Council District'].apply(lambda x: int(x))\n\ndf['Zip Code'] = df['Zip Code'].astype('category')\ndf['Council District'] = df['Council District'].astype('category')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creating a column for the time it takes for a ticket to be closed","metadata":{}},{"cell_type":"code","source":"df['Created Date'] = pd.to_datetime(df['Created Date'])\ndf['Closed Date'] = pd.to_datetime(df['Closed Date'])\ndf['time to close'] = (df['Closed Date'] - df['Created Date']).apply(lambda x: pd.Timedelta.total_seconds(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Converting the dates into a number. This will be easier to use in our modeling algorithms.","metadata":{}},{"cell_type":"code","source":"df['Created Date'] = df['Created Date'].apply(lambda x: int(x.timestamp()))\ndf['Closed Date'] = df['Closed Date'].apply(lambda x: int(x.timestamp()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.shape)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's look at each column's value and see if we can find anything else to clean.","metadata":{}},{"cell_type":"code","source":"for i in list(df):\n    print(i, len(np.unique(df[i])))\n    print(np.unique(df[i]))\n    print()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The only thing that looks like it could use some extra cleaning is the Street Name, but it may be too complicated to do that now. There are packages and methods to find minor typos in manually entered data programmatically, but it's not necessary for this class.","metadata":{}},{"cell_type":"markdown","source":"For the classification problem, we need to label our classes based on the case's status. We are looking to predict closed or resolved cases.","metadata":{}},{"cell_type":"code","source":"df.groupby('SR Status')['SR Description'].count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['SR Status'].replace({'Closed': 1, 'Closed -Incomplete': 0, 'Closed -Incomplete Information': 0, 'Duplicate (closed)': 0, 'Duplicate (open)': 0, 'Incomplete':0, 'New': 0, 'Open': 0, 'Resolved':1, 'TO BE DELETED': 0, 'Work In Progress': 0}, inplace = True)\ndf.groupby('SR Status')['SR Description'].count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. EDA","metadata":{}},{"cell_type":"markdown","source":"In this section we will try to do some basic exploratory data analysis by visualizing the data.","metadata":{}},{"cell_type":"markdown","source":"The first thing I want to try is to see how different zip codes are reacted to differently. We can look at the zip codes with the most 311 complaints, as well as how their 311 complaints were resolved.","metadata":{}},{"cell_type":"code","source":"#find top and bottom zip codes for number of complaints\ntop_zips = [(i, df['Zip Code'][df['Zip Code'] == i].count()) for i in np.unique(df['Zip Code'])]\ntop_zips = sorted(top_zips, key = lambda x: x[1], reverse = True)[0:8]\n\nbot_zips = [(i, df['Zip Code'][df['Zip Code'] == i].count()) for i in np.unique(df['Zip Code'])]\nbot_zips = sorted(bot_zips, key = lambda x: x[1], reverse = False)[0:8]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#seperate zip codes by number of completed and incomplete compaints\nzips = [i[0] for i in top_zips]\nzips_zeros = [df['Zip Code'][(df['Zip Code'] == i) & (df['SR Status'] == 0)].count() for i in zips]\nzips_ones = [df['Zip Code'][(df['Zip Code'] == i) & (df['SR Status'] == 1)].count() for i in zips]\n\nbzips = [i[0] for i in bot_zips]\nbzips_zeros = [df['Zip Code'][(df['Zip Code'] == i) & (df['SR Status'] == 0)].count() for i in bzips]\nbzips_ones = [df['Zip Code'][(df['Zip Code'] == i) & (df['SR Status'] == 1)].count() for i in bzips]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot top zip codes\nx = np.arange(len(zips))\nwidth = 0.35\n\nfig, ax = plt.subplots(figsize = (8,3))\nrects1 = ax.bar(x - width/2, zips_zeros, width, label='0')\nrects2 = ax.bar(x + width/2, zips_ones, width, label='1')\n\nax.set_ylabel('Scores')\nax.set_title('Scores by Zip Code and Status')\nax.set_xticks(x)\nax.set_xticklabels(zips)\nax.legend()\n\n\nfig.tight_layout()\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are a lot of 311 calls in 78704. This area of Austin is pretty packed, as it's near downtown, so that seems to make sense. \n\nSimilarly,  we can look at the zip codes with the least 311 complaints and how they were resolved.","metadata":{}},{"cell_type":"code","source":"#plot bottom zip codes\nx = np.arange(len(zips))\nwidth = 0.35\n\nfig, ax = plt.subplots(figsize = (8,3))\nrects1 = ax.bar(x - width/2, bzips_zeros, width, label='0')\nrects2 = ax.bar(x + width/2, bzips_ones, width, label='1')\n\nax.set_ylabel('Scores')\nax.set_title('Scores by Zip Code and Status')\nax.set_xticks(x)\nax.set_xticklabels(bzips)\nax.legend()\n\n\nfig.tight_layout()\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I don't know much about Austin, but 78664 appears to be in Round Rock. Maybe Round Rock is a less populated area, or it is generally safer or has little to no problems. It could also be possible that Round Rock has a seperate 311 line that most complaints get directed to, and only a few of them make it to the Austin 311 dataset. ","metadata":{}},{"cell_type":"markdown","source":"Lets also look at the ratio of incomplete complaints to total complaints, and see if we can learn anything from there.","metadata":{}},{"cell_type":"code","source":"#find ratio of incomplete complaints to total complaints for each zip code\n\ntop_zips = [(i, df['Zip Code'][df['Zip Code'] == i].count()) for i in np.unique(df['Zip Code'])]\ntop_zips = sorted(top_zips, key = lambda x: x[1], reverse = True)\nzips = [i[0] for i in top_zips]\n\nratio_zips = [(i, df['Zip Code'][(df['Zip Code'] == i) & (df['SR Status'] == 0)].count()/(df['Zip Code'][(df['Zip Code'] == i) & \\\n            (df['SR Status'] == 1)].count() + df['Zip Code'][(df['Zip Code'] == i) & (df['SR Status'] == 0)].count())) \\\n             for i in zips]\nratio_zips = sorted(ratio_zips, key = lambda x: x[1], reverse = True)[0:8]\nzips = [i[0] for i in ratio_zips]\nratios = [i[1] for i in ratio_zips]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot\nx = np.arange(len(ratio_zips))\nwidth = 0.35\n\nfig, ax = plt.subplots(figsize = (8,3))\nrects1 = ax.bar(x, ratios, width)\n\nax.set_ylabel('Incompletion Rate')\nax.set_title('Highest Incompletion Rate')\nax.set_xticks(x)\nax.set_xticklabels(zips)\n\nfig.tight_layout()\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"What's going on in 78737? They seem to have a ton of incomplete complaints! This could be something worth digging further into.","metadata":{}},{"cell_type":"markdown","source":"As a final part of my EDA, I wanted to look at the distribution of the time it takes to close a ticket.","metadata":{}},{"cell_type":"code","source":"_ = sns.distplot(df['time to close'], hist = False)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From this plot we can see there are some strong outliers that may influence us when we try to model the time to close. I filter out some outliers by removing rows that are more than three standard deviations outside of our mean time to close. Note that this reduces our total number of rows down to 836854. ","metadata":{}},{"cell_type":"code","source":"df = df[(np.abs(stats.zscore(df['time to close'])) < 3)]\ndf.shape","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_ = sns.distplot(df['time to close'], hist = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Making Predictions","metadata":{}},{"cell_type":"code","source":"X = df.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Encoding each of the categorical variables to make it easier to put into the algorithms. I keep the label encoders in a dictionary so that I can re-use them later if necessary.","metadata":{}},{"cell_type":"code","source":"le_dict = {}\nfor i in ['SR Description', 'Method Received', 'Street Name', 'City', 'Zip Code', 'County', 'Council District']:\n    le = LabelEncoder()\n    le.fit(X[i])\n    X[i] = le.transform(X[i])\n    le_dict[i] = le","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Removed Closed Date and time to close from classification problem. Removed Closed Date from regression problem. Including those columns would provide information to the model that it wouldn't have if it were to be used for making predictions in real time.","metadata":{}},{"cell_type":"code","source":"#remove the target variable from each problem\nX1 = X[['SR Description','Method Received', 'Street Name', 'City', 'Zip Code', 'County', 'Latitude Coordinate', 'Longitude Coordinate', 'Council District', 'Created Date']]\ny1 = X['SR Status']\n\nX2 = X[['SR Description', 'Method Received', 'SR Status', 'Street Name', 'City', 'Zip Code', 'County', 'Latitude Coordinate', 'Longitude Coordinate', 'Council District', 'Created Date']]\ny2 = X['time to close']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#splitting into a train and test set\nX1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.33)\nX2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.33)\n\ny1_train = y1_train.values.ravel()\ny1_test = y1_test.values.ravel()\ny2_train = y2_train.values.ravel()\ny2_test = y2_test.values.ravel()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X1_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.1 Classification","metadata":{}},{"cell_type":"markdown","source":"Using a Random Forest for a simple classification algorithm. We want to use a classification algorithm to see if we can predict if a call will be successfully resolved.","metadata":{}},{"cell_type":"code","source":"rfc = RandomForestClassifier(n_estimators = 10)\nrfc.fit(X1_train, y1_train)\ny1_pred = rfc.predict(X1_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(y1_test, rfc.predict(X1_test)))\nprint(roc_auc_score(y1_test, y1_pred), accuracy_score(y1_test, y1_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This isn't too bad of a prediction based on the confusion matrix, auc score, and accuracy score. But let's see if we can make some improvements using hyperparameter tuning.","metadata":{}},{"cell_type":"code","source":"n_estimators = [10, 20, 30]\n\nfor i in n_estimators:\n    rfc = RandomForestClassifier(n_estimators = i)\n    rfc.fit(X1_train, y1_train)\n    y1_pred = rfc.predict(X1_test)\n    print(roc_auc_score(y1_test, y1_pred))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Playing with n_estimators didn't seem to make a big difference, so let's keep it at the default.","metadata":{}},{"cell_type":"code","source":"max_depth = [None, 10, 100, 500]\n\nfor i in max_depth:\n    rfc = RandomForestClassifier(n_estimators = 10, max_depth = i)\n    rfc.fit(X1_train, y1_train)\n    y1_pred = rfc.predict(X1_test)\n    print(roc_auc_score(y1_test, y1_pred))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Playing with max_depth seems to say that having more max depth is (generally) best for our auc score. Let's keep it at None.","metadata":{}},{"cell_type":"markdown","source":"### 3.2 Regression","metadata":{}},{"cell_type":"markdown","source":"Using a Gradient Boosting Tree for a simple regression algorithm. We want to use a regression algorithm to see if we can predict the mean time to resolution for a case.","metadata":{}},{"cell_type":"code","source":"gbr = GradientBoostingRegressor()\ngbr.fit(X2_train, y2_train)\ny2_pred = gbr.predict(X2_test)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(mean_squared_error(y2_test, y2_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wow this looks like a huge error... Let's look at it a little closer","metadata":{}},{"cell_type":"code","source":"#plotting the predictions and the true values side by side. (When we plot on top it's hard to see them)\nplt.figure(figsize = (80, 5))\nplt.plot(y2_pred)\nplt.show()\nplt.figure(figsize = (80, 5))\n_ = plt.plot(y2_test, c = 'orange')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The look pretty similar, maybe looking at the differences will help show me why the error is so large.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (15, 5))\n_ = plt.plot(y2_test - y2_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The errors don't look crazy on this graph. They're centered near 0 and are fairly stable.","metadata":{}},{"cell_type":"markdown","source":"The original error was really not quite as bad as it looked originally, it only looked bad because I was looking at the mean SQUARED error and given the magnitudes of the errors, squaring them made it seem worse.","metadata":{}},{"cell_type":"markdown","source":"With additional hyperparameter tuning, or by trying different models, we may be able to lower the error further. But what we have here is a valid model that gives us reasonable predictions depending on what we are using them for. ","metadata":{}}]}