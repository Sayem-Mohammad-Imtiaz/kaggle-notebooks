{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Twitter sentiment analysis of airlines:\n![sentiment analysis: credits: kdnuggets](https://www.kdnuggets.com/wp-content/uploads/sentiment-hero-480.jpg)<br/>\nSentiment analysis is a term that refers to the use of natural language processing, text analysis, and computational linguistics in order to ascertain the attitude of a speaker or writer toward a specific topic.<br/>\n<br/>\nBasically, it helps to determine whether a text is expressing sentiments that are positive, negative, or neutral. Sentiment analysis is an excellent way to discover how people, particularly consumers, feel about a particular topic, product, or idea.<br/>\n<br/>\nThe origin of sentiment analysis can be traced to the 1950s, when sentiment analysis was primarily used on written paper documents. Today, however, sentiment analysis is widely used to mine subjective information from content on the Internet, including texts, tweets, blogs, social media, news articles, reviews, and comments. This is done using a variety of different techniques, including NLP, statistics, and machine learning methods. Organizations then use the information mined to identify new opportunities and better target their message toward their target demographics. The Obama Administration used sentiment analysis to predict public response to its policy announcements.<br/>  \n## How many types of sentiment analysis are there?\nAccording to [upgrad](https://www.upgrad.com/blog/types-of-sentiment-analysis/), there are 4 types of sentiment analyses. <br/>\n### (1) Fine grained sentiment analysis:\nThis analysis gives you an understanding of the feedback you get from customers. You can get precise results in terms of the polarity of the input. However, the process to understand this can be more labor and cost-intensive as compared to other types. <br/>\n### (2) Emotion Detection Sentiment Analysis\n\nThis is a more sophisticated way of identifying the emotion in a piece of text. Lexicons and machine learning are used to determine the sentiment. Lexicons are lists of words that are either positive or negative. This makes it easier to segregate the terms according to their sentiment. The advantage of using this is that a company can also understand why a customer feels a particular way. This is more algorithm-based and might be complex to understand at first.<br/>\n\n### (3) Aspect-based analysis\n\nThis type of sentiment analysis is usually for one aspect of a service or product. For example, if a company that sells televisions uses this type of sentiment analysis, it could be for one aspect of televisions â€“ like brightness, sound, etc. So they can understand how customers feel about specific attributes of the product. <br/>\n\n### (4) Intent analysis\n\nThis is a deeper understanding of the intention of the customer. For example, a company can predict if a customer intends to use the product or not. This means that the intention of a particular customer can be tracked, forming a pattern, and then used for marketing and advertising. <br/>\n<br/>\nIn this notebook, we are going to explore different sentiment analysis procedures but we will not train any new one. For training a sentiment analysis procedure from scratch, follow this [notebook](https://www.kaggle.com/shyambhu/sentiment-classification-using-lstm).<br/>\n### Here are the contents of this notebook:\n(1) [Data analysis and cleaning for airline data](#dataclean)<br/>\n(2) [sentiment analysis using NLTK](#nltk)<br/>\n(3) [sentiment analysis using textblob](#blob)<br/>\n(4) [sentiment analysis using huggingface](#huggingface)<br/>\n(5) [sentiment analysis using flair](#flair)<br/>\n(6) [conclusion](#conclude)<br/>\n### Resources:\n(1) [upgrad introduction to sentiment analysis](https://www.upgrad.com/blog/types-of-sentiment-analysis/)<br/>\n(2) [lexalytics sentiment analysis introduction](https://www.lexalytics.com/technology/sentiment-analysis)<br/>\n(3) [Contractions, a useful python library](https://github.com/kootenpv/contractions)<br/>\n(4) [Different sentiment analysis libraries in python](https://www.iflexion.com/blog/sentiment-analysis-python)<br/>\n(5) [sentiment analysis using NLTK](https://realpython.com/python-nltk-sentiment-analysis/)<br/>\n(6) [monkeylearn api; not implemented here](https://app.monkeylearn.com/main/classifiers/cl_pi3C7JiL/tab/api/)<br/>\n(7) [sentiment analysis using textblob](https://www.presentslide.in/2019/08/sentiment-analysis-textblob-library.html)<br/>\n(8) [Using pretrained models for sentiment analysis](https://medium.com/@b.terryjack/nlp-pre-trained-sentiment-analysis-1eb52a9d742c)<br/>\n(9) [text classification using sentiment analysis](https://towardsdatascience.com/text-classification-with-state-of-the-art-nlp-library-flair-b541d7add21f)\n### Acknowledgements:\nI would like to thank [vetrivel-ps](https://www.kaggle.com/vetrirah) and [Atif hassan](https://www.kaggle.com/atifhassan) for helping me with some of the resources and ideas for improvements.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweet_data = pd.read_csv('/kaggle/input/twitter-airline-sentiment/Tweets.csv')\nprint(\"data shape:\",tweet_data.shape)\nprint(\"what are columns:\",tweet_data.columns)\ntweet_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <a id = dataclean> Data Cleaning</a>\nNow, our goal in this work is to detect sentiment from the tweet text. So we will drop all the unnecessary columns from the data as well as clean it a bit.","metadata":{}},{"cell_type":"code","source":"tweet_data = tweet_data.drop(['tweet_id','retweet_count', 'tweet_coord', 'tweet_created',\n                               'tweet_location','name','user_timezone'],axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweet_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweet_data['negativereason_gold'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweet_data['negativereason'] = tweet_data['negativereason'].fillna('')\ntweet_data['negativereason_confidence'] = tweet_data['negativereason_confidence'].fillna(0)\ntweet_data['airline_sentiment_gold'] = tweet_data['airline_sentiment_gold'].fillna('')\ntweet_data['negativereason_gold'] = tweet_data['negativereason_gold'].fillna('')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweet_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"different topics of negative reasons are:\",tweet_data['negativereason'].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install contractions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.corpus import stopwords\nimport string\nimport re\nimport contractions\ndef text_cleaning(text):\n    #not removing the stopwords so that the sentences stay normal.\n    #forbidden_words = set(stopwords.words('english'))\n    if text:\n        text = contractions.fix(text)\n        text = ' '.join(text.split('.'))\n        text = re.sub(r'\\s+', ' ', re.sub('[^A-Za-z0-9]', ' ', text.strip().lower())).strip()\n        text = re.sub(r'\\W+', ' ', text.strip().lower()).strip()\n        text = [word for word in text.split()]\n        return text\n    return []","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweet_data['text'] = tweet_data['text'].apply(lambda x: ' '.join(text_cleaning(x)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweet_data.head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <a id = nltk> Sentiment Analysis with NLTK</a>:\nIn this section we will perform sentiment analysis using nltk.","metadata":{}},{"cell_type":"code","source":"import nltk","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nltk.download([\"names\",\"stopwords\",\"state_union\",\"twitter_samples\",\n              \"movie_reviews\",\"averaged_perceptron_tagger\",\"vader_lexicon\",\n              \"punkt\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Description of the nltk packages downloaded:\n*     names: A list of common English names compiled by Mark Kantrowitz\n*     stopwords: A list of really common words, like articles, pronouns, prepositions, and conjunctions\n*     state_union: A sample of transcribed State of the Union addresses by different US presidents, compiled by Kathleen Ahrens\n*     twitter_samples: A list of social media phrases posted to Twitter\n*     movie_reviews: Two thousand movie reviews categorized by Bo Pang and Lillian Lee\n*     averaged_perceptron_tagger: A data model that NLTK uses to categorize words into their part of speech\n*     vader_lexicon: A scored list of words and jargon that NLTK references when performing sentiment analysis, created by C.J. Hutto and Eric Gilbert\n*     punkt: A data model created by Jan Strunk that NLTK uses to split full texts into word lists\n","metadata":{}},{"cell_type":"markdown","source":"## How to calculate sentiment from nltk:\nNLTK already has a built-in, pretrained sentiment analyzer called VADER (Valence Aware Dictionary and sEntiment Reasoner).\n\nSince VADER is pretrained, you can get results more quickly than with many other analyzers. However, VADER is best suited for language used in social media, like short sentences with some slang and abbreviations. Itâ€™s less accurate when rating longer, structured sentences, but itâ€™s often a good launching point.\n\nTo use VADER, first create an instance of nltk.sentiment.SentimentIntensityAnalyzer, then use .polarity_scores() on a raw string:","metadata":{}},{"cell_type":"code","source":"from nltk.sentiment import SentimentIntensityAnalyzer as SIA\nsia = SIA()\nprint(sia.polarity_scores('wow! this nltk library really works'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see, we get back a dictionary of different scores. The negative, neutral, and positive scores are related: They all add up to 1 and canâ€™t be negative. The compound score is calculated differently. Itâ€™s not just an average, and it can range from -1 to 1.<br/>\n### Question1: comment if you know:\nhow is the compound score calculated as it is clearly not a average?","metadata":{}},{"cell_type":"markdown","source":"Let's append this sentiment scores to our original dataset. ","metadata":{}},{"cell_type":"code","source":"texts = tweet_data['text'].tolist()\nnegative_scores = []\nneutral_scores = []\npositive_scores = []\ncompound_scores = []\nfinal_tag = []\nfor text in texts:\n    score_dictionary = sia.polarity_scores(text)\n    negative_scores.append(score_dictionary['neg'])\n    positive_scores.append(score_dictionary['pos'])\n    neutral_scores.append(score_dictionary['neu'])\n    compound_scores.append(score_dictionary['compound'])\n    if score_dictionary['compound']>0:\n        final_tag.append('positive')\n    elif score_dictionary['compound']<0:\n        final_tag.append('negative')\n    else:\n        final_tag.append('neutral')\ntweet_data['negative_score'] = negative_scores\ntweet_data['positive_score'] = positive_scores\ntweet_data['neutral_score'] = neutral_scores\ntweet_data['compound_score'] = compound_scores\ntweet_data['final_tag'] = final_tag","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweet_data.head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's check why some sentences are failing.","metadata":{}},{"cell_type":"code","source":"texts[17]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"probably this fails as the negativity is in the sense; but not on any word basis. Let's now try textblob. Let's see if that works.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report as crep\nprint(\"sentiment analysis performance for nltk:\")\nprint(crep(tweet_data['airline_sentiment'],tweet_data['final_tag']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <a id = 'blob'>Sentiment analysis with Textblob</a>:\n","metadata":{}},{"cell_type":"code","source":"!pip install -U textblob\n!python -m textblob.download_corpora","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from textblob import TextBlob","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tb1 = TextBlob('I just am trying textblob first time.')\ntb1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So clearly, textblob also follows the normal pipeline format, where we make a textblob object out of the text and then we will be working with this object further for the different processing.","metadata":{}},{"cell_type":"markdown","source":"Before doing sentiment analysis, let's explore a few attributes.","metadata":{}},{"cell_type":"markdown","source":"### tokenization and sentence segmentation:","metadata":{}},{"cell_type":"code","source":"tb1.words","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tb1.sentences","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tb1.noun_phrases","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### pos tagging:","metadata":{}},{"cell_type":"code","source":"tb2=TextBlob(\"Tags will give the Part of speech for all the words.\")\ntb2.tags","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tb3=TextBlob(\" We are learning cool Library . We are enjoying a lot .\")\ntb3.noun_phrases","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(tb3.noun_phrases)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Polarity:\n\nPolarity as discussed earlier helps us in finding the expression and emotion of the author in the text. The value ranges from -1.0 to +1.0 and they contain float values.<br/>\n\nLess than 0 denotes Negative<br/>\nEqual to 0 denotes Neutral<br/>\nGreater than 0 denotes Positive<br/>\n<br/>\nA value near to +1 is more likely to be positive than a value near 0. The same is in the case of negativity.<br/>","metadata":{}},{"cell_type":"code","source":"doc2=TextBlob(\"We are having fun here\")\ndoc2.polarity","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"texts = tweet_data['text'].tolist()\ntextblob_score = []\ntextblob_tag = []\nfor text in texts:\n    doc_current = TextBlob(text)\n    score = doc_current.polarity\n    textblob_score.append(score)\n    if score > 0:\n        textblob_tag.append('positive')\n    elif score<0:\n        textblob_tag.append('negative')\n    else:\n        textblob_tag.append('neutral')\ntweet_data['textblob_score'] = textblob_score\ntweet_data['textblob_sentiment_tag'] = textblob_tag","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweet_data[['airline_sentiment','text','textblob_score','textblob_sentiment_tag']].head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So textblob is also fine and matches most of the airline tags, but doesn't match in a few cases. Interestingly, the case 17th, where it was a sense wise negative sentence, is again missed by textblob as well. Let's check the textblob's accuracy.","metadata":{}},{"cell_type":"code","source":"print(\"sentiment analysis with textblob:\")\nprint(crep(tweet_data['airline_sentiment'],tweet_data['textblob_sentiment_tag']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <a id= 'huggingface'>Huggingface Transformer based sentiment analysis</a>\nIn this section we will do sentiment analysis using pretrained huggingface transformer models. We will also measure their performances and comment on it.<br/>\n(1) [different sentiment models in huggingface](https://huggingface.co/models?search=sentim)<br/>\n(2) [huggingface quicktour](https://huggingface.co/transformers/quicktour.html)<br/>\n(3) [possible bug to look for](https://github.com/huggingface/transformers/issues/4263)<br/>\n","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\nclassifier = pipeline('sentiment-analysis')\nclassifier(\"I am so happy to use huggingface today!\")[0]['label']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier(\"it was a extremely bad movie!\")[0]['label']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier(\"it is a statement\")[0]['label']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweet_data['bert_based_sentiment'] = tweet_data['text'].apply(lambda x: classifier(x)[0]['label'].lower())\ntweet_data_cut = tweet_data[tweet_data['airline_sentiment']!='neutral']\nprint(crep(tweet_data_cut['airline_sentiment'],tweet_data_cut['bert_based_sentiment']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier_febu = pipeline('sentiment-analysis',model = 'facebook/bart-large')\nclassifier_febu(\"I hate it!\")\nclassifier_febu(\"I love you!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sentiment_analysis(text):\n    sentiment = classifier_febu(text)[0]['label']\n    if sentiment == 'LABEL_0': return 'positive'\n    return 'negative'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweet_data['facebook_bert_based_sentiment'] = tweet_data['text'].apply(sentiment_analysis)\ntweet_data_cut = tweet_data[tweet_data['airline_sentiment']!='neutral']\nprint(crep(tweet_data_cut['airline_sentiment'],tweet_data_cut['facebook_bert_based_sentiment']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier_third = pipeline('sentiment-analysis',model = 'cardiffnlp/twitter-roberta-base-sentiment')\nprint(classifier_third(\"I hate it!\"))\nprint(classifier_third(\"I love you!\"))\nprint(classifier_third(\"I don't know about the routine\"))\ndef sentiment_analysis_third(text):\n    sentiment = classifier_third(text)[0]['label']\n    if sentiment == 'LABEL_0': return 'negative'\n    elif sentiment == 'LABEL_1': return 'neutral'\n    elif sentiment == 'LABEL_2': return 'positive'\n    return 'neutral'\ntweet_data['facebook_bert_based_sentiment'] = tweet_data['text'].apply(sentiment_analysis_third)\nprint(crep(tweet_data['airline_sentiment'],tweet_data['facebook_bert_based_sentiment']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Flair:\n[Flair NLP](https://github.com/flairNLP/flair) is a very simple NLP framework and contains a number of pretrained models. We will use the library for sentiment analysis in this section.","metadata":{}},{"cell_type":"code","source":"!pip install flair","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from flair.models import TextClassifier\nfrom flair.data import Sentence\nclassifier = TextClassifier.load('en-sentiment')\nsentence = Sentence('Flair is pretty neat!')\nclassifier.predict(sentence)\n# print sentence with predicted labels\nprint('Sentence above is: ', sentence.labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(str(sentence.labels[0]).split(\"(\")[0].lower()[:-1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sentiment_analysis_flair(text):\n    sentence = Sentence(text)\n    classifier.predict(sentence)\n    return str(sentence.labels[0]).split(\"(\")[0].lower()[:-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweet_data['flair_based_sentiment'] = tweet_data['text'].apply(sentiment_analysis_flair)\ntweet_data_cut = tweet_data[tweet_data['airline_sentiment']!='neutral']\nprint(crep(tweet_data_cut['airline_sentiment'],tweet_data_cut['flair_based_sentiment']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <a id = conclude>Conclusion</a>:\nIn this notebook, we preprocessed a airline tweet data set and then used both nltk ( VADER based pretrained system) and textblob to detect, and generate the scores for sentiments for the tweets. We did a bit of superficial observation of the performance of both the systems as well. In both cases, we saw that very implicitly meant negative cases are missed by the models; and hints at the importance of custom sentiment model training.<br/>\nWe also tried out a number of pretrained models from huggingface for sentiment analysis and the vanilla models didn't function well, while models specifically trained for sentiment performed much better.<br/>\n### percentage-wise model comparison:\nThe NLTK, textblob performed at 50% around accuracy, and while facebook's bart model seemed to be unfit for the downstream task of sentiment analysis, other two models such as the default huggingface model for sentiment analysis performed at 89% accuracy for positive/negative sentiment classification and the cardiffnlp's twitter data based roberta model performed at 70% accuracy for the 3 class classification.<br/>\nWith this, our sentiment analysis concludes. We may add further frameworks in later versions of this work.<br/>\nIn the comments, please let us know what specific insights could have been made, or what other frameworks we should definitely try in this case. Thanks for reading the notebook. It will be great to see your appreciation if you liked my work.","metadata":{}}]}