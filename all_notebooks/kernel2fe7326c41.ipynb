{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Used Package"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport re\nimport nltk \nfrom nltk.corpus import stopwords\nfrom  nltk.stem.porter import PorterStemmer\nnltk.download('stopwords')\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM, SpatialDropout1D,Dropout\nfrom keras.utils.np_utils import to_categorical\nfrom keras import regularizers\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report,multilabel_confusion_matrix\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Read Data\n"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"Tweets= pd.read_csv(\"/kaggle/input/twitter-airline-sentiment/Tweets.csv\")\nTweets.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualize count of each class"},{"metadata":{"trusted":true},"cell_type":"code","source":"classes_count=Tweets['airline_sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=[1,2,3]\nplt.bar(x,classes_count)\nplt.xticks(x,['negative','neutral','positive'])\nplt.xlabel('Classes')\nplt.ylabel('Number of Sentence')\nplt.title('Sentences in each class')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visulize lenght of text"},{"metadata":{"trusted":true},"cell_type":"code","source":"Tweets['tw_len'] = Tweets['text'].apply(len)\nTweets.groupby(['tw_len', 'airline_sentiment']).size().unstack().plot(kind='line', stacked=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(max(Tweets['tw_len']))\nprint(min(Tweets['tw_len']))\nprint(np.mean(Tweets['tw_len']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Select Features(Text) and Label (airline_sentiment)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"Tweets=Tweets[['text','airline_sentiment']]\nTweets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Tweets['text'][1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Clean and Preprocessing Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus=[]\nfor i in range(14640):\n    review=re.sub('[^a-zA-z]',' ',Tweets['text'][i])\n    review=review.lower()\n    review=review.split()\n    \n    # remove stopwords\n    review=[word for word in review if not word in set(stopwords.words('english'))]\n    \n    \n    \n    #to taken the route of the word\n    ps=PorterStemmer()\n    review=[ps.stem(word) for word in  review]\n    review=' ' .join(review)\n    corpus.append(review)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create bag of words"},{"metadata":{"trusted":true},"cell_type":"code","source":"cv=CountVectorizer(analyzer = 'word',max_features=8000)\nX=cv.fit_transform(corpus).toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Label Encoded \n  "},{"metadata":{"trusted":true},"cell_type":"code","source":"y= Tweets['airline_sentiment']\nlabelencoder=LabelEncoder()\ny=labelencoder.fit_transform(y)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range (4):\n    print('class :',Tweets['airline_sentiment'][i] ,'--> label is :',y[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Machine learning model\n"},{"metadata":{},"cell_type":"markdown","source":"Split data to train and test"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclasifier=RandomForestClassifier(n_estimators=20,criterion='entropy')\nclasifier.fit(X_train,y_train)\n\n\n\n##evaluate model \ny_pred=clasifier.predict(X_test)\n\nprint(clasifier.score(X_train,y_train))\n\nprint(clasifier.score(X_test,y_test))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" with random forest classifier the model is suffer from overfitting problem ,I tried to decrease number of feature to reduce the over fitting but it didn't work ,and I tried with different number of estimator(trees ),but also didn't work"},{"metadata":{},"cell_type":"markdown","source":"* I tried Using DecisionTree but also it suffered from overfitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"clasifier= DecisionTreeClassifier()\nclasifier.fit(X_train,y_train)\n\n\n#evaluate model \ny_pred=clasifier.predict(X_test)\n\nprint(clasifier.score(X_train,y_train))\nprint(clasifier.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I has been used Regularization technique (Grid search ) to  avoid overfitting and worked well and  has been avoided overfitting "},{"metadata":{"trusted":true},"cell_type":"code","source":"\nrandom_classifier=RandomForestClassifier()\n\nparameters = { 'max_features':np.arange(5,10),'n_estimators':[400],'min_samples_leaf': [10,30,50,100,200,500]}\n\nrandom_grid = GridSearchCV(random_classifier, parameters, cv = 5)\nrandom_grid.fit(X_train,y_train)\n\n\n\n##evaluate model \ny_pred=random_grid.predict(X_test)\n\nprint(random_grid.score(X_train,y_train))\n\nprint(random_grid.score(X_test,y_test))\nRF_ACC=random_grid.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Evaluate Machine learning Model(Statistical Tests)"},{"metadata":{"trusted":true},"cell_type":"code","source":"acc=random_grid.score(X_test,y_test)\nprecision=metrics.precision_score(y_test, y_pred, average='macro') \nrecall=metrics.recall_score(y_test, y_pred, average='micro')\nf1_score=metrics.f1_score(y_test, y_pred, average='weighted')  \ncm=multilabel_confusion_matrix(y_test, y_pred,labels=[0, 1,2])\nprint ('confusion matrix ',cm)\nprint('Accuracy : ',acc)\nprint('Precision : ',precision)\nprint('Recall : ',recall)\nprint('F1_score : ',f1_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"   # Deep learning model "},{"metadata":{},"cell_type":"markdown","source":"I used Onehotencoded to work well with deep learning nodel"},{"metadata":{"trusted":true},"cell_type":"code","source":"y=to_categorical(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range (4):\n    print('class :',Tweets['airline_sentiment'][i] ,'--> label is :',y[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split Data to train ,Validation,Test (using validation set to  tune parameter and known if overfitting happened"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.15)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape,y_train.shape)\nprint(X_test.shape,y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_size = 2196\n\nX_validate = X_train[-validation_size:]\ny_validate = y_train[-validation_size:]\nX_train = X_train[:-validation_size]\ny_train = y_train[:-validation_size]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape,y_train.shape)\nprint(X_validate.shape,y_validate.shape)\nprint(X_test.shape,y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* I has used ANN but also suffer from over fitting so t used regularization and Dropout to overfitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_model = Sequential()\nreg_model.add(Dense(64, kernel_regularizer=regularizers.l2(0.03), activation='relu', input_dim=X.shape[1]))\nreg_model.add(Dropout(0.5))\nreg_model.add(Dense(64, kernel_regularizer=regularizers.l2(0.02), activation='relu'))\nreg_model.add(Dropout(0.5))\nreg_model.add(Dense(3, activation='softmax'))\nreg_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_model.compile(optimizer='Adam'\n                  , loss='categorical_crossentropy'\n                  , metrics=['accuracy'])\n    \nhistory = reg_model.fit(X_train\n                       , y_train\n                       , epochs=20\n                       , batch_size=64\n                       , validation_data=(X_validate, y_validate)\n                       , verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. evaluate Deep learning model(Statistical Tests)"},{"metadata":{"trusted":true},"cell_type":"code","source":"score=reg_model.evaluate(X_test,y_test,verbose=0)\nprint('Accuracy : ' ,score[1])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.legend(['train','validation'])\nplt.title('accuracy')\nplt.xlabel('epochs')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['training','test'])\nplt.title('Loss')\nplt.xlabel('epochs')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comparison Between Machine learning model and Deep learning progress "},{"metadata":{"trusted":true},"cell_type":"code","source":"Models=['Machine Leaning Model ','Deep Learning Model ']\naccu=[RF_ACC,score[1]]\n     \nx = [1,2]\nplt.bar(x,accu)\nplt.xticks(x, Models,rotation=45)\nplt.ylabel('Accuracy')\nplt.xlabel('Models')\nplt.title('Accuracies of Models')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}