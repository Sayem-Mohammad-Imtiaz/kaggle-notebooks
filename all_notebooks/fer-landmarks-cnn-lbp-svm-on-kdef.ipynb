{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7495bef6cc10035b66e3af683b81ad5738d3f13e"},"cell_type":"code","source":"import tensorflow as tf\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom keras.layers import Dense, Activation, Dropout, Flatten\n\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ntrain_lan=np.load('../input/kdef-landmarks-lbp/landmarks.npy')\nprint(train_lan.shape)\nvalid_lan=np.load('../input/jaffe-landmarks-lbp/landmarks.npy')\n\nprint(os.listdir(\"../input/modified-kdef-facial-expression-dataset\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96de23a9cb130caee4597f33fc16a1235c8d63ba"},"cell_type":"code","source":"# get the data\n# filname = '../input/facial-expression/fer2013/fer2013.csv'\nfilname = '../input/modified-kdef-facial-expression-dataset/kdef_pixels.csv'\nlabel_map = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\nnames=['emotion','pixels','usage']\n# df=pd.read_csv('../input/facial-expression/fer2013/fer2013.csv',names=names, na_filter=False)\ndf=pd.read_csv('../input/modified-kdef-facial-expression-dataset/kdef_pixels.csv',names=names, na_filter=False)\nim=df['pixels']\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a98de52ae868487f81fa3b048569ea87898dacd"},"cell_type":"code","source":"\n# Read and process train dataset\n\ndf = pd.read_csv('../input/modified-kdef-facial-expression-dataset/kdef_pixels.csv')\ndf.head()\n\ndf[\"Usage\"].value_counts()\n\ntrain = df[[\"emotion\", \"pixels\"]][df[\"Usage\"] == \"Training\"]\ntrain.isnull().sum()\n\n\ntrain['pixels'] = train['pixels'].apply(lambda im: np.fromstring(im, sep=' '))\nx_train = np.vstack(train['pixels'].values)\ny_train = np.array(train[\"emotion\"])\nprint(x_train.shape, y_train.shape)\n\nx_train = np.array(x_train) / 255.0\nprint(x_train.shape, y_train.shape)\n\nN = len(x_train)\nX_train = x_train.reshape(N, 256, 256, 1)\nprint(X_train.shape, y_train.shape)\n\nnum_class = len(set(y_train))\nprint(num_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"694b3456620ea42ca5f367fe3c6025f0e835f8d2"},"cell_type":"code","source":"\n\n# Read and process valid dataset\n\ndf = pd.read_csv('../input/modified-jaffe-facial-expression-dataset/jaffe_pixels.csv')\ndf.head()\n\ndf[\"Usage\"].value_counts()\n\npublic_test_df = df[[\"emotion\", \"pixels\"]][df[\"Usage\"] == \"Training\"]\npublic_test_df.isnull().sum()\n\npublic_test_df[\"pixels\"] = public_test_df[\"pixels\"].apply(lambda im: np.fromstring(im, sep=' '))\nx_valid = np.vstack(public_test_df[\"pixels\"].values)\ny_valid = np.array(public_test_df[\"emotion\"])\n\nx_valid = np.array(x_valid) / 255.0\nprint(x_valid.shape, y_valid.shape)\n\nN = len(x_valid)\nX_valid = x_valid.reshape(N, 256, 256, 1)\nprint(X_valid.shape, y_valid.shape)\n\nnum_class = len(set(y_valid))\nprint(num_class)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15dc232a1b56fa24611ebf8ff6a96c6f8ab7c3d0"},"cell_type":"code","source":"\n\n# Read and process test dataset\n\ndf = pd.read_csv('../input/modified-ck-facial-expression-dataset/ck_pixels.csv')\ndf.head()\n\ndf[\"Usage\"].value_counts()\n\nprivate_test_df = df[[\"emotion\", \"pixels\"]][df[\"Usage\"] == \"Training\"]\nprivate_test_df.isnull().sum()\n\n\nprivate_test_df[\"pixels\"] = private_test_df[\"pixels\"].apply(lambda im: np.fromstring(im, sep=' '))\nx_test = np.vstack(private_test_df[\"pixels\"].values)\ny_test = np.array(private_test_df[\"emotion\"])\n# print(x_test)\n\nx_test = np.array(x_test) / 255.0\n# print(x_test)\nprint(x_test.shape, y_test.shape)\n\nN = len(x_test)\nX_test = x_test.reshape(N, 256, 256, 1)\n# print(X_test)\nprint(X_test.shape, y_test.shape)\n\nnum_class = len(set(y_test))\nprint(num_class)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd00ed1659567c18bcac8757b6abebc57762f7b8"},"cell_type":"code","source":"\n\n# X_train, X_valid, X_test is used for training CNN\n\n# For applying to LBP+SVM\n\nx_train = x_train.reshape(-1, 256, 256, 1)\nx_valid = x_valid.reshape(-1, 256, 256, 1)\nx_test = x_test.reshape(-1, 256, 256, 1)\n\nprint(x_train.shape, x_valid.shape, x_test.shape)\nprint(y_train.shape, y_valid.shape, y_test.shape)\nprint(y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3c3a306c981b2dd5bd10855d5dfd44bac9782ef"},"cell_type":"code","source":"\n# from sklearn.model_selection import train_test_split\n# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=0)\n\n# Process y for CNN (get capital Y)\n\nY_train = (np.arange(num_class) == y_train[:, None]).astype(np.float32)\nY_valid = (np.arange(num_class) == y_valid[:, None]).astype(np.float32)\nY_test = (np.arange(num_class) == y_test[:, None]).astype(np.float32)\nprint(Y_train.shape, Y_valid.shape, Y_test.shape)\nprint(Y_test)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"517d0207ba370ec69239ae33a0e65e1aa3d70fb3"},"cell_type":"code","source":"\nprint(os.listdir(\"../input\"))\nprint(os.listdir(\"../input/kdef-landmarks-lbp\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b11b82c85e653c93bf5acd5672c799721b53eae7"},"cell_type":"code","source":"\n\n# Get landmarks and lbp data\n\nimport numpy as np\n\ntrain_lan=np.load('../input/kdef-landmarks-lbp/landmarks.npy')\nvalid_lan=np.load('../input/jaffe-landmarks-lbp/landmarks.npy')\ntest_lan=np.load('../input/ck-landmarks-lbp/landmarks.npy')\n\ntrain_lbp=np.load('../input/kdef-landmarks-lbp/lbp_features.npy')\nvalid_lbp=np.load('../input/jaffe-landmarks-lbp/lbp_features.npy')\ntest_lbp=np.load('../input/ck-landmarks-lbp/lbp_features.npy')\n\nprint(train_lan.shape)\nprint(train_lbp.shape)\n\ntrain_lan = np.array([x.flatten() for x in train_lan])\nvalid_lan = np.array([x.flatten() for x in valid_lan])\ntest_lan = np.array([x.flatten() for x in test_lan])\nprint(train_lan.shape)\n\n\nlbp_train = np.concatenate((train_lan, train_lbp), axis=1)\nlbp_valid = np.concatenate((valid_lan, valid_lbp), axis=1)\nlbp_test = np.concatenate((test_lan, test_lbp), axis=1)\nprint(lbp_train.shape)\nprint(lbp_valid.shape)\nprint(lbp_test.shape)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75324952b870b181a9c2b9a914d29397874d31c6"},"cell_type":"code","source":"\n\nprint('LAN+LBP+SVM is going to applicable. resolution doesn\\'t')\ndef evaluate(model, X, Y):\n    predicted_Y = model.predict(X)\n    accuracy = accuracy_score(Y, predicted_Y)\n    return accuracy\n\n\ndef matrix(svm_model):\n\n#     validation_accuracy = evaluate(svm_model, lbp_test, y_test)\n#     print(\"  - validation accuracy = {0:.1f}\".format(validation_accuracy*100))\n\n#     valid_labels = svm_model.predict(lbp_test)\n#     print(classification_report(y_test, valid_labels))\n#     mat = confusion_matrix(y_test, valid_labels)\n#     print(mat)\n    \n    \n    validation_accuracy = evaluate(svm_model, lbp_valid, y_valid)\n    print(\"  - validation accuracy = {0:.1f}\".format(validation_accuracy*100))\n    valid_labels = svm_model.predict(lbp_valid)\n    print(classification_report(y_valid, valid_labels))\n    mat = confusion_matrix(y_valid, valid_labels)\n    print(mat)\n\n    \n    test_accuracy = evaluate(svm_model, lbp_test, y_test)\n    print(\"  - test accuracy = {0:.1f}\".format(test_accuracy*100))\n    test_labels = svm_model.predict(lbp_test)\n    print(classification_report(y_test, test_labels))\n    mat = confusion_matrix(y_test, test_labels)\n    print(mat)\n    \n#     test_accuracy = evaluate(svm_model, lbp_valid, y_test)\n#     print(\"  - test accuracy = {0:.1f}\".format(test_accuracy*100))\n#     test_labels = svm_model.predict(lbp_valid)\n    \n#     print(classification_report(y_valid, valid_labels))\n#     print(mat)\n\n\n\n#     test_accuracy = evaluate(svm_model, lbp_test, y_test)\n#     print(\"  - test accuracy = {0:.1f}\".format(test_accuracy*100))\n\n#     test_labels = svm_model.predict(lbp_test)\n#     print(classification_report(y_test, test_labels))\n#     mat = confusion_matrix(y_test, test_labels)\n#     print(mat)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb9603a4ffce0702596e1ee571fb1bd7c7866e16"},"cell_type":"code","source":"\n\nimport time\nfrom sklearn.svm import LinearSVC, SVC, NuSVC\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"719ce7ff734f69bdda7791f60a146b5dc1a4b6da"},"cell_type":"code","source":"\n# Application of SVM model 1\n\nstart_time = time.time()\nsvm_model_1 = LinearSVC(C=100.0)\nsvm_model_1.fit(lbp_train, y_train)\nprint('fitting done !!!')\n\nmatrix(svm_model_1)\ntraining_time = time.time() - start_time\nprint(\"training time = {0:.1f} sec\".format(training_time))\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"22cb0aa7986223bd2fb86414e3de32aa6fe2bbc9"},"cell_type":"code","source":"\n# Application of SVM model 2\n\nrandom_state = 0\nepochs = 10000\nkernel = 'rbf'  # 'rbf', 'linear', 'poly' or 'sigmoid'\ndecision_function = 'ovr'  # 'ovo' for OneVsOne and 'ovr' for OneVsRest'\n\nstart_time = time.time()    \nsvm_model_2 = SVC(random_state=random_state, max_iter=epochs, kernel=kernel, decision_function_shape=decision_function)\nsvm_model_2.fit(lbp_train, y_train)\nprint('fitting done !!!')\n\nmatrix(svm_model_2)\ntraining_time = time.time() - start_time\nprint(\"training time = {0:.1f} sec\".format(training_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da53f08b715a444e90c2594d54c1e72e353f8edd"},"cell_type":"code","source":"# Landmark+LBP+SVM is done\n\n# Landmark+CNN+SVM is starting","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e92f3b17feb85a3c2b5ce08de16cc7b5e213561e"},"cell_type":"code","source":"\nimport tensorflow as tf\nimport keras\nimport time\n\nfrom keras.optimizers import *\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.metrics import categorical_accuracy\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import Sequential, model_from_json, load_model, Model\n\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom keras.layers import Dense, Activation, Dropout, Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"876f0a0bef4f55e3f6c6c909b11f28955c33bacc"},"cell_type":"code","source":"\n# CNN model declaration\n\ndef my_model(w,h):\n    model = Sequential()\n    input_shape = (w,h,1)\n    model.add(Conv2D(64, (5, 5), input_shape=input_shape,activation='relu', padding='same'))\n    model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    ############\n#     model.add(Flatten())\n#     model.add(Dense(256, name=\"dense_one\"))\n#     model.add(BatchNormalization())\n#     model.add(Activation('relu'))\n#     model.add(Dropout(0.2))\n    ###########\n    \n    model.add(Flatten())\n    model.add(Dense(128, name=\"dense_one\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(0.2))\n    \n    model.add(Dense(7))\n    model.add(Activation('softmax'))\n    \n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n    # UNCOMMENT THIS TO VIEW THE ARCHITECTURE\n    #model.summary()\n    \n    return model\nmodel=my_model(256,256)\nmodel.summary()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9474cfc6b2344f764c17ed41bad5c4e7160f8cdd"},"cell_type":"code","source":"# Training CNN\n\nstart_time = time.time()  \n\npath_model='model_filter_2.h5' # save model at this location after each epoch\nK.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\nmodel=my_model(256,256) # create the model\nK.set_value(model.optimizer.lr,1e-3) # set the learning rate\n# fit the model\nh=model.fit(x=X_train,     \n            y=Y_train, \n            batch_size=64, \n            epochs=20, \n            verbose=1, \n            validation_data=(X_valid,Y_valid),\n            shuffle=True,\n            callbacks=[\n                ModelCheckpoint(filepath=path_model),\n            ]\n            )\n\ntraining_time = time.time() - start_time\nprint(\"training time = {0:.1f} sec\".format(training_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01ba9969c51898e536f941d3aaa5c772e96567cf"},"cell_type":"code","source":"# Find earlier layer value of CNN anduse as feature extractor\n\nmodel_feat = Model(inputs=model.input,outputs=model.get_layer('dense_one').output)\n\nprint(model.input, model.get_layer('dense_one').output)\n\nfeat_train = model_feat.predict(X_train)\nprint(feat_train.shape)\nfeat_train = np.concatenate((train_lan, feat_train), axis=1)\nprint(feat_train.shape)\n\nfeat_valid = model_feat.predict(X_valid)\nfeat_valid = np.concatenate((valid_lan, feat_valid), axis=1)\nprint(feat_valid.shape)\n\nfeat_test = model_feat.predict(X_test)\nfeat_test = np.concatenate((test_lan, feat_test), axis=1)\nprint(feat_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66405397e9bca59cf2ecb741b0862c0cf6edf8a7"},"cell_type":"code","source":"def evaluate(model, X, Y):\n    predicted_Y = model.predict(X)\n    accuracy = accuracy_score(Y, predicted_Y)\n    return accuracy\n\ndef matrix2(svm_model):\n\n    validation_accuracy = evaluate(svm_model, feat_valid, y_valid)\n    print(\"  - validation accuracy = {0:.1f}\".format(validation_accuracy*100))\n\n    valid_labels = svm_model.predict(feat_valid)\n    print(classification_report(y_valid, valid_labels))\n    mat = confusion_matrix(y_valid, valid_labels)\n    print(mat)\n\n    test_accuracy = evaluate(svm_model, feat_test, y_test)\n    print(\"  - test accuracy = {0:.1f}\".format(test_accuracy*100))\n\n    test_labels = svm_model.predict(feat_test)\n    print(classification_report(y_test, test_labels))\n    mat = confusion_matrix(y_test, test_labels)\n    print(mat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a62bb50f5bd9924ca1cfa55b9e910e041aa579ef"},"cell_type":"code","source":"# Application of SVM model 3\n\nstart_time = time.time()  \nsvm_model_3 = LinearSVC(C=100.0)\nsvm_model_3.fit(feat_train, y_train)\nprint('fitting done !!!')\n\nmatrix2(svm_model_3)\ntraining_time = time.time() - start_time\nprint(\"training time = {0:.1f} sec\".format(training_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5cd278a2f36b2c09604f74421de60bb555cb8013"},"cell_type":"code","source":"# Application of SVM model 4\n\nrandom_state = 0\nepochs = 10000\nkernel = 'rbf'  # 'rbf', 'linear', 'poly' or 'sigmoid'\ndecision_function = 'ovr'  # 'ovo' for OneVsOne and 'ovr' for OneVsRest'\n\nstart_time = time.time()  \nsvm_model_4 = SVC(random_state=random_state, max_iter=epochs, kernel=kernel, decision_function_shape=decision_function)\nsvm_model_4.fit(feat_train, y_train)\nprint('fitting done !!!')\n\nmatrix2(svm_model_4)\ntraining_time = time.time() - start_time\nprint(\"training time = {0:.1f} sec\".format(training_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe1a32b5362682e8619e625f217b897f1ab873fa"},"cell_type":"code","source":"# use fer2013 as next test case:\n\n# first lbp+svm\n\ntest_lan_2 = np.load('../input/train-landmarks-fer2013/PrivateTest_landmarks.npy')\n\ntest_lbp_2 = np.load('../input/train-landmarks-fer2013/PrivteTest_lbp_features.npy')\n\ntest_lan_2 = np.array([x.flatten() for x in test_lan_2])\n\nprint(test_lan_2.shape)\nprint(test_lbp_2.shape)\n\nlbp_test_2 = np.concatenate((test_lan_2, test_lbp_2), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae1bab71557c1eafd03ad525012528f27d4d26ff"},"cell_type":"code","source":"def evaluate(model, X, Y):\n    predicted_Y = model.predict(X)\n    accuracy = accuracy_score(Y, predicted_Y)\n    return accuracy\n\ndef matrix3(svm_model, t2, y2):\n    \n    test_accuracy = evaluate(svm_model, t2, y2)\n    print(\"  - test accuracy = {0:.1f}\".format(test_accuracy*100))\n\n    test_labels = svm_model.predict(t2)\n    print(classification_report(y2, test_labels))\n    mat = confusion_matrix(y2, test_labels)\n    print(mat)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40632938bffd21a1ff2c4a716616261a69a3203f"},"cell_type":"code","source":"# Read and process test dataset\n\ndf = pd.read_csv('../input/modified-fer2013/modified_fer2013/fer2013.csv')\ndf.head()\n\ndf[\"Usage\"].value_counts()\n\nprivate_test_df = df[[\"emotion\", \"pixels\"]][df[\"Usage\"]==\"PrivateTest\"]\n# private_test_df.isnull().sum()\n\n\nprivate_test_df[\"pixels\"] = private_test_df[\"pixels\"].apply(lambda im: np.fromstring(im, sep=' '))\nx_test_2 = np.vstack(private_test_df[\"pixels\"].values)\ny_test_2 = np.array(private_test_df[\"emotion\"])\n# print(x_test)\n\nx_test_2 = np.array(x_test_2) / 255.0\n# print(x_test)\nprint(x_test_2.shape, y_test_2.shape)\n\nN = len(x_test_2)\nX_test_2 = x_test_2.reshape(N, 48, 48, 1)\n# print(X_test)\nprint(X_test_2.shape, y_test_2.shape)\n\nY_test_2 = (np.arange(num_class) == y_test_2[:, None]).astype(np.float32)\n\nnum_class = len(set(y_test_2))\nprint(num_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d9c9b4cc17c5f54f76046656f8abb9a56c03837"},"cell_type":"code","source":"# Application of SVM model by fer\n\nstart_time = time.time()  \nmatrix3(svm_model_1, lbp_test_2, y_test_2)\ntraining_time = time.time() - start_time\nprint(\"training time = {0:.1f} sec\".format(training_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b7105f18fe3f966878d4519008cb690452dc25c"},"cell_type":"code","source":"# Application of SVM model by fer\n\nstart_time = time.time()  \nmatrix3(svm_model_2, lbp_test_2, y_test_2)\ntraining_time = time.time() - start_time\nprint(\"training time = {0:.1f} sec\".format(training_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98d3431cf8d64ecad5984a340e635dcc19f12d5f"},"cell_type":"code","source":"# For CNN+SVM\n\nmodel=my_model(48,48)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c81deba6ce82ba9bdbf21f565e68bbcf8097fab0"},"cell_type":"code","source":"# Training CNN\n\nstart_time = time.time()  \n\npath_model='model_filter_2.h5' # save model at this location after each epoch\nK.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\nmodel=my_model(48,48) # create the model\nK.set_value(model.optimizer.lr,1e-3) # set the learning rate\n# fit the model\nh=model.fit(x=X_test_2,     \n            y=Y_test_2, \n            batch_size=64, \n            epochs=20, \n            verbose=1, \n#             validation_data=(X_valid,Y_valid),\n            shuffle=True,\n            callbacks=[\n                ModelCheckpoint(filepath=path_model),\n            ]\n            )\n\ntraining_time = time.time() - start_time\nprint(\"training time = {0:.1f} sec\".format(training_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dcdb5a2770de055309380f9b95dddfa6e248c801"},"cell_type":"code","source":"# Find earlier layer value of CNN anduse as feature extractor\n\nmodel_feat_2 = Model(inputs=model.input,outputs=model.get_layer('dense_one').output)\n\nprint(model.input, model.get_layer('dense_one').output)\n\nfeat_test_2 = model_feat_2.predict(X_test_2)\nfeat_test_2 = np.concatenate((test_lan_2, feat_test_2), axis=1)\nprint(feat_test_2.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a08789712def5774d687dd00d876b8d0af235d5"},"cell_type":"code","source":"# Application of SVM model by fer\n\nstart_time = time.time()  \nmatrix3(svm_model_3, feat_test_2, y_test_2)\ntraining_time = time.time() - start_time\nprint(\"training time = {0:.1f} sec\".format(training_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ec763cdaa0cf0d6e773f433adc73b38170fa665"},"cell_type":"code","source":"# Application of SVM model by fer\n\nstart_time = time.time()  \nmatrix3(svm_model_4, feat_test_2, y_test_2)\ntraining_time = time.time() - start_time\nprint(\"training time = {0:.1f} sec\".format(training_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b28b2da9033ca6e5be58486421fee88bf281bcd"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6bf58a1dd52cd056b8e0f69418a7de1a535fc573"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}