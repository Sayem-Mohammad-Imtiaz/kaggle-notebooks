{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://www.pata.org/wp-content/uploads/2014/09/TripAdvisor_Logo-300x119.png)\n# Predict TripAdvisor Rating\n## В этом соревновании нам предстоит предсказать рейтинг ресторана в TripAdvisor"},{"metadata":{},"cell_type":"markdown","source":"# import"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\n# Загружаем специальный удобный инструмент для разделения датасета:\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\nRANDOM_SEED = 42","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n!pip freeze > requirements.txt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DATA"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"DATA_DIR = '/kaggle/input/sf-dst-restaurant-rating/'\ndf_train = pd.read_csv(DATA_DIR+'/main_task.csv')\ndf_test = pd.read_csv(DATA_DIR+'kaggle_task.csv')\nsample_submission = pd.read_csv(DATA_DIR+'/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ВАЖНО! для корректной обработки признаков объединяем трейн и тест в один датасет\ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0 # помечаем где у нас тест\ndf_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Подробнее по признакам:\n* City: Город \n* Cuisine Style: Кухня\n* Ranking: Ранг ресторана относительно других ресторанов в этом городе\n* Price Range: Цены в ресторане в 3 категориях\n* Number of Reviews: Количество отзывов\n* Reviews: 2 последних отзыва и даты этих отзывов\n* URL_TA: страница ресторана на 'www.tripadvisor.com' \n* ID_TA: ID ресторана в TripAdvisor\n* Rating: Рейтинг ресторана"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Как видим, большинство признаков у нас требует очистки и предварительной обработки."},{"metadata":{},"cell_type":"markdown","source":"# Cleaning and Prepping Data"},{"metadata":{},"cell_type":"markdown","source":"## Обработка NAN \nУ наличия пропусков могут быть разные причины, но пропуски нужно либо заполнить, либо исключить из набора полностью. Но с пропусками нужно быть внимательным, **даже отсутствие информации может быть важным признаком!**   \nПо этому перед обработкой NAN лучше вынести информацию о наличии пропуска как отдельный признак "},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def isnan_feature(data):\n    # makes new feature with 1 if value in existing feature is NaN else 0\n    for col in data.columns[data.isna().nunique() == 2]:\n        data[col.replace(' ','_')+'_isNaN'] = pd.isna(data[col]).astype('uint8')\n    return data\n\n\ndata = isnan_feature(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Далее заполняем пропуски в Number of Reviews нулем\n\ndef fill_zero(series):\n    # fills NaN with 0\n    series.fillna(0, inplace=True)\n\n\nfill_zero(data['Number of Reviews'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Обработка признаков"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.nunique(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Restaurant_id:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Restaurant_id.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Значения Restaurant_id не уникальны"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('Restaurant_id').Restaurant_id.agg('count').sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data.Restaurant_id == 'id_871'].City.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[(data.Restaurant_id == 'id_871') & (data.City == 'Berlin')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Значения Restaurant_id уникальны для каждого города в тренировочной выборке. Те же значения могут относится к другому ресторану в тестовой выборке. Для модели признак бесполезен."},{"metadata":{},"cell_type":"markdown","source":"### Price Range:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Price Range'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"По описанию 'Price Range' это - Цены в ресторане.  \nИх можно поставить по возрастанию (значит это не категориальный признак). А это значит, что их можно заменить последовательными числами, например 1,2,3  "},{"metadata":{"trusted":true},"cell_type":"code","source":"def price_range_to_digits(series):\n    # change values from '$','$$ - $$$','$$$$' to digits 1,2,3; fills NaN with mode (2)\n    series = series.apply(lambda x: 1 if x=='$' else (3 if x=='$$$$' else 2))\n    return series\n\n\ndata['Price Range'] = price_range_to_digits(data['Price Range'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Price Range'].isna().value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### City:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.City.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data.City.unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Признак City содержит названия крупных европейских городов. Добавим больше информации о городах из внешних источников."},{"metadata":{"trusted":true},"cell_type":"code","source":"# внешний датасет, содержащий информацию о населении городов и их координатах:\nworld_cities = pd.read_csv('/kaggle/input/world-cities/worldcities.csv',\n                           usecols=['city_ascii',\n                                    'capital',\n                                   'population'])\n\n# приведение в соответствие с рабочим датасетом названия города Порто:\nworld_cities.city_ascii[world_cities.city_ascii == 'Porto'] = 'Oporto'\nworld_cities = world_cities[world_cities.city_ascii.isin(data.City)]\n# предположительно, рестораны находятся в крупнейших городах из одноименных\nworld_cities.sort_values(['city_ascii','population'], inplace=True)\nworld_cities.drop_duplicates('city_ascii', keep='last', inplace=True)\nworld_cities.capital = world_cities.capital.apply(lambda x: 1 if x=='admin' else 0)\nworld_cities","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"world_cities.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"world_cities.columns = ['City',\n                        'capital',\n                        'population']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.merge(world_cities, on='City')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Добавим ещё больше информации о городах:"},{"metadata":{"trusted":true},"cell_type":"code","source":"qol = pd.read_csv('/kaggle/input/city-quality-of-life-dataset/uaScoresDataFrame.csv',\n                  usecols=['UA_Name', \n#                            'UA_Country', \n#                            'UA_Continent', \n                           'Housing', \n                           'Cost of Living', \n#                            'Startups', \n#                            'Venture Capital', \n                           'Travel Connectivity',\n                           'Commute', \n#                            'Business Freedom', \n                           'Safety', \n#                            'Healthcare', \n#                            'Education',\n#                            'Environmental Quality',\n                           'Economy',\n#                            'Taxation',\n#                            'Internet Access',\n                           'Leisure & Culture', \n#                            'Tolerance', \n#                            'Outdoors'\n                          ])\n\nqol.UA_Name[qol.UA_Name == 'Porto'] = 'Oporto'\nqol = qol[qol.UA_Name.isin(data.City)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qol","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qol.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.merge(qol, left_on='City', right_on='UA_Name', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# для One-Hot Encoding в pandas есть готовая функция - get_dummies. Особенно радует параметр dummy_na\ndata = data.join(pd.get_dummies(data['City'], dummy_na=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cuisine Style:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Cuisine Style'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cuisine_style(data):\n    # генерация dummy признаков по видам кухни:\n    data['Cuisine Style'] = data['Cuisine Style'].str.strip('[] ')\n    cuisines = data['Cuisine Style'].str.get_dummies(sep=', ')\n    cuisines.columns = cuisines.columns.str.strip(\"'\")\n\n    # создание отдельного столбца с количеством заявленных рестораном видов кухни:\n    cuisines['number_of_cuisine_styles'] = cuisines.agg('sum', axis = 1)\n    data = data.join(cuisines)\n    return data\n\n\ndata = cuisine_style(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.number_of_cuisine_styles.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reviews:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Reviews","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(data.Reviews[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Значения представляют собой вложенные списки в строковом формате"},{"metadata":{"trusted":true},"cell_type":"code","source":"import ast","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reviews(data):\n    data.Reviews.fillna('[[], []]', inplace=True)\n    # ast.literal_eval не работает с 'nan'\n    data.Reviews = data.Reviews.str.replace('nan,', \"'',\")\n    data.Reviews = data.Reviews.str.replace(' nan', \" ''\")\n    \n    # преобразование строковых значений в список\n    data.Reviews = data.Reviews.apply(lambda x: ast.literal_eval(x))\n    \n    # выделение текста каждого отзыва в отдельные колонки\n    data['rev_text'] = data.Reviews.apply(lambda x: x[0])\n    data['rev1_text'] = data.rev_text.apply(lambda x: x[0] if x != [] else None)\n    data['rev2_text'] = data.rev_text.apply(lambda x: x[1] if len(x) == 2 else None)\n\n    # выделение времени оставления каждого отзыва в отдельные колонки\n    data['rev_date'] = data.Reviews.apply(lambda x: x[1])\n    data['rev1_date'] = data.rev_date.apply(lambda x: pd.to_datetime(x[0]) if x != [] else None)\n    data['rev2_date'] = data.rev_date.apply(lambda x: pd.to_datetime(x[1]) if len(x) == 2 else None)\n    \n    # Создание признака, содержащего количество дней между двумя отзывами:\n    data['rev_delta'] = abs((data.rev1_date - data.rev2_date).dt.days)\n    data.rev_delta.fillna(0, inplace=True)\n    \n    # Создание признаков, содержащих для каждого отзыва год, код дня недели, день в году:\n    data['rev1_y'] = data.rev1_date.apply(lambda x: pd.Timestamp(x).year)\n    data['rev2_y'] = data.rev2_date.apply(lambda x: pd.Timestamp(x).year)\n    data['rev1_w'] = data.rev1_date.apply(lambda x: pd.Timestamp(x).weekday())\n    data['rev2_w'] = data.rev2_date.apply(lambda x: pd.Timestamp(x).weekday())\n    data['rev1_d'] = data.rev1_date.apply(lambda x: pd.Timestamp(x).dayofyear)\n    data['rev2_d'] = data.rev2_date.apply(lambda x: pd.Timestamp(x).dayofyear)\n    \n    # Заполнение пропусков средним значением:\n    \n    data.rev1_y.fillna(data.rev1_y.median(), inplace=True)\n    data.rev2_y.fillna(data.rev2_y.median(), inplace=True)\n\n    data.rev1_w.fillna(data.rev1_w.median(), inplace=True)\n    data.rev2_w.fillna(data.rev2_w.median(), inplace=True)\n\n    data.rev1_d.fillna(data.rev1_d.median(), inplace=True)\n    data.rev2_d.fillna(data.rev2_d.median(), inplace=True)\n    \n    # Создание признака, содержащего количество отзывов на сайте:\n    data['number_of_reviews_site'] = data.rev_text.apply(lambda x: len(x))\n    \n    # Создание признаков, содержащих длину каждого отзыва и среднюю длину двух отзывов, заполнение пропусков нулями:\n    data['rev1_len'] = data.rev1_text.str.len()\n    data['rev2_len'] = data.rev2_text.str.len()\n\n    data[['rev1_len', 'rev2_len']] = data[['rev1_len', 'rev2_len']].fillna(0)\n\n    data['rev_len_mean'] = (data.rev1_len + data.rev2_len)/2\n    \n    \n    data.drop(['rev_text', 'rev_date', 'rev1_text', 'rev2_text', 'rev1_date', 'rev2_date'], axis=1, inplace=True)\n    \n    \n    \n    \n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = reviews(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Создание нового признака с количеством ресторанов в городе:"},{"metadata":{"trusted":true},"cell_type":"code","source":"Restaurants_in_City = data.City.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Restaurants_in_City'] = data.City.apply(lambda x: Restaurants_in_City[x])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def restaurants_in_city(data):\n    Restaurants_in_City = data.City.value_counts()\n    data['Restaurants_in_City'] = data.City.apply(lambda x: Restaurants_in_City[x])\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing\nТеперь, для удобства и воспроизводимости кода, завернем всю обработку в одну большую функцию."},{"metadata":{"trusted":true},"cell_type":"code","source":"# на всякий случай, заново подгружаем данные\ndf_train = pd.read_csv(DATA_DIR+'/main_task.csv')\ndf_test = pd.read_csv(DATA_DIR+'/kaggle_task.csv')\ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0 # помечаем где у нас тест\ndf_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preproc_data(df_input):\n    '''includes several functions to pre-process the predictor data.'''\n    \n    df_output = df_input.copy()\n    \n    # ################### 1. Предобработка ############################################################## \n    # убираем не нужные для модели признаки\n    df_output.drop(['Restaurant_id','ID_TA',], axis = 1, inplace=True)\n    \n    \n    # ################### 2. NAN ############################################################## \n    # Далее заполняем пропуски\n    df_output = isnan_feature(df_output)\n    df_output.drop(['Number_of_Reviews_isNaN'], axis=1, inplace=True)\n\n    fill_zero(df_output['Number of Reviews'])\n    \n    \n    # ################### 3. Encoding & Feature Engineering ############################################################## \n    \n    df_output['Price Range'] = price_range_to_digits(df_output['Price Range'])\n\n    df_output = df_output.join(pd.get_dummies(df_output.City, dummy_na=True))\n    \n    df_output = df_output.merge(world_cities, on='City', how='left')\n    \n    df_output = df_output.merge(qol, left_on='City', right_on='UA_Name', how='left')\n    \n    # признак снижает значение метрики\n    df_output.drop(['Cuisine_Style_isNaN'], axis=1, inplace=True)\n    \n    df_output = cuisine_style(df_output)\n     \n    df_output = restaurants_in_city(df_output)\n    \n    df_output = reviews(df_output)\n    \n    \n    # ################### 4. Clean #################################################### \n    # убираем признаки которые еще не успели обработать, \n    # модель на признаках с dtypes \"object\" обучаться не будет, просто выберим их и удалим\n    object_columns = [s for s in df_output.columns if df_output[s].dtypes == 'object']\n    df_output.drop(object_columns, axis = 1, inplace=True)\n    \n    return df_output","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Запускаем и проверяем что получилось"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preproc = preproc_data(data)\ndf_preproc.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preproc.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preproc.isna().agg('sum').index.to_list()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Теперь выделим тестовую часть\ntrain_data = df_preproc.query('sample == 1').drop(['sample'], axis=1)\ntest_data = df_preproc.query('sample == 0').drop(['sample'], axis=1)\n\ny = train_data.Rating.values            # наш таргет\nX = train_data.drop(['Rating'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Перед тем как отправлять наши данные на обучение, разделим данные на еще один тест и трейн, для валидации. \nЭто поможет нам проверить, как хорошо наша модель работает, до отправки submissiona на kaggle.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n# выделим 20% данных на валидацию (параметр test_size)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# проверяем\ntest_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model \nСам ML"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Импортируем необходимые библиотеки:\nfrom sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\nfrom sklearn import metrics # инструменты для оценки точности модели","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\nmodel = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Обучаем модель на тестовом наборе данных\nmodel.fit(X_train, y_train)\n\n# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n# Предсказанные значения записываем в переменную y_pred\ny_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Значения рейтинга представлены с шагом 0,5. Округлим результат работы модели:"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = (y_pred*2).round()/2\ny_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\nprint('MAE:', metrics.mean_absolute_error(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MAE: 0.21240125","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MAE: 0.21087374999999997\n# isNaN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MAE: 0.210635\n# price range","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MAE: 0.209500625\n# все кухни в дамми","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MAE: 0.209245\n# убрана колонка Cuisine_Style_isNaN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MAE: 0.20915249999999996\n# убрана колонка Number_of_Reviews_isNaN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MAE: 0.207923125\n#  добавлен world_cities без координат","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MAE: 0.20692687499999998\n# добавлен qol","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MAE: 0.180375\n# округление рейтинга","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MAE: 0.1794375\n# restaurants_in_city","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MAE: 0.1778125\n# reviews","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MAE: 0.1736875\n#     reviews2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MAE: 0.1723125\n# reviews3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\nplt.rcParams['figure.figsize'] = (10,10)\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(15).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission\nЕсли все устраевает - готовим Submission на кагл"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = test_data.drop(['Rating'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission = model.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# округление рейтинга до 0.5\npredict_submission = (predict_submission * 2).round() / 2\npredict_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['Rating'] = predict_submission\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission.head(10)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}