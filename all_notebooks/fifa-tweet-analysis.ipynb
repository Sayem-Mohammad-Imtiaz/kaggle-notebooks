{"cells":[{"metadata":{"trusted":true,"_uuid":"cedf3081b357b584c071926c763172db180905ad"},"cell_type":"code","source":"**Word Cloud of all the tweets **","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# this word cloud takes apprx. 1hr and 15 mins to run completely, please take this into consideration\n#while running... \n\nimport pandas as pd \nimport numpy as np\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nimport re\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\n\n# reading the data from csv\ndata = pd.read_csv('../input/FIFA.csv')\n\n#deleting rows with blank tweets\ndata['Tweet'].replace('  ', np.nan, inplace=True)\ndata = data.dropna(subset=['Tweet'])\ntweet = data['Tweet']\n\n\n#apply tokenization\nstop_words = set(stopwords.words('english'))\nstemmer = PorterStemmer()\nlemmatizer = WordNetLemmatizer()\ncomment_words = ' '\nstopwords = set(STOPWORDS)\n\ndef stem_tokenize(tokens, stemmer):\n    stemmed = []\n    for item in tokens:\n        stemmed.append(stemmer.stem(item))\n    return stemmed\n\n\ndef tokenize(text):\n    tokens = nltk.word_tokenize(text)\n    #token_sanitize = re.sub(\"[^a-zA-Z]+\",\"\", str(tokens))\n    #stems = stem_tokenize(token_sanitize , stemmer)\n    stems = stem_tokenize(tokens , stemmer)\n    return ' '.join(stems)\n\ncorpus = []\n\nfor item in tweet:\n    item = item.lower()\n    tokens = tokenize(item)\n    corpus.append(tokens)\n    \nfor words in corpus:\n    comment_words = comment_words + words + ' '\n \nwordcloud = WordCloud(width = 800, height = 800,\n                background_color ='white',\n                stopwords = stopwords,\n                min_font_size = 10).generate(comment_words)\n \n# plot the WordCloud image                       \nplt.figure(figsize = (8, 8), facecolor = None)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad = 0)\n \nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"abf357ed356ed28b325ffa596dfd5d9a1ecc6d51"},"cell_type":"markdown","source":"**Top 10 sources for tweets**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = pd.read_csv('../input/FIFA.csv')\n\ndata['Tweet'].replace('  ', np.nan, inplace=True)\ndata = data.dropna(subset=['Tweet'])\n\n#combining the iphone and ipad tweet count into a single category\n\ndata.loc[data['Source'] == 'Twitter for iPhone', 'Source'] = 'Twitter for iPhone/iPad'\ndata.loc[data['Source'] == 'Twitter for iPad', 'Source'] = 'Twitter for iPhone/iPad'\n\n#Grouping by source and counts\n\ng1 = data.groupby([\"Source\"]).size().reset_index(name='counts')\ng2 = g1.sort_values('counts', ascending=False).reset_index(drop=True)\n\n#Taking only top 10 sources by count\ng3 = g2.head(10)\n\n#Plotting a simple bar chart for view purposes\n\ng3.plot(x=\"Source\", y = \"counts\", kind=\"bar\")\nplt.show()\ndata.loc[data['Source'] == 'Twitter for iPhone', 'Source'] = 'Twitter for iPhone/iPad'\ndata.loc[data['Source'] == 'Twitter for iPad', 'Source'] = 'Twitter for iPhone/iPad'","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}