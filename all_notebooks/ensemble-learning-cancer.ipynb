{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Esercitazione su Ensemble Learning"},{"metadata":{},"cell_type":"markdown","source":"## Indice contenuti\n- [Ensemble Learning](#Ensemble-Learning)\n- [Descrizione dataset](#Descrizione-dataset)\n- [Analisi esplorativa del dataset](#Analisi-esplorativa-del-dataset)\n    - [Caricamento in memoria del dataset](#Caricamento-in-memoria-del-dataset)\n    - [Pre-processing del dataset](#Pre-processing-del-dataset)\n    - [Gestione valori nulli](#Gestione-valori-nulli)\n    - [Normalizzazione delle features](#Normalizzazione-delle-features)\n- [Algoritmi Bagging](#Algoritmi-Bagging)\n    - [Bagged Decision Trees](#Bagged-Decision-Trees)\n    - [Random Forest](#Random-Forest)\n    - [Extra Trees](#Extra-Trees)\n- [Algoritmi Boosting](#Algoritmi-Boosting)\n    - [AdaBoost](#AdaBoost)\n    - [Stochastic Gradient Boosting](#Stochastic-Gradient-Boosting)\n- [Voting Ensemble](#Voting-Ensemble)\n<hr>"},{"metadata":{},"cell_type":"markdown","source":"### Ensemble Learning\nL'Ensemble Learning è una metodologia strategica per migliorare le performance del modello addestrato. Di solito conviene applicare l'Ensemble Learning considerando differenti modelli che potrebbero essere costruiti per il dataset in analisi.\n\nL'Ensemble Learning è, pertanto, utilizzato al fine di combinare insieme diversi insiemi di learners (detti individual models) e le rispettive predizioni al fine di poter avere un unico risultato.\n\nL'errore che emerge da qualsiasi modello può essere scomposto matematicamente in tre componenti.\n\n$\\text{Err}(x) = \\text{Bias}^2 + \\text{Varianza} + \\text{Errore irriducibile}$\n\nLa spiegazione di ciascuna componente è di seguito riportata:\n- <b>Bias</b>: quantifica in media quanto i valori attesi siano diversi dal valore effettivo\n- <b>Varianza</b>: indica in che modo le previsioni effettuate sulla stessa osservazione siano differenti l'una dall'altra\n\nNaturalmente, incrementando la complessità del tuo modello, si assisterà ad una riduzione dell'errore dovuta alla prsenza di un minore bias nel modello. Tuttavia, questo accade solo fino ad un certo punto. Man mano che, infatti, si tende a rendere il modello sempre più complesso, tale si adatterà eccessivamente iniziando a soffrire di varianza elevata.\n\nUn modello ideale, pertanto, dovrebbe mantenere un equilibrio tra questi due tipi di errori. Tale problema passa sotto il nome di \"trade-off di Bias e Varianza\". L'Ensemble Learning risulta utile in questo frangente per poter ottenere il giusto compromesso.\n\nI tre principali metodi per combinare le predizioni derivanti da differenti modelli sono riportati di seguito:\n\n- <b>Bagging</b>: Bagging cerca di implementare learners simili tra loro su un piccolo campione della popolazione e prende una media di tutte le previsioni. Nel Bagging generalizzato, è possibile usare differenti learners su popolazioni diverse al fine di ridurre la varianza.\n\n![Esempio di Bagging](https://www.analyticsvidhya.com/wp-content/uploads/2015/07/bagging.png)\n- <b>Boosting</b>: Boosting è una tecnica iterativa che regola il peso di un'osservazione in base all'ultima classificazione effettuata. Se un'osservazione è stata classificata in modo errato, si cerca di aumentare il peso di questa osservazione e viceversa. La tecnica Boosting, in generale, riduce il bias e crea modelli predittivi solidi. Tuttavia, a volte possono adattarsi eccessivamente ai dati di training, andando in overfitting.\n\n![Esempio di Boosting](https://www.analyticsvidhya.com/wp-content/uploads/2015/07/boosting.png)\n- <b>Voting</b>: La tecnica per votazione è una delle tecniche di apprendimento Ensemble più dirette in cui vengono combinate le previsioni ottenute da più modelli. Il metodo inizia con la creazione di due o più modelli separati con lo stesso set di dati. In seguito, un modello Ensemble basato sul voto può essere utilizzato per racchiudere i modelli precedenti e aggregare le previsioni di tali modelli. Dopo che il modello Ensemble basato sul voto è stato costruito, può essere utilizzato per fare una previsione sui nuovi dati. Alle previsioni fatte dai sottomodelli possono essere assegnati pesi. L'aggregazione utilizzando lo Stack è una tecnica che può essere utilizzata per imparare a valutare queste previsioni nel miglior modo possibile.\n\n![Esempio di Voting](https://www.analyticsvidhya.com/wp-content/uploads/2015/07/stacking-297x300.png)"},{"metadata":{},"cell_type":"markdown","source":"## Descrizione dataset\n\nPer costruire i differenti modelli, verrà utilizzato il dataset <a href=\"https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)\">Breast Cancer Wisconsin</a> riguardante esempi di casi clinici circa il cancro.\n\nDi seguito sono riportate le features presenti:\n 1. Sample code number: id number\n 2. Clump Thickness: 1 - 10\n 3. Uniformity of Cell Size: 1 - 10\n 4. Uniformity of Cell Shape: 1 - 10\n 5. Marginal Adhesion: 1 - 10\n 6. Single Epithelial Cell Size: 1 - 10\n 7. Bare Nuclei: 1 - 10\n 8. Bland Chromatin: 1 - 10\n 9. Normal Nucleoli: 1 - 10\n 10. Mitoses: 1 - 10\n 11. Class: (2 for benign, 4 for malignant)\n   \nPer ciascun algoritmo di tipo Ensemble, si utilizzerà al fine della valutazione sui dati non visti una 10-Fold Cross Validation."},{"metadata":{},"cell_type":"markdown","source":"## Analisi esplorativa del dataset"},{"metadata":{},"cell_type":"markdown","source":"### Caricamento in memoria del dataset\nCon il seguente comando si effettua il caricamento in memoria di quanto contenuto nel dataset _'pima-indians-diabetes.csv'_.\n\nPer condurre una prima fase di analisi esplorativa e comprendere la natura dei dati a disposizione, si stampano di seguito i primi cinque esempi presenti nel dataset:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\ncol_names=['Sample code number','Clump Thickness','Uniformity of Cell Size','Uniformity of Cell Shape','Marginal Adhesion','Single Epithelial Cell Size','Bare Nuclei','Bland Chromatin','Normal Nucleoli','Mitoses','Class']\ndataframe = pd.read_csv('../input/breast-cancer-csv/breastCancer.csv', header=0, names = col_names)\narray = dataframe.values\n\ndataframe.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Rimozione della feature _Sample code number_\ndataframe.drop(['Sample code number'],axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pre-processing del dataset"},{"metadata":{},"cell_type":"markdown","source":"Per ottenere informazioni statistiche inerenti ciascuna feature a disposizione, mediante il metodo _describe()_ si è provveduto al calcolo delle seguenti informazioni:\n- <b>count</b>: conteggio del numero di esempi per la feature selezionata\n- <b>mean</b>: media aritmetica per la feature selezionata\n- <b>std</b>: deviazione standard per la feature selezionata\n- <b>min</b>: valore minimo presentato dagli esempi per la feature selezionata\n- <b>25%</b>: primo quartile calcolato sugli esempi per la feature selezionata\n- <b>50%</b>: secondo quartile calcolato sugli esempi per la feature selezionata\n- <b>75%</b>: terzo quartile calcolato sugli esempi per la feature selezionata\n- <b>max</b>: valore massimo presentato dagli esempi per la feature selezionata"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Al fine di ottenere una descrizione complessiva del Dataframe (e dunque del relativo dataset) caricato, mediante il metodo _info()_ si sono ottenute le seguenti informazioni:\n- <b>#</b>: numero di feature presente nel DataFrame\n- <b>Column</b>: intestazione delle features nel DataFrame\n- <b>Non-Null Count</b>: contatore di valori non nulli per ogni feature presente nel DataFrame\n- <b>Dtype</b>: tipo di dato memorizzato per ogni feature presente nel DataFrame"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Gestione valori nulli"},{"metadata":{},"cell_type":"markdown","source":"Dal metodo _info()_ si evince che per la feature _Bare Nuclei_ ci sono dei valori che fanno divenire il tipo di dati da int64 a object. Infatti, analizzando il contenuto della feature _Bare Nuclei_ si evince la presenza di valori _?_.\nAl fine di trattare valori mancanti, si utilizzerà la _Mean Imputation_ mentre per la gestione di tali caratteri ? verrà convertito tale valore con 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe.replace('?',0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n# Conversione del DataFrame in array NumPy per applicare il metodo Imputer().\nvalues = dataframe.values\n\nimputer = SimpleImputer()\nimputedData = imputer.fit_transform(values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Normalizzazione delle features\nVista la presenza di dati espressi su un diverso range numerico, si effettua la standardizzazione, mediante apposito metodo StandardScaler()."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range=(0, 1))\nnormalizedData = scaler.fit_transform(imputedData)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split del dataset in X e Y\nX = normalizedData[:,0:9] #Esclude la colonna relativa alla classe\nY = normalizedData[:,9] #Considera esclusivamente la classe come feature target\n\n#Impostazione del seed\nseed = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_trees_list = [x for x in range(5,100+1,5)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_graph(num_trees_list, means):\n    plt.plot(num_trees_list, means)\n    plt.xlabel('Numero alberi')\n    plt.ylabel('Media Cross-Validation')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_max_accuracy(num_trees_list, means):\n    max_index = means.index(max(means))\n    zipped_list = list(zip(num_trees_list, means))\n    print(f\"Numero alberi: {zipped_list[max_index][0]} -> Accuracy CV: {zipped_list[max_index][1]}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Algoritmi Bagging\n1. Bagged Decision Trees\n2. Random Forest\n3. Extra Trees"},{"metadata":{},"cell_type":"markdown","source":"## Bagged Decision Trees\nL'algoritmo Bagging registra le migliori performance quando applicato su dataset con un'alta varianza. Un classico esempio è rappresentato dai DecisionTrees, spesso costruiti senza alcuna potatura.\n\nNegli snippet di codice sottostanti, è mostrato l'utilizzo di _BaggingClassifier_ costruito con _DecisionTreeClassifier_. \nSi valuterà il _BaggingClassifier_ utilizzando un numero variabile di alberi. Infine, si stamperà il plot dell'accuratezza ritornata dalla Cross-Validation e il rispettivo numero di alberi. Tra tali valori, inoltre, è ritornato il numero di alberi consigliati in base al valore dell'accuratezza restituita dalla Cross-Validation.\n\nParametri utilizzat in BaggingClassifier:\n- <b>base_estimator</b>: lo stimatore base da fittare su un subset random del dataset. Se non importato, lo stimatore è un albero di decisione\n- <b>n_estimators</b>: numero di stimatori nell'ensemble\n- <b>random_state</b>: utilizzato per controllare il resampling randomico del dataset originale. Se lo stimatore base acetta questo attrivuto, nell'ensemble viene generato un seme differente per ogni istanza.\n- <b>max_samples</b>: numero di esempi da prendere in considerazione da X per il train di ogni stimatore.\n- <b>max_features</b>: numero di features da considerare per ogni stimatore base\n- <b>bootstrap</b>: vero se gli esempi sono prelevati con rimessa.\n- <b>bootstrap_features</b>: vero se le features sono prelevate con rimessa.\n- <b>n_jobs</b>: numero di processi da eseguire in parallelo per il fit e il predict."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bagged Decision Trees for Classification\nfrom sklearn import model_selection\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dichiarazione del modello\nkfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle = True)\n\n#Classificatore di base\n#criterion='gini' restituisce un numero di alberi pari a 80, con la stessa accuracy\ncart = DecisionTreeClassifier(criterion='entropy', max_depth=None, random_state=1)\n\nmeans = []\nfor num_trees in num_trees_list:\n    #Dichiarazione del modello Bagging\n    model = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=seed, max_samples=1.0, max_features=1.0, bootstrap=True, bootstrap_features=False, n_jobs=1)\n    results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n    means.append(results.mean())\n    \nprint_graph(num_trees_list, means)\nprint_max_accuracy(num_trees_list, means)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1, stratify=Y)\n\ncart = cart.fit(X_train, y_train)\ny_train_pred = cart.predict(X_train)\ny_test_pred = cart.predict(X_test)\n\ntree_train = accuracy_score(y_train, y_train_pred)\ntree_test = accuracy_score(y_test, y_test_pred)\nprint('Decision tree train/test accuracies %.3f/%.3f' % (tree_train, tree_test))\n\nmodel = model.fit(X_train, y_train)\ny_train_pred = model.predict(X_train)\ny_test_pred = model.predict(X_test)\n\nmodel_train = accuracy_score(y_train, y_train_pred) \nmodel_test = accuracy_score(y_test, y_test_pred) \nprint('Bagging train/test accuracies %.3f/%.3f' % (model_train, model_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest\n\nRandom Forest è una estensione del Bagged Decision Trees, visto precedentemente. In questo caso, i campioni del training set sono presi con rimpiazzamento, ma gli alberi sono costruiti in modo tale che sia ridotta la correlazione tra i singoli classificatori.\n\nNegli snippet di codice sottostanti, è mostrato l'utilizzo di _RandomForestClassifier_ con un punto di split scelto dalla selezione randomica di tre features. \nSi valuterà il _RandomForestClassifier_ utilizzando un numero variabile di alberi. Infine, si stamperà il plot dell'accuratezza ritornata dalla Cross-Validation e il rispettivo numero di alberi. Tra tali valori, inoltre, è ritornato il numero di alberi consigliati in base al valore dell'accuratezza restituita dalla Cross-Validation.\n\nParametri utilizzati in RandomForestClassifier:\n- <b>n_estimators</b>: numero di alberi decisionali da utilizzare\n- <b>max_features</b>: numero di feature massimo da utilizzare\n- <b>n_jobs</b>: numero di processi da utilizzare per il fit e la predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dichiarazione del modello\nmax_features = 3\nkfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle = True)\n\n#Dichiarazione del modello RandomForestClassifier\nmeans = []\nfor num_trees in num_trees_list:\n    model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features, n_jobs = -1)\n    results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n    means.append(results.mean())\n    \nprint_graph(num_trees_list, means)\nprint_max_accuracy(num_trees_list, means)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1, stratify=Y)\n\nmodel = model.fit(X_train, y_train)\ny_train_pred = model.predict(X_train)\ny_test_pred = model.predict(X_test)\n\nmodel_train = accuracy_score(y_train, y_train_pred) \nmodel_test = accuracy_score(y_test, y_test_pred) \nprint('RandomForestClassifier train/test accuracies %.3f/%.3f' % (model_train, model_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extra Trees\nExtra Trees sono una ulteriore modifica al Bagging, visto precedentemente, dove vengono costruiti degli alberi randomici dai campioni presenti all'interno del training set.\n\nNegli snippet di codice sottostanti, è mostrato l'utilizzo di _ExtraTreesClassifier_ con un punto di split scelto dalla selezione randomica di sette features. \nSi valuterà il _ExtraTreesClassifier_ utilizzando un numero variabile di alberi. Infine, si stamperà il plot dell'accuratezza ritornata dalla Cross-Validation e il rispettivo numero di alberi. Tra tali valori, inoltre, è ritornato il numero di alberi consigliati in base al valore dell'accuratezza restituita dalla Cross-Validation.\n\nParametri utilizzati in ExtraTreesClassifier:\n- <b>n_estimators</b>: numero di stimatori base da utilizzare\n- <b>max_features</b>: numero massimo di features da utilizzare\n- <b>random_state</b>: : utilizzato per controllare il resampling randomico del dataset originale. Se lo stimatore base acetta questo attrivuto, nell'ensemble viene generato un seme differente per ogni istanza.\n- <b>n_jobs</b>: numero di processi da utilizzare per il fit e la predizione"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection\nfrom sklearn.ensemble import ExtraTreesClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Definizione parametri del modello\nnum_trees = 100\nmax_features = 7\n\nkfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle = True)\n\n#Dichiarazione del modello ExtraTreesClassifier\nmeans = []\nfor num_trees in num_trees_list:\n    model = ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features, n_jobs = -1, random_state=seed)\n    results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n    means.append(results.mean())\n    \nprint_graph(num_trees_list, means)\nprint_max_accuracy(num_trees_list, means)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1, stratify=Y)\n\nmodel = model.fit(X_train, y_train)\ny_train_pred = model.predict(X_train)\ny_test_pred = model.predict(X_test)\n\nmodel_train = accuracy_score(y_train, y_train_pred) \nmodel_test = accuracy_score(y_test, y_test_pred) \nprint('ExtraTreesClassifier train/test accuracies %.3f/%.3f' % (model_train, model_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Algoritmi Boosting\n\nGli algoritmi Ensembel di Boosting creano una sequenza di modelli che permettono si correggere gli errori fatti dai modelli precedenti presenti nella sequenza. Una volta creati, i modelli effettuano le predizioni, le quali possono essere pesate dalla rispettiva accuracy del modello e i risultati sono combinati al fine di ottenere una predizione complessiva finale.\n\nI due algoritmi principali di Boosting Ensemble sono classificabili in:\n1. AdaBoost\n2. Stochastic Gradient Boosting"},{"metadata":{},"cell_type":"markdown","source":"Si calcola l'accuratezza delle predizioni sul training e test set per comparare le performance del bagging e del singolo decision Tree."},{"metadata":{},"cell_type":"markdown","source":"## AdaBoost\nAdaBoost pesa le istanze presenti nel dataset in base alla difficoltà/facilità di classificazione, permettendo all'algoritmo di porre più o meno attenzione a tali esempi nella costruzione dei modelli seguenti.\n\n\nNegli snippet di codice sottostanti, è mostrato l'utilizzo di _AdaBoostClassifier_\nSi valuterà il _AdaBoostClassifier_ utilizzando un numero variabile di alberi. Infine, si stamperà il plot dell'accuratezza ritornata dalla Cross-Validation e il rispettivo numero di alberi. Tra tali valori, inoltre, è ritornato il numero di alberi consigliati in base al valore dell'accuratezza restituita dalla Cross-Validation."},{"metadata":{"trusted":true},"cell_type":"code","source":"# AdaBoost Classification\nfrom sklearn import model_selection\nfrom sklearn.ensemble import AdaBoostClassifier\n\nkfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle = True)\n#Classificatore di base\n#tree = DecisionTreeClassifier(criterion='entropy', max_depth=1,random_state=1)\n\n#Dichiarazione del modello AdaBoost\nmeans = []\nfor num_trees in num_trees_list:\n    #Opzionalmente si potrebbe parametrizzare con il classificatore di base l'attributo base_estimator\n    #model = AdaBoostClassifier(n_estimators=num_trees, random_state=seed, learning_rate=0.1, base_estimator=tree)\n    model = AdaBoostClassifier(n_estimators=num_trees, random_state=seed, learning_rate=0.1)\n\n    results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n    means.append(results.mean())\n    \nprint_graph(num_trees_list, means)\nprint_max_accuracy(num_trees_list, means)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1, stratify=Y)\n\n#Se base_estimator è definito, è possibile rimuovere il commento\n\"\"\"tree = tree.fit(X_train, y_train)\ny_train_pred = tree.predict(X_train)\ny_test_pred = tree.predict(X_test)\n\ntree_train = accuracy_score(y_train, y_train_pred)\ntree_test = accuracy_score(y_test, y_test_pred)\nprint('Decision tree train/test accuracies %.3f/%.3f' % (tree_train, tree_test))\"\"\"\n\nmodel = model.fit(X_train, y_train)\ny_train_pred = model.predict(X_train)\ny_test_pred = model.predict(X_test)\n\nmodel_train = accuracy_score(y_train, y_train_pred) \nmodel_test = accuracy_score(y_test, y_test_pred) \nprint('AdaBoost train/test accuracies %.3f/%.3f' % (model_train, model_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Stochastic Gradient Boosting\nStochastic Gradient Boosting (conosciuto anche come Gradient Boosting Machines) fa riferimento ad una delle tecniche più sofisticate tra le tecniche di Ensemble Learning, basate sul metodo di ottimizzazione che tiene conto della discesa del gradiente stocastica.\n\nNegli snippet di codice sottostanti, è mostrato l'utilizzo di _GradientBoostingClassifier_.\nSi valuterà il _GradientBoostingClassifier_ utilizzando un numero variabile di alberi. Infine, si stamperà il plot dell'accuratezza ritornata dalla Cross-Validation e il rispettivo numero di alberi. Tra tali valori, inoltre, è ritornato il numero di alberi consigliati in base al valore dell'accuratezza restituita dalla Cross-Validation.\n\nAnche in questo caso, i parametri utilizzati in GradientBoostingClassifier sono i seguenti:\n- <b>n_estimators</b>: numero di alberi da utilizzare\n- <b>random_state</b>: : utilizzato per controllare il resampling randomico del dataset originale. Se lo stimatore base acetta questo attrivuto, nell'ensemble viene generato un seme differente per ogni istanza."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nnum_trees = 100\nkfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle = True)\n\n#Dichiarazione del modello GradientBoostingClassifier\nmeans = []\nfor num_trees in num_trees_list:\n    model = GradientBoostingClassifier(n_estimators=num_trees, random_state=seed)\n    results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n    means.append(results.mean())\n    \nprint_graph(num_trees_list, means)\nprint_max_accuracy(num_trees_list, means)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1, stratify=Y)\n\nmodel = model.fit(X_train, y_train)\ny_train_pred = model.predict(X_train)\ny_test_pred = model.predict(X_test)\n\nmodel_train = accuracy_score(y_train, y_train_pred) \nmodel_test = accuracy_score(y_test, y_test_pred) \nprint('GradientBoostingClassifier train/test accuracies %.3f/%.3f' % (model_train, model_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Voting Ensemble\n\nL'ultima famiglia di Ensemble considerata permette, mediante votazioni, di combinare le predizioni derivanti da diversi algoritmi di apprendimento automatico.\n\nIl funzionamento si asa sulla creazione di due o più modelli standalone rispetto ai dati presenti nel training set. Successivamente, un VotingClassifier può essere utilizzato per unire i modelli e mediare circa le predizioni fatte dai due sotto-modelli sui nuovi dati presenti nel test-set.\n\nLe predizioni fatte dai sotto-modelli possono essere pesate, ma tale compito risulta essere arduo. Tale tecnica è chiamata Stacked Generalization e non è attualmente implementata in scikit-learn.\n\nNegli snippet di codice sottostanti, è mostrato l'utilizzo di VotingClassifier. In particolare, VotingClassifier si baserà sulle predizioni derivanti da LogisticRegression, DecisionTreeClassifier e Support Vector Machine, mediando i risultati ottenuti mediante Cross-Validation."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import VotingClassifier\n\n\nkfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle = True)\n\n# Creazione dei singoli algoritmi\nsub_models = []\nlr = LogisticRegression(max_iter=1000)\nsub_models.append(('Logistic Regression', lr))\n\ncart = DecisionTreeClassifier()\nsub_models.append(('Decision Tree (CART)', cart))\n\nsvc = SVC()\nsub_models.append(('Support Vector Machine', svc))\n\n# Creazione dell'Ensemble\nensemble = VotingClassifier(sub_models, voting='hard')\nresults = model_selection.cross_val_score(ensemble, X, Y, cv=kfold)\nprint(\"Accuracy: \", results.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1, stratify=Y)\n\nensemble = ensemble.fit(X_train, y_train)\ny_train_pred = ensemble.predict(X_train)\ny_test_pred = ensemble.predict(X_test)\n\nmodel_train = accuracy_score(y_train, y_train_pred) \nmodel_test = accuracy_score(y_test, y_test_pred) \nprint('VotingClassifiler train/test accuracies %.3f/%.3f' % (model_train, model_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}