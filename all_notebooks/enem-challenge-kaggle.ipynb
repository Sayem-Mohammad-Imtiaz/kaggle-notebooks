{"cells":[{"metadata":{},"cell_type":"markdown","source":"# ENEM Challenge","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Data from ENEM 2016, the Brazilian High School National Exam.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Context\nThis dataset was downloaded from INEP, a department from the Brazilian Education Ministry. It contains data from the applicants for the 2016 National High School Exam.\n\n### Content\nInside this dataset there are not only the exam results, but the social and economic context of the applicants.\n\n### Acknowledgements\nThe original dataset is provided by INEP (http://portal.inep.gov.br/microdados).\n\n### Inspiration\nThe objective is to explore the dataset to achieve a better understanding of the social and economic context of the applicants in the exams results.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Imports","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install joblib","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.ensemble import *\nfrom sklearn.linear_model import *\nfrom xgboost import XGBRegressor #ML\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom joblib import dump, load\nimport warnings\nwarnings.filterwarnings(action='ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['NU_NOTA_MT','NU_NOTA_COMP1','NU_NOTA_COMP2','NU_NOTA_COMP4','NU_NOTA_COMP5','NU_NOTA_COMP3','NU_NOTA_REDACAO','NU_NOTA_LC','NU_NOTA_CH','NU_NOTA_CN']\ndata = pd.read_csv('../input/enem-2016/microdados_enem_2016_coma.csv', encoding='latin-1', sep=',', usecols=features, nrows=200000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[['NU_NOTA_MT']].info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"col = data.columns       # .columns gives columns names in data \nprint(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['NU_NOTA_MT','NU_NOTA_COMP1','NU_NOTA_COMP2','NU_NOTA_COMP4','NU_NOTA_COMP5','NU_NOTA_COMP3','NU_NOTA_REDACAO','NU_NOTA_LC','NU_NOTA_CH','NU_NOTA_CN']\ntarget = \"NU_NOTA_MT\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total = data[features].isnull().sum().sort_values(ascending = False)\npercent = (data[features].isnull().sum()/data[features].isnull().count()*100).sort_values(ascending = False)\nmissing  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_map = data[[target]]\ndata_map[features] = data[features]\nplt.figure(figsize=(15,15))\nsns.heatmap(data_map.corr(), annot=True, square=True, cmap='coolwarm')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in features:\n    plt.figure(figsize = (20, 3))\n    data.plot(kind='scatter', x=column, y=target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Clean Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"duplicated_data = data.duplicated()\ndata[duplicated_data]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = data.copy()\ntrain = train.loc[:, features]\ntrain.dropna(subset=[target], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train[target]\nX = train.drop([target], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns = list(X._get_numeric_data().columns)\ncategorical_columns = list(set(X.columns) - set(numerical_columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_pipeline = Pipeline([\n        ('data_filler', SimpleImputer(strategy=\"median\")),\n        ('std_scaler', StandardScaler()),\n    ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_pipeline = Pipeline([\n        ('data_filler', SimpleImputer(strategy='most_frequent')),\n        ('encoder', OneHotEncoder(handle_unknown='ignore'))\n    ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transformer = ColumnTransformer([\n    (\"numerical\", numerical_pipeline, numerical_columns),\n    (\"categorical\", categorical_pipeline, categorical_columns)\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_ensemble_models(X, y):\n    clf1 = LinearRegression()\n    clf2 = Lasso(alpha=.5)\n    clf3 = Ridge(alpha=.1)\n    clf4 = LassoLars(alpha=.1)\n    clf5 = AdaBoostRegressor()\n    clf6 = SVR(kernel='rbf',gamma='scale',C=100)\n    clf7 = GradientBoostingRegressor()\n\n    for clf, label in zip([clf1, clf2, clf3, clf4, clf5, clf6, clf7], ['Linear Regression', 'Lasso', 'Ridge','Lasso Lars','Ada Boost Regressor','SVR', 'Gradient Boosting Regressor']):\n        execute_pipeline(clf, X, y, label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def execute_pipeline(clf, X, y, title):\n    \n    pipe = Pipeline([\n        ('transformer', transformer),\n        ('reduce_dim', 'passthrough'),\n        ('classify', clf)\n    ])\n\n    N_FEATURES_OPTIONS = [2, 4, 8]\n    \n    param_grid = [\n        {\n            'reduce_dim': [PCA()],\n            'reduce_dim__n_components': N_FEATURES_OPTIONS\n        },\n        {\n            'reduce_dim': [SelectKBest()],\n            'reduce_dim__k': N_FEATURES_OPTIONS\n        },\n    ]\n    reducer_labels = ['PCA', 'KBest']\n\n    grid = GridSearchCV(pipe,  param_grid=param_grid, scoring='r2', cv=10, verbose=1, n_jobs=-1, return_train_score=True)\n    grid.fit(X, y)\n\n    mean_train_scores = np.array(grid.cv_results_['mean_train_score'])\n    mean_scores = np.array(grid.cv_results_['mean_test_score'])\n    mean_scores = mean_scores.reshape(2, len(N_FEATURES_OPTIONS))\n    bar_offsets = (np.arange(len(N_FEATURES_OPTIONS)) * (len(reducer_labels) + 1) + .5)\n\n    plt.figure()\n    COLORS = 'bgrcmyk'\n    for i, (label, reducer_scores) in enumerate(zip(reducer_labels, mean_scores)):\n        plt.bar(bar_offsets + i, mean_train_scores[i], label='{} train'.format(label),alpha=.7)\n        plt.bar(bar_offsets + i, reducer_scores, label='{} test'.format(label), color=COLORS[i])\n\n    plt.title(title)\n    plt.xlabel('Number of features')\n    plt.xticks(bar_offsets + len(reducer_labels) / 2, N_FEATURES_OPTIONS)\n    plt.ylabel('Classification accuracy')\n    plt.ylim((0, 1))\n    plt.legend(loc='upper left')\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_result = train_ensemble_models(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Validated Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"transformer = transformer\nreduction = SelectKBest(k=8)\nmodel = GradientBoostingRegressor()\n\nX_train_transformer = transformer.fit_transform(X_train)\nX_test_transformer = transformer.transform(X_test)\n\nX_train_reduction_transformer = reduction.fit_transform(X_train_transformer, y_train)\nX_test_reduction_transformer = reduction.transform(X_test_transformer)\n\nmodel.fit(X_train_reduction_transformer, y_train)\n\ny_predict = model.predict(X_test_reduction_transformer)\n\nrmse = (np.sqrt(mean_squared_error(y_test, y_predict)))\nr2 = r2_score(y_test, y_predict)\nprint('RMSE is {}'.format(rmse))\nprint('R2 score is {}'.format(r2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = reduction.get_support(indices=True)\nnew_features = []\nfor bool, feature in zip(cols, X_train.columns):\n    if bool:\n        new_features.append(feature)\n        \ndataframe = pd.DataFrame(X_train, columns=new_features)\ndataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe['target'] = y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\nsns.heatmap(dataframe.corr(), annot=True, square=True, cmap='coolwarm')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Save models and results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"persistence = {}\npersistence['transformer'] = transformer\npersistence['reduction'] = reduction\npersistence['model']  = model\ndump(persistence, 'persist.joblib')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"persistence = load('persist.joblib')\n\ntransformer = persistence['transformer']\nreduction = persistence['reduction']\nmodel = persistence['model']\n\ndataset_test_transformer = transformer.transform(dataset_test)\ndataset_test_reduction_transformer = reduction.transform(dataset_test_transformer)\n\npredictions = model.predict(dataset_test_reduction_transformer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame({'NU_INSCRICAO': nuInscricao, 'NU_NOTA_MT': predictions})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output.to_csv('answer.csv', index=False)\nprint(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}