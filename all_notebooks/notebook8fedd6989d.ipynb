{"cells":[{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nSUBJECTS=[\"ENGLISH\",\"MATHS\",\"SCIENCE\",\"HISTORY\",\"GEOGRAPHY\"]\nMARKS=[86,83,86,90,88] \ntick_label=[\"ENGLISH\",\"MATHS\",\"SCIENCE\",\"HISTORY\",\"GEOGRAPHY\"]  \nplt.bar(SUBJECTS,MARKS,tick_label=tick_label,width=0.8,color=['green','red','green','green','green'])   \nplt.xlabel('SUBJECTS') \nplt.ylabel('MARKS')  \nplt.title(\"STUDENT's MARKS DATASET\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"arr1 = []\na = int(input(\"Size of array:\"))\nfor i in range(a):\n    arr1.append(float(input(\"Element:\")))\narr1 = np.array(arr1)\narr2 = []\na = int(input(\"Size of array:\"))\nfor i in range(a):\n    arr2.append(float(input(\"Element:\")))\narr2 = np.array(arr2)\n# Checking if arr1 has views to arr2 memmory\nprint(arr1.base is arr2)\n# Checking if arr2 has views to arr1 memmory\nprint(arr2.base is arr1)\nfor i in arr1.data:\n    if i % 3 == 0:\n        print (f\"{i} is divisible by 3\")\n    else:\n        print (f\"{i} is not divisible by 3\")\nfor i in arr2.data:\n    if i % 3 == 0:\n        print (f\"{i} is divisible by 3\")\n    else:\n        print (f\"{i} is not divisible by 3\")\n        print(np.sort(arr2))\n    sum = np.sum(arr1)\nprint(f\"The sum of all elements in arr1 is {sum}\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\niris = pd.read_csv('../input/iriscsv/Iris.csv')\niris.drop('Id', axis=1, inplace=True)\niris.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"print(iris[\"Species\"].value_counts())\nprint()\nprint(iris.info())\nprint()\nprint(iris.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"def _split_iris_dataset(iris):\n    from sklearn.model_selection import train_test_split\n    from sklearn.preprocessing import StandardScaler\n    \n    y = iris['Species']\n    X = iris.drop('Species', axis=1)\n\n    scaler = StandardScaler()\n    X_trans = scaler.fit_transform(X)\n\n    X_train, X_test, y_train, y_test = train_test_split(X_trans, y, test_size=0.33, random_state=42)\n    return (X_train, X_test, y_train, y_test)\n\ndef _evaluate_iris_classifier(feature, clf, dataset):\n    X_train, X_test, y_train, y_test = _split_iris_dataset(dataset)\n    \n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import confusion_matrix\n    from sklearn.metrics import precision_score, recall_score\n    from sklearn.metrics import f1_score\n\n    y_train_feature = (y_train == feature)\n    y_test_feature = (y_test == feature)\n\n    predict = cross_val_predict(clf, X_train, y_train_feature, cv=3)\n    print(\"confusion matrix on\", feature)\n    print(confusion_matrix(y_train_feature, predict))\n    print(\"percision:\", precision_score(y_train_feature, predict))\n    print(\"recall:\", recall_score(y_train_feature, predict))\n    print(\"f1 score:\", f1_score(y_train_feature, predict))\n    from sklearn.linear_model import SGDClassifier\nsgd_clf = SGDClassifier(random_state=42)\n\nprint(\"---------- Original iris ----------\")\n_evaluate_iris_classifier('Iris-versicolor', sgd_clf, iris)\nprint()\nprint(\"---------- Enhanced iris ----------\")\niris_sgd = iris.copy()\niris_sgd['SepalWidth_PetalLength'] = iris_sgd['SepalWidthCm'] / iris_sgd['PetalLengthCm']\niris_sgd['SepalWidth_PetalWidth'] = iris_sgd['SepalWidthCm'] / iris_sgd['PetalWidthCm']\n_evaluate_iris_classifier('Iris-versicolor', sgd_clf, iris_sgd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"import pandas as pd\ntitanic_data=pd.read_csv(\"../input/titanic/train_and_test2.csv\")\nprint(\"TITANIC DATASET : \")\nprint(titanic_data.head())\nprint(\"TITANIC DATASET SHAPE : \",titanic_data.shape)\nprint(titanic_data.shape)\n\ntitanic_data.dropna(axis=1, how='all')\nprint(\"__\\nTITANIC DATASET : \")\nprint(titanic_data.head())\nprint(\"TITANIC DATASET SHAPE : \",titanic_data.shape)\nprint(titanic_data.shape)\n\nprint(\"__\\nMean value of first 50 samples: \\n\",titanic_data[:50].mean())\n\nprint(\"__\\nMean of the number of male passengers( Sex=1) on the ship :\\n\",titanic_data[titanic_data['Sex']==1].mean())\n\nprint(\"__\\nHighest fare paid by any passenger: \",titanic_data['Fare'].max())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}