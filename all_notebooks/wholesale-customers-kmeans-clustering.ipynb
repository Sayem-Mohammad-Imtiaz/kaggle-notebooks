{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler, MinMaxScaler, PowerTransformer, MaxAbsScaler, Normalizer, QuantileTransformer\nimport seaborn as sns\nfrom sklearn import decomposition\nimport plotly.express as px\n\ndata = pd.read_csv(\"/kaggle/input/wholesale-customers-data-set/Wholesale customers data.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Look at \"Region\" categorical composition"},{"metadata":{"trusted":true},"cell_type":"code","source":"regions = pd.DataFrame(data['Region'].value_counts().T)\nregions.rename(index={1:'Lisbon',2:'Oporto',3:'Other'},inplace=True)\nprint('Region Bar Plot')\nregions.T.plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Simply drop region because it's very incomplete. It has a lot of \"others\""},{"metadata":{"trusted":true},"cell_type":"code","source":"df=data.drop(['Region'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Look for obvious outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 6))\nsns.boxplot(data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Drop obvious outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(df.index[(df['Fresh']==112151) | (df['Milk']==73498) | (df['Grocery']==92780) | (df['Frozen']==60869) | (df['Delicassen']==47943)],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Calculate a PCA on the full stardardized data, and look for obvious clusters"},{"metadata":{"trusted":true},"cell_type":"code","source":"dfSTD=pd.DataFrame(StandardScaler().fit_transform(df))\npca = decomposition.PCA(n_components=3)\n\n### Numpy 1.19.5 produces non-convergance random error on first pass, so retry if necessary ###\nwhile True: \n    try: \n        XSTD = pca.fit_transform(dfSTD) \n        break \n    except: \n        continue\nprint(\"Explained Variance ratio:\",pca.explained_variance_ratio_)\nXSTD.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter_3d(x=XSTD[:, 0], y=XSTD[:, 1], z=XSTD[:, 2], width=1200, height=900)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Look at \"Channel\" categorical composition"},{"metadata":{"trusted":true},"cell_type":"code","source":"channels = pd.DataFrame(data['Channel'].value_counts().T)\nchannels.rename(index={1:'HoReCa',2:'Retail'},inplace=True)\nprint('Channels Bar Plot')\nchannels.T.plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# First divide by channel and visualize product mix differences"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Divide Retail from HoReCa and try to divide HoReCa in Hotel, Restaurant and Café\ndfHoReCa = df[df['Channel']==1].drop(['Channel'],axis=1)\ndfRetail = df[df['Channel']==2].drop(['Channel'],axis=1)\n\n# Plot both groups to visualize the difference\nfig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True,figsize=(25, 10))\nax1.set_title('Hotels / Restaurants / Cafés')\nax2.set_title('Retail')\nsns.boxplot(data=dfHoReCa, ax=ax1)\nsns.boxplot(data=dfRetail, ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# \"HoReCa Channel\" Analysis and Clustering"},{"metadata":{"trusted":true},"cell_type":"code","source":"# dfcolumns = dfHoReCa.columns\n# ### Use QuantileTransformer if we want to force it to suggest a k=3 elbow ###\n# dfHoReCa=pd.DataFrame(QuantileTransformer().fit_transform(dfHoReCa))\n# dfHoReCa.columns = dfcolumns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"distortions = []\nK = range(1,10)\nfor k in K:\n    model = KMeans(n_clusters=k)\n    model.fit(dfHoReCa)\n    distortions.append(model.inertia_)\nprint(distortions)\nplt.plot(K, distortions, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Distortion')\nplt.title('Elbows')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Disregard the suggested k=2 Elbow, and use k=3 in order to *try* to classify into Hotels vs Restaurants vs Cafés"},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters=3,max_iter=1000,random_state=42)\nkmeans.fit(dfHoReCa)\npredict = kmeans.predict(dfHoReCa)\ncentroids = kmeans.cluster_centers_\nprint(centroids)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bar Chart with Totals and Percentages (HoReCa Channel)"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True,figsize=(25, 10))\nax1.set_title('Totals')\nax2.set_title('Percentages')\n\ngroups = pd.DataFrame({'Group 1: Restaurants?':centroids[0],'Group 2: Cafés?':centroids[1],'Group 3: Hotels?':centroids[2]},index=dfHoReCa.columns).T\nstacked_data = groups\nstacked_data.plot.barh(stacked=False,ax=ax1)\ngroups = pd.DataFrame({'Group 1: Restaurants?':centroids[0],'Group 2: Cafés?':centroids[1],'Group 3: Hotels?':centroids[2]},index=dfHoReCa.columns).T\nstacked_data2 = groups.apply(lambda x: x*100/sum(x), axis=1)\nstacked_data2.plot.barh(stacked=True,ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Alternative view with boxplots (HoReCa Channel)"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(25, 10))\nax1.set_title('Group 1: Restaurants?')\nax2.set_title('Group 2: Cafés?')\nax3.set_title('Group 3: Hotels?')\ndata = dfHoReCa.copy()\ndata['predict'] = predict\nsns.boxplot(data=data[data['predict']==0], ax=ax1)\nsns.boxplot(data=data[data['predict']==1], ax=ax2)\nsns.boxplot(data=data[data['predict']==2], ax=ax3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## PCA (HoReCa)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#dfHoReCa=pd.DataFrame(StandardScaler().fit_transform(dfHoReCa))\npca = decomposition.PCA(n_components=3)\n\n### Numpy 1.19.5 produces non-convergance random error on first pass, so retry if necessary ###\nwhile True: \n    try: \n        XHoReCa = pca.fit_transform(dfHoReCa) \n        break \n    except: \n        continue\nprint(\"Explained Variance ratio:\",pca.explained_variance_ratio_)\nXHoReCa.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize HoReCa Clusters"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter_3d(x=XHoReCa[:, 0], y=XHoReCa[:, 1], z=XHoReCa[:, 2], color=predict,width=1200, height=900)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# \"Retail Channel\" Analysis and Clustering"},{"metadata":{"trusted":true},"cell_type":"code","source":"dfcolumns = dfRetail.columns\ndfRetail=pd.DataFrame(PowerTransformer().fit_transform(dfRetail))\ndfRetail=pd.DataFrame(MinMaxScaler().fit_transform(dfRetail))\ndfRetail.columns = dfcolumns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"distortions = []\nK = range(1,10)\nfor k in K:\n    model = KMeans(n_clusters=k)\n    model.fit(dfRetail)\n    distortions.append(model.inertia_)\nprint(distortions)\nplt.plot(K, distortions, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Distortion')\nplt.title('Elbows')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Disregard the clearly suggested k=3 Elbow, and use Elbow k=2 since this is a channels subset with very few samples"},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters=2,max_iter=1000,random_state=42)\nkmeans.fit(dfRetail)\npredict = kmeans.predict(dfRetail)\ncentroids = kmeans.cluster_centers_\nprint(centroids)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bar Chart with Totals and Percentages (Retail Channel)"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True,figsize=(25, 10))\nax1.set_title('Totals')\nax2.set_title('Percentages')\n\ngroups = pd.DataFrame({'Group 1':centroids[0],'Group 2':centroids[1]},index=dfRetail.columns).T\nstacked_data = groups\nstacked_data.plot.barh(stacked=False,ax=ax1)\ngroups = pd.DataFrame({'Group 1':centroids[0],'Group 2':centroids[1]},index=dfRetail.columns).T\nstacked_data2 = groups.apply(lambda x: x*100/sum(x), axis=1)\nstacked_data2.plot.barh(stacked=True,ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Alternative view with boxplots (Retail Channel)"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(25, 10))\nax1.set_title('Group 1')\nax2.set_title('Group 2')\ndata = dfRetail.copy()\ndata['predict'] = predict\nsns.boxplot(data=data[data['predict']==0], ax=ax1)\nsns.boxplot(data=data[data['predict']==1], ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## PCA (Retail)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#dfRetail=pd.DataFrame(StandardScaler().fit_transform(dfRetail))\npca = decomposition.PCA(n_components=3)\n\n### Numpy 1.19.5 produces non-convergance random error on first pass, so retry if necessary ###\nwhile True: \n    try: \n        XRetail = pca.fit_transform(dfRetail)\n        break \n    except: \n        continue\nprint(\"Explained Variance ratio:\",pca.explained_variance_ratio_)\nXRetail.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize Retail Clusters"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter_3d(x=XRetail[:, 0], y=XRetail[:, 1],z=XRetail[:, 2], color=predict,width=1200, height=900)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# \"Full Dataset\" Analysis and Clustering"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['Channel'],axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dfcolumns = df.columns\n# # df=pd.DataFrame(StandardScaler().fit_transform(df))\n# df=pd.DataFrame(MinMaxScaler().fit_transform(df))\n# df.columns = dfcolumns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"distortions = []\nK = range(1,10)\nfor k in K:\n    model = KMeans(n_clusters=k)\n    model.fit(df)\n    distortions.append(model.inertia_)\nprint(distortions)\nplt.plot(K, distortions, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Distortion')\nplt.title('Elbows')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Use the suggested k=3"},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters=3,max_iter=1000,random_state=42)\nkmeans.fit(df)\npredict = kmeans.predict(df)\ncentroids = kmeans.cluster_centers_\nprint(centroids)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bar Chart with Totals and Percentages (Full Dataset)"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True,figsize=(25, 10))\nax1.set_title('Totals')\nax2.set_title('Percentages')\n\ngroups = pd.DataFrame({'Group 1: Big Fresh':centroids[0],'Group 2: Small Balanced':centroids[1],'Group 3: Milk/Groceries':centroids[2]},index=df.columns).T\nstacked_data = groups\nstacked_data.plot.barh(stacked=False,ax=ax1)\ngroups = pd.DataFrame({'Group 1: Big Fresh':centroids[0],'Group 2: Small Balanced':centroids[1],'Group 3: Milk/Groceries':centroids[2]},index=df.columns).T\nstacked_data2 = groups.apply(lambda x: x*100/sum(x), axis=1)\nstacked_data2.plot.barh(stacked=True,ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Alternative view with boxplots (Full Dataset)"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(25, 10))\nax1.set_title('Group 1: Big Fresh')\nax2.set_title('Group 2: Small Balanced')\nax3.set_title('Group 3: Milk/Groceries')\ndata = df.copy()\ndata['predict'] = predict\nsns.boxplot(data=data[data['predict']==0], ax=ax1)\nsns.boxplot(data=data[data['predict']==1], ax=ax2)\nsns.boxplot(data=data[data['predict']==2], ax=ax3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## PCA (Full Dataset)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#df=pd.DataFrame(StandardScaler().fit_transform(df))\npca = decomposition.PCA(n_components=3)\n\n### Numpy 1.19.5 produces non-convergance random error on first pass, so retry if necessary ###\nwhile True: \n    try: \n        XFull = pca.fit_transform(df)\n        break \n    except: \n        continue\nprint(\"Explained Variance ratio:\",pca.explained_variance_ratio_)\nXFull.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize Full dataset clusters"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter_3d(x=XFull[:, 0], y=XFull[:, 1],z=XFull[:, 2], color=predict,width=1200, height=900)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"# import sys\n# np.set_printoptions(threshold=sys.maxsize)\n# print(XFull)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}