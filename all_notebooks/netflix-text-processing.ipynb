{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport nltk\nimport sklearn\nimport re","metadata":{"execution":{"iopub.status.busy":"2021-07-04T07:19:33.582116Z","iopub.execute_input":"2021-07-04T07:19:33.582502Z","iopub.status.idle":"2021-07-04T07:19:33.58855Z","shell.execute_reply.started":"2021-07-04T07:19:33.582471Z","shell.execute_reply":"2021-07-04T07:19:33.587242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df= pd.read_csv('../input/netflix-shows/netflix_titles.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2021-07-04T07:19:33.590323Z","iopub.execute_input":"2021-07-04T07:19:33.590651Z","iopub.status.idle":"2021-07-04T07:19:33.694143Z","shell.execute_reply.started":"2021-07-04T07:19:33.590619Z","shell.execute_reply":"2021-07-04T07:19:33.693035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### dropping nan/ null value columns","metadata":{}},{"cell_type":"code","source":"df.dropna()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T07:19:33.696242Z","iopub.execute_input":"2021-07-04T07:19:33.696569Z","iopub.status.idle":"2021-07-04T07:19:33.737971Z","shell.execute_reply.started":"2021-07-04T07:19:33.696538Z","shell.execute_reply":"2021-07-04T07:19:33.737068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### text cleaning ","metadata":{}},{"cell_type":"markdown","source":"##### importing required functions from nltk(most used libaray for text analysis)","metadata":{}},{"cell_type":"code","source":"from nltk import PorterStemmer\nfrom nltk import WordNetLemmatizer\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom nltk.corpus import stopwords","metadata":{"execution":{"iopub.status.busy":"2021-07-04T07:19:33.740181Z","iopub.execute_input":"2021-07-04T07:19:33.740642Z","iopub.status.idle":"2021-07-04T07:19:33.744655Z","shell.execute_reply.started":"2021-07-04T07:19:33.740607Z","shell.execute_reply":"2021-07-04T07:19:33.743827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.description","metadata":{"execution":{"iopub.status.busy":"2021-07-04T07:19:33.745863Z","iopub.execute_input":"2021-07-04T07:19:33.74631Z","iopub.status.idle":"2021-07-04T07:19:33.764189Z","shell.execute_reply.started":"2021-07-04T07:19:33.746267Z","shell.execute_reply":"2021-07-04T07:19:33.762685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### firstly we need to remove stopwords ie words of no use in this columns","metadata":{}},{"cell_type":"code","source":"list_of_sw= stopwords.words('english')\nprint(list_of_sw)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T07:19:33.765823Z","iopub.execute_input":"2021-07-04T07:19:33.766379Z","iopub.status.idle":"2021-07-04T07:19:33.78567Z","shell.execute_reply.started":"2021-07-04T07:19:33.766338Z","shell.execute_reply":"2021-07-04T07:19:33.784228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def no_sw(input):\n    words= input.lower()\n    words= input.split()\n    noise_free_words= [word for word in words if word not in stopwords.words('english')]\n    noise_free_text= ' '.join(noise_free_words)\n    return noise_free_text","metadata":{"execution":{"iopub.status.busy":"2021-07-04T07:19:33.787762Z","iopub.execute_input":"2021-07-04T07:19:33.788308Z","iopub.status.idle":"2021-07-04T07:19:33.797258Z","shell.execute_reply.started":"2021-07-04T07:19:33.788255Z","shell.execute_reply":"2021-07-04T07:19:33.796267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"no_sw(df.description[0])","metadata":{"execution":{"iopub.status.busy":"2021-07-04T07:19:33.798977Z","iopub.execute_input":"2021-07-04T07:19:33.799665Z","iopub.status.idle":"2021-07-04T07:19:33.818705Z","shell.execute_reply.started":"2021-07-04T07:19:33.799617Z","shell.execute_reply":"2021-07-04T07:19:33.817813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## for comparison\n\ndf.description[0]","metadata":{"execution":{"iopub.status.busy":"2021-07-04T07:19:33.820202Z","iopub.execute_input":"2021-07-04T07:19:33.820514Z","iopub.status.idle":"2021-07-04T07:19:33.83183Z","shell.execute_reply.started":"2021-07-04T07:19:33.820483Z","shell.execute_reply":"2021-07-04T07:19:33.830754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### using this function we can apply stopword removal only in particular record, lets see how to remove this from whole column","metadata":{"execution":{"iopub.status.busy":"2021-07-04T07:07:18.385767Z","iopub.execute_input":"2021-07-04T07:07:18.386237Z","iopub.status.idle":"2021-07-04T07:07:18.391254Z","shell.execute_reply.started":"2021-07-04T07:07:18.386196Z","shell.execute_reply":"2021-07-04T07:07:18.389671Z"}}},{"cell_type":"markdown","source":"#### lets apply lemmatizer & stopwords operation","metadata":{}},{"cell_type":"code","source":"lm = WordNetLemmatizer()\nps=PorterStemmer()\ndef clean_text(column):\n    corpus = []\n    for value in column:\n        # convert each word into lower case\n        value = value.lower()\n        # take only alphabets\n        value = re.sub('[^a-z]', ' ', value)\n        value = value.split()\n        # lemmatizing those words which are not stop words\n        value= [ps.stem(word) for word in value if word not in list_of_sw]\n        value = [lm.lemmatize(word) for word in value if word not in list_of_sw]\n        corpus.append(' '.join(value))\n    return corpus    \n","metadata":{"execution":{"iopub.status.busy":"2021-07-04T07:19:33.8333Z","iopub.execute_input":"2021-07-04T07:19:33.833808Z","iopub.status.idle":"2021-07-04T07:19:33.844902Z","shell.execute_reply.started":"2021-07-04T07:19:33.833767Z","shell.execute_reply":"2021-07-04T07:19:33.843778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['description']=clean_text(df.description)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T07:19:33.846576Z","iopub.execute_input":"2021-07-04T07:19:33.847198Z","iopub.status.idle":"2021-07-04T07:19:38.631265Z","shell.execute_reply.started":"2021-07-04T07:19:33.847159Z","shell.execute_reply":"2021-07-04T07:19:38.630144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### below is the description column of above data with no stopwords and lemmatized , stemmed output","metadata":{}},{"cell_type":"code","source":"df.description","metadata":{"execution":{"iopub.status.busy":"2021-07-04T07:19:38.633713Z","iopub.execute_input":"2021-07-04T07:19:38.634254Z","iopub.status.idle":"2021-07-04T07:19:38.642922Z","shell.execute_reply.started":"2021-07-04T07:19:38.63422Z","shell.execute_reply":"2021-07-04T07:19:38.641799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## wordcloud","metadata":{}},{"cell_type":"code","source":"fake_wc = WordCloud(width = 600, height = 400, \n                    background_color ='yellow', \n                  min_font_size = 10).generate(' '.join(df.description)) \n  \n# plot the WordCloud image                        \nplt.figure(figsize = (12, 6), facecolor = None) \nplt.imshow(fake_wc) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \nplt.title('Wordcloud for description')","metadata":{"execution":{"iopub.status.busy":"2021-07-04T07:19:38.644906Z","iopub.execute_input":"2021-07-04T07:19:38.645349Z","iopub.status.idle":"2021-07-04T07:19:40.637745Z","shell.execute_reply.started":"2021-07-04T07:19:38.645305Z","shell.execute_reply":"2021-07-04T07:19:40.636891Z"},"trusted":true},"execution_count":null,"outputs":[]}]}