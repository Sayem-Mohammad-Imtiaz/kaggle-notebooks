{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_bcell=pd.read_csv(\"../input/epitope-prediction/input_bcell.csv\")\ndf_covid=pd.read_csv(\"../input/epitope-prediction/input_covid.csv\")\ndf_sars=pd.read_csv(\"../input/epitope-prediction/input_sars.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# BCELL","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bcell.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bcell.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bcell.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bcell.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelEncoder_Y=LabelEncoder()\ndf_bcell.iloc[:,0]=labelEncoder_Y.fit_transform(df_bcell.iloc[:,0].values)\ndf_bcell.iloc[:,1]=labelEncoder_Y.fit_transform(df_bcell.iloc[:,1].values)\ndf_bcell.iloc[:,4]=labelEncoder_Y.fit_transform(df_bcell.iloc[:,4].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bcell.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bcell.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualize the correlation\nplt.figure(figsize=(10,10))\nsns.heatmap(df_bcell.corr(), annot=True,fmt=\".0%\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# COVID","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_covid.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_covid.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_covid.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_covid.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelEncoder_Y=LabelEncoder()\ndf_covid.iloc[:,0]=labelEncoder_Y.fit_transform(df_covid.iloc[:,0].values)\ndf_covid.iloc[:,1]=labelEncoder_Y.fit_transform(df_covid.iloc[:,1].values)\ndf_covid.iloc[:,4]=labelEncoder_Y.fit_transform(df_covid.iloc[:,4].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_covid.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_covid.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualize the correlation\nplt.figure(figsize=(10,10))\nsns.heatmap(df_covid.corr(), annot=True,fmt=\".0%\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SARS","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sars.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sars.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sars.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sars.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelEncoder_Y=LabelEncoder()\ndf_sars.iloc[:,0]=labelEncoder_Y.fit_transform(df_sars.iloc[:,0].values)\ndf_sars.iloc[:,1]=labelEncoder_Y.fit_transform(df_sars.iloc[:,1].values)\ndf_sars.iloc[:,4]=labelEncoder_Y.fit_transform(df_sars.iloc[:,4].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sars.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sars.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualize the correlation\nplt.figure(figsize=(10,10))\nsns.heatmap(df_sars.corr(), annot=True,fmt=\".0%\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# BCELL VS COVID","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split the data set into independent(x) and dependent (y) data sets\nx=df_bcell.iloc[:,1:14].values\ny=df_bcell.iloc[:,0].values.reshape(-1,1)\nx_test  = df_covid.drop(\"parent_protein_id\",axis=1).copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test=train_test_split(x,y,test_size=0.469,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scale the data(feature scaling)\nfrom sklearn.preprocessing import StandardScaler\n\nsc=StandardScaler()\nx_train=sc.fit_transform(x_train)\nx_test=sc.fit_transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def models(x_train,y_train):\n  #Logistic Regression Model\n  from sklearn.linear_model import LogisticRegression\n  log=LogisticRegression(random_state=42)\n  log.fit(x_train,y_train)\n  \n  #Decision Tree\n  from sklearn.tree import DecisionTreeClassifier\n  tree=DecisionTreeClassifier(criterion='entropy',random_state=0)\n  tree.fit(x_train,y_train)\n  \n  #Random Forest Classifier\n  from sklearn.ensemble import RandomForestClassifier\n  forest = RandomForestClassifier(n_estimators=15,criterion=\"entropy\",random_state=0)\n  forest.fit(x_train,y_train)\n\n  #Print the models accuracy on the training data\n  print(\"[0]Logistic Regression Training Accuracy:\",log.score(x_train,y_train))\n  print(\"[1]Decision Tree Classifier Training Accuracy:\",tree.score(x_train,y_train))\n  print(\"[2]Random Forest Classifier Training Accuracy:\",forest.score(x_train,y_train))\n  \n  return log,tree,forest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting all of the models\nmodel = models(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test model accuracy on confusion matrix\nfrom sklearn.metrics import confusion_matrix\n\n\nfor i in range(len(model)):\n  print(\"Model \", i)\n  cm =confusion_matrix(y_test,model[i].predict(x_test))\n\n  TP=cm[0][0]\n  TN=cm[1][1]\n  FN=cm[1][0]\n  FP=cm[0][1]\n\n  print(cm)\n  print(\"Testing Accuracy = \", (TP+TN) / (TP+TN+FN+FP))\n  print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#show another way to get metrics of the models\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\nfor i in range(len(model) ):\n  print(\"Model \",i)\n  print( classification_report(y_test,model[i].predict(x_test)))\n  print( accuracy_score(y_test,model[i].predict(x_test)))\n  print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=model[2].predict(x_test)\nprint(pred)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}