{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior() \nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/default-of-credit-card-clients-dataset/UCI_Credit_Card.csv\", index_col=\"ID\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Kontrol\n\n## Anormallikler\n\nİçe aktarılan veri seti içerisindeki gözlemlerde değişkenlerin aldığı değerlerin veri sağlayıcısı tarafından verilen bilgiler ile uyuşup uyuşmadığının kontrolü."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Kategorik veriler için kurallar\ncategoric_attribute_information = {\n    \"SEX\": [1,2],\n    \"EDUCATION\": [1, 2, 3, 4],\n    \"MARRIAGE\": [1, 2, 3]\n}\n\nfor column in categoric_attribute_information.keys():\n    unique_values = list(set(df[column].tolist()))\n    if unique_values == categoric_attribute_information[column]:\n        print(\"DOĞRU\", column, categoric_attribute_information[column], \"==\", unique_values, \"\\n\")\n    else:\n        print(\"HATA!\", column, categoric_attribute_information[column], \"!=\", unique_values, \"\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Burada cinsiyet verisini içeren değişkene ait gözlemlerde bir anormallik olmadığı tespit edildi fakat hem eğitim seviyesi hem de medeni durum değişkenlerine ait gözlemlerde ortak olarak 0 kategorisi veri sağlayıcısı tarafından verilen kategoriler arasında yer almamaktadır. Bu kategori eğitim seviyesi ve medeni durumun belirtilmediğini ifade ediyor olabilir.\n\nEğitim durumunda ise diğer diye bir kategori olmasına rağmen 5 ve 6 olmak üzere fazladan iki kategori daha olduğu tespit edildi. Daha sonradan eklenmiş kategoriler olabilir. Bunlar ile tüm anormallikleri tespit ettikten sonra ilgileneceğim.\n<hr>\nVeri sağlayısı tarafından yaş değişkeninin alabileceği değerler hakkında bir bilgi verilmemiştir. Fakat bu veri setinin Taiwanda kredi kartı sahibi insan olduğunu bilerek basitçe mümkün olabilecek minimum ve maksimum yaşı araştırabiliriz. Aşağıda linki verilmiş kaynakta Taiwanda kredi kartı alabilmek için gerekli minimum yaş kriterinin 20 olduğu belirtilmekte.\n\nhttps://www.hsbc.com.tw/en-tw/credit-cards/faq/"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"En küçük yaş:\", min(df[\"AGE\"].tolist()), \"\\n\")\nprint(\"En büyük yaş:\", max(df[\"AGE\"].tolist()), \"\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Gözlemler arasındaki en küçük yaş kurala uyduğundan burada bir problem yok. En büyük yaş için bir kural yok fakat 79 değeri makul görünüyor.\n<hr>\nVeri sağlayısı tarafından PAY_0 - ... - PAY_6  değişkenleri için verilen kural aşağıdaki gibidir:"},{"metadata":{},"cell_type":"markdown","source":"$$ \ntest(x) = \\left\\{\n\\begin{array}{}\n      True & x=-1 \\\\\n      True & x>0\\\\\n\\end{array} \n\\right.\n$$"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_starts_with_pay = [column for column in df.columns if column[:4] == \"PAY_\" and len(column) == 5]\n\nfor column in columns_starts_with_pay:\n    unique_values = list(set(df[column].tolist()))\n    for value in unique_values:\n        if not ((value == -1) or (value > 0)):\n            print(\"HATA!\", column, \"=\", value)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Veri sağlayısı tarafından bu değişkenler için verilen alınabilecek değerler arasında 0 ve -2 verilmemiştir. Bu değerlerin de ne anlama geldiğini bilmiyoruz. Aşağıdaki linkte bu veri seti hakkında veri sağlayısından alınan ekstra bilgiler mevcuttur.\n\nhttps://www.kaggle.com/uciml/default-of-credit-card-clients-dataset/discussion/34608#latest-325928\n\nBu kaynağa göre anormallik tespit ettiğimiz değişkenler için veri sağlayıcısının verdiği bilgiler aşağıdaki gibidir;\n\n- X3: Education (1 = graduate school; 2 = university; 3 = high school; 0, 4, 5, 6 = others).\n- X4: Marital status (1 = married; 2 = single; 3 = divorce; 0=others).\n- X6 - X11: History of past payment (-2: No consumption; -1: Paid in full; 0: The use of revolving credit; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above).\nBurada eğitim seviyesi değişkeninde 0, 4, 5, 6 kategorilerini tek kategori altında toplamak haricinde yapılacak birşey yok gibi görünüyor.\n\nAyrıca bu veri seti içerisindeki gözlemlerin hem bireysel kredi kartı sahibi müşterilere hem de ek karta sahip müşterilere ait olabileceği bilgisi de verilmiştir bu durumda Taiwan da kredi kartı alma koşulları arasında minimum yaşın ek kart için 16 olduğu bilgisine dayanarak veri seti içerisindeki yaş aralığını tekrardan doğrulamış olduk."},{"metadata":{"trusted":true},"cell_type":"code","source":"def combine_categories(x):\n    if x in [4, 5, 6]:\n        return 0\n    else:\n        return x\n\ndf[\"EDUCATION\"] = df[\"EDUCATION\"].apply(\n    lambda x: combine_categories(x)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(set(df[\"EDUCATION\"].tolist()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Eksik Veri\nVeri seti içerisinde eksik değer içeren bir değişken ve gözlem yoktur."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ön işleme\n## Sayısallaştırma\n\nBu veri seti içerisindeki tüm değişkenler sayısaldır yani bir sayısallaştırma gereksinimi yoktur. Fakat aslında kategorik olan medeni hal değişkeni içerisindeki verilerin birbiri üzerinde bir büyüklük durumu olmadığından bu değişkeni ve ayrıca eğitim seviyesi değişkenini sayısaldan kategoriğe dönüştürüp one hot encoder ile tekrar sayısallaştıracağım."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Eğitim seviyesi kategorileri\neducation_categories = {\n    0: \"others\",\n    1: \"graduate_student\",\n    2: \"university\",\n    3: \"high_school\",\n}\n# Medeni durum kategorileri\n# Bu kategoriler yukarıda linkini verdiğim kaynağa göre veri sağlayıcısı tarafından sonradan düzeltilen kategorilerdir\nmarriage_categories = {\n    0: \"others\",\n    1: \"married\",\n    2: \"single\",\n    3: \"divorce\"\n}\n\nfor category in education_categories.keys():\n    df[\"EDUCATION\"][df[\"EDUCATION\"] == category] = education_categories[category]\n    \nfor category in marriage_categories:\n    df[\"MARRIAGE\"][df[\"MARRIAGE\"] == category] = marriage_categories[category]\n    \ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One Hot Encoder\ncategoric_variables = df.select_dtypes(\n    include=[np.object]\n).columns.tolist()\ndf = pd.get_dummies(df, prefix=categoric_variables)\n\n# Hedef değişkeni sayısaldan kategorik tipe dönüştürüldü\ndf[\"default.payment.next.month\"][df[\"default.payment.next.month\"] == 1] = \"Yes\"\ndf[\"default.payment.next.month\"][df[\"default.payment.next.month\"] == 0] = \"No\"\n\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Normalizasyon"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0 - 1 Normalizasyon\nnumeric_variables = df.select_dtypes(\n    exclude=[np.object]\n).columns.tolist()\nfor variable in numeric_variables:\n    data = list(set(df[variable].tolist()))\n    min_value = min(data)\n    max_value = max(data)\n    df[variable] = df[variable].apply(\n        lambda x: (x-min_value)/(max_value-min_value)\n    )\n    \ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelleme\n## Hedef Kategorilerin Dağılımı\nHedef değişkenin kategorileri arasındaki orana bakıldığında dengesiz bir dağılım olduğu görülmektedir. Bu durum oluşacak modelin başarısını negatif etkileyecektir."},{"metadata":{"trusted":true},"cell_type":"code","source":"count_yes = df[\"default.payment.next.month\"].tolist().count(\"Yes\")\ncount_no = df[\"default.payment.next.month\"].tolist().count(\"No\")\nprint(\"Yes sayısı:\", count_yes)\nprint(\" No sayısı:\", count_no)\nprint(\" Yes oranı:\", count_yes / (count_yes+count_no))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Verinin Eğitim İçin Hazırlanması"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.rename(columns={\"default.payment.next.month\": \"target\"})\n\nX = df.drop(columns=[\"target\"]).values\ny = df.filter([\"target\"])\ny = pd.get_dummies(y, prefix=[\"target\"]).values\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=42\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"split = int(len(y_test)/2)\ninputX = X_train\ninputY = y_train\ninputX_valid = X_test[:split]\ninputY_valid = y_test[:split]\ninputX_test = X_test[split:]\ninputY_test = y_test[split:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_nodes = inputX.shape[1]\n\nmultiplier = 3\n\nhidden_nodes1 = input_nodes\nhidden_nodes2 = round(hidden_nodes1 * multiplier)\nhidden_nodes3 = round(hidden_nodes2 * multiplier)\n\npkeep = tf.placeholder(tf.float32)\n\n# Input\nx = tf.placeholder(tf.float32, [None, input_nodes])\n\n# Layer 1\nW1 = tf.Variable(tf.truncated_normal([input_nodes, hidden_nodes1], stddev = 0.15))\nb1 = tf.Variable(tf.zeros([hidden_nodes1]))\ny1 = tf.nn.sigmoid(tf.matmul(x, W1) + b1)\n\n# Layer 2\nW2 = tf.Variable(tf.truncated_normal([hidden_nodes1, hidden_nodes2], stddev = 0.15))\nb2 = tf.Variable(tf.zeros([hidden_nodes2]))\ny2 = tf.nn.sigmoid(tf.matmul(y1, W2) + b2)\n\n# Layer 3\nW3 = tf.Variable(tf.truncated_normal([hidden_nodes2, hidden_nodes3], stddev = 0.15)) \nb3 = tf.Variable(tf.zeros([hidden_nodes3]))\ny3 = tf.nn.sigmoid(tf.matmul(y2, W3) + b3)\ny3 = tf.nn.dropout(y3, pkeep)\n\n# Layer 4\nW4 = tf.Variable(tf.truncated_normal([hidden_nodes3, 2], stddev = 0.15)) \nb4 = tf.Variable(tf.zeros([2]))\ny4 = tf.nn.softmax(tf.matmul(y3, W4) + b4)\n\n# Output\ny = y4\ny_ = tf.placeholder(tf.float32, [None, 2])\n\ntraining_epochs = 100\ntraining_dropout = 0.9\ndisplay_step = 10\nn_samples = y_train.shape[0]\nbatch_size = 2048\nlearning_rate = 0.01\n\n# Cross entropy\ncost = -tf.reduce_sum(y_ * tf.log(y))\n\noptimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n\ncorrect_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\naccuracy_summary = []\ncost_summary = []\nvalid_accuracy_summary = [] \nvalid_cost_summary = [] \nstop_early = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    \n    for epoch in range(training_epochs):\n        for batch in range(int(n_samples/batch_size)):\n            batch_x = inputX[batch*batch_size : (1+batch)*batch_size]\n            batch_y = inputY[batch*batch_size : (1+batch)*batch_size]\n            \n            sess.run([optimizer], feed_dict={\n                x: batch_x,\n                y_: batch_y,\n                pkeep: training_dropout\n            })\n            \n        if (epoch) % display_step == 0:\n            train_accuracy, newCost = sess.run([accuracy, cost], feed_dict={\n                x: inputX,\n                y_: inputY,\n                pkeep: training_dropout\n            })\n            \n            valid_accuracy, valid_newCost = sess.run([accuracy, cost], feed_dict={\n                x: inputX_valid,\n                y_: inputY_valid,\n                pkeep: 1\n            })\n            \n            print(\n                \"Epoch:\", epoch,\n                \"Acc =\", \"{:.5f}\".format(train_accuracy),\n                \"Cost =\", \"{:.5f}\".format(newCost),\n                \"Valid_Acc =\", \"{:.5f}\".format(valid_accuracy),\n                \"Valid_Cost = \", \"{:.5f}\".format(valid_newCost)\n            )\n            \n            accuracy_summary.append(train_accuracy)\n            cost_summary.append(newCost)\n            valid_accuracy_summary.append(valid_accuracy)\n            valid_cost_summary.append(valid_newCost)\n            \n            if valid_accuracy < max(valid_accuracy_summary) and epoch > 100:\n                stop_early += 1\n                if stop_early == 15:\n                    break\n            else:\n                stop_early = 0\n                \n    print(\"Optimization Finished!\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Başarısı\nTest için olan cost ve accuracy mavi renkte, validasyon için gösterilen cost ve accuracy ise yeşil renktedir."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n\naxes[0].set_ylabel(\"Cost\", fontsize=14)\naxes[0].plot(cost_summary, color='blue')\naxes[0].plot(valid_cost_summary, color='green')\n\naxes[1].set_ylabel(\"Accuracy\", fontsize=14)\naxes[1].set_xlabel(\"Epoch\", fontsize=14)\naxes[1].plot(accuracy_summary, color='blue')\naxes[1].plot(valid_accuracy_summary, color='green')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tensorflow model inspired by [Ilias Siamplis](https://www.kaggle.com/isiablis)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}