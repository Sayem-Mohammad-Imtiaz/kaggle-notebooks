{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport bqplot\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\nimport sklearn\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nprint(\"Setup Complete\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"order_products_train_df = pd.read_csv(\"../input/instacart-market-basket-analysis/order_products__train.csv\")\norder_products_prior_df = pd.read_csv(\"../input/instacart-market-basket-analysis/order_products__prior.csv\")\norders_df = pd.read_csv(\"../input/instacart-market-basket-analysis/orders.csv\")\nproducts_df = pd.read_csv(\"../input/instacart-market-basket-analysis/products.csv\")\naisles_df = pd.read_csv(\"../input/instacart-market-basket-analysis/aisles.csv\")\ndepartments_df = pd.read_csv(\"../input/instacart-market-basket-analysis/departments.csv\")\nprint(\"Setup Complete\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"order_products_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"order_products_prior_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"orders_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"products_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aisles_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"departments_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merging csv files\n# what day of the week is 1 in order_dow? Sunday or Monday?\n# reordered appears to work in binary 1s and 0s. 1 means yes?\n# add_to_cart_order refers to the order in which the product was added to the cart.\n# the amount of each product added to each order/cart is not provided.\n\norder_products_prior_df = pd.merge(order_products_prior_df, products_df, on='product_id', how='left')\norder_products_prior_df = pd.merge(order_products_prior_df, orders_df, on='order_id', how='left')\norder_products_prior_df = pd.merge(order_products_prior_df, aisles_df, on='aisle_id', how='left')\norder_products_prior_df = pd.merge(order_products_prior_df, departments_df, on='department_id', how='left')\norder_products_prior_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"order_products_prior_df['product_id'] == 33120","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sorts out product with the product id of 33120\n# loc gets rows with particular labels in it\negg_whites_order_info = order_products_prior_df.loc[order_products_prior_df['product_id'] == 33120, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# All egg whites purchased on a Sunday or Monday (what the first day of the week is).\n    # While not super useful now, it might be something to keep in mind. Also, this is currently not sorted in any way.\n# Data not given: is the week beginning on Sunday or Monday for order_dow? \n# Interesting idea: making a chart that sorts orders by order_dow.\negg_whites_order_info.loc[egg_whites_order_info['order_dow'] == 1, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# orders the egg whites orders by ascending value of user id (user id 155 likes the egg whites)\nsorted_egg_whites = egg_whites_order_info.sort_values('user_id', ascending = True)\nsorted_egg_whites","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gives the first 15 rows of the previous chart. While the data in this chart isn't the most useful\n    # it is useful in that I definitely will need to use iloc later. So this is more for myself than anything.\n# iloc gets index position\n# What is the difference between .head() and .iloc[]? So far, they appear to be interchangeable.\n# Correction from earlier block: User 155 loves egg whites. (total of 14 separate orders that began on their 2nd order.)\nsorted_egg_whites.iloc[0:15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This is how many times a specific product is on an order\n# well, this looks weird, but despite the count being in every column, the count is correct.\n# is there a nicer way of coding this that's less messy? Yes, see next block.\n# also, there are 49,677 unique product names in this dataset.\nproduct_count = order_products_prior_df.groupby('product_name').count()\nproduct_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# quick test to check count\nmech_pencil_orders = order_products_prior_df.loc[order_products_prior_df['product_name'] == '#2 Mechanical Pencils', :]\nmech_pencil_orders.product_name.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking for null values\n# I'm beginning to think that axis = 0 refers to columns and axis = 1 means rows\n# This may mean that days_since_prior_order may have null values\n\nnull_value_columns = order_products_prior_df.isnull().any(axis = 0)\nprint(null_value_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# list of all rows containing a null value. In this case, the nulls appear to be in days_since_prior_order.\n# This makes sense since a new customer wouldn't have an order prior to their first.\n# This means there are likely over 2 million new customers in this dataset. See row count of 2,078,068 at bottom.\nnull_value_rows = order_products_prior_df.isnull().any(axis = 1)\norder_products_prior_df[null_value_rows]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shows unique product names\n# semi-failed attempt at data cleaning\n# this was an attempt to make sure everything is spelled correctly, but that didn't work since I can't see all the names in the list in Kaggle.\nunique_product_names = order_products_prior_df['product_name'].unique()\nunique_product_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting a single row for each order_id in prior set, not training set\n# useful for seeing order_id with the order_dow, order_hour_of_day, and days_since_prior_order\n\norder_id_groups = order_products_prior_df.groupby('order_id').first()\norder_id_sorted_groups = order_id_groups.sort_values('order_id', ascending = True)\norder_id_sorted_groups","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Well, this way was easier than the prior block. This includes training data, though.\n# I organized it to makes sure I wasn't getting duplicates of order ids\norders_df.sort_values('order_id', ascending = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15,8))\nsns.countplot(x = 'days_since_prior_order', data = orders_df)\nplt.ylabel('Count')\nplt.xlabel('Days since prior order')\nplt.title('Frequency of days since prior order')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,8))\nsns.countplot(x = \"order_hour_of_day\", data = orders_df)\nplt.ylabel('Count')\nplt.xlabel('Hour of day')\nplt.title(\"Frequency of orders by hour of day\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Info learned: days of the week start from 0 and go to 6. Does not start on 1 like originally thought.\n# Still unknown if 0 represents Sunday or Monday\n# counts each individual order including orders from the training data as well as prior data.\n\nplt.figure(figsize = (12,8))\nsns.countplot(x = 'order_dow', data = orders_df)\nplt.ylabel('Count')\nplt.xlabel('Day of the week')\nplt.title('Frequency of orders each day of the week')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}