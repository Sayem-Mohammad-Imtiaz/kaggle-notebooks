{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{},"cell_type":"markdown","source":"**Objective:** To build Logistic Regression model for classification using scikitlearn.\n\n**Secondary Objectives:** \n* To study sigmoid function , maximum likelihood estimation.\n* To study confusion matrix and ROC curve.\n"},{"metadata":{},"cell_type":"markdown","source":"Logistic regression is a statistical method for predicting binary classes. The output variable has two possible outcomes 0 or 1. **For example:** Email Spam Filter,Transaction is fraudulent, Yes/No ,Tumor is Benign/Malignant.\n\n\nLogistics regression majorly makes predictions to handle problems which require a probability estimate as output, in the form of 0/1. It is a special case of linear regression where the output variable is categorical in nature,like married /unmarried/divorced such scenarios are classified as multinomial logistic regression.\n\n**Linear Regression Equation:**\n![![image.png](attachment:image.png)](https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1534281880/image1_ga8gze.png)\n\nWhere, y is dependent variable and x1, x2 ... and Xn are explanatory variables.\n\n\n**Sigmoid Function:**\nThe sigmoid function, also called logistic function gives an ‘S’ shaped curve that can take any real-valued number and map it into a value between 0 and 1. If the curve goes to positive infinity, y predicted will become 1, and if the curve goes to negative infinity, y predicted will become 0. If the output of the sigmoid function is more than 0.5, we can classify the outcome as 1 or YES, and if it is less than 0.5, we can classify it as 0 or NO.\n\n![![image.png](attachment:image.png)](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1534281880/image2_kwxquj.png)\n\n![![image.png](attachment:image.png)](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1534281070/sigmoid2_lv4c7i.png)\n\n**Applying Sigmoid function on linear equation:**\n![![image.png](attachment:image.png)](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1534281880/image3_qldafx.png)\n\n**Maximum Likelihood Estimation:** Maximizing the likelihood function determines the parameters that are most likely to produce the observed data. From a statistical point of view, MLE sets the mean and variance as parameters in determining the specific parametric values for a given model. This set of parameters can be used for predicting the data needed in a normal distribution.\n\n\n**Types of Logistic Regression:**\n\n**Binary Logistic Regression:** The target variable has only two possible outcomes such as Spam or Not Spam, Cancer or No Cancer.\n\n**Multinomial Logistic Regression:** The target variable has three or more nominal categories such as predicting the type of Wine.\n\n**Ordinal Logistic Regression:** The target variable has three or more ordinal categories such as restaurant or product rating from 1 to 5.\n"},{"metadata":{},"cell_type":"markdown","source":"Here I am going to use Insurance dataset for Logistic Regression classification which tells  insurance bought by a customer on the basis of age."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\ndf = pd.read_csv('../input/insurance/insurance_data.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df.plot.scatter(x='age',y='bought_insurance')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model Building using scikit learn:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\ny = df['bought_insurance']\nX = sm.add_constant(df[['age']])\nmod = sm.Logit(y,X)\nresult= mod.fit()\nprint(result.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nlogreg = LogisticRegression()\nlogreg.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = logreg.predict(X)\nprint('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X, y)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The confusion matrix:** \nIt shows the ways in which your classification model is confused when it makes predictions on observations, it helps us to measure the type of error our model is making while classifying the observation into different classes.\n\n**Key Parts Of Confusion Matrix:**\n\n**True Positive (TP):** This refers to the cases in which we predicted “YES” and our prediction was actually TRUE\n\n**True Negative (TN):** This refers to the cases in which we predicted “NO” and our prediction was actually TRUE\n\n**False Positive (FP):** This refers to the cases in which we predicted “YES”, but our prediction turned out FALSE\n\n**False Negative (FN):** This refers to the cases in which we predicted “NO” but our prediction turned out FALSE\n\n\n**Key Learning Metrics From Confusion Matrix:**\n\n![![image.png](attachment:image.png)](https://www.researchgate.net/profile/Ibrahim_Gad3/post/What_is_the_best_metric_precision_recall_f1_and_accuracy_to_evaluate_the_machine_learning_model_for_imbalanced_data/attachment/5f0d92695e3fff000177fe28/AS%3A913156859777024%401594724969138/download/accuracy.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix = confusion_matrix(y, y_pred)\nprint(confusion_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.heatmap(pd.DataFrame(confusion_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual')\nplt.xlabel('Predicted')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One more useful metric to evaluate and compare predictive models is the\n\n**ROC Curve:**\n\nIn statistics, a Receiver Operating Characteristic (ROC), or ROC curve, is a graphical plot that illustrates the performance of a binary classifier system. The curve is created by plotting the true positive rate (sensitivity) against the false positive rate (1 — specificity) at various threshold settings.The model which predicts at chance will have a ROC curve that looks like the diagonal green line. That is not a discriminating model. The further the curve is from the diagonal line, the better the model is at discriminating between positives and negatives in general.\n\nWhere,\n**Specificity or True Negative Rate = TN/(TN+FP)\nSensitivity or True Positive Rate= TP/(TP+FN)\nSo, False Positive Rate = 1–Specificity**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\n\ny_pred_proba = logreg.predict_proba(X)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y,  y_pred_proba)\nauc = metrics.roc_auc_score(y, y_pred_proba)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion:** Thus, we have build a classification model with 89% accuracy. The area under the ROC curve is 0.89."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}