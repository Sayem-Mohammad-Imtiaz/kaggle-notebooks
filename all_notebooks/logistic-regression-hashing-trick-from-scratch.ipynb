{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Logistic Regression from scratch with SGD + Hashing trick","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport re\nfrom tqdm.notebook import tqdm\nimport math\nimport sklearn\ntqdm.pandas()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-25T15:48:07.479791Z","iopub.execute_input":"2021-07-25T15:48:07.48022Z","iopub.status.idle":"2021-07-25T15:48:08.565458Z","shell.execute_reply.started":"2021-07-25T15:48:07.480125Z","shell.execute_reply":"2021-07-25T15:48:08.564689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\n\nlemmatizer = WordNetLemmatizer()\n\ndef lemmatize_sentence(sentence):\n    return \" \".join([lemmatizer.lemmatize(t) for t in sentence.split()])\n\ndef simple_clean(text):\n    text = text.lower()\n    text = re.sub(r\"[^a-z ]+\", \" \", text)\n    return lemmatize_sentence(text)\ndef encode_sentiment(text):\n    if text == \"positive\":\n        return 1\n    elif text == \"negative\":\n        return 0\n    else:\n        print(\"error\")\ndef decode_sentiment(number):\n    if number == 1:\n        return \"positive\"\n    elif number == 0:\n        return \"negative\"","metadata":{"execution":{"iopub.status.busy":"2021-07-25T15:48:08.566962Z","iopub.execute_input":"2021-07-25T15:48:08.567505Z","iopub.status.idle":"2021-07-25T15:48:09.146342Z","shell.execute_reply.started":"2021-07-25T15:48:08.567463Z","shell.execute_reply":"2021-07-25T15:48:09.145331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-07-25T15:48:09.148392Z","iopub.execute_input":"2021-07-25T15:48:09.149005Z","iopub.status.idle":"2021-07-25T15:48:10.792453Z","shell.execute_reply.started":"2021-07-25T15:48:09.14896Z","shell.execute_reply":"2021-07-25T15:48:10.791693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"sentiment_value\"] = df[\"sentiment\"].apply(encode_sentiment)\ndf[\"review_clean\"] = df[\"review\"].progress_apply(simple_clean)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T15:48:10.794068Z","iopub.execute_input":"2021-07-25T15:48:10.794649Z","iopub.status.idle":"2021-07-25T15:49:20.511783Z","shell.execute_reply.started":"2021-07-25T15:48:10.794584Z","shell.execute_reply":"2021-07-25T15:49:20.510617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize(text):\n    tokens = []\n    one_gram = text.split(\" \")\n    for i in range(len(one_gram)-1):\n        tokens.append(one_gram[i]+\" \"+one_gram[i+1])\n    tokens += one_gram\n    return tokens\n\ndef hash_trick(tokens,dim=512):\n    arr = np.zeros((dim))\n    for t in tokens:\n        h = sklearn.utils.murmurhash3_32(t)\n        if h >= 0:\n            arr[h%dim] += 1\n        else:\n            arr[abs(h)%dim] -= 1\n    return arr\n\ndef preprocess(batch_text,dim=512):\n    return np.concatenate([np.expand_dims(hash_trick(tokenize(t),dim),0) for t in batch_text],axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T15:49:20.513286Z","iopub.execute_input":"2021-07-25T15:49:20.513899Z","iopub.status.idle":"2021-07-25T15:49:20.52305Z","shell.execute_reply.started":"2021-07-25T15:49:20.513853Z","shell.execute_reply":"2021-07-25T15:49:20.521953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(df[\"review_clean\"].values,df[\"sentiment_value\"].values, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T15:49:20.526191Z","iopub.execute_input":"2021-07-25T15:49:20.526471Z","iopub.status.idle":"2021-07-25T15:49:20.540624Z","shell.execute_reply.started":"2021-07-25T15:49:20.526438Z","shell.execute_reply":"2021-07-25T15:49:20.53937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sigmoid(x):\n    x = np.where(x >= 0, \n                    1 / (1 + np.exp(-x)), \n                    np.exp(x) / (1 + np.exp(x)))\n    return np.clip(x,0,1)\n\ndef loss(y_prob,y_true):\n    y_prob = np.clip(y_prob,0.0000001,0.9999999)\n    return -np.mean(y_true*(np.log(y_prob)) + (1-y_true)*np.log(1-y_prob))\n\nclass LogRegModel:\n    def __init__(self,size_w):\n        self.w = np.random.randn(size_w)\n        self.b = 0\n        self.mw = np.zeros_like(self.w)\n        self.mb = 0\n    \n    def forward(self,x):\n        return sigmoid(x.dot(self.w) + self.b)\n    \n    def update(self,x,y_true,lr,reg=0.1):\n        \"\"\"no autograd here so need to pass in true and predicted values\"\"\"\n        bs = y_true.shape[0]\n        y_prob = self.forward(x)\n        batch_loss = loss(y_prob,y_true)\n        dw = 1/bs * (x.T.dot(y_prob-y_true) + reg*self.w)\n        db = 1/bs * np.sum(y_prob-y_true)\n        # momentum\n        self.mw = 0.9*self.mw + 0.1*dw\n        self.mb = 0.9*self.mb + 0.1*db\n        \n        self.w -= lr*self.mw\n        self.b -= lr*self.mb\n        return batch_loss","metadata":{"execution":{"iopub.status.busy":"2021-07-25T16:48:04.035412Z","iopub.execute_input":"2021-07-25T16:48:04.035755Z","iopub.status.idle":"2021-07-25T16:48:04.047243Z","shell.execute_reply.started":"2021-07-25T16:48:04.035728Z","shell.execute_reply":"2021-07-25T16:48:04.046293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2021-07-25T16:48:05.266873Z","iopub.execute_input":"2021-07-25T16:48:05.267198Z","iopub.status.idle":"2021-07-25T16:48:05.273208Z","shell.execute_reply.started":"2021-07-25T16:48:05.267172Z","shell.execute_reply":"2021-07-25T16:48:05.272272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 20\nbatch_size = 100\ndim = 16384\nmodel = LogRegModel(dim)\nlr = 1\navg_meter = AverageMeter()\n\nnum_batches = math.ceil(X_train.shape[0]/batch_size)\nfor epoch in range(epochs):    \n    tk = tqdm(range(num_batches))\n    total_loss = 0\n    perm = np.arange(X_train.shape[0])\n    np.random.shuffle(perm)\n    shuffled_x = X_train[perm]\n    shuffled_y = y_train[perm]\n    avg_meter.reset()\n    # Training\n    for i in tk:\n        x_batch = shuffled_x[i*batch_size:(i+1)*batch_size]\n        x_batch = preprocess(x_batch,dim)\n        y_batch = shuffled_y[i*batch_size:(i+1)*batch_size]\n        \n        batch_loss = model.update(x_batch,y_batch,lr)\n        avg_meter.update(batch_loss,x_batch.shape[0])\n        total_loss += batch_loss\n        tk.set_postfix({'loss':avg_meter.avg})\n    # validation\n    y_prob = model.forward(preprocess(X_test,dim))\n    val_loss = loss(y_prob,y_test)\n    val_acc = ((y_prob>0.5) == y_test).mean().item()\n    print(f\"Epoch: {epoch} Training Loss:{total_loss/num_batches} validation_loss:{val_loss} validation accuracy:{val_acc}\")\n    \n    if epoch%5==0:\n        lr *= 0.5","metadata":{"execution":{"iopub.status.busy":"2021-07-25T16:48:06.843511Z","iopub.execute_input":"2021-07-25T16:48:06.843902Z","iopub.status.idle":"2021-07-25T17:13:04.542639Z","shell.execute_reply.started":"2021-07-25T16:48:06.843869Z","shell.execute_reply":"2021-07-25T17:13:04.541265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.forward(preprocess(X_test,dim)) > 0.5","metadata":{"execution":{"iopub.status.busy":"2021-07-25T17:22:19.769297Z","iopub.execute_input":"2021-07-25T17:22:19.769653Z","iopub.status.idle":"2021-07-25T17:22:32.49722Z","shell.execute_reply.started":"2021-07-25T17:22:19.769623Z","shell.execute_reply":"2021-07-25T17:22:32.495932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-07-25T17:22:34.726088Z","iopub.execute_input":"2021-07-25T17:22:34.726425Z","iopub.status.idle":"2021-07-25T17:22:34.756435Z","shell.execute_reply.started":"2021-07-25T17:22:34.726397Z","shell.execute_reply":"2021-07-25T17:22:34.755559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}