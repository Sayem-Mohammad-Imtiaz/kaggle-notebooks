{"cells":[{"metadata":{},"cell_type":"markdown","source":"The SMS Spam Collection is a set of SMS tagged messages that have been collected for SMS Spam research. It contains one set of SMS messages in English, tagged acording being ham (legitimate) or spam. The challenge is classify messages Spam there of not.  \nFirst of all, let's read full datasets from CSV file using pandas lib."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\ndf = pd.read_csv(\"../input/sms-spam-collection-dataset/spam.csv\", encoding = 'latin-1', usecols=[0,1])\ndf.columns = ['category', 'message']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Initially target column has two values 'spam' and 'ham'. Encode it to numeric column."},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode_category(cat):\n    if cat == 'spam':\n        return 1\n    else:\n        return 0\n    \ndf['category'] = df['category'].apply(encode_category)\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Convert Message text to features columns using CountVectorizer, based on token occurrence counts.  \nAlso I tried using TfidfVectorizer, but accuracy didn't improve.  \nI tried to add new feature 'Length of message'. And this also didn't provide any benefits to final accuracy."},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.sparse import hstack\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nvectorizer = CountVectorizer(encoding = \"latin-1\", strip_accents = \"unicode\", stop_words = \"english\")\n\nfeatures = vectorizer.fit_transform(df[\"message\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split all data to train and validation datasets. Use Stratify parameter to keep proportion of Spam/Ham values in training data same as in validation dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(features, df[\"category\"], stratify = df[\"category\"], test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Trying to use most appropriate classifiers for test data processing: MultinomialNB and SGDClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn import metrics\nmn_clf = MultinomialNB().fit(X_train, y_train)\n\ny_pred = mn_clf.predict(X_test)\n\nprint(\"Classifier %s:\\n%s\"\n      % (mn_clf, metrics.classification_report(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nsgd_clf = SGDClassifier().fit(X_train, y_train)\n\ny_pred = sgd_clf.predict(X_test)\nprint(\"Classifier %s:\\n%s\"\n      % (sgd_clf, metrics.classification_report(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SGDClassifier wins!\nTrying to fing best hyperparameters using GridSearchCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparams = {\n    \"loss\" : [\"hinge\"],\n    \"alpha\" : [0.0001, 0.001, 0.01, 0.1],\n    \"penalty\" : [\"l2\", \"l1\", \"none\"],\n}\n\nsgd_clf = SGDClassifier()\ngs_clf = GridSearchCV(sgd_clf, param_grid=params)\n\ngs_clf.fit(X_train, y_train)\nprint(gs_clf.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Getting final score with best parameters."},{"metadata":{"trusted":true},"cell_type":"code","source":"sgd_clf = SGDClassifier(**gs_clf.best_params_).fit(X_train, y_train)\n\ny_pred = sgd_clf.predict(X_test)\nprint(\"Best for classifier %s:\\n%s\"\n      % (sgd_clf, metrics.classification_report(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's take a look at messages falsely recognized as Spam."},{"metadata":{"trusted":true},"cell_type":"code","source":"false_pos = list(y_test[(y_test != y_pred) & (y_pred == 1)].index)\nprint(\"False spam:\", df.iloc[false_pos]['message'].values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No false Spam messages! This is unexected but great result.  \nLet's find messages falsely recognized as not Spam."},{"metadata":{"trusted":true},"cell_type":"code","source":"false_neg = list(y_test[(y_test != y_pred) & (y_pred == 0)].index)\nprint(\"False ham:\", df.iloc[false_neg]['message'].values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Definitely, there is room for improvement."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}