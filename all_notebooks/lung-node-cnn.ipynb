{"cells":[{"metadata":{"_uuid":"b1f37b3d76f670c6f90ee25c2643b8e3f6a0596e","_cell_guid":"3b744bfd-8e36-439e-8399-2adb5709b967","trusted":true},"cell_type":"code","source":"from __future__ import print_function, division\nimport numpy as np\nfrom glob import glob\nimport pandas as pd\nimport os\nfrom tqdm import tqdm\noutput_path = os.path.join('..','input')\nimport matplotlib.pyplot as plt\nfrom skimage.util import montage\nfrom skimage.color import label2rgb\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98011364ae3e806899592f64fde65dc69c2a8b6c","_cell_guid":"ec465ae2-55e2-4469-adee-715638e8aa79","trusted":true},"cell_type":"code","source":"import h5py\nwith h5py.File(os.path.join(output_path, 'all_patches.hdf5'), 'r') as luna_h5:\n    all_slices = luna_h5['ct_slices'].value\n    all_classes = luna_h5['slice_class'].value\n    print('data', all_slices.shape, 'classes', all_classes.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"25194796a1c4bffa74ec88bf97fb7cf4768f59e9","_cell_guid":"04554997-3948-4720-9401-6301a759f432","trusted":true},"cell_type":"code","source":"from skimage.util import montage\nfig, (ax1, ax2) = plt.subplots(1,2,figsize = (12, 6))\nplt_args = dict(cmap = 'bone', vmin = -600, vmax = 300)\nax1.imshow(montage(all_slices[np.random.choice(np.where(all_classes>0.5)[0],size = 64)]), **plt_args)\nax1.set_title('Malignant Tiles')\nax2.imshow(montage(all_slices[np.random.choice(np.where(all_classes<0.5)[0],size = 64)]), **plt_args)\nax2.set_title('Benign Tiles')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad67302a9687e267ad4cf1078b46024633033356","_cell_guid":"db05d806-063c-4ab4-b435-3573b39b9e46"},"cell_type":"markdown","source":"# Creating a Simple CNN\nHere we make a simple CNN based on SqueezeNet (since we have limited computational resources on Kaggle). The model will also be trained from scratch although it is often a good idea to fine-tune pretrained models"},{"metadata":{"_uuid":"4b324604300ee86a8ff302a9782d571e38d8ec8d","_cell_guid":"9091a475-fcc8-4202-9bd6-dd66fcdf735a","trusted":true},"cell_type":"code","source":"from keras_applications.imagenet_utils import _obtain_input_shape\nfrom keras import backend as K\nfrom keras.layers import Input, Convolution2D, MaxPooling2D, Activation, concatenate, Dropout, GlobalAveragePooling2D, \\\n     BatchNormalization\nfrom keras.models import Model\nfrom keras.engine.topology import get_source_inputs\nfrom keras.utils import get_file\nfrom keras.utils import layer_utils\n\nsq1x1 = \"squeeze1x1\"\nexp1x1 = \"expand1x1\"\nexp3x3 = \"expand3x3\"\nrelu = \"relu_\"\n\n# Modular function for Fire Node\n\ndef fire_module(x, fire_id, squeeze=16, expand=64):\n    s_id = 'fire' + str(fire_id) + '/'\n\n    if K.image_data_format() == 'channels_first':\n        channel_axis = 1\n    else:\n        channel_axis = 3\n    \n    x = Convolution2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)\n    x = Activation('relu', name=s_id + relu + sq1x1)(x)\n\n    left = Convolution2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)\n    left = Activation('relu', name=s_id + relu + exp1x1)(left)\n\n    right = Convolution2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)\n    right = Activation('relu', name=s_id + relu + exp3x3)(right)\n\n    x = concatenate([left, right], axis=channel_axis, name=s_id + 'concat')\n    return x\n\n\n# Original SqueezeNet from paper.\n\ndef SqueezeNet(input_tensor=None, input_shape=None,\n               weights='imagenet',\n               classes=1000,\n              use_bn_on_input = False, # to avoid preprocessing\n               first_stride = 2\n              ):\n    if weights not in {'imagenet', None}:\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization) or `imagenet` '\n                         '(pre-training on ImageNet).')\n\n    if weights == 'imagenet' and classes != 1000:\n        raise ValueError('If using `weights` as imagenet with `include_top`'\n                         ' as true, `classes` should be 1000')\n\n    if input_tensor is None:\n        raw_img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n    if use_bn_on_input:\n        img_input = BatchNormalization()(raw_img_input)\n    else:\n        img_input = raw_img_input\n\n\n    x = Convolution2D(64, (3, 3), strides=(first_stride, first_stride), padding='valid', name='conv1')(img_input)\n    x = Activation('relu', name='relu_conv1')(x)\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n\n    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n\n    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n\n    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n    x = Dropout(0.5, name='drop9')(x)\n\n    x = Convolution2D(classes, (1, 1), padding='valid', name='conv10')(x)\n    x = Activation('relu', name='relu_conv10')(x)\n    x = GlobalAveragePooling2D()(x)\n    out = Activation('softmax', name='loss')(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = raw_img_input\n\n    model = Model(inputs, out, name='squeezenet')\n\n    # load weights\n    if weights == 'imagenet':\n\n        weights_path = get_file('squeezenet_weights_tf_dim_ordering_tf_kernels.h5',\n                                    WEIGHTS_PATH,\n                                    cache_subdir='models')\n        model.load_weights(weights_path)\n        if K.backend() == 'theano':\n            layer_utils.convert_all_kernels_in_model(model)\n\n        if K.image_data_format() == 'channels_first':\n\n            if K.backend() == 'tensorflow':\n                warnings.warn('You are using the TensorFlow backend, yet you '\n                              'are using the Theano '\n                              'image data format convention '\n                              '(`image_data_format=\"channels_first\"`). '\n                              'For best performance, set '\n                              '`image_data_format=\"channels_last\"` in '\n                              'your Keras config '\n                              'at ~/.keras/keras.json.')\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nlung_node_cnn = SqueezeNet(input_shape = (64, 64, 1), \n                           weights = None, classes = 2,\n                  use_bn_on_input = True)\n# initiate RMSprop optimizer\nopt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n\n# Let's train the model using RMSprop\nlung_node_cnn.compile(loss='categorical_crossentropy',\n              optimizer=opt,\n              metrics=['accuracy'])\nloss_history = []\nlung_node_cnn.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c8d293899d545b47b88eeeadb952a5f54eb62005","_cell_guid":"5cb1cd2c-4f2d-4a05-8e82-f6dc2025f278"},"cell_type":"markdown","source":"# Partition and Reformat the data\nWe want to partition the data into training and validation datasets and then reform the class as a one-hot so it fits to the model. We also perform a simple normalization of the image data so the range is between -1 and 1 instead of -3000 to 2000"},{"metadata":{"_uuid":"434ec37a2e9246bc48ebbdc801c3e37edf3d62ea","_cell_guid":"ca159b6a-66fd-4333-99d7-bc5942931b29","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nX_vec = (np.expand_dims(all_slices,-1) - np.mean(all_slices))/np.std(all_slices)\n\ny_vec = to_categorical(all_classes)\nX_train, X_test, y_train, y_test = train_test_split(X_vec, y_vec, \n                                                   train_size = 0.75,\n                                                   random_state = 1, \n                                                   stratify = all_classes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Starting Point\nHow does a completely untrained model do"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\ny_pred_proba = lung_node_cnn.predict(X_test)\ny_pred = np.argmax(y_pred_proba,1)\nprint('')\nprint(classification_report(np.argmax(y_test,1),\n                      y_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6ebac69e1f9637a58ae29ed07dbc730e0a46080","_cell_guid":"9cc2c40e-11d3-4b58-a277-a134c7b7d17c","trusted":true},"cell_type":"code","source":"for i in range(5):\n    loss_history += [lung_node_cnn.fit(X_train, y_train, \n              validation_data=(X_test, y_test),\n                               shuffle = True,\n                               batch_size = 32,\n                               epochs = 1)]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"77a5478f1b828d3203938ac8f9cae30ec0db16cd","_cell_guid":"1394ef97-df06-4830-ba36-7deaa7c8c4a2","trusted":true},"cell_type":"code","source":"epich = np.cumsum(np.concatenate(\n    [np.linspace(0.5, 1, len(mh.epoch)) for mh in loss_history]))\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n_ = ax1.plot(epich,\n             np.concatenate([mh.history['loss'] for mh in loss_history]),\n             'b-',\n             epich, np.concatenate(\n        [mh.history['val_loss'] for mh in loss_history]), 'r-')\nax1.legend(['Training', 'Validation'])\nax1.set_title('Loss')\n\n_ = ax2.plot(epich, np.concatenate(\n    [mh.history['acc'] for mh in loss_history]), 'b-',\n                 epich, np.concatenate(\n        [mh.history['val_acc'] for mh in loss_history]),\n                 'r-')\nax2.legend(['Training', 'Validation'])\nax2.set_title('Accuracy')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results after training\nHere we show the results after training a model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\ny_pred_proba = lung_node_cnn.predict(X_test)\ny_pred = np.argmax(y_pred_proba,1)\nprint('')\nprint(classification_report(np.argmax(y_test,1),\n                      y_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea38d77983dc6bee57ffa77a80b91b9401e02aaa","_cell_guid":"a2a4c7a7-d2dc-4169-accb-309810127db7","trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nfpr, tpr, thresholds = roc_curve(np.argmax(y_test, 1), y_pred_proba[:,1])\nfig, ax1 = plt.subplots(1,1)\nax1.plot(fpr, tpr, 'r-.', label = 'CNN (%2.2f)' % auc(fpr, tpr))\nax1.set_xlabel('False Positive Rate')\nax1.set_ylabel('True Positive Rate')\nax1.plot(fpr, fpr, 'b-', label = 'Random Guess')\nax1.legend()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"pygments_lexer":"ipython3","mimetype":"text/x-python","file_extension":".py","version":"3.6.1","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","nbconvert_exporter":"python"}},"nbformat":4,"nbformat_minor":4}