{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/mushroom-classification/mushrooms.csv\")\n\n#print(y)\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nle = LabelEncoder()\nds=df.apply(le.fit_transform)\ndata = ds.values\n\ny = data[:,0]\nx = data[:,1:]\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nxtr, xts, ytr,yts = train_test_split(x, y, test_size = 0.2, random_state = 0)\n#print(y)\n\nds.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prior_prob(y_train,label):\n    \n    total_examples = y_train.shape[0]#total no. of classes\n    class_examples = np.sum(y_train==label)#total no. of rows of that class\n    \n    return (class_examples)/float(total_examples)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(x_train,y_train,xtest):\n    \"\"\"Xtest is a single testing point, n features\"\"\"\n    \n    classes = np.unique(y_train)\n    n_features = x_train.shape[1]\n    post_probs = [] # List of prob for all classes and given a single testing point\n    #Compute Posterior for each class\n    for label in classes:\n        \n        #Post_c = likelihood*prior\n        likelihood = 1.0\n        for f in range(n_features):\n            cond = cond_prob(x_train,y_train,f,xtest[f],label)\n            likelihood *= cond \n            \n        prior = prior_prob(y_train,label)\n        post = likelihood*prior\n        post_probs.append(post)\n        \n    pred = np.argmax(post_probs)\n    return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cond_prob(x_train,y_train,feature_col,feature_val,label):\n    \n    x_filtered = x_train[y_train==label]\n    numerator = np.sum(x_filtered[:,feature_col]==feature_val)\n    denominator = np.sum(y_train==label)\n    \n    return numerator/float(denominator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def score(x_train,y_train,x_test,y_test):\n\n    pred = []\n    for i in range(x_test.shape[0]):\n        pred_label = predict(x_train,y_train,x_test[i])\n        pred.append(pred_label) # <===Correction\n    \n    pred = np.array(pred)\n    \n    accuracy = np.sum(pred==y_test)/y_test.shape[0]\n    return accuracy\nprint(score(xtr,ytr,xts,yts))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}