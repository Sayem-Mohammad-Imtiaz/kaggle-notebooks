{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Manipulando dados com Pandas"},{"metadata":{},"cell_type":"markdown","source":"Saber manipular dados e realizar algumas transformações neles é essencial. Nesse tutorial, iremos passar por funções importantes da biblioteca Pandas e utilizar o dataset de \"Inauguração de Estações de Metrô e da CPTM\" para exemplificá-las.\n\nPara esse tutorial, é necessário conhecer o básico de Python (funções, bibliotecas, etc)."},{"metadata":{},"cell_type":"markdown","source":"Tópicos\n- como carregar dados\n- valores nulos\n- filtros\n- ver máximo, média, mediana\n- contar valores, ordenação"},{"metadata":{},"cell_type":"markdown","source":"Bibliotecas que iremos utilizar:"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport os","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Introdução\n\nPara carregar os dados com a biblioteca Pandas, iremos utilizar o método ```pd.read_csv()```.\nBasta passarmos para a função o local onde se encontram os dados, que no nosso caso, são do tipo ```.csv``` (outros parâmetros podem ser encontrados na [documentação](pandas.pydata.org/)).\nO Pandas carrega nossos dados em tipo chamado ```DataFrame```.\n\nPara verificarmos o tamanho do dataset utilizamos o ```.shape``` em nosso DataFrame, ou seja, ```data.shape```.\n\nTambém, queremos ver um trecho dos nossos dados, e podemos ver os 5 primeiros itens com ```data.head()```."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/inauguracao-de-estacoes-do-metrosp-e-da-cptm/inauguracoes.csv')\nprint(f'Dataset shape -> {data.shape}')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para acessar o valor de uma linha, não fazemos como nas listas, de selecionar um elemento pelo index. Veja saída, caso tentemos fazer isso:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O erro nos diz essa chave não existe, porque na verdade, a busca procura pelas colunas do dataset.\n\nPara acessar uma linha pelo valor de sua posição, podemos usar a função ```data.iloc[idx]```:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.iloc[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para uma descrição das colunas numéricas, com algumas medidas de posição, máximo e mínimo, podemos executar ```data.describe()```:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seria possível obter esses valores por meio das funções de máximo, mínimo, desvio padrão e dos quantis:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Média: {data.Linha.mean()}')\nprint(f'Desvio: {data.Linha.std()}')\nprint(f'Max: {data.Linha.max()}')\nprint(f'Min: {data.Linha.min()}')\nprint(f'Quantis (25%, 50%, 75%, 100%): {data.Linha.quantile(.25)}, {data.Linha.quantile(.5)}, {data.Linha.quantile(.75)}, {data.Linha.quantile(1)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos também querer informações sobre todas as colunas, com informações sobre valores nulos, tipo de dados da coluna. A função ```data.info()``` permite isso:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Valores nulos\n\nUm ponto bem importante para competições é verificarmos valores nulos. Tanto para que medidas façam mais sentido (e.g. a média) quanto para nossos modelos, valores nulos podem impactar nossa avaliação, portanto, é necessário tratá-los de alguma forma. Existem diferentes técnicas para inputar dados, que não iremos abordar aqui, mas valem a [referência](https://scikit-learn.org/stable/modules/impute.html).\n\nUm passo inicial, é verificar a existência de valores nulos. O método ```data.info()``` permite que visualizemos a existência deles por colunas, o que pode ser chato de ver quando o nosso número de colunas é grande. Uma forma mais prática é utilizar o método do Pandas ```data.isna()```."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vemos acima que ele verifica o valor de uma célula, retornando verdadeiro ou falso caso ela seja nula (ou não). Ainda não é o que queremos.\n\nO que falta é chamar o método ```sum()```, para que os valores sejam somados (verdadeiro = 1 e falso = 0), e assim checarmos por coluna a existência de nulos:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Uma outra alternativa, para checar a existência de nulos entre todas as colunas, é chamar o método ```sum()``` mais uma vez:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Por fim, verificamos que não há nenhum dado faltante em nosso dataset."},{"metadata":{},"cell_type":"markdown","source":"# Unicidade e filtros\n\nUma pergunta interessante de se fazer, considerando nossos dados, seria saber quais são as estações de Metrô ou CPTM que foram inauguradas.\nTemos a coluna ```Nome``` que diz o nome de uma estação, mas não sabemos se esse nome pode estar em mais de uma linha.\n\nPara isso, podemos utilizar o método ```data.Nome.unique()```, que nos diz os valores únicos naquela coluna.\nTambém, podemos querer saber apenas o número de valores únicos nessa coluna, o que pode ser feito com o método ```data.Nome.nunique()```:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Number of unique stations: {data.Nome.nunique()}')\ndata.Nome.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos perceber que nosso dataset possui duplicatas, já que são 169 estações mas 184 linhas.\n\nQuais são as linhas duplicadas?\nO método ```data.Nome.duplicated()``` pode nos ajudar com essa pergunta. Ele retorna verdadeiro ou falso.\n\nComo queremos observar todas as informações dessas estações duplicadas, queremos as linhas que são ```True``` no retorno desse método.\nAqui entram os filtros!\n\n# Filtros\n\nPodemos filtrar nosso dataset com o retorno booleano (verdadeiro ou falso) do método ```data.Nome.duplicated()``` da seguinte maneira:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'O que a função duplicated retorna: \\n{data.Nome.duplicated()}\\n____')\n\nprint('Estações duplicadas:')\ndata[data.Nome.duplicated()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para investigar mais a fundo as informações de uma estação que está duplicada, podemos selecionar algumas delas, e filtrá-las pelo nome.\n\nNo Pandas, podemos encadear filtros (com ```or``` e ```and```), mas a sintaxe muda:\n1. ```or``` -> |\n2. ```and``` -> &\n3. ```not``` -> ~\n\nPor exemplo, iremos filtrar:\n1. Estações com nome Luz ou Santa Cruz\n2. Estações com nome Luz e construídas pelo Metrô\n3. Estações com nome Luz e não construídas pelo Metrô"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[(data.Nome == 'Luz') | (data.Nome == 'Santa Cruz')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[(data.Nome == 'Luz') & (data.Construção == 'Metrô')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[(data.Nome == 'Luz') & ~(data.Construção == 'Metrô')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Também pode ser o caso em que desejamos retirar os valores duplicados, o que pode ser feito com a função ```data.drop_duplicates()```.\n\nA função remove o item duplicado, levando em consideração a coluna de comparação. Ela retorna um novo ```DataFrame``` caso o parâmetro ```inplace``` não seja utilizado (```inplace=True```).\n\nUm parâmetro importante dessa função é o ```keep```. Como padrão, o Pandas mantém a primeira ocorrência daquele valor, mas podemos alterá-lo para manter o último.\nPara nosso estudo, isso acaba não fazendo tanta diferença."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_without_duplicates = data.drop_duplicates(subset=['Nome'], keep='last')\ndata_without_duplicates.Nome.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Os filtros também podem ser aplicados as demais colunas.\n\nTemos abaixo o exemplo com as idades das estações. Podemos querer aquelas com mais de 40 anos (mais antigas), ou com menos de 4 anos (mais recentes)."},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data.Idade > 40]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data.Idade < 4]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conversões de tempo (datetime)\n\nSaber lidar com dados temporais é importante. O primeiro passo é convertê-los para o tipo certo, facilitando a sua manipulação, construção de novas\nfeatures e até mesmo que realizemos filtros baseados em tempo.\n\nNo nosso dataset, temos a coluna de Inauguração, que representa a data de inauguração de uma estação. Podemos observar que o tipo dela é ```object```:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Inauguração.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Iremos convertê-la para ```datetime``` com a função do Pandas ```pd.to_datetime()```:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Inauguração'] = pd.to_datetime(data['Inauguração'])\ndata.Inauguração.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dessa forma, podemos derivar novas features com facilidade:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Ano'] = pd.DatetimeIndex(data.Inauguração).year\ndata['Mês'] = pd.DatetimeIndex(data.Inauguração).month\ndata['Dia'] = pd.DatetimeIndex(data.Inauguração).day\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ordenação de valores\n\nOutro ponto que é interessante é conseguirmos ordenar nossos dados.\n\nIsso pode ser feito tanto para ```Series``` quanto ```DataFrame```. Podemos ver alguns exemplos abaixo,\nque levam em consideração a data de inauguração da estação:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Inauguração.sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sort_values(by=['Inauguração'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Além da ordenação levando em consideração o tempo, podemos ordenar por qualquer outra coluna, como por exemplo, pelo nome:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sort_values(by=['Nome'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lembre-se: a função ```sort_values``` também retorna um novo ```DataFrame/Series```, e você deve atribuí-lo caso deseje usar esse novo df. Também é possível fazer isso ```inplace```.\n\nEssa função também pode considerar diferentes eixos na hora de ordenar (linhas ou colunas)."},{"metadata":{},"cell_type":"markdown","source":"# Criando novas colunas (features)\n\nO processo de criar novas features (características) também é essencial. Muitas vezes, derivar uma nova feature pode melhorar (e muito) a performance do seu modelo.\nEla eleva a \"riqueza\" das informações a serem utilizadas.\n\nExistem formas mais programáticas de gerar features, como [features polinomiais](https://scikit-learn.org/stable/modules/preprocessing.html#generating-polynomial-features), mas iremos fazer isso\nde uma forma um pouco mais manual, apenas para dar uma ideia/sugestão.\n\nDentro do nosso contexto, poderiamos estar trabalhando em um problema de decidir a qualidade ou eficiência de uma estação de metrô.\nPensando nesse problema (imaginário), iriamos nos perguntar:\n\n1. Será que a estação ser da CPTM faz diferença?\n2. Ser antiga ou nova muda algo?\n\nOutros pontos, que talvez fossem meio inusitados de se perguntar, mas eventualmente poderiam evidenciar algo não facilmente percebido nos dados, seria:\n\n1. O nome da estação contém z?\n2. A idade da estação é par?\n3. Ela foi inaugurada no mês do Natal?\n4. Ela foi inaugurada no segundo semestre?\n5. Ela foi inaugurada nas férias (férias sendo janeiro e julho)?\n\nCada uma dessas perguntas poderia gerar uma nova feature, como exemplificado abaixo:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['isCPTM'] = (data.Construção == 'CPTM').astype('int')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['isOld'] = (data.Idade > 40).astype('int')\ndata['hasZ'] = data.Nome.str.contains('z').astype('int')\ndata['ageIsEven'] = (data.Idade % 2 == 0).astype('int')\ndata['yearIsOdd'] = (data.Ano % 2 != 0).astype('int')\ndata['isChristmasMonth'] = (data.Mês == 12).astype('int')\ndata['isSecondSemester'] = (data.Mês >= 6).astype('int')\ndata['isVacation'] = ((data.Mês == 7) | (data.Mês == 1)).astype('int')\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Contagem de valores\n\nPor fim, iremos verificar como contar a ocorrência de valores em nosso dataset.\n\nA função ```value_counts()``` permite que façamos isso. Basta passar uma coluna:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Ano.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como resultado, obtemos o número de ocorrências de cada um dos valores, o que pode ser particularmente útil para visualizações, verificarmos se os dados estão desbalanceados (mais de uma classe, menos das outras) dentro do contexto de classificação, e mais.\n\nComo exemplo, iremos visualizar esses dados (não se preocupe em como fazer a visualização):"},{"metadata":{"trusted":true},"cell_type":"code","source":"xy = data.Ano.value_counts()\n\nplt.figure(figsize=(50,10))\nplt.bar(xy.index.astype('str'), height=xy.values);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# FIM\n\nNesse notebook, passamos por alguns dos pontos mais importantes quando falamos de manipulação de dados.\nVimos como descrever uma ou mais colunas, checar se ela contém valores nulos, como acessar os valores de um dataset.\nTambém, como criar novas colunas derivadas de informações que já temos (feature engineering), lidar com dados de tempo, ordenar e filtrar valores.\n\nSe você gostou do notebook, dê um up :)\n\nSugestões de melhoria, críticas e qualquer mensagem que quiser passar, deixe nos comentários!\n\n\nEsse notebook foi criado para uma apresentação no GT Estudos do [BeeData](https://www.facebook.com/BeeDataUSP/). Fique à vontade para entrar em contato!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}