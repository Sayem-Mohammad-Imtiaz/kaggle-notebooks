{"cells":[{"metadata":{},"cell_type":"markdown","source":"# CREDIT RISK DEFAULT DATA <br>Probability of Default (PD) Model\n## Gradient Boosting\n\n* *Warning: The model we develop is a \"black box\" model and should be treated as such for decision support purposes. The standard method for PD model development is Logistic Regression*"},{"metadata":{},"cell_type":"markdown","source":"Refer to [Exploratory Data Analysis](https://www.kaggle.com/yanpapadakis/credit-default-risk-data-eda) for more information about the dataset we utilize."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\n\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Prohibited Variables (redlining regulations)\nprohibited = ['zip_code','addr_state']\n\n# Many Errors / Not Codified\nmany_errors = ['desc','emp_title','title']\n\n# Suspicious Data\n# next_pymnt_d: missing correlates suspiciously to default rate\n# issue_d and last_credit_pull_d are surpisingly and counterintuitively predictive\n# id: significant, maybe is proxy of tenure or time of Origination / drop however\n# member_id: same as id\nsuspect = ['next_pymnt_d', 'issue_d', 'last_credit_pull_d', 'id', 'member_id']\n\nunknown_at_origination = ['funded_amnt_inv', 'funded_amnt', 'int_rate', 'installment', 'grade', 'sub_grade',\n    'out_prncp', 'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv',\n    'total_rec_prncp', 'total_rec_int', #'total_rec_late_fee', 'recoveries',\n    'collection_recovery_fee', 'last_pymnt_amnt', 'last_pymnt_d']\n\nzero_variance = ['policy_code','pymnt_plan'] # zero or near-zero variance\n\nquasi_separation = [\n    'open_il_6m', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il', 'total_bal_il',\n    'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util', 'inq_fi', 'inq_last_12m', \n    'open_acc_6m', 'total_cu_tl'\n]\n\nskipvars = prohibited + many_errors + suspect + unknown_at_origination + zero_variance + quasi_separation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dates = ['issue_d', 'last_pymnt_d', 'next_pymnt_d', 'last_credit_pull_d'] #,'earliest_cr_line']\n    # earliest_cr_line is not parsed correctly automatically\n    \ncred = pd.read_csv(\n    '../input/Data File.csv',\n    usecols = lambda x: x not in skipvars,\n    parse_dates = list(set(dates) - set(skipvars)),\n    date_parser = lambda x: pd.to_datetime(x,format='%b-%y'),\n    low_memory=False\n)\nprint('Dataset Dimensions:',cred.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove Already Delinquent\n\ncred = cred[(cred.total_rec_late_fee == 0) & (cred.recoveries == 0)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with pd.option_context('display.max_rows', 10, 'display.max_columns', None): \n    display(cred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Transformations"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = cred['default_ind'].values\nprint(\"Mean Bad Rate = {:.2%}\".format(np.mean(y)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_earliest_cr_date(s):\n    year2 = int(s[4:])\n    y = year2 if year2 > 16 else year2 + 100\n    return 116 - y\n\ncred['years_since_first_credit'] = cred['earliest_cr_line'].apply(read_earliest_cr_date)\ncred.drop('earliest_cr_line', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# metadata\nmetadata = dict()\nfor v in cred.dtypes.index:\n    if v != \"default_ind\":\n        metadata.setdefault(str(cred.dtypes[v]), []).append(v)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set missing to default values\ncred.fillna({col:'Missing' for col in metadata['object']}, inplace=True)\ncred.fillna({col:-99 for col in metadata['int64']}, inplace=True)\ncred.fillna({col:-999.0 for col in metadata['float64']}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert Dates to Integers\nbase = pd.Timestamp('2000-01-01 00:00:00')\nyr = pd.to_timedelta(pd.Timestamp('2001-01-01 00:00:00')-base)\n\ntry:\n    for col in metadata['datetime64[ns]']:\n        cred[col+'_t'] = (cred[col]-base) / yr\n    cred.fillna({col+'_t':0 for col in metadata['datetime64[ns]']}, inplace=True)\n    metadata['dates_t'] = [col+'_t' for col in metadata['datetime64[ns]']]\nexcept KeyError:\n    metadata['dates_t'] = []\n    print('No datetime64[ns] Variables in the Model')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictors = [col for mgroup in ['int64','float64','dates_t'] for col in metadata[mgroup]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dum = pd.get_dummies(cred[metadata['object']])\ndum.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cred = pd.concat([cred[predictors], dum],axis=1)\npredictors += list(dum.columns)\ndel dum\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Data Frame and Fitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    cred.values,\n    y,\n    test_size=0.20,\n    random_state=19,\n    stratify = y\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_train = lgb.Dataset(X_train, y_train)\nlgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n\n# specify your configurations as a dict\nparams = {\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'metric': ['auc','binary_logloss'],\n    'max_depth':10,\n    'max_bin':255,\n    'learning_rate': 0.004,\n    'feature_fraction': 0.5,\n    'pos_bagging_fraction': 0.6,\n    'neg_bagging_fraction':0.05,\n    'random_seed':2019,\n    'min_data_in_leaf':400,\n    'bagging_freq': 1,\n    'verbosity': 0\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out = dict()\ngbm = lgb.train(\n    params,\n    lgb_train,\n    num_boost_round=13000,\n    verbose_eval=500,\n    valid_sets=[lgb_train,lgb_eval],\n    feature_name=predictors,\n    evals_result = out\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb.plot_metric(out, metric='auc');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb.plot_metric(out, metric='binary_logloss');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"validation AUC has reached maximum (we know this from previous runs with higher value for num_boosting_round)"},{"metadata":{},"cell_type":"markdown","source":"#### Below is a depiction of the first tree out of <num_boosting_round> in our ensemble."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looks better in \"Edit Mode\"\n#lgb.create_tree_digraph(\n#    gbm, tree_index=0,\n#    show_info=('internal_value', 'internal_count', 'leaf_count'),\n#    precision = 3\n#)\n\n#You should be able to zoom in on this. Right-click on the graph.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb.plot_tree(\n    gbm, tree_index=0,\n    show_info=('internal_value', 'internal_count', 'leaf_count'),\n    precision = 3,\n    figsize=(44,35)\n);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb.plot_importance(gbm, importance_type=\"gain\", precision=0, max_num_features=30, figsize=(7,11));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lst = sorted(zip(gbm.feature_importance(importance_type=\"gain\"),gbm.feature_name()))\n#[nm for imp, nm in lst if imp > 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<hr>\nAll Done! We have a model ready. "},{"metadata":{},"cell_type":"markdown","source":"## Sensitivity Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"def sensitivity(on_column,column_names,X,model):\n    idx = [column_names.index(col) for col in on_column]\n    stats = [(i,np.mean(X[:,i]),np.std(X[:,i])) for i in idx]\n    res = []\n    for i, mean_, std_ in stats:\n        logdiff = []\n        print(\"{:20} Mean: {:9.2f} St.Dev.: {:9.2f}\".format(column_names[i], mean_, std_))\n        original_column = X[:,i]\n        X[:,i] = mean_ - 0.5 * std_\n        prob = model.predict(X)\n        logit0 = np.log( prob / (1-prob) )\n        X[:,i] = mean_ + 0.5 * std_\n        prob = model.predict(X)\n        logit1 = np.log( prob / (1-prob) )\n        srs = pd.Series(logit1-logit0, index = logit0, name = column_names[i])\n        res += [srs.sort_index()]\n        X[:,i] = original_column\n    return res\n\nsmp = np.random.choice(len(X_test),400)\nsens = sensitivity(['revol_util','total_rev_hi_lim'], predictors, X_test[smp], gbm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfor srs in sens:\n    avg = pd.Series(srs.mean(),index=srs.index)\n    plt.scatter(srs.index, srs, marker='.', label='Logit Diff')\n    plt.plot(avg.index,avg,'r--', label='Mean Effect')\n    plt.title(srs.name)\n    plt.legend()\n    plt.grid()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gains Table"},{"metadata":{"trusted":true},"cell_type":"code","source":"score_test = gbm.predict(X_test)\nscore = pd.DataFrame({\"true\":y_test,\"score\":score_test})\n\nscore.groupby(\"score\")[\"true\"].agg([\"sum\",\"size\"])[\"size\"].mean() # no score ties","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"buckets = 20\ngains_table = score.groupby(pd.qcut(score.score,buckets))[\"true\"].agg([\"sum\",\"size\"])\ngains_table['bad'] = gains_table['sum']\ngains_table['good'] = gains_table['size'] - gains_table['sum']\ngains_table['p_bad'] = gains_table['bad'] / gains_table['size']\ngains_table['p_good'] = gains_table['good'] / gains_table['size']\ngains_table = gains_table.reset_index(drop=True)\ngains_table = gains_table.iloc[::-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = gains_table[[\"size\",\"bad\",\"good\"]].cumsum()\ntmp = tmp / tmp.iloc[-1]\ntmp.columns = [\"prop\",\"prop_bad\",\"prop_good\"]\ngains_table = pd.concat([gains_table,tmp],axis=1)\nplt.plot(gains_table.prop,gains_table.prop,'k:',label='prop')\nplt.plot(gains_table.prop,gains_table.prop_bad,'r-',label='prop_bad')\nplt.plot(gains_table.prop,gains_table.prop_good,'b-.',label='prop_good')\nplt.legend()\nplt.grid()\nplt.show()\ngains_table.index = gains_table[\"prop\"].apply(lambda x: \"{:.1%}\".format(x))\ngains_table = gains_table.drop([\"sum\",\"size\",\"bad\",\"good\",\"prop\"],axis=1)\ngains_table.style.format(\"{:.4f}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n> END of Notebook"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}