{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Importing relevant libraries","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\nimport altair as alt\nfrom sklearn.ensemble import IsolationForest\nimport plotly.graph_objects as go","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Understanding the Data","metadata":{}},{"cell_type":"code","source":"cloudwatch_df = pd.read_csv(\"/kaggle/input/nab/realAWSCloudwatch/realAWSCloudwatch/ec2_cpu_utilization_53ea38.csv\")\ncloudwatch_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cloudwatch_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cloudwatch_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cloudwatch_df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Preprocessing/ feature engineering","metadata":{}},{"cell_type":"code","source":"cloudwatch_df['timestamp'] = pd.to_datetime(cloudwatch_df['timestamp'])\ncloudwatch_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cloudwatch_df['year'] = cloudwatch_df['timestamp'].apply(lambda x: x.year)\ncloudwatch_df['month'] = cloudwatch_df['timestamp'].apply(lambda x: x.month)\ncloudwatch_df['day'] = cloudwatch_df['timestamp'].apply(lambda x: x.day)\ncloudwatch_df['weekday'] = cloudwatch_df['timestamp'].apply(lambda x: x.weekday())\ncloudwatch_df['hour'] = cloudwatch_df['timestamp'].apply(lambda x: x.hour)\n\ncloudwatch_df = cloudwatch_df[['timestamp', 'year', 'month', 'day', 'weekday', 'hour', 'value']]\n\n# Weekday starts from Monday\nprint(f'{cloudwatch_df.timestamp[0]} with weekday {cloudwatch_df.weekday[0]} is {cloudwatch_df.timestamp[0].strftime(\"%A\")}.\\n')\n\ncloudwatch_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cloudwatch_df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"fig = px.line(cloudwatch_df, x='timestamp', y='value', title='Overview of time series data')\n\nfig.update_xaxes(rangeslider_visible=True,)\nfig","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cloudwatch_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alt.Chart(cloudwatch_df).mark_rect().encode(alt.X('hour:O', title='hour of day'),\n                                      alt.Y('weekday:O', title='weekday'),\n                                      alt.Color('value:Q', title='CPU usage')).properties(\n                                            width=800,\n                                            height=300)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alt.Chart(cloudwatch_df).mark_bar().encode(x = 'weekday:O',\n                                     y = 'value:Q').properties(width=600)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Unsupervised Models","metadata":{}},{"cell_type":"markdown","source":"## 5.1 Isolation Forests","metadata":{}},{"cell_type":"code","source":"x = cloudwatch_df['value'].apply(lambda x: [x]).to_list()\n\niso_forest = IsolationForest(n_estimators = 100, \n                        max_samples = \"auto\",\n                        contamination = 0.01, \n                        random_state = 42)\niso_forest.fit(x)\ny_pred = iso_forest.predict(x)\ny_pred = [1 if x == -1 else 0 for x in y_pred]\ny_pred[:10]\n# Points that are 1 are outliers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cloudwatch_df[\"anomaly\"] = y_pred\ncloudwatch_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iso_anomaly_df = pd.DataFrame(cloudwatch_df)\niso_anomaly_df = iso_anomaly_df.loc[iso_anomaly_df['anomaly'] == 1]\niso_anomaly_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.line(cloudwatch_df, x='timestamp', y='value', title='Unsupervised anomaly detection in CPU utilization')\nfig.add_trace(go.Scatter(x=iso_anomaly_df[\"timestamp\"].to_list(), y=iso_anomaly_df[\"value\"].to_list(), mode='markers', name='anomalies'))\nfig.update_xaxes(rangeslider_visible=True)\nfig","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Too bad we do not have labelled data to measure the amount of anomalies we manage to capture","metadata":{}},{"cell_type":"markdown","source":"## 5.2 Local Outlier Factor","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import LocalOutlierFactor\nlof = LocalOutlierFactor(n_neighbors=2)\ny_pred = lof.fit_predict(x)\ny_pred = [1 if x == -1 else 0 for x in y_pred]\ny_pred[:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cloudwatch_df[\"anomaly\"] = y_pred\ncloudwatch_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lof_anomaly_df = pd.DataFrame(cloudwatch_df)\nlof_anomaly_df = lof_anomaly_df.loc[lof_anomaly_df['anomaly'] == 1]\nlof_anomaly_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.line(cloudwatch_df, x='timestamp', y='value', title='Unsupervised anomaly detection in CPU utilization')\nfig.add_trace(go.Scatter(x=lof_anomaly_df[\"timestamp\"].to_list(), y=lof_anomaly_df[\"value\"].to_list(), mode='markers', name='anomalies'))\nfig.update_xaxes(rangeslider_visible=True)\nfig","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Model comparison","metadata":{}},{"cell_type":"code","source":"fig = px.line(cloudwatch_df, x='timestamp', y='value', title='Unsupervised anomaly detection in CPU utilization')\nfig.add_trace(go.Scatter(x=lof_anomaly_df[\"timestamp\"].to_list(), y=lof_anomaly_df[\"value\"].to_list(), mode='markers', name='Local Outlier Factor'))\nfig.add_trace(go.Scatter(x=iso_anomaly_df[\"timestamp\"].to_list(), y=iso_anomaly_df[\"value\"].to_list(), mode='markers', name='Isolation Forests'))\nfig.update_xaxes(rangeslider_visible=True)\nfig","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Just based on the two visualizations, it is easy to see that Isolation Forest provides is more robust as a model for capturing anomalies. Isolation Forest also allows more flexibility by defining a contamination parameter when defining the model.","metadata":{}}]}