{"cells":[{"metadata":{},"cell_type":"markdown","source":"# This notebook comprehends studies in the Avian dataset"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\"\"\" `imageio_ffmpeg` contains a pre-built `ffmpeg` binary, needed for mp3 decoding by `librosa`. \n    It is installed as a custom package on Kaggle. If no `ffmpeg` binary is found in \n    `/usr/local/bin` then create a softlink to the `imageio_ffmpeg` binary. \n\"\"\"\n!pip install imageio_ffmpeg\n\nimport os\nif not os.path.exists(\"/usr/local/bin/ffmpeg\"): \n    #! pip install imageio_ffmpeg \n    import imageio_ffmpeg\n    os.link(imageio_ffmpeg.get_ffmpeg_exe(), \"/usr/local/bin/ffmpeg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\"\"\" Common imports \"\"\"\nfrom matplotlib.gridspec import GridSpec\nimport keras\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras.models import Sequential\nfrom keras.utils import to_categorical\nimport re\nfrom tqdm import tqdm\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.naive_bayes import GaussianNB\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## First things first, lets read the input csv file\n\n### After that we want to check how they are separated into species names and how the audios are distributed in matter of lenghts"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom matplotlib import pyplot as plt\nfrom glob import glob\nimport pandas as pd\nimport numpy as np\n\n\ndata_dir = '../input/xenocanto-avian-vocalizations-canv-usa/xeno-canto-ca-nv/'\ndf = pd.read_csv(\"../input/xenocanto-avian-vocalizations-canv-usa/xeno-canto_ca-nv_index.csv\").drop('Unnamed: 0',axis=1)\n\nlabel_encoder = LabelEncoder().fit(df['english_cname'] )\nn_classes = len(label_encoder.classes_)\nprint(\"The dataset contains %i distinct species labels.\"%n_classes)\nprint(\"%i mp3s found in %s\"%(len(glob(data_dir+\"*.mp3\")), data_dir))\n\ny_encoded_entire_dataset = np.array(label_encoder.transform(df['english_cname']))\n\nplt.figure(figsize=(15,2))\nplt.title(\"Distribution of Samples per Species\")\nplt.hist(y_encoded_entire_dataset, bins=n_classes)\nplt.xlim(-1,91)\nplt.ylabel(\"Number of Samples\")\nplt.xticks(range(n_classes), label_encoder.classes_, rotation='vertical')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"label_encoder = LabelEncoder().fit(df['duration_seconds'] )\nn_classes = len(label_encoder.classes_)\ny_encoded_entire_dataset = np.array(label_encoder.transform(df['duration_seconds']))\n\nplt.figure(figsize=(15,2))\nplt.title(\"Distribution of Time-lenght in all samples\")\nplt.hist(y_encoded_entire_dataset, bins=n_classes)\nplt.xlim(-1,91)\nplt.ylabel(\"Number of Samples\")\nplt.xlabel(\"Length of audio\")\nplt.xticks(range(n_classes), label_encoder.classes_, rotation='vertical')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## From here, we make a exploratory analysis: comprehending (STFT, MelSpec)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from librosa.display import specshow\nfrom IPython.display import Audio\nfrom itertools import islice\nfrom scipy import signal\nimport librosa\n\nAbert = df[df.english_cname.str.contains('Abert\\'s Towhee')]  #  Filtering over english name (for example)\n\nhop_length = 512\nn_fft = 2048\n\nplt.rcParams[\"figure.figsize\"] = (16,6)\nfor i, sample in islice(Abert.iterrows(), 0, Abert.shape[0]):\n    print(\"%s: %s, contributed by: %s %s\"%(sample.file_name, sample.full_name, sample.recordist, sample.recordist_url))\n    data, samplerate = librosa.load(\"../input/xenocanto-avian-vocalizations-canv-usa/xeno-canto-ca-nv/\" + sample.file_name)\n    display(Audio(data, rate=samplerate))\n    \n    # Trim data and show\n    data_t, _ = librosa.effects.trim(data)\n    librosa.display.waveplot(data_t, sr=samplerate)\n    plt.title(\"Time domain\")\n    plt.show()\n    \n    # STFT of normal data\n    D = np.abs(librosa.stft(data_t[:n_fft], n_fft=n_fft, hop_length=n_fft+1))\n    plt.plot(D)\n    plt.title(\"Short-time frequency domain\")\n    plt.show()\n    \n    # Normal melspec\n    sg = librosa.feature.melspectrogram(data, sr=samplerate, hop_length=hop_length, n_fft=n_fft)\n    \n    # Normal stft\n    X = librosa.stft(data, n_fft=n_fft, hop_length=hop_length)\n    \n    # Creation of the filter\n    cutOff = 1000 # Cutoff frequency\n    N  = 6    # Filter order\n    nyq = 0.5 * samplerate\n    fc = cutOff / nyq # Cutoff frequency normal\n    b, a = signal.butter(N, fc)\n\n    # Apply the filter over data\n    tempf = signal.filtfilt(b, a, data)\n    \n#     D1 = np.abs(librosa.stft(tempf[:n_fft], n_fft=n_fft, hop_length=n_fft+1))\n#     plt.plot(D1)\n\n    # Filtered STFT\n    X_after_filter = librosa.stft(tempf, n_fft=n_fft, hop_length=hop_length)\n    \n    # Filtered_melspec\n    f_sg = librosa.feature.melspectrogram(tempf, sr=samplerate, hop_length=hop_length, n_fft=n_fft)\n\n    fig, axs = plt.subplots(2, 2)\n    fig.suptitle(\"%s: %s\"%(sample.file_name, sample.full_name))\n    \n    specshow(np.log(sg), y_axis='mel', x_axis='time', ax=axs[0][0], hop_length=hop_length)\n    axs[0][0].set_title(\"log(Melspectrogram)\")\n    \n    axs[1][0].hist(np.log(sg.flatten()), bins=100)\n    axs[1][0].set_title(\"Histogram of log(Melspectrogram)\")\n    \n    # \n    librosa.display.specshow(X, sr=samplerate, hop_length=hop_length, ax=axs[0][1], x_axis='time', y_axis='linear')\n    axs[0][1].set_title(\"SFTF\")\n    \n#     specshow(np.log(f_sg), y_axis='mel', x_axis='time', ax=axs[1][1], hop_length=hop_length)\n    librosa.display.specshow(X_after_filter, sr=samplerate, hop_length=hop_length, ax=axs[1][1], x_axis='time', y_axis='linear')\n    axs[1][1].set_title(\"Histogram of filtered log(Melspectrogram)\")\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\ny_english_labels_entire_dataset = [s['english_cname'] for i,s in df.iterrows()]\nlabel_encoder = LabelEncoder().fit(y_english_labels_entire_dataset)\ny_encoded_entire_dataset = np.array(label_encoder.transform(y_english_labels_entire_dataset))\n\nn_classes = len(label_encoder.classes_)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    np.array([s['file_id'] for i,s in df.iterrows()]), \n    y_encoded_entire_dataset, \n    test_size=1/5, \n    stratify=y_encoded_entire_dataset, \n    shuffle=True, \n    random_state=37,\n)\nprint(\"Training data shape:\",X_train.shape, y_train.shape)\nprint(\"Test data shape:    \",X_test.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Abert = df[df.english_cname.str.contains('Abert\\'s Towhee')] # Other type of filter \n\nhop_length = 512\nn_fft = 2048\n\nplt.rcParams[\"figure.figsize\"] = (16,6)\nfor i, sample in islice(Abert.iterrows(), 0, 2):\n    print(\"%s: %s, contributed by: %s %s\"%(sample.file_name, sample.full_name, sample.recordist, sample.recordist_url))\n    data, samplerate = librosa.load(\"../input/xenocanto-avian-vocalizations-canv-usa/xeno-canto-ca-nv/\" + sample.file_name)\n    display(Audio(data, rate=samplerate))\n    \n    # Trim data and show\n    data_t, _ = librosa.effects.trim(data)\n    librosa.display.waveplot(data_t, sr=samplerate)\n    plt.title(\"Time domain\")\n    plt.show()\n\n    # Creation of the filter\n    cutOff = 1000 # Cutoff frequency\n    N  = 6    # Filter order\n    nyq = 0.5 * samplerate\n    fc = cutOff / nyq # Cutoff frequency normal\n    b, a = signal.butter(N, fc)\n\n    # Apply the filter over data\n    tempf = signal.filtfilt(b, a, data)\n    \n    D1 = np.abs(librosa.stft(tempf[:n_fft], n_fft=n_fft, hop_length=n_fft+1))\n    plt.plot(D1)\n    plt.show()\n    \n    \n    display(Audio(tempf, rate=samplerate))\n    \n    # Trim data and show\n    data_t, _ = librosa.effects.trim(tempf)\n    librosa.display.waveplot(data_t, sr=samplerate)\n    plt.title(\"Time domain\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}