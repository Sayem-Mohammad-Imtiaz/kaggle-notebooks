{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load in \n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the \"../input/\" directory.\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport cufflinks as cf\nimport plotly\nimport missingno as msno\nimport seaborn as sns\n%pylab inline\n\ncf.go_offline()\npy.init_notebook_mode()\n\nsns.set_style('whitegrid')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/uncover/UNCOVER/einstein/diagnosis-of-covid-19-and-its-clinical-spectrum.csv\")\ndf[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATIENT_ID = \"patient_id\"\nPATIENT_AGE_QUANTILE = \"patient_age_quantile\"\nADMITTED_REGULAR = \"patient_addmited_to_regular_ward_1_yes_0_no\"\nADMITTED_SEMI_ICU = \"patient_addmited_to_semi_intensive_unit_1_yes_0_no\"\nADMITTED_ICU = \"patient_addmited_to_intensive_care_unit_1_yes_0_no\"\nEXAM_RESULT = \"sars_cov_2_exam_result\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Missing Values Analysis\n- I see a lot of null values. The values most present are from the blood chemistry tests and a viral history of the patient."},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove variables that are all null\nnull_pct = (df.isnull().sum() / len(df)).sort_values()[::-1]\ndf = df.drop(columns=null_pct[null_pct == 1].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.bar(df.iloc[:, :50]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.bar(df.iloc[:, 50:100]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.matrix(df);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.dendrogram(df, );","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Target Distributions\n- We have 558 positive results (9.88%) from the SARS-COV-2 exam.\n- The admitted variables may or may not have positive results\n- *Define severity in our case definition to be: Positive, Positive and admitted to regular ward, admitted to semi-ICU and admitted to ICU*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[EXAM_RESULT].value_counts()/len(df)`","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[EXAM_RESULT].value_counts().iplot(kind='barh', title='Positive SARS-COV-2 Result',)\ndf.groupby(EXAM_RESULT)[ADMITTED_REGULAR].value_counts().unstack().iplot(kind='barh', title='Admitted to regular ward', )\ndf.groupby(EXAM_RESULT)[ADMITTED_SEMI_ICU].value_counts().unstack().iplot(kind='barh', title='Admitted to semi-ICU', )\ndf.groupby(EXAM_RESULT)[ADMITTED_ICU].value_counts().unstack().iplot(kind='barh', barmode='stack', title='Admitted to ICU', )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TARGETS = [ADMITTED_REGULAR, ADMITTED_SEMI_ICU, ADMITTED_ICU]\nSEVERITY = \"Severity\"\nSEVERITY_CATEGORICAL = \"SeverityCategorical\"\n# create new ordinal variable, based on severity\ndf.loc[(df[EXAM_RESULT] == \"positive\"), SEVERITY] = 1\ndf.loc[(df[ADMITTED_REGULAR] == \"t\") & (df[EXAM_RESULT] == \"positive\"), SEVERITY] = 2\ndf.loc[(df[ADMITTED_SEMI_ICU] == \"t\") & (df[EXAM_RESULT] == \"positive\"), SEVERITY] = 3\ndf.loc[(df[ADMITTED_ICU] == \"t\") & (df[EXAM_RESULT] == \"positive\"), SEVERITY] = 4\n# those that are turned out negative that are admitted to the wards will be dropped\ndf.loc[(df[EXAM_RESULT] == \"negative\") & (np.all(df.filter(like=\"addmited\") == 'f', axis=1)), SEVERITY] = 0\n\ndf.loc[df[EXAM_RESULT] == \"positive\", SEVERITY_CATEGORICAL] = \"Positive\"\ndf.loc[(df[ADMITTED_REGULAR] == \"t\") & (df[EXAM_RESULT] == \"positive\"), SEVERITY_CATEGORICAL] = \"Admitted to regular ward\"\ndf.loc[(df[ADMITTED_SEMI_ICU] == \"t\") & (df[EXAM_RESULT] == \"positive\"), SEVERITY_CATEGORICAL] = \"Admitted to semi-ICU\"\ndf.loc[(df[ADMITTED_ICU] == \"t\") & (df[EXAM_RESULT] == \"positive\"), SEVERITY_CATEGORICAL] = \"Admitted to ICU\"\ndf.loc[(df[EXAM_RESULT] == \"negative\") & (np.all(df.filter(like=\"addmited\") == 'f', axis=1)), SEVERITY_CATEGORICAL] = \"Negative\"\n\n# dropping null severity\ndf = df.dropna(subset=[SEVERITY, SEVERITY_CATEGORICAL])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://stackoverflow.com/questions/43214978/seaborn-barplot-displaying-values\ndef show_values_on_bars(axs, fmt=\"{:.2f}\"):\n    def _show_on_single_plot(ax):        \n        for p in ax.patches:\n            _x = p.get_x() + p.get_width() / 2\n            _y = p.get_y() + p.get_height()\n            value = fmt.format(p.get_height())\n            ax.text(_x, _y, value, ha=\"center\") \n\n    if isinstance(axs, np.ndarray):\n        for idx, ax in np.ndenumerate(axs):\n            _show_on_single_plot(ax)\n    else:\n        _show_on_single_plot(axs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vc = df[SEVERITY_CATEGORICAL].value_counts().to_frame(\"Count of Cases\").reset_index()\nvc = vc.rename(columns={\"index\" : SEVERITY})\n\nplt.figure(figsize=(15, 7))\ng=sns.barplot(x=SEVERITY,y='Count of Cases',data=vc, )\nshow_values_on_bars(g, fmt='{:.0f}')\n\n# layout = dict(yaxis=dict(side='left'),title='Positive SARS-COV-2 Result')\n# vc.iplot(kind='bar', layout=layout,)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Distribution of the blood chemistry variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"BLOOD_VARIABLES = ['hematocrit',\n       'hemoglobin', 'platelets', 'mean_platelet_volume', 'red_blood_cells', 'neutrophils',\n       'lymphocytes', 'mean_corpuscular_hemoglobin_concentration_mchc',\n       'leukocytes', 'basophils', 'mean_corpuscular_hemoglobin_mch',\n       'eosinophils', 'mean_corpuscular_volume_mcv', 'monocytes',\n       'red_blood_cell_distribution_width_rdw', 'serum_glucose', 'creatinine', 'sodium', 'urea', 'potassium',\n       'proteina_c_reativa_mg_dl']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[BLOOD_VARIABLES].corr().round(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Positive vs Negative"},{"metadata":{"trusted":true},"cell_type":"code","source":"for var_name in BLOOD_VARIABLES:\n    fig = plt.figure(figsize=(15, 7))\n    sns.distplot(df[df[SEVERITY] == 0][var_name], label=\"Negative\")\n    sns.distplot(df[df[SEVERITY] > 0][var_name], label=\"Positive, all\")\n    fig.suptitle(\"{} Positive vs Negative\".format(var_name).title())\n    plt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Negative vs Admitted"},{"metadata":{"trusted":true},"cell_type":"code","source":"for var_name in BLOOD_VARIABLES:\n    fig = plt.figure(figsize=(15, 7))\n    sns.distplot(df[df[SEVERITY] == 0][var_name], label=\"Negative\")\n    sns.distplot(df[df[SEVERITY] > 1][var_name], label=\"Admitted, all\")\n    fig.suptitle(\"{} Positive vs Admitted\".format(var_name).title())\n    plt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Antigen Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"ANTIGEN_VARIABLES = ['respiratory_syncytial_virus', 'influenza_a',\n       'influenza_b', 'parainfluenza_1', 'coronavirusnl63',\n       'rhinovirus_enterovirus', 'coronavirus_hku1',\n       'parainfluenza_3', 'chlamydophila_pneumoniae', 'adenovirus',\n       'parainfluenza_4', 'coronavirus229e', 'coronavirusoc43',\n       'inf_a_h1n1_2009', 'bordetella_pertussis', 'metapneumovirus',\n       'parainfluenza_2', 'influenza_b_rapid_test',\n       'influenza_a_rapid_test']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for var_name in ANTIGEN_VARIABLES:\n    fig = plt.figure(figsize=(15, 7))\n    vc = df.groupby(var_name)[SEVERITY_CATEGORICAL].value_counts().unstack().T\n    # order\n    vc = vc.loc[[\"Admitted to ICU\", \"Admitted to semi-ICU\", \"Admitted to regular ward\", \"Positive\"]]\n    vc_pct = vc.div(vc.sum(axis=1), axis=0)\n#     vc_pct.iplot(kind='bar', barmode = 'stack', title = \"{} on Severity\".format(var_name).title());\n    vc.iplot(kind='bar', barmode = 'stack', title = \"{} on Severity\".format(var_name).title());","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Antigen Correlation with Positive Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"for var_name in ANTIGEN_VARIABLES:\n    vc = df.groupby(EXAM_RESULT)[var_name].value_counts().unstack()\n    vc_pct = vc.div(vc.sum(axis=1), axis=0)\n#     vc_pct.iplot(kind='bar', barmode = 'stack', title = \"{} on Severity\".format(var_name).title());\n    \n    g = vc.plot.barh()\n#     vc.iplot(kind='bar', barmode = 'stack', title = \"{} on Severity\".format(var_name).title());","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling\n- I am choosing only the blood chemistry variables for this, since most other tests are null.\n- The antigen variables seem to not indicate anything useful from the above figures.\n- I am combining all the positive results due to the lack of samples for admitted categories.\n\n- *First run: dropping all rows with null blood variables*\n- *Second run: imputing to 0 all null blood variables. Since these are I think z-scores (hopefully), this will be fine.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(subset=BLOOD_VARIABLES)[SEVERITY_CATEGORICAL].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_validate, StratifiedShuffleSplit\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifierCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1 = df.dropna(subset=BLOOD_VARIABLES)\ny1 = np.where(X1[EXAM_RESULT] == \"negative\", 0, 1)\nX1 = X1[BLOOD_VARIABLES].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Removing collinearity through VIF"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor    \n\ndef calculate_vif_(X, thresh=5.0):\n    variables = list(range(X.shape[1]))\n    dropped = True\n    while dropped:\n        dropped = False\n        vif = [variance_inflation_factor(X.iloc[:, variables].values, ix)\n               for ix in range(X.iloc[:, variables].shape[1])]\n\n        maxloc = vif.index(max(vif))\n        if max(vif) > thresh:\n            print('dropping \\'' + X.iloc[:, variables].columns[maxloc] +\n                  '\\' at index: ' + str(maxloc))\n            del variables[maxloc]\n            dropped = True\n\n    print('Remaining variables:')\n    print(X.columns[variables])\n    return X.iloc[:, variables]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1_selected = calculate_vif_(X1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing regularization (high C)\nlr = LogisticRegression(C=1e10, max_iter=10000)\nresults = cross_validate(lr, X1_selected, y1, cv=10, scoring=['roc_auc', \"precision\", \"recall\"])\npd.DataFrame(results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_repeats=20\nlist_results = []\nlpo = StratifiedShuffleSplit(n_splits=10)\nfor _ in range(n_repeats):\n    for train_index, test_index in lpo.split(X1_selected, y1):\n        lr.fit(X1_selected.iloc[train_index], y1[train_index])\n        y_preds = lr.predict(X1_selected.iloc[test_index])\n        list_results.append(precision_recall_fscore_support(y1[test_index], y_preds))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_results = pd.DataFrame(np.array(list_results).reshape(n_repeats * 10, -1), columns=[\"Precision0\", \"Precision1\", \"Recall0\", \"Recall1\", \"FScore0\", \"FScore1\", \"Support0\", \"Support1\"])\ndisplay(df_results.mean().to_frame().T)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Coefficients"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr.fit(X1_selected, y1)\ncoef = pd.Series(lr.coef_.ravel(), index=X1_selected.columns)\ncoef.sort_values().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nx = sm.add_constant(X1_selected, prepend=False)\n\nres1 = sm.Logit(y1, x).fit()\nprint(res1.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Support Vector Machine\n- The best result is a linear kernel. That does not bode well for our nonlinear classifiers."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = SVC(class_weight='balanced')\nparams = {\"C\": [0.01, 0.1, 1, 10, ], \"kernel\": [\"linear\", \"poly\", \"rbf\"],}\ngs = GridSearchCV(svc, params, scoring='roc_auc', cv= 10)\ngs.fit(X1, y1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best ROC AUC Score:\", gs.best_score_.round(2))\nprint(\"Best Params:\", gs.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = gs.best_estimator_.fit(X1, y1)\ncoef = pd.Series(svc.coef_.ravel(), index=X1.columns)\ncoef.sort_values().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_repeats=20\nlist_results = []\nlpo = StratifiedShuffleSplit(n_splits=10)\nfor _ in range(n_repeats):\n    for train_index, test_index in lpo.split(X1, y1):\n        svc.fit(X1.iloc[train_index], y1[train_index])\n        y_preds = svc.predict(X1.iloc[test_index])\n        list_results.append(precision_recall_fscore_support(y1[test_index], y_preds))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_results = pd.DataFrame(np.array(list_results).reshape(n_repeats * 10, -1), columns=[\"Precision0\", \"Precision1\", \"Recall0\", \"Recall1\", \"FScore0\", \"FScore1\", \"Support0\", \"Support1\"])\ndisplay(df_results.mean().to_frame().T)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree\n- Not good at all"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing regularization (high C)\ndt = DecisionTreeClassifier(class_weight='balanced')\nparams = {\"max_depth\": [3, 5, 7], \"min_samples_split\": [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30]}\ngs = GridSearchCV(dt, params, scoring='roc_auc', cv= 10)\ngs.fit(X1, y1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best ROC AUC Score:\", gs.best_score_.round(2))\nprint(\"Best Params:\", gs.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Imputation"},{"metadata":{"trusted":true},"cell_type":"code","source":"X1 = df[BLOOD_VARIABLES].fillna(0)\ny1 = np.where(df[EXAM_RESULT] == \"negative\", 0, 1)\nX1 = X1[BLOOD_VARIABLES].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Removing collinearity through VIF"},{"metadata":{"trusted":true},"cell_type":"code","source":"X1_selected = calculate_vif_(X1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing regularization (high C)\nlr = LogisticRegression(C=1e10, max_iter=10000, class_weight='balanced')\nresults = cross_validate(lr, X1_selected, y1, cv=10, scoring=['roc_auc', \"precision\", \"recall\"])\npd.DataFrame(results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_repeats=20\nlist_results = []\nlpo = StratifiedShuffleSplit(n_splits=10)\nfor _ in range(n_repeats):\n    for train_index, test_index in lpo.split(X1_selected, y1):\n        lr.fit(X1_selected.iloc[train_index], y1[train_index])\n        y_preds = lr.predict(X1_selected.iloc[test_index])\n        list_results.append(precision_recall_fscore_support(y1[test_index], y_preds))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_results = pd.DataFrame(np.array(list_results).reshape(n_repeats * 10, -1), columns=[\"Precision0\", \"Precision1\", \"Recall0\", \"Recall1\", \"FScore0\", \"FScore1\", \"Support0\", \"Support1\"])\ndisplay(df_results.mean().to_frame().T)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Coefficients"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr.fit(X1_selected, y1)\ncoef = pd.Series(lr.coef_.ravel(), index=X1_selected.columns)\ncoef.sort_values().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nx = sm.add_constant(X1_selected, prepend=False)\n\nres1 = sm.Logit(y1, x).fit()\nprint(res1.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Support Vector Machine\n- The best result is a linear kernel. That does not bode well for our nonlinear classifiers.\n- The best score is not very impressive either."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = SVC(class_weight='balanced')\nparams = {\"C\": [0.01, 0.1, 1, 10, ], \"kernel\": [\"linear\", \"poly\", \"rbf\"],}\ngs = GridSearchCV(svc, params, scoring='roc_auc', cv= 3)\ngs.fit(X1, y1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best ROC AUC Score:\", gs.best_score_.round(2))\nprint(\"Best Params:\", gs.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = gs.best_estimator_.fit(X1, y1)\ncoef = pd.Series(svc.coef_.ravel(), index=X1.columns)\ncoef.sort_values().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_repeats=20\nlist_results = []\nlpo = StratifiedShuffleSplit(n_splits=10)\nfor _ in range(n_repeats):\n    for train_index, test_index in lpo.split(X1, y1):\n        svc.fit(X1.iloc[train_index], y1[train_index])\n        y_preds = svc.predict(X1.iloc[test_index])\n        list_results.append(precision_recall_fscore_support(y1[test_index], y_preds))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_results = pd.DataFrame(np.array(list_results).reshape(n_repeats * 10, -1), columns=[\"Precision0\", \"Precision1\", \"Recall0\", \"Recall1\", \"FScore0\", \"FScore1\", \"Support0\", \"Support1\"])\ndisplay(df_results.mean().to_frame().T)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree\n- Not good at all"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing regularization (high C)\ndt = DecisionTreeClassifier(class_weight='balanced')\nparams = {\"max_depth\": [3, 5, 7], \"min_samples_split\": [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30]}\ngs = GridSearchCV(dt, params, scoring='roc_auc', cv= 10)\ngs.fit(X1, y1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best ROC AUC Score:\", gs.best_score_.round(2))\nprint(\"Best Params:\", gs.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}