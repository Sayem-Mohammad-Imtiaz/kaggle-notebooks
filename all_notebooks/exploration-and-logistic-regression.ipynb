{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"80a6bb89-4a7d-68c5-7af4-43ca5d802969"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nfrom matplotlib import patches\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelBinarizer, StandardScaler\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"198cbed0-c9c0-386c-5e6c-c5134e6c8916"},"outputs":[],"source":"data = pd.read_csv('../input/data.csv')"},{"cell_type":"markdown","metadata":{"_cell_guid":"2697c92e-dc51-76de-69e5-47275c3bd57f"},"source":"## Take A Quick Peek at Data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5980db96-ee68-9a08-0cbf-c86245461a83"},"outputs":[],"source":"data.tail(10)"},{"cell_type":"markdown","metadata":{"_cell_guid":"0c0544c3-448b-cdab-d3ca-008053cf656e"},"source":"## Visualize Differences Between Malignant and Benign"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9d87516d-b490-444d-9661-236367f7bbb4"},"outputs":[],"source":"\nplt.figure(figsize=(20, 15))\nfor ii, col in enumerate(data.columns[2:11]):\n    plt.subplot(3,3,ii+1)\n    plt.title(col)\n    plt.legend(handles = [patches.Patch(label = 'Malignant', color=(.43,.23,.54)),\n                          patches.Patch(label = 'Benign', color=(.63,.83,.24))])\n    b = data[data['diagnosis'] == 'B'][col]\n    m = data[data['diagnosis'] == 'M'][col]\n    plt.hist(m, stacked=True, normed = True, color=(.43,.23,.54))\n    plt.hist(b, stacked=True, normed = True, color=(.63,.83,.24))\n    \nplt.tight_layout()\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b3de05cc-2a32-a1b7-3333-27f0d74379bb"},"outputs":[],"source":"plt.figure(figsize=(20, 15))\nfor ii, col in enumerate(data.columns[11:20]):\n    plt.subplot(3,3,ii+1)\n    plt.title(col)\n    plt.legend(handles = [patches.Patch(label = 'Malignant', color=(.43,.23,.54)),\n                          patches.Patch(label = 'Benign', color=(.63,.83,.24))])\n    b = data[data['diagnosis'] == 'B'][col]\n    m = data[data['diagnosis'] == 'M'][col]\n    plt.hist(m, stacked=True, normed = True, color=(.43,.23,.54))\n    plt.hist(b, stacked=True, normed = True, color=(.63,.83,.24))\n    \nplt.tight_layout()\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7d01941e-310b-3e85-1a8a-61185b1faf91"},"outputs":[],"source":"plt.figure(figsize=(20, 15))\nfor ii, col in enumerate(data.columns[20:29]):\n    plt.subplot(3,3,ii+1)\n    plt.title(col)\n    plt.legend(handles = [patches.Patch(label = 'Malignant', color=(.43,.23,.54)),\n                          patches.Patch(label = 'Benign', color=(.63,.83,.24))])\n    b = data[data['diagnosis'] == 'B'][col]\n    m = data[data['diagnosis'] == 'M'][col]\n    plt.hist(m, stacked=True, normed = True, color=(.43,.23,.54))\n    plt.hist(b, stacked=True, normed = True, color=(.63,.83,.24))\n    \nplt.tight_layout()\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"7e6d9aa4-5b9d-e71d-0ea3-ee1bde198764"},"source":"## Scale data to decrease convergence time"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"eaf9682d-f7f9-ca54-8a6b-c04edc139b0b"},"outputs":[],"source":"binarizer = LabelBinarizer().fit(data['diagnosis'])\ndata.iloc[:,2:32] = StandardScaler().fit_transform(data.iloc[:,2:32])\ndata['diagnosis'] = binarizer.transform(data['diagnosis'])\n\ndata.tail(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e78dfa46-21d1-ddf0-a019-3d9bfb35a39d"},"outputs":[],"source":"train_attrs = data.iloc[:400,2:32].as_matrix()\ntrain_labels = data.iloc[:400,1].as_matrix()\ntest_attrs = data.iloc[400:,2:32].as_matrix()\ntest_labels = data.iloc[400:,1].as_matrix()"},{"cell_type":"markdown","metadata":{"_cell_guid":"f62fdd48-ffd8-0c3a-d599-9eed42b4cca3"},"source":"## Build our classifier"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b294dee3-5629-ea5d-62df-267c813006b1"},"outputs":[],"source":"def labeler(x):\n    \n    return np.array([0 if i<0.5 else 1 for i in x])\n\nclass LogisticRegression:\n    \n    def __init__(self, X, y, max_iter=1000):\n        \n        self.X = self.add_bias(X)\n        self.y = y\n        self.weights = np.random.randn(self.X.shape[1]) * 15\n        self.max_iter = max_iter\n        \n    def add_bias(self, X):\n        \n        return np.concatenate((np.ones((X.shape[0], 1)), X), axis=1)\n    \n    def sigmoid(self, z):\n        \n        return 1.0/(1.0 + np.exp(-z))\n    \n    def gradient(self, weights):\n        \n        def partial_derivative(weight):\n            \n            return 1.0/len(self.X) * sum((self.predict(self.X) - self.y) * (self.X[:, weight]))\n       \n        gradient = np.array([partial_derivative(weight) for weight in range(len(weights))])\n        return gradient\n    def gradient_descent(self, learning_rate=0.01, loop=0):\n        \n        while loop < self.max_iter:\n            self.weights = self.weights - (learning_rate * self.gradient(self.weights))\n            if loop % 100 == 0:\n                acc = (test_labels == labeler(clf.predict(clf.add_bias(test_attrs)))).mean()\n                print(\"At iteration {0} the accuracy is {1}\".format(loop, acc))\n            loop+=1\n            \n            \n        return self\n    def predict(self, X):\n      \n        return np.array([self.sigmoid(np.dot(self.weights, x)) for x in X])"},{"cell_type":"markdown","metadata":{"_cell_guid":"6aef2191-72f4-7131-1fec-e81bf80c85a4"},"source":"## Train our classifier"},{"cell_type":"markdown","metadata":{"_cell_guid":"3704bf0c-e703-7205-d1b0-85cc0c4f1b13"},"source":"## Test our Classifer"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9eed137b-f576-ac33-784a-cb54389e9fe3"},"outputs":[],"source":"clf = LogisticRegression(train_attrs, train_labels, 10000)\nclf.gradient_descent()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d21698c7-15b5-ac60-3e33-575c0b9546f3"},"outputs":[],"source":"(test_labels == labeler(clf.predict(clf.add_bias(test_attrs)))).mean()"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}