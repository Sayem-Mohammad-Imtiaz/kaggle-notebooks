{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Table of Contents **\n* [Introduction](#Introduction)\n* [EDA](#EDA)\n    - [Univariate](#Univariate)\n    - [Bivariate](#Bivariate)\n* [Clustering](#Clustering)\n    - [K-Means Clustering](#K-Means Clustering)\n    - [Clusters visualization with Principal Component Analysis (PCA)](#Cluster vizualisation with Principal Component Analysis - PCA)\n* [Conclusion](#Conclusion)","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"<a id=\"section-one\"></a>\n# Introduction\nHi everyone,\n\nI am going to explore the [*wholesale  customer dataset*](https://archive.ics.uci.edu/ml/datasets/Wholesale+customers#) from the UCI Machine Learning Repository and use an unsupervised machine learning clustering model to make a customer segmentation.\n\nThe dataset contains information on the clients of a wholesale distributor, and more specifically:\n* Consumer annual spending (m.u.) on: fresh products, milk products, grocery products, frozen products, detergents and paper products, delicatessen products\n* Retail channel: Horeca (Hotel/Restaurant/Cafe) vs Retail channel (Nominal)\n* Purchase region: Lisnon, Oporto or Other.\n\nWe are first going to explore the dataset before applying the K-Means Clustering model to discover different segments of customers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%watermark -a \"Adrien DB\" -d -v -u \n%watermark --iversions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the Libraries\nimport numpy as np\nimport math\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nimport dabl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the Dataset\nimport os\ndf = pd.read_csv(r\"../input/wholesale-customers-data-set/Wholesale customers data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.matrix(df, figsize = (30,4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our dataset seems to be complete, let's check the type of data that we have:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_data = dabl.clean(df, verbose=1)\ndabl.detect_types(df_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We don't have to clean our dataset as we can see that out of our 8 columns, we already have:\n* 6 continuous types of feature ('Fresh', 'Milk', 'Grocery', 'Frozen',\t'Detergents_Paper', 'Delicassen')\n* 2 categoricals features ('Channel',\t'Region')\n\nHowever, let's change the content of 'Channel' and\t'Region' to make it clearer later:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Channel'] = df['Channel'].map({1:'Horeca', 2:'Retail'})\ndf['Region'].replace([1,2,3],['Lisbon','Oporto','other'],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"section-two\"></a>\n# EDA\nWe are going to start exploring our data with the Univariate analysis (each feature individually), before carrying the Bivariate analysis and compare pairs of features to find correlation between them.\n\n<a id=\"subsection-two\"></a>\n## Univariate","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_distribution(df, cols=5, width=20, height=15, hspace=0.2, wspace=0.5):\n    plt.style.use('seaborn-whitegrid')\n    fig = plt.figure(figsize=(width,height))\n    fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=wspace, hspace=hspace)\n    rows = math.ceil(float(df.shape[1]) / cols)\n    for i, column in enumerate(df.columns):\n        ax = fig.add_subplot(rows, cols, i + 1)\n        ax.set_title(column)\n        if df.dtypes[column] == np.object:\n            g = sns.countplot(y=column, data=df)\n            substrings = [s.get_text()[:18] for s in g.get_yticklabels()]\n            g.set(yticklabels=substrings)\n            plt.xticks(rotation=25)\n        else:\n            g = sns.distplot(df[column])\n            plt.xticks(rotation=25)\n    \nplot_distribution(df, cols=3, width=20, height=20, hspace=0.45, wspace=0.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the graphs on the distribution of product it seems that we have some outliers in the data, let's have a closer look before we decide what to do:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let’s remove the categorical columns:\ndf2 = df[df.columns[+2:df.columns.size]]\n\n#Let’s plot the distribution of each feature\ndef plot_distribution(df2, cols=5, width=20, height=15, hspace=0.2, wspace=0.5):\n    plt.style.use('seaborn-whitegrid')\n    fig = plt.figure(figsize=(width,height))\n    fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=wspace, hspace=hspace)\n    rows = math.ceil(float(df2.shape[1]) / cols)\n    for i, column in enumerate(df2.columns):\n        ax = fig.add_subplot(rows, cols, i + 1)\n        ax.set_title(column)\n        g = sns.boxplot(df2[column])\n        plt.xticks(rotation=25)\n    \nplot_distribution(df2, cols=3, width=20, height=10, hspace=0.45, wspace=0.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Outliers** should be detected but not necessarily removed, it depends of the situation. Here I will assume that the wholesale distributor provided us a dataset with correct data, so I will keep them as is.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"<a id=\"subsection-two\"></a>\n## Bivariate\n*(Not that it is required for our clustering segmentation, let's just see more relations in our dataset out of curiosity)*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Let's use Seaborn pairplot to have a first look at how our data is interracting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style=\"ticks\")\ng = sns.pairplot(df,corner=True,kind='reg')\ng.fig.set_size_inches(15,15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the pairplot above, the correlation between the \"*detergents and paper products*\" and the \"*grocery products*\" seems to be pretty strong, meaning that consumers would often spend money on these two types of product. Let's look at the Pearson correlation coefficient to confirm this:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute the correlation matrix\ncorr = df.corr()\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0.5,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .6},annot=True)\n\nplt.title(\"Pearson correlation\", fontsize =20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"In a Classification or Regression problem we would have explored this r of 0.92 but we'll skip this now to jump into the clustering","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"section-three\"></a>\n# Clustering\n<a id=\"K-Means Clustering\"></a>\n## K-Means Clustering\nOur dataset isn't that big so we can implement a K-Means clustering model here instead of using a hierarchical clustering model.\n### The Elbow Method\nLet's find the optimal number of clusters by using the Elbow method","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# First we need to convert our categorical features (region and channel) to dummy variable:\ndf2 = pd.get_dummies(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df2.iloc[:,:].values\n\nsns.set()\nfrom sklearn.cluster import KMeans\nwcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', \n                    max_iter = 300,\n                    n_init=10)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\n\nplt.plot(range(1, 11), wcss)\nplt.xticks(ticks=range(1, 11))\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So the idea here is to select a number of clusters after which we don't see much difference in the WCSS, let's go for 6 ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Training the K-Means model on the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters = 6,\n                init = 'k-means++',\n                max_iter = 300,\n                n_init=10,\n                random_state = 0)\ny_kmeans = kmeans.fit_predict(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Adding the cluster numbers to the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cluster = df\ndf_cluster['Cluster'] = y_kmeans\ndf_cluster.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cluster.Cluster.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"Cluster vizualisation with Principal Component Analysis - PCA\"></a>\n## Cluster visualization with Principal Component Analysis - PCA\nWe cannot visualize our clusters that easily beacause our dataset is multidimentional. So we'll use the Principal Component Analysis to reduce our dataset to a two dimentional one, then add our identified clusters to visualize them.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Feature Scaling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX = sc.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Applying PCA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components = 2)\npc = pca.fit_transform(df2)\npc_df = pd.DataFrame(pc)\npc_df.columns = ['pc1','pc2']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_clustering = pd.concat([pc_df,df_cluster['Cluster']],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualizing our clusters on PCA axis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(7,7))\nsns.scatterplot(x='pc1', y='pc2', hue= 'Cluster', data=pca_clustering,palette='Set1').set_title('K-Means Clustering')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"section-four\"></a>\n# Conclusion","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The K-Means clustering model allowed us to segments the customers between 6 distinct groups. We were able to visualize these clusters after performing a dimensionality reduction with the Principle Component Analysis.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}