{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.cluster import KMeans\nfrom sklearn.cluster import AgglomerativeClustering\nfrom sklearn import metrics\nimport sys\nif not sys.warnoptions:\n    import warnings\n    warnings.simplefilter(\"ignore\")\nimport plotly as py\nimport plotly.graph_objs as go\npy.offline.init_notebook_mode(connected = True)\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.figure_factory as ff","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# REGRESSION","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"diamonds = pd.read_csv(\"/kaggle/input/diamonds/diamonds.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamonds.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lmplot(y=\"carat\", x=\"price\", hue=\"clarity\", data= diamonds, fit_reg= False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lmplot(y=\"carat\", x=\"price\", hue=\"cut\", data= diamonds, fit_reg= False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style = \"whitegrid\", font_scale = 1.5)\n\nf, axes = plt.subplots(3, figsize = (8,16))\n\nsns.countplot(y = \"clarity\", data = diamonds, ax = axes[0])\n\nsns.countplot(y = \"color\", data = diamonds, ax = axes[1])\n\nsns.countplot(y = \"cut\", data = diamonds, ax = axes[2])\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nohe = OneHotEncoder()\ncut = diamonds.iloc[:,1:2]\ncolor = diamonds.iloc[:,2:3]\nclarity = diamonds.iloc[:,3:4]\ncut = ohe.fit_transform(cut).toarray()\ncolor = ohe.fit_transform(color).toarray()\nclarity = ohe.fit_transform(clarity).toarray()\n\ndiamonds.drop(columns = ['cut', 'color', 'clarity'], inplace = True)\n\ncut = pd.DataFrame(cut)\ncolor = pd.DataFrame(color)\nclarity = pd.DataFrame(clarity)\n\ndiamonds = pd.concat([diamonds, cut, color, clarity], axis = 1)\n\nX = diamonds.drop(columns = 'price').values\nY = diamonds.iloc[:,3:4].values\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test,y_train,y_test = train_test_split(X, Y,test_size=0.2, random_state=0)\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(x_train)\nX_test = sc.fit_transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# OLS Regression Results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm \n\nX_l = diamonds.iloc[:,[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n].values\nr_ols = sm.OLS(endog = diamonds.iloc[:,-1:], exog =X_l).fit()\n\nprint(r_ols.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Significance Level: 0.05 we do not screen because there is no column exceeding this value.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Linear Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression()\nlin_reg.fit(x_train,y_train)\ny_pred_linReg = lin_reg.predict(x_test)\n\nprint(r2_score(y_test, y_pred_linReg))\n\nprint('coef', lin_reg.coef_,'\\n\\n')\n\nprint('intercept', lin_reg.intercept_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Polynomial Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.preprocessing import PolynomialFeatures\npoly_reg = PolynomialFeatures(degree = 1) \nx_poly = poly_reg.fit_transform(x_train) \nx_poly2 = poly_reg.fit_transform(x_test) \nlin_reg = LinearRegression()\nlin_reg.fit(x_poly, y_train)\ny_pred_poly = lin_reg.predict(x_poly2)\n\nprint(r2_score(y_test, y_pred_poly))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Support Vector Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVR\nsvr_reg = SVR(kernel = 'linear')\nsvr_reg.fit(X_train, y_train)\ny_pred_svr = svr_reg.predict(X_test)\n\nprint(r2_score(y_test, y_pred_svr))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Kernel trick: 'rbf', 'poly', 'linear', 'sigmoid', 'precomputed'","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\ndt_reg = DecisionTreeRegressor(random_state = 0)\ndt_reg.fit(X_train,y_train)\ny_pred_dt = dt_reg.predict(X_test)\n\nprint(r2_score(y_test, y_pred_dt))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrf_reg = RandomForestRegressor(random_state = 0, n_estimators = 100)\nrf_reg.fit(X_train, y_train)\ny_pred_rf = rf_reg.predict(X_test)\n\nprint(r2_score(y_test, y_pred_rf))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGBRegressor","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBRegressor\nxgb = XGBRegressor(n_estimators = 100)\nxgb.fit(x_train, y_train)\ny_pred_xgb = xgb.predict(x_test)\n\nprint(r2_score(y_test, y_pred_xgb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CLASSIFICATION","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"iris = sns.load_dataset('iris')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iris.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iris.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for n in range(0,150):\n    if iris['species'][n] == 'setosa':\n        plt.scatter(iris['sepal_length'][n], iris['sepal_width'][n], color = 'red')\n        plt.xlabel('sepal_length')\n        plt.ylabel('sepal_width')\n    elif iris['species'][n] == 'versicolor':\n        plt.scatter(iris['sepal_length'][n], iris['sepal_width'][n], color = 'blue')\n        plt.xlabel('sepal_length')\n        plt.ylabel('sepal_width')\n    elif iris['species'][n] == 'virginica':\n        plt.scatter(iris['sepal_length'][n], iris['sepal_width'][n], color = 'green')\n        plt.xlabel('sepal_length')\n        plt.ylabel('sepal_width')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lmplot(x = 'sepal_length', y = 'sepal_width', data = iris, hue = 'species', col = 'species')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = iris.iloc[:,:4].values\ny = iris.iloc[:,4:5].values\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 0)\n\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(x_train)\nX_test = sc.fit_transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modelling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_evaluate(model, test):\n    y_pred = model.predict(test)\n    print(classification_report(y_test, y_pred))\n    cm = confusion_matrix(y_test, y_pred)\n\n    categories = ['Setosa', 'Versicolor', 'Virginica']\n    \n    sns.heatmap(cm, cmap = 'Blues', fmt = '', annot = True,\n                xticklabels = categories, yticklabels = categories)\n\n    plt.xlabel(\"Predicted values\", fontdict = {'size':14}, labelpad = 10)\n    plt.ylabel(\"Actual values\"   , fontdict = {'size':14}, labelpad = 10)\n    plt.title (\"Confusion Matrix\", fontdict = {'size':18}, pad = 20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\nmodel_evaluate(model, X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Support Vector Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nmodel = SVC(kernel = 'linear') #kernel = poly, rbf, precomputed\nmodel.fit(X_train, y_train)\n\nmodel_evaluate(model, X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Naive Bayes\n\n* **Gaussian Naive Bayes**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nmodel = GaussianNB()\nmodel.fit(X_train, y_train)\n\nmodel_evaluate(model, X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Multinomial Naive Bayes**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nmodel = MultinomialNB()\nmodel.fit(x_train, y_train)\n\nmodel_evaluate(model, x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Complement Naive Bayes**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import ComplementNB\nmodel = ComplementNB()\nmodel.fit(x_train, y_train)\n\nmodel_evaluate(model, x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Bernoulli Naive Bayes**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import BernoulliNB\nmodel = BernoulliNB()\nmodel.fit(X_train, y_train)\n\nmodel_evaluate(model, X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Categorical Naive Bayes**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import CategoricalNB\nmodel = CategoricalNB()\nmodel.fit(x_train, y_train)\n\nmodel_evaluate(model, x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## KNeighbors Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nmodel = KNeighborsClassifier(n_neighbors = 3, metric = 'minkowski')\nmodel.fit(X_train, y_train)\n\nmodel_evaluate(model, X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier(random_state = 0)\nmodel.fit(X_train, y_train)\n\nmodel_evaluate(model, X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators = 10, criterion = 'entropy')\nmodel.fit(X_train, y_train)\n\nmodel_evaluate(model, X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## AdaBoost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nmodel = AdaBoostClassifier(n_estimators = 50)\nmodel.fit(X_train, y_train)\n\nmodel_evaluate(model, X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Other\n\n* **XGBClassifier**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nmodel = XGBClassifier(n_estimators = 100)\nmodel.fit(X_train, y_train)\n\nmodel_evaluate(model, X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **ExplainableBoostingClassifier**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install interpret","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from interpret.glassbox import ExplainableBoostingClassifier\nebm = ExplainableBoostingClassifier()\nebm.fit(X_train, y_train)\n\nmodel_evaluate(model, X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CLUSTERING","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mall_customers = pd.read_csv('/kaggle/input/customer-segmentation-tutorial-in-python/Mall_Customers.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mall_customers.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mall_customers.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mall_customers.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lab = mall_customers[\"Gender\"].value_counts().keys().tolist()\nval = mall_customers[\"Gender\"].value_counts().values.tolist()\n\ntrace = go.Pie(labels = lab ,\n               values = val ,\n               marker = dict(colors =  [ 'royalblue' ,'lime'],\n                             line = dict(color = \"white\",\n                                         width =  1.3)\n                            ),\n               rotation = 20,\n               hoverinfo = \"label+value+text\",\n               hole = .5\n              )\nlayout = go.Layout(dict(title = \"Customer attrition in data\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                       )\n                  )\n\ndata = [trace]\nfig = go.Figure(data = data, layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style=\"darkgrid\",font_scale=1.5)\nf, axes = plt.subplots(1,3,figsize=(20,8))\nsns.distplot(mall_customers[\"Age\"], ax = axes[0], color = 'y')     \nsns.distplot(mall_customers[\"Annual Income (k$)\"], ax = axes[1], color = 'g')\nsns.distplot(mall_customers[\"Spending Score (1-100)\"],ax = axes[2], color = 'r')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dz=ff.create_table(mall_customers.groupby('Gender').mean())\npy.iplot(dz)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,4))\nsns.heatmap(mall_customers.corr(),annot=True,cmap=sns.cubehelix_palette(light=1, as_cmap=True),fmt='.2f',linewidths=2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = mall_customers.iloc[:,2:]\nprint(x.head())\nx = x.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kMeans = KMeans(n_clusters = 3, init = 'k-means++')\ny_pred = kMeans.fit_predict(x)\nprint('Pred:\\n', y_pred)\nprint('\\n\\ninertia: ', kMeans.inertia_, '\\n\\nclusters centers:\\n', kMeans.cluster_centers_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = []\nfor i in range(1, 12):\n    kMeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 123)\n    kMeans.fit(x)        \n    result.append(kMeans.inertia_)\n\n\nplt.plot(range(1,12), result)\nplt.title('WCSS')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kMeans = KMeans(n_clusters = 6, init = 'k-means++') \ny_pred_kMeans = kMeans.fit_predict(x)\nprint('Pred:\\n', y_pred_kMeans)\nprint('\\n\\ninertia: ', kMeans.inertia_, '\\n\\nclusters centers:\\n', kMeans.cluster_centers_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hierarchical Clustering","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"agglomerative = AgglomerativeClustering(n_clusters = 6, affinity = 'euclidean', linkage = 'ward')\ny_pred_agg = agglomerative.fit_predict(x)\nprint('Pred:\\n', y_pred_agg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.cluster.hierarchy as sch\ndendrogram = sch.dendrogram(sch.linkage(x, method = 'ward'))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(1, 2, sharey='col', num = 10, figsize = (15,5))\n\nax1.scatter( x = 'Annual Income (k$)' ,y = 'Spending Score (1-100)' , data = mall_customers , c = y_pred_kMeans,s = 100)\nax1.title.set_text('KMeans')\n\nax2.scatter( x = 'Annual Income (k$)' ,y = 'Spending Score (1-100)' , data = mall_customers , c = y_pred_agg,s = 100)\nax2.title.set_text('Agglomerative')\nf.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**throwing the age column**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x = mall_customers.iloc[:,3:].values\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kMeans = KMeans(n_clusters = 6, init = 'k-means++') \ny_pred_kMeans = kMeans.fit_predict(x)\nprint('Pred:\\n', y_pred_kMeans)\nprint('\\n\\ninertia: ', kMeans.inertia_, '\\n\\nclusters centers:\\n', kMeans.cluster_centers_)\n\nresult = []\nfor i in range(1, 14):\n    kMeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 123)\n    kMeans.fit(x)        \n    result.append(kMeans.inertia_)\n\n\nplt.plot(range(1,14), result)\nplt.title('WCSS')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('K-Means')\nkMeans = KMeans(n_clusters = 5, init = 'k-means++') \ny_pred_kMeans = kMeans.fit_predict(x)\nprint('Pred:\\n', y_pred_kMeans)\nprint('\\n\\ninertia: ', kMeans.inertia_, '\\n\\nclusters centers:\\n', kMeans.cluster_centers_)\n\nprint('\\n\\nAgglomerative')\nagglomerative = AgglomerativeClustering(n_clusters = 5, affinity = 'euclidean', linkage = 'ward')\ny_pred_agg = agglomerative.fit_predict(x)\nprint('Pred:\\n', y_pred_agg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(1, 2, sharey='col', num = 10, figsize = (15,5))\n\nax1.scatter( x = 'Annual Income (k$)' ,y = 'Spending Score (1-100)' , data = mall_customers , c = y_pred_kMeans,s = 100)\nax1.title.set_text('K-Means')\nax2.scatter( x = 'Annual Income (k$)' ,y = 'Spending Score (1-100)' , data = mall_customers , c = y_pred_agg,s = 100)\nax2.title.set_text('Agglomerative')\nf.show()\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}