{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import plot_roc_curve\nfrom sklearn.model_selection import cross_val_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stars = pd.read_csv(\"../input/star-dataset/6 class csv.csv\")\nstars.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Mostly numerical data, but star color is a categorical data. Let's take a look at it a little closer.","metadata":{}},{"cell_type":"code","source":"stars[\"Star color\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These colors are not uniform. That is, what is the difference between Blue-white and Blue White? I can fix these up and reduce the number of features. ","metadata":{}},{"cell_type":"code","source":"stars[\"Star color\"] = stars[\"Star color\"].str.lower().str.replace(\" \", \"\").str.replace(\"-\", \"\")\nstars[\"Star color\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This has reduced the number of columns that are bad, but there are still a few weird things. This might be taking a bit of a leap, but I am of the opinion that yellowwhite, yellowishwhite, and whiteyellow are the same, and whitish can be grouped into white.","metadata":{}},{"cell_type":"code","source":"stars[\"Star color\"] = stars[\"Star color\"].str.replace(\"yellowishwhite\", \"yellowwhite\").str.replace(\"whiteyellow\", \"yellowwhite\").str.replace(\"whitish\", \"white\")\nstars[\"Star color\"] = stars[\"Star color\"].str.replace(\"orangered\", \"orange\").str.replace(\"paleyelloworange\", \"orange\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stars['Star color'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I am personally OK with this set up. I am willing to believe that someone legitimately classified the remaining categories as separate entities. Anyway, let's continue with the data exploration.","metadata":{}},{"cell_type":"code","source":"stars.hist(bins=20, figsize=(20,15));","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks like most of the stars are actually not too different from our own sun, at least in terms of temperature, luminosity, and radius. The sun's abolute magnitude is ~4.83, so it actually exists in the region of the Absolute Magnitude plot that is less occupied by the general population.","metadata":{}},{"cell_type":"markdown","source":"How do some of the features correlate with each other?","metadata":{}},{"cell_type":"code","source":"corr_mat = stars.corr()\nsns.heatmap(corr_mat, annot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It looks like there is a failr negative correlation between Absolute Magnitude and Star Type, with lots of other featues in between $\\pm 0.5$","metadata":{}},{"cell_type":"markdown","source":"# Now let's get into some preprocessing.","metadata":{}},{"cell_type":"markdown","source":"First, split the data into training and test data","metadata":{}},{"cell_type":"code","source":"X = stars.drop(\"Star type\", axis=1)\ny = stars[\"Star type\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we do need to handle the object columns so that our algorith will handle them properly.","metadata":{}},{"cell_type":"code","source":"enc = OneHotEncoder(handle_unknown='ignore')\n\ncat_columns = [\"Star color\", 'Spectral Class']\nnum_columns = [\"Temperature (K)\", \"Luminosity(L/Lo)\", \"Radius(R/Ro)\", \"Absolute magnitude(Mv)\"]\n\none_hot = ColumnTransformer([(\"one_hot\", enc, cat_columns)], remainder=\"passthrough\")\nscaler = StandardScaler()\npreprocessor = ColumnTransformer(\n                transformers=[\n                    (\"cat\", one_hot, cat_columns),\n                    (\"scale\", scaler, num_columns)\n                ])\nmodel = Pipeline(steps=\n                [(\"preprocessor\", preprocessor),\n                (\"model\", RandomForestClassifier())\n                ])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I am going to use a Random Forest for this problem. If that does not prove terribly useful, I will reasses and try another model.","metadata":{}},{"cell_type":"code","source":"model.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So our accuracy is 1.0, which means that the model accurately classified every star in the test set. This is good, and I think for a simpler data set like this one, it is OK to leave it at that. I think was a good exercise in getting used to typing out ML code.","metadata":{}}]}