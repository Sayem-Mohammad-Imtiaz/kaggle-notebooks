{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Print multiple lines within same cell\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n# Show all columns and rows\nfrom IPython.display import display\npd.options.display.max_columns = None\npd.options.display.max_rows = None\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix,accuracy_score\nimport os\nimport itertools\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"zomato=pd.read_csv(\"../input/zomato.csv\",encoding='latin1')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd90bef295bc2230410d3cab9761052fed34d34c"},"cell_type":"markdown","source":"# 1) Inspect data and get a general feel for variables"},{"metadata":{"trusted":true,"_uuid":"59dc719f79458b52b2ab60365fbbf3ddd4f67d27"},"cell_type":"code","source":"# Size of data and how it looks\nzomato.shape\nzomato.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73a52d0479cc88bddba9bf46ecc805f30eeb3d53"},"cell_type":"code","source":"# How many missing values and where\n# How many missing values an which column\nzomato.isnull().values.sum()\nzomato.isnull().any()[zomato.isnull().any()==True]\n# Cuisines is the only feature which has null values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5ae0dda4a5f5fe6151c273b76d26589e92c2ef67"},"cell_type":"markdown","source":"***There are 9 missing values in feature Cusines. We will drop these rows from the data, as we cannot impute these values unless we go their website, and am too lazy for that :)*******"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"253a26945423af778550a82cc59539c8c4dfe741"},"cell_type":"code","source":"# removing rows with missing values\nzomato.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"755f10e21df49b21492bc12adbad3dafea08bf5c"},"cell_type":"code","source":"# Let's remove the features we do not want to use for our modelling\nrelvnt=zomato.drop(['Restaurant ID', 'Restaurant Name',\n                        'Address','Locality Verbose', 'Longitude', 'Latitude', 'Rating color','Aggregate rating'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9b3ebc2a65bd7976ee16b39f24fb64b6ea1b817"},"cell_type":"markdown","source":"# 2) Let's perform some feature engineering"},{"metadata":{"_uuid":"5bd34759002930bf3f11bec7b974f32fc200902f"},"cell_type":"markdown","source":"Since We plan to apply random forest we need to do one hot encoding on the categorical variables"},{"metadata":{"trusted":true,"_uuid":"a6906299a3b85f28ca1ccfdc1ed5bdde6b46f2dc"},"cell_type":"code","source":"# Let's find out variables that are categorical:\ncategorical=[]\nfor i in relvnt.columns:\n    if relvnt[i].dtype=='object':\n        categorical.append(i)\n# Which variables are categorical ?\nprint(categorical)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d4e087c6822ad58b16fcd8ca74ed06ee47fc51d5"},"cell_type":"markdown","source":"Lets convert these categorical variables using one hot encoding into new features except target variable \"Rating Text\""},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"53cb6f85b166f2d62d5edcf27105c18dd3389412"},"cell_type":"code","source":"for i in categorical:\n    if i!='Rating text':\n        relvnt=pd.concat([relvnt,pd.get_dummies(relvnt[i],prefix=i)],axis=1)\n        relvnt.drop(i,axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9114ae2ec665ba221a5d3ca13966edd90e091d6b"},"cell_type":"markdown","source":"Covert target variable \"Rating Text\" to numerical values and select are predictor variables in new dataframe"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1d13e60c5481635275bb3b5b5224e54559accfe6"},"cell_type":"code","source":"target=relvnt['Rating text']\ntarget_map={'Excellent':1, 'Very Good':2, 'Good':3, 'Average':4, 'Not rated':5, 'Poor':6}\ntarget=target.apply(lambda x: target_map[x])\npredictors=relvnt.drop('Rating text',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a613cbb9e9e0cbb660e814e30beebf76168d2847"},"cell_type":"code","source":"target=relvnt['Rating text']\nsns.countplot(target)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e0575d1f534237c10de70606d045844635bd081b"},"cell_type":"markdown","source":"# 3) Applying Random Forest Model using Grid Search"},{"metadata":{"trusted":true,"_uuid":"7eb795fb472a88c5c11709e49ba0338ffa0cd4c0"},"cell_type":"code","source":"# Splitting data into train and test set\nX_train,X_test,Y_train,Y_test=train_test_split(predictors,target,test_size=.33)\n\nfrom sklearn.model_selection import GridSearchCV\n\n# Create Grid search funtion\ndef rfzomato(X,Y,nfolds):\n    n_est=[100,300,500]\n    min_samples_split=[10,50,100]\n    param_grid={'n_estimators':n_est,'min_samples_split':min_samples_split}\n    grid_search=GridSearchCV(RandomForestClassifier(random_state=42,n_jobs=-1),cv=nfolds,param_grid=param_grid)\n    grid_search.fit(X,Y)\n    return grid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f10192ca32b28f34775a2db5af34574cf08a6b4e"},"cell_type":"markdown","source":"# 4) Applying Random forest model"},{"metadata":{"trusted":true,"_uuid":"1195b4380f97fea1ee37705ffc3fc908ab9a5184"},"cell_type":"code","source":"m=rfzomato(X_train,Y_train,5)\nrandFor=RandomForestClassifier(random_state=42,n_jobs=-1,n_estimators=m['n_estimators'],min_samples_split=m['min_samples_split'])\nrandFor.fit(X_train,Y_train)\nY_pred=randFor.predict(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"355d8ddff1b8fad6baa3e14715cfdda32a3a9ba7"},"cell_type":"code","source":"acc_score=accuracy_score(Y_test,Y_pred)\ncnf_mat=confusion_matrix(Y_test,Y_pred)\nprint (\"accuracy score\",acc_score)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0de1a645c6f9ef414c2227ecea2d650222702ab1"},"cell_type":"code","source":"# Function to plot confusion matrix\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    target_map={1:'Excellent',2:'Very Good', 3:'Good', 4:'Average', 5:'Not rated', 6:'Poor'}\n    classes=pd.Series(classes)\n    classes=classes.apply(lambda x: target_map[x])            \n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a557962486262f94ec5aca359b30785865f67e0e"},"cell_type":"code","source":"# Plot confusion matrix \nplt.figure()\nplot_confusion_matrix(cnf_mat, classes=target.unique(),\n                      title='Confusion matrix, without normalization')\n\n# Plot normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_mat, classes=target.unique(), normalize=True,\n                      title='Normalized confusion matrix')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6264ccf71c8d5c84186d4de6fe38c0339a69630e"},"cell_type":"markdown","source":"# We have 76 % accuracy which is pretty good in this case"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}