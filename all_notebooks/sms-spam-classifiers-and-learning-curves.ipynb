{"cells":[{"metadata":{},"cell_type":"markdown","source":"   # SMS spam classifiers and learning curves"},{"metadata":{},"cell_type":"markdown","source":"In this notebook I build some alternatives of classifiers and I evaluate them by means of learning curves."},{"metadata":{},"cell_type":"markdown","source":"## Loading libraries and checking input folder"},{"outputs":[],"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"_cell_guid":"f3ce6f65-b217-46a9-b8b5-dd5d14a353d5","_uuid":"d54f06f79e433af73de5b35f3e3fb7c4eae8a538"},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import ShuffleSplit\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":33},{"metadata":{},"cell_type":"markdown","source":"## Method to plot learning curves"},{"metadata":{},"cell_type":"markdown","source":"Source: [http://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html](http://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html)"},{"outputs":[],"metadata":{"collapsed":true},"cell_type":"code","source":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n    \"\"\"\n    Generate a simple plot of the test and training learning curve.\n\n    Parameters\n    ----------\n    estimator : object type that implements the \"fit\" and \"predict\" methods\n        An object of that type which is cloned for each validation.\n\n    title : string\n        Title for the chart.\n\n    X : array-like, shape (n_samples, n_features)\n        Training vector, where n_samples is the number of samples and\n        n_features is the number of features.\n\n    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n        Target relative to X for classification or regression;\n        None for unsupervised learning.\n\n    ylim : tuple, shape (ymin, ymax), optional\n        Defines minimum and maximum yvalues plotted.\n\n    cv : int, cross-validation generator or an iterable, optional\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n          - None, to use the default 3-fold cross-validation,\n          - integer, to specify the number of folds.\n          - An object to be used as a cross-validation generator.\n          - An iterable yielding train/test splits.\n\n        For integer/None inputs, if ``y`` is binary or multiclass,\n        :param train_sizes:\n        :class:`StratifiedKFold` used. If the estimator is not a classifier\n        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validators that can be used here.\n\n    n_jobs : integer, optional\n        Number of jobs to run in parallel (default 1).\n    \"\"\"\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt","execution_count":34},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing the data"},{"metadata":{},"cell_type":"markdown","source":"After loading the data, we drop some columns that hardly have non-null data, we transform the class column to categorical, we rename its columns, and finally, we put them in a natural order, that is, first the \"text\" column and then the \"isspam\" column."},{"outputs":[],"metadata":{},"cell_type":"code","source":"df = pd.read_csv('../input/spam.csv', encoding='latin-1')\ndf.drop(df.columns[[2, 3, 4]], axis=1, inplace=True)\ndf['v1'] = df['v1'].astype('category').cat.codes\ndf.rename(index=str, columns={\"v1\": \"isspam\", \"v2\": \"text\"}, inplace=True)\ndf = df[['text', 'isspam']]\ndf.head()","execution_count":35},{"metadata":{},"cell_type":"markdown","source":"We need to create the features from raw text. So, we apply some transformation and normalisation to the text before that."},{"outputs":[],"metadata":{},"cell_type":"code","source":"# Preprocess:\n# lowercase\ndf.text = df.text.str.lower()\n# numbers\ndf.text = df.text.str.replace('\\d+', ' number ')\n# urls\ndf.text = df.text.str.replace('(http|https)://[^\\s]*', ' httpaddr ')\n# email adresses\ndf.text = df.text.str.replace('[^\\s]+@[^\\s]+', ' emailaddr ')\n\ndf.head()","execution_count":36},{"metadata":{},"cell_type":"markdown","source":"But we realise that some weird symbols (å) exists in the text near the pounds symbol."},{"outputs":[],"metadata":{},"cell_type":"code","source":"df[df['text'].str.contains(\"[£]+\")].head(10)","execution_count":37},{"metadata":{},"cell_type":"markdown","source":"There are other special symbols."},{"outputs":[],"metadata":{},"cell_type":"code","source":"df[df['text'].str.contains(\"&lt;#&gt;\")].head()","execution_count":38},{"outputs":[],"metadata":{},"cell_type":"code","source":"df[df['text'].str.contains(\"<|>\")].head()","execution_count":39},{"metadata":{},"cell_type":"markdown","source":"And we realise that those symbols help to classify some rows of our data. So, we need to use them as a features."},{"outputs":[],"metadata":{},"cell_type":"code","source":"df[df['text'].str.contains(\"&lt;#&gt;\")].groupby('isspam').describe()","execution_count":40},{"outputs":[],"metadata":{},"cell_type":"code","source":"df[df['text'].str.contains(\"<|>\")].groupby('isspam').describe()","execution_count":41},{"metadata":{},"cell_type":"markdown","source":"We perform the last transformations to the text."},{"outputs":[],"metadata":{},"cell_type":"code","source":"df.text = df.text.str.replace('&lt;#&gt;', ' impltgt ')\ndf.text = df.text.str.replace('<|>', ' expltgt ')\ndf.text = df.text.str.replace('[^a-zA-Z0-9\\s]+', ' othersym ')\ndf.text = df.text.str.replace('\\s+', ' ')\ndf.head()","execution_count":42},{"metadata":{},"cell_type":"markdown","source":"## Computing features using CountVectorizer"},{"outputs":[],"metadata":{},"cell_type":"code","source":"count_vect = CountVectorizer(max_df=0.99, min_df=0.01)\nX = count_vect.fit_transform(df.text)\ny = df.isspam\nX.shape","execution_count":43},{"metadata":{},"cell_type":"markdown","source":"Now, we create the learning curves by means of Scikit-learn method. We need to create a ShuffleSplit to configure the sizes of our splits."},{"outputs":[],"metadata":{"collapsed":true},"cell_type":"code","source":"# Shuffle for learning curves\ncv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)","execution_count":44},{"metadata":{},"cell_type":"markdown","source":"### Train using SVC"},{"outputs":[],"metadata":{},"cell_type":"code","source":"from sklearn.svm import SVC\nmodel_svc = SVC(kernel='rbf', gamma=0.001, C=1.0)\nplot_learning_curve(model_svc, 'Learning Curve (SVC)', X, y, (0.7, 1.01), cv=cv, n_jobs=4)\nplt.show()","execution_count":45},{"metadata":{},"cell_type":"markdown","source":"### Train using GaussianNB"},{"outputs":[],"metadata":{},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nmodel_gnb = GaussianNB()\nplot_learning_curve(model_gnb, 'Learning Curve (Gaussian NB)', X.toarray(), y, (0.5, 1.01), cv=cv, n_jobs=4)\nplt.show()","execution_count":46},{"metadata":{},"cell_type":"markdown","source":"### Train using MultinomialNB"},{"outputs":[],"metadata":{},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nmodel_mnb = MultinomialNB()\nplot_learning_curve(model_mnb, 'Learning Curve (Multinomial NB)', X.toarray(), y, (0.7, 1.01), cv=cv, n_jobs=4)\nplt.show()","execution_count":47},{"metadata":{},"cell_type":"markdown","source":"### Train using Random Forest"},{"outputs":[],"metadata":{},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nmodel_rb = RandomForestClassifier(random_state=0)\nplot_learning_curve(model_rb, 'Learning Curve (Random Forest)', X, y, (0.7, 1.01), cv=cv, n_jobs=4)\nplt.show()","execution_count":48},{"metadata":{},"cell_type":"markdown","source":"### Training with Multilayer Perceptron Classifier"},{"outputs":[],"metadata":{},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nmodel_mlp = MLPClassifier()\nplot_learning_curve(model_rb, 'Learning Curve (Multilayer Perceptron)', X, y, (0.7, 1.01), cv=cv, n_jobs=4)\nplt.show()","execution_count":49},{"metadata":{},"cell_type":"markdown","source":"We conclude that GaussianNB clearly fails, both SVC and MultinomialNB perform good results but with some bias, and finally, both RandomForestClassifier and MLPClassifier also perform good results but with some variance, so, it is feasible to improve them with more data."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"nbconvert_exporter":"python","version":"3.6.4","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","name":"python","file_extension":".py","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}