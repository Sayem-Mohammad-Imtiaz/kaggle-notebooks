{"cells":[{"metadata":{},"cell_type":"markdown","source":"# IESB - Graduacao - CIA028 - Cross Validation e OOB"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Doenças cardiovasculares - Modelo de classificação binária"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importando a base\ndf_cardio = pd.read_csv('/kaggle/input/cardiovascular-disease-dataset/cardio_train.csv', sep=';')\n\ndf_cardio.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizando os dados\ndf_cardio.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tipos e tamanhos\ndf_cardio.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecionando as colunas para treinamento\nfeats = [c for c in df_cardio.columns if c not in ['id', 'cardio']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separando o dataframe\nfrom sklearn.model_selection import train_test_split\n\ntrain, test = train_test_split(df_cardio, random_state = 42, test_size=0.1)\n\ntrain, valid = train_test_split(train, random_state = 42, test_size=0.1)\n\ntrain.shape, valid.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Treinando um modelo de RF Classifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42)\n\nrf.fit(train[feats], train['cardio'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fazendo previsões com o modelo treinado na base de validação\npreds_val = rf.predict(valid[feats])\n\npreds_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizando os 3 primeiros registros da base de validação\nvalid.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizando os 3 últimos registros da base de validação\nvalid.tail(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando o desempenho de acordo com a métrica - base de validação\nfrom sklearn.metrics import accuracy_score\n\naccuracy_score(valid['cardio'], preds_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos verificar qual o valor de base para a coluna target da base de validação\nvalid['cardio'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fazendo previsões com o modelo treinado na base de teste\npreds_test = rf.predict(test[feats])\n\npreds_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificandos os 3 primeiros registros da base de teste\ntest.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando o desempenho de acordo com a métrica - base de teste\naccuracy_score(test['cardio'], preds_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cross Validation\nConjunto de técnicas que usam os próprios dados de treinamento para realizar a validação do modelo.\n\nComo o modelo deve ser validado com dados que não foram usados ainda, são aplicadas técnicas específicas para separar alguns dados de treino e assim realizar a validação.\n\nA vantagem é não precisar dividir nossos dados de treino em conjuntos de treino e validação, já que a validação vai ser feita pelo Cross Validation. Isso é extremamente útil principalmente em conjunto de dados pequenos, onde a separação em treino e validação pode reduzir muito o conjunto de dados de treinamento e com isso comprometer o desempenho do modelo.\n\nUm exemplo de técnica é o KFold, que divide os dados de treino em k iterações e para cada iteração uma amostra dos dados de treino é separada para fazer validação.\n\n\n![Cross](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dividindo novamente os dados apenas em treino e teste\ntrain, test = train_test_split(df_cardio, random_state = 42, test_size=0.1)\n\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando um modelo de RF Classifier e usando o Cross Validation\nrf = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42)\n\nfrom sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(rf, train[feats], train['cardio'], cv=5, n_jobs=-1)\n\nscores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Médias dos scores de validação\nscores.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Treinamento e fazendo previsões\nrf.fit(train[feats], train['cardio'])\n\npreds_test = rf.predict(test[feats])\n\naccuracy_score(test['cardio'], preds_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## OOB - Out Of Bag\nInicialmente precisamos lembrar como funciona o modelo de random forest: são criadas diversas árvores de decisão que recebem amostras dos dados originais. Essas amostras são criadas de forma aleatória, com repetição.\n\n![random](https://miro.medium.com/max/1050/1*ixvrbH45K8CcNZaj98JGuA.png)\n\nÉ fácil notar que, em cada árvore criada, alguns dados foram usados e outros não. Ou seja, para cada árvore, alguns dados entraram na cesta de dados de treinamento, enquanto outros ficaram fora da cesta de treinamento (out of bag).\n\n![oob](https://miro.medium.com/max/1043/1*_J-O7FJ99a3Zehb3eUlqcg.png)\n\nPara cada árvore existe um conjunto de dados que o modelo nunca viu, aqueles que ficaram fora da cesta de treinamento. Então, podemos usar esses dados nunca vistos pela árvore para fazer a validação da própria árvore, uma vez que precisamos de dados não usados no treinamento para realizarmos a validação.\n\nPara usar o conceito de OOB e determinar que o modelo deve ser validado com o dados que ele mesmo deixou de fora do treinamento, basta usar o parâmetro **oob_score = True** no momento de instanciar o modelo de Randon Forest.\n\nMais uma vez, esse artifício é de grande valia para bases pequenas, pois não precisamos criar uma base de dados de validação, mas apenas usar para validação os dados que o próprio modelo descartou.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dividindo novamente os dados apenas em treino e teste\ntrain, test = train_test_split(df_cardio, random_state = 42, test_size=0.1)\n\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Treinando um modelo de RF Classifier usando oob_score\nrf = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42, oob_score=True)\n\nrf.fit(train[feats], train['cardio'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fazendo previsões com o modelo treinado na base de teste\npreds_test = rf.predict(test[feats])\n\naccuracy_score(test['cardio'], preds_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Melhorando os parâmetros do modelo Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Treinando um modelo de RF Classifier\nrf = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42, oob_score=True,\n                           min_samples_leaf=5, min_samples_split=20, max_depth=10)\n\nrf.fit(train[feats], train['cardio'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fazendo previsões com o modelo treinado na base de teste\npreds_test = rf.predict(test[feats])\n\naccuracy_score(test['cardio'], preds_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mudando os parametros\n\n# Treinando um modelo de RF Classifier\nrf = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42, oob_score=True,\n                           min_samples_leaf=5, min_samples_split=15, max_depth=20)\n\nrf.fit(train[feats], train['cardio'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fazendo previsões com o modelo treinado na base de teste\npreds_test = rf.predict(test[feats])\n\naccuracy_score(test['cardio'], preds_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}