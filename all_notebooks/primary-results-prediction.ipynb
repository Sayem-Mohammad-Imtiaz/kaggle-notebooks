{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import pandas as pd\nfrom pandas import Series,DataFrame\nimport numpy as np\nimport sklearn\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import BayesianRidge\nfrom sklearn.cross_validation import train_test_split\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\n%matplotlib inline"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#-----------------------------------------------------------------------------------------------\ndef prediction_ols (X_train, Y_train, X_test, Y_test,normalize):\n    \"\"\"\n    The function gets train and test data sets, normalize flag (True/False)\n    and returns predictions for test and train data sets as well as coefficients\n    based on ordinary least squares prediction method\n    \"\"\"\n    # Print shapes of the training and testing data sets\n    print (\"Shapes of the training and testing data sets\")\n    print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n\n\n    #Create our regression object\n    lreg = LinearRegression(normalize=normalize)\n\n    #do a linear regression, except only on the training\n    lreg.fit(X_train,Y_train)\n\n    print(\"The estimated intercept coefficient is %.2f \" %lreg.intercept_)\n    print(\"The number of coefficients used was %d \" % len(lreg.coef_))\n\n\n\n    # Set a DataFrame from the Facts\n    coeff_df = DataFrame(X_train.columns)\n    coeff_df.columns = [\"Fact\"]\n\n\n    # Set a new column lining up the coefficients from the linear regression\n    coeff_df[\"Coefficient\"] = pd.Series(lreg.coef_)\n\n\n    # Show\n    #coeff_df\n\n    #highest correlation between a fact and fraction votes\n    print (\"Highest correlation fact: %s is %.9f\" % (cf_dict.loc[coeff_df.iloc[coeff_df[\"Coefficient\"].idxmax()][\"Fact\"],\"description\"], coeff_df.iloc[coeff_df[\"Coefficient\"].idxmax()][\"Coefficient\"]) )\n    #sns_plot = sns.jointplot(coeff_df.iloc[coeff_df[\"Coefficient\"].idxmax()][\"Fact\"],\"Fraction Votes\",pd.merge(X_test,pd.DataFrame(Y_test), right_index=True, left_index=True),kind=\"scatter\")\n\n\n    #Predictions on training and testing sets\n    pred_train = lreg.predict(X_train)\n    pred_test = lreg.predict(X_test)\n\n    # The mean square error\n    print(\"Fit a model X_train, and calculate MSE with Y_train: %.6f\"  % np.mean((Y_train - pred_train) ** 2))\n    print(\"Fit a model X_test, and calculate MSE with Y_test: %.6f\"  %np.mean((Y_test - pred_test) ** 2))\n    #Explained variance score: 1 is perfect prediction\n    print(\"Variance score: %.2f\" % lreg.score(X_test, Y_test))\n\n    \n    return pred_test,coeff_df,pred_train\n#-----------------------------------------------------------------------------------------------\ndef prediction_ridge (X_train, Y_train, X_test, Y_test,alpha,normalize):\n    \"\"\"\n    The function gets train and test data sets, normalize flag (True/False)\n    and returns predictions for test and train data sets as well as coefficients\n    based on Ridge method\n    \"\"\"\n    # Print shapes of the training and testing data sets\n    print (\"Shapes of the training and testing data sets\")\n    print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n    #Create our regression object\n\n    lreg = Ridge (alpha = alpha,normalize=normalize)\n\n    #do a linear regression, except only on the training\n    lreg.fit(X_train,Y_train)\n\n    print(\"The estimated intercept coefficient is %.2f \" %lreg.intercept_)\n    print(\"The number of coefficients used was %d \" % len(lreg.coef_))\n\n\n\n    # Set a DataFrame from the Facts\n    coeff_df = DataFrame(X_train.columns)\n    coeff_df.columns = [\"Fact\"]\n\n\n    # Set a new column lining up the coefficients from the linear regression\n    coeff_df[\"Coefficient\"] = pd.Series(lreg.coef_)\n\n\n    # Show\n    #coeff_df\n\n    #highest correlation between a fact and fraction votes\n    print (\"Highest correlation fact: %s is %.9f\" % (cf_dict.loc[coeff_df.iloc[coeff_df[\"Coefficient\"].idxmax()][\"Fact\"],\"description\"], coeff_df.iloc[coeff_df[\"Coefficient\"].idxmax()][\"Coefficient\"]) )\n\n    #sns_plot = sns.jointplot(coeff_df.iloc[coeff_df[\"Coefficient\"].idxmax()][\"Fact\"],\"Fraction Votes\",pd.merge(X_test,pd.DataFrame(Y_test), right_index=True, left_index=True),kind=\"scatter\")\n\n\n    #Predictions on training and testing sets\n    pred_train = lreg.predict(X_train)\n    pred_test = lreg.predict(X_test)\n\n    # The mean square error\n    print(\"Fit a model X_train, and calculate MSE with Y_train: %.6f\"  % np.mean((Y_train - pred_train) ** 2))\n    print(\"Fit a model X_test, and calculate MSE with Y_test: %.6f\"  %np.mean((Y_test - pred_test) ** 2))\n\n    #Explained variance score: 1 is perfect prediction\n    print(\"Variance score: %.2f\" % lreg.score(X_test, Y_test))\n\n    return pred_test,coeff_df,pred_train\n#-----------------------------------------------------------------------------------------------\ndef prediction_lasso (X_train, Y_train, X_test, Y_test,alpha,normalize):\n    \"\"\"\n    The function gets train and test data sets, normalize flag (True/False)\n    and returns predictions for test and train data sets as well as coefficients\n    based on Lasso method\n    \"\"\"\n    # Print shapes of the training and testing data sets\n    print (\"Shapes of the training and testing data sets\")\n    print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n    #Create our regression object\n\n    lreg = Lasso (alpha = alpha,normalize=normalize)\n\n    #do a linear regression, except only on the training\n    lreg.fit(X_train,Y_train)\n\n    print(\"The estimated intercept coefficient is %.2f \" %lreg.intercept_)\n    print(\"The number of coefficients used was %d \" % len(lreg.coef_))\n\n\n\n    # Set a DataFrame from the Facts\n    coeff_df = DataFrame(X_train.columns)\n    coeff_df.columns = [\"Fact\"]\n\n\n    # Set a new column lining up the coefficients from the linear regression\n    coeff_df[\"Coefficient\"] = pd.Series(lreg.coef_)\n\n\n    # Show\n    #coeff_df\n\n    #highest correlation between a fact and fraction votes\n    print (\"Highest correlation fact: %s is %.9f\" % (cf_dict.loc[coeff_df.iloc[coeff_df[\"Coefficient\"].idxmax()][\"Fact\"],\"description\"], coeff_df.iloc[coeff_df[\"Coefficient\"].idxmax()][\"Coefficient\"]) )\n\n    #sns_plot = sns.jointplot(coeff_df.iloc[coeff_df[\"Coefficient\"].idxmax()][\"Fact\"],\"Fraction Votes\",pd.merge(X_test,pd.DataFrame(Y_test), right_index=True, left_index=True),kind=\"scatter\")\n\n\n    #Predictions on training and testing sets\n    pred_train = lreg.predict(X_train)\n    pred_test = lreg.predict(X_test)\n\n    # The mean square error\n    print(\"Fit a model X_train, and calculate MSE with Y_train: %.6f\"  % np.mean((Y_train - pred_train) ** 2))\n    print(\"Fit a model X_test, and calculate MSE with X_test and Y_test: %.6f\"  %np.mean((Y_test - pred_test) ** 2))\n\n    #Explained variance score: 1 is perfect prediction\n    print(\"Variance score: %.2f\" % lreg.score(X_test, Y_test))\n\n    return pred_test,coeff_df,pred_train\n#-----------------------------------------------------------------------------------------------\ndef prediction_BayesianRidge (X_train, Y_train, X_test, Y_test,normalize):\n    \"\"\"\n    The function gets train and test data sets, normalize flag (True/False)\n    and returns predictions for test and train data sets as well as coefficients\n    based on BayesianRidge method\n    \"\"\"\n    # Print shapes of the training and testing data sets\n    print (\"Shapes of the training and testing data sets\")\n    print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n    #Create our regression object\n\n    lreg = BayesianRidge(normalize=normalize)\n\n    #do a linear regression, except only on the training\n    lreg.fit(X_train,Y_train)\n\n    print(\"The estimated intercept coefficient is %.2f \" %lreg.intercept_)\n    print(\"The number of coefficients used was %d \" % len(lreg.coef_))\n\n\n\n    # Set a DataFrame from the Facts\n    coeff_df = DataFrame(X_train.columns)\n    coeff_df.columns = [\"Fact\"]\n\n\n    # Set a new column lining up the coefficients from the linear regression\n    coeff_df[\"Coefficient\"] = pd.Series(lreg.coef_)\n\n\n    # Show\n    #coeff_df\n\n    #highest correlation between a fact and fraction votes\n    print (\"Highest correlation fact: %s is %.9f\" % (cf_dict.loc[coeff_df.iloc[coeff_df[\"Coefficient\"].idxmax()][\"Fact\"],\"description\"], coeff_df.iloc[coeff_df[\"Coefficient\"].idxmax()][\"Coefficient\"]) )\n\n    #sns_plot = sns.jointplot(coeff_df.iloc[coeff_df[\"Coefficient\"].idxmax()][\"Fact\"],\"Fraction Votes\",pd.merge(X_test,pd.DataFrame(Y_test), right_index=True, left_index=True),kind=\"scatter\")\n\n\n    #Predictions on training and testing sets\n    pred_train = lreg.predict(X_train)\n    pred_test = lreg.predict(X_test)\n\n    # The mean square error\n    print(\"MSE with X_train and Y_train: %.6f\"  % np.mean((Y_train - pred_train) ** 2))\n    print(\"MSE with X_test and Y_test: %.6f\"  %np.mean((Y_test - pred_test) ** 2))\n\n    #Explained variance score: 1 is perfect prediction\n    print(\"Variance score: %.2f\" % lreg.score(X_test, Y_test))\n\n    return pred_test,coeff_df,pred_train\n#-----------------------------------------------------------------------------------------------\ndef residual_plot(Y_train, pred_train, Y_test, pred_test, candidate, test_dataset_name, train_dataset_name,method):\n    \"\"\"\n    The function builds the residual plot to show the difference between the observed value \n    of the dependent variable (y) and the predicted value (Å·)\n    \"\"\"\n    \n    # Scatter plot the training data\n    train = plt.scatter(pred_train,(Y_train-pred_train),c=\"b\",alpha=0.5)\n    # Scatter plot the testing data\n    test = plt.scatter(pred_test,(Y_test-pred_test),c=\"r\",alpha=0.5)\n    # Plot a horizontal axis line at 0\n    plt.hlines(y=0,xmin=-0.5,xmax=1)\n\n    #Labels\n    plt.legend((train,test),(\"Train\",\"Test\"),loc=\"lower left\")\n    plt.title(\"Residual Plots for %s  using %s method \" % (candidate, method) )\n   \n#-----------------------------------------------------------------------------------------------\ndef vis_results(Y_train, pred_train, Y_test, pred_test, candidate, test_dataset_name, train_dataset_name,method):\n    \"\"\"\n    The function builds residual and joinplots for the predicted results\n    \"\"\"\n    #prediction in csv\n    CandidateFractionPrediction=pd.DataFrame(Y_test)\n    CandidateFractionPrediction[\"Prediction\"]=pred_test\n    CandidateFractionPrediction=pd.merge(CandidateFractionPrediction,facts[[\"area_name\",\"state_abbreviation\"]], right_index=True, left_index=True)\n    CandidateFractionPrediction=CandidateFractionPrediction.reset_index()\n    CandidateFractionPrediction.columns=[\"fips\", \"Fraction Votes\", \"Prediction\", \"county\", \"state\"]\n    CandidateFractionPrediction[CandidateFractionPrediction[\"state\"]==\"CA\"]\n    \n    #joinplot\n    sns_plot = sns.jointplot(\"Fraction Votes\",\"Prediction\",CandidateFractionPrediction,kind=\"scatter\")\n    #residual plot\n    plt.close()\n    residual_plot(Y_train, pred_train, Y_test, pred_test, candidate, test_dataset_name, train_dataset_name,method)\n    \n    #-----------------------------------------------------------------------------------------------\ndef get_data(candidate):\n    \"\"\"\n    Builds the source data for a candidate (name, string)\n    \"\"\"\n    # source data\n    pr=pd.read_csv(\"../input/primary_results.csv\")\n    #pivoting and drop Null values for clean and easy analysis\n    pr_piv= pr[[\"fips\", \"candidate\",\"fraction_votes\"]].pivot_table(index=\"fips\", columns=\"candidate\", values=\"fraction_votes\")\n    pr_piv.drop(\" No Preference\", axis=1, inplace=True)\n    pr_piv.drop(\" Uncommitted\", axis=1, inplace=True)\n\n    #merge fraction votes and facts to have a complete data set for all counties for each candidate\n    pr_facts=pd.merge(pr_piv, facts, right_index=True, left_index=True)\n\n    Candidate_data=pr_facts[[candidate,\"PST045214\", \"PST040210\", \"PST120214\", \"POP010210\", \"AGE135214\",\"AGE295214\", \"AGE775214\", \"SEX255214\", \"RHI125214\", \"RHI225214\",\"RHI325214\", \"RHI425214\", \"RHI525214\", \"RHI625214\", \"RHI725214\",\"RHI825214\", \"POP715213\", \"POP645213\", \"POP815213\",\"VET605213\", \"LFE305213\", \"HSG010214\", \"HSG445213\",\"HSG096213\", \"HSG495213\", \"HSD410213\", \"HSD310213\", \"INC910213\",\"INC110213\", \"PVY020213\", \"BZA010213\", \"BZA110213\", \"BZA115213\",\"NES010213\", \"SBO001207\", \"SBO315207\", \"SBO115207\", \"SBO215207\",\"SBO515207\", \"SBO415207\", \"SBO015207\", \"MAN450207\", \"WTN220207\",\"RTN130207\", \"RTN131207\", \"AFN120207\", \"BPS030214\", \"LND110210\",\"POP060210\"]]\n    Candidate_data=Candidate_data.dropna()\n    Candidate_data.columns=[\"Fraction Votes\",\"PST045214\", \"PST040210\", \"PST120214\", \"POP010210\", \"AGE135214\",\"AGE295214\", \"AGE775214\", \"SEX255214\", \"RHI125214\", \"RHI225214\",\"RHI325214\", \"RHI425214\", \"RHI525214\", \"RHI625214\", \"RHI725214\",\"RHI825214\", \"POP715213\", \"POP645213\", \"POP815213\",\"VET605213\", \"LFE305213\", \"HSG010214\", \"HSG445213\",\"HSG096213\", \"HSG495213\", \"HSD410213\", \"HSD310213\", \"INC910213\",\"INC110213\", \"PVY020213\", \"BZA010213\", \"BZA110213\", \"BZA115213\",\"NES010213\", \"SBO001207\", \"SBO315207\", \"SBO115207\", \"SBO215207\",\"SBO515207\", \"SBO415207\", \"SBO015207\", \"MAN450207\", \"WTN220207\",\"RTN130207\", \"RTN131207\", \"AFN120207\", \"BPS030214\", \"LND110210\",\"POP060210\"]\n    Candidate_fractions=Candidate_data[\"Fraction Votes\"]\n    Candidate_facts=Candidate_data.drop(\"Fraction Votes\", 1)\n\n    return Candidate_facts,Candidate_fractions\n#-----------------------------------------------------------------------------------------------\ndef run(candidate):\n    \"\"\"\n    Runs prediction and visualizes results for a candidate (name, string)\n    \"\"\"\n    print (\"----------%s PRIMARY RESULTS PREDICTION------------\" %candidate)\n\n    test_dataset_name=\"Test part\"\n    train_dataset_name=\"Train part\"\n\n    #get source data\n    Candidate_facts,Candidate_fractions=get_data(candidate)\n\n    #separate to training and test data sets\n    X_train, X_test, Y_train, Y_test = train_test_split(Candidate_facts,Candidate_fractions)\n\n    #Prediction\n    #multi\n    print (\"----------------------Ordinary least square  ------------\")\n    pred_test,coeff_df,pred_train=prediction_ols (X_train, Y_train, X_test, Y_test,False)\n    vis_results(Y_train, pred_train, Y_test, pred_test, candidate, test_dataset_name, train_dataset_name,'ols')\n    \n    print (\"------------------------------Ridge 0.01 Normalize ------------\")\n    pred_test,coeff_df,pred_train=prediction_ridge(X_train, Y_train, X_test, Y_test, 0.01,False)\n    #vis_results(Y_train, pred_train, Y_test, pred_test, candidate, test_dataset_name, train_dataset_name,'ridge')\n    print (\"------------------------------Lasso 0.0001-----------------------\")\n    pred_test,coeff_df,pred_train=prediction_lasso(X_train, Y_train, X_test, Y_test, 0.0001,True)\n    #vis_results(Y_train, pred_train, Y_test, pred_test, candidate, test_dataset_name, train_dataset_name,'lasso')\n    print (\"---------------------------BayesianRidge-----------------------\")\n    pred_test,coeff_df,pred_train=prediction_BayesianRidge(X_train, Y_train, X_test, Y_test,False)\n    #vis_results(Y_train, pred_train, Y_test, pred_test, candidate, test_dataset_name, train_dataset_name,'br')\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#facts and  dictionary\ncf_dict=pd.read_csv(\"../input/county_facts_dictionary.csv\")\ncf_dict=cf_dict.set_index(\"column_name\")\nfacts=pd.read_csv(\"../input/county_facts.csv\")\nfacts=facts.set_index(\"fips\")\nprint (\"Hillary Clinton and Bernie Sanders fraction votes are most correlated with the county facts. The variance is above 0.5-0.6 for these 2 candidates.\") \nprint (\"The mean square errors between the training and testing data sets are pretty close\")\nprint (\"No structure or pattern in the residual plots\")\nprint (\".........................................................................................\")\nprint (\"The quality of the predicted values for the rest of the candidates is low with 0.2 - 0.4 and less varience values.\")\nprint (\".........................................................................................\")\nprint (\"Ordinary least squares method works perfectly fine fo the data. The rest of the method can give a slightly better results but not very significant\")\nprint (\"Lasso method works better with normalized data\")\nprint (\"=========================================================================================\")\nprint (\"Please see more details for Hillary Clinton as example below\")\nprint (\"=========================================================================================\")\nrun(\"Hillary Clinton\")\n#run(\"Bernie Sanders\")\n#run(\"Donald Trump\")\n#run(\"Marco Rubio\")\n#run(\"Ted Cruz\")"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}