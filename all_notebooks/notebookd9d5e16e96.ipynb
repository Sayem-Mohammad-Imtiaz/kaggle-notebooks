{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"## all necessary modules\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,classification_report\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import breast-cancer data\ndf=pd.read_csv(\"/kaggle/input/breast-cancer-wisconsin-data/data.csv\",header=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display the top 5 records of the data\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Each features names and its datatype\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding null values in a each column\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing unnamed:32 feature containing all null values\ndf.drop([\"Unnamed: 32\"],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In order to view some basic statistics of dataframe\ndf.iloc[:,1:].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_features=['radius_mean', 'texture_mean', 'perimeter_mean',\n       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']\nse_features=['radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n       'fractal_dimension_se']\nworst_features=['radius_worst', 'texture_worst',\n       'perimeter_worst', 'area_worst', 'smoothness_worst',\n       'compactness_worst', 'concavity_worst', 'concave points_worst',\n       'symmetry_worst', 'fractal_dimension_worst']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\ndf[\"diagnosis\"].value_counts().plot(kind=\"bar\")\nplt.ylabel(\"count\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Here B means Beningn(non cancerous) and M means Malignant(cancerous) **"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displaying each features distribution\nfor feature in mean_features:\n    plt.figure(figsize=(10,6))\n    sns.distplot(df[feature])\n    plt.title(feature+\" skew \"+str(df[feature].skew()))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**All features in mean_features category are lightly positive skewed**"},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in se_features:\n    plt.figure(figsize=(10,6))\n    sns.distplot(df[feature])\n    plt.title(feature+\" skew \"+str(df[feature].skew()))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**All features in se_features category are highly positive skewed then mean_features**"},{"metadata":{"trusted":true},"cell_type":"code","source":"for feature in worst_features:\n    plt.figure(figsize=(10,6))\n    sns.distplot(df[feature])\n    plt.title(feature+\" skew \"+str(df[feature].skew()))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# target feature diagnosis vs mean_features\nfor item in mean_features:\n    plt.figure(figsize=(10,6))\n    sns.boxplot(x=\"diagnosis\",y=item,data=df)\n    plt.title(item)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**From above box plot we can say that malignant has high median value compared to benign** "},{"metadata":{"trusted":true},"cell_type":"code","source":"# target feature diagnosis vs se_features\nfor item in se_features:\n    plt.figure(figsize=(10,6))\n    sns.boxplot(x=\"diagnosis\",y=item,data=df)\n    plt.title(item)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**From above box plot we can say that malignant has high median value compared to benign for most of the features**"},{"metadata":{"trusted":true},"cell_type":"code","source":"for item in worst_features:\n    plt.figure(figsize=(10,6))\n    sns.boxplot(x=\"diagnosis\",y=item,data=df)\n    plt.title(item)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert target feature diagnosis to banary\nle=LabelEncoder()\ndf[\"diagnosis\"]=le.fit_transform(df[\"diagnosis\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation between diagnosis feature and mean_features\nplt.figure(figsize=(20,10))\nsns.heatmap(df[[\"diagnosis\"]+mean_features].corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The feature which are correlated with target feature(diagnosis) are radius_mean,texture_mean,perimeter_mean,area_mean,\"smoothness_se\",\"compactness_se\",\"symmetry_se\",'concavity_mean','concave points_mean'but (radius_mean,texture_mean,perimeter_mean,area_mean) are highly correlated to eachother to consider any one feature i.e.,radius_mean and (\"compactness_se\",'concavity_mean','concave points_mean) consider one feature \"compactness_se\""},{"metadata":{"trusted":true},"cell_type":"code","source":"final_mean_features=[\"radius_mean\",\"texture_mean\",\"smoothness_mean\",\"compactness_mean\",\"symmetry_mean\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation between diagnosis feature and se_features\nplt.figure(figsize=(20,10))\nsns.heatmap(df[[\"diagnosis\"]+mean_features].corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_se_features=[\"radius_se\",\"texture_se\",\"smoothness_se\",\"compactness_se\",\"symmetry_se\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation between diagnosis feature and worst_features\nplt.figure(figsize=(20,10))\nsns.heatmap(df[[\"diagnosis\"]+mean_features].corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_worst_features=[\"radius_worst\",\"texture_worst\",\"smoothness_worst\",\"compactness_worst\",\"symmetry_worst\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scale the final features by using minmaxscaler\nmms=MinMaxScaler()\ndf[final_mean_features]=mms.fit_transform(df[final_mean_features])\ndf[final_se_features]=mms.fit_transform(df[final_se_features])\ndf[final_worst_features]=mms.fit_transform(df[final_worst_features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=df[final_mean_features+final_se_features+final_worst_features]\ny=df[\"diagnosis\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting the data into train and test data\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model(x_train,y_train):\n    ## LogisticRegression\n    lr=LogisticRegression()\n    lr.fit(x_train,y_train)\n    y_plr=lr.predict(x_test)\n    ## DecisionTreeClassifier\n    dtc=DecisionTreeClassifier(criterion=\"entropy\")\n    dtc.fit(x_train,y_train)\n    y_dtc=dtc.predict(x_test)\n    ## RandomForestClassifier\n    rfc=RandomForestClassifier(n_estimators=40,criterion=\"entropy\")\n    rfc.fit(x_train,y_train)\n    y_rfc=rfc.predict(x_test)\n    ## Supprt vector machines\n    svm=SVC(kernel=\"rbf\")\n    svm.fit(x_train,y_train)\n    y_svm=svm.predict(x_test)\n    ## Accuracy\n    print(\"the logistic accuracy is\",accuracy_score(y_test,y_plr))\n    print(\"the Decision accuracy is\",accuracy_score(y_test,y_dtc))\n    print(\"the Random accuracy is\",accuracy_score(y_test,y_rfc))\n    print(\"the svm accuracy is\",accuracy_score(y_test,y_svm))\n    print(\"the logistic classification_report is\")\n    print(classification_report(y_test,y_plr))\n    print(\"the Decision classification_report is\")\n    print(classification_report(y_test,y_dtc))\n    print(\"the Random classification_report is\")\n    print(classification_report(y_test,y_rfc))\n    print(\"the svm classification_report is\")\n    print(classification_report(y_test,y_svm))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}