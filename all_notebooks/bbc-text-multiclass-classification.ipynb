{"cells":[{"metadata":{},"cell_type":"markdown","source":"# BBC Text MultiClass Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load packages\nfrom sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer,HashingVectorizer\nfrom sklearn import decomposition, ensemble\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas, xgboost, numpy, textblob, string\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load the dataset\ntrainDF = pd.read_csv('../input/bbc-text.csv') # encoding = \"latin\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainDF.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainDF.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainDF['category'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainDF['category'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(10,10)})\nsns.countplot(trainDF['category'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# split the dataset into training and validation datasets \ntrain_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['category'])\n\ntrain_labels = train_y\nvalid_labels = valid_y\n# label encode the target variable \nencoder = preprocessing.LabelEncoder()\ntrain_y = encoder.fit_transform(train_y)\nvalid_y = encoder.fit_transform(valid_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Extraction"},{"metadata":{},"cell_type":"markdown","source":"### Count Vectors"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count Vectors as features\n# create a count vectorizer object \ncount_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\ncount_vect.fit(trainDF['text'])\n\n# transform the training and validation data using count vectorizer object\nxtrain_count =  count_vect.transform(train_x)\nxvalid_count =  count_vect.transform(valid_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the train features\npca = PCA(n_components=2).fit(xtrain_count.toarray())\ndata2D = pca.transform(xtrain_count.toarray())\ncmap = sns.cubehelix_palette(dark=.3, light=.8, as_cmap=True)\nax = sns.scatterplot(data2D[:,0], data2D[:,1],\nhue=train_labels.tolist(),size=train_labels.tolist(),palette=\"husl\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the validation features\npca = PCA(n_components=2).fit(xvalid_count.toarray())\ndata2D = pca.transform(xvalid_count.toarray())\ncmap = sns.cubehelix_palette(dark=.3, light=.8, as_cmap=True)\nax = sns.scatterplot(data2D[:,0], data2D[:,1],\nhue=valid_labels.tolist(),size=valid_labels.tolist(),palette=\"husl\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  TF-IDF Vectors"},{"metadata":{},"cell_type":"markdown","source":" TF-IDF Vectors as features\n \n a. Word Level TF-IDF : Matrix representing tf-idf scores of every term in different documents\n \n b. N-gram Level TF-IDF : N-grams are the combination of N terms together. This Matrix representing tf-idf scores  of N-grams\n \n c. Character Level TF-IDF : Matrix representing tf-idf scores of character level n-grams in the corpus"},{"metadata":{},"cell_type":"markdown","source":"### word level tf-idf"},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\ntfidf_vect.fit(trainDF['text'])\nxtrain_tfidf =  tfidf_vect.transform(train_x)\nxvalid_tfidf =  tfidf_vect.transform(valid_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the train features\npca = PCA(n_components=2).fit(xtrain_tfidf.toarray())\ndata2D = pca.transform(xtrain_tfidf.toarray())\ncmap = sns.cubehelix_palette(dark=.3, light=.8, as_cmap=True)\nax = sns.scatterplot(data2D[:,0], data2D[:,1],\nhue=train_labels.tolist(),size=train_labels.tolist(),palette=\"husl\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the validation features\npca = PCA(n_components=2).fit(xvalid_tfidf.toarray())\ndata2D = pca.transform(xvalid_tfidf.toarray())\ncmap = sns.cubehelix_palette(dark=.3, light=.8, as_cmap=True)\nax = sns.scatterplot(data2D[:,0], data2D[:,1],\nhue=valid_labels.tolist(),size=valid_labels.tolist(),palette=\"husl\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ngram level tf-idf "},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\ntfidf_vect_ngram.fit(trainDF['text'])\nxtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\nxvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the train features\npca = PCA(n_components=2).fit(xtrain_tfidf_ngram.toarray())\ndata2D = pca.transform(xtrain_tfidf_ngram.toarray())\ncmap = sns.cubehelix_palette(dark=.3, light=.8, as_cmap=True)\nax = sns.scatterplot(data2D[:,0], data2D[:,1],\nhue=train_labels.tolist(),size=train_labels.tolist(),palette=\"husl\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the validation features\npca = PCA(n_components=2).fit(xvalid_tfidf_ngram.toarray())\ndata2D = pca.transform(xvalid_tfidf_ngram.toarray())\ncmap = sns.cubehelix_palette(dark=.3, light=.8, as_cmap=True)\nax = sns.scatterplot(data2D[:,0], data2D[:,1],\nhue=valid_labels.tolist(),size=valid_labels.tolist(),palette=\"husl\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### characters level tf-idf"},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\ntfidf_vect_ngram_chars.fit(trainDF['text'])\nxtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \nxvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the train features\npca = PCA(n_components=2).fit(xtrain_tfidf_ngram_chars.toarray())\ndata2D = pca.transform(xtrain_tfidf_ngram_chars.toarray())\ncmap = sns.cubehelix_palette(dark=.3, light=.8, as_cmap=True)\nax = sns.scatterplot(data2D[:,0], data2D[:,1],\nhue=train_labels.tolist(),size=train_labels.tolist(),palette=\"husl\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the validation features\npca = PCA(n_components=2).fit(xvalid_tfidf_ngram_chars.toarray())\ndata2D = pca.transform(xvalid_tfidf_ngram_chars.toarray())\ncmap = sns.cubehelix_palette(dark=.3, light=.8, as_cmap=True)\nax = sns.scatterplot(data2D[:,0], data2D[:,1],\nhue=valid_labels.tolist(),size=valid_labels.tolist(),palette=\"husl\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### HashingVectorizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting train features\nhash_vectorizer = HashingVectorizer(n_features=5000)\nhash_vectorizer.fit(trainDF['text'])\nxtrain_hash_vectorizer =  hash_vectorizer.transform(train_x) \nxvalid_hash_vectorizer =  hash_vectorizer.transform(valid_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the train features\npca = PCA(n_components=2).fit(xtrain_hash_vectorizer.toarray())\ndata2D = pca.transform(xtrain_hash_vectorizer.toarray())\ncmap = sns.cubehelix_palette(dark=.3, light=.8, as_cmap=True)\nax = sns.scatterplot(data2D[:,0], data2D[:,1],\nhue=train_labels.tolist(),size=train_labels.tolist(),palette=\"husl\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the validation features\npca = PCA(n_components=2).fit(xvalid_hash_vectorizer.toarray())\ndata2D = pca.transform(xvalid_hash_vectorizer.toarray())\ncmap = sns.cubehelix_palette(dark=.3, light=.8, as_cmap=True)\nax = sns.scatterplot(data2D[:,0], data2D[:,1],\nhue=valid_labels.tolist(),size=valid_labels.tolist(),palette=\"husl\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Building"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n    # fit the training dataset on the classifier\n    classifier.fit(feature_vector_train, label)\n    \n    # predict the labels on validation dataset\n    predictions = classifier.predict(feature_vector_valid)\n    \n    if is_neural_net:\n        predictions = predictions.argmax(axis=-1)\n    \n    return metrics.accuracy_score(predictions, valid_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Naive Bayes on Count Vectors\naccuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\nprint(\"NB, Count Vectors: \", accuracy)\n\n# Naive Bayes on Word Level TF IDF Vectors\naccuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\nprint(\"NB, WordLevel TF-IDF: \", accuracy)\n\n# Naive Bayes on Ngram Level TF IDF Vectors\naccuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\nprint(\"NB, N-Gram Vectors: \", accuracy)\n\n# Naive Bayes on Character Level TF IDF Vectors\naccuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\nprint(\"NB, CharLevel Vectors: \", accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Linear Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Linear Classifier on Count Vectors\naccuracy = train_model(linear_model.LogisticRegression(solver=\"lbfgs\",multi_class=\"auto\",max_iter=4000), xtrain_count, train_y, xvalid_count)\nprint(\"LR, Count Vectors: \", accuracy)\n\n# Linear Classifier on Word Level TF IDF Vectors\naccuracy = train_model(linear_model.LogisticRegression(solver=\"lbfgs\",multi_class=\"auto\",max_iter=4000), xtrain_tfidf, train_y, xvalid_tfidf)\nprint(\"LR, WordLevel TF-IDF: \", accuracy)\n\n# Linear Classifier on Ngram Level TF IDF Vectors\naccuracy = train_model(linear_model.LogisticRegression(solver=\"lbfgs\",multi_class=\"auto\",max_iter=4000), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\nprint(\"LR, N-Gram Vectors: \", accuracy)\n\n# Linear Classifier on Character Level TF IDF Vectors\naccuracy = train_model(linear_model.LogisticRegression(solver=\"lbfgs\",multi_class=\"auto\",max_iter=4000), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\nprint(\"LR, CharLevel Vectors: \", accuracy)\n\n# Linear Classifier on Hash Vectors\naccuracy = train_model(linear_model.LogisticRegression(solver=\"lbfgs\",multi_class=\"auto\",max_iter=4000), xtrain_hash_vectorizer, train_y, xvalid_hash_vectorizer)\nprint(\"LR, Hash Vectors: \", accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### RandomForestClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# RF on Count Vectors\naccuracy = train_model(ensemble.RandomForestClassifier(n_estimators=10), xtrain_count, train_y, xvalid_count)\nprint(\"RF, Count Vectors: \", accuracy)\n\n# RF on Word Level TF IDF Vectors\naccuracy = train_model(ensemble.RandomForestClassifier(n_estimators=10), xtrain_tfidf, train_y, xvalid_tfidf)\nprint(\"RF, WordLevel TF-IDF: \", accuracy)\n\n# RF on Ngram Level TF IDF Vectors\naccuracy = train_model(ensemble.RandomForestClassifier(n_estimators=10), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\nprint(\"RF, N-Gram Vectors: \", accuracy)\n\n# RF on Character Level TF IDF Vectors\naccuracy = train_model(ensemble.RandomForestClassifier(n_estimators=10), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\nprint(\"RF, CharLevel Vectors: \", accuracy)\n\n# RF on Hash Vectors\naccuracy = train_model(ensemble.RandomForestClassifier(n_estimators=10), xtrain_hash_vectorizer, train_y, xvalid_hash_vectorizer)\nprint(\"RF, Hash Vectors: \", accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extreme Gradient Boosting"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extreme Gradient Boosting on Count Vector\naccuracy = train_model(xgboost.XGBClassifier(), xtrain_count.tocsc(), train_y, xvalid_count.tocsc())\nprint(\"Xgb, Count Vectors: \", accuracy)\n\n# Extreme Gradient Boosting on Word Level TF IDF Vectors\naccuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), train_y, xvalid_tfidf.tocsc())\nprint(\"Xgb, WordLevel TF-IDF: \", accuracy)\n\n# Extreme Gradient Boosting on Ngram Level TF IDF Vectors\naccuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\nprint(\"Xgb, N-Gram Vectors: \", accuracy)\n\n# Extreme Gradient Boosting on Character Level TF IDF Vectors\naccuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram_chars.tocsc(), train_y, xvalid_tfidf_ngram_chars.tocsc())\nprint(\"Xgb, CharLevel Vectors: \", accuracy)\n\n# Extreme Gradient Boosting on Hash Vectors\naccuracy = train_model(xgboost.XGBClassifier(), xtrain_hash_vectorizer, train_y, xvalid_hash_vectorizer)\nprint(\"Xgb, Hash Vectors: \", accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}