{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Trabalho de conclusao - Data Mining e Machine Learning II**"},{"metadata":{},"cell_type":"markdown","source":"Sera apresentado a seguir estudo para base de emprestimo HMEQ.CSV, com analise exploratoria dos dados e modelo preditivo em random forest com e sem cross validation."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importando dataset\ndf= pd.read_csv('/kaggle/input/hmeq-data/hmeq.csv')\ndf.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Temos algumas colunas sem registro(NaN),principalmente a coluna de Debtinc com 1267 valores faltantes."},{"metadata":{},"cell_type":"markdown","source":"# Analise Exploratória"},{"metadata":{"trusted":true},"cell_type":"code","source":"graf1 = sns.barplot(x=df.BAD, y=df.BAD, data=df, estimator=lambda x: len(x) / len(df) * 100)\ngraf1.set(ylabel=\"Percent\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"20% dos Clientes sao maus pagadores "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df.LOAN.dropna())\nplt.title('Distribuição de quantidade de emprestimo')\nplt.xlabel('Valor')\nplt.ylabel('Quantidade')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df.MORTDUE.dropna())\nplt.title('Distribição do valor do empréstimo ')\nplt.ylabel('Quantidade')\nplt.xlabel('Valor da divida')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df.VALUE.dropna())\nplt.title('Distribuição do valor do imovel')\nplt.xlabel('Valor')\nplt.ylabel('Quantidade')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Distribuiçao de anos de trabalho')\nsns.distplot(df.YOJ.dropna())\nplt.xlabel('Anos trabalhaos')\nplt.ylabel('Quantidade')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = df.REASON.copy()\na[pd.isnull(a)==True] = 'Missing'\nsns.countplot(a, hue = df.BAD)\nplt.title('Status de Emprestimo para pagar outro emprestimo')\nplt.xlabel('Motivo')\nplt.ylabel('Quantidade')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"b = df.JOB.copy()\nb[pd.isnull(b)==True] = 'Missing'\nsns.countplot(b, hue= df.BAD)\nplt.title('Emprestimo por Cargo')\nplt.ylabel('Quantidade')\nplt.xlabel('Cargo')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A marioria dos emprestimos sao para pagamento de outras dividas, o maior volume de pessos que procuram emprestimos tem o cargo classificados como outros"},{"metadata":{"trusted":true},"cell_type":"code","source":"def dist_boxplot(x, **kwargs):\n    ax = sns.distplot(x, hist_kws=dict(alpha=0.2))\n    ax2 = ax.twinx()\n    sns.boxplot(x=x, ax=ax2)\n    ax2.set(ylim=(-5, 5))\n\ng = sns.FacetGrid(df, col=\"BAD\")\ng1 = g.map(dist_boxplot, 'CLAGE', data = df)\n\ng = sns.FacetGrid(df, col=\"BAD\")\ng2 = g.map(dist_boxplot, 'NINQ', data = df)\n\ng = sns.FacetGrid(df, col=\"BAD\")\ng3 = g.map(dist_boxplot, 'CLNO', data = df)\n\ng = sns.FacetGrid(df, col=\"BAD\")\ng4 = g.map(dist_boxplot, 'DEBTINC', data = df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As variaveis CLAGE, NINQ, CLNO e DEBTINC parecem variar bastante em relação à variável BAD e podem servir como possíveis preditores."},{"metadata":{},"cell_type":"markdown","source":"**Substituindo valores faltantes em Dectinc"},{"metadata":{"trusted":true},"cell_type":"code","source":"# input de valores na varial DEBTINC pela media de acordo com a descrição da coluna REASON\ndf.loc[(df.REASON == 'HomeImp') & (pd.isnull(df.DEBTINC) == True),'DEBTINC'] = np.mean(df.loc[df.REASON == 'HomeImp','DEBTINC'])\ndf.loc[(df.REASON == 'DebtCon') & (pd.isnull(df.DEBTINC) == True),'DEBTINC'] = np.mean(df.loc[df.REASON == 'DebtCon','DEBTINC'])\ndf.loc[(pd.isnull(df.REASON) == True) & (pd.isnull(df.DEBTINC) == True),'DEBTINC'] = np.mean(df.loc[pd.isnull(df.REASON) == True,'DEBTINC'])\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#input de 0 para valores faltantes na coluna de credito inadimplente \ndf.loc[pd.isnull(df.DELINQ)==True, 'DELINQ'] = 0\ndf.loc[pd.isnull(df.JOB)==True, 'JOB'] = 'Missing'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Criando Modelo de Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport sklearn\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport scikitplot as skplt\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Criando um novo dataframe para o modelo de random forest com inclusao de colunas dummy"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_rf = pd.get_dummies(df, df.dtypes[(df.dtypes==np.object) | (df.dtypes=='category')].index.values, drop_first=True)\ndf_rf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Separado o novo dataframe em traino e teste"},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = train_test_split(df_rf, test_size=0.20, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"separando o base treino em treino e validação"},{"metadata":{"trusted":true},"cell_type":"code","source":"train, valid = train_test_split(train, test_size=0.20, random_state=42)\n\ntrain.shape, valid.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_rf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Incio do modelo de Random Forest**"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_jobs=-1, oob_score=True, n_estimators = 150, random_state=150)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feats = [c for c in df_rf.columns if c not in ['BAD']]\nfeats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf.fit(train[feats],train['BAD'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prevendo os dados de validação\npreds_val = rf.predict(valid[feats])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(valid['BAD'], preds_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_test = rf.predict(test[feats])\n\npreds_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(test['BAD'], preds_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skplt.metrics.plot_confusion_matrix(test['BAD'], preds_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apos a primeira tentativa usando o modelo de random forest, é possivel observar uma acuracia de 91% considerado muito boa para o modelo."},{"metadata":{},"cell_type":"markdown","source":"## Revendo Random Forest utilizando Cross Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = train_test_split(df_rf, test_size=0.20, random_state=42)\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = cross_val_score(rf, train[feats], train['BAD'], n_jobs=-1, cv=5)\n\nscores, scores.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = cross_val_score(rf, test[feats], test['BAD'], n_jobs=-1, cv=5)\n\nscores, scores.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apos a realização do random foreste usando o metodo de validação cruzada de 5 conjuntos, obtivemos 92,4% de acuracia na base de treino,1% melhor que o primeito modelo de random forest testado anteriormente. Quando aplicando o mesmo modelo na base de teste tivemos o resultado de 89,3 que ainda assim é condiderado um bom modelo."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}