{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# initial information about data\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# initial statistic about data\ndf.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking null value\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No null or missing value"},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking duplicate data\ndf.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No duplicated data"},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# check Outcome column\ndf['Outcome'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['Outcome'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.hist(figsize=(10,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are multiple columns with 0 as their value and it makes no sense"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Glucose: ', df[df['Glucose'] == 0]['Glucose'].count())\nprint('BloodPressure: ', df[df['BloodPressure'] == 0]['BloodPressure'].count())\nprint('SkinThickness: ', df[df['SkinThickness'] == 0]['SkinThickness'].count())\nprint('Insulin: ', df[df['Insulin'] == 0]['Insulin'].count())\nprint('BMI: ', df[df['BMI'] == 0]['BMI'].count())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can change 0 in those columns with the mean of each column using imputation technique"},{"metadata":{"trusted":true},"cell_type":"code","source":"# change 0 into Nan (empty)\ndf[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = df[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0, np.NaN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that the values of these columns are empty, we can fill them in with the mean of the column using the imputation technique using the Outcome class as the benchmark."},{"metadata":{},"cell_type":"markdown","source":"### Checking the mean of each column which has NaN value"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('Outcome')['Glucose'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('Outcome')['BloodPressure'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('Outcome')['SkinThickness'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('Outcome')['Insulin'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('Outcome')['BMI'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Imputation Function For Each Column"},{"metadata":{"trusted":true},"cell_type":"code","source":"# imputation Function for Glucose\ndef impute_glucose(cols):\n    glucose = cols[0]\n    outcome = cols[1]\n    \n    if pd.isnull(glucose):\n        if outcome == 0:\n            return 111\n        else:\n            return 142\n    else:\n        return glucose","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# imputation function for bloodpreassure column\ndef impute_bloodpreasure(cols):\n    bloodpreasure = [0]\n    outcome = [1]\n    \n    if pd.isnull(bloodpreasure):\n        if outcome == 0:\n            return 71\n        else:\n            return 75\n    else:\n        return bloodpreasure","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# imputation function for skinthickness column\ndef impute_skinthickness(cols):\n    skinthickness = [0]\n    outcome = [1]\n    \n    if pd.isnull(skinthickness):\n        if outcome == 0:\n            return 27\n        else:\n            return 33\n    else:\n        return skinthickness","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# imputation function for insulin column\ndef impute_insulin(cols):\n    insulin = [0]\n    outcome = [1]\n    \n    if pd.isnull(insulin):\n        if outcome == 0:\n            return 130\n        else:\n            return 207\n    else:\n        return insulin","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# imputation function for bmi column\ndef impute_bmi(cols):\n    bmi = [0]\n    outcome = [1]\n    \n    if pd.isnull(bmi):\n        if outcome == 0:\n            return 31\n        else:\n            return 35\n    else:\n        return bmi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# applying imputation function\ndf['Glucose'] = df[['Glucose', 'Outcome']].apply(impute_glucose, axis=1)\ndf['BloodPressure'] = df[['BloodPressure', 'Outcome']].apply(impute_glucose, axis=1)\ndf['SkinThickness'] = df[['SkinThickness', 'Outcome']].apply(impute_glucose, axis=1)\ndf['Insulin'] = df[['Insulin', 'Outcome']].apply(impute_glucose, axis=1)\ndf['BMI'] = df[['BMI', 'Outcome']].apply(impute_glucose, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking outliers\nplt.figure(figsize=(12,7))\nsns.boxplot(data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that there are multiple outliers across multiple columns, and we need to delete them"},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove Outliers using Interquartile Range\nQ1 = df.quantile(0.25)\nQ3 = df.quantile(0.75)\nIQR = Q3 - Q1\nprint(IQR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clearing the outliers\ndf_filtered = df.loc[~((df < (Q1 - 1.5 * IQR)).any(axis=1)|(df > (Q3 + 1.5 * IQR)).any(axis=1))].dropna()\ndf_filtered.reset_index(drop=True, inplace=True)\ndf_filtered.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,9))\nsns.boxplot(data=df_filtered)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Normalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_filtered.drop('Outcome', axis=1)\ny = df_filtered['Outcome']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Using Min Max Scaler"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler.fit(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = scaler.transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.DataFrame(X)\nX.columns=[df_filtered.columns[:8]]\nX.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train and Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training Model"},{"metadata":{},"cell_type":"markdown","source":"### KNN "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_rate = []\n\nfor i in range(1,40):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train, y_train)\n    knn_prediction = knn.predict(X_test)\n    error_rate.append(np.mean(knn_prediction != y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs. K Value', fontsize=30, color='black', pad=15, loc='center')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\ny_pred_proba = knn.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr, label='Knn')\nplt.xlabel('fpr')\nplt.ylabel('tpr')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Area under ROC curve\nfrom sklearn.metrics import roc_auc_score\nroc_auc_score(y_test,y_pred_proba)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import GridSearchCV\nfrom sklearn.model_selection import GridSearchCV\n#In case of classifier like knn the parameter to be tuned is n_neighbors\nparam_grid = {'n_neighbors':np.arange(1,40)}\nknn = KNeighborsClassifier()\nknn_cv= GridSearchCV(knn,param_grid,cv=10)\nknn_cv.fit(X,y)\n\nprint(\"Best Score:\" + str(knn_cv.best_score_))\nprint(\"Best Parameters: \" + str(knn_cv.best_params_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import tree\ndtc = tree.DecisionTreeClassifier(min_impurity_split=0.001)\ndtc.fit(X_train, y_train)\ndtc_prediction = dtc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import Module\nfrom sklearn import metrics\n\n# Show the Confussion Matrix\nprint(metrics.confusion_matrix(y_test, dtc_prediction))\nprint(metrics.classification_report(y_test, dtc_prediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show the Accuracy, Precision, Recall\nacc_dtc = metrics.accuracy_score(y_test, dtc_prediction)\nprec_dtc = metrics.precision_score(y_test, dtc_prediction)\nrec_dtc = metrics.recall_score(y_test, dtc_prediction)\nf1_dtc = metrics.f1_score(y_test, dtc_prediction)\nkappa_dtc = metrics.cohen_kappa_score(y_test, dtc_prediction)\n\nprint(\"Accuracy:\", acc_dtc)\nprint(\"Precision:\", prec_dtc)\nprint(\"Recall:\", rec_dtc)\nprint(\"F1 Score:\", f1_dtc)\nprint(\"Cohens Kappa Score:\", kappa_dtc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import Visualization Package\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set Size and Style\nplt.rcParams['figure.figsize'] = (10, 10)\nplt.style.use('ggplot')\n\n# Visualize ROC Curve\ndtc_prediction_proba = dtc.predict_proba(X_test)[::,1]\nfprdtc, tprdtc, _ = metrics.roc_curve(y_test,  dtc_prediction_proba)\naucdtc = metrics.roc_auc_score(y_test, dtc_prediction_proba)\nplt.plot(fprdtc,tprdtc,label=\"Decision Tree, auc=\"+str(aucdtc))\nplt.title('ROC Curve - Decision Tree')\nplt.xlabel('false positive rate') \nplt.ylabel('true positive rate')\nplt.legend(loc=4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import Module\nfrom sklearn import ensemble\n\n# Modeling Random Forest\nrdf = ensemble.RandomForestClassifier(n_estimators=600)\nrdf.fit(X_train, y_train)\n\n# Predict to Test Data \nrdf_prediction = rdf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import Module\nfrom sklearn import metrics\n\n# Show the Confussion Matrix\nprint(metrics.confusion_matrix(y_test, rdf_prediction))\nprint(metrics.classification_report(y_test, rdf_prediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show the Accuracy, Precision, Recall\nacc_rdf = metrics.accuracy_score(y_test, rdf_prediction)\nprec_rdf = metrics.precision_score(y_test, rdf_prediction)\nrec_rdf = metrics.recall_score(y_test, rdf_prediction)\nf1_rdf = metrics.f1_score(y_test, rdf_prediction)\nkappa_rdf = metrics.cohen_kappa_score(y_test, rdf_prediction)\n\nprint(\"Accuracy:\", acc_rdf)\nprint(\"Precision:\", prec_rdf)\nprint(\"Recall:\", rec_rdf)\nprint(\"F1 Score:\", f1_rdf)\nprint(\"Cohens Kappa Score:\", kappa_rdf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ROC Curve\nrdf_prediction_proba = rdf.predict_proba(X_test)[::,1]\nfprrdf, tprrdf, _ = metrics.roc_curve(y_test,  rdf_prediction_proba)\naucrdf = metrics.roc_auc_score(y_test, rdf_prediction_proba)\nplt.plot(fprrdf,tprrdf,label=\"Random Forest, auc=\"+str(aucrdf))\nplt.title('ROC Curve - Random Forest')\nplt.xlabel('false positive rate') \nplt.ylabel('true positive rate')\nplt.legend(loc=4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest model is the best model to do classification for this dataset with auc in roc curve = 95"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}