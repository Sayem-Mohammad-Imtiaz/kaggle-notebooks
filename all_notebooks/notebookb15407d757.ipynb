{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AUSTRALIAN BEER FORECAST","metadata":{}},{"cell_type":"markdown","source":"## Task setup","metadata":{}},{"cell_type":"markdown","source":"Using only the following data (https://www.kaggle.com/sergiomora823/monthly-beer-production),\nplease provide a forecast of monthly Australian beer production for the year 1996.\nVerbally summarize the forecast and give a comment on what you did,\nwhy you did what you did and,\nhow you ended up with the final forecast. Use a Kaggle notebook.","metadata":{}},{"cell_type":"markdown","source":"# # python Libraries","metadata":{}},{"cell_type":"markdown","source":"Here a list is provided of the the python libraries imported to be used by the script of the analysis that follows below","metadata":{}},{"cell_type":"code","source":"# Python modules used\nimport pandas as pd\nimport numpy as np\nimport datetime\nimport matplotlib.pylab as plt\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize'] = 15, 6\nimport statsmodels.api as sm\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom scipy import stats\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import LSTM\nimport itertools\nfrom sklearn.metrics import mean_squared_error\nimport warnings","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data load","metadata":{}},{"cell_type":"markdown","source":"Data is loaded from a text (.csv) file","metadata":{}},{"cell_type":"code","source":"beer_prod_df = pd.read_csv('../input/monthly-beer-production/datasets_56102_107707_monthly-beer-production-in-austr.csv', header=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Descriptive analysis","metadata":{}},{"cell_type":"markdown","source":"We have a single time series data with monthly frequency, representing the total Australian beer output in megalitres\nduring the period from January 1956 till August 1995","metadata":{}},{"cell_type":"code","source":"beer_prod_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# First, let's re-format data to fit the python requirements:","metadata":{}},{"cell_type":"markdown","source":"*Month string variable is converted into datetime variable","metadata":{}},{"cell_type":"code","source":"beer_prod_df['Month']=beer_prod_df['Month'].astype('datetime64[ns]')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Output string variable is converted into float variable","metadata":{}},{"cell_type":"code","source":"beer_prod_df['Monthly beer production']=beer_prod_df['Monthly beer production'].astype('float')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*The 'Month' column is renamed according to its data type, as well as the output column 'Monthly beer production' to make it informative and succinct","metadata":{}},{"cell_type":"code","source":"beer_prod_df.columns = ['DATETIME', 'MEGALITRES']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Set DATETIME as an index","metadata":{}},{"cell_type":"code","source":"beer_prod_df = beer_prod_df.set_index('DATETIME')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Plotting the output time series implies:\n    -> 3-4 year-to-year trends, stable (unchanging) for approximately 10 years and,\n    -> seasonality characterized by peak at the Australian summer (Dec-Mar) and bottom at the Australian winter (Jun-Sep)\nTheoretically speaking, a scientific guess can be made that trend is driven by income demand effects, while seasonality is driven by taste demand factors, e.g. athmospheric temperature (the hotter the weather, the higher the thirst for beer) )\n    -> There is a distinctive structural break in the winter of 1974","metadata":{}},{"cell_type":"code","source":"beer_prod_df.plot(figsize=(15, 7))\nplt.title('Beer Production')\nplt.ylabel('megalitres')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Data is obviously non-stationary following an AR(1) process that does not oscilate around its initial anchor value. Rigorously, this could be shown by the results from the unit-root Dickey-Fuller test","metadata":{}},{"cell_type":"code","source":"def plot_test_stationarity(timeseries):\n    #Determing rolling statistics\n    rolmean = timeseries.rolling(12).mean()\n    rolstd = timeseries.rolling(12).std()\n    \n    #Plot rolling statistics:\n    orig = plt.plot(timeseries, color='blue',label='Original')\n    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n    plt.legend(loc='best')\n    plt.title('Rolling Mean & Standard Deviation')\n    plt.show(block=False)\n    \n    #Perform Dickey-Fuller test:\n    print('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print(dfoutput)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_test_stationarity(beer_prod_df['MEGALITRES'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Test (unit root t) statistic exceeds the critical level at 5% and even 10% significance thus providing no evidence for rejecting the null hypothesis of having non-stationary AR(1) process","metadata":{}},{"cell_type":"markdown","source":"*Respective data transformations need to be applied to finish with a stationary dataset which allows for statistical inference and prediction:\n    -> taking a natural logarithm, linearizes the exponential segments of the year-to-year trend, i.e. it leads to a decrease in the trend curvature","metadata":{}},{"cell_type":"code","source":"plot_test_stationarity(np.log(beer_prod_df['MEGALITRES']))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Still the data annual moving averages are characterized by high volatility visualized by the upward sloping red line at the plot above (zero hypothesis cannot be rejected at 5% significance level).\n        -> First differencing of the logged values could be applied to reduce variability of means","metadata":{}},{"cell_type":"code","source":"plot_test_stationarity(np.log(beer_prod_df.iloc[1:, :])-np.log(beer_prod_df.iloc[:,:].shift(1).dropna()))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*The test statistics from the Dickey-Fuller test on the diff-log data provides evidence to reject the zero hypothesis for non-stationary data at even 1% significance level","metadata":{}},{"cell_type":"markdown","source":"# PREDICTION 1: EXTRAPOLATION","metadata":{}},{"cell_type":"markdown","source":"*The simplest forecasting method with stationary data is seasonal extrapolation which in the case of monthly forecast implies taking the computed growth rate in the same month but in the previous year and applying them to the corresponding lagged test data points. In our case, we can estimate the forecast values for the test period from January 1986 till December 1996 based on growth rates for the years in the range January 1984 till December 1994, respectively.","metadata":{}},{"cell_type":"code","source":"index = pd.date_range(\"1956-01-01\", periods=500, freq=\"MS\")\nbeer_prod_pred_df=pd.DataFrame(index)\nbeer_prod_pred_df.columns = ['DATETIME']\nbeer_prod_pred_df=beer_prod_pred_df.set_index('DATETIME').join(beer_prod_df.iloc[:, :], how = 'left')\nbeer_prod_pred_df.columns=['MEGALITRES_OBS']\nbeer_prod_pred_df['LOG_MEGALITRES']=np.log(beer_prod_pred_df.iloc[:, :1])\nbeer_prod_pred_df['LOG_MEGALITRES_LAG1']=np.log(beer_prod_pred_df.iloc[:, :1].shift(1))\nbeer_prod_pred_df['LOG_MEGALITRES_DIFF1']=np.log(beer_prod_pred_df.iloc[:, :1])-np.log(beer_prod_pred_df.iloc[:, :1].shift(1))\nbeer_prod_pred_df['LOG_MEGALITRES_DIFF1_LAG12b']=(np.log(beer_prod_pred_df.iloc[:, :1])-np.log(beer_prod_pred_df.iloc[:, :1].shift(1))).shift(24)\nstart_date=datetime.date(1985, 12, 1)\nend_date=datetime.date(1996, 12, 1)\nbeer_prod_pred0_df=beer_prod_pred_df.loc[start_date:end_date, :].copy()\nbeer_prod_pred0_df=beer_prod_pred0_df[['MEGALITRES_OBS', 'LOG_MEGALITRES_LAG1','LOG_MEGALITRES_DIFF1_LAG12b']]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"beer_prod_pred0_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Run rolling forecast for the period from 1986-01-01 till 1996-12-31","metadata":{}},{"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")\nbeer_prod_pred2_df=pd.DataFrame()\nfor i in range(1, 133):\n    beer_prod_pred1_df=beer_prod_pred0_df.iloc[i:i+1,:]\n    beer_prod_pred1_df['LOG_MEGALITRES_PRED']=beer_prod_pred1_df['LOG_MEGALITRES_LAG1']+beer_prod_pred1_df['LOG_MEGALITRES_DIFF1_LAG12b']\n    beer_prod_pred0_df.iloc[i+1:i+2,1:2]=beer_prod_pred1_df['LOG_MEGALITRES_PRED'][0]\n    beer_prod_pred2_df=beer_prod_pred2_df.append(beer_prod_pred1_df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"beer_prod_pred2_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"beer_prod_pred3_df=beer_prod_pred2_df.copy()\nbeer_prod_pred3_df['MEGALITRES_EXTRAPRED']=np.exp(beer_prod_pred3_df['LOG_MEGALITRES_PRED'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"beer_prod_pred3_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"beer_prod_extrapred_df=beer_prod_pred3_df[['MEGALITRES_OBS', 'MEGALITRES_EXTRAPRED']]\nbeer_prod_extratest_df=beer_prod_extrapred_df.iloc[:-16,:]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"beer_prod_extratest_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(beer_prod_extrapred_df['MEGALITRES_OBS'], label='observed')\nplt.plot(beer_prod_extrapred_df['MEGALITRES_EXTRAPRED'], label='extrapred')\nplt.title('Beer Production')\nplt.ylabel('megalitres')\nplt.legend(loc='best')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extra_rmse=np.sqrt(mean_squared_error(beer_prod_extratest_df['MEGALITRES_OBS'], beer_prod_extratest_df['MEGALITRES_EXTRAPRED']))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(extra_rmse)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PREDICTION 2: Exponential smoothening with seasonality a la Holt(1957)-Winters(1960)","metadata":{}},{"cell_type":"markdown","source":"*Here, a simple exponential smoothening model is applied based on Holt(1957)-Winters(1960) seasonal method","metadata":{}},{"cell_type":"code","source":"beer_prod_expotrain_df=beer_prod_df.iloc[:360,:]\nbeer_prod_expotest_df=beer_prod_df.iloc[360:,:]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"beer_prod_expotrain_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Select the optimal combination of hyperparameters based on the minimal RMSE metrics","metadata":{}},{"cell_type":"code","source":"metrics_df=pd.DataFrame()\nlevels = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\ntrends = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\nseasonal_components = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\nfor l in levels:\n    for t in trends:\n        for s in seasonal_components:\n            beer_prod_expofit_df=(ExponentialSmoothing(beer_prod_expotrain_df, trend='add', seasonal='add',\n                      seasonal_periods=12).fit(smoothing_level=l, smoothing_trend=t, smoothing_seasonal=s)).forecast(116)\n            beer_prod_expofit_df=beer_prod_expofit_df.to_frame()\n            beer_prod_expofit_df=beer_prod_expofit_df.reset_index()\n            beer_prod_expofit_df.columns=['DATETIME', 'MEGALITRES_EXPOPRED']\n            beer_prod_expofit_df=beer_prod_expofit_df.set_index('DATETIME')\n            beer_prod_expofit_df=beer_prod_expofit_df.join(beer_prod_expotest_df, how='right')\n            beer_prod_expofit_df.columns=['MEGALITRES_EXPOPRED', 'MEGALITRES_OBSERVED']\n            rmse=np.sqrt(mean_squared_error(beer_prod_expofit_df['MEGALITRES_OBSERVED'], beer_prod_expofit_df['MEGALITRES_EXPOPRED']))\n#             print('level={}, trend={}, seasonal_component={}, rmse ={}'.format(l, t, s, rmse))\n            metrics_dict0 = {'level':[l], 'trend':[t], 'seasonal_component':[s], 'rmse':[rmse]}\n            metrics_dict0_df = pd.DataFrame(metrics_dict0)\n            metrics_df=metrics_df.append(metrics_dict0_df)\nprint(metrics_df[metrics_df['rmse']==min(metrics_df['rmse'])])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Apply the optimal parameter values to forecast beer production in the period from 1986-01-01 till 1996-12-31","metadata":{}},{"cell_type":"code","source":"l=0.1\nt=0.9\ns=0.3\nbeer_prod_expopred_df=(ExponentialSmoothing(beer_prod_expotrain_df, trend='add', seasonal='add', seasonal_periods=12).fit(smoothing_level=l, smoothing_trend=t, smoothing_seasonal=s)).forecast(132)\nbeer_prod_expopred_df=beer_prod_expopred_df.to_frame()\nbeer_prod_expopred_df=beer_prod_expopred_df.reset_index()\nbeer_prod_expopred_df.columns=['DATETIME', 'MEGALITRES_EXPOPRED']\nbeer_prod_expopred_df=beer_prod_expopred_df.set_index('DATETIME')\nbeer_prod_expopred_df=beer_prod_expopred_df.join(beer_prod_expotest_df, how='left')\nbeer_prod_expopred_df.columns=['MEGALITRES_EXPOPRED', 'MEGALITRES_OBSERVED']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"beer_prod_expopred_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(beer_prod_expopred_df['MEGALITRES_OBSERVED'], label='observed')\nplt.plot(beer_prod_expopred_df['MEGALITRES_EXPOPRED'], label='expopred')\nplt.title('Beer Production')\nplt.ylabel('megalitres')\nplt.legend(loc='best')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"expo_rmse=metrics_df[metrics_df['rmse']==min(metrics_df['rmse'])]['rmse'][0]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(expo_rmse)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PREDICTION 3: SARIMA model","metadata":{}},{"cell_type":"markdown","source":"*Here, the classical time-series econometrics autocorrelation SARIMA model will be applied to forecast the monthly beer production in Australia","metadata":{}},{"cell_type":"code","source":"sarima_traintest_df=beer_prod_df.copy()\nsarima_traintest_df['LOG_MEGALITRES']=np.log(beer_prod_df['MEGALITRES'])\nsarima_traintest_df=sarima_traintest_df[['LOG_MEGALITRES']]\nsarima_train = sarima_traintest_df.iloc[:360,:]\nsarima_test = sarima_traintest_df.iloc[360:,:]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*After specifying the train and test data subsets, the optimal lags and differencing orders will be identified for the seasonal and non-seasonal parts of the SARIMA model","metadata":{}},{"cell_type":"code","source":"p = d = q = range(0, 3)\npdq = list(itertools.product(p, d, q))\npdq","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics_df=pd.DataFrame()\nfor param in pdq:\n    for param_seasonal in seasonal_pdq:\n        mod = sm.tsa.statespace.SARIMAX(sarima_train, order=param, seasonal_order=param_seasonal, enforce_stationarity=False, enforce_invertibility=False)\n        results = mod.fit()\n        print('ARIMA{}x{}12- AIC:{}'.format(param, param_seasonal, results.aic))\n        metrics_dict0 = {'Non-seasonal:':[param], 'Seasonal':[param_seasonal], 'AIC':[results.aic]}\n        metrics_dict0_df = pd.DataFrame(metrics_dict0)\n        metrics_df=metrics_df.append(metrics_dict0_df)\nprint(metrics_df[metrics_df['AIC']==min(metrics_df['AIC'])])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*The optimal combination of SARIMA parameters is applied to fit the model","metadata":{}},{"cell_type":"code","source":"mod = sm.tsa.statespace.SARIMAX(sarima_train,\n                                order=(1, 1, 2),\n                                seasonal_order=(1, 0, 1, 12),\n                                enforce_stationarity=False,\n                                enforce_invertibility=False)\n\nresults = mod.fit()\n\nprint(results.summary().tables[1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Residuals analysis implies stationarity and unbiasedness of the estimated coefficients","metadata":{}},{"cell_type":"code","source":"residuals1 = pd.DataFrame(results.resid[1:])\nresiduals1.plot(figsize=(20,5))\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"residuals1.plot(kind='kde', figsize=(20,5))\nplt.show()\nprint(residuals1.describe())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"KS P-value = \"+str(round(stats.kstest(residuals1, 'norm')[1], 10)))\nprint(\"D’Agostino and Pearson’s P-value = \"+str(round(stats.normaltest(residuals1, axis=0)[1][0], 6)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Finally, a rolling forecast is run for the period from 1986-01-01 till 1996-12-31","metadata":{}},{"cell_type":"code","source":"beer_prod_sarimapred_df=pd.DataFrame()\nfor i in range(0, 132):\n    print(i)\n    t=360+i\n    if t<476:\n        sarima_train=sarima_traintest_df.iloc[:t,:]\n        mod=sm.tsa.statespace.SARIMAX(sarima_train, order=(1, 1, 2), seasonal_order=(1, 0, 1, 12))\n        mod_fit=mod.fit(disp=0)\n        beer_prod_datetime = sarima_traintest_df.index[t]\n        beer_prod_sarimapred_value = np.exp(mod_fit.forecast()[0])\n        beer_prod_observed_value = np.exp(sarima_test.iloc[i:i+1, -1:]['LOG_MEGALITRES'][0])\n    else:\n        train_dict={'DATETIME': [beer_prod_datetime], 'LOG_MEGALITRES': [mod_fit.forecast()[0]]}\n        train_dict_df=pd.DataFrame.from_dict(train_dict)\n        sarima_train=sarima_train.reset_index()\n        sarima_train=sarima_train.append(train_dict_df)\n        sarima_train=sarima_train.set_index('DATETIME')\n        mod=sm.tsa.statespace.SARIMAX(sarima_train, order=(1, 1, 2), seasonal_order=(1, 0, 1, 12))\n        mod_fit=mod.fit(disp=0)\n        if beer_prod_datetime.month==12:\n            beer_prod_datetime=datetime.datetime(beer_prod_datetime.year+1, 1, beer_prod_datetime.day)\n        else:\n            beer_prod_datetime=datetime.datetime(beer_prod_datetime.year, beer_prod_datetime.month+1, beer_prod_datetime.day)\n        beer_prod_sarimapred_value = np.exp(mod_fit.forecast()[0])\n        beer_prod_observed_value = float(\"NaN\")\n    print(beer_prod_datetime)\n    beer_prod_sarimapred_dict={'DATETIME': [beer_prod_datetime], 'MEGALITRES_SARIMAPRED': [beer_prod_sarimapred_value], 'MEGALITRES_OBSERVED': [beer_prod_observed_value]}\n    beer_prod_sarimapred_df0=pd.DataFrame.from_dict(beer_prod_sarimapred_dict)\n    beer_prod_sarimapred_df=beer_prod_sarimapred_df.append(beer_prod_sarimapred_df0)\nbeer_prod_sarimapred_df=beer_prod_sarimapred_df.set_index('DATETIME')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"beer_prod_sarimapred_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(beer_prod_sarimapred_df['MEGALITRES_OBSERVED'], label='observed')\nplt.plot(beer_prod_sarimapred_df['MEGALITRES_SARIMAPRED'], label='sarimapred')\nplt.title('Beer Production')\nplt.ylabel('megalitres')\nplt.legend(loc='best')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sarima_rmse=np.sqrt(mean_squared_error(beer_prod_sarimapred_df.iloc[:116,-1:], beer_prod_sarimapred_df.iloc[:116,-2:-1]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sarima_rmse)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PREDICTION 4: LSTM model","metadata":{}},{"cell_type":"markdown","source":"*Finally, let's use a LSTM (Long Short-Term Memory) recurrent neural network architecture for predicting the beer production in Australia","metadata":{}},{"cell_type":"code","source":"lstm_traintest_df=beer_prod_df.copy()\nlstm_traintest_df['LOG_MEGALITRES']=np.log(beer_prod_df['MEGALITRES'])\nlstm_traintest_df=lstm_traintest_df[['LOG_MEGALITRES']]\nlstm_train = lstm_traintest_df.iloc[:360,:]\nlstm_test = lstm_traintest_df.iloc[360:,:]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Before training the LSTM model, it is necessary to normalize data within the min-max scale","metadata":{}},{"cell_type":"code","source":"scaler = MinMaxScaler()\nscaler.fit(lstm_train)\nlstm_train_normalized = scaler.transform(lstm_train)\nlstm_test_normalized = scaler.transform(lstm_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Next, define the generator of the input and output data over which the LSTM model should be trained and fitted","metadata":{}},{"cell_type":"code","source":"generator = TimeseriesGenerator(lstm_train_normalized, lstm_train_normalized, length=12, batch_size=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Now, the model could be trained","metadata":{}},{"cell_type":"code","source":"lstm_model = Sequential()\nlstm_model.add(LSTM(200, input_shape=(12, 1)))\nlstm_model.add(Dense(1))\nlstm_model.compile(optimizer='adam', loss='mean_squared_error')\nlstm_model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Use the generator to fit the model","metadata":{}},{"cell_type":"code","source":"lstm_model.fit_generator(generator,epochs=15)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Plot the iterative convergence path of the recursive optimization","metadata":{}},{"cell_type":"code","source":"losses_lstm = lstm_model.history.history['loss']\nplt.figure(figsize=(20,5))\nplt.xticks(np.arange(0,15,1))\nplt.plot(range(len(losses_lstm)),losses_lstm);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Run rolling forecast of the beer production in the period from 1986-01-01 till 1996-12-31","metadata":{}},{"cell_type":"code","source":"beer_prod_lstmpred = list()\n\nbatch = lstm_train_normalized[-12:]\ncurrent_batch = batch.reshape((1, 12, 1))\n\nfor i in range(132):   \n    lstm_pred = lstm_model.predict(current_batch)[0]\n    beer_prod_lstmpred.append(lstm_pred) \n    current_batch = np.append(current_batch[:,1:,:],[[lstm_pred]],axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"beer_prod_lstmpred = scaler.inverse_transform(beer_prod_lstmpred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"beer_prod_lstmpred","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"beer_prod_lstmpred_df=pd.DataFrame(beer_prod_lstmpred, columns=['LOG_MEGALITRES_LSTMPRED'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index = pd.date_range(\"1986-01-01\", periods=132, freq=\"MS\")\nbeer_prod_pred_df=pd.DataFrame(index)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"beer_prod_lstmpred_df=beer_prod_lstmpred_df.set_index(index)\nbeer_prod_lstmpred_df=beer_prod_lstmpred_df.reset_index()\nbeer_prod_lstmpred_df.columns=['DATETIME', 'LOG_MEGALITRES_LSTMPRED']\nbeer_prod_lstmtest_df=beer_prod_lstmpred_df.copy()\nbeer_prod_lstmpred_df=beer_prod_lstmpred_df.set_index('DATETIME').join(lstm_test, how='left')\nbeer_prod_lstmtest_df=beer_prod_lstmtest_df.set_index('DATETIME').join(lstm_test, how='right')\nbeer_prod_lstmpred_df['MEGALITRES_LSTMPRED']=np.exp(beer_prod_lstmpred_df['LOG_MEGALITRES_LSTMPRED'])\nbeer_prod_lstmpred_df['MEGALITRES_OBSERVED']=np.exp(beer_prod_lstmpred_df['LOG_MEGALITRES'])\nbeer_prod_lstmtest_df['MEGALITRES_LSTMPRED']=np.exp(beer_prod_lstmtest_df['LOG_MEGALITRES_LSTMPRED'])\nbeer_prod_lstmtest_df['MEGALITRES_OBSERVED']=np.exp(beer_prod_lstmtest_df['LOG_MEGALITRES'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"beer_prod_lstmpred_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"beer_prod_lstmpred_df=beer_prod_lstmpred_df[['MEGALITRES_LSTMPRED', 'MEGALITRES_OBSERVED']]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"beer_prod_lstmpred_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(beer_prod_lstmpred_df['MEGALITRES_OBSERVED'], label='observed')\nplt.plot(beer_prod_lstmpred_df['MEGALITRES_LSTMPRED'], label='lstmpred')\nplt.title('Beer Production')\nplt.ylabel('megalitres')\nplt.legend(loc='best')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"beer_prod_lstmtest_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_rmse=np.sqrt(mean_squared_error(beer_prod_lstmtest_df['MEGALITRES_OBSERVED'], beer_prod_lstmtest_df['MEGALITRES_LSTMPRED']))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(lstm_rmse)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CONCLUSION","metadata":{}},{"cell_type":"markdown","source":"*Summarizing the RMSE metrics for the 4 forecasting methods applied leads to the conclusion that the forecast based on the SARIMA model performed best in the tested period, only marginally outperforming the exponential smoothening model.","metadata":{}},{"cell_type":"code","source":"error_metrics_dbeer_prod_lstmpred_df=pd.DataFrame({'Model':['EXTRA', 'EXPO', 'SARIMA', 'LSTM'], 'RMSE': [extra_rmse, expo_rmse, sarima_rmse, lstm_rmse]})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error_metrics_dbeer_prod_lstmpred_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"beer_prod_allpred_df=pd.DataFrame()\nbeer_prod_allpred_df=beer_prod_allpred_df.append(beer_prod_extrapred_df)\nbeer_prod_allpred_df=beer_prod_allpred_df.join(beer_prod_expopred_df.iloc[:, -2:-1], how='left')\nbeer_prod_allpred_df=beer_prod_allpred_df.join(beer_prod_sarimapred_df.iloc[:, -2:-1], how='left')\nbeer_prod_allpred_df=beer_prod_allpred_df.join(beer_prod_lstmpred_df.iloc[:, -2:-1], how='left')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"beer_prod_allpred_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Here's a summary plot of all forecasts","metadata":{}},{"cell_type":"code","source":"plt.plot(beer_prod_allpred_df['MEGALITRES_OBS'], label='observed')\nplt.plot(beer_prod_allpred_df['MEGALITRES_EXTRAPRED'], label='extrapred')\nplt.plot(beer_prod_allpred_df['MEGALITRES_EXPOPRED'], label='expopred')\nplt.plot(beer_prod_allpred_df['MEGALITRES_SARIMAPRED'], label='sarimapred')\nplt.plot(beer_prod_allpred_df['MEGALITRES_LSTMPRED'], label='lstmpred')\nplt.title('Beer Production')\nplt.ylabel('megalitres')\nplt.legend(loc='best')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Extrapolation and exponential smoothing tend to overshoot the summer peak each December while on the contrary the LSTM forecast estimates tend to overshoot the winter bottom months.\nSARIMA trend tracks most closely the observed variance of beer production which is in line with RMSE results.\nTherefore, my final conclusion is that for the purpose of making an annual forecast (with monthly frequency) of the Australian beer production in the period from 1986-01-01 till 1996-12-31,\nout of the 4 methods considered, autocorrelation (SARIMA) modelling performs as having the highest predictive power. Still if the forecast needs to be done regularly and time of execution is a factor, exponential smoothening comes as faster 2nd best method to apply without big losses of precision (at the summer months).","metadata":{}},{"cell_type":"code","source":"beer_prod_allpred_df.to_csv('beer_prod_allpred.csv', index=True)","metadata":{},"execution_count":null,"outputs":[]}]}