{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport re\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom wordcloud import WordCloud, STOPWORDS\n\nplt.style.use('fivethirtyeight')","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:49:00.389676Z","iopub.execute_input":"2021-07-30T02:49:00.390063Z","iopub.status.idle":"2021-07-30T02:49:01.43679Z","shell.execute_reply.started":"2021-07-30T02:49:00.389979Z","shell.execute_reply":"2021-07-30T02:49:01.435884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# globals\nDATA_DIR = os.path.join(os.pardir, 'input', 'urbandictionary')\n\nCOL_NAMES = ['character', 'browsing_page_url', 'word_url', 'word', 'definition', 'sentence']","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:49:01.438174Z","iopub.execute_input":"2021-07-30T02:49:01.438464Z","iopub.status.idle":"2021-07-30T02:49:01.443108Z","shell.execute_reply.started":"2021-07-30T02:49:01.438438Z","shell.execute_reply":"2021-07-30T02:49:01.442034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reading Data","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-30T00:46:44.197009Z","iopub.execute_input":"2021-07-30T00:46:44.197459Z","iopub.status.idle":"2021-07-30T00:46:44.289514Z","shell.execute_reply.started":"2021-07-30T00:46:44.197345Z","shell.execute_reply":"2021-07-30T00:46:44.288779Z"}}},{"cell_type":"code","source":"file_paths = []\nfor root, dirs, files in os.walk(os.path.join(DATA_DIR, 'Urban')):\n    for f in files:\n        if f.endswith('.csv') and f.startswith('urban_data'):\n            file_paths.append(os.path.join(root, f))","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:49:01.445386Z","iopub.execute_input":"2021-07-30T02:49:01.445863Z","iopub.status.idle":"2021-07-30T02:49:01.613433Z","shell.execute_reply.started":"2021-07-30T02:49:01.445823Z","shell.execute_reply":"2021-07-30T02:49:01.612554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_urban = pd.concat([pd.read_csv(f, names=COL_NAMES) for f in file_paths])","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:49:01.614792Z","iopub.execute_input":"2021-07-30T02:49:01.615045Z","iopub.status.idle":"2021-07-30T02:49:30.075655Z","shell.execute_reply.started":"2021-07-30T02:49:01.61502Z","shell.execute_reply":"2021-07-30T02:49:30.074757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_urban.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:49:30.07693Z","iopub.execute_input":"2021-07-30T02:49:30.077204Z","iopub.status.idle":"2021-07-30T02:49:30.085649Z","shell.execute_reply.started":"2021-07-30T02:49:30.077177Z","shell.execute_reply":"2021-07-30T02:49:30.084712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_urban.reset_index(inplace=True, drop=True)\ndf_urban.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:49:30.087014Z","iopub.execute_input":"2021-07-30T02:49:30.087356Z","iopub.status.idle":"2021-07-30T02:49:30.117877Z","shell.execute_reply.started":"2021-07-30T02:49:30.08732Z","shell.execute_reply":"2021-07-30T02:49:30.117185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# all unique character are present check\nprint(sorted(df_urban['character'].unique()))","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:49:30.118993Z","iopub.execute_input":"2021-07-30T02:49:30.119448Z","iopub.status.idle":"2021-07-30T02:49:30.284682Z","shell.execute_reply.started":"2021-07-30T02:49:30.119421Z","shell.execute_reply":"2021-07-30T02:49:30.283969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# null values check\ndf_nulls = df_urban[(df_urban.isnull().any(axis=1)) | (df_urban.isna().any(axis=1))]\ndf_nulls.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:49:30.286373Z","iopub.execute_input":"2021-07-30T02:49:30.286867Z","iopub.status.idle":"2021-07-30T02:49:33.032878Z","shell.execute_reply.started":"2021-07-30T02:49:30.286824Z","shell.execute_reply":"2021-07-30T02:49:33.031911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# random samples check (some may contain harsh language)\ndf_sample = df_urban[['word', 'definition', 'sentence']].sample(1)\n\nfor i in df_sample.values:\n    i[1] = re.sub('\\r', ' ', i[1])\n    i[2] = re.sub('\\r', ' ', i[2])\n    print(\"Word: \", i[0])\n    print(\"Meaning: \", i[1])\n    print(\"Sentence: \", i[2])\n    print(\"---\"*20)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:49:33.034411Z","iopub.execute_input":"2021-07-30T02:49:33.03478Z","iopub.status.idle":"2021-07-30T02:49:33.333973Z","shell.execute_reply.started":"2021-07-30T02:49:33.034734Z","shell.execute_reply":"2021-07-30T02:49:33.332775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop nulls\ndf_urban = df_urban.drop(df_nulls.index)\ndf_urban.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:50:33.302884Z","iopub.execute_input":"2021-07-30T02:50:33.303254Z","iopub.status.idle":"2021-07-30T02:50:33.639244Z","shell.execute_reply.started":"2021-07-30T02:50:33.303223Z","shell.execute_reply":"2021-07-30T02:50:33.638065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Very Simple EDA\n\n- Number of words per character\n\n- Length of words, meaning, sentence\n\n- Number of characters in word, meaning, sentence\n\n- Frequent special characters used","metadata":{}},{"cell_type":"code","source":"# histogram simple helper function\ndef plot_hist(vals, bins, title, xlabel, ylabel):\n    plt.figure(figsize=(12,8))\n    sns.distplot(vals, kde=False, bins=bins)\n    plt.title(title)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.show();","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:50:35.151617Z","iopub.execute_input":"2021-07-30T02:50:35.15199Z","iopub.status.idle":"2021-07-30T02:50:35.158041Z","shell.execute_reply.started":"2021-07-30T02:50:35.151956Z","shell.execute_reply":"2021-07-30T02:50:35.15694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### By Word/Phrase/Slang analysis","metadata":{}},{"cell_type":"code","source":"df_urban['word_chars_num'] = df_urban['word'].apply(lambda x: len(x))\ndf_urban['word_words_num'] = df_urban['word'].apply(lambda x: len(x.split()))","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:50:37.766222Z","iopub.execute_input":"2021-07-30T02:50:37.766567Z","iopub.status.idle":"2021-07-30T02:50:40.910691Z","shell.execute_reply.started":"2021-07-30T02:50:37.766535Z","shell.execute_reply":"2021-07-30T02:50:40.909719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_hist(df_urban.word_chars_num, bins=70,\n          title='Characters length in Word/Phrase/Slang',\n          xlabel='Length',\n          ylabel='Count')","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:50:40.912023Z","iopub.execute_input":"2021-07-30T02:50:40.912289Z","iopub.status.idle":"2021-07-30T02:50:41.296806Z","shell.execute_reply.started":"2021-07-30T02:50:40.912263Z","shell.execute_reply":"2021-07-30T02:50:41.295916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_urban['word_chars_num'].quantile([0.1, 0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 0.999])","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:50:41.298205Z","iopub.execute_input":"2021-07-30T02:50:41.29863Z","iopub.status.idle":"2021-07-30T02:50:41.373243Z","shell.execute_reply.started":"2021-07-30T02:50:41.298598Z","shell.execute_reply":"2021-07-30T02:50:41.372567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_hist(df_urban.word_words_num, bins=50,\n          title='Length of Words in Word/Phrase/Slangs',\n          xlabel='Length',\n          ylabel='Count')","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:50:41.374434Z","iopub.execute_input":"2021-07-30T02:50:41.374842Z","iopub.status.idle":"2021-07-30T02:50:41.690019Z","shell.execute_reply.started":"2021-07-30T02:50:41.374811Z","shell.execute_reply":"2021-07-30T02:50:41.68907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_urban['word_words_num'].quantile([0.1, 0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 0.999])","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:50:41.691236Z","iopub.execute_input":"2021-07-30T02:50:41.691521Z","iopub.status.idle":"2021-07-30T02:50:41.743715Z","shell.execute_reply.started":"2021-07-30T02:50:41.691494Z","shell.execute_reply":"2021-07-30T02:50:41.742821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# curiosity: what are some slangs with more than 3 words?\ndf_urban[df_urban.word_words_num > 3].sample(5)['word'].values","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:50:41.744853Z","iopub.execute_input":"2021-07-30T02:50:41.745138Z","iopub.status.idle":"2021-07-30T02:50:41.842037Z","shell.execute_reply.started":"2021-07-30T02:50:41.745109Z","shell.execute_reply":"2021-07-30T02:50:41.84101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### By Definition Analysis","metadata":{}},{"cell_type":"code","source":"df_urban['defn_chars_num'] = df_urban['definition'].apply(lambda x: len(x))\ndf_urban['defn_words_num'] = df_urban['definition'].apply(lambda x: len(x.split()))","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:50:41.845154Z","iopub.execute_input":"2021-07-30T02:50:41.845441Z","iopub.status.idle":"2021-07-30T02:50:49.503104Z","shell.execute_reply.started":"2021-07-30T02:50:41.845413Z","shell.execute_reply":"2021-07-30T02:50:49.50219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_hist(df_urban.defn_chars_num, bins=80,\n          title='Characters length in Definition',\n          xlabel='Length',\n          ylabel='Count')","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:50:49.50572Z","iopub.execute_input":"2021-07-30T02:50:49.506081Z","iopub.status.idle":"2021-07-30T02:50:49.871527Z","shell.execute_reply.started":"2021-07-30T02:50:49.506052Z","shell.execute_reply":"2021-07-30T02:50:49.870572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_urban['defn_chars_num'].quantile([0.1, 0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 0.999])","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:50:49.873118Z","iopub.execute_input":"2021-07-30T02:50:49.873412Z","iopub.status.idle":"2021-07-30T02:50:49.961175Z","shell.execute_reply.started":"2021-07-30T02:50:49.873375Z","shell.execute_reply":"2021-07-30T02:50:49.960219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_hist(df_urban.defn_words_num, bins=80,\n          title='Length of Words in Definition',\n          xlabel='Length',\n          ylabel='Count')","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:50:49.962376Z","iopub.execute_input":"2021-07-30T02:50:49.962672Z","iopub.status.idle":"2021-07-30T02:50:50.454543Z","shell.execute_reply.started":"2021-07-30T02:50:49.96264Z","shell.execute_reply":"2021-07-30T02:50:50.453538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_urban['defn_words_num'].quantile([0.1, 0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 0.999])","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:50:50.456308Z","iopub.execute_input":"2021-07-30T02:50:50.456637Z","iopub.status.idle":"2021-07-30T02:50:50.542398Z","shell.execute_reply.started":"2021-07-30T02:50:50.456606Z","shell.execute_reply":"2021-07-30T02:50:50.541484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### By Sentence Analysis","metadata":{}},{"cell_type":"code","source":"df_urban['sent_chars_num'] = df_urban['sentence'].apply(lambda x: len(x))\ndf_urban['sent_words_num'] = df_urban['sentence'].apply(lambda x: len(x.split()))","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:50:50.543657Z","iopub.execute_input":"2021-07-30T02:50:50.543949Z","iopub.status.idle":"2021-07-30T02:50:56.599135Z","shell.execute_reply.started":"2021-07-30T02:50:50.543923Z","shell.execute_reply":"2021-07-30T02:50:56.59834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_hist(df_urban.sent_chars_num, bins=80,\n          title='Characters length in Sentence',\n          xlabel='Length',\n          ylabel='Count')","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:50:56.600326Z","iopub.execute_input":"2021-07-30T02:50:56.600787Z","iopub.status.idle":"2021-07-30T02:50:56.958926Z","shell.execute_reply.started":"2021-07-30T02:50:56.600727Z","shell.execute_reply":"2021-07-30T02:50:56.957883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_urban['sent_chars_num'].quantile([0.1, 0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 0.999])","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:50:56.960379Z","iopub.execute_input":"2021-07-30T02:50:56.960655Z","iopub.status.idle":"2021-07-30T02:50:57.058183Z","shell.execute_reply.started":"2021-07-30T02:50:56.960629Z","shell.execute_reply":"2021-07-30T02:50:57.05716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_urban[df_urban.sent_chars_num > 1000].shape","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:50:57.059416Z","iopub.execute_input":"2021-07-30T02:50:57.059702Z","iopub.status.idle":"2021-07-30T02:50:57.162973Z","shell.execute_reply.started":"2021-07-30T02:50:57.059673Z","shell.execute_reply":"2021-07-30T02:50:57.161854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_hist(df_urban.sent_words_num, bins=200,\n          title='Length of Words in Sentence',\n          xlabel='Length',\n          ylabel='Count')","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:50:57.164444Z","iopub.execute_input":"2021-07-30T02:50:57.164803Z","iopub.status.idle":"2021-07-30T02:50:57.798658Z","shell.execute_reply.started":"2021-07-30T02:50:57.164729Z","shell.execute_reply":"2021-07-30T02:50:57.797774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_urban['sent_words_num'].quantile([0.1, 0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 0.999])","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:50:57.800114Z","iopub.execute_input":"2021-07-30T02:50:57.800475Z","iopub.status.idle":"2021-07-30T02:50:57.875924Z","shell.execute_reply.started":"2021-07-30T02:50:57.80044Z","shell.execute_reply":"2021-07-30T02:50:57.874918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can choose to remove all the words, definitions and sentences with extreme lengths.","metadata":{}},{"cell_type":"markdown","source":"## Cleaning\n\nThese are the cleaning steps I believe needed to be done based on the data:\n\n- Remove any row with nulls or nans. ✅\n\n- Replace \\r with single white space in a string. ✅\n\n- Remove trailing white spaces at the end. ✅\n\n- Remove word / meaning / sentence that are empty strings. (None of them have empty strings) ✅\n\n- Replace all spaces that exist before a period symbol or punctuation at the end. ✅\n\n- Replace double or more spaces with single space. ✅\n\n- Remove emojis. ✅\n\n- Apply transformations based off EDA. ✅\n\n*I had it as a script so some steps are repetitive.*","metadata":{}},{"cell_type":"code","source":"import os\nimport re\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\n# set globals\nDATA_DIR = os.path.join(os.pardir, 'input', 'urbandictionary')\nCOL_NAMES = ['character', 'browsing_page_url', 'word_url', 'word', 'definition', 'sentence']\n\ndef replace_special(string):\n    \"\"\"Replace special \\r character from text.\"\"\"\n    new_str = re.sub('\\r', ' ', string)\n    return new_str\n\ndef replace_space_before_punct(string):\n    \"\"\"Remove all existing spaces before punctuation.\"\"\"\n    new_str = re.sub(r\"\\b\\s+’\\b\", r\"'\", string)\n    new_str = re.sub(r\"\\\"\\s\\b\", r'\"', new_str)\n    new_str = re.sub(r\"\\b\\s+,\\s*\\b\", r', ', new_str)\n    new_str = re.sub(r'\\s([?.!\"](?:\\s|$))', r'\\1', new_str)\n    return new_str\n\ndef replace_double_spaces(string):\n    \"\"\"Replace all more than one spaces to single space.\"\"\"\n    return ' '.join(string.split())\n\ndef remove_emoji(string):\n    \"\"\"Replace emojis from text\n    Source: https://stackoverflow.com/a/49146722/330558\"\"\"\n\n    emoji_pattern = re.compile(\"[\"\n                          u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                          u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                          u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                          u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                          u\"\\U00002702-\\U000027B0\"\n                          u\"\\U000024C2-\\U0001F251\"\n                          \"]+\", flags=re.UNICODE)\n\n    return emoji_pattern.sub(r'', string)\n\ndef eda_based_cleaning(df):\n    \"\"\"Filter data based off observations from EDA.\"\"\"\n\n    df['word_chars_num'] = df['word'].apply(lambda x: len(x))\n    df['word_words_num'] = df['word'].apply(lambda x: len(x.split()))\n    df['defn_chars_num'] = df['definition'].apply(lambda x: len(x))\n    df['defn_words_num'] = df['definition'].apply(lambda x: len(x.split()))\n    df['sent_chars_num'] = df['sentence'].apply(lambda x: len(x))\n    df['sent_words_num'] = df['sentence'].apply(lambda x: len(x.split()))\n\n    df = df[~((df.word_chars_num > 17) | (df.word_words_num > 3))]\n    print(\"After filtering based on word length: \", df.shape[0])\n    df = df[~((df.defn_chars_num > 190) | (df.defn_words_num > 38))]\n    print(\"After filtering based on definition length: \", df.shape[0])\n    df = df[~((df.sent_chars_num > 155) | (df.sent_words_num > 25))]\n    print(\"After filtering based on sentence length: \", df.shape[0])\n\n    print(\"New dataframe shape: \", df.shape)\n\n    return df\n\ndef final_clean(text):\n    \"\"\"Main function to apply all cleaning functions.\"\"\"\n    cleaned_text = replace_special(text)\n    cleaned_text = replace_space_before_punct(cleaned_text)\n    cleaned_text = replace_double_spaces(cleaned_text)\n    cleaned_text = remove_emoji(cleaned_text)\n\n    return cleaned_text\n\nif __name__ == \"__main__\":\n    print(\"-\"*50)\n    print(\"Loading data...\")\n    file_paths = []\n    for root, dirs, files in os.walk(os.path.join(DATA_DIR, 'Urban')):\n        for f in files:\n            if f.endswith('.csv') and f.startswith('urban_data'):\n                file_paths.append(os.path.join(root, f))\n\n    df_urban = pd.concat([pd.read_csv(f, names=COL_NAMES) for f in file_paths])\n    print(\"Data loaded.\")\n    print(\"Data shape: \", df_urban.shape)\n    df_urban.reset_index(inplace=True)\n    print(\"-\"*50)\n\n    df_nulls = df_urban[(df_urban.isnull().any(axis=1)) | (df_urban.isna().any(axis=1))]\n    print(\"Records with at least one column null: \", df_nulls.shape[0])\n    print(\"Dropping nulls.\")\n    df_urban = df_urban.drop(df_nulls.index)\n    df_urban.reset_index(inplace=True)\n    print(\"New data shape: \", df_urban.shape)\n    print(\"-\"*50)\n\n    print(\"Applying transformation based off EDA.\")\n    df_urban_new = eda_based_cleaning(df_urban)\n    print(\"-\"*50)\n\n    print(\"Cleaning texts...\")\n    df_urban_new['word'] = df_urban_new['word'].apply(lambda x: final_clean(x))\n    df_urban_new['definition'] = df_urban_new['definition'].apply(lambda x: final_clean(x))\n    df_urban_new['sentence'] = df_urban_new['sentence'].apply(lambda x: final_clean(x))\n    print(\"Data shape: \", df_urban_new.shape)\n    print(\"-\"*50)\n\n    print(\"Success!\")","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:50:57.877341Z","iopub.execute_input":"2021-07-30T02:50:57.877685Z","iopub.status.idle":"2021-07-30T02:53:13.262446Z","shell.execute_reply.started":"2021-07-30T02:50:57.877654Z","shell.execute_reply":"2021-07-30T02:53:13.261496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### New pre-processed data samples","metadata":{}},{"cell_type":"code","source":"df_sample = df_urban_new[['word', 'definition', 'sentence']].sample(1)\n\nfor i in df_sample.values:\n    i[1] = re.sub('\\r', ' ', i[1])\n    i[2] = re.sub('\\r', ' ', i[2])\n    print(\"Word: \", i[0])\n    print(\"Meaning: \", i[1])\n    print(\"Sentence: \", i[2])\n    print(\"---\"*20)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T03:23:20.026968Z","iopub.execute_input":"2021-07-30T03:23:20.027574Z","iopub.status.idle":"2021-07-30T03:23:20.185938Z","shell.execute_reply.started":"2021-07-30T03:23:20.027515Z","shell.execute_reply":"2021-07-30T03:23:20.184833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}