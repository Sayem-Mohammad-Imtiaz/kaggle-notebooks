{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":10,"outputs":[{"output_type":"stream","text":"['stopword-lists-for-19-languages', 'ndsc-beginner', 'indonesian-stoplist']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import time\nimport pandas as pd\nimport numpy as np\nimport json\nfrom gensim.models import Word2Vec\nstart = time.time()\ntest = pd.read_csv('../input/ndsc-beginner/test.csv')\ntrain = pd.read_csv('../input/ndsc-beginner/train.csv')\ncategories = pd.read_json('../input/ndsc-beginner/categories.json')\n\n# with open('../input/ndsc-beginner/categories.json') as f:\n#     cats = json.load(f)\n\n\n# English stop words\nenglish_stopwords = open('../input/stopword-lists-for-19-languages/englishST.txt').read()\nenglish_stopwords = english_stopwords.split(sep = '\\n')\n\n# Bahasa Indonesia stop words\nbi_stopwords = pd.read_csv('../input/indonesian-stoplist/stopwordbahasa.csv')\n\ndef prep_bi_stopwords():\n    temp_list = []\n    for word in bi_stopwords['ada']:\n        temp_list.append(word)\n    \n    return temp_list\n\nbi_stopwords = prep_bi_stopwords()\n\n# junk alphabets and fullstop\nlone_alphabets = 'a b c d e f g h i j k l m n o p q r s t u v w x y z .'\nlone_alphabets = lone_alphabets.split()\n\n# stop_words_master_list = english_stopwords + bi_stopwords + lone_alphabets\nstop_words_master_list = english_stopwords + bi_stopwords\n\n\ndef remove_num_from_string(string_sentence):\n    string_sentence =  list(filter(lambda x: x not in '0123456789', string_sentence))\n    string_sentence = ''.join(string_sentence)\n    return string_sentence\n\ndef df_column_to_list(train_or_test):\n    \n    train_or_test = train_or_test['title']\n    train_or_test = list(map(lambda x: remove_num_from_string(x), train_or_test))\n    train_or_test = list(map(lambda y: y.strip().lower().split(), train_or_test))\n    \n    return train_or_test\n\ntrain_feature_list = df_column_to_list(train)\ntest_feature_list = df_column_to_list(test)\n\ncorpus = train_feature_list + test_feature_list\n\n\n\ndef remove_words(target_list, remove_list):\n    done = list(filter(lambda x: x not in remove_list,target_list))\n    return done\n\ntrain_feature_list = list(map(lambda x: remove_words(x,stop_words_master_list), train_feature_list))\ntest_feature_list = list(map(lambda x: remove_words(x,stop_words_master_list), test_feature_list))\n\n\ncorpus = train_feature_list + test_feature_list\ntime.time()-start","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"117.06366562843323"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"categories[categories.Fashion.notnull()]","execution_count":51,"outputs":[{"output_type":"execute_result","execution_count":51,"data":{"text/plain":"                Mobile  Fashion  Beauty\nA Line Dress       NaN     21.0     NaN\nBig Size Dress     NaN     24.0     NaN\nBig Size Top       NaN     30.0     NaN\nBlouseÂ             NaN     26.0     NaN\nBodycon Dress      NaN     22.0     NaN\nCasual Dress       NaN     18.0     NaN\nCrop Top           NaN     29.0     NaN\nMaxi Dress         NaN     20.0     NaN\nOthers             NaN     17.0     NaN\nParty Dress        NaN     19.0     NaN\nShirt              NaN     27.0     NaN\nTanktop            NaN     28.0     NaN\nTshirt             NaN     25.0     NaN\nWedding Dress      NaN     23.0     NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mobile</th>\n      <th>Fashion</th>\n      <th>Beauty</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A Line Dress</th>\n      <td>NaN</td>\n      <td>21.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Big Size Dress</th>\n      <td>NaN</td>\n      <td>24.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Big Size Top</th>\n      <td>NaN</td>\n      <td>30.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Blouse</th>\n      <td>NaN</td>\n      <td>26.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Bodycon Dress</th>\n      <td>NaN</td>\n      <td>22.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Casual Dress</th>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Crop Top</th>\n      <td>NaN</td>\n      <td>29.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Maxi Dress</th>\n      <td>NaN</td>\n      <td>20.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Others</th>\n      <td>NaN</td>\n      <td>17.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Party Dress</th>\n      <td>NaN</td>\n      <td>19.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Shirt</th>\n      <td>NaN</td>\n      <td>27.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Tanktop</th>\n      <td>NaN</td>\n      <td>28.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Tshirt</th>\n      <td>NaN</td>\n      <td>25.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Wedding Dress</th>\n      <td>NaN</td>\n      <td>23.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_iphone_rows = train.loc[train['Category']== 31.0]\ntrain_iphone_rows = train_iphone_rows.loc[~train_iphone_rows['title'].str.contains('iphone', 'i phone')]","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_iphone_rows.tail()","execution_count":50,"outputs":[{"output_type":"execute_result","execution_count":50,"data":{"text/plain":"            itemid                        ...                                                                 image_path\n666297  1040030637                        ...                          mobile_image/c67afd8ebb5d14eff8598d8331b09b67.jpg\n666320  1074177259                        ...                          mobile_image/a4010da2a9050e8308c5ff877471d92f.jpg\n666480  1339297962                        ...                          mobile_image/024d1f53de8b9b3d4130637dd9ed5aa8.jpg\n666572  1454512401                        ...                          mobile_image/6430429cc6cca6113ff8156a2cb55fc5.jpg\n666581  1470187746                        ...                          mobile_image/69c1afc0b9d6bd70e731b68778d02b3c.jpg\n\n[5 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>itemid</th>\n      <th>title</th>\n      <th>Category</th>\n      <th>image_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>666297</th>\n      <td>1040030637</td>\n      <td>081240029833handphone oppo f5 ram 4gb 32gb gar...</td>\n      <td>31</td>\n      <td>mobile_image/c67afd8ebb5d14eff8598d8331b09b67.jpg</td>\n    </tr>\n    <tr>\n      <th>666320</th>\n      <td>1074177259</td>\n      <td>wa 083136315777 beli 2 bonus 1 xiaomi mi max r...</td>\n      <td>31</td>\n      <td>mobile_image/a4010da2a9050e8308c5ff877471d92f.jpg</td>\n    </tr>\n    <tr>\n      <th>666480</th>\n      <td>1339297962</td>\n      <td>murah ready stock bnib google pixel 2 4g lte x...</td>\n      <td>31</td>\n      <td>mobile_image/024d1f53de8b9b3d4130637dd9ed5aa8.jpg</td>\n    </tr>\n    <tr>\n      <th>666572</th>\n      <td>1454512401</td>\n      <td>ipad mini 1 16gb wifi+celluler second sold</td>\n      <td>31</td>\n      <td>mobile_image/6430429cc6cca6113ff8156a2cb55fc5.jpg</td>\n    </tr>\n    <tr>\n      <th>666581</th>\n      <td>1470187746</td>\n      <td>ready xiaomi gaming black shark 6gb 64gb wa o8...</td>\n      <td>31</td>\n      <td>mobile_image/69c1afc0b9d6bd70e731b68778d02b3c.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"categories.loc['Iphone']\n\n\ncheck_miss = list(filter(lambda x: ('iphone' or 'i phone' or 'apple') not in x, list(train_iphone_rows['title'])))","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(check_miss)","execution_count":40,"outputs":[{"output_type":"execute_result","execution_count":40,"data":{"text/plain":"4732"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categories.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def replace_empty_with_other_2d(target_list):\n    \n    output_list = list(map(lambda x: 'product' if len(x)==0 else x, target_list))\n    \n    return output_list\n\n\ntrain_feature_list = replace_empty_with_other_2d(train_feature_list)\ntest_feature_list = replace_empty_with_other_2d(test_feature_list)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.time()\nword_model = Word2Vec(corpus,size = 100, min_count = 1)\ntime.time()-start","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.time()\n\n\ndef prep_feature_arr_list(target_list):\n    output_list = word_model.wv[target_list]\n    output_list_final = output_list.copy()\n    output_list_final.resize(19,100)\n    return output_list_final\n\n\ntrain_feature_arr = np.array(list(map(lambda x: prep_feature_arr_list(x), train_feature_list)))\n\ntest_feature_arr = np.array(list(map(lambda x: prep_feature_arr_list(x), test_feature_list)))\n\ntime.time()-start","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_feature_arr.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ML Stuff"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv1D, GlobalMaxPooling1D, Flatten\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n\n# start = time.time()\n\n# model = Sequential()\n# # model.add(embedding_layer)\n# # model.add(Dropout(0.2))\n\n# # model.add(Conv1D(128, 3, padding='valid',activation='relu',strides=1))\n# model.add(Conv1D(64, 3, padding='valid',activation='relu',strides=1))\n# model.add(Conv1D(32, 3, padding='valid',activation='relu',strides=1))\n# model.add(Flatten())\n# model.add(Dropout(0.2))\n# model.add(Dense(64,activation='relu'))\n# model.add(Dropout(0.2))\n# model.add(Dense(58,activation='softmax'))\n# # opt = keras.optimizers.Adam(lr=1, epsilon=0.1)\n# model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['acc'])\n# time.time()-start","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import LSTM, Dense\nimport numpy as np\n\n# data_dim = 16\n# timesteps = 8\n# num_classes = 58\n\ntrain_label = keras.utils.to_categorical(train['Category'].values, num_classes=58, dtype='float32')\n\n# expected input data shape: (batch_size, timesteps, data_dim)\nmodel = Sequential()\nmodel.add(LSTM(32, return_sequences=True, activation='relu', input_shape=(19, 100)))  # returns a sequence of vectors of dimension 32\nmodel.add(LSTM(32, return_sequences=True, activation='relu'))  # returns a sequence of vectors of dimension 32\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32, activation='relu'))  # return a single vector of dimension 32\nmodel.add(Dropout(0.2))\nmodel.add(Dense(58, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n\n\n\nhistory = model.fit(train_feature_arr, train_label,validation_split = 0.2, epochs=5, batch_size=64, verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_feature_arr.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import keras\n# start = time.time()\n\n# train_label = keras.utils.to_categorical(train['Category'].values, num_classes=58, dtype='float32')\n\n\n# history = model.fit(train_feature_arr, train_label, validation_split = 0.2, epochs=3, batch_size=64, verbose = 1)\n\n# time.time()-start","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.plot(model.history['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"start = time.time()\npredicted = model.predict(test_feature_arr)\npredicted = predicted.argmax(axis=1)\nprint(predicted)\ntime.time()-start","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ans = pd.DataFrame(predicted)\nsubmission = pd.DataFrame(test.itemid)\nsubmission = submission.join(ans)\nsubmission = submission.rename(columns = {0:'Category'})\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('Predominant_submission_LSTM_3epoch.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}