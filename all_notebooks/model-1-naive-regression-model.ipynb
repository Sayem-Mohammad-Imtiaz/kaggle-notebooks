{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        pass\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-29T17:48:25.74077Z","iopub.execute_input":"2021-06-29T17:48:25.741134Z","iopub.status.idle":"2021-06-29T17:48:29.355922Z","shell.execute_reply.started":"2021-06-29T17:48:25.741055Z","shell.execute_reply":"2021-06-29T17:48:29.355093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# README\n\nThis is the implementation code for the first model. The preprocessed dataset we used to train this model has been made public. \n\nEach cell is self-explanatory.\n\nTo reproduce the result in our paper:\n\nplease click on the **Run** tab and choose *run all*. \n\nThe training step is found at cell 16.\n\nThe validation accuracy is zero for the first few iterations because the model hasn't reached the level where a region of interest is detected with IOU > 0.8 for an image. After a few iterations it will start to show a \ndifferent result. ","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport math\nfrom datetime import datetime\nfrom collections import Counter\nimport pandas as pd\nimport numpy as np\n\nimport cv2\nfrom PIL import Image\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\nfrom sklearn.model_selection import train_test_split\nimport xml.etree.ElementTree as ET\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models\nfrom scipy import stats ","metadata":{"execution":{"iopub.status.busy":"2021-06-29T17:48:33.974473Z","iopub.execute_input":"2021-06-29T17:48:33.974801Z","iopub.status.idle":"2021-06-29T17:48:36.708859Z","shell.execute_reply.started":"2021-06-29T17:48:33.974768Z","shell.execute_reply":"2021-06-29T17:48:36.707987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preprocess and loading \ndef normalize(im):\n    \"\"\"Normalizes images with Imagenet stats.\"\"\"\n    imagenet_stats = np.array([[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]])\n    return (im - imagenet_stats[0])/imagenet_stats[1]\n\nclass GAICDataset(Dataset):\n    def __init__(self, paths, bb, transforms=True):\n        self.paths = paths.values\n        self.bb = bb.values\n#         self.transforms = transforms\n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, idx):\n        path = self.paths[idx]\n#         y_class = self.y[idx]\n        x = cv2.imread(str(path)).astype(np.float32)\n        x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)/255\n        y_bb = np.array(self.bb[idx])\n#         x, y_bb = transformsXY(path, self.bb[idx], self.transforms)\n        x = normalize(x)\n        x = np.rollaxis(x, 2)\n        return x, y_bb","metadata":{"execution":{"iopub.status.busy":"2021-06-29T17:48:36.710426Z","iopub.execute_input":"2021-06-29T17:48:36.710807Z","iopub.status.idle":"2021-06-29T17:48:36.719678Z","shell.execute_reply.started":"2021-06-29T17:48:36.710769Z","shell.execute_reply":"2021-06-29T17:48:36.718702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dataset(path):\n    main_path = '../input/processeddataset/Processed2/'\n    df_train = pd.read_csv(main_path + path)\n    df_train['new_path'] = df_train['new_path'].apply(lambda x: f'{main_path}{x}')\n    X_train = df_train['new_path']\n    Y = df_train['new_bb']\n    Y = Y.apply(lambda x: list(map(float, x[1:-1].split())))\n    print(X_train.shape, Y.shape)\n    return X_train, Y\n\nX_train, Y_train = get_dataset('df_train.csv')\nX_val, Y_val = get_dataset('df_val.csv')\nX_test, Y_test = get_dataset('df_test.csv')\n\ntrain_ds = GAICDataset(X_train, Y_train)\nvalid_ds = GAICDataset(X_val, Y_train)\ntest_ds = GAICDataset(X_test, Y_test)\n\nprint(f'size of train data {len(X_train)}, size of test {len(X_test)}, size of val {len(X_val)}')","metadata":{"execution":{"iopub.status.busy":"2021-06-29T17:48:37.763874Z","iopub.execute_input":"2021-06-29T17:48:37.764188Z","iopub.status.idle":"2021-06-29T17:48:37.835845Z","shell.execute_reply.started":"2021-06-29T17:48:37.764156Z","shell.execute_reply":"2021-06-29T17:48:37.834984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\ntrain_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\nvalid_dl = DataLoader(valid_ds, batch_size=batch_size)\ntest_dl = DataLoader(test_ds,  batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T17:48:54.520203Z","iopub.execute_input":"2021-06-29T17:48:54.52057Z","iopub.status.idle":"2021-06-29T17:48:54.52643Z","shell.execute_reply.started":"2021-06-29T17:48:54.520539Z","shell.execute_reply":"2021-06-29T17:48:54.525335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BB_model(nn.Module):\n    def __init__(self):\n        super(BB_model, self).__init__()\n        resnet = models.resnet34(pretrained=True)\n        layers = list(resnet.children())[:8]\n        self.features1 = nn.Sequential(*layers[:6])\n        self.features2 = nn.Sequential(*layers[6:])\n#         self.classifier = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 4))\n        self.bb = nn.Sequential(nn.BatchNorm1d(512), nn.Linear(512, 4))\n        \n    def forward(self, x):\n        x = self.features1(x)\n        x = self.features2(x)\n        x = F.relu(x)\n        x = nn.AdaptiveAvgPool2d((1,1))(x)\n        x = x.view(x.shape[0], -1)\n        return  self.bb(x) #self.classifier(x),","metadata":{"execution":{"iopub.status.busy":"2021-06-29T17:49:01.153803Z","iopub.execute_input":"2021-06-29T17:49:01.154121Z","iopub.status.idle":"2021-06-29T17:49:01.163797Z","shell.execute_reply.started":"2021-06-29T17:49:01.154091Z","shell.execute_reply":"2021-06-29T17:49:01.162994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def update_optimizer(optimizer, lr):\n    for i, param_group in enumerate(optimizer.param_groups):\n        param_group[\"lr\"] = lr","metadata":{"execution":{"iopub.status.busy":"2021-06-29T17:49:05.645887Z","iopub.execute_input":"2021-06-29T17:49:05.646209Z","iopub.status.idle":"2021-06-29T17:49:05.652919Z","shell.execute_reply.started":"2021-06-29T17:49:05.646179Z","shell.execute_reply":"2021-06-29T17:49:05.651962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_epocs(model, optimizer, train_dl, val_dl, epochs=10,C=1000):\n    idx = 0\n    for i in range(epochs):\n        model.train()\n        total = 0\n        sum_loss = 0\n        for x, y_bb in train_dl:\n            batch = x.shape[0]\n            x = x.cuda().float()\n#             y_class = y_class.cuda()\n            y_bb = y_bb.cuda().float()\n#             print(y_bb)\n            out_bb = model(x)\n#             print('outbb', out_bb)\n#             loss_class = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n            loss_bb = F.l1_loss(out_bb, y_bb, reduction=\"none\").sum(1)\n            loss_bb = loss_bb.sum()\n            loss =  loss_bb/C #loss_class +\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            idx += 1\n            total += batch\n            sum_loss += loss.item()\n#             print('loss', loss.item())\n        train_loss = sum_loss/total\n        val_loss, val_acc = val_metrics(model, valid_dl, C)\n        print(\"train_loss %.3f val_loss %.3f val_acc %.3f \" % (train_loss, val_loss, val_acc))\n    return sum_loss/total","metadata":{"execution":{"iopub.status.busy":"2021-06-29T17:51:18.883183Z","iopub.execute_input":"2021-06-29T17:51:18.88353Z","iopub.status.idle":"2021-06-29T17:51:18.892619Z","shell.execute_reply.started":"2021-06-29T17:51:18.883498Z","shell.execute_reply":"2021-06-29T17:51:18.891642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def bb_intersection_over_union(boxA, boxB):\n    \n#     print('boxes', boxA, boxB)\n    \n    xA = max(boxA[0], boxB[0])\n    yA = max(boxA[1], boxB[1])\n    xB = min(boxA[2], boxB[2])\n    yB = min(boxA[3], boxB[3])\n    \n    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n\n    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n\n    iou = interArea / float(boxAArea + boxBArea - interArea)\n    return iou\n\ndef run(bboxes1, bboxes2):\n    \n    x11, y11, x12, y12 = np.split(bboxes1, 4, axis=1)\n    x21, y21, x22, y22 = np.split(bboxes2, 4, axis=1)\n    xA = np.maximum(x11, x21)\n    yA = np.maximum(y11, y21)\n    xB = np.minimum(x12, x22)\n    yB = np.minimum(y12, y22)\n    interArea = np.maximum((xB - xA + 1), 0) * np.maximum((yB - yA + 1), 0)\n    boxAArea = (x12 - x11 + 1) * (y12 - y11 + 1)\n    boxBArea = (x22 - x21 + 1) * (y22 - y21 + 1)\n    iou = interArea / (boxAArea + boxBArea - interArea)\n    return iou\n\ndef pears(a, b):\n    pearc = []\n    for i, j in zip(a, b):\n        pearc.append(stats.pearsonr(i,j)[0])\n    return sum(pearc)\n    \ndef val_metrics(model, valid_dl, C=1000):\n    model.eval()\n    total = 0\n    sum_loss = 0\n    correct = 0 \n    perc = 0\n    for x, y_bb in valid_dl:\n        batch = x.shape[0]\n        x = x.cuda().float()\n#         y_class = y_class.cuda()\n        y_bb = y_bb.cuda().float()\n        with torch.no_grad():\n            out_bb = model(x)\n#         print(y_bb, out_bb)\n#         loss_class = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n        loss_bb = F.l1_loss(out_bb, y_bb, reduction=\"none\").sum(1)\n        loss_bb = loss_bb.sum()\n        loss = loss_bb/C\n        y_bb = y_bb.cpu().numpy()\n        out_bb = out_bb.cpu().numpy()\n        iou = run(y_bb, out_bb).sum(axis=1)\n#         perc += pears(y_bb, out_bb)\n#         print('iou=', iou)\n        \n        correct += sum(iou.flatten() > 0.8)\n#         _, pred = torch.max(out_class, 1)\n#         correct += pred.eq(y_class).sum().item()\n        sum_loss += loss.item()\n        total += batch\n    return sum_loss/total, correct/total","metadata":{"execution":{"iopub.status.busy":"2021-06-29T17:51:21.120195Z","iopub.execute_input":"2021-06-29T17:51:21.12058Z","iopub.status.idle":"2021-06-29T17:51:21.137917Z","shell.execute_reply.started":"2021-06-29T17:51:21.120546Z","shell.execute_reply":"2021-06-29T17:51:21.136981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"USE_GPU = True\n\nif USE_GPU and torch.cuda.is_available():\n    print('using device: cuda')\nelse:\n    print('using device: cpu')","metadata":{"execution":{"iopub.status.busy":"2021-06-29T17:51:22.284274Z","iopub.execute_input":"2021-06-29T17:51:22.284708Z","iopub.status.idle":"2021-06-29T17:51:22.29479Z","shell.execute_reply.started":"2021-06-29T17:51:22.284669Z","shell.execute_reply":"2021-06-29T17:51:22.293109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = BB_model().cuda()\nparameters = filter(lambda p: p.requires_grad, model.parameters())\noptimizer = torch.optim.Adam(parameters)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T17:51:23.14042Z","iopub.execute_input":"2021-06-29T17:51:23.140748Z","iopub.status.idle":"2021-06-29T17:51:23.734588Z","shell.execute_reply.started":"2021-06-29T17:51:23.140717Z","shell.execute_reply":"2021-06-29T17:51:23.733753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_epocs(model, optimizer, train_dl, valid_dl, epochs=25)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T17:51:24.532654Z","iopub.execute_input":"2021-06-29T17:51:24.532979Z","iopub.status.idle":"2021-06-29T18:18:17.244059Z","shell.execute_reply.started":"2021-06-29T17:51:24.532948Z","shell.execute_reply":"2021-06-29T18:18:17.243225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_metrics(model, valid_dl, C=1000):\n    model.eval()\n    total = 0\n    sum_loss = 0\n    correct = 0 \n#     perc = 0\n    for x, y_bb in valid_dl:\n        batch = x.shape[0]\n        x = x.cuda().float()\n#         y_class = y_class.cuda()\n        y_bb = y_bb.cuda().float()\n        with torch.no_grad():\n            out_bb = model(x)\n#         print(y_bb, out_bb)\n#         loss_class = F.cross_entropy(out_class, y_class, reduction=\"sum\")\n        loss_bb = F.l1_loss(out_bb, y_bb, reduction=\"none\").sum(1)\n        loss_bb = loss_bb.sum()\n        loss = loss_bb/C\n        y_bb = y_bb.cpu().numpy()\n        out_bb = out_bb.cpu().numpy()\n        iou = run(y_bb, out_bb).sum(axis=1)\n#         perc += pears(y_bb, out_bb)\n#         print('iou=', iou)\n        \n        correct += sum(iou.flatten() > 0.8)\n#         _, pred = torch.max(out_class, 1)\n#         correct += pred.eq(y_class).sum().item()\n        sum_loss += loss.item()\n        total += batch\n        mydict = {\n            'x': denormalize(x.cpu().numpy().transpose((0, 2, 3, 1))),\n            'y_bb': y_bb,\n            'out_bb': out_bb,\n            'ious': iou\n        }\n        break\n    return sum_loss/total, correct/total, mydict","metadata":{"execution":{"iopub.status.busy":"2021-06-29T18:30:27.572691Z","iopub.execute_input":"2021-06-29T18:30:27.573001Z","iopub.status.idle":"2021-06-29T18:30:27.582552Z","shell.execute_reply.started":"2021-06-29T18:30:27.57297Z","shell.execute_reply":"2021-06-29T18:30:27.58029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_lossp, test_accp, mydict = test_metrics(model, test_dl, C=1000)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# random visualization\nplt.imshow(mydict['x'][3])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T18:38:50.052509Z","iopub.execute_input":"2021-06-29T18:38:50.05284Z","iopub.status.idle":"2021-06-29T18:38:50.359473Z","shell.execute_reply.started":"2021-06-29T18:38:50.052807Z","shell.execute_reply":"2021-06-29T18:38:50.358563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = mydict['x']\nxs = x[0]   #.cpu().numpy()\n# xp = xs.reshape((300, 447, 3))\nxr = xs # np.transpose(xs,(1, 2, 0))","metadata":{"execution":{"iopub.status.busy":"2021-06-29T18:35:44.180755Z","iopub.execute_input":"2021-06-29T18:35:44.18107Z","iopub.status.idle":"2021-06-29T18:35:44.186928Z","shell.execute_reply.started":"2021-06-29T18:35:44.181038Z","shell.execute_reply":"2021-06-29T18:35:44.186185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def denormalize(im):\n    \"\"\"Normalizes images with Imagenet stats.\"\"\"\n    imagenet_stats = np.array([[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]])\n#     return (im - imagenet_stats[0])/imagenet_stats[1]\n    return im*imagenet_stats[1] + imagenet_stats[0]\nxr = denormalize(xr)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T18:35:46.247894Z","iopub.execute_input":"2021-06-29T18:35:46.248204Z","iopub.status.idle":"2021-06-29T18:35:46.25437Z","shell.execute_reply.started":"2021-06-29T18:35:46.248174Z","shell.execute_reply":"2021-06-29T18:35:46.253238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_corner_rect(bb, color='red'):\n    bb = np.array(bb, dtype=np.float32)\n    return plt.Rectangle((bb[1], bb[0]), bb[3]-bb[1], bb[2]-bb[0], color=color,\n                         fill=False, lw=1.6)\n    \nnrows=4\nncols=3\nfig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, 12))\nfor i in range(nrows):\n    for j in range(ncols):\n        num = i*nrows + j\n        axes[i][j].imshow(mydict['x'][num])\n        axes[i][j].add_patch(create_corner_rect(mydict['out_bb'][num], 'red'))\n        axes[i][j].add_patch(create_corner_rect(mydict['y_bb'][num], 'greenyellow'))\n        axes[i][j].set(title=mydict['ious'][num])\n        axes[i][j].axis('off')\nplt.subplots_adjust(left=0.125,\n                    bottom=0.1, \n                    right=0.9, \n                    top=0.9, \n                    wspace=0.05, \n                    hspace=0.05)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-29T18:35:55.194725Z","iopub.execute_input":"2021-06-29T18:35:55.195048Z","iopub.status.idle":"2021-06-29T18:35:56.204434Z","shell.execute_reply.started":"2021-06-29T18:35:55.195017Z","shell.execute_reply":"2021-06-29T18:35:56.203643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_loss, test_acc = val_metrics(model, test_dl, C=1000)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T18:38:09.740711Z","iopub.execute_input":"2021-06-29T18:38:09.741033Z","iopub.status.idle":"2021-06-29T18:38:09.746068Z","shell.execute_reply.started":"2021-06-29T18:38:09.740999Z","shell.execute_reply":"2021-06-29T18:38:09.744883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_loss, test_acc","metadata":{"execution":{"iopub.status.busy":"2021-06-29T18:38:08.368481Z","iopub.execute_input":"2021-06-29T18:38:08.368789Z","iopub.status.idle":"2021-06-29T18:38:08.372747Z","shell.execute_reply.started":"2021-06-29T18:38:08.36876Z","shell.execute_reply":"2021-06-29T18:38:08.371581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #Reading an image\n# def read_image(path):\n#     return cv2.cvtColor(cv2.imread(str(path)), cv2.COLOR_BGR2RGB)\n\n# def resize_image_bb(read_path,write_path,sz=300):\n#     \"\"\"Resize an image and its bounding box and write image to new path\"\"\"\n#     read_path = Path(read_path)\n#     im = read_image(read_path)\n#     im_resized = cv2.resize(im, (int(1.49*sz), sz))\n# #     Y_resized = cv2.resize(create_mask(bb, im), (int(1.49*sz), sz))\n#     print(write_path)\n#     new_path = f'{write_path}/{read_path.parts[-1]}'\n#     print(new_path)\n#     cv2.imwrite(new_path, cv2.cvtColor(im_resized, cv2.COLOR_RGB2BGR))\n#     return new_path","metadata":{"execution":{"iopub.status.busy":"2021-06-29T18:37:12.317148Z","iopub.execute_input":"2021-06-29T18:37:12.317516Z","iopub.status.idle":"2021-06-29T18:37:12.325169Z","shell.execute_reply.started":"2021-06-29T18:37:12.317484Z","shell.execute_reply":"2021-06-29T18:37:12.324156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# resize_path = resize_image_bb('../input/d/kal1224/random/tsinghua.jpg', '/kaggle/working')","metadata":{"execution":{"iopub.status.busy":"2021-06-29T18:39:14.383789Z","iopub.execute_input":"2021-06-29T18:39:14.384103Z","iopub.status.idle":"2021-06-29T18:39:14.387238Z","shell.execute_reply.started":"2021-06-29T18:39:14.384071Z","shell.execute_reply":"2021-06-29T18:39:14.386426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def create_bb_array(x):\n#     \"\"\"Generates bounding box array from a train_df row\"\"\"\n#     return np.array([x[5],x[4],x[7],x[6]])\n\n# #Reading an image\n# def read_image(path):\n#     return cv2.cvtColor(cv2.imread(str(path)), cv2.COLOR_BGR2RGB)\n\n# def create_corner_rect(bb, color='red'):\n#     bb = np.array(bb, dtype=np.float32)\n#     return plt.Rectangle((bb[1], bb[0]), bb[3]-bb[1], bb[2]-bb[0], color=color,\n#                          fill=False, lw=3)\n# def show_corner_bb(im, bb):\n#     plt.imshow(im)\n#     plt.gca().add_patch(create_corner_rect(bb))\n    \n# im = cv2.imread('/kaggle/working/tsinghua.jpg')\n# # bb = create_bb_array(df_train.values[42])\n# bb = bb.cpu().detach().numpy()\n# # print(bb.cpu())\n# # print(bb)\n# show_corner_bb(im, bb[0])","metadata":{"execution":{"iopub.status.busy":"2021-06-29T18:38:03.206202Z","iopub.execute_input":"2021-06-29T18:38:03.206572Z","iopub.status.idle":"2021-06-29T18:38:03.212046Z","shell.execute_reply.started":"2021-06-29T18:38:03.20654Z","shell.execute_reply":"2021-06-29T18:38:03.211199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# paths = []\n# bbs = [1, 2, 3, 4]\n# df_trial = pd.DataFrame([])","metadata":{"execution":{"iopub.status.busy":"2021-06-29T18:38:03.743508Z","iopub.execute_input":"2021-06-29T18:38:03.743829Z","iopub.status.idle":"2021-06-29T18:38:03.747129Z","shell.execute_reply.started":"2021-06-29T18:38:03.743799Z","shell.execute_reply":"2021-06-29T18:38:03.746263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_trial['path'] = '/kaggle/working/tsinghua.jpg'\n# df_trial['bb'] = bbs\n# df_trial['class'] = 1","metadata":{"execution":{"iopub.status.busy":"2021-06-29T18:38:04.143424Z","iopub.execute_input":"2021-06-29T18:38:04.143762Z","iopub.status.idle":"2021-06-29T18:38:04.148249Z","shell.execute_reply.started":"2021-06-29T18:38:04.143725Z","shell.execute_reply":"2021-06-29T18:38:04.14712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trial_ds = GAICDataset(df_trial['path'], df_trial['bb'], df_trial['class'])","metadata":{"execution":{"iopub.status.busy":"2021-06-29T18:39:26.534986Z","iopub.execute_input":"2021-06-29T18:39:26.535326Z","iopub.status.idle":"2021-06-29T18:39:26.538886Z","shell.execute_reply.started":"2021-06-29T18:39:26.535293Z","shell.execute_reply":"2021-06-29T18:39:26.538018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trial_dl = DataLoader(valid_ds, batch_size=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-29T18:37:18.801848Z","iopub.execute_input":"2021-06-29T18:37:18.802162Z","iopub.status.idle":"2021-06-29T18:37:18.806674Z","shell.execute_reply.started":"2021-06-29T18:37:18.802132Z","shell.execute_reply":"2021-06-29T18:37:18.805652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# im = im.reshape((1,)+im.shape)\n# x = torch.from_numpy(im)\n# x = x.cuda().float()\n# for x, y in trial_dl:\n#     print(x.shape, y)\n#     bb = model(x.cuda().float())\n#     break\n# #     ","metadata":{"execution":{"iopub.status.busy":"2021-06-29T18:39:22.240125Z","iopub.execute_input":"2021-06-29T18:39:22.240485Z","iopub.status.idle":"2021-06-29T18:39:22.244036Z","shell.execute_reply.started":"2021-06-29T18:39:22.240452Z","shell.execute_reply":"2021-06-29T18:39:22.242941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}