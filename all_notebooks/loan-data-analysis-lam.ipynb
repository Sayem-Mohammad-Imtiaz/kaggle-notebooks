{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"datacamp.com/workspacecompetition\" target=\"_blank\">![banner](banner.png)</a>\n\n# Loan Data\n\nReady to put your coding skills to the test? Join us for our Workspace Competition.  \nFor more information, visit [datacamp.com/workspacecompetition](https://datacamp.com/workspacecompetition) ","metadata":{"tags":[]}},{"cell_type":"markdown","source":"## Context\nThis dataset ([source](https://www.kaggle.com/itssuru/loan-data)) consists of data from almost 10,000 borrowers that took loans - with some paid back and others still in progress. It was extracted from lendingclub.com which is an organization that connects borrowers with investors. We've included a few suggested questions at the end of this template to help you get started.","metadata":{}},{"cell_type":"code","source":"# Load packages\nimport numpy as np \nimport pandas as pd \n\n#import visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#to create Pmf and Cdf\n!pip install empiricaldist \nfrom empiricaldist import Pmf\nfrom empiricaldist import Cdf\n\n#To use linear regression between variables\nfrom scipy.stats import linregress","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:25.955905Z","iopub.execute_input":"2021-09-03T11:40:25.95654Z","iopub.status.idle":"2021-09-03T11:40:38.755548Z","shell.execute_reply.started":"2021-09-03T11:40:25.956505Z","shell.execute_reply":"2021-09-03T11:40:38.754366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load your data","metadata":{}},{"cell_type":"code","source":"#For Kaggle usage only\nimport os\n#Print out the file paths\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:38.757665Z","iopub.execute_input":"2021-09-03T11:40:38.758009Z","iopub.status.idle":"2021-09-03T11:40:38.77409Z","shell.execute_reply.started":"2021-09-03T11:40:38.757973Z","shell.execute_reply":"2021-09-03T11:40:38.772737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loading file from Kaggle\ndf = pd.read_csv('/kaggle/input/loan-data-analysis-datacamp-workspace/loan_data.csv', index_col=None)\n\n# Load data from the csv file\n# df = pd.read_csv('loan_data.csv', index_col=None)\n\n# Change the dots in the column names to underscores\ndf.columns = [c.replace(\".\", \"_\") for c in df.columns]\nprint(f\"Number of rows/records: {df.shape[0]}\")\nprint(f\"Number of columns/variables: {df.shape[1]}\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:38.776413Z","iopub.execute_input":"2021-09-03T11:40:38.776858Z","iopub.status.idle":"2021-09-03T11:40:38.86046Z","shell.execute_reply.started":"2021-09-03T11:40:38.776812Z","shell.execute_reply":"2021-09-03T11:40:38.859639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Understand your variables","metadata":{}},{"cell_type":"code","source":"# Understand your variables\nvariables = pd.DataFrame(columns=['Variable','Number of unique values','Values'])\n\nfor i, var in enumerate(df.columns):\n    variables.loc[i] = [var, df[var].nunique(), df[var].unique().tolist()]\n    \n#Loading file from Kaggle\nvar_dict = pd.read_csv('/kaggle/input/loan-data-analysis-datacamp-workspace/variable_explanation.csv', index_col=0) \n\n# Join with the variables dataframe\n# var_dict = pd.read_csv('variable_explanation.csv', index_col=0)\nvariables.set_index('Variable').join(var_dict)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:38.861943Z","iopub.execute_input":"2021-09-03T11:40:38.862502Z","iopub.status.idle":"2021-09-03T11:40:38.977931Z","shell.execute_reply.started":"2021-09-03T11:40:38.862466Z","shell.execute_reply":"2021-09-03T11:40:38.97725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now you can start to explore this dataset with the chance to win incredible prices! Can't think of where to start? Try your hand at these suggestions:\n\n- Extract useful insights and visualize them in the most interesting way possible.\n- Find out how long it takes for users to pay back their loan.\n- Build a model that can predict the probability a user will be able to pay back their loan within a certain period.\n- Find out what kind of people take a loan for what purposes.","metadata":{}},{"cell_type":"code","source":"#See the full descriptions of each of the variable\n#Iterator for var_dict's values to be used in printing\nvar_description = (item for item in var_dict.values)\nfor i in range(len(variables['Variable'])):\n    print(variables['Variable'][i],':', next(var_description))","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:38.979077Z","iopub.execute_input":"2021-09-03T11:40:38.979618Z","iopub.status.idle":"2021-09-03T11:40:38.992736Z","shell.execute_reply.started":"2021-09-03T11:40:38.979585Z","shell.execute_reply":"2021-09-03T11:40:38.991354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Judging Criteria\n| CATEGORY | WEIGHTAGE | DETAILS                                                              |\n|:---------|:----------|:---------------------------------------------------------------------|\n| **Analysis** | 30%       | <ul><li>Documentation on the goal and what was included in the analysis</li><li>How the question was approached</li><li>Visualisation tools and techniques utilized</li></ul>       |\n| **Results**  | 30%       | <ul><li>How the results derived related to the problem chosen</li><li>The ability to trigger potential further analysis</li></ul> |\n| **Creativity** | 40% | <ul><li>How \"out of the box\" the analysis conducted is</li><li>Whether the publication is properly motivated and adds value</li></ul> |","metadata":{}},{"cell_type":"markdown","source":"# **Exploratory Data Analysis**","metadata":{}},{"cell_type":"markdown","source":"We'll begin with some basic descriptive statistics below to understand more about each variable","metadata":{}},{"cell_type":"code","source":"#See the important stats of each variable in the dataset\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:38.994072Z","iopub.execute_input":"2021-09-03T11:40:38.994421Z","iopub.status.idle":"2021-09-03T11:40:39.062471Z","shell.execute_reply.started":"2021-09-03T11:40:38.994389Z","shell.execute_reply":"2021-09-03T11:40:39.061395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check the variable types and whether there're any missing values\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:39.063769Z","iopub.execute_input":"2021-09-03T11:40:39.064077Z","iopub.status.idle":"2021-09-03T11:40:39.082801Z","shell.execute_reply.started":"2021-09-03T11:40:39.064043Z","shell.execute_reply":"2021-09-03T11:40:39.081764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, there's no missing data in the dataset above, which will make the job of filling missing\nvalues easier. ","metadata":{}},{"cell_type":"code","source":"sns.set()  #Set to the default style of seaborn\n#See the distribution of people who qualify for credit underwriting criteria\nfig , ax = plt.subplots()\nplt.hist(x = df['credit_policy'], bins = 2)\nplt.title(\"Distribution of credit underwriting criteria\")\nplt.ylabel('Number of people')\nax.set_xticks((0.25, 0.75))\nax.set_xticklabels(['Do not meet criteria','Meet criteria'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:39.085481Z","iopub.execute_input":"2021-09-03T11:40:39.085829Z","iopub.status.idle":"2021-09-03T11:40:39.27966Z","shell.execute_reply.started":"2021-09-03T11:40:39.085797Z","shell.execute_reply":"2021-09-03T11:40:39.278568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that **there're almost 4 times the number of people** who meet underwriting criteria compared to those who don't.","metadata":{}},{"cell_type":"code","source":"fig,ax = plt.subplots()\nplt.bar(x = df['purpose'].unique(), height = df['purpose'].value_counts()) #default will sort from highest\nplt.title(\"Purpose of the loan by frequency\")\nplt.ylabel('Frequency')\nax.set_ylim(0, 4500)\n# Add the values on top of the x axis\nvalues = df['purpose'].value_counts()\nfor hor, ver in enumerate(values):\n    #hor is horizontal coordinate, ver is vertical coordinate\n    ax.text(hor - 0.25, ver+ver*0.05, s = str(ver), color = 'red')\nplt.xticks(x = df['purpose'].unique(), rotation=45) #Rotate X ticks by 45 degrees\nplt.yticks()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:39.281711Z","iopub.execute_input":"2021-09-03T11:40:39.282302Z","iopub.status.idle":"2021-09-03T11:40:39.53354Z","shell.execute_reply.started":"2021-09-03T11:40:39.282256Z","shell.execute_reply":"2021-09-03T11:40:39.532343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We'll visualize this with seaborn to see which category has the most number of people who have not paid back their loan\nplt.figure(figsize = (10, 7))\nsns.countplot(x = 'purpose', hue ='not_fully_paid', data=df, palette = 'Set2')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:39.535366Z","iopub.execute_input":"2021-09-03T11:40:39.535808Z","iopub.status.idle":"2021-09-03T11:40:39.850954Z","shell.execute_reply.started":"2021-09-03T11:40:39.535761Z","shell.execute_reply":"2021-09-03T11:40:39.85022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Debt consolidation category has the highest number of unpaid loans, at over 500 people. ","metadata":{}},{"cell_type":"markdown","source":"Next we'll see the percentage of people who are most likely to not pay back based on their FICO score. We'll use the image below as guideline to divide into different categories.\n1. 300 - 560: very bad\n2. 560 - 650: bad\n3. 650 - 700: fair\n4. 700 - 750: good\n5. 750 - 850: excellent \n![](https://d187qskirji7ti.cloudfront.net/news/wp-content/uploads/2014/04/Credit-Score-Factors.jpg)","metadata":{}},{"cell_type":"code","source":"plt.suptitle('Distribution of people by fico score')\npd.cut(df['fico'], bins = [300,560,650,700,750,850],\n        labels =['Very bad','Bad','Fair','Good','Excellent']).hist()\nplt.show()\ndf_fico = pd.cut(df['fico'], bins = [300,560,650,700,750,850],\n        labels =['Very bad','Bad','Fair','Good','Excellent'])\nprint(df_fico.value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:39.851956Z","iopub.execute_input":"2021-09-03T11:40:39.852444Z","iopub.status.idle":"2021-09-03T11:40:40.06756Z","shell.execute_reply.started":"2021-09-03T11:40:39.852404Z","shell.execute_reply":"2021-09-03T11:40:40.066681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that there're no people with \"very bad\" credit scores. There're over 5200 people, or more than 50% of dataset with scores of good or excellent. ","metadata":{}},{"cell_type":"code","source":"#Alternative way to visualize this with credit policy variable\nplt.figure(figsize = (10,6))\nplt.suptitle('Distribution of people by fico score and their credit')\ndf[df['credit_policy'] == 1]['fico'].hist(bins = 15,alpha = 0.4, color = 'green',\n                                          label ='Meet credit policy')\ndf[df['credit_policy'] == 0]['fico'].hist(bins = 15,alpha = 0.3, color = 'red',\n                                          label ='Do not meet credit policy')\nplt.legend()\nplt.show()\nprint(\"Number of people with good (700) or above credit score but do not meet credit policy is: \" + \n      str(df[(df['credit_policy']==0) & (df['fico']>=700)]['credit_policy'].count()))","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:40.068853Z","iopub.execute_input":"2021-09-03T11:40:40.069154Z","iopub.status.idle":"2021-09-03T11:40:40.388958Z","shell.execute_reply.started":"2021-09-03T11:40:40.069124Z","shell.execute_reply":"2021-09-03T11:40:40.38799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"According to graph above, it's surprising to see that there's quite some number of people who do not meet underwriting credit criteria, but have \"good\" or even \"excellent\" scores. Next we'll look at the relationship between these variables: interest rate, credit policy, not_fully_paid, and fico score.","metadata":{}},{"cell_type":"code","source":"sns.lmplot(x = 'int_rate', y = 'fico', hue = 'credit_policy', col ='not_fully_paid', data=df, palette = 'RdBu')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:40.390368Z","iopub.execute_input":"2021-09-03T11:40:40.390672Z","iopub.status.idle":"2021-09-03T11:40:42.741167Z","shell.execute_reply.started":"2021-09-03T11:40:40.390645Z","shell.execute_reply":"2021-09-03T11:40:42.740108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"People who meet credit policy tend to have lower interest rate and have higher fico score. In both plots, int_rate and fico score have negative linear relationship as indicated by the lines. ","metadata":{}},{"cell_type":"code","source":"df_nfp_0 = df[df['not_fully_paid'] == 0]\ndf_nfp_1 = df[df['not_fully_paid'] == 1]\npub_rec_fico0 = linregress(df_nfp_0['pub_rec'], df_nfp_0['fico'])\npub_rec_fico1 = linregress(df_nfp_1['pub_rec'], df_nfp_1['fico'])\nprint(pub_rec_fico0)\nprint(pub_rec_fico1)\nfx_pub_rec_0 = df_nfp_0['pub_rec']\nfx_pub_rec_1 = df_nfp_1['pub_rec']\nfy_fico_0 = pub_rec_fico0.intercept + fx_pub_rec_0 * pub_rec_fico0.slope\nfy_fico_1 = pub_rec_fico1.intercept + fx_pub_rec_1 * pub_rec_fico1.slope\nsns.catplot(x = 'pub_rec', y = 'fico', hue = 'not_fully_paid', data=df)\nplt.plot(fx_pub_rec_0, fy_fico_0, '-')\nplt.plot(fx_pub_rec_1, fy_fico_1, '-')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:42.742553Z","iopub.execute_input":"2021-09-03T11:40:42.742864Z","iopub.status.idle":"2021-09-03T11:40:43.62619Z","shell.execute_reply.started":"2021-09-03T11:40:42.742837Z","shell.execute_reply":"2021-09-03T11:40:43.625353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There's a strong correlation between having 0 public record and having fully paid. Also, if people have a public record or more, then it's very likely that their FICO score will be below 750. We also see that for every public record the person has, he/she will get -20 or -18 points deducted from their FICO score, depending on whether they have paid their loan in full. People who have not paid yet only have bad public records up to 2 times. ","metadata":{}},{"cell_type":"code","source":"df.groupby(['pub_rec'])['not_fully_paid'].describe()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:43.627285Z","iopub.execute_input":"2021-09-03T11:40:43.627694Z","iopub.status.idle":"2021-09-03T11:40:43.668304Z","shell.execute_reply.started":"2021-09-03T11:40:43.627654Z","shell.execute_reply":"2021-09-03T11:40:43.667272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create correlation matrix and graph it\ncorr = df.corr()\n#To cover half away the correlation matrix\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\nwith sns.axes_style('white'):\n    fig, ax = plt.subplots(figsize = (10,8))\n    ax = sns.heatmap(corr, mask = mask, vmax = 1, square = True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:43.669666Z","iopub.execute_input":"2021-09-03T11:40:43.669995Z","iopub.status.idle":"2021-09-03T11:40:44.21419Z","shell.execute_reply.started":"2021-09-03T11:40:43.669963Z","shell.execute_reply":"2021-09-03T11:40:44.213202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the correlation matrix, we can infer a few things: \n- There's a strong negative correlation between fico score and interest rate, that is they move in opposite direction. This makes sense because if someone has poor credit score, their interest will be higher and vice versa. We'll graph this below.\n- There's a strong negative correlation between number of inquiry in the past 6 months and credit policy. As people make more credit inquiries, they'll be less likely to meet underwriting credit criteria. \n- Strong negative correlation between revolving utility (the amount of credit used over the total credit line available) and fico. For people who overspends their credit limit, this will have negative impact on their fico score. \n- Moderate positive correlation between natural log of annual income & installment. As people earn more money annually, they will also have a bigger monthly payment (installment) since they have more disposable income to spend. \n- Interest rate & revolving utility has moderate positive correlation. As people utilizes more of their available credit line, the interest rate for them will go up.\n- Dti (debt-to-income ratio) and revolving utility has mild positive correlation. As people own more debt, it also means that they're utilizing more of their own available credit line. \n- Log annual income has mild positive correlation with days with credit line (how long they have had a credit line). ","metadata":{}},{"cell_type":"code","source":"sns.jointplot(x ='fico', y = 'int_rate', data =df)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:44.215409Z","iopub.execute_input":"2021-09-03T11:40:44.215721Z","iopub.status.idle":"2021-09-03T11:40:44.975662Z","shell.execute_reply.started":"2021-09-03T11:40:44.215691Z","shell.execute_reply":"2021-09-03T11:40:44.974681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the graph on top, we can see that interest rate will drop as fico score gets better.","metadata":{}},{"cell_type":"code","source":"#Select continous variables (float)\ncont_var = [c for c in df.columns if df[c].dtype == 'float']\n\n#Graph continuous variables to see the distribution\nfor i in cont_var:\n    sns.boxplot(y = i, palette = 'rainbow', data = df)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:44.976985Z","iopub.execute_input":"2021-09-03T11:40:44.977308Z","iopub.status.idle":"2021-09-03T11:40:45.716628Z","shell.execute_reply.started":"2021-09-03T11:40:44.977276Z","shell.execute_reply":"2021-09-03T11:40:45.715554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next we'll answer the question of when the loan will be paid off assuming that a monthly installment is being made. We'll create a new column for this. Then we'll use pivot table to see what types of loans will take the longest to pay off. ","metadata":{}},{"cell_type":"code","source":"df['time_to_paid_off_mths'] = df['revol_bal']/df['installment']\npd.pivot_table(index = 'purpose', values = 'time_to_paid_off_mths', aggfunc = 'mean', margins = True, \n               margins_name = 'Average across all purposes', data = df)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:45.717867Z","iopub.execute_input":"2021-09-03T11:40:45.718161Z","iopub.status.idle":"2021-09-03T11:40:45.752694Z","shell.execute_reply.started":"2021-09-03T11:40:45.718132Z","shell.execute_reply":"2021-09-03T11:40:45.751623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Home improvement seems to take the longest to pay off, at 95 months on average. The category \"major_purchase\" has the shortest paid off time at 42 months.","metadata":{}},{"cell_type":"code","source":"pd.pivot_table(index = 'purpose', values = ['log_annual_inc', 'dti', 'delinq_2yrs'], \n               aggfunc = {'log_annual_inc':np.mean,'dti':np.mean,\n                           'delinq_2yrs': 'count'             }, data = df)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:45.754362Z","iopub.execute_input":"2021-09-03T11:40:45.754801Z","iopub.status.idle":"2021-09-03T11:40:45.784811Z","shell.execute_reply.started":"2021-09-03T11:40:45.754752Z","shell.execute_reply":"2021-09-03T11:40:45.78377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There's not much income variation across different purposes, but we can see that groups with the most number of delinquencies in the past 2 years are \"debt consolidation\" and \"all other\". Debt-to-income ratio is also high in the debt consolidation and credit card groups.","metadata":{}},{"cell_type":"markdown","source":"Since income is a log variable, we'll use a special KDE plot to see its distribution.","metadata":{}},{"cell_type":"code","source":"sns.kdeplot(df['log_annual_inc'], hue = df['not_fully_paid'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:45.787357Z","iopub.execute_input":"2021-09-03T11:40:45.787807Z","iopub.status.idle":"2021-09-03T11:40:46.2854Z","shell.execute_reply.started":"2021-09-03T11:40:45.78776Z","shell.execute_reply":"2021-09-03T11:40:46.284343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It has a perfect normal distribution with mean at around 11. There're more people who have fully paid than people who have not fully paid. ","metadata":{}},{"cell_type":"markdown","source":"We'll turn some variables into PMF functions to be able to more easily visualize them. Let's begin with delinq_2yrs","metadata":{}},{"cell_type":"code","source":"pmf_delinq = Pmf.from_seq(df['delinq_2yrs'], normalize = True)\npmf_delinq.bar()\nplt.xlabel('Number of delinquencies in the past 2 years')\nplt.ylabel('Probability')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:46.286691Z","iopub.execute_input":"2021-09-03T11:40:46.286982Z","iopub.status.idle":"2021-09-03T11:40:46.533219Z","shell.execute_reply.started":"2021-09-03T11:40:46.286955Z","shell.execute_reply":"2021-09-03T11:40:46.53216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Over 85% of people do not have any deliquencies in the past 2 years. There's an insignificant % of people with deliquencies greater than 3. ","metadata":{}},{"cell_type":"code","source":"pmf_pubrec = Pmf.from_seq(df['pub_rec'], normalize = True)\npmf_pubrec.bar()\nplt.xlabel('Number of derogatory public records')\nplt.ylabel('Probability')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:46.536612Z","iopub.execute_input":"2021-09-03T11:40:46.53695Z","iopub.status.idle":"2021-09-03T11:40:46.751152Z","shell.execute_reply.started":"2021-09-03T11:40:46.536917Z","shell.execute_reply":"2021-09-03T11:40:46.750126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Over 90% have 0 derogatory public records and a few % who have 1 derogatory public record. ","metadata":{}},{"cell_type":"code","source":"dti_0 = df[df['not_fully_paid'] == 0]['dti']\ndti_1 = df[df['not_fully_paid'] == 1]['dti']  \ncdf_dti_0 = Cdf.from_seq(dti_0, normalize = True)\ncdf_dti_1 = Cdf.from_seq(dti_1, normalize = True)\ncdf_dti_0.plot(label = \"Fully paid\")\ncdf_dti_1.plot(label = \"Not fully paid\")\nplt.legend()\nplt.xlabel('Debt-to-income ratio')\nplt.ylabel('CDF')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:46.752827Z","iopub.execute_input":"2021-09-03T11:40:46.753129Z","iopub.status.idle":"2021-09-03T11:40:47.019498Z","shell.execute_reply.started":"2021-09-03T11:40:46.7531Z","shell.execute_reply":"2021-09-03T11:40:47.018259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Overall, about 82% of the people who have fully paid have debt to income ratio smaller than 20 vs. 80% of people who have not fully paid. ","metadata":{}},{"cell_type":"markdown","source":"# **Preprocessing**","metadata":{}},{"cell_type":"markdown","source":"Next we'll go into the preprocessing aspect for the variables. First we'll import the necessary libraries. ","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, MinMaxScaler, OrdinalEncoder, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nimport optuna\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import plot_confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:47.021071Z","iopub.execute_input":"2021-09-03T11:40:47.021507Z","iopub.status.idle":"2021-09-03T11:40:48.118637Z","shell.execute_reply.started":"2021-09-03T11:40:47.021464Z","shell.execute_reply":"2021-09-03T11:40:48.117501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Use dummy encoding for purpose\ndf_dummy = pd.get_dummies(df['purpose'], prefix = 'purpose', drop_first = True) #to avoid multicollinearity\n#Merging dataframes to get the dummy variables\ndf = df.merge(df_dummy, left_index = True, right_index = True)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:48.119956Z","iopub.execute_input":"2021-09-03T11:40:48.120316Z","iopub.status.idle":"2021-09-03T11:40:48.133536Z","shell.execute_reply.started":"2021-09-03T11:40:48.120285Z","shell.execute_reply":"2021-09-03T11:40:48.132157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Separate 'not_fully_paid' into the target for prediction\ny = df['not_fully_paid']\n#Drop the target and old categorical 'purpose' from dataframe\nX = df\nX.drop('purpose', axis='columns',inplace = True)\nX.drop('not_fully_paid', axis = 'columns', inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:48.135042Z","iopub.execute_input":"2021-09-03T11:40:48.135583Z","iopub.status.idle":"2021-09-03T11:40:48.146884Z","shell.execute_reply.started":"2021-09-03T11:40:48.135546Z","shell.execute_reply":"2021-09-03T11:40:48.1453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Cont var will be standardized\ncont_var = [c for c in df.columns if df[c].dtype == 'float']\ncont_var.remove('log_annual_inc')\ncont_var_exc_inc = cont_var\n\nint_var = [c for c in df.columns if df[c].dtype == 'int']\nint_var.remove('credit_policy')\nint_var_exc_credit_policy = int_var\n\n#Standardize the integer variables to improve accuracy except for log_annual_inc\nstandardizeX = StandardScaler()\n\n# Initialize column transformer\ncolumnTrans = ColumnTransformer(transformers = [\n    ('cont',standardizeX,cont_var_exc_inc),\n    ],remainder='passthrough')","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:48.148361Z","iopub.execute_input":"2021-09-03T11:40:48.148686Z","iopub.status.idle":"2021-09-03T11:40:48.15811Z","shell.execute_reply.started":"2021-09-03T11:40:48.148656Z","shell.execute_reply":"2021-09-03T11:40:48.157194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Hyperparameter tuning**","metadata":{}},{"cell_type":"markdown","source":"This section below was only run a few times in order to get the optimized parameters for the logistic regression model.","metadata":{}},{"cell_type":"code","source":"#With Optuna for tuning\naccuracy = []\ndef run(trial):\n#     penalty = trial.suggest_categorical('penalty',['l1', 'l2', 'elasticnet', 'none'])\n    tol = trial.suggest_float('tol', 0.0000001, 0.0001, log = True)\n    C = trial.suggest_float('C', 1.0, 1000)\n    max_iter = trial.suggest_int('max_iter', 10, 100000)\n    solver = trial.suggest_categorical('solver', ['saga'])\n#     l1_ratio = trial.suggest_float('l1_ratio', 0, 1)\n\n    #Standardize the continuous variables\n    # Using regular train_test split to work with Optuna\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n    X_train = columnTrans.fit_transform(X_train)\n    X_test = columnTrans.transform(X_test)\n    model1 = LogisticRegression(penalty='l2', tol=0.0001, C=1.0, solver='lbfgs', \n                                max_iter=100, multi_class='auto', verbose=0, \n                            warm_start=False, n_jobs=-1, l1_ratio=None, random_state = 0)\n    #Fiting the model\n    model1.fit(X_train, y_train)\n\n    #Make prediction\n    preds = model1.predict(X_test)\n\n    #Scoring the model\n    score = model1.score(X_test, y_test)\n    accuracy.append(score)\n    print(f'Accuracy score is: {score}')\n    return score","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:18.638963Z","iopub.execute_input":"2021-09-03T11:40:18.639456Z","iopub.status.idle":"2021-09-03T11:40:18.656574Z","shell.execute_reply.started":"2021-09-03T11:40:18.639356Z","shell.execute_reply":"2021-09-03T11:40:18.655809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Suppress optuna output\noptuna.logging.set_verbosity(optuna.logging.WARNING)\noptuna.samplers.RandomSampler(seed = 0) #Use random sampling\nstudy = optuna.create_study(direction = 'maximize')\nstudy.optimize(run, n_trials = 200)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:40:48.159739Z","iopub.execute_input":"2021-09-03T11:40:48.160396Z","iopub.status.idle":"2021-09-03T11:43:00.237784Z","shell.execute_reply.started":"2021-09-03T11:40:48.160356Z","shell.execute_reply":"2021-09-03T11:43:00.236342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Get the best parameters for the model\nstudy.best_params","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:43:38.616433Z","iopub.execute_input":"2021-09-03T11:43:38.617126Z","iopub.status.idle":"2021-09-03T11:43:38.62399Z","shell.execute_reply.started":"2021-09-03T11:43:38.617087Z","shell.execute_reply":"2021-09-03T11:43:38.623004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model Building**","metadata":{}},{"cell_type":"markdown","source":"First we'll use logistic regression to predict whether a person has fully paid yet or not. ","metadata":{}},{"cell_type":"code","source":"#Plugged in with tuned parameters from Optuna 200 trials\nbest_params = {'tol': 7.651638057784127e-06,\n             'C': 952.0477857994174,\n             'max_iter': 95461,\n             'solver': 'saga'}\nmodel1 = LogisticRegression(random_state = 0,**best_params)\n\n#to hold results\naccuracy = []\ncoef = np.zeros((1,19))\nintercept = np.zeros((1,1))\n\n#Establish stratified Kfold with 10 splits\nskf = StratifiedKFold(n_splits = 10, shuffle = True)\n\nfor fold, (train_index,test_index) in enumerate(skf.split(X, y)):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n\n    #Standardize the continuous variables\n    X_train = columnTrans.fit_transform(X_train)\n    X_test = columnTrans.transform(X_test)\n\n    #Fiting the model\n    model1.fit(X_train, y_train)\n\n    #Make prediction\n    preds = model1.predict(X_test)\n\n    #Scoring the model\n    score = model1.score(X_test, y_test)\n    accuracy.append(score)\n    coef += model1.coef_\n    intercept += model1.intercept_\n    print(f'Accuracy score for {fold}th is: {score}')\n\nprint(f'The average score across all 10 folds is {np.mean(accuracy)}')","metadata":{"execution":{"iopub.status.busy":"2021-09-03T11:43:56.033391Z","iopub.execute_input":"2021-09-03T11:43:56.033786Z","iopub.status.idle":"2021-09-03T11:46:33.683776Z","shell.execute_reply.started":"2021-09-03T11:43:56.033753Z","shell.execute_reply":"2021-09-03T11:46:33.682386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that this logistic regression model has an **average accuracy of roughly 84%** across 10 folds in predicting who will be most likely to pay back the loan.","metadata":{}},{"cell_type":"markdown","source":"Then we'll analyze the relationship between X and y of each independent variables have on not_fully_paid","metadata":{}},{"cell_type":"code","source":"#Divide by the number of folds to get the average coefficients and intercept\ncoef = coef/10\nintercept = intercept/10\ncoef = coef[0]\nintercept = intercept[0]","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:00:40.892574Z","iopub.status.idle":"2021-09-03T10:00:40.892942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pprint #to print dictionary output nicely\npos_coef_list = []\nneg_coef_list = []\npos_coef = {} #for positive coefficients var\nneg_coef = {} #for negative coefficients var\nfor i,c in enumerate(X.columns): \n    if coef[i] > 0:\n        pos_coef[c] = coef[i]\n        pos_coef_list.append(coef[i])\n    else:\n        neg_coef[c] = coef[i]\n        neg_coef_list.append(coef[i])\nprint('The default person with 0 across all variables has a probability of having not fully paid equals to:', intercept)\nprint('The bigger these variables below get, it means the more likely that the person has not fully paid')\npprint.pprint(pos_coef)\nprint(\"The bigger these variables below get, it means the more likely that the person has fully paid\")\npprint.pprint(neg_coef)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:00:40.893787Z","iopub.status.idle":"2021-09-03T10:00:40.894184Z"},"trusted":true},"execution_count":null,"outputs":[]}]}