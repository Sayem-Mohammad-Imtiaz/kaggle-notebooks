{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport cv2\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/indian-dance-form-recognition/dataset/train.csv')\ntest=pd.read_csv('/kaggle/input/indian-dance-form-recognition/dataset/test.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train['target'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Class_map={'manipuri':0, 'bharatanatyam':1, 'odissi':2 ,'kathakali':3, 'kathak':4, 'sattriya':5,\n 'kuchipudi':6, 'mohiniyattam':7}\ninverse_map={0:'manipuri', 1:'bharatanatyam', 2:'odissi' ,3:'kathakali',4: 'kathak', 5:'sattriya',\n 6:'kuchipudi', 7:'mohiniyattam'}\ntrain['target']=train['target'].map(Class_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_h,img_w= (224,224)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img=[]\ntrain_label=[]\nj=0\npath='/kaggle/input/indian-dance-form-recognition/dataset/train'\nfor i in tqdm(train['Image']):\n    final_path=os.path.join(path,i)\n    img=cv2.imread(final_path)\n    img=cv2.resize(img,(img_h,img_w))\n    img=img.astype('float32')\n    train_img.append(img)\n    train_label.append(train['target'][j])\n    j=j+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_valid, y_train, y_valid = train_test_split(train_img, train_label, test_size=0.30, shuffle= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_img=[]\npath='/kaggle/input/indian-dance-form-recognition/dataset/test'\nfor i in tqdm(test['Image']):\n    final_path=os.path.join(path,i)\n    img=cv2.imread(final_path)\n    img=cv2.resize(img,(img_h,img_w))\n    img=img.astype('float32')\n    test_img.append(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,# divide each input by its std\n        rescale=1./255,\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.3, # Randomly zoom image \n        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ntest_datagen= ImageDataGenerator(rescale=1./255)\nvalid_datagen= ImageDataGenerator(rescale=1./255)\ntrain_datagen.fit(x_train)\ntest_datagen.fit(test_img)\nvalid_datagen.fit(x_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img=np.array(train_img)\nx_train= np.array(x_train)\nx_valid= np.array(x_valid)\ny_train= np.array(y_train)\ny_valid= np.array(y_valid)\ntest_img=np.array(test_img)\ntrain_label=np.array(train_label)\nprint(\"Shape of training data=\",x_train.shape,\" and shape of labels of training data= \",y_train.shape)\nprint(\"Shape of validation data=\",x_valid.shape,\" and shape of labels of validation data= \",y_valid.shape)\nprint(\"Shape of test data=\",test_img.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom tensorflow.keras.layers import Dropout\n\nbase_model= InceptionResNetV2(include_top=False, weights='imagenet', \n                              input_tensor=None, input_shape=(img_h,img_w,3), pooling='avg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''for layer in base_model.layers[:-10]:\n    layer.trainable=False'''\nbase_model.trainable=False\n    \nbase_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\n\nmodel=Sequential()\nmodel.add(base_model)\nmodel.add(Flatten())\nmodel.add(Dropout(0.4))\nmodel.add(BatchNormalization())\n\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\n\n#model.add(Dense(256, activation='relu'))\n#model.add(Dropout(0.2))\n#model.add(BatchNormalization())\n\nmodel.add(Dense(8,activation='softmax'))\n\n\nfrom keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n\n\n#NASnet.trainable=False\n\nreduce_learning_rate = ReduceLROnPlateau(monitor='loss',\n                                         factor=0.1,\n                                         patience=2,\n                                         cooldown=2,\n                                         min_lr=0.00001,\n                                         verbose=1)\n\ncallbacks = [reduce_learning_rate]\n    \n\n\nmodel.compile( optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_datagen.flow(x_train, to_categorical(y_train,8), batch_size=32),\n                    epochs=10,\n          callbacks=callbacks,\n          validation_data= valid_datagen.flow(x_valid, to_categorical(y_valid,8), batch_size=32),\n          verbose=1\n             )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model_2 is resnetV2","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications.resnet import ResNet50\nbase_model_2= ResNet50(include_top=False, weights='imagenet',input_shape=(img_h,img_w,3), pooling='max')\n\n'''for layer in base_model_2.layers[:-3]:\n    layer.trainable=False'''\nbase_model_2.trainable=False\n    \nmodel_2=Sequential()\nmodel_2.add(base_model_2)\nmodel_2.add(Flatten())\nmodel_2.add(Dropout(0.4))\nmodel_2.add(BatchNormalization())\n\nmodel_2.add(Dense(768, activation='relu'))\nmodel_2.add(Dropout(0.2))\nmodel_2.add(BatchNormalization())\n\nmodel_2.add(Dense(256, activation='relu'))\nmodel_2.add(Dropout(0.1))\nmodel_2.add(BatchNormalization())\n\n\nmodel_2.add(Dense(8,activation='softmax'))\n\nmodel_2.compile( optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nmodel_2.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_2.fit(train_datagen.flow(x_train, to_categorical(y_train,8), batch_size=32),\n                    epochs=10,\n          callbacks=callbacks,\n          validation_data= valid_datagen.flow(x_valid, to_categorical(y_valid,8), batch_size=32),\n          verbose=1\n             )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model_3 is VGG19","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications.vgg19 import VGG19,preprocess_input\nbase_model_3=VGG19(include_top=False, weights='imagenet',input_shape=(img_h,img_w,3), pooling='max')\n\nfor layer in base_model_3.layers[:-4]:\n    layer.trainable=False\n#base_model_3.trainable=False\n    \nmodel_3=Sequential()\nmodel_3.add(base_model_3)\nmodel_3.add(Flatten())\n\nmodel_3.add(BatchNormalization())\nmodel_3.add(Dropout(0.2))\n\n\nmodel_3.add(Dense(256, activation='relu'))\nmodel_3.add(BatchNormalization())\n\n\nmodel_3.add(Dense(64, activation='relu'))\nmodel_3.add(BatchNormalization())\nmodel_3.add(Dropout(0.2))\n\n\n\nmodel_3.add(Dense(8,activation='softmax'))\n\nmodel_3.compile( optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nmodel_3.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_3.fit(train_datagen.flow(x_train, to_categorical(y_train,8), batch_size=32),\n                    epochs=20,\n          callbacks=callbacks,\n          validation_data= valid_datagen.flow(x_valid, to_categorical(y_valid,8), batch_size=32),\n          verbose=1\n             )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Stacking ensemble","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras import Input\nfrom tensorflow.keras.layers import concatenate\ndef stacking_ensemble(members,input_shape,n_classes):\n  commonInput = Input(shape=input_shape)\n  out=[]\n\n  for model in members:\n    #model._name= model._name+\"test\"+ str(members.index(model)+1)\n    model._name= model.get_layer(index = 0)._name +\"-test\"+ str(members.index(model)+1)\n    out.append(model(commonInput))\n\n  modeltmp = concatenate(out,axis=-1)\n  modeltmp = Dense(32, activation='relu')(modeltmp)\n  modeltmp = Dense(16, activation='relu')(modeltmp)\n  modeltmp = Dense(n_classes, activation='softmax')(modeltmp)\n  stacked_model = Model(commonInput,modeltmp)\n  stacked_model.compile( loss='categorical_crossentropy',optimizer= 'adam', metrics=['accuracy'])\n\n  return stacked_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#members=[model,model_2,model_3]\nmembers=[model,model_2,model_3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stacked_model= stacking_ensemble(members,(img_h,img_w,3),8)\nstacked_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stacked_model.fit(train_datagen.flow(x_train, to_categorical(y_train,8), batch_size=32),\n                    epochs=10,\n          callbacks=callbacks,\n          validation_data= valid_datagen.flow(x_valid, to_categorical(y_valid,8), batch_size=32),\n          verbose=1\n             )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = stacked_model.predict(test_img)\nprint(labels[:4])\nlabel = [np.argmax(i) for i in labels]\nclass_label = [inverse_map[x] for x in label]\nprint(class_label[:3])\nsubmission = pd.DataFrame({ 'Image': test.Image, 'target': class_label })\nsubmission.head(10)\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}