{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nI found this dataset randomly when I was looking for more interesting classification problems. The dataset was already fairly clean, hence why it was not a troublesome to run a simple classifier. Since I have flown all over the world in the past 4 years, I was interested to see if provided variables could be useful in determining the satisfaction levels of the customers, and I found out that almost all of them indeed are useful. Also, after seeing that the problem itself is a binary classification problem and due to its simplicity, I realized that I probably would not need to run several models, therefore I chose to go with Random Forests, since it's my favorite classifier.\n\nI found that the dataset could be skewed in a lot of ways. There is no information on how the dataset was created, but I assume it was just a simple survey sent to the passengers. In a lot of cases, it seems that people answer the surveys without giving it much thought, thus making the numbers heavily skewed.\n\nWhen looking into the dataset more, I found that some variables could have been better. A very simple example is the satisfaction levels themselves. The dataset only provides 2 classification: neutral or dissatisfied and satisfied. I think it would be better if the satisfaction levels were rated, rather than classified or neutral or dissatisfied was split into two. Also, I wish the prices of the tickets were provided in the dataset, since I assume that prices would play a relatively important role in the satisfaction levels.\n\nIn addition, it would be interesting to explore the satisfaction levels of economy class passengers more. I assume that business class or first class passengers regardless of the airline would be satisfied with their flights and that economy class passengers would be more prone to being dissatisfied with their experiences. Determining what makes economy class passengers happier without it being too costly could definitely increase the sales of tickets, since economy class tickets are the most common. \n\nOverall, with Random Forests, I was able to get a 96% accuracy rate, which is not surprising since the dataset was fairly clean and it was a binary classification problem. "},{"metadata":{},"cell_type":"markdown","source":"## Initial Cleaning and Exploration"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import SelectKBest, chi2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I dropped Arrival Delay after comparing it with Departure Delay, they are both essentially the same. I also dropped Gender with the assumption that it is not important in overall satisfaction with the flight."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/airline-passenger-satisfaction/train.csv')\ntest = pd.read_csv('/kaggle/input/airline-passenger-satisfaction/test.csv')\nd = pd.concat([train, test])\nd = d.drop(columns=['Unnamed: 0', 'id', 'Arrival Delay in Minutes', 'Gender'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = d.satisfaction\nydict = {'neutral or dissatisfied':0,\n        'satisfied':1}\ny = y.map(ydict)\n\nd = d.drop(columns='satisfaction')\nX = d\n\nX = pd.get_dummies(X, columns=['Customer Type', 'Type of Travel', 'Class'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I was surprised to see that Flight Distance is significantly more important than all the other variables, especially knowing that the distances in the dataset are mostly domestic flights, and because of that reason alone, actually, I assumed that the distances would not matter as much. After all, if it is all about the destination, I would think that a customer would go with the cheapest ticket.\n\nOnce again, the credit goes to [this article](https://towardsdatascience.com/feature-selection-techniques-in-machine-learning-with-python-f24e7da3f36e)."},{"metadata":{"trusted":true},"cell_type":"code","source":"bestfeatures = SelectKBest(score_func=chi2, k=X.columns.size)\nfit = bestfeatures.fit(X,y)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X.columns)\n#concat two dataframes for better visualization \nfeatureScores = pd.concat([dfcolumns,dfscores],axis=1)\nfeatureScores.columns = ['Feature','Score'] \nprint(featureScores.nlargest(X.columns.size,'Score')) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\nprint('Train', X_train.shape, y_train.shape)\nprint('Test', X_test.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestClassifier()\nmodel.fit(X_train, y_train)\npred = model.predict(X_test)\nprint('Accuracy: ', accuracy_score(y_test, pred))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}