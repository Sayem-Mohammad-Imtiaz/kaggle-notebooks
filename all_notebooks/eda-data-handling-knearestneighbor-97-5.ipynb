{"cells":[{"metadata":{"_uuid":"7c268c289bd0fe0194e7282a163f3b39b2abb668"},"cell_type":"markdown","source":"# Hello and welcome to my notebook\n## you will find:\n        * EDA\n        * Visual EDA\n        * K-Nearest-Neighbors approach to the data\n        * Comparison and Conclusion"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# importing common libraries...\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"## EDA"},{"metadata":{"trusted":true,"_uuid":"5c6c663dbcbfa0ad7d8bb0245821c9a19c561e46"},"cell_type":"code","source":"data_train = pd.read_csv(\"../input/train.csv\")  # loading the data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"823482636c43b390bdcc2fc85511f8e728438aca"},"cell_type":"code","source":"data_train.info()  # checking for data types","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"25ac3d7b7cdd997c7755a3c6022fdd4977719f9b"},"cell_type":"code","source":"print(list(data_train.any().isnull()))   # there is no null value in our columns, which is great","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"d7fc12f8ea4d0541e15f60f8b9cbb03bc594a862"},"cell_type":"code","source":"data_train.describe()   # I see that in most of the cases values are distributed between -1.00 and 1.00  ...","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9df626e14b6d161ffb66e3fd344f91ef664bb76b"},"cell_type":"code","source":"data_train.head(20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"465faeeb919c0f333f3b4893d2fa33a73c1840b0"},"cell_type":"markdown","source":"\n# In Overview of this dataset, I realize that column \"rn\" is pretty much an id number of activity. But this is ruining the dataset !!! because labels grouped in order of \"rn\" column and this would effect our models very dramatically. (Which is basically cheating)\n\nTo be fair, I would rather making a model for real life scenarios without correlated ID numbers.  So, I will drop that \"rn\" column."},{"metadata":{"trusted":true,"_uuid":"feb3b1344e478d89ed946d07d0588f6aed757d47"},"cell_type":"code","source":"data_train.drop([\"rn\"],axis=1,inplace=True)    ## removing the rn column.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49bbcdcb739d03cc9726a9ee8790f440b051edc1"},"cell_type":"code","source":"data_train.head(10)  ## As seen, problem solved!! :)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bddf60191d1974aae1982d2aa39655b4ef6be645"},"cell_type":"markdown","source":"## Visual EDA"},{"metadata":{"trusted":true,"_uuid":"6cff8bd46ce3b695abb4674e415b3cc470807180"},"cell_type":"code","source":"# importing data visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01c9359362f2cd0528867117548cdb41f5f9b290"},"cell_type":"code","source":"plt.figure(figsize=(30,20))\nsns.heatmap(data=(data_train.corr()*data_train.corr()),cmap=\"BuPu\",vmin=0.4)\nplt.show()\n\n# what I do here is: only showing correlation x on => ((x^2)>0.4).  By this we only see highly correlated columns. and seems like there are many of them.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"27e96b69d0efb3907d608779460b86320b4a68b3"},"cell_type":"markdown","source":"As we see above, our data has too many columns and they are sensor results. So they are not practically the best data to viusalize."},{"metadata":{"_uuid":"4d3ec6b9e0ba213bd4617f3434d03fca70ee9cc6"},"cell_type":"markdown","source":"### PreProcessing the data"},{"metadata":{"trusted":true,"_uuid":"96279a485579d11984eb9c81d2a6b8d717072ea9"},"cell_type":"code","source":"# Let's see our labels.\nlabels = list(data_train.activity.unique())\nprint(labels) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4887431a390598246b2a4131a693e8a412c13bf4"},"cell_type":"code","source":"# they are strings, we should make them numerical values.  for this i will use scikit-learn\n\n# importing and setting\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n# fitting each possible label\nle.fit(labels)\n# updating our data with LabelEncoder\ndata_train.activity = le.transform(data_train.activity)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f53bd2f08125ff7573f155aaa7dca8e4bddd711d"},"cell_type":"code","source":"y_train = data_train.activity.values.reshape(-1,1)  # scikit doesn't likes when it is like (n,). it rathers (n,m).. that's why I used reshape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b18a22ab687a7bd5c13cf0b1b123033acf2d3e16"},"cell_type":"code","source":"x_train = data_train.values ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc3d655e40dc547c3092e4cc4fe71120abf4aae3"},"cell_type":"markdown","source":"## K Nearest Neighbors approach"},{"metadata":{"trusted":true,"_uuid":"acc00a49cb0b13a81d22033c22ebd210d60177b2","collapsed":true},"cell_type":"markdown","source":"### Before training my completed model, I want to check it's accuracy\nfor this I will use train_test_split on my training data and then I will be able to compare"},{"metadata":{"trusted":true,"_uuid":"2953c4386508c70383c49fe6e21f8286873a89d4"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split \nx_tr,x_tst,y_tr,y_tst = train_test_split(x_train,y_train,test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d1d802ac0420fc3812081b92aa2acce4e3866739"},"cell_type":"markdown","source":"now I can create my initial model to estimate my final accuracy."},{"metadata":{"trusted":true,"_uuid":"e99fa73663db072f1ad5cc00084501d0dea7004c"},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn_model = KNeighborsClassifier(n_neighbors=1,algorithm=\"auto\")\n\nknn_model.fit(x_tr,y_tr.ravel())\n\ny_head = knn_model.predict(x_tst)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"972b8132e509fe33ce54e4faba2f4f8fe38d8381"},"cell_type":"code","source":"knn_model.score(x_tst,y_tst)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ebc7fe555afe5c3b241f002386b1eeb5c5158a4b"},"cell_type":"markdown","source":"## As you can see above, model reached 97.6% of success.\nwhich is acceptable for me but we should tune and see the best amount of n_neighbors for our data"},{"metadata":{"_uuid":"9941a95a3fc2af4a3c5ca8cf32b23a6a2053a11e"},"cell_type":"markdown","source":"# Comparison\nfo this my range will be 1 to 10 neighbors."},{"metadata":{"trusted":true,"_uuid":"11a200443363cbba6932ae568ee58edd3bb0a0f5","_kg_hide-output":false},"cell_type":"code","source":"n = range(1,30)\nresults = []\nfor i in n:\n    #print(i)\n    knn_tester = KNeighborsClassifier(n_neighbors=i)\n    knn_tester.fit(x_tr,y_tr.ravel())\n    results.append(knn_tester.score(x_tst,y_tst))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a767018f4fb4f98b55f63225cfdf397890b4ce36"},"cell_type":"code","source":"plt.clf()\n\nplt.suptitle(\"SCORES\",fontsize=18)\n\nplt.figure(figsize=(20,10))\nplt.plot(n,results,c=\"red\",linewidth=4)\nplt.xlabel(\"n neighbors\")\nplt.ylabel(\"score\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe5828153ce11f3453a4795b91fde0f428d2dd86"},"cell_type":"markdown","source":"## Conclusion\n\nTo sum up, I see that in some datasets, it is not very good to increase the amount of n_neighbors"},{"metadata":{"_uuid":"8ee7c8fdff9ded2406412ef364995f007f90610a"},"cell_type":"markdown","source":"### Here is the Confusion Matrix"},{"metadata":{"trusted":true,"_uuid":"10ce5f8b04f1cc220953fd5fb7e51daffaa5e7a1"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5941e20ee6fe6ac3151d2acd43885e2aab7ef25c"},"cell_type":"code","source":"conf = confusion_matrix(y_pred=y_head,y_true=y_tst)\nconf = conf.astype('float') / conf.sum(axis=1)[:, np.newaxis]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be490a66403753c75add6f9b28587077843e6ce3"},"cell_type":"code","source":"plt.figure(figsize=(20,20))\nsns.heatmap(conf,annot=True,cmap=\"summer\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f73cba08c15fcfeeb70526213463de3d543b043"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"913bba4dcd8feb943dae352dc9c65a4091fab245"},"cell_type":"code","source":"## I am currently improving my skills on data science. If you have any advice or comment, make sure you show it.  Best Regards.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"766456c8de8b7c8a2ee2933c29dcbb6b6cf00724"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56fb947f5c2fa63e588517b51d7f7ea551f85356"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}