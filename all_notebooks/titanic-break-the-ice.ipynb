{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##                          **This is my first Kaggle Notebook.**\n**This notebook explores the basic use of Pandas for data analysis and cleaning and scikit-learn for using ML algorithms for this Classifcation problem.**","metadata":{}},{"cell_type":"markdown","source":"**What will you find in this notebook:**\n1. Exploratory Data Analysis on Titanic Dataset.\n    * Understanding the Data\n2. Data Preprocessing.\n    * Handling missing values\n    * Converting categorical features to numerical\n    * Splitting Data to train and test data for ML algorithm\n3. Scikit-learn basic ML algorithms.\n    * implement different Classifiers from the sklearn library like Logistic regression, Gaussian naive Bayes, KNN, Decision tree, Random forest, SVM\n4. Comparison of Model performances.\n    * using performance metrics like confusion_matrix, accuracy_score. ","metadata":{}},{"cell_type":"markdown","source":"References:\n\n* Udemy: Machine Learning A to Z: Hands-on Python & R, Team Data Science\n* Krish Naik: Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"#### If you find this useful in helping you learn some new things, please upvote and let's begin...","metadata":{}},{"cell_type":"markdown","source":"#### Importing Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set()\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Loading the Dataset.","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv('../input/titanic/train.csv',na_values={'Cabin':0},index_col='PassengerId')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Let us begin with Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **There are 891 entries**\n* **Columns like Age,Cabin has missing values**\n* **Columns like Name, Sex, Cabin, etc has Categorical Data** ","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Out of the two labels(survived, or Died) . Let us check how many survived, how many died according to our Data?**","metadata":{}},{"cell_type":"code","source":"sns.countplot(x='Survived', data=df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Is the inference true that Females had Higher Survival Rate in this Incident??\n   Let us see, If yes? Can you come up with a reason justifying this??**","metadata":{}},{"cell_type":"code","source":"df.groupby(['Survived','Sex'])['Survived'].count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(x='Sex', col='Survived', kind='count', data=df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The reason might be that at the time of disaster, people give preferences to save Women and Children first**","metadata":{}},{"cell_type":"markdown","source":"**Can you come up with a guess of Survival rate with respect to Passenger Class???\n  Let's just see it.**","metadata":{}},{"cell_type":"code","source":"pd.crosstab(df['Pclass'], df['Survived'], margins=True).style.background_gradient(cmap='autumn_r')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"% of survivals in\") \nprint(\"Pclass=1 : \", df['Survived'][df['Pclass'] == 1].sum()/df[df['Pclass'] == 1]['Survived'].count())\nprint(\"Pclass=2 : \", df['Survived'][df['Pclass'] == 2].sum()/df[df['Pclass'] == 2]['Survived'].count())\nprint(\"Pclass=3 : \", df['Survived'][df['Pclass'] == 3].sum()/df[df['Pclass'] == 3]['Survived'].count())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**You got the guess right. The Survival Rate of those people is higher who had tickets of Higher class(i.e. class 1 > class 2, etc.), the reason is again understandable. Maybe the people having tickets of higher class were rich and able to make an escape first by offering money to rescuers.**","metadata":{}},{"cell_type":"code","source":"pd.crosstab([df['Sex'], df['Survived']], df['Pclass'], margins=True).style.background_gradient(cmap='autumn_r')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Data Cleaning","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/titanic/train.csv',na_values={'Cabin':0})\ndf_test = pd.read_csv('../input/titanic/test.csv',na_values={'Cabin':0})\ndf_apply = df.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_apply_x = pd.get_dummies(df_apply, columns=['Sex', 'Embarked', 'Pclass'], drop_first=True)\ndf_apply_x = df_apply_x.drop(['PassengerId','Name','Ticket','Cabin'],axis=1)\ndf_apply_y = df_apply['Survived']\n\ndf_test = pd.get_dummies(df_test, columns=['Sex', 'Embarked', 'Pclass'], drop_first=True)\nsubmission = pd.DataFrame()\nsubmission['PassengerId'] = df_test['PassengerId']\ndf_test = df_test.drop(['PassengerId','Name','Ticket','Cabin'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_apply_x.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_apply_y.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Replacing the NaN values in Age column by median of this column and NaN values in cabin by 0.**","metadata":{}},{"cell_type":"code","source":"median=df_apply_x['Age'].median()\ndf_apply_x['Age'].fillna(median,inplace=True)\n#df_apply_x['Cabin'][df_apply_x['Cabin']!=1]=0\ndf_apply_x.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"median_test=df_test['Age'].median()\ndf_test['Age'].fillna(median,inplace=True)\n#df_apply_x['Cabin'][df_apply_x['Cabin']!=1]=0\ndf_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_apply_x.dropna(inplace=True)\ndf_apply_x.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_apply_x.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Correlation Matrix**","metadata":{}},{"cell_type":"code","source":"corr = df_apply_x.corr()\n\nf,ax = plt.subplots(figsize=(9,6))\nsns.heatmap(corr, annot = True, linewidths=1.5 , fmt = '.2f',ax=ax)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Survived and Fare are positively correlated, Survived and Sex_male negatively correlated.\nAlso, Survived and Pclass_3 negatively correlated.\nIf you need to Brush up about what Correlation and Covariance are, just go to StatQuest Youtube Channel, that Guy is just Awesome. BAM!!!**","metadata":{}},{"cell_type":"markdown","source":"**Converting data frames into arrays, since our sklearn library ML models takes input in the form of arrays**","metadata":{}},{"cell_type":"code","source":"df_apply_x.fillna(df_apply_x.mean(), inplace=True)\ndf_apply_x = df_apply_x.drop(['Survived'],axis=1)\nX=df_apply_x.values\nY=df_apply_y.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Removed Label column from X.","metadata":{}},{"cell_type":"markdown","source":"Splitting the data into test and training set","metadata":{}},{"cell_type":"code","source":"#from sklearn.model_selection import train_test_split\n#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 1)\nX_train = X\nY_train = Y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(X_train)\nprint(len(X_train))\n#print(X_test)\n#print(len(X_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for df_test_ml\ndf_test.fillna(df_test.mean(), inplace=True)\n# scaler.fit(df_test_ml)\nscaled_features = sc.transform(df_test)\nX_test = pd.DataFrame(scaled_features, columns=df_test.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Scikit-learn basic ML algorithms**\n* KNN\n* Logistic Regression\n* Naive Bayes\n* SVM\n* Descicon Tree\n* Random Forest","metadata":{}},{"cell_type":"markdown","source":"**Training KNN  model**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier_KNN = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nclassifier_KNN.fit(X_train, Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_KNN = classifier_KNN.predict(X_test)\n#print(confusion_matrix(Y_test, Y_pred_KNN))\n#print(classification_report(Y_test, Y_pred_KNN))\n#print(\"Accuracy: \",accuracy_score(Y_test, Y_pred_KNN)*100, \"%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Training Logistic Regression Model**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclassifier_LR = LogisticRegression()\nclassifier_LR.fit(X_train,Y_train)\nY_pred_LR = classifier_LR.predict(X_test)\nprint(confusion_matrix(Y_test, Y_pred_LR))\nprint(classification_report(Y_test, Y_pred_LR))\nprint(\"Accuracy: \",accuracy_score(Y_test, Y_pred_LR)*100 ,\"%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Gaussian Naive Bayes**","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nclassifier_GNB = GaussianNB()\nclassifier_GNB.fit(X_train,Y_train)\nY_pred_GNB = classifier_GNB.predict(X_test)\nprint(confusion_matrix(Y_test,Y_pred_GNB ))\nprint(classification_report(Y_test, Y_pred_GNB))\nprint(\"Accuracy: \",accuracy_score(Y_test, Y_pred_GNB)*100,\" %\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Descision Tree**","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nclassifier_DT= DecisionTreeClassifier()\nclassifier_DT.fit(X_train,Y_train)\nY_pred_DT = classifier_DT.predict(X_test)\nprint(classification_report(Y_test,Y_pred_DT))\nprint(accuracy_score(Y_test, Y_pred_DT))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Random forest**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclassifier_RF = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nclassifier_RF.fit(X_train, Y_train)\nY_pred_RF = classifier_RF.predict(X_test)\nprint(classification_report(Y_test,Y_pred_RF))\nprint(\"Accuracy: \",accuracy_score(Y_test, Y_pred_RF)*100, \" %\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SVM**","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nclassifier_SVC = SVC(gamma = 0.01, C = 100)#, probability=True)\nclassifier_SVC.fit(X_train, Y_train)\nY_pred_SVC = classifier_SVC.predict(X_test)\n#print(classification_report(Y_test,Y_pred_SVC))\n#print(\"Accuracy: \",accuracy_score(Y_test, Y_pred_SVC)*100, \" %\")\nsubmission['Survived'] = Y_pred_SVC\nsubmission.to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Thank You!!!**","metadata":{}}]}