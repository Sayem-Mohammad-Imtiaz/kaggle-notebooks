{"nbformat_minor":1,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"nbconvert_exporter":"python","codemirror_mode":{"version":3,"name":"ipython"},"version":"3.6.4","pygments_lexer":"ipython3","file_extension":".py","mimetype":"text/x-python","name":"python"}},"cells":[{"metadata":{},"cell_type":"markdown","source":"### Import Libraries"},{"execution_count":null,"outputs":[],"source":"# import libraries and set max column width as 100 to display \nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly\nimport getpass \nimport pandas as pd\nimport os\n\nplotly.tools.set_credentials_file(username='jonamjar', api_key=getpass.getpass())\npd.set_option(\"display.max_colwidth\", 40)\npd.set_option(\"display.max_columns\", 100)\npd.set_option(\"display.max_rows\", 100)","cell_type":"code","metadata":{}},{"metadata":{},"cell_type":"markdown","source":"### Get Data"},{"execution_count":null,"outputs":[],"source":"# Importing Data and display fill \n\ndata_h1 = pd.read_csv(\"../input/H-1B_Disclosure_Data_FY17.csv\", low_memory=False, index_col=0)\nprint(\"%s MB\" %(os.path.getsize('../input/H-1B_Disclosure_Data_FY17.csv') / 1000000))","cell_type":"code","metadata":{}},{"metadata":{},"cell_type":"markdown","source":"### Data Exploration"},{"execution_count":null,"outputs":[],"source":"# display all column Names\n\nprint(\"Number of features: %d\\n\" %len(data_h1.columns))\nprint(\"##### All features ######\")\nfor col in data_h1.columns:\n    print(col)","cell_type":"code","metadata":{"scrolled":false}},{"execution_count":null,"outputs":[],"source":"# Proportions of all available Visa types in the data set \n\ndata_h1.VISA_CLASS.value_counts(normalize = True) * 100","cell_type":"code","metadata":{}},{"execution_count":null,"outputs":[],"source":"# Getting rid of non h1b visa and checking top 10 states based on h1b visa counts\n\ndata_h1 = data_h1[data_h1[\"VISA_CLASS\"] == \"H-1B\"]\npd.DataFrame(data_h1.EMPLOYER_STATE.value_counts(normalize = True)).head(10) * 100 ","cell_type":"code","metadata":{"scrolled":false}},{"execution_count":null,"outputs":[],"source":"# Most popular job in a state\n\nmost_popular_job_title = data_h1[[\"EMPLOYER_STATE\",\"JOB_TITLE\"]]\nmost_popular_job_title = most_popular_job_title.groupby([\"EMPLOYER_STATE\",\"JOB_TITLE\"]).size().reset_index()\nmost_popular_job_title.columns = ['EMPLOYER_STATE', 'JOB_TITLE', \"COUNT\"]\ntest = most_popular_job_title.groupby(['EMPLOYER_STATE', 'JOB_TITLE']).agg({'COUNT':sum})\ntest = test['COUNT'].groupby(level=0, group_keys=False)\nres = test.apply(lambda x: x.sort_values(ascending=False).head(1))\nres = pd.DataFrame(res).reset_index()\n\ntot = pd.DataFrame(data_h1[\"EMPLOYER_STATE\"].value_counts()).reset_index()\ntot.columns = [\"EMPLOYER_STATE\",\"TOTAL\"]\nres = pd.merge(res, tot, on = \"EMPLOYER_STATE\", how = \"left\")\nres[\"PERCENTAGE\"] = res[\"COUNT\"] * 100 /res[\"TOTAL\"]","cell_type":"code","metadata":{"scrolled":true,"collapsed":true}},{"execution_count":null,"outputs":[],"source":"res.head()","cell_type":"code","metadata":{"scrolled":true}},{"execution_count":null,"outputs":[],"source":"# Companies in a particular state Sponsoring\n\ndef H1Bcompanies_in_state(state_two_letter, top = None):\n    companies_in_ut = data_h1[data_h1[\"EMPLOYER_STATE\"] == state_two_letter][[\"EMPLOYER_STATE\",\"EMPLOYER_NAME\"]][\"EMPLOYER_NAME\"].value_counts()\n#     for c, n in zip(companies_in_ut.index, companies_in_ut):\n#         print(c, n)\n    if top == None:result = companies_in_ut \n    else:result = companies_in_ut.head(top)\n    return result","cell_type":"code","metadata":{"scrolled":true,"collapsed":true}},{"execution_count":null,"outputs":[],"source":"# Top 10 coompanies in Utah Sponsoring H1-B\n\nH1Bcompanies_in_state(\"UT\", top = 10)","cell_type":"code","metadata":{"scrolled":true}},{"execution_count":null,"outputs":[],"source":"# Top 10 companies in Georgia Sponsoring H1-B\n\nH1Bcompanies_in_state(\"GA\",top = 10)","cell_type":"code","metadata":{"scrolled":true}},{"execution_count":null,"outputs":[],"source":"# Top 10 companies in a state Sponsoring H1-B\n\nH1Bcompanies_in_state(\"CA\",top = 10)","cell_type":"code","metadata":{}},{"execution_count":null,"outputs":[],"source":"# Levels share\n\ndata_h1[\"PW_WAGE_LEVEL\"].value_counts(normalize = True) * 100","cell_type":"code","metadata":{}},{"execution_count":null,"outputs":[],"source":"# Top 10 H1B job titles in USA\n\ntitle = pd.DataFrame(data_h1.JOB_TITLE.value_counts()).reset_index()\ntitle[\"Percentage\"] = pd.DataFrame(data_h1.JOB_TITLE.value_counts\n                                   (normalize = True) * 100).reset_index()[\"JOB_TITLE\"]\ntitle.columns = [\"title\",\"count\",\"perc\"]\ntitle.head(10)","cell_type":"code","metadata":{"scrolled":true}},{"execution_count":null,"outputs":[],"source":"# Where does Data Science and related title Stand here?\n\nds_title = title[title[\"title\"].str.contains(\"|\".join([\"DATA SCIE\",\"MACHINE LEAR\"]))]\nprint(\"Percentage & Count of Data Science and Related Titles : %f, %d\"\n      %(ds_title[\"perc\"].sum(), ds_title[\"count\"].count()))","cell_type":"code","metadata":{}},{"execution_count":null,"outputs":[],"source":"# Checking available \"PW_UNIT_OF_PAY\"\n\npd.DataFrame(data_h1[\"PW_UNIT_OF_PAY\"].value_counts(normalize = True))","cell_type":"code","metadata":{"scrolled":true}},{"execution_count":null,"outputs":[],"source":"# Creating \"ACTUAL_SALARY\" variable to normalize all the salaries  \n\n# unitpay_to_num = {\"Year\":1, \"Hour\": 2080, \"Month\": 12, \"Bi-Weekly\": 24}\n# data_h1[\"MULTIPLIER\"] = data_h1[\"PW_UNIT_OF_PAY\"].map(unitpay_to_num)\n# data_h1[\"ACTUAL_SALARY\"] = data_h1[\"WAGE_RATE_OF_PAY_FROM\"] * data_h1[\"MULTIPLIER\"]\n\n# retaining only yearly pays\ndata_h1 = data_h1[data_h1[\"PW_UNIT_OF_PAY\"] == \"Year\"]","cell_type":"code","metadata":{"scrolled":true,"collapsed":true}},{"execution_count":null,"outputs":[],"source":"# What are associate data scientist are being paid in US?\n\nass_ds = data_h1[data_h1[\"JOB_TITLE\"] == \"ASSOCIATE DATA SCIENTIST\"][[\"WAGE_RATE_OF_PAY_FROM\",\"PW_UNIT_OF_PAY\",\"EMPLOYER_NAME\",\"EMPLOYER_CITY\",\"EMPLOYER_STATE\"]]\nass_ds = ass_ds.reset_index(drop = True)","cell_type":"code","metadata":{"scrolled":true,"collapsed":true}},{"execution_count":null,"outputs":[],"source":"# Visualization of Associate Data Scientist \n\nviz = ass_ds.sort_values(by = \"WAGE_RATE_OF_PAY_FROM\", ascending= False)","cell_type":"code","metadata":{"scrolled":true,"collapsed":true}},{"execution_count":null,"outputs":[],"source":"#viz = viz.drop(\"text\", axis = 1)\n\nviz[\"WAGE_RATE_OF_PAY_FROM\"] = viz[\"WAGE_RATE_OF_PAY_FROM\"].astype(float)\nfinal_viz = pd.DataFrame(viz.groupby(['EMPLOYER_STATE'])['WAGE_RATE_OF_PAY_FROM'].mean()).reset_index()","cell_type":"code","metadata":{"scrolled":true,"collapsed":true}},{"execution_count":null,"outputs":[],"source":"# fill missing job titles with \"not available\"\n\ndata_h1[\"JOB_TITLE\"] = data_h1[\"JOB_TITLE\"].fillna(\"not available\")","cell_type":"code","metadata":{"collapsed":true}},{"metadata":{},"cell_type":"markdown","source":"### Only Data Science related jobs"},{"execution_count":null,"outputs":[],"source":"#function to get data for visualization\n\ndef dataviz_job_salary_dist(data, job_title_list, salary_column):\n    df_list = [data_h1[data_h1[\"JOB_TITLE\"].str.contains(jt)] for jt in job_title_list]\n    result_df = pd.concat(df_list, axis = 1)\n    return ( result_df, pd.DataFrame(result_df.groupby(['EMPLOYER_STATE'])[salary_column].mean()).reset_index())","cell_type":"code","metadata":{"collapsed":true}},{"execution_count":null,"outputs":[],"source":"#getting data for map visualization\n\nresult_df, all_final_viz = dataviz_job_salary_dist(data_h1[data_h1[\"NEW_EMPLOYMENT\"] == 1], [\"DATA SCIENTIST\"],\"WAGE_RATE_OF_PAY_FROM\")","cell_type":"code","metadata":{"collapsed":true}},{"metadata":{},"cell_type":"markdown","source":"#### PLOTLY"},{"execution_count":null,"outputs":[],"source":"df = all_final_viz\nfor col in df.columns:\n    df[col] = df[col].astype(str)\n\nscl = [[0.0, 'rgb(242,240,247)'],[0.2, 'rgb(218,218,235)'],[0.4, 'rgb(188,189,220)'],\\\n            [0.6, 'rgb(158,154,200)'],[0.8, 'rgb(117,107,177)'],[1.0, 'rgb(84,39,143)']]\n\ndf['text'] = df['EMPLOYER_STATE'] + '<br>' +'Salary '+ df['WAGE_RATE_OF_PAY_FROM']\n\ndata = [ dict(\n        type='choropleth',\n        colorscale = scl,\n        autocolorscale = False,\n        locations = df['EMPLOYER_STATE'],\n        z = df['WAGE_RATE_OF_PAY_FROM'].astype(float),\n        locationmode = 'USA-states',\n        text = df['text'],\n        marker = dict(\n            line = dict (\n                color = 'rgb(255,255,255)',\n                width = 2\n            ) ),\n        colorbar = dict(\n            title = \"Millions USD\")\n        ) ]\n\nlayout = dict(\n        title = 'H1 B Heat Map',\n        geo = dict(\n            scope='usa',\n            projection=dict( type='albers usa' ),\n            showlakes = True,\n            lakecolor = 'rgb(255, 255, 255)'),\n             )\n    \nfig = dict( data=data, layout=layout )\npy.iplot( fig, filename='d3-cloropleth-map' )","cell_type":"code","metadata":{}},{"execution_count":null,"outputs":[],"source":"# One person details\n\ndef lca_single_indv(dataset, employer_name_like, title_like):\n    test = data_h1[data_h1[\"EMPLOYER_NAME\"].str.contains(employer_name_like)]\n    return test[test[\"JOB_TITLE\"] ==title_like].T","cell_type":"code","metadata":{"scrolled":true,"collapsed":true}},{"execution_count":null,"outputs":[],"source":"# Status of Application of Change of Employment\n\ndata_h1[data_h1[\"CHANGE_PREVIOUS_EMPLOYMENT\"] != 0][\"CASE_STATUS\"].value_counts(normalize = True) * 100","cell_type":"code","metadata":{"scrolled":true}},{"execution_count":null,"outputs":[],"source":"# Average Salary of a company\n\ndef avg_salary_company(employer_name, column):\n     return data_h1[(data_h1[\"EMPLOYER_NAME\"] == employer_name)][column].mean()\n    \navg_salary_company(\"OVERSTOCK.COM, INC.\",\"WAGE_RATE_OF_PAY_FROM\")","cell_type":"code","metadata":{}}],"nbformat":4}