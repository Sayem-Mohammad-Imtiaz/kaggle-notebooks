{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras.utils.vis_utils import plot_model\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn import tree\nfrom sklearn.metrics import confusion_matrix\nfrom matplotlib import pyplot as pyplot\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.metrics import plot_confusion_matrix\nfrom warnings import simplefilter\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import time\nstart = time.time()\n\n#import two dataset splitted\ndftrain = pd.read_csv(\"../input/mqttset/Data/FINAL_CSV/train70_reduced.csv\") \ndftest = pd.read_csv(\"../input/mqttset/Data/FINAL_CSV/test30_reduced.csv\")\nsimplefilter(action='ignore', category=FutureWarning)\nseed = 7\n\n#train\n#print(dftrain.loc[dftrain['target'] == 'legitimate'])\nclass_names = dftrain.target.unique()\ndftrain=dftrain.astype('category')\ncat_columns = dftrain.select_dtypes(['category']).columns\ndftrain[cat_columns] = dftrain[cat_columns].apply(lambda x: x.cat.codes)\n#print(dftrain.loc[125, 'target'])\nx_columns = dftrain.columns.drop('target')\nx_train = dftrain[x_columns].values\ny_train = dftrain['target']\n\n#test\nclass_names = dftest.target.unique()\ndftest=dftest.astype('category')\ncat_columns = dftest.select_dtypes(['category']).columns\ndftest[cat_columns] = dftest[cat_columns].apply(lambda x: x.cat.codes)\nx_columns = dftest.columns.drop('target')\nx_test = dftest[x_columns].values\ny_test = dftest['target']\n\n\nprint(\"Ready to generate train and test datasets\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Neural network\nprint(\"Starting Random forest\")\nmodel = Sequential()\nmodel.add(Dense(50, input_dim=x_train.shape[1], kernel_initializer='normal', activation='relu'))\nmodel.add(Dense(30, input_dim=x_train.shape[1], kernel_initializer='normal', activation='relu'))\nmodel.add(Dense(20, kernel_initializer='normal'))\nmodel.add(Dense(6,activation='softmax'))\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmonitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\nhistory = model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=2,epochs=200,batch_size=1000) \nend = time.time()\ndiff=end-start\nprint(\"Training time: \" + str(diff))\nstarttest = time.time()\ny_pred_nn = model.predict(x_test)\ny_pred_nn = np.argmax(y_pred_nn,axis=1)\nendtest =time.time()\ndifftest = endtest-starttest\nprint(\"Test time: \" + str(difftest))\n\nprint(model.summary())\n\n\n#Create Naive Bayes Classifier\nprint(\"Starting Naive Bayes\")\ngnb = GaussianNB()\ngnb.fit(x_train, y_train)\nend = time.time()\ndiff=end-start\nprint(\"Training time: \" + str(diff))\nstarttest = time.time()\ny_pred_nb = gnb.predict(x_test)\nendtest =time.time()\ndifftest = endtest-starttest\nprint(\"Test time: \" + str(difftest))\n\n#Decision tree\nprint(\"Starting Decision tree\")\nclf = DecisionTreeClassifier()\nclf = clf.fit(x_train,y_train)\nend = time.time()\ndiff=end-start\nprint(\"Training time: \" + str(diff))\nstarttest = time.time()\ny_pred_dt = clf.predict(x_test)\ny_pred_dt_roc = clf.predict_proba(x_test)\nendtest =time.time()\ndifftest = endtest-starttest\nprint(\"Test time: \" + str(difftest))\n\n\nprint(\"Decision Tree, accuracy: \" + str(metrics.accuracy_score(y_test, y_pred_dt)) + \" F1 score:\" + str(metrics.f1_score(y_test, y_pred_dt,average='weighted')))\nmatrixdt = confusion_matrix(y_test,y_pred_dt)\nprint(matrixdt)\n\n\nprint(\"Naive Bayes, accuracy: \" + str(metrics.accuracy_score(y_test, y_pred_nb)) + \" F1 score:\" + str(metrics.f1_score(y_test, y_pred_nb,average='weighted')))\nmatrixnv = confusion_matrix(y_test,y_pred_nb)\nprint(matrixnv)\n\n\nprint(\"Neural network, accuracy: \" + str(metrics.accuracy_score(y_test, y_pred_nn)) + \" F1 score:\" + str(metrics.f1_score(y_test, y_pred_nn,average='weighted')))\nmatrixnn = confusion_matrix(y_test,y_pred_nn)\nprint(matrixnn)\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}