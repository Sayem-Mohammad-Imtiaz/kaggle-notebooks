{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom sklearn.model_selection import train_test_split\nimport scikitplot as skplt\nimport time\nimport torch.nn.functional as F ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/mnist-in-csv/mnist_train.csv')\ntest = pd.read_csv('/kaggle/input/mnist-in-csv/mnist_test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's create a barchart to check the number of digits in each class:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"label_counts  = train[\"label\"].value_counts().sort_index()\nlabel_counts.plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Now splitting labels and features in the dataset.-->","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_fe=train.iloc[:,1:]  # neglecting the label column\ntrain_lab=train['label']  # taking the labels column\n\n# converting to numpy 1d array\n\ntrain_fe_numpy = train_fe.to_numpy()\ntrain_lab_numpy = train_lab.to_numpy()\ntest_numpy = test.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_fe_numpy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_fe_numpy.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_numpy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualising some training examples with it's labels:--> ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_img(data, label):\n    fig, axs = plt.subplots(2,2)\n    k = 0\n    for i in range(2):\n        for j in range(2):        \n            axs[i, j].imshow(data[k].reshape(28, 28))            \n            axs[i, j].set_ylabel(\"label:\" + str(label[k].item()))   \n            k +=4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_img(train_fe_numpy, train_lab_numpy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting the Dataset-->","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train,test,train_label,test_label=train_test_split(train_fe_numpy,train_lab_numpy, test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(train_label.shape)\nprint(test.shape)\nprint(test_label.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check if both datasets represent all classes in fair proportion:-->","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"unique, counts_train = np.unique(train_label, return_counts=True)\nplt.subplot(1, 2, 1)\nplt.bar(unique, counts_train/len(train_label))\nunique, counts_val = np.unique(test_label, return_counts=True)\nplt.subplot(1, 2, 2)\nplt.bar(unique, counts_val/len(test_label))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# So we saw that the class balance is fair so we can go ahead..","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# To use pytorch we must convert the input vectors to tensors from numpy..","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_all_tensor = torch.as_tensor(train_fe_numpy).type(torch.FloatTensor)\n# train_all_label_tensor = torch.as_tensor(train_lab_numpy)\n# test_tensor = torch.as_tensor(test_numpy).type(torch.FloatTensor)\n\ntrain_tensor = torch.as_tensor(train).type(torch.FloatTensor)\ntrain_label = torch.as_tensor(train_label)\n\ntest_tensor = torch.as_tensor(test).type(torch.FloatTensor)\ntest_label = torch.as_tensor(test_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_img(train_tensor,train_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_tensor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_tensor","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Neural Network Architecture:-->","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class FNet(nn.Module):\n    def __init__(self):\n         super(FNet, self).__init__()  \n         \n         self.l1=nn.Linear(in_features=784, out_features=600)   # 784 inputs, connects to hidden layer with 600 nodes\n         \n#          self.relu = nn.ReLU()\n            \n         self.l2=nn.Linear(in_features=600, out_features=500)   #  600 nodes connects to hidden layer with 500 nodes\n         \n#          self.relu = nn.ReLU()   \n        \n         self.l3 = nn.Linear(in_features=500, out_features=250)  # 500 nodes connects to hidden layer with 250 nodes\n            \n#          self.relu = nn.ReLU()\n        \n         self.l4 = nn.Linear(in_features=250, out_features=10)   # 250 nodes connects to hidden layer and output layer of 10 nodes\n        \n    def forward(self, x):\n        x = x.view(-1,784)   # Putting all the entries of the image in the vector     \n        x = F.relu(self.l1(x))     # Input x into first layer and apply a ReLU\n                                    # to the nodes in this layer\n        x = F.relu(self.l2(x))        \n        x = F.relu(self.l3(x))\n        x = self.l4(x)\n        return x               ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training Process:-->","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# We have to do four processes here:-->\n- Do a forward pass\n- Calculate loss function\n- Calculate the gradients\n- Change the weights based on gradients","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def training(loader,model,epochs,criteria,optimizer):\n    \n    tr_accuracy,tr_loss= [], []\n    \n    model.train()\n    \n    for epoch in range(epochs):\n        \n        train_loss = 0 \n        train_accuracy = 0\n        total_batch = 0\n        \n        t0=time.time()\n        for data,labels in loader:\n             # zero the parameters gradient to not accumulate gradients from previous iteration\n            optimizer.zero_grad()\n            \n            # put data into the model\n            predictions = net(data)\n            \n            # calculating loss\n            loss = criterion(predictions, labels)\n            \n            # calculating accuracy\n            accuracy = get_accuracy(predictions, labels)\n            \n            # computing gradients\n            loss.backward()\n            \n            # changing the weights\n            optimizer.step()\n            \n            total_batch+=1\n            train_loss += loss.item()\n            train_accuracy += accuracy\n            \n        tfin= time.time()-t0   \n        acc=train_accuracy/total_batch  \n        loss=train_loss/total_batch\n        tr_accuracy.append(acc)\n        tr_loss.append(loss)\n        \n        print(\"Epoch {}/{}\".format(epoch+1,epochs),\"Training Loss: {}\".format(loss),\"Training Accuracy: {}\".format(acc),\"Time: {} seconds\".format(tfin))\n        \n    return tr_accuracy, tr_loss   \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 128                                     \ntrain_dataset = torch.utils.data.TensorDataset(train_tensor, train_label)\ntrainloader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n\nepochs = 60                                              # setting number of epochs\n\nnet = FNet()                                              # initializing the  network\ncriterion = nn.CrossEntropyLoss()                         # setting criterion\noptimizer = torch.optim.SGD(net.parameters(), lr = 3e-4) # setting optimizer\n\ntr_acc, tr_loss = training(trainloader, net,epochs, criterion, optimizer)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plot:-->","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def curves(epochs,loss,acc):\n    \n    iters=range(1,epochs+1)\n    fig,(ax1,ax2)=plt.subplots(ncols=2,figsize=(15,5))\n    fig.suptitle('Training Curve')\n    ax1.plot(iters, loss)\n    ax1.set_xlabel(\"Iterations\")\n    ax1.set_ylabel(\"Training Loss\")\n    ax2.plot(iters, acc, color = 'g')\n    ax2.set_xlabel(\"Iterations\")\n    ax2.set_ylabel(\"Training Accuracy\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"curves(epochs,tr_loss,tr_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Evaluation:-->","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"net.eval()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_accuracy(predictions, true_labels):\n    _, predicted = torch.max(predictions, 1)\n    corrects = (predicted == true_labels).sum()\n    accuracy = 100.0 * corrects/len(true_labels)\n    return accuracy.item()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_pred = net(test_tensor)\nval_loss = criterion(val_pred, test_label)\nval_accuracy = get_accuracy(val_pred, test_label)\n \nprint(\"Loss: \", (val_loss.item()), \"Accuracy: \", (val_accuracy))\n\n# to get class with the maximum score as prediction\n_, val_predicted = torch.max(val_pred.data,1)            \n\nskplt.metrics.plot_confusion_matrix(test_label, val_predicted, figsize=(10,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# So all the predictions are class balanced..","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# And our Test accuracy leads to 97%..","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_img(test,val_predicted)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}