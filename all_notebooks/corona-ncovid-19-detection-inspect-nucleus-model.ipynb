{"cells":[{"metadata":{},"cell_type":"markdown","source":"Orginial project:\nhttps://colab.research.google.com/drive/13FbpgU8TTgcQm3_QMGP5R9Fh7kIsojaj"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tensorflow==1.15.0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!git clone  https://github.com/matterport/Mask_RCNN","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!wget -c https://raw.githubusercontent.com/matterport/Mask_RCNN/master/samples/nucleus/nucleus.py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install mrcnn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport random\nimport math\nimport re\nimport time\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\n# Root directory of the project\nROOT_DIR = os.path.abspath(\"../../content\")\n\n# Import Mask RCNN\nsys.path.append(ROOT_DIR)  # To find local version of the library\nfrom mrcnn import utils\nfrom mrcnn import visualize\nfrom mrcnn.visualize import display_images\nimport mrcnn.model as modellib\nfrom mrcnn.model import log\n\nimport nucleus\n\n%matplotlib inline \n\n# Directory to save logs and trained model\nLOGS_DIR = os.path.join(ROOT_DIR, \"logs\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATASET_DIR = os.path.join(ROOT_DIR, \"datasets/nucleus\")\n\n# Inference Configuration\nconfig = nucleus.NucleusInferenceConfig()\nconfig.display()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Device to load the neural network on.\n# Useful if you're training a model on the same \n# machine, in which case use CPU and leave the\n# GPU for training.\nDEVICE = \"/cpu:0\"  # /cpu:0 or /gpu:0\n\n# Inspect the model in training or inference modes\n# values: 'inference' or 'training'\n# Only inference mode is supported right now\nTEST_MODE = \"inference\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_ax(rows=1, cols=1, size=16):\n    \"\"\"Return a Matplotlib Axes array to be used in\n    all visualizations in the notebook. Provide a\n    central point to control graph sizes.\n    \n    Adjust the size attribute to control how big to render images\n    \"\"\"\n    fig, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n    fig.tight_layout()\n    return ax","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load validation dataset\ndataset = nucleus.NucleusDataset()\ndataset.load_nucleus(DATASET_DIR, \"val\")\ndataset.prepare()\n\nprint(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create model in inference mode\nwith tf.device(DEVICE):\n    model = modellib.MaskRCNN(mode=\"inference\",\n                              model_dir=LOGS_DIR,\n                              config=config)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Path to a specific weights file\n# weights_path = \"/path/to/mask_rcnn_nucleus.h5\"\n\n# Or, load the last model you trained\nweights_path = model.find_last()\n\n# Load weights\nprint(\"Loading weights \", weights_path)\nmodel.load_weights(weights_path, by_name=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_id = random.choice(dataset.image_ids)\nimage, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n    modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\ninfo = dataset.image_info[image_id]\nprint(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \n                                       dataset.image_reference(image_id)))\nprint(\"Original image shape: \", modellib.parse_image_meta(image_meta[np.newaxis,...])[\"original_image_shape\"][0])\n\n# Run object detection\nresults = model.detect_molded(np.expand_dims(image, 0), np.expand_dims(image_meta, 0), verbose=1)\n\n# Display results\nr = results[0]\nlog(\"gt_class_id\", gt_class_id)\nlog(\"gt_bbox\", gt_bbox)\nlog(\"gt_mask\", gt_mask)\n\n# Compute AP over range 0.5 to 0.95 and print it\nutils.compute_ap_range(gt_bbox, gt_class_id, gt_mask,\n                       r['rois'], r['class_ids'], r['scores'], r['masks'],\n                       verbose=1)\n\nvisualize.display_differences(\n    image,\n    gt_bbox, gt_class_id, gt_mask,\n    r['rois'], r['class_ids'], r['scores'], r['masks'],\n    dataset.class_names, ax=get_ax(),\n    show_box=False, show_mask=False,\n    iou_threshold=0.5, score_threshold=0.5)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}