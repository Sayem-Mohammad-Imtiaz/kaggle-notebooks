{"cells":[{"metadata":{"_uuid":"b6269c0e8f417f82daf093dda8fa0da6d2c57d86","_cell_guid":"e81ee64d-e474-4662-9036-ce23df615199"},"cell_type":"markdown","source":"# Introduction\n**This will be your workspace for the [Machine Learning course](https://www.kaggle.com/learn/machine-learning).**\n\nYou will need to translate the concepts to work with the data in this notebook, the Iowa data. Each page in the Machine Learning course includes instructions for what code to write at that step in the course.\n\n# Write Your Code Below"},{"metadata":{"trusted":true,"_uuid":"64fc04a91b2cab908547e75a5be772729a3bbb69","collapsed":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\n\ndef get_mae(max_leaf_nodes, predictors_train, predictors_val, targ_train, targ_val):\n    model = RandomForestRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n    model.fit(predictors_train, targ_train)\n    preds_val = model.predict(predictors_val)\n    mae = mean_absolute_error(targ_val, preds_val)\n    return(mae)\n\nmain_file_path = '../input/house-prices-advanced-regression-techniques/train.csv' # this is the path to the Iowa data that you will use\ndata = pd.read_csv(main_file_path)\ncolumns = data.columns\nusedColumns = []\ny=data.SalePrice\nfor column_n in range(0, columns.size-1):\n    X = data[columns[column_n]]\n    if not (data.dtypes[column_n]==object or data.dtypes[column_n]=='float64'):\n        usedColumns.append(columns[column_n])\nX = data[usedColumns]\ntrain_X, val_X, train_y, val_y = train_test_split(X, y)\nmodel = RandomForestRegressor()\nmodel.fit(train_X,train_y)\npredicted_values = model.predict(val_X)\nmae = mean_absolute_error(val_y, predicted_values)\n#print(columns[column_n])\nprint(mae)   \nprint(usedColumns)\ncount = 0\nn_trees = 1\ntotal_leaf_nodes = 0\nlowest_tree_depth = 1000\nhighest_tree_depth = 0\nfor trees_n in range(1, n_trees+1):\n    current_lowest = y.max()\n    for max_leaf_nodes in range(2,500):\n       my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n       if my_mae<current_lowest:\n           current_lowest=my_mae\n           optimum_leaf = max_leaf_nodes\n           print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(optimum_leaf, current_lowest))\n    if optimum_leaf<lowest_tree_depth:\n        lowest_tree_depth = optimum_leaf\n    if optimum_leaf>highest_tree_depth:\n        highest_tree_depth = optimum_leaf\n    total_leaf_nodes = total_leaf_nodes + optimum_leaf\n    count = count + 1\n    print(count)\nprint(lowest_tree_depth)\nprint(highest_tree_depth)\nprint(total_leaf_nodes/count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f46c08c8cf3cc20b1405f5fa5d69eb272bbad93"},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\n\n\n\nmain_file_path = '../input/house-prices-advanced-regression-techniques/train.csv' # this is the path to the Iowa data that you will use\ndata = pd.read_csv(main_file_path)\ncolumns = data.columns\nusedColumns = []\ny=data.SalePrice\nfor column_n in range(0, columns.size-1):\n    X = data[columns[column_n]]\n    if not (data.dtypes[column_n]==object or data.dtypes[column_n]=='float64'):\n        usedColumns.append(columns[column_n])\nX = data[usedColumns]\narrayn = [[0] * 2 for i in range(32)]\nrepeats = 1\nfor column_j in range(1, X.columns.size-1):\n    mae = 0;\n    for n in range(0,repeats):\n        train_X, val_X, train_y, val_y = train_test_split(X[usedColumns[1]], y, train_size=0.9,test_size=0.1) \n        model = RandomForestRegressor(n_estimators = 10)\n        model.fit(train_X.values.reshape(-1,1),train_y)\n        predicted_values = model.predict(val_X.values.reshape(-1,1))\n        mae = mae + mean_absolute_error(val_y, predicted_values)\n    print(usedColumns[column_j])\n    arrayn[column_j-1][0] = usedColumns[column_j] \n    print(mae/repeats+1)\n    arrayn[column_j-1][1] = mae/repeats +1 \nprint(usedColumns)\nprint(sorted(arrayn, key=lambda x: x[1]))\nlowest = 100000\ntoothTable = [0]*32\nfor i in range(0,32):\n    tempColumns = []\n    tempColumns.append(arrayn[0][0])\n    tempColumns.append(arrayn[i][0])\n    mae = 0\n    for n in range(0,repeats):\n        train_X, val_X, train_y, val_y = train_test_split(X[tempColumns], y, train_size=0.9,test_size=0.1) \n        model = RandomForestRegressor(n_estimators = 10)\n        model.fit(train_X.values,train_y)\n        predicted_values = model.predict(val_X.values)\n        mae = mae + mean_absolute_error(val_y, predicted_values)\n    print(arrayn[i][0])\n    print(mae/repeats+1)\n    together = (arrayn[0][1] + arrayn[i][1])/2\n    if together - 250 > mae/repeats + 1:\n        toothTable[i] = 1\n    elif together + 250 < mae/repeats + 1:\n        toothTable[i] = 0\n    else:\n        toothTable[i] = 2\nprint(toothTable)        \n\nfor j in range (0,32):\n    if toothTable[j] == 1 :\n        for i in range(0,32):\n            if toothTable[i] == 1 :\n                tempColumns = []\n                tempColumns.append(arrayn[0][0])\n                tempColumns.append(arrayn[j][0])\n                tempColumns.append(arrayn[i][0])\n                mae=0\n                for n in range(0,repeats):\n                    train_X, val_X, train_y, val_y = train_test_split(X[tempColumns], y, train_size=0.9,test_size=0.1) \n                    model = RandomForestRegressor(n_estimators = 10)\n                    model.fit(train_X.values,train_y)\n                    predicted_values = model.predict(val_X.values)\n                    mae = mae + mean_absolute_error(val_y, predicted_values)\n                print(arrayn[0][0])\n                print(arrayn[i][0])\n                print(arrayn[j][0])\n                print(mae/repeats+1)\n            \n    \n        \n    \n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b93fd6a890974b021ab0d15b860cfade34b570e","collapsed":true},"cell_type":"code","source":"# import pandas as pd\n# from sklearn.ensemble import RandomForestRegressor\n# from sklearn.metrics import mean_absolute_error\n# from sklearn.model_selection import train_test_split\n\n# def get_mae(max_leaf_nodes, predictors_train, predictors_val, targ_train, targ_val):\n#     model = RandomForestRegressor(max_leaf_nodes=max_leaf_nodes, random_state=random_state_x)\n#     model.fit(predictors_train, targ_train)\n#     preds_val = model.predict(predictors_val)\n#     mae = mean_absolute_error(targ_val, preds_val)\n#     return(mae)\n\n# main_file_path = '../input/house-prices-advanced-regression-techniques/train.csv' # this is the path to the Iowa data that you will use\n# data = pd.read_csv(main_file_path)\n# columns_of_interest = ['LotArea','YearBuilt','1stFlrSF','2ndFlrSF','FullBath','BedroomAbvGr','TotRmsAbvGrd']\n# X = data[columns_of_interest]\n# y = data.SalePrice\n\n# current_lowest = y.max()\n# random_state_n=5\n# random_state_x=79\n    \n# train_X, val_X, train_y, val_y = train_test_split(X, y)\n\n# for max_leaf_nodes in range(2,150):\n#     my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n#     if my_mae<current_lowest:\n#         current_lowest=my_mae\n#         optimum_leaf = max_leaf_nodes\n#         print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d \\t\\t Random State  %d\" %(optimum_leaf, current_lowest, random_state_n))\n# print(random_state_n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c087eb42ae3837bdd1a3473cbbd4c25aee036d1","_kg_hide-output":false},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\n\nmain_file_path = '../input/house-prices-advanced-regression-techniques/train.csv' # this is the path to the Iowa data that you will use\ndata = pd.read_csv(main_file_path)\ntest = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\ncolumns = data.columns\nusedColumns = []\nusedColumns2 = []\ny=data.SalePrice\nfor column_n in range(0, columns.size-1):\n    if not (test.dtypes[column_n]==object or test.dtypes[column_n]=='float64' or data.dtypes[column_n]==object or data.dtypes[column_n]=='float64'):\n        usedColumns.append(columns[column_n])\n        \nX = data[usedColumns]\ny = data.SalePrice\n\nmodel = RandomForestRegressor(max_leaf_nodes=264, random_state=79)\nmodel.fit(X, y)\n\n\ntest_X = test[usedColumns]\n#Use the model to make predictions\npredicted_prices = model.predict(test_X)\nprint(usedColumns)\nprint(predicted_prices)\n\nmy_submission = pd.DataFrame({'Id': test.Id, 'SalePrice': predicted_prices})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission2.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64fde43ae8511da761549c42f24eccb5d1039271","_cell_guid":"06a2e301-f224-40d0-8709-a942b24cd124"},"cell_type":"markdown","source":"\n**If you have any questions or hit any problems, come to the [Learn Discussion](https://www.kaggle.com/learn-forum) for help. **\n\n**Return to [ML Course Index](https://www.kaggle.com/learn/machine-learning)**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}