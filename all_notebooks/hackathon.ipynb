{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler\n\n#for PCA\nfrom sklearn.decomposition import PCA\nfrom sklearn.decomposition import IncrementalPCA\n\nfrom sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport statsmodels.api as sm\nfrom sklearn.metrics import r2_score\n\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\n\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\n\nfrom sklearn import metrics\n\nfrom sklearn import svm \nfrom fancyimpute import KNN \nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.metrics import roc_curve, auc\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n# Suppressing Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset=pd.read_csv('../input/janatahack-crosssell-prediction/train.csv')\ntest=pd.read_csv('../input/janatahack-crosssell-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"null_value_table=pd.DataFrame((dataset.isna().sum()/dataset.shape[0])*100).sort_values(0,ascending=False )\nnull_value_table.columns=['null percentage']\nnull_value_table[null_value_table['null percentage']>0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Vehicle_Age'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Response'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Response', data=dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Response'].value_counts()[1]/dataset['Response'].value_counts()[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.describe(include='object').columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_columns=['Gender', 'Vehicle_Age', 'Vehicle_Damage','Driving_License','Previously_Insured']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_columns=[ 'Age', 'Region_Code','Annual_Premium', 'Policy_Sales_Channel', 'Vintage']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.describe().columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Driving_License'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Previously_Insured'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr=dataset.corr()\ncorr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see the correlation matrix \nplt.figure(figsize = (15,10))        # Size of the figure\nsns.heatmap(corr,annot = True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.boxplot(x=\"Response\", y=\"Annual_Premium\", data=dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.boxplot(x=\"Response\", y=\"Vintage\", data=dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.boxplot(x=\"Response\", y=\"Policy_Sales_Channel\", data=dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.boxplot(x=\"Response\", y=\"Age\", data=dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n# dummy encode the categorical columns\ndataset_dummies = pd.concat([dataset,pd.get_dummies(dataset[cat_columns], drop_first=True)], axis=1)\n\n# drop the original columns\ndataset_dummies.drop(cat_columns, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_dummies.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n# dummy encode the categorical columns\ndataset_dummies = pd.concat([dataset,pd.get_dummies(dataset[cat_columns], drop_first=True)], axis=1)\n\n# drop the original columns\ndataset_dummies.drop(cat_columns, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n# dummy encode the categorical columns\nTest_dataset_dummies = pd.concat([test,pd.get_dummies(test[cat_columns], drop_first=True)], axis=1)\n\n# drop the original columns\nTest_dataset_dummies.drop(cat_columns, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Test_dataset_dummies.drop('id',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = dataset_dummies['Response']\nX = dataset_dummies.drop(['Response','id'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, train_size=0.7, random_state=1,stratify=y)\nprint(\"Dimension of X_train:\", X_train.shape)\nprint(\"Dimension of X_test:\", X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.preprocessing import MinMaxScaler\n\n#scaler = MinMaxScaler()\n\n#X_train = scaler.fit_transform(X_train)\n\n#X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_test = scaler.transform(X_test)\n\n#X_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def CalculateMetrics(confusion):\n    TP = confusion[1,1] # true positive \n    TN = confusion[0,0] # true negatives\n    FP = confusion[0,1] # false positives\n    FN = confusion[1,0] # false negatives\n    print(\"Sesitivity For the Model : \",(TP / float(TP+FN)))\n    print(\"specificity For the Model : \",(TN / float(TN+FP)))\n    print(\"false postive rate For the Model : \",(FP/ float(TN+FP)))\n    print(\"precision/false postive rate For the Model : \",(TP / float(TP+FP)))\n    print(\"Negative predictive value For the Model : \",(TN / float(TN+ FN)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_roc( actual, probs ):\n    fpr, tpr, thresholds = roc_curve( actual, probs, drop_intermediate = False )\n    auc_score = roc_auc_score( actual, probs )\n    plt.figure(figsize=(6, 6))\n    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve')\n    plt.legend(loc=\"lower right\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\n\nlogreg = LogisticRegression(class_weight='balanced',random_state=2)\nlogreg.fit(X_train, y_train)\n\ny_pred = logreg.predict(X_test)\nprint(\"Accuracy {}\".format(metrics.accuracy_score(y_test, y_pred)))\nprint(\"Recall/Sensitivity {}\".format(metrics.recall_score(y_test, y_pred)))\n# Confusion matrix \nconfusion = metrics.confusion_matrix(y_test, y_pred)\nCalculateMetrics(confusion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# ROC-AUC curve\ndraw_roc(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport statsmodels.api as sm \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = X_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculateVIF(X):\n    vif = pd.DataFrame()\n    vif['Features'] = X.columns\n    vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n    vif['VIF'] = round(vif['VIF'], 2)\n    vif = vif.sort_values(by = \"VIF\", ascending = False)\n    return(vif)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_sm = sm.add_constant(X_train[col])\nlogm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm2.fit()\nres.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the predicted values on the train set\ny_train_pred = res.predict(X_train_sm)\ny_train_pred[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = y_train_pred.values.reshape(-1)\ny_train_pred = y_train_pred * 100\ny_train_pred[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred_final = pd.DataFrame({'Conversion':y_train.values, 'Conversion_Prob':y_train_pred})\ny_train_pred_final['id'] = y_train.index\ny_train_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred_final['predicted'] = y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.5 else 0)\n\n# Let's see the head\ny_train_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n# Confusion matrix \nconfusion = metrics.confusion_matrix(y_train_pred_final.Conversion, y_train_pred_final.predicted )\nprint(confusion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the overall accuracy.\nprint(metrics.accuracy_score(y_train_pred_final.Conversion, y_train_pred_final.predicted))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calculateVIF(X_train[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col=col.drop('Age',1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's re-run the model using the selected variables\nX_train_sm = sm.add_constant(X_train[col])\nlogm3 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm3.fit()\nres.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calculateVIF(X_train[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col=col.drop('Vintage',1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's re-run the model using the selected variables\nX_train_sm = sm.add_constant(X_train[col])\nlogm3 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm3.fit()\nres.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calculateVIF(X_train[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = res.predict(X_train_sm).values.reshape(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred_final = pd.DataFrame({'Conversion':y_train.values, 'Conversion_Prob':y_train_pred})\ny_train_pred_final['id'] = y_train.index\ny_train_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred_final['predicted'] = y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.5 else 0)\n\n# Let's see the head\ny_train_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion matrix \nconfusion = metrics.confusion_matrix(y_train_pred_final.Conversion, y_train_pred_final.predicted )\nprint(confusion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the overall accuracy.\nprint(metrics.accuracy_score(y_train_pred_final.Conversion, y_train_pred_final.predicted))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.Conversion, y_train_pred_final.Conversion_Prob, drop_intermediate = False )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_roc(y_train_pred_final.Conversion, y_train_pred_final.Conversion_Prob)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's create columns with different probability cutoffs \nnumbers = [float(x)/10 for x in range(10)]\nfor i in numbers:\n    y_train_pred_final[i]= y_train_pred_final.Conversion_Prob.map(lambda x: 1 if x > i else 0)\ny_train_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df = pd.DataFrame( columns = ['probability','accuracy','sensitivity','specificity'])\nfrom sklearn.metrics import confusion_matrix\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = metrics.confusion_matrix(y_train_pred_final.Conversion, y_train_pred_final[i] )\n    total1=sum(sum(cm1))\n    accuracy = (cm1[0,0]+cm1[1,1])/total1\n    \n    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\nprint(cutoff_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's plot accuracy sensitivity and specificity for various probabilities.\ncutoff_df.plot.line(x='probability', y=['accuracy','sensitivity','specificity'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred_final['final_predicted'] = y_train_pred_final.Conversion_Prob.map( lambda x: 1 if x > 0.22 else 0)\n\ny_train_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the overall accuracy.\nmetrics.accuracy_score(y_train_pred_final.Conversion, y_train_pred_final.final_predicted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion2 = metrics.confusion_matrix(y_train_pred_final.Conversion, y_train_pred_final.final_predicted)\nconfusion2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CalculateMetrics(confusion2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = X_test[col]\nX_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adding constant\nX_test_sm = sm.add_constant(X_test)\n#Making prediction\ny_test_pred = res.predict(X_test_sm)\ny_test_pred[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting y_pred to a dataframe which is an array\ny_pred_1 = pd.DataFrame(y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting y_test to dataframe\ny_test_df = pd.DataFrame(y_test)\n# Putting CustID to index\ny_test_df['id'] = y_test_df.index\n# Removing index for both dataframes to append them side by side \ny_pred_1.reset_index(drop=True, inplace=True)\ny_test_df.reset_index(drop=True, inplace=True)\n# Appending y_test_df and y_pred_1\ny_pred_final = pd.concat([y_test_df, y_pred_1],axis=1)\ny_pred_final.head()\n# Renaming the column \ny_pred_final= y_pred_final.rename(columns={ 0 : 'Conversion_Prob'})\n# Let's see the head of y_pred_final\ny_pred_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_final['final_predicted'] = y_pred_final.Conversion_Prob.map(lambda x: 1 if x > 0.22 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(\"Accuracy {}\".format(metrics.accuracy_score(y_test, y_pred_final['final_predicted'])))\nprint(\"Recall/Sensitivity {}\".format(metrics.recall_score(y_test, y_pred_final['final_predicted'])))\nprint(\"AUC_ROC\",roc_auc_score(y_test, y_pred_final['Conversion_Prob']))\nconfusion = metrics.confusion_matrix(y_test, y_pred_final['final_predicted'])\nCalculateMetrics(confusion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 4, stratify = y)\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import StratifiedKFold\n# logistic regression - the class weight is used to handle class imbalance - it adjusts the cost function\nlogistic = LogisticRegression(class_weight='balanced',random_state=42)\n\n# hyperparameter space\nparams = {'C': [0.1, 0.5, 1, 2, 3, 4, 5, 10], 'penalty': ['l1', 'l2']}\n\n# create 5 folds\nfolds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 4)\n\n# create gridsearch object\nmodel = GridSearchCV(logistic, cv=folds, param_grid=params, scoring='roc_auc', n_jobs=-1, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the grid search to the data\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# printing the optimal accuracy score and hyperparameters\nprint('We can get accuracy of',model.best_score_,'using',model.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize the Logistic regression\nmodel = LogisticRegression(class_weight='balanced',C=0.1, penalty='l2',random_state=42)\n# fit the pca training data\nmodel.fit(X_train, y_train)\n# predict the testing pca data\ny_pred = model.predict(X_test)\nprint(\"Accuracy {}\".format(metrics.accuracy_score(y_test, y_pred)))\nprint(\"Recall/Sensitivity {}\".format(metrics.recall_score(y_test, y_pred)))\nconfusion = metrics.confusion_matrix(y_test, y_pred)\nCalculateMetrics(confusion)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"ROC_AUC\",roc_auc_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.preprocessing import MinMaxScaler\nMinmaxscaler = MinMaxScaler()\n#X_scaled = Minmaxscaler.fit_transform(X)\n\nX_train_NB, X_test_NB, y_train_NB, y_test_NB = train_test_split(X,y, train_size=0.8,test_size=0.2,random_state=111)\n\nmnb = MultinomialNB()\n\n# fit\nmnb.fit(X_train_NB,y_train_NB)\n\n# predict class\npredictions = mnb.predict(X_test_NB)\n\n# predict probabilities\ny_pred_proba = mnb.predict_proba(X_test_NB)\naccuracy = metrics.accuracy_score(y_test_NB, predictions)\nprint(\"Classification Report:\")\nprint(classification_report(y_test_NB,predictions))\nfpr, tpr, threshold = metrics.roc_curve(y_test_NB, predictions)\nroc_auc = metrics.auc(fpr, tpr)\nprint(\"Accuracy {}\".format(metrics.accuracy_score(y_test_NB, predictions)))\nprint(\"Recall/Sensitivity {}\".format(metrics.recall_score(y_test_NB, predictions)))\nconfusion = metrics.confusion_matrix(y_test_NB, predictions)\nCalculateMetrics(confusion)\nprint(\"Accuracy for the test dataset\",'{:.1%}'.format(accuracy) )\nprint(\"ROC for the test dataset\",'{:.1%}'.format(roc_auc))\nplt.plot(fpr,tpr,label=\"Test, auc=\"+str(roc_auc))\nplt.legend(loc=4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom xgboost import plot_importance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\nregex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n\nX.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X.columns.values]\nTest_dataset_dummies.columns= [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in Test_dataset_dummies.columns.values]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the data into train and test\nX_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.7,test_size=0.3,random_state=100,stratify=y,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit model on training data with default hyperparameters\nmodel = XGBClassifier(class_weight='balanced',random_state=2)\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make predictions for test data\n# use predict_proba since we need probabilities to compute auc\ny_pred = model.predict_proba(X_test)\ny_pred[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# evaluate predictions\nimport sklearn.metrics as metrics\nroc = metrics.roc_auc_score(y_test, y_pred[:, 1])\nprint(\"Area under the curve: %.2f%%\" % (roc * 100.0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hyperparameter tuning with XGBoost\nfrom sklearn.model_selection import GridSearchCV\n# creating 3 Fold object \nfolds = 3\n\n# specify range of hyperparameters\nparam_grid = {'learning_rate': [0.2, 0.6], \n             'subsample': [0.3, 0.6, 0.9]}          \n\n\n# specify model\nxgb_model = XGBClassifier(class_weight='balanced',max_depth=2, n_estimators=200)\n\n# set up GridSearchCV()\nmodel_cv = GridSearchCV(estimator = xgb_model, \n                        param_grid = param_grid, \n                        scoring= 'roc_auc', \n                        cv = folds, \n                        verbose = 1,\n                        return_train_score=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit the model\nmodel_cv.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cv results\ncv_results = pd.DataFrame(model_cv.cv_results_)\ncv_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # plotting\nplt.figure(figsize=(16,6))\n\nparam_grid = {'learning_rate': [0.2, 0.6], \n             'subsample': [0.3, 0.6, 0.9]} \n\n\nfor n, subsample in enumerate(param_grid['subsample']):\n    \n\n    plt.subplot(1,len(param_grid['subsample']), n+1)\n    plot_df = cv_results[cv_results['param_subsample']==subsample]\n\n    plt.plot(plot_df[\"param_learning_rate\"], plot_df[\"mean_test_score\"])\n    plt.plot(plot_df[\"param_learning_rate\"], plot_df[\"mean_train_score\"])\n    plt.xlabel('learning_rate')\n    plt.ylabel('AUC')\n    plt.title(\"subsample={0}\".format(subsample))\n    plt.ylim([0.60, 1])\n    plt.legend(['test score', 'train score'], loc='upper left')\n    plt.xscale('log')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# chosen hyperparameters\n# from the above graph it is evident that learning_rate =0.2 and subsample=0.9 produces a model with higher AUC with overfitting.\n#so using those parameters for the final model.\nparams = {'learning_rate': 0.2,\n          'max_depth': 2, \n          'n_estimators':200,\n          'subsample':0.9,\n         'objective':'binary:logistic'}\n\n# fit model on training data\nmodel = XGBClassifier(params = params)\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# predict\n#y_pred_actual was for the predictions interms of churns\n#y_pred is for probabilistic predictions used for AUC.\ny_pred_actual = model.predict(X_test)\ny_pred = model.predict_proba(X_test)\ny_pred[:10]\nauc = roc_auc_score(y_test, y_pred[:, 1])\nauc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submmission = pd.read_csv('../input/janatahack-crosssell-prediction/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Test_dataset_dummies.drop('id',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_pred= model.predict_proba(Test_dataset_dummies)[:, 1]\nsubmmission['Response']=cat_pred\nsubmmission.to_csv(\"final_output.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}