{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Compx310 Assignment Two\n## Morgan Dally - 1313361\n## I've only just now realised that I've written in SDG instead of SGD everywhere"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b666080ead657f8ecce56f8e6d518b162a2cee2b"},"cell_type":"code","source":"# CONSTS USED\n# pinned random state\nRANDOM_STATE=1313361\n\n# model keys\nSGD = 'sgd_classifier'\nRFOREST = 'random_forest_30_branches'\nNAIVE_BAYES = 'naive_bayes'\n\n# dict storing keys\nCV = 'cv'\nCV_SCORE = 'cv_score'\nFIT = 'fit'\nFPR = 'fpr'\nTPR = 'tpr'\nCLASSIFIED_BY = 'classified_by'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f773da46b5b41efb62205358ebde21f2159c1b79"},"cell_type":"code","source":"from sklearn.base import clone\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import roc_curve\nimport warnings\n\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n\ndef get_pred_results(y_pred, y_actual):\n    '''Gets the prediction accuracy'''\n    n_correct = sum(y_pred == y_actual)\n    return n_correct / len(y_actual)\n\ndef benchmark_predictions(x_dat, y_dat, model):\n    '''computes the cross_val and prediction score for a model given x and y dat'''\n    warnings.filterwarnings(\"ignore\")\n    x_train, x_test, y_train, y_test = train_test_split(x_dat, y_dat, test_size=0.2, stratify=y_dat, random_state=RANDOM_STATE)\n    y_train, y_test = y_train == 1.0, y_test == 1.0\n\n    # get predictions via cross-validation\n    cv_pred = cross_val_predict(model, x_dat, y_dat, cv=10) == 1.0\n    cv_result = get_pred_results(cv_pred, y_dat)\n    cv_fpr, cv_tpr, _ = roc_curve(y_dat, cv_pred)\n    \n    # get predictions via just using the inital split\n    cloned_model = clone(model)\n    cloned_model.fit(x_train, y_train)\n    y_pred = cloned_model.predict(x_test) == 1.0\n    fit_result = get_pred_results(y_pred, y_test)\n\n    # figure out which was more accurate\n    max_val = cv_result if cv_result >= fit_result else fit_result\n    classifier = CV if cv_result >= fit_result else FIT\n    return {\n        CV: cv_result,\n        CV_SCORE: np.mean(cross_val_score(model, x_dat, y_dat, cv=10, scoring='accuracy')),\n        FIT: fit_result,\n        FPR: cv_fpr,\n        TPR: cv_tpr,\n        'max': max_val,\n        CLASSIFIED_BY: classifier\n    }\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64fc873e61b72e3e06c12e00f162613b8c6389ee"},"cell_type":"code","source":"import itertools \n\ndef generate_subsets(full_set):\n    '''Generates every possible subset for `full_set`'''\n    set_length = len(full_set)\n    # can't generate any subsets\n    assert set_length >= 2\n\n    # inclusive subset range\n    set_length += 1\n    subsets = []\n    for i in range(2, set_length):\n        subsets += list(itertools.combinations(full_set, i))\n    return subsets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04ba0a8fd1384d6735fbb04f5202bc6b67a27412"},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\ndef predict_all_subsets(full_data, y_dat, subsets, model):\n    '''\n    Goes through every possible subset and finds gets\n    the cross_validation and prediction accuracy scores.\n    Returns the information in a dict\n    '''\n    results = {}\n    for index, subset in enumerate(subsets):\n        x_dat = full_data.iloc[:, list(subset)]\n        results[subset] = benchmark_predictions(x_dat, y_dat, model)\n    return results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca98a0fb93d76ec01b7bca22f3526132b650a671"},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\ndef get_model_list(random_seed):\n    '''Don't get models until actually requests'''\n    return {\n        SGD: SGDClassifier(random_state=random_seed), \n        RFOREST: RandomForestClassifier(n_estimators=30, random_state=random_seed),\n        NAIVE_BAYES: GaussianNB()\n    }\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"input_csv_loc = '../input/wisconsin_breast_cancer.csv'\nbccf = pd.read_csv(input_csv_loc)\n\nbccf_clean = bccf.dropna()\nbccf_clean.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc50fb4bda623101617aa6fba6b0683f28dbf402"},"cell_type":"code","source":"# split the data\nfrom sklearn.model_selection import train_test_split\n\nx_indexes = [1,2,3,4,5,6,7,8]\n# generates all possible subsets, uses indexes for easier looping\nsubsets = generate_subsets(x_indexes)\n\nx_dat = bccf_clean.iloc[:, x_indexes[0]:x_indexes[-1]+1]\n\n# select all entries, then get col 10\ny_dat = bccf_clean.iloc[:, 10]\ny_dat_bin = y_dat == 1.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"571d720f950afea9753821b624c82ce4951050b8"},"cell_type":"code","source":"# get the list of models that are being tested\nmodels = get_model_list(RANDOM_STATE)\nresults = {}\nfor model in models:\n    print('calculating subset accuracy for %s' % model)\n    # for each model get the accuracy for every possible subset\n    results[model] = predict_all_subsets(bccf_clean, y_dat_bin, subsets, models[model])\nprint('found subsets')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def look_up_subset(data, subset):\n    '''Gets the column names of a subset'''\n    columns = []\n    for index in subset:\n        columns.append(data.columns[index])\n    return columns\n\ndef get_perfect_cv_scores(results, num_to_get):\n    '''Gets the `highest_count` number of highest cross_val_score subsets'''\n    model_ss = {}\n    if num_to_get <= 0:\n        return None\n    for model in results:\n        model_results = results[model]\n        cv_accuracies_lambda = lambda ss : model_results[ss][CV_SCORE]\n        cv_accuracies = []\n        cv_ss_scores = {}\n        for subset in model_results:\n            cv_score = cv_accuracies_lambda(subset)\n            cv_accuracies.append(cv_score)\n            cv_ss_scores[cv_score] = subset\n        cv_accuracies = sorted(cv_accuracies, key=float, reverse=True)\n        model_best = {}\n        for _, accuracy in zip(range(0, num_to_get), cv_accuracies):\n            subset = cv_ss_scores[accuracy]\n            model_best[subset] = {\n                CV_SCORE: accuracy,\n                CV: model_results[subset][CV],\n                FIT: model_results[subset][FIT]\n            }\n        model_ss[model] = model_best\n    return model_ss\n\nbest_cv_scores = get_perfect_cv_scores(results, 1)\nfor model in best_cv_scores:\n    print(model)\n    scores = best_cv_scores[model]\n    for subset in scores:\n        col_names = look_up_subset(bccf_clean, subset)\n        print('\\tsubset_indexes: %s\\n\\tsubset: %s\\n\\tcv_score average: %f\\n\\tcv_prediction: %f\\n\\tfit_prediction: %f\\n' % (\n            subset, col_names, scores[subset][CV_SCORE], scores[subset][CV], scores[subset][FIT])\n         )\n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b7e812f91bbdfd4bdf672dd69f47537a90086b5"},"cell_type":"code","source":"def print_max_details(data, results):\n    '''Prints the maximum accuracy (i.e. fit or cross val) scored by a model'''\n    for model_key in results:\n        model_results = results[model_key]\n        max_subset = None\n        max_val = 0.0\n        for subset in model_results:\n            subset_results = model_results[subset]\n            ss_max_val = subset_results['max']\n            if ss_max_val > max_val:\n                max_val = ss_max_val\n                max_subset = subset\n        print('model: %s, max_subset: %s (%s) accuracy: %s' % (model_key, max_subset, subset_results[CLASSIFIED_BY], max_val))\n        print('subset column names: ' + ', '.join(look_up_subset(data, max_subset)))\n        print()\n\n\ndef print_results(data, results):\n    '''Prints the results scored by every subset of every model in results'''\n    for model_key in results:\n        model_results = results[model_key]\n        for subset in model_results:\n            result = model_results[subset]\n            # prediction, trained_model keys\n            fit = result[FIT]\n            cv_avg = result[CV]\n            difference = cv_avg - fit\n            print('%s: subset: %s (%s), fit: %s, cv: %s, dif: %s' % (model_key, subset, result[CLASSIFIED_BY], fit, cv_avg, difference))\n            print('col names: ' + ', '.join(look_up_subset(data, subset)))\n            print()\n\ndef print_results_for_subset(data, results, subset):\n    '''Prints every models results for a specific subset'''\n    for model_key in results:\n        model_results = results[model_key]\n        if subset not in model_results:\n            print('could not find %s in %s' % (subset, model_key))\n            return\n        result = model_results[subset]\n        # prediction, trained_model keys\n        fit = result[FIT]\n        cv_avg = result[CV]\n        difference = cv_avg - fit\n        subset_col_names = look_up_subset(data, subset)\n        print('%s: subset: %s (%s), fit: %s, cv: %s, dif: %s' % (model_key, subset, result[CLASSIFIED_BY], fit, cv_avg, difference))\n        print('col names: ' + ', '.join(look_up_subset(data, subset)))\n        print()\n\nprint_max_details(bccf_clean, results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"45108586bc8853afcd5ceb7af583ad234357db33"},"cell_type":"code","source":"def extract_scatter_plot_data(model_results):\n    '''\n    Helper function for produce_scatter_plot.\n    Extracts the cv and test-accuracy data\n    from the results dict.\n    '''\n    cv_results = []\n    fit_results = []\n    for subset in model_results:\n        result = model_results[subset]\n        # prediction, trained_model keys\n        cv_results.append(result[CV])\n        fit_results.append(result[FIT])\n    return (cv_results, fit_results)\n\ndef produce_scatter_plot(results, results_key):\n    '''creates a scatter plot for an entry in results'''\n    assert results_key in results\n    sp_data = extract_scatter_plot_data(results[results_key])\n    sp = sns.scatterplot(x=sp_data[0], y=sp_data[1])\n    sp.set(title=results_key, xlabel='cv-accuracy', ylabel='test-accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"074d312bbba10429f6f634320f2ff81f9411ac47"},"cell_type":"code","source":"# sgd scatter plot\nproduce_scatter_plot(results, SGD)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8988dced9a6cb4f4bdf4c53f730b9a8da0fa9365"},"cell_type":"code","source":"# randomforest scatter plot\nproduce_scatter_plot(results, RFOREST)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c8fa24adb899ece39d936ae7cf64bc706bdecaa"},"cell_type":"code","source":"# naive bayes scatter plot\nproduce_scatter_plot(results, NAIVE_BAYES)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0aa39c3dc3f8d86a1823b8225d815f7dd1504828"},"cell_type":"code","source":"# roc curve making\ndef find_highest_avg_subset(results):\n    '''\n    Finds the subset that has the highest average\n    accross all of the models in results.\n    '''\n    subset_results = [0] * len(subsets)\n    for model_key in results:\n        model_results = results[model_key]\n        for index, subset in enumerate(model_results):\n            subset_results[index] += model_results[subset][CV]\n\n    # average the array by number of models in results\n    subset_sums = [subset_sum / len(results) for subset_sum in subset_results]\n    max_subset = max(subset_sums)\n\n    # get the index where the max value occured and use it\n    # to get the corresponding subset\n    index_of_ss = subset_sums.index(max_subset)\n    return subsets[index_of_ss]\n\nhighest_avg_subset = find_highest_avg_subset(results)\nprint(look_up_subset(bccf_clean, highest_avg_subset))\nprint_results_for_subset(results, highest_avg_subset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f1ae750c23998883f908d70f0a7a37368ce1027"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef create_roc_graph(results, subset):\n    '''Creates a roc curve graph with every models curve on it'''\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.plot([0, 1], [0, 1], 'k--')\n    for model_key in results:\n        model_results = results[model_key]\n        specific_ss = model_results.get(subset,)\n        ax.plot(specific_ss[FPR], specific_ss[TPR], linewidth=2, label=model_key)\n    plt.legend(loc='lower right')\n    plt.xlabel(FPR)\n    plt.ylabel(TPR)\n    plt.suptitle('roc curve for all models')\n    plt.show()\n\ncreate_roc_graph(results, highest_avg_subset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"976419180b6419b843ae3b1f3c08cddd7c17a5ab"},"cell_type":"code","source":"# for all selected data cols\ncreate_roc_graph(results, subsets[-1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Disccussion\n## CV Score Results:\nsgd_classifier\n\tsubset_indexes: (1, 2, 3, 4, 6, 7)\n\tsubset: ['thickness', 'size', 'shape', 'adhesion', 'nuclei', 'chromatin']\n\tcv_score average: 0.970822\n\tcv_prediction: 0.970717\n\tfit_prediction: 0.970803\n\n\nrandom_forest_30_branches\n\tsubset_indexes: (1, 2, 3, 4, 5, 6, 7, 8)\n\tsubset: ['thickness', 'size', 'shape', 'adhesion', 'single', 'nuclei', 'chromatin', 'nucleoli']\n\tcv_score average: 0.973785\n\tcv_prediction: 0.973646\n\tfit_prediction: 0.970803\n\n\nnaive_bayes\n\tsubset_indexes: (1, 2, 3, 5, 6, 8)\n\tsubset: ['thickness', 'size', 'shape', 'single', 'nuclei', 'nucleoli']\n\tcv_score average: 0.966496\n\tcv_prediction: 0.966325\n\tfit_prediction: 0.963504\n\n## Subset Prediction Results:\n### SGD Classifier\n* max_subset: (2, 5, 6, 8) (regular prediction)\n* subset accuracy: 97.81% (0.9781021897810219)\n\n### Random Forest - 30 Branches\n* max_subset: (7, 8) (chromatin, nucleoli) (cross validation prediction) \n* accuracy: 97.81% (0.9781021897810219)\n\n### Naives Bayes (GaussianNB)\n* max_subset: (2, 7) (size, chromatin) (regular prediction)\n* subset accuracy: 97.08% (0.9708029197080292)\n\n## Classifier Discussion\n### SGD Classifier\n#### Which Subset Looks Best?\n##### CV Score Predicition\nLooking at CV scores the subset of: ['thickness', 'size', 'shape', 'adhesion', 'nuclei', 'chromatin'] looks to have the best average fold.\ncv_score average: 0.970822\ncv_prediction: 0.970717\nfit_prediction: 0.970803\n\n##### Best Subset\nSelecting the subset with highest maximum prediction gave the subset with the indexes of (2, 5, 6, 8) which correlates to:\n* size\n* single\n* nuclei\n* nucleoli\n\nThis subset had an accuracy of 97.81% which I believe this may be the best predicition due to the RandomForestClassifier also achievieving the exact performance.\n\n### Random Forest Classifier\n#### Which Subset Looks Best?\n##### CV Score Predicition\nLooking at CV scores the subset of: ['thickness', 'size', 'shape', 'adhesion', 'single', 'nuclei', 'chromatin', 'nucleoli'] looks to have the best average fold.\ncv_score average: 0.973785\ncv_prediction: 0.973646\nfit_prediction: 0.970803\n\n##### Best Subset\nSelecting the subset with highest maximum prediction gave the subset with the indexes of (7, 8) which correlates to:\n* chromatin\n* nucleoli\n\nThis subset had an accuracy of 97.81% which I believe this may be the best predicition due to the SGD Classifier also achievieving the exact performance.\n\n### Naive Bayes Classifier\n#### Which Subset Looks Best?\n##### CV Score Predicition\nLooking at CV scores the subset of: ['thickness', 'size', 'shape', 'single', 'nuclei', 'nucleoli'] looks to have the best average fold.\ncv_score average: 0.966496\ncv_prediction: 0.966325\nfit_prediction: 0.963504\n\n##### Best Subset\nSelecting the subset with highest maximum prediction gave the subset with the indexes of (2, 7) which correlates to:\n* size\n* chromatin\n\nThis subset had an accuracy of 97.08%. I don't believe is the best possible performance as the above two classifiers achieved higher.\n\n## Best Subset average accross the three models\nThe subset containing: ['size', 'single', 'nuclei'] produced the best average results which are shown below:\nsgd_classifier: subset: (2, 5, 6) fit: 0.9708029197080292, cv: 0.9604685212298683\nrandom_forest_regressor_30_branches: subset: (2, 5, 6) fit: 0.8394160583941606, cv: 0.8799414348462665\nnaive_bayes: subset: (2, 5, 6) fit: 0.9562043795620438, cv: 0.9619326500732065"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}