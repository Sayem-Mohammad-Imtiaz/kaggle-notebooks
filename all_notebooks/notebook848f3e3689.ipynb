{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset=pd.read_csv(r'../input/pima-indians-diabetes-database/diabetes.csv',delimiter=',')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset=dataset.to_numpy()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=dataset[:,0:8]\nY=dataset[:,8]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(Y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=Sequential()\nmodel.add(Dense(12,input_dim=8,kernel_initializer='uniform',activation='relu'))\nmodel.add(Dense(8,kernel_initializer='uniform',activation='relu'))\nmodel.add(Dense(1,kernel_initializer='uniform',activation='sigmoid'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X,Y,epochs=150,batch_size=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score=model.evaluate(X,Y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('%s: %.2f%%' %(model.metrics_names[1],score[1]*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.metrics_names[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"with k fold ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nkfold=StratifiedKFold(n_splits=10,shuffle=True)\nscoreall=[]\nfor train,test in kfold.split(X,Y):\n    model=Sequential()\n    model.add(Dense(12,input_dim=8,kernel_initializer='uniform',activation='relu'))\n    model.add(Dense(8,kernel_initializer='uniform',activation='relu'))\n    model.add(Dense(1,kernel_initializer='uniform',activation='sigmoid'))\n    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n    model.fit(X[train],Y[train],epochs=150,batch_size=10,verbose=0)\n    scores=model.evaluate(X[test],Y[test],verbose=0)\n    print('%s: %.2f%%' %(model.metrics_names[1],scores[1]*100))\n    scoreall.append(scores[1]*100)\nprint('%.2f%% (+/- %.2f%%)'%(np.mean(scoreall),np.std(scoreall)))\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# grid search parameter \n","metadata":{}},{"cell_type":"code","source":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model(optimizer='rmsprop',kernel_initializer='uniform'):\n    # create model\n    model = Sequential()\n    model.add(Dense(12, input_dim=8, kernel_initializer=kernel_initializer, activation='relu' ))\n    model.add(Dense(8, kernel_initializer=kernel_initializer, activation= 'relu'))\n    model.add(Dense(1, kernel_initializer=kernel_initializer, activation= 'sigmoid' ))\n    # Compile model\n    model.compile(loss='binary_crossentropy' , optimizer=optimizer, metrics=['accuracy'])\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=KerasClassifier(build_fn=create_model,verbose=0)\n#grid serch for ephocs , batch size optimazer\noptimizers=['rmsprop','adam']\nkernel_initializer=[ 'glorot_uniform' , 'normal' , 'uniform' ]\nepochs = [50, 100, 150]\nbatches = [5, 10, 20]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_grid=dict(optimizer=optimizers,epochs=epochs, batch_size=batches, kernel_initializer=kernel_initializer)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid)\ngrid_result = grid.fit(X, Y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for params, mean_score, scores in grid_result.param_grid:\n    print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(grid_result.param_grid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}