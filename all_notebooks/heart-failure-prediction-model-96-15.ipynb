{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Heart Failiure prediciton model","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Importing dependencies","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTENC\nimport tensorflow as tf\nimport numpy as np\nimport sys\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom scipy import stats\nfrom sklearn.model_selection import RandomizedSearchCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loading the dataset","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = df.drop(\"DEATH_EVENT\", axis = 1)\ny = df.DEATH_EVENT","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Scaling features (making them all of equal scale)","metadata":{}},{"cell_type":"code","source":"scaler = MinMaxScaler()\nx[['age', 'creatinine_phosphokinase', 'ejection_fraction', 'platelets', 'serum_creatinine', 'serum_sodium', 'time']] = scaler.fit_transform(x[['age', 'creatinine_phosphokinase', 'ejection_fraction', 'platelets', 'serum_creatinine', 'serum_sodium', 'time']])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Mean encoding","metadata":{}},{"cell_type":"code","source":"def mean_encoding(dataset, collumnname_for_encoding, label_collumn_name):\n    mean_encoded_collum = df.groupby([collumnname_for_encoding])[label_collumn_name].mean().to_dict()\n    return mean_encoded_collum","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"anaemia_mean_encoding = mean_encoding(df, \"anaemia\", \"DEATH_EVENT\")\nanaemia_mean_encoding = x[\"anaemia\"].map(anaemia_mean_encoding)\n\ndiabetes_mean_encoding = mean_encoding(df, \"diabetes\", \"DEATH_EVENT\")\ndiabetes_mean_encoding = x[\"diabetes\"].map(diabetes_mean_encoding)\n\nhigh_blood_pressure_mean_encoding = mean_encoding(df, \"high_blood_pressure\", \"DEATH_EVENT\")\nhigh_blood_pressure_mean_encoding = x[\"high_blood_pressure\"].map(high_blood_pressure_mean_encoding)\n\nsex_mean_encoding = mean_encoding(df, \"sex\", \"DEATH_EVENT\")\nsex_mean_encoding = x[\"sex\"].map(sex_mean_encoding)\n\nsmoking_mean_encoding = mean_encoding(df, \"smoking\", \"DEATH_EVENT\")\nsmoking_mean_encoding = x[\"smoking\"].map(smoking_mean_encoding)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x['anaemia_mean_encoding'] = anaemia_mean_encoding\nx['diabetes_mean_encoding'] = diabetes_mean_encoding\nx['high_blood_pressure_mean_encoding'] = high_blood_pressure_mean_encoding\nx['sex_mean_encoding'] = sex_mean_encoding\nx['smoking_mean_encoding'] = smoking_mean_encoding","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Removal of outliers via the Z score","metadata":{}},{"cell_type":"code","source":"z_score = np.abs(stats.zscore(x))\nlocation_of_outliers = np.where(z_score > 3)\nx.drop(location_of_outliers[0], inplace = True)\ny.drop(location_of_outliers[0], inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_x, new_y = SMOTENC(categorical_features=[1,3,5,9,10]).fit_resample(x, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting the data into training and test sets","metadata":{}},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(new_x, new_y, test_size = 0.2, random_state = 25)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modeling","metadata":{}},{"cell_type":"code","source":"random_forest = RandomForestClassifier(max_depth=12, random_state=25)\nrandom_forest.fit(x_train, y_train)\ny_hat = random_forest.predict(x_test)\nAccuracy = accuracy_score(y_test, y_hat)\nprint(\"Accuracy : \",Accuracy)\nprint(accuracy_score(y_train, random_forest.predict(x_train)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Was going to use residual boosting but due to the train accuracy being so high (100%) there is no point, due to the second algorithm having no errors to work with","metadata":{}}]}