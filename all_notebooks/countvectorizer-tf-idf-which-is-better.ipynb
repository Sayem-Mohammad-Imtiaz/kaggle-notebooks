{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV, cross_validate\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n\nfrom wordcloud import WordCloud\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils.multiclass import unique_labels\n\nimport pandas_profiling","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pylab import rcParams\nrcParams['figure.figsize'] = 8, 16","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Load & Clean the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/spam.csv', encoding = 'ISO-8859-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pandas_profiling.ProfileReport(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Key take aways from pandas profiling:__\n\n- there are 86.6% of ham sms and 13.4% of spam sms -> we should make sure that the training and testing have relatively same distribution as the sample\n- Most (99%) of the unamed 2, 3 and 4 columns are empty -> we can perform feature engineering later on them, but we will go ahead and ignore them for now"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating copy of our data for latter exploration\ndf_v2 = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#change the label columns to 0 for spam and 1 for ham in order to feed into the models\ndf_v2.loc[df_v2.v1 == 'spam', 'label'] = 0\ndf_v2.loc[df_v2.v1 == 'ham', 'label'] = 1\n#Dropped the unamed 3 columns and rename the remaining 2 columns\ndf_v2 = df_v2.drop(['v1','Unnamed_2', 'Unnamed_3', 'Unnamed_4'],  axis=1)\ndf_v2 = df_v2.rename(index=str, columns={\"v2\": \"text\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Config the setting and show\npd.set_option('display.max_colwidth', -1)\ndf_v2.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Setting parameters for reproductivity\nX = df_v2['text']\ny = df_v2['label']\nrandom_seed = 2019\ntick_labels = ['spam', 'ham']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Stratified train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25, random_state = random_seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sanity checks no.1 train, test shape\nprint('The shape of the traning set is {}'.format(X_train.shape))\nprint('The shape of the testing set is {}'.format(X_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sanity checks no.2 splited sample percentage\ny_train_percentage = y_train.value_counts()[0] / y_train.value_counts()[1] * 100\ny_test_percentage = y_test.value_counts()[0] / y_test.value_counts()[1] * 100\nprint('The percentage of spam in training y set is {:.1f}%'.format(y_train_percentage))\nprint('The percentage of spam in testing y set is {:.1f}%'.format(y_test_percentage))\nprint('which is close to the original dataset of 13.4%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.1 Count Vectorizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"count_vectorizer = CountVectorizer(decode_error='ignore')\nX_cv_train = count_vectorizer.fit_transform(X_train)\nX_cv_test = count_vectorizer.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Multinomial NB\nnb_model = MultinomialNB()\nnb_model.fit(X_cv_train, y_train)\nprint(\"train score:\", nb_model.score(X_cv_train, y_train))\nprint(\"test score:\", nb_model.score(X_cv_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_cv_pred = nb_model.predict(X_cv_test)\nmat = confusion_matrix(y_test, y_cv_pred)\nsns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False, xticklabels = tick_labels, yticklabels=tick_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, the original model is already performing pretty well on the data. There are in total 16 out of 1393 miss classified data points, the accuracy is 98.9% "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualize the key words\n#Referring to https://github.com/JJtheNOOB/machine_learning_examples/blob/master/nlp_class/spam2.py\ndef visualize(label):\n  words = ''\n  for msg in df_v2[df_v2['label'] == label]['text']:\n    msg = msg.lower()\n    words += msg + ' '\n  wordcloud = WordCloud(width=1200, height=800, background_color=\"white\").generate(words)\n  plt.imshow(wordcloud)\n  plt.axis('off')\n  plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Forest\nn_estimators = range(10, 200, 20)\ntrain_results = []\ntest_results = []\n\n\nfor estimator in n_estimators:\n   rf = RandomForestClassifier(n_estimators=estimator, max_depth=40, n_jobs=-1)\n   rf.fit(X_cv_train, y_train)\n   train_pred = rf.predict(X_cv_train)\n   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n   roc_auc = auc(false_positive_rate, true_positive_rate)\n   train_results.append(roc_auc)\n   y_pred = rf.predict(X_cv_test)\n   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n   roc_auc = auc(false_positive_rate, true_positive_rate)\n   test_results.append(roc_auc)\n\n\nfrom matplotlib.legend_handler import HandlerLine2D\nline1, = plt.plot(n_estimators, train_results, 'b', label='Train AUC')\nline2, = plt.plot(n_estimators, test_results, 'r', label='Test AUC')\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.ylabel('AUC score')\nplt.xlabel('n_estimators')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on our random forest model performance, it is not optimal compared to naive bayes for count vectorizer (plus the model is already overfitting the data)."},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2 TF-IDF"},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf = TfidfVectorizer(decode_error='ignore')\nX_tf_train = tfidf.fit_transform(X_train)\nX_tf_test = tfidf.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Multinomial NB\nnb_model = MultinomialNB()\nnb_model.fit(X_tf_train, y_train)\nprint(\"train score:\", nb_model.score(X_tf_train, y_train))\nprint(\"test score:\", nb_model.score(X_tf_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_tf_pred = nb_model.predict(X_tf_test)\nmat = confusion_matrix(y_test, y_tf_pred)\nsns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False, xticklabels = tick_labels, yticklabels=tick_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Although it seems that the total accuracy of the tf-idf vectorized model is performing slightly worse than the count vectorized model, there is no spam text actually classified as ham text. This will fit those people who would not want to see even a single spam email in their inbox. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Forest\nn_estimators = range(10, 200, 20)\ntrain_results = []\ntest_results = []\n\n\nfor estimator in n_estimators:\n   rf = RandomForestClassifier(n_estimators=estimator, max_depth=40, n_jobs=-1)\n   rf.fit(X_tf_train, y_train)\n   train_pred = rf.predict(X_tf_train)\n   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n   roc_auc = auc(false_positive_rate, true_positive_rate)\n   train_results.append(roc_auc)\n   y_pred = rf.predict(X_tf_test)\n   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n   roc_auc = auc(false_positive_rate, true_positive_rate)\n   test_results.append(roc_auc)\n\n\nfrom matplotlib.legend_handler import HandlerLine2D\nline1, = plt.plot(n_estimators, train_results, 'b', label='Train AUC')\nline2, = plt.plot(n_estimators, test_results, 'r', label='Test AUC')\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\nplt.ylabel('AUC score')\nplt.xlabel('n_estimators')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Same for count vectorizer, random forest model performance is not optimal. "},{"metadata":{},"cell_type":"markdown","source":"## 2.3 LSTM + Keras"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load all the libararies\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM\nfrom keras.utils.np_utils import to_categorical\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import load_model\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use the Keras tokenizer\nnum_words = 2000\ntokenizer = Tokenizer(num_words=num_words)\ntokenizer.fit_on_texts(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pad the data so they have the same lengths\n# \nX_padded = tokenizer.texts_to_sequences(X.values)\nX_padded = pad_sequences(X_padded, maxlen=800)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build out our simple LSTM\nembed_dim = 128\nlstm_out = 196\n\n# Model saving callback\nckpt_callback = ModelCheckpoint('keras_model', \n                                 monitor='val_loss', \n                                 verbose=1, \n                                 save_best_only=True, \n                                 mode='auto')\n\nmodel = Sequential()\nmodel.add(Embedding(num_words, embed_dim, input_length = X_padded.shape[1]))\nmodel.add(LSTM(lstm_out, recurrent_dropout=0.2, dropout=0.2))\nmodel.add(Dense(2,activation='softmax'))\nmodel.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['binary_crossentropy'])\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = pd.get_dummies(y).values\nX_train_keras, X_test_keras, Y_train_keras, Y_test_keras = train_test_split(X_padded, Y, test_size = 0.2, random_state = random_seed, stratify=Y)\nprint(X_train_keras.shape, Y_train_keras.shape)\nprint(X_test_keras.shape, Y_test_keras.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\nmodel.fit(X_train_keras, Y_train_keras, epochs=8, batch_size=batch_size, validation_split=0.2, callbacks=[ckpt_callback])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = load_model('keras_model')\nkeras_preds = model.predict(X_test_keras)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mat_keras = confusion_matrix(Y_test_keras.argmax(axis = 1), keras_preds.argmax(axis = 1))\nsns.heatmap(mat_keras.T, square=True, annot=True, fmt='d', cbar=False, xticklabels = tick_labels, yticklabels=tick_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The LSTM is performing the best now with 99.1% accuracy."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}