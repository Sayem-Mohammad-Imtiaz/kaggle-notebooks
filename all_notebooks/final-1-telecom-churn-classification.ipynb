{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To find if there are any null values in given dataset\nfor i in df.select_dtypes(exclude='object'):\n    if(df[i].isnull().sum()>0):\n        print(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_columns=None\ndf.drop('customerID',axis=1,inplace=True) # Dropping customerID, as it wont be of much use to use\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.select_dtypes(include='object').head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This copy is only for visualization of data before encoding!\ndf1=df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MultipleLines,InternetService,OnlineSecurity,OnlineBackup,DeviceProtection,TechSupport,\n# StreamingTV,StreamingMovies,Contract [multiclass features]\n\ndf['gender']=df['gender'].replace({'Male':1,'Female':0})\ndf['Partner']=df['Partner'].replace({'Yes':1,'No':0})\ndf['Dependents']=df['Dependents'].replace({'Yes':1,'No':0})\ndf['PhoneService']=df['PhoneService'].replace({'Yes':1,'No':0})\ndf['PaperlessBilling']=df['PaperlessBilling'].replace({'Yes':1,'No':0})\ndf['Churn']=df['Churn'].replace({'Yes':1,'No':0})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"################################ Problems ####################################\n#   1-We have to convert all categorical variables by using manual label encoding.\n#   2-fix the datatype of TotalCharges which is numerical feature but it appears to be object datatype.\n#   3- Replace null values by respective mean/median.\n\n# for i in df.select_dtypes(include='object'):\n#     if df[i].nunique()>2:\n#         print(i,':\\n',df[i].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fixing data type of totalcharges to float and Imputing missing values with median.\ndf['TotalCharges']=pd.to_numeric(df['TotalCharges'],errors='coerce')\ndf['TotalCharges']=df['TotalCharges'].fillna(df['TotalCharges'].median())\n\n##### using get_dummies to encode multiclass features\ndfcopy=pd.get_dummies(df.select_dtypes(include='object'),drop_first=True) #creating dummies with 3 categories.\ndf=pd.concat([df,dfcopy],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.select_dtypes(include='object').columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup',\n       'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies',\n       'Contract', 'PaymentMethod'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df is clean dataframe","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visulization:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df1.select_dtypes(include='object'):\n    sns.countplot(df1[i])\n    plt.show()\n# plt.figure(figsize=(15,18))\n# for i in range(1, len(df1.select_dtypes(include=object).columns)-1):\n#     plt.subplot(10, 2, i)\n#     sns.countplot(df1[df1.columns[i]])\n# plt.show()\n\n## As we can observe from given data,\n## 1-There are equal number of males and females,equal number of people with and without partner in the given data.\n## 2-There are around roughly 2000 people who are dependents\n## 3-Almost 90% of people do have access to phone service.But,there are a few people who dont have access to phone service.\n## 4-There are people who have access to landline internet n/w as well mobile n/w\n## 5-People with Fiber optic,DSL access are more.\n## 6-Its very surprising that majority of people from the sample dont have online security.\n## 7-Again majority of people also dont onlinebackup\n## 8-But,Its good to see that people care enough about their devices so as to protect them.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.select_dtypes(exclude='object').columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert tenure to years!\ndf1['tenure']=np.round((df1['tenure']/12),1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['TotalCharges']=pd.to_numeric(df1['TotalCharges'],errors='coerce')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,axes=plt.subplots(1,3,figsize=(15,5))\nsns.distplot(df1['tenure'],ax=axes[0])\nsns.distplot(df1['MonthlyCharges'],ax=axes[1])\nsns.distplot(df1['TotalCharges'],ax=axes[2])\nplt.show()\n#So,majority of people stick around with their operator from 0 to 6 years.\n#Monthly charges range around from 20 to 120 dollars.\n#Total charges incurred by customers are around 0 to 8000 dollars per year.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(df1['MonthlyCharges'],df1['TotalCharges'],hue=df1['Churn'])\nplt.show()\n# People who are churning to other operator seem mostly below 4000 only.There are a few people with monthly charges\n# and with total charges above 5000,But,the frequency to churn is low.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['Churn']=df1['Churn'].replace({'Yes':1,'No':0})\ndf1['Churn']=df1['Churn'].astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df1.corr(),annot=True)\n# Total charges,","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing Libraries:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\n# from sklearn.preprocessing import LabelEncoder,OneHotEncoder #this is optional\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import scale\nfrom scipy.stats import zscore\n\nfrom sklearn.model_selection import train_test_split,KFold,StratifiedKFold,GridSearchCV,cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier,BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier\nfrom sklearn.linear_model import LinearRegression,LogisticRegression,Lasso, Ridge\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import r2_score,roc_auc_score,classification_report,mean_squared_error,accuracy_score,confusion_matrix\n\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1-Logistic and Naive Bayes Classifier:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df.drop('Churn',axis=1)\ny=df['Churn']\n\nlr = LogisticRegression()\ngb = GaussianNB()\nmodels = []\nmodels.append(('LogisticRegression',lr))\nmodels.append(('NaviveBayes',gb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = []\nnames = []\nfor name, model in models:\n    kfold = KFold(shuffle=True, n_splits=5, random_state=0)\n    cv_results = cross_val_score(model, X, y, cv=kfold, scoring='roc_auc')\n    results.append(1 - cv_results)\n    names.append(name)\n    print('%s : %f(%f)' %(name,np.mean(cv_results), np.var(cv_results,ddof=1)))\n# boxplot algorithm comparision\nfig = plt.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting X&y using train_test:\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.2,random_state=8)\n\nlogreg=LogisticRegression()\nlogreg.fit(X_train,y_train)\ny_prob_train = logreg.predict_proba(X_train)\ny_pred_train = logreg.predict(X_train)\ny_prob_test = logreg.predict_proba(X_test)\ny_pred_test = logreg.predict(X_test)\n\nprint('Confusion Matrix - Train:', '\\n', confusion_matrix(y_train, y_pred_train))\nprint('Overall Accuracy', accuracy_score(y_train, y_pred_train))\n\nprint('Confusion Matrix - Test:', '\\n', confusion_matrix(y_test, y_pred_test))\nprint('Overall Accuracy', accuracy_score(y_test, y_pred_test))\n      \nfrom sklearn.metrics import log_loss\nprint('log loss: ',log_loss(y_test,y_prob_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2 - KNN Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df.drop('Churn',axis=1)\ny=df['Churn']\nsc = StandardScaler()\nX_scaled = sc.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier()\nknn_params = {'n_neighbors':np.arange(3,20), 'weights':['uniform','distance']}\ngscv = GridSearchCV(knn, knn_params, cv=5, scoring='roc_auc')\ngscv.fit(X_scaled, y)\nprint(gscv.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gscv_best_knn=gscv.best_params_\n\nKNN=KNeighborsClassifier(**gscv_best_knn)\n\nKNN.fit(X_scaled,y)\nKNN.score(X_scaled,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting X&y using train_test:\nX_train,X_test,y_train,y_test=train_test_split(X_scaled,y,test_size=.2,random_state=8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_prob_train = KNN.predict_proba(X_train)\ny_pred_train = KNN.predict(X_train)\ny_prob_test = KNN.predict_proba(X_test)\ny_pred_test = KNN.predict(X_test)\n\nprint('Confusion Matrix - Train:', '\\n', confusion_matrix(y_train, y_pred_train))\nprint('Overall Accuracy', accuracy_score(y_train, y_pred_train))\n\nprint('Confusion Matrix - Test:', '\\n', confusion_matrix(y_test, y_pred_test))\nprint('Overall Accuracy', accuracy_score(y_test, y_pred_test))\n      \nfrom sklearn.metrics import log_loss\nprint('log loss: ',log_loss(y_test,y_prob_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3- Decision tree: [No need to do scaling now]"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df.drop('Churn',axis=1)\ny=df['Churn']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = DecisionTreeClassifier()\ndt_params = {'max_depth':np.arange(1,10), 'min_samples_leaf':np.arange(2,100), 'criterion':['entropy','gini']}\ngscv = GridSearchCV(dt, dt_params, cv=5, scoring='roc_auc')\ngscv.fit(X, y)\nprint(gscv.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gscv_best_DT=gscv.best_params_\nDT=DecisionTreeClassifier(**gscv_best_DT)\nDT.fit(X,y)\nDT.score(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting X&y using train_test:\nX_train,X_test,y_train,y_test=train_test_split(X_scaled,y,test_size=.2,random_state=8)\n\n\nDT.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_prob_train = DT.predict_proba(X_train)\ny_pred_train = DT.predict(X_train)\ny_prob_test = DT.predict_proba(X_test)\ny_pred_test = DT.predict(X_test)\n\nprint('Confusion Matrix - Train:', '\\n', confusion_matrix(y_train, y_pred_train))\nprint('Overall Accuracy', accuracy_score(y_train, y_pred_train))\n\nprint('Confusion Matrix - Test:', '\\n', confusion_matrix(y_test, y_pred_test))\nprint('Overall Accuracy', accuracy_score(y_test, y_pred_test))\n      \nfrom sklearn.metrics import log_loss\nprint('log loss: ',log_loss(y_test,y_prob_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4 - Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df.drop('Churn',axis=1)\ny=df['Churn']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_avg = []\nauc_var = []\nfor ne in np.arange(1,30):\n    RF=RandomForestClassifier(n_estimators=ne,random_state=0)\n    kfold = KFold(shuffle=True,n_splits=5,random_state=0)\n    auc = cross_val_score(RF, X, y, cv=kfold, scoring='roc_auc')\n    auc_avg.append(1 - np.mean(auc))\n    auc_var.append(np.var(auc,ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Min Bias Error:',np.min(auc_avg),' n_estimator:',np.argmin(auc_avg)+1,' Variance Error:',auc_var[np.argmin(auc_avg)])\nprint('Bias Error:',auc_avg[np.argmin(auc_var)],' n_estimator:',np.argmin(auc_var)+1,'Min Variance Error:',np.min(auc_var))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting X&y using train_test:\nX_train,X_test,y_train,y_test=train_test_split(X_scaled,y,test_size=.2,random_state=8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RF=RandomForestClassifier(n_estimators=16)\nRF.fit(X,y)\nRF.score(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RF.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_prob_train = RF.predict_proba(X_train)\ny_pred_train = RF.predict(X_train)\ny_prob_test = RF.predict_proba(X_test)\ny_pred_test = RF.predict(X_test)\n\nprint('Confusion Matrix - Train:', '\\n', confusion_matrix(y_train, y_pred_train))\nprint('Overall Accuracy', accuracy_score(y_train, y_pred_train))\n\nprint('Confusion Matrix - Test:', '\\n', confusion_matrix(y_test, y_pred_test))\nprint('Overall Accuracy', accuracy_score(y_test, y_pred_test))\n      \nfrom sklearn.metrics import log_loss\nprint('log loss: ',log_loss(y_test,y_prob_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Comparison so far..!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df.drop('Churn',axis=1)\ny=df['Churn']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\ngb = GaussianNB()\nknn=KNeighborsClassifier(**gscv_best_knn)\ndt = DecisionTreeClassifier(**gscv_best_DT)\nrf=RandomForestClassifier(n_estimators=17,random_state=0)\nmodels = []\nmodels.append(('LogisticRegression',lr))\nmodels.append(('NaiveBayes',gb))\nmodels.append(('KNeighborsClassifier',knn))\nmodels.append(('DecisionTreeClassifier',dt))\nmodels.append(('RandomForestClassifier',rf))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = []\nnames = []\nfor name, model in models:\n    kfold = KFold(shuffle=True, n_splits=5, random_state=0)\n    cv_results = cross_val_score(model, X_scaled, y, cv=kfold, scoring='roc_auc')\n    results.append(1-cv_results)\n    names.append(name)\n    print('%s : %f(%f)' %(name,1 - np.mean(cv_results), np.var(cv_results,ddof=1)))\n# boxplot algorithm comparision\nfig = plt.figure(figsize=(15,5))\nfig.suptitle('Algorithm Comparision')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":" So, As we can observe from above box plot,bias variance tradeoff for logistic regression is better as\ncomapared to other other classification models."},{"metadata":{},"cell_type":"markdown","source":"# 5- RF Boosting Classifier: "},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df.drop('Churn',axis=1)\ny=df['Churn']\n\nauc_avg = []\nauc_var = []\nfor ne in np.arange(1,20):\n    ab_rf = AdaBoostClassifier(base_estimator=rf,n_estimators= ne,random_state=0)\n    kfold = KFold(shuffle=True,n_splits=5,random_state=0)\n    auc = cross_val_score(ab_rf, X, y, cv=kfold, scoring='roc_auc')\n    auc_avg.append(1 - np.mean(auc))\n    auc_var.append(np.var(auc,ddof=1))\n\nprint('Min Bias Error:',np.min(auc_avg),' n_estimator:',np.argmin(auc_avg)+1,' Variance Error:',auc_var[np.argmin(auc_avg)])\nprint('Bias Error:',auc_avg[np.argmin(auc_var)],' n_estimator:',np.argmin(auc_var)+1,'Min Variance Error:',np.min(auc_var))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From ada boosting the random forest,we can observe that,bias reduced slightly and variance was already reduced\n# because of random forest itself","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6 - Ada boosted DT: "},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df.drop('Churn',axis=1)\ny=df['Churn']\n\nauc_avg = []\nauc_var = []\nfor ne in np.arange(1,30):\n    ab_dt = AdaBoostClassifier(n_estimators= ne,random_state=0)\n    kfold = KFold(shuffle=True,n_splits=5,random_state=0)\n    auc = cross_val_score(ab_dt, X, y, cv=kfold, scoring='roc_auc')\n    auc_avg.append(1 - np.mean(auc))\n    auc_var.append(np.var(auc,ddof=1))\n\nprint('Min Bias Error:',np.min(auc_avg),' n_estimator:',np.argmin(auc_avg)+1,' Variance Error:',auc_var[np.argmin(auc_avg)])\nprint('Bias Error:',auc_avg[np.argmin(auc_var)],' n_estimator:',np.argmin(auc_var)+1,'Min Variance Error:',np.min(auc_var))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Again,here as well,bias error of decision tree was reduced slightly.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7 - Ada boosted NB:[Needs scaled X]"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df.drop('Churn',axis=1)\ny=df['Churn']\nauc_avg = []\nauc_var = []\nfor ne in np.arange(1,30):\n    ab_nb = AdaBoostClassifier(base_estimator=gb,n_estimators=ne, random_state=0)\n    kfold = KFold(shuffle=True,n_splits=5,random_state=0)\n    auc = cross_val_score(ab_nb, X_scaled, y, cv=kfold, scoring='roc_auc')\n    auc_avg.append(1 - np.mean(auc))\n    auc_var.append(np.var(auc,ddof=1))\nprint('Min Bias Error:',np.min(auc_avg),' n_estimator:',np.argmin(auc_avg)+1,' Variance Error:',auc_var[np.argmin(auc_avg)])\nprint('Bias Error:',auc_avg[np.argmin(auc_var)],' n_estimator:',np.argmin(auc_var)+1,'Min Variance Error:',np.min(auc_var))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 9 - Ada boosted Logistic Regression:[scaled X]"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df.drop('Churn',axis=1)\ny=df['Churn']\nauc_avg = []\nauc_var = []\nfor ne in np.arange(1,30):\n    ab_lr = AdaBoostClassifier(base_estimator=lr,n_estimators=ne, random_state=0)\n    kfold = KFold(shuffle=True,n_splits=5,random_state=0)\n    auc = cross_val_score(ab_lr, X_scaled, y, cv=kfold, scoring='roc_auc')\n    auc_avg.append(1 - np.mean(auc))\n    auc_var.append(np.var(auc,ddof=1))\nprint('Min Bias Error:',np.min(auc_avg),' n_estimator:',np.argmin(auc_avg)+1,' Variance Error:',auc_var[np.argmin(auc_avg)])\nprint('Bias Error:',auc_avg[np.argmin(auc_var)],' n_estimator:',np.argmin(auc_var)+1,'Min Variance Error:',np.min(auc_var))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 10 - Bagged Logistic Regression:[scaled X]"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df.drop('Churn',axis=1)\ny=df['Churn']\nauc_avg = []\nauc_var = []\nfor ne in np.arange(1,30):\n    bgcl_lr = BaggingClassifier(base_estimator=lr, random_state=0, n_estimators=ne)\n    kfold = KFold(shuffle=True,n_splits=5,random_state=0)\n    auc = cross_val_score(bgcl_lr, X_scaled, y, cv=kfold, scoring='roc_auc')\n    auc_avg.append(1 - np.mean(auc))\n    auc_var.append(np.var(auc,ddof=1))\nprint('Min Bias Error:',np.min(auc_avg),' n_estimator:',np.argmin(auc_avg)+1,' Variance Error:',auc_var[np.argmin(auc_avg)])\nprint('Bias Error:',auc_avg[np.argmin(auc_var)],' n_estimator:',np.argmin(auc_var)+1,'Min Variance Error:',np.min(auc_var))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final Comparison:"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\ngb = GaussianNB()\nknn=KNeighborsClassifier(**gscv_best_knn)\ndt = DecisionTreeClassifier(**gscv_best_DT)\nrf=RandomForestClassifier(n_estimators=17,random_state=0)\n\nab_rf = AdaBoostClassifier(base_estimator=rf,n_estimators=2,random_state=0)\nab_dt = AdaBoostClassifier(base_estimator=dt,n_estimators=21,random_state=0)\nab_nb=  AdaBoostClassifier(base_estimator=gb,n_estimators=3,random_state=0)\nab_lr=  AdaBoostClassifier(base_estimator=lr,n_estimators=29,random_state=0)\nbgcl_lr = BaggingClassifier(base_estimator=lr, random_state=0, n_estimators=17)\n\n\n#gbcl = GradientBoostingClassifier(random_state=0, n_estimators=27)\n#stacked = VotingClassifier(estimators=[('BoostedDT',ab_dt),('BaggedLR',bgcl_lr)], voting='soft')\nmodels = []\nmodels.append(('LogisticRegression',lr))\nmodels.append(('NaiveBayes',gb))\nmodels.append(('KNeighborsClassifier',knn))\nmodels.append(('DecisionTreeClassifier   ',dt))\nmodels.append(('RandomForestClassifier',rf))\nmodels.append(('BoostedRF',ab_rf))\nmodels.append(('BoostedDT',ab_dt))\nmodels.append(('BoostedNB',ab_nb))\nmodels.append(('BoostedLR',ab_lr))\nmodels.append(('BaggedLR',bgcl_lr))\n\n#models.append(('GBoostClassifier',gbcl))\n#models.append(('VotingClassifier',stacked))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = []\nnames = []\nfor name, model in models:\n    kfold = KFold(shuffle=True, n_splits=5, random_state=0)\n    cv_results = cross_val_score(model, X_scaled, y, cv=kfold, scoring='roc_auc')\n    results.append(1 - cv_results)\n    names.append(name)\n    print('%s : %f(%f)' %(name,1 - np.mean(cv_results), np.var(cv_results,ddof=1)))\n# boxplot algorithm comparision\nfig = plt.figure(figsize=(20,5))\nfig.suptitle('Algorithm Comparision')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final model with testing:\n# We choose Logistic Regresion as our model because it is best in terms of bias and variance."},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df.drop('Churn',axis=1)\ny=df['Churn']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)\n\nfrom sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression(solver = 'liblinear')\n\nlogreg.fit(X_train, y_train)\n\n\n\ny_pred_train = logreg.predict(X_train) # actual prediction of train \ny_pred_test = logreg.predict(X_test) # actual prediction of test\ny_test_pred_new=logreg.predict_proba(X_test)\ny_test_pred_new=y_test_pred_new[:,1]\n\n\n\nprint('Confusion Matrix - Train:', '\\n', confusion_matrix(y_train, y_pred_train))\nprint('Overall Accuracy', accuracy_score(y_train, y_pred_train))\n\nprint('Confusion Matrix - Test:', '\\n', confusion_matrix(y_test, y_pred_test))\nprint('Overall Accuracy', accuracy_score(y_test, y_pred_test))\n\n\n# print('auc score train: ',roc_auc_score(X_train,y_prob_train_pro))\nprint('auc score test: ',roc_auc_score(y_test,y_test_pred_new))\n\nfrom sklearn.metrics import log_loss\nprint('log loss: ',log_loss(y_test,y_test_pred_new))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#set seed for same results everytime\nseed=0\nimport sklearn.ensemble as ensemble\nimport sklearn.metrics as metrics\n\n\n\nX=df.drop('Churn',axis=1)\ny=df['Churn']\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state =3)\n\n#declare the models\nlr = LogisticRegression()\nrf=RandomForestClassifier(n_estimators=17,random_state=0)\nadb=ensemble.AdaBoostClassifier()\nbgc=ensemble.BaggingClassifier()\ngnb = GaussianNB()\nknn=KNeighborsClassifier(**gscv_best_knn)\ndt = DecisionTreeClassifier(**gscv_best_DT)\nab_rf = AdaBoostClassifier(base_estimator=rf,n_estimators=2,random_state=0)\nab_dt = AdaBoostClassifier(base_estimator=dt,n_estimators=21,random_state=0)\nab_nb=  AdaBoostClassifier(base_estimator=gnb,random_state=0)\nab_lr=  AdaBoostClassifier(base_estimator=lr,n_estimators=29,random_state=0)\nbgcl_lr = BaggingClassifier(base_estimator=lr, random_state=0, n_estimators=17)\nxgb = XGBClassifier()\n\nmodels=[lr,rf,adb,bgc,gnb,knn,dt,ab_rf,ab_dt,ab_nb,ab_lr,bgcl_lr,xgb]\nsctr,scte,auc,ps,rs=[],[],[],[],[]\ndef ens(X_train,X_test, y_train, y_test):\n    for model in models:\n            model.fit(X_train, y_train)\n            y_test_pred = model.predict(X_test)\n            y_test_pred_new=model.predict_proba(X_test)\n            y_test_pred_new=y_test_pred_new[:,1]\n            train_score=model.score(X_train,y_train)\n            test_score=model.score(X_test,y_test)\n            p_score=metrics.precision_score(y_test,y_test_pred)\n            r_score=metrics.recall_score(y_test,y_test_pred)\n            \n            ac=metrics.roc_auc_score(y_test,y_test_pred_new)\n            \n            sctr.append(train_score)\n            scte.append(test_score)\n            ps.append(p_score)\n            rs.append(r_score)\n            auc.append(ac)\n    return sctr,scte,auc,ps,rs\nens(X_train,X_test, y_train, y_test)\n\nensemble=pd.DataFrame({'names':['Logistic Regression','Random Forest','Ada boost','Bagging',\n                                'Naive-Bayes','KNN','Decistion Tree','ab_rf','ab_dt','ab_nb','ab_lr','bgcl_lr','XGB'],\n                       'auc_score':auc,'training':sctr,'testing':scte,'precision':ps,'recall':rs})\nensemble=ensemble.sort_values(by=['auc_score','precision','recall'],ascending=False).reset_index(drop=True)\nensemble","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nfrom imblearn.over_sampling import SMOTE\n\nsmote_X=df.drop('Churn',axis=1)\nsmote_Y=df['Churn']\n# X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state =3)\n\n# smote_X = telcom[cols]\n# smote_Y = telcom[target_col]\n\n#Split train and test data\nsmote_train_X,smote_test_X,smote_train_Y,smote_test_Y = train_test_split(smote_X,smote_Y,\n                                                                         test_size = .25 ,\n                                                                         random_state = 111)\n\n#oversampling minority class using smote\nos = SMOTE(random_state = 0)\nos_smote_X,os_smote_Y = os.fit_sample(smote_train_X,smote_train_Y)\nos_smote_X = pd.DataFrame(data = os_smote_X,columns=smote_X.columns)\nos_smote_Y = pd.DataFrame(data = os_smote_Y,columns=['Churn'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#set seed for same results everytime\nseed=0\nimport sklearn.ensemble as ensemble\nimport sklearn.metrics as metrics\n\n\n\nX=os_smote_X\ny=os_smote_Y\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state =3)\n\n#declare the models\nlr = LogisticRegression()\nrf=RandomForestClassifier(n_estimators=17,random_state=0)\nadb=ensemble.AdaBoostClassifier()\nbgc=ensemble.BaggingClassifier()\ngnb = GaussianNB()\nknn=KNeighborsClassifier(**gscv_best_knn)\ndt = DecisionTreeClassifier(**gscv_best_DT)\nab_rf = AdaBoostClassifier(base_estimator=rf,n_estimators=2,random_state=0)\nab_dt = AdaBoostClassifier(base_estimator=dt,n_estimators=21,random_state=0)\nab_nb=  AdaBoostClassifier(base_estimator=gnb,random_state=0)\nab_lr=  AdaBoostClassifier(base_estimator=lr,n_estimators=29,random_state=0)\nbgcl_lr = BaggingClassifier(base_estimator=lr, random_state=0, n_estimators=17)\nxgb = XGBClassifier()\n\nmodels=[lr,rf,adb,bgc,gnb,knn,dt,ab_rf,ab_dt,ab_nb,ab_lr,bgcl_lr,xgb]\nsctr,scte,auc,ps,rs=[],[],[],[],[]\ndef ens(X_train,X_test, y_train, y_test):\n    for model in models:\n            model.fit(X_train, y_train)\n            y_test_pred = model.predict(X_test)\n            y_test_pred_new=model.predict_proba(X_test)\n            y_test_pred_new=y_test_pred_new[:,1]\n            train_score=model.score(X_train,y_train)\n            test_score=model.score(X_test,y_test)\n            p_score=metrics.precision_score(y_test,y_test_pred)\n            r_score=metrics.recall_score(y_test,y_test_pred)\n            \n            ac=metrics.roc_auc_score(y_test,y_test_pred_new)\n            \n            sctr.append(train_score)\n            scte.append(test_score)\n            ps.append(p_score)\n            rs.append(r_score)\n            auc.append(ac)\n    return sctr,scte,auc,ps,rs\nens(X_train,X_test, y_train, y_test)\n\nensemble=pd.DataFrame({'names':['Logistic Regression','Random Forest','Ada boost','Bagging',\n                                'Naive-Bayes','KNN','Decistion Tree','ab_rf','ab_dt','ab_nb','ab_lr','bgcl_lr','XGB'],\n                       'auc_score':auc,'training':sctr,'testing':scte,'precision':ps,'recall':rs})\nensemble=ensemble.sort_values(by=['auc_score','precision','recall'],ascending=False).reset_index(drop=True)\nensemble","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=os_smote_X\ny=os_smote_Y\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 2)\n\nfrom sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression(solver = 'liblinear')\n\nlogreg.fit(X_train, y_train)\n\n\ny_pred_train = logreg.predict(X_train) # actual prediction of train \ny_pred_test = logreg.predict(X_test) # actual prediction of test\ny_test_pred_new=logreg.predict_proba(X_test)\ny_test_pred_new=y_test_pred_new[:,1]\n\n\n\nprint('Confusion Matrix - Train:', '\\n', confusion_matrix(y_train, y_pred_train))\nprint('Overall Accuracy', accuracy_score(y_train, y_pred_train))\n\nprint('Confusion Matrix - Test:', '\\n', confusion_matrix(y_test, y_pred_test))\nprint('Overall Accuracy', accuracy_score(y_test, y_pred_test))\n\n\n# print('auc score train: ',roc_auc_score(X_train,y_prob_train_pro))\nprint('auc score test: ',roc_auc_score(y_test,y_test_pred_new))\nprint('classification report:\\n',classification_report(y_test,y_pred_test))\nfrom sklearn.metrics import log_loss\nprint('log loss: ',log_loss(y_test,y_test_pred_new))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Before SMOTE:\\n')\nX=df.drop('Churn',axis=1)\ny=df['Churn']\nprint('X shape: ',X.shape)\nprint('y shape: ',y.shape)\nprint('Target variable distribution before smote:\\n',y.value_counts())\n\nprint('\\n\\n\\n')\n\nprint('After SMOTE:\\n')\nX=os_smote_X\ny=os_smote_Y\nprint('X shape: ',X.shape)\nprint('y shape: ',y.shape)\nprint('Target variable distribution after smote:\\n',y['Churn'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As we can observe from the result of our function precision and recall along with auc_roc score improved drastically \n# when we applied smote to our data to make it more balanced.","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}