{"cells":[{"metadata":{"_cell_guid":"4472600f-de97-4576-a3d5-458d2b3609a1","_uuid":"bbd4f5543e935dc8db73356a10d0e8e55f2cda60"},"cell_type":"markdown","source":"本人為機器學習的新人,最近學習完GOOGLE的Machine Learning課程([https://developers.google.com/machine-learning/crash-course/](http://)),因為網上的機器學習例子多數是用R語言或Python的sklearn,所以在此嘗試以tensorflow來解決tantic問題"},{"metadata":{"_cell_guid":"91c92d46-8e87-4a14-ae3d-ab13068df406","_uuid":"25d221c544246948ddecf334b2115db77a21e474"},"cell_type":"markdown","source":"**1.  Import Libary and Dataset 導入庫與數據**"},{"metadata":{"_cell_guid":"46663dbd-e50f-4260-966f-a9360e1d3fb6","_uuid":"75315b37415ced4becc196f4996917c8dfe463ce"},"cell_type":"markdown","source":"1.1 import Libary"},{"metadata":{"_kg_hide-output":false,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import math\n\nfrom IPython import display\nfrom matplotlib import cm\nfrom matplotlib import gridspec\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn import metrics\nimport tensorflow as tf\nfrom tensorflow.python.data import Dataset\nimport datetime\nimport random\nimport seaborn as sns\nfrom functools import reduce\n\ntf.logging.set_verbosity(tf.logging.ERROR)\npd.options.display.max_rows = 10\npd.options.display.float_format = '{:.2f}'.format\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"21f3e9e9-9d41-4e6c-b016-50f9421a49d5","_uuid":"2e5bb6d00953ba2867769da0f628b4b046b4eddd"},"cell_type":"markdown","source":"1.2 import dataset"},{"metadata":{"_cell_guid":"da61dd86-a4cd-4095-bd2b-5f4615b0276b","_kg_hide-input":false,"_uuid":"751d8e43a47e3bf807faf560789175e79ef06b04","_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\", sep=\",\")\ntest = pd.read_csv(\"../input/test.csv\", sep=\",\")\nfull = train.append(test)\n\n#train = train.reindex(np.random.permutation(train.index))\nfull.info()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"04a1d7e6-15b1-4dda-bf7d-0993c21bdd93","_uuid":"a8a3f8ce27652111f613835c52c6235189f861f9","trusted":true},"cell_type":"code","source":"train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"29cd83af-0731-448c-a7e2-fc1c70b8f97d","_uuid":"e664ab55fdf6eb9a0b835433433cf216800aa0a6","trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2db3e072-89c7-486c-97bd-d2e41f8a18d4","_uuid":"6cc4bbaa914440926ac5dbd99cdcd86ac051363f"},"cell_type":"markdown","source":"經觀察初步了解數據的內容,接下來尋找各數據與Survived的關係。"},{"metadata":{"_cell_guid":"87de62e7-9f32-45da-a4a9-d1ef919aac36","_uuid":"1b898420a918be5a399534697d13207eb3dbc10c"},"cell_type":"markdown","source":"**2.  Feature Engineering 特征工程**\n\n從現有的特征當中尋找出與目標有關聯的部份,對缺失的項進行修補,或從現有的特征中派生出潛在的特征。\n\n"},{"metadata":{"_cell_guid":"10bc2bd3-665d-4cfe-b6e5-ec938e92657b","_uuid":"7d61e567393134b76cb6469220b8833220765fb6"},"cell_type":"markdown","source":"2.1 Observation觀察數據\n\n在進行數據挖掘時往往會在特征工程的部份花費最多的時間,由於本人在機器學習方面的經驗較少,所以進行特征工程亦參考了其他優秀的kernal,接下來我會先對Pclass, Sex, Embarked, SibSp, Parch 這幾項特征值總數較少的特征開始,畫圖表進行分析。"},{"metadata":{"_kg_hide-input":true,"_uuid":"3224c85eccba6d8e7fe9a1149cb70ced217c2acf","_cell_guid":"6e90e8c7-6322-4bee-bda9-666298478e01","trusted":true},"cell_type":"code","source":"f,ax = plt.subplots(2,3,figsize=(16,10))\nsns.countplot('Pclass',hue='Survived',data=train,ax=ax[0,0])\nsns.countplot('Sex',hue='Survived',data=train,ax=ax[0,1])\nsns.countplot('Embarked',hue='Survived',data=train,ax=ax[0,2])\nsns.countplot('SibSp',hue='Survived',data=train,ax=ax[1,0])\nsns.countplot('Parch',hue='Survived',data=train,ax=ax[1,1])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7f349d0c-0752-4a82-8d5c-9736991c2188","_uuid":"1c225fd77d7478d0a0e16b08e0991ba3a126ce05"},"cell_type":"markdown","source":"從以上圖表可對存活率初步得出以下的結論:\n\nPclass: 1 > 2 > 3\n\nSex: female > male\n\nEmbark: C > Q > S\n\nSibSp: 1 > others\n\nParch: 1 > others\n\n這些均可作為有效的特征以供機器學習"},{"metadata":{"_cell_guid":"c719491f-c698-4661-8e28-ace3014f7320","_uuid":"bfae47b6652e1bc32bedd7fbc608a64a35205473"},"cell_type":"markdown","source":"2.2 Missing Data 缺失數據\n\n從full.info()中得知數據中Age, Cabin, Embarked, Fare均有缺失的項,如果不進行處理則會影響計算的結果,令學習不能收斂,因此要先補上缺失項。\n\n可以簡單地直接將該項的平均數,中位數或眾數填補到缺失項中,或以其他特征作分組,再以該分組的平均值作為替補值,更可以以一個新值作為替補,因為缺失數據本身也是一項資訊。\n\n下面先以Embarked作示範,先將缺失值標記為X,觀察與Fare, Pclass間的關係:"},{"metadata":{"_kg_hide-input":true,"_uuid":"d28930e038f1eab57b55493ef2e901116444456d","_cell_guid":"65427a93-11f1-4cec-a315-fecc9c189c13","trusted":true},"cell_type":"code","source":"x = 'Embarked'\ny = 'Fare'\nhue = 'Pclass'\ndata = full.copy()\ndata['Embarked'].fillna('X', inplace=True)\nf, ax = plt.subplots(figsize=(8, 5))\nfig = sns.boxplot(x=x, y=y,  data=data)\nfig.axis(ymin=0, ymax=200);","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"489b9673-3523-4066-b39c-4d7c53d44556","_uuid":"cd1476f577a80653129fabfb1e6b7aef32fcd5a5"},"cell_type":"markdown","source":"從上圖可看出,缺失Embarked的乘客,其票價相對於Embarked S和Q都屬於偏離值,所以其Embarked較大可能是C,又考慮到Fare與Pclass有關,下面再畫出根據Pclass分類的關係圖:"},{"metadata":{"_kg_hide-input":true,"_uuid":"bd97ba2bf3fd6a4c9fa1ae3c300f6d9f88278ffa","_cell_guid":"3ee390e6-768f-483b-9761-f53708bf7ddd","trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(8, 5))\nfig = sns.boxplot(x=x, y=y, hue=hue, data=data)\nfig.axis(ymin=0, ymax=250);","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"eca3ee52-508e-4294-bdab-ba1191efeabc","_uuid":"3e573589de841912ff7d4f930da5a172065be4f7"},"cell_type":"markdown","source":"可以看到,缺失Embarked的乘客的Pclass為1, 其Fare又與Embarked=C Pclass=1的中位數相吻合,所以將其缺失值填為C"},{"metadata":{"_kg_hide-output":false,"_uuid":"340bf79e7d26253030ff4db403fc102e5c55fda2","_cell_guid":"9b1ee33f-4377-46c4-9c78-03635fe5a2ea","trusted":true},"cell_type":"code","source":"full['Embarked'].fillna('C', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3f23139b-e027-409d-b3e8-ef3b5b80ae8f","collapsed":true,"_uuid":"b967ee2471fd470ba7f7771eb3eb2f32ce43596a"},"cell_type":"markdown","source":"接下來觀察Fare與Pclass, Sex, Embarked間的關係:"},{"metadata":{"_kg_hide-input":true,"_uuid":"638e12deefba70c910c938b8cecd138ce598f82f","_cell_guid":"36d109b5-bf29-49dd-a281-e02f35d93fdf","trusted":true},"cell_type":"code","source":"f,ax = plt.subplots(1,3,figsize=(16,5))\n\nx = 'Embarked'\ny = 'Fare'\nhue = 'Sex'\ndata = full.copy()\nfig = sns.boxplot(x=x, y=y, hue=hue, data=data,ax=ax[0])\nfig.axis(ymin=0, ymax=300);\n\nx = 'Sex'\ny = 'Fare'\nhue = 'Pclass'\ndata = full.copy()\nfig = sns.boxplot(x=x, y=y, hue=hue, data=data,ax=ax[1])\nfig.axis(ymin=0, ymax=300);\n\nx = 'Pclass'\ny = 'Fare'\nhue = 'Embarked'\ndata = full.copy()\nfig = sns.boxplot(x=x, y=y, hue=hue, data=data,ax=ax[2])\nfig.axis(ymin=0, ymax=300);","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"eaf0c5bb-c005-4a13-ad66-9fa484f064b7","_uuid":"7a97f2e516089bb2b8c6263311dd5ff32ba3462c"},"cell_type":"markdown","source":"可看到Fare與Embarked, Sex和Pclass都有相對的關係,且存在著一定數量的離群值,所以選擇Fare的缺失值以此三項分組,找出中位數來填補"},{"metadata":{"_cell_guid":"6a9750ea-1ef9-48f1-8ffc-9538dc25373e","_uuid":"3c75175a56072ba38b05fabdb677e70ec9003b2e","trusted":true},"cell_type":"code","source":"for sex in full.Sex.unique():\n    for pclass in full.Pclass.unique():\n        for embarked in full.Embarked.unique():\n            features = (full.Sex == sex) & (full.Pclass == pclass) & (full.Embarked == embarked)\n            select_nan = np.isnan(full[\"Fare\"]) & features\n            full.loc[select_nan,'Fare'] = full[features].Fare.median()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"85ffb298-05af-4646-b07d-5396d4c2d216","_uuid":"0f3479582093df92452646909881678949dfc165"},"cell_type":"markdown","source":"再來是Age, 同樣地觀察Age與其他特征的關係:"},{"metadata":{"_kg_hide-input":true,"_uuid":"678972e9a558779f978307878f435da8937fc255","_cell_guid":"eb6df6c3-e1e5-4be7-a711-e109cc879b72","trusted":true},"cell_type":"code","source":"f,ax = plt.subplots(1,5,figsize=(20,5))\n\nx = 'Embarked'\ny = 'Age'\ndata = full.copy()\nfig = sns.boxplot(x=x, y=y, data=data,ax=ax[0])\nfig.axis(ymin=0, ymax=85);\n\nx = 'Sex'\ny = 'Age'\ndata = full.copy()\nfig = sns.boxplot(x=x, y=y,  data=data,ax=ax[1])\nfig.axis(ymin=0, ymax=85);\n\nx = 'Pclass'\ny = 'Age'\ndata = full.copy()\nfig = sns.boxplot(x=x, y=y,  data=data,ax=ax[2])\nfig.axis(ymin=0, ymax=85);\n\nx = 'Parch'\ny = 'Age'\ndata = full.copy()\nfig = sns.boxplot(x=x, y=y,  data=data,ax=ax[3])\nfig.axis(ymin=0, ymax=85);\n\nx = 'SibSp'\ny = 'Age'\ndata = full.copy()\nfig = sns.boxplot(x=x, y=y,  data=data,ax=ax[4])\nfig.axis(ymin=0, ymax=85);","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"db5940d0-b151-4d95-a2bf-ef04d8134d94","_uuid":"30e53e7e1765570ded5eecd210e5a3ccf0da753a"},"cell_type":"markdown","source":"從上面三圖判斷Age與Sex並沒有太大的相關性,Parch因為父輩和子輩間年齡差較大,所以選擇用Embarked, Pclass, SibSp作分組,計選其平均值以填補缺失"},{"metadata":{"_cell_guid":"ead3966b-d4ef-4c33-9863-def6f6b5746d","_uuid":"1a77d027de30dc8483833874fbc393848efdffe3","trusted":true},"cell_type":"code","source":"for sibSp in full.SibSp.unique():\n    for pclass in full.Pclass.unique():\n        for embarked in full.Embarked.unique():\n            features = (full.SibSp == sibSp) & (full.Pclass == pclass) & (full.Embarked == embarked)\n            select_nan = np.isnan(full[\"Age\"]) & features\n            full.loc[select_nan,'Age'] = full[features].Age.mean()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"63e2fb1c-dca3-440e-8f62-25b01429862e","collapsed":true,"_uuid":"462233c74e0497ffd352603674f1169d92d69bf2"},"cell_type":"markdown","source":"而Cabin因為缺失值太多,所以選擇放棄其特征,把其他缺失值都補全後再檢查一下full.info().以確保沒有缺失值:"},{"metadata":{"_cell_guid":"9a49bb29-2ab3-4056-8efd-36be79a3d1e3","_uuid":"1e91ba9336836f4ccec19bf3eb205934e145dac0","trusted":true},"cell_type":"code","source":"full.info()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c00a81bf-97f5-4dde-b7e5-d24dd4ed7ca1","_uuid":"7429ae50a9e3ce0dc11a49de483c6bc03ed5cf49"},"cell_type":"markdown","source":"發現Age仍然後三條缺失的資料,因為以SibSp, Pclass和 Embarked為分組後,這三條為同一組且沒有非缺失的值,因為選擇只以其中兩項作分組再次填補"},{"metadata":{"_cell_guid":"06ba7781-83bd-4774-9e9d-f31ed8f283cb","scrolled":true,"_uuid":"d53376d9afadac23dcc489a1f3e887f3e65ef4b8","trusted":true},"cell_type":"code","source":"full['Age'].fillna(full[(full.SibSp == 2) & (full.Pclass == 3)]['Age'].mean(), inplace=True)\nfull.info()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"13cf3361-7ef1-4506-a2c9-e4e655685723","collapsed":true,"_uuid":"fdcac18d02f1fd00f594906da4576ad6b7ec2cfa"},"cell_type":"markdown","source":"填補完後,再觀察連結值Age和Fare與Survived的關係:"},{"metadata":{"_kg_hide-input":true,"_uuid":"afe2adb4d28ce1122fe4c41b5ed1cdb6adc97c5b","_cell_guid":"a4bba7ba-89ce-41e7-9aaf-ba64699439b5","trusted":true},"cell_type":"code","source":"a = sns.FacetGrid( train, hue = 'Survived', aspect=3 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , train['Age'].max()))\na.add_legend()\n\na = sns.FacetGrid( train, hue = 'Survived', aspect=3 )\na.map(sns.kdeplot, 'Fare', shade= True )\na.set(xlim=(0 , train['Fare'].quantile(0.95)))\na.add_legend()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a0dadbb4-0df3-460e-b2d2-f101b4ddf8e5","_uuid":"5ad0642713ab8475664947bf248315805346285d"},"cell_type":"markdown","source":"可得知在不同年齡段和票價段,其生存率亦有所不同,因為以圖中的交點作為分段,作出Age和Fare的boundaries"},{"metadata":{"_cell_guid":"b86e441b-5296-4802-b145-ee7e73fddf5b","_uuid":"610c0e229acd15c02e679cbf50ccc89eba0bcc06","trusted":true},"cell_type":"code","source":"age_boundaries = [14, 30, 40, 49, 57]\nfare_boundaries = [18, 25]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ddb0f246-ee7e-4197-9fee-dbd8f85dae23","_uuid":"5d370860558f13cc39fb6a0ecdb34350e6f943ba"},"cell_type":"markdown","source":"2.3 Derived Feature 派生特征\n從現有的特征中通過計算組合出新的特征,或從特征的值中提取出新特征"},{"metadata":{"_cell_guid":"88eb64d9-d231-4296-82a4-cc28941d4e33","_uuid":"0cc2b4d5e250a8501022ebddd7e47552f46046a2","trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_uuid":"b5feb1411227565f93a0cd4f6be801164b322c6d","_cell_guid":"872053a3-5637-4d96-a542-c9d0a58c7ea3","trusted":true},"cell_type":"code","source":"full['FamilySize'] = full.SibSp + full.Parch + 1\ntrain = full.head(891)\ntest = full.tail(418)\nsns.countplot('FamilySize',hue='Survived',data=train)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1197d0ec-343c-4ef1-be9b-fe1a7990fa92","_uuid":"781415d161338a598a050a3a8de22e0eb39d6ca0"},"cell_type":"markdown","source":"從圖得知FamilySize為2~4時生存機率較高,因此設定family_size_boundaries的邊界為1和4"},{"metadata":{"_cell_guid":"0ca4bbee-ae86-4ed6-83b0-c1b1817ced68","_uuid":"24b9766ead1d0add85915508f59c3299e157782b","trusted":true},"cell_type":"code","source":"family_size_boundaries=[1, 4]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d4592f75-f26f-460b-b45d-34c9a18069e2","_uuid":"3c811da6d68ae1d4f3fd7343478b94be7fcbf75e","trusted":true},"cell_type":"code","source":"full['Single'] = full.FamilySize.apply(lambda fs: True if fs == 1 else False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"05743f4b-7687-4413-99be-bbfd5effd482","_uuid":"0b237633325acf96065b4934d0f40f0dba098873"},"cell_type":"markdown","source":"接下來看一看name的數據"},{"metadata":{"_cell_guid":"990c9432-6dc8-4784-8403-86be40836e55","_uuid":"5a540bcb36ee4e3a5bba9866f3070e55112fc16a","trusted":true},"cell_type":"code","source":"full.Name.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5321f137-b7eb-4eec-9ac0-355f6d2865b6","_uuid":"aa1adfac5b86382145578986fc3b98d6099b266d"},"cell_type":"markdown","source":"所有的名字中間均有其稱呼,因此可以將其提取出來作為Title特征"},{"metadata":{"_cell_guid":"e0eb0fb1-f50d-499e-8c33-d3e66469e7f4","_uuid":"b65f9ef21154357f2d018c73b5756bc825a006c2","trusted":true},"cell_type":"code","source":"full['Title'] = full['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\nfull['Title'].unique()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"410e0c7e-5e15-47d1-bd0f-6e1262040473","_uuid":"b2e0d460a04c89aaff36b2aaa5d31218826916e9"},"cell_type":"markdown","source":"將Title數目大於2和小於2分開兩張圖表示"},{"metadata":{"_cell_guid":"5d501be1-29d9-43f1-96f7-b3d519af7a8d","_uuid":"d1187fefdd59978ea360a30e27589e80c6f2b910","trusted":true},"cell_type":"code","source":"train = full.head(891)\ntest = full.tail(418)\n\ntitle_names = (train['Title'].value_counts() > 2) \ntrain.insert(loc = len(train.columns),column='BigTitle', value=train['Title'].apply(lambda x: title_names.loc[x]))\ntrain[train.BigTitle == True].Title.unique()\nf,ax = plt.subplots(1,2,figsize=(16,5))\nsns.countplot('Title',hue='Survived',data=train[train.BigTitle == True], ax=ax[0])\nsns.countplot('Title',hue='Survived',data=train[train.BigTitle == False], ax=ax[1])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e629cbdd-2167-400c-9e35-aa62a2b1661b","_uuid":"89f8e984c296fa9417740f67edcaad3ca4b8dab9"},"cell_type":"markdown","source":"將小於2的Title轉成同一種Title作為同類處理"},{"metadata":{"_cell_guid":"1ab6d41e-789a-431e-9efa-33894db23f48","_uuid":"c50324bd6c7cdbeb1a92cc05481384dd821c552c","trusted":true},"cell_type":"code","source":"full['Title'] = full['Title'].apply(lambda title: 'Don' if not title_names.index.contains(title) else title)\nfull['Title'] = full['Title'].apply(lambda title: title if title_names.loc[title] == True else 'X')\nfull.Title.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"觀察名字長度與生存率之間的關係"},{"metadata":{"_cell_guid":"1c66db27-fcaf-4fc8-a032-c44cbcc770d4","_uuid":"f1fbf479b9004ead2bffe940fe03cc146438bda4","trusted":true},"cell_type":"code","source":"full['NameLength'] = full['Name'].apply(lambda name: len(name))\ntrain = full.head(891)\ntest = full.tail(418)\na = sns.FacetGrid( train, hue = 'Survived', aspect=3 )\na.map(sns.kdeplot, 'NameLength', shade= True )\na.set(xlim=(0 , train['NameLength'].quantile(0.95)))\na.add_legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"從圖得知nameLength為12~25時生存機率較低,因此設定family_size_boundaries的邊界為12和28"},{"metadata":{"_cell_guid":"e1b8fc30-33f1-46ef-af4f-d65d2b957152","_uuid":"0e958c9aef90b1e22fd43e40c42db7080aa3c415","trusted":true},"cell_type":"code","source":"name_length_boundaries = [12, 28]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fbd6d63b-3e68-4b2b-99cc-277633c458e8","_uuid":"7982573a7cdc87bd09cf7f6a99a51c8bb8b0906d","trusted":true},"cell_type":"code","source":"full.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"接下來觀察組合特征,了解在不同維度的特征組合下的生存機率"},{"metadata":{"_cell_guid":"94602c37-b75e-42c5-ae57-ed507dd0ccce","_uuid":"e4b3d9709f5f1d95967723927358edcb802e64a8","trusted":true},"cell_type":"code","source":"a = sns.FacetGrid( train,col='Sex', hue = 'Survived', aspect=3 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , train['Age'].max()))\na.add_legend()\n\na = sns.FacetGrid( train,col='Pclass', hue = 'Survived', aspect=3 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , train['Age'].max()))\na.add_legend()\n\na = sns.FacetGrid( train,col='Pclass', hue = 'Survived', aspect=3 )\na.map(sns.kdeplot, 'Fare', shade= True )\na.set(xlim=(0 , 100))\na.add_legend()\n\na = sns.FacetGrid( train,col='Sex', hue = 'Survived', aspect=3 )\na.map(sns.kdeplot, 'NameLength', shade= True )\na.set(xlim=(0 , 100))\na.add_legend()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cee8f141-98f7-4d17-9eec-ef3dffd27370","_uuid":"91ca7e592f9b72a8358fb53ab803f0284335d73a","trusted":true},"cell_type":"code","source":"a = sns.FacetGrid( train,col='Sex', row='Single', hue = 'Survived', aspect=3 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , 100))\na.add_legend()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"59b33b78-16dd-4aee-86ea-11c7cee41a89","_uuid":"7dd2526b12ada4d2341658f3042bb1f31bf4086a","trusted":true},"cell_type":"code","source":"sex_cross_age_boundaries = [15, 26, 32,46, 54]\nparch_cross_age_boundaries = [5, 10, 18, 30, 35]\npclass_cross_age_boundaries = [18, 30, 36, 40, 47]\npclass_cross_fare_boundaries = [8,18,25, 55]\nsex_cross_name_length_boundaries = [12, 26, 42]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"13fcedbd-1e47-45a2-80f3-6459cd4b11aa","_uuid":"a85a29ba2f9a7e077916293c7e021a0fe3544605","trusted":true},"cell_type":"code","source":"train = full.head(891)\ntest = full.tail(418)\n\ntrain['SexCode'] = train.Sex.apply(lambda sex: 1 if sex == 'male' else 0)\n\nf,ax = plt.subplots(2,2,figsize=(20,16))\n\nsns.swarmplot(x='Single',y='Pclass',hue='Survived',data=train,palette='husl',ax=ax[0,0])\nsns.swarmplot(x='Parch',y='SexCode',hue='Survived',data=train,palette='husl',ax=ax[0,1])\nsns.swarmplot(x='Embarked',y='Pclass',hue='Survived',data=train,palette='husl',ax=ax[1,0])\nsns.swarmplot(x='Embarked',y='SexCode',hue='Survived',data=train,palette='husl',ax=ax[1,1])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"00852b4b-68f1-453e-a897-d0ba7fe05675","_uuid":"44aa510686f7119ae8b29c387c263c3a08a692bd","trusted":true},"cell_type":"code","source":"full['Parch'] = full['Parch'].apply(lambda parch: parch if parch <= 2 else 2)\nfull['SibSp'] = full['SibSp'].apply(lambda parch: parch if parch <= 5 else 5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"得出存活率與各條件的相關圖"},{"metadata":{"_cell_guid":"e9276014-8d50-43f7-bcc8-b95a747650d0","_uuid":"d2a1e847652f96c60b5d2699d579195c07b10126","trusted":true},"cell_type":"code","source":"train = full.head(891)\ntest = full.tail(418)\ntrain['SexCode'] = train.Sex.apply(lambda sex: 1 if sex == 'male' else 0)\n#train = pd.get_dummies(data=train, columns = ['Sex'])\ncorrmat = train[['Survived', 'SexCode', 'Pclass', 'Age', 'SibSp', 'FamilySize', 'Parch', 'Fare']].corr()\nf, ax = plt.subplots(figsize=(12, 9))\ncolormap = plt.cm.RdBu\nsns.heatmap(corrmat,linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"df4a7a74-9f01-4d46-bf28-4e660b508b96","_uuid":"9e6a48561ce0d6650fd042b29b26dbc8861b6866"},"cell_type":"markdown","source":"**3.  Maching Learning with Tensorflow 用Tensorflow 進行機器學習**"},{"metadata":{"_cell_guid":"d4a712a2-9ad8-416e-8d1f-487f03776506","_uuid":"d12ff368777aa2bd59b259560dc56e8aaeb98a59"},"cell_type":"markdown","source":"下面的函數都是參考GOOGLE的課程練習,再加以修改以取得dataframe中的features欄目"},{"metadata":{"_kg_hide-input":false,"_uuid":"3b6f3c6312ae6270a55f76d8922162d9ccd8fc48","_cell_guid":"5fd08938-3a56-49f6-84ea-80861e0d65f7","trusted":true},"cell_type":"code","source":"def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n    \"\"\"Trains a linear regression model of one feature.\n\n    Args:\n      features: pandas DataFrame of features\n      targets: pandas DataFrame of targets\n      batch_size: Size of batches to be passed to the model\n      shuffle: True or False. Whether to shuffle the data.\n      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\n    Returns:\n      Tuple of (features, labels) for next data batch\n    \"\"\"\n    \n    # Convert pandas data into a dict of np arrays.\n    features = {key:np.array(value) for key,value in dict(features).items()}                             \n\n    # Construct a dataset, and configure batching/repeating\n    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit      \n    ds = ds.batch(batch_size).repeat(num_epochs)\n    \n    # Shuffle the data, if specified\n    if shuffle:\n        ds = ds.shuffle(10000)\n\n    # Return the next batch of data\n    features, labels = ds.make_one_shot_iterator().get_next()\n\n    return features, labels","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_uuid":"4835fb034e3ad87f7e3bc9ecec54d1d200f08ae2","_cell_guid":"8a5b4b3e-bb22-44db-ad51-f72353cc8df0","trusted":true},"cell_type":"code","source":"def train_linear_classifier_model(\n    learning_rate,\n    steps,\n    batch_size,\n    periods,\n    regularization_strength,\n    training_examples,\n    training_targets,\n    validation_examples,\n    validation_targets):\n    \"\"\"Trains a linear regression model of one feature.\n  \n  In addition to training, this function also prints training progress information,\n  as well as a plot of the training and validation loss over time.\n  \n  Args:\n    learning_rate: A `float`, the learning rate.\n    steps: A non-zero `int`, the total number of training steps. A training step\n      consists of a forward and backward pass using a single batch.\n    batch_size: A non-zero `int`, the batch size.\n    training_examples: A `DataFrame` containing one or more columns from\n      `california_housing_dataframe` to use as input features for training.\n    training_targets: A `DataFrame` containing exactly one column from\n      `california_housing_dataframe` to use as target for training.\n    validation_examples: A `DataFrame` containing one or more columns from\n      `california_housing_dataframe` to use as input features for validation.\n    validation_targets: A `DataFrame` containing exactly one column from\n      `california_housing_dataframe` to use as target for validation.\n      \n  Returns:\n    A `LinearClassifier` object trained on the training data.\n  \"\"\"\n\n    steps_per_period = steps / periods\n    \n    # Create a linear classifier object.\n    my_optimizer = tf.train.FtrlOptimizer(learning_rate=learning_rate, l1_regularization_strength=regularization_strength)\n    #my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n    my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)    \n    linear_classifier = tf.estimator.DNNClassifier(\n    #linear_classifier = tf.estimator.LinearClassifier(\n      feature_columns=construct_feature_columns(training_examples),\n      hidden_units=[10, 10],\n      optimizer=my_optimizer\n    )\n    \n    # Create input functions\n    training_input_fn = lambda: my_input_fn(training_examples, \n                                          training_targets[\"target\"], \n                                          batch_size=batch_size)\n    predict_training_input_fn = lambda: my_input_fn(training_examples, \n                                                  training_targets[\"target\"], \n                                                  num_epochs=1, \n                                                  shuffle=False)\n    predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n                                                    validation_targets[\"target\"], \n                                                    num_epochs=1, \n                                                    shuffle=False)\n    # Train the model, but do so inside a loop so that we can periodically assess\n    # loss metrics.\n    print(\"Training model...\")\n    print(\"LogLoss (on training data):\")\n    training_log_losses = []\n    validation_log_losses = []\n    for period in range (0, periods):\n        # Train the model, starting from the prior state.\n        linear_classifier.train(\n            input_fn=training_input_fn,\n            steps=steps_per_period\n        )\n        # Take a break and compute predictions.    \n        training_probabilities = linear_classifier.predict(input_fn=predict_training_input_fn)\n        training_probabilities = np.array([item['probabilities'] for item in training_probabilities])\n\n        validation_probabilities = linear_classifier.predict(input_fn=predict_validation_input_fn)\n        validation_probabilities = np.array([item['probabilities'] for item in validation_probabilities])\n\n        training_log_loss = metrics.log_loss(training_targets, training_probabilities)\n        validation_log_loss = metrics.log_loss(validation_targets, validation_probabilities)\n        # Occasionally print the current loss.\n        print( \"  period %02d : %0.2f\" % (period, training_log_loss))\n        # Add the loss metrics from this period to our list.\n        training_log_losses.append(training_log_loss)\n        validation_log_losses.append(validation_log_loss)\n    print(\"Model training finished.\")\n    \n    # Output a graph of loss metrics over periods.\n    plt.ylabel(\"LogLoss\")\n    plt.xlabel(\"Periods\")\n    plt.title(\"LogLoss vs. Periods\")\n    plt.tight_layout()\n    plt.plot(training_log_losses, label=\"training\")\n    plt.plot(validation_log_losses, label=\"validation\")\n    plt.legend()\n\n    return linear_classifier","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_uuid":"5711fb54ba4b2bacb458e5df3da2f8f1289adb65","_cell_guid":"5f28a801-889e-4840-a18b-5598ce05ac23","trusted":true},"cell_type":"code","source":"def preprocess_features(df):\n    \"\"\"Prepares input features from tantic data set.\n\n    Args:\n    df: A Pandas DataFrame expected to contain data\n      from the train data set.\n    Returns:\n    A DataFrame that contains the features to be used for the model, including\n    synthetic features.\n    \"\"\"\n    selected_features = df[\n        ['Sex', 'Pclass', 'Age', 'Parch', 'SibSp', 'FamilySize', 'Single', 'Fare', 'Title', 'Embarked', 'NameLength']]\n    processed_features = selected_features.copy()\n    \n    return processed_features\n\ndef preprocess_targets(df):\n    \"\"\"Prepares target features (i.e., labels) from tantic data set.\n\n    Args:\n    df: A Pandas DataFrame expected to contain data\n      from the train data set.\n    Returns:\n    A DataFrame that contains the target feature.\n    \"\"\"\n    output_targets = pd.DataFrame()\n    output_targets[\"target\"] =  df['Survived'] \n    return output_targets","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"定義好函數後,將數據分割為訓練組train和答案test,再將traing分為訓練和驗證組validation"},{"metadata":{"_cell_guid":"bc292ef4-2331-47a5-be28-08e76d4cfe08","_uuid":"713979d0eedbe937f63d4d67fe022a1f9e751488","_kg_hide-input":false,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"train = full.head(891)\ntest = full.tail(418)\n\ntraining_examples = preprocess_features(train.head(700))\ntraining_targets = preprocess_targets(train.head(700))\n\nvalidation_examples = preprocess_features(train.tail(291))\nvalidation_targets = preprocess_targets(train.tail(291))\n\n# Double-check that we've done the right thing.\nprint (\"Training examples summary:\")\ndisplay.display(training_examples.describe())\nprint( \"Validation examples summary:\")\ndisplay.display(validation_examples.describe())\n\n#print( \"Training targets summary:\")\n#display.display(training_targets.describe())\n#print( \"Validation targets summary:\")\n#display.display(validation_targets.describe())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"將上一部份所得的相關項套入函數中,構建訓練用的欄目,主要用bucket column和numeric column去學習"},{"metadata":{"_kg_hide-input":false,"_uuid":"23febf589eb9e2c42710aadd97bd792472397bb3","_cell_guid":"65ddc4aa-2822-45ba-b841-2a6bd3ff2e95","trusted":true},"cell_type":"code","source":"def cross_columns(crolss_array, hash_bucket_size=1000):\n    cross_column = tf.feature_column.indicator_column(tf.feature_column.crossed_column(crolss_array , hash_bucket_size=hash_bucket_size))\n    return cross_column\n    \ndef construct_feature_columns(input_features):\n    \"\"\"Construct the TensorFlow Feature Columns.\n\n    Args:\n    input_features: The names of the numerical input features to use.\n    Returns:\n    A set of feature columns\n    \"\"\"\n    features = []\n\n    sex_categorical_column = tf.feature_column.categorical_column_with_vocabulary_list(key='Sex',vocabulary_list=[\"M\", \"F\"])\n    sex_indicator_column = tf.feature_column.indicator_column(sex_categorical_column)\n    features.append(sex_indicator_column)\n\n    pclass_categorical_column = tf.feature_column.categorical_column_with_identity(key='Pclass',num_buckets=4)\n    pclass_indicator_column = tf.feature_column.indicator_column(pclass_categorical_column)\n    features.append(pclass_indicator_column)\n    \n    embarked_categorical_column = tf.feature_column.categorical_column_with_vocabulary_list(key='Embarked',vocabulary_list=[\"S\", \"C\", \"Q\"])\n    embarked_indicator_column = tf.feature_column.indicator_column(embarked_categorical_column)\n    features.append(embarked_indicator_column)\n        \n    title_categorical_column = tf.feature_column.categorical_column_with_vocabulary_list(key='Title',vocabulary_list=full.Title.unique())\n    title_indicator_column = tf.feature_column.indicator_column(title_categorical_column)\n    features.append(title_indicator_column)\n    \n    name_length_categorical_column = tf.feature_column.numeric_column(\"NameLength\")\n    name_length_bucket_column = tf.feature_column.bucketized_column(name_length_categorical_column, boundaries=name_length_boundaries)\n    features.append(name_length_bucket_column)\n\n    parch_categorical_column = tf.feature_column.categorical_column_with_identity(key='Parch',num_buckets=4)\n    parch_indicator_column = tf.feature_column.indicator_column(parch_categorical_column)\n    #features.append(parch_indicator_column)\n    \n    sibsp_categorical_column = tf.feature_column.categorical_column_with_identity(key='SibSp',num_buckets=4)\n    sibsp_indicator_column = tf.feature_column.indicator_column(sibsp_categorical_column)\n    #features.append(sibsp_indicator_column)\n    \n    family_size_categorical_column = tf.feature_column.numeric_column(\"FamilySize\")\n    family_size_bucket_column = tf.feature_column.bucketized_column(family_size_categorical_column, boundaries=family_size_boundaries)\n    features.append(family_size_bucket_column)\n    \n    single_numric_column = tf.feature_column.numeric_column('Single')\n    features.append(single_numric_column)\n    \n    age_categorical_column = tf.feature_column.numeric_column(\"Age\")\n    age_bucket_column = tf.feature_column.bucketized_column(age_categorical_column, boundaries=age_boundaries)\n    #features.append(age_bucket_column)\n    \n    fare_categorical_column = tf.feature_column.numeric_column(\"Fare\")\n    fare_bucket_column = tf.feature_column.bucketized_column(fare_categorical_column, boundaries=fare_boundaries)\n    features.append(fare_bucket_column)    \n    \n    \n    sex_cross_age_bucket_column = tf.feature_column.bucketized_column(age_categorical_column, boundaries=age_boundaries)\n    features.append(cross_columns(['Sex', 'Single', sex_cross_age_bucket_column]))        \n            \n    parch_cross_age_bucket_column = tf.feature_column.bucketized_column(age_categorical_column, boundaries=parch_cross_age_boundaries)\n    #features.append(cross_columns(['Parch', parch_cross_age_bucket_column]))\n    \n    pclass_cross_fare_bucket_column = tf.feature_column.bucketized_column(fare_categorical_column, boundaries=pclass_cross_fare_boundaries)\n    #features.append(cross_columns(['Pclass', pclass_cross_fare_bucket_column]))\n    \n    pclass_cross_age_bucket_column = tf.feature_column.bucketized_column(age_categorical_column, boundaries=pclass_cross_age_boundaries)\n    #features.append(cross_columns(['Pclass', pclass_cross_age_bucket_column]))\n    \n    sex_cross_name_length_bucket_column = tf.feature_column.bucketized_column(name_length_categorical_column, boundaries=sex_cross_name_length_boundaries)\n    #features.append(cross_columns(['Sex', sex_cross_name_length_bucket_column]))\n        \n    #features.append(cross_columns(['Sex', 'Pclass']))\n    features.append(cross_columns(['SibSp', 'Parch'], 18))\n    features.append(cross_columns(['SibSp', 'Sex'], 12))\n    features.append(cross_columns(['Single', 'Pclass'], 6))\n    \n    #features.append(cross_columns([age_bucket_column, 'Pclass']))\n    \n    #features.append(cross_columns([age_bucket_column, 'Sex']))\n    \n    #features.append(cross_columns(['Embarked', 'Sex']))\n    \n    #features.append(cross_columns(['Embarked', age_bucket_column]))\n    \n    features.append(cross_columns(['Embarked', 'Pclass']))\n\n    feature_columns = set(features)\n    return feature_columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"開始訓練模型,從結果圖可以得知訓練出的模型(藍線)套用在驗證組(橙線)的效果,如果偏差太大則說明出現了overfitting"},{"metadata":{"_cell_guid":"0d63ec78-0ff7-4c18-8bc7-16b0f698274b","_uuid":"a4e4e1fea76761b466aadcb48e4fbddbe7ad1f9e","_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"linear_classifier = train_linear_classifier_model(\n    learning_rate=0.16,\n    steps=200,\n    batch_size=500,\n    periods=15,\n    regularization_strength=0.015,\n    training_examples=training_examples,\n    training_targets=training_targets,\n    validation_examples=validation_examples,\n    validation_targets=validation_targets)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"使用訓練後的模型去預測驗證組的數據,得出模型的準確率等數據"},{"metadata":{"_kg_hide-input":false,"_uuid":"71c5ade415531633fd41c0e289a0954101f31edc","_cell_guid":"d05ece9c-ce12-430d-9547-6ccb7738d159","trusted":true},"cell_type":"code","source":"predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n                                                    validation_targets[\"target\"], \n                                                    num_epochs=1, \n                                                    shuffle=False)\n\nevaluation_metrics = linear_classifier.evaluate(input_fn=predict_validation_input_fn)\nprint(evaluation_metrics.keys())\nprint(\"AUC on the validation set: %0.2f\" % evaluation_metrics['auc'])\nprint(\"Accuracy on the validation set: %0.2f\" % evaluation_metrics['accuracy'])\nprint(evaluation_metrics)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_uuid":"cb040ccdaad8c2df22d87368e1405fd337db1562","_cell_guid":"f1f22bdf-237e-4e4a-961a-aae7d5d62259","_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"validation_probabilities = linear_classifier.predict(input_fn=predict_validation_input_fn)\n# Get just the probabilities for the positive class\nvalidation_probabilities = np.array([item['probabilities'][1] for item in validation_probabilities])\n\nfalse_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(\n    validation_targets, validation_probabilities)\nplt.plot(false_positive_rate, true_positive_rate, label=\"our model\")\nplt.plot([0, 1], [0, 1], label=\"random classifier\")\n_ = plt.legend(loc=2)\n\ntrue_positive_rate","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_uuid":"d72f07e6f5e7c079519ec4ff3709e07f52a089e9","_cell_guid":"00b80fde-5607-418f-832c-52059ebddf59","trusted":true},"cell_type":"code","source":"def assign_probability(df, linear_classifier, validation=False,field='probability'):\n    result = df.copy()\n    fake = df.copy()\n    fake['Survived'] = 0\n    v_examples = preprocess_features(result)\n    if validation:\n        v_targets = preprocess_targets(result)\n    else:\n        v_targets = preprocess_targets(fake)\n    predict_validation_input_fn = lambda: my_input_fn(v_examples, \n                                                        v_targets['target'], \n                                                        num_epochs=1, \n                                                        shuffle=False)\n    validation_probabilities = linear_classifier.predict(input_fn=predict_validation_input_fn)\n    result[field] = np.array([item['probabilities'][1] for item in validation_probabilities])\n    return result","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_uuid":"eeb838662dc9e8aa4d70c6dca45a3a9479cd09dc","_cell_guid":"f141150d-5bb5-460b-985b-89eb11aed2b6","trusted":true},"cell_type":"code","source":"result = assign_probability(test, linear_classifier,False)\nvalidation = assign_probability(train, linear_classifier,True)\nvalidation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_treshold(validation):\n    best_accuracy = 0\n    best_threshold = 0\n    target = 'Survived'\n    for i in range(0, 101):\n        threshold = i/100.0\n        validation['new_survived'] = validation['probability'].apply(lambda p: 1 if p >= threshold else 0)\n        accuracy = validation[validation['new_survived'] == validation['Survived']]['Survived'].count()/validation['Survived'].count().astype(float)\n        if accuracy > best_accuracy:\n            best_accuracy = accuracy\n            best_threshold = threshold\n    threshold = best_threshold\n    validation['new_survived'] = validation['probability'].apply(lambda p: 1 if p >= best_threshold else 0)\n\n    p = validation[validation['probability'] >= threshold]\n    n = validation[validation['probability'] < threshold]\n    tp = p[p[target] == 1]\n    fp = p[p[target] == 0]\n    tn = n[n[target] == 0]\n    fn = n[n[target] == 1]\n\n    pn = p['Survived'].count().astype(float)\n    nn = n['Survived'].count().astype(float)\n    tpn = tp['Survived'].count().astype(float)\n    fpn = fp['Survived'].count().astype(float)\n    tnn = tn['Survived'].count().astype(float)\n    fnn = fn['Survived'].count().astype(float)\n\n    print ('best_threshold: %s' % threshold)\n    print ('best_accuracy: %s' % best_accuracy)\n    print ('result number: %s' % pn)\n    print ('tpn: %s' % tpn)\n    print ('fpn: %s' % fpn)\n    print ('tnn: %s' % tnn)\n    print ('fnn: %s' % fnn)\n\n    precision = tpn / pn\n    tp_rate = tpn / (tpn + fnn)\n    fp_rate = fpn / (fpn + tnn)\n    precision_n = tnn / (tnn + fnn)\n\n    print ('precision: %s' % precision)\n    print ('tp_rate: %s' % tp_rate)\n    print ('fp_rate: %s' % fp_rate)\n    print ('precision_n: %s' % precision_n)\n    return best_threshold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold = find_treshold(validation)\nthreshold","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b0ddf966-f3e6-42f1-aeb6-d5878ea80a55","_uuid":"145c77c877cf2df4f09083c12ed7ece17375628b","trusted":true},"cell_type":"code","source":"result[\"Survived\"] = result[\"probability\"].apply(lambda a: 1 if a > threshold else 0)\nevaluation = result[[\"PassengerId\", \"Survived\"]]\nevaluation","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"_cell_guid":"12dd1989-5d3a-4fe7-9b74-7f4a80c1ed63","_uuid":"a82983b9b9da4a8e7f45feeeb95d3c125b98bb3e","_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"evaluation.to_csv(\"evaluation_submission.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"file_extension":".py","pygments_lexer":"ipython3","mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","version":"3.6.4","nbconvert_exporter":"python"}},"nbformat":4,"nbformat_minor":1}