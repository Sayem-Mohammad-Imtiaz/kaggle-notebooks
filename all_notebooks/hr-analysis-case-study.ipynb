{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Let's start by importing the important libraries for data analysis, data visualization, etc.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's now import our training data and store in a dataframe named train_data.","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/hranalysis/train.csv')\ntrain_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's now do some exploratory data analysis by using the pairplot feature of seaborn to get a brief idea about our dataset and its features.(Warning: this can take some time)","metadata":{}},{"cell_type":"code","source":"sns.pairplot(train_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our main goal is to effectively classify our data. Feature employee_id has no contribution in this since the employee-id is not anyhow related to whether the person gets promotion or not. So we just remove that from our dataset.","metadata":{}},{"cell_type":"code","source":"train_data.drop('employee_id',inplace=True,axis='columns')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's do some more analysis of our data by using these countlots. I have restricted myself to only 2 and rather given more time to the cleaning and improvement of our data.","metadata":{}},{"cell_type":"code","source":"sns.countplot(x='department',data=train_data,hue='is_promoted')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x='gender',data=train_data,hue='is_promoted')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's now look for the presence of any missing values in out data and try to clean it.","metadata":{}},{"cell_type":"code","source":"sns.heatmap(train_data.isnull(),yticklabels=False,cbar=False,cmap='viridis')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Only 2 columns have missing data in them: education and previous_year_rating. For education, most of the entries are 'Bachelor's'. So it would make sense to actually replace all the missing values with 'Bachelor's' since they are having maximum probability. The function below will do this.","metadata":{}},{"cell_type":"code","source":"def fill_edu(col):\n    if(pd.isnull(col)):\n        return \"Bachelor's\"\n    else:\n        return col","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['education'] = train_data['education'].apply(fill_edu)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's check our data.","metadata":{}},{"cell_type":"code","source":"sns.heatmap(train_data.isnull(),yticklabels=False,cbar=False,cmap='viridis')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Great! Now that our data doesn't have any missing education values, let's try and do the same for previous_year_rating column also. Here we'll try to find the most popular rating and assign that to all missing values.","metadata":{}},{"cell_type":"code","source":"sns.countplot(x='previous_year_rating',data=train_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that 3.0 is the most common rating so we will insert 3.0 for all missing values in previous_year_rating.","metadata":{}},{"cell_type":"code","source":"def fill_rating(col):\n    if(pd.isnull(col)):\n        return 3.0\n    else:\n        return col","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['previous_year_rating'] = train_data['previous_year_rating'].apply(fill_rating)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's check our dataset now.","metadata":{}},{"cell_type":"code","source":"sns.heatmap(train_data.isnull(),yticklabels=False,cbar=False,cmap='viridis')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Great! Now our dataset has no missing values. We'll now proceeed further to convert the categorical data formats to dummies format so that our models can use them more effectively. We will use the get_dummies() method of pandas for this purpose. (Dummies can increase the precision of a model a lot instead of normal object types)","metadata":{}},{"cell_type":"code","source":"train_data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dep = pd.get_dummies(train_data['department'],drop_first=True)\nedu = pd.get_dummies(train_data['education'],drop_first=True)\nreg = pd.get_dummies(train_data['region'],drop_first=True)\ngen = pd.get_dummies(train_data['gender'],drop_first=True)\nrec = pd.get_dummies(train_data['recruitment_channel'],drop_first=True)\ndep.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that we have all our dummies let's remove the object type columns and insert our dummies instead.","metadata":{}},{"cell_type":"code","source":"train_data.drop(['department','region','education','gender','recruitment_channel'],axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.concat([train_data,dep,reg,edu,gen,rec],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now our data is ready to be fit into our model, so let's first start by doing a train_test_split to validate our model.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(train_data.drop('is_promoted',axis=1), \n                                                    train_data['is_promoted'], test_size=0.25, \n                                                    random_state=101)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us now use a simple logistic regression model to classify our data. We will check its accuracy later on.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logmodel = LogisticRegression()\nlogmodel.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's predict our test data and evaluate the precision of our model now.","metadata":{}},{"cell_type":"code","source":"predictions = logmodel.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(y_test,predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's try using an decision tree classifier and check its precision.","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtree = DecisionTreeClassifier()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dtree.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = dtree.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(y_test,predictions))\nprint(\"Training Accuracy for Decision tree classifier :\", dtree.score(X_train, y_train))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see that the our models are able to predict is_promoted=0 quite accurately but not as much for is_promoted=1. This is probably because the dataset doesn't have as much is_promoted=1 cases as is_promoted=0. Let's try standard scaling our data and then check the precision.(training accuracy is good but not good enough for validation accuracy)","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test  = sc.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's try first for logistic regression model and test.","metadata":{}},{"cell_type":"code","source":"logmodel2 = LogisticRegression()\nlogmodel2.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = logmodel2.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that the precision of is_promoted=1 is much better here. Now lets try to do the same for a random forest classifier.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(n_estimators=100)\nrfc.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfc_pred = rfc.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,rfc_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that the random forest classifier is slightly better that logistic regression. Let us test their training accuracy to check which is better.","metadata":{}},{"cell_type":"code","source":"print(\"Training Accuracy for Random Forest classifier :\", rfc.score(X_train, y_train))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Training Accuracy for logistic regression classifier :\", logmodel2.score(X_train, y_train))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that accuracy of Random forest classifier is only better. Thanks for reading upto here, if you liked my kernel please leave an upvote.","metadata":{}}]}