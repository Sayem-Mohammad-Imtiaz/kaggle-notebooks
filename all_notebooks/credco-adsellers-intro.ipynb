{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Packages","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# List File Names","metadata":{}},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read Direct ads.txt Records\n\nHere we attempt to save a little bit of RAM by reading chunks and filtering out reseller records as we go.","metadata":{}},{"cell_type":"code","source":"file_path = '/kaggle/input/credco-adstxt-and-sellersjson/adstxt_records.csv'\ndf_ads_chunks = pd.read_csv(file_path, chunksize=5_000_000)\ndf_direct = pd.DataFrame()\nfor ii_chunk, df_ads_chunk in enumerate(df_ads_chunks):\n    df_direct_chunk = df_ads_chunk[df_ads_chunk['account_type']=='direct']\n    df_direct = pd.concat([df_direct, df_direct_chunk])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Drop account type column and add seller tag","metadata":{}},{"cell_type":"code","source":"seller_split = '|@|'\ndf_direct = df_direct.drop(columns=['account_type'])\ndf_direct['seller_tag'] = df_direct['seller_id'] + seller_split + df_direct['ad_domain']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_direct","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Report numbers","metadata":{}},{"cell_type":"code","source":"print('unique host domain: ', df_direct['host_domain'].nunique())\nprint('unique seller tag: ', df_direct['seller_tag'].nunique())\nprint('unique ad domain: ', df_direct['ad_domain'].nunique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Add shared direct pool size","metadata":{}},{"cell_type":"code","source":"df_direct['pool_size'] = df_direct.groupby('seller_tag')['seller_tag'].transform('size')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_direct","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read sellers.json Records","metadata":{}},{"cell_type":"code","source":"file_path = '/kaggle/input/credco-adstxt-and-sellersjson/sellersjson_records.csv'\ndf_slr = pd.read_csv(file_path, dtype={'seller_id': str, 'seller_name': str, 'seller_domain': str})\ndf_slr['seller_tag'] = df_slr['seller_id'] + seller_split + df_slr['ad_domain'] \n# there should not be duplicates but we have some from sellers.json files \n# that have duplicate seller_ids created in strange ways\n# (for example checkout seller_id 146595 at revcontent.com)\ndf_slr = df_slr.drop_duplicates(subset=['seller_tag'], keep=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_slr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create pools DataFrame and Merge with Sellers","metadata":{}},{"cell_type":"code","source":"df_pools = pd.merge(\n    df_direct.drop_duplicates(subset=['seller_tag'])[['seller_id', 'ad_domain', 'seller_tag', 'pool_size']],\n    df_slr.drop(columns=['seller_id', 'ad_domain']),\n    on='seller_tag',\n    how='left',\n)\n\ndf_pools['seller_id_or_name'] = df_pools['seller_name']\ndf_pools['seller_id_or_name'] = df_pools['seller_id_or_name'].fillna(df_pools['seller_id'])\n\ndf_pools = df_pools.fillna('unknown')\ndf_pools['log_pool_size'] = np.log10(df_pools['pool_size'])\n\ndf_pools","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Record mismatch","metadata":{}},{"cell_type":"markdown","source":"## How many direct ads.txt records can be matched to sellers.json records","metadata":{}},{"cell_type":"code","source":"# fraction of unmatched direct records\ndf_pools[df_pools['seller_type']=='unknown']['pool_size'].sum() / df_direct.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fraction of unmatched pools\ndf_pools[df_pools['seller_type']=='unknown'].shape[0] / df_pools.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## How many direct ads.txt records are matched with seller_type `intermediary`","metadata":{}},{"cell_type":"code","source":"df_pools[df_pools['seller_type']=='intermediary']['pool_size'].sum() / df_direct.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pools[df_pools['seller_type']=='intermediary'].shape[0] / df_pools.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The size of shared direct pools","metadata":{}},{"cell_type":"code","source":"df_pools[df_pools['pool_size']>1].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bins_1 = [\n#    ('1', (0.5, 1.5)),\n    ('2', (1.5, 2.5)), \n    ('3', (2.5, 3.5)),\n    ('4', (3.5, 4.5)),\n    ('5', (4.5, 5.5)),\n    ('6-10', (5.5, 10.5)), \n    ('11-50', (10.5, 50.5)),\n    ('51-100', (50.5, 100.5)),\n    ('101-500', (100.5, 500.5)),\n    ('501-1k', (500.5, 1000.5)),\n    ('1k-5k', (1000.5, 5000.5)),\n    ('5k-10k', (5000.5, 10000.5)),\n    ('10k-50k', (10000.5, 50000.5)),\n]\n\nbins_2 = [\n    ('1', (0.5, 1.5)),\n    ('2-100', (1.5, 100.5)), \n    ('101-1k', (100.5, 1000.5)),\n    ('1k+', (1000.5, 50000.5)),\n]\n\nbins_3 = [\n    ('2-100', (1.5, 100.5)), \n    ('101-1k', (100.5, 1000.5)),\n    ('1k+', (1000.5, 50000.5)),\n]\n\nbins_4 = [\n    ('2-50', (1.5, 50.5)),\n    ('51-100', (50.5, 100.5)),\n    ('101-500', (100.5, 500.5)),\n    ('501-1k', (500.5, 1000.5)),\n    ('1k+', (1000.5, 50000.5)),\n]\n\nbins = bins_1\n#bins = bins_2\n#bins = bins_3\n#bins = bins_4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"records = []\nfor indx, (nm, rn) in enumerate(bins):\n    m1 = df_pools['pool_size'] > rn[0]\n    m2 = df_pools['pool_size'] < rn[1]\n    records.append({\n        'bin_num': indx,\n        'bin_name': nm,\n        'num_pools': (m1 & m2).sum(),\n        'num_records': df_pools[m1 & m2]['pool_size'].sum()\n    })\ndf_hist = pd.DataFrame.from_records(records)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_hist = df_hist.sort_values('bin_num')\ndf_hist['cumu_pools'] = df_hist['num_pools'].cumsum()\ndf_hist['cumu_records'] = df_hist['num_records'].cumsum()\ndf_hist","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_line = df_pools[['pool_size']].sort_values('pool_size').copy()\ndf_line = df_line[df_line['pool_size'] > 1]\ndf_line['rank'] = np.arange(df_line.shape[0]) + 1\ndf_line['pool_frac'] = df_line['rank'] / df_line.shape[0]\ndf_line['pool_perc'] = df_line['pool_frac'] * 100\ndf_line['records'] = df_line['pool_size'].cumsum()\ndf_line['records_frac'] = df_line['records'] / df_line.iloc[-1]['records']\ndf_line['records_perc'] = df_line['records_frac'] * 100\n\ndf_line","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = make_subplots(rows=2, cols=2, horizontal_spacing=0.1, vertical_spacing=0.05, shared_xaxes=True)\ncolor_scale = px.colors.qualitative.D3\nbar_color = color_scale[0]\nline_color = color_scale[1]\n\nbar_color = 'black' # color_scale[0]\nline_color = 'black' # color_scale[1]\n\nfig.add_trace(\n    go.Bar(\n    x=df_hist['bin_name'],\n    y=df_hist['num_pools'],\n    text=df_hist['num_pools'],\n    textposition='auto',\n    name='',\n    marker_color=bar_color,\n), row=1, col=1)\n\n# we subsample the later part of the continuous line plot\n# as the log scale compresses that part of the plot\ndf_plt = pd.concat([df_line.iloc[:20], df_line.iloc[20:-1:40]])\n\nfig.add_trace(\n    go.Scatter(\n    x=df_plt['pool_size'],\n    y=df_plt['pool_perc'],\n    name='',\n    marker_color=line_color,\n), row=1, col=2)\n\nfig.add_trace(\n    go.Bar(\n    x=df_hist['bin_name'],\n    y=df_hist['num_records'],\n    text=df_hist['num_records'],\n    textposition='auto',\n    name='',\n    marker_color=bar_color,\n), row=2, col=1)\n\nfig.add_trace(\n    go.Scatter(\n    x=df_plt['pool_size'],\n    y=df_plt['records_perc'],\n    name='',\n    marker_color=line_color,\n), row=2, col=2)\n\nx_axis_name = 'Pool Size (Number of Publishers)'\nfig.update_xaxes(row=1, col=1)\nfig.update_yaxes(type=\"linear\", title='Number of Pools', row=1, col=1)\n\nfig.update_xaxes(type='log', row=1, col=2)\nfig.update_yaxes(type=\"linear\", title='Cumulative % of Pools', row=1, col=2)\n\nfig.update_xaxes(title=x_axis_name, row=2, col=1)\nfig.update_yaxes(type=\"linear\", title='Number of Records', row=2, col=1)\n\nfig.update_xaxes(type='log', title=x_axis_name, row=2, col=2)\nfig.update_yaxes(type=\"linear\", title='Cumulative % of Records', row=2, col=2)\n\nfig.update_layout(\n    showlegend=False, \n    title='Shared Direct Sales Pool Sizes',\n    font={'size': 14},\n    height=900,\n)\n\nfig_name = 'shared_direct_pool_size'\nfig.write_html(fig_name + '.html')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Vertical Runs? ","metadata":{}},{"cell_type":"markdown","source":"## 501 - Taboola and TownNews","metadata":{}},{"cell_type":"code","source":"df_501 = df_pools[df_pools['pool_size']==501]\ndf_501","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_501['ad_domain'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_501['seller_name'].str.contains('TownNews').sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# are the same publishers in all of these pools? \nref_row = df_501.loc[4311]\nref_pubs = set(df_direct[df_direct['seller_tag'] == ref_row['seller_tag']]['host_domain'].values)\nprint('seller_tag\\tpercent_overlap')\nfor indx, row in df_501.head(20).iterrows():\n    df = df_direct[df_direct['seller_tag'] == row['seller_tag']]\n    pubs = set(df['host_domain'].values)\n    print('{}\\t{}'.format(row['seller_tag'], 1 - len(ref_pubs-pubs) / len(ref_pubs)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4172 - This Old House ","metadata":{}},{"cell_type":"code","source":"df_4172 = df_pools[np.abs(df_pools['pool_size'] - 4172) < 25].sort_values('pool_size')\ndf_4172","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# are the same publishers in all of these pools? \nref_row = df_4172.loc[3393]\nref_pubs = set(df_direct[df_direct['seller_tag'] == ref_row['seller_tag']]['host_domain'].values)\nprint('seller_tag\\tpercent_overlap')\nfor indx, row in df_4172.iterrows():\n    df = df_direct[df_direct['seller_tag'] == row['seller_tag']]\n    pubs = set(df['host_domain'].values)\n    print('{}\\t{}'.format(row['seller_tag'], 1 - len(ref_pubs-pubs) / len(ref_pubs)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4210 - United Online / Business on Web","metadata":{}},{"cell_type":"code","source":"df_4210 = df_pools[np.abs(df_pools['pool_size'] - 4210) < 25].sort_values('pool_size')\ndf_4210","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# are the same publishers in all of these pools? \nref_row = df_4210.loc[42]  # United Online \nref_pubs = set(df_direct[df_direct['seller_tag'] == ref_row['seller_tag']]['host_domain'].values)\nprint('seller_tag\\tpercent_overlap')\nfor indx, row in df_4210.head(20).iterrows():\n    df = df_direct[df_direct['seller_tag'] == row['seller_tag']]\n    pubs = set(df['host_domain'].values)\n    print('{}\\t{}'.format(row['seller_tag'], 1 - len(ref_pubs-pubs) / len(ref_pubs)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# are the same publishers in all of these pools? \nref_row = df_4210.loc[3376] # Business on Web\nref_pubs = set(df_direct[df_direct['seller_tag'] == ref_row['seller_tag']]['host_domain'].values)\nprint('seller_tag\\tpercent_overlap')\nfor indx, row in df_4210.head(10).iterrows():\n    df = df_direct[df_direct['seller_tag'] == row['seller_tag']]\n    pubs = set(df['host_domain'].values)\n    print('{}\\t{}'.format(row['seller_tag'], 1 - len(ref_pubs-pubs) / len(ref_pubs)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 10090 - SportsEngine","metadata":{}},{"cell_type":"code","source":"df_10090 = df_pools[np.abs(df_pools['pool_size'] - 10090) < 25].sort_values('pool_size')\ndf_10090","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# are the same publishers in all of these pools? \nref_row = df_10090.loc[3292] \nref_pubs = set(df_direct[df_direct['seller_tag'] == ref_row['seller_tag']]['host_domain'].values)\nprint('seller_tag\\tpercent_overlap')\nfor indx, row in df_10090.head(10).iterrows():\n    df = df_direct[df_direct['seller_tag'] == row['seller_tag']]\n    pubs = set(df['host_domain'].values)\n    print('{}\\t{}'.format(row['seller_tag'], 1 - len(ref_pubs-pubs) / len(ref_pubs)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 18713 - Freewheel.tv","metadata":{}},{"cell_type":"code","source":"df_18713 = df_pools[np.abs(df_pools['pool_size'] - 18713) < 10].sort_values('pool_size')\ndf_18713","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_18713['ad_domain'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# are the same publishers in all of these pools? \nref_row = df_18713.loc[128] \nref_pubs = set(df_direct[df_direct['seller_tag'] == ref_row['seller_tag']]['host_domain'].values)\nprint('seller_tag\\tpercent_overlap')\nfor indx, row in df_18713.head(10).iterrows():\n    df = df_direct[df_direct['seller_tag'] == row['seller_tag']]\n    pubs = set(df['host_domain'].values)\n    print('{}\\t{}'.format(row['seller_tag'], 1 - len(ref_pubs-pubs) / len(ref_pubs)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(pubs)[0:20]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Treemaps","metadata":{}},{"cell_type":"code","source":"color_scale = px.colors.qualitative.D3\ncolor_map = {\n    'publisher': color_scale[0],\n    'intermediary': color_scale[1],\n    'both': color_scale[4],\n    'unknown': color_scale[3],\n}\nhovertemplate = (\n    '<b>%{label} </b> <br>    '\n    'Seller Type: %{customdata[0]} <br>    '\n    'Seller Name: %{customdata[1]} <br>    '\n    'Seller Domain: %{customdata[2]} <br>    '\n    'Pool Size: %{value} <br>    ' \n)\n\nlegend_name = 'seller type'\nlegend_strings = ['publisher', 'intermediary', 'both', 'unknown']\nmargin=dict(l=5, r=5, t=0, b=35)\nlgnd_treemap = go.Treemap(\n    labels = [legend_name] + legend_strings,\n    parents = [''] + [legend_name] * 4,\n    marker_colors = ['lightgray'] + [color_map[el] for el in legend_strings],\n    insidetextfont = {'size': 16},\n    outsidetextfont = {\"size\": 16},\n    name = '',\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_plot_data(df_plt, root_name=''):\n\n    df_one = (\n        df_plt.groupby('ad_domain')['pool_size'].sum().to_frame('pool_size').reset_index()\n    )\n\n    # do root node\n    labels = [root_name]\n    parents = ['']\n    values = [df_one['pool_size'].sum()]\n    marker_colors = ['white']\n    text = [root_name]\n    seller_name = ['']\n    seller_type = ['']\n    seller_domain = ['']\n\n    # do ad domain parents\n    labels += df_one['ad_domain'].to_list()\n    parents += [root_name] * df_one.shape[0]\n    values += df_one['pool_size'].to_list()\n    marker_colors += ['lightgray'] * df_one.shape[0]\n    text += df_one['ad_domain'].to_list()\n    seller_name += [''] * df_one.shape[0]\n    seller_type += [''] * df_one.shape[0]\n    seller_domain += [''] * df_one.shape[0]\n\n    # do seller leaves\n    labels += df_plt['seller_tag'].to_list()\n    parents += df_plt['ad_domain'].to_list()\n    values += df_plt['pool_size'].to_list()\n    marker_colors += df_plt['seller_type'].apply(lambda x: color_map[x]).to_list()\n    text += df_plt['seller_id_or_name'].to_list()\n    seller_name += df_plt['seller_name'].to_list()\n    seller_type += df_plt['seller_type'].to_list()\n    seller_domain += df_plt['seller_domain'].to_list()\n\n    df = pd.DataFrame({\n        'labels': labels,\n        'parents': parents,\n        'values': values,\n        'marker_colors': marker_colors,\n        'text': text,\n        'seller_type': seller_type,\n        'seller_name': seller_name,\n        'seller_domain': seller_domain,\n    })\n\n    return df ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The Largest Shared Direct Pools","metadata":{}},{"cell_type":"code","source":"df_pools = df_pools.sort_values('pool_size', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_plt = df_pools.head(500)\ndf_tree = get_plot_data(df_plt, root_name='root')\ncustomdata = df_tree[['seller_type', 'seller_name', 'seller_domain']].values\n\nfig = make_subplots(\n    rows=2, cols=4,\n    row_heights = [0.08, 0.92],\n    vertical_spacing = 0.02,\n    specs = [\n        [None, {'type': 'treemap', 'colspan': 2}, None, None], \n        [{'type': 'treemap', 'colspan': 4}, None, None, None],\n    ]\n)\n\nfig.add_trace(lgnd_treemap, row=1, col=2)\nfig.add_trace(go.Treemap(\n    labels = df_tree['labels'],\n    parents = df_tree['parents'],\n    values = df_tree['values'],\n    marker_colors = df_tree['marker_colors'],\n    text = df_tree['text'],\n    customdata = customdata,\n    branchvalues = 'total',\n    hovertemplate = hovertemplate, \n    texttemplate = '%{text}',\n    insidetextfont = {'size': 16},\n    outsidetextfont = {\"size\": 16},\n    name = '',\n), row=2, col=1)\n\nfig.update_layout(\n    height=1200,\n    margin=margin,\n)\n\nfig.show()\nfig_name = 'treemap_shared_direct_top500'\nfig.write_html(fig_name + '.html')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Focus on Freewheel.tv","metadata":{}},{"cell_type":"code","source":"df_plt = df_pools[\n    (df_pools['ad_domain'] == 'freewheel.tv') & \n    (df_pools['pool_size'] > 100)\n]\n\ndf_tree = get_plot_data(df_plt, root_name='root')\ncustomdata = df_tree[['seller_type', 'seller_name', 'seller_domain']].values\n\n\nfig = make_subplots(\n    rows=2, cols=4,\n    row_heights = [0.06, 0.94],\n    vertical_spacing = 0.01,\n    specs = [\n        [None, {'type': 'treemap', 'colspan': 2}, None, None], \n        [{'type': 'treemap', 'colspan': 4}, None, None, None],\n    ]\n)\n\nfig.add_trace(lgnd_treemap, row=1, col=2)\nfig.add_trace(go.Treemap(\n    labels = df_tree['labels'],\n    parents = df_tree['parents'],\n    values = df_tree['values'],\n    marker_colors = df_tree['marker_colors'],\n    text = df_tree['text'],\n    customdata = customdata,\n    branchvalues = 'total',\n    hovertemplate = hovertemplate, \n    texttemplate = '%{text}',\n    insidetextfont = {'size': 16},\n    outsidetextfont = {\"size\": 16},\n    name = '',\n), row=2, col=1)\n\nfig.update_layout(\n    height=1200,\n    margin=margin,\n)\n\nfig.show()\nfig_name = 'treemap_shared_direct_freewheeltv'\nfig.write_html(fig_name + '.html')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Focus on Taboola","metadata":{}},{"cell_type":"code","source":"df_plt = df_pools[\n    (df_pools['ad_domain'] == 'taboola.com') & \n    (df_pools['pool_size'] > 100)\n]\n\ndf_tree = get_plot_data(df_plt, root_name='root')\ncustomdata = df_tree[['seller_type', 'seller_name', 'seller_domain']].values\n\n\nfig = make_subplots(\n    rows=2, cols=4,\n    row_heights = [0.06, 0.94],\n    vertical_spacing = 0.01,\n    specs = [\n        [None, {'type': 'treemap', 'colspan': 2}, None, None], \n        [{'type': 'treemap', 'colspan': 4}, None, None, None],\n    ]\n)\n\nfig.add_trace(lgnd_treemap, row=1, col=2)\nfig.add_trace(go.Treemap(\n    labels = df_tree['labels'],\n    parents = df_tree['parents'],\n    values = df_tree['values'],\n    marker_colors = df_tree['marker_colors'],\n    text = df_tree['text'],\n    customdata = customdata,\n    branchvalues = 'total',\n    hovertemplate = hovertemplate, \n    texttemplate = '%{text}',\n    insidetextfont = {'size': 16},\n    outsidetextfont = {\"size\": 16},\n    name = '',\n), row=2, col=1)\n\nfig.update_layout(\n    height=1200,\n    margin=margin,\n)\n\nfig.show()\nfig_name = 'treemap_shared_direct_taboola'\nfig.write_html(fig_name + '.html')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Focus on Seller Type = Publisher","metadata":{}},{"cell_type":"code","source":"df_plt = df_pools[\n    (df_pools['pool_size'] > 1_000) & \n    (df_pools['seller_type'].isin(['publisher']))\n]\ndf_tree = get_plot_data(df_plt, root_name='root')\ncustomdata = df_tree[['seller_type', 'seller_name', 'seller_domain']].values\n\nfig = make_subplots(\n    rows=2, cols=4,\n    row_heights = [0.08, 0.92],\n    vertical_spacing = 0.02,\n    specs = [\n        [None, {'type': 'treemap', 'colspan': 2}, None, None], \n        [{'type': 'treemap', 'colspan': 4}, None, None, None],\n    ]\n)\n\nfig.add_trace(lgnd_treemap, row=1, col=2)\nfig.add_trace(go.Treemap(\n    labels = df_tree['labels'],\n    parents = df_tree['parents'],\n    values = df_tree['values'],\n    marker_colors = df_tree['marker_colors'],\n    text = df_tree['text'],\n    customdata = customdata,\n    branchvalues = 'total',\n    hovertemplate = hovertemplate, \n    texttemplate = '%{text}',\n    insidetextfont = {'size': 16},\n    outsidetextfont = {\"size\": 16},\n    name = '',\n), row=2, col=1)\n\nfig.update_layout(\n    height=1200,\n    margin=margin,\n)\n\nfig.show()\nfig_name = 'treemap_shared_direct_pub'\nfig.write_html(fig_name + '.html')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Focus on Breibart and RT","metadata":{}},{"cell_type":"code","source":"m1 = df_direct['host_domain'] == 'breitbart.com'\nm2 = df_direct['host_domain'] == 'rt.com'\ndf_tmp = df_direct[m1 | m2].groupby('seller_tag').size().to_frame('count').sort_values('count', ascending=False).reset_index()\ndf_tmp = df_tmp[df_tmp['count'] > 1]\ndf_plt = df_pools[df_pools['seller_tag'].isin(df_tmp['seller_tag'])]\n\ndf_tree = get_plot_data(df_plt, root_name='root')\ncustomdata = df_tree[['seller_type', 'seller_name', 'seller_domain']].values\n\nfig = make_subplots(\n    rows=2, cols=4,\n    row_heights = [0.08, 0.92],\n    vertical_spacing = 0.02,\n    specs = [\n        [None, {'type': 'treemap', 'colspan': 2}, None, None], \n        [{'type': 'treemap', 'colspan': 4}, None, None, None],\n    ]\n)\n\nfig.add_trace(lgnd_treemap, row=1, col=2)\nfig.add_trace(go.Treemap(\n    labels = df_tree['labels'],\n    parents = df_tree['parents'],\n    values = df_tree['values'],\n    marker_colors = df_tree['marker_colors'],\n    text = df_tree['text'],\n    customdata = customdata,\n    branchvalues = 'total',\n    hovertemplate = hovertemplate, \n    texttemplate = '%{text}',\n    insidetextfont = {'size': 16},\n    outsidetextfont = {\"size\": 16},\n    name = '',\n), row=2, col=1)\n\nfig.update_layout(\n    height=1200,\n    margin=margin,\n)\n\nfig.show()\nfig_name = 'treemap_shared_direct_breitbart_rt'\nfig.write_html(fig_name + '.html')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}