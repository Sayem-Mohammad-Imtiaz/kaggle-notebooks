{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\nWe show in this Kernel how we can process the data to prepare it for easier processing. Let's check the data files.","metadata":{"papermill":{"duration":0.016514,"end_time":"2021-06-27T10:51:13.055481","exception":false,"start_time":"2021-06-27T10:51:13.038967","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"papermill":{"duration":0.040165,"end_time":"2021-06-27T10:51:13.113222","exception":false,"start_time":"2021-06-27T10:51:13.073057","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-05T13:27:50.64207Z","iopub.execute_input":"2021-07-05T13:27:50.642798Z","iopub.status.idle":"2021-07-05T13:27:50.661843Z","shell.execute_reply.started":"2021-07-05T13:27:50.642675Z","shell.execute_reply":"2021-07-05T13:27:50.660606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analysis preparation\n\n## Load packages","metadata":{"papermill":{"duration":0.015753,"end_time":"2021-06-27T10:51:13.147286","exception":false,"start_time":"2021-06-27T10:51:13.131533","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pandas as pd","metadata":{"papermill":{"duration":0.023042,"end_time":"2021-06-27T10:51:13.186322","exception":false,"start_time":"2021-06-27T10:51:13.16328","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-05T13:28:46.624211Z","iopub.execute_input":"2021-07-05T13:28:46.624617Z","iopub.status.idle":"2021-07-05T13:28:46.628958Z","shell.execute_reply.started":"2021-07-05T13:28:46.62457Z","shell.execute_reply":"2021-07-05T13:28:46.627855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load the data\n\nThe datafiles are in TSV format. We will read the files using pandas, just include in the function call the `sep` (tab separator data).\nWe demonstrate first how to read and process the Annual data.","metadata":{"papermill":{"duration":0.015424,"end_time":"2021-06-27T10:51:13.217618","exception":false,"start_time":"2021-06-27T10:51:13.202194","status":"completed"},"tags":[]}},{"cell_type":"code","source":"data_df = pd.read_csv(\"/kaggle/input/population-by-education-level-in-europe/lfsa_pgaed.tsv\", sep='\\t')","metadata":{"papermill":{"duration":0.050825,"end_time":"2021-06-27T10:51:13.283813","exception":false,"start_time":"2021-06-27T10:51:13.232988","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-05T13:37:34.340425Z","iopub.execute_input":"2021-07-05T13:37:34.340809Z","iopub.status.idle":"2021-07-05T13:37:34.572113Z","shell.execute_reply.started":"2021-07-05T13:37:34.340768Z","shell.execute_reply":"2021-07-05T13:37:34.571278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's glimpse the data columns.","metadata":{"papermill":{"duration":0.015363,"end_time":"2021-06-27T10:51:13.315104","exception":false,"start_time":"2021-06-27T10:51:13.299741","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print(list(data_df.columns))","metadata":{"papermill":{"duration":0.023964,"end_time":"2021-06-27T10:51:13.354411","exception":false,"start_time":"2021-06-27T10:51:13.330447","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-05T13:37:36.099873Z","iopub.execute_input":"2021-07-05T13:37:36.100251Z","iopub.status.idle":"2021-07-05T13:37:36.105472Z","shell.execute_reply.started":"2021-07-05T13:37:36.100217Z","shell.execute_reply":"2021-07-05T13:37:36.104419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The first column is a composed one, containing 5 different information (unit, sex, age, isced-11 education attainment levels classification and geography). The next columns are the year value, from last (2020) to first (1983).","metadata":{"papermill":{"duration":0.016682,"end_time":"2021-06-27T10:51:13.387624","exception":false,"start_time":"2021-06-27T10:51:13.370942","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Data pre-processing\n\nWe start by defining two working lists.","metadata":{"papermill":{"duration":0.016181,"end_time":"2021-06-27T10:51:13.420397","exception":false,"start_time":"2021-06-27T10:51:13.404216","status":"completed"},"tags":[]}},{"cell_type":"code","source":"pivot_data_col = data_df.columns[0]\ntime_columns = data_df.columns[1:]","metadata":{"papermill":{"duration":0.023812,"end_time":"2021-06-27T10:51:13.460363","exception":false,"start_time":"2021-06-27T10:51:13.436551","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-05T13:37:38.375561Z","iopub.execute_input":"2021-07-05T13:37:38.37594Z","iopub.status.idle":"2021-07-05T13:37:38.380347Z","shell.execute_reply.started":"2021-07-05T13:37:38.375907Z","shell.execute_reply":"2021-07-05T13:37:38.37936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then, we split from `pivot_data_col` the 3 separate fields:\n* unit;\n* sex;\n* age (this is age group actually);\n* isced11 - ISCED-11 education attainment level classification;\n* geography (countries and Euro country groups).","metadata":{"papermill":{"duration":0.015016,"end_time":"2021-06-27T10:51:13.491366","exception":false,"start_time":"2021-06-27T10:51:13.47635","status":"completed"},"tags":[]}},{"cell_type":"code","source":"data_df['unit'] = data_df[pivot_data_col].apply(lambda x: x.split(\",\")[0])\ndata_df['sex']     = data_df[pivot_data_col].apply(lambda x: x.split(\",\")[1])\ndata_df['age'] = data_df[pivot_data_col].apply(lambda x: x.split(\",\")[2])\ndata_df['isced11'] = data_df[pivot_data_col].apply(lambda x: x.split(\",\")[3])\ndata_df['geography'] = data_df[pivot_data_col].apply(lambda x: x.split(\",\")[4])","metadata":{"papermill":{"duration":0.041236,"end_time":"2021-06-27T10:51:13.549451","exception":false,"start_time":"2021-06-27T10:51:13.508215","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-05T13:37:41.388525Z","iopub.execute_input":"2021-07-05T13:37:41.388859Z","iopub.status.idle":"2021-07-05T13:37:41.448442Z","shell.execute_reply.started":"2021-07-05T13:37:41.388832Z","shell.execute_reply":"2021-07-05T13:37:41.447329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We select now only the new columns resulted from splitting the `pivot_data_col` and the time columns.","metadata":{"papermill":{"duration":0.015361,"end_time":"2021-06-27T10:51:13.581863","exception":false,"start_time":"2021-06-27T10:51:13.566502","status":"completed"},"tags":[]}},{"cell_type":"code","source":"selected_columns = list(['unit', 'sex', 'age', 'isced11', 'geography']) +  list(time_columns)\ndata_df = data_df[selected_columns]","metadata":{"papermill":{"duration":0.031068,"end_time":"2021-06-27T10:51:13.628504","exception":false,"start_time":"2021-06-27T10:51:13.597436","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-05T13:37:43.91645Z","iopub.execute_input":"2021-07-05T13:37:43.916779Z","iopub.status.idle":"2021-07-05T13:37:43.946416Z","shell.execute_reply.started":"2021-07-05T13:37:43.916753Z","shell.execute_reply":"2021-07-05T13:37:43.945417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, we pivot the time columns using `melt` operation in pandas.  \nWe also make sure we transform `date` to be an integer (here is a year data).  \nWe set `value` to be a float, after we replace \": \" (for N/A) with `NAN`.","metadata":{"papermill":{"duration":0.017163,"end_time":"2021-06-27T10:51:13.661992","exception":false,"start_time":"2021-06-27T10:51:13.644829","status":"completed"},"tags":[]}},{"cell_type":"code","source":"data_tr_df = data_df.melt(id_vars=['unit', 'sex', 'age', 'isced11', 'geography'], \n        var_name=\"date\", \n        value_name=\"value\")\ndata_tr_df['date'] = data_tr_df['date'].apply(lambda x: int(x))\ndata_tr_df['value'] = data_tr_df['value'].apply(lambda x: str(x).replace(\"bp\", \"\"))\ndata_tr_df['value'] = data_tr_df['value'].apply(lambda x: str(x).replace(\"b\", \"\"))\ndata_tr_df['value'] = data_tr_df['value'].apply(lambda x: str(x).replace(\"u\", \"\"))\ndata_tr_df['value'] = data_tr_df['value'].apply(lambda x: str(x).replace(\"c\", \"\"))\ndata_tr_df['value'] = data_tr_df['value'].apply(lambda x: str(x).replace(\"d\", \"\"))\ndata_tr_df['value'] = data_tr_df['value'].apply(lambda x: str(x).replace(\": \", \"NAN\"))\ndata_tr_df['value'] = data_tr_df['value'].apply(lambda x: float(x))","metadata":{"papermill":{"duration":0.064873,"end_time":"2021-06-27T10:51:13.743772","exception":false,"start_time":"2021-06-27T10:51:13.678899","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-05T13:38:03.022559Z","iopub.execute_input":"2021-07-05T13:38:03.02294Z","iopub.status.idle":"2021-07-05T13:38:06.394043Z","shell.execute_reply.started":"2021-07-05T13:38:03.022908Z","shell.execute_reply":"2021-07-05T13:38:06.390485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's inspect the result.","metadata":{"papermill":{"duration":0.016165,"end_time":"2021-06-27T10:51:13.775517","exception":false,"start_time":"2021-06-27T10:51:13.759352","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print(f\"Transformed data shape: {data_tr_df.shape} (rows/columns)\")\ndata_tr_df.head()","metadata":{"papermill":{"duration":0.042561,"end_time":"2021-06-27T10:51:13.835815","exception":false,"start_time":"2021-06-27T10:51:13.793254","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-05T13:38:18.668852Z","iopub.execute_input":"2021-07-05T13:38:18.669247Z","iopub.status.idle":"2021-07-05T13:38:18.695766Z","shell.execute_reply.started":"2021-07-05T13:38:18.669207Z","shell.execute_reply":"2021-07-05T13:38:18.694625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_tr_df.tail()","metadata":{"papermill":{"duration":0.033099,"end_time":"2021-06-27T10:51:13.885605","exception":false,"start_time":"2021-06-27T10:51:13.852506","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-05T13:38:22.212751Z","iopub.execute_input":"2021-07-05T13:38:22.213109Z","iopub.status.idle":"2021-07-05T13:38:22.228634Z","shell.execute_reply.started":"2021-07-05T13:38:22.213081Z","shell.execute_reply":"2021-07-05T13:38:22.227482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# A very preliminary exploratory data analysis\n\nThis would be a very short exploratory data analysis. The role of this Kernel is just to show how we can prepare the annual data for analysis and we already did this.","metadata":{"papermill":{"duration":0.016814,"end_time":"2021-06-27T10:51:13.919968","exception":false,"start_time":"2021-06-27T10:51:13.903154","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pandas_profiling\npandas_profiling.ProfileReport(data_tr_df)","metadata":{"papermill":{"duration":11.995252,"end_time":"2021-06-27T10:51:25.932187","exception":false,"start_time":"2021-06-27T10:51:13.936935","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-05T13:38:27.496597Z","iopub.execute_input":"2021-07-05T13:38:27.497168Z","iopub.status.idle":"2021-07-05T13:38:56.6586Z","shell.execute_reply.started":"2021-07-05T13:38:27.497132Z","shell.execute_reply":"2021-07-05T13:38:56.65768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Export data in csv format","metadata":{}},{"cell_type":"code","source":"data_tr_df.to_csv(\"population_by_education_level.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]}]}