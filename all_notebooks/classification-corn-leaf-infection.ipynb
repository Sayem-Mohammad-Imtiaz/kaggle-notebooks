{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n    break\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"root_dir = \"/kaggle/input/corn-leaf-infection-dataset/Corn Disease detection\"\nos.listdir(root_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPool2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hyper parameters\nbatch_size = 32\nimg_height, img_width=128,128\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2) # set validation split\n\ntrain_generator = train_datagen.flow_from_directory(\n    root_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training') # set as training data\n\nvalidation_generator = train_datagen.flow_from_directory(\n    root_dir, # same directory as training data\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation') # set as validation data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_generator[0][1][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show(img, title=None, fig_size=(5, 5)):\n    fig = plt.figure(figsize=fig_size)\n    if title is not None:\n        plt.title(title)\n    plt.imshow(img)\n    plt.axis(\"off\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nplt.style.use('seaborn-whitegrid')\nfor i in range(3):\n    labels = [\"Normal\", \"Infected\"]\n    img = validation_generator[0][0][i]\n    lbl = labels[np.argmax(validation_generator[0][1][i])]\n    \n    img = cv2.resize(img, (img_height, img_width))\n    img = img.reshape(img_height, img_width, 3)\n    show(img, title=lbl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.inception_resnet_v2 import preprocess_input, InceptionResNetV2\nfrom keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input\nfrom keras.models import Model\n\nimg_input = Input(shape=(img_height, img_width, 3), name = 'grayscale_input_layer')\n# x = Conv2D(3, (3,3),  padding= 'same', name = 'grayscale_RGB_layer')(img_input)\ninception = InceptionResNetV2(input_shape = (img_height, img_width, 3), include_top = False, weights = 'imagenet')\ninception.layers.pop()  # Remove classification layer\n\nfor layer in inception.layers:\n    layer.trainable = False\n    if type(layer) == 'BatchNormalization':\n        layer.momentum = 1.0\n\ninception = inception(img_input)\noutput = inception\noutput = GlobalAveragePooling2D()(output)\n\noutput = Dropout(0.5)(output)\noutput = Dense(2, activation=\"softmax\")(output) \nmodel = Model(inputs=[img_input], outputs=[output], name='embedding_model')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr=1e-03\nepochs=15\n\nopt = Adam(lr=lr, decay=lr / epochs)\n\n# compile it !\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt,\tmetrics=[\"accuracy\"])\n\n# train it\nhistory=model.fit_generator(\n\ttrain_generator,\n\tsteps_per_epoch=len(train_generator),\n\tvalidation_data=validation_generator,\n\tvalidation_steps=len(validation_generator),\n\tepochs=epochs,\n  verbose=1,\n\tworkers=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\n\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}