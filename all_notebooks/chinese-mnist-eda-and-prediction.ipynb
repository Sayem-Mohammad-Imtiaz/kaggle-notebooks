{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"cell_type":"markdown","source":"<h1><center><font size=\"6\">Chinese MNIST EDA and Prediction</font></center></h1>\n\n![](https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F769452%2Ffae77a81c057fe419de60f5e2b20be25%2Fchinese_mnist_profile_small.png?generation=1596963542354014&alt=media)\n \n\n# <a id='0'>Content</a>\n\n- <a href='#1'>Introduction</a>  \n- <a href='#2'>Prepare the data analysis</a>  \n - <a href='#21'>Load packages</a>  \n - <a href='#21'>Load the data</a>  \n - <a href='#21'>Preprocessing data</a>  \n- <a href='#3'>Data exploration</a>   \n - <a href='#31'>Check for missing data</a>  \n - <a href='#32'>Explore image data</a>  \n  - <a href='#33'>Suites</a>  \n- <a href='#4'>Characters classification</a>  \n - <a href='#40'>Split the data</a>  \n - <a href='#41'>Build a baseline model</a>  \n - <a href='#42'>Model evaluation</a>    \n - <a href='#43'>Add Dropout</a>  \n - <a href='#44'>Model refinement</a>  \n- <a href='#6'>Conclusions</a>    \n- <a href='#7'>References</a>    ","execution_count":null},{"metadata":{"_uuid":"a8e77ace65f04c89a878bf18249e4d8e23fec996"},"cell_type":"markdown","source":"# <a id='1'>Introduction</a>  \n\n\nIn this Kernel, we will explore a dataset with adnotated images of Chinese numbers, handwritten by a number of 100 volunteers, each providing a number of 10 samples, each sample with a complete set of 15 Chinese characters for numbers.\n\nThe Chinese characters are the following:\n* 零 - for 0  \n* 一 - for 1\n* 二 - for 2  \n* 三 - for 3  \n* 四 - for 4  \n* 五 - for 5  \n* 六 - for 6  \n* 七 - for 7  \n* 八 - for 8  \n* 九 - for 9  \n* 十 - for 10\n* 百 - for 100\n* 千 - for 1000\n* 万 - for 10 thousands\n* 亿 - for 100 millions\n\n\nThe objective of the Kernel is to take us through the steps of a machine learning analysis.   \nWe start by preparing the analysis (load the libraries and the data), continue with an Exploratory Data Analysis (EDA) where we highlight the data features, spending some time to try to understand the data and also get an idea about various features predictive potential and correlation with other features.   \n\nWe follow then with features engineering and preparation for creation of a model. The dataset is split in training, validation and test set. We start then with a simple model to classify the Chinese numbers images, something we are calling a baseline model.   \n\nWe evaluate the model, estimating the training error and accuracy and also the validation error and accuracy. With these, and with an rough estimate of what will be the (human) error rate for classification of Chinese numbers images, we decide how to follow our machine learning for image classification work. If we have at start a high bias, we will try first to improve our model so that will learn better the train images dataset. If we have a small bias but large variance (the model learns well the training data but fails to generalize, that means our model is overfitting. Based on these kind of observation, we make decission for how to adjust the model.   \n\nWe run few models with the improvements decided based on analysis or error and accuracy and we decide at the end for a final model. This model will be used for classification of fresh, new data, not used for training or validation, the test set.\n\n<a href=\"#0\"><font size=\"1\">Go to top</font></a>  ","execution_count":null},{"metadata":{"_uuid":"4e97555eb77978a29a51c41f39cec67136b18157"},"cell_type":"markdown","source":"# <a id='2'>Prepare the data analysis</a>   \n\n\nBefore starting the analysis, we need to make few preparation: load the packages, load and inspect the data.\n\n","execution_count":null},{"metadata":{"_uuid":"cb2e73fe056a3dda7eb48eeac2facf0c441816d1"},"cell_type":"markdown","source":"# <a id='21'>Load packages</a>\n\nWe load the packages used for the analysis.\n","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"af08260bfbe163f9132f39d09627899bbc4c1dae","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport sys\nimport os\nimport random\nfrom pathlib import Path\nimport imageio\nimport skimage\nimport skimage.io\nimport skimage.transform\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom plotly import tools\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\nimport scipy\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom keras import optimizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout, BatchNormalization,LeakyReLU\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\nfrom keras.utils import to_categorical\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nimport tensorflow","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_uuid":"a2082fb1e56fc6cfc91d40820b905267bc1ca468","trusted":true},"cell_type":"code","source":"IMAGE_PATH = '..//input//chinese-mnist//data//data//'\nIMAGE_WIDTH = 64\nIMAGE_HEIGHT = 64\nIMAGE_CHANNELS = 1\nRANDOM_STATE = 42\nTEST_SIZE = 0.2\nVAL_SIZE = 0.2\nCONV_2D_DIM_1 = 16\nCONV_2D_DIM_2 = 16\nCONV_2D_DIM_3 = 32\nCONV_2D_DIM_4 = 64\nMAX_POOL_DIM = 2\nKERNEL_SIZE = 3\nBATCH_SIZE = 32\nNO_EPOCHS_1 = 5\nNO_EPOCHS_2 = 10\nNO_EPOCHS_3 = 50\nPATIENCE = 5\nVERBOSE = 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"307f656565365ff05faf226e5a447875dd0dfead"},"cell_type":"markdown","source":"<a href=\"#0\"><font size=\"1\">Go to top</font></a>  \n\n\n# <a id='22'>Load the data</a>  \n\nLet's see first what data files do we have in the root directory.","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"9f1df6658b17558179d8a9016f544410de16c354","trusted":true},"cell_type":"code","source":"os.listdir(\"..//input//chinese-mnist\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"241b8735a85a25e16421fda8c35bc3d3c69e7ea8"},"cell_type":"markdown","source":"There is a dataset file and a folder with images.  \n\nLet's load the dataset file first.","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"d7b9f11a014428e56e422d97a5b3ef70efec007e","trusted":true},"cell_type":"code","source":"data_df=pd.read_csv('..//input//chinese-mnist//chinese_mnist.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22b3984ccc3e29daaf77a796d9d7966cd798e1a8"},"cell_type":"markdown","source":"Let's glimpse the data. First, let's check the number of columns and rows.","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"535f3f9cea3b26428bec3ede4ed49009bdb91889","trusted":true},"cell_type":"code","source":"data_df.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b4405ddcce03ee722f05234d508188997817f8d"},"cell_type":"markdown","source":"There are 15000 rows and 5 columns. Let's look to the data.","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"4d326f747f0a14580b20c2e034e6c3368edcd18b","trusted":true},"cell_type":"code","source":"data_df.sample(100).head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c97047b17cda76e346e444229485ac91ec966423"},"cell_type":"markdown","source":"The data contains the following values:  \n\n* suite_id - each suite corresponds to a set of handwritten samples by one volunteer;  \n* sample_id - each sample wil contain a complete set of 15 characters for Chinese numbers;\n* code - for each Chinese character we are using a code, with values from 1 to 15;\n* value - this is the actual numerical value associated with the Chinese character for number;  \n* character - the Chinese character;  \n\nWe index the files in the dataset by forming a file name from suite_id, sample_id and code. The pattern for a file is as following:\n\n> \"input_{suite_id}_{sample_id}_{code}.jpg\"","execution_count":null},{"metadata":{"_uuid":"55dd26f919decca9d67daec9895a5d9e11f1d28b"},"cell_type":"markdown","source":"<a href=\"#0\"><font size=\"1\">Go to top</font></a>  \n\n# <a id='3'>Data exploration</a>  \n\n\n\nLet's start by checking if there are missing data, unlabeled data or data that is inconsistently labeled. \n","execution_count":null},{"metadata":{"_uuid":"14443450ba96e12ad8e18ce4dd1779f18d5f914b"},"cell_type":"markdown","source":"## <a id='31'>Check for missing data</a>  \n\nLet's create a function that check for missing data in the dataset.","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"4544dd470d743c54f815faaee863038ad5e8398f","trusted":true},"cell_type":"code","source":"def missing_data(data):\n    total = data.isnull().sum().sort_values(ascending = False)\n    percent = (data.isnull().sum()/data.isnull().count()*100).sort_values(ascending = False)\n    return pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data(data_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3cb0410e8b9afd75ac7b50d0489d90eda6e1b109"},"cell_type":"markdown","source":"There is no missing (null) data in the dataset. Still it might be that some of the data labels are misspelled; we will check this when we will analyze each data feature.","execution_count":null},{"metadata":{"_uuid":"1fbab44688fb2ab073aac8f964e534f90ce1dfff"},"cell_type":"markdown","source":"<a href=\"#0\"><font size=\"1\">Go to top</font></a>  \n\n## <a id='32'>Explore image data</a>  \n\nLet's also check the image data. First, we check how many images are stored in the image folder.","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"46f15681887fa82ab13224e52df69d91119fc9ad","trusted":true},"cell_type":"code","source":"image_files = list(os.listdir(IMAGE_PATH))\nprint(\"Number of image files: {}\".format(len(image_files)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"68523860593e9a64059b51d40a316454e6937a68"},"cell_type":"markdown","source":"Let's also check that each line in the dataset has a corresponding image in the image list.  \nFirst, we will have to compose the name of the file from the indexes.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_file_name(x):\n    \n    file_name = f\"input_{x[0]}_{x[1]}_{x[2]}.jpg\"\n    return file_name","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"data_df[\"file\"] = data_df.apply(create_file_name, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_uuid":"457cd17212904bb96f86ec1770cbdbefc5ffb395","trusted":true},"cell_type":"code","source":"file_names = list(data_df['file'])\nprint(\"Matching image names: {}\".format(len(set(file_names).intersection(image_files))))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b20cd791ede3f23d0c9275aafc75827b9424df4"},"cell_type":"markdown","source":"Let's also check the image sizes.","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"64f4416a8e20197d60f7dbc9dd41a5e73049bfd0","trusted":true},"cell_type":"code","source":"def read_image_sizes(file_name):\n    image = skimage.io.imread(IMAGE_PATH + file_name)\n    return list(image.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c72a7d125efb51e00a58554692dbd99adc74b55","trusted":true},"cell_type":"code","source":"m = np.stack(data_df['file'].apply(read_image_sizes))\ndf = pd.DataFrame(m,columns=['w','h'])\ndata_df = pd.concat([data_df,df],axis=1, sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a2b88af0c239ca3d9e37e159889836a4f38913c8"},"cell_type":"markdown","source":"## <a id='33'>Suites</a>  \n\nLet's check the suites of the images. For this, we will group by `suite`.","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"6f1c39d0398275215f92f61542544132a0d574a0","trusted":true},"cell_type":"code","source":"print(f\"Number of suites: {data_df.suite_id.nunique()}\")\nprint(f\"Samples: {data_df.sample_id.unique()}\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fd421a7d1872af204c26588d1a15eaddca08a396"},"cell_type":"markdown","source":"We have 100 suites, each with 10 samples.","execution_count":null},{"metadata":{"_uuid":"c2a5e2401b418f1723c859ee9e0b4ad5071e4a82"},"cell_type":"markdown","source":"# <a id='4'>Characters classification</a>\n\nOur objective is to use the images that we investigated until now to correctly identify the Chinese numbers (characters).   \n\nWe have a unique dataset and we will have to split this dataset in **train** and **test**. The **train** set will be used for training a model and the test will be used for testing the model accuracy against new, fresh data, not used in training.\n\n","execution_count":null},{"metadata":{"_uuid":"e8c0a6df4bb85bcdf90f7c908decab07304d660f"},"cell_type":"markdown","source":"## <a id='40'>Split the data</a>  \n\nFirst, we split the whole dataset in train and test. We will use **random_state** to ensure reproductibility of results.   \n\nThe train-test split is **80%** for training set and **20%** for test set.\n","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"352d452d5212d8c9eff074f11820b03a0d44387b","trusted":true},"cell_type":"code","source":"train_df, test_df = train_test_split(data_df, test_size=TEST_SIZE, random_state=RANDOM_STATE)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"856060cc500db00e472b7755c91aba20c953a5f6"},"cell_type":"markdown","source":"Next, we will split further the **train** set in **train** and **validation**. We want to use as well a validation set to be able to measure not only how well fits the model the train data during training (or how well `learns` the training data) but also how well the model is able to generalize so that we are able to understands not only the bias but also the variance of the model.  \n\nThe train-validation split is **80%** for training set and **20%** for validation set.","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"83d0be04ae5a4ad5834631bf18e21917d6313bcd","trusted":true},"cell_type":"code","source":"train_df, val_df = train_test_split(train_df, test_size=VAL_SIZE, random_state=RANDOM_STATE)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_uuid":"0dcaa8c2c5423ab8fc2898d4a4aa937801592c2c"},"cell_type":"markdown","source":"Let's check the shape of the three datasets.","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"8247f70b4deb4600fe322f004733234ed37617f0","trusted":true},"cell_type":"code","source":"print(\"Train set rows: {}\".format(train_df.shape[0]))\nprint(\"Test  set rows: {}\".format(test_df.shape[0]))\nprint(\"Val   set rows: {}\".format(val_df.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_count(feature, title, df, size=1):\n    f, ax = plt.subplots(1,1, figsize=(4*size,4))\n    total = float(len(df))\n    g = sns.countplot(df[feature], order = df[feature].value_counts().index[:20], palette='Set3')\n    g.set_title(\"Number and percentage of {}\".format(title))\n    if(size > 2):\n        plt.xticks(rotation=90, size=8)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()/2.,\n                height + 3,\n                '{:1.2f}%'.format(100*height/total),\n                ha=\"center\") \n    plt.show()    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count(\"value\", \"value (train data)\", train_df, size=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count(\"value\", \"value (validation data)\", val_df, size=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count(\"value\", \"value (test data)\", test_df, size=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Note**:  Training, validation and test data are slightly unbalanced. We can improve on this part, if we use a different train-test split approach, imposing to have balanced distribution in the splits, based on the label feature. Let's do it now.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df, test_df = train_test_split(data_df, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=data_df[\"code\"].values)\ntrain_df, val_df = train_test_split(train_df, test_size=VAL_SIZE, random_state=RANDOM_STATE, stratify=train_df[\"code\"].values)\nprint(\"Train set rows: {}\".format(train_df.shape[0]))\nprint(\"Test  set rows: {}\".format(test_df.shape[0]))\nprint(\"Val   set rows: {}\".format(val_df.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count(\"value\", \"value (train data)\", train_df, size=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count(\"value\", \"value (validation data)\", val_df, size=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_count(\"value\", \"value (test data)\", test_df, size=3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee768c083f40fcbd109425182bc55ce86173b69d"},"cell_type":"markdown","source":"Now, using `stratify` option, we also balanced train, validation and test set with respect with the classes distribution.  \nWe are now ready to start building our first model.","execution_count":null},{"metadata":{"_uuid":"d76e822dd76565d29fcfed323cb034939f307581"},"cell_type":"markdown","source":"## <a id='41'>Build a baseline model</a>    \n\n\nNext step in our creation of a predictive model is to create a simple model, a **baseline model**.  \n\n Why start with a simple model (as simple as possible, but not simpler :-) )?\n \n With a simple model, we can get fast insight in how well will the data predict our target value. Looking to the training results (the training error and accuracy, the validation error and accuracy), we can understand if we need to add more data (because the training accuracy is small) or if we need to optimize the model (by adding more convolutional layers) or if we need to add Dropout layers (because the validation error is increasing after few steps - the model is overfitting) etc.\n \nLet's define few auxiliary functions that we will need for creation of our models.","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"f80b4e20e98ce5bf328fba3a22457c4a994de06b","trusted":true},"cell_type":"code","source":"def read_image(file_name):\n    image = skimage.io.imread(IMAGE_PATH + file_name)\n    image = skimage.transform.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT, 1), mode='reflect')\n    return image[:,:,:]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e396e0cd23633af2169e4d50985f1987654205a9"},"cell_type":"markdown","source":"A function to create the dummy variables corresponding to the categorical target variable.","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"0f7a2146ca93aef9367ecd64300980005d89911b","trusted":true},"cell_type":"code","source":"def categories_encoder(dataset, var='character'):\n    X = np.stack(dataset['file'].apply(read_image))\n    y = pd.get_dummies(dataset[var], drop_first=False)\n    return X, y","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_uuid":"b40c205d5189b23cbbc4ef0cda8798721d504ff9"},"cell_type":"markdown","source":"Let's populate now the train, val and test sets with the image data and create the  dummy variables corresponding to the categorical target variable, in our case `subspecies`.","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"70acefcd6dc5d494b1c7db6dc90bae5f8c856d94","trusted":true},"cell_type":"code","source":"X_train, y_train = categories_encoder(train_df)\nX_val, y_val = categories_encoder(val_df)\nX_test, y_test = categories_encoder(test_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5093354dc9c7f0510ba54a254690db45e38d0bcc"},"cell_type":"markdown","source":"Now we are ready to start creating our model.  \n\nWe will add the folllowing elements to our model: \n* One convolutional layer, with 16 filters of dimmension 3;  \n* One maxpoll2d layer, with reduction factor 2;  \n* One convolutional layer, with 16 filters of dimmension 3;  \n* A flatten layer;  \n* A dense layer;  ","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"bd7147baf9c45217988df92cf631202684fb3609","trusted":true},"cell_type":"code","source":"model1=Sequential()\nmodel1.add(Conv2D(CONV_2D_DIM_1, kernel_size=KERNEL_SIZE, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 1), activation='relu', padding='same'))\nmodel1.add(MaxPool2D(MAX_POOL_DIM))\nmodel1.add(Conv2D(CONV_2D_DIM_2, kernel_size=KERNEL_SIZE, activation='relu', padding='same'))\nmodel1.add(Flatten())\nmodel1.add(Dense(y_train.columns.size, activation='softmax'))\nmodel1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_uuid":"046612eda2408801ded03cc6a5e2357a99298969","trusted":true},"cell_type":"code","source":"model1.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0149020f748dc9eaa89ebf732829031d6d9d35a2"},"cell_type":"markdown","source":"We train the first model using and a predefined batch size. We are using the predefined epoch number for this first experiment (5 steps) and as well validation, using the validation set. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model1 = model1.fit(X_train, y_train,\n                  batch_size=BATCH_SIZE,\n                  epochs=NO_EPOCHS_1,\n                  verbose=1,\n                  validation_data=(X_val, y_val))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5837b3e9cb131fab2c58f4b9de92f147f48b59ae"},"cell_type":"markdown","source":"<a href=\"#0\"><font size=\"1\">Go to top</font></a>  \n\n\n## <a id='42'>Model evaluation</a> \n\n\nLet's start by plotting the loss error for the train and validation set. \nWe define a function to visualize these values.","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"a87e3beea44a87a806893b798a38d26904d10718","trusted":true},"cell_type":"code","source":"def create_trace(x,y,ylabel,color):\n        trace = go.Scatter(\n            x = x,y = y,\n            name=ylabel,\n            marker=dict(color=color),\n            mode = \"markers+lines\",\n            text=x\n        )\n        return trace\n    \ndef plot_accuracy_and_loss(train_model):\n    hist = train_model.history\n    acc = hist['accuracy']\n    val_acc = hist['val_accuracy']\n    loss = hist['loss']\n    val_loss = hist['val_loss']\n    epochs = list(range(1,len(acc)+1))\n    #define the traces\n    trace_ta = create_trace(epochs,acc,\"Training accuracy\", \"Green\")\n    trace_va = create_trace(epochs,val_acc,\"Validation accuracy\", \"Red\")\n    trace_tl = create_trace(epochs,loss,\"Training loss\", \"Blue\")\n    trace_vl = create_trace(epochs,val_loss,\"Validation loss\", \"Magenta\")\n    fig = tools.make_subplots(rows=1,cols=2, subplot_titles=('Training and validation accuracy',\n                                                             'Training and validation loss'))\n    #add traces to the figure\n    fig.append_trace(trace_ta,1,1)\n    fig.append_trace(trace_va,1,1)\n    fig.append_trace(trace_tl,1,2)\n    fig.append_trace(trace_vl,1,2)\n    #set the layout for the figure\n    fig['layout']['xaxis'].update(title = 'Epoch')\n    fig['layout']['xaxis2'].update(title = 'Epoch')\n    fig['layout']['yaxis'].update(title = 'Accuracy', range=[0,1])\n    fig['layout']['yaxis2'].update(title = 'Loss', range=[0,1])\n    #plot\n    iplot(fig, filename='accuracy-loss')\n\nplot_accuracy_and_loss(train_model1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a77c0127288f090233e70831e6b909c1618efa35"},"cell_type":"markdown","source":"\nLet's continue by evaluating the **test** set **loss** and **accuracy**. We will use here the test set.","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"1f54e33fcba0e3054d364f35a22f69ef350e8e0d","trusted":true},"cell_type":"code","source":"score = model1.evaluate(X_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"46cd7e86e92ac2ec484f0c38c451465cc16a2736"},"cell_type":"markdown","source":"Let's check also the test accuracy per class.","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"55e96cfdaf488df5bc3d5511fa062563926227ad","trusted":true},"cell_type":"code","source":"def test_accuracy_report(model):\n    predicted = model.predict(X_test)\n    test_predicted = np.argmax(predicted, axis=1)\n    test_truth = np.argmax(y_test.values, axis=1)\n    print(metrics.classification_report(test_truth, test_predicted, target_names=y_test.columns)) \n    test_res = model.evaluate(X_test, y_test.values, verbose=0)\n    print('Loss function: %s, accuracy:' % test_res[0], test_res[1])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_uuid":"68c06c36ae2f89e070c878bf5f660e765d23878b","trusted":true},"cell_type":"code","source":"test_accuracy_report(model1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"28293f20eb559420e61e052397bd998fe6e6ff05"},"cell_type":"markdown","source":"We used a simple model. We separated 20% of the data for testing. From the training data, 80% is used for actual training and 20% for testing.   \n\nAdding additional data will only slightly increase the accuracy of the training set (it is already very good).   \nTo reduce the loss of the validation set (which is a sign of overfitting), we can have three strategies:  \n* add Dropout layers;  \n* introduce strides;  \n* modify the learning rate during the training;  \n","execution_count":null},{"metadata":{"_uuid":"74de02a417db465b77495147c810911d81f491a9"},"cell_type":"markdown","source":"<a href=\"#0\"><font size=\"1\">Go to top</font></a>  \n\n\n## <a id='43'>Add Dropout</a>  \n\nWe add two Dropout layers.  The role of the Dropout layers is to reduce the overfitting, by dropping, each training epoch, a certain percent of the nodes connections (by rotation). This is equivalent of using less training data and in the same time training the network with various data as well as using `parallel` alternative networks, thus reducing the likelihood that the network will overfit the train data.  \n\nThe definition of the second model is:","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"ca30aceff3500c10383761962a7908f0b2b558f3","trusted":true},"cell_type":"code","source":"model2=Sequential()\nmodel2.add(Conv2D(CONV_2D_DIM_1, kernel_size=KERNEL_SIZE, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT,IMAGE_CHANNELS), activation='relu', padding='same'))\nmodel2.add(MaxPool2D(MAX_POOL_DIM))\n# Add dropouts to the model\nmodel2.add(Dropout(0.4))\nmodel2.add(Conv2D(CONV_2D_DIM_2, kernel_size=KERNEL_SIZE, activation='relu', padding='same'))\n# Add dropouts to the model\nmodel2.add(Dropout(0.4))\nmodel2.add(Flatten())\nmodel2.add(Dense(y_train.columns.size, activation='softmax'))\nmodel2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cff8a87a7e837de5dd0b001ace6249933027d95b"},"cell_type":"markdown","source":"Let's inspect the new model.","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"63dff8b355758d2d55d3e7aff154e9ed6f23d961","trusted":true},"cell_type":"code","source":"model2.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dd8b5497fa489c35d7ff77319f7d05de46186ac1"},"cell_type":"markdown","source":"We can observe that this model has the same number of parameters and trainable parameters as  the previous model.","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"b97e8d966f8a369c4503bffd419d57c1d113bd1b","trusted":true},"cell_type":"code","source":"train_model2  = model2.fit(X_train, y_train,\n                  batch_size=BATCH_SIZE,\n                  epochs=NO_EPOCHS_2,\n                  verbose=1,\n                  validation_data=(X_val, y_val))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2254e9082c703f5744f61bc59018f107aca6757c"},"cell_type":"markdown","source":"### Evaluate model accuracy and loss","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"9a69aeb83cee0c57a2e362349925ff509c7af7ee","trusted":true},"cell_type":"code","source":"plot_accuracy_and_loss(train_model2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dc0fb043121e04f92f1af7d7821b8581cca8c572"},"cell_type":"markdown","source":"### Test accuracy and loss\n\nLet's evaluare as well the test accuracy and loss.","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"19285aa59a4a6dabbf55e81ebdc235ef50c46411","trusted":true},"cell_type":"code","source":"test_accuracy_report(model2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"349c34acbba6d761b959a0a7a5b31df9abdf722b"},"cell_type":"markdown","source":"<a href=\"#0\"><font size=\"1\">Go to top</font></a>  \n\n## <a id='45'>Model refinement</a>  \n\n\nWe define now also a refined model. \n\nWe add an early stopping condition (monitor the loss error and stops the training if for a number of stept given in the `patience` parameters the loss is not improving).\n\nWe are also saving a model checkpoint after each epoch when accuracy improves; if accuracy degrades, no new model is saved. Thus, Model Checkpoint saves all the time the best model in terms of accuracy.  \n\nWe adjust as well the learning rate with the training epochs.\n\nAlso, we increase the number of training epochs to 50.\n\n","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"deb1e2d4ced60d163ae5257830a3b60dc2d8fc0f","trusted":true},"cell_type":"code","source":"annealer3 = LearningRateScheduler(lambda x: 1e-3 * 0.995 ** (x+NO_EPOCHS_3))\nearlystopper3 = EarlyStopping(monitor='loss', patience=PATIENCE, verbose=VERBOSE)\ncheckpointer3 = ModelCheckpoint('best_model_3.h5',\n                                monitor='val_acc',\n                                verbose=VERBOSE,\n                                save_best_only=True,\n                                save_weights_only=True)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_uuid":"83da1405441c237be0537abd81baf8f90638ce40","trusted":true},"cell_type":"code","source":"model3=Sequential()\nmodel3.add(Conv2D(CONV_2D_DIM_1, kernel_size=KERNEL_SIZE, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT,IMAGE_CHANNELS), activation='relu', padding='same'))\nmodel3.add(MaxPool2D(MAX_POOL_DIM))\n# Add dropouts to the model\nmodel3.add(Dropout(0.4))\nmodel3.add(Conv2D(CONV_2D_DIM_2, kernel_size=KERNEL_SIZE, activation='relu', padding='same'))\n# Add dropouts to the model\nmodel3.add(Dropout(0.4))\nmodel3.add(Flatten())\nmodel3.add(Dense(y_train.columns.size, activation='softmax'))\nmodel3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"66c5f7c6d62ee01b17b85960456f7b0502415aa8"},"cell_type":"markdown","source":"Let's inspect the refined model.","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"b521fad3c6db559e77eeee1147f0b7a02fd91a13","trusted":true},"cell_type":"code","source":"model3.summary()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_uuid":"c773e443457fb4999513b5d0eb7d2454bae419e7"},"cell_type":"markdown","source":"Now, let's train the model.","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"a7ac74a25bed9338906effff9d7df171d7b8b154","scrolled":false,"trusted":true},"cell_type":"code","source":"train_model3  = model3.fit(X_train, y_train,\n                  batch_size=BATCH_SIZE,\n                  epochs=NO_EPOCHS_3,\n                  verbose=1,\n                  validation_data=(X_val, y_val),\n                  callbacks=[earlystopper3, checkpointer3, annealer3])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c1d333286edff47c2452cdd54df91c5ad7959ef7"},"cell_type":"markdown","source":"### Model accuracy and loss","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"8adfacee0f01e584915a712f0501c105287e70dc","trusted":true},"cell_type":"code","source":"plot_accuracy_and_loss(train_model3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c0a45ee7288e16e571110dd134248ec880ccaadc"},"cell_type":"markdown","source":"### Test accuracy and loss","execution_count":null},{"metadata":{"_kg_hide-input":true,"_uuid":"1ad166de21bdd7e097fb73e64ec564b61358a6c1","trusted":true},"cell_type":"code","source":"test_accuracy_report(model3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd6bd3fba3f98e9775dac4f313371af4701febf3"},"cell_type":"markdown","source":"<a href=\"#0\"><font size=\"1\">Go to top</font></a>  \n\n# <a id='6'>Conclusions</a>  \n\nAfter exploring the data to understand its various features, a baseline model is created.  We start with a baseline model because we want to evaluate first how a simple model performs, what is the precision/accuracy for training, validation and test set. \n\nEvaluation of the baseline model  results for valid set and test set allows us to decide, based on analysis of bias and variance, how to conduct furher our experiments. After the analysis of the baseline solution, we decided that, while the training is good enough, we would like to improve on the variance, thus reducing overfitting.\n\nFrom the possible solutions for overfitting, we choose to add Dropout layers. Adding Dropout layers improve a bit the algorithm performance (reduce overfitting).  \n\nA third model, with adjustable learning rate, early stoping based on validation accuracy measurement. The model is saved every time when validation accuracy improves. Also, the training will stop if after a number of steps the validation accuracy is not improving. With this model, accuracy of prediction for the test set was improved. But looking to the validation loss, we can see we do have a problem - we most probably we still overfit on train data, so we will have to further improve this model.\n\nThe **key lessons learned** from this Kernel are the following:   \n* start by analyzing the data;   \n* follow with a simple baseline model;   \n* refine gradually the model, by making corrections based on the analysis of the (partial) results.\n\n**Note**: we didn't used an accelerator for this Kernel. Therefore, if you want to improve the calculation speed, select to use one accelerator (**GPU**/**TPU**) for your Kernel.\n\n<a href=\"#0\"><font size=\"1\">Go to top</font></a>","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true},"cell_type":"markdown","source":"# <a id='7'>References</a>  \n\n[1] Gabriel Preda, RSNA Pneumonia Detection EDA, https://www.kaggle.com/gpreda/rsna-pneumonia-detection-eda     \n[2] Gabriel Preda, CNN with Tensorflow|Keras for Fashion-MNIST, https://www.kaggle.com/gpreda/cnn-with-tensorflow-keras-for-fashion-mnist    \n[3] DanB, CollinMoris, Deep Learning From Scratch, https://www.kaggle.com/dansbecker/deep-learning-from-scratch  \n[4] DanB, Dropout and Strides for Larger Models, https://www.kaggle.com/dansbecker/dropout-and-strides-for-larger-models  \n[5] BGO, CNN with Keras, https://www.kaggle.com/bugraokcu/cnn-with-keras  \n[6] Dmitri Pukhov, Honey Bee health detection using CNN, https://www.kaggle.com/gpreda/honey-bee-health-detection-with-cnn/notebook     \n[7] Why Dropounts prevent overfitting in Deep Neural Networks, https://medium.com/@vivek.yadav/why-dropouts-prevent-overfitting-in-deep-neural-networks-937e2543a701  \n[8] Dropout: A Simple Way to Prevent Neural Networks from Overfitting, https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf  \n[9] Gabriel Preda, Honey Bee Subspecies Classification, https://www.kaggle.com/gpreda/honey-bee-subspecies-classification  \n<a href=\"#0\"><font size=\"1\">Go to top</font></a>\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}