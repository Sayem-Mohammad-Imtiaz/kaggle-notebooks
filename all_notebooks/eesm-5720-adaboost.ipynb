{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ***Training Support Vector Machines for Multiclass Classification ***","metadata":{"_uuid":"7598684e739d1a55535e9e1a43d0d259f05d4c76","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np\nimport pylab as pl\nimport pandas as pd\nimport matplotlib.pyplot as plt \n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.utils import shuffle\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nfrom sklearn.datasets import load_iris\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.datasets import load_iris\nfrom sklearn.ensemble import AdaBoostClassifier\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load the Train and Test set","metadata":{"_uuid":"33307fccd56232da9374ba513d18959b8c4e9d0f"}},{"cell_type":"code","source":"# train = shuffle(pd.read_csv(\"../input/human-activity-recognition-with-smartphones/train.csv\"))\n# test = shuffle(pd.read_csv(\"../input/human-activity-recognition-with-smartphones/test.csv\"))\ntrain = shuffle(pd.read_csv(\"../input/motion-recog-data-train-test-validation/train.csv\"))\nvalidation = shuffle(pd.read_csv(\"../input/motion-recog-data-train-test-validation/validation.csv\"))\ntest = shuffle(pd.read_csv(\"../input/motion-recog-data-train-test-validation/test11.csv\"))","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check for missing values in the dataset","metadata":{"_uuid":"e993e4190daa3f4a0518ed12cda67a1242329576"}},{"cell_type":"code","source":"print(\"Any missing sample in training set:\",train.isnull().values.any())\nprint(\"Any missing sample in test set:\",validation.isnull().values.any(), \"\\n\")\nprint(\"Any missing sample in test set:\",test.isnull().values.any(), \"\\n\")\n\n","metadata":{"_uuid":"2c1a405bd11dd03fb3c5dc1638123ac731855f48","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Frequency Distribution of the Outome","metadata":{"_uuid":"e1e38202e14cc4aa861a00965bd2bd9a349da2d3"}},{"cell_type":"code","source":"#Frequency distribution of classes\"\ntrain_outcome = pd.crosstab(index=train[\"Activity\"],  # Make a crosstab\n                              columns=\"count\")      # Name the count column\n\ntrain_outcome\n","metadata":{"_uuid":"055e3422bcb69ef382451a43a5a08bdf3c3901f8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing Outcome Distribution ","metadata":{"_uuid":"a21236c02b43101be1cc9d834e86e8459fe8618f"}},{"cell_type":"code","source":"# Visualizing Outcome Distribution \ntemp = train[\"Activity\"].value_counts()\ndf = pd.DataFrame({'labels': temp.index,\n                   'values': temp.values\n                  })\n\n#df.plot(kind='pie',labels='labels',values='values', title='Activity Ditribution',subplots= \"True\")\n\nlabels = df['labels']\nsizes = df['values']\ncolors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral','cyan','lightpink']\npatches, texts = plt.pie(sizes, colors=colors, shadow=True, startangle=90, pctdistance=1.1, labeldistance=1.2)\nplt.legend(patches, labels, loc=\"best\")\nplt.axis('equal')\nplt.tight_layout()\nplt.show()\n","metadata":{"_uuid":"542c5c78e2e73b387712f9149066cf36d8563fae","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Normalize the Predictor(Feature Set) ","metadata":{"_uuid":"9fc1cca22b036f2ac4b90a6b3e8f45e116b24990"}},{"cell_type":"code","source":"# Seperating Predictors and Outcome values from train and test sets\nX_train = pd.DataFrame(train.drop(['Activity','subject'],axis=1))\nY_train_label = train.Activity.values.astype(object)\nX_validation = pd.DataFrame(validation.drop(['Activity','subject'],axis=1))\nY_validation_label = validation.Activity.values.astype(object)\nX_test = pd.DataFrame(test.drop(['Activity','subject'],axis=1))\nY_test_label = test.Activity.values.astype(object)\n\n# Dimension of Train and Test set \nprint(\"Dimension of Train set\",X_train.shape)\nprint(\"Dimension of Train set\",X_validation.shape)\nprint(\"Dimension of Test set\",X_test.shape,\"\\n\")\n\n# Transforming non numerical labels into numerical labels\nfrom sklearn import preprocessing\nencoder = preprocessing.LabelEncoder()\n\n# encoding train labels \nencoder.fit(Y_train_label)\nY_train = encoder.transform(Y_train_label)\n\n# encoding validation labels \nencoder.fit(Y_validation_label)\nY_validation = encoder.transform(Y_validation_label)\n\n# encoding test labels \nencoder.fit(Y_test_label)\nY_test = encoder.transform(Y_test_label)\n\n#Total Number of Continous and Categorical features in the training set\nnum_cols = X_train._get_numeric_data().columns\nprint(\"Number of numeric features:\",num_cols.size)\n#list(set(X_train.columns) - set(num_cols))\n\n\nnames_of_predictors = list(X_train.columns.values)\n\n# Scaling the Train, validation and Test feature set \nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_validation_scaled = scaler.fit_transform(X_validation)\nX_test_scaled = scaler.transform(X_test)\n","metadata":{"_uuid":"8769e8194b0f01cf7b11edc0251af286a10a05e4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # **Modified code to use a Adaboost classifier**","metadata":{}},{"cell_type":"code","source":"# logistic regression classifier\n# clf = LogisticRegression(random_state=0, C=2).fit(X_train_scaled, Y_train)\nclf = AdaBoostClassifier(n_estimators=5)\nplot_n_estimators=[]\nplot_y_validation=[]\nplot_y_training=[]\n\n# to use different number of estimators, uncomment one of the following code\n\n# clf = AdaBoostClassifier(n_estimators=20)\n# clf = AdaBoostClassifier(n_estimators=40)\n# clf = AdaBoostClassifier(n_estimators=60)\n# clf = AdaBoostClassifier(n_estimators=80)\n# clf = AdaBoostClassifier(n_estimators=100)\n\n\nclf.fit(X_train_scaled, Y_train)\nscores = cross_val_score(clf, X_validation_scaled, Y_validation, cv=5)\nprint(\"cross_val_score=\", scores)\n# clf = LogisticRegression(random_state=0,solver='newton-cg')\nY_validation_pred = clf.predict(X_validation_scaled)\nY_validation_pred_label = list(encoder.inverse_transform(Y_validation_pred))\nprint(\"training set score for logistic regression with different solver\")\nprint(clf.score(X_train_scaled  , Y_train ))\n\nprint(\"validation set score for logistic regression with different solver\")\nprint(clf.score(X_validation_scaled  , Y_validation ))\n\n    \n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"_uuid":"46f747a23e396621b636cd18fe252f8156e30023"}},{"cell_type":"markdown","source":"### Confusion Matrix  and Accuracy Score ","metadata":{"_uuid":"46f747a23e396621b636cd18fe252f8156e30023"}},{"cell_type":"code","source":"# View the accuracy score\n# print('Best score for training data:', svm_model.best_score_,\"\\n\") \n\n# print('Best score for training data:', clf.best_score_,\"\\n\") \n\n# View the best parameters for the model found using grid search\n# print('Best C:',svm_model.best_estimator_.C,\"\\n\") \n# print('Best Kernel:',svm_model.best_estimator_.kernel,\"\\n\")\n# print('Best Gamma:',svm_model.best_estimator_.gamma,\"\\n\")\n\n# final_model = svm_model.best_estimator_\n# Y_pred = final_model.predict(X_test_scaled)\n# Y_pred_label = list(encoder.inverse_transform(Y_pred))\n\n#using logistic regression\nY_test_pred = clf.predict(X_test_scaled)\nY_test_pred_label = list(encoder.inverse_transform(Y_test_pred))","metadata":{"_uuid":"93e0a22c486017ed59d8837b95a8eeeaeab6a59b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Making the Confusion Matrix\n#print(pd.crosstab(Y_test_label, Y_pred_label, rownames=['Actual Activity'], colnames=['Predicted Activity']))\nprint(confusion_matrix(Y_test_label,Y_test_pred_label))\nprint(\"\\n\")\nprint(classification_report(Y_test_label,Y_test_pred_label))\n\nprint(\"Training set score for linear regression: %f\" % clf.score(X_train_scaled , Y_train))\nprint(\"Testing  set score for linear regression: %f\" % clf.score(X_test_scaled  , Y_test ))\n\nprint(\"Training set score for linear regression: %f\" % clf.score(X_train_scaled , Y_train))\nprint(\"Testing  set score for linear regression: %f\" % clf.score(X_test_scaled  , Y_test ))\n\nclf.score","metadata":{"_uuid":"52792b55ee8429aecdce0ca8592131764ce66828","trusted":true},"execution_count":null,"outputs":[]}]}