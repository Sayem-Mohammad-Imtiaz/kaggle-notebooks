{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Sign Language MNIST\n### Contents of the notebook.\n* Importing dataset.\n* Data Preprocessing.\n* Image Augmentation.\n* Model creation and training.\n* Testing model on test data.\n\n### About the dataset\n* The dataset format is patterned to match closely with the classic MNIST.\n* Each training and test case represents a label (0-25) as a one-to-one map for each alphabetic letter A-Z (**and no cases for 9=J or 25=Z because of gesture motions**).\n* The training data (27,455 cases) and test data (7172 cases) are approximately half the size of the standard MNIST but otherwise similar with a header row of label, pixel1,pixel2â€¦.pixel784 which represent a single 28x28 pixel image with grayscale values between 0-255.\n\n![](https://storage.googleapis.com/kagglesdsdata/datasets%2F3258%2F5337%2Famer_sign2.png?GoogleAccessId=databundle-worker-v2@kaggle-161607.iam.gserviceaccount.com&Expires=1596398964&Signature=cUKmt2o%2F060VyoeUu9jpOYUhkcJ%2F639zVXND24JizRxQ1q0qxVQYYg3OYK0huHN9prmoh1yGEkbF9H4ipkmZmbwEN5wyWC2xjhqpjArXDlv%2BWUr9i7G%2BVQiPrdr%2F06BFyooOjsjJ5t7D%2FKwgp%2BAStYtGHrOyhaOxFfJcmphxG1PYz7qGTQtJ6EL9qDn%2BdshCtI1qbJb%2FYawL9azzBSbpj86ju%2F3QSkGlitK%2BYk8R9z9ZWDC6Hpe9Z89WbTnhIPYMqgMho6GfYuEVJenAdw8bJ2fdLVUV0XL06afQseEXVxiBOrqI8W1xWcO2gm94l1qBjRL%2BmHsAI4moEHrtJv3EFA%3D%3D)","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau,EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing Dataset","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_csv('../input/sign-language-mnist/sign_mnist_train/sign_mnist_train.csv')\ntest=pd.read_csv('../input/sign-language-mnist/sign_mnist_test/sign_mnist_test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing\n### Removing dependent column y from the dataframe. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train=train['label']\ny_test=test['label']\ndel train['label']\ndel test['label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train=train.values\nx_test=test.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train.shape, x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reshaping the Arrays so that 2D images can be formed that will be used in CNN layers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train=x_train.reshape(-1,28,28,1)\nx_test=x_test.reshape(-1,28,28,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalize the data\nx_train = x_train / 255\nx_test = x_test / 255\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.imshow(x_train[0][:,:,0],cmap='gray')\nplt.title(y_train[0])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check the distribution of the dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.countplot(y_train)\n\ny_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Use LabelBinarizer to convert dependent variables into [one-hot vectors](https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelBinarizer\nlabel_binarizer = LabelBinarizer()\ny_train = label_binarizer.fit_transform(y_train)\ny_test = label_binarizer.fit_transform(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Image Augmentation\n### Image augmentation is used to prevent overfitting as it creates augmented images that help the model to learn better.\n\nRefer the documention of [ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n        rotation_range=10, \n        zoom_range = 0.1,  \n        width_shift_range=0.1,  \n        height_shift_range=0.1)  \n\n\ndatagen.fit(x_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Refer the documentation of [ReduceLROnPlateau](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.5, min_lr=0.00001)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Creation and Training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(100 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (28,28,1)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\nmodel.add(Conv2D(50 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n\nmodel.add(Flatten())\nmodel.add(Dense(units = 512 , activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(units = 24 , activation = 'softmax'))\nmodel.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(datagen.flow(x_train,y_train, batch_size = 128) ,epochs = 30 , validation_data = (x_test, y_test) , callbacks = [learning_rate_reduction, EarlyStopping(monitor='val_accuracy', patience=3)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label='val accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate(x_test, y_test, verbose=0)\nprint(\"Accuracy on test data\", score[1]*100)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}