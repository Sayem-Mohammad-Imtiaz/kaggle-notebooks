{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### **Summary**\n\n* Exploring data\n* Visualizing image\n* Data augmentation\n* Preparing data\n* Training AlexNet to classifies images\n* Result\n---> AUC = 97%","metadata":{}},{"cell_type":"markdown","source":"# 1. Import libs","metadata":{}},{"cell_type":"code","source":"# Common lib\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\n# Utils\nfrom tqdm import tqdm\nimport datetime\n\n# Sklearn\nfrom sklearn.model_selection import train_test_split\n\n# Tensorflow\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.layers import InputLayer\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Add, MaxPooling2D, Flatten, AveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.metrics import AUC, TruePositives, TrueNegatives, FalsePositives, FalseNegatives\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\nfrom tensorflow.keras.layers.experimental.preprocessing import Resizing, Rescaling\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l2","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:54:47.093625Z","iopub.execute_input":"2021-07-30T02:54:47.094035Z","iopub.status.idle":"2021-07-30T02:54:52.913779Z","shell.execute_reply.started":"2021-07-30T02:54:47.093928Z","shell.execute_reply":"2021-07-30T02:54:52.912758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Explore data","metadata":{}},{"cell_type":"code","source":"# Init variables\ninput_folder = '../input/coronahack-chest-xraydataset'\ntest_img_folder = os.path.join(input_folder, 'Coronahack-Chest-XRay-Dataset', 'Coronahack-Chest-XRay-Dataset', 'test')\ntrain_img_folder = os.path.join(input_folder, 'Coronahack-Chest-XRay-Dataset', 'Coronahack-Chest-XRay-Dataset', 'train')\nmetadata_df = pd.read_csv(os.path.join(input_folder, 'Chest_xray_Corona_Metadata.csv'), index_col=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:54:52.915475Z","iopub.execute_input":"2021-07-30T02:54:52.915863Z","iopub.status.idle":"2021-07-30T02:54:52.970866Z","shell.execute_reply.started":"2021-07-30T02:54:52.915823Z","shell.execute_reply":"2021-07-30T02:54:52.970135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metadata_df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:54:52.972615Z","iopub.execute_input":"2021-07-30T02:54:52.972959Z","iopub.status.idle":"2021-07-30T02:54:53.022884Z","shell.execute_reply.started":"2021-07-30T02:54:52.972922Z","shell.execute_reply":"2021-07-30T02:54:53.022038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split to train & test set\ntrain_df = metadata_df[metadata_df.Dataset_type == 'TRAIN'].reset_index(drop=True)\ntest_df = metadata_df[metadata_df.Dataset_type == 'TEST'].reset_index(drop=True)\n\n# Check train_df size + test_df size == metadata_df size\nassert train_df.size + test_df.size == metadata_df.size\n\nprint(f'Shape of train data: { train_df.shape }')\nprint(f'Shape of test data: { test_df.shape }')\n\ntrain_df.sample(10)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:54:53.024585Z","iopub.execute_input":"2021-07-30T02:54:53.024948Z","iopub.status.idle":"2021-07-30T02:54:53.049468Z","shell.execute_reply.started":"2021-07-30T02:54:53.02491Z","shell.execute_reply":"2021-07-30T02:54:53.048723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Count number of null values in train and test dataset**","metadata":{}},{"cell_type":"code","source":"def count_plot_null_value(dataset, xticks):\n    fig = plt.figure()\n    if dataset == 'train':\n        dataset_df = train_df\n    else:\n        dataset_df = test_df\n    ax = sns.barplot(x=dataset_df.isnull().sum(), \n                     y=dataset_df.columns,\n                     order=['X_ray_image_name', 'Dataset_type', 'Label', 'Label_1_Virus_category', 'Label_2_Virus_category'],\n                     palette=\"Blues\")\n    ax.set_xticks(xticks)\n    ax.set_ylabel('Column')\n    ax.set_xlabel('Count')\n    ax.set_title(f'Number of null values of each column in { dataset } data')\n\n    # Add text to chart\n    for p in ax.patches:\n        ax.annotate(int(p.get_width()),\n                    (p.get_width() + 10, p.get_y() + p.get_height() / 2),\n                    va='center',\n                    size=12)\n    plt.show()\n        \ncount_plot_null_value('train', np.arange(0, 7000, 1000))\ncount_plot_null_value('test', np.arange(0, 750, 100))","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:54:53.050713Z","iopub.execute_input":"2021-07-30T02:54:53.051054Z","iopub.status.idle":"2021-07-30T02:54:53.556461Z","shell.execute_reply.started":"2021-07-30T02:54:53.051011Z","shell.execute_reply":"2021-07-30T02:54:53.555465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fill na\ntrain_df.fillna('unknow', inplace=True)\ntest_df.fillna('unknow', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:54:53.557961Z","iopub.execute_input":"2021-07-30T02:54:53.558352Z","iopub.status.idle":"2021-07-30T02:54:53.567586Z","shell.execute_reply.started":"2021-07-30T02:54:53.558298Z","shell.execute_reply":"2021-07-30T02:54:53.566345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Count value in Label column**","metadata":{}},{"cell_type":"code","source":"def count_plot_value_in_column(column, dataset, ax, order=None):\n    ax = sns.countplot(y=column, \n                       data=dataset, \n                       palette='Blues',\n                       ax=ax,\n                       order=order)\n    return ax\n\ndef add_annotate_to_chart(ax):\n    for p in ax.patches:\n        ax.annotate(int(p.get_width()),\n                    (p.get_width() + 10, p.get_y() + p.get_height() / 2),\n                    va='center',\n                    size=12)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:54:53.569287Z","iopub.execute_input":"2021-07-30T02:54:53.569729Z","iopub.status.idle":"2021-07-30T02:54:53.577309Z","shell.execute_reply.started":"2021-07-30T02:54:53.569693Z","shell.execute_reply":"2021-07-30T02:54:53.576254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n\n# Train set\nax = count_plot_value_in_column('Label', train_df, axs[0])\nax.set_xticks(np.arange(0, 5000, 500))\nax.set_title('Train set')\nadd_annotate_to_chart(ax)\n\n# Test set\nax = count_plot_value_in_column('Label', test_df, axs[1])\nax.set_xticks(np.arange(0, 500, 50))\nax.set_title('Test set')\nadd_annotate_to_chart(ax)\n\nfig.suptitle('Number of each values in Label column', size=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:54:53.580702Z","iopub.execute_input":"2021-07-30T02:54:53.581059Z","iopub.status.idle":"2021-07-30T02:54:53.83912Z","shell.execute_reply.started":"2021-07-30T02:54:53.581008Z","shell.execute_reply":"2021-07-30T02:54:53.838195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Make sure that all normal cases go with unknow value in Label_1_Virus_category and Label_2_Virus_category**","metadata":{}},{"cell_type":"code","source":"train_normal = train_df[train_df.Label == 'Normal']\ntest_normal = test_df[test_df.Label == 'Normal']\n\ntrain_normal_with_unknow = train_normal[(train_normal.Label_1_Virus_category == 'unknow') & (train_normal.Label_2_Virus_category == 'unknow')]\ntest_normal_with_unknow = test_normal[(test_normal.Label_1_Virus_category == 'unknow') & (test_normal.Label_2_Virus_category == 'unknow')]\n\ntotal_normal_cases = train_normal.shape[0] + test_normal.shape[0]\ntotal_normal_with_unknow_cases = train_normal_with_unknow.shape[0] + test_normal_with_unknow.shape[0]\n\nprint(f'Label = Normal: { total_normal_cases }')\nprint(f\"Label = Normal & Label_1 = unknow & Label_2 = unknow: { total_normal_with_unknow_cases }\")\n\nassert total_normal_cases + total_normal_with_unknow_cases","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:54:53.841159Z","iopub.execute_input":"2021-07-30T02:54:53.841563Z","iopub.status.idle":"2021-07-30T02:54:53.856488Z","shell.execute_reply.started":"2021-07-30T02:54:53.841522Z","shell.execute_reply":"2021-07-30T02:54:53.855357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Count value in Label_1_Virus_category column**","metadata":{}},{"cell_type":"code","source":"train_pnemonia = train_df[~train_df.index.isin(train_normal.index)]\ntest_pnemonia = test_df[~test_df.index.isin(test_normal.index)]\n\nassert train_pnemonia.shape[0] + train_normal.shape[0] == train_df.shape[0]\nassert test_pnemonia.shape[0] + test_normal.shape[0] == test_df.shape[0]","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:54:53.858466Z","iopub.execute_input":"2021-07-30T02:54:53.859067Z","iopub.status.idle":"2021-07-30T02:54:53.868726Z","shell.execute_reply.started":"2021-07-30T02:54:53.859017Z","shell.execute_reply":"2021-07-30T02:54:53.867675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n\n# Train pnemonia\nax = count_plot_value_in_column('Label_1_Virus_category', \n                                train_pnemonia, \n                                axs[0])\nax.set_xticks(np.arange(0, 3500, 500))\nax.set_title('Pnemonia cases in train set')\nadd_annotate_to_chart(ax)\n\n# Test pnemonia\nax = count_plot_value_in_column('Label_1_Virus_category',\n                                test_pnemonia,\n                                axs[1])\nax.set_xticks(np.arange(0, 350, 50))\nax.set_title('Pnemonia cases in test set')\nadd_annotate_to_chart(ax)\n\nfig.suptitle('Number of each values in Label_1_Virus_category', size=15)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:54:53.870242Z","iopub.execute_input":"2021-07-30T02:54:53.870903Z","iopub.status.idle":"2021-07-30T02:54:54.135079Z","shell.execute_reply.started":"2021-07-30T02:54:53.870861Z","shell.execute_reply":"2021-07-30T02:54:54.134071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Count value in Label_2_Virus_category column**","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n\n# Train pnemonia\nax = count_plot_value_in_column('Label_2_Virus_category', \n                                train_pnemonia, \n                                axs[0])\nax.set_xticks(np.arange(0, 5000, 500))\nax.set_title('Pnemonia cases in train set')\nadd_annotate_to_chart(ax)\n\n# Test pnemonia \nax = count_plot_value_in_column('Label_2_Virus_category', test_pnemonia, axs[1])\nax.set_xticks(np.arange(0, 500, 50))\nax.set_title('Pnemonia cases in test set')\nadd_annotate_to_chart(ax)\n\nfig.suptitle('Number of each values in Label_2_Virus_category', size=15)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:54:54.136465Z","iopub.execute_input":"2021-07-30T02:54:54.136832Z","iopub.status.idle":"2021-07-30T02:54:54.423839Z","shell.execute_reply.started":"2021-07-30T02:54:54.136792Z","shell.execute_reply":"2021-07-30T02:54:54.422914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference from charts\n* We have 2 cases that is Pnemonia and Normal case. \n* Pnemonia cases is much more than Normal cases in both train set and test set.\n* All Normal cases is labeled as unknow/null in Label_1_Virus_category and Label_2_Virus_category.\n* All Pnemonia cases is labeled as bacteria, virus, stress-smoking and dont have any unknow/null value in Label_1_Virus_category in both train set and test set. \n* In train set, most of pnemonia case is labeled as unknow/null value (3875/3944).\n* In test set, all pnemonia case is labels as unknow/null value.\n* In Label_1_Virus_category, those value are different to much.\n* In Label_2_Virus_category, if we remove all unknow value then we just have 69 sample.\n* Thus we are going to construct a model which classifies Normal and Pnemonia cases.\n* Cause the difference of Pnemonia and Normal cases so that we should use AUC or F1 score to evaluate the goodness of model.","metadata":{}},{"cell_type":"markdown","source":"# 3. Visualize image","metadata":{}},{"cell_type":"markdown","source":"**Plot random 6 images in train set**","metadata":{}},{"cell_type":"code","source":"assert os.path.exists(train_img_folder)\nassert os.path.exists(test_img_folder)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:54:54.425229Z","iopub.execute_input":"2021-07-30T02:54:54.425578Z","iopub.status.idle":"2021-07-30T02:54:54.446814Z","shell.execute_reply.started":"2021-07-30T02:54:54.425542Z","shell.execute_reply":"2021-07-30T02:54:54.446076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_train_img = train_df.sample(6).reset_index(drop=True)\n\nfig = plt.figure(figsize=(15, 15))\nfor i in range(6):\n    ax = plt.subplot(3, 2, i+1)\n    img_path = os.path.join(train_img_folder, random_train_img.loc[i, 'X_ray_image_name'])\n    label = random_train_img.loc[i, 'Label']\n    img = load_img(img_path)\n    ax.axis('off')\n    ax.set_title(label, size=15)\n    ax.imshow(img)\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:54:54.447748Z","iopub.execute_input":"2021-07-30T02:54:54.447985Z","iopub.status.idle":"2021-07-30T02:54:55.650732Z","shell.execute_reply.started":"2021-07-30T02:54:54.447962Z","shell.execute_reply":"2021-07-30T02:54:55.649893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Image histogram\n> An image histogram is a type of histogram that acts as a graphical representation of the tonal distribution in a digital image. It plots the number of pixels for each tonal value. By looking at the histogram for a specific image a viewer will be able to judge the entire tonal distribution at a glance.","metadata":{}},{"cell_type":"markdown","source":"**Image histogram of 5 Normal cases**","metadata":{}},{"cell_type":"code","source":"normal_case_img_name = train_df[train_df.Label == 'Normal'].X_ray_image_name[:5]\n\nfig, axs = plt.subplots(5, 2, figsize=(15, 20))\nfor idx, img_name in enumerate(normal_case_img_name):\n    # Plot image\n    img_path = os.path.join(train_img_folder, img_name)\n    img = load_img(img_path)\n    img = img.resize((700, 700))\n    axs[idx, 0].imshow(img)\n    axs[idx, 0].axis('off')\n    # Plot image histogram\n    img_arr = img_to_array(img)\n    axs[idx, 1].hist(img_arr.ravel(), 256)\n    \naxs[0, 0].set_title('Image')    \naxs[0, 1].set_title('Image histogram')\nfig.suptitle('Normal case', size = 15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:54:55.651898Z","iopub.execute_input":"2021-07-30T02:54:55.652222Z","iopub.status.idle":"2021-07-30T02:54:59.357152Z","shell.execute_reply.started":"2021-07-30T02:54:55.65219Z","shell.execute_reply":"2021-07-30T02:54:59.356238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pnemonia_case_img_name = train_df[train_df.Label == 'Pnemonia'].X_ray_image_name[:5]\n\nfig, axs = plt.subplots(5, 2, figsize=(15, 20))\nfor idx, img_name in enumerate(pnemonia_case_img_name):\n    # Plot image\n    img_path = os.path.join(train_img_folder, img_name)\n    img = load_img(img_path)\n    img = img.resize((700, 700))\n    axs[idx, 0].imshow(img)\n    axs[idx, 0].axis('off')\n    # Plot image histogram\n    img_arr = img_to_array(img)\n    axs[idx, 1].hist(img_arr.ravel(), 256)\n\naxs[0, 0].set_title('Image')\naxs[0, 1].set_title('Image histogram')\nfig.suptitle('Pnemonia cases', size=15)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:54:59.358563Z","iopub.execute_input":"2021-07-30T02:54:59.358921Z","iopub.status.idle":"2021-07-30T02:55:03.297028Z","shell.execute_reply.started":"2021-07-30T02:54:59.358884Z","shell.execute_reply":"2021-07-30T02:55:03.296245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Data augmentation","metadata":{}},{"cell_type":"code","source":"def load_img_path(quantity, dataset):\n    if dataset == 'train':\n        df = train_df\n        folder = train_img_folder\n    elif dataset == 'test':\n        df = test_df\n        folder = test_img_folder\n    if quantity <= 0:\n        return None\n    img_names = df.X_ray_image_name[:quantity]\n    img_paths = [os.path.join(folder, img_name) for img_name in img_names]\n    return img_paths\n\ndef img_path_to_array(img_paths):\n    img_arr = [img_to_array(load_img(img_path).resize((500, 500))) for img_path in tqdm(img_paths)]\n    img_arr = np.array(img_arr)\n    return img_arr\n\ndef show_img(img):\n    plt.imshow(array_to_img(img))\n    \ndef show_multi_img(img_arr):\n    fig = plt.figure(figsize=(20,10))\n    for i in range(len(img_arr)):\n        plt.subplot(len(img_arr) / 4, 4, i+1)\n        show_img(img_arr[i])\n        plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:55:03.298603Z","iopub.execute_input":"2021-07-30T02:55:03.298971Z","iopub.status.idle":"2021-07-30T02:55:03.308357Z","shell.execute_reply.started":"2021-07-30T02:55:03.298933Z","shell.execute_reply":"2021-07-30T02:55:03.307153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rotation_range=10,\n                              brightness_range=(0.1, 1.2),\n                              horizontal_flip=True,\n                              zoom_range=[0.75, 1])\ntest_datagen = ImageDataGenerator()","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:55:03.309688Z","iopub.execute_input":"2021-07-30T02:55:03.310098Z","iopub.status.idle":"2021-07-30T02:55:03.317027Z","shell.execute_reply.started":"2021-07-30T02:55:03.310061Z","shell.execute_reply":"2021-07-30T02:55:03.316199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Plot images after augmentation**","metadata":{}},{"cell_type":"code","source":"img_paths = load_img_path(100, 'train')\nimg_arr = img_path_to_array(img_paths)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:55:03.3182Z","iopub.execute_input":"2021-07-30T02:55:03.318584Z","iopub.status.idle":"2021-07-30T02:55:10.608456Z","shell.execute_reply.started":"2021-07-30T02:55:03.318539Z","shell.execute_reply":"2021-07-30T02:55:10.607514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aug_imgs = train_datagen.flow(img_arr ,batch_size=8)\nprint(f'Number of batches: { len(aug_imgs) }')","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:55:10.610137Z","iopub.execute_input":"2021-07-30T02:55:10.610547Z","iopub.status.idle":"2021-07-30T02:55:10.616281Z","shell.execute_reply.started":"2021-07-30T02:55:10.610501Z","shell.execute_reply":"2021-07-30T02:55:10.615159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_multi_img(aug_imgs[0])","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:55:10.617805Z","iopub.execute_input":"2021-07-30T02:55:10.618189Z","iopub.status.idle":"2021-07-30T02:55:11.804702Z","shell.execute_reply.started":"2021-07-30T02:55:10.61815Z","shell.execute_reply":"2021-07-30T02:55:11.803774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Prepare data","metadata":{}},{"cell_type":"code","source":"train_df, valid_df = train_test_split(train_df, test_size=0.2, shuffle=True, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:55:11.806036Z","iopub.execute_input":"2021-07-30T02:55:11.806386Z","iopub.status.idle":"2021-07-30T02:55:11.813875Z","shell.execute_reply.started":"2021-07-30T02:55:11.80635Z","shell.execute_reply":"2021-07-30T02:55:11.812977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_batches = train_datagen.flow_from_dataframe(train_df,\n                                             directory=train_img_folder,\n                                             x_col='X_ray_image_name',\n                                             y_col='Label',\n                                             class_mode='binary',\n                                             batch_size=128)\n\nvalid_batches = test_datagen.flow_from_dataframe(valid_df,\n                                             directory=train_img_folder,\n                                             x_col='X_ray_image_name',\n                                             y_col='Label',\n                                             class_mode='binary',\n                                             batch_size=128)\n\ntest_batches = test_datagen.flow_from_dataframe(test_df,\n                                            directory=test_img_folder,\n                                            x_col='X_ray_image_name',\n                                            y_col='Label',\n                                            class_mode='binary',\n                                            batch_size=8,\n                                            shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:55:11.818716Z","iopub.execute_input":"2021-07-30T02:55:11.819185Z","iopub.status.idle":"2021-07-30T02:55:25.248488Z","shell.execute_reply.started":"2021-07-30T02:55:11.819135Z","shell.execute_reply":"2021-07-30T02:55:25.247565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Label encode: { train_batches.class_indices }')","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:55:25.250678Z","iopub.execute_input":"2021-07-30T02:55:25.251165Z","iopub.status.idle":"2021-07-30T02:55:25.257057Z","shell.execute_reply.started":"2021-07-30T02:55:25.25112Z","shell.execute_reply":"2021-07-30T02:55:25.255838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_batches_series = pd.Series(train_batches.classes)\nvalid_batches_series = pd.Series(valid_batches.classes)\n\nprint(f'Value count in train_batches: \\n{ train_batches_series.value_counts() }')\nprint(f'Value count in valid_batches: \\n{ valid_batches_series.value_counts() }')","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:55:25.258606Z","iopub.execute_input":"2021-07-30T02:55:25.259431Z","iopub.status.idle":"2021-07-30T02:55:25.274011Z","shell.execute_reply.started":"2021-07-30T02:55:25.259387Z","shell.execute_reply":"2021-07-30T02:55:25.272948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Build AlexNet","metadata":{}},{"cell_type":"code","source":"def create_dir(dir_path):\n    if not os.path.exists(dir_path):\n        os.mkdir(dir_path)\n        \ncreate_dir('models')","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:55:25.275473Z","iopub.execute_input":"2021-07-30T02:55:25.275813Z","iopub.status.idle":"2021-07-30T02:55:25.280279Z","shell.execute_reply.started":"2021-07-30T02:55:25.27578Z","shell.execute_reply":"2021-07-30T02:55:25.279416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Preprocessing layers**","metadata":{}},{"cell_type":"code","source":"# When export model, these preprocessing layers will be saved along with the rest of model\nresize_and_rescale = Sequential([\n    Resizing(227, 227),\n    Rescaling(1./255)\n])","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:55:25.281761Z","iopub.execute_input":"2021-07-30T02:55:25.282321Z","iopub.status.idle":"2021-07-30T02:55:27.263548Z","shell.execute_reply.started":"2021-07-30T02:55:25.282284Z","shell.execute_reply":"2021-07-30T02:55:27.262611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Define metrics used for all models**","metadata":{}},{"cell_type":"code","source":"metrics = [TruePositives(name='TP'),\n           TrueNegatives(name='TN'),\n           FalsePositives(name='FP'),\n           FalseNegatives(name='FN'),\n           AUC(curve='PR', name='AUC')]","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:55:27.26481Z","iopub.execute_input":"2021-07-30T02:55:27.265191Z","iopub.status.idle":"2021-07-30T02:55:27.295229Z","shell.execute_reply.started":"2021-07-30T02:55:27.265153Z","shell.execute_reply":"2021-07-30T02:55:27.294466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.1 AlexNet","metadata":{}},{"cell_type":"markdown","source":"**Define model architecture**","metadata":{}},{"cell_type":"code","source":"lamb = 0.9\n\nmodel = Sequential([\n    # Preprocessing layer\n    resize_and_rescale,\n    \n    InputLayer((227, 227, 3)),\n    \n    # 1st layer\n    Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), padding='valid', activation='relu', kernel_regularizer=l2(lamb), name='conv1'),\n    MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'),\n    BatchNormalization(),\n    \n    # 2nd layer\n    Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(lamb), name='conv2'),\n    MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'),\n    BatchNormalization(),\n    \n    # 3rd layer\n    Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(lamb), name='conv3'),\n    BatchNormalization(),\n    \n    # 4th layer\n    Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(lamb), name='conv4'),\n    BatchNormalization(),\n    \n    # 5th layer\n    Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu', kernel_regularizer=l2(lamb), name='conv5'),\n    MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'),\n    BatchNormalization(),\n    \n    # Flatten\n    Flatten(),\n    \n    # 6th layer\n    Dense(units=4096, activation='relu'),\n    Dropout(0.5),\n    \n    # 7th layer\n    Dense(units=4096, activation='relu'),\n    Dropout(0.5),\n    \n    # 8th layer (output)\n    Dense(units=1, activation='sigmoid')\n], name='AlexNet')","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:55:27.296492Z","iopub.execute_input":"2021-07-30T02:55:27.296856Z","iopub.status.idle":"2021-07-30T02:55:27.341401Z","shell.execute_reply.started":"2021-07-30T02:55:27.296818Z","shell.execute_reply":"2021-07-30T02:55:27.340403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create folder contains model's files\nmodel_dir = 'models/alexnet'\nmodel_file = 'best_alexnet.hdf5'\ncreate_dir(model_dir)\n\ncheckpoint = ModelCheckpoint(os.path.join(model_dir, model_file),\n                             monitor='val_loss',\n                             verbose=1,\n                             save_best_only=True,\n                             save_weights_only=False)\n\nearly_stopping = EarlyStopping(monitor='val_loss',\n                               patience=30,\n                               verbose=1,\n                               restore_best_weights=True)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), \n                              patience=7, min_delta=1e-3, verbose=1, min_lr=1e-7)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:55:27.342575Z","iopub.execute_input":"2021-07-30T02:55:27.342922Z","iopub.status.idle":"2021-07-30T02:55:27.349528Z","shell.execute_reply.started":"2021-07-30T02:55:27.342885Z","shell.execute_reply":"2021-07-30T02:55:27.348272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize TensorBoard\nlog_dir = 'models/alexnet/logs' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:55:27.351018Z","iopub.execute_input":"2021-07-30T02:55:27.351416Z","iopub.status.idle":"2021-07-30T02:55:27.695796Z","shell.execute_reply.started":"2021-07-30T02:55:27.351379Z","shell.execute_reply":"2021-07-30T02:55:27.694744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.2 Train AlexNet","metadata":{}},{"cell_type":"code","source":"batch_size = 128\nepochs = 200\nlr = 1e-3\n\nmodel.compile(loss='binary_crossentropy', optimizer=Adam(lr=lr), metrics=metrics)\n\ntraining_time_start = datetime.datetime.now()\n\nhistory = model.fit(train_batches,\n                                epochs=epochs,\n                                verbose=1,\n                                callbacks=[checkpoint, early_stopping, reduce_lr, tensorboard_callback],\n                                validation_data=valid_batches,\n                                steps_per_epoch=len(train_batches),\n                                validation_steps=len(valid_batches))\n\ntraining_time_end = datetime.datetime.now()","metadata":{"execution":{"iopub.status.busy":"2021-07-30T02:55:27.697199Z","iopub.execute_input":"2021-07-30T02:55:27.697582Z","iopub.status.idle":"2021-07-30T07:52:04.472466Z","shell.execute_reply.started":"2021-07-30T02:55:27.697543Z","shell.execute_reply":"2021-07-30T07:52:04.471438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_training_seconds = (training_time_end - training_time_start).seconds\nprint('Total training time: ', str(datetime.timedelta(seconds=total_training_seconds)))","metadata":{"execution":{"iopub.status.busy":"2021-07-30T07:52:04.47397Z","iopub.execute_input":"2021-07-30T07:52:04.474523Z","iopub.status.idle":"2021-07-30T07:52:04.480241Z","shell.execute_reply.started":"2021-07-30T07:52:04.474478Z","shell.execute_reply":"2021-07-30T07:52:04.479402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.3 Plot learning curve","metadata":{}},{"cell_type":"code","source":"history_df = pd.DataFrame(history.history)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T07:52:04.481528Z","iopub.execute_input":"2021-07-30T07:52:04.482017Z","iopub.status.idle":"2021-07-30T07:52:04.493243Z","shell.execute_reply.started":"2021-07-30T07:52:04.481975Z","shell.execute_reply":"2021-07-30T07:52:04.492119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_df[['loss', 'val_loss']].plot()\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-30T07:52:04.494907Z","iopub.execute_input":"2021-07-30T07:52:04.495269Z","iopub.status.idle":"2021-07-30T07:52:04.687579Z","shell.execute_reply.started":"2021-07-30T07:52:04.49523Z","shell.execute_reply":"2021-07-30T07:52:04.686716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_df[['AUC', 'val_AUC']].plot()\nplt.ylabel('AUC')\nplt.xlabel('Epoch')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-30T07:52:04.688829Z","iopub.execute_input":"2021-07-30T07:52:04.689172Z","iopub.status.idle":"2021-07-30T07:52:04.875093Z","shell.execute_reply.started":"2021-07-30T07:52:04.689141Z","shell.execute_reply":"2021-07-30T07:52:04.874289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_of_epochs = history_df.shape[0]\nhalf_epoch = int(num_of_epochs / 2)\n\nfirst_half_history = history_df.loc[:half_epoch]\nfirst_title = f'Loss value at epoch 0 - { half_epoch }'\n\nlast_half_history = history_df.loc[half_epoch:len(history_df)]\nlast_title = f'Loss value at epoch { half_epoch } - { len(history_df) }'\n\nhists = [first_half_history, last_half_history]\ntitles = [first_title, last_title]\n\nfor i in range(2):\n    ax = hists[i][['loss', 'val_loss']].plot()\n    ax.set_xlabel('Epoch')\n    ax.set_ylabel('Loss value')\n    ax.set_title(titles[i])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-30T07:52:04.876593Z","iopub.execute_input":"2021-07-30T07:52:04.876956Z","iopub.status.idle":"2021-07-30T07:52:05.507418Z","shell.execute_reply.started":"2021-07-30T07:52:04.876919Z","shell.execute_reply":"2021-07-30T07:52:05.506553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"first_title = f'AUC value at epoch 0 - { half_epoch }'\nlast_title = f'AUC value at epoch { half_epoch } - { len(history_df) }'\n\ntitles = [first_title, last_title]\n\nfor i in range(2):\n    ax = hists[i][['AUC', 'val_AUC']].plot()\n    ax.set_xlabel('Epoch')\n    ax.set_ylabel('AUC value')\n    ax.set_title(titles[i])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-30T07:52:05.508874Z","iopub.execute_input":"2021-07-30T07:52:05.509216Z","iopub.status.idle":"2021-07-30T07:52:05.878834Z","shell.execute_reply.started":"2021-07-30T07:52:05.509178Z","shell.execute_reply":"2021-07-30T07:52:05.877674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.4 Evaluate","metadata":{}},{"cell_type":"code","source":"evaluate = model.evaluate(test_batches, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T07:52:05.880357Z","iopub.execute_input":"2021-07-30T07:52:05.880786Z","iopub.status.idle":"2021-07-30T07:52:18.497854Z","shell.execute_reply.started":"2021-07-30T07:52:05.880739Z","shell.execute_reply":"2021-07-30T07:52:18.496964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, tp, fp, tn, fn, auc = evaluate[0], evaluate[1], evaluate[2], evaluate[3], evaluate[4], evaluate[5]\nprint(f'Test loss: { loss }')\nprint(f'True positive: { tp }')\nprint(f'False positive: { fp }')\nprint(f'True negative: { tn }')\nprint(f'False negative: { fn }')\nprint('AUC: %.2f' % auc)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T07:52:18.501054Z","iopub.execute_input":"2021-07-30T07:52:18.501347Z","iopub.status.idle":"2021-07-30T07:52:18.50873Z","shell.execute_reply.started":"2021-07-30T07:52:18.501308Z","shell.execute_reply":"2021-07-30T07:52:18.507681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}