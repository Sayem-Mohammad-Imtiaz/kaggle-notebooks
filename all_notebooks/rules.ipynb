{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## ASSOCIATION RULES","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ASSOCIATION RULES","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nfrom mlxtend.preprocessing import TransactionEncoder\nfrom mlxtend.frequent_patterns import apriori, fpmax, fpgrowth\n\n\ndataset = [['Milk', 'Onion', 'Eggs', 'Yogurt'],\n           ['Dill', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt'],\n           ['Milk', 'Apple', 'Kidney Beans', 'Eggs'],\n           ['Milk', 'Nutmeg', 'Apple', 'Kidney Beans'],\n           ['Kidney Beans', 'Eggs'],\n           ['Milk', 'Unicorn', 'Corn', 'Kidney Beans', 'Yogurt'],\n           ['Corn', 'Onion', 'Onion', 'Kidney Beans', 'Ice cream', 'Eggs'],\n           ['Dill', 'Onion', 'Nutmeg',  'Eggs', 'Yogurt','Kidney Beans'],\n           ['Milk', 'Unicorn', 'Corn', 'Kidney Beans', 'Yogurt'],\n           ['Corn', 'Onion', 'Onion', 'Kidney Beans',  'Eggs', 'Ice cream'],\n           ['Dill', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt'],\n           ['Kidney Beans', 'Eggs', 'Milk', 'Unicorn', 'Corn'],\n           ['Milk', 'Kidney Beans', 'Eggs', 'Apple'],\n           ['Milk', 'Unicorn', 'Corn', 'Kidney Beans', 'Yogurt'],\n           ['Corn', 'Onion', 'Onion', 'Kidney Beans', 'Ice cream', 'Eggs'],\n           [ 'Kidney Beans', 'Yogurt',  'Eggs', 'Apple']]\n\nte = TransactionEncoder()\nte_ary = te.fit(dataset).transform(dataset)\ndf = pd.DataFrame(te_ary, columns=te.columns_)\n\nfrequent_itemsets = fpgrowth(df, min_support=0.6, use_colnames=True)\nfrequent_itemsets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mlxtend.frequent_patterns import association_rules\n\nrules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rules","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rules.pivot('antecedents', 'consequents', 'antecedent support').fillna(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter \n\n\npair = lambda arr: [(i, v) for i, v in zip(arr[:-1], arr[1:])]\nunikeys = lambda _dcc: Counter(_dcc.keys())\n\ndef _count_occurences(_sequences):\n    \"\"\" Given list of lists [[A,B,A,B,A], [C,B,C]] \n        Let Unique Inner-array-wise Pair be UIP\n        e.g. (A,B), (B,A), (B,C), (C,B) bot NOT (A,C)\n        > count of UIPs in whole list\n        > occurence of UIPs in unique lists\n        ========================================\n        {\n        (A, B): 2, \n        (B, A): 2, \n        (C, B): 1, \n        (B, C): 1}\n        --- AND --- \n        {\n        (A, B): 1, \n        (B, A): 1, \n        (C, B): 1, \n        (B, C): 1}\n\n    \"\"\"\n    cc = Counter(pair(_sequences[0]))\n    ucc = unikeys(cc)\n    for cX in _sequences[1:]:\n        _cc = Counter(pair(cX))\n\n        ucc += unikeys(_cc)\n        cc += _cc\n    return cc, ucc\n\n\n\ndef _pair_count_occurence(_sequences):\n    _cnt, _occ = _count_occurences(_sequences)\n    _cntDF = pd.DataFrame(_cnt, index=['CNT']).T.reset_index()\n    _occDF = pd.DataFrame(_occ, index=['OCC']).T.reset_index()\n\n    _cdf = pd.merge(_cntDF, _occDF, how='left',\n                    left_on=['level_0', 'level_1'],\n                    right_on=['level_0', 'level_1'])\n\n    _cdf.rename(columns={'level_0': 'POSTERIOR',\n                         'level_1': 'PRIOR'}, inplace=True)\n\n    _cdf['RELATIVE_OCC'] = _cdf['OCC'].apply(lambda c: c / len(_sequences))\n    _cdf['RELATIVE_PRIOR'] = _cdf.apply(lambda r: r['CNT'] / (_cdf[_cdf.PRIOR == r['PRIOR']]['CNT'].sum()), axis=1)\n    _cdf['RELATIVE_POSTERIOR'] = _cdf.apply(lambda r: r['CNT'] / (_cdf[_cdf.POSTERIOR == r['POSTERIOR']]['CNT'].sum()),\n                                            axis=1)\n    _cdf['RELATIVE_CNT'] = _cdf.apply(lambda r: r['CNT'] / (_cdf['CNT'].sum()), axis=1)\n    _cdf['RELATIVE_PRIOR_BY_OCC'] = 2*_cdf['RELATIVE_PRIOR']*_cdf['RELATIVE_OCC']/(_cdf['RELATIVE_PRIOR']+_cdf['RELATIVE_OCC'])\n    _cdf['RELATIVE_POSTERIOR_BY_OCC'] = 2*_cdf['RELATIVE_POSTERIOR']*_cdf['RELATIVE_OCC']/(_cdf['RELATIVE_POSTERIOR']+_cdf['RELATIVE_OCC'])\n    \n    return _cdf[\n        ['PRIOR', 'POSTERIOR', 'CNT', 'RELATIVE_CNT', 'RELATIVE_PRIOR', 'RELATIVE_PRIOR_BY_OCC', 'RELATIVE_POSTERIOR', 'RELATIVE_POSTERIOR_BY_OCC', 'OCC', 'RELATIVE_OCC']]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = _pair_count_occurence(dataset).sort_values('CNT', ascending = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res.sort_values('CNT', ascending = False).head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res.pivot('PRIOR', 'POSTERIOR', 'RELATIVE_PRIOR').fillna(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nimport plotly.graph_objects as go\n\nfrom matplotlib import pyplot as plt\n\nupper_str = lambda s: s.upper()\n\n\ndef _plot_path(_cnt, _item, _col: str = 'CNT'):\n    _Ccnt = _cnt[(_cnt['PRIOR'] == _item) | (_cnt['POSTERIOR'] == _item)]\n    uniques = dict(enumerate(list(set(_Ccnt['PRIOR']).union(set(_Ccnt['POSTERIOR'])))))\n    iuniques = {v: k for k, v in uniques.items()}\n    _perc = _Ccnt[_col].dtype != int\n    _labels = list(map(upper_str, uniques.values()))\n\n    fig = go.Figure(data=[go.Sankey(\n        node=dict(\n            pad=15,\n            thickness=20,\n            line=dict(color=\"black\", width=0.5),\n            label=_labels,\n            color=list(map(lambda r: 'darkred' if r == _item else 'blue', uniques.values())),\n            customdata=_labels, hovertemplate='%{customdata}'\n\n        ),\n        link=dict(\n            source=list(map(lambda r: iuniques.get(r), _Ccnt.PRIOR.values)),\n            target=list(map(lambda r: iuniques.get(r), _Ccnt.POSTERIOR.values)),\n            value=list(map(lambda r: 100 * r if _perc else r, _Ccnt[_col].values)),\n            color='rgba(200, 205, 206, 0.6)',\n            hovertemplate='%{value} of %{source.customdata} to %{target.customdata}'\n        ))])\n\n    fig.update_layout(title_text=f\"ITEM {_item} BY {_col}\", font_size=10)\n    fig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res.query('RELATIVE_PRIOR_BY_OCC > 0.2')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_plot_path(res, 'Corn')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### THIS IS PRETTY MUCH IT","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.datasets import load_iris, load_wine","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndata = load_iris()\nprint('\\n'.join(data['target_names']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(data['data'], columns = data['feature_names'])\ndf['target'] = data['target']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##  LET'S SEE OTHERS","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install h2o=='3.32.1.2'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import h2o\nh2o.__version__","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import h2o\nfrom h2o.estimators import H2ORuleFitEstimator","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from typing import List, AnyStr\n\ndef _replace_str(_source, keys: List, values: (List, AnyStr)):\n    equalen = len(keys) == len(values)\n    singlevalue = len(values) == 1\n    assert sum({equalen, singlevalue}) == 1, f'{FAIL} no apparent mapping between {keys} and {values}'\n\n    for k, v in zip(keys, values if equalen else values * len(keys)):\n        _source = _source.replace(k, v)\n    return _source\n\nclass H2ORule(H2ORuleFitEstimator, object):\n    def __init__(self, **kw):\n        \"\"\" Adjusted to work with pd.DataFrames. \"\"\"\n        h2o.init()\n        self.Rules_ = 'tuple()'\n        self.frame_ = pd.DataFrame()\n        super(H2ORule, self).__init__(**kw)\n\n    @property\n    def Rules_(self):\n        return self.__Rules_\n\n    @Rules_.setter\n    def Rules_(self, _rulette_):\n        self.__Rules_ = _rulette_\n\n    @property\n    def frame_(self):\n        return self.__frame_\n\n    @property\n    def TopRule_(self):\n        if self.Rules_:\n            return self.Rules_[0]\n        else:\n            print(f'Warning no rules recieved')\n            return 'tuple()'\n\n    @frame_.setter\n    def frame_(self, _frame_):\n        self.__frame_ = _frame_\n\n    @staticmethod\n    def _translated(_rl):\n        \"\"\" Makes the rule pd.DataFrame.query(*_rl) compatible \"\"\"\n\n        return _replace_str(_rl, keys=['&', ' is NA'], values=['and', ' == 0'])\n\n    @staticmethod\n    def _asH2O(_df: pd.DataFrame):\n        return h2o.H2OFrame(_df)\n\n    def fit(self, _xx: pd.DataFrame, _yy: pd.Series, **kw):\n\n        _xcols = list(_xx)\n\n        _x = _xx.reset_index().copy(deep=True)\n        _x['target'] = _yy\n\n        del _xx\n        del _yy\n\n        self.frame_ = _x\n        self.train(training_frame=self._asH2O(self.frame_),\n                   x=_xcols,\n                   y='target')\n\n        self.Rules_ =  list(self.process_rules_to_pd()['Rules'].values)\n        \n    def process_rules_to_pd(self) -> pd.DataFrame:\n        _rule_frame = self._model_json['output']['rule_importance'].as_data_frame()\n        return pd.DataFrame(\n            _rule_frame.sort_values(\n                'coefficient', ascending=False).query(\n                'coefficient > 0.0')['rule'].apply(\n                lambda r: self._translated(r))).rename(\n            columns={'rule': 'Rules'}).query('Rules != \"\"')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h2oRule = H2ORule()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns = list(map(lambda st: st.replace('(', '').replace(')', '').replace(' ', '_'), list(df)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = list(df)[:-1]\ntarget = list(df)[-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['target'] = df['target'].apply((lambda r: 1 if r != 1 else 0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h2oRule.fit(df[features], df[target].apply(lambda r: 1 if r != 1 else 0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h2oRule.Rules_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.scatterplot(data = df, x = 'petal_width_cm', y = 'petal_length_cm', hue = 'target');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.query(h2oRule.Rules_[0]).groupby('target')['target'].count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install wittgenstein","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wittgenstein as lw\nripper_clf = lw.RIPPER()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ripper_clf.fit(df[features], df[target])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ripper_clf.ruleset_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ripper_clf.ruleset_.__dict__['rules'][0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ripper_clf.ruleset_.__dict__['rules'][1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df.petal_width_cm.between(1.0,1.3)].groupby('target')['target'].count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"irep_clf = lw.IREP() # IREP","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"irep_clf.fit(df[features], df[target].apply(lambda r: 1 if r == 1 else 0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"irep_clf.ruleset_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ripper_clf.ruleset_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install skope-rules","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skrules import SkopeRules","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sk = SkopeRules(feature_names = features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sk.fit(df[features], df[target])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.query(sk.rules_[0][0]).groupby('target')['target'].count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.query(sk.rules_[0][0]).target.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### THIS IS PRETTY MUCH IT","metadata":{}},{"cell_type":"code","source":"# ### SKOPE RULES\n# sk.__dict__","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"irep_clf.__dict__['VALID_HYPERPARAMETERS']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ripper_clf.__dict__['VALID_HYPERPARAMETERS']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}