{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npd.set_option('display.max_columns', 500)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\nfrom warnings import simplefilter\nsimplefilter(action='ignore', category=FutureWarning)\nsimplefilter(action='ignore', category=DeprecationWarning)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/heart-disease-uci/heart.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def df_stats(df):\n    lines = df.shape[0]\n    d_types = df.dtypes\n    counts = df.apply(lambda x: x.count())\n    unique = df.apply(lambda x: x.unique().shape[0])\n    nulls = df.isnull().sum()\n    missing_ratio = (df.isnull().sum()/lines)*100\n    skew = df.skew()\n    kurt = df.kurt()\n    col_names = ['dtypes', 'counts', 'unique', 'nulls', 'missing_ratio', 'skewness', 'kurtosis']\n    temp = pd.concat([d_types, counts, unique, nulls, missing_ratio, skew, kurt], axis=1)\n    temp.columns = col_names\n    return temp\n    \nst = df_stats(data)\nst","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data, vars=['age', 'trestbps', 'chol', 'thalach', 'oldpeak'], hue='target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(18, 10))\nsns.heatmap(data.corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\nnum_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n\nfig, ax = plt.subplots(4, 2, figsize=(15, 25))\nfig.suptitle('Bar Plots of Categorical Data', fontsize=20)\n\ndef plot_cats(df, cols, target, ax):\n    pos = 1\n    sns.countplot(x=target, data=df, ax=ax[0, 0])\n    sns.countplot(x=cols[0], hue=target, data=df, ax=ax[0, 1])\n    for i in range(1, ax.shape[0]):\n        for j in range(ax.shape[1]):\n            sns.countplot(x=cols[pos], hue=target, data=df, ax=ax[i, j])\n            pos += 1\n            \n    plt.show()      \n        \nplot_cats(data, cat_cols, 'target', ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_numeric(df, cols, target):\n    for col in cols:\n        fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n        sns.distplot(a=df[col], ax=ax[0])\n        ax[0].set_title('distribution of {}, skew={:.4f}'.format(col, df[col].skew()))\n        sns.boxenplot(data=df, x=target, y=col, ax=ax[1])\n        ax[1].set_title('Boxen Plot Split by Target')\n    plt.show()\n        \nplot_numeric(data, num_cols, 'target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import PowerTransformer, StandardScaler\ndata[['oldpeak']] = PowerTransformer(method='yeo-johnson').fit_transform(data[['oldpeak']])\ndata[['age', 'trestbps', 'chol', 'thalach']] = StandardScaler().fit_transform(data[['age', 'trestbps', 'chol', 'thalach']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature Importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(data[data.columns[:-1]].values, data['target'].values)\n\nfig = plt.figure(figsize=(18, 8))\nimportance = pd.Series(rf.feature_importances_, index=data.columns[:-1]).sort_values(ascending=False)\nsns.barplot(x=importance, y=importance.index)\nplt.title('Feature Importance')\nplt.xlabel('Score')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[['cp','restecg', 'slope', 'ca', 'thal']] = data[['cp','restecg', 'slope', 'ca', 'thal']].astype(str)\ndata = pd.get_dummies(data)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data['target'].values\nX = data.drop(['target'], axis=1).values\nprint('Label shape:    {}'.format(y.shape))\nprint('Features shape: {}'.format(X.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The default Adaboost base estimator is a decision stump. it is a decision tree with a max depth of 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\n\nada_base = AdaBoostClassifier()\nada_deci = AdaBoostClassifier(DecisionTreeClassifier())\nada_extr = AdaBoostClassifier(ExtraTreeClassifier())\nada_logr = AdaBoostClassifier(LogisticRegression())\nada_svml = AdaBoostClassifier(SVC(probability=True , kernel='linear'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold, cross_val_score\ndef cv_score_model(mod, X, y, folds, scoring):\n    cv = StratifiedKFold(n_splits=folds, shuffle=True)\n    cv_estimate = cross_val_score(mod, X, y, cv=cv, scoring=scoring, n_jobs=4)\n    return np.mean(cv_estimate), np.std(cv_estimate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [ada_base, ada_deci, ada_extr, ada_logr, ada_svml]\nmodel_names = ['Base', 'DecisonTree', 'ExtraTree', 'LogisticRegression', 'SVC']\n\ndef fill_results_df(mod_list, name_list, scoring_list, X, y, folds):\n    \n    results = pd.DataFrame(index=name_list)\n    for score in scoring_list:\n        sc_mean = '{}_mean'.format(score)\n        sc_std = '{}_std'.format(score)\n        for name, model in zip(name_list, mod_list):\n            mean, std = cv_score_model(model, X, y, folds, score)\n            results.loc[name, sc_mean] = mean\n            results.loc[name, sc_std] = std\n    \n    return results\ns = ['roc_auc', 'accuracy', 'precision', 'recall']\nr = fill_results_df(models, model_names, s, X, y, 10)\nprint('Results from untuned classifiers')\nr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.base import clone\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base = clone(ada_base)\nbase.get_params()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv=StratifiedKFold(n_splits=10, shuffle=True)\n\nparam_grid={'n_estimators' :[50, 100, 250, 500, 750, 1000],\n            'learning_rate' :[0.0001, 0.001, 0.01, 0.1, 1]}\n\n\nbase_grid = GridSearchCV(estimator=base,\n                        param_grid=param_grid,\n                        cv=cv,\n                        scoring='roc_auc',\n                        return_train_score=True,\n                        n_jobs=4,\n                        verbose=1)\n\nbase_grid.fit(X, y)\nbase_best_mod = base_grid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('For Adaboost with default decision stump as base estimator\\n')\nprint('Best GridSearchCV Score roc_auc {}'.format(base_grid.best_score_))\nprint('Hyperparameters                 Values')\nprint('n_estimators:                    {}'.format(base_grid.best_estimator_.n_estimators))\nprint('learning_rate:                   {}'.format(base_grid.best_estimator_.learning_rate))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"deci = clone(ada_deci)\ndeci.get_params()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv=StratifiedKFold(n_splits=10, shuffle=True)\n\nparam_grid = {'base_estimator__max_depth' :[1, 2, 5],\n              'base_estimator__min_samples_split' :[2, 3 ,5],\n              'base_estimator__min_samples_leaf' :[2, 3, 5 ,10],\n              'n_estimators' :[10, 50, 100, 250, 500, 750, 1000],\n              'learning_rate' :[0.0001, 0.001, 0.01, 0.1, 1]}\n\n\ndeci_grid = GridSearchCV(estimator=deci,\n                        param_grid=param_grid,\n                        cv=cv,\n                        scoring='roc_auc',\n                        return_train_score=True,\n                        n_jobs=4,\n                        verbose=1)\n\ndeci_grid.fit(X, y)\ndeci_best_mod = deci_grid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('For Adaboost with decision tree as base estimator\\n')\nprint('Best GridSearchCV roc_auc Score {}'.format(deci_grid.best_score_))\nprint('Hyperparameters                   Values')\nprint('base_estimator__max_depth:          {}'.format(deci_grid.best_estimator_.base_estimator.max_depth))\nprint('base_estimator__min_samples_split:  {}'.format(deci_grid.best_estimator_.base_estimator.min_samples_split))\nprint('base_estimator__min_samples_leaf:   {}'.format(deci_grid.best_estimator_.base_estimator.min_samples_leaf))\nprint('n_estimators:                       {}'.format(deci_grid.best_estimator_.n_estimators))\nprint('learning_rate:                      {}'.format(deci_grid.best_estimator_.learning_rate))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"extr = clone(ada_extr)\nextr.get_params()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv=StratifiedKFold(n_splits=10, shuffle=True)\n\nparam_grid = {'base_estimator__criterion' :['gini', 'entropy'],\n              'base_estimator__max_depth' :[1, 2, 5],\n              'base_estimator__min_samples_split' :[2, 3 ,5],\n              'base_estimator__min_samples_leaf' :[2, 3, 5 ,10],\n              'n_estimators' :[10, 50, 100, 250, 500, 750, 1000],\n              'learning_rate' :[0.0001, 0.001, 0.01, 0.1, 1]}\n\n\n\nextr_grid = GridSearchCV(estimator=extr,\n                        param_grid=param_grid,\n                        cv=cv,\n                        scoring='roc_auc',\n                        return_train_score=True,\n                        n_jobs=4,\n                        verbose=1)\n\nextr_grid.fit(X, y)\nextr_best_mod = extr_grid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('For Adaboost with extra tree as base estimator\\n')\nprint('Best GridSearchCV roc_auc Score {}'.format(extr_grid.best_score_))\nprint('Hyperparameters                   Values')\nprint('base_estimator__criterion:          {}'.format(extr_grid.best_estimator_.base_estimator.criterion))\nprint('base_estimator__max_depth:          {}'.format(extr_grid.best_estimator_.base_estimator.max_depth))\nprint('base_estimator__min_samples_split:  {}'.format(extr_grid.best_estimator_.base_estimator.min_samples_split))\nprint('base_estimator__min_samples_leaf:   {}'.format(extr_grid.best_estimator_.base_estimator.min_samples_leaf))\nprint('n_estimators:                       {}'.format(extr_grid.best_estimator_.n_estimators))\nprint('learning_rate:                      {}'.format(extr_grid.best_estimator_.learning_rate))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logr = clone(ada_logr)\nlogr.get_params()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv=StratifiedKFold(n_splits=10, shuffle=True)\n\nparam_grid = {'base_estimator__C' :[0.01, 0.1, 1, 10, 50, 100, 500, 1000],\n              'n_estimators' :[10, 50, 100, 250, 500, 750, 1000],\n              'learning_rate' :[0.0001, 0.001, 0.01, 0.1, 1]}\n\n\n\nlogr_grid = GridSearchCV(estimator=logr,\n                        param_grid=param_grid,\n                        cv=cv,\n                        scoring='roc_auc',\n                        return_train_score=True,\n                        n_jobs=4,\n                        verbose=1)\n\nlogr_grid.fit(X, y)\nlogr_best_mod = logr_grid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('For Adaboost with logistic regression as base estimator\\n')\nprint('Best GridSearchCV roc_auc Score {}'.format(logr_grid.best_score_))\nprint('Hyperparameters           Values')\nprint('base_estimator__C:          {}'.format(logr_grid.best_estimator_.base_estimator.C))\nprint('n_estimators:               {}'.format(logr_grid.best_estimator_.n_estimators))\nprint('learning_rate:              {}'.format(logr_grid.best_estimator_.learning_rate))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svml = clone(ada_svml)\nsvml.get_params()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv=StratifiedKFold(n_splits=10, shuffle=True)\n\nparam_grid = {'base_estimator__C' :[0.01, 0.1, 1, 10, 50, 100, 500, 1000],\n              'n_estimators' :[10, 50, 100, 250, 500, 750, 1000],\n              'learning_rate' :[0.0001, 0.001, 0.01, 0.1, 1]}\n\n\n\nsvml_grid = GridSearchCV(estimator=svml,\n                        param_grid=param_grid,\n                        cv=cv,\n                        scoring='roc_auc',\n                        return_train_score=True,\n                        n_jobs=4,\n                        verbose=1)\n\nsvml_grid.fit(X, y)\nsvml_best_mod = svml_grid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('For Adaboost with linear kernal SVM as base estimator\\n')\nprint('Best GridSearchCV roc_auc Score {}'.format(svml_grid.best_score_))\nprint('Hyperparameters           Values')\nprint('base_estimator__C:          {}'.format(svml_grid.best_estimator_.base_estimator.C))\nprint('n_estimators:               {}'.format(svml_grid.best_estimator_.n_estimators))\nprint('learning_rate:              {}'.format(svml_grid.best_estimator_.learning_rate))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s = ['roc_auc', 'accuracy', 'precision', 'recall']\nmod_names = ['Base', 'DecisonTree', 'ExtraTree', 'LogisticRegression', 'SVC']\nmods = [clone(base_best_mod), clone(deci_best_mod), clone(extr_best_mod), clone(logr_best_mod), clone(svml_best_mod)]\n\nfinal_results = fill_results_df(mods, mod_names, s, X, y, 10)\nprint('Results from tuned classifiers')\nfinal_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3)\n\ndef grade_model(probs, thresh):\n    return np.array([1 if x>=thresh else 0 for x in probs[:,1]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_probs = []\nfor mod in mods:\n    temp_mod = clone(mod)\n    temp_mod.fit(X_train, y_train)\n    best_probs.append(temp_mod.predict_proba(X_test))\n    \nbest_scores = []\nfor pb in best_probs:\n    best_scores.append(grade_model(pb, .5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, auc, roc_curve\n\ndef plot_auc(labels, probs, ax, mod_name):\n    fpr, tpr, threshold = roc_curve(labels, probs[:,1])\n    roc = auc(fpr, tpr)\n    sns.lineplot(x=fpr, y=tpr, ax=ax, label = 'AUC = {:.4f}'.format(roc))\n    sns.lineplot(x=[0, 1], y=[0, 1], ax=ax)\n    ax.legend(loc = 'lower right')\n    ax.set_xlim([0, 1])\n    ax.set_ylim([0, 1])\n    ax.set_title('Receiver Operating Characteristic for {}'.format(mod_name))\n    ax.set_ylabel('True Positive Rate')\n    ax.set_xlabel('False Positive Rate')\n    return plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas.plotting import table\n\ndef plot_confusion(lab, scor, mod_name, ax):\n    conf = confusion_matrix(lab, scor)\n    tab = pd.DataFrame(conf, columns=['Score positive', 'Score negative'], index=['Actual positive', 'Actual negative'])\n    t = table(ax , tab, loc='center')\n    t.scale(1, 3)\n    ax.set_title('Confusion matrix for {}'.format(mod_name))\n    ax.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(5, 2, figsize=(15, 30))\n\nplot_confusion(y_test, best_scores[0], 'Base Adaboost', ax[0, 0])\nplot_auc(y_test, best_probs[0], ax[0, 1], 'Base Adaboost')\n\nplot_confusion(y_test, best_scores[1], 'DecisionTree Adaboost', ax[1, 0])\nplot_auc(y_test, best_probs[1], ax[1, 1], 'DecisionTree Adaboost')\n\nplot_confusion(y_test, best_scores[2], 'ExtraTree Adaboost', ax[2, 0])\nplot_auc(y_test, best_probs[2], ax[2, 1], 'ExtraTree Adaboost')\n\nplot_confusion(y_test, best_scores[3], 'Logistic Adaboost', ax[3, 0])\nplot_auc(y_test, best_probs[3], ax[3, 1], 'Logistic Adaboost')\n\nplot_confusion(y_test, best_scores[4], 'SVC Adaboost', ax[4, 0])\nplot_auc(y_test, best_probs[4], ax[4, 1], 'SVC Adaboost')\n\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}