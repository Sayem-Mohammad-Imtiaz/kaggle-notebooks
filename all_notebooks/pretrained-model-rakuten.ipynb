{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nimport matplotlib.pyplot as plt\n%matplotlib inline \nimport time\nimport cv2\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom statsmodels.graphics.gofplots import qqplot\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Model, load_model\nfrom keras.layers import Embedding, LSTM, Dropout, Dense, Input, Bidirectional, Flatten, Conv2D, MaxPooling2D, concatenate, Conv1D, MaxPooling1D, GlobalMaxPool1D\nimport keras.backend as K\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nfrom keras.applications.resnet50 import ResNet50\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras import layers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom gensim.models import KeyedVectors\nfrom tensorflow import keras\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications import DenseNet201\nfrom sklearn.preprocessing import LabelEncoder \nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, add\nfrom keras import layers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers.merge import concatenate\nfrom tensorflow.keras.utils import Sequence\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install nagisa\nimport nagisa\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pickle\n%tensorflow_version 2.x\nfrom keras import utils, layers, models, optimizers\nfrom keras.preprocessing import image\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"densenet_weights_path = '../input/densenet201-imagenet-pretrained-weights/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = pd.read_csv(\"../input/rakuten-multimodal-colour-extraction/X_train.csv\", index_col=0)\ny_train = pd.read_csv(\"../input/rakuten-multimodal-colour-extraction/y_train.csv\", index_col=0)\nX_test = pd.read_csv(\"../input/rakuten-multimodal-colour-extraction/X_test.csv\", index_col=0)\ntrain_clean = pd.read_csv('../input/rakuten-multimodal-colour-extraction/train_clean.csv')\ntest_clean = pd.read_csv('../input/rakuten-multimodal-colour-extraction/test_clean.csv')\nseparated_X_train = pd.read_csv('../input/d/xianlili/vectorized-x-train/separated_X_train.csv')\nseparated_X_test = pd.read_csv('../input/d/xianlili/vectorized-x-train/separated_X_test.csv')\nvectorized_X_test = pd.read_csv('../input/d/xianlili/vectorized-x-train/vectorized_X_test.csv', index_col=0)\nvectorized_X_train = pd.read_csv('../input/d/xianlili/vectorized-x-train/vectorized_X_train.csv', index_col=0)\npredict = pd.read_csv('../input/predict/predict.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorized_X_train[\"vectorized item name\"] = vectorized_X_train[\"vectorized item name\"].apply(lambda x : x.strip(\"[]\")).apply(lambda x : x.split(', ')).apply(lambda x : [float(element) for element in x] )\nvectorized_X_train[\"vectorized item description\"] = vectorized_X_train[\"vectorized item description\"].apply(lambda x : x.strip(\"[]\")).apply(lambda x : x.split(', ')).apply(lambda x : [float(element) for element in x] )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorized_X_test[\"vectorized item name\"] = vectorized_X_test[\"vectorized item name\"].apply(lambda x : x.strip(\"[]\")).apply(lambda x : x.split(', ')).apply(lambda x : [float(element) for element in x] )\nvectorized_X_test[\"vectorized item description\"] = vectorized_X_test[\"vectorized item description\"].apply(lambda x : x.strip(\"[]\")).apply(lambda x : x.split(', ')).apply(lambda x : [float(element) for element in x] )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\nDIM = 256\nIMG_DIM = (DIM, DIM)\nIMG_SHAPE = (DIM, DIM, 3)\nIMG_PREFIX  = \"../input/rakuten-multimodal-colour-extraction/images/images/\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.concat([\n    X_train,y_train,vectorized_X_train,train_clean,separated_X_train\n], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.loc[:,~train.columns.duplicated()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.dropna()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.concat([\n    X_test,vectorized_X_test,test_clean,separated_X_test,y_train\n], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.loc[:,~test.columns.duplicated()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.iloc[:37347,:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test = test.dropna()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_rakuten = train.copy()\n\nindex_train = int(train.shape[0]*0.7)\nindex_val = int(train.shape[0]*0.85)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df_rakuten.iloc[:index_train, :]\ndf_val = df_rakuten.iloc[index_train:index_val, :]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encode(encoder, colors):\n    # Encode colors to numerical array\n    indexes = encoder.transform(colors)\n    \n    # Create an array with 0s\n    encoded = np.zeros(len(encoder.classes_))\n    \n    # Put 1s at the specified indexes\n    encoded[indexes] = 1\n    \n    return encoded\n\ndef decode(encoder, encoded):\n    # Decode the encoded\n    decoded = np.where(encoded == 1)[0].ravel()\n            \n    # Get the colors\n    return encoder.inverse_transform(decoded)\n\ndef extract_colors(col):\n    colors = set()\n    \n    # Loop over the rows\n    for row in col.values:\n        # Some cleaning & list transformation\n        row = row[1:-1].split(', ')\n        # Loop over the elements of the list\n        for color in row:\n            # Quick clean\n            color = color.replace(\"'\", \"\")\n            # Add to the set\n            colors.add(color)\n        \n    return list(colors)\n\nclean_tags = lambda x: [e.replace(\"'\", \"\")  for e in x[1:-1].split(', ')]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# Get colors\ncolors = extract_colors(df_train['color_tags'])\n\n# Prepare the encoder for color tags\nencoder = LabelEncoder()\nencoder = encoder.fit(colors)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# Clean\ndf_train[\"color_tags\"] = df_train[\"color_tags\"].apply(clean_tags)\n\n# Create column encoded which are the encoded colors\ndf_train[\"encoded_colors\"] = df_train[\"color_tags\"].apply(lambda x: encode(encoder, x))\n\n# Clean\ndf_val[\"color_tags\"] = df_val[\"color_tags\"].apply(clean_tags)\n\n# Create column encoded which are the encoded colors\ndf_val[\"encoded_colors\"] = df_val[\"color_tags\"].apply(lambda x: encode(encoder, x))\n\n# Clean\ntest[\"color_tags\"] = test[\"color_tags\"].apply(clean_tags)\n\n# Create column encoded which are the encoded colors\ntest[\"encoded_colors\"] = test[\"color_tags\"].apply(lambda x: encode(encoder, x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[\"encoded_colors\"] = df_train[\"encoded_colors\"].apply(lambda x : [int(element) for element in x] )\ndf_val[\"encoded_colors\"] = df_val[\"encoded_colors\"].apply(lambda x : [int(element) for element in x] )\ntest[\"encoded_colors\"] = test[\"encoded_colors\"].apply(lambda x : [int(element) for element in x] )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(df_train))\ndf_train = df_train[df_train[\"color_tags\"].apply(len) < 4]\nprint(len(df_train))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(df_val))\ndf_val = df_val[df_val[\"color_tags\"].apply(len) < 4]\nprint(len(df_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MultiLabelBinarizer\nmlb = MultiLabelBinarizer()\nmlb.fit(df_train[\"color_tags\"].tolist())\nmlb.classes_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels = mlb.transform(df_train[\"color_tags\"].tolist())\ntrain_labels.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_labels = mlb.transform(df_val[\"color_tags\"].tolist())\nval_labels.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_labels = mlb.transform(test[\"color_tags\"].tolist())\ntest_labels.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df_train.drop(columns = ['item_name', 'item_caption', 'color_tags', 'item_description','Unnamed: 0','separated item name', 'separated item description'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val = df_val.drop(columns = ['item_name', 'item_caption', 'color_tags', 'item_description','Unnamed: 0','separated item name', 'separated item description'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.drop(columns = ['item_name', 'item_caption', 'color_tags', 'item_description','Unnamed: 0','separated item name', 'separated item description'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predict = predict.drop(columns = ['Unnamed: 0'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_predict = predict.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_predict[\"colors_tags\"] = df_predict[\"colors\"].apply(lambda x: decode(encoder, x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_predict[\"color_tags\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import backend as K\n#IMPLEMENTATION DE LA METRIC UTILISEE PAR LE CONCOURS F1\n\ndef f1(y_true, y_pred):\n    def recall(y_true, y_pred):\n        \"\"\"Recall metric.\n\n        Only computes a batch-wise average of recall.\n\n        Computes the recall, a metric for multi-label classification of\n        how many relevant items are selected.\n        \"\"\"\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + K.epsilon())\n        return recall\n\n    def precision(y_true, y_pred):\n        \"\"\"Precision metric.\n\n        Only computes a batch-wise average of precision.\n\n        Computes the precision, a metric for multi-label classification of\n        how many selected items are relevant.\n        \"\"\"\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n    precision = precision(y_true, y_pred)\n    recall = recall(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomSequenceGenerator(Sequence):\n\n    def __init__(self, df, dim=DIM, batch_size=10,\n                 n_classes=19, n_channels=3, vec_size=64, shuffle=True):\n        # Keras generator\n        self.image_dir = IMG_PREFIX\n        self.df = df\n        self.batch_size = batch_size\n        #self.csv_file = pd.read_csv(csv_file_path)\n        self.n_classes = n_classes\n        self.dim = dim\n        self.n_channels = n_channels\n        self.shuffle = shuffle\n        self.vec_size = vec_size\n\n        #self.csv_file.set_index('File', inplace=True, drop=True)\n\n    def __len__(self):\n        \"\"\"It is mandatory to implement it on Keras Sequence\"\"\"\n        return int(np.ceil(self.df.shape[0] / float(self.batch_size)))\n\n    def __getitem__(self, index):\n\n        # Generate indexes of the batch\n        samples = self.df.values[index * self.batch_size : (index + 1) * self.batch_size, : ]\n\n        x, y = self.__data_generation(samples, index)\n        return x, y\n\n    def __data_generation(self, samples, start_index):\n\n        x_batch_image = np.empty((self.batch_size, self.dim, self.dim, self.n_channels))\n        x_batch_vector_name = np.empty((self.batch_size, self.vec_size))\n        x_batch_vector_description = np.empty((self.batch_size, self.vec_size))\n        y_batch = np.empty((self.batch_size, self.n_classes))\n        #self.csv_file.reindex()\n        for i, sample in enumerate(samples):\n            image_file_path = self.image_dir + sample[0]\n            image = keras.preprocessing.image.load_img(image_file_path, target_size=IMG_DIM)\n\n            #features, labels = self.preprocess_csv(self.csv_file, sample, self.labels_dict, self.n_classes)\n            \n            x_batch_image[i] = image\n            x_batch_vector_name[i] = sample[1]\n            x_batch_vector_description[i] = sample[2]\n            y_batch[i] = sample[3]\n\n        return [x_batch_image, x_batch_vector_name, x_batch_vector_description], y_batch\n    \ntrain_generator = CustomSequenceGenerator(df_train)\nval_generator = CustomSequenceGenerator(df_val)\ntest_generator =  CustomSequenceGenerator(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications import DenseNet201\nfrom keras import optimizers\nfrom tensorflow import keras\n\ndef compile_model():\n    \n    vectorisation_inputs_name = Input(shape = (64,))\n    x1 = Dense(64, activation='relu')(vectorisation_inputs_name)\n    x1 = Dropout(0.3)(x1)\n    x1 = Dense(64, activation = \"relu\")(x1)\n    x1 = Dropout(0.3)(x1)\n    vectorisation_out_name = Dense(18, activation = 'relu')(x1)\n    \n    vectorisation_inputs_description = Input(shape = (64,))\n    x2 = Dense(64, activation='relu')(vectorisation_inputs_description)\n    x2 = Dropout(0.3)(x2)\n    x2 = Dense(64, activation = \"relu\")(x2)\n    x2 = Dropout(0.3)(x2)\n    vectorisation_out_description = Dense(18, activation = 'relu')(x2)\n\n    cnn_input = Input(shape=IMG_SHAPE)\n    y = DenseNet201(include_top = False, pooling = 'avg', weights=densenet_weights_path)(cnn_input)\n    cnn_out = Dense(512, activation='relu')(y)\n\n    concat_inp = concatenate([cnn_out, vectorisation_out_name, vectorisation_out_description])\n    z = Dense(256, activation='relu')(concat_inp)\n    z = Dropout(0.3)(z)\n    z = Dense(128, activation='relu')(z)\n    z = Dropout(0.3)(z)\n    output = Dense(train_labels.shape[1], activation='sigmoid')(z)\n\n    model = Model(inputs=[cnn_input, vectorisation_inputs_name, vectorisation_inputs_description], outputs=[output])\n    adam = Adam(lr=0.001, decay=1e-5)\n\n    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',f1])\n    \n    return model\n  \nmodel = compile_model()\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.layers[9].trainable = False #freeze DenseNet201","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [keras.callbacks.ModelCheckpoint(\"../input/model-densetext/save_at_{epoch}.h5\")]\nes = EarlyStopping(monitor='val_loss',patience=4)\n\nfit_history = model.fit_generator(\n        train_generator,\n        epochs = 15,\n        validation_data=val_generator,\n        callbacks = [callbacks,es]\n)\n\nmodel.save('model_image_text.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dependencies = {\n    'f1': f1\n}\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.load_model(\"../input/model-densetext/model_image_text.h5\", custom_objects=dependencies)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\npredict=model.predict(test_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nimport numpy\nnumpy.set_printoptions(threshold=sys.maxsize)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_predict = pd.DataFrame(data=predict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_predict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_predict.to_csv('./predict.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_predict = df_predict.drop(columns = ['Unnamed: 0'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_predict[df_predict > 0.2] = 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf_predict[df_predict < 0.2] = 0","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_predict.columns = ['Beige', 'Black', 'Blue', 'Brown', 'Burgundy', 'Gold', 'Green',\n       'Grey', 'Khaki', 'Multiple Colors', 'Navy', 'Orange', 'Pink',\n       'Purple', 'Red', 'Silver', 'Transparent', 'White', 'Yellow']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_predict['color_tags'] = df_predict.values.tolist()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_predict[\"colors\"] = df_predict[\"colors\"].apply(lambda x : [int(element) for element in x] )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss     = model.history['loss']\nval_loss = model.history['val_loss']\nacc      = model.history['accuracy']\nval_acc  = model.history['val_accuracy']\nf1       = model.history['f1']\nval_f1   = model.history['val_f1']\n\n# Visualize the history plots\nplt.figure()\nplt.plot(loss, 'b', label='Training loss')\nplt.plot(val_loss, 'm', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()\nplt.figure()\nplt.plot(acc, 'b', label='Training acc')\nplt.plot(f1, 'v', label='Training f1')\nplt.plot(val_acc, 'm', label='Validation acc')\nplt.plot(val_f1, 'y', label='Validation f1')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}