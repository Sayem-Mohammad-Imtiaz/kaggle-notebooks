{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Fake News detector**\n\nIn this very first NN model I make I try to use some 'sentiment analysis' (with conv1d) to try to detect fake news.\nI developed a Vocabulary class which converts words to indeces, based on frequency of words. This class in particular can be largely improved.\n\nI achieved an interesting result of 98%, which seems to be confirmed testing on titles available online.\n\nHowever the model sill has some issues might be resolved in the future:\n* Fake news seem to use CAPSLOCK much more often, this is not detected\n* Longer titles are more likely to be read as Fake, whereas shorter are read as Real"},{"metadata":{"id":"4lxFCxTdRtmK","outputId":"119a98ba-214c-440c-b3da-bd338eb8759a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, LSTM, Embedding, Flatten\n\nfrom sklearn.compose import ColumnTransformer","execution_count":null,"outputs":[]},{"metadata":{"id":"jBmymYWagKiZ"},"cell_type":"markdown","source":"Inspired from web."},{"metadata":{"id":"-JvA8JQsgHPQ","trusted":true},"cell_type":"code","source":"class Vocabulary:\n\n  def __init__(self,max_words):\n    self.max_words = max_words\n    self.word2index = {}\n    self.word2count = {}\n    self.index2word = {}\n    self.num_words = 0\n\n  def add_word(self, word):\n    if word not in self.word2count:\n      # First entry of word into vocabulary\n      self.word2count[word] = 1\n      self.num_words += 1\n    else:\n      # Word exists; increase word count\n      self.word2count[word] += 1\n          \n  def add_sentence(self, sentence):\n    for word in sentence.split(' '):\n      self.add_word(word.lower())\n\n  def consolidate(self):\n    self.index2word = {0 : \"NULL\"}\n\n    sortedList = [k for k, v in sorted(self.word2count.items(), key=lambda item: item[1],reverse=True)]\n    for idx in range(1,min(len(sortedList),self.max_words)+1):\n      self.index2word[idx] = sortedList[idx-1]\n    self.word2index = dict({(value,key) for (key,value) in self.index2word.items()})\n\n\n  def to_word(self, index):\n    return self.index2word[index]\n\n  def to_index(self, word):\n    return self.word2index[word]","execution_count":null,"outputs":[]},{"metadata":{"id":"zOKdPQbFSB3t","outputId":"9875136b-c94c-410e-a56a-8694a826fcad","trusted":true},"cell_type":"code","source":"Fake = pd.read_csv(\"/kaggle/input/fake-and-real-news-dataset/Fake.csv\",index_col=0,error_bad_lines=False,engine='python')\nReal = pd.read_csv(\"/kaggle/input/fake-and-real-news-dataset/True.csv\",index_col=0,error_bad_lines=False,engine='python')\nFake[\"Fake\"]=1\nReal[\"Fake\"]=0\ndata = pd.concat([Fake,Real])\ndata=data.sort_values(by='text')\n#data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Useful for later transformations"},{"metadata":{"id":"HB89cRkomMZf","trusted":true},"cell_type":"code","source":"def sent2list(sent):\n  idxList=[word2idx.get(word.lower(),0) for word in sent.split(' ')]\n  if 0 in idxList: idxList.remove(0)\n  return np.array(idxList)","execution_count":null,"outputs":[]},{"metadata":{"id":"OFJPbhLazCUk"},"cell_type":"markdown","source":"**Create word to index conversion and viceversa**"},{"metadata":{"id":"F9xqhLk1cFjX","trusted":true},"cell_type":"code","source":"num_words = 20000\n\nvoc = Vocabulary(num_words)\n\nfor sentence in data.index:\n  voc.add_sentence(sentence)\n\nvoc.consolidate()\n\nidx2word = voc.index2word\nword2idx = voc.word2index","execution_count":null,"outputs":[]},{"metadata":{"id":"YvWx3gZ7x4xG","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ny = data['Fake'].values\nX = data.index.values\n\nX = np.array([sent2list(sent) for sent in X])\n\nX_train, X_test, y_train, y_test = train_test_split(X,y)\n\n#[idx2word[idx] for idx in X[0]]","execution_count":null,"outputs":[]},{"metadata":{"id":"eH2YupWwiVX4","trusted":true},"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\n\nmax_words = 50\n\nX_train = pad_sequences(X_train, maxlen = max_words)\nX_test = pad_sequences(X_test, maxlen = max_words)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finished preprocessing, start the model"},{"metadata":{"id":"UsT3zjCljaip","outputId":"783e1746-31d0-4a5b-e83a-3096d4adce7d","trusted":true},"cell_type":"code","source":"from keras.layers.convolutional import Conv1D,MaxPooling1D\n\nmodel = Sequential()\nmodel.add(Embedding(num_words+1,75,input_length=max_words))\nmodel.add(LSTM(32, dropout=0.9, return_sequences=True))\nmodel.add(Conv1D(filters=32,kernel_size=3,padding='same',activation='relu'))\nmodel.add(MaxPooling1D())\nmodel.add(Flatten())\nmodel.add(Dropout(0.9))\nmodel.add(Dense(1,activation='sigmoid'))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"tu4HngJLkkqR","outputId":"7f3afdd0-e847-471d-a5f4-91fe10535b71","trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\nmodel.fit(X_train,y_train,batch_size=512,epochs=15,validation_split=0.2)\n\nmodel.evaluate(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"About 98% accuracy on test set"},{"metadata":{"id":"OxaC8yDyp-V_","trusted":true},"cell_type":"code","source":"def fake_or_not(y):\n  if y>0.75: return print(\"Fake\")\n  elif y>0.5: return print(\"Probably Fake\")\n  elif y>0.25: return print(\"Probably True\")\n  else: return print(\"True\")\n\nfrom re import sub\n\ndef preprocess(sent):\n    sent = sub(r'[^\\w\\s]','',sent)\n    return sent2list(sent)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random title from NYT"},{"metadata":{"id":"Aqc4yHF7mqDe","outputId":"87b90c08-b3c1-41cb-e529-3eaf475240f4","trusted":true},"cell_type":"code","source":"title = 'Facebook Points to ‘Signs of Stability’ as Ad Declines Flatten'\nsentTest = preprocess(title)\n\nsentTest = sentTest.reshape(1,sentTest.shape[0])\nsentTest\nsentTest = pad_sequences(sentTest, maxlen = max_words)\n\ny = model.predict(sentTest)\ny, fake_or_not(y)","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"FakeRealNews.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":4}