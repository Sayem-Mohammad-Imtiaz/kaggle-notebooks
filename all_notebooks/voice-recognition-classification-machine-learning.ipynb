{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Voice Recognition Classification","metadata":{}},{"cell_type":"markdown","source":"**Imports & Functions**","metadata":{}},{"cell_type":"code","source":"# Imports\nimport numpy as np\nimport pandas as pd\nfrom io import StringIO\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.metrics import confusion_matrix,precision_recall_fscore_support, accuracy_score, plot_confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import learning_curve, cross_val_score\n\nkfold = KFold(n_splits=5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Forest feature importance Function\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'Importance':m.feature_importances_}\n                       ).sort_values('Importance', ascending=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Forest feature importance Plot Function\ndef plot_fi(fi):\n    return fi.plot('cols', 'Importance', 'barh', figsize=(12,7), legend=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"### Reading the Dataset","metadata":{}},{"cell_type":"code","source":"voicef=r'voice.csv'\nvoiceDf = pd.read_csv(voicef)\nvoiceDf.head()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset Discription:\n<li>The goal is to classify the gender based on the voice features</li>\n<li>The dataset containts 21 columns including 20 attributes and 1 taregt values whcih is the gender</li>\n<li>The Dimensions of the dataset are 3167x21</li>","metadata":{}},{"cell_type":"markdown","source":"## Data Wrangling & visualization","metadata":{}},{"cell_type":"markdown","source":"### Dataset Attributes:\n\n<ol>\n<li>meanfreq: mean frequency (in kHz)</li>\n<li>sd: standard deviation of frequency</li>\n<li>median: median frequency (in kHz)</li>\n<li>Q25: first quantile (in kHz)</li>\n<li>Q75: third quantile (in kHz)</li>\n<li>IQR: interquantile range (in kHz)</li>\n<li>skew: skewness</li>\n<li>kurt: kurtosis</li>\n<li>sp.ent: spectral entropy</li>\n<li>sfm: spectral flatness</li>\n<li>centroid: frequency centroid (see specprop)</li>\n<li>peakf: peak frequency (frequency with highest energy)</li>\n<li>meanfun: average of fundamental frequency measured across acoustic signal</li>\n<li>minfun: minimum fundamental frequency measured across acoustic signal</li>\n<li>maxfun: maximum fundamental frequency measured across acoustic signal</li>\n<li>meandom: average of dominant frequency measured across acoustic signal</li>\n<li>mindom: minimum of dominant frequency measured across acoustic signal</li>\n<li>maxdom: maximum of dominant frequency measured across acoustic signal</li>\n<li>dfrange: range of dominant frequency measured across acoustic signal</li>\n<li>modindx: modulation index. Calculated as the accumulated absolute difference between adjacent measurements of fundamental frequencies divided by the frequency range </li>\n<li>label: male or female</li></ol>","metadata":{}},{"cell_type":"code","source":"voiceDf.dtypes.unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**As shown above all the features are numerical and the target value is an object.**","metadata":{}},{"cell_type":"code","source":"voiceDf.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**There's no missing data in any of the features in the dataset**\n\nnow we need to convert the laberl column into numerical to be able to visualize the dataset","metadata":{}},{"cell_type":"code","source":"voiceDf[\"label\"] = LabelEncoder().fit_transform(voiceDf[\"label\"]) # 1 -> male , 0-> female","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Visualization","metadata":{}},{"cell_type":"code","source":"sns.pairplot(voiceDf[['meanfreq', 'Q25', 'Q75', 'skew', 'centroid', 'label']], hue='label', size=2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**This pairplot is plotted to show the relations between the dataset features and we find that the skewness with the quartiles are having a weak relation unlike the meanfreq with the centroid as they have a strong relation.**","metadata":{}},{"cell_type":"code","source":"voiceDf.hist(figsize=(21, 10))\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The bar charts above to show if there is any outliers; and by looking at it we can se that the data does not contain alot of outliers and the highest features that contains outliers is the skewness  and kurt; also we can find that The Data is not biased as it is split evenly between the class (50% males, 50% females).**","metadata":{}},{"cell_type":"code","source":"f, ax = plt.subplots(figsize=(15, 10))\ncorr = voiceDf.corr()\nsns.heatmap(corr,mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n            square=True, ax=ax)\nplt.title('The Correlation Between Features')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**This Heatmap shows the correlations between the features; and by looking at it we find a positive correlation between the label and IQR, label and sp.ent, and a huge negative correlation between the label and meanfun.**","metadata":{}},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"**We first split the dataset into the feature, class**","metadata":{}},{"cell_type":"code","source":"gender_label = voiceDf.iloc[:, -1].to_numpy()\nvoiceDf1 = voiceDf.iloc[:, :-1]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Then splitting them into train, validation sub-datasets**","metadata":{}},{"cell_type":"code","source":"voiceX_train, voiceX_test, voiceY_train, voiceY_test = train_test_split(voiceDf1, gender_label, test_size=0.3, random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Scaling the dataset**\n- Fiting the scaler on the training features\n- Transforming the validation features\n","metadata":{}},{"cell_type":"code","source":"sc1= StandardScaler()\nvoiceX_train = sc1.fit_transform(voiceX_train)\nvoiceX_test = sc1.transform(voiceX_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Machine Learning Models","metadata":{}},{"cell_type":"markdown","source":"### K-Nearest Neighbor","metadata":{}},{"cell_type":"code","source":"# KNN test run to determine the optimal n_neighbors\nknn_valid_score_list=[]\nn_neighbors_num = [1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n\nfor i in range(1,15):\n    test_knn = KNeighborsClassifier(n_neighbors=i)\n    test_knn.fit(voiceX_train, voiceY_train)\n    knn_valid_score_list.append(test_knn.score(voiceX_test, voiceY_test))\n    \nplt.plot(n_neighbors_num,  knn_valid_score_list, \"b\")\nplt.plot(n_neighbors_num,  knn_valid_score_list, \"bo\")\nplt.xlabel(\"Neighbors Number\")\nplt.ylabel(\"Score %\")\nplt.grid(True)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**After this test train for the KNN we found that the best n_neighbor = 4 as shown in the figure above, so we train with the optimal parameter** ","metadata":{}},{"cell_type":"code","source":"# Best Model Build\nknn = KNeighborsClassifier(n_neighbors=4).fit(voiceX_train, voiceY_train)\n\n# Model Prediction\nvoice_pred_knn=knn.predict(voiceX_test)\nprf_knn=precision_recall_fscore_support(voiceY_test, voice_pred_knn, average='macro')\n\n# Model Evaluation Methods\nvoice_score_knn = accuracy_score(voice_pred_knn, voiceY_test)\naccuracy_results_knn = cross_val_score(knn, voiceX_train, voiceY_train, cv=kfold).mean()\nPrecision_knn = prf_knn[0]\nRecall_knn = prf_knn[1]\nf1_knn = prf_knn[2]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(knn,voiceX_test, voiceY_test, cmap='PuBuGn')\nplt.title('Confusion matrix of theKNN Model')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**After we calculated the different evaluation we plot the confution matrix**","metadata":{}},{"cell_type":"markdown","source":"### Support Vector Machine","metadata":{}},{"cell_type":"code","source":"# Model Build\nsvm = SVC().fit(voiceX_train,voiceY_train)\n\n# Model Prediction\nvoice_pred_svm=svm.predict(voiceX_test)\nprf_svm=precision_recall_fscore_support(voiceY_test, voice_pred_svm, average='macro')\n\n# Model Evaluation Methods\nvoice_score_svm = accuracy_score(voice_pred_svm, voiceY_test)\naccuracy_results_svm = cross_val_score(svm, voiceX_train, voiceY_train, cv=kfold).mean()\nPrecision_svm = prf_svm[0]\nRecall_svm = prf_svm[1]\nf1_svm = prf_svm[2]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(svm,voiceX_test, voiceY_test, cmap='PuBuGn')\nplt.title('Confusion matrix of theKNN Model')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**After we calculated the different evaluation we plot the confution matrix**","metadata":{}},{"cell_type":"markdown","source":"### Random Forest","metadata":{}},{"cell_type":"code","source":"# Model Build\nrf = RandomForestClassifier(n_estimators=100).fit(voiceX_train, voiceY_train)\n\n# Model Prediction\nvoice_pred_rf = rf.predict(voiceX_test)\nprf_rf=precision_recall_fscore_support(voiceY_test, voice_pred_rf, average='macro')\n\n# Model Evaluation Methods\nvoice_score_rf = accuracy_score(voice_pred_rf, voiceY_test)\naccuracy_results_rf = cross_val_score(rf, voiceX_train, voiceY_train, cv=kfold).mean()\nPrecision_rf = prf_rf[0]\nRecall_rf = prf_rf[1]\nf1_rf = prf_rf[2]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(rf,voiceX_test, voiceY_test, cmap='PuBuGn')\nplt.title('Confusion matrix of theKNN Model')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**After we calculated the different evaluation we plot the confution matrix**","metadata":{}},{"cell_type":"markdown","source":"**Also we can extract the importance of each feature according to the random forest classifier and plot it in a line chart**","metadata":{}},{"cell_type":"code","source":"rf_importance = rf_feat_importance(rf, voiceDf1)\nrf_importance.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_fi(rf_importance);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**we find that the meanfun is the most important feature among all the features then comes IQR**","metadata":{}},{"cell_type":"markdown","source":"## Learning Curves\nhere we plot the learning curves for all the models to give extra insight on the performance of the model","metadata":{}},{"cell_type":"code","source":"knn_train_sizes, knn_train_scores, knn_valid_scores, *_ = learning_curve(knn, voiceX_train, voiceY_train, n_jobs=-1,\n                                                        random_state=42, cv=3)\n\nsvm_train_sizes, svm_train_scores, svm_valid_scores, *_ = learning_curve(svm, voiceX_train, voiceY_train, n_jobs=-1,\n                                                        random_state=42, cv=3)\n\nrf_train_sizes, rf_train_scores, rf_valid_scores, *_ = learning_curve(rf, voiceX_train, voiceY_train, n_jobs=-1,\n                                                        random_state=42, cv=3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(15, 5))\nfig.suptitle('Learning Curve', fontsize=16)\n# The Training Plots\nsns.scatterplot(ax=axes[0], x= rf_train_sizes, y= rf_train_scores.mean(axis=1))\nsns.lineplot(ax=axes[0], x= rf_train_sizes, y= rf_train_scores.mean(axis=1))\nsns.scatterplot(ax=axes[0], x= svm_train_sizes, y= svm_train_scores.mean(axis=1))\nsns.lineplot(ax=axes[0], x= svm_train_sizes, y= svm_train_scores.mean(axis=1))\nsns.scatterplot(ax=axes[0], x= knn_train_sizes, y= knn_train_scores.mean(axis=1))\nsns.lineplot(ax=axes[0], x= knn_train_sizes, y= knn_train_scores.mean(axis=1))\naxes[0].set_title('Train')\naxes[0].set_xlabel('Data size')\naxes[0].set_ylabel('Score')\naxes[0].legend(['RF', 'SVM', 'KNN'])\n\n# The Validation Plots\nsns.scatterplot(ax=axes[1], x= rf_train_sizes, y= rf_valid_scores.mean(axis=1))\nsns.lineplot(ax=axes[1], x= rf_train_sizes, y= rf_valid_scores.mean(axis=1))\nsns.scatterplot(ax=axes[1], x= svm_train_sizes, y= svm_valid_scores.mean(axis=1))\nsns.lineplot(ax=axes[1], x= svm_train_sizes, y= svm_valid_scores.mean(axis=1))\nsns.scatterplot(ax=axes[1], x= knn_train_sizes, y= knn_valid_scores.mean(axis=1))\nsns.lineplot(ax=axes[1], x= knn_train_sizes, y= knn_valid_scores.mean(axis=1))\naxes[1].set_title('Valid')\naxes[1].set_xlabel('Data size')\naxes[1].set_ylabel('Score')\naxes[1].legend(['RF', 'SVM', 'KNN'])\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Models' Performance Evaluation Table\nthe below table compares the applied models using different evaluation metrics which are: `model.score`,`Cross Validation`,  `Precision`, `Recall`, `F1 Score` in order to see which model is the **optimal** model for this dataset","metadata":{}},{"cell_type":"code","source":"model_performance_table = pd.DataFrame({\n    'Model': ['SVM', 'KNN', 'RF'],\n    'Model Score': [voice_score_svm, voice_score_knn, voice_score_rf],\n    'Cross Validation': [accuracy_results_svm, accuracy_results_knn, accuracy_results_rf],\n    'Valid Precision': [Precision_svm, Precision_knn, Precision_rf],\n    'Valid Recall': [Recall_svm, Recall_knn, Recall_rf],\n    'Valid F1 Score': [f1_svm, f1_knn, f1_rf]\n})\n\nmodel_performance_table.sort_values(by=\"Model Score\", ascending=False)","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looking at the table above we find that the **Support Vectore Machine** Model achieved the best performance with accuracy of **98.1%** and the **Random Forest** Model comes the second with accuracy of **98%** which is only **0.1%** lower than the SVM.","metadata":{}}]}