{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Load Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path    # platform independent paths\nfrom IPython.display import Markdown, display\nimport pandas as pd\nfrom nltk.probability import FreqDist    # frequency dictionary\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set figure size\nplt.rcParams['figure.figsize'] = [20, 10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## User-defined Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def printmd(string, color=None):\n    ''' NOT MINE\n    Markdown printing from a code cell\n    Ex. printmd(\"**bold and blue**\", color=\"blue\")\n    https://stackoverflow.com/questions/23271575/printing-bold-colored-etc-text-in-ipython-qtconsole\n    '''\n    colorstr = \"<span style='color:{}'>{}</span>\".format(color, string)\n    display(Markdown(colorstr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def freq_dist(some_list, min_freq = 1, exact_freq = 1, top = 0):\n    '''\n    Adding in fucntionality to FreqDist\n    Need to add in raise errors if more than one optional argument used.\n    '''\n    temp = FreqDist(some_list)\n    if (min_freq != 1):\n        temp = [(k, v) for k, v in temp.items() if v > min_freq]\n        temp.sort(key=lambda x: x[1], reverse = True)\n        return temp\n    elif (exact_freq != 1):\n        temp = [(k, v) for k, v in temp.items() if v == exact_freq]\n        return temp\n    elif (top != 0):\n        return temp.most_common(top)\n    else:\n        temp = [(k, v) for k, v in temp.items()]\n        temp.sort(key=lambda x: x[1], reverse = True)\n        return temp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Files"},{"metadata":{"trusted":true},"cell_type":"code","source":"# File locations\nfile_neg = Path('../input/comments_negative.csv')\nfile_pos = Path('../input/comments_positive.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load into dataframes\ndf_neg = pd.read_csv(file_neg)\ndf_pos = pd.read_csv(file_pos)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_neg = df_neg.sample(n=100000, random_state=1)\n#df_pos = df_pos.sample(n=100000, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_neg.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pos.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Combine positive and negative comment data sets and exclude those without text or parent text fields"},{"metadata":{"trusted":true},"cell_type":"code","source":"totalDF = pd.concat([df_pos,df_neg])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"totalDF = totalDF[totalDF['text'].notnull()]\ntotalDF = totalDF[totalDF['parent_text'].notnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pos = 5\ndf_neg = 5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bin scores to give < -1000, < -100, -100 < 100, >100, >1000 as our labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"conditions = [\n    (totalDF['score'] < -1000) ,\n    (totalDF['score'] > -1000) & (totalDF['score'] < -100),\n    (totalDF['score'] > -100) & (totalDF['score'] < 100),\n    (totalDF['score'] > 100) & (totalDF['score'] < 1000),\n    (totalDF['score'] > 1000)]\nchoices = [-2, -1, 0,1,2]\ntotalDF['category'] = np.select(conditions, choices, default=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split dataset in half to allow test and training, due to using transfer learning from BERT interesting to assess whether training/fine tuning bert on a small subset of the data is effective"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(totalDF, totalDF[\"category\"], test_size=0.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"install bert libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n!pip install bert\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install bert-tensorflow","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport tensorflow_hub as hub\nimport os\nimport re\nimport numpy as np\nfrom bert.tokenization import FullTokenizer\nfrom tqdm import tqdm_notebook\nfrom tensorflow.keras import backend as K\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize session\nsess = tf.Session()\n\n# Params for bert model and tokenization\nbert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"sample training data to a smaller subset of 100k reddit posts to allow quicker fitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train =  X_train.sample(n=500000, random_state=1)\n#X_train =  X_train.sample(n=100000, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#max_seq_length = 32\nmax_seq_length = 18\n\n# Create datasets (Only take up to max_seq_length words for memory)\ntrain_text = X_train['text'].tolist()\ntrain_text = [' '.join(t.split()[0:max_seq_length]) for t in train_text]\ntrain_text = np.array(train_text, dtype=object)[:, np.newaxis]\n\n\n#train_label = totalDF['score'].tolist()\ntrain_label = X_train['category'].tolist()\n\ntrain2_text = X_train['parent_text'].tolist()\ntrain2_text = [' '.join(t.split()[0:max_seq_length]) for t in train2_text]\ntrain2_text = np.array(train2_text, dtype=object)[:, np.newaxis]\n\ntest_text = X_test['text'].tolist()\ntest_text = [' '.join(t.split()[0:max_seq_length]) for t in test_text]\ntest_text = np.array(test_text, dtype=object)[:, np.newaxis]\n\ntest2_text = X_test['parent_text'].tolist()\ntest2_text = [' '.join(t.split()[0:max_seq_length]) for t in test2_text]\ntest2_text = np.array(test2_text, dtype=object)[:, np.newaxis]\n\ntest_label =  X_test['category'].tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check what label bins are represented in the test and train data (sometimes doesn't capture any -2 scores (<-1000)"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.unique(train_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.unique(test_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_label = totalDF[.tolist()\n# train_text = totalDF['text'].tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is a modified version of Jacob Zweig's code for using bert with tensorflow https://towardsdatascience.com/bert-in-keras-with-tensorflow-hub-76bcbc9417b.\n\nModifications have been made to add parent_text and the text of the reddit post itself as inputs rather than just one text feature."},{"metadata":{"trusted":true},"cell_type":"code","source":"class PaddingInputExample(object):\n    \"\"\"Fake example so the num input examples is a multiple of the batch size.\n  When running eval/predict on the TPU, we need to pad the number of examples\n  to be a multiple of the batch size, because the TPU requires a fixed batch\n  size. The alternative is to drop the last batch, which is bad because it means\n  the entire output data won't be generated.\n  We use this class instead of `None` because treating `None` as padding\n  battches could cause silent errors.\n  \"\"\"\n\nclass InputExample(object):\n    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n\n    def __init__(self, guid, text_a, text_b=None, label=None):\n        \"\"\"Constructs a InputExample.\n    Args:\n      guid: Unique id for the example.\n      text_a: string. The untokenized text of the first sequence. For single\n        sequence tasks, only this sequence must be specified.\n      text_b: (Optional) string. The untokenized text of the second sequence.\n        Only must be specified for sequence pair tasks.\n      label: (Optional) string. The label of the example. This should be\n        specified for train and dev examples, but not for test examples.\n    \"\"\"\n        self.guid = guid\n        self.text_a = text_a\n        self.text_b = text_b\n        self.label = label\n\ndef create_tokenizer_from_hub_module():\n    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n    bert_module =  hub.Module(bert_path)\n    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n    vocab_file, do_lower_case = sess.run(\n        [\n            tokenization_info[\"vocab_file\"],\n            tokenization_info[\"do_lower_case\"],\n        ]\n    )\n\n    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n\ndef convert_single_example(tokenizer, example, max_seq_length=256):\n    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n\n    if isinstance(example, PaddingInputExample):\n        input_ids = [0] * max_seq_length\n        input_mask = [0] * max_seq_length\n        segment_ids = [0] * max_seq_length\n        label = 0\n        return input_ids, input_mask, segment_ids, label\n\n    tokens_a = tokenizer.tokenize(example.text_a)\n    if len(tokens_a) > max_seq_length - 2:\n        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n\n    tokens = []\n    segment_ids = []\n    tokens.append(\"[CLS]\")\n    segment_ids.append(0)\n    for token in tokens_a:\n        tokens.append(token)\n        segment_ids.append(0)\n    tokens.append(\"[SEP]\")\n    segment_ids.append(0)\n\n    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n\n    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n    # tokens are attended to.\n    input_mask = [1] * len(input_ids)\n\n    # Zero-pad up to the sequence length.\n    while len(input_ids) < max_seq_length:\n        input_ids.append(0)\n        input_mask.append(0)\n        segment_ids.append(0)\n\n    assert len(input_ids) == max_seq_length\n    assert len(input_mask) == max_seq_length\n    assert len(segment_ids) == max_seq_length\n\n    return input_ids, input_mask, segment_ids, example.label\n\ndef convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n\n    input_ids, input_masks, segment_ids, labels = [], [], [], []\n    for example in tqdm_notebook(examples, desc=\"Converting examples to features\"):\n        input_id, input_mask, segment_id, label = convert_single_example(\n            tokenizer, example, max_seq_length\n        )\n        input_ids.append(input_id)\n        input_masks.append(input_mask)\n        segment_ids.append(segment_id)\n        labels.append(label)\n    return (\n        np.array(input_ids),\n        np.array(input_masks),\n        np.array(segment_ids),\n        np.array(labels).reshape(-1, 1),\n    )\n\ndef convert_text_to_examples(texts, labels):\n    \"\"\"Create InputExamples\"\"\"\n    InputExamples = []\n    for text, label in zip(texts, labels):\n        InputExamples.append(\n            InputExample(guid=None, text_a=\" \".join(text), text_b=None, label=label)\n        )\n    return InputExamples\n\n# Instantiate tokenizer\ntokenizer = create_tokenizer_from_hub_module()\n\n# Convert data to InputExample format\ntrain_examples = convert_text_to_examples(train_text, train_label)\ntrain2_examples = convert_text_to_examples(train2_text, train_label)\ntest_examples = convert_text_to_examples(test_text, test_label)\ntest2_examples = convert_text_to_examples(test2_text, test_label)\n\n# Convert to features\n(train_input_ids, train_input_masks, train_segment_ids, train_labels \n) = convert_examples_to_features(tokenizer, train_examples, max_seq_length=max_seq_length)\n\n(train2_input_ids, train2_input_masks, train2_segment_ids, train_labels \n) = convert_examples_to_features(tokenizer, train2_examples, max_seq_length=max_seq_length)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now have  tokenized masks and segment ids for bert layer to use"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_label[4]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"one hot encode training labels to use with 5 wide NN output layer"},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn\nlabel_binarizer = sklearn.preprocessing.LabelBinarizer()\nlabel_binarizer.fit([-2,-1,0,1,2])\ntrain_label_bak = train_labels\ntrain_labels = label_binarizer.transform(train_labels)\n#test_labels = label_binarizer.transform(test_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(train_label_bak,10, facecolor='blue', alpha=0.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_labels = pd.get_dummies(train_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create NN model using Bert once again this was taken from Jacob Zweig's notebook"},{"metadata":{"trusted":true},"cell_type":"code","source":"class BertLayer(tf.keras.layers.Layer):\n    def __init__(\n        self,\n        n_fine_tune_layers=10,\n        pooling=\"first\",\n        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n        **kwargs,\n    ):\n        self.n_fine_tune_layers = n_fine_tune_layers\n        self.trainable = True\n        self.output_size = 768\n        self.pooling = pooling\n        self.bert_path = bert_path\n        if self.pooling not in [\"first\", \"mean\"]:\n            raise NameError(\n                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n            )\n\n        super(BertLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.bert = hub.Module(\n            self.bert_path, trainable=self.trainable, name=f\"{self.name}_module\"\n        )\n\n        # Remove unused layers\n        trainable_vars = self.bert.variables\n        if self.pooling == \"first\":\n            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n            trainable_layers = [\"pooler/dense\"]\n\n        elif self.pooling == \"mean\":\n            trainable_vars = [\n                var\n                for var in trainable_vars\n                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n            ]\n            trainable_layers = []\n        else:\n            raise NameError(\n                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n            )\n\n        # Select how many layers to fine tune\n        for i in range(self.n_fine_tune_layers):\n            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n\n        # Update trainable vars to contain only the specified layers\n        trainable_vars = [\n            var\n            for var in trainable_vars\n            if any([l in var.name for l in trainable_layers])\n        ]\n\n        # Add to trainable weights\n        for var in trainable_vars:\n            self._trainable_weights.append(var)\n\n        for var in self.bert.variables:\n            if var not in self._trainable_weights:\n                self._non_trainable_weights.append(var)\n\n        super(BertLayer, self).build(input_shape)\n\n    def call(self, inputs):\n        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n        input_ids, input_mask, segment_ids = inputs\n        bert_inputs = dict(\n            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n        )\n        if self.pooling == \"first\":\n            pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n                \"pooled_output\"\n            ]\n        elif self.pooling == \"mean\":\n            result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n                \"sequence_output\"\n            ]\n\n            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n            input_mask = tf.cast(input_mask, tf.float32)\n            pooled = masked_reduce_mean(result, input_mask)\n        else:\n            raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\n\n        return pooled\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], self.output_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define metrics to measure during runtime of keras\ndef f1(y_true, y_pred):\n    def recall(y_true, y_pred):\n        \"\"\"Recall metric.\n\n        Only computes a batch-wise average of recall.\n\n        Computes the recall, a metric for multi-label classification of\n        how many relevant items are selected.\n        \"\"\"\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + K.epsilon())\n        return recall\n\n    def precision(y_true, y_pred):\n        \"\"\"Precision metric.\n\n        Only computes a batch-wise average of precision.\n\n        Computes the precision, a metric for multi-label classification of\n        how many selected items are relevant.\n        \"\"\"\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n    precision = precision(y_true, y_pred)\n    recall = recall(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n# Build model\ndef build_model(max_seq_length): \n    # add width to acommodate combined parent_text and text features\n    in_id = tf.keras.layers.Input(shape=(max_seq_length*2,), name=\"input_ids\")\n    in_mask = tf.keras.layers.Input(shape=(max_seq_length*2,), name=\"input_masks\")\n    in_segment = tf.keras.layers.Input(shape=(max_seq_length*2,), name=\"segment_ids\")\n    bert_inputs = [in_id, in_mask, in_segment]\n    \n    bert_output = BertLayer(n_fine_tune_layers=3, pooling=\"first\")(bert_inputs)\n    #dense = tf.keras.layers.Dense(256, activation='relu')(bert_output)\n    dense = tf.keras.layers.Dense(42, activation='relu')(bert_output)\n    #pred = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n    pred = tf.keras.layers.Dense(5, activation='softmax')(dense)\n    \n    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n    #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1])\n    model.summary()\n    \n    return model\n\ndef initialize_vars(sess):\n    sess.run(tf.local_variables_initializer())\n    sess.run(tf.global_variables_initializer())\n    sess.run(tf.tables_initializer())\n    K.set_session(sess)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"combine ids masks and segment ids into one array"},{"metadata":{"trusted":true},"cell_type":"code","source":"train3_input_ids = np.hstack((train_input_ids, train2_input_ids))\ntrain3_input_masks = np.hstack((train_input_masks, train2_input_masks))\ntrain3_segment_ids = np.hstack((train_segment_ids, train2_segment_ids))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Run Bert model with combined parent_text and text input parameters as our features"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"model = build_model(max_seq_length)\n\n# Instantiate variables\ninitialize_vars(sess)\n\nmodel.fit(\n    [train3_input_ids, train3_input_masks, train3_segment_ids], \n    train_labels,\n   # validation_data=([test_input_ids, test_input_masks, test_segment_ids], test_labels),\n    epochs=1,\n    batch_size=32\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('BertModel.h5')\n# pre_save_preds = model.predict([test3_input_ids[0:100], \n#                                 test3_input_masks[0:100], \n#                                 test3_segment_ids[0:100]]\n#                               ) # predictions before we clear and reload model\n\n# # Clear and load model\n# model = None\n# model = build_model(max_seq_length)\n# initialize_vars(sess)\n# model.load_weights('BertModel.h5')\n\n#post_save_preds = model.predict([test3_input_ids[0:100], \n                             #   test3_input_masks[0:100], \n                           #     test3_segment_ids[0:100]]\n                         #     ) # predictions after we clear and reload model\n#all(pre_save_preds == post_save_preds) # Are they the same?","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Assess the metrics of training error using F1 score, we will check later how well this translates against the full set of test data we split out previously"},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.evaluate( [train3_input_ids, train3_input_masks, train3_segment_ids], \n    train_labels, \n                        verbose=1)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check class performance for very negative posts\nVNeg = train_labels[:,0] == 1\n\n\n\n\nscores = model.evaluate( [train3_input_ids[VNeg], train3_input_masks[VNeg], train3_segment_ids[VNeg]], \n    train_labels[VNeg], \n                        verbose=1)\nprint(\"Very Negative Class performance %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check class performance for very postive posts\nVNeg = train_labels[:,4] == 1\n\n\n\nscores = model.evaluate( [train3_input_ids[VNeg], train3_input_masks[VNeg], train3_segment_ids[VNeg]], \n    train_labels[VNeg], \n                        verbose=1)\nprint(\"Very Positive Class performance %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In prior modelling it was found that parent_score is an especially useful feature, this alone outperformed all other features we used when we had only used TF IDF to vectorise the text features.\n\n\nSo I will build a second model which also uses parent_score in the final relu hidden layer, for this it will have to bypass the bert layer and go directly from input layer to the final hidden layer."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Input, Conv1D, Dense, concatenate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model2(max_seq_length): \n    in_id = tf.keras.layers.Input(shape=(max_seq_length*2,), name=\"input_ids\")\n    in_mask = tf.keras.layers.Input(shape=(max_seq_length*2,), name=\"input_masks\")\n    in_segment = tf.keras.layers.Input(shape=(max_seq_length*2,), name=\"segment_ids\")\n\n        \n    in_non_bert = tf.keras.layers.Input(shape=(1,), name=\"parent_score\")\n    \n    all_inputs = [in_id, in_mask, in_segment,in_non_bert]\n    bert_inputs = [in_id, in_mask, in_segment]\n\n    \n    bert_output = BertLayer(n_fine_tune_layers=3, pooling=\"first\")(bert_inputs)\n    #dense = tf.keras.layers.Dense(256, activation='relu')(bert_output)\n    merged = tf.keras.layers.concatenate([bert_output, in_non_bert])\n    dense = tf.keras.layers.Dense(42, activation='relu')( merged)\n    #pred = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n    pred = tf.keras.layers.Dense(5, activation='softmax')(dense)\n    \n    model = tf.keras.models.Model(inputs=all_inputs , outputs=pred)\n    #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1])\n    model.summary()\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create a new variable just containing all the training set parent scores"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_parent_scores = X_train['parent_score']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_parent_scores = train_parent_scores.as_matrix()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Run the second model with combined text parent_text and Parent_score features"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"model2 = build_model2(max_seq_length)\n\n# Instantiate variables\ninitialize_vars(sess)\n\nmodel2.fit(\n    [train3_input_ids, train3_input_masks, train3_segment_ids,train_parent_scores], \n    train_labels,\n   # validation_data=([test_input_ids, test_input_masks, test_segment_ids], test_labels),\n    epochs=1,\n    batch_size=32\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model2.evaluate( [train3_input_ids, train3_input_masks, train3_segment_ids,train_parent_scores], \n    train_labels, \n                        verbose=1)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I'm very interested in the per class performance especially for -2 and +2 as they're relatively rare"},{"metadata":{"trusted":true},"cell_type":"code","source":"# check class performance for very postive posts\nVNeg = train_labels[:,4] == 1\n\n\n\nscores = model2.evaluate( [train3_input_ids[VNeg], train3_input_masks[VNeg], train3_segment_ids[VNeg]], \n    train_labels[VNeg], \n                        verbose=1)\nprint(\"Very Positive Class performance %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check class performance for very postive posts\nVNeg = train_labels[:,0] == 1\n\n\n\nscores = model2.evaluate( [train3_input_ids[VNeg], train3_input_masks[VNeg], train3_segment_ids[VNeg]], \n    train_labels[VNeg], \n                        verbose=1)\nprint(\"Very Positive Class performance %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"tokenize and create test data masks"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(test_input_ids, test_input_masks, test_segment_ids, test_labels \n) = convert_examples_to_features(tokenizer, test_examples, max_seq_length=max_seq_length)\n\n(test2_input_ids, test2_input_masks, test2_segment_ids, test_labels \n) = convert_examples_to_features(tokenizer, test2_examples, max_seq_length=max_seq_length)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test3_input_ids = np.hstack((test_input_ids, test2_input_ids))\ntest3_input_masks = np.hstack((test_input_masks, test2_input_masks))\ntest3_segment_ids = np.hstack((test_segment_ids, test2_segment_ids))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test2_examples\ntest_parent_scores = X_test['parent_score']\ntest_parent_scores = test_parent_scores.as_matrix()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test3_input_ids.shape)\nprint(test3_input_masks.shape)\nprint(test3_segment_ids.shape)\nprint(test_labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Evalutate first model with only text features performance (this usually takes 2 hrs on a GTX 1080 level GPU)"},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.evaluate([test3_input_ids, \n                                test3_input_masks, \n                                test3_segment_ids],\n                        test_labels, \n                        verbose=1)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Evalutate second model with text features and parent_score feature's performance (this usually takes 2 hrs on a GTX 1080 level GPU)"},{"metadata":{"trusted":true},"cell_type":"code","source":"scores2 = model2.evaluate([test3_input_ids, \n                                test3_input_masks, \n                                test3_segment_ids,test_parent_scores],\n                        test_labels, \n                        verbose=1)\nprint(\"%s: %.2f%%\" % (model2.metrics_names[1], scores2[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}