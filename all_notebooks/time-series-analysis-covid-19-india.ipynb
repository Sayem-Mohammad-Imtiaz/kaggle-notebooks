{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Overview\n\n### **Context**\n###### Coronaviruses are a large family of viruses which may cause illness in animals or humans. In humans, several coronaviruses are known to cause respiratory infections ranging from the common cold to more severe diseases such as Middle East Respiratory Syndrome (MERS) and Severe Acute Respiratory Syndrome (SARS). The most recently discovered coronavirus causes coronavirus disease COVID-19 - World Health Organization\n\n###### The number of new cases are increasing day by day around the world. This dataset has information from the states and union territories of India at daily level.\n\n### **I use Time series analysis to understand the data better and to answer many questions which may arise.**\n\n## So what is Time Series?\n\n###   1. **A time series is a series of data points indexed (or listed or graphed) in time order. Most commonly, a time series is a sequence taken at successive equally spaced points in time. Thus it is a sequence of discrete-time data.**\n###   2. **An observed time series can be decomposed into three components:** \n       * the trend (long term direction)\n       * the seasonal (systematic, calendar related movements) \n       * the irregular (unsystematic, short term fluctuations).\n###   3. **Time series analysis is a statistical technique that deals with time series data, or trend analysis. Time series data means that data is in a series of particular time periods or intervals.** \n       \n## **How to do a time series analysis?**\n\n#### Step 1: Visualize the Time Series. )It is essential to analyze the trends prior to building any kind of time series model)\n#### Step 2: Stationarize/Decompose the Series\n#### Step 3: Find Optimal Parameters\n#### Step 4: Build ARIMA Model\n#### Step 5: Make Predictions"},{"metadata":{},"cell_type":"markdown","source":"# Import libraries & Read file "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import warnings\nimport itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nwarnings.filterwarnings(\"ignore\")\nplt.style.use('fivethirtyeight')\nimport pandas as pd\nimport statsmodels.api as sm\nimport matplotlib\nmatplotlib.rcParams['axes.labelsize'] = 14\nmatplotlib.rcParams['xtick.labelsize'] = 12\nmatplotlib.rcParams['ytick.labelsize'] = 12\nmatplotlib.rcParams['text.color'] = 'k'\n\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/covid19-in-india/covid_19_india.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Insights of Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"try :\n    df.drop('Unnamed: 9',axis=1,inplace= True)\n    df.shape\nexcept : \n    print('Done')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['Deaths'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try :\n    a=[]\n    for i in df['Deaths'].values:\n        if '\\xa0' in i:\n            a.append(int(i.replace(\"\\xa0\", '')))\n        else:\n            a.append(int(i))\n\n    df['Deaths'] = a\n    len(a)\nexcept:\n    pass\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['Deaths'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Deaths'].astype('int64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['State/UnionTerritory'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df['State/UnionTerritory'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def drop_star(df):\n    for i in df['State/UnionTerritory'].iteritems():\n        if i[1][-3:] == \"***\":\n            df.drop(i[0],inplace=True)\n        \ndrop_star(df)\ndf['State/UnionTerritory'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df['State/UnionTerritory'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visualizations"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Cured'].plot(alpha=0.8)\ndf['Deaths'].plot(alpha=0.3)\ndf['Confirmed'].plot(alpha=0.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('State/UnionTerritory')['Confirmed'].plot()\nplt.show()\ndf.groupby('State/UnionTerritory')['Deaths'].plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Datetime'] = df['Date']+' '+df['Time']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* adding both columns for easy time series analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"l = df.groupby('State/UnionTerritory')\ncurrent = l.last()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig ,ax = plt.subplots(figsize= (12,8))\nplt.title('Top 10 Contaminated States')\ncurrent = current.sort_values(\"Confirmed\",ascending=False)[:10]\np = sns.barplot(ax=ax,x= current.index,y=current['Confirmed'])\np.set_xticklabels(labels = current.index,rotation=90)\np.set_yticklabels(labels=(p.get_yticks()*1).astype(int))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* ### Maharashtra being the most contaminated state followed byKarnataka and Andhra Pradesh with approximately equal cases. "},{"metadata":{"trusted":true},"cell_type":"code","source":"l = df.groupby('State/UnionTerritory')\ncurrent = l.last()\ncurrent = current.sort_values(\"Confirmed\",ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Date'].min(), df['Date'].max()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Time Series Analysis For RAJASTHAN State\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"Raj = df.loc[df['State/UnionTerritory'] == 'Rajasthan']\nRaj.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Raj.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Checking the data for any null/ missing value"},{"metadata":{"trusted":true},"cell_type":"code","source":"Raj.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Raj.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### - Dropping all other columns and using only \"Date+Time and Confirmed Cases\""},{"metadata":{"trusted":true},"cell_type":"code","source":"cols=['Sno', 'Time', 'State/UnionTerritory',\n       'ConfirmedIndianNational', 'ConfirmedForeignNational', 'Cured',\n       'Deaths']\nRaj['Date'] = Raj['Date']+' '+Raj['Time']\nRaj.drop(cols, axis=1, inplace=True)\nRaj= Raj.sort_values('Date')\nRaj.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Raj.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Raj.index","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### - The initial index is Sr.no so lets change it to ****\" Date \"****."},{"metadata":{"trusted":true},"cell_type":"code","source":"Raj = Raj.groupby('Date')['Confirmed'].sum().reset_index()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Raj = Raj.set_index('Date')\nRaj.index = pd.to_datetime(Raj.index)\nRaj.index","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### - Resampling with 'W' means we are taking the weekly data from the whole time period. (Every Sunday)"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = Raj['Confirmed'].resample('W').mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"y.fillna(method='ffill',inplace=True)\ny['2020':]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Raj.plot(figsize=(16, 6))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### - The above is initial graph showing the increasing trend and seasonality in the data."},{"metadata":{},"cell_type":"markdown","source":"### Now lets plot the Decomposition Plot which shows :\n   - orignal data\n   - Trend in the data\n   - Seasonality \n   - Residual \n     "},{"metadata":{"trusted":true},"cell_type":"code","source":"from pylab import rcParams\nrcParams['figure.figsize'] = 18, 8\ndecomposition = sm.tsa.seasonal_decompose(y, freq = 20, model='additive')\nfig = decomposition.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### But why do we decompose time series?\n###### When we decompose a time series into components, we usually combine the trend and cycle into a single trend-cycle component (sometimes called the trend for simplicity). Often this is done to help improve understanding of the time series, but it can also be used to improve forecast accuracy.\n\n### Types of decomposition :\n   - Multiplicative : The components multiply together to make the time series. If you have an increasing trend, the amplitude of seasonal activity increases. Everything becomes more exaggerated.\n   - Addative : In an additive time series, the components add together to make the time series.\n   \n(Here we used Addative)"},{"metadata":{"trusted":true},"cell_type":"code","source":"p = d = q = range(0, 2)\npdq = list(itertools.product(p, d, q))\nseasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\nprint('Examples of parameter combinations for Seasonal ARIMA...')\nprint('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[1]))\nprint('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[2]))\nprint('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[3]))\nprint('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[4]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(We used SARIMAX)\n### -> Seasonal AutoRegressive Integrated Moving Averages\n#### One of the methods available in Python to model and predict future points of a time series is known as SARIMAX, which stands for Seasonal AutoRegressive Integrated Moving Averages with eXogenous regressors\n\n### -> What does an Arima model do?\n#### Autoregressive Integrated Moving Average Model. An ARIMA model is a class of statistical models for analyzing and forecasting time series data. It explicitly caters to a suite of standard structures in time series data, and as such provides a simple yet powerful method for making skillful time series forecasts.\n\n### -> How to select perfect ARIMA model\n#### Rules for identifying ARIMA models. General seasonal models: ARIMA (0,1,1)x(0,1,1) etc. Identifying the order of differencing and the constant: If the series has positive autocorrelations out to a high number of lags (say, 10 or more), then it probably needs a higher order of differencing."},{"metadata":{"trusted":true},"cell_type":"code","source":"for param in pdq:\n    for param_seasonal in seasonal_pdq:\n        try:\n            mod = sm.tsa.statespace.SARIMAX(y,\n                                            order=param,\n                                            seasonal_order=param_seasonal,\n                                            enforce_stationarity=False,\n                                            enforce_invertibility=False)\n            results = mod.fit()\n            print('ARIMA{}x{}7 - AIC:{}'.format(param, param_seasonal, results.aic))\n        except:\n            continue","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### -> We choose the one with lowest AIC value from above. In this case we have => ARIMA(0, 1, 1)x(1, 1, 1, 12)7 - AIC:588.9188045652764"},{"metadata":{"trusted":true},"cell_type":"code","source":"mod = sm.tsa.statespace.SARIMAX(y,\n                                order=(0, 1, 1),\n                                seasonal_order=(1, 1, 1, 12),\n                                enforce_stationarity=False,\n                                enforce_invertibility=False)\nresults = mod.fit()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### -> Plot on the training data to check how well our model is predicting."},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = results.get_prediction(start=pd.to_datetime('2020-08-02'), dynamic=False)\npred_ci = pred.conf_int()\nax = y['2020':].plot(label='observed')\npred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=.7, figsize=(14, 7))\nax.fill_between(pred_ci.index,\n                pred_ci.iloc[:, 0],\n                pred_ci.iloc[:, 1], color='k', alpha=.2)\nax.set_xlabel('Date')\nax.set_ylabel('Confirmed Cases')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### -> Graph showing predicted trends for the next 50 steps."},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_uc = results.get_forecast(steps=50)\npred_ci = pred_uc.conf_int()\nax = y.plot(label='observed', figsize=(14, 7))\npred_uc.predicted_mean.plot(ax=ax, label='Forecast')\nax.fill_between(pred_ci.index,\n                pred_ci.iloc[:, 0],\n                pred_ci.iloc[:, 1], color='k', alpha=.25)\nax.set_xlabel('Date')\nax.set_ylabel('Confirmed Cases')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Thank You !!\n\n## Drop an UpVote if you liked the Kernel :)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}