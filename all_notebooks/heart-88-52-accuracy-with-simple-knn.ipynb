{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns #importing seaborn module \nimport warnings\nfrom collections import Counter\nwarnings.filterwarnings('ignore')  #this will ignore the warnings.it wont display warnings in notebook\n#plt.style.use('fivethirtyeight')\nplt.style.use('ggplot')\nplt.rcParams['figure.figsize']=[6,3]\nplt.rcParams['figure.dpi']=80","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/heart-disease-uci/heart.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Missing Values\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#No missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"303 rows & 14 columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Generate categorical and numerical columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_col = ['sex', 'cp', 'restecg', 'exang', 'slope', 'ca','thal','fbs','target']\nnum_col = ['age', 'trestbps', 'chol','thalach','oldpeak']\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First Look at categorical data "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 28))\ncount = 1\nfor cols in cat_col:\n    plt.subplot(9, 2, count)\n    data[cols].value_counts().plot.pie(shadow=True,autopct='%1.1f%%')\n    count +=1\n    plt.subplot(9, 2, count)\n    sns.countplot(cols, data=data)\n    count+=1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* male (68.3%), female (31.7%) \n* cp - maximum value is 0 (47.2%) i.e.  0 -> 2-> 1 -> 3\n* restecg - max occurance is 0(50.2%) & 1 (48.5%), 2 (1.3%) is minimal\n* exang - 67.3% have no and 32.7% are yes\n* slope - max occurance of 1&2 (46%), 0 is minimal (6.9%)\n* ca- values from 0 to 4, 0 -> 1 -> 2 -> 3 -> 4 \n* thal - 0,1,2,3 ; 2&3 are max, o is min\n* fbs - 85.1% = 0 n 14.9%=1\n* target - 54.5% have heart diesese, 45.5% have none"},{"metadata":{},"cell_type":"markdown","source":"Numerical Data - Outlier detection and removal"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = num_col\n\ndef outlier_hunt(df):\n    \"\"\"\n    Takes a dataframe df of features and returns a list of the indices\n    corresponding to the observations containing more than 2 outliers. \n    \"\"\"\n    outlier_indices = []\n    \n    # iterate over features(columns)\n    for col in df.columns.tolist():\n        print(\"col\", col)\n        # 1st quartile (25%)\n        Q1 = np.percentile(df[col], 25)\n        print(\"Q1\", Q1)\n        \n        # 3rd quartile (75%)\n        Q3 = np.percentile(df[col],75)\n        print(\"Q3\", Q3)\n        \n        # Interquartile rrange (IQR)\n        IQR = Q3 - Q1\n        print(\"IQR\", IQR)\n        # outlier step\n        outlier_step = 1.5 * IQR\n        print(\"outlier_step\", outlier_step)\n        \n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        \n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > 2 )\n    \n    print(\"outlier_indices\",outlier_indices)\n    return multiple_outliers   \n\nprint('The dataset contains %d observations with more than 2 outliers' %(len(outlier_hunt(data[features]))))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No outliers > 2, hence no need to drop"},{"metadata":{},"cell_type":"markdown","source":"Numerical Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 24))\ncount = 1\nfor cols in num_col:\n    plt.subplot(6, 2, count)\n    sns.boxplot(x='target', y= cols, data= data)\n    count +=1\n    plt.subplot(6, 2, count)\n    \n    g = sns.kdeplot(data[cols][(data[\"target\"] == 0) & (data[cols].notnull())], color=\"Red\", shade = True)\n    g = sns.kdeplot(data[cols][(data[\"target\"] == 1) & (data[cols].notnull())], ax =g, color=\"Blue\", shade= True)\n    g.set_xlabel(cols)\n    g.set_ylabel(\"Frequency\")\n    g = g.legend([\"No Diesese\",\"Diesese\"])\n    count+=1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* age - young people (25-30) have higher chance than older people\n* For People having heart diesese - max distribution lies between (45-59) \n  Vs not having heart diesese (51-62)\n* trestbps - people with value 190-220 & (80-85) have no heart diesese\n* chol - people with very high chol (530-600) have heart diesese\n* fbs - Doesn't not have any variance\n* thalach - people with value (52-85) do not have diesese\n* max freq of having diesese is between (150-172)\n* oldpeak - people with value (5-7)& (-1.5 to -1.2) : No diesese\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Categorical Variables : Catplot\nfor cols in cat_col:\n    if cols!='target':\n        sns.catplot(x=cols,y='target',kind='bar',data=data)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* sex - Female have more chance of heart diesese than male\n* cp - Value 1,2&3 indicate higher chance of heart diesese than 0\n* restecg - Value 0 & 1 indicate higher chance of diesese than 2.\n* Value 2 seems to be a outlier\n* exang - value 0 indicates higher chance of diesese than 1\n* slope - 2 indiactes higher chances of diesese than 0&1\n* ca - Value 4&0 have higher chance of diesese than 1,2,3\n* thal - Value 2 have highest chance and 3 have minimum chance of heart diesese\n* fbs - fbs=0 have slightly higher chance of heart diesese than fbs=1\n"},{"metadata":{},"cell_type":"markdown","source":"Explore Categorical Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Catplot cp+target+restecg+sex\nsns.catplot(x='cp',y='target',kind='point',data=data,col='restecg',hue='sex')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"female have higher chances of having heart diesese than male for cp = 0to3 & restecg from 0-2"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Catplot cp+target+exang+sex\nsns.catplot(x='cp',y='target',kind='point',data=data,col='exang',hue='sex')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"female have higher chances of having heart diesese than male for cp = 0to3 & exang from 0-3\nexcept for cp=3 & exang=3 for which female does not have heart diesese\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Catplot cp+target+slope+sex\nsns.catplot(x='cp',y='target',kind='point',data=data,col='slope',hue='sex')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* female have no heart diesese for slope =0 & cp = 0to3\n* for slope = 1 & 2, female have higher chance of heart diesese than male\n* for cp=0to3, except slope=1 & cp=3, for which female have no heart diesese\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Catplot cp+target+ca+sex\nsns.catplot(x='cp',y='target',kind='point',data=data,col='ca',hue='sex')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Female - \n* For ca=0, higher chance for female than male for diesese\n* For ca=1, & cp=0to2,higher chance for female than male for diesese\n* For ca=2& cp=0,1, only female have diesese\n* For ca=3 & 4 female do not have diesese\n\n* male - \n* For (ca=1 & cp=3) and (ca=2 & cp=2to3) and ca=3 and 4, only male have diesese\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Catplot cp+target+thal+sex\nsns.catplot(x='cp',y='target',kind='point',data=data,col='thal',hue='sex')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* male - for thal=0 & cp=2, only male have diesese\n* for thal=1 & cp=0-3 only male have diesese\n* for thal=2 & cp=0,2,3 , female have higher chance than male of heart diesese\n* except for cp=1 where both have equal chance for heart diesese\n* For thal=3, female have higher chance for cp=2, for other cp values only male have heart diesese\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Catplot restecg+target+exang+sex\nsns.catplot(x='exang',y='target',kind='point',data=data,col='restecg',hue='sex')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* for restecg=2, only female have diesese for exang=0\n* For restecg=0, female have higher diesese chance than male\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Explore Numerical Variables\nsns.catplot(x='target',y='age',data=data,kind='box',hue='sex', col='cp')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For cp=0&3 age of female is slightly higher than male "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='target',y='chol',data=data,kind='box',hue='sex', col='exang')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Freq distribution of chol is higher for female than male  "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='target',y='chol',data=data,kind='box',hue='sex', col='slope')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For slope=0 & diesese = 1, chol value for male are higher than female"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='target',y='age',data=data,kind='box',hue='sex', col='ca')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For ca=2, and diesese=1, male have very low age than female"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='target',y='oldpeak',data=data,kind='box',hue='sex', col='thal')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For thal=3 & diesese=1, age of male&female are lower than diesese=0"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Catplot cp+target+fbs+sex\nsns.catplot(x='cp',y='target',kind='point',data=data,col='fbs',hue='sex')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"female have higher chances of having heart diesese than male for fbs = 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Variable = age Vs restecg\nf,ax=plt.subplots(1,3,figsize=(12,8))\nsns.distplot(data[data['restecg']==0].age,ax=ax[0])\nax[0].set_title('age in restecg 0')\nsns.distplot(data[data['restecg']==1].age,ax=ax[1])\nax[1].set_title('age in restecg 1')\nsns.distplot(data[data['restecg']==2].age,ax=ax[2])\nax[2].set_title('age in restecg 2')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"older people (age= 60 & 80) have restecg=2"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Variable = age Vs fbs\nf,ax=plt.subplots(1,2,figsize=(18,8))\nsns.distplot(data[data['fbs']==0].age,ax=ax[0])\nax[0].set_title('age in fbs 0')\nsns.distplot(data[data['fbs']==1].age,ax=ax[1])\nax[1].set_title('age in fbs 1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"people (age< 42) have no fbs"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Final Pair plot\nsns.heatmap(data.corr(),annot=True,cmap='RdYlGn',linewidths=0.2,annot_kws={'size':12})\nfig=plt.gcf()\nfig.set_size_inches(18,10)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Processing "},{"metadata":{"trusted":true},"cell_type":"code","source":"train = data.drop([\"target\"],axis=1)\ntrain_ = data[\"target\"]\n\nX_train = train.values\ny_train = train_.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_predict,cross_validate\ntrain_x, test_x,train_y,test_y = train_test_split(X_train,y_train,test_size  = 0.2, random_state=0)\nprint(\"Train dataset shape: {0}, \\nTest dataset shape: {1}\".format(train_x.shape, test_x.shape))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Machine Learning Algorithm begins"},{"metadata":{},"cell_type":"markdown","source":"Simple KNN (K Nearest Neighbours)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n#storing  the K nearest neighbors classifier\nMisclassified_sample = []\nfor i in range(1, 30):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(train_x,train_y)\n    pred_i = knn.predict(test_x)\n    Misclassified_sample.append((test_y != pred_i).sum())\nprint(\"Misclassified_sample = \", Misclassified_sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lowest number of samples for K=8\n\nKNN_classifier = KNeighborsClassifier(n_neighbors=8)\n\n# Fitting the values fo X and Y\nKNN_classifier.fit(train_x, train_y)\n\n#Predicting the test values with Model\nprediction =  KNN_classifier.predict(test_x)\n\n###### confusion matrix  starts ######\nfrom sklearn.metrics import accuracy_score, confusion_matrix\ncm_knn = confusion_matrix(test_y,prediction) \nnames = np.unique(prediction)\nsns.heatmap(cm_knn, square=True, annot=True, cbar=False,xticklabels=names, yticklabels=names, cmap=\"YlGnBu\" ,fmt='g')\nplt.xlabel('Truth')\nplt.ylabel('Predicted')\n###### Confusion matrix ends ########\n\n#calculating the accuracy\naccuracy_score = accuracy_score(test_y,prediction)\nprint(\"accuracy_score KNN=8 :\",accuracy_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"KNN accuracy : 88.52% with only 7 misclassified samples"},{"metadata":{},"cell_type":"markdown","source":"Logistic Regresion "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generic function for model building\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\ndef fit_and_test(classifier, X_train, y_train, X_test, y_test, only_return_accuracy=False):\n  classifier.fit(X_train, y_train)\n  y_hat = classifier.predict(X_test)\n  print('accuracy:', accuracy_score(y_test, y_hat))\n  if not only_return_accuracy:\n    print('f1_score:', f1_score(y_test, y_hat))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n#grid search over regularisation hyperparameter 'c'\nfor c in [0.001,.01, 0.02, 0.05, 0.25, 0.5, 0.75, 1,1.05,1.1,1.5,1.6,2,7]:\n  lr = LogisticRegression(C=c, max_iter=1000) \n  print (f'At C = {c}:-', end=' ')\n  fit_and_test(lr, train_x, train_y, test_x, test_y, True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logistic Regression Accuracy : 85.42% "},{"metadata":{},"cell_type":"markdown","source":"# Conclusion : We recommend KNN (88.52% accuracy with only 7 misclassified samples) to build the model"},{"metadata":{},"cell_type":"markdown","source":"# **Please UpVote, if you have liked my Kernel :)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}