{"cells":[{"metadata":{},"cell_type":"markdown","source":"# My first classification notebook\nEl objetivo principal de este libro es aplicar mis conocimientos basicos de machine learning en un problema practico presentado en las competencias de Kaggle, esto con el fin de recibir retroalimentación de la comunidad, aprender de sus aportes y orientar a quienes recien empiezan.\n\nEn este cuaderno se llevará a cabo un proceso de machine learning aplicado a los datos \"Titanic: Machine Learning From Desaster\" con el fin de predecir los sobrevivientes del hundimiento del titanic en 1912. La descripción general de la competencia se encuentra aquí: https://www.kaggle.com/c/titanic\n\nPara este proceso de predicción seguiré la siguiente estructura:\n1. Definir el problema\n2. Analizar los datos\n3. Preparar los datos\n4. Hacer predicciones\n5. Mejorar los resultados\n\nEsta estructura es bien definida en el siguiente sitio: https://machinelearningmastery.com/process-for-working-through-machine-learning-problems/ \n\nComenzamos."},{"metadata":{},"cell_type":"markdown","source":"# 1. Definir el problema\n\nA partir de un conjunto muestral de entrenamiento que enumera a los pasajeros que sobrevivieron al desastre del Titanic y a los que no, se debe crear un modelo que pueda determinar con base a un conjunto de test si dichos pasajeros sobreviven o no.\n\nLa información detallada del problema se encuentra en aquí: https://www.kaggle.com/c/titanic"},{"metadata":{},"cell_type":"markdown","source":"# 2. Analizar los datos"},{"metadata":{},"cell_type":"markdown","source":"Antes de iniciar la exploración y procesamiento de datos es necesario importar las librerias que usaremos a lo largo de nuestro proyecto."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #Gives us Graphics\nimport seaborn as sns #Libreria para gráficar\nfrom sklearn.model_selection import cross_val_score #libreria para obtener puntuación de algoritmos\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obtenemos nuestro conjunto de entrenamiento que será almacenado en la variable \"titanicTrain\", al mimsmo tiempo que obtenemos nuestro conjunto de prueba que será almacenado en la variable \"titanicTest\""},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#firts i import the data\ntitanicTrain = pd.read_csv(\"../input/titanic/train.csv\")\ntitanicTest = pd.read_csv(\"../input/titanic/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hacemos una inspección rapida del contenido de cada conjunto de datos."},{"metadata":{"trusted":true},"cell_type":"code","source":"titanicTrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanicTest.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanicTrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanicTest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanicTrain.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanicTest.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Observaciones\nObservando ambos conjuntos de datos podemos apreciar que el conjunto de entrenamiento cuenta con 11 columnas, mientras el de test cuenta con solo 10. Esto es porque el conjunto de test no contiene la columna \"Survived\" que es la que indica si el tripulante sobrevive o no, y es con base a este conjunto de datos que vamos a evaluar nuestros modelos.\n\nTambién podemos hacer una suposición lógica de la importancia de las columnas (Basandonos en la gravedad del suceso). Como por ejemplo que el sexo y la edad son variables de gran importancia ya que daban prioridad a mujeres y niños. \n\nTambién podemos suponer que la variable de clase \"Pclass\" debe ser importante, ya que en el barco iban personas de status social bastante alto. \n\nEl nombre no debe ser de importancia para nuestros modelos.\n\nY la columna \"Cabin\" debe ser eliminada ya que cuenta con demasiados valroes Null.\n\n**Estas suposiciones serán verificadas más adelante**"},{"metadata":{},"cell_type":"markdown","source":"Veamos el comportamiento de la variable a predecir \"Survived\""},{"metadata":{"trusted":true},"cell_type":"code","source":"titanicTrain.Survived.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanicTrain['Survived'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"El resultado obtenido nos indica que tan solo sobrevivieron 342 personas de las 891 que iban a bordo.\n\nVeamoslo gráficamente:\n\n(Para eso usaremos la librería de matplotlib asignada como plt)"},{"metadata":{"trusted":true},"cell_type":"code","source":"noSobrevivientes = titanicTrain.Survived[titanicTrain.Survived ==0].count()\nsobrevivientes = titanicTrain.Survived[titanicTrain.Survived ==1].count()\nplt.bar(['No sobrevivientes', 'Sobrevivientes'], [noSobrevivientes, sobrevivientes])\nplt.title('Survived')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.pie(titanicTrain.Survived.value_counts(),labels=['No sobrevivientes', 'Sobrevivientes'], autopct=\"%0.1f %%\")\nplt.title('Survived')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ya sabemos cual fue el porcentaje de sobrevivientes. Ahora veamos cual es la cantidad de mujeres que sobrevivieron"},{"metadata":{"trusted":true},"cell_type":"code","source":"titanicTrain.Sex.head() #ver etiquetas","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanicTrain.Survived[(titanicTrain.Survived == 1)&(titanicTrain.Sex.str.contains('female'))].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Esto nos arroja un resultado de 233, lo que significa que de los 342 sobrevivientes 233 son mujeres y el restante son hombres.\n\nAhora veamoslo gráficamente:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.pie([233,109], labels=['female','male'],autopct=\"%0.1f %%\" )\nplt.title('Hombres y mujeres sobrevivientes')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Con este grafico podemos ver que el 68.1% de los sobrevivientes eran mujeres y el 31,9% restante eran hombres.\n\nLo mismo con el diagrama de barras:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.bar(['female','male'], [233, 109], width=0.98)\nplt.title('Sobrevivientes')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Una vez sabiendo cual es el porcentaje de mujeres y hombres sobrevivientes, queremos saber como se comporta la edad ante la columna \"Survived\". \nPara ello primero veamos qué edades tenemos en el conjunto de datos de entrenamiento."},{"metadata":{"trusted":true},"cell_type":"code","source":"titanicTrain['Age'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Con esta descripción de la columna de edades podemos sacar conclusiones como que la edad minima es 0 años, la máxima es 80 y la edad media es de 29."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(titanicTrain['Age'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Con el gráfico podemos interpretar que en el barco viajaba una mayor cantidad de niños que de adultos mayores, que la mayor cantidad de personas abordo estaban entre los 20 y 30 años, Entre otras cosas...\n\nObservemos la cantidad de personas menores de 20 años que sobreviven y las que no:"},{"metadata":{"trusted":true},"cell_type":"code","source":"menores = titanicTrain[titanicTrain.Age < 20] #164 menores de 20 años\nmenores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"menores.Survived[menores.Survived == 1].count() #de 164 personas menores de 20, 79 sobrevivieron","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"menores.Survived[menores.Survived == 0].count() #de 164 personas menores de 20 años, 85 no sobrevivieron.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ahora obervemos esto mismo con las personas mayores de 60 años "},{"metadata":{"trusted":true},"cell_type":"code","source":"mayores = titanicTrain[titanicTrain.Age >= 60] #26 personas tienen una edad igual o mayor a 60 años\nmayores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mayores.Survived[mayores.Survived == 1].count() #7 de las 26 personas mayores sobrevivieron","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mayores.Survived[mayores.Survived == 0].count() #19 de las 26 personas mayores no sobreviven","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y para finalizar el analisis de la columna \"Age\", observemos como resulta estos datos con las personas de edad media."},{"metadata":{"trusted":true},"cell_type":"code","source":"media = titanicTrain[(titanicTrain.Age >= 20) & (titanicTrain.Age <= 30)] #245 personas tienen una edad entre 20 y 30 años\nmedia","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"media.Survived[media.Survived == 1].count() #87 de las 245 personas de edad media sobreviven","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"media.Survived[media.Survived == 0].count() #158 de las 245 personas de edad media No sobreviven","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Por último vamos a observar como se comporta la columna \"Pclass\" que es una de las columnas que hemos supuesto como importante ante la mortandad del accidente."},{"metadata":{"trusted":true},"cell_type":"code","source":"titanicTrain['Pclass'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.bar(['clase 3', 'clase 1', 'clase 2'],titanicTrain['Pclass'].value_counts())\nplt.title('Distribución de clases en el barco')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Con este grafico podemos observar que la clase 3 es un poco más que el doble que la clase 1. Mientras que la clase 2 es un poco menor en tamaño que la clase 1.\n\nAhora observemos la mortandad en cada clase."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Observación de primera clase\nclassSobre = titanicTrain.Survived[(titanicTrain.Survived == 1)&(titanicTrain.Pclass == 1)].count()\nclassNoSobre = titanicTrain.Survived[(titanicTrain.Survived == 0)&(titanicTrain.Pclass == 1)].count()\nplt.bar(['No sobrevivientes', 'Sobrevivientes'], [classNoSobre,classSobre])\nplt.title('Distribución de muerte en primera clase')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.pie([classSobre, classNoSobre], labels=['Sobrevivientes', 'No sobrevivientes'],autopct=\"%0.1f %%\" )\nplt.title('Distribuación de muerte en primera clase')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Observación de segunda clase\nclassSobre = titanicTrain.Survived[(titanicTrain.Survived == 1)&(titanicTrain.Pclass == 2)].count()\nclassNoSobre = titanicTrain.Survived[(titanicTrain.Survived == 0)&(titanicTrain.Pclass == 2)].count()\nplt.bar(['No sobrevivientes', 'Sobrevivientes'], [classNoSobre,classSobre])\nplt.title('Distribuación de muerte en segunda clase')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.pie([classSobre, classNoSobre], labels=['Sobrevivientes', 'No sobrevivientes'],autopct=\"%0.1f %%\" )\nplt.title('Distribuación de muerte en segunda clase')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Observación de tercera clase\nclassSobre = titanicTrain.Survived[(titanicTrain.Survived == 1)&(titanicTrain.Pclass == 3)].count()\nclassNoSobre = titanicTrain.Survived[(titanicTrain.Survived == 0)&(titanicTrain.Pclass == 3)].count()\nplt.bar(['No sobrevivientes', 'Sobrevivientes'], [ classNoSobre, classSobre])\nplt.title('Distribuación de muerte en tercera clase')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.pie([classSobre, classNoSobre], labels=['Sobrevivientes', 'No sobrevivientes'],autopct=\"%0.1f %%\" )\nplt.title('Distribuación de muerte en tercera clase')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos observar en las gráficas y como se podía tener una idea, la primera clase tuvo una gran cantidad de sobrevivientes (63%) en comparación con las demás clases. Mientras que en la 3ra clase solo sobrevivió un 24.2% de la tripulación, teniendo en cuenta que la cantidad de personas pertenecientes a la 3ra clase era más del doble que los de la primera clase.\n\nUna vez habiendo analizado las columnas que creímos importantes, vamos a observar las columnas restantes. "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(titanicTrain)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Con este grafico podemos observar las variables numericas que nos hace falta por explorar. Observamos que la columna \"sibps\" que representa el numero de hermanos o conyugues a bordo; tiene en su mayoria numero bajos, lo que quiere decir que existían pocas personas con este tipo de parentesco. \n\nDe igual manera se observa con la columna \"Parch\" que representa el numero de padres e hijos a bordo; tiene en su mayoria numeros bajos. \n\ny por último la columna \"Fare\" que representa la tarifa de pasajero. Esta columna tiene numeros muy bajos, lo que tiene sentido porque la gran mayoría de la tripulación eran de la 3ra clase. Quizás esta columna tenga importacia ya que dependiendo la tarifa se puede suponer la clase o estrato de la persona. Pero es algo que veremos en un grafico más adelante.\n\nFalta por observar las caolumnas etiquetadas como Cabin, Embarked y Ticket. Observemos:"},{"metadata":{"trusted":true},"cell_type":"code","source":"titanicTrain[['Cabin','Ticket','Embarked']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Observemos la columna Cabin\ntitanicTrain['Cabin'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanicTrain['Cabin'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De 891 registros, la columna Cabin contiene 687 valores nulos, lo que significa que debemos eliminarla por su gran cantidad de datos vacios. "},{"metadata":{"trusted":true},"cell_type":"code","source":"titanicTrain.drop('Cabin', axis = 1, inplace=True)\ntitanicTest.drop('Cabin', axis = 1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Observemos la columna Ticket\ntitanicTrain['Ticket'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Observemos la columna Cabin\ntitanicTrain['Ticket'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Esta columna tiene sus registros completos, pero no creo que por el ticket de una persona se pueda decidir si alguien sobrevive o no sobrevive. Sin embargo, se podrá ver la relación que tiene esta columna con nuestro Target (Objetivo de predecir supervivencia o no) en un grafico más adelante. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#veamos la columna Embarked\ntitanicTrain['Embarked'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanicTrain['Embarked'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como vemos, la columna \"Embarked\" tiene dos registros faltantes que no representan ningún problema. Se pueden eliminar estas dos filas o llenarlas con el promedio de la embarcación. Tambien vemos que existen 3 embarcaciones: S,C,Q y con base a esto nos podemos preguntar ¿La embarcación representó un factor para la supervivencia de los tripulantes ? ¿Como se presenta la mortandad en cada una de las embarcaciones? Vamos a responder estas preguntas."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Embarked S\nsobrevivientes = titanicTrain.Embarked[(titanicTrain.Survived == 1) & (titanicTrain.Embarked.str.contains('S'))].count()\nnoSobrevivientes = titanicTrain.Embarked[(titanicTrain.Survived == 0) & (titanicTrain.Embarked.str.contains('S'))].count()\nplt.pie([sobrevivientes, noSobrevivientes],labels=['Sobrevivientes', 'No Sobrevivientes'],autopct=\"%0.1f %%\")\nplt.title('Mortalidad de la embarcación S')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Embarked C\nsobrevivientes = titanicTrain.Embarked[(titanicTrain.Survived == 1) & (titanicTrain.Embarked.str.contains('C'))].count()\nnoSobrevivientes = titanicTrain.Embarked[(titanicTrain.Survived == 0) & (titanicTrain.Embarked.str.contains('C'))].count()\nplt.pie([sobrevivientes, noSobrevivientes],labels=['Sobrevivientes', 'No Sobrevivientes'],autopct=\"%0.1f %%\")\nplt.title('Mortalidad de la embarcación C')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Embarked Q\nsobrevivientes = titanicTrain.Embarked[(titanicTrain.Survived == 1) & (titanicTrain.Embarked.str.contains('Q'))].count()\nnoSobrevivientes = titanicTrain.Embarked[(titanicTrain.Survived == 0) & (titanicTrain.Embarked.str.contains('Q'))].count()\nplt.pie([sobrevivientes, noSobrevivientes],labels=['Sobrevivientes', 'No Sobrevivientes'],autopct=\"%0.1f %%\")\nplt.title('Mortalidad de la embarcación Q')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Con estas gráficas podemos darnos una idea de la mortaldiad correspondiente a cada embarcación. A simple vista podemos ver que la mortalidad en cada una de ellas se da de manera común, por lo tanto no hay indicio de que pertenecer a cierta embarcación tuviera conseciencia en sobrevivir o no al hundimiento del barco. Pero no podemos descartarla aún. \n\nEn cuanto a las columnas de \"PassengerId\", \"Name\" y \"Ticket\" las descartaremos ya que estas columnas de tipo Object dificilmente se pueden pasar a tipo numerico, y además no podrían aportar nada a nuestros modelos."},{"metadata":{"trusted":true},"cell_type":"code","source":"titanicTrain.drop(['PassengerId','Name', \"Ticket\"], axis = 1, inplace = True)\ntitanicTest.drop(['PassengerId','Name', \"Ticket\"], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(titanicTrain)\nprint(titanicTest)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Una vez hemos visto el comportamiento de cada una de las columnas de nuestros datos; vamos a observar la correlación de ellas con nuestro target \"Survived\". Pero como esta correlación solo se puede dar con variables de tipo numerico, debemos transformar las variables \"Sex\" y \"Embarked\" que son categoricas a variables numericas."},{"metadata":{"trusted":true},"cell_type":"code","source":"#conjunto de test\ntitanicTrain['Sex'].replace(['male','female'],[0,1], inplace = True)\ntitanicTrain['Embarked'].replace(['S','C','Q'],[1,2,3], inplace = True)\n\n#conjunto de test\ntitanicTest['Sex'].replace(['male','female'],[0,1], inplace = True)\ntitanicTest['Embarked'].replace(['S','C','Q'],[1,2,3], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanicTrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanicTest","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ahora si podemos usar nuestro cuadro de correlación gracias a la libreria seaborn que hemos implementado al inicio de nuestro código."},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = titanicTrain.corr()\nsns.heatmap(corr, cmap='RdBu', annot=True, fmt=\".2f\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"y acá podemos ver los porcentajes ordenados de manera descendente:"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr[['Survived']].sort_values(by = 'Survived',ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos observar, los coeficientes de correlación con respecto a nuestro target son demasiado bajos, pero debemos trabajar con ellos. La puntuación más alta es la de \"Sex\" que corresponde a un 54% de correlación, por tal motivo necesitaremos esa columna para entrenar nuestros algoritmos.\n\nLa columna \"Fare\" es la puntuación más alta por debajo de la columna \"Sex\" con un 25% de correlación. Pero si nos situamos en la intersección entre la columna \"Fare\" y la columna \"Pclass\" podemos ver que entre estas dos variables existe una relación negativa de un 55%,lo que significa que en esa medida las dos columnas representan lo mismo y una de las dos es innecesaria. Por tal motivo vamos a eliminar la columna \"Fare\" y nos quedaremos con la columna \"Plcass\" ya que tiene una mayor relación con nuestra columna \"Survived\". *(Las relaciones son independiente del signo, por tal motivo puede existir un porcentaje de correlación con ambos signos y representar el mismo nivel de relación)*\n\nSeguido de esto usaremos la columna \"Embarked\" que tiene un 10% de relación.  \n\nPor último eliminaremos las columnas \"Parch\" y \"SipSp\" ya que haciendo un análisis mental (sin soporte estadistico) considero que tener lazos familiares no aporta en gran medida a la supervivencia de una persona. Sin embargo, NO eliminaremos la columna de \"Age\" a pesar de tener una correlación tan baja, ya que se debió tener mayor prioridad en salvar a niños que a personas adultas.\n\nDe tal manera nuestros conjuntos de datos  quedan de la siguiente manera: "},{"metadata":{"trusted":true},"cell_type":"code","source":"titanicTrain = titanicTrain.loc[:,['Sex','Pclass','Age','Embarked','Survived']]\ntitanicTest = titanicTest.loc[:,['Sex','Pclass','Age','Embarked']]\ntitanicTrain, titanicTest","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Una vez hecho nuestro análisis y seleccionado nuestras características, estamos listos para seguir con nuestra siguiente etapa de preprocesamiento de datos.\n\n# 3. Preparar los datos\n\nEn esta etapa se suele hacer el siguiente preprocesamiento: \n1. Transformar variables categóricas a numéricas.\n2. Tratar los datos faltantes.\n3. Tratar los datos atípicos.\n4. Considerar el escalado de los datos.\n\n\n1. Para nuestro primer punto no debemos hacer ninguna transformación ya que en el proceso de análisis fuimos tranformando las columnas necesarias para nuestra observación y ahora todo nuestro conjunto de datos es de tipo numérico.\n2. **Tratar los datos faltantes**. En este punto si debemos analizar cada columna para ver la cantidad de datos que faltan en cada una de ellas y como tratarlos."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(titanicTrain['Sex'].isnull().sum()) #Cantidad de valores vacíos en entrenamiento\nprint(titanicTest['Sex'].isnull().sum())#Cantidad de valores vacíos en test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(titanicTrain['Pclass'].isnull().sum()) #Cantidad de valores vacíos en entrenamiento\nprint(titanicTest['Pclass'].isnull().sum())#Cantidad de valores vacíos en test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(titanicTrain['Age'].isnull().sum()) #Cantidad de valores vacíos en entrenamiento \nprint(titanicTest['Age'].isnull().sum()) #Cantidad de valores vacíos en test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(titanicTrain['Embarked'].isnull().sum()) #Cantidad de valores vacíos en entrenamiento \nprint(titanicTest['Embarked'].isnull().sum()) #Cantidad de valores vacíos en test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(titanicTrain['Survived'].isnull().sum()) #Cantidad de valores vacíos en entrenamiento","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Teniendo en cuenta que las columnas \"Age\" y \"Embarked\" tiene valores vacíos vamos a tratarlos.\n\nLa columna \"Age\" tiene 177 valores faltantes de 891. Existen distintas formas de rellenar estos valore faltantes, pero en esta ocación los llenaremos con el valor promedio de edades."},{"metadata":{"trusted":true},"cell_type":"code","source":"promedio = titanicTrain['Age'].mean()\ntitanicTrain['Age'].fillna(promedio, inplace = True)\nprint(titanicTrain['Age'].isnull().sum())\n\n#Ahora con el conjunto de prueba\npromedio = titanicTest['Age'].mean()\ntitanicTest['Age'].fillna(promedio, inplace = True)\nprint(titanicTest['Age'].isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De esta manera hemos rellenado los valores vacíos de la columna \"Age\" con el promedio de edad. Ahora nos falta la columna \"Embarked\" el cual tiene 2 registros faltantes de 891. En este caso vamos a rellenar estos dos valores vacíos con el numero que más se repite."},{"metadata":{"trusted":true},"cell_type":"code","source":"titanicTrain['Embarked'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanicTrain['Embarked'].fillna(1, inplace = True)\nprint(titanicTrain['Embarked'].isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(titanicTrain.info())\nprint(titanicTest.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ahora ya no tenemos valores vacíos en nuestro conjunto de datos, hemos terminado el segundo punto y podemos seguir con nuestro preprocesamiento de datos.\n\n3.  **Tratar los datos atípicos.**\nPara este punto solo debemos centrarnos en la columna \"Age\" ya que las demás columnas son categóricas y no tienen mayor variedad de números, de esta manera no existe riesgo de valores Outliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(titanicTrain['Age'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Esta gráfica nos muestra algunos puntos de ánalisis, el cuartil inferior que es un poco mayor a 20, la media que es 30 y el cuartil superior que está al rededor de 35. los bigotes (lineas verticales de los lados) exponen que todo numero que esté dentro de estos limites se consideran normales, mientras que los que están por fuera se consideran datos atípicos. En este caso se consideran datos atípicos las edades inferiores a 3 y superiores a 53 aproximadamente. Dependiendo del caso se deberían eliminar estos datos para que no afecten el rendimiento de nuestros agoritmos, pero en esta ocación no es necesario, ya que sí es posible que una persona de 70 u 80 años estuviera en el bote, o un bebé de apenas 1 año de edad. Caso contrario sería de una persona de 150 o 200 años, o alguien con -3 años, en ese momento si se deberían eliminar dichos registros ya que es ilógico que un caso así se presente.  \n\nUna vez considerado los datos Outliers podemos seguir con nuestro último paso de escalado de datos.\n\n4. **Considerar el escalado de los datos**. El escalado de los datos se debe realizar cuando existen columnas con diferencias de valores muy altos, como por ejemplo el valor de un apartamento (200000000) y el numero de habitaciones de este (4). El escalado se hace precisamente para reducir esta diferencia y poder dar los mejores resultados con nuestros algoritmos. Como nuestro problema es de clasificación y no presentamos diferencias en nuestros valores de columnas, entonces no es necesario hacer el escalado de los datos. \n\nCon esto último hemos terminado nuestro proceso de pre-procesamiento y ya tenemos listos nuestros datos para poder entrenar nuestros modelos de la mejor manera. "},{"metadata":{"trusted":true},"cell_type":"code","source":"titanicTrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titanicTest","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Hacer predicciones\n\nEn esta etapa entrenaremos nuestros modelos con la data previamente procesada y haremos nuestras predicciones. Utilizaremos modelos de clasificación tales como :\n\n* Logistic Regression\n* KNN o k-Nearest Neighbors\n* SVM o Support Vector Machine\n* Naive Bayes classifier\n* Decision Tree\n* Random Forrest\n\nCompararemos y mejoraremos los resultados."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = titanicTrain.loc[:, 'Survived']\nx_train = titanicTrain.drop('Survived', axis = 1)\nx_test = titanicTest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Regresión logistica\nfrom sklearn.linear_model import LogisticRegression #Importamos la librería del modelo\n\nclasificador = LogisticRegression(random_state = 0)\nclasificador.fit(x_train, y_train) #Entrenamos el modelo con los datos de entrenamiento \n\ny_pred = clasificador.predict(x_test) #Hacemos predicciones sobre el conjunto de test\n\ncv = cross_val_score(estimator = clasificador, X = x_train, y = y_train, cv = 10) # metodo para obtener la precisión (Validación cruzada)\ncvRegression = cv.mean()\nstdRegression = cv.std()\nprint(\"promedio Validación cruzada Regresión logística: \", cvRegression)\nprint('Varianza de Regresión logística: ',stdRegression)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#KNN o k-Nearest Neighbors\nfrom sklearn.neighbors import KNeighborsClassifier #Importamos la librería del modelo\n\nclasificador = KNeighborsClassifier()\nclasificador.fit(x_train, y_train) #Entrenamos el modelo con los datos de entrenamiento \n\ny_pred = clasificador.predict(x_test) #Hacemos predicciones sobre el conjunto de test\n\ncv = cross_val_score(estimator = clasificador, X = x_train, y = y_train, cv = 10) #metodo para obtener la precisión\ncvKnn = cv.mean()\nstdKnn = cv.std()\nprint(\"promedio Validación cruzada KNN: \", cvKnn)\nprint('Varianza de KNN: ',stdKnn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#SVM o Support Vector Machine\nfrom sklearn.svm import SVC #Importamos la librería del modelo\n#Para implementar el modelo de SVM es obligatorio tener los datos escalados\nfrom sklearn.preprocessing import StandardScaler #Libreria para escalar los datos\n\nscaler = StandardScaler()\nx_entrenamiento = scaler.fit_transform(x_train) #Escalar los datos de entrenamiento\nx_prueba = scaler.fit_transform(x_test)\n\nclasificador = SVC(random_state = 0) \nclasificador.fit(x_entrenamiento, y_train) #Entrenamos el modelo con los datos de entrenamiento \n\ny_pred = clasificador.predict(x_prueba) #Hacemos predicciones sobre el conjunto de test\n\ncv = cross_val_score(estimator = clasificador, X = x_train, y = y_train, cv = 10) #metodo para obtener la precisión\ncvSVM = cv.mean()\nstdSVM = cv.std()\nprint(\"promedio Validación cruzada SVM: \", cvSVM)\nprint('Varianza de SVM: ',stdSVM)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB #Importamos la librería del modelo\n\nclasificador = GaussianNB()\nclasificador.fit(x_train, y_train) #Entrenamos el modelo con los datos de entrenamiento \n\ny_pred = clasificador.predict(x_test) #Hacemos predicciones sobre el conjunto de test\n\ncv = cross_val_score(estimator = clasificador, X = x_train, y = y_train, cv = 10) #metodo para obtener la precisión\ncvNB = cv.mean()\nstdNB = cv.std()\nprint(\"promedio Validación cruzada NB: \", cvNB)\nprint('Varianza de NB: ',stdNB)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier #Importamos la librería del modelo\n\nclasificadorTree = DecisionTreeClassifier(random_state = 0)\nclasificadorTree.fit(x_train, y_train) #Entrenamos el modelo con los datos de entrenamiento \n\ny_pred = clasificadorTree.predict(x_test) #Hacemos predicciones sobre el conjunto de test\n\ncv = cross_val_score(estimator = clasificadorTree, X = x_train, y = y_train, cv = 10) #metodo para obtener la precisión\ncvTree = cv.mean()\nstdTree = cv.std()\nprint(\"promedio Validación cruzada Decision Tree: \", cvTree)\nprint('Varianza de Decision Tree: ',stdTree)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Forest \nfrom sklearn.ensemble import RandomForestClassifier #Importamos la librería del modelo\n\nclasificadorForest = RandomForestClassifier(random_state = 0)\nclasificadorForest.fit(x_train, y_train) #Entrenamos el modelo con los datos de entrenamiento \n\ny_pred = clasificadorForest.predict(x_test) #Hacemos predicciones sobre el conjunto de test\n\ncv = cross_val_score(estimator = clasificadorForest, X = x_train, y = y_train, cv = 10) #metodo para obtener la precisión\ncvForest = cv.mean()\nstdForest = cv.std()\nprint(\"promedio Validación cruzada Random Forest: \", cvForest)\nprint('Varianza de Random Forest: ',stdForest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#score = [scoreRegression, scoreKnn, scoreSVM, scoreNB, scoreTree, scoreForest]\nmeanValidaCruz = [cvRegression, cvKnn, cvSVM, cvNB, cvTree, cvForest]\nstdValidaCruz = [stdRegression, stdKnn, stdSVM, stdNB, stdTree, stdForest]\nlabels = ['Regresion lineal', 'Knn', 'SVM', 'Naive Bayes', 'Árbol de decision', 'Random Forest']\n\nscoreModels = pd.DataFrame({'Models': labels,\n                            'Vali. Cruz.': meanValidaCruz,\n                            'Varianza': stdValidaCruz})\nscoreModels.sort_values(by = 'Vali. Cruz.', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"width = 0.30\nind =np.arange(6)\nplt.bar(ind ,meanValidaCruz, width, label='VC')\nplt.bar(ind + width,stdValidaCruz, width, label='Varianza')\n#plt.bar(ind + width*2,score, width, color='r', label='Score')\nplt.xticks(ind + width/2,('Regression', 'Knn', 'SVM', 'NB', 'Tree','Forest'))\nplt.legend()\nplt.title(\"Puntuaciones\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ahora que sabemos la precisión de cada modelo debemos mejorar las puntuaciones obtenidas. Como los modelos Random Forest y Árbol de decisión presentaron los mejores resultados; nos enfocaremos en optimizar dichos modelos. Para esto haremos uso de la librería GridSearchCV de Sklearn que nos permite hallar los mejores parametros para implementar nuestros algoritmos. \n\n# 5. Mejorar los resultados"},{"metadata":{"trusted":true},"cell_type":"code","source":"#GirdSearchCV con el modelo de árbol de decisión\n\nfrom sklearn.model_selection import GridSearchCV #Importamos la librería\n\nminSplit = np.arange(20,26,1)\nmaxDepth = np.arange(4.0,4.6,0.1)\n\nparametros = [{'criterion': ['gini'],'max_depth': [3.5,4.1], 'min_samples_split': minSplit},\n              {'criterion': ['entropy'], 'max_depth':  [3.5,4.1], 'min_samples_split':  minSplit}\n             ] #Definimos los parametros para que la librería nos indique cuál es el mejor\n\ngridSearch = GridSearchCV(estimator = clasificadorTree, \n                          param_grid = parametros,\n                          scoring = 'accuracy',\n                          cv = 10) #En el constructor pasamos el modelo que queremos mejorar, los parametros, medida de calificacion y nuemero de pruebas.\n\ngridSearch = gridSearch.fit(x_train, y_train) #Entrenamos el GridSearchCV\nprint(gridSearch.best_score_) #vemos como la puntuación cv pasó de 0.7924 a  0.8215\nprint(gridSearch.best_params_) #Muestras los parametros más optimos\n\n\n#Aplicacion de parametros\nclasificadorTree = DecisionTreeClassifier(criterion= 'gini', \n                                          max_depth= 4.1,min_samples_split = 21,\n                                          random_state = 0)\n\nclasificadorTree.fit(x_train, y_train) #Entrenamos el modelo con los datos de entrenamiento \n\ny_pred = clasificadorTree.predict(x_test) #Hacemos predicciones sobre el conjunto de test\n\nscoreTreeGS = clasificadorTree.score(x_train, y_train) #Obtenemos la precisión del algoritmo\nprint('Precisión de algoritmo de Decision Tree: ',scoreTreeGS)\n\ncv = cross_val_score(estimator = clasificadorTree, X = x_train, y = y_train, cv = 10) #Metodo para obtener la precisión\ncvTreeGS = cv.mean()\nstdTreeGS = cv.std()\nprint(\"promedio Validación cruzada Decision Tree: \", cvTreeGS)\nprint('Varianza de Decision Tree: ',stdTreeGS)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cuadro comparativo de resultados\ndefectpVsGSTree = pd.DataFrame({'Parametros. Árbol de Decisión':['Por Defecto', 'GridSearchCV'],\n                                'Mean Vali. Cruz.':[cvTree,cvTreeGS ],\n                                'Varianza': [stdTree, stdTreeGS]})\n\ndefectpVsGSTree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#GirdSearchCV con el modelo de bosques aleatorios\n\nnEstimators = np.arange(80,86)\nmaxDepth = np.arange(4.0,4.3,0.1)\n\n#best'max_features': ['auto'],\n#best'criterion' :['entropy']\nparametros = { \n    'n_estimators': nEstimators,\n    'max_depth' :  maxDepth,\n}#Definimos los parametros que para que la librería nos indique cuál es el mejor\n\ngridSearch = GridSearchCV(estimator = clasificadorForest, \n                          param_grid = parametros,\n                          scoring = 'accuracy',\n                          cv = 10)#En el constructor pasamos el modelo que queremos mejorar, los parametros, medida de calificacion y nuemero de pruebas.\n\ngridSearch = gridSearch.fit(x_train, y_train) #Entrenamos el GridSearch\nprint(gridSearch.best_score_) #vemos como la puntuación de cv pasó de 0.8025 a 0.8237 \nprint(gridSearch.best_params_) #Vemos los parametros más optimos\n\n\n#Aplicación de parametros \nclasificadorForest = RandomForestClassifier(max_features ='auto',\n                                            criterion = 'entropy',\n                                            n_estimators = 84,\n                                            max_depth =  4,\n                                            random_state = 0)\nclasificadorForest.fit(x_train, y_train) #Entrenamos el modelo con los datos de entrenamiento \n\ny_pred = clasificadorForest.predict(x_test) #Hacemos predicciones sobre el conjunto de test\n\nscoreForestGS = clasificadorForest.score(x_train, y_train) #Obtenemos la precisión del algoritmo\nprint('Precisión de algoritmo de Random Forest: ',scoreForestGS)\n\ncv = cross_val_score(estimator = clasificadorForest, X = x_train, y = y_train, cv = 10) #Otro metodo para obtener la precisión\ncvForestGS = cv.mean()\nstdForestGS = cv.std()\nprint(\"promedio Validación cruzada Random Forest: \", cvForestGS)\nprint('Varianza de Random Forest: ',stdForestGS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cuadro comparativo de resultados\ndefectpVsGSForest = pd.DataFrame({'Bosques Aleatorios':['Por Defecto', 'GridSearchCV'],\n                                'Mean Vali. Cruz.':[cvForest,cvForestGS],\n                                'Varianza': [stdForest, stdForestGS]})\n\ndefectpVsGSForest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cuadro comparativo de modelos\nmodelos = pd.DataFrame({'Modelo': ['DecisionTree', 'RandomForest'],\n                      'Precision': [cvTreeGS, cvForestGS],\n                       'Varianza': [stdTreeGS, stdForestGS]\n                      })\nmodelos.sort_values(by='Precision',  ascending = False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Con estos resultados hemos finalizado el proceso de predicción de la supervivencia de los tripulantes del titanic. \nEn este punto hemos hecho un análisis, pre-procesamiento de datos, selección, entrenamiento y optimización de modelos para la solución del problema planteado. \n\nHemos terminado con dos modelos que presentan los mejores resultados en comparación con los demás escogidos. Estos son: El modelo de RandomForest con una precisión del 82,26% y con una varianza del 3,5%. El otro modelo es el de DecisionTree, que presenta una precisión de 82,21% con una varianza del 3,8%\n\nCon estas conclusiones pueden surgir preguntas como: \n1. ¿Pueden mejorar estos resultados ?\n2. ¿Como podemos mejorar estos resultados ? \n3. ¿Hemos hecho una correcta selección de caracteristicas ? \n4. ¿Hemos hecho un correcto pre-procesamiento de datos ? \n5. ¿Podríamos implementar modelos que se ajusten mejor a este problema ? \n\nSi tiene alguna respuesta a estas preguntas podría dejarlas en un comentario, o si tiene dudas o sugerencias podría hacermelo saber para crear retroalimentación y aprender entre nosotros. \n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}