{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!git clone https://github.com/fizyr/keras-retinanet.git","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd keras-retinanet/\n!pip install .","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python setup.py build_ext --inplace","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd ..","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport cv2\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nimport urllib\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\nfrom keras_retinanet import models\nfrom keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\nfrom keras_retinanet.utils.visualization import draw_box, draw_caption\nfrom keras_retinanet.utils.colors import label_color","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"images=os.path.join(\"/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images\")\nannotations=os.path.join(\"/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/annotations\")\ntrain=pd.read_csv(os.path.join(\"/kaggle/input/face-mask-detection-dataset/train.csv\"),header=None)\nsubmission=pd.read_csv(os.path.join(\"/kaggle/input/face-mask-detection-dataset/submission.csv\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_file=pd.DataFrame(columns=['name','x1' , 'x2', 'y1', 'y2','label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.iloc[1:]\nprint(len(train))\nprint(train.head())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(submission))\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(os.listdir(images))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a=os.listdir(images)\nb=os.listdir(annotations)\na.sort()\nb.sort()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(b),len(a))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images=a[1698:]\ntest_images=a[:1698]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(test_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img=plt.imread(os.path.join(images,test_images[0]))\nplt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img=plt.imread(os.path.join(images,train_images[1]))\nplt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"options=['face_with_mask','face_no_mask']\ntrain= train[train[5].isin(options)]\ntrain.sort_values(0,axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_image_objects(image_row):\n\n    img_path = image_row[0]\n    box = [\n    image_row[1], image_row[2], image_row[3], image_row[4]\n    ]\n    img_dir='../input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images'\n    x=os.path.join(img_dir, img_path)\n    image = read_image_bgr(x)\n\n    draw = image.copy()\n    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n\n    draw_box(draw, box, color=(255, 255, 0))\n\n    plt.axis('off')\n    plt.imshow(draw)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[0][13382]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img=plt.imread(os.path.join(images,train[0][13382]))\nplt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_image_objects(train.iloc[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[0] = '../input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images/' + train[0].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df, test_df = train_test_split(\n  train, \n  test_size=0.15, \n  shuffle=False\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PRETRAINED_MODEL = 'pretrained_model.h5'\n\nURL_MODEL = 'https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5'\nurllib.request.urlretrieve(URL_MODEL, PRETRAINED_MODEL)\n\nprint('Downloaded pretrained model to ' + PRETRAINED_MODEL)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.to_csv(r'train_annot.csv', index = False, header=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.to_csv(r'test_annot.csv', index = False, header=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = [['face_with_mask',0],['face_no_mask',1]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv(r'clas.csv', index = False, header=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ANNOTATIONS_FILE = 'train_annot.csv'\nCLASSES_FILE = 'clas.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!keras-retinanet/keras_retinanet/bin/train.py --freeze-backbone --random-transform --weights {PRETRAINED_MODEL} --batch-size 8 --steps 500 --epochs 10 csv train_annot.csv clas.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls snapshots","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nfilename = 'model_raw.sav'\npickle.dump(model, open(filename, 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_path = os.path.join('snapshots', sorted(os.listdir('snapshots'), reverse=True)[0])\nprint(model_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.load_model(model_path, backbone_name='resnet50')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.convert_model(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights(\"model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_to_names = pd.read_csv(CLASSES_FILE, header=None).T.loc[0].to_dict()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_to_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(image):\n  image = preprocess_image(image.copy())\n  image, scale = resize_image(image)\n\n  boxes, scores, labels = model.predict_on_batch(\n    np.expand_dims(image, axis=0)\n  )\n\n  boxes /= scale\n\n  return boxes, scores, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"THRES_SCORE = 0.5\n\ndef draw_detections(image, boxes, scores, labels):\n  for box, score, label in zip(boxes[0], scores[0], labels[0]):\n    if score < THRES_SCORE:\n        break\n\n    color = label_color(label)\n\n    b = box.astype(int)\n    draw_box(image, b, color=color)\n\n    caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n    draw_caption(image, b, caption)\n    print(box,score,caption)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_detected_objects(image_row):\n  img_path = image_row[\"name\"]\n\n  image = read_image_bgr(img_path)\n\n  boxes, scores, labels = predict(image)\n\n  draw = image.copy()\n  draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n\n  true_box = [\n    image_row[\"x1\"], image_row[\"x2\"], image_row[\"y1\"], image_row[\"y2\"]\n  ]\n  draw_box(draw, true_box, color=(255, 255, 0))\n\n  draw_detections(draw, boxes, scores, labels)\n\n  plt.axis('off')\n  plt.imshow(draw)\n  plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.columns = ['name', 'x1', 'x2', 'y1','y2','classname']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_detected_objects(test_df.iloc[430])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df[test_df['classname']=='face_with_mask']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = submission.drop_duplicates()\nsubmit.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(submit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"THRES_SCORE = 0.5\n\ndef draw_detections(image, boxes, scores, labels):\n    boxes_list=[]\n    labels_list=[]\n    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n        if score < THRES_SCORE:\n            break\n\n        color = label_color(label)\n\n        b = box.astype(int)\n        draw_box(image, b, color=color)\n\n        caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n        draw_caption(image, b, caption)\n        print(box,score,caption)\n        boxes_list.append(box)\n        labels_list.append(labels_to_names[label])\n    return boxes_list,labels_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_detected_objects_fin(image_row):  \n  img_path = image_row[\"name\"]\n  img_dir='../input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images'\n  img_path=os.path.join(img_dir, img_path)\n\n  image = read_image_bgr(img_path)\n\n  boxes, scores, labels = predict(image)\n\n  draw = image.copy()\n  draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n\n  draw_detections(draw, boxes, scores, labels) \n\n  dimension, classify = draw_detections(draw, boxes, scores, labels)\n\n  temp = pd.DataFrame(dimension,columns = ['x1' , 'x2', 'y1', 'y2'])\n  temp['label'] = classify\n  temp['name'] = image_row[\"name\"]\n  temp = temp[['name','x1' , 'x2', 'y1', 'y2','label']]\n  return temp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,len(submit)):\n    detected=show_detected_objects_fin(submit.iloc[i])\n    submission_file = submission_file.append(detected,ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_file.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_file.to_csv('submit_this.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}