{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ***Training Support Vector Machines for Multiclass Classification ***","metadata":{"_uuid":"7598684e739d1a55535e9e1a43d0d259f05d4c76","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np\nimport pylab as pl\nimport pandas as pd\nimport matplotlib.pyplot as plt \n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.utils import shuffle\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nfrom sklearn.datasets import load_iris\nfrom sklearn.linear_model import LogisticRegression\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load the Train and Test set","metadata":{"_uuid":"33307fccd56232da9374ba513d18959b8c4e9d0f"}},{"cell_type":"code","source":"# train = shuffle(pd.read_csv(\"../input/human-activity-recognition-with-smartphones/train.csv\"))\n# test = shuffle(pd.read_csv(\"../input/human-activity-recognition-with-smartphones/test.csv\"))\ntrain = shuffle(pd.read_csv(\"../input/motion-recog-data-train-test-validation/train.csv\"))\nvalidation = shuffle(pd.read_csv(\"../input/motion-recog-data-train-test-validation/validation.csv\"))\ntest = shuffle(pd.read_csv(\"../input/motion-recog-data-train-test-validation/test11.csv\"))","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check for missing values in the dataset","metadata":{"_uuid":"e993e4190daa3f4a0518ed12cda67a1242329576"}},{"cell_type":"code","source":"print(\"Any missing sample in training set:\",train.isnull().values.any())\nprint(\"Any missing sample in test set:\",validation.isnull().values.any(), \"\\n\")\nprint(\"Any missing sample in test set:\",test.isnull().values.any(), \"\\n\")\n\n","metadata":{"_uuid":"2c1a405bd11dd03fb3c5dc1638123ac731855f48","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Frequency Distribution of the Outome","metadata":{"_uuid":"e1e38202e14cc4aa861a00965bd2bd9a349da2d3"}},{"cell_type":"code","source":"#Frequency distribution of classes\"\ntrain_outcome = pd.crosstab(index=train[\"Activity\"],  # Make a crosstab\n                              columns=\"count\")      # Name the count column\n\ntrain_outcome\n","metadata":{"_uuid":"055e3422bcb69ef382451a43a5a08bdf3c3901f8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing Outcome Distribution ","metadata":{"_uuid":"a21236c02b43101be1cc9d834e86e8459fe8618f"}},{"cell_type":"code","source":"# Visualizing Outcome Distribution \ntemp = train[\"Activity\"].value_counts()\ndf = pd.DataFrame({'labels': temp.index,\n                   'values': temp.values\n                  })\n\n#df.plot(kind='pie',labels='labels',values='values', title='Activity Ditribution',subplots= \"True\")\n\nlabels = df['labels']\nsizes = df['values']\ncolors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral','cyan','lightpink']\npatches, texts = plt.pie(sizes, colors=colors, shadow=True, startangle=90, pctdistance=1.1, labeldistance=1.2)\nplt.legend(patches, labels, loc=\"best\")\nplt.axis('equal')\nplt.tight_layout()\nplt.show()\n","metadata":{"_uuid":"542c5c78e2e73b387712f9149066cf36d8563fae","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Normalize the Predictor(Feature Set) for SVM training ","metadata":{"_uuid":"9fc1cca22b036f2ac4b90a6b3e8f45e116b24990"}},{"cell_type":"code","source":"# Seperating Predictors and Outcome values from train and test sets\nX_train = pd.DataFrame(train.drop(['Activity','subject'],axis=1))\nY_train_label = train.Activity.values.astype(object)\nX_validation = pd.DataFrame(validation.drop(['Activity','subject'],axis=1))\nY_validation_label = validation.Activity.values.astype(object)\nX_test = pd.DataFrame(test.drop(['Activity','subject'],axis=1))\nY_test_label = test.Activity.values.astype(object)\n\n# Dimension of Train and Test set \nprint(\"Dimension of Train set\",X_train.shape)\nprint(\"Dimension of Train set\",X_validation.shape)\nprint(\"Dimension of Test set\",X_test.shape,\"\\n\")\n\n# Transforming non numerical labels into numerical labels\nfrom sklearn import preprocessing\nencoder = preprocessing.LabelEncoder()\n\n# encoding train labels \nencoder.fit(Y_train_label)\nY_train = encoder.transform(Y_train_label)\n\n# encoding validation labels \nencoder.fit(Y_validation_label)\nY_validation = encoder.transform(Y_validation_label)\n\n# encoding test labels \nencoder.fit(Y_test_label)\nY_test = encoder.transform(Y_test_label)\n\n#Total Number of Continous and Categorical features in the training set\nnum_cols = X_train._get_numeric_data().columns\nprint(\"Number of numeric features:\",num_cols.size)\n#list(set(X_train.columns) - set(num_cols))\n\n\nnames_of_predictors = list(X_train.columns.values)\n\n# Scaling the Train, validation and Test feature set \nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_validation_scaled = scaler.fit_transform(X_validation)\nX_test_scaled = scaler.transform(X_test)\n","metadata":{"_uuid":"8769e8194b0f01cf7b11edc0251af286a10a05e4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hyperparameter tuning using grid search and cross validation","metadata":{"_uuid":"4c422604ae452b9ace06f3c6931a049f764cedfd"}},{"cell_type":"code","source":"#Libraries to Build Ensemble Model : Random Forest Classifier \n# Create the parameter grid based on the results of random search \nparams_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n                     'C': [1, 10, 100, 1000]},\n                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n","metadata":{"_uuid":"8d671c6040d43dc07b988654498f69e58c43e470","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training SVM model using radial kernel","metadata":{"_uuid":"b793c9dd270b8c6f5fcf8bf4bd34cafc16d8f01c"}},{"cell_type":"code","source":"# Performing CV to tune parameters for best SVM fit \n# svm_model = GridSearchCV(SVC(), params_grid, cv=5)\n# svm_model.fit(X_train_scaled, Y_train)\n","metadata":{"_uuid":"763f0f44847242aa484fa301f23f3367118e9c9f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # **Modified/added code--Using a logistic regression linear classifier**","metadata":{}},{"cell_type":"code","source":"# logistic regression classifier\nclf = LogisticRegression(random_state=0, C=2).fit(X_train_scaled, Y_train)\n\nplot_C=[]\nplot_y_validation=[]\nplot_y_training=[]\n\n# The solver for the logistic regression is changed for liblinear, lbfgs, sag, saga, newton-cg\nfor i in range(20):\n    C=0.1*i\n    clf = LogisticRegression(random_state=0,solver='liblinear')\n    clf.fit(X_train_scaled, Y_train)\n    Y_validation_pred = clf.predict(X_validation_scaled)\n    Y_validation_pred_label = list(encoder.inverse_transform(Y_validation_pred))\n    print(\"validation set score for logistic regression with C=\")\n    print(C , clf.score(X_validation_scaled  , Y_validation ))\n    plot_C.append(C)                    \n    plot_y_validation.append(clf.score(X_validation_scaled  , Y_validation ))\n    plot_y_training.append(clf.score(X_train_scaled, Y_train))\n\nplt.plot(plot_C,plot_y_validation)\nplt.plot(plot_C,plot_y_training)\nplt.legend(['validation set', 'training set'], loc='upper left')\nplt.title('Accuracy vs C')            \n\n\nclf = LogisticRegression(random_state=0,solver='lbfgs')\nclf.fit(X_train_scaled, Y_train)\nY_validation_pred = clf.predict(X_validation_scaled)\nY_validation_pred_label = list(encoder.inverse_transform(Y_validation_pred))\nprint(\"training set score for logistic regression with lbfgs\")\nprint(clf.score(X_train_scaled  , Y_train ))\nprint(\"validation set score for logistic regression with lbfgs\")\nprint(clf.score(X_validation_scaled  , Y_validation ))\n\n\n\nclf = LogisticRegression(random_state=0,solver='newton-cg')\nclf.fit(X_train_scaled, Y_train)\nY_validation_pred = clf.predict(X_validation_scaled)\nY_validation_pred_label = list(encoder.inverse_transform(Y_validation_pred))\nprint(\"training set score for logistic regression with newton-cg\")\nprint(clf.score(X_train_scaled  , Y_train ))\nprint(\"validation set score for logistic regression with newton-cg\")\nprint(clf.score(X_validation_scaled  , Y_validation ))\n\nclf = LogisticRegression(random_state=0,solver='sag')\nclf.fit(X_train_scaled, Y_train)\nY_validation_pred = clf.predict(X_validation_scaled)\nY_validation_pred_label = list(encoder.inverse_transform(Y_validation_pred))\nprint(\"training set score for logistic regression with sag\")\nprint(clf.score(X_train_scaled  , Y_train ))\nprint(\"validation set score for logistic regression with sag\")\nprint(clf.score(X_validation_scaled  , Y_validation ))\n\n\nclf = LogisticRegression(random_state=0,solver='saga')\nclf.fit(X_train_scaled, Y_train)\nY_validation_pred = clf.predict(X_validation_scaled)\nY_validation_pred_label = list(encoder.inverse_transform(Y_validation_pred))\nprint(\"training set score for logistic regression with saga\")\nprint(clf.score(X_train_scaled  , Y_train ))\nprint(\"validation set score for logistic regression with saga\")\nprint(clf.score(X_validation_scaled  , Y_validation ))\n\n\n\nclf = LogisticRegression(random_state=0,solver='liblinear')\nclf.fit(X_train_scaled, Y_train)\nY_validation_pred = clf.predict(X_validation_scaled)\nY_validation_pred_label = list(encoder.inverse_transform(Y_validation_pred))\nprint(\"training set score for logistic regression with liblinear\")\nprint(clf.score(X_train_scaled  , Y_train ))\nprint(\"validation set score for logistic regression with liblinear\")\nprint(clf.score(X_validation_scaled  , Y_validation ))\n\n    \n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"_uuid":"46f747a23e396621b636cd18fe252f8156e30023"}},{"cell_type":"markdown","source":"### Confusion Matrix  and Accuracy Score ","metadata":{"_uuid":"46f747a23e396621b636cd18fe252f8156e30023"}},{"cell_type":"code","source":"\n#using logistic regression\nY_test_pred = clf.predict(X_test_scaled)\nY_test_pred_label = list(encoder.inverse_transform(Y_test_pred))","metadata":{"_uuid":"93e0a22c486017ed59d8837b95a8eeeaeab6a59b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Making the Confusion Matrix\n#print(pd.crosstab(Y_test_label, Y_pred_label, rownames=['Actual Activity'], colnames=['Predicted Activity']))\nprint(confusion_matrix(Y_test_label,Y_test_pred_label))\nprint(\"\\n\")\nprint(classification_report(Y_test_label,Y_test_pred_label))\n\nprint(\"Training set score for logistic regression: %f\" % clf.score(X_train_scaled , Y_train))\nprint(\"Testing  set score for logistic regression: %f\" % clf.score(X_test_scaled  , Y_test ))\n\nprint(\"Training set score for logistic regression: %f\" % clf.score(X_train_scaled , Y_train))\nprint(\"Testing  set score for logistic regression: %f\" % clf.score(X_test_scaled  , Y_test ))\n\nclf.score","metadata":{"_uuid":"52792b55ee8429aecdce0ca8592131764ce66828","trusted":true},"execution_count":null,"outputs":[]}]}