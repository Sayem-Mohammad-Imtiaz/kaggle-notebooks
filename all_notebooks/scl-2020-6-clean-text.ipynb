{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Changelog\n\n### Version 3\n\n* Convert series to dataframe before save to parquet format\n\n### Version 1\n\n* Initialize code","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Library","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pyenchant pysastrawi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget http://archive.ubuntu.com/ubuntu/pool/main/libr/libreoffice-dictionaries/hunspell-id_6.4.3-1_all.deb\n!dpkg -i hunspell-id_6.4.3-1_all.deb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!apt update && apt install -y enchant libenchant1c2a hunspell hunspell-en-us libhunspell-1.6-0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import re\nimport os\nimport gc\nimport random\n\nimport numpy as np\nimport pandas as pd\nimport sklearn\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nimport enchant","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip freeze > requirements.txt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"print('Numpy version:', np.__version__)\nprint('Pandas version:', pd.__version__)\nprint('Scikit-Learn version:', sklearn.__version__)\nprint('Matplotlib version:', matplotlib.__version__)\nprint('Seaborn version:', sns.__version__)\nprint('NLTK version:', nltk.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 42\n\nos.environ['PYTHONHASHSEED']=str(SEED)\nrandom.seed(SEED)\nnp.random.seed(SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nltk.download('wordnet')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -lha /kaggle/input\n!ls -lha /kaggle/input/student-shopee-code-league-sentiment-analysis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/student-shopee-code-league-sentiment-analysis/train.csv')\ndf_train.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train2 = pd.read_csv('/kaggle/input/shopee-reviews/shopee_reviews.csv')\n\ndef to_int(r):\n    try:\n        return np.int32(r)\n    except:\n        return np.nan\n\ndf_train2['label'] = df_train2['label'].apply(to_int)\ndf_train2 = df_train2.dropna()\ndf_train2['label'] = df_train2['label'].astype(np.int32)\ndf_train2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/student-shopee-code-league-sentiment-analysis/test.csv')\ndf_test.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = pd.concat([df_train['review'], df_train2['text']], axis=0)\nX_train = X_train.reset_index(drop=True)\ny_train = pd.concat([df_train['rating'], df_train2['label']], axis=0)\ny_train = y_train.reset_index(drop=True)\n\nX_test = df_test['review']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Class weight","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rating_count = y_train.value_counts().sort_index().to_list()\ntotal_rating = sum(rating_count)\nlowest_rating_count = min(rating_count)\nrating_weight = [lowest_rating_count/rc for rc in rating_count]\n\nprint(rating_count)\nprint(total_rating)\nprint(rating_weight)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weight = np.empty((total_rating,))\nfor i in range(total_rating):\n    class_weight[i] = rating_weight[y_train[i] - 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocess","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\nfrom Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n\nlemmatizer = WordNetLemmatizer() # for en\nfactory = StemmerFactory() # for id\nstemmer = factory.create_stemmer() # for id\n\ntweet_tokenizer = nltk.tokenize.TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n\neng_dict = enchant.Dict('en')\nind_dict = enchant.Dict('id_ID')\n\ndef remove_char(text):\n    text = re.sub(r'[^a-z ]', ' ', text)\n    return text\n\n\ndef stem_lemma(tokens):\n    new_token = []\n    for token in tokens:\n        if eng_dict.check(token):\n            new_token.append(lemmatizer.lemmatize(token))\n        elif ind_dict.check(token):\n            new_token.append(stemmer.stem(token))\n        else:\n            new_token.append(token)\n    return new_token\n\ndef upper_or_lower(tokens):\n    new_token = []\n    for token in tokens:\n        total_lower = len(re.findall(r'[a-z]',token))\n        total_upper = len(re.findall(r'[A-Z]',token))\n        if total_lower == 0 or total_upper == 0:\n            new_token.append(token)\n        elif total_lower > total_upper:\n            new_token.append(token.lower())\n        else:\n            new_token.append(token.upper())\n    return new_token\n    \n\ndef preprocess(X):\n    X = X.apply(tweet_tokenizer.tokenize)\n    X = X.apply(lambda token: [t for t in token if t != ''])\n    X = X.apply(upper_or_lower)\n    X = X.apply(stem_lemma)\n#     X = X.apply(lambda token: ' '.join(token)) # need to join token because sklearn tf-idf only accept string, not list of string\n    \n#     X = X.apply(remove_char)\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = preprocess(X_train)\nX_test = preprocess(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Save to parquet","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = pd.DataFrame({'X': X_train})\nX_train.to_parquet('X_train.parquet', engine='pyarrow')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = pd.DataFrame({'X': X_test})\nX_test.to_parquet('X_test.parquet', engine='pyarrow')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = pd.DataFrame({'y': y_train})\ny_train.to_parquet('y_train.parquet', engine='pyarrow')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}