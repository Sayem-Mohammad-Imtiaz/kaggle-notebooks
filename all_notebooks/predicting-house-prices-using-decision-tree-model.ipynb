{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport pandas as pd\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\n\n# Path of the file to read\niowa_file_path = '../input/home-data-for-ml-course/train.csv'\n\nhome_data = pd.read_csv(iowa_file_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using a decision tree model, I wish to perform regression to predict the price of houses in Iowa based on several pertinent features. I will optimize my model using a decision tree regressor."},{"metadata":{"trusted":true},"cell_type":"code","source":"# print the list of columns in the dataset to find the name of the prediction target\nprint(home_data.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = home_data.SalePrice\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the list of features below\nfeature_names = [ 'LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n\n# Select data corresponding to features in feature_names\nX = home_data[feature_names]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Review data\n# print description or statistics from X\nprint(X.describe)\n\n# print the top few lines\nprint(X.head)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n#specify the model. We will be using the Decision Tree Regression Algorithim\niowa_model = DecisionTreeRegressor(random_state=1)\n\n\n# Fit the model\niowa_model.fit(X,y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#making predictions with the data. Recall that we defined the data under the variable X.\npredictions = iowa_model.predict(X)\nprint(predictions)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Comparing the first few price predictions to the actual values, using head\nprint(\"Predictions for the first 5 houses:\")\nprint(iowa_model.predict(X.head()))\nprint(\"Actual values:\") \nprint(y.head().tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Improving our predictions by training/testing & model validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\n\n# split data into training and validation data\n#uniform random state\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 1)\n# Define model\niowa_model = DecisionTreeRegressor()\n# Fit model\niowa_model.fit(train_X, train_y)\n\n# get predicted prices on validation data\nval_predictions = iowa_model.predict(val_X)\n#error\nprint(mean_absolute_error(val_y, val_predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Can we improve our model?\n\nSince I am using a decision tree model, we can add more splits for the tree to increase the number of leaves we will have and the number of groups we are splitting up the houses into.\n\nOverfitting: Lesser leaves make our model highly accurate to the training data, but a poor performer on new, unfamiliar data.\nUnderfitting: does even poorly on training data"},{"metadata":{},"cell_type":"markdown","source":"# Optimization of our Model\nLet's optimize our model to account for underfitting and overfitting."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.tree import DecisionTreeRegressor\n\n#Mean absolute error to help us understand which number of leaves is optimum\n#Using max_leaf_nodes function, which grows a tree with the \"best\" nodes first (best nodes are determined as having the\n#lowest impurity value)\ndef get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Looping through an assortment of models to find the optimum number of leaves\ncandidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500]\n\nfor max_leaf_nodes in candidate_max_leaf_nodes:\n    optimization_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, optimization_mae))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seems to be that the optimum number of leaf nodes is 100. "},{"metadata":{"trusted":true},"cell_type":"code","source":"best_tree_size = 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will fit the model using all of our data in the set."},{"metadata":{"trusted":true},"cell_type":"code","source":"best_model = DecisionTreeRegressor(max_leaf_nodes=best_tree_size, random_state=1)\nbest_model.fit(X, y)\n\nprint(\"Predictions for the first 5 houses using our new model:\")\nprint(best_model.predict(X.head()))\nprint(\"Actual values:\") \nprint(y.head().tolist())\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Accuracy on our validation data\nbest_model.score(val_X, val_y)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}