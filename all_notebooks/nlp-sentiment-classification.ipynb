{"cells":[{"metadata":{"_uuid":"f774d666019848b75052f046269d3b01bb3abbb0"},"cell_type":"markdown","source":"# Sentiment Classification of Clothing ReviewsðŸ’ƒðŸ‘˜ðŸ‘— [WIP]\n![Clothes](https://images.unsplash.com/photo-1521335629791-ce4aec67dd15?ixlib=rb-0.3.5&ixid=eyJhcHBfaWQiOjEyMDd9&s=aa5acd64bf664bc9de6f22d03f6d9c91&auto=format&fit=crop&w=1350&q=80)\n"},{"metadata":{"_uuid":"d1b1689797697e5bd76be6eec77cb268ca205bd1"},"cell_type":"markdown","source":"# Introduction\n\nThe goal is to gather sentiment from reviews for clothes from shopping reviews. I will be using the Fast.ai library to achieve this. The dataset is [Womens Ecommerce Clothing Reviews](https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews) which has 23 000 customer reviews and ratings.  \n\nI will do some light EDA to make sense of the data. I will also do the basic NLP preparation techniques like tokenaztion with spacy. \n"},{"metadata":{"_uuid":"084297bd2760dd7bb3b027b1797c6b7e68794153"},"cell_type":"markdown","source":"# Resources Used\n\n* [fast.ai](http://https://github.com/fastai/fastai/blob/master/courses/dl1/lesson4-imdb.ipynb)\n* [How to interpert the 'perplexed' metric](https://www.quora.com/What-is-perplexity-in-NLP)\n* [Pytorch Docs](https://torchtext.readthedocs.io/en/latest/data.html#)\n* [Datacamp](https://github.com/AmoDinho/datacamp-python-data-science-track/blob/master/Cleaning%20Data%20in%20Python/Chapter%205%20-%20Case%20study.py)\n"},{"metadata":{"_uuid":"078177376505a70809c8f27a8c43eb82e9b259da"},"cell_type":"markdown","source":"# Table of Contents\n\n1. Load Data \n2. EDA\n3. Natural Language Processing\n4. Build The Model\n5. Determine Sentiment  [NB remember to build your own torch text dataset]"},{"metadata":{"_uuid":"88d656ec2188500c340d4d1ffe37b47794246152"},"cell_type":"markdown","source":"# 1. Load Data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nfrom fastai.learner import *\n\nimport torchtext\nfrom torchtext import vocab, data\nfrom torchtext.datasets import language_modeling\n\nfrom fastai.rnn_reg import *\nfrom fastai.rnn_train import *\nfrom fastai.nlp import *\nfrom fastai.lm_rnn import *\n\nimport dill as pickle\nimport spacy\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nprint(os.listdir(\"../input\"))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c54ddbc316752fdaabf41f04294df5d9680680d8"},"cell_type":"code","source":"PATH = \"../input/Womens Clothing E-Commerce Reviews.csv\"\n\nPATH_WRITE = '/kaggle/working/'\nTMP_PATH = '/kaggle/working/tmp/'\nMODELS_PATH = '/kaggle/working/models/'\n\n%mkdir -p {MODELS_PATH}\n%mkdir -p {TMP_PATH}","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"reviews = pd.read_csv(\"../input/Womens Clothing E-Commerce Reviews.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb81b3b8eb094f9d217b5a4c9bf68fd59bc3cad9"},"cell_type":"code","source":"reviews.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49bdf5e47ae7b7b1295236c95777cb421aa0441b"},"cell_type":"code","source":"reviews.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"baf347fa5a247127d3959293db147c0b8f184ed6"},"cell_type":"code","source":"reviews.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e31a0e67bd37670131eabf0ea910baf3c514bb58"},"cell_type":"markdown","source":"# 2. EDA \n Univariavte Analysis\n\n\n\n\n"},{"metadata":{"trusted":true,"_uuid":"1a0a75da1161eff6e02607e3af20bbb4ea714836"},"cell_type":"code","source":"fig, axarr = plt.subplots(2,1,figsize=(12,8))\n\nsns.distplot(reviews['Age'],ax=axarr[0])\nsns.countplot(x=reviews['Rating'],data=reviews['Rating'], order=reviews['Rating'].value_counts().index, ax=axarr[1])\naxarr[0].set_title(\"Distribution of Age\")\naxarr[1].set_title(\"Count of Ratings\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76d21ed0210c9664daa43cd30ca4e12dcd9c2f54"},"cell_type":"code","source":"plots = [\"Division Name\", \"Department Name\"]\nfig, axarr = plt.subplots(1,len(plots),figsize=(14,8))\n\n\nfor i,x in enumerate(plots):\n     sns.countplot(y=x,data=reviews, order=reviews[x].value_counts().index, ax=axarr[i])\n     axarr[i].set_title(\"Count of Catergories in {}\".format(x))\n     \naxarr[0].set_ylabel(\"Category\")\naxarr[1].set_ylabel(\"\")\naxarr[0].set_xlabel(\"Frequency Count\")\naxarr[1].set_xlabel(\"Frequency Count\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3b07d380d365fe01b1f10cf7f314464c929f07d"},"cell_type":"code","source":"plt.figure(figsize=(13,4))\nsns.countplot(reviews[\"Class Name\"], order=reviews[\"Class Name\"].value_counts().index)\nplt.title(\"Count of Class Name Items\")\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35648e76726c48a86c5441edd89da29bb96dcc5b"},"cell_type":"code","source":"sns.countplot(y=\"Clothing ID\", data=reviews[reviews[\"Clothing ID\"].isin(reviews[\"Clothing ID\"].value_counts()[:30].index)], \n              \n              order=reviews[\"Clothing ID\"].value_counts()[:30].index)\nplt.figure(figsize=(14,7))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e93dfcb22a1b43e48e1bc2c2ea483c5fa9adbb68"},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_uuid":"4b0ffe3860173bf119f6157e78d1f9aec85898ae"},"cell_type":"markdown","source":"Questions to explore for multivariate analysis: \n\n* Count the positive vs negative ratings\n* Can we find the which age give the most ratings on a particular item of clothing?\n* What kind of ratings to different age groups give?\n* Which item of clothing has the highest rating?"},{"metadata":{"_uuid":"59978fb8c42b8202376be108dd8c4f18d53e3ee1"},"cell_type":"markdown","source":"# 3. Natural Language Processing\n"},{"metadata":{"_uuid":"129ce57ffb385cb2dbcaec45f0df782efc08c198"},"cell_type":"markdown","source":"We are only interested in the review text and rating columns, so we will go ahead and extract that from the `reviews` dataset."},{"metadata":{"trusted":true,"_uuid":"6f1fe35fb24d718eb552e384ac41e0c7bc278033"},"cell_type":"code","source":"review_text = reviews[['Review Text', 'Rating']]\nreview_text.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a894c247b5f12b32f2e27146097c65d7235f9a5c"},"cell_type":"code","source":"review_text.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd5a38f1d766ea04fccb5b840cf7355fd3e881e7"},"cell_type":"code","source":"review_text.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02807f0ad09fe9cff10239c6df09ac7ef61365e3"},"cell_type":"markdown","source":"Lets do some cleaning up of the data:"},{"metadata":{"trusted":true,"_uuid":"2c42545b05b417d6ec5ce996dc7f0376f75ede4f"},"cell_type":"code","source":"len(review_text.isnull())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"46073280ba72c84663c181a5234f0f93c3ccd618"},"cell_type":"markdown","source":"`isnull()` checks if there are null values in a dataframe and returns a boolean value. In this case we used len to count the instances where it is `False`. 23486 is the count of entires in the DataFrame, So we can safely assume there are not null values in this column."},{"metadata":{"trusted":true,"_uuid":"36a154f7e6869efc6680ae211a8d916bb059afde"},"cell_type":"code","source":"len(review_text['Rating'].isnull())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe97dc1477f20f082f5fa2dce908b4022bbd56f8"},"cell_type":"markdown","source":"Like wise for the `Rating` column."},{"metadata":{"_uuid":"14a87374a5c9942adff35fb329477bd4e316bdd0"},"cell_type":"markdown","source":"If we found null values, we could choose to fill those rows with something like \"no review\"."},{"metadata":{"trusted":true,"_uuid":"90f6e38d7738d0cc18841a6413654e09c5c2895c"},"cell_type":"code","source":"#review_text[review_text['Review Text']==\"\"]=np.NaN\n#review_text['Review Text'].fillna(\"No review\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe0391e28d0b6dc19c627d885b64e531938d6aa8"},"cell_type":"markdown","source":"We need to split the data. We are simply using a 80/20 split :"},{"metadata":{"trusted":true,"_uuid":"ed3dad98845f37f9e83959f7b4459a06a57de4b5"},"cell_type":"code","source":"split = np.random.randn(len(review_text)) <0.8\nTRN = review_text[split]\nTEST = review_text[~split]\nprint(\"Total rows in train:\" ,len(TRN),\"and test:\", len(TEST))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22354e5b16c4be2c5e0cdbe5c6b12b48a5f15fd6"},"cell_type":"markdown","source":"## Lets find out the length of reviews"},{"metadata":{"trusted":true,"_uuid":"d06f117c5a4a966d71072015e0be9a5e05d70b5e"},"cell_type":"code","source":"lens=TRN['Review Text'].str.len()\nprint(\"Avg length:\",lens.mean(), \"Shortest Review:\",lens.min(), \"Longest Review:\",lens.max())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2cecc457aceb33bd946df53b16ce822cf7323abe"},"cell_type":"markdown","source":"We need to use [SpaCy](https://spacy.io/) for our language model. SpaCy allows us to do powerfull Natural Language Processing, which will allow us to do tokenization, named entity recognition and much more. We will obvisouly be using the English module.\n\nYou can download it by typing the following in your terminal:\n`$ python -m spacy download en`"},{"metadata":{"trusted":true,"_uuid":"f2e457de937be4e63c94dd972509266cf4909b02"},"cell_type":"code","source":"spacy_tok = spacy.load('en')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fdb54946c3a54f18e71c81d78a9e116d1efe9845"},"cell_type":"markdown","source":"Below is some tokenized text:"},{"metadata":{"trusted":true,"_uuid":"95466f21c402a2830127767fcf63afed61d89289"},"cell_type":"code","source":"' '.join([sent.string.strip() for sent in spacy_tok(TRN['Review Text'][4])])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"668fd74fb7d25109f237837e21c81aa040ec5582"},"cell_type":"markdown","source":"Fastai uses torchtext very tightly.  so we need to make it aware that it needs SpaCy for tokenization."},{"metadata":{"trusted":true,"_uuid":"a284d8e73a02dc47c7356a94a8fe1b3dc336f23e"},"cell_type":"code","source":"TEXT = data.Field(lower=True, tokenize=\"spacy\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"54a536e562cdd61896c7ee3647c805754ad17814"},"cell_type":"markdown","source":"bs is our batch size parameter, while bptt defines how many layers we need to backprop through. The higher it is, it will increase time and memory requirements but improve the models ability to handle longer sentences."},{"metadata":{"trusted":true,"_uuid":"05955ea37adf59cca125a47dcf2c9d0e5d022fdc"},"cell_type":"code","source":"bs=64; bptt=70","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"47a2a3c5ec367fe242f8d5df8946697e7d6e56e2"},"cell_type":"markdown","source":"We create a dictionary, that specifies the path to our files as well as create a ModelData object. This will fill the TEXT object with the `TEXT.vocab`, it will store which words have been seen in the text, as well as how each word will be mapped to a unique integer id. \n\n"},{"metadata":{"trusted":true,"_uuid":"4fad830b50863f631062e9ecdf82515ad257f5f6"},"cell_type":"code","source":"FILES =dict(train_df=TRN, val_df=TEST, test_df=TEST,col=\"Review Text\")\nmd = LanguageModelData.from_dataframes(PATH, TEXT, **FILES,bs=bs,bptt=bptt, min_freq=10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8bbba4f53c53ada131a595fb307172d85aada3a3"},"cell_type":"markdown","source":"We use dill to let us save it and use it later. "},{"metadata":{"trusted":true,"_uuid":"e91214c18ad2a13b894b35a9eb97885727c23e9a"},"cell_type":"code","source":"pickle.dump(TEXT, open(f'{PATH_WRITE}models/TEXT.pkl','wb'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"19a76021ac9838eb8ed6d8f795260ed6e97a524b"},"cell_type":"markdown","source":"#of Batch,  #unique tokens, #tokens in training set, #sentences "},{"metadata":{"trusted":true,"_uuid":"2b3c954911b0e4781ac634efff5e753cbdec8c0c"},"cell_type":"code","source":"len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"54518547e66d5542e0324307b224bb67c52e90bb"},"cell_type":"markdown","source":"Here we can see the start of mapping from integer IDs to unique tokens:"},{"metadata":{"trusted":true,"_uuid":"a2a70af1564776cb4a57b2bbd9b45d5d702aeed6"},"cell_type":"code","source":"TEXT.vocab.itos[:12]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ca11c5eaefc5a331d0e25e11a9ec79ea5abf50a"},"cell_type":"markdown","source":"For the word \"ugly\" we can display the mapping of token strings to numerical identifiers:"},{"metadata":{"trusted":true,"_uuid":"768c188618381b27d23ffa55b50c87a77a4ef078"},"cell_type":"code","source":"TEXT.vocab.stoi['ugly']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0160ab5123194b0bd67f26d266c49c16706068a"},"cell_type":"code","source":"md.trn_ds[0].text[:50]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5e4a4967c14e30af71b2392ef5635d6dcfd1d46f"},"cell_type":"markdown","source":"Torchtext will turn all the words above into integer IDs:"},{"metadata":{"trusted":true,"_uuid":"d8e540e61e22d597ac1cff3f5c4e1fb60969caca"},"cell_type":"code","source":"TEXT.numericalize([md.trn_ds[0].text[:50]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b72a2e9ed88fc908a9ec80d792f2c9c7f5093bf1"},"cell_type":"code","source":"next(iter(md.trn_dl))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c0b94fff54ecb59d59ce1314838d05cb7e43febc"},"cell_type":"markdown","source":"# 4. Build the model"},{"metadata":{"_uuid":"838584c2c33664e6a50abefc3ba5c1ef74b78a20"},"cell_type":"markdown","source":"We specify the number of parameters to set, which are the size of the embedding vector (`em_sz`), hidden activations per layer(`nh`) and number of layers(`nl`)."},{"metadata":{"trusted":true,"_uuid":"40eb80ee6bc03933433122682a22d080b688d11e"},"cell_type":"code","source":"em_sz = 200\nnh = 500\nnl =3","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c86fd8ab95442e87ead09e867edafbe18fcffec0"},"cell_type":"markdown","source":"This is a Adam optimizer with less momentum, because the kind of RNN we are making will not work well with larges amounts of momentum."},{"metadata":{"trusted":true,"_uuid":"4a3a27229dec4c61be9371c143eb81ead94d172c"},"cell_type":"code","source":"opt_fn = partial(optim.Adam, betas=(0.7, 0.99))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b0c44169f0dc58a314a8a3a95de1a06c14447f5"},"cell_type":"markdown","source":"Below we are specifying our own get model function, specifically for Kaggle. If you are recreating this notebook elsewhere, do not include this function, as well as `tmp_name` and `models_name` in your `get_model()` function. "},{"metadata":{"trusted":true,"_uuid":"9455bc63d1d551e4e5e3f7dfc78fd632c0306bf0"},"cell_type":"code","source":"LEARNER_KWARGS = [\n    'tmp_name', 'models_name', 'metrics', 'clip', 'crit',\n]\n\ndef get_model(self, opt_fn, emb_sz, n_hid, n_layers, **kwargs):\n    lm_kwargs = {k:v for k,v in kwargs.items() if k not in LEARNER_KWARGS}\n    m = get_language_model(self.nt, emb_sz, n_hid, n_layers, self.pad_idx, **lm_kwargs)\n    model = SingleModel(to_gpu(m))\n    learner_kwargs = {k:v for k,v in kwargs.items() if k in LEARNER_KWARGS}\n    return RNN_Learner(self, model, opt_fn=opt_fn, **learner_kwargs)\n\nLanguageModelData.get_model = get_model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"13d4ed0e368e2571fe792777a697af4a0490ce5c"},"cell_type":"markdown","source":"We setup our `learner` model object as well as specify the regulariztion for the different layers. "},{"metadata":{"trusted":true,"_uuid":"b56d1571826b8a34bcc1b2d2fe0d94a594c3246e"},"cell_type":"code","source":"learner = md.get_model(opt_fn, em_sz, nh, nl,\n                      dropouti=0.05,dropout=0.05, wdrop=0.1,dropoute=0.02,dropouth=0.05,\n                      tmp_name=TMP_PATH,models_name=MODELS_PATH)\nlearner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\nlearner.clip=0.3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e109df72c1db3b713862c9c9cfe2e89a06626c38"},"cell_type":"code","source":"learner","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55403774bdce89a8001a1f00c58dddcdf306a467"},"cell_type":"markdown","source":"We can begin to train our model:"},{"metadata":{"trusted":true,"_uuid":"26791dab6e42f4e0f3f33bf9217ff8db43b2d6f6"},"cell_type":"code","source":"learner.fit(3e-3,2,wds=1e-6,cycle_len=1, cycle_mult=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f965ad642a3300b7a5af66156313f05079d8827"},"cell_type":"code","source":"math.exp(3.495)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"483054a59abb0a57c6c4b4d8a226244533c8c23a"},"cell_type":"markdown","source":"For NLP models, their accuracy is measured using a metric called perlexity. This interperts  how perplexed or confused it is about a given text. A score of 95% would imply that is very perplexed, but at 33% our model is not entirely perplexed.  "},{"metadata":{"_uuid":"879cf15b4d532e53f8b89c0e9c9767658fe69f34"},"cell_type":"markdown","source":"What is great is that were are not overfitting! For the sentiment analysis section we will save the encoder part of the language model."},{"metadata":{"trusted":true,"_uuid":"e5015213f2e3a4f9c6a092b6bb6b6ddd2a0ded4a"},"cell_type":"code","source":"learner.save_encoder('adam1_enc')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ee9ae39398cb57916871cd4941949349e17c676"},"cell_type":"code","source":"learner.load_encoder('adam1_enc')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f754e846315fefc74de3ea128435fe14e320d22c"},"cell_type":"markdown","source":"Lets try and train our model for a bit longer. "},{"metadata":{"trusted":true,"_uuid":"3e62e0907a7f5c97ee2d54e63d66e966ed61aa66"},"cell_type":"code","source":"learner.fit(3e-3,1,wds=1e-6,cycle_len=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee49924838fb175cf4cd66b9ff6506e6aa27da5f"},"cell_type":"code","source":"math.exp(3.275)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"458155d9e530ecab844494d84a40acb2b802b509"},"cell_type":"code","source":"pickle.dump(TEXT, open(f'{PATH_WRITE}models/TEXT.pkl','wb'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c8f1b2253c94c73e2c166b79f9a30a5d1711eb3f"},"cell_type":"markdown","source":"# Test time\n\nWe need to be able to play around with our model to see if it can predict words and sentences to offer after being given a string of text."},{"metadata":{"_uuid":"9f4f8e7e15a15c4a4be1cfcab6fdd914a094aaae"},"cell_type":"markdown","source":"Below we start off by creating a small snippet of text."},{"metadata":{"trusted":true,"_uuid":"a33c99db25ca8f6c771c0e1cda395eb3a675d960"},"cell_type":"code","source":"m=learner.model\nss=\"\"\". So, this is the best  \"\"\"\ns = [TEXT.preprocess(ss)]\nt=TEXT.numericalize(s)\n' '.join(s[0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b635cc6de2be3342021937e709b715a5beb6b22a"},"cell_type":"markdown","source":"Here all we are doing are setting up some of the model's parameters:"},{"metadata":{"trusted":true,"_uuid":"93d3b5e7bfc61593ec34234997f2dd0dcf70afd1"},"cell_type":"code","source":"# Set batch size to 1\nm[0].bs=1\n# Turn off dropout\nm.eval()\n# Reset hidden state\nm.reset()\n# Get predictions from model\nres,*_ = m(t)\n# Put the batch size back to what it was\nm[0].bs=bs","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61021ff23c7f282b395d20b42c26119973f34475"},"cell_type":"markdown","source":"Below we are able to see what the 10 ten predictions for the next are given the snippet of text from two cells ago. "},{"metadata":{"trusted":true,"_uuid":"1ec8a3ef27da2627d65072d889268efece09b171"},"cell_type":"code","source":"nexts = torch.topk(res[-1], 10)[1]\n[TEXT.vocab.itos[o] for o in to_np(nexts)]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f72bc19c1a969f5f408b4c11d3fbefe793b3357e"},"cell_type":"markdown","source":"We can now see if it can generate a sentence:"},{"metadata":{"trusted":true,"_uuid":"acf21f993800fe7690021be226e931efaf1b97cb"},"cell_type":"code","source":"print(ss,\"\\n\")\nfor i in range(50):\n    n=res[-1].topk(2)[1]\n    n = n[1] if n.data[0]==0 else n[0]\n    print(TEXT.vocab.itos[n.data[0]], end=' ')\n    res,*_ = m(n[0].unsqueeze(0))\nprint('...')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b236ca84a196c48bfecebbd4b1485c598e61ed28"},"cell_type":"markdown","source":"At the moment we are unable to generate a sentence due to the error above."},{"metadata":{"_uuid":"9cd8ddc949a4e69ad20e7df6674807aec757052e"},"cell_type":"markdown","source":"# 5. Determine Sentiment\n\nIn this part we need to use the vocab from the model to develop our own torchtext dataset and then train it to determine negative and positive reviews. "},{"metadata":{"_uuid":"ac811359e3acd2a61226bf6e76811e73e09e1a63"},"cell_type":"markdown","source":"We need to make sure we use the saved vocab from our language model to ensure that the same words map to the same IDs "},{"metadata":{"trusted":true,"_uuid":"5c8edd18a89aaea817e6c0652c80cb03040ce4bb"},"cell_type":"code","source":"TEXT = pickle.load(open(f'{PATH_WRITE}models/TEXT.pkl','rb'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3adefdad1d1dfd5e51f856831dab5fecb3dd7644"},"cell_type":"markdown","source":"This is an attempt to create the torchtext dataset for the review vocabulary, it is not functional at the moment."},{"metadata":{"trusted":true,"_uuid":"2e81f1a01b4d11665f8db96b5c762ec83ee167f5"},"cell_type":"code","source":"class ReviewsDataset(torchtext.data.Dataset):\n    def __init__(self, path, text_field, label_field,col, label, dfs, **kwargs):\n        fields = [(\"text\", text_field), (\"label\", label_field)]\n        examples = []\n        \n        \n        \n        for key, df in dfs.items():\n            for i, row in df.iterrows():\n            text = row[col]\n            label = dfs[label]\n            examples.append(data.Example.fromlist([text, label], fields))\n        super().__init__(examples, fields, **kwargs)\n\n    @staticmethod\n    def sort_key(ex): return len(ex.text)\n    \n    @classmethod\n    def splits(cls, text_field, label_field, path,\n               train,  test=None, dfs,col, label,valid=None, **kwargs):\n        dfs = {'train': train}\n        \n        if valid is not None:\n            dfs['valid'] = valid\n            has_validation = 'valid'\n        else:\n            has_validation = None\n        if test is not None:\n            dfs['test'] = test\n            has_test = 'test'\n        else:\n            has_test = None\n        \n        return super().splits(path,\n            text_field=text_field, label_field=label_field,\n            train='train', validation=has_validation, test=has_test,col=col,label=label, dfs=dfs, **kwargs)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e2ad4cf435bf402650b6127f718c7a317f8fa7c9"},"cell_type":"markdown","source":"`sequential=False` alerts torchtext that the text field should be tokenized "},{"metadata":{"trusted":true,"_uuid":"31a44d9763bd6497b5a1ffb8064c81624779eefa"},"cell_type":"code","source":"TEXT = pickle.load(open(f'{PATH_WRITE}models/TEXT.pkl','rb'))\nLABEL = data.Field(sequential=False)\nsplits = ReviewsDataset.splits(TEXT, LABEL, path='/kaggle/working/',train=TRN, val=TEST,test=TEST,col=\"Review Text\", label=\"Rating\",dfs=review_text)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"33621fec31a79835748b41b6f6bbd6c1389418b9"},"cell_type":"markdown","source":"I am struggling with Creating My own Torchtext dataset. I've looked at the following resources:\n\n[Lessons from custom torchtext datasets](http://forums.fast.ai/t/lessons-learned-setting-up-custom-dataset-torchtext/8227)\n\n[A Comprehensive Introduction to Torchtext (Practical Torchtext part 1)](http://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/)\n"},{"metadata":{"_uuid":"a381bdd0c07d6d7aa98a9e9fd0aca307b9394c55"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}