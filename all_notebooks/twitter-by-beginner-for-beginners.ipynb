{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## sentiment analysis of twitter text","metadata":{}},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud\nimport nltk\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report,confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout, SpatialDropout1D, LSTM","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"### download data from here\n https://www.kaggle.com/saurabhshahane/twitter-sentiment-dataset\n","metadata":{}},{"cell_type":"code","source":"# download data from here\n# https://www.kaggle.com/saurabhshahane/twitter-sentiment-dataset\n\ndf = pd.read_csv(\"../input/twitter-sentiment-dataset/Twitter_Data.csv\")\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.category.unique()\n\n# -1 is negative\n# 0 is neutral\n# +1 is positive","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df['category'].isna()]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df['clean_text'].isna()]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# delete these...","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(df[df['clean_text'].isna()].index, inplace=True)\ndf.drop(df[df['category'].isna()].index, inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# word cloud is the only visualiztion i know for nlp so, lets do it","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# positive tweets\n\ntext = ''\n\nfor tweet in df[df['category'] == 1.0]['clean_text']:\n    text += f\" {tweet}\"\n    \nwordcloud = WordCloud(\nwidth=3000, height=2000, background_color='black',\nstopwords = set(nltk.corpus.stopwords.words(\"english\"))).generate(text)\n\nfig = plt.figure(figsize=(40,30), facecolor='k',edgecolor='k')\n\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show\n\ndel text","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# negative tweets\n\ntext = ''\n\nfor tweet in df[df['category'] == -1.0 ]['clean_text']:\n    text += f\" {tweet}\"\n    \nwordcloud = WordCloud(\nwidth=3000, height=2000, background_color='black',\nstopwords = set(nltk.corpus.stopwords.words(\"english\"))).generate(text)\n\nfig = plt.figure(figsize=(40,30), facecolor='k',edgecolor='k')\n\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show\n\ndel text","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# positive tweets\n\ntext = ''\n\nfor tweet in df[df['category'] == 0.0 ]['clean_text']:\n    text += f\" {tweet}\"\n    \nwordcloud = WordCloud(\nwidth=3000, height=2000, background_color='black',\nstopwords = set(nltk.corpus.stopwords.words(\"english\"))).generate(text)\n\nfig = plt.figure(figsize=(40,30), facecolor='k',edgecolor='k')\n\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show\n\ndel text","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using count vectorizer and one vs rest approach","metadata":{}},{"cell_type":"code","source":"vec = CountVectorizer(max_features=10000)\nvec.fit(df['clean_text'])\n\ntrn, val = train_test_split(df, test_size=0.3, random_state=42)\n\ntrn_abs = vec.transform(trn['clean_text'])\nval_abs = vec.transform(val['clean_text'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.multiclass import OneVsRestClassifier\nclf = OneVsRestClassifier(LogisticRegression(C = 10, n_jobs=-1))\nclf.fit(trn_abs, trn['category'])\n\nval_preds = clf.predict(val_abs)\nf1_score(val['category'], val_preds, average='micro')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(clf.score(val_abs, val['category']))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(val['category'], val_preds)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix(val['category'], val_preds)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(val['category'], val_preds))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Tfidf Vectorizer**","metadata":{}},{"cell_type":"code","source":"vec = TfidfVectorizer(max_features=10000)\n_ = vec.fit(list(df['clean_text']))\n\ntrn_abs = vec.transform(trn['clean_text'])\nval_abs = vec.transform(val['clean_text'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = OneVsRestClassifier(LogisticRegression(C = 10, n_jobs=-1))\n_ = clf.fit(trn_abs, trn['category'])\n\nval_preds = clf.predict(val_abs)\nf1_score(val['category'], val_preds, average='micro')\n\n# i've seen tfidf perform bad in another case as well...","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(clf.score(val_abs, val['category']))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Word embeddings","metadata":{}},{"cell_type":"code","source":"# i need to learn more about the below code but i thought i'd try it..","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tokenize\ntok = Tokenizer(num_words = 1000000)\n# fit\ntok.fit_on_texts(df['clean_text'].str.lower().tolist())\n\nvocab_size = len(tok.word_index) + 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nX_trn = tok.texts_to_sequences(trn['clean_text'])\nX_val = tok.texts_to_sequences(val['clean_text'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"maxlen = 200\nX_trn = pad_sequences(X_trn, maxlen=maxlen)\nX_val = pad_sequences(X_val, maxlen=maxlen)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_dim = 50\nvocab_size = len(tok.word_index) + 1\n\nmodel = Sequential()\nmodel.add(Embedding(input_dim=vocab_size,\n                    output_dim=embedding_dim,\n                    input_length=maxlen))\n\nmodel.add(Flatten())\nmodel.add(Dense(200, activation='relu', name = 'Fully_Connected'))\nmodel.add(Dense(1, activation='sigmoid', name = 'Output'))\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr = 1e-3),\n              loss='binary_crossentropy',\n              metrics=['accuracy'],\n              )\n\nmodel.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_trn, trn['category'], validation_data=(X_val, val['category']), verbose=True, epochs=20, batch_size=256,\n          callbacks = [tf.keras.callbacks.ReduceLROnPlateau()])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_preds = model.predict(X_val)\n\nf1_score(val['category'], val_preds, average='micro')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Performance metrics","metadata":{}},{"cell_type":"code","source":"accuracy_score(val['category'], val_preds)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix(val['category'], val_preds)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(val['category'], val_preds))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Thank you\n## Don't forget to like or upvote if it was worth your time","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}