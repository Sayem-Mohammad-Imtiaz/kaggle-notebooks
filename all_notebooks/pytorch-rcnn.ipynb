{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection import FasterRCNN\nfrom torchvision.models.detection import fasterrcnn_resnet50_fpn\nfrom torchvision.models.detection.rpn import AnchorGenerator\nfrom PIL import Image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-20T13:14:13.561497Z","iopub.execute_input":"2021-07-20T13:14:13.562034Z","iopub.status.idle":"2021-07-20T13:14:17.416936Z","shell.execute_reply.started":"2021-07-20T13:14:13.561919Z","shell.execute_reply":"2021-07-20T13:14:17.415817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CarDataset(Dataset):\n    def __init__(self, df, image_dir, transforms=None):\n        super().__init__()\n        \n        self.image_ids = df[\"image\"].unique() # all image filenames\n        self.df = df\n        self.image_dir = image_dir # dir to image files\n        self.transforms = transforms\n\n    def __getitem__(self, idx: int):\n        image_id = self.image_ids[idx]\n        records = self.df[self.df[\"image\"] == image_id]\n        image = cv2.imread(f\"{self.image_dir}/{image_id}\", cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image /= 255.0\n        image = torch.tensor(image)\n        image = image.permute(2,0,1)\n        \n        \n        boxes = records[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values\n        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n        \n        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n        area = torch.as_tensor(area, dtype=torch.float32)\n        \n        # There is only one class\n        labels = torch.ones((records.shape[0]), dtype=torch.int64)\n        \n        target = {}\n        target[\"boxes\"] = torch.tensor(boxes)\n        target[\"labels\"] = labels\n        target[\"image_id\"] = torch.tensor([idx])\n        target[\"area\"] = area\n\n\n        if self.transforms:\n            sample = {\"image\": image, \"boxes\": target[\"boxes\"], \"labels\": labels}\n            sample = self.transforms(**sample)\n            image = sample[\"image\"]\n            target[\"boxes\"] = torch.stack(tuple(map(torch.tensor, zip(*sample[\"boxes\"])))).permute(1, 0)\n\n        return image, target, image_id\n\n    def __len__(self):\n        return self.image_ids.shape[0]","metadata":{"execution":{"iopub.status.busy":"2021-07-20T13:14:17.418515Z","iopub.execute_input":"2021-07-20T13:14:17.418868Z","iopub.status.idle":"2021-07-20T13:14:17.434019Z","shell.execute_reply.started":"2021-07-20T13:14:17.418835Z","shell.execute_reply":"2021-07-20T13:14:17.432827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Albumentations\ndef get_train_transform():\n    return A.Compose([\n        A.Flip(0.5),\n        ToTensorV2(p=1.0)\n    ], bbox_params={\"format\": \"pascal_voc\", \"label_fields\": [\"labels\"]})","metadata":{"execution":{"iopub.status.busy":"2021-07-20T10:53:26.374314Z","iopub.execute_input":"2021-07-20T10:53:26.374621Z","iopub.status.idle":"2021-07-20T10:53:26.379338Z","shell.execute_reply.started":"2021-07-20T10:53:26.374592Z","shell.execute_reply":"2021-07-20T10:53:26.37814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load model pretrained on COCO\nmodel = fasterrcnn_resnet50_fpn(pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T13:14:17.559569Z","iopub.execute_input":"2021-07-20T13:14:17.560017Z","iopub.status.idle":"2021-07-20T13:14:31.171673Z","shell.execute_reply.started":"2021-07-20T13:14:17.559958Z","shell.execute_reply":"2021-07-20T13:14:31.170466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes = 2 # 1 class (car) + background\n\n# get number of input features for the classifier\nin_features = model.roi_heads.box_predictor.cls_score.in_features\n\n# replace pre-trained head with new one\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T13:14:31.174209Z","iopub.execute_input":"2021-07-20T13:14:31.174874Z","iopub.status.idle":"2021-07-20T13:14:31.182713Z","shell.execute_reply.started":"2021-07-20T13:14:31.174818Z","shell.execute_reply":"2021-07-20T13:14:31.181329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T13:14:31.184972Z","iopub.execute_input":"2021-07-20T13:14:31.1854Z","iopub.status.idle":"2021-07-20T13:14:31.20508Z","shell.execute_reply.started":"2021-07-20T13:14:31.185362Z","shell.execute_reply":"2021-07-20T13:14:31.203415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def collate_fn(batch):\n    return tuple(zip(*batch))\n\ntrain_df = pd.read_csv(\"../input/car-object-detection/data/train_solution_bounding_boxes (1).csv\")\ndir_train = \"../input/car-object-detection/data/training_images\"\ntrain_ds = CarDataset(train_df, dir_train)\n\ntrain_dl = DataLoader(train_ds, batch_size=8, shuffle=False, num_workers=4, collate_fn=collate_fn)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T11:11:18.788949Z","iopub.execute_input":"2021-07-20T11:11:18.789277Z","iopub.status.idle":"2021-07-20T11:11:18.824609Z","shell.execute_reply.started":"2021-07-20T11:11:18.789241Z","shell.execute_reply":"2021-07-20T11:11:18.823919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2021-07-20T11:11:18.826035Z","iopub.execute_input":"2021-07-20T11:11:18.82636Z","iopub.status.idle":"2021-07-20T11:11:18.889898Z","shell.execute_reply.started":"2021-07-20T11:11:18.826327Z","shell.execute_reply":"2021-07-20T11:11:18.889047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, targets, image_ids = next(iter(train_dl))","metadata":{"execution":{"iopub.status.busy":"2021-07-20T11:11:18.893282Z","iopub.execute_input":"2021-07-20T11:11:18.893645Z","iopub.status.idle":"2021-07-20T11:11:19.698964Z","shell.execute_reply.started":"2021-07-20T11:11:18.893618Z","shell.execute_reply":"2021-07-20T11:11:19.698002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"boxes = targets[6]['boxes'].numpy().astype(np.int32)\nsample = images[6].permute(1,2,0).numpy()\n\nfig, ax = plt.subplots(1, 1, figsize=(16, 8))\n\nfor box in boxes:\n    cv2.rectangle(sample,\n                  (box[0], box[1]),\n                  (box[2], box[3]),\n                  (220, 0, 0), 3)\n    \nax.set_axis_off()\nax.imshow(sample)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T11:11:19.700439Z","iopub.execute_input":"2021-07-20T11:11:19.700801Z","iopub.status.idle":"2021-07-20T11:11:20.080377Z","shell.execute_reply.started":"2021-07-20T11:11:19.700761Z","shell.execute_reply":"2021-07-20T11:11:20.079477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.to(device)\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.Adam(params, lr=0.0005, weight_decay=0.0005)\n# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\nlr_scheduler = None\n\nnum_epochs = 5","metadata":{"execution":{"iopub.status.busy":"2021-07-20T11:11:20.081489Z","iopub.execute_input":"2021-07-20T11:11:20.081855Z","iopub.status.idle":"2021-07-20T11:11:24.379798Z","shell.execute_reply.started":"2021-07-20T11:11:20.081818Z","shell.execute_reply":"2021-07-20T11:11:24.378951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Averager:\n    def __init__(self):\n        self.current_total = 0.0\n        self.iterations = 0.0\n\n    def send(self, value):\n        self.current_total += value\n        self.iterations += 1\n\n    @property\n    def value(self):\n        if self.iterations == 0:\n            return 0\n        else:\n            return 1.0 * self.current_total / self.iterations\n\n    def reset(self):\n        self.current_total = 0.0\n        self.iterations = 0.0","metadata":{"execution":{"iopub.status.busy":"2021-07-20T11:11:24.382033Z","iopub.execute_input":"2021-07-20T11:11:24.382381Z","iopub.status.idle":"2021-07-20T11:11:24.38825Z","shell.execute_reply.started":"2021-07-20T11:11:24.382345Z","shell.execute_reply":"2021-07-20T11:11:24.387459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_hist = Averager()\nitr = 1\nmodel.train()\n\nfor epoch in range(num_epochs):\n    loss_hist.reset()\n    \n    for images, targets, image_ids in train_dl:\n        images = list(image.to(device) for image in images)\n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n        \n        loss_dict = model(images, targets)\n\n        losses = sum(loss for loss in loss_dict.values())\n        loss_value = losses.item()\n\n        loss_hist.send(loss_value)\n\n        optimizer.zero_grad()\n        losses.backward()\n        optimizer.step()\n\n        if itr % 50 == 0:\n            print(f\"Iteration #{itr} loss: {loss_value}\")\n\n        itr += 1\n    \n    # update the learning rate\n    if lr_scheduler is not None:\n        lr_scheduler.step()\n\n    print(f\"Epoch #{epoch} loss: {loss_hist.value}\") ","metadata":{"execution":{"iopub.status.busy":"2021-07-20T12:01:52.646827Z","iopub.execute_input":"2021-07-20T12:01:52.64718Z","iopub.status.idle":"2021-07-20T12:08:47.514042Z","shell.execute_reply.started":"2021-07-20T12:01:52.647151Z","shell.execute_reply":"2021-07-20T12:08:47.512859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = cv2.imread(\"../input/car-object-detection/data/testing_images/vid_5_26640.jpg\", cv2.IMREAD_COLOR)\nimages = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\nimages /= 255.0\nsample = images\nimages = torch.tensor(images)\nimages = images.permute(2,0,1)\nimages = torch.unsqueeze(images, 0)\nimages = images.to(device)\nmodel.eval()\ncpu_device = torch.device(\"cpu\")\n\noutputs = model(images)\noutputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\nboxes = outputs[0][\"boxes\"].detach().numpy().astype(np.int32)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T12:08:47.516195Z","iopub.execute_input":"2021-07-20T12:08:47.51679Z","iopub.status.idle":"2021-07-20T12:08:47.747408Z","shell.execute_reply.started":"2021-07-20T12:08:47.516743Z","shell.execute_reply":"2021-07-20T12:08:47.746499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n\nfor box in boxes:\n    cv2.rectangle(sample,\n                  (box[0], box[1]),\n                  (box[2], box[3]),\n                  (220, 0, 0), 3)\n    \nax.set_axis_off()\nax.imshow(sample)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T12:08:47.749989Z","iopub.execute_input":"2021-07-20T12:08:47.75066Z","iopub.status.idle":"2021-07-20T12:08:48.113539Z","shell.execute_reply.started":"2021-07-20T12:08:47.7506Z","shell.execute_reply":"2021-07-20T12:08:48.112595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}