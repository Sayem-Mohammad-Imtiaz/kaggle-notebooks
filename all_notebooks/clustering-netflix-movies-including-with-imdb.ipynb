{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n!pip install imdbpy\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport plotly as pl\nimport plotly.graph_objs as gobj\nimport pandas as pd\nfrom plotly.offline import download_plotlyjs,init_notebook_mode,plot,iplot\nimport squarify  \nimport matplotlib.pyplot as plt\n\nimport matplotlib.pyplot as plt\nimport random\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import imdb\ndf = pd.read_csv('/kaggle/input/imdbfile/mycsvfile.csv')\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a dictionary of show_id and titles to be used later\nshowNames = pd.Series(df.title.values,index=df.show_id).to_dict()\n\ndef filmPredict(title):\n    print(showNames[(title)])\n    \nfilmPredict(81145628)\nfilmPredict(81035887)\nfilmPredict(80232095)\nfilmPredict(80108610)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import collections\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot\nimport pandas as pd \n\ncol = \"listed_in\"\ncategories = \", \".join(df['listed_in']).split(\", \")\ncounter_list = collections.Counter(categories).most_common(50)\nlabels = [_[0] for _ in counter_list][::-1]\nvalues = [_[1] for _ in counter_list][::-1]\ntrace1 = go.Bar(y=labels, x=values, orientation=\"h\", name=\"TV Shows\", marker=dict(color=\"#a678de\"))\n\ndata = [trace1]\nlayout = go.Layout(title=\"Content added over the years\", legend=dict(x=0.1, y=1.1, orientation=\"h\"))\nfig = go.Figure(data, layout=layout)\nfig.show()\n\n\nnumber_of_colors = len(labels)\n\ncolors = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n             for i in range(number_of_colors)]\n#print(color)\nfig = plt.figure(figsize=(30,15))\n\nsquarify.plot(sizes=values, label=labels, alpha=.8,color=colors )\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#same with countries\n\n\ncol = \"country\"\ndf['country'] = df.country.fillna('none')\ncategories = \", \".join(df['country']).split(\",\")\n\ncounter_list = collections.Counter(categories).most_common(50)\ncounter_list = counter_list[1:50]\nlabels = [_[0] for _ in counter_list][::-1]\nvalues = [_[1] for _ in counter_list][::-1]\ntrace1 = go.Bar(y=labels, x=values, orientation=\"h\", name=\"TV Shows\", marker=dict(color=\"#a678de\"))\n\ndata = [trace1]\nlayout = go.Layout(title=\"Most common actors\", legend=dict(x=0.1, y=1.1, orientation=\"h\"))\nfig = go.Figure(data, layout=layout)\nfig.show()\n\nimport plotly.express as px\n\n\n#try to do one for other countriesp\n\nlabels\n\n#make an interactive pie chart and countries with less than 20 make as 'other'\n\ndf1 = {'Country':labels,'number':values}\ndf1 = pd.DataFrame(df1)\ndf1.loc[df1['number'] < 50, 'Country'] = 'Other countries' \nfig = px.pie(df1, values='number', names='Country', color_discrete_sequence=px.colors.cyclical.Phase)\nfig.show()\n\n\n#initializing the data variable\ndata = dict(type = 'choropleth',\n            \n            locations = labels,\n            locationmode = 'country names',\n            colorscale= 'Portland',\n            \n            text= labels,\n            z=values,\n            colorbar = {'title':'Country Colours', 'len':200,'lenmode':'pixels' })\n\nlayout = dict(geo = {'scope':'world'}, title_text ='Netflix shows in each country')\n\ncol_map = gobj.Figure(data = [data],layout = layout)\n\niplot(col_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncol = \"cast\"\ndf['cast'] = df.cast.fillna('bam')\ncategories = \", \".join(df['cast']).split(\", \")\n\ncounter_list = collections.Counter(categories).most_common(50)\ncounter_list = counter_list[1:50]\nlabels = [_[0] for _ in counter_list][::-1]\nvalues = [_[1] for _ in counter_list][::-1]\ntrace1 = go.Bar(y=labels, x=values, orientation=\"h\", name=\"TV Shows\", marker=dict(color=\"#a678de\"))\n\ndata = [trace1]\nlayout = go.Layout(title=\"Most common actors\", legend=dict(x=0.1, y=1.1, orientation=\"h\"))\nfig = go.Figure(data, layout=layout)\nfig.show()\nprint(len(categories))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a function for putting in name of actor and getting films/shows they are in \n\nactorDictionary = {}\ncounter_list = collections.Counter(categories).most_common(1000)\ncounter_list = counter_list[1:1000]\nActors = [_[0] for _ in counter_list][::-1]\njustActors = pd.DataFrame()\njustActors['title'] = df['title']\njustActors['cast'] = df['cast']\n\n\n\n#cycle through the labels and if they - i know its the worst fofrmula ever\ncount = 0\nfor cols, rows in justActors.iterrows():\n    for actor in Actors:\n        if actor in (rows[1]):\n            actorDictionary.setdefault(actor, []).append(rows[0])\n            count+=1\n\nactorDictionary\nprint(count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def findFilms(name):\n    x = actorDictionary[name]\n    print(x)\n    \n\nfindFilms('Ricky Gervais')\nfindFilms('Nicolas Cage')\nfindFilms('Brad Pitt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import imdb\n\nia = imdb.IMDb()\n\nmovies = ia.search_movie('matrix')\nmovies[0]\n\nfor k,v in movies[0].items():\n    print(k,v)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movie = movies[0]\n\nia.update(movie, info=['taglines','vote details'])\n\n#create function for retriveing ratings\n\ndef rating(name):\n    name = str(name)\n    movies = ia.search_movie(name)\n    movie = movies[0]\n    ia.update(movie, info=['taglines','vote details'])\n    rating = movie['arithmetic mean']\n    return (rating)\n\n\ndef rating_test(name):\n    try:\n        x = rating(name)\n        return(x)\n    \n    except:\n         x = 0\n         return(x)\n        \nx = rating_test('Babel')\nprint(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"okk = df['title'][3]\nrating_test(okk)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#only run once to get imdb ratings\n\n#df['rating'] = df['title'].apply(rating_test)\n#df.head(10)\n\n#df.to_csv('mycsvfile.csv',index=False)\ndf = pd.read_csv('/kaggle/input/imdbfile/mycsvfile.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n#df.rating.plot()\nplt.hist(df['rating'])\n\n#so most movies on netflix have a rating of \n\nx = df['rating'].median()\nplt.axvline(x, color='k', linestyle='dashed', linewidth=1)\n#plt.line(y=6.4)\nplt.show()\nlen(actorDictionary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ratingDic = {}\n\nhay = df['title'].tolist()\nhay = pd.Series(df.rating.values,index=df.title).to_dict()\n    \nhay\n\ncount = 0\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a dictionary for average imdb score for each actor to find which actors are in the best films - do similiar for genre etc - then think of how to cluster the categrical data\nactorMean = {}\n\nfor k,v in actorDictionary.items():\n    count = 0\n    for i in v:\n        count += hay[i]\n    actorMean[k] = (count/len(v))\n\n    \nactorMean\n#sort by highest first \nsort = {k: v for k, v in sorted(actorMean.items(), key=lambda item: item[1])}\ndfRate = pd.DataFrame.from_dict(sort.items())\n#df.sort_values(by=[1])\n\ntitle = ['actor','mean']\ndfRate.columns = title\ndfRate.info()\n\n#df.sort_values(by = ['mean', 'actor'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"counter_list = dfRate.tail(50)\ncounter_list\n\nlabels = counter_list['actor']\nvalues = counter_list['mean']\ntrace1 = go.Bar(y=labels, x=values, orientation=\"h\", name=\"TV Shows\", marker=dict(color=\"#a678de\"))\n\ndata = [trace1]\nlayout = go.Layout(title=\"Actors with the highest average ratings\", legend=dict(x=0.1, y=1.1, orientation=\"h\"))\nfig = go.Figure(data, layout=layout)\nfig.show()\nprint(len(categories))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def findIMDBaverage(name):\n    ave = actorMean[name]\n    return(ave)\n\n#example\nfindIMDBaverage('Keanu Reeves')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#do the same for genre? or try to create a model/cluster to find other films someone might like based on what they liked previously. \n\ndfCopy = df\n#only keep columns you want for algorith\ndfCopy.head()\ndfCopy['director'] = dfCopy.director.fillna('MR')\n\ndfCopy['director3'], dfCopy['director2'] = dfCopy['director'].str.split(',',1).str\ndfCopy.head()\n\ndfCopy[\"director3\"] = dfCopy[\"director3\"].astype('category')\ndfCopy[\"directorCode2\"] = dfCopy[\"director3\"].cat.codes\ndfCopy = dfCopy.replace(-1,1)\ndfCopy.head()\ndfCopy[\"listed_in\"] = dfCopy[\"listed_in\"].astype('category')\ndfCopy[\"genreCombo\"] = dfCopy[\"listed_in\"].cat.codes\ndfCopy.head()\n#dfCopy[\"genreCombo\"].value_counts()\n\ndfCopy[\"country\"] = dfCopy[\"country\"].astype('category')\ndfCopy[\"country1\"] = dfCopy[\"country\"].cat.codes\ndfCopy = dfCopy.set_index('show_id')\nscalerValues = dfCopy.drop('type', axis=1) \nscalerValues = scalerValues.drop('title', axis=1) \nscalerValues = scalerValues.drop('director', axis=1) \nscalerValues = scalerValues.drop('cast', axis=1) \nscalerValues = scalerValues.drop('date_added', axis=1) \nscalerValues = scalerValues.drop('duration', axis=1) \nscalerValues = scalerValues.drop('listed_in', axis=1) \nscalerValues = scalerValues.drop('description', axis=1) \nscalerValues = scalerValues.drop('director2', axis=1) \nscalerValues = scalerValues.drop('director3', axis=1) \nscalerValues = scalerValues.drop('country', axis=1) \n\nscalerValues.head()\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom sklearn import preprocessing\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\n\ncol_names = list(scalerValues.columns)\n\n\nmm_scaler = preprocessing.MinMaxScaler()\ndf_mm = mm_scaler.fit_transform(scalerValues)\n\nscalerValues = pd.DataFrame(df_mm, columns=col_names)\n\nfig, (ax1) = plt.subplots(ncols=1, figsize=(10, 8))\nax1.set_title('After MinMaxScaler')\n\nsns.kdeplot(scalerValues['rating'], ax=ax1)\n\nsns.kdeplot(scalerValues['genreCombo'], ax=ax1)\nsns.kdeplot(scalerValues['directorCode2'], ax=ax1)\nsns.kdeplot(scalerValues['release_year'], ax=ax1)\nscalerValues.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nX = scalerValues\n\npca = PCA()\npca.fit(X)\nprint(pca.explained_variance_ratio_)\n\n#pca.info()\nplt.plot(range(1,6),pca.explained_variance_ratio_.cumsum(),marker='o')\nplt.title(\"explained variance by components\")\nplt.xlabel('Number of Components')\nplt.ylabel('Cumulative explained variance')\n\nscalerValues.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we keep 3 pc's beause this give 80% of the variance\n\npca = PCA(n_components=3)\npca.fit(X)\nscores_PCA = pca.transform(X)\n\n#sum of squares\n#we potentially want a lot of clusters so im going to say up to 100\nsos = []\nfor i in range(1,100):\n    kmeans_pca = KMeans(n_clusters = i,init ='k-means++',random_state=200)\n    kmeans_pca.fit(scores_PCA)\n    sos.append(kmeans_pca.inertia_)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    \nplt.figure(figsize=(20,20))\nplt.plot(range(1,100),sos,marker='o')\nplt.xlabel('Number of clusters')\nplt.ylabel('SOS')\nplt.title('k-meas with PCA clusterinn')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gonna go for 20 because i know i want a lot of clusters \n\nkmeans_pca = KMeans(n_clusters=10,init='k-means++',random_state=42)\nkmeans_pca.fit(scores_PCA)\n\nZ = kmeans_pca.predict(scores_PCA)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#next task create a word frequency graph with description column\n\ndf_kmeans = pd.concat([X,pd.DataFrame(scores_PCA)],axis=1)\ndf_kmeans.columns.values[-3:]=['comp 1','comp 2','comp 3']\ndf_kmeans['segment k means PCA'] = kmeans_pca.labels_\n\ndf_kmeans = df_kmeans.set_index(df['show_id'])\ndf_kmeans.head()\n\nx_axis = df_kmeans['comp 2']\ny_axis = df_kmeans['comp 1']\nplt.figure(figsize=(20,20))\nsns.scatterplot(x_axis,y_axis,hue=df_kmeans['segment k means PCA'])\nplt.title('clusters by pca components')\nplt.show()\n\n\ndf_kmeans.info()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install chart_studio\n!pip install plotly\nimport glob\nimport numpy as np\nimport pandas as pd\nimport chart_studio\nimport plotly\n#import plotly.plotly as py\n#import chart_studio.plotly as py\nimport plotly.graph_objs as pgo\nimport chart_studio.plotly as py\n#import chart_studio.plotly as py\n\n\nchart_studio.tools.set_credentials_file(username='sarahjeeeze', api_key='SvTKCDpH5TQ7aCJuROxR')\n\ntrace0 = pgo.Scatter(x=df_kmeans['comp 2'],\n                    y=df_kmeans['comp 1'],\n                    text=df_kmeans.index,\n                    mode='markers',\n                    # Size by total population of each neighborhood. \n                    marker=plotly.graph_objs.scatter.Marker(size=df_kmeans['rating'],\n                                      sizemode='diameter',\n                                      sizeref=df_kmeans['rating'].max()/5,\n                                      opacity=0.5,\n                                     color=Z\n                                                       ))\nmodel = kmeans_pca\nn_cluster = 10\n\n# Represent cluster centers.\ntrace1 = pgo.Scatter(x=model.cluster_centers_[:, 0],\n                     y=model.cluster_centers_[:, 1],\n                     name='',\n                     mode='markers',\n                     marker=pgo.Marker(symbol='x',\n                                       size=12,\n                                      ),\n                     \n                     showlegend=False\n)\n\nlayout5 = pgo.Layout(title='Baltimore Vital Signs (PCA)',\n                     xaxis=pgo.XAxis(showgrid=False,\n                                     zeroline=False,\n                                     showticklabels=False),\n                     yaxis=pgo.YAxis(showgrid=False,\n                                     zeroline=False,\n                                     showticklabels=False),\n                     hovermode='closest'\n)\ndatad = pgo.Data([trace0, trace1])\nlayout7 = layout5\nlayout7['title'] = 'Netflix  in 10 clustsers)'\nfig7 = pgo.Figure(data=datad, layout=layout7)\npy.iplot(fig7, filename='baltimore-cluster-map')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#defo needs some work \n#could not use titles as indexes because then you have to pay for plotly. #want to try hierachical next and create a function that out puts the 5 closest for the name of a film.\nfilmPredict(60004083)\nfilmPredict(80119188)\n\n#could add more things to include in pca\n#look here for idea of how to create labels for the numbers using sci kit learn as well as one hot encoding which could be used for genres and or feature hashing\n#https://towardsdatascience.com/understanding-feature-engineering-part-2-categorical-data-f54324193e63","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}