{"cells":[{"metadata":{"_uuid":"ccb1e722c98e9674dadb632cb2d55be7dd948879","_cell_guid":"2168c414-06dc-427b-a79b-57e420a7650a"},"cell_type":"markdown","source":"# Dense-Sparse-Dense Convolutional Neural Network\nA convolutional neural network is used for training on image data because of it's properties. Dense-Sparse-Training is a method used on ANY neural network(CNN,RNN,GRU,LSTM) to improve convergence. The process is pretty simple."},{"metadata":{"collapsed":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Input, Dropout, Activation, Flatten\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nfrom skimage.io import imshow\nfrom keras import backend as K\nfrom keras.constraints import Constraint","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"672527778174ec2b2cd323c37cdef90ccc60d4e9","_cell_guid":"dbc49540-eb18-4e4f-9731-80985aeefe63"},"cell_type":"markdown","source":"## Getting the Data\nThe data is encoded into Comma Separated Value(csv) files. It is essentially a table of values. Let's import that using Pandas, a data science framework and separate the images from the labels."},{"metadata":{"collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"#Read CSV\ncsv = pd.read_csv('../input/fashionmnist/fashion-mnist_train.csv')\n#Separate into matricies\nX_train = csv.iloc[:,1:786].as_matrix()\nY_train = csv.iloc[:,0].as_matrix()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3aae6f95e1c90744bc9713391be5505263d7b984","_cell_guid":"fda1ea99-2e73-4964-88ae-81ee4d2a3fd5"},"cell_type":"markdown","source":"## Our Data\nThe data we just got is in 2 different variables as matricies. We have 60 thousand examples of 10 different articles of clothing. The `X_train` variable contains the images in flattened form and the `Y_train`  variable contains the labeled clothing item for each flattened image.\nPeople have used flattened images for recognition, but it doesn't work as well. The problem with doing so is that the structure of the image is destroyed. Imagine trying to learn what a shoe or hat looks like by looking at a string of numbers instead of an image. We have 2 steps we must complete before we feed in the data.\n\n### 1. Convert the strings of numbers to images"},{"metadata":{"collapsed":true,"_uuid":"023b33013f30f4b0281ea5f4d20fd66c3fb869b0","_cell_guid":"80127a14-8a5d-4e1a-a1df-e7fe854fdb02","trusted":false},"cell_type":"code","source":"# This is very simple\nX_train_imgs = np.zeros([X_train.shape[0],28,28,1])\nfor i in range(X_train.shape[0]):\n    img = X_train[i,:].reshape([28,28,1])/255.\n    X_train_imgs[i] = img","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a22325bc73f5e812de2c75950084dbdc94feb40d","_cell_guid":"15c497c4-ec4f-43ed-8c2a-1b83a0438c73"},"cell_type":"markdown","source":"### 2. Now we have to get the number encodings to one-hot encodings\nLike in our last club meeting, we used vectors(lists) of ones and zeros to find out what type of land it was. Kindly they had already made the labels one-hot encoded, but this time we have to do it ourselves. The good thing is, it's really easy. Let's get out of the way:"},{"metadata":{"collapsed":true,"_uuid":"f7583a913705e1329e0f6f365b5945c7ca9bfc63","_cell_guid":"8556e9ec-2a78-4f20-b265-0361ce993640","trusted":false},"cell_type":"code","source":"#oh stands for one-hot\n#There are 60000 examples and 10 different pieces of clothing\nY_train_oh = np.zeros([Y_train.shape[0],10])\nfor i in range(Y_train.shape[0]):\n    oh = np.zeros([10])\n    oh[int(Y_train[i])] = 1.\n    Y_train_oh[i] = oh","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a8dbc84e732c80ccb14aeb1d580ee4a761581e73","_cell_guid":"9fab0995-753e-4d26-9a45-4d03224523d6"},"cell_type":"markdown","source":"Keep in mind there are WAY faster ways to do those 2 steps using the power of libraries like numpy. If you were to be working with Big Data(Terabytes of information), it is extremely important that you optimize for speed. However, the amount of data we are working with is tiny enough we don't have to worry about it."},{"metadata":{"_uuid":"3897c1749c9a6e2cb5c0eed9a0ad959048c0b610","_cell_guid":"059d4df1-021e-4f6d-b69a-b484ce618444"},"cell_type":"markdown","source":"#### Let's take a look at these images now"},{"metadata":{"_uuid":"ecab74998b559c4af1f1a88a066d4d46fbbbf7ec","_cell_guid":"578dc27c-2190-443a-aa88-a1fddc4316b4","trusted":false,"collapsed":true},"cell_type":"code","source":"ix = 12345 #0-41999\nimshow(np.squeeze(X_train_imgs[ix]))\nplt.show()\nlabel = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle Boot']\nprint ('This is:',label[int(Y_train[ix])])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"372ff2105e7851a87cb34b21137fb52d6268ba50","_cell_guid":"6044e5bb-dafa-4b56-9bce-b735f7cde9a2"},"cell_type":"markdown","source":"## How to do Dense-Sparse-Dense Training\ndense-sparse-dense(DSD) training is a method used in this paper -> https://arxiv.org/pdf/1607.04381.pdf <- for improving the convergence of neural networks. It works like this:\n1. Train neural network to convergence\n2. Set all weights at a certain threshold to 0\n3. Train the neural network again while keeping those weights 0\n4. Release the 0 weights and train at 1/10 the learning rate\n\nThis method of training improves the accuracy of every model it has been tested against on the paper(~9% relative improvements). In Keras, I think we can use a kernel constraint to keep weights at 0 to train a neural network sparsely.\n"},{"metadata":{"collapsed":true,"_uuid":"50ed34b2578391fde00334e91c374b44b93f891a","_cell_guid":"1715daa4-f943-468d-a1a9-78ab38b09df0","trusted":false},"cell_type":"code","source":"#Let's code our own constraint!\nclass Sparse(Constraint):\n    '''\n    We will use one variable: Mask\n    After we train our model dense model,\n    we will save the weights and analyze them.\n    We will create a mask where 1 means the\n    number is far away enough from 0 and 0\n    if it is to close to 0. We will multiply\n    the weights by 0(making them 0) if they\n    are supposed to be masked.\n    '''\n    \n    def __init__(self, mask):\n        self.mask = K.cast_to_floatx(mask)\n    \n    def __call__(self,x):\n        return self.mask * x\n    \n    def get_config(self):\n        return {'mask': self.mask}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8bd818d94120bc05f85c316a894b4f772eede2a8","_cell_guid":"ccf5a4a5-2135-4e43-aa3c-37023a33d339"},"cell_type":"markdown","source":"## Time to make the neural network\nLet's get the layers coded.\n\n 1. Convolution with 32 5x5 filters and input_shape=(28,28,1)\n 2. relu Activation\n 3. 2x2 Pooling with a stride of 2\n 4. Convolution with 64 5x5 filters\n 5. relu Activation\n 6. 2x2 Pooling with a stride of 2\n 7. Flatten\n 8. Dense Layer with 1024 units\n 9. relu Activation\n 10. Dropout with p=0.4\n 11. Dense Layer with 10 units\n 12. softmax Activation"},{"metadata":{"collapsed":true,"_uuid":"a71f3a502e941bfc2524546c25c2dccc647a93ce","_cell_guid":"f203ef3e-72e9-4c1f-9287-b178ca8a25b3","trusted":false},"cell_type":"code","source":"# Make sure you separate layers with commas!\nmodel = Sequential([\n    Conv2D(32,3,input_shape=(28,28,1)),\n    Activation('relu'),\n    MaxPooling2D(2,2),\n    Dropout(0.25),\n    Conv2D(64,3),\n    Activation('relu'),\n    MaxPooling2D(2,2),\n    Dropout(0.25),\n    Flatten(),\n    Dense(250),\n    Activation('relu'),\n    Dropout(0.4),\n    Dense(10),\n    Activation('softmax')\n])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"460a04d3b61cb62d8acaf6de4ad034f9813f599d","_cell_guid":"0b0173ca-ae5d-41e4-a824-425b3d3e674f"},"cell_type":"markdown","source":"## Let's compile and view the model!\nTo do that we need to have a loss function, optimizer, and metrics.\nThe loss function we will use is 'categorical_crossentropy'.\nThe optimizer is called the adam(Adaptive Momentum).\nThe metric we will use is 'accuracy' so we can see our model accuracy during training.\n\nThen we call `model.summary()` to see some stats about our model"},{"metadata":{"_uuid":"0d0418ab726a23aa5bd4bf50d651664dabbe56db","_cell_guid":"62bc7bc3-4b20-47ca-9d8d-f6edb24e2aaa","trusted":false,"collapsed":true},"cell_type":"code","source":"adam = Adam()\nmodel.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9cd69c9bb61b2cbbcaee1d188ade2b03d8d7360a","_cell_guid":"424accf2-b7b8-492f-9bd5-48694c58b42d"},"cell_type":"markdown","source":"## Alright! Time to Train our Dense Model!\nThe first step in the process of Dense-Sparse-Dense training is to converge a model. That's pretty simple. We just have to train our model!"},{"metadata":{"_uuid":"906fb5838dde78e1e69c55b4cd7511d02bd68300","_cell_guid":"d55ac67d-0842-4448-8dbe-6f6b120967bb","trusted":false,"collapsed":true},"cell_type":"code","source":"#We will train on 41000 examples and validate on 18999(To be quick)\nmodel.fit(X_train_imgs[:41000], Y_train_oh[:41000],\n          batch_size=32,\n          epochs=10,\n          verbose=1,\n          validation_data=(X_train_imgs[41001:], Y_train_oh[41001:]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"11511adc038e054c27e5b2d7c886f47c3f0f86db","_cell_guid":"f6b3836a-6ad6-4add-952f-67b2337e75b6"},"cell_type":"markdown","source":"## Now it's time to make the Sparse Model!\nFirst let's get the weights of the model and set the mask to be the x% closest to 0! This function I implemented is very simple. All it does is set the closest x% to 0.\n**NOTE**: Make sure the list returned by model.get_weights() goes with this:\n`[weights,biases,weights,biases.....]`\nWe analyze every other variable(which is weights) for masking. If every layer that should have weights and biases has biases on, it should be fine*(IDK about BatchNorm)*."},{"metadata":{"collapsed":true,"_uuid":"74a8d7d6517ac0fd4847f189d800391ce2188a0f","_cell_guid":"3887e0de-72bc-4538-b4d7-ddeae1f42758","trusted":false},"cell_type":"code","source":"def create_sparsity_masks(model,sparsity):\n    weights_list = model.get_weights()\n    masks = []\n    for weights in weights_list:\n        #We can ignore biases\n        if len(weights.shape) > 1:\n            weights_abs = np.abs(weights)\n            masks.append((weights_abs>np.percentile(weights_abs,sparsity))*1.)\n    return masks","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"569d85f8ac380b23f7fb42b41739f6bcc4cc0a7f","_cell_guid":"3bab7111-b2e4-4f2f-8486-383c156599ce","trusted":false},"cell_type":"code","source":"masks = create_sparsity_masks(model,30)#Closest 30% to 0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7dcfa676baff1a533a5a03e337a6463d348b967","_cell_guid":"00b5a78e-f492-44da-8803-3bdd5b7a2329","trusted":false,"collapsed":true},"cell_type":"code","source":"sparse_model = Sequential([\n    Conv2D(32,3,input_shape=(28,28,1), kernel_constraint=Sparse(masks[0])),\n    Activation('relu'),\n    MaxPooling2D(2,2),\n    Dropout(0.25),\n    Conv2D(64,3, kernel_constraint=Sparse(masks[1])),\n    Activation('relu'),\n    MaxPooling2D(2,2),\n    Dropout(0.25),\n    Flatten(),\n    Dense(250, kernel_constraint=Sparse(masks[2])),\n    Activation('relu'),\n    Dropout(0.4),\n    Dense(10, kernel_constraint=Sparse(masks[3])),\n    Activation('softmax')\n])\n\nadam = Adam()\nsparse_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\nsparse_model.summary()\n#Get weights from densely trained model\nsparse_model.set_weights(model.get_weights())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d700fe4cfcb29b79d0d6a40356157ef70dcec8f4","_cell_guid":"d4e6666e-42f4-42fc-83e4-4176ef872cf7"},"cell_type":"markdown","source":"## Let's train the Sparse Model Now!\nJust use the same learning rate and stuff for the fit function!"},{"metadata":{"_uuid":"9a6cf6808b00c9df9330419cd7bb2fdb1be2d391","_cell_guid":"0dd74994-6d5e-470d-b796-39476258e5cb","trusted":false,"collapsed":true},"cell_type":"code","source":"sparse_model.fit(X_train_imgs[:41000], Y_train_oh[:41000],\n          batch_size=32,\n          epochs=10,\n          verbose=1,\n          validation_data=(X_train_imgs[41001:], Y_train_oh[41001:]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fba2af1c03d9167679eb2bf9da4d8d7fbf7a46bd","_cell_guid":"8ce17f76-9107-4511-b984-3324e059a826"},"cell_type":"markdown","source":"## Now to train it as a Dense Network\nWe will do it just like we did the last step:\n1. Create new model without the Sparse constraint\n2. Train the network(with 1/10 the learning rate)"},{"metadata":{"_uuid":"cb57576924e3ce71d2c1d492420e22334a694a86","_cell_guid":"121d2d72-911f-4b38-ad93-7861b5f1cdb9","trusted":false,"collapsed":true},"cell_type":"code","source":"redense_model = Sequential([\n    Conv2D(32,3,input_shape=(28,28,1)),\n    Activation('relu'),\n    MaxPooling2D(2,2),\n    Dropout(0.25),\n    Conv2D(64,3),\n    Activation('relu'),\n    MaxPooling2D(2,2),\n    Dropout(0.25),\n    Flatten(),\n    Dense(250),\n    Activation('relu'),\n    Dropout(0.4),\n    Dense(10),\n    Activation('softmax')\n])\n\nadam = Adam(lr=0.0001)#Default Adam lr is 0.001 so I set it to 0.0001\nredense_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\nredense_model.summary()\n#Get weights from sparsely trained model\nredense_model.set_weights(sparse_model.get_weights())\n\nredense_model.fit(X_train_imgs[:41000], Y_train_oh[:41000],\n          batch_size=32,\n          epochs=10,\n          verbose=1,\n          validation_data=(X_train_imgs[41001:], Y_train_oh[41001:]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35e9a38133d4f6f36217d06a3a0b1102de0a7b59","_cell_guid":"8c0a6047-3c69-4aed-8547-0a68fe39dc26"},"cell_type":"markdown","source":"## Phew! That took some time!\nThe biggest disadvantage for DSD training is the tripled training time, but if you already have a trained and well-tuned model, I would use this method to improve accuracy."},{"metadata":{"_uuid":"63a9e4d7bf4a95d5426d6b7ee5ba7eafa81f0a13","_cell_guid":"98d01a63-f13e-431a-9be5-b47fbf55c36f","trusted":false,"collapsed":true},"cell_type":"code","source":"#First, let's get all the predictions\np = redense_model.predict(X_train_imgs[41000:],verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad598c5e2039e8ee148aa3926817a52e3e730a7a","_cell_guid":"0bcd06c9-2a03-4f1f-a1eb-870da63c086c"},"cell_type":"markdown","source":"### Now we can see the outputs\nWhen we get the prediction out it is in a list as 10 probabilites. One for each clothing item."},{"metadata":{"_uuid":"b7e26752179921b85075271f04740fca61434195","_cell_guid":"b50510a7-d879-4075-857b-267012c6e38b","trusted":false,"collapsed":true},"cell_type":"code","source":"ix = 300\nimshow(np.squeeze(X_train_imgs[41000+ix]))\nplt.show()\nprint ('Probabilities:')\ni = 0\nfor i in range(10):\n    correct = (Y_train[41000+ix] == i)*1\n    print ('|'+'\\u2588'*int(p[ix,i]*50)+' '+label[i]+' {:.5f}%'.format(p[ix,i]*100)+' <=='*correct)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"9bfd4b1e6fe697b6cea821e64b927dbb7a65974e","_cell_guid":"72285b86-6f7d-4dd1-bbe0-65c0ed53c693","trusted":false},"cell_type":"markdown","source":"This method can be used multiple times in another sparse -> redense cycle to gain a decreasing amount of performance."}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}