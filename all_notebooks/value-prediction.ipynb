{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(2021)\nimport matplotlib.pyplot as plt\nimport warnings\nimport pprint\n# warnings.simplefilter(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_dataset = pd.read_csv(\"/kaggle/input/200000-jeopardy-questions/JEOPARDY_CSV.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Renaming Columns to remove trailing whitespace and bring down to lower case"},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_dataset.columns = [x.strip().lower() for x in questions_dataset.columns]\nquestions_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_dataset['round'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Visualization Utility Functions\nfrom wordcloud import WordCloud\nimport matplotlib.colors as mcolors\n\n# No_of ques per Round distribution\ndef plot_dist(data, title, xlabel, ylabel):\n    x_pos = np.arange(len(data.keys()))\n    plt.figure(figsize=[12,8])\n    plt.bar(x_pos, data.values(), color = \"blue\")\n    plt.title(title)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    \n    plt.xticks(x_pos, data.keys())\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distribution of the Questions accross the Rounds, Since rounds Final Jeopardy and tiebraker rounds got the less number of questions compared to others,and the value is None they're ignored for the further purpose."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_dist(questions_dataset[\"round\"].value_counts().to_dict(),\n               'Number of questions in each Round',\n               'Rounds',\n               'Number of Questions'\n              )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_dataset.drop(questions_dataset[questions_dataset['value'] == \"None\"].index, inplace= True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"+ Convert the entries of the value column to int from string.\n+ The variables of the value column are rounded to the nearest whole number and groupped as bins which makes the target column for the rest of the problem."},{"metadata":{"trusted":true},"cell_type":"code","source":"## Utility Functions.\n\ndef process_value(value):\n    value = value.strip('$')\n    value = ''.join(value.split(','))\n    return int(value)\n\ndef binning(value):\n    if value < 1000:\n        return np.round(value, -2)\n    elif value < 10000:\n        return np.round(value, -3)\n    else:\n        return np.round(value, -4)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_dataset['num_value'] = questions_dataset['value'].apply(process_value)\nquestions_dataset.num_value.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_dataset['value_bins'] = questions_dataset['num_value'].apply(binning)\nquestions_dataset.value_bins.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Preprocess the Questions column"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport nltk\n# nltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nstop_words = set(stopwords.words('english'))\nporter_stemmer = PorterStemmer()\ndef preprocess_text(question):\n    question = question.lower()\n    question = re.sub(\"[^a-z A-Z]\", ' ', question)\n    question = \" \".join([porter_stemmer.stem(word) for word in question.split(' ') if not word in stop_words and word != ''])\n    return question","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"processed_question = questions_dataset['question'].apply(preprocess_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"processed_question.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\ntf_idf = TfidfVectorizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = tf_idf.fit_transform(processed_question)\nY = questions_dataset.value_bins","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distribution of the Classes/Bins "},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_dist(questions_dataset[\"value_bins\"].value_counts().to_dict(),\n               'Number of questions in each Value Bin',\n               'Value Bins',\n               'Number of Questions'\n              )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weights = questions_dataset.value_bins.value_counts().to_dict()\npprint.pprint(class_weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, Y,\n                                                   test_size= 0.30,\n                                                   random_state= 1,\n                                                   stratify= Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.ensemble import RandomForestClassifier\n\n# RFC=RandomForestClassifier(max_features=\"sqrt\")\n# parameters={ \"max_depth\":[5,25], \n#              \"min_samples_split\":[1,5], \"n_estimators\":[800,1200]}\n# from sklearn.model_selection import GridSearchCV\n# clf = GridSearchCV(RFC, parameters)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlog_reg = LogisticRegression(random_state= 1, class_weight= class_weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_logreg = log_reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nRFC = RandomForestClassifier(max_depth= 25,\n                             min_samples_split= 8,\n                             n_estimators = 800,\n                             max_features= 'sqrt',\n                             class_weight= class_weights\n                            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RFC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RFC.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_rfc = RFC.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n# cm = confusion_matrix(y_true= y_test, y_pred= y_pred)\nlr_accuracy = accuracy_score(y_true= y_test, y_pred= y_pred_logreg)\nrf_accuracy = accuracy_score(y_true= y_test, y_pred= y_pred_rfc)\n# cls_report = classification_report(y_true= y_test, y_pred= y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(lr_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(rf_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}