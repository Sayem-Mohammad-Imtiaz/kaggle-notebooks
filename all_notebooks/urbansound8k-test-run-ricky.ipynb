{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader\nimport librosa\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mel Spectrogram preprocessing / use with model 1\n\ndef extract_features(file_name):\n    try:\n        audio,sr = librosa.load(file_name, res_type='kaiser_fast')\n        \n        # pad audio files less than 3s, cut more than 3s\n        if audio.shape[0] < 4*sr:\n            audio = np.pad(audio, int(np.ceil((4*sr-audio.shape[0])/2)), mode='reflect')\n        else:\n            audio = audio[:4*sr]\n        \n        mel_spec = librosa.feature.melspectrogram(audio, n_mels=128, fmin=20, fmax=8300)\n        db_mel_spec = librosa.power_to_db(mel_spec, top_db=80)\n    \n    except Exception as e:\n        print(\"Error while parsing file: \", file)\n        return None\n    \n    return db_mel_spec","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # MFCCs mean preprocessing / use with model 2\n\n# def extract_features(file_name):\n#     try:\n#         audio,sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n        \n#         mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=64)\n        \n#         mfccsscaled = np.mean(mfccs.T, axis=0)\n        \n#         mfccsscaled = np.reshape(mfccsscaled, (8,8))\n    \n#     except Exception as e:\n#         print(\"Error while parsing file: \", file)\n#         return None\n    \n#     return mfccsscaled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # MFCCs padded preprocessing / use with Model 3\n\n# def extract_features(file_name):\n#     try:\n#         audio,sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n#         max_pad = 174\n        \n#         mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n#         pad_width = max_pad - mfccs.shape[1]\n        \n#         mfccspadded = np.pad(mfccs, pad_width=((0,0),(0,pad_width)), mode='constant')\n    \n#     except Exception as e:\n#         print(\"Error while parsing file: \", file)\n#         return None\n    \n#     return mfccspadded","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model 1\n\nclass ConvNet(nn.Module):\n    def __init__(self):\n        super(ConvNet, self).__init__()\n        \n        self.conv1 = nn.Conv2d(1, 24, 3, padding=0)\n        self.conv1_bn = nn.BatchNorm2d(24)\n        self.conv2 = nn.Conv2d(24, 48, 3, padding=0)\n        self.conv2_bn = nn.BatchNorm2d(48)\n        self.conv3 = nn.Conv2d(48, 64, 3, padding=0)\n        self.conv3_bn = nn.BatchNorm2d(64)\n        self.conv4 = nn.Conv2d(64, 64, 3, padding=0)\n        self.conv4_bn = nn.BatchNorm2d(64)\n        \n        self.fc1 = nn.Linear(5376, 10)\n    \n    def forward(self, x):\n        x = F.max_pool2d(F.relu(self.conv1_bn(self.conv1(x))), (2,4))\n        x = F.dropout(x, p = 0.2)\n        \n        x = F.max_pool2d(F.relu(self.conv2_bn(self.conv2(x))), 2)\n        x = F.dropout(x, p = 0.2)\n        \n        x = F.max_pool2d(F.relu(self.conv3_bn(self.conv3(x))), 2)\n        x = F.dropout(x, p = 0.2)\n        \n        x = F.relu(self.conv4_bn(self.conv4(x)))\n        x = F.dropout(x, p = 0.2)\n        \n        x = torch.flatten(x, start_dim = 1)\n        \n        x = F.softmax(self.fc1(x), dim = 0)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Model 2\n\n# class ConvNet(nn.Module):\n#     def __init__(self):\n#         super(ConvNet, self).__init__()\n        \n#         self.conv1 = nn.Conv2d(1, 32, 3)\n#         self.conv2 = nn.Conv2d(32, 64, 3)\n#         self.conv3 = nn.Conv2d(64, 128, 3)\n        \n#         self.fc1 = nn.Linear(512, 128)\n#         self.fc2 = nn.Linear(128, 10)\n    \n#     def forward(self, x):\n#         x = F.relu(self.conv1(x))\n#         x = F.dropout(x, p = 0.2)\n        \n#         x = F.relu(self.conv2(x))\n#         x = F.dropout(x, p = 0.2)\n        \n#         x = F.relu(self.conv3(x))\n#         x = F.dropout(x, p = 0.2)\n        \n#         x = torch.flatten(x, start_dim = 1)\n#         x = torch.tanh(self.fc1(x))\n#         x = F.softmax(self.fc2(x), dim = 0)\n#         return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #Model 3\n\n# class ConvNet(nn.Module):\n#     def __init__(self):\n#         super(ConvNet, self).__init__()\n        \n#         self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n#         self.conv1_bn = nn.BatchNorm2d(16)\n#         self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n#         self.conv2_bn = nn.BatchNorm2d(32)\n#         self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n#         self.conv3_bn = nn.BatchNorm2d(64)\n#         self.conv4 = nn.Conv2d(64, 128, 3, padding=1)\n#         self.conv4_bn = nn.BatchNorm2d(128)\n#         self.conv5 = nn.Conv2d(128, 196, 3, padding = 1)\n#         self.conv5_bn = nn.BatchNorm2d(196)\n        \n#         self.fc1 = nn.Linear(980, 10)\n    \n#     def forward(self, x):\n#         x = F.max_pool2d(F.relu(self.conv1_bn(self.conv1(x))), 2)\n#         x = F.dropout(x, p = 0.2)\n        \n#         x = F.max_pool2d(F.relu(self.conv2_bn(self.conv2(x))), 2)\n#         x = F.dropout(x, p = 0.2)\n        \n#         x = F.max_pool2d(F.relu(self.conv3_bn(self.conv3(x))), 2)\n#         x = F.dropout(x, p = 0.2)\n        \n#         x = F.max_pool2d(F.relu(self.conv4_bn(self.conv4(x))), 2)\n#         x = F.dropout(x, p = 0.2)\n        \n#         x = F.avg_pool2d(F.relu(self.conv5_bn(self.conv5(x))), 2)\n#         x = F.dropout(x, p = 0.2)\n        \n#         x = torch.flatten(x, start_dim = 1)\n        \n#         x = torch.tanh(self.fc1(x))\n#         x = F.softmax((x), dim = 0)\n#         return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def weights_init(m):\n    if isinstance(m, nn.Conv2d) or isinstance (m, nn.Linear):\n        torch.nn.init.xavier_uniform_(m.weight)\n        torch.nn.init.zeros_(m.bias)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_loader(inputdf, batch):\n    x = np.array(inputdf.feature.tolist())\n    x = torch.from_numpy(x)\n\n    y = torch.tensor(inputdf['classID'].values)\n\n    data = TensorDataset(x, y)\n    loader = DataLoader(data, batch_size = batch, shuffle = True)\n    \n    return loader","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model, train_loader, MAX_EPOCHS, l_rate):    \n    \n    criterion = nn.CrossEntropyLoss()\n    model.train()\n#     model.apply(weights_init)\n    \n    for epoch in range(MAX_EPOCHS):\n        total = 0.0\n        correct = 0.0\n        \n#         if epoch % 30 == 0:\n#             optimizer = torch.optim.Adam(model.parameters(), lr=l_rate, weight_decay=0.0001)\n#             l_rate = l_rate / 10\n\n        # note: momentum SGD > Adam for Model 1 + Mel-Spec\n        optimizer = torch.optim.SGD(model.parameters(), momentum=0.9, lr=l_rate, nesterov=True, weight_decay=0.0001)\n        \n        \n        \n        for local_batch, local_labels in train_loader:\n            optimizer.zero_grad()\n            \n            local_batch = local_batch.to(device, dtype = torch.float32)\n            local_labels = local_labels.to(device, dtype = torch.long)\n\n            local_batch = local_batch.unsqueeze(dim=1)\n\n            local_outputs = model(local_batch)\n            \n            _, predicted = torch.max(local_outputs.data, 1)\n            total += local_labels.size(0)\n            correct += (predicted == local_labels).sum().item()\n            \n            loss = criterion(local_outputs, local_labels)\n            loss.backward()\n            optimizer.step()\n           \n        if epoch % 10 == 0:\n             print('Epoch ', epoch, ' Acc: %d %%' % (100 * correct / total),)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def validate(model, test_loader):\n\n    total = 0.0\n    correct = 0.0\n    \n    model.eval()\n\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n\n            images = images.unsqueeze(dim=1)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    accuracy = (100 * correct / total)\n    \n    return accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data import segment\n\nfulldatasetpath = '../input/urbansound8k'\n\nmetadata = pd.read_csv(fulldatasetpath + '/UrbanSound8K.csv')\n\nCLASS_NAMES = ['air conditioner', 'car horn', 'children playing', 'dog bark', 'drilling', 'engine idling', 'gun shot', 'jackhammer', 'siren', 'street music']\n\nfeatures = []\n\ni = 0\n\nfor index, row in metadata.iterrows():\n    \n    file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n    \n    class_id = row[\"classID\"]\n    fold = row[\"fold\"]\n    data = extract_features(file_name)\n    \n#     print(data.shape)\n    \n    features.append([data, class_id, fold])\n    \n#     #limit for compute constraints\n#     i += 1\n#     if (i > 100):\n#         break\n\n# keep fold feature to evaluate according to UrbanSound specification\nfeaturesdf = pd.DataFrame(features, columns=['feature','classID','fold'])\nprint(featuresdf.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(featuresdf['feature'][0].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save data to csv, need to implement converting csv entries back to array\n\nfeaturesdf.to_csv('mel_spec.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random train/test split\nfrom sklearn.model_selection import train_test_split\n\nx, y = np.array(featuresdf.feature.tolist()), np.array(featuresdf.classID.tolist())\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n\nx_train = torch.from_numpy(x_train)\ny_train = torch.tensor(y_train)\n\ntrain_data = TensorDataset(x_train, y_train)\ntrain_loader = DataLoader(train_data, batch_size = 64, shuffle = True)\n\nx_test = torch.from_numpy(x_test)\ny_test = torch.tensor(y_test)\n\ntest_data = TensorDataset(x_test, y_test)\ntest_loader = DataLoader(test_data, batch_size = 64, shuffle = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_EPOCHS = 60\n\nif torch.cuda.is_available():\n  device=torch.device('cuda:0')\nelse:\n  device=torch.device('cpu')\n\nmodel = ConvNet()\nmodel = model.to(device)\n\n# 0.001 for Adam, 0.01 for SGD\nmodel = train(model, train_loader, MAX_EPOCHS, l_rate=0.01)\n\nac = validate(model, test_loader)\n# Accs.append(ac)\n\nprint('Test Accuracy: ', ac, '%%')\n    \n# print('10 Fold Cross Validation: ', np.mean(Accs), '%%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 10-fold cross validation\nMAX_EPOCHS = 60\naccs = []\n\nif torch.cuda.is_available():\n  device=torch.device('cuda:0')\nelse:\n  device=torch.device('cpu')\n\nfor fold in range(1,11):\n\n    test_fold = fold\n\n    traindf = featuresdf[featuresdf['fold'] != test_fold]\n    testdf = featuresdf[featuresdf['fold'] == test_fold]\n\n    train_loader = create_loader(traindf, 64)\n    test_loader = create_loader(testdf, 64)\n\n    model = ConvNet()\n    model = model.to(device)\n\n    model = train(model, train_loader, MAX_EPOCHS, l_rate=0.001)\n\n    ac = validate(model, test_loader)\n    accs.append(ac)\n\n    print('Fold ', fold, ' Accuracy: ', ac, '%%')\n\nprint('10 Fold Cross Validation: ', np.mean(accs), '%%')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}