{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Black FRIDAY SALES Prediction \nModel explanination using eli5, Lime, shape "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import all lib\nimport pandas as pd\nfrom sklearn import * ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_url=\"../input/black-friday-sales-prediction/train_oSwQCTC (1)/train.csv\"\ntest_url=\"../input/black-friday-sales-prediction/test_HujdGe7 (1)/test.csv\"\n\ndf=pd.read_csv(train_url)\n\nprint('---------------------')\nprint('No. of rows: {} and columns: {}'.format(df.shape[0],df.shape[1]))\nprint('----------------------')\nprint('Cloumns names: {}'.format(df.columns))\nprint('\\n----------------------')\nprint(df.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Features information*\n* User_ID: Unique identifier of shopper.\n* Product_ID: Unique identifier of product. (No key given)\n* Gender: Sex of shopper.\n* Age: Age of shopper split into bins.\n* Occupation: Occupation of shopper. (No key given)\n* City_Category: Residence location of shopper. (No key given)\n* Stay_In_Current_City_Years: Number of years stay in current city.\n* Marital_Status: Marital status of shopper.\n* Product_Category_1: Product category of purchase.\n* Product_Category_2: Product may belong to other category.\n* Product_Category_3: Product may belong to other category.\n* Purchase: Purchase amount in dollars."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('----------Data Types--------------')\nprint(df.info())\nprint('\\n-------Total Null values in each column---------')\nprint(df.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(columns=['Product_ID','User_ID','Product_Category_2','Product_Category_3',],inplace=True)\n\nprint('---------------------')\nprint('No. of rows: {} and columns: {}'.format(df.shape[0],df.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_features=[]\ncat_features=[]\nfor i in df.columns:\n    if df[i].dtype==\"object\":\n        cat_features.append(i)\n    else:\n        num_features.append(i)\nnum_features.remove('Purchase')\ntarget = ['Purchase']\nfeatures=num_features+cat_features\nprint('--------num_features---------')\nprint(num_features)\nprint('--------cat_features---------')\nprint(cat_features)\nprint('--------Features---------')\nprint(features)\nprint('---------Target----------')\nprint(target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Building the model and pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = model_selection.train_test_split(df[features], \n                                                                     df['Purchase'],\n                                                                     test_size=.3, \n                                                                     random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocessing for categorical data\ncategorical_transformer = preprocessing.OneHotEncoder(handle_unknown='ignore')\n\n\nnum_transformer=preprocessing.MinMaxScaler()\n# Bundle preprocessing for numerical and categorical data\npreprocessor = compose.ColumnTransformer(\n    transformers=[\n        ('num', num_transformer, num_features),\n        ('cat', categorical_transformer, cat_features)\n    ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = ensemble.RandomForestRegressor()\nmodel = linear_model.Lasso()\n\nclf=pipeline.Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)\n                             ])\n\n# fit model \nclf.fit(X_train, y_train)\n\n# Preprocessing of validation data, get predictions\npreds = clf.predict(X_valid)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate the model\nimport numpy as np\nscore = np.sqrt(metrics.mean_squared_error(y_valid, preds))\nprint('MAE:', score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import eli5\n\n#To extract the features from OneHotEncoding\npreprocessor = clf.named_steps[\"preprocessor\"]\nohe_categories = preprocessor.named_transformers_[\"cat\"].categories_\nnew_ohe_features = [f\"{col}__{val}\" for col, vals in zip(cat_features, ohe_categories) for val in vals]\n\n#All feature column\nall_features = num_features + new_ohe_features\n\n#Show weights\neli5.show_weights(clf.named_steps[\"model\"], feature_names=all_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}