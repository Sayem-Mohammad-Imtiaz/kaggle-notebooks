{"cells":[{"metadata":{},"cell_type":"markdown","source":"Hello there, we are going to use **Machine Learning to detect fake news**.So lets start.\nhere we are using following algorithms.\n\n\n**1.Naivy bayes\n2.logistic regression\n3.Decision Tree\n4.Random Forest\n5.KNN\n6.SVM(Support vector machine)**\n\n\nNote:-we can code one aspect in different ways. So my way of coding may be different from yours. but untimately output will be same.\n\nLets start with importing basic pakages","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing datasets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfake = pd.read_csv('../input/fake-and-real-news-dataset/Fake.csv', delimiter = ',')\ntrue = pd.read_csv('../input/fake-and-real-news-dataset/True.csv', delimiter = ',')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now We are going to combine these two dataset to one dataset to simplify processing.\nalso to combine we need to add an extra column as sentiment to differtiate news as 1=true_news 0=fake_news","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"fake['sentiment']= 0\ntrue['sentiment']= 1\n\ndataset =pd.DataFrame()\ndataset = true.append(fake)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Column **'Date' and 'Subject'** are important to Descriptive analysis but here for prediction they are less important so i am going to drop these columns.\nAlso Created array of **'title' column as input_array** for preprocessing.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"column = ['date','subject']\ndataset = dataset.drop(columns=column)\ninput_array=np.array(dataset['title'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next part is most important, That is **claning the text and forming curpus**.\nsuch as removing symbols, stpwords,using porterstremer etc.\nI have selected 40000 title as input. you can chose these number depending on your system performance but not less than 10000.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport nltk\n# ltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\ncorpus = []\nfor i in range(0, 40000):\n    review = re.sub('[^a-zA-Z]', ' ', input_array[i])\n    review = review.lower()\n    review = review.split()\n    ps = PorterStemmer()\n    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    corpus.append(review)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, We crate bag of world model. if you dont know just google it.\nAlso we are going to initialize  x and y that is x=independent_variable(title) y=dependent_variable(sentiment 0 or 1).\nI am going to select max features as 5000. this figure also depends on your preference.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features = 5000)\nX = cv.fit_transform(corpus).toarray()\ny = dataset.iloc[0:40000, 2].values\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Splitting the dataset into the Training set and Test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fitting Naive Bayes to the Training set.\nCanculate accuracy form confusion matrix that is 88.58%.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting Naive Bayes to the Training set\nfrom sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\n\nprint(cm)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fitting Logistic Regression to the Training set.\nFinding accuracy by confusion matrix that is 94.92%","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclassifier1 = LogisticRegression(random_state = 0)\nclassifier1.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_predL = classifier1.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm1 = confusion_matrix(y_test, y_predL)\n\nprint(cm1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fitting Decision Tree Classification to the Training set\nFinding accuracy by confusion matrix that is 89.70%\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nclassifier2 = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier2.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_predD = classifier2.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm2 = confusion_matrix(y_test, y_predD)\n\nprint(cm2)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fitting Random Forest Classification to the Training set.\nFinding accuracy by confusion matrix that is 92.37%\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclassifier3 = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nclassifier3.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_predR = classifier3.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm3 = confusion_matrix(y_test, y_predR)\n\n\nprint(cm3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fitting SVM to the Training set.\nFinding accuracy by confusion matrix that is 94.92%","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nclassifier = SVC(kernel = 'linear', random_state = 0)\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm5 = confusion_matrix(y_test, y_pred)\n\nprint(cm5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fitting K-NN to the Training set.\nhere , i have given 5 as n_neighbors value for simple processing time. if  you change value accuracy also changes.\nFinding accuracy by confusion matrix that is 94.92%","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nclassifier4 = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nclassifier4.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_predK = classifier4.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm4 = confusion_matrix(y_test, y_predK)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note:- Decision Tree and random forest take time so you have to be patient while running code.\nThank you.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}