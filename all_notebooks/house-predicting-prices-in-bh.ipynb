{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Se você deseja ver o storytelling dessa análise, recomendo [clicar aqui](https://medium.com/@guiisaac12/pre%C3%A7o-de-im%C3%B3veis-em-bh-data-science-project-234e53ce7ce6), para ler no Medium.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Importando algums bibliotecas que serão usadas posteriormente","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import seaborn as sns\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\nimport statsmodels.api as sm\nfrom statsmodels.stats import diagnostic as diag\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lendo o arquivo e criando o dataframe","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/brasilian-houses-to-rent/houses_to_rent_v2.csv')\ndata=pd.DataFrame(data)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vimos que precisamos transformar algumas dessas variáveis em números (na estatística chamamos de variáveis Dummies)\n \n [1=sim, 0=não] ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['animal']=data['animal'].replace(to_replace =\"acept\", \n                 value =1) \ndata['animal']=data['animal'].replace(to_replace =\"not acept\", \n                 value =0)\n\ndata['furniture']=data['furniture'].replace(to_replace =\"furnished\", \n                 value =1) \ndata['furniture']=data['furniture'].replace(to_replace =\"not furnished\", \n                 value =0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vamos verificar se possui algum dado omitido no dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ótimo, não temos. Podemos prosseguir.\n\nAgora vamos ver a categoria de cada variável.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Com isso, vemos que o floor não é um número, e por isso temos que transformar o Tipo dele em numeral.\n\nAntes disso, vamos ver os valores dele.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['floor'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Precisamos corrigir algumas coisas, o \"-\" significa andar 0 e também temos um \"301\", que é um outlier totalmente.\n\nVamos transformar o \"-\" e \"301\" em 0. Passar os dois para numeral também.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['floor'] = data['floor'].replace(['-','301'], 0)\ndata['floor'] = data['floor'].astype(int)\ndata['floor'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ótimo.\n\nAgora vamos ver um resumo de todos os outros dados.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vou dividir o dataset em 5 cidades, para analisarmos cada cidade.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sp = data.loc[data.city=='São Paulo']\nsp= sp.drop(['city'], axis=1)\nrj = data.loc[data.city=='Rio de Janeiro']\nrj=rj.drop(['city'], axis=1)\nbh = data.loc[data.city=='Belo Horizonte']\nbh=bh.drop(['city'], axis=1)\npoa = data.loc[data.city=='Porto Alegre']\npoa=poa.drop(['city'], axis=1)\ncam = data.loc[data.city=='Campinas']\ncam=cam.drop(['city'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Agora vamos fazer nossas primeiras análises visuais, e depois vamos para a estatística.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(bh)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Mudando nome de colunas\nbh.columns=['area','rooms','bathroom','parking_spaces','floor','animal','furniture','hoa','rent_amount','property_tax','fire_insurance','total']\n\n## Descobrindo o aluguel mais caro da cidade\nbh_rent= bh.sort_values(\"rent_amount\",ascending=False).reset_index()\nbh_rent=bh_rent.drop(['index'], axis=1)\n\n## Analisando essas propriedades\nbh_rent1=bh_rent.loc[0:34]\nbh_rent1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Analisando os imóveis com aluguéis mais caros","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bh_rent1.hist(bins=20,figsize=(20,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Agora vamos ver a frequência das características dos outros imóveis.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(bh['animal'].value_counts())\nprint(bh['area'].value_counts())\nprint(bh['rooms'].value_counts())\nprint(bh['bathroom'].value_counts())\nprint(bh['parking_spaces'].value_counts())\nprint(bh['floor'].value_counts())\nprint(bh['furniture'].value_counts())\nprint(bh['hoa'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tiramos os outliers, mas vou manter o dataset bh.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"std_dev = 3\nbh_remove = bh[(np.abs(stats.zscore(bh)) < float(std_dev)).all(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Temos que olhar a correlação também entre as variáveis, para minimizar possíveis erros de multicolinearidade.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bh_cor1=bh_remove.corr()\nsns.heatmap(bh_cor1, xticklabels=bh_cor1.columns, yticklabels=bh_cor1.columns, cmap='RdBu')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vamos ver numericamente.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Definindo dois dataframes, um antes de eliminar variáveis, e outro depois\nbh_before = bh_remove\nbh_after = bh_remove.drop(['hoa','rent_amount','property_tax','fire_insurance'], axis = 1)\n\nX1 = sm.tools.add_constant(bh_before)\nX2 = sm.tools.add_constant(bh_after)\n\n# Criando uma series para ambos\nseries_before = pd.Series([variance_inflation_factor(X1.values, i) for i in range(X1.shape[1])], index=X1.columns)\nseries_after = pd.Series([variance_inflation_factor(X2.values, i) for i in range(X2.shape[1])], index=X2.columns)\n\n# mostrando as series\nprint('Antes')\nprint('-'*100)\ndisplay(series_before)\n\nprint('Depois')\nprint('-'*100)\ndisplay(series_after)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"E faz sentido tirar alguns dos dados, pois é possível intuir que basicamente o Valor do condomínio, Valor de aluguel, IPTU e Taxa de incêndio estão muito relacionados ao valor do imóvel.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Gráfico\nsns.pairplot(bh_after)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Agora podemos começar o construção do modelo de predição do preço de um imóvel em Belo Horizonte. Vamos utilizar regressão linear múltipla.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# define our input variable (X) & output variable\nX = bh_after.drop('total', axis = 1)\nY = bh_after[['total']]\n\n# Split X and y into X_\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=1)\n\n# create a Linear Regression model object\nregression_model = LinearRegression()\n\n# pass through the X_train & y_train data set\nregression_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separando o intercepto e o coeficiente\nintercept = regression_model.intercept_[0]\ncoefficent = regression_model.coef_[0][0]\n\nprint(\"The intercept for our model is {:.5}\".format(intercept))\nprint('-'*100)\n\n# loop through the dictionary and print the data\nfor coef in zip(X.columns, regression_model.coef_[0]):\n    print(\"The Coefficient for {} is {:.4}\".format(coef[0],coef[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Utiizando o OLS.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# define our intput\nX2 = sm.add_constant(X)\n\n# create a OLS model\nmodel = sm.OLS(Y, X2)\n\n# fit the data\nest = model.fit()\n\n# print out a summary\nprint(est.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logicamente, existem diversos outros testes que deveríamos fazer a partir daqui para avaliar erros, heterocedasticidade…Mas vamos encerrar por aqui, porque o artigo está ficando longo demais. Na segunda parte o artigo vou mostrar todos esses testes, e o que podemos fazer para melhorar ainda mais o modelo.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Então vamos tentar prever o preço de aluguel de um apartarmento, com 4 banheiros, 4 quartos, 4 vagas de garagem, 200m², aceita animal, segundo andar, mobiliado.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"price=-1192.89+4.0463*200+375.3567*4+972.98*4+451.79*4+142.79*2-264.15*1+887.14*1\nprice","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obs: Ainda estou aprendendo, portanto  pode ter falhas no modelo. Sinta-se totalmente a vontade para fazer sugestões e observações, gosto demais de feedback. De qualquer forma gostei demais de fazer esse exercício, mesmo que o R² não tenha ficado tão alto. \n\nAlgo que eu tentaria fazer posteriormente, seria adiciona dummies de localização de bairro, penso que essa informação possa fazer muita diferença no preço do imóvel em BH.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}