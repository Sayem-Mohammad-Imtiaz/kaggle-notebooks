{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Covid-19 Tweet Sentimental Analysis using Naive Bayes"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# importing necessary libraries\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport re\n\nimport nltk\nnltk.download('stopwords')\n\nfrom nltk.corpus import stopwords","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_train.csv\",encoding='latin1')\ndf = pd.DataFrame(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.countplot(x='Sentiment', data=df, order=['Extremely Negative', 'Negative', 'Neutral', 'Positive', 'Extremely Positive'], )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# showing column wise %ge of NaN values they contains \n\nfor i in df.columns:\n  print(i,\"\\t-\\t\", df[i].isna().mean()*100)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Here  ___Location___ has some null values. Since location does not affects are model as we are not considering it as feature in analysis, we will leave it as it is.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Since our main columns for analysis \"OriginalTweet\" contains lots of unnecssary stuff like links, hashtags, mentions etc., we have to clean them and extract the content of tweet. For that I'm using regex and ommitting the perticular sequences which resembles links, hashtags, mentions."},{"metadata":{"trusted":true},"cell_type":"code","source":"a = re.compile(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\")\ntweet = []\n\nfor i in df[\"OriginalTweet\"]:\n  tweet.append(a.sub(\" \", i))\n\ndf = pd.concat([df, pd.DataFrame(tweet, columns=[\"CleanedTweet\"])], axis=1, sort=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Since we got our cleaned tweets, now we have to convert them in vectors for classifications.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nstop_words = set(stopwords.words('english'))     # Here making a set of stopwords (useless words which will not affect the classification)\nvectoriser = TfidfVectorizer(stop_words=None)    # of English language do that can be removed while vectorization","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = vectoriser.fit_transform(df[\"CleanedTweet\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encoding the classes in numerical values\n\nfrom sklearn.preprocessing import LabelEncoder\n\nencoder = LabelEncoder()\ny_train = encoder.fit_transform(df['Sentiment'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\n\nclassifier = MultinomialNB()\nclassifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing the Test dataset for prediction and testing purposes\n\ntest_data = pd.read_csv(\"/kaggle/input/covid-19-nlp-text-classification/Corona_NLP_test.csv\",encoding='latin1')\ntest_df = pd.DataFrame(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# showing column wise %ge of NaN values they contains \n\nfor i in test_df.columns:\n  print(i,\"\\t-\\t\", test_df[i].isna().mean()*100)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Like training dataset, ignoring ___Location___ as it has no significance in classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"a = re.compile(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\")\ntweet = []\n\nfor i in test_df[\"OriginalTweet\"]:\n  tweet.append(a.sub(\" \", i))\n\ntest_df = pd.concat([test_df, pd.DataFrame(tweet, columns=[\"CleanedTweet\"])], axis=1, sort=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = vectoriser.transform(test_df[\"CleanedTweet\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = encoder.transform(test_df[\"Sentiment\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction\n\ny_pred = classifier.predict(X_test)\n\npred_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\npred_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Plotting ROC Curve (Receiver operating characteristic) for checking the accuracy of classifier."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\n# Generate the roc curve using scikit-learn.\nfpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=1)\nplt.plot(fpr, tpr)\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.show()\n\n# Measure the area under the curve.  The closer to 1, the \"better\" the predictions.\nprint(\"AUC of the predictions: {0}\".format(metrics.auc(fpr, tpr)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Since we got 0.64 auc score for the classifier, we can say that the classifier (Naive Bayes) is not that good but acceptable. Since more neerer to 1 auc score, more better the classifier."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}