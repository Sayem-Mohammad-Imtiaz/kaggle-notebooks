{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv('../input/amazoncom-employee-access-challenge/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"ACTION\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dc=DecisionTreeClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Probability Distribution plot "},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n#Zoom in\nfor feature in data.columns:\n    if feature !='ACTION':\n        plt.figure(figsize=(9,6));\n        sns.kdeplot(data[data['ACTION']==1][feature],label='Accepted',shade=True);\n        sns.kdeplot(data[data['ACTION']==0][feature],label='Rejected',shade=True);\n        plt.title('Distribution of '+feature+' variable');\n        plt.xlabel(feature);\n        plt.ylabel('Prob. Density');\n        \n        \n    \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Correlation Heatmap"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(data.corr())\nplt.figure(figsize=(9,6));\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"features of dataset are not very correlated"},{"metadata":{},"cell_type":"markdown","source":"# Target Class representation"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data['ACTION'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The total % of ACTION taken are \" + str(round(len(data[data['ACTION']==0])/len(data[\"ACTION\"])*100,2))+\"%\")\nprint(\"The total % of not ACTION taken are \" + str(round(len(data[data['ACTION']==1])/len(data[\"ACTION\"])*100,2))+\"%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data is hugely unbalanced as one class consists of 94% and the other has only 5% of total outcome."},{"metadata":{},"cell_type":"markdown","source":"# Target guided encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"dt=list()\ndata_preprocessed=data.copy()\nfor feature in data_preprocessed.columns:\n    if feature!='ACTION':\n        uniques=data_preprocessed[feature].unique()\n        d=data.groupby(feature)\n        mean_dict=dict()\n        print(feature)\n        for grps in d.groups:\n            d1=d.get_group(grps).groupby('ACTION')\n            try:\n                zero=(d1.count().loc[0][1])\n            except:\n                zero=0\n            try:\n                ones=d1.count().loc[1][1]\n            except:\n                ones=0\n            mean=round(zero/(zero+ones),2)\n            #print(\"Mean for \" + str(grps)+ \" is \"+str(mean))\n            mean_dict[grps]=mean\n        dt.append(mean_dict)\n            \n            \n        \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_preprocessed['RESOURCE']=data_preprocessed[\"RESOURCE\"].replace(dt[0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_preprocessed['MGR_ID']=data_preprocessed[\"MGR_ID\"].replace(dt[1])\ndata_preprocessed['ROLE_ROLLUP_1']=data_preprocessed[\"ROLE_ROLLUP_1\"].replace(dt[2])\ndata_preprocessed['ROLE_ROLLUP_2']=data_preprocessed[\"ROLE_ROLLUP_2\"].replace(dt[3])\ndata_preprocessed['ROLE_DEPTNAME']=data_preprocessed[\"ROLE_DEPTNAME\"].replace(dt[4])\ndata_preprocessed['ROLE_TITLE']=data_preprocessed[\"ROLE_TITLE\"].replace(dt[5])\ndata_preprocessed['ROLE_FAMILY_DESC']=data_preprocessed[\"ROLE_FAMILY_DESC\"].replace(dt[6])\ndata_preprocessed['ROLE_FAMILY']=data_preprocessed[\"ROLE_FAMILY\"].replace(dt[7])\ndata_preprocessed['ROLE_CODE']=data_preprocessed[\"ROLE_CODE\"].replace(dt[8])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_preprocessed.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Building"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y=data_preprocessed[\"ACTION\"]\nX=data_preprocessed.iloc[:,1:]\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,random_state=1,test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dc.fit(X_train,Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred=dc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(Y_test,Y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The accuracy score for the model is \" + str(accuracy_score(Y_test,Y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import recall_score,precision_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The recall score for the model is \" +str(recall_score(Y_test,Y_pred)))\nprint(\"The precision score for the model is \" +str(precision_score(Y_test,Y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"the F1 score for the model is \"+str(f1_score(Y_test,Y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The ROC_AUC score value of model is \"+str(roc_auc_score(Y_test,Y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_prob=dc.predict_proba(X_test)[:,1]\ndt_auc = roc_auc_score(Y_test, dt_prob)\n# summarize scores\nprint('Decision tree: ROC AUC=%.3f' % (dt_auc))\n# calculate roc curves\nfrom sklearn.metrics import roc_curve\ndt_fpr, dt_tpr, _ = roc_curve(Y_test, Y_pred)\n# plot the roc curve for the model\nplt.plot(dt_fpr, dt_tpr, marker='.', label='Decision Tree')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}