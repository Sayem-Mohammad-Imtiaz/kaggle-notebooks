{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-01T21:43:48.696553Z","iopub.execute_input":"2021-06-01T21:43:48.697405Z","iopub.status.idle":"2021-06-01T21:43:48.709867Z","shell.execute_reply.started":"2021-06-01T21:43:48.697345Z","shell.execute_reply":"2021-06-01T21:43:48.708472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import data \n\ndata = data.head(n = 100)\ndata = data.copy().sample(frac= 0.1,random_state= 1)\nprint(data)\n\n# Data Cleaning \n# # Data has some elements that need to be either deleted or transformed: \n\n# # Education. Categories defined are: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).\n# #However it also has values 5 & 6. So converting those values into 4, to classify as others \n\nfor i in len(data['education']):\n    if data['education'][i] > 4:\n        data['education'][i] = 4\n\n# # Marital status (1 = married; 2 = single; 3 = others).\n# #However it also has values 0 (Unknown) So remove these values\ndata = data[data.marriage != 0]\nprint(data.shape)\n\n#Descriptive Analysis\nobservations: int = data.shape[0]\nfeatures: int = data.shape[1]\nprint(\"Dataset has\", observations, \"observations and\", features, \"features.\")\n# print(\"Dataset has\", data.isna().sum())\nprint('Average age of the customer is', data['age'].mean())\nprint(data.describe())\n\n# #distribution of Limited_Bal \nplt.subplot()\n# sns.distplot(data.balance_limit)\nplt.show()\nprint(data.balance_limit.skew())\n\n# #distrubution plot Age\nplt.subplot()\n# sns.distplot(data.age)\nplt.show()\ndata.age.describe()\ndef_cnt = (data.Y.value_counts())\ndef_cnt.plot.bar()\nfor x,y in zip([0,1],def_cnt):\n    plt.text(x,y,y,fontsize=12)\nplt.show()\nprint(data.age.skew())\n# #Bivariate Analysis \n\n# print(data.corr())\n# # #Age Vs default \nplt.scatter(data.age, data.Y)\nplt.show()\n\n# # #Boxplot \nax = data[['balance_limit','sex','education', 'marriage','age','pay_hist_apr','pay_hist_may','pay_hist_jun','pay_hist_jul',\t'pay_hist_aug',\t'pay_hist_sep']].plot(kind='box', title='boxplot', showmeans=True)\nplt.xticks(rotation=90)\nplt.show()\n\n# # #Analysing relationship between Variables \nf = plt.figure(figsize = (10,3)) # Fix plot size\nax1 = f.add_subplot() # Instantiate figure 1\nax2 = f.add_subplot() # Instantiate figure 2\nax3 = f.add_subplot() # Instantiate figure 2\nax4 = f.add_subplot() # Instantiate figure 2\n\nax1.scatter(data.balance_limit, data.Y) # Plot figure 1\nax1.set_xlabel('balance_limit')\nax1.set_ylabel('Y')\nax1.set_title('balance_limit vs Y')\n\nax2.scatter(data.age, data.Y) # Plot figure 1\nax2.set_xlabel('age')\nax2.set_ylabel('Y')\nax2.set_title('age vs Y')\n\nax3.scatter(data.bill_amt_sep, data.Y) # Plot figure 1\nax3.set_xlabel('bill_amt_sep')\nax3.set_ylabel('Y')\nax3.set_title('bill_amt_sep vs Y')\n\nax4.scatter(data.prev_amt_paid_apr, data.Y) # Plot figure 1\nax4.set_xlabel('prev_amt_paid_apr')\nax4.set_ylabel('Y')\nax4.set_title('prev_amt_paid_apr vs Y')\nplt.show()\n\n#No sharp linear relation between Xs and Y. Let's try different models to see which one works best\n\ndata = pd.get_dummies(data, columns = ['sex','education','marriage','pay_hist_apr','pay_hist_may','pay_hist_jun',\t'pay_hist_jul',\t'pay_hist_aug',\t'pay_hist_sep'], drop_first = True) \nX = data.drop(['Y'],axis = 1)\ny = data['Y']\n# print(y.value_counts()) # compare 0 and 1 values . Skewed distribution with 23364 non events(0) and 6636 events(1)\n\nprint('######################### Checking LOGISTIC REGRESSION model results #########################')\n\n# Splitting data into train_valid, test data set with 80% test set\nX_train_valid, X_test, y_train_valid, y_test = train_test_split(X, y, test_size=0.8, random_state = 7283)\n\n# # #Further splitting the data into train and valid set\nX_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size = 0.37, random_state = 7283)\n\n# # Fit Logistic Regerssion to check if changing weights make a difference\n# # Tuning hyperparameters \n\nprint('##################### LOGISTIC REGRESSION *Threshold , weights and alpha Tuning* #####################') \nprint('############# Performing 5 Fold CV #######################')\n\n# # # Set up the candidate hyperparameters\n\nthresholds = np.linspace(0, 1, 11)\nthresholds = np.delete(thresholds,[10]) #remove th = 1\nlambdas = np.logspace(-4, 4, 9)\n\nkfold = KFold(5, False) #set K = 5\nhyperparameter_triplet = list(itertools.product(thresholds,lambdas)) #create unique triplet pairs using itertools.product\nvalidation_scores = [] #initialise list to store MSE validation scores\nfor index, triplet in enumerate(hyperparameter_triplet): #iterate on each hyperparameter triplet \n    validation_scores_tmp = []\n    for train_index, valid_index in kfold.split(X_train_valid): #splitting into train, valid set\n        X_train, Y_train = X_train_valid.iloc[train_index], y_train_valid.iloc[train_index] # Training set\n        X_valid, Y_valid = X_train_valid.iloc[valid_index], y_train_valid.iloc[valid_index] # Validation set\n        scaler = StandardScaler() # Instantiate\n        scaler.fit(X_train) # Fit the data\n        X_train = pd.DataFrame(scaler.transform(X_train)) #transform X data\n        X_valid = pd.DataFrame(scaler.transform(X_valid))\n\n        lr = LogisticRegression(solver = 'liblinear', C=triplet[1], penalty='l1') #building logistic regression model\n        lr.fit(X_train, Y_train) #fitting the lr model\n        y_pred = lr.predict_proba(X_valid)[:,1] #predicting on validation set using likelihood function\n        y_hat = np.where(y_pred > triplet[0], 1, 0) #classifying outcomes based on threshold 'a'\n        confmat = confusion_matrix(Y_valid, y_hat, labels = [1,0]) #creating confusion matrix based on classification done above \n        TP = confmat[0,0] \n        FN = confmat[0,1]\n        FP = confmat[1,0]\n        TN = confmat[1,1]\n        validation_scores_tmp.append((TP + TN) / sum(sum(confmat))) #calc accuracy and append in acc_list_tmp\n    validation_scores.append(np.mean(validation_scores_tmp))\n\nprint(\"\")\nprint('MAX ACCURACY ##############################################################')\nacc_max = max(validation_scores)\nbest_triplet = hyperparameter_triplet[np.argmax(validation_scores)]\nbest_threshold = best_triplet[0]\nbest_alpha = best_triplet[1]\nprint('Maximum Accuracy is ',acc_max, 'at the threshold value', best_threshold, 'for alpha ',best_alpha ) \n#Max accuracy of the model is 82% at 0.5 Threshold value and alpha  100 \n\nscaler.fit(X_train_valid) # Fit the data\nX_train_valid = pd.DataFrame(scaler.transform(X_train_valid)) # Transform the data\nX_test = pd.DataFrame(scaler.transform(X_test))\n\n# # #Fitting model for max accuracy\nfinal_model_acc_max = LogisticRegression(max_iter = 10000, random_state = 1, C= best_alpha, penalty='l1',solver = 'liblinear')\nfinal_model_acc_max.fit(X_train_valid, y_train_valid)\ny_hat = np.where(final_model_acc_max.predict_proba(X_test)[:,1] > best_threshold, 1, 0) #classifying using th_acc_max\nfinal_confmat = confusion_matrix(y_test, y_hat, labels = [1,0])\nTP = final_confmat[0,0]\nFN = final_confmat[0,1]\nFP = final_confmat[1,0]\nTN = final_confmat[1,1]\n\nAcc = (TP + TN) / sum(sum(final_confmat)) #Accuracy\nPrecision = TP / (TP + FP) # Precision \nTPR = TP/(TP+FN)\nFPR = FP/(FP+TN)\n\nprint('Final Confusion Matrix for Max accuracy:')\nprint(final_confmat)\n\nprint('TPR is ', TPR) # 35% times able to coreectly classify events as events \nprint('FPR is ' , FPR) # 5% times incorrectly classify non events as events \nprint('Accuracy of the model is', Acc) # 81% of the times able to correctly predict events the class \nprint('Precision of the model is', Precision) #67%\nprint('MSE of Logistic model is ', metrics.mean_squared_error(y_test, y_hat)) #0.18\nprint('Loss function of Logistic model is ', metrics.log_loss(y_test, y_hat)) #6.2\n#Final variables chosen \npd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\nprint(pd.DataFrame(zip(final_model_acc_max.coef_[0], X.columns.values)))\n\nprint(np.exp(0.23))\nprint(np.exp(0.009))\nprint(np.exp(0.08))\nprint(np.exp(0.1))\nprint(np.exp(0.06))\n#Interpreting variables\n# # Few variables were eliminated : pay_hist_sep_8, pay_hist_aug_8, pay_hist_jul_6 etc\n# # Balance_limit: A unit change in Balance_limit is associated with decrease\n# in the odds of customer being a defaulter by exp(0.23) or 1.25 times\n# # Age: A unit change in Age is associated with increase\n# in the odds of customer being a defaulter by exp(0.009) or 1.009 times\n# # Sex: A female customer is exp(0.08) or 1.008 times more likely to \n# default than a male customer \n# #Education: Customers who have University & high school degree are exp(0.1) or 1.105 and exp(0.06 ) or 1.106\n# times more likely to default than a customer with graduate degree\n\nprint('')\nprint('##################### KNN #####################') \nX_train_valid, X_test, y_train_valid, y_test = train_test_split(X, y, test_size=0.2, random_state = 283)\n\nn_neighbors = np.arange(1,21,3)\nleaf_size = list(range(1,50))\nkfold = KFold(5, False) \nhyperparameter_couple = list(itertools.product(n_neighbors, leaf_size))\nvalid_acc = []\nfor index, couple in enumerate(hyperparameter_couple): #iterate on each hyperparameter triplet \n    valid_acc_tmp = []\n    for train_index, valid_index in kfold.split(X_train_valid): #splitting into train, valid set\n        X_train, Y_train = X_train_valid.iloc[train_index], y_train_valid.iloc[train_index] # Training set\n        X_valid, Y_valid = X_train_valid.iloc[valid_index], y_train_valid.iloc[valid_index] # Validation set\n        ss = StandardScaler().fit(X_train)\n        X_train = pd.DataFrame(ss.transform(X_train))\n        X_valid = pd.DataFrame(ss.transform(X_valid))\n        \n        knn = neighbors.KNeighborsClassifier(n_neighbors = couple[0], leaf_size = couple[1])\n        knn.fit(X_train, Y_train)\n        y_hat = knn.predict(X_valid)\n        score = metrics.accuracy_score(Y_valid, y_hat)\n        valid_acc_tmp.append(score)\n    valid_acc.append(np.mean(valid_acc_tmp))\n\nbest_couple = hyperparameter_couple[np.argmax(valid_acc)+1]\nbestK = best_couple[0]\nbest_leaf_size = best_couple[1]\n\n# Calculating final accuracy on the Tesing Set\n# KNN Scale Data\nss = StandardScaler().fit(X_train_valid)\nX_train_valid_knn = pd.DataFrame(ss.transform(X_train_valid))\nX_test_knn = pd.DataFrame(ss.transform(X_test))\n\nknn = neighbors.KNeighborsClassifier(n_neighbors = bestK, leaf_size =  best_leaf_size)\nknn.fit(X_train_valid_knn, y_train_valid)\ny_hat = knn.predict(X_test_knn)\nscore = metrics.accuracy_score(y_test, y_hat)\nprint(best_couple) # best K = 19, Best leaf size = 2\nprint('Accuracy Score of KNN Classifier is ',score) # ~ 0.82\nprint('MSE of KNN model is ',metrics.mean_squared_error(y_test, y_hat)) # 0.17\n\nprint('##################### Random Forest #####################') \nn_estimators = [50,100,150,200,250,300]\nmax_depth= range(10,20)\n# features = range(1, 14)\nhyperparameter_triplets = list(itertools.product(n_estimators, max_depth)) #create unique triplet pairs using itertools.product\nvalidation_scores = [] #initialise list to store MSE validation scores\nfor index, triplets in enumerate(hyperparameter_triplets): #iterate on each hyperparameter triplet \n    rf = RandomForestClassifier(n_estimators = triplets[0], max_depth = triplets[1]) #Build RandomForest model for the triplets\n    rf.fit(X_train, y_train) # Fit model on training set\n    accuracy = accuracy_score(y_test, rf.predict(X_test)) #Calculate MSE on Validation set\n    validation_scores.append(accuracy)\n\nbest_triplet = hyperparameter_triplets[np.argmin(validation_scores)]\nprint('Final Tunes Parameters are : n_estimators: ', best_triplet[0], 'max_depth: ', best_triplet[1]) #200, 18\nrf = RandomForestClassifier(n_estimators = best_triplet[0], max_depth = best_triplet[1])\nrf.fit(X_train_valid, y_train_valid)\nprint('MSE of Random Forest Model on Test set is ',mean_squared_error(rf.predict(X_test), y_test)) #0.13\nprint(sorted(zip(rf.feature_importances_,X.columns.values), reverse = True))\nprint('Accuracy score of Random forest is ' ,accuracy_score(y_test, rf.predict(X_test))) # ~ 0.86\n\n# # #Top 2 Important Features are: age & balance_limit","metadata":{"execution":{"iopub.status.busy":"2021-06-01T21:43:48.717622Z","iopub.execute_input":"2021-06-01T21:43:48.718553Z","iopub.status.idle":"2021-06-01T21:43:48.777302Z","shell.execute_reply.started":"2021-06-01T21:43:48.718494Z","shell.execute_reply":"2021-06-01T21:43:48.776105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}