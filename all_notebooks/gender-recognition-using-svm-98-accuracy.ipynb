{"cells":[{"metadata":{"id":"view-in-github"},"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/Nikunjbansal99/GenderPrediction/blob/main/GenderRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"},{"metadata":{"id":"WXs0i6qa9O_F"},"cell_type":"markdown","source":"# **About Data:**"},{"metadata":{"id":"Z40vvBej82g9"},"cell_type":"markdown","source":"**To analyze gender by voice and speech, a training database was required. A database was built using thousands of samples of male and female voices, each labeled by their gender of male or female. Voice samples were collected from the following resources:**\n\n**The Harvard-Haskins Database of Regularly-Timed Speech Telecommunications & Signal Processing Laboratory (TSP) Speech Database at McGill University VoxForge Speech Corpus Festvox CMU_ARCTIC Speech Database at Carnegie Mellon University Each voice sample is stored as a.WAV file, which is then pre-processed for acoustic analysis using the specan function from the WarbleR R package. Specan measures 22 acoustic parameters on acoustic signals for which the start and end times are provided.**\n\n**The output from the pre-processed WAV files were saved into a CSV file, containing 3168 rows and 21 columns (20 columns for each feature and one label column for the classification of male or female). You can download the pre-processed dataset in CSV format, using the link above.In order to analyze gender by voice and speech, a training database was required. A database was built using thousands of samples of male and female voices, each labeled by their gender of male or female.**\n\n"},{"metadata":{"id":"fiRD6YSSyNVD"},"cell_type":"markdown","source":"# **Methodology**"},{"metadata":{"id":"WpReS1eEySYj"},"cell_type":"markdown","source":"\n*   Importing Some Basic Libraries\n*   Importing Data\n*   Performing Descriptive Analysis on the dataset\n    *   Data Description\n    *   Checking null values\n*   Processing Categorical Values using encoding\n*   Analysis of Target Variable\n    *   Plotting Kernel Density Estimate Plot\n    *   Plotting Distance Plot\n    *   Plotting Correlation Matrix and Heat Map\n*   Select Features based on above analysis\n*   Splitting voice_df into 70% and 30% to construct Training data and Testing data respectively\n*   Optimizing Best Parameters for SVM Classifier\n*   Applying Dimensionality reduction\n*   Visualization\n*   Creating Final SVM Classifier\n    *   Perform Prediction on Training Data\n    *   Perform Prediction on Testing Data\n*   For Training data, Evaluating Model based on Confusion Matrix and Classification Report\n*   For Testing data, Evaluating Model based on Confusion Matrix and Classification Report\n*   Save predictions of Testing data in gender_pred.csv"},{"metadata":{"id":"NsTeYKU1i8kn"},"cell_type":"markdown","source":"# **Importing Some Basic Libraries**"},{"metadata":{"id":"FDrOlV9tlxiW","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport sys, os\nfrom matplotlib import pyplot as plt\nfrom sklearn.utils import resample\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.preprocessing import LabelEncoder\nfrom itertools import product\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"id":"3yzClrp5jFWl"},"cell_type":"markdown","source":"# **Importing Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"id":"mgD5zlZfyej6"},"cell_type":"code","source":"gender_data_dir = \"/kaggle/input/voicegender/\"\nvoice_df = pd.read_csv(os.path.join(gender_data_dir, \"voice.csv\"))","execution_count":null,"outputs":[]},{"metadata":{"id":"3B2D63L7xWHT","outputId":"b9290567-a4f9-4748-be62-90b63b96cd7a","trusted":true},"cell_type":"code","source":"voice_df.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"5I8rZpuTrle_"},"cell_type":"markdown","source":"# **Descriptive Analysis of the dataset**"},{"metadata":{"trusted":true,"id":"65rq-BSYrlfE","outputId":"68586ebd-6f1e-4807-d1a4-5ca3a62b4ba8"},"cell_type":"code","source":"print(\"Size of Gender Recognition dataset       : {}\".format(voice_df.shape))","execution_count":null,"outputs":[]},{"metadata":{"id":"Ex0Pj2NVrlfN"},"cell_type":"markdown","source":"## **Data Description**"},{"metadata":{"id":"AOjBt6d-rlfP","outputId":"ce7f0c6e-cf8e-4f9a-a1db-3256324f43b9","trusted":true},"cell_type":"code","source":"voice_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"id":"wrC8TEXZyekb","outputId":"54f0c87f-9118-4b64-a254-be07d4663e75"},"cell_type":"code","source":"voice_df.describe().T","execution_count":null,"outputs":[]},{"metadata":{"id":"i31IFe-u0BF5"},"cell_type":"markdown","source":"## **Checking NULL/NaN Values :**"},{"metadata":{"id":"ICqlDLS48vPP","outputId":"772658bc-dadd-40d8-8076-bcd282fcce66","trusted":true},"cell_type":"code","source":"voice_df.isna().sum()                        # Printing a count of missing value w.r.t each feature in full_df","execution_count":null,"outputs":[]},{"metadata":{"id":"6PMgSC3X2FxM"},"cell_type":"markdown","source":"# **Analysis of Target Variable**"},{"metadata":{"id":"aDyAhe-55cV3","outputId":"83c762eb-7998-43ab-9e5b-49c53dfc25f9","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(9,6))\nsns.countplot(x='label', data=voice_df, order=[\"male\", \"female\"] )","execution_count":null,"outputs":[]},{"metadata":{"id":"uXc3r7IM5VCv","outputId":"cdacf423-f751-4e52-90e7-b3492ae5dfcc","trusted":true},"cell_type":"code","source":"voice_df['label'].value_counts()           # Prints the count of different classes in 'label'","execution_count":null,"outputs":[]},{"metadata":{"id":"fM-N50VpF6t2"},"cell_type":"markdown","source":"**Hence, We found that our data is Balanced.**"},{"metadata":{"id":"nt_shoMsIXVF"},"cell_type":"markdown","source":"## **Processing Categorical Values:**"},{"metadata":{"id":"uhN3xL0IIE7a","trusted":true},"cell_type":"code","source":"# creating instance of labelencoder\nlabel_encode = LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{"id":"SBbQopHCIksl","trusted":true},"cell_type":"code","source":"# Perform Encoding by coverting 'label' feature into numerical form\nvoice_df['label'] = label_encode.fit_transform(voice_df['label'])","execution_count":null,"outputs":[]},{"metadata":{"id":"Boqi84wOJBUL","outputId":"62c367f4-fbe8-4b42-f8e0-e9362b2f99ea","trusted":true},"cell_type":"code","source":"voice_df.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"POmNmnUOL9y7"},"cell_type":"markdown","source":"## **Kernel Density Estimate Plot :**"},{"metadata":{"id":"VnL9j4fuL-JT"},"cell_type":"markdown","source":"**It is analagous to a histogram. It represents the data using a continuous probability density curve.**"},{"metadata":{"id":"b3Xwcy0cJKwU","outputId":"9fdacaf4-a87a-4fb9-f8f7-3d03988ca8ba","trusted":true},"cell_type":"code","source":"plt.subplots(4,5,figsize=(30,30))\nfor i in range(1,21):\n    plt.subplot(4,5,i)\n    plt.title(voice_df.columns[i-1])\n    sns.kdeplot(voice_df.loc[voice_df['label'] == 0, voice_df.columns[i-1]], color= 'red', label='female')\n    sns.kdeplot(voice_df.loc[voice_df['label'] == 1, voice_df.columns[i-1]], color= 'brown', label='male')","execution_count":null,"outputs":[]},{"metadata":{"id":"H3hxBdUCx-sd"},"cell_type":"markdown","source":"**Hence, it is clearly visible that Q25, IQR and meanfun features will play an important role while classification. Since, they can classify Male and Female more effectively.**"},{"metadata":{"id":"z162vt5qM5r0"},"cell_type":"markdown","source":"## **Distance Plot :**"},{"metadata":{"id":"Xs9nWohTN1k0","outputId":"845553af-15cc-4bae-986d-c30cb2534f47","trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (20, 15))\nj = 0\nfor i in voice_df.columns:\n    plt.subplot(5, 5, j+1)\n    j += 1\n    sns.distplot(voice_df[i][voice_df['label']==0], color='r', label = 'Female')\n    sns.distplot(voice_df[i][voice_df['label']==1], color='b', label = 'Male')\n    plt.legend(loc='best')\nfig.suptitle('Voice Data Analysis')\nfig.tight_layout()\nfig.subplots_adjust(top=0.90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"sysDJ_m3yucK"},"cell_type":"markdown","source":"**Hence, it is clearly visible that Q25, IQR and meanfun features will play an important role while classification. Since, they can classify Male and Female more effectively.**"},{"metadata":{"id":"B0brPl2EW0tO"},"cell_type":"markdown","source":"## **Correlation Matrix and Heat Map**"},{"metadata":{"id":"9GwyNKpp8Ayg","outputId":"0b361a25-17ea-4b7e-9bd9-42d0f4502196","trusted":true},"cell_type":"code","source":"corr_data = voice_df.corr()                              # calculating correlation data between features\nplt.figure(figsize=(32, 20))                            # setting figure size\nsns.set_style('ticks')                                  # setting plot style\nsns.heatmap(corr_data, cmap='viridis',annot=True)       # plotting heatmap using sns library\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"lQWMSdX08Nhh","outputId":"e9174278-30b3-413b-c856-6952134aaec2","trusted":true},"cell_type":"code","source":"selected_pixel_features = corr_data['label'].apply(lambda x: abs(x)).sort_values(ascending=False).iloc[1:21][::-1]\nplt.figure(figsize=(25,12))\nselected_pixel_features.plot(kind='barh',color='red')\n# calculating highest correlated faetures\n# with respect to target variable i.e. \"convert\"\nplt.title(\"Top highly correlated features\", size=20, pad=26)\nplt.xlabel(\"Correlation coefficient\")\nplt.ylabel(\"Features\")","execution_count":null,"outputs":[]},{"metadata":{"id":"OAYRFX72zHuK"},"cell_type":"markdown","source":"**If we will set the threshold i.e. correlation coefficient >= 0.5. We got three feature's which are meanfun, IQR, Q25**"},{"metadata":{"id":"PbNPh3f7ztY8"},"cell_type":"markdown","source":"# **Selected Features :**"},{"metadata":{"id":"V5HPLtE4z99n"},"cell_type":"markdown","source":"**Using Above Analysis(KDE Plot, Distance Plot & correlation coefficient) on Voice DataFrame, we got to know that there are three important features which are IQR, Q25, meanfun.**"},{"metadata":{"id":"uxUgb5akzyNy","trusted":true},"cell_type":"code","source":"selected_features = ['IQR','Q25','meanfun']","execution_count":null,"outputs":[]},{"metadata":{"id":"pQY0Afm47oth","trusted":true},"cell_type":"code","source":"voice_df_X = voice_df[selected_features]\nvoice_df_y = voice_df.label","execution_count":null,"outputs":[]},{"metadata":{"id":"kvX0wcd69ymP","outputId":"6d050e46-2229-49c6-d8a8-6f18b62d9df8","trusted":true},"cell_type":"code","source":"voice_df_X.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"PBMsqsYuSqbc","outputId":"a8b6282d-82d8-4656-c693-307224a7590f","trusted":true},"cell_type":"code","source":"voice_df_y.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"C6iRaZd7-Q7-"},"cell_type":"markdown","source":"# **Train-Test Splitting :**"},{"metadata":{"id":"3HEGc9QrE4fB","trusted":true},"cell_type":"code","source":"# Splitting voice_df into 70% and 30% to construct Training and Testing Data respectively.\ntrainX, testX, trainy, testy = train_test_split(voice_df_X, voice_df_y,test_size=0.3,random_state=14)","execution_count":null,"outputs":[]},{"metadata":{"id":"fZzLTC4bFQkr","outputId":"ab6edba0-2b91-4bd8-ed10-a40114e7bd5a","trusted":true},"cell_type":"code","source":"trainX.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"EiVJxqMEGHoH","outputId":"87fd63fc-a270-4e06-ef9a-16db9a18af3d","trusted":true},"cell_type":"code","source":"trainX.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"_XNzbyXz95e0","outputId":"7818bef6-c913-42d0-8779-6ba5998094e6","trusted":true},"cell_type":"code","source":"trainy.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"EX_z9p6_F7_x","outputId":"d78e3441-9c7c-44f5-cb63-4f6785beef26","trusted":true},"cell_type":"code","source":"trainy.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"onY0EG9DFUh1","outputId":"3ad809ef-dd90-4058-c16d-2f815ea9cd1c","trusted":true},"cell_type":"code","source":"testX.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"tgATwo6hTVGs","outputId":"745034d9-548e-4758-dd22-ca37cc899d36","trusted":true},"cell_type":"code","source":"testX.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"yyG5Pc-w97Ny","outputId":"94699561-80c7-4829-f75a-d3cc3baa560e","trusted":true},"cell_type":"code","source":"testy.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"ifTcS__WTbNY","outputId":"cdec49eb-c5f1-4a82-a56d-d1f282fe5993","trusted":true},"cell_type":"code","source":"testy.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"GUXl7voy2Qhn"},"cell_type":"markdown","source":"# **Optimizing Best Parameters for SVM Classifier :**"},{"metadata":{"id":"y5sae5P-1aAZ","trusted":true},"cell_type":"code","source":"def svm_kernel(trainX, trainy, testX, testy):\n    rate=[]\n    kernel=['rbf','poly','linear']\n    for i in kernel:\n        SVM_Model = SVC(kernel=i).fit(trainX,trainy)\n        y_pred = SVM_Model.predict(trainX)\n        print(i, 'Accuracy of Train Data : ', accuracy_score(trainy,y_pred))\n        y_pred = SVM_Model.predict(testX)\n        print(i, 'Accuracy of Test Data : ', accuracy_score(testy,y_pred))\n        rate.append(accuracy_score(testy,y_pred))\n    nloc = rate.index(max(rate))\n    print(\"Highest accuracy is %s occurs at %s kernel.\" % (rate[nloc], kernel[nloc]))\n    return kernel[nloc]","execution_count":null,"outputs":[]},{"metadata":{"id":"5LsxfjQ83qWx","trusted":true},"cell_type":"code","source":"def svm_error(k,C,x_train,y_train,x_test,y_test):\n    error_rate = []\n    C = range(1,C)\n    for i in C:\n        model = SVC(kernel=k,C=i).fit(x_train,y_train)\n        model.fit(x_train, y_train)\n        y_pred = model.predict(x_test)\n        error_rate.append(np.mean(y_pred != y_test))\n    cloc = error_rate.index(min(error_rate))\n    print(\"Lowest error is %s occurs at C=%s.\" % (error_rate[cloc], C[cloc]))\n\n    plt.plot(C, error_rate, color='red', linestyle='dashed', marker='o', markerfacecolor='green', markersize=10)\n    plt.title('Error Rate Vs C Value')\n    plt.xlabel('C')\n    plt.ylabel('Error Rate')\n    plt.show()\n    return C[cloc]","execution_count":null,"outputs":[]},{"metadata":{"id":"lWZRS9s_2nAe","outputId":"7d99bd89-6cd6-4c82-b06a-28d18126adfa","trusted":true},"cell_type":"code","source":"k = svm_kernel(trainX, trainy, testX, testy)","execution_count":null,"outputs":[]},{"metadata":{"id":"kZb0AKgyJtks"},"cell_type":"markdown","source":"**Hence, RBF kernel is Selected for our final SVM Model.**"},{"metadata":{"id":"QJMXvYv63zqx","outputId":"3ed6f396-a0ed-47d3-eeab-08f995efe152","trusted":true},"cell_type":"code","source":"c = svm_error(k, 10, trainX, trainy, testX, testy)","execution_count":null,"outputs":[]},{"metadata":{"id":"5Qd_d6NyJ4jM"},"cell_type":"markdown","source":"**Hence, Value of C is Selected as 9 for our final SVM Model.**"},{"metadata":{"id":"yr8mKNT8A01H"},"cell_type":"markdown","source":"# **Applying Dimensionality Reduction :**"},{"metadata":{"id":"K6MohmzLA94j","trusted":true},"cell_type":"code","source":"# Initializing Principal Component Analysis(PCA)\nPCA_method = PCA(n_components=2)","execution_count":null,"outputs":[]},{"metadata":{"id":"W_ghlrZTBBwb","trusted":true},"cell_type":"code","source":"# Fit And Transorm Data\ntraindf= PCA_method.fit_transform(trainX)\ntestdf = PCA_method.transform(testX)","execution_count":null,"outputs":[]},{"metadata":{"id":"aGeY_cXtJAHR"},"cell_type":"markdown","source":"# **Visualization :**"},{"metadata":{"id":"ZXxO2u9m_vJE","outputId":"3e4b7ded-fa56-4b87-9da9-3689eff81163","trusted":true},"cell_type":"code","source":"# Plotting decision regions\nx_min, x_max = traindf[:, 0].min() - 1, traindf[:, 0].max() + 1\ny_min, y_max = traindf[:, 1].min() - 1, traindf[:, 1].max() + 1\n\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n\nf, ax = plt.subplots(figsize=(20, 12))\n\nSVM_Model = SVC(kernel=k, C=c).fit(traindf,trainy)\n\nfor clf, tt in zip([SVM_Model],['RBF Kernel SVM']):\n    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    ax.contourf(xx, yy, Z, alpha=0.5)\n    ax.scatter(traindf[:, 0], traindf[:, 1], c=trainy, s=30, edgecolor='k')\n    ax.set_title(tt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"9H_bpucdXIN3"},"cell_type":"markdown","source":"# **Creating Final SVM Classifier :**"},{"metadata":{"id":"TFp9RxyD2wa7","outputId":"5797522f-2d0d-43b5-b83c-85f57b2e1325","trusted":true},"cell_type":"code","source":"# Initailizing the Final SVM Classifier\nFinal_SVM_Model = SVC(kernel=k, C=c)\n# Train the model using the training sets\nFinal_SVM_Model.fit(trainX, trainy)","execution_count":null,"outputs":[]},{"metadata":{"id":"Ld8vjhGVVma6"},"cell_type":"markdown","source":"### **Perform Prediction on Training Data :**"},{"metadata":{"id":"AmjhTV4aT2wn","trusted":true},"cell_type":"code","source":"Final_SVM_Model_train_predictions = Final_SVM_Model.predict(trainX)","execution_count":null,"outputs":[]},{"metadata":{"id":"3th_tConzvFT"},"cell_type":"markdown","source":"### **Perform Prediction on Testing Data :**"},{"metadata":{"id":"u3z6rYRpRE54","trusted":true},"cell_type":"code","source":"Final_SVM_Model_test_predictions = Final_SVM_Model.predict(testX)","execution_count":null,"outputs":[]},{"metadata":{"id":"8jtDKdBm9ZOu"},"cell_type":"markdown","source":"# **Evaluation**"},{"metadata":{"id":"_s1DjSmvVqci"},"cell_type":"markdown","source":"### **On Training :**"},{"metadata":{"id":"Pqws9xUoymp4","outputId":"759e8f96-c6cb-4cbd-b163-4c7836ee9a74","trusted":true},"cell_type":"code","source":"print(\"SVM Model Confusion Matrix:\")\nprint(confusion_matrix(trainy, Final_SVM_Model_train_predictions))\n\nprint(\"SVM Model Classification Report\")\nprint(classification_report(trainy, Final_SVM_Model_train_predictions))","execution_count":null,"outputs":[]},{"metadata":{"id":"p69GzxneVvTM"},"cell_type":"markdown","source":"### **On Testing :**"},{"metadata":{"id":"HiAd7sM8PHqk","outputId":"08f40d12-1696-43a4-96a0-23fec06828b9","trusted":true},"cell_type":"code","source":"print(\"SVM Model Confusion Matrix:\")\nprint(confusion_matrix(testy, Final_SVM_Model_test_predictions))\n\nprint(\"SVM Model Classification Report\")\nprint(classification_report(testy, Final_SVM_Model_test_predictions))","execution_count":null,"outputs":[]},{"metadata":{"id":"MWjBgW_dn3UQ"},"cell_type":"markdown","source":"# **Predictions on Test Data :**"},{"metadata":{"id":"xh_Ma3LR_RWq","trusted":true},"cell_type":"code","source":"OutputDF = pd.DataFrame({'Actual_label':testy,'Predicted_label':Final_SVM_Model_test_predictions})","execution_count":null,"outputs":[]},{"metadata":{"id":"voeGQWFC_umG","outputId":"7c697e4b-cc7a-45ee-a03c-01259c1009fc","trusted":true},"cell_type":"code","source":"#Save to csv\nOutputDF.to_csv('gender_pred.csv',index=False)\nOutputDF.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"2Ul0yliH26wK"},"cell_type":"markdown","source":"**Thank you**,<br>\nNikunj Bansal,<br>\nR177218063,<br>\nB2 Batch<br>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}