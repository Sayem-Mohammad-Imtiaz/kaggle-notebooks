{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. One hot encoding on all the values\n## 2. One hot encoding on top 10 values\n## 3. Replacing the variables with their count\n## 4. Ordinal Number Encoding\n## 5. Target Guided Ordinal Encoding\n## 6. Mean Encoding\n## 7. Probablity Ratio Encoding","metadata":{}},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## One Hot Encoding for Categorical data ","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('../input/mercedesbenz-greener-manufacturing/train.csv',usecols=['X1','X2','X3','X4','X5','X6'])\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To check the Unique values\nfor i in data.columns:\n    print(i,' : ',len(data[i].unique()), 'labels')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. One hot encoding on all the values","metadata":{}},{"cell_type":"code","source":"#If we perform one hot encoding, lets see how many columns will be generated\npd.get_dummies(data,drop_first =True ).shape\n\n#Its says it will generate 117 columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. One hot encoding on top 10 values\n","metadata":{}},{"cell_type":"markdown","source":"### Apply one hot encoding on top 10 values of each column (Showing for X2 first)","metadata":{}},{"cell_type":"code","source":"#Finding top 10 most frequent values of X2\na = data['X2'].value_counts()\nb = a.sort_values(ascending = False)\nb.head(10)\n#OR\n#data['X2'].value_counts().sort_values(ascending = False).head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Making a list of the index values of top 10 frequent values\nl = []\nfor i in data['X2'].value_counts().sort_values(ascending = False).head(10).index:\n    l.append(i)\nprint(l)\n#OR\n#l = [i for i in data['X2'].value_counts().sort_values(ascending = False).head(10).index]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get whole set of dummy variables, for all the categorical variables\ndef one_hot_encoding_top_x(data, variable, l):\n    # function to create the dummy variables for the most frequent labels\n    # we can vary the number of most frequent labels that we encode\n    for label in l:\n        data[label] = np.where(data[variable]==label,1,0)\none_hot_encoding_top_x(data, 'X2', l)\ndata.head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#You can now do the same thing for all the other columns\n#After completing the for all the columns, drop the initial columns (X1,X2,X3,X4,X5,X6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Advantages of one hot encoding on top variables","metadata":{}},{"cell_type":"markdown","source":"* Does not require hours of variable exploration\n* Straightforward Implementation\n* Does not expand the no. of columns massively","metadata":{}},{"cell_type":"markdown","source":"### Disadvantages","metadata":{}},{"cell_type":"markdown","source":"* Does not add any information that makes the variables more predictable\n* Does not keep the information of the ignored variables","metadata":{}},{"cell_type":"markdown","source":"# 3. Replacing the variables with their count","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/mercedesbenz-greener-manufacturing/train.csv',usecols=['X1','X2'])\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Take the count of unique values and convert into a dictionary\ndict_var = df.X2.value_counts().to_dict()\ndict_var","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['X2'].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.X2 = df.X2.map(dict_var)\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Advantages","metadata":{}},{"cell_type":"markdown","source":"* Easy to implement\n* Does not increase the feature dimension size (columns)","metadata":{}},{"cell_type":"markdown","source":"## Disadvantages ","metadata":{}},{"cell_type":"markdown","source":"* If the labels have same count, they will get the same values. It may lead to important information loss","metadata":{}},{"cell_type":"markdown","source":"# 4. Ordinal Number Encoding","metadata":{}},{"cell_type":"code","source":"import datetime","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Today's date\ntoday = datetime.datetime.today()\ntoday","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Difference between today's date and the no. of days mentioned(In our case - 2)\ntoday-datetime.timedelta(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Taking 15 days data in a list comprehension\ndays = [today-datetime.timedelta(x) for x in range(15)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.DataFrame(days)\ndata.columns = ['Day']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To get the day's value\ndata['Weekday']=data['Day'].dt.strftime(\"%A\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating a dictionary to give ranks to each day\ndict = {'Moday':1,'Tuesday':2,'Wednesday':3,'Thursday':4,'Friday':5,'Saturday':6,'Sunday':7}\n#Creating a new column and appending the ranks based on the day\ndata['ordinal_rank'] = data['Weekday'].map(dict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Target Guided Ordinal Encoding\n1. Ordering the labels according to the target\n2. Replace the labels by the joint probability of being 1 or 0","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv('../input/titanic/train.csv', usecols=['Cabin','Survived'])\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Filled the missing values with the word 'Missing'\ndf['Cabin'].fillna('Missing',inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Taking only the first letter of the word (For eg if C85 then only C will be taken)\ndf['Cabin']=df['Cabin'].astype(str).str[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking the unique values in cabin column now\ndf.Cabin.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Taking the mean of the Cabin value along with the survived column to check for the percentages\ndf.groupby(['Cabin'])['Survived'].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Taking the index of Cabin column\ndf.groupby(['Cabin'])['Survived'].mean().sort_values().index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Adding the sorted values in ordinal_labels\nordinal_labels=df.groupby(['Cabin'])['Survived'].mean().sort_values().index\nordinal_labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Assigning ranks as per the sorted percentage\n#The ranks range from 0 to length of ordinal_labels\nordinal_labels2={k:i for i,k in enumerate(ordinal_labels,0)}\nordinal_labels2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating a new column containing ranks\ndf['Cabin_ordinal_labels']=df['Cabin'].map(ordinal_labels2)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Mean Encoding","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv('../input/titanic/train.csv', usecols=['Cabin','Survived'])\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Filled the missing values with the word 'Missing'\ndf['Cabin'].fillna('Missing',inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Taking only the first letter of the word (For eg if C85 then only C will be taken)\ndf['Cabin']=df['Cabin'].astype(str).str[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking the unique values in cabin column now\ndf.Cabin.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Take the mean and store the values in dict\nmean_ordinal=df.groupby(['Cabin'])['Survived'].mean().to_dict()\nmean_ordinal","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating a new column and appending the values according to the mean\ndf['mean_ordinal_encode']=df['Cabin'].map(mean_ordinal)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Probablity Ratio Encoding","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv('../input/titanic/train.csv', usecols=['Cabin','Survived'])\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Filled the missing values with the word 'Missing'\ndf['Cabin'].fillna('Missing',inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Taking only the first letter of the word (For eg if C85 then only C will be taken)\ndf['Cabin']=df['Cabin'].astype(str).str[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking the unique values in cabin column now\ndf.Cabin.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create a varible to take the mean of survived group by cabin\nmean_prob=df.groupby(['Cabin'])['Survived'].mean()\nmean_prob","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating a new dataframe and storing the above data\na = pd.DataFrame(mean_prob)\na","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating the Died Column\na['Died']=1-a['Survived']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating a column and appending the calculated probablity values\na['Prob'] = a['Survived']/a['Died']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating a new variable and passing the Prob column of dataset a into a dictionary\nprobablity_encoded = a.Prob.to_dict()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating a new column in original dataframe (df) and adding the probablity values using map function\ndf['Cabin_encoded'] = df['Cabin'].map(probablity_encoded)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}