{"cells":[{"metadata":{},"cell_type":"markdown","source":"![RNNvsLSTM.png](attachment:RNNvsLSTM.png)","attachments":{"RNNvsLSTM.png":{"image/png":"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"}}},{"metadata":{},"cell_type":"markdown","source":"**Introduction**\n\nThe aim of this study is to compare to accuracies of RNN and LSTM. I compare results of RNN and LSTM to each others and I changed hyperparameters in these methods and I compared them again with their modified versions.\n\nThe main differece of LSTM from RNN is that LSTM can store data longer than RNN."},{"metadata":{},"cell_type":"markdown","source":"### **Content**\n* [Import Data](#3)\n* [RNN](#4)\n* [Visualizing of RNN](#5)\n* [LSTM](#6)\n* [Visualizing of LSTM](#7)\n* [Visualizing of RNN vs LSTM](#8)\n* [Modified RNN](#9)\n* [Visualizing of RNN vs Modified RNN](#10)\n* [Modified LSTM](#11)\n* [Visualizing of LSTM vs Modified LSTM](#12)\n* [Visualizing of RNN vs Modified RNN vs LSTM vs Modified LSTM](#13)\n* [Visualizing of Modified RNN vs Modified LSTM](#14)\n* [Conclusion](#15)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3\"></a>\n### Import Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/gooogle-stock-price/Google_Stock_Price_Train.csv',sep=\",\")\n\n# We assign column \"Open\" to variable \"Data\"\ndata = data.loc[:,[\"Open\"]].values\n\n\ntrain = data[:len(data)-50] \ntest = data[len(train):] # last 50 data will be our test data\n\n# reshape\ntrain=train.reshape(train.shape[0],1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# feature scalling\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range= (0,1)) # defining of Scaler\ntrain_scaled = scaler.fit_transform(train) # applying to Scaler to train\n\nplt.plot(train_scaled)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We add first 50 locution to \"X_train\" and we 51. locution to \"y_train\" .\nX_train = []\ny_train = []\ntimesteps = 50\n\nfor i in range(timesteps, train_scaled.shape[0]):\n    X_train.append(train_scaled[i-timesteps:i,0])\n    y_train.append(train_scaled[i,0])\n\nX_train, y_train = np.array(X_train), np.array(y_train)\n\n\n# Reshaping\nX_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)  # Dimension of array is 3.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4\"></a>\n### RNN\n"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# --- RNN ---\n\n# Importing the Keras libraries and packages\n\nfrom keras.models import Sequential  \nfrom keras.layers import Dense \nfrom keras.layers import SimpleRNN\nfrom keras.layers import Dropout # it block to overfitting \n\n# Initialising the RNN\nregressor = Sequential()\n\n# Adding the first RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True, input_shape = (X_train.shape[1], 1)))\nregressor.add(Dropout(0.2)) \n\n# Adding a second RNN layer and some Dropout regularisation.\nregressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True))\nregressor.add(Dropout(0.2))\n\n# Adding a third RNN layer and some Dropout regularisation. \nregressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True))\nregressor.add(Dropout(0.2))\n\n# Adding a fourth RNN layer and some Dropout regularisation.\nregressor.add(SimpleRNN(units = 50))\nregressor.add(Dropout(0.2))\n\n\n# Adding the output layer\nregressor.add(Dense(units = 1))\n\n# Compiling the RNN\nregressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n\n# Fitting the RNN to the Training set\nregressor.fit(X_train, y_train, epochs = 100, batch_size = 32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = data[len(data) - len(test) - timesteps:]\ninputs = scaler.transform(inputs)  # min max scaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = []\nfor i in range(timesteps, inputs.shape[0]):\n    X_test.append(inputs[i-timesteps:i, 0]) # 0 dan 50 ye, 1 den 51 e gibi kaydirarark 50 eleman aliyoruz \nX_test = np.array(X_test)\nX_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_data = regressor.predict(X_test)\npredicted_data = scaler.inverse_transform(predicted_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5\"></a>\n### Visualization of RNN\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,4), dpi=80, facecolor='w', edgecolor='k')\nplt.plot(test,color=\"orange\",label=\"Real value\")\nplt.plot(predicted_data,color=\"c\",label=\"RNN predicted result\")\nplt.legend()\nplt.xlabel(\"Days\")\nplt.ylabel(\"Values\")\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6\"></a>\n### LSTM"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ------ LSTM --------------\n\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(LSTM(10, input_shape=(None,1))) # We want to add 10 LSTM block. One layer has 10 LSTM unit (node).\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(X_train, y_train, epochs=50, batch_size=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_data2=model.predict(X_test)\npredicted_data2=scaler.inverse_transform(predicted_data2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"7\"></a>\n### Visualization of LSTM"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,4), dpi=80, facecolor='w', edgecolor='k')\nplt.plot(test,color=\"LimeGreen\",label=\"Real values\")\nplt.plot(predicted_data2,color=\"Gold\",label=\"Predicted LSTM result\")\nplt.legend()\nplt.xlabel(\"Days\")\nplt.ylabel(\"Values\")\nplt.grid(True)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"8\"></a>\n### Visualization of RNN vs LSTM"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,4), dpi=80, facecolor='w', edgecolor='k')\nplt.plot(test,color=\"green\", linestyle='dashed',label=\"Real values\")\nplt.plot(predicted_data2,color=\"blue\", label=\"LSTM predicted result\")\nplt.plot(predicted_data,color=\"red\",label=\"RNN predicted result\") # ben ekledim\nplt.legend()\nplt.xlabel(\"Days)\")\nplt.ylabel(\"Real values\")\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LSTM looks greatly successful from the RNN.\n\nNow we change hyperparemeter like \"units, number of layers, epochs, batch_size, activation\" in RNN"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"9\"></a>\n### Modified RNN"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# RNN Modified\n\nfrom keras.models import Sequential  \nfrom keras.layers import Dense \nfrom keras.layers import SimpleRNN\nfrom keras.layers import Dropout \n\n# Initialising the RNN\nregressor = Sequential()\n\n\nregressor.add(SimpleRNN(units = 100,activation='relu', return_sequences = True, input_shape = (X_train.shape[1], 1)))\nregressor.add(Dropout(0.2))\n\n\nregressor.add(SimpleRNN(units = 50))\nregressor.add(Dropout(0.2))\n\n\n# Adding the output layer\nregressor.add(Dense(units = 1)) \n\n# Compiling the RNN\nregressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n\n# Fitting the RNN to the Training set\nregressor.fit(X_train, y_train, epochs = 500, batch_size = 16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_data_modified = regressor.predict(X_test)\npredicted_data_modified = scaler.inverse_transform(predicted_data_modified)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"10\"></a>\n### Visualization of RNN vs Modified RNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,4), dpi=80, facecolor='w', edgecolor='k')\nplt.plot(test,color=\"gray\",label=\"Real values\")\nplt.plot(predicted_data,color=\"cyan\",label=\"RNN result\")\nplt.plot(predicted_data_modified,color=\"blue\",label=\"RNN Modified Result\")\n\nplt.legend()\nplt.xlabel(\"Days\")\nplt.ylabel(\"Values\")\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks Modified RNN more successful than RNN."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"11\"></a>\n### Modified LSTM"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#  LSTM Modified\n\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler \n\n\nmodel = Sequential()\nmodel.add(LSTM(10, input_shape=(None,1)))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(X_train, y_train, epochs=200, batch_size=4) #degistirdim train leri RNN kilerle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_data2_modified=model.predict(X_test)\npredicted_data2_modified=scaler.inverse_transform(predicted_data2_modified)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"12\"></a>\n### Visualization of LSTM vs Modified LSTM"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,4), dpi=80, facecolor='w', edgecolor='k')\nplt.plot(test,color=\"DimGray\",label=\"Real values\", linestyle=\"dashed\")\nplt.plot(predicted_data2,color=\"Magenta\",label=\"LSTM predicted\")\nplt.plot(predicted_data2_modified,color=\"c\", label=\"Modified LSTM predicted\")\nplt.legend()\nplt.xlabel(\"Days\")\nplt.ylabel(\"Values\")\nplt.grid(True)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Modified LSTM looks more successful than LSTM."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"13\"></a>\n### Visualization of LSTM vs Modified LSTM vs RNN vs Modified RNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualization LSTM vs LSTM modified vs RNN vs RNN modified\n\nplt.figure(figsize=(16,8), dpi=80, facecolor='w', edgecolor='k')\nplt.plot(test,color=\"DimGray\",label=\"Real value\", linestyle=\"dashed\")\nplt.plot(predicted_data2,color=\"blue\",label=\"LSTM predicted\")\nplt.plot(predicted_data2_modified,color=\"red\", linestyle=\"dashed\", label=\"LSTM Modified predicted\")\nplt.plot(predicted_data,color=\"c\",label=\"RNN predicted\")\nplt.plot(predicted_data_modified,color=\"green\", linestyle=\"dashed\", label=\"RNN modified predicted\")\nplt.legend()\nplt.xlabel(\"Days\")\nplt.ylabel(\"Values\")\nplt.grid(True)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualization Modified RNN vs Modified LSTM\n\nplt.figure(figsize=(16,8), dpi=80, facecolor='w', edgecolor='k')\nplt.plot(test,color=\"DimGray\", linestyle= \"dashed\", label=\"true result\")\nplt.plot(predicted_data2_modified,color=\"Magenta\",  label=\"LSTM Modified predicted\")\nplt.plot(predicted_data_modified,color=\"c\",  label=\"RNN modified predicted\")\nplt.legend()\nplt.xlabel(\"Days\")\nplt.ylabel(\"Values\")\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion\nChanging hyperparameter can increase to accuracy.\n\nLSTM looks more successful than RNN in predict to values about time."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}