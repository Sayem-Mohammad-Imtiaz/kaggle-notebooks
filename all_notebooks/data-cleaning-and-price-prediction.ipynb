{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport re\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom collections import Counter\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/cartier-jewelry-catalog/cartier_catalog.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n\n# Goal: \nThere are 692 entries of jewelry products with description and price. Our goal is to predict the price. The main focus of this kernel is to practice data cleaning, as all the meaningful data is hidden in the text.\n\n# Evaluation metric: \nMean square error","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We need some base estimator to compare our future work to some trivial guess. The only information available immediately is categorie. Let us make some plots. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(12,4))\nsns.countplot(data.categorie, ax=axes[0])\nsns.boxplot(x='categorie', y='price', data=data, ax=axes[1])\nplt.ylim(0,100000)\nplt.suptitle('Count and price distribution by categories')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The simplest guess will be to guess the average price in each category without looking into further details. Let us write such an estimator and compute its R2 score.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_by_cat = data.groupby('categorie').price.mean()\n\ndef base_est(X):\n    \"\"\"returns average price for each category\"\"\"\n    \n    X['predict'] = X.categorie.apply(lambda x: avg_by_cat[x])\n    return X.predict.values    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2_score(data.price, base_est(data))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Base estimator has R^2 score of 0.05, we want to improve on that.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"\n# What to do with the data?\n\n## Categorie\n    OK, no missing values. Do not touch it.\n\n# Title\n\n    1) Extract most commonly appearing words, and choose the one that possibly represent the brand. \n    (we could use 2-grams, but after examining the values, there does not seem to be anything new we will get from it)\n\n    \n# Tags\n    1) The tags are well organized, contain main features \n    (like presence of a diamond or a garnet, and type of metals). \n    Choose most commonly appearing tags (we'll set a threshold for >30 appearances).\n    \n# Description\n \n    1) Extract quantative information: number of diamonds, sapphires, etc. \n        How many carat for the diamond, or size of the rings... \n    2) Extract sizes of the product (small, medium, large)\n    \n    Possibly, we could extract other adjectives, like type of cut of the diamonds, \n    or some other superlatives in the description. However, the dataset is very small,\n    and we already have many featuresm and will overfit, so I stopped here.\n    \n    \n# Image:\n    It is possible that the directories in which image is saved, \n    contain some valuable classification information \n    (perhaps all luxurious brands are saved in the same directory).\n    I will not use it, as it is sort of cheating, but one can try \n    to train a model on that. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Title column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus = []\nfor i in data.index:\n    tokens = nltk.word_tokenize(data.title[i])\n    corpus += list(tokens)\n    \nword_counts = Counter(corpus)\nword_counts.most_common(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After looking at some entries in Title column, many of these words always appear together, like 'de Cartier' or 'Juste Clou'. We also remove the words like 'diamonds', 'bracelet', 'ring' for which the information will be in other columns.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"common_words = ['Cartier', 'Panth√®re', 'wedding', 'Love', 'Trinity', 'Juste']\nfor word in common_words:\n    data[word] = data.title.apply(lambda x: int(word in nltk.word_tokenize(x)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Working on Description column:\n\nTokenize and determine parts of speech. We will write a function that each time it finds a number in the sentence, it will look for the next noun to understand the meaning of that number. Some quantities like the width are given before the number, so we will have the option to look for previous noun.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['descr_tok'] = data.description.apply(lambda x: nltk.word_tokenize(x))\ndata['descr_pos'] = data.descr_tok.apply(lambda x: nltk.pos_tag(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract(string, nouns, kind='count', following=True):\n    \"\"\"extracts a number such that noun follows it, i.e. 3 beautiful diamonds.\n       accepts list of nouns(need plural and singular)\n       kind - mostly used for count, but for some cases we need to use mean\"\"\"\n    \n    count = []\n\n    for num, word in enumerate(string):\n        if word[1]=='CD':\n            if find_next_noun(string, num, following) in nouns:\n                if word[0] in ['one', 'One']:\n                    numerical = [1]\n                elif word[0] in ['two', 'Two']:\n                    numerical = [2]\n                elif word[0] in ['three', 'Three']:\n                    numerical = [3]\n                elif word[0] in ['four', 'Four']:\n                    numerical = [4]\n                elif word[0] in ['five', 'Five']:\n                    numerical = [5]\n                else:    \n                    numerical =  re.findall('\\d+.\\d+|\\d+', word[0])\n                if len(numerical):\n                    try:\n                        count.append(float(numerical[0]))\n                    except ValueError:\n                        pass\n        if (word[0] in ['a', 'one']) and following==True:\n            if find_next_noun(string, num, following) in nouns:\n                count.append(1)                    \n                \n    if len(count)==0:\n        count=[0]\n    if kind=='count':\n        return np.sum(count)\n    if kind=='mean':\n        return np.mean(count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_next_noun(string, position, following=True):\n    \"\"\"finds next noun appearing after position in pos_tagged string, \n       if following==False, finds preceding noun \"\"\"\n    \n    step = 1\n    if following == False:\n        step=-1\n    i=position+step\n    while (i<len(string)) and (i>-1):\n        if string[i][1] in ['NN', 'NNS', 'NNP', 'NNPS']:\n            return string[i][0]\n        i=i+step","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract the numerical info\n\ndata['num_diamonds'] = data.descr_pos.apply(lambda x: extract(x, ['diamond', 'diamonds'], kind='count'))\ndata['carat'] = data.descr_pos.apply(lambda x: extract(x, ['carat', 'carats'], kind='count'))\ndata['purity'] = data.descr_pos.apply(lambda x: extract(x, ['gold'], kind='mean'))\ndata['width'] = data.descr_pos.apply(lambda x: extract(x, ['width', 'Width'], kind='mean', following=False))\ndata['num_garnets'] = data.descr_pos.apply(lambda x: extract(x, ['garnet', 'garnets'], kind='count'))\ndata['num_sapphires'] = data.descr_pos.apply(lambda x: extract(x, ['sapphire', 'sapphires'], kind='count'))\ndata['num_emeralds'] = data.descr_pos.apply(lambda x: extract(x, ['emerald', 'emeralds'], kind='count'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.purity.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Platinum is always 950 from observing the data, and purity is always 18K. So we can as well remove this data. Other columns are more diverse.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(columns=['purity'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Room for imporvement here\n\nIt is possible, that some of the values are read incorrectly. We could double check using regex the width, because it appears often with the units (mm) or purity which appears as 18K (with K in the end) and other values. However, I felt lazy and was happy that everything works using just one function.\n\nMoreover, in some descriptions, it just says sapphires and emeralds, without specifying the number, while it is clearly more than one. We could treat it as missing value, and fill it with most common number of sapphires or emeralds, but currently it is filled by 0.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract sizes\n\nsmall = ['small', 'Small', 'S', 'XS', 'xs']\nmedium = ['medium', 'Medium', 'M']\nlarge = ['large', 'Large', 'L', 'XL', 'big', 'Big']\n\ndef size_encoder(string, size):\n    return  int(len(set(size) & set(nltk.word_tokenize(string)))>0)\n\ndata['small'] = data.description.apply(lambda x: size_encoder(x, small))\ndata['medium'] = data.description.apply(lambda x: size_encoder(x, medium))\ndata['large'] = data.description.apply(lambda x: size_encoder(x, large))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tags column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Obtaining a list of most common tags from the data\n\ntag_set = []\nfor tags in data.tags.values:\n    tag_set += tags.split(',')\n\ntag_count = Counter(tag_set)    \ncommon_tags = [ word for (word, count) in tag_count.most_common(15)]    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One hot encoding of tags\nfor tag in common_tags:\n    data[tag] = data.tags.apply(lambda x: int(tag in x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One hot encoding of categories.\n\ndata = pd.get_dummies(data=data, columns=['categorie'], drop_first=True)\n#data['rings'] = data.categorie.apply(lambda x: int(x=='rings'))\n#data['bracelets'] = data.categorie.apply(lambda x: int(x=='bracelets'))\n#data['necklaces'] = data.categorie.apply(lambda x: int(x=='necklaces'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = data.drop(columns=['ref', 'title', 'tags', 'description', 'image', 'descr_tok', 'descr_pos'])\n\nX_train, X_test, y_train, y_test = train_test_split(\n                    df.drop(columns=['price']), df.price, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regr = RandomForestRegressor(n_estimators=100, max_depth=20)\nregr.fit(X_train,y_train)\nregr.score(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"regr.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# R2 - Score: ~80\n\nFine tuning might improve it. ","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}