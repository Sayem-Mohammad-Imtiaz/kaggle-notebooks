{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Objective: To demonstrate structured format of Performing Exploratory data Analysis.\n\nNote that this notebook only contains Bivariate analysis. the preceeding Univaiate analysis can be found in a separate notebook, I highly recommend that you go through that notebook first.\n\n\nhttps://www.kaggle.com/lonewolf95/eda-101-structured-univariate-analysis\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Overview:\n\n1. Recapping the problem statement\n2. Recapping generated hypothesis\n3. Recapping investigation leads from univariate analysis\n4. Importing dataset + variabe typecasting\n5. Bivariate Analysis : Numerical Numerical\n6. Bivariate Analysis : Numerical Categorical\n7. Bivariate Analysis : Categorical Categorical\n8. Summary of Bivariate analysis  ","execution_count":null},{"metadata":{"id":"e9mGxzDF5Cl9"},"cell_type":"markdown","source":"## 1. Recapping problem statement:\nA Bank wants to take care of customer retention for their product; savings accounts. The bank wants you to identify customers likely to churn balances below the minimum balance. You have the customers information such as age, gender, demographics along with their transactions with the bank. Your task as a data scientist would be to predict the propensity to churn for each customer.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 2. Recapping generated hypothesis:\nDuring the univariate anlysis we saw that hypothesis testing was not possible because hypothesis testing primarily deals with the combination of some independent variable with the target variable. As we are not diving into bivariate analysis, **we will be performing hypothesis testing extensively.**\n\n\nGiven below are the hypothesis we will be working with in this EDA\n\n**On basis of Demographics**\n1. Are females less likely to churn than males?\n2. Are young customers more likely to churn?\n3. Are customers in the lower income bracket more likely to churn?\n4. Are customers with dependent(s) less likely to churn?\n5. Customers with an average family size less than 4 are more likely to churn?\n\n**On the basis of customer behaviour**\n1. Are vintage customers less likely to churn?\n2. Are customers with higher average balance less likely to churn?\n3. Are customers dropping monthly balance highly likely to churn?\n4. Are customers with no transaction is the last 3 months more likely to churn?\n5. Are customers who have large withdrawal amounts in the last month more likely to churn?\n6. Are customers who have large withdrawal amounts in the last quarter more likely to churn?\n7. Customers who have not engaged with the bank in the last quarter are more likely to churn?","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 3. Investigation leads from Univariate analysis:\n\n1. Is there there any common trait/relation between the customers who are performing high transaction credit/debits?\n    * customer_nw_category might explain that.\n    * Occupation = Company might explain them\n    * popular cities might explain this\n2. Customers whose last transaction was 6 months ago, did all of them churn?\n3. Possibility that cities and branch code with very few accounts may lead to churning.\n\n","execution_count":null},{"metadata":{"id":"1FzYccB24irQ"},"cell_type":"markdown","source":"## 4. Importing libraries + Datset + Variable identification and typecasting.","execution_count":null},{"metadata":{"id":"zDWO5w4jIiWL","trusted":true},"cell_type":"code","source":"# importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(action = 'ignore')\n\n#importing data\ndata = pd.read_csv('../input/banking-churn-prediction/Banking_churn_prediction.csv')\n\n# converting churn/brnch_code/customer_nw_category to category type\ndata['churn'] = data['churn'].astype('category')\ndata['branch_code'] = data['branch_code'].astype('category')\ndata['customer_nw_category'] = data['customer_nw_category'].astype('category')\ndata.dtypes[data.dtypes == 'int64']\n\n# converting \"dependents\" and \"city\" to their respective types\ndata['dependents'] = data['dependents'].astype('Int64')\ndata['city'] = data['city'].astype('category')\n\n# typecasting \"gender\" and \"occupation\" to category type\ndata['gender'] = data['gender'].astype('category')\ndata['occupation'] = data['occupation'].astype('category')\n\n# creating an instance(date) of DatetimeIndex class using \"last_transaction\"\ndate = pd.DatetimeIndex(data['last_transaction'])\n\n##### extracting new columns from \"last_transaction\"\n\n# last day of year when transaction was done\ndata['doy_ls_tran'] = date.dayofyear\n\n# week of year when last transaction was done\ndata['woy_ls_tran'] = date.weekofyear\n\n# month of year when last transaction was done\ndata['moy_ls_tran'] = date.month\n\n# day of week when last transaction was done\ndata['dow_ls_tran'] = date.dayofweek\n\n# Removing the original datetime column\ndata = data.drop(columns = ['last_transaction'])\n\n\n#dropping customer_id\ndata = data.drop(columns=['customer_id'])\n\n#checking\ndata.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# seggregating variables into groups\ncustomer_details = ['customer_id','age','vintage']\ncurrent_month = ['current_balance','current_month_credit','current_month_debit','current_month_balance']\nprevious_month = ['previous_month_end_balance','previous_month_credit','previous_month_debit','previous_month_balance']\nprevious_quarters = ['average_monthly_balance_prevQ','average_monthly_balance_prevQ2']\ntransaction_date = ['doy_ls_tran','woy_ls_tran','moy_ls_tran','dow_ls_tran']","execution_count":null,"outputs":[]},{"metadata":{"id":"3iPcgNAHEkB5"},"cell_type":"markdown","source":"## 5. Bivariate Analysis : Numerical-Numerical\nIn this section we will be performing bivariate analysis for the Numerical Numerical combination of variables.\n\n**Although we do not have have any hypothesis which falls under this combination of variables, but we will still perform the numerical numerical bivariate analysis and relation between the independent variables can be used during the preprocessing and feature engineering.**","execution_count":null},{"metadata":{"id":"2Ae5gGfMEkB6","outputId":"c8915ab4-e36f-4cea-c730-6ecb19a294a7","trusted":true},"cell_type":"code","source":"# isolating numerical datatypes\nnumerical = data.select_dtypes(include=['int64','float64','Int64'])[:]\nnumerical.dtypes","execution_count":null,"outputs":[]},{"metadata":{"id":"jYBGrb8IqF1r"},"cell_type":"markdown","source":"### Correlation Matrix\nA straight forward goto method is to print the correlation matrix.","execution_count":null},{"metadata":{"id":"hMPGkRKrEkB-","outputId":"1e2606e9-8d1a-49f8-9abf-7d38e4242c80","trusted":true},"cell_type":"code","source":"# calculating correlation\ncorrelation = numerical.dropna().corr()\ncorrelation","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**As number of variables are too large, correlation matrix is not much help.**","execution_count":null},{"metadata":{"id":"O5kVn205Uc4B"},"cell_type":"markdown","source":"### Heatmap\nHeatmap will allow us to visually figure out the key correlation between variables and filter the down the essential variables so that we will have lesss to deal with during the scatter plots.\n\nIn order to have different perspectives on the correlation of the independent variables, we will be plotting the heatmaps using three methods of calculating the correlation.\n\n1. Pearson Correlation\n2. Kendal's Tau\n3. Spearman Correlation","execution_count":null},{"metadata":{"id":"yDwEhSSDEkCA","outputId":"07473abb-4218-4724-9ea5-979efee14523","trusted":true},"cell_type":"code","source":"# plotting heatmap usingl all methods for all numerical variables (peason, kendall, spearman)\nplt.figure(figsize=(36,6), dpi=140)\nfor j,i in enumerate(['pearson','kendall','spearman']):\n  plt.subplot(1,3,j+1)\n  correlation = numerical.dropna().corr(method=i)\n  sns.heatmap(correlation, linewidth = 2)\n  plt.title(i, fontsize=18)\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"KbatuwlduSNl"},"cell_type":"markdown","source":"* Kendall and Spearman correlation seem to have very similar pattern between them, except the slight variation in magnitude of correlation.\n*  Too many variables with insignificant correlation.\n*  Major correlation lies between the transaction variables and balance variables.\n\n**As the there are are many variables with insignificant correlation, let's filter down to the most important ones.**","execution_count":null},{"metadata":{"id":"ssUvYsgyEkCC","trusted":true},"cell_type":"code","source":"# extracting transaction information of current and previous months\nvar = []\nvar.extend(previous_month)\nvar.extend(current_month)\nvar.extend(previous_quarters)","execution_count":null,"outputs":[]},{"metadata":{"id":"D61XZIlDEkCF","outputId":"58ce1264-781d-4985-bf6a-b5845f845a6e","trusted":true},"cell_type":"code","source":"# plotting heatmap usill all methods for all transaction variables\nplt.figure(figsize=(36,6), dpi=140)\nfor j,i in enumerate(['pearson','kendall','spearman']):\n  plt.subplot(1,3,j+1)\n  correlation = numerical[var].dropna().corr(method=i)\n  sns.heatmap(correlation, linewidth = 2)\n  plt.title(i, fontsize=18)","execution_count":null,"outputs":[]},{"metadata":{"id":"26W7HQLJS_Rz"},"cell_type":"markdown","source":"**Inferences:**\n\n\n1.   Transaction variables like credit/debit have a strong correlation among themselves.\n2.  Balance variables have strong correlation among themselves.\n3.   Transaction variables like credit/debit have insignificant or no correlation with the Balance variables.\n\n","execution_count":null},{"metadata":{"id":"VaYygjVJUf0I"},"cell_type":"markdown","source":"### Scatterplot\n**Now that we have a bird's eye view of the correlations, let's look over them closely with the help of scatter plots.**","execution_count":null},{"metadata":{"id":"2cirarNgU1Dn","trusted":true},"cell_type":"code","source":"# Grouping variables\ntransactions = ['current_month_credit','current_month_debit','previous_month_credit','previous_month_debit']\nbalance = ['previous_month_end_balance','previous_month_balance','current_balance','current_month_balance']","execution_count":null,"outputs":[]},{"metadata":{"id":"1sWiCzLIGMWn","outputId":"4436436c-487b-45ee-fcf6-bf938a688266","trusted":true},"cell_type":"code","source":"# scatter plot for transactional variables\nplt.figure(dpi=140)\nsns.pairplot(numerical[transactions])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"izeFVmArdlcL"},"cell_type":"markdown","source":"**the scatter plot is is not meaningful due to the presence of outliers**\nOne way to visualise them is to take logarithm transform of every variable is to nullify the effect of outliers.","execution_count":null},{"metadata":{"id":"TYWU6jHpeEJf","trusted":true},"cell_type":"code","source":"#taking log of every value to negate outliers\nfor column in var:\n  mini=1\n  if numerical[column].min()<0:\n    mini =  abs(numerical[column].min()) + 1\n  \n  numerical[column] = [i+mini for i in numerical[column]]\n  numerical[column] = numerical[column].map(lambda x : np.log(x))","execution_count":null,"outputs":[]},{"metadata":{"id":"rAmHdUT8zyqG","outputId":"64f01b28-22b9-4f91-a430-d756fbbf232e","trusted":true},"cell_type":"code","source":"# scatter plot for transactional variables\nplt.figure(dpi=140)\nsns.pairplot(numerical[transactions])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"AEpANup5eZwV"},"cell_type":"markdown","source":"**Inferences**\n1.    This validates the high correlation between the transaction variables.\n2.    This high correlation can be used for feature engineering during the later stages.","execution_count":null},{"metadata":{"id":"gJ1VkLc43tfI","outputId":"5133e48d-f37a-4c51-a69e-25f6c1a4ef7d","trusted":true},"cell_type":"code","source":"# balance variables\nplt.figure(dpi=140, figsize = (20,20))\nsns.pairplot(numerical[balance])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"as-bXBoFf1y5"},"cell_type":"markdown","source":"**Inferences**\n1.    This validates the high correlation between the balance variables.\n2.    This high correlation can be used for feature engineering during the later stages.","execution_count":null},{"metadata":{"id":"1M0SKcLQB31s","outputId":"9c286ef6-485f-443f-fe38-a00a48b62c3b","trusted":true},"cell_type":"code","source":"# previous quarters\nplt.figure(dpi=140)\nsns.scatterplot(numerical['average_monthly_balance_prevQ'], numerical['average_monthly_balance_prevQ2'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"oL-II51yfz3F"},"cell_type":"markdown","source":"**Inferences**\n1.    This validates the high correlation between the two previous quarters\n2.    This high correlation can be used for feature engineering during the later stages.\n\n\n**Key Insight**\n\nWe can generate dozens of new features from these highly correlated variables during the feature engineering phase, which should be able to explain the presence of outliers and may contribute to better model performance.","execution_count":null},{"metadata":{"id":"4HFqabIBc_fb"},"cell_type":"markdown","source":"## 6. Bivariate Analysis: Continuous-Categorical u to plot the categorical mean and the categorical distribution.\nMoreover, in this section we will working with hypothesis testing. I you need a quick refresher on hypothesis testing and how p-value works, just follow along the this article.\n\nhttps://medium.com/analytics-vihttps://medium.com/analytics-vidhya/everything-you-should-know-about-p-value-from-scratch-for-data-science-f3c0bfa3c4cc","execution_count":null},{"metadata":{"id":"Bb-bvjsifduo"},"cell_type":"markdown","source":"List of Hypothesis and investigation to perform under this combination.\n\n1.  Are vintage customers less likely to churn?for large number of observations.\n2.  Are customers with higher average balance less likely to churn?\n3.  Are customers dropping monthly balance highly likely to churn?\n\nWe will be performing the hypothesis testing as we go along plotting the graphs. This will save a lot of time in the long run. For this we will be making three functions.\n1. Function for 2sample Z-Test\n2. Function for 2 sample T-Test\n3. Function for plotting which uses the above mentioned two functions.\n\nNote that I am using both Z-test and T-test here to quantify that they perform similarly.","execution_count":null},{"metadata":{"id":"icJUfIIuFPW2","trusted":true},"cell_type":"code","source":"def TwoSampZ(X1, X2, sigma1, sigma2, N1, N2):\n  '''\n  takes mean, standard deviation, and number of observations and returns p-value calculated for 2-sampled Z-Test\n  '''\n  from numpy import sqrt, abs, round\n  from scipy.stats import norm\n  ovr_sigma = sqrt(sigma1**2/N1 + sigma2**2/N2)\n  z = (X1 - X2)/ovr_sigma\n  pval = 2*(1 - norm.cdf(abs(z)))\n  return pval","execution_count":null,"outputs":[]},{"metadata":{"id":"ojv6RiYJFjwA","trusted":true},"cell_type":"code","source":"def TwoSampT(X1, X2, sd1, sd2, n1, n2):\n  '''\n  takes mean, standard deviation, and number of observations and returns p-value calculated for 2-sample T-Test\n  '''\n  from numpy import sqrt, abs, round\n  from scipy.stats import t as t_dist\n  ovr_sd = sqrt(sd1**2/n1 + sd2**2/n2)\n  t = (X1 - X2)/ovr_sd\n  df = n1+n2-2\n  pval = 2*(1 - t_dist.cdf(abs(t),df))\n  return pval","execution_count":null,"outputs":[]},{"metadata":{"id":"JctgZ8-PdGq0","trusted":true},"cell_type":"code","source":"def Bivariate_cont_cat(data, cont, cat, category):\n  #creating 2 samples\n  x1 = data[cont][data[cat]==category][:]\n  x2 = data[cont][~(data[cat]==category)][:]\n  \n  #calculating descriptives\n  n1, n2 = x1.shape[0], x2.shape[0]\n  m1, m2 = x1.mean(), x2.mean()\n  std1, std2 = x1.std(), x2.mean()\n  \n  #calculating p-values\n  t_p_val = TwoSampT(m1, m2, std1, std2, n1, n2)\n  z_p_val = TwoSampZ(m1, m2, std1, std2, n1, n2)\n\n  #table\n  table = pd.pivot_table(data=data, values=cont, columns=cat, aggfunc = np.mean)\n\n  #plotting\n  plt.figure(figsize = (20,4), dpi=140)\n  \n  #barplot\n  plt.subplot(1,3,1)\n  sns.barplot([str(category),'not {}'.format(category)], [m1, m2])\n  plt.ylabel('mean {}'.format(cont))\n  plt.xlabel(cat)\n  plt.title('t-test p-value = {} \\n z-test p-value = {}\\n {}'.format(t_p_val,\n                                                                z_p_val,\n                                                                table))\n\n  # category-wise distribution\n  plt.subplot(1,3,2)\n  sns.kdeplot(x1, shade= True, color='blue', label = 'churned')\n  sns.kdeplot(x2, shade= False, color='green', label = 'not churned', linewidth = 1)\n  plt.title('categorical distribution')\n    \n  # boxplot\n  plt.subplot(1,3,3)\n  sns.boxplot(x=cat, y=cont, data=data)\n  plt.title('categorical boxplot')","execution_count":null,"outputs":[]},{"metadata":{"id":"gjroB6UIld90"},"cell_type":"markdown","source":"### 6.1 Are vintage customers less likely to churn?\n\n","execution_count":null},{"metadata":{"id":"FdIx6TGl2dhI","outputId":"7f4ec278-2f21-48b9-8578-325f42f259d8","trusted":true},"cell_type":"code","source":"Bivariate_cont_cat(data, 'vintage', 'churn', 1)","execution_count":null,"outputs":[]},{"metadata":{"id":"0CPEtIyBRXHr"},"cell_type":"markdown","source":"**Inferences**\n\n1.    Vintage customers churned more, but results are not significantly different\n2.    Boxplot shows very similar distribution with outliers on the lower end.\n\n**Result**\n\np-value is >0.05, which means that the two samples are more or less similar to each other.\n\nThefore, we can safely reject the hypothesis that vintage customers are more likely to churn.","execution_count":null},{"metadata":{"id":"HInM0jShT9Jb"},"cell_type":"markdown","source":"### 6.2 Are customers with higher average balance less likely to churn?","execution_count":null},{"metadata":{"id":"fMPDXootDyvB","outputId":"5a2514e0-26c6-4d1a-980a-945b52a119aa","trusted":true},"cell_type":"code","source":"Bivariate_cont_cat(data, 'average_monthly_balance_prevQ', 'churn', 1)","execution_count":null,"outputs":[]},{"metadata":{"id":"cUJl9KUDTYOc"},"cell_type":"markdown","source":"**Result**    \n\np-value < 0.05, the the two samples are significantly different.\n\nCustomers who churned have significantly higher balance during immediate preceeding quarter, which is contrary to what we were were testing but the result is significant.","execution_count":null},{"metadata":{"id":"0k-pJMTrUHmH","outputId":"c78f4836-52e3-4dec-d569-ce4c0298f537","trusted":true},"cell_type":"code","source":"Bivariate_cont_cat(data, 'average_monthly_balance_prevQ2', 'churn', 1)","execution_count":null,"outputs":[]},{"metadata":{"id":"XAKAT5c12COw"},"cell_type":"markdown","source":"**Inferences**\n\nWe can see that people who churned actually had significantly higher balance during their previous two quarters.**This validates the previous plot conveying the message that people whoc hurned actually had higher balance.\n**","execution_count":null},{"metadata":{"id":"uzAeFI-42nyt"},"cell_type":"markdown","source":"#### previous month/current month","execution_count":null},{"metadata":{"id":"ZvVrUKlQUnfl","outputId":"ad018583-b8f6-4433-9b6f-a3a4aef6e9c7","trusted":true},"cell_type":"code","source":"Bivariate_cont_cat(data, 'previous_month_balance', 'churn', 1)","execution_count":null,"outputs":[]},{"metadata":{"id":"SFv6JzLs3YJI","outputId":"5f00612d-94fb-4908-9d89-4277c29b7bfd","trusted":true},"cell_type":"code","source":"Bivariate_cont_cat(data, 'current_month_balance', 'churn', 1)","execution_count":null,"outputs":[]},{"metadata":{"id":"m153z6Cf6LtY"},"cell_type":"markdown","source":"**Inferences**\n\n> Customers who churned had significantly high balance throughout the previous two quarters and previous month. But their average balance reduced significantly in the current month. Moreover the customers who are maintaining higher balance are more prone to churning (so it seems)\n","execution_count":null},{"metadata":{"id":"D8j1HmO-63zF"},"cell_type":"markdown","source":"### 6.3 Are customers dropping monthly balance highly likely to churn?","execution_count":null},{"metadata":{"id":"whwCbr3Z6_ir","trusted":true},"cell_type":"code","source":"# Extracting drop of balance in previous and current month\ndifference = data[['churn','previous_month_balance','current_month_balance']][:]\ndifference['bal_diff'] = difference['current_month_balance']-difference['previous_month_balance']","execution_count":null,"outputs":[]},{"metadata":{"id":"4b26Y6C_9RjJ","outputId":"fb12145a-b4ce-4750-e697-4c1bff01a01a","trusted":true},"cell_type":"code","source":"Bivariate_cont_cat(difference, 'bal_diff', 'churn', 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is a a very absurd plot to gain insight from, so what actually happening here is that.... \n* the customers who churned have a negative average balance differenceand that too is a huge number.\n* Whereas the customers who did not churn slighly positive balance difference betwwen the previous month and the current month.","execution_count":null},{"metadata":{"id":"nlb_UiLqexPX"},"cell_type":"markdown","source":"**Inference**\n\nCustomers who churned had a very high drop in their balance which is signified by the negative value in this bar plot.\n\n**This factor can be used generate a new feature.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Bivariate: Categorical Categorical\nIn this section we will be working with the categorical categorical combination of variables. **Grouped bar plot and stacked bar plots are the 2 key ways to visualise them.** Also we will be performing the the hypothesis testing using chi-square.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### List of Hypothesis to check under this combination\n1.   Are females less likely to churn than males?\n2.   Are young customers more likely to churn?\n3.   Are customers in the lower income bracket more likely to churn?\n4.   Are customers with dependent(s) less likely to churn?\n5.   Customers with an average family size less than 4 are more likely to churn?\n6.   Customers whose last transaction was more than 6 months ago, do they have higher churn rate?\n7.   Possibility that cities and branch code with very few accounts may lead to churning.\n\n**Missing Values** - finding behaviour\n\n**Gender**: \n  *  Do missing values churn more?\n\n**Dependents**:\n  *  Do missing values have any relation with churn?\n\n**Occupation:**\n   * Do they have some relation with churn?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def BVA_categorical_plot(data, tar, cat):\n  '''\n  take data and two categorical variables,\n  calculates the chi2 significance between the two variables \n  and prints the result with countplot & CrossTab\n  '''\n  #isolating the variables\n  data = data[[cat,tar]][:]\n\n  #forming a crosstab\n  table = pd.crosstab(data[tar],data[cat],)\n  f_obs = np.array([table.iloc[0][:].values,\n                    table.iloc[1][:].values])\n\n  #performing chi2 test\n  from scipy.stats import chi2_contingency\n  chi, p, dof, expected = chi2_contingency(f_obs)\n  \n  #checking whether results are significant\n  if p<0.05:\n    sig = True\n  else:\n    sig = False\n\n  #plotting grouped plot\n  sns.countplot(x=cat, hue=tar, data=data)\n  plt.title(\"p-value = {}\\n difference significant? = {}\\n\".format(round(p,8),sig))\n\n  #plotting percent stacked bar plot\n  #sns.catplot(ax, kind='stacked')\n  ax1 = data.groupby(cat)[tar].value_counts(normalize=True).unstack()\n  ax1.plot(kind='bar', stacked='True',title=str(ax1))\n  int_level = data[cat].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 1. Are females less likely to churn than males?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"BVA_categorical_plot(data, 'churn', 'gender')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Result:**\n\nthe difference between the males and females customer churning is significant. Males churn significantly more than females.\n\n**this info can be used to generate new feature.**\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 2. Are young customers more likely to churn?\nFor this I will be making 4 segments:\n1. young\n2. adult\n3. senior citizen\n4. very old","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# segregating customers into segments\nchurn = data[['churn','age']][:]\nchurn['age_group'] = 'str'\nchurn['age_group'][churn['age']>=80] = 'very old'\nchurn['age_group'][(churn['age']<80) & (churn['age']>=60)] = 'senior citizen'\nchurn['age_group'][(churn['age']<60) & (churn['age']>=18)] = 'adult'\nchurn['age_group'][churn['age']<18] = 'young'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BVA_categorical_plot(churn, 'churn', 'age_group')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Result**:\nAge group has significant effect on the churning rate. Each group has a significantly different churning rate with respect to the expected churning rate (20/80 approx)\n\n**This info can be used to generate new features**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 3. Customers from low income bracket more likely to churn","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"BVA_categorical_plot(data, 'churn', 'customer_nw_category')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Result:**\n\nDifferent income brackets have significant effect on the churn rate.\n\n**This information can be used for feature engineering**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 4,5. Are customers with dependent(s) less likely to churn?\nFor this I am making 4 segments:\n1. single\n2. small family\n3. large family\n6. joint family","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# segregating dependents into categories\ndependents = data[['churn','dependents']][:]\ndependents.dropna(inplace=True)\ndependents['dep_group'] = None\ndependents['dep_group'][dependents['dependents']==0] = 'single'\ndependents['dep_group'][(dependents['dependents']>=1) & (dependents['dependents']<=3)] = 'small family'\ndependents['dep_group'][(dependents['dependents']>=4) & (dependents['dependents']<=9)] = 'large family'\ndependents['dep_group'][(dependents['dependents']>=10)] = 'joint family'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BVA_categorical_plot(dependents, 'churn', 'dep_group')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Result:**\n\nNumber of dependents also play significant role in churning.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 7. Possibility that cities and branch code with very few accounts may lead to churning.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### City : Isolating cities with less than 1% of total customers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting city codes which have less than 280 (1%) of accounts\ntmp = data['city'].value_counts()[:]\ncities = tmp[tmp<280].index\n\nchurn_acc = data[['churn','city']][:]\nchurn_acc['city_cat'] = None\nchurn_acc['city_cat'][churn_acc['city'].isin(cities[:])] = 'low accounts'\nchurn_acc['city_cat'][~churn_acc['city'].isin(cities[:])] = 'high accounts'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BVA_categorical_plot(churn_acc, 'churn', 'city_cat')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Result**\n\ncities having less than 1 percent of the total have significantly lower churn rates as compared to the cities with more accounts. This is contrary to what we assumed.\n\nthis information can be used to generate new feature.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Branch code: Isolating branches with less than 0.5%of accounts","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting branch codes with more than 0.5% of total accounts\ntmp = data['branch_code'].value_counts()[:]\nbranch = tmp[tmp<140].index\n\n# making two segments\nchurn_acc = data[['churn','branch_code']][:]\nchurn_acc['branch_cat'] = None\nchurn_acc['branch_cat'][churn_acc['branch_code'].isin(branch[:])] = 'low accounts'\nchurn_acc['branch_cat'][~churn_acc['branch_code'].isin(branch[:])] = 'high accounts'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BVA_categorical_plot(churn_acc, 'churn', 'branch_cat')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Result**\n\nHere we see that the branches with low number of accounts do not have any significant difference from the branches with higher number of accounts.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Missing Values : Gender\nTo check whether the missing values in gender have some common behaviour among themselves.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# isolating rows with missing gender\nmiss_gender = data[:]\nmiss_gender['missing_gender'] = 'not_missing'\nmiss_gender['missing_gender'][~miss_gender['gender'].isin(['Male','Female'])] = 'missing value'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BVA_categorical_plot(miss_gender, 'churn', 'missing_gender')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**There is no diffrent behaviour of the missing values in gender wrt churn variable. Or in other words, male and female customers are equally likely to churn.**\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Missing Values : Dependents\nWhether the missing values in dependents have some common behavior among themselves.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# isolating rows with missing gender\nmiss_dependents = data[:]\nmiss_dependents['missing_dependents'] = 'not_missing'\nmiss_dependents['missing_dependents'][~miss_dependents['dependents'].isin([0, 2, 3, 1, 7, 4,\n                                                                           6, 5, 9, 52, 36, 50,\n                                                                           8, 25, 32])] = 'missing value'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BVA_categorical_plot(miss_dependents, 'churn', 'missing_dependents')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"**Result**\nthe missing values in gender have significantly higher churn rate.\n\nWe can make a new feature for this","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Missing values : Occupation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# isolating rows with missing gender\nmiss_occupation = data[:]\nmiss_occupation['missing_occupation'] = 'not_missing'\nmiss_occupation['missing_occupation'][~miss_occupation['occupation'].isin(['self_employed',\n                                                                           'salaried',\n                                                                           'retired',\n                                                                           'student',\n                                                                           'company'])] = 'missing value'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BVA_categorical_plot(miss_occupation, 'churn', 'missing_occupation')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Missing values in occupation does not have any significantly different relation with churn rate.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Summary of Bivariare Analysis:\n\n### numerical numerical\n1. Transactional variables, balance variables, previous quarter variables have strong correlations among themselves. This can be used to generate a bunch of meaningful new features.\n\n### Numerical Categorical\n1. Customers who are mantaining a higher balance in their accounts are actually more susceptible to churning.\n2. The customers who churned drastically dropped their balance in the most recent month. (which validates the definition of churn).\n\n### Categorical categorical\n1. Rate of churning among the different age groups vary significantly.\n2. Different age brackets also affect the rate of churning.\n3. Number of dependents also affect the churning rate significantly.\n\n### Things to investigate further in Multivariate Analysis:\n* Whether there are any independent (or combination of them) variables which can explain missing values or outliers. (this will govern the preprocessing step)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The succeeding notebook addressing the multivariate analysis and other miscellaneous analysis can be found at...\n\n<Link>","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}