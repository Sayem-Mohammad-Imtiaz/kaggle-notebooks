{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Purpose\n\nI have no background whatsoever on medicine. So just to approach the dataset, I decided to train a Word2Vec so I can get around the jargon\n\nI'm training the model. Will share the trained binaries once it finishes training\n\n# Pretrained model\n\nYou can download the pretrained model from [here](https://www.kaggle.com/elsonidoq/covid19-challenge-trained-w2v-model)\n\nLoad the model with [this code](https://www.kaggle.com/elsonidoq/checkout-the-covid-19-word2vec-model)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path\n\nDATA_PATH = Path('/kaggle/input/CORD-19-research-challenge/2020-03-13/')\nJUST_SOME = True # helpful for testing the code with small data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm.auto import tqdm\n\nimport json\n\ndef iter_texts():\n    \"\"\"\n    Iterate over all directories, all file names, and yield all elements on body_text and abstract\n    \"\"\"\n    dirs = 'comm_use_subset noncomm_use_subset pmc_custom_license biorxiv_medrxiv'.split()\n    for dir in dirs:\n        fnames = (DATA_PATH / dir / dir).glob('*')\n        for fname in fnames:\n            with fname.open() as f:\n                content = json.load(f)\n                \n            for key in 'abstract body_text'.split():\n                for row in content[key]:\n                    yield row['text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import spacy\n\n# make sure to run python3 -m spacy download en_core_web_sm\nnlp = spacy.load(\"en_core_web_sm\")\n\ndef iter_sents(just_some=False):\n    \"\"\"\n    Use spacy to tokenize what's yielded by iter_sents\n    \"\"\"\n    for i, text in enumerate(iter_texts()):\n        if just_some and i == 1000: break\n        doc = nlp(text)\n        for sent in doc.sents:\n            yield [t.text.lower() for t in sent if not t.is_stop and t.is_alpha and len(t.text) > 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\n\n# dump on a jsonlines file so we do the tokenization just once\nwith open('all_sentences.jl', 'w') as f:\n    for i, sent in enumerate(tqdm(iter_sents(just_some=JUST_SOME))):\n        if i > 0: f.write('\\n')\n        f.write(json.dumps(sent))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CachedSentenceIterator:\n    \"\"\"\n    An iterator that is compatible with gensim (you need to be able to iterate this more than once for the epochs to work)\n    \"\"\"\n    def __init__(self, just_some=False, fname='all_sentences.jl'): \n        self.just_some = just_some\n        self.fname = fname\n    \n    def __iter__(self):\n        with open(self.fname) as f:\n            for line in f:\n                yield json.loads(line)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from gensim.models import Word2Vec\n\nsi = CachedSentenceIterator(just_some=JUST_SOME)\n\nmodel = Word2Vec()\nmodel.build_vocab(sentences=tqdm(si))\nmodel.train(tqdm(si), total_examples=model.corpus_count, epochs=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('covid.w2v')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.wv.most_similar('virus')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.wv.most_similar('coronavirus')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}