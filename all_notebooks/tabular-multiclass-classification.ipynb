{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\nimport  matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset,DataLoader,WeightedRandomSampler\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'quality', data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class2idx = {\n    3:0,\n    4:1,\n    5:2,\n    6:3,\n    7:4,\n    8:5\n}\n\nidx2class = {v: k for k, v in class2idx.items()}\n\ndf['quality'].replace(class2idx, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.iloc[:,0:-1]\ny = df.iloc[:,-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split into train+val and test\n\nX_trainval , X_test, y_trainval, y_test = train_test_split(X,y,test_size=0.2, stratify = y, random_state=69)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split train into train-val \nX_train,X_val,y_train,y_val = train_test_split(X_trainval,y_trainval,test_size=0.1, stratify=y_trainval, random_state = 21)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)\nX_test = scaler.transform(X_test)\n\nX_train,y_train = np.array(X_train),np.array(y_train)\nX_val, y_val = np.array(X_val),np.array(y_val)\nX_test, y_test = np.array(X_test),np.array(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_class_distribution(obj):\n    count_dict = {\n        \"rating_3\":0,\n        \"rating_4\": 0,\n        \"rating_5\": 0,\n        \"rating_6\": 0,\n        \"rating_7\": 0,\n        \"rating_8\": 0,\n    }\n    \n    for i in obj:\n        if i == 0:\n            count_dict['rating_3'] += 1\n        elif i  == 1:\n            count_dict['rating_4'] += 1\n        elif i == 2:\n            count_dict['rating_5'] += 1\n        elif i == 3:\n            count_dict['rating_6'] += 1\n        elif i == 4:\n            count_dict['rating_7'] += 1\n        elif i == 5:\n            count_dict['rating_8'] += 1\n        else:\n            print(\"Check classes.\")\n    return count_dict        \n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,axes = plt.subplots(nrows=1,ncols=3,figsize=(25,7))\n\n# Train\nsns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(y_train)]).melt(), x=\"variable\",\n            y = \"value\", hue=\"variable\",ax=axes[0]).set_title('Class Distribution in Train Set')\n\n# Validation\nsns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(y_val)]).melt(), x=\"variable\",\n           y = \"value\", hue=\"variable\", ax=axes[1]).set_title('Class Distribution in Val Set')\n\n# Test\nsns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(y_test)]).melt(), x=\"variable\",\n           y = \"value\", hue = \"variable\",ax=axes[2]).set_title('Class Distribution in Test Set')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ClassifierDataset(Dataset):\n    def __init__(self,X_data,y_data):\n        self.X_data = X_data\n        self.y_data = y_data\n        \n    def __getitem__(self,index):\n        return self.X_data[index], self.y_data[index]\n    \n    def __len__(self):\n        return len(self.X_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = ClassifierDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\nval_dataset = ClassifierDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val).long())\ntest_dataset = ClassifierDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_list = []\n\nfor _, t in train_dataset:\n    target_list.append(t)\n    \ntarget_list = torch.tensor(target_list)\ntarget_list = target_list[torch.randperm(len(target_list))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_count = [i for i in get_class_distribution(y_train).values()]\nclass_weights = 1./torch.tensor(class_count, dtype = torch.float)\n\nprint(class_weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weights_all = class_weights[target_list]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weights_all","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weighted_sampler = WeightedRandomSampler(weights = class_weights_all, num_samples = len(class_weights_all),\n                                        replacement = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weighted_sampler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 300\nBATCH_SIZE = 6\nLEARNING_RATE =  0.01\nNUM_FEATURES = len(X.columns)\nNUM_CLASSES = 6","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(dataset = train_dataset, batch_size = BATCH_SIZE, sampler = weighted_sampler)\nval_loader = DataLoader(dataset  = val_dataset, batch_size = 1)\ntest_loader = DataLoader(dataset = test_dataset, batch_size = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MultiClassClassification(nn.Module):\n    def __init__(self,num_feature,num_class):\n        super(MultiClassClassification,self).__init__()\n        self.layer1 =nn.Linear(num_feature,512)\n        self.layer2 = nn.Linear(512,128)\n        self.layer3 = nn.Linear(128,64)\n        self.layer_out = nn.Linear(64,num_class)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=0.2)\n        self.batchnorm1 = nn.BatchNorm1d(512)\n        self.batchnorm2 = nn.BatchNorm1d(128)\n        self.batchnorm3 = nn.BatchNorm1d(64)\n        \n    def forward(self,x):\n        x = self.layer1(x)\n        x = self.batchnorm1(x)\n        x = self.relu(x)\n        x = self.layer2(x)\n        x = self.batchnorm2(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.layer3(x)\n        x = self.batchnorm3(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.layer_out(x)\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = MultiClassClassification(num_feature = NUM_FEATURES, num_class = NUM_CLASSES)\nmodel.to(device)\n\ncriterion = nn.CrossEntropyLoss(weight = class_weights.to(device))\noptimizer = optim.Adam(model.parameters(),lr = LEARNING_RATE)\nprint(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def multi_acc(y_pred,y_test):\n    y_pred_softmax = torch.log_softmax(y_pred,dim=1)\n    _,y_pred_tags = torch.max(y_pred_softmax,dim=1)\n    correct_pred = (y_pred_tags == y_test).float()\n    acc = correct_pred.sum() / len(correct_pred)\n    acc = torch.round(acc)*100\n    return acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_stats = {\n    'train': [],\n    'val': []\n}\n\nloss_stats = {\n    \"train\": [],\n    \"val\": []\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Begin Training')\n\nfor e in tqdm(range(1,EPOCHS+1)):\n    #  training\n    train_epoch_loss = 0\n    train_epoch_acc = 0\n    model.train()\n    for X_train_batch , y_train_batch in train_loader:\n        X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n        optimizer.zero_grad()\n        y_train_pred = model(X_train_batch)\n        train_loss = criterion(y_train_pred, y_train_batch)\n        train_acc = multi_acc(y_train_pred, y_train_batch)\n        train_loss.backward()\n        optimizer.step()\n        \n        train_epoch_loss += train_loss.item()\n        train_epoch_acc += train_acc.item()\n        \n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Validation\n\nwith torch.no_grad():\n    val_epoch_loss = 0\n    val_epoch_acc = 0\n    \n    model.eval()\n    \n    for X_val_batch,y_val_batch in val_loader:\n        X_val_batch , y_val_batch = X_val_batch.to(device),y_val_batch.to(device)\n        y_val_pred = model(X_val_batch)\n        val_loss = criterion(y_val_pred, y_val_batch)\n        val_acc = multi_acc(y_val_pred, y_val_batch)\n        \n        val_epoch_loss += val_loss.item()\n        val_epoch_acc += val_acc.item()\n        \n        loss_stats['train'].append(train_epoch_loss/len(train_loader))\n        loss_stats['val'].append(val_epoch_loss/len(val_loader))\n        accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n        accuracy_stats['val'].append(val_epoch_acc/len(val_loader))\n        print(f\"epoch {e+0.03}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | val Loss :{val_epoch_loss/len(val_loader):.5f} | Train Acc : {train_epoch_acc/len(train_loader):.3f} | Val Acc:{val_epoch_acc/len(val_loader):.3f}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create DataFrame\n\ntrain_val_acc_df = pd.DataFrame.from_dict(accuracy_stats).reset_index().melt(id_vars = ['index']).rename(columns={\"index\":\"epochs\"})\n\ntrain_val_loss_df = pd.DataFrame.from_dict(loss_stats).reset_index().melt(id_vars=['index']).rename(columns={'index':'epochs'})\n\n# Plot the dataframe\nfig,axes = plt.subplots(nrows=1,ncols=2,figsize=(20,7))\n\nsns.lineplot(data = train_val_acc_df ,x = \"epochs\", y = \"value\", hue=\"variable\",ax=axes[0]).set_title('Train-Val Accuracy/Epoch')\n\nsns.lineplot(data = train_val_loss_df, x = \"epochs\",y =\"value\", hue=\"variable\",ax=axes[1]).set_title('Train-Val Loss/Epoch')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing the Model****"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_list = []\n\nwith torch.no_grad():\n    model.eval()\n    for X_batch,_ in test_loader:\n        X_batch = X_batch.to(device)\n        y_test_pred = model(X_batch)\n        _,y_pred_tags = torch.max(y_test_pred,dim=1)\ny_pred_list.append(y_pred_tags.cpu().numpy())\ny_pred_list  = [a.squeeze().tolist() for a in y_pred_list]    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_list","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}