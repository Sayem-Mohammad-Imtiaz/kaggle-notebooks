{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Kensho Derived Wikimedia Dataset (KDWD) - Wikidata Introduction\n\nThis notebook will introduce you to the Wikidata Sample of the Kensho Derived Wikimedia Dataset (KDWD).  We'll explore the files and make some basic \"getting to know you\" plots.  Lets start off by importing some packages."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from collections import Counter\nimport csv\nimport gc\nimport json\nimport os\n\nimport matplotlib.pyplot as plt\nimport networkx as nx\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"pd.set_option('max_colwidth', 160)\nsns.set()\nsns.set_context('talk')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next we'll check the input directory to see what files we have access to. "},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All of the KDWD files have one \"thing\" per line.  We'll hard code the number of lines in the files we're going to use so we can have nice progress bars when streaming through them."},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_STATEMENT_LINES = 141_206_854\nNUM_ITEM_LINES = 51_450_317\nkdwd_path = os.path.join(\"/kaggle/input\", \"kensho-derived-wikimedia-data\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Properties\nWe'll begin by reading the property metadata."},{"metadata":{"trusted":true},"cell_type":"code","source":"file_path = os.path.join(kdwd_path, \"property.csv\")\nproperty_df = pd.read_csv(file_path, keep_default_na=False, index_col='property_id')\nproperty_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The two most important ontological properties in Wikidata are,  \n * [P31 (instance of)](https://www.wikidata.org/wiki/Property:P31)\n * [P279 (subclass of)](https://www.wikidata.org/wiki/Property:P279)"},{"metadata":{"trusted":true},"cell_type":"code","source":"property_df.loc[31, 'en_description']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"property_df.loc[279, 'en_description']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ontological Statements \nNow we will move on to statements. In order to stay within the 16GB RAM limit of this kernel, we will focus on the ontological statements in Wikidata. Remember that statements are triples of the form (source item, property, target item). Lets read just the `P31 (instance of)` and `P279 (subclass of)` statements from `statements.csv`"},{"metadata":{"trusted":true},"cell_type":"code","source":"file_path = os.path.join(kdwd_path, \"statements.csv\")\nchunksize = 1_000_000\nqpq_df_chunks = pd.read_csv(file_path, chunksize=chunksize)\nqpq_p31_df = pd.DataFrame()\nqpq_p279_df = pd.DataFrame()\nfor qpq_df_chunk in tqdm(qpq_df_chunks, total=NUM_STATEMENT_LINES/chunksize, desc='reading ontology statements'):\n    qpq_p31_df = pd.concat([\n        qpq_p31_df, \n        qpq_df_chunk[qpq_df_chunk['edge_property_id']==31][['source_item_id', 'target_item_id']]\n    ])\n    qpq_p279_df = pd.concat([\n        qpq_p279_df, \n        qpq_df_chunk[qpq_df_chunk['edge_property_id']==279][['source_item_id', 'target_item_id']]\n    ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# instance of statements\nqpq_p31_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# subclass of statements\nqpq_p279_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Engish Labels and Descriptions\nNow lets read the English labels and descriptions for the items that are in our ontological statement DataFrames. "},{"metadata":{"trusted":true},"cell_type":"code","source":"keep_p279_ids = (\n    set().\n    union(set(qpq_p279_df['source_item_id'].values)).\n    union(set(qpq_p279_df['target_item_id'].values))\n)\n\nkeep_p31_ids = (\n    set().\n    union(set(qpq_p31_df['source_item_id'].values)).\n    union(set(qpq_p31_df['target_item_id'].values))\n)\n\nkeep_item_ids = keep_p279_ids.union(keep_p31_ids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file_path = os.path.join(kdwd_path, \"item.csv\")\nchunksize = 1_000_000\nitem_df_chunks = pd.read_csv(\n    file_path, chunksize=chunksize, index_col='item_id', keep_default_na=False)\nitem_df = pd.DataFrame()\nfor item_df_chunk in tqdm(item_df_chunks, total=NUM_ITEM_LINES/chunksize, desc='reading item labels'):\n    item_df = pd.concat([\n        item_df, \n        item_df_chunk.loc[set(item_df_chunk.index.values).intersection(keep_item_ids)]\n    ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notice that not every item has a label and description in English."},{"metadata":{"trusted":true},"cell_type":"code","source":"item_df[item_df['en_label']=='']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The first item without an English label or description is Q7868.  At the time this kernel was run (2020-01-31), the live Wikidata page (https://www.wikidata.org/wiki/Q7868) indicated that the label for this item was \"cell\", the description was \"the basic structural and functional unit of all organisms\", and the linked English Wikipedia page was https://en.wikipedia.org/wiki/Cell_(biology).  The full edit histoy of every Wikidata item is available for anyone to view, so lets investigate. The edit history for Q7868 can be viewed at https://www.wikidata.org/w/index.php?title=Q7868&action=history.  The Wikidata dump for the KDWD was made on 2019-12-02, and we can see that someone vandalized the page on 2019-12-01 and that it was reverted on 2019-12-03.  This is a good example of the pros and the cons of working with crowd-sourced data!  However, not all empty English descriptions are vandalism.  The next item that is empty is Q44423.  Visiting the Wikidata page (https://www.wikidata.org/wiki/Q44423) indicated that it had labels in Japanese, Korean, and Chinese but not in English. "},{"metadata":{},"cell_type":"markdown","source":"Also, note that the English labels of Wikidata items are not unique. "},{"metadata":{"trusted":true},"cell_type":"code","source":"item_df[item_df['en_label']=='city']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# instance of what?\nNow lets examine the `P31 (instance of)` statements.  Grouping them by `target_item_id` will show us the most common things in our sample. "},{"metadata":{"trusted":true},"cell_type":"code","source":"is_instance_counts = (\n    qpq_p31_df.groupby(['target_item_id']).\n    size().\n    sort_values(ascending=False).\n    to_frame().\n    rename(columns={0: 'is_instance_count'})\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"is_instance_counts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That's great, but lets merge that with the `item_df` DataFrame so we can see labels and descriptions."},{"metadata":{"trusted":true},"cell_type":"code","source":"is_instance_df = pd.merge(\nis_instance_counts,\nitem_df,\nleft_index=True,\nright_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"is_instance_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the most common use of the [P31 (instance of)](https://www.wikidata.org/wiki/Property:P31) property is to indicate that an item is an instance of [Q5 (human)](https://www.wikidata.org/wiki/Q5).  There are 6,221,695 humans in our Wikidata sample but only 5.3 million pages total in our Wikipedia sample.  This indicates that many of these humans are on the target side of statements as opposed to the source side. The second most common target is [Q16521 (taxon)](https://www.wikidata.org/wiki/Q16521). For example [Q33609 (polar bear)](https://www.wikidata.org/wiki/Q33609) is an instance of taxon and the polar bear item has statements about the [P105 (taxon rank)](https://www.wikidata.org/wiki/Property:P105) being [Q7432 (species)](https://www.wikidata.org/wiki/Q7432), and the [P171 (parent taxon)](https://www.wikidata.org/wiki/Property:P171) being [Q243359 (Ursus)](https://www.wikidata.org/wiki/Q243359). "},{"metadata":{},"cell_type":"markdown","source":"# A Closer Look at One Item\nLets take a closer look at the instance of statements for one item, [Q61 (Washington, D.C.)](https://www.wikidata.org/wiki/Q61)."},{"metadata":{"trusted":true},"cell_type":"code","source":"item_id = 61\np31_for_q61 = qpq_p31_df[qpq_p31_df['source_item_id']==item_id]\np31_for_q61","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_df.reindex(p31_for_q61['target_item_id'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we see that there are four instance of statements with the following target items, \n * [Q5119 (capital)](https://www.wikidata.org/wiki/Q5119)\n * [Q475050 (federal district)](https://www.wikidata.org/wiki/Q475050)\n * [Q1093829 (city of the United States)](https://www.wikidata.org/wiki/Q1093829)\n * [Q1549591 (big city)](https://www.wikidata.org/wiki/Q1549591)\n \nNote that [Q5119 (capital)](https://www.wikidata.org/wiki/Q5119) and [Q475050 (federal district)](https://www.wikidata.org/wiki/Q475050) have associated English Wikipedia pages while [Q1093829 (city of the United States)](https://www.wikidata.org/wiki/Q1093829) and [Q1549591 (big city)](https://www.wikidata.org/wiki/Q1549591) do not."},{"metadata":{},"cell_type":"markdown","source":"# \"Subclass of\" Subgraph\nNow lets build a networkx directed graph from the [P279 (subclass of)](https://www.wikidata.org/wiki/Property:P279) statements and draw a small part of it around [Q1093829 (city of the United States)](https://www.wikidata.org/wiki/Q1093829)."},{"metadata":{"trusted":true},"cell_type":"code","source":"subclass_graph = nx.DiGraph()\nsubclass_graph.add_edges_from(qpq_p279_df.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets examine the `out_edges` and the `in_edges` for [Q1093829 (city of the United States)](https://www.wikidata.org/wiki/Q1093829).  `out_edges` will show us things that `Q1093829 (city of the United States)` is a subclass of while `in_edges` will show us things that are subclass of `Q1093829 (city of the United States)`."},{"metadata":{"trusted":true},"cell_type":"code","source":"item_id = 1093829 # city of the United States\nin_edges = subclass_graph.in_edges(item_id)\nout_edges = subclass_graph.out_edges(item_id)\n\nprint('out edges')\nprint('-' * 20)\nfor source_item_id, target_item_id in out_edges:\n    print('Q{} (label={}, description={})\\n is subclass of\\nQ{} (label={}, description={})'.format(\n        source_item_id,\n        item_df.loc[source_item_id, 'en_label'],\n        item_df.loc[source_item_id, 'en_description'],\n        target_item_id,\n        item_df.loc[target_item_id, 'en_label'],\n        item_df.loc[target_item_id, 'en_description']))\n    print()\n\nprint('in edges')\nprint('-' * 20)\nfor source_item_id, target_item_id in in_edges:\n    print('Q{} (label={}, description={})\\n is subclass of\\nQ{} (label={}, description={})'.format(\n        source_item_id,\n        item_df.loc[source_item_id, 'en_label'],\n        item_df.loc[source_item_id, 'en_description'],\n        target_item_id,\n        item_df.loc[target_item_id, 'en_label'],\n        item_df.loc[target_item_id, 'en_description']))\n    print()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now lets build a subgraph around the neighborhood of `Q1093829 (city of the United States)` and draw it. Remember, we are still only looking at `subclass of` statements."},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_neighborhood(graph, start_qid, k_max):\n    subnodes = set([start_qid])\n    for k in range(k_max):\n        nodes_to_add = set()\n        for qid in subnodes:\n            nodes_to_add.update(graph.neighbors(qid))\n        subnodes.update(nodes_to_add)\n    return graph.subgraph(subnodes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_attributes_to_graph(graph, item_df):\n    for node in graph:\n        graph.nodes[node]['qid'] = node\n        graph.nodes[node]['label'] = item_df.loc[node, 'en_label']\n        graph.nodes[node]['description'] = item_df.loc[node, 'en_description']\n    return graph","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_graph(graph):\n    fig, ax = plt.subplots(figsize=(14,14))\n    pos = nx.circular_layout(graph, scale=2.0)\n\n    node_labels = nx.get_node_attributes(graph, 'label')\n    nx.draw_networkx_labels(graph, pos, labels=node_labels, font_size=18, font_weight=1000)\n    nx.draw_networkx_nodes(graph, pos, node_size=800, node_color='red')\n    nx.draw_networkx_edges(graph, pos, arrowsize=30, min_target_margin=20)\n\n    xpos = [el[0] for el in pos.values()]\n    xmin = min(xpos)\n    xmax = max(xpos)\n    ypos = [el[1] for el in pos.values()]\n    ymin = min(ypos)\n    ymax = max(ypos)\n\n    xdif = xmax - xmin\n    ydif = ymax - ymin\n    fac = 0.3\n\n    ax.set_xlim(xmin-xdif*fac, xmax+xdif*fac)\n    ax.set_ylim(ymin-ydif*fac, ymax+ydif*fac)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_qid = 1093829\nk_max = 2\nsg = build_neighborhood(subclass_graph, start_qid, k_max)\nsg = add_attributes_to_graph(sg, item_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_graph(sg)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}