{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import torch\n# TORCH = torch.__version__\n# CUDA = torch.version.cuda if torch.version.cuda is not None else \"cpu\"\n# !pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-${TORCH}+${CUDA}.html --quiet\n# !pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-${TORCH}+${CUDA}.html --quiet\n# !pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-${TORCH}+${CUDA}.html --quiet\n# !pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-${TORCH}+${CUDA}.html --quiet\n# !pip install torch-geometric --quiet\n# !pip install \"gif[plotly]\" --quiet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+cu102.html --quiet\n!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cu102.html --quiet\n!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.7.0+cu102.html --quiet\n!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.7.0+cu102.html --quiet\n!pip install torch-geometric==1.6.3 --quiet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\n\nimport networkx as nx\n\nimport torch\n\nfrom torch_geometric.data import Data\nfrom torch_geometric.nn import Node2Vec\nfrom torch_geometric.utils import degree\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.manifold import TSNE\n\nimport plotly.graph_objects as go\n\nimport json\nimport pickle","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bio_decagon_combo = pd.read_csv(\"../input/dpi-dataset/bio-decagon-combo.csv\")\nbio_decagon_ppi = pd.read_csv(\"../input/dpi-dataset/bio-decagon-ppi.csv\")\nbio_decagon_targets_all = pd.read_csv(\"../input/dpi-dataset/bio-decagon-targets-all.csv\")\nbio_decagon_targets = pd.read_csv(\"../input/dpi-dataset/bio-decagon-targets.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"edge_type_mapping = np.stack(\n    (\n        np.array(bio_decagon_combo.groupby([\"Polypharmacy Side Effect\"]).ngroup()),\n        np.array(bio_decagon_combo[\"Polypharmacy Side Effect\"]),\n    ),\n    axis=1,\n)\n\nedge_type_mapping = edge_type_mapping[edge_type_mapping[:, 0].argsort()]\nedge_type_mapping = dict((value, key) for key, value in edge_type_mapping)\n\nedge_type_mapping[\"ppi\"] = edge_type_mapping[list(edge_type_mapping.keys())[-1]] + 1\nedge_type_mapping[\"target\"] = edge_type_mapping[\"ppi\"] + 1\nedge_type_mapping[\"targeted_by\"] = edge_type_mapping[\"target\"] + 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drug_nodes_mapping = dict(\n    (drug, i)\n    for i, drug in enumerate(\n        np.unique(\n            np.append(\n                np.array(bio_decagon_combo[\"STITCH 1\"]),\n                np.array(bio_decagon_combo[\"STITCH 2\"]),\n            )\n        )\n    )\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"protein_nodes_mapping = dict(\n    (uniprot, i)\n    for i, uniprot in enumerate(\n        np.unique(\n            np.append(\n                np.array(bio_decagon_ppi[\"Gene 1\"]),\n                np.array(bio_decagon_ppi[\"Gene 2\"]),\n            )\n        )\n    )\n)\n\nprotein_nodes_mapping = dict(\n    (key, value + drug_nodes_mapping[list(drug_nodes_mapping.keys())[-1]] + 1)\n    for key, value in protein_nodes_mapping.items()\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"G = nx.DiGraph()\nfor i in drug_nodes_mapping.values():\n    G.add_node(i, type=\"Drug\")\nfor i in protein_nodes_mapping.values():\n    G.add_node(i, type=\"Protein\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"row = []\ncol = []\n\nedge_meta_type = []\nedge_type = []\n\nfor drug_i, drug_j, edge_type_i_j in zip(bio_decagon_combo[\"STITCH 1\"], bio_decagon_combo[\"STITCH 2\"], bio_decagon_combo[\"Polypharmacy Side Effect\"]):\n    row.append(drug_nodes_mapping[drug_i])\n    col.append(drug_nodes_mapping[drug_j])\n    edge_type.append(edge_type_mapping[edge_type_i_j])\n    edge_meta_type.append(1)\n    \n    row.append(drug_nodes_mapping[drug_j])\n    col.append(drug_nodes_mapping[drug_i])\n    edge_type.append(edge_type_mapping[edge_type_i_j])\n    edge_meta_type.append(1)\n    \n    G.add_edge(drug_nodes_mapping[drug_i], drug_nodes_mapping[drug_j], relation=edge_type_mapping[edge_type_i_j])\n    G.add_edge(drug_nodes_mapping[drug_j], drug_nodes_mapping[drug_i], relation=edge_type_mapping[edge_type_i_j])\n    \nfor uniprot_i, uniprot_j in zip(bio_decagon_ppi[\"Gene 1\"], bio_decagon_ppi[\"Gene 2\"]):\n    row.append(protein_nodes_mapping[uniprot_i])\n    col.append(protein_nodes_mapping[uniprot_j])\n    edge_type.append(edge_type_mapping[\"ppi\"])\n    edge_meta_type.append(2)\n    \n    row.append(protein_nodes_mapping[uniprot_j])\n    col.append(protein_nodes_mapping[uniprot_i])\n    edge_type.append(edge_type_mapping[\"ppi\"])\n    edge_meta_type.append(2)\n    \n    G.add_edge(protein_nodes_mapping[uniprot_i], protein_nodes_mapping[uniprot_j], relation=edge_type_mapping[\"ppi\"])\n    G.add_edge(protein_nodes_mapping[uniprot_j], protein_nodes_mapping[uniprot_i], relation=edge_type_mapping[\"ppi\"])\n    \nfor drug_i, uniprot_j in zip(bio_decagon_targets[\"STITCH\"], bio_decagon_targets[\"Gene\"]):\n    if uniprot_j not in protein_nodes_mapping.keys():\n        continue # about 10 proteins are in targets, but not in ppi network, so we are skipping them\n    row.append(drug_nodes_mapping[drug_i])\n    col.append(protein_nodes_mapping[uniprot_j])\n    edge_type.append(edge_type_mapping[\"target\"])\n    edge_meta_type.append(3)\n    \n    row.append(protein_nodes_mapping[uniprot_j])\n    col.append(drug_nodes_mapping[drug_i])\n    edge_type.append(edge_type_mapping[\"targeted_by\"])\n    edge_meta_type.append(4)\n    \n    G.add_edge(protein_nodes_mapping[uniprot_j], drug_nodes_mapping[drug_i], relation=edge_type_mapping[\"targeted_by\"])\n    G.add_edge(drug_nodes_mapping[drug_i], protein_nodes_mapping[uniprot_j], relation=edge_type_mapping[\"target\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def random_init(feat_len, distribution):\n    features = []\n    \n    (mu_uniprot, sigma_uniprot, mu_drug, sigma_drug) = distribution\n    \n    for node in G.nodes():\n        if G.nodes[node][\"type\"] == \"Protein\":\n            features.append(np.random.normal(mu_uniprot, sigma_uniprot, feat_len))\n        elif G.nodes[node][\"type\"] == \"Drug\":\n            features.append(np.random.normal(mu_drug, sigma_drug, feat_len))\n        else:\n            raise Exception(f\"\"\"{G.nodes[node][\"type\"]}, This node type doesnt exist!\"\"\")\n            \n    return features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_init_features(cheat=False, random=False, feat_len=10, distribution=(0, 1, 5, 2)):\n    \"\"\"\n    Make initial feature embedding for each node\n    \n    cheat(default = False): whether at test time a node knows how many total nodes it is connected to or not.\n    random(default = False): whether to form random feature embeddings for nodes.\n    feat_len(default = 10): size of init embedding for each node. Only used when random=True\n    distribution(default = mu_uniprot:0, sigma_uniprot:1, mu_drug:5, sigma_drug:2): distributional properties of the normal distribution from which the samples will be chosen as embeddings.\n    \"\"\"\n    \n    if random:\n        return random_init(feat_len, distribution)\n    \n    features = []\n\n    for node in G.nodes():\n        neighbors = [i for i in G.neighbors(node)]\n\n        if cheat == True:\n            features.append((G.nodes[node][\"type\"], len(neighbors)))\n\n        else:\n            count_proteins = 0\n            for neighbor in neighbors:\n                if G.nodes[neighbor][\"type\"] == \"Protein\":\n                    count_proteins += 1\n\n            features.append((G.nodes[node][\"type\"], count_proteins))\n\n    return features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cheat_encoder = OneHotEncoder(handle_unknown='ignore')\ncheat_features = cheat_encoder.fit_transform(make_init_features(cheat=True)).toarray()\ntrue_encoder = OneHotEncoder(handle_unknown='ignore')\ntrue_features = true_encoder.fit_transform(make_init_features(cheat=False)).toarray()\nrandom_features = np.array(make_init_features(random=True, feat_len=10, distribution=(-1, 0.5, 1, 0.5)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cheat_features.shape, true_features.shape, random_features.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_feat = true_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = [0  for _ in range(len(drug_nodes_mapping))]\ny.extend([1  for _ in range(len(protein_nodes_mapping))])\ny = np.array(y)\n\ntrain_mask = torch.tensor([False for _ in range(len(row))])\nval_mask = torch.tensor([False for _ in range(len(row))])\ntest_mask = torch.tensor([False for _ in range(len(row))])\n\n\nx = torch.tensor(layer_feat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"edges_ = np.stack((row, col)).T\nedge_meta_type = np.array(edge_meta_type)\ntrain_val, test = next(StratifiedShuffleSplit(test_size=0.1, random_state=0).split(edges_, edge_meta_type))\ntrain, val = next(StratifiedShuffleSplit(test_size=0.111, random_state=0).split(edges_[train_val], edge_meta_type[train_val]))\n\ntrain_mask[train] = True\nval_mask[val] = True\ntest_mask[test] = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"edge_index = torch.tensor(np.stack((row, col)))\nrow, col = torch.tensor(row), torch.tensor(col)\n\nedge_meta_type = torch.tensor(edge_meta_type)\nedge_type = torch.tensor(edge_type)\n\nnum_relations = edge_type.unique().size(0)\n\ny = torch.tensor(y)\n\nnum_nodes = len(y)\n\nedge_attr = 1.0 / degree(edge_index[1], num_nodes)[edge_index[1]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- `edge_index` stores all the edges in the dataset in the form of a 2-D tensor. Each column represents an edge formed by two nodes and the number of columns indicate the total number of edges in the dataset. For example, the first column in `edge_index` is [0, 9052], which represents an edge between node 0 and node 9052.\n- `edge_attr` contains edge attributes calulated using `1.0 / torch_geometric.utils.degree(col, num_nodes)[col]`. This attribute is used for GraphSAINT sampler. Please see [this](https://github.com/rusty1s/pytorch_geometric/blob/master/examples/graph_saint.py) and [this](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html) for reference. \n- `edge_meta_type` helps to identify the meta edge type of each edge in `edge_index`. Because drug and protein edges are directional, we use edge meta types here to do negative sampling more easily.  There are 3 meta edges. `1` represents edges between a drug and a drug, where drug is the starting node and drug is the ending node. `2` represents edges between proteins and proteins. `3` represents edges between a drug and a protein where drug is the starting node and protein is the ending node. `4` represents edges between a protein and a drug where protein is the starting node and drug is the ending node.\n- `edge_type` stores the edge type for each edge in `edge_index`. See `edge_type_mapping`.\n- `x` stores the input embeddings/attributes of each node, with dimension of 128. The main reason to use these embeddings is to decrease the input dimension for each node from 25455 to \\approx in 100s. Naively, one-hot-encoded embeddings are used to represent each node. Alternatively, one can use random Gaussian vectors as input embeddings/attributes. In applications where side feature information about nodes is available, x can be used to integrate that information into the model.\n- `y` stores the node type, where `0` represents a drug and `1` represents a protein.","metadata":{}},{"cell_type":"code","source":"data = Data(\n    edge_index=edge_index,\n    edge_attr=edge_attr,\n    edge_type=edge_type,\n    edge_meta_type=edge_meta_type,\n    x=x,\n    y=y,\n    train_mask=train_mask,\n    val_mask=val_mask,\n    test_mask=test_mask,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Node2Vec Inititial Embeddings","metadata":{}},{"cell_type":"code","source":"node2vec_model = Node2Vec(\n    data.edge_index,\n    embedding_dim=128,\n    walk_length=20,\n    context_size=10,\n    walks_per_node=10,\n    num_negative_samples=1,\n    p=1,\n    q=1,\n    sparse=True,\n).to(device)\n\nloader = node2vec_model.loader(batch_size=2048, shuffle=True, num_workers=4)\noptimizer = torch.optim.SparseAdam(list(node2vec_model.parameters()), lr=0.01)\n\n\ndef train():\n    node2vec_model.train()\n    total_loss = 0\n    for pos_rw, neg_rw in loader:\n        optimizer.zero_grad()\n        loss = node2vec_model.loss(pos_rw.to(device), neg_rw.to(device))\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    return total_loss / len(loader)\n\n\n@torch.no_grad()\ndef test():\n    node2vec_model.eval()\n    z = model()\n    acc = node2vec_model.test(\n        z[data.train_mask],\n        data.y[data.train_mask],\n        z[data.test_mask],\n        data.y[data.test_mask],\n        max_iter=150,\n    )\n    return acc\n\nnode2vec_path = \"../input/node2vec-embedding/node2vec_embeddings.h5\"\n\nif not os.path.isfile(node2vec_path):\n    for epoch in range(1, 60):\n        loss = train()\n        acc = test()\n        print(f\"Epoch: {epoch:02d}, Loss: {loss:.4f}, Acc: {acc:.4f}\") if (epoch%20 == 0) else None","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.save(model.state_dict(), \"./node2vec_ebeddings.h5\")\nnode2vec_model.load_state_dict(torch.load(node2vec_path, map_location=device))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef plot_points():\n    node2vec_model.eval()\n    z = node2vec_model(torch.arange(data.num_nodes, device=device))\n    z = TSNE(n_components=2).fit_transform(z.cpu().numpy())\n    y = data.y.cpu().numpy()\n    \n    fig = go.Figure()\n    fig.add_trace(go.Scatter(x=z[y == 0, 0], y=z[y == 0, 1], mode=\"markers\", name=\"drug\")) \n    fig.add_trace(go.Scatter(x=z[y == 1, 0], y=z[y == 1, 1], mode=\"markers\", name=\"protein\"))\n\n    fig.update_layout(autosize=False, width=700, height=700, xaxis=dict(visible=False), yaxis=dict(visible=False))\n    return fig\n\nfig = plot_points()\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"node2vec_ebeddings = node2vec_model(torch.arange(data.num_nodes, device=device)).cpu().detach()\ndata.x = node2vec_ebeddings","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(data, 'data.pt')\n\ntorch.save(edge_index, 'edge_index.pt')\ntorch.save(edge_meta_type, 'edge_meta_type.pt')\ntorch.save(edge_type, 'edge_type.pt')\ntorch.save(y, 'y.pt')\ntorch.save(edge_attr, 'edge_attr.pt')\n\ntorch.save(node2vec_ebeddings, 'node2vec_ebeddings.pt')\ntorch.save(torch.tensor(cheat_features), 'cheat_features.pt')\ntorch.save(torch.tensor(true_features), 'true_features.pt')\ntorch.save(torch.tensor(random_features), 'random_features.pt')\n\nwith open('edge_type_mapping.p', 'wb') as fp:\n    pickle.dump(edge_type_mapping, fp, protocol=pickle.HIGHEST_PROTOCOL)\nwith open('drug_nodes_mapping.p', 'wb') as fp:\n    pickle.dump(drug_nodes_mapping, fp, protocol=pickle.HIGHEST_PROTOCOL)\nwith open('protein_nodes_mapping.p', 'wb') as fp:\n    pickle.dump(protein_nodes_mapping, fp, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}