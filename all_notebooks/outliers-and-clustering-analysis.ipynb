{"cells":[{"metadata":{},"cell_type":"markdown","source":"Hello! I'm a begginer and I had the following ideia about this dataset:\n\n    What if we were asked to answer the following question: \n    Where should we place facilities in order to attend the emergency calls?\n\nTo do so, I intend to make a clustering analysis and show how outliers can be damaging in the results if not well treated. \n\nIt's a simple analysis and the main goal here is to show the importance of treating outliers in a clusterization (mainly for begginers like me). So please, don't get alarmed if something doesn't make much sense for this particular dataset.\n\nSo, this notebook has the following objectives:\n1. How to treat outliers?\n1. Make a cluster analysis (KMeans) comparing outliers with treated data  \n\n\nSummary:\n1. Loading and preparing data\n    * Quick overview of the data\n2. Treating outliers\n    * Geographic distribution of the data (using Folium)\n    * Treating outliers with Boxplot\n    * Cleaning outliers\n3. Clustering\n    * KMeans\n    * Elbow technique\n    * Treated data\n    * Non treated data\n    * Comparison\n\n\nThanks in advance. I hope you enjoy it!\n\nReferences: \n\nhttps://medium.com/analytics-vidhya/outlier-treatment-9bbe87384d02 \n\nhttps://www.scikit-yb.org/en/latest/api/cluster/elbow.html\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing libraries\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport folium as fo\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom yellowbrick.cluster import KElbowVisualizer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Loading and preparing data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#reading data\ndf=pd.read_csv('/kaggle/input/montcoalert/911.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A quick loock in the data\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating columns that might be useful\ndf['timeStamp']=df['timeStamp'].apply(pd.Timestamp)\ndf['Year']=df.timeStamp.dt.year\ndf['Month']=df.timeStamp.dt.month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Year'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#since 2015 and 2020 are not complete, we're not using them\ndf=df[df['Year'].isin([2016,2017,2018,2019])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['title'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#There are 3 major categories: EMS (Emergency Medical Services), Traffic and Fire, \n#so let's use them to aggregate data\ndf['title']=df['title'].str.split(':').str.get(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#How many calls per year?\nplt.figure(figsize=(10,6))\nsns.set_palette('tab10')\nsns.set_style('darkgrid')\nsns.countplot(x='Year',data=df)\nplt.title('Number of calls per year')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number doesn't change much from one to another year","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#How many calls per month over the years?\nplt.figure(figsize=(13,7))\nsns.set_style('darkgrid')\nsns.countplot(x='Month',hue='Year',data=df)\nplt.title('Number of calls per month over the years')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These 2 last plots show that the number of calls doesn't vary much over the months. Apparently there's not some kind of seasonality.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#How many calls per category (title)?\nplt.figure(figsize=(10,6))\nsns.set_style('darkgrid')\nsns.countplot(x='Year',hue='title',data=df,hue_order=['EMS','Traffic','Fire'])\nplt.title('Number of calls per per category over the years')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#How many calls per category (title) over the months?\nplt.figure(figsize=(10,6))\nsns.set_style('darkgrid')\nsns.countplot(x='Month',hue='title',data=df,hue_order=['EMS','Traffic','Fire'])\nplt.title('Number of calls per per category over the months')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apparently the number of calls doesn't change much per category. We could make a deeper analysis into each category, but that's not my goal here.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":" In order to answer the question presented in the introduction, we will consider only EMS (Emergency Medical Services) to make the clustering analysis, considering the hospitals are the ones responsible for attending this service category.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"EMS=df[df['title']=='EMS']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Top 25 towns with more calls\ntop_25=EMS['twp'].value_counts(ascending=False,normalize=True).head(25).index\nplt.figure(figsize=(10,6))\nsns.countplot(y='twp',data=EMS,order=top_25)\nplt.title('Top 25 towns with more calls')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Treating outliers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's plot a few points to take a look\nMap=fo.Map([40.121354,-75.363829],zoom_start=7)\nrandom_index=np.random.choice(df.index,1000) #getting some random points to plot\nfor ind in random_index:\n    lat=df.loc[ind,'lat']\n    long=df.loc[ind,'lng']\n    fo.CircleMarker([lat,long],radius=2).add_to(Map)\nMap","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apparently the data is well concentrated in a particular region of PA. Let's make a scatterplot with the whole data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=EMS['lat'],y=EMS['lng'],data=df, alpha=0.3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apparently there are some outliers. Let's use boxplot to do this analysis.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Analysing Latitude\nsns.boxplot(x=EMS['lat'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting outliers data (take a look at https://medium.com/analytics-vidhya/outlier-treatment-9bbe87384d02)\nQ1=EMS['lat'].quantile(.25)\nQ3=EMS['lat'].quantile(.75)\nIQR=Q3-Q1\nLower_Whisker=Q1-1.5*IQR\nUpper_Whisker = Q3+1.5*IQR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#How many outliers?\nEMS[EMS['lat']>Upper_Whisker].shape[0]+EMS[EMS['lat']<Lower_Whisker].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's save the outliers for posteriori analysis\noutliers=EMS[(EMS['lat']>Upper_Whisker)|(EMS['lat']<Lower_Whisker)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#removing outliers\nEMS_treated=EMS[(EMS['lat']<Upper_Whisker)&(EMS['lat']>Lower_Whisker)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting the treated data \nsns.scatterplot(x=EMS_treated['lat'],y=EMS_treated['lng'],data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#boxplot with treated data\nsns.boxplot(x=EMS_treated['lat'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's possible to see a big difference already. Those who knows a bit about latitude and longitude know that a small variance in any value (lat or long) can make a big difference. Let's repeat the process for longitude.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#the same process for long\nsns.boxplot(x=EMS_treated['lng'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Q1=EMS_treated['lng'].quantile(.25)\nQ3=EMS_treated['lng'].quantile(.75)\nIQR=Q3-Q1\nLower_Whisker=Q1-1.5*IQR\nUpper_Whisker = Q3+1.5*IQR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#How many outliers?\nEMS_treated[EMS_treated['lng']>Upper_Whisker].shape[0]+EMS_treated[EMS_treated['lng']<Lower_Whisker].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#saving outliers\noutliers=pd.concat([EMS_treated[(EMS_treated['lng']>Upper_Whisker)|(EMS_treated['lng']<Lower_Whisker)],outliers])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cleaning longitude outliers\nEMS_treated=EMS_treated[(EMS_treated['lng']<Upper_Whisker)&(EMS_treated['lng']>Lower_Whisker)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Total outliers\noutliers.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Percentagem in relation to the whole data\n(outliers.shape[0]/EMS.shape[0])*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can just drop the outliers since they are not so representative. If this was the case, we could consider a way to treat these data in order to use them. \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's see again the treated data\n#It's clear the improvement of this plot in relation to the first ones\nsns.scatterplot(x=EMS_treated['lat'],y=EMS_treated['lng'],data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=EMS_treated['lng'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can plot these data in a real map to see if there is really some difference","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"outliers.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Outliers in red\nMap_outliers=fo.Map([40.269061,-75.69959],zoom_start=6)\nfor index,row in outliers.iterrows():\n    lat=row['lat']\n    long=row['lng']\n    fo.CircleMarker([lat,long],radius=2,color='red').add_to(Map_outliers)\n\n# Treated data in blue\nrandom_indexes=np.random.choice(EMS_treated.index,2000)\nfor rand_in in random_indexes:\n    lat=EMS_treated.loc[rand_in,'lat']\n    long=EMS_treated.loc[rand_in,'lng']\n    fo.CircleMarker([lat,long],radius=2,color='blue').add_to(Map_outliers)\nMap_outliers","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we zoom out we can see points in other states of USA. Also there are points even in the ocean and in another continent.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"One may say that there are points next to the aggregated data (those near to West Grove and East Greenville, for instance)  and even so they were considered as outliers. Again, these data are not so representative in relation to the whole data and, in a practical way, these calls can easily be attended since they are not far from the massive data, where the facilities are to be located in order to attend the calls.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Once we have treated the outliers, let's work on the clusterization.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 3. Clustering","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting lat long\nX=np.array(EMS_treated[['lat','lng']])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How many clusters should we use?\nI'm using the well known elbow technique to find out. (Take a look at https://www.scikit-yb.org/en/latest/api/cluster/elbow.html)\n\nAn alternative is to use an automatic clustering algorithm.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating instance of KMeans\nkmeans=KMeans(init='k-means++')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating instance of Elbow Visualizer to find how many clusters we use\nvisualizer = KElbowVisualizer(model=kmeans, k=(5,20))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting the model\nvisualizer.fit(X)      ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will use k=10 according to the Visualizer.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clustering=KMeans(init='k-means++',n_clusters=10)\nclustering.fit(X)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clusters=clustering.cluster_centers_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see where the clusters were positioned with a few points","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Map=fo.Map([ 40.13572425, -75.20909773],zoom_start=8)\nfor i in range(1000):\n    random_index=np.random.choice(EMS_treated.index,1)\n    lat=df.loc[random_index,'lat']\n    long=df.loc[random_index,'lng']\n    fo.Circle([lat,long],radius=2).add_to(Map)     \n    \nfor c in clusters:\n    lat=c[0]\n    long=c[1]\n    fo.RegularPolygonMarker([lat,long],radius=4,number_of_sides=3,color='black').add_to(Map) \nMap","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A clusterization can gives us an ideia of how to alocate our facilities in order to attend the anual emergency calls. Of course in a real case we cannot rely our answer only in a clustering result, but this is a good \"first kick\" to start our analysis, since KMeans clustering is based on data distribution.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"And what if we had used the whole data, that is, without treating the outliers?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Clustering including outliers\nX_outliers=np.array(EMS[['lat','lng']])\nclustering_outliers=KMeans(init='k-means++',n_clusters=10)\nclustering_outliers.fit(X_outliers)\nclusters_outliers=clustering_outliers.cluster_centers_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adding the outlier clusters to the Map\nfor c in clusters_outliers:\n    lat=c[0]\n    long=c[1]\n    fo.RegularPolygonMarker([lat,long],radius=4,number_of_sides=3,color='red').add_to(Map) \nMap","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we zoom out, the algorithm has placed clusters far away from PA. That's because those outlier points we recognized as clusters. This shows us the importance of make a good data cleaning/preparing. That's crucial for any machine learning model.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"That's all folks. I'll be glad to hear your feedback and suggestions. Thank you so much!","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}