{"nbformat":4,"cells":[{"cell_type":"markdown","metadata":{"_uuid":"edc7edb55ee00e90a2a2c08fe139d562bd4afd5c","_cell_guid":"b29af070-773e-46ac-bbb9-08e1003ec96c","_execution_state":"idle"},"source":""},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"9816e5c315b42c301a077a34419ed2d6a770cad4","collapsed":true,"_cell_guid":"cea32ec5-bd0c-4bec-a662-305567a23447","_execution_state":"idle"},"execution_count":null,"source":"# Import libraries for data wrangling, preprocessing and visualization\nimport numpy \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline"},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"cc2b6c62dae5a9365275ea52d1325cf327751c35","_cell_guid":"3e16a613-24a2-4a93-aac1-de77fa04735b","_execution_state":"idle"},"execution_count":null,"source":"# Importing libraries for building the neural network\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score"},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"ff2bcb1da57a000e5bdeca2a91008e5f9f3375db","_cell_guid":"044daf15-71d3-4a16-bd64-f1539d6c0b8e","_execution_state":"idle"},"execution_count":null,"source":"# Read data file\ndata = pd.read_csv(\"../input/data.csv\", header=0)\nseed = 5\nnumpy.random.seed(seed)"},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"530182522a5acbbb6b2ce39f9083c4295deabf9e","_cell_guid":"86c9b981-7e94-4754-a92a-cf315b2dd657","_execution_state":"idle"},"execution_count":null,"source":"# Take a look at the data\nprint(data.head(2))"},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"70be146675985e248470a061fce9873ce3ced30d","_cell_guid":"ec7024e0-8284-4e01-8542-bcd79986a04e","_execution_state":"idle"},"execution_count":null,"source":"# Take a look at the types of data\ndata.info()"},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"e7f4309e0b823e2ccfb6df30c3253ca1dd518f70","collapsed":true,"_cell_guid":"784cf37d-c7c2-4564-b0f6-c445a3a181f2","_execution_state":"idle"},"execution_count":null,"source":"# Column Unnamed : 32 holds only null values, so it is of no use to us. We simply drop that column.\ndata.drop(\"Unnamed: 32\",axis=1,inplace=True)\ndata.drop(\"id\", axis=1, inplace=True)"},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"f3387f6b4d3ae7b4c873da33b363031c938682eb","_cell_guid":"8ff203cd-e784-4102-9ccc-513b711aeec7","_execution_state":"idle"},"execution_count":null,"source":"# Check whether the column has been dropped\ndata.columns"},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"05a5534143ea04e93e4fa60261b0c11dd6a7aa61","collapsed":true,"_cell_guid":"53acdb86-84e5-43f9-88a0-df5833632f4c","_execution_state":"idle"},"execution_count":null,"source":"# Select the columns to use for prediction in the neural network\nprediction_var = ['radius_mean', 'texture_mean', 'perimeter_mean',\n       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n       'perimeter_worst', 'area_worst', 'smoothness_worst',\n       'compactness_worst', 'concavity_worst', 'concave points_worst',\n       'symmetry_worst', 'fractal_dimension_worst']\nX = data[prediction_var].values\nY = data.diagnosis.values"},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"8eb6476e8ac397650744fe38383e694abc0de00c","collapsed":true,"_cell_guid":"fae4896f-4447-4a3f-b335-6a99839a1ca3","_execution_state":"idle"},"execution_count":null,"source":"# Diagnosis values are strings. Changing them into numerical values using LabelEncoder.\nencoder = LabelEncoder()\nencoder.fit(Y)\nencoded_Y = encoder.transform(Y)"},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"0dd2c53db60b120e26e7bb1d98cc7718705bb723","collapsed":true,"_cell_guid":"c31c1113-83ce-4ad4-969f-d2b422ae92b1","_execution_state":"idle"},"execution_count":null,"source":"# Baseline model for the neural network. We choose a hidden layer of 10 neurons. The lesser number of neurons helps to eliminate the redundancies in the data and select the more important features.\ndef create_baseline():\n    # create model\n    model = Sequential()\n    model.add(Dense(10, input_dim=30, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n    # Compile model. We use the the logarithmic loss function, and the Adam gradient optimizer.\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model"},{"cell_type":"code","outputs":[],"metadata":{"_uuid":"e336f2c3debe3aa57c541c4da4cbfde382a95a5e","_cell_guid":"aa12c540-6d86-4fce-9b82-be0e2276d371","_execution_state":"idle"},"execution_count":null,"source":"# Evaluate model using standardized dataset. \nestimators = []\nestimators.append(('standardize', StandardScaler()))\nestimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)))\npipeline = Pipeline(estimators)\nkfold = StratifiedKFold(n_splits=10, shuffle=True)\nresults = cross_val_score(pipeline, X, encoded_Y, cv=kfold)\nprint(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"}],"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","version":"3.6.1","name":"python","nbconvert_exporter":"python","mimetype":"text/x-python"}},"nbformat_minor":1}