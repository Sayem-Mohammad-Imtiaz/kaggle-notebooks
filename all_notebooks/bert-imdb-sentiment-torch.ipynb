{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Check for GPU","metadata":{}},{"cell_type":"code","source":"!nvidia-smi -L","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:15:32.655176Z","iopub.execute_input":"2021-05-31T04:15:32.655484Z","iopub.status.idle":"2021-05-31T04:15:33.29852Z","shell.execute_reply.started":"2021-05-31T04:15:32.65541Z","shell.execute_reply":"2021-05-31T04:15:33.297645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Initial Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nprint(f'Using {device.type.upper()}')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-31T04:15:33.300153Z","iopub.execute_input":"2021-05-31T04:15:33.300505Z","iopub.status.idle":"2021-05-31T04:15:34.440459Z","shell.execute_reply.started":"2021-05-31T04:15:33.300457Z","shell.execute_reply":"2021-05-31T04:15:34.439541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Text Cleaning","metadata":{}},{"cell_type":"code","source":"import re\nimport string\n\ndef remove_html_tag(text): \n    return re.sub(\n        '<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});', \n        '', text)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:15:34.442342Z","iopub.execute_input":"2021-05-31T04:15:34.442847Z","iopub.status.idle":"2021-05-31T04:15:34.447783Z","shell.execute_reply.started":"2021-05-31T04:15:34.442809Z","shell.execute_reply":"2021-05-31T04:15:34.44693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Dataset and Clean Text","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\ndf['clean_text'] = df.review.apply(remove_html_tag)\ndf","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:15:34.449299Z","iopub.execute_input":"2021-05-31T04:15:34.450015Z","iopub.status.idle":"2021-05-31T04:15:37.045814Z","shell.execute_reply.started":"2021-05-31T04:15:34.449976Z","shell.execute_reply":"2021-05-31T04:15:37.044958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Token Length Exploration","metadata":{}},{"cell_type":"code","source":"df.clean_text.apply(lambda x: len(x.split(' '))).describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:15:37.047129Z","iopub.execute_input":"2021-05-31T04:15:37.047466Z","iopub.status.idle":"2021-05-31T04:15:37.599189Z","shell.execute_reply.started":"2021-05-31T04:15:37.04742Z","shell.execute_reply":"2021-05-31T04:15:37.598218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndf_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\ndf_train = df_train.reset_index()\ndf_test = df_test.reset_index()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:15:37.600623Z","iopub.execute_input":"2021-05-31T04:15:37.601004Z","iopub.status.idle":"2021-05-31T04:15:38.529029Z","shell.execute_reply.started":"2021-05-31T04:15:37.600952Z","shell.execute_reply":"2021-05-31T04:15:38.52788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BertDataset(torch.utils.data.Dataset):\n    def __init__(self, df, bert_model_name='bert-base-cased'):\n        self.review = df.clean_text\n        self.sentiment = df.sentiment.apply(lambda x: 1 if x == 'positive' else 0)\n        self.tokenizer = BertTokenizerFast.from_pretrained(bert_model_name)\n        \n    def __len__(self):\n        return len(self.sentiment)\n    \n    def __getitem__(self, idx):\n        x = self.tokenize(self.review[idx])\n        for key in x:\n            x[key] = x[key].view(-1).to(device)\n        y = self.sentiment[idx]\n        return x, y\n    \n    def tokenize(self, x):\n        x = self.tokenizer(x, max_length=256, padding='max_length', \n                              truncation=True, return_tensors='pt')\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:15:38.530505Z","iopub.execute_input":"2021-05-31T04:15:38.530828Z","iopub.status.idle":"2021-05-31T04:15:38.544192Z","shell.execute_reply.started":"2021-05-31T04:15:38.530794Z","shell.execute_reply":"2021-05-31T04:15:38.543181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizerFast\n\ntrainloader = torch.utils.data.DataLoader(BertDataset(df_train), batch_size=32)\ntestloader = torch.utils.data.DataLoader(BertDataset(df_test), batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:15:38.549455Z","iopub.execute_input":"2021-05-31T04:15:38.551463Z","iopub.status.idle":"2021-05-31T04:15:43.790516Z","shell.execute_reply.started":"2021-05-31T04:15:38.551426Z","shell.execute_reply":"2021-05-31T04:15:43.789642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Definition and Training","metadata":{}},{"cell_type":"code","source":"from transformers import BertModel\n\nclass BertClassifier(torch.nn.Module):\n    def __init__(self, bert_model_name='bert-base-cased', bert_freeze=False):\n        super(BertClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained(bert_model_name)\n        for param in self.bert.parameters():\n            param.requires_grad = False if bert_freeze else True\n        self.dropout = torch.nn.Dropout(0.1)\n        self.classifier = torch.nn.Linear(768, 1)\n        \n    def forward(self, input_ids, attention_mask, token_type_ids):\n        out = self.bert(input_ids, attention_mask, token_type_ids).pooler_output\n        out = self.dropout(out)\n        out = torch.sigmoid(self.classifier(out)).view(-1)\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:15:43.792035Z","iopub.execute_input":"2021-05-31T04:15:43.792375Z","iopub.status.idle":"2021-05-31T04:15:43.82764Z","shell.execute_reply.started":"2021-05-31T04:15:43.792341Z","shell.execute_reply":"2021-05-31T04:15:43.826929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = BertClassifier().to(device)\noptimizer = torch.optim.Adam(model.parameters(), 2e-5)\nloss = torch.nn.BCELoss()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:15:43.828797Z","iopub.execute_input":"2021-05-31T04:15:43.829165Z","iopub.status.idle":"2021-05-31T04:16:12.442471Z","shell.execute_reply.started":"2021-05-31T04:15:43.829131Z","shell.execute_reply":"2021-05-31T04:16:12.441598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\nfrom sklearn.metrics import accuracy_score\n\ndef train(epoch, model, optimizer, loss_fn, dataloader):\n    # Enable training\n    model.train()\n    with tqdm(dataloader, total=len(dataloader)) as pbar:\n        accuracy = []\n        losses = []\n        pbar.set_description('Epoch %d - Training\\t' %(epoch + 1))\n        for x, y in pbar:\n            # Zero the parameter gradients\n            optimizer.zero_grad()\n            \n            # Convert label for specified device and to float type\n            y = y.to(device).float()\n                \n            # Update weights and parameters by, forward + backward + optimize\n            y_pred = model(**x)\n            loss = loss_fn(y_pred, y)\n            loss.backward()\n            optimizer.step()\n            \n            # Convert tensors to CPU mode and integer type\n            y = y.cpu().int()\n            y_pred = (y_pred > 0.5).cpu().int()\n            \n            # Add metrics record to lists\n            accuracy.append(accuracy_score(y, y_pred))\n            losses.append(loss.item())\n            \n            # Store average of metrics\n            history = {'training_loss': np.mean(losses), \n                       'training_accuracy': np.mean(accuracy)}\n            \n            # Update progress bar\n            pbar.set_postfix(history)\n        return history\n    \ndef evaluate(epoch, model, loss_fn, dataloader):\n    # Disable training\n    model.eval()\n    with torch.no_grad(), tqdm(dataloader, total=len(dataloader)) as pbar:\n        accuracy = []\n        losses = []\n        pbar.set_description('Epoch %d - Validation\\t' %(epoch + 1))\n        for x, y in pbar:\n            # Generate prediction\n            y_pred = model(**x)\n            \n            # Convert label for specified device and to float type\n            y = y.to(device).float()\n            \n            # Compute loss\n            loss = loss_fn(y_pred, y)\n            \n            # Convert tensors to CPU mode and integer type\n            y_pred = (y_pred > 0.5).cpu().int()\n            y = y.cpu().int()\n            \n            # Add metrics record to lists\n            accuracy.append(accuracy_score(y, y_pred))\n            losses.append(loss.item())\n            \n            # Store average of metrics\n            history = {'validation_loss': np.mean(losses), \n                       'validation_accuracy': np.mean(accuracy)}\n            \n            # Update progress bar\n            pbar.set_postfix(history)\n        return history","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:16:12.443795Z","iopub.execute_input":"2021-05-31T04:16:12.444149Z","iopub.status.idle":"2021-05-31T04:16:12.457669Z","shell.execute_reply.started":"2021-05-31T04:16:12.444113Z","shell.execute_reply":"2021-05-31T04:16:12.456948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = [{**train(epoch, model, optimizer, loss, trainloader),\n            **evaluate(epoch, model, loss, testloader)}\n           for epoch in range(5)]","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:16:12.458733Z","iopub.execute_input":"2021-05-31T04:16:12.459667Z","iopub.status.idle":"2021-05-31T04:16:34.921253Z","shell.execute_reply.started":"2021-05-31T04:16:12.459481Z","shell.execute_reply":"2021-05-31T04:16:34.91919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_loss = [h['training_loss'] for h in history]\nvalidation_loss = [h['validation_loss'] for h in history]\ntraining_accuracy = [h['training_accuracy'] for h in history]\nvalidation_accuracy = [h['validation_accuracy'] for h in history]","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:16:34.922012Z","iopub.status.idle":"2021-05-31T04:16:34.92241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Styling\nplt.style.use('seaborn-darkgrid')\n\n# Initialize plot\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n# Left plot\nax1.set_title('Loss')\nax1.plot(training_loss, 'o-', label='Training Loss')\nax1.plot(validation_loss, 'o-', label='Validation Loss')\nax1.legend()\n# Right plot\nax2.set_title('Accuracy')\nax2.plot(training_accuracy, 'o-', label='Training Accuracy')\nax2.plot(validation_accuracy, 'o-', label='Validation Accuracy')\nax2.legend()\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T04:16:34.925195Z","iopub.status.idle":"2021-05-31T04:16:34.925567Z"},"trusted":true},"execution_count":null,"outputs":[]}]}