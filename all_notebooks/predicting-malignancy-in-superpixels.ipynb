{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"4324c511-2ee9-8382-a4e4-6c88a7eb5e5c"},"source":"A script to show how to get started with segmenting superpixels in PETCT images. Here we show both 2d, 3d, single channel and multichannel analyses"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cd1d06de-3331-4fb7-fef2-1250ca6ab4ee"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom skimage.util.montage import montage2d\nimport os\nimport h5py\nmake_proj = lambda x: np.sum(x,1)[::-1]\nmake_mip = lambda x: np.max(x,1)[::-1]"},{"cell_type":"markdown","metadata":{"_cell_guid":"b508aa73-eb83-77d0-6d1b-15e98e5ea52f"},"source":"# Loading and Displaying PET and CT\nHere we load the PET and CT data from a single patient and show the projection image for CT and the MIP view for the PET data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f75abea4-fcd8-12d0-339a-98a5fbea8306"},"outputs":[],"source":"%matplotlib inline\nwith h5py.File(os.path.join('..', 'input', 'lab_petct_vox_5.00mm.h5'), 'r') as p_data:\n    id_list = np.random.permutation(list(p_data['ct_data'].keys()))\n    print(list(p_data.keys()))\n    ct_image = p_data['ct_data'][id_list[0]].value\n    pet_image = p_data['pet_data'][id_list[0]].value\n    label_image = (p_data['label_data'][id_list[0]].value>0).astype(np.uint8)\nfig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (12, 4))\nct_proj = make_proj(ct_image)\nsuv_max = make_mip(pet_image)\nlab_proj = make_proj(label_image)\nax1.imshow(ct_proj, cmap = 'bone')\nax1.set_title('CT Image')\nax2.imshow(np.sqrt(suv_max), cmap = 'magma')\nax2.set_title('SUV Image')\nax3.imshow(lab_proj, cmap = 'gist_earth')\nax3.set_title('Tumor Labels')"},{"cell_type":"markdown","metadata":{"_cell_guid":"610beb89-b447-5d85-75c0-eb2cf9146a96"},"source":"# Make a Superpixel Segmentation of the images\nWe make basic superpixels for the CT image here. The primary parameters we adjust are the \n\n - **n_segments** the number of different segments to make (approximately)\n - **compactness** the weight of spatial dimensions versus image intensity (low values are more irregularly shaped)"},{"cell_type":"markdown","metadata":{"_cell_guid":"530bff45-04f1-d4d7-9f59-da11767ee48f"},"source":"# Combined PET/CT Super-pixels\nHere we use image data from both PET and CT\n# Full 3D Superpixels\nHere we make full 3D superpixels for PETCT and show a simple rendering of them"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fef8216f-d1d3-040a-3bad-4811dab5a419"},"outputs":[],"source":"pet_weight = 5.0 # how strongly to weight the pet_signal (1.0 is the same as CT)\npetct_vol = np.stack([np.stack([(ct_slice+-200).clip(0,2048)/2048, \n                            pet_weight*(suv_slice).clip(0,5)/5.0\n                           ],-1) for ct_slice, suv_slice in zip(ct_image, pet_image)],0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6ca7a2ea-6dcf-8722-5ee6-4ff6c2ed49ec"},"outputs":[],"source":"%%time\nfrom skimage.segmentation import slic\nfrom skimage.segmentation import mark_boundaries\ndef make_sp_seg(seed_val):\n    np.random.seed(seed_val)\n    return slic(petct_vol, \n                  n_segments = 10000, \n                  compactness = 0.1,\n                 multichannel = True)\npetct_segs = make_sp_seg(0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d722d804-2218-335c-86cf-62e8de438f35"},"outputs":[],"source":"petct_max_segs = make_mip(petct_segs)\nct_proj = make_proj(petct_vol[:,:,:,0])\nsuv_mip = make_mip(petct_vol[:,:,:,1])\n\nfig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (14, 6))\nax1.imshow(suv_mip, cmap = 'magma')\nax1.set_title('SUV Image')\nax2.imshow(petct_max_segs, cmap = plt.cm.rainbow)\nax2.set_title('Segmented Image')\nax3.imshow(mark_boundaries(suv_mip, petct_max_segs))"},{"cell_type":"markdown","metadata":{"_cell_guid":"788bb6ee-07a3-2ab8-e13c-b5cc1e574ef5"},"source":"## Compare Segments to Labels\nWe look at each superpixel and see how many different labels are inside it. We want each superpixel to be an 'atomic' unit of the image and so we only want one in each"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"485205e9-10fe-0926-41cc-16ab790c3aad"},"outputs":[],"source":"for idx in np.unique(petct_segs):\n    cur_region_mask = petct_segs == idx\n    labels_in_region = label_image[cur_region_mask]\n    labeled_regions_inside = np.unique(labels_in_region)\n    if len(labeled_regions_inside)>1:\n        print('Superpixel id', idx, 'regions', len(labeled_regions_inside))\n        print('\\n',pd.value_counts(labels_in_region))\n        print('Missclassified Pixels:', np.sum(pd.value_counts(labels_in_region)[1:].values))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"592e61d9-a830-a7ef-e1fa-85f005d6b987"},"outputs":[],"source":"nz_labels = [i for i in np.unique(label_image) if i>=0]\nfig, m_axs = plt.subplots(len(nz_labels), 2, figsize = (5, 15))\nfor (ax1, ax2), i_label in zip(m_axs, nz_labels):\n    out_sp = np.zeros_like(petct_segs)\n    cur_label_mask = label_image == i_label\n    labels_in_region = petct_segs[cur_label_mask]\n    \n    superpixels_in_region = np.unique(labels_in_region)\n    for i, sp_idx in enumerate(superpixels_in_region):\n        out_sp[petct_segs == sp_idx] = i+1\n    \n    ax1.imshow(make_proj(cur_label_mask), cmap = 'bone')\n    ax1.set_title('Label Map {}'.format(i_label) if i_label>0 else 'Background Label')\n    ax1.axis('off')\n    \n    ax2.imshow(make_proj(out_sp), cmap = 'gist_earth')\n    ax2.set_title('Superpixels ({})'.format(len(superpixels_in_region)))\n    ax2.axis('off')"},{"cell_type":"markdown","metadata":{"_cell_guid":"3215327d-ad91-e365-9c02-ee735fd0d083"},"source":"## Show the superpixels for each label\nHere we can show which superpixels are inside each label."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"68bd9eaf-6a55-c4a7-5ace-d67c3b4056b5"},"outputs":[],"source":"for idx in np.unique(label_image):\n    cur_region_mask = label_image == idx\n    labels_in_region = petct_segs[cur_region_mask]\n    labeled_regions_inside = np.unique(labels_in_region)\n    print('Label id', idx, 'superpixels inside', len(labeled_regions_inside))\n    #print(pd.value_counts(labels_in_region))"},{"cell_type":"markdown","metadata":{"_cell_guid":"7c3c6145-b642-981c-78e2-052bd39c1b11"},"source":"# Calculate Features for each Superpixel"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"50ee5e29-cdfb-03c5-61ce-39e2a27b6165"},"outputs":[],"source":"from skimage.measure import regionprops\nimport warnings\nfrom warnings import warn\ndef scalar_attributes_list(im_props):\n    \"\"\"\n    Makes list of all scalar, non-dunder, non-hidden\n    attributes of skimage.measure.regionprops object\n    \"\"\"\n\n    attributes_list = []\n\n    for i, test_attribute in enumerate(dir(im_props[0])):\n\n        # Attribute should not start with _ and cannot return an array\n        # does not yet return tuples\n        try:\n            if test_attribute[:1] != '_' and not \\\n                    isinstance(getattr(im_props[0], test_attribute), np.ndarray):\n                attributes_list += [test_attribute]\n        except Exception as e:\n            warn(\"Not implemented: {} - {}\".format(test_attribute, e), RuntimeWarning)\n\n    return attributes_list\n\n\ndef regionprops_to_df(im_props):\n    \"\"\"\n    Read content of all attributes for every item in a list\n    output by skimage.measure.regionprops\n    \"\"\"\n\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        attributes_list = scalar_attributes_list(im_props)\n\n    # Initialise list of lists for parsed data\n    parsed_data = []\n\n    # Put data from im_props into list of lists\n    for i, _ in enumerate(im_props):\n        parsed_data += [[]]\n\n        for j in range(len(attributes_list)):\n            parsed_data[i] += [getattr(im_props[i], attributes_list[j])]\n\n    # Return as a Pandas DataFrame\n    return pd.DataFrame(parsed_data, columns=attributes_list)"},{"cell_type":"markdown","metadata":{"_cell_guid":"7f2d6962-82c4-1044-5995-40f3d67ac73c"},"source":"## Calculate Features and Make Dataframe\nEach row represents a superpixel and the values are derived from the SUV signal in the PET image"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"df363ef8-fced-9236-4520-ddd4cfb19ff2"},"outputs":[],"source":"%%time\nsp_rprops = regionprops(petct_segs, intensity_image=pet_image)\nsp_rprop_df = regionprops_to_df(sp_rprops)\nprint('Region Analysis for ', len(sp_rprops), 'superpixels')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1467bfbe-35d8-83ba-fe1f-faf9bebf369d"},"outputs":[],"source":"# add a malignancy score\nsp_rprop_df['malignancy'] = sp_rprop_df['label'].map(lambda sp_idx: np.mean(label_image[petct_segs==sp_idx]))\n# add the mean CT value\nsp_rprop_df['meanCT'] = sp_rprop_df['label'].map(lambda sp_idx: np.mean(petct_vol[:,:,:,0][petct_segs==sp_idx]))\nsp_rprop_df.sample(3)"},{"cell_type":"markdown","metadata":{"_cell_guid":"df60b579-8d67-040c-d389-94bec6e2daae"},"source":"## Accounting for variability\nmake a few different segmentations and tables using different random seeds"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"107c56c6-0b4f-a22a-65f6-aff2a08f128a"},"outputs":[],"source":"%%time\nout_df_list = [sp_rprop_df]\nfor seed_val in range(1,5):\n    t_petct_segs = make_sp_seg(seed_val)\n    sp_rprops = regionprops(t_petct_segs, intensity_image=pet_image)\n    sp_rprop_df = regionprops_to_df(sp_rprops)\n    # add a malignancy score\n    sp_rprop_df['malignancy'] = sp_rprop_df['label'].map(lambda sp_idx: np.mean(label_image[t_petct_segs==sp_idx]))\n    # add the mean CT value\n    sp_rprop_df['meanCT'] = sp_rprop_df['label'].map(lambda sp_idx: np.mean(petct_vol[:,:,:,0][t_petct_segs==sp_idx]))\n    out_df_list += [sp_rprop_df]\nsp_rprop_df = pd.concat(out_df_list)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"75bf21f1-4594-d38c-874c-a0f1f57d5a5a"},"outputs":[],"source":"reg_var = 'malignancy'\n# boost the malignancy count by 1e3\nboost_df = sp_rprop_df.sample(10000, weights=(1e-3+sp_rprop_df[reg_var].values), replace = True)\n\n# break into variables and outcomes\nnumeric_df = boost_df.select_dtypes(include=[np.number])\nx_data = numeric_df[[ccol for ccol in numeric_df.columns if ccol not in [reg_var]]]\ny_data = boost_df[reg_var].values"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ebfaedac-c4f7-51b7-bfa8-05300c0411f8"},"outputs":[],"source":"# predict the malignancy based on the other features\nfrom sklearn.tree import DecisionTreeRegressor\nmalig_tree = DecisionTreeRegressor()\nmalig_tree.fit(x_data, y_data)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b4c4bb5a-3a8c-0d96-9507-02af1d74f5d9"},"outputs":[],"source":"# show the accuracy (on the original data, which is clearly cheating)\ny_predict = malig_tree.predict(x_data)\nfig, ax1 = plt.subplots(1,1)\nax1.plot(y_data, y_predict, 'b+', label = '')\nax1.plot([0,1], [0,1], 'r-', label = 'ideal')\nax1.set_xlabel('Actual Malignancy')\nax1.set_ylabel('Predicted Malignancy')\nax1.legend()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"31fd20f3-1d9a-8bdf-ab8c-fca71ed4c8e1"},"outputs":[],"source":"from sklearn.tree import export_graphviz\nfrom subprocess import check_call\nfrom IPython.display import Image\ndef visualize_tree(tree, feature_names):\n    \"\"\"Create tree png using graphviz.\n\n    Args\n    ----\n    tree -- scikit-learn DecsisionTree.\n    feature_names -- list of feature names.\n    \"\"\"\n    with open(\"dt.dot\", 'w') as f:\n        export_graphviz(tree, out_file=f,\n                        feature_names=feature_names)\n\n    command = [\"dot\", \"-Tpng\", \"dt.dot\", \"-o\", \"dt.png\"]\n    try:\n        check_call(command)\n        return Image('dt.png')\n    except Exception as e:\n        raise RuntimeError(\"Could not run dot, ie graphviz, to \"\n             \"produce visualization: {}\".format(e))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8bb1c5c3-c1e1-70f3-aa72-6bca424c98a4"},"outputs":[],"source":"visualize_tree(malig_tree, x_data.columns)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"922cdbba-8b59-81f2-ee5d-faa057d709b6"},"outputs":[],"source":"def get_code(tree, feature_names, target_names,\n             spacer_base=\"    \"):\n    \"\"\"Produce psuedo-code for decision tree.\n\n    Args\n    ----\n    tree -- scikit-leant DescisionTree.\n    feature_names -- list of feature names.\n    target_names -- list of target (class) names.\n    spacer_base -- used for spacing code (default: \"    \").\n\n    Notes\n    -----\n    based on http://stackoverflow.com/a/30104792.\n    \"\"\"\n    left      = tree.tree_.children_left\n    right     = tree.tree_.children_right\n    threshold = tree.tree_.threshold\n    features  = [feature_names[i] for i in tree.tree_.feature]\n    value = tree.tree_.value\n\n    def recurse(left, right, threshold, features, node, depth):\n        spacer = spacer_base * depth\n        if (threshold[node] != -2):\n            print(spacer + \"if ( \" + features[node] + \" <= \" + \\\n                  str(threshold[node]) + \" ) {\")\n            if left[node] != -1:\n                    recurse(left, right, threshold, features,\n                            left[node], depth+1)\n            print(spacer + \"}\\n\" + spacer +\"else {\")\n            if right[node] != -1:\n                    recurse(left, right, threshold, features,\n                            right[node], depth+1)\n            print(spacer + \"}\")\n        else:\n            target = value[node]\n            for i, v in zip(np.nonzero(target)[1],\n                            target[np.nonzero(target)]):\n                target_name = target_names[i]\n                target_count = int(v)\n                print(spacer + \"return \" + str(target_name) + \\\n                      \" ( \" + str(target_count) + \" examples )\")\n\n    recurse(left, right, threshold, features, 0, 0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ff8634e7-cf7c-8f35-9b62-fabb15b52515"},"outputs":[],"source":"# meant for decision trees but shows we have made something\nget_code(malig_tree, x_data.columns, ['regression_value'])"},{"cell_type":"markdown","metadata":{"_cell_guid":"94d326c9-d852-5ccc-677b-5a508f3eed75"},"source":"Make a visualization for the super-pixel scores from the decision tree"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"70c53e71-089b-415f-dbf7-77d8a859724a"},"outputs":[],"source":"%%time\nn_petct_segs = make_sp_seg(0)\nnsp_rprops = regionprops(n_petct_segs, intensity_image=pet_image)\nnsp_rprop_df = regionprops_to_df(sp_rprops)\nnsp_rprop_df['meanCT'] = nsp_rprop_df['label'].map(lambda sp_idx: np.mean(petct_vol[:,:,:,0][n_petct_segs==sp_idx]))\n\nfnsp_rprop_df=nsp_rprop_df.select_dtypes(include=[np.number])\nfnsp_rprop_df=fnsp_rprop_df[[ccol for ccol in numeric_df.columns if ccol not in [reg_var]]]\nnsp_rprop_df['score']=malig_tree.predict(fnsp_rprop_df)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f3b7d0e9-97a5-5198-bba2-1b1013c7dd29"},"outputs":[],"source":"%%time\nn_img=np.zeros(n_petct_segs.shape,dtype=np.float32)\nfor _, n_row in nsp_rprop_df.iterrows():\n    n_img[n_petct_segs==n_row['label']]=n_row['score']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0fed20ca-fba0-5a75-6b82-6be79201e518"},"outputs":[],"source":"%matplotlib inline\noverlay_image=0.5*plt.cm.bone(petct_vol[:,:,:,0])+0.5*plt.cm.inferno(n_img)\nfig, m_axes = plt.subplots(3,3, figsize = (12, 12))\nfor c_title,c_img,(ax1, ax2, ax3) in zip(['Prediction','Label','Overlay'],\n                           [n_img,label_image,overlay_image],\n                           m_axes):\n    \n    for i, (cax, clabel) in enumerate(zip([ax1, ax2, ax3], ['xy', 'zy', 'zx'])):\n        cax.imshow(np.max(c_img[::-1],i).squeeze(), interpolation='none', cmap = 'bone_r',vmin=0,vmax=1)\n        cax.set_title('%s %s Projection' % (c_title,clabel))\n        cax.set_xlabel(clabel[0])\n        cax.set_ylabel(clabel[1])\n        cax.axis('off')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d1da0b83-8a17-cd34-59d5-09a8dbe39a90"},"outputs":[],"source":"%matplotlib inline\npos_img=(label_image==1)*n_img\nneg_img=(label_image==0)*(n_img)\n\noverlay_image=plt.cm.bone(petct_vol[:,:,:,0])\n\nfig, m_axes = plt.subplots(3,3, figsize = (12, 12))\nfor c_title,c_img,(ax1, ax2, ax3) in zip(['CT Image','True Positives','False Positives'],\n                           [petct_vol[:,:,:,0],pos_img,neg_img],\n                           m_axes):\n    \n    for i, (cax, clabel) in enumerate(zip([ax1, ax2, ax3], ['xy', 'zy', 'zx'])):\n        cax.imshow(np.mean(c_img[::-1],i).squeeze(), interpolation='none', cmap = 'bone')\n        cax.set_title('%s %s Projection' % (c_title,clabel))\n        cax.set_xlabel(clabel[0])\n        cax.set_ylabel(clabel[1])\n        cax.axis('off')"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}