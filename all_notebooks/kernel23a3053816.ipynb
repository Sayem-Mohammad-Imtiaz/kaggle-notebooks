{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#importing all the important lib.\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport keras\nimport re\n# Setting seed for reproducability\nnp.random.seed(1234)  \nPYTHONHASHSEED = 0\nfrom sklearn import preprocessing\nfrom sklearn.metrics import confusion_matrix, recall_score, precision_score\nfrom keras.models import Sequential\nimport glob\nfrom keras.layers import Dense, Dropout, LSTM, Activation\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#combining all the samples into one dataframe \npath = r'/kaggle/input/one-year-industrial-component-degradation/' \nall_files = glob.glob(path + \"/*.csv\")\nprint (len(all_files))\ndata=[]\nfor i in all_files:\n    \n    #taking the unique mode value for example there are 8 mode so my dataframe will contain mode number to which that data point belong \n    file=re.split(\"_\",i)\n    mode=re.split(\".csv\",file[2])\n    mode=re.search(\"[0-9]\",mode[0])\n    \n    #taking all the unique sample values i.e 519 and datapoint will have respective sample no in dataframe \n    sample=re.split(\".csv\",file[1])\n    \n    #creating a dataframe \n    dataframe=pd.read_csv(i)\n    dataframe[\"mode\"]=mode.group(0)\n    dataframe[\"sample\"]=sample[0].lstrip(\"0\")\n    \n    #appending it to the list \n    data.append(dataframe)\n    \n#concating a list to get final whole dataframe     \ndata_final=pd.concat(data,ignore_index=True)\nprint (data_final.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for taking sample no 0 \ndef sample_edit(data):\n        return \"0\"\ndata_final[\"sample\"].loc[0:2048]=data_final[\"sample\"].head(2048).apply(sample_edit)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lest see distribution of datapoints with respect to mode \ndata_final[\"mode\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets see distribution of sample with respect to mode \ndata_final.groupby([\"sample\",\"mode\"]).size().groupby(\"mode\").count()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_final[\"sample\"].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#renaming column name as we are having unneccessary lengthy names \ndata_final.rename(columns={\"pCut::Motor_Torque\":\"MT\",\"pCut::CTRL_Position_controller::Lag_error\": \"Lag_error\",\"pCut::CTRL_Position_controller::Actual_position\" :\"AP\",\"pCut::CTRL_Position_controller::Actual_speed\":\"As\",\"pSvolFilm::CTRL_Position_controller::Actual_position\":\"pAp\",\"pSvolFilm::CTRL_Position_controller::Actual_speed\":\"pAs\",\"pSvolFilm::CTRL_Position_controller::Lag_error\":\"ple\",\"pSpintor::VAX_speed\":\"vax\"},inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets fill the null values\ndata_final.fillna(method=\"backfill\",inplace=True)\n\n#lets change the datatype of column name mode and sample\n#data_final[\"sample\"]=data_final[\"sample\"].astype(\"int32\")\ndata_final[\"mode\"]=data_final[\"mode\"].astype(\"int32\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_sample=np.unique(data_final[\"sample\"].values)\nall_sample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets create cycle for every data point \n\n\"\"\" here i am creating a cycle for example lets take mode 1 and sample no 001 so we have \n    2048 total datapoints in this sample.\n    so i will create a cycle starting from 1st datapoint to last datapoint.\n    so for first my cycle value will be 1 because this is the first reading at timestamp 0.008 so i will increament my cycle \n    by 1 for every datapoint i.e for 2nd datapoint my cycle value will be 2 . \n    it will continue to increase by 1 till last point i.e 2048 so my final datapoint will be having cycle as 2048 or 2049\n    if my data points starts from 0 or 1 \"\"\"\ndata_final=data_final.assign(cycle=\" \")\ndata_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets increment the cycle\nfor i in all_sample:\n    i=i\n    cycle=0\n    for row in data_final.itertuples():\n        sample=row[11]\n        index=row[0]\n        if i==sample:\n            cycle +=1\n            data_final.at[index,\"cycle\"]=cycle\n           \n            \n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_final.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#lets create remaining useful life based on cycle\n\n\"\"\" so lets take example of mode 1 and sample no 001.\n    so we have total 2048 datapoints means 2048 cycle , so for first datapoint of mode 1 and sample 001 \n    our mode 1 still having 2047 cycles are left or you can say still our mode 1 has 2048 readings .\n    based on that i will create RUL(remaining useful life) like for first datapoint my RUL will be 2048-1 as there \n    are still 2048 reading or cycles needs to be complete, same thing i will repeat for remaining datapoints in \n    my data like for 2nd datapoint i will be having 2048-2 and it goes on.\"\"\"\n\nrul = pd.DataFrame(data_final.groupby('mode')['cycle'].max()).reset_index()\nrul.columns = ['mode', 'max']\nprint (rul.head())\ndata_final = data_final.merge(rul, on=['mode'], how='left')\ndata_final['RUL'] =data_final['max'] - data_final['cycle']\ndata_final.drop('max', axis=1, inplace=True)\ndata_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA\n\n### Lets explore or visualize how our new feature and data behaves over certain time."},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndata_final[\"RUL\"]=data_final[\"RUL\"].astype(\"int32\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets see how does our features behaves with timestamp\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplot_df = data_final.loc[(data_final['mode'] == 2) & \n                        (data_final['timestamp'] > 0.006) & \n                        (data_final['timestamp'] < 1.000),\n                        ['timestamp','vax']]\nsns.set_style(\"darkgrid\")\nplt.figure(figsize=(20, 8))\nplt.plot(plot_df['timestamp'], plot_df['vax'])\nplt.ylabel('voltage')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplot_df = data_final.loc[(data_final['mode'] == 4) & \n                        (data_final['timestamp'] > 0.006) & \n                        (data_final['timestamp'] < 1.000),\n                        ['timestamp','pAs']]\nsns.set_style(\"darkgrid\")\nplt.figure(figsize=(20, 8))\nplt.plot(plot_df['timestamp'], plot_df['pAs'])\nplt.ylabel('voltage')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets see how does our features behaves with timestamp\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplot_df = data_final.loc[(data_final['mode'] == 2) & \n                        (data_final['timestamp'] > 0.006) & \n                        (data_final['timestamp'] < 1.000),\n                        ['timestamp','pAp']]\nsns.set_style(\"darkgrid\")\nplt.figure(figsize=(20, 8))\nplt.plot(plot_df['timestamp'], plot_df['pAp'])\nplt.ylabel('voltage')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let us create a helper function to ease exploration of each feature invidually\n\ndef explore_col(s, e):\n    \n    \"\"\"Plot 4 main graphs for a single feature.\n    \n        plot1: histogram \n        plot2: boxplot \n        plot3: line plot (time series over cycle)\n        plot4: scatter plot vs. regression label ttf\n        \n    Args:\n        s (str): The column name of the feature to be plotted.\n        e (int): The number of random mode to be plotted for plot 3. Range from 1 -8 (becuase we have only 8 mode)\n\n    Returns:\n        plots\n    \n    \"\"\"\n    \n    fig = plt.figure(figsize=(10, 8))\n    sub1 = fig.add_subplot(221) \n    sub1.set_title(s +' histogram') \n    sub1.hist(data_final[s])\n\n    sub2 = fig.add_subplot(222)\n    sub2.set_title(s +' boxplot')\n    sub2.boxplot(data_final[s])\n    \n    if e > 9 or e <= 0:\n        select_mode = list(pd.unique(data_final.mode))\n    else:\n        select_mode = np.random.choice(range(0,9), e, replace=False)\n        \n    sub3 = fig.add_subplot(223)\n    sub3.set_title('time series: ' + s +' / cycle')\n    sub3.set_xlabel('cycle')\n    for i in select_mode:\n        df = data_final[['cycle', s]][data_final[\"mode\"] == i]\n        sub3.plot(df['cycle'],df[s])\n        \n    sub4 = fig.add_subplot(224)\n    sub4.set_title(\"scatter: \"+ s + \" / RUL (regr label)\")\n    sub4.set_xlabel('RUL')\n    sub4.scatter(data_final['RUL'],data_final[s])\n\n\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explore_col(\"vax\",4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explore_col(\"vax\",4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a function to explore the time series plot each sensor selecting random sample engines\n\ndef plot_time_series(s):\n    \n    \"\"\"Plot time series of a single sensor for 10 random sample engines.\n    \n        Args:\n        s (str): The column name of the sensor to be plotted.\n\n    Returns:\n        plots\n        \n    \"\"\"\n    \n    fig, axes = plt.subplots(5, 1, sharex=True, figsize = (15, 15))\n    fig.suptitle(s + ' time series / cycle', fontsize=15)\n    \n    #np.random.seed(12345)\n    select_engines = np.random.choice(range(1,9), 5, replace=False).tolist()\n    \n    for e_id in select_engines:\n        df = data_final[['cycle', s]][data_final[\"mode\"]== e_id]\n        i = select_engines.index(e_id)\n        axes[i].plot(df['cycle'],df[s])\n        axes[i].set_ylabel('mode ' + str(e_id))\n        axes[i].set_xlabel('cycle')\n        #axes[i].set_title('engine ' + str(e_id), loc='right')\n\n    #plt.tight_layout()\n    plt.subplots_adjust(wspace=0, hspace=0)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_time_series('vax')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plot_time_series('AP')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  if we see above graphs we didnt get any useful information . so lets create a cycle for all the mode irespective with sample and also lets create RUL based on mode "},{"metadata":{"trusted":true},"cell_type":"code","source":"#overall cycle\n\n\"\"\" so lets take example of mode 1 and we have total 468992 datapoints for mode1 means 468992 cycle & we will increment by 1\n    for every datapoint as we did for cycle for mode1 and sample 001\"\"\"\n\nall_mode=np.unique(data_final[\"mode\"].values)\ndata_final=data_final.assign(tot_cycle=\" \")\nfor i in all_mode:\n    i=int(i)\n    cycle=0\n    for row in data_final.itertuples():\n        mode=row[10]\n        index=row[0]\n        if i==mode:\n            cycle +=1\n            data_final.at[index,\"tot_cycle\"]=cycle\n           \n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets create remaining useful life based on tot_cycle\n\n\"\"\" so lets take example of mode 1 my tot_rulL will be 468992-1 as there \n    are still 468992 reading or cycles needs to be complete, same thing i will repeat for remaining datapoints in \n    my data like for 2nd datapoint i will be having 468992-2 and it goes on and will do same for others mode also \"\"\"\n\ntot_rul = pd.DataFrame(data_final.groupby('mode')['tot_cycle'].max()).reset_index()\ntot_rul.columns = ['mode', 'max']\nprint (tot_rul.head())\ndata_final = data_final.merge(tot_rul, on=['mode'], how='left')\ndata_final['Tot_RUL'] =data_final['max'] - data_final['tot_cycle']\ndata_final.drop('max', axis=1, inplace=True)\ndata_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let us create a helper function to ease exploration of each feature invidually\n\ndef explore_col(s, e):\n    \n    \"\"\"Plot 4 main graphs for a single feature.\n    \n        plot1: histogram \n        plot2: boxplot \n        plot3: line plot (time series over cycle)\n        plot4: scatter plot vs. regression label ttf\n        \n    Args:\n        s (str): The column name of the feature to be plotted.\n        e (int): The number of random mode to be plotted for plot 3. Range from 1 -8 (becuase we have only 8 mode)\n\n    Returns:\n        plots\n    \n    \"\"\"\n    \n    fig = plt.figure(figsize=(10, 8))\n    sub1 = fig.add_subplot(221) \n    sub1.set_title(s +' histogram') \n    sub1.hist(data_final[s])\n\n    sub2 = fig.add_subplot(222)\n    sub2.set_title(s +' boxplot')\n    sub2.boxplot(data_final[s])\n    \n    if e > 9 or e <= 0:\n        select_mode = list(pd.unique(data_final.mode))\n    else:\n        select_mode = np.random.choice(range(0,9), e, replace=False)\n        \n    sub3 = fig.add_subplot(223)\n    sub3.set_title('time series: ' + s +' / cycle')\n    sub3.set_xlabel('cycle')\n    for i in select_mode:\n        df = data_final[['tot_cycle', s]][data_final[\"mode\"] == i]\n        sub3.plot(df['tot_cycle'],df[s])\n        \n    sub4 = fig.add_subplot(224)\n    sub4.set_title(\"scatter: \"+ s + \" / RUL (regr label)\")\n    sub4.set_xlabel('Tot_RUL')\n    sub4.scatter(data_final['Tot_RUL'],data_final[s])\n\n\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nexplore_col(\"pAs\",2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explore_col(\"vax\",4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a function to explore the time series plot each sensor selecting random sample engines\n\ndef plot_time_series(s):\n    \n    \"\"\"Plot time series of a single sensor for 10 random sample engines.\n    \n        Args:\n        s (str): The column name of the sensor to be plotted.\n\n    Returns:\n        plots\n        \n    \"\"\"\n    \n    fig, axes = plt.subplots(5, 1, sharex=True, figsize = (15, 15))\n    fig.suptitle(s + ' time series / cycle', fontsize=15)\n    \n    #np.random.seed(12345)\n    select_engines = np.random.choice(range(1,9), 5, replace=False).tolist()\n    \n    for e_id in select_engines:\n        df = data_final[['tot_cycle', s]][data_final[\"mode\"]== e_id]\n        i = select_engines.index(e_id)\n        axes[i].plot(df['tot_cycle'],df[s])\n        axes[i].set_ylabel('mode ' + str(e_id))\n        axes[i].set_xlabel('cycle')\n        #axes[i].set_title('engine ' + str(e_id), loc='right')\n\n    #plt.tight_layout()\n    plt.subplots_adjust(wspace=0, hspace=0)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plot_time_series('vax')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plot_time_series('AP')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot and compare the standard deviation of features:\nfeatures=['MT', 'Lag_error', 'AP', 'As', 'pAp', 'pAs', 'ple', 'vax']\ndata_final[features].std().plot(kind=\"bar\",figsize=(8,6), title=\"Features Standard Deviation\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get ordered list of top variance features:\n\nfeaturs_top_var = data_final[features].std().sort_values(ascending=False)\nfeaturs_top_var","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get ordered list features correlation with regression label RUL\ndata_final[features].corrwith(data_final.RUL).sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get ordered list features correlation with regression label tot_RUL\ndata_final[\"Tot_RUL\"]=data_final[\"Tot_RUL\"].astype(\"int32\")\ndata_final[\"tot_cycle\"]=data_final[\"tot_cycle\"].astype(\"int32\")\ndata_final[\"cycle\"]=data_final[\"cycle\"].astype(\"int32\")\ndata_final[features].corrwith(data_final.Tot_RUL).sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot a heatmap to display correlation:\nimport seaborn as sns\nfeatures.extend([\"RUL\",\"Tot_RUL\",\"cycle\",\"tot_cycle\"])\ncm = np.corrcoef(data_final[features].values.T)\nsns.set(font_scale=1.0)\nfig = plt.figure(figsize=(12, 10))\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 8}, yticklabels=features, xticklabels=features)\nplt.title('Features Correlation Heatmap')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}