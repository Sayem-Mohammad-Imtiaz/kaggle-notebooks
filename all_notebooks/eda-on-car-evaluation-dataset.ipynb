{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils.multiclass import unique_labels\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport os\nprint(os.listdir('../input'))\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/car_evaluation.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# assigning column names \ndata.columns = [\"buying\",\"maint\",\"doors\",\"persons\",\"lug_boot\",\"safety\",\"value\"]\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Description\n### Features\n<li><strong>buying:</strong> vhigh, high, med, low. </li>\n<li><strong>maint:</strong> vhigh, high, med, low. </li>\n<li><strong>doors: </strong>2, 3, 4, 5more. </li>\n<li><strong>persons:</strong> 2, 4, more. </li>\n<li><strong>lug_boot:</strong> small, med, big.</li> \n<li><strong>safety:</strong> low, med, high. </li>\n\n### Target\n<li><strong>buying:</strong> unacc, acc, good, vgood. </li>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# to view class distribution\ndata.value.value_counts().plot(kind='bar', title='Count (target)');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data is higly imbalanced and bisaed to unacc class. This will result in overfitting.\n<li> acc  - 22% </li>\n<li> good  - 3.9% </li>\n<li> unacc - 70% </li>\n<li> vgood - 3.7% </li>\n\nIf the model perdicts all input as unacc then it will be 70% accurate which is wrong.<br>\nHence we cannot conclude a model's performance just by accuracy.\n\nTo overcome this I'm oversampling it"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Class count\nclass_count = data.value.value_counts()\n# for oversampling getting the max count\nmax_class = max(class_count)\n\n# Divide DataFrame by class\ndf_class_0 = data[data['value'] == \"acc\"]\ndf_class_1 = data[data['value'] == \"good\"]\ndf_class_2 = data[data['value'] == \"unacc\"]\ndf_class_3 = data[data['value'] == \"vgood\"]\n\n#Oversampling\ndf_class_0_over = df_class_0.sample(max_class,replace = True)\ndf_class_1_over = df_class_1.sample(max_class,replace = True)\n# df_class_2_over = df_class_2.sample(max_class) # not using maximum class\ndf_class_3_over = df_class_3.sample(max_class,replace = True)\n\ndata_os = pd.concat([df_class_0_over,df_class_1_over,df_class_3_over,df_class_2], axis = 0)\ndata_os.value.value_counts().plot(kind='bar', title='Count (target)');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"source :https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"# data cleansing\ndata_os.doors = data_os.doors.replace({\"5more\": 5}) \n# data_os.doors = data_os.doors.replace({\"3\":2,\"5\":4,\"2\":2,\"4\":4,5:4})\ndata_os.persons = data_os.persons.replace({\"more\": 5})\ndata_os.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# label encoding\nmap1 = {\"low\" : 1, \"med\":2,\"high\":3, \"vhigh\": 4}\nmap2 = {\"small\" : 1, \"med\":2,\"big\":3}\ndata_os[\"buying\"] = data_os[\"buying\"].map(map1)\ndata_os[\"maint\"] = data_os[\"maint\"].map(map1)\ndata_os[\"safety\"] = data_os[\"safety\"].map(map1)\ndata_os[\"lug_boot\"] = data_os[\"lug_boot\"].map(map2)\ndata_os.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_os[\"doors\"]  = pd.to_numeric(data_os[\"doors\"])\ndata_os[\"persons\"] = pd.to_numeric(data_os[\"persons\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_os[\"car_type\"] = data_os[\"doors\"]+data_os[\"persons\"] # created feature\ntype_dict = {4:\"Coupe\",\n             5:\"Coupe\",\n            6:\"GT\",\n            7:\"Sedan\",\n            8:\"Hatchback\",\n            9:\"SUV\",\n            10:\"SUV\"}\n# data_os[\"car_type\"] = data_os[\"car_type\"].map(type_dict)\n\n# set(data_os[\"car_type\"].values.tolist())\ndata_os[\"car_type\"] = data_os[\"car_type\"].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = ['value']\nreject = target\nfeatures = [x for x in data_os.columns if x not in reject]\nx = data_os[features]\ny = data_os[target]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.25, random_state = 0)\nprint(xTrain.shape)\nprint(xTest.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn\nfrom sklearn.ensemble import RandomForestClassifier\nmodel=RandomForestClassifier(n_jobs=-1,random_state=51)\n\nmodel.fit(xTrain,yTrain)\nprint(model.score(xTest,yTest))\nprint(sklearn.metrics.f1_score(yTest,model.predict(xTest),average='macro'))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}