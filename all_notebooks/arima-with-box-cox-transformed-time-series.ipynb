{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Importing Libraries and Dataset","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom pandas import Grouper\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nfrom math import log\nfrom math import exp\n\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom statsmodels.graphics.gofplots import qqplot\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.arima_model import ARIMAResults\nfrom scipy.stats import boxcox\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:11:11.974812Z","iopub.execute_input":"2021-06-20T02:11:11.975187Z","iopub.status.idle":"2021-06-20T02:11:13.341666Z","shell.execute_reply.started":"2021-06-20T02:11:11.975152Z","shell.execute_reply":"2021-06-20T02:11:13.340814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dados = pd.read_csv(\"/kaggle/input/corona-virus-brazil/brazil_covid19_macro.csv\")\ndados.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:11:39.484862Z","iopub.execute_input":"2021-06-20T02:11:39.485228Z","iopub.status.idle":"2021-06-20T02:11:39.531334Z","shell.execute_reply.started":"2021-06-20T02:11:39.485199Z","shell.execute_reply":"2021-06-20T02:11:39.530234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Problem Description\n\n### The problem is to predict the number of deaths by covid-19 in Brazil.","metadata":{}},{"cell_type":"code","source":"covid = pd.DataFrame(data=dados.deaths.values, index=dados.date, columns=[\"deaths\"])\ncovid","metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:13:13.961131Z","iopub.execute_input":"2021-06-20T02:13:13.961475Z","iopub.status.idle":"2021-06-20T02:13:13.975971Z","shell.execute_reply.started":"2021-06-20T02:13:13.961446Z","shell.execute_reply":"2021-06-20T02:13:13.974553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Test Harness","metadata":{}},{"cell_type":"code","source":"split_point = len(covid) - 56\ndataset, validation = covid[0:split_point], covid[split_point:]\n\nprint('Dataset %d, Validation %d' % (len(dataset), len(validation)))","metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:13:45.436786Z","iopub.execute_input":"2021-06-20T02:13:45.437143Z","iopub.status.idle":"2021-06-20T02:13:45.443285Z","shell.execute_reply.started":"2021-06-20T02:13:45.437113Z","shell.execute_reply":"2021-06-20T02:13:45.442144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare data\nX = dataset.values\nX = X.astype('int64')\n\ntrain_size = int(len(X) * 0.5)\ntrain, test = X[0:train_size], X[train_size:]","metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:13:56.136664Z","iopub.execute_input":"2021-06-20T02:13:56.137071Z","iopub.status.idle":"2021-06-20T02:13:56.142105Z","shell.execute_reply.started":"2021-06-20T02:13:56.137035Z","shell.execute_reply":"2021-06-20T02:13:56.141151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Persistence\n\nBefore getting bogged down in data analysis and modeling is to establish a baseline of performance. This will provide both a template for evaluating models using the proposed\ntest harness and a performance measure by which all more elaborate predictive models can be compared. The baseline prediction for time series forecasting is called the naive forecast, or persistence. This is where the observation from the previous time step is used as the prediction for the observation at the next time step.","metadata":{}},{"cell_type":"code","source":"# walk-forward validation\nhistory = [x for x in train]\npredictions = list()\nfor i in range(len(test)):\n    # predict\n    yhat = history[-1]\n    predictions.append(yhat)\n    \n    # observation\n    obs = test[i]\n    history.append(obs)\n    print('>Predicted=%.3f, Expected=%.3f' % (yhat, obs))\n\n# report performance\nrmse = sqrt(mean_squared_error(test, predictions))\nprint('RMSE: %.3f' % rmse)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:14:34.178604Z","iopub.execute_input":"2021-06-20T02:14:34.179137Z","iopub.status.idle":"2021-06-20T02:14:34.195119Z","shell.execute_reply.started":"2021-06-20T02:14:34.179008Z","shell.execute_reply":"2021-06-20T02:14:34.194054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"The persistence model achieved an RMSE of {rmse}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:15:16.445093Z","iopub.execute_input":"2021-06-20T02:15:16.4457Z","iopub.status.idle":"2021-06-20T02:15:16.451699Z","shell.execute_reply.started":"2021-06-20T02:15:16.445653Z","shell.execute_reply":"2021-06-20T02:15:16.450291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Data Analysis","metadata":{}},{"cell_type":"markdown","source":"## 5.1 Summary Statistics","metadata":{}},{"cell_type":"code","source":"dataset.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:16:28.9079Z","iopub.execute_input":"2021-06-20T02:16:28.908265Z","iopub.status.idle":"2021-06-20T02:16:28.927881Z","shell.execute_reply.started":"2021-06-20T02:16:28.908235Z","shell.execute_reply":"2021-06-20T02:16:28.926576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.2 Line Plot","metadata":{}},{"cell_type":"code","source":"# line plots of time series\ndataset.plot()\nplt.tight_layout()\nplt.xticks(rotation=45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:17:03.178758Z","iopub.execute_input":"2021-06-20T02:17:03.179111Z","iopub.status.idle":"2021-06-20T02:17:03.452826Z","shell.execute_reply.started":"2021-06-20T02:17:03.179083Z","shell.execute_reply":"2021-06-20T02:17:03.451666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* There is an increasing trend of robberies over time.\n\n* The trend means the dataset is almost certainly non-stationary and the apparent change in fluctuation may also contribute.","metadata":{}},{"cell_type":"markdown","source":"## 5.3 Density Plot","metadata":{}},{"cell_type":"code","source":"plt.figure()\ndataset.hist(edgecolor='k')\ndataset.plot(kind='kde')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:18:11.706486Z","iopub.execute_input":"2021-06-20T02:18:11.70687Z","iopub.status.idle":"2021-06-20T02:18:12.048589Z","shell.execute_reply.started":"2021-06-20T02:18:11.706837Z","shell.execute_reply":"2021-06-20T02:18:12.047779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The distribution is not Gaussian, but is pretty close.\n\n* The distribution may be exponential or a double Gaussian.","metadata":{}},{"cell_type":"markdown","source":"# 6. Arima Models","metadata":{}},{"cell_type":"markdown","source":"## 6.1 Manually Configured ARIMA","metadata":{}},{"cell_type":"code","source":"# create a differenced time series\ndef difference(dataset):\n    diff = list()\n    for i in range(1, len(dataset)):\n        value = dataset[i] - dataset[i-1]\n        diff.append(value)\n    return pd.Series(diff)\n\n# difference data\nstationary = difference(X)\nstationary.index = dataset.index[1:]\n\n# check if stationary\nresult = adfuller(stationary)\nprint('ADF Statistic: %f' % result[0])\nprint('p-value: %f' % result[1])\nprint('Critical Values:')\nfor key, value in result[4].items():\n    print('\\t%s: %.3f' % (key, value))","metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:19:17.668467Z","iopub.execute_input":"2021-06-20T02:19:17.668839Z","iopub.status.idle":"2021-06-20T02:19:17.713832Z","shell.execute_reply.started":"2021-06-20T02:19:17.668807Z","shell.execute_reply":"2021-06-20T02:19:17.711221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The results show that the test statistic value 0.747134 is bigger than the critical value at 5% of -2.869. This suggests that we can not reject the null hypothesis. Accepting the null hypothesis means that time series is no-stationary or have time-dependent structure.","metadata":{}},{"cell_type":"code","source":"# ACF and PACF plots of time series\nplt.figure()\nplt.subplot(211)\nplot_acf(dataset, lags=50, ax=plt.gca())\nplt.subplot(212)\nplot_pacf(dataset, lags=50, ax=plt.gca())\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:20:26.972839Z","iopub.execute_input":"2021-06-20T02:20:26.973205Z","iopub.status.idle":"2021-06-20T02:20:27.462432Z","shell.execute_reply.started":"2021-06-20T02:20:26.973176Z","shell.execute_reply":"2021-06-20T02:20:27.460848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The ACF shows a significant lag for 30-32 months.\n\n* The PACF shows a significant lag for perhaps 2 months.\n\n* A good starting point for the p and q values are 31 and 2.\n\nSome experimentation shows that the model does not appear to be stable, with non-zero AR and MA orders defined at the same time. The model can be simplified to ARIMA(0,2,2).","metadata":{}},{"cell_type":"code","source":"# evaluate manually configured ARIMA model\n\nX = dataset.values\nX = X.astype('float32')\ntrain_size = int(len(X) * 0.50)\ntrain, test = X[0:train_size], X[train_size:]\n# walk-forward validation\nhistory = [x for x in train]\npredictions = list()\nfor i in range(len(test)):\n    model = ARIMA(history, order=(0,2,2))\n    model_fit = model.fit(disp=0)\n    yhat = model_fit.forecast()[0]\n    predictions.append(yhat)\n    # observation\n    obs = test[i]\n    history.append(obs)\n    print('>Predicted=%.3f, Expected=%.3f' % (yhat, obs))\n# report performance\nrmse = sqrt(mean_squared_error(test, predictions))\nprint('RMSE: %.3f' % rmse)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:21:37.550677Z","iopub.execute_input":"2021-06-20T02:21:37.551074Z","iopub.status.idle":"2021-06-20T02:21:55.476309Z","shell.execute_reply.started":"2021-06-20T02:21:37.551033Z","shell.execute_reply":"2021-06-20T02:21:55.474926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.2 Grid Search ARIMA \n\nWe will search all combinations of the following parameters:\n\n* p: 0 to 5.\n* d: 0 to 2.\n* q: 0 to 5.","metadata":{}},{"cell_type":"code","source":"# evaluate an ARIMA model for a given order (p,d,q) and return RMSE\ndef evaluate_arima_model(X, arima_order):\n    # prepare training dataset\n    X = X.astype('float32')\n    train_size = int(len(X) * 0.50)\n    train, test = X[0:train_size], X[train_size:]\n    history = [x for x in train]\n    # make predictions\n    predictions = list()\n    for t in range(len(test)):\n        model = ARIMA(history, order=arima_order)\n        model_fit = model.fit(disp=0)\n        yhat = model_fit.forecast()[0]\n        predictions.append(yhat)\n        history.append(test[t])\n    # calculate out of sample error\n    rmse = sqrt(mean_squared_error(test, predictions))\n    return rmse","metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:22:38.054987Z","iopub.execute_input":"2021-06-20T02:22:38.055351Z","iopub.status.idle":"2021-06-20T02:22:38.063268Z","shell.execute_reply.started":"2021-06-20T02:22:38.055319Z","shell.execute_reply":"2021-06-20T02:22:38.062344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate combinations of p, d and q values for an ARIMA model\ndef evaluate_models(dataset, p_values, d_values, q_values):\n    dataset = dataset.astype('float32')\n    best_score, best_cfg = float(\"inf\"), None\n    for p in p_values:\n        for d in d_values:\n            for q in q_values:\n                order = (p,d,q)\n                try:\n                    rmse = evaluate_arima_model(dataset, order)\n                    if rmse < best_score:\n                        best_score, best_cfg = rmse, order\n                    print('ARIMA%s RMSE=%.3f' % (order,rmse))\n                except:\n                    continue\n    print('Best ARIMA%s RMSE=%.3f' % (best_cfg, best_score))","metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:22:52.493772Z","iopub.execute_input":"2021-06-20T02:22:52.494152Z","iopub.status.idle":"2021-06-20T02:22:52.501064Z","shell.execute_reply.started":"2021-06-20T02:22:52.49412Z","shell.execute_reply":"2021-06-20T02:22:52.499987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate parameters\np_values = range(0,5)\nd_values = range(0,2)\nq_values = range(0,5)\n\nevaluate_models(dataset.values, p_values, d_values, q_values)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:23:06.882097Z","iopub.execute_input":"2021-06-20T02:23:06.88267Z","iopub.status.idle":"2021-06-20T02:44:46.607628Z","shell.execute_reply.started":"2021-06-20T02:23:06.882618Z","shell.execute_reply":"2021-06-20T02:44:46.606438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The results show that the best configuration discovered was ARIMA(4,1,2)","metadata":{}},{"cell_type":"markdown","source":"## 6.3 Review Residual Errors","metadata":{}},{"cell_type":"code","source":"# walk-forward validation\nhistory = [x for x in train]\npredictions = list()\nfor i in range(len(test)):\n    # predict\n    model = ARIMA(history, order=(4,1,2))\n    model_fit = model.fit(disp=0)\n    yhat = model_fit.forecast()[0]\n    predictions.append(yhat)\n    # observation\n    obs = test[i]\n    history.append(obs)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:46:03.461142Z","iopub.execute_input":"2021-06-20T02:46:03.461686Z","iopub.status.idle":"2021-06-20T02:48:56.14234Z","shell.execute_reply.started":"2021-06-20T02:46:03.461635Z","shell.execute_reply":"2021-06-20T02:48:56.141537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# errors\nresiduals = [test[i]-predictions[i] for i in range(len(test))]\nresiduals = pd.DataFrame(residuals)\nplt.figure()\nplt.subplot(211)\nresiduals.hist(ax=plt.gca())\nplt.subplot(212)\nresiduals.plot(kind='kde', ax=plt.gca())\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:49:22.661079Z","iopub.execute_input":"2021-06-20T02:49:22.66161Z","iopub.status.idle":"2021-06-20T02:49:22.949342Z","shell.execute_reply.started":"2021-06-20T02:49:22.661559Z","shell.execute_reply":"2021-06-20T02:49:22.948273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The distribution of residual errors is a Gaussian with a zero mean. It's the ideal. It is also a good idea to check the time series of the residual errors for any type of autocorrelation. If present, it would suggest that the model has more opportunity to model the temporal structure in the data.","metadata":{}},{"cell_type":"code","source":"plt.figure()\nplt.subplot(211)\nplot_acf(residuals, lags=50, ax=plt.gca())\nplt.subplot(212)\nplot_pacf(residuals, lags=50, ax=plt.gca())\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:50:07.070854Z","iopub.execute_input":"2021-06-20T02:50:07.071202Z","iopub.status.idle":"2021-06-20T02:50:07.413409Z","shell.execute_reply.started":"2021-06-20T02:50:07.071174Z","shell.execute_reply":"2021-06-20T02:50:07.412352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The results suggest that what little autocorrelation is present in the time series has been captured by the model.","metadata":{}},{"cell_type":"markdown","source":"## 6.4 Box-Cox Transformed Dataset\n\nThe Box-Cox transform is a method that is able to evaluate a suite of power transforms, including, but not limited to, log, square root, and reciprocal transforms of the data.","metadata":{}},{"cell_type":"code","source":"X = dataset.values\nX = X[(X!=0).any(axis=1)]\ntransformed, lam = boxcox(X.flatten())\nprint('Lambda: %f' % lam)\nplt.figure(1)\n# line plot\nplt.subplot(311)\nplt.plot(transformed)\n# histogram\nplt.subplot(312)\nplt.hist(transformed)\n# q-q plot\nplt.subplot(313)\nqqplot(transformed, line='r', ax=plt.gca())\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:51:16.536663Z","iopub.execute_input":"2021-06-20T02:51:16.537023Z","iopub.status.idle":"2021-06-20T02:51:17.015283Z","shell.execute_reply.started":"2021-06-20T02:51:16.536993Z","shell.execute_reply":"2021-06-20T02:51:17.013914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Evaluate ARIMA models with box-cox transformed time series","metadata":{}},{"cell_type":"code","source":"# invert box-cox transform\ndef boxcox_inverse(value, lam):\n    if lam == 0:\n        return exp(value)\n    return exp(log(lam * value + 1) / lam)\n\nX = dataset.values\nX = X[(X!=0).any(axis=1)]\nX = X.flatten()\ntrain_size = int(len(X) * 0.50)\ntrain, test = X[0:train_size], X[train_size:]\n# walk-forward validation\nhistory = [x for x in train]\npredictions = list()\nfor i in range(len(test)):\n    # transform\n    transformed, lam = boxcox(history)\n    if lam < -5:\n        transformed, lam = history, 1\n    # predict\n    model = ARIMA(transformed, order=(4,1,2))\n    model_fit = model.fit(disp=0)\n    yhat = model_fit.forecast()[0]\n    # invert transformed prediction\n    yhat = boxcox_inverse(yhat, lam)\n    predictions.append(yhat)\n    # observation\n    obs = test[i]\n    history.append(obs)\n    print('>Predicted=%.3f, Expected=%.3f' % (yhat, obs))\n# report performance\nrmse = sqrt(mean_squared_error(test, predictions))\nprint('RMSE: %.3f' % rmse)","metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:51:57.899466Z","iopub.execute_input":"2021-06-20T02:51:57.89986Z","iopub.status.idle":"2021-06-20T02:53:22.190645Z","shell.execute_reply.started":"2021-06-20T02:51:57.899825Z","shell.execute_reply":"2021-06-20T02:53:22.188947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Model Validation","metadata":{}},{"cell_type":"markdown","source":"## 7.1 Finalize Model","metadata":{}},{"cell_type":"code","source":"# prepare data\nX = dataset.values\nX = X[(X!=0).any(axis=1)]\nX = X.flatten()\n# transform data\ntransformed, lam = boxcox(X)\n# fit model\nmodel = ARIMA(transformed, order=(4,1,2))\nmodel_fit = model.fit(disp=0)\n# save model\nmodel_fit.save('model.pkl')\nnp.save('model_lambda.npy', [lam])","metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:54:08.663529Z","iopub.execute_input":"2021-06-20T02:54:08.663939Z","iopub.status.idle":"2021-06-20T02:54:09.181609Z","shell.execute_reply.started":"2021-06-20T02:54:08.663902Z","shell.execute_reply":"2021-06-20T02:54:09.180773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7.2 Validate Model","metadata":{}},{"cell_type":"code","source":"# invert box-cox transform\ndef boxcox_inverse(value, lam):\n    if lam == 0:\n        return exp(value)\n    return exp(log(lam * value + 1) / lam)\n\n# load and prepare datasets\nX = dataset.values\nX = X[(X!=0).any(axis=1)]\nX = X.flatten()\nhistory = [x for x in X]\ny = validation.values\ny = y[(y!=0).any(axis=1)]\ny = y.flatten()\n# load model\nmodel_fit = ARIMAResults.load('model.pkl')\nlam = np.load('model_lambda.npy')\n# make first prediction\npredictions = list()\nyhat = model_fit.forecast()[0]\nyhat = boxcox_inverse(yhat, lam)\npredictions.append(yhat)\nhistory.append(y[0])\nprint('>Predicted=%.3f, Expected=%.3f' % (yhat, y[0]))\n# rolling forecasts\nfor i in range(1, len(y)):\n    # transform\n    transformed, lam = boxcox(history)\n    if lam < -5:\n        transformed, lam = history, 1\n    # predict\n    model = ARIMA(transformed, order=(4,1,2))\n    model_fit = model.fit(disp=0)\n    yhat = model_fit.forecast()[0]\n    # invert transformed prediction\n    yhat = boxcox_inverse(yhat, lam)\n    predictions.append(yhat)\n    # observation\n    obs = y[i]\n    history.append(obs)\n    print('>Predicted=%.3f, Expected=%.3f' % (yhat, obs))\n# report performance\nrmse = sqrt(mean_squared_error(y, predictions))\nprint('RMSE: %.3f' % rmse)\nplt.plot(y)\nplt.plot(predictions, color='red')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-20T02:55:11.927287Z","iopub.execute_input":"2021-06-20T02:55:11.92769Z","iopub.status.idle":"2021-06-20T02:55:41.561013Z","shell.execute_reply.started":"2021-06-20T02:55:11.927653Z","shell.execute_reply":"2021-06-20T02:55:41.559942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}