{"cells":[{"metadata":{},"cell_type":"markdown","source":"# ARIMA (Autoregressive Integrated Moving Averages)\n\n##### The general process for ARIMA models is the following:\n    1. Visualize the Time Series Data\n    2. Make the time series data stationary\n    3. Plot the Correlation and AutoCorrelation Charts\n    4. Construct the ARIMA Model or Seasonal ARIMA based on the data\n    5. Use the model to make predictions\n\n##### Formula of Auto Regressive Model:\n    yt = c + ϕ1 yt−1 + ϕ2 yt−2 + .............. + ϕp yt−p + εt\n    Here,\n    p = 1, 2, 3, ......\n    t-1, t-2, ..... = lags\n    \n<br/>\n<br/>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Load the dataset and Reconnaissance\ndataset used here: Perrin Freres monthly champagne sales","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('../input/perrin-freres-monthly-champagne-sales/Perrin Freres monthly champagne sales millions.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br/>\n\n### Checking if there is any missing values in the dataset\nWe got one missing value in the 'Month' column and two in the rest.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Removing the rows containing missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop([105,106], axis = 0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br/>\n\n### Changing the name of the 2nd column\nWe shouldn't break our teeth pronouncing any column name.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns = ['Month', 'Sales']\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br/>\n\n### Shape of the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br/>\n\n### Data types of the variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br/>\n\n### Change the data type of the month column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Month'] = pd.to_datetime(df['Month'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### After changing the data type, it will be looking like this","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br/>\n\n### Convert the month column into index","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.set_index('Month', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br/>\n\n## PLot the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Note:\nFrom the plot, we are seeing that it's kind of a seasional data. It may not be stationary. To clarify the confusion, we can apply here the 'Dickey Fuller Test' to see whether it is stationary or not.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<br/>\n\n## Dickey Fuller Test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller\n\ndef adfuller_test(sales):\n    result = adfuller(sales)\n    labels = ['ADF test statistics', 'P-value', '#Lags used', 'Number of observation used']\n    for value, label in zip(result, labels):\n        print(label+' : '+str(value))\n    if result[1] <= 0.05:\n        print('Strong evidence against the null hypothesis (Ho), Reject the null hypothesis, Data has no unit root and is stationary')\n    else:\n        print('Weak evidence against the null hypothesis (Ho), time series has a unit root, indicating it is non stationary. ')\n        \n        \nadfuller_test(df['Sales'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Note:\nAs the P-value is grater than 0.005, the Dickey Fuller Test tells us that the data is not stationary.  \nNow it's time to make the data stationary","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<br/>\n\n## Making the data stationary by Differencing (Integrated)\n\nAs the data is seasional and each year consists 12 month, from the graph we are seeing that the per cycle difference of the data is 12 months.  \nThat's why we will shift 12 here and the substraction from the 'Sales' column will be stored in a new column titled 'seasonal_first_difference'.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['seasional_first_difference'] = df['Sales'] - df['Sales'].shift(12)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br>\n\n## Again applying Dickey Fuller Test\nNow, we want to see if our new data became stationary or not.  \nBut this time we should pay extra attention to 'dropna()'. Because for shifting 12, the 1st 12 values of the 'Sales_first_difference' will be NaN. We have to keep them aside.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"adfuller_test(df['seasional_first_difference'].dropna())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Note:\nDone! As our P-value this time becomes less than 0.005, we can easily tell this data a stationary one.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<br/>\n\n## Plotting our new stational data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['seasional_first_difference'].plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br/>\n\n## Plotting ACF and PACF\nACF = Auto correlation function  \nPACF= Partial Auto correlation function\n<br/>\n\nACF and PACF are used to find the best lag value for the model. \n##### PACF is most suitable for AR model.  \n##### And ACF is most suitable for MA model.\n<br/>\n\nshuts off - The abrupt decrease in PACF. It normally happens in PACF only. And in ACF the decrease is exponential.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.graphics.tsaplots import plot_acf, plot_pacf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nfig = plt.figure(figsize=(12,8))\nax1 = fig.add_subplot(211)\nfig = sm.graphics.tsa.plot_acf(df['seasional_first_difference'].iloc[13:],lags=40,ax=ax1)\nax2 = fig.add_subplot(212)\nfig = sm.graphics.tsa.plot_pacf(df['seasional_first_difference'].iloc[13:],lags=40,ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ARIMA Model takes 3 values.\n\n###### p - AR model lag   : find out from the PACF, where shuts off happens.  \n###### d - Differencing    : how many times the shifting are done?\n###### q - MA model lag : find out from ACF, where exponential decrease happens.  \n<br/>\n\nIn our case,  \np = 1 (As abrupt decrease happens in 1)  \nd = 1  \nq = 0 (As we can't see any exponential decrease in ACF. The decrease in ACF is also abrupt. but in this case, we can also consider an exponential decrease in 1. Then q value can also be 1.)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<br/>\n\n# ARIMA model\n#### Note : ARIMA should be selected when the data is seasional. Though we have seasional data here, we are implementing ARIMA to see the process.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.arima_model import ARIMA\n\nmodel_arima = ARIMA(df['Sales'], order = (1,1,1))     #order = (p, d, q)\nmodel_arima_fit = model_arima.fit()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model summary","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_arima_fit.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br/>\n\n## Plotting the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['forecast_arima']=model_arima_fit.predict(start=90, end=103, dynamic=True)\ndf[['Sales','forecast_arima']].plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### As the data isn't seasional, ARIMA model doesn't perform well","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<br/>\n\n# SARIMAX model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_sarimax = sm.tsa.statespace.SARIMAX(df['Sales'],\n                                          order = (1,1,1),                  # order = (p, d, q)\n                                          seasonal_order = (1,1,1, 12))     # seasonal_order = (p, d, q, shift)  \nmodel_sarimax_fit = model_sarimax.fit()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br/>\n\n## Plotting the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['forecast_sarimax']=model_sarimax_fit.predict(start=90, end=103, dynamic=True)      # 90 and 103 are the index range to be predicted\ndf[['Sales','forecast_sarimax']].plot(figsize = (12, 8))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br/>\n<br/>\n\n### Creating a additional dataset for forecasting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas.tseries.offsets import DateOffset\nfuture_dates = [df.index[-1] + DateOffset (months = x) for x in range(0, 24)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"future_date_dataset = pd.DataFrame(index = future_dates[1:], columns = df.columns)\nfuture_date_dataset.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now concate as well as merge the new dataset with the existing one","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_df = pd.concat([df, future_date_dataset])\nmerged_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_df['forecast_sarimax'] = model_sarimax_fit.predict(start =104, end = 120, dynamic= True )\nmerged_df[['Sales', 'forecast_sarimax']].plot(figsize = (12, 8))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br/>\n<br/>\n\nGratitude: Krish Naik\n### Feel free to share your thoughts and if you find it helpful, please upvote. It will keep me motivated. Thyanks!","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}