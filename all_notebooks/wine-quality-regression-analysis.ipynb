{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Wine Quality Regression Analysis\n\nThis is my first regression analysis. At the end of chapter 2 of \"Hands-On Machine Learning with Scikit-Learn and Tensorflow\", the author encourages us to show off our skills by working on a kaggle dataset and this is what I'm doing now\n\nThese are the steps that I will go through:\n\n\n1. Look at the big picture\n2. Get the data\n3. Discover and visualize the data to gain insights\n4. Prepare the data for Machine Learning algorithms\n5. Select a model and train it\n6. Fine tune your model.\n7. Present your solution"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# **1. The Big Picture**\n\nThis seems like a good candidate for a supervised regression algorithm as we have a known output variable (quality) thats between 0 and 10"},{"metadata":{},"cell_type":"markdown","source":"# 2. Get the Data\n\nThe data is already provided to us so all we need to do is load it into pandas"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/winequality-red.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Discover and Visualize the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The wine quality ranges from 3 to 8. \n\nLet's plot histograms of the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\ndf.hist(bins = 50, figsize = (20,15))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The majority of the wine is at a quality of 5 or 6.\n"},{"metadata":{},"cell_type":"markdown","source":"Lets now look at which values affect the wine quality the most"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = df.corr()\ncorr_matrix['quality'].sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The alcohol, sulphates, and volatile acidity effect the wine quality the most"},{"metadata":{},"cell_type":"markdown","source":"# 4. Prepare the Data for Machine Learning"},{"metadata":{},"cell_type":"markdown","source":"We should first perform feature scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ndf_scaled = scaler.fit_transform(df)\ndf_scaled = pd.DataFrame(df_scaled, columns = df.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We should now split the data into train and test sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = df_scaled.drop(['quality'], axis = 1)\ny = df_scaled['quality']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since all the variables are numerical therefore the data does not require anymore cleaning"},{"metadata":{},"cell_type":"markdown","source":"# 5. Select a Model and Train it"},{"metadata":{},"cell_type":"markdown","source":"Since this is a simple example we will try linear regression and if the results are not satisfactory we will try another model."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nlm = LinearRegression()\nlm.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = lm.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model Evaluation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nlm_mse = mean_squared_error(y_test,predictions)\nlm_rmse = np.sqrt(lm_mse)\nlm_rmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"0.79? hmm. Thats almost 8% in error which is okay but I can do better. Lets try decision trees"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\ntree = DecisionTreeRegressor()\ntree.fit(X_train, y_train)\npredictions = tree.predict(X_test)\ntree_mse = mean_squared_error(y_test, predictions)\ntree_rmse = np.sqrt(tree_mse)\ntree_rmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1.0?? Thats even worse. Let's stick to linear regression"},{"metadata":{},"cell_type":"markdown","source":"# 6. Fine-tune Your Model"},{"metadata":{},"cell_type":"markdown","source":"I dont know how to do this so Ill just skip"},{"metadata":{},"cell_type":"markdown","source":"# 7. Present Your Solution"},{"metadata":{},"cell_type":"markdown","source":"In the end I was able to fit the data to a linear model with 92% accuracy. Maybe I'll revisit this once I am more experienced"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}