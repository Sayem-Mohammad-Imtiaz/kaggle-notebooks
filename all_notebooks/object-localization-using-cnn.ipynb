{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Importing Needed Libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pickle\nimport matplotlib.pyplot as plt\nfrom math import sqrt, ceil\nfrom timeit import default_timer as timer\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AvgPool2D, BatchNormalization, Reshape\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('../input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nprint(os.listdir('../input'))\n\n# Any results we write to the current directory are saved as output\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Opening file for reading in binary mode\nwith open('../input/traffic-signs-preprocessed/data2.pickle', 'rb') as f:\n    data = pickle.load(f, encoding='latin1')  # dictionary type\n\n# Preparing y_train and y_validation for using in Keras\ndata['y_train'] = to_categorical(data['y_train'], num_classes=43)\ndata['y_validation'] = to_categorical(data['y_validation'], num_classes=43)\n\n# Making channels come at the end\ndata['x_train'] = data['x_train'].transpose(0, 2, 3, 1)\ndata['x_validation'] = data['x_validation'].transpose(0, 2, 3, 1)\ndata['x_test'] = data['x_test'].transpose(0, 2, 3, 1)\n\n# Showing loaded data from file\nfor i, j in data.items():\n    if i == 'labels':\n        print(i + ':', len(j))\n    else: \n        print(i + ':', j.shape)\n\n# x_train: (86989, 32, 32, 3)\n# y_train: (86989, 43)\n# x_test: (12630, 32, 32, 3)\n# y_test: (12630,)\n# x_validation: (4410, 32, 32, 3)\n# y_validation: (4410, 43)\n# labels: 43\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n\n# Preparing function for ploting set of examples\n# As input it will take 4D tensor and convert it to the grid\n# Values will be scaled to the range [0, 255]\ndef convert_to_grid(x_input):\n    N, H, W, C = x_input.shape\n    grid_size = int(ceil(sqrt(N)))\n    grid_height = H * grid_size + 1 * (grid_size - 1)\n    grid_width = W * grid_size + 1 * (grid_size - 1)\n    grid = np.zeros((grid_height, grid_width, C)) + 255\n    next_idx = 0\n    y0, y1 = 0, H\n    for y in range(grid_size):\n        x0, x1 = 0, W\n        for x in range(grid_size):\n            if next_idx < N:\n                img = x_input[next_idx]\n                low, high = np.min(img), np.max(img)\n                grid[y0:y1, x0:x1] = 255.0 * (img - low) / (high - low)\n                next_idx += 1\n            x0 += W + 1\n            x1 += W + 1\n        y0 += H + 1\n        y1 += H + 1\n\n    return grid\n\n\n# Visualizing some examples of training data\nexamples = data['x_train'][:60, :, :, :]\nprint(examples.shape)  # (81, 32, 32, 3)\n\n# Plotting\nfig = plt.figure()\ngrid = convert_to_grid(examples)\nplt.imshow(grid.astype('uint8'), cmap='gray')\nplt.axis('off')\nplt.gcf().set_size_inches(15, 15)\nplt.title('Some examples of training data', fontsize=18)\nplt.show()\nplt.close()\n\n# Saving plot\nfig.savefig('training_examples.png')\nplt.close()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Building Model of CNN with Keras Back-end\n\n#Trying one model with filters of size 3x3 first\n\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=3, padding='same', activation='relu', input_shape=(32, 32, 3)))\nmodel.add(MaxPool2D(pool_size=2))\nmodel.add(Flatten())\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(43, activation='softmax'))\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Overfitting Small data\n\nannealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** (x + epochs))\nepochs = 15\n\nh = model.fit(data['x_train'][:10], data['y_train'][:10],\n              batch_size=5, epochs = epochs,\n              validation_data = (data['x_validation'], data['y_validation']),\n              callbacks=[annealer], verbose=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Epochs={0:d}, Train accuracy={1:.5f}, \\\n      Validation accuracy={2:.5f}'.\\\n      format(epochs, max(h.history['acc']), max(h.history['val_acc'])))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nplt.rcParams['figure.figsize'] = (15.0, 5.0) # Setting default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['image.cmap'] = 'gray'\n\nfig = plt.figure()\nplt.plot(h.history['acc'], '-o')\nplt.plot(h.history['val_acc'], '-o')\nplt.title('Overfitting small data', fontsize=18)\nplt.legend(['train', 'validation'], loc='upper left')\nplt.xlabel('Epoch', fontsize=15)\nplt.ylabel('Accuracy', fontsize=15)\nplt.show()\n\n# Saving plot\nfig.savefig('model_accuracy.png')\nplt.close()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now Building set of models of CNN with Keras\n\n#Trying different models with different sizes of filters\n\nfilters = [3,5,9,13,15,19,23,25,31]\nmodel = [0] * len(filters)\n\nfor i in range(len(model)):\n    model[i] = Sequential()\n    model[i].add(Conv2D(32, kernel_size=filters[i], padding='same', activation='relu', input_shape=(32, 32, 3)))\n    model[i].add(MaxPool2D(pool_size=2))\n    model[i].add(Flatten())\n    model[i].add(Dense(500, activation='relu'))\n    model[i].add(Dense(43, activation='softmax'))\n    model[i].compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** (x + epochs))\nepochs = 5\n\nh = [0] * len(model)\n\nfor i in range(len(h)):\n    h[i] = model[i].fit(data['x_train'], data['y_train'],\n                        batch_size=5, epochs = epochs,\n                        validation_data = (data['x_validation'], data['y_validation']),\n                        callbacks=[annealer], verbose=0)\n    \n    print('Model with filters {0:d}x{0:d}, Epochs={1:d}, Train accuracy={2:.5f}, \\\n      Validation accuracy={3:.5f}'.\\\n      format(filters[i], epochs, max(h[i].history['acc']), max(h[i].history['val_acc'])))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting comparison results for accuracy\n\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (15.0, 15.0) # Setting default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['image.cmap'] = 'gray'\nplt.rcParams[\"font.family\"] = 'Times New Roman'\n\n# Plotting history of training accuracy\nplt.subplot(2, 1, 1)\nplt.plot(h[8].history['acc'], '-o')\nplt.plot(h[7].history['acc'], '-s')\nplt.plot(h[6].history['acc'], '-D')\nplt.plot(h[5].history['acc'], '-D')\nplt.plot(h[4].history['acc'], '-o')\nplt.plot(h[3].history['acc'], '-o')\nplt.plot(h[2].history['acc'], '-o')\nplt.plot(h[1].history['acc'], '-o')\nplt.plot(h[0].history['acc'], '-o')\nplt.legend(['filter 31', 'filter 25', 'filter 23', 'filter 19', 'filter 15', 'filter 13', 'filter 9', 'filter 5', 'filter 3'], loc='lower right', fontsize='medium', borderpad=2)\nplt.xlabel('Epoch', fontsize=10, fontname='Times New Roman')\nplt.ylabel('Training Accuracy', fontsize=10, fontname='Times New Roman')\nplt.yscale('linear')  # {\"linear\", \"log\", \"symlog\", \"logit\", ...}\nplt.ylim(0.85, 1.0)\nplt.xlim(0.5, 5.3) \nplt.title('Accuracy for different sizes of filters', fontsize=18)\n\nplt.subplot(2, 1, 2)\n# plt.gca().set_title('Validation accuracy')\nplt.plot(h[8].history['val_acc'], '-o')\nplt.plot(h[7].history['val_acc'], '-s')\nplt.plot(h[6].history['val_acc'], '-D')\nplt.plot(h[5].history['val_acc'], '-D')\nplt.plot(h[4].history['val_acc'], '-o')\nplt.plot(h[3].history['val_acc'], '-o')\nplt.plot(h[2].history['val_acc'], '-o')\nplt.plot(h[1].history['val_acc'], '-o')\nplt.plot(h[0].history['val_acc'], '-o')\nplt.legend(['filter 31', 'filter 25', 'filter 23', 'filter 19', 'filter 15', 'filter 13', 'filter 9', 'filter 5', 'filter 3'], loc='lower right', fontsize='medium', borderpad=2)\nplt.xlabel('Epoch', fontsize=10, fontname='Times New Roman')\nplt.ylabel('Validation Accuracy', fontsize=10, fontname='Times New Roman')\nplt.yscale('linear')  # {\"linear\", \"log\", \"symlog\", \"logit\", ...}\nplt.ylim(0.75, 0.9)\nplt.xlim(0.5, 5.3) \n\nplt.show()\n\n# Saving plot\nfig.savefig('model_accuracy.png')\nplt.close()\n\n\n# Showing values of accuracy for different filters\nfor i in range(len(h)):\n    print('data2 filter {0:d} training accuracy = {1:.5f}'.\\\n          format(filters[i], np.max(h[i].history['acc'])))\n\nprint()\n\nfor i in range(len(h)):\n    print('data2 filter {0:d} training accuracy = {1:.5f}'.\\\n          format(filters[i], np.max(h[i].history['val_acc'])))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculating accuracy with testing dataset\n\nfor i in range(len(model)):\n    temp = model[i].predict(data['x_test'])\n    temp = np.argmax(temp, axis=1)\n\n    # We compare predicted class with correct class for all input images\n    # And calculating mean value among all values of following numpy array\n    # By saying 'testing_accuracy == data['y_test']' we create numpy array with True and False values\n    # 'np.mean' function will return average of the array elements\n    # The average is taken over the flattened array by default\n    temp = np.mean(temp == data['y_test'])\n    \n    print('data2 filter {0:d} testing accuracy = {1:.5f}'.format(filters[i], temp))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#time for calculation\n\n# Getting scores from forward pass of one input image\n# Scores is given for each image with 43 numbers of predictions for each class\n# Measuring at the same time execution time\n\nfor i in range(len(model)):\n    start = timer()\n    temp = model[i].predict(data['x_test'][:1, :, :, :])\n    end = timer()\n    \n    print('data2 filter {0:d} classification time = {1:.5f}'.format(filters[i], end - start))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualizing filters of convolutional layers\n\n\nfor i in range(len(model)):\n    w = model[i].get_weights()\n    print(w[0].shape)\n    # print(model[i].get_config())\n    # l = model[i].layers\n    # print(l[0].get_weights()[0].shape)\n\n    # Visualizing filters\n    temp = w[0].transpose(3, 0, 1, 2)\n    print(temp.shape)  # (81, 32, 32, 3)\n\n    # Plotting\n    fig = plt.figure()\n    grid = convert_to_grid(temp)\n    plt.imshow(grid.astype('uint8'), cmap='gray')\n    plt.axis('off')\n    plt.gcf().set_size_inches(10, 10)\n    name = 'Trained filters ' + str(filters[i]) + 'x' + str(filters[i])\n    plt.title(name, fontsize=18)\n    plt.show()\n    plt.close()\n\n    # Saving plot\n    name = 'filters-' + str(filters[i]) + 'x' + str(filters[i]) + '.png'\n    fig.savefig(name)\n    plt.close()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Predicting with one image from test dataset\n\n\n%matplotlib inline\n\n# Preparing image for predicting from test dataset\nx_input = data['x_test'][55:56]\nprint(x_input.shape)\ny_input = data['y_test'][55:56]\nprint(y_input)\n\nplt.rcParams['figure.figsize'] = (2.5, 2.5) # Setting default size of plots\nplt.imshow(x_input[0, :, :, :])\nplt.axis('off')\nplt.show()\n\n# Getting scores from forward pass of input image\nscores = model[0].predict(x_input)\nprint(scores[0].shape) # (43,)\n\n# Scores is given for image with 43 numbers of predictions for each class\n# Getting only one class with maximum value\nprediction = np.argmax(scores)\nprint('ClassId:', prediction)\n\n# Defining function for getting texts for every class - labels\ndef label_text(file):\n    # Defining list for saving label in order from 0 to 42\n    label_list = []\n    \n    # Reading 'csv' file and getting image's labels\n    r = pd.read_csv(file)\n    # Going through all names\n    for name in r['SignName']:\n        # Adding from every row second column with name of the label\n        label_list.append(name)\n    \n    # Returning resulted list with labels\n    return label_list\n\n\n# Getting labels\nlabels = label_text('../input/traffic-signs-preprocessed/label_names.csv')\n\n# Printing label for classified Traffic Sign\nprint('Label:', labels[prediction])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Saving Models\n\nfor i in range(len(model)):\n    name = 'model-' + str(filters[i]) + 'x' + str(filters[i]) + '.h5'\n    model[i].save(name)\n\n# # Saving model locally without committing\n# from IPython.display import FileLink\n\n# FileLink('model-3x3.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}