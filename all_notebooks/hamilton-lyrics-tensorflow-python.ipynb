{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://lionsgateccrc.org/wp-content/uploads/2018/10/hamilton.jpg)"},{"metadata":{},"cell_type":"markdown","source":"CREDITS to [anasofiauzsoy](https://www.kaggle.com/anasofiauzsoy/writing-hamilton-lyrics-with-tensorflow-r) for her Notebook written in R. This is a port to Python"},{"metadata":{},"cell_type":"markdown","source":"Hamilton is an incredibly popular musical about the life of Alexander Hamilton by Lin-Manuel Miranda. It's about five years old, but many people, like me, hadn't seen it until this past week, when the film version came out on Disney Plus.\n\nLet's see if we can take the lyrics from the show's songs, and use Tensorflow to build a text generation model to write new ones. I've used R in this notebook- if you're interested in seeing a Python version, leave a comment and let me know, and I can work on that. Let's get started!"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Import Packages\n\nimport tensorflow as tf\nfrom pathlib import Path\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom sklearn.feature_extraction import text\nimport matplotlib.pyplot as plt\nimport string\nimport re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_folder = Path(\"/kaggle/input\")\ninput_file = input_folder/\"hamilton-lyrics\"/\"ham_lyrics.csv\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(input_file,encoding = \"ISO-8859-1\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get Title Counts\ndf['title'].value_counts().sort_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter Data with more than 3 words\ndf = df[df['lines'].apply(lambda x: len(x.split(\" \")) > 3)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Punctuation Regex\npunct = re.compile(r'[!\\\\\"#$%&\\'()*+,-./:;<=>?@\\[\\]^_`{|}~0-9]+')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get Frequency Counts after processing => Lowercase + remove numbers, punctuation + strip whitespace\ncv = text.CountVectorizer(lowercase=True,preprocessor=lambda x: punct.sub(\"\",x.strip()).lower(),stop_words='english')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"op = cv.fit_transform(df[\"lines\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_freq = pd.DataFrame(op.toarray(),columns=cv.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_freq.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_words = df_freq.sum(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_words.sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wc = WordCloud(width=600,height=300).generate_from_frequencies(freq_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams[\"figure.figsize\"] = (20,5)\nplt.imshow(wc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Store processed text in a new column\ndf['cleaned_lines'] = df['lines'].apply(lambda x: punct.sub(\"\",x.strip()).lower())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Join lines of a song by title\ndf_song = df.groupby('title',sort=False).apply(lambda x: \" \".join(x['cleaned_lines']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_song.iloc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_words = 5000\noov_token = '<UNK>'\npad_type = 'post'\ntrunc_type = 'post'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer(num_words=num_words,oov_token=oov_token)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer.fit_on_texts(df_song)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seqs = tokenizer.texts_to_sequences(df_song)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_grams = 11\ngram_seqs = []\nn_seqs = len(seqs)\nfor i in seqs:\n    n_i = len(i)\n    for j in range(n_i-n_grams):\n        gram_seqs.append(i[j:j+n_grams])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = [i[-1] for i in gram_seqs]\ninputs = [i[:-1] for i in gram_seqs]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nfrom keras.utils import to_categorical\nfrom keras import Model\nfrom keras.layers import Dense, Embedding, LSTM, Input, Bidirectional","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_labels = to_categorical(labels,num_classes=num_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class lyrics_generator(Model):\n    def __init__(self):\n        super(lyrics_generator,self).__init__()\n        self.embedding = Embedding(num_words,64,input_length=n_grams-1)\n        self.lstm = Bidirectional(LSTM(20))\n        self.dense = Dense(num_words,activation='softmax')\n    \n    def call(self,x):\n        x = self.embedding(x)\n        x = self.lstm(x)\n        x = self.dense(x)\n        return x\n    \n    def model(self):\n        x = Input(shape=(n_grams-1))\n        return Model(inputs=[x], outputs=self.call(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = lyrics_generator()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = tf.data.Dataset.from_tensor_slices((inputs,encoded_labels)).batch(64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n          ,loss=tf.keras.losses.CategoricalCrossentropy()\n         ,metrics=[tf.keras.metrics.CategoricalAccuracy()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m.model().summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = m.fit(dataset,epochs=200,verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Loss: {} and Accuracy: {}\".format(history.history['loss'][-1],history.history['categorical_accuracy'][-1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def write_lyric(text,text_length=10):\n    for i in range(text_length):\n        seqs_test = tokenizer.texts_to_sequences([text])\n        seqs_test = pad_sequences(seqs_test,maxlen=n_grams-1,value=1)\n        pred_probs = m(seqs_test)\n        index = tf.argmax(pred_probs,axis=1)[0].numpy()\n        word = tokenizer.index_word[index]\n        text = text+\" \"+word\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"write_lyric(\"the man\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"write_lyric(\"he was\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"write_lyric(\"alexander\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"write_lyric(\"there was\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"write_lyric(\"it has\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"write_lyric(\"I am\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"write_lyric(\"Eliza\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"write_lyric(\"sir\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"write_lyric(\"Thomas Jefferson\",text_length=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}