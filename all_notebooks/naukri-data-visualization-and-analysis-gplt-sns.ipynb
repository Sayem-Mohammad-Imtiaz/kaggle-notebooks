{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Overview","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Job searching is one of the biggest concern for many people. It is important to know job market in general and understand the industry and role that you are interested in so that you can better prepare for entering an new industry or job-hopping. In this project, I will first investigate job market geographically, second experience requirement and last key skills requirement, industry wise.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Preparation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 1. Load Data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import csv\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n%matplotlib inline\nimport geopandas as gpd\nimport geoplot as gplt\n\n# data = []\n# with open('/kaggle/input/jobs-on-naukricom/home/sdf/marketing_sample_for_naukri_com-jobs__20190701_20190830__30k_data.csv', newline='', encoding=\"utf8\") as csvfile:\n#     spamreader = csv.reader(csvfile)\n#     for row in spamreader:\n#         sub = np.array(row)\n#         if sub[2] == \"\":\n#             continue\n#         data.append(sub)\npd.set_option('display.max_columns',15)\npd.set_option('display.max_rows',None)\ndata_df=pd.read_csv('/kaggle/input/jobs-on-naukricom/home/sdf/marketing_sample_for_naukri_com-jobs__20190701_20190830__30k_data.csv')\n# data = np.array(data)\ndata_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Data wrangling","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 1). What's the data type in each column?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> #### 2). Is there any missing data?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.isna().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3). Let's check the pattern and frequency of the missing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(data_df.isnull(),cbar=True,cmap='gnuplot')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4). How many data are missing in each column?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_col = ['Job Title', 'Job Salary', 'Job Experience Required', 'Key Skills', 'Role Category', 'Location', 'Functional Area', 'Industry', 'Role']\nmissing = []\nfor col in selected_col:\n    print('Number of missing data in', col,':', data_df[col].isna().value_counts()[1])\n    missing.append((col, data_df[col].isna().value_counts()[1]))\nprint('Total number of missing data :', len(data_df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing.sort(key=lambda x: x[1], reverse = True)\nx_pos = [i for i in range(len(missing))]\nnums = [words[1] for words in missing]\nx = [words[0] for words in missing]\nsns.set(rc={'figure.figsize':(19,9)})\nsns.barplot(x=x, y=nums)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 5). Drop missing data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.dropna(axis=0,inplace=True)\ndata_df.isna().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualize Jobs Market on India Map¶","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> ### 1. Get a india map! We will visualize the number of jobs in the India Map.\nThere are 4000 cities and towns in India and it would be too messy to visualize each of them on the map. Therefore, I choose to visualize job market in 28 states and 8 union territories in India¶","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fp = '../input/data-ana-for-jobs-on-naukri-supplements/india-polygon.shp'\nmap_df = gpd.read_file(fp)\nmap_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"map_df[\"st_nm\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2). Location Information Cleaning \nAfter inspecting the location data in data frame, I decide to delete everything in the \"()\" because they are location included in the preceding term (Ex:Delhi (Bhikaji Cama) )","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# ind will pass the industry into the function, if ind == '', this means that we are looking at all industries\ndef get_ind_city_cnt(ind):\n    cityCnt = {}\n    sub_data = data_df[data_df['Industry'].str.contains(ind)]\n    for i in range(len(sub_data)):\n        cities = sub_data.iloc[i, 7]\n        if \"(\" in cities:\n            index = cities.find(\"(\")\n            cities = cities[:index]\n        cities = cities.split(\",\")\n        uniqueCities = set()\n        for city in cities:\n            tmp = city\n            # cleaning data\n            if \")\" in tmp:\n                print(city)\n            if \"/\" in tmp:\n                sameName = city.split(\"/\")\n                sameName.sort()\n                tmp = sameName[0]\n            tmp = tmp.strip()\n            uniqueCities.add(tmp.lower())\n        for city in uniqueCities:\n            cityCnt[city] = cityCnt.get(city, 0) + 1\n\n    # some location information need to be deleted\n    cleanSet = [\"electronics city\", \"1700000\", \"300000\", \"400000\", \"500000\", \"700000\"]\n    for i in cleanSet:\n        if i in cityCnt:\n            del cityCnt[i]\n    return cityCnt\ncityCnt = get_ind_city_cnt(\"\")\nprint(\"Number of unique locations in dataset is\", len(cityCnt))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Map locations to states\nMapping strategy: map locations to state -> sum up jobs for each state -> plot on the map\n#### 1). map loations to state\nIn order to map locations that includes, cities, towns, and states, we a dataset that tell us which state these locations belong to.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cityData = pd.ExcelFile(\"../input/data-ana-for-jobs-on-naukri-supplements/Town_Codes_2001.xls\")\ncity_df = cityData.parse(\"Sheet1\")\ncity_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2). Find unmatched states between two dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"notFound = set([])\nfor name in city_df[\"State/Union territory\"]:\n    if map_df[map_df[\"st_nm\"].isin([name])].empty:\n        notFound.add(name)\nnotFound","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3). Let's creat a mapping between unmatched names in two datasets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"stateTran = {'Andaman & Nicobar Islands *':'Andaman and Nicobar Islands' ,\n             \"Chandigarh *\":'Chandigarh' ,\n             \"Dadra & Nagar Haveli *\":'Dadra and Nagar Haveli',\n             \"Daman & Diu *\":'Daman and Diu',\n             \"Lakshadweep *\":'Lakshadweep',\n             \"Delhi *\":'Delhi',\n             \"Pondicherry *\":'Puducherry',\n             \"Uttaranchal\": 'Uttarakhand',\n             \"Orissa\":'Odisha',\n             \"Jammu & Kashmir\": 'Jammu and Kashmir'\n            }","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4). Find unmatched cities between naukri job data and city_state data and create another mapping relation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"notFoundCities = []\ncityToState = {}\nfor name in cityCnt.keys():\n    if name == \"\":\n        continue\n    tmp = name[0].upper()+name[1:]\n    if city_df[city_df[\"City/Town\"].isin([tmp])].empty:\n        if city_df[city_df[\"State/Union territory\"].isin([tmp])].empty:\n            sub = tmp.split()\n            add = False\n            for i in sub:\n                i = i[0].upper()+i[1:]\n                if city_df[city_df[\"City/Town\"].isin([i])].empty and city_df[city_df[\"State/Union territory\"].isin([i])].empty:\n                    add = True\n                else:\n                    add = False\n            if add:\n                notFoundCities.append(name)\nprint(\"Number of location that is no matched in either cities or states\",len(notFoundCities))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I have saved all unmatched locations into a file so that it looks cleaner and compact in the code","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Save\n# np.save('unmatchedLocations.npy', cityTran) \n\n# Load\ncityTran = np.load('../input/data-ana-for-jobs-on-naukri-supplements/unmatchedLocations.npy',allow_pickle='TRUE').item()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Sum up location for each state","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# retrieve state according to its location\ndef getState(city):\n    if city == \"\":\n        return \"\"\n    tmp = city[0].upper()+city[1:]\n    if city_df[city_df[\"City/Town\"].isin([tmp])].empty:\n        if city_df[city_df[\"State/Union territory\"].isin([tmp])].empty:\n            sub = tmp.split()\n            add = False\n            for i in sub:\n                i = i[0].upper()+i[1:]\n                if city_df[city_df[\"City/Town\"].isin([i])].empty:\n                    if city_df[city_df[\"State/Union territory\"].isin([i])].empty:\n                        add = True\n                    else:\n                        return city_df.loc[city_df[\"State/Union territory\"]==i][\"State/Union territory\"].values[0]\n                else:\n                    return city_df.loc[city_df[\"City/Town\"]==i][\"State/Union territory\"].values[0]\n                    \n            if add:\n                return \"\"\n    else:\n        return city_df.loc[city_df[\"City/Town\"]==tmp][\"State/Union territory\"].values[0]\n\n# translate the state\ndef validState(state):\n    if state in stateTran:\n        return stateTran[state]\n    else:\n        return state\n\n# get the number of jobs with respect to its state\ndef get_state_cnt(cityCnt):\n    stateCnt = {}\n    missing = []\n    for city, num in cityCnt.items():\n        state = getState(city)\n        if state == \"\" or state is None:\n            if city in cityTran:\n                state = validState(cityTran[city])\n                stateCnt[state] = stateCnt.get(state, 0) + num\n            else:\n                missing.append(city)\n\n        else:\n            state = validState(state)\n            stateCnt[state] = stateCnt.get(state, 0) + num\n    return stateCnt, missing\n\nstateCnt, missing = get_state_cnt(cityCnt)\nprint(\"The number of locations that is still not mapped to states\", len(missing))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that our cleaning is successful. These location information can not be mapped to states on india map¶","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"missing","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Plot the job info on the india map","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_geo(stateCnt, ind):\n    stateData = []\n    for key, val in stateCnt.items():\n        stateData.append((key, val))\n    for state in map_df[\"st_nm\"]:\n        if state not in stateCnt:\n            stateData.append((state, 0))\n    \n    jobNum = [0 for _ in range(len(DATA_df))]\n    new_col = ind+\" Number of Jobs\"\n    DATA_df[new_col] = jobNum\n    \n    for state, num in stateData:\n        DATA_df.loc[DATA_df[\"st_nm\"] == state, new_col] = num\n    merged= map_df.merge(DATA_df, on = \"st_nm\", how = \"left\")\n    \n    fig, ax = plt.subplots(1, figsize=(10, 10))\n    ax.axis(\"off\")\n    ax.set_title(ind+\" Job data\", fontdict={\"fontsize\": \"25\", \"fontweight\" : \"10\"})\n    merged.plot(column=new_col,cmap=\"YlGnBu\", linewidth=0.8, ax=ax, edgecolor=\"0\", legend=True,markersize=[39.739192*2, -104.990337*2])\n    plt.show()\n    merged = merged.sort_values(new_col, ascending=False)\n    sns.barplot(x=merged['st_nm'][:10], y=merged[new_col][:10])\n    \ndef ind_geo_dist(ind):\n    city_cnt = get_ind_city_cnt(ind)\n    state_cnt, missing = get_state_cnt(city_cnt)\n    plot_geo(state_cnt, ind)\n\nDATA_df = pd.read_excel(\"../input/data-ana-for-jobs-on-naukri-supplements/data_ecxel.xlsx\")\nDATA_df.rename(columns={\"Name of State / UT\": \"st_nm\"},inplace=True)\nind_geo_dist(\"\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that India job opportunities was not evenly dstributed. Some areas have way more jobs than other areas. Maharashtra,  Karnataka, Uttar Pradesh are the top 3 states that provide job opportunities","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Industry & Geo Distribution\n### 1. How does job distribution vary according to each industry?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df['Industry'].value_counts()[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As the \"IT-Software / Software Services\" is the same as \"IT-Software, Software Services\" and \"Recruitment / Staffing\" is the same as \"Recruitment , Staffing\" , let's first merge two data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.loc[data_df['Industry'].str.contains('IT-Software / Software Services',case=False)]='IT-Software, Software Services'\ndata_df.loc[data_df['Industry'].str.contains('Recruitment / Staffing',case=False)]='Recruitment , Staffing'\ndata_df['Industry'].value_counts()[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"We will focus on the top 10 industries because they compose\", '{:.1%}'.format(sum(data_df['Industry'].value_counts()[:10])/len(data_df)), 'of all data')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_ten_state = data_df['Industry'].value_counts()[:10].index\nfor ind in top_ten_state:\n    ind_geo_dist(ind)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Job seekers may take these as a reference when thinking of moving from one place to another to pursue a career in specific industires\nOf course, it is clear that Maharashtra the most opportunities. Other factors, such as living costs, living environment and salary should also be considered.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Job Salary","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df['Job Salary'].value_counts()[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As most of the information is not disclosed, we will not further investigate on these","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Job Experience","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df['Job Experience Required'].value_counts()[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We see that there're many entry is overlapped with one another. I'd like to set them into 4 categories<br>0-1 -> Newbie <br>1-5 -> Semiprofessional<br> 5-10 -> Professional<br>10-?  Expert\n### 1. Create a new column for \"Experience Categories\"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"exp_cat = ['' for _ in range(len(data_df))]\ndata_df['Experience Categories'] = exp_cat\ndata_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Let's map the \"Job Experience Required\" to \"Experience Categories\" according to the categories I created above\nNote that 1-7 will be classified as both semiprofessional and professional","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"CAT = {(0, 1):\"Newbie\", (1, 5):\"Semiprofessional\", (5, 10):\"Professional\", (10, 100):\"Expert\"}\ndef get_cat(yrs):\n    if len(yrs) != 2:\n        return \"\"\n    start, end = str(yrs[0]), str(yrs[1])\n    start, end = start.strip(), end.strip()\n    if not start.isnumeric():\n        return \"\"\n    start, end = int(start), int(end)\n    res = ''\n    for key, val in CAT.items():\n        if start <= key[1] and end > key[0]:\n            res += ' ' + val\n    if start >= 10:\n        res += ' Expert'\n    res = res.strip()\n    return res\n\nfor i in range(len(data_df)):\n    job_req = data_df.iloc[i, 4].lower()\n    #print(job_req)\n    index = job_req.find('y')\n    job_req = job_req[:index]\n    yrs = job_req.split('-')\n    cat = get_cat(yrs)\n    data_df.iloc[i, -1] = cat\n\ndata_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Great! Now, let's see how many jobs are in each category","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"value_cnt = {\"Newbie\":0, \"Semiprofessional\":0, \"Professional\":0, \"Expert\":0}\nfor i in range(len(data_df)):\n    sub_cat = data_df.iloc[i, -1]\n    sub_cat = sub_cat.split()\n    for key in value_cnt.keys():\n        if key in sub_cat:\n            value_cnt[key] += 1\nfor key, val in value_cnt.items():\n    print(key, \":\", val)\nplt.pie(x=[val for val in value_cnt.values()], labels=[key for key in value_cnt.keys()], autopct='%1.1f%%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Many company needs semiprofessional and professional. Meanwhile, newbie is also welcome. However, experts is not in urgent for many company.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Industry & Experience\n### 1. How do different industries relate to experience requirement?\n#### 1). Newbie Recruitment","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df = data_df[data_df['Experience Categories'].str.contains('Newbie', case=True)]\nnew_cnt = new_df['Industry'].value_counts()\nplot = new_cnt[:10].plot.pie(figsize=(7, 7), autopct='%.1f')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2). Semiprofessional Recruitment","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"semipro_df = data_df[data_df['Experience Categories'].str.contains('Semiprofessional', case=True)]\nsemipro_cnt = semipro_df['Industry'].value_counts()\nplot = semipro_cnt[:10].plot.pie(figsize=(7, 7), autopct='%.1f')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3). Professional Recruitment","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pro_df = data_df[data_df['Experience Categories'].str.contains('Professional', case=True)]\npro_cnt = pro_df['Industry'].value_counts()[:10]\nplot = pro_cnt[:10].plot.pie(figsize=(7, 7), autopct='%.1f')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4). Expert Recruitment","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"exp_df = data_df[data_df['Experience Categories'].str.contains('Expert', case=True)]\nexp_cnt = exp_df['Industry'].value_counts()[:10]\nplot = exp_cnt[:10].plot.pie(figsize=(7, 7), autopct='%.1f')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pie charts tell us that jobs opportunites provided by each industry at 4 experience levels. As IT industry provides more job opportunities, it is not quite useful if we want to know whether some industries prefer semiprofessal over others or reverse.\n### 2. Let's look at recruitment patterns in each industry\n#### 1). Merge data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pro_cnt = pd.DataFrame(pro_cnt)\npro_cnt.reset_index(inplace=True)\npro_cnt.rename(columns={'Industry':'Professional'},inplace=True)\nsemipro_cnt = pd.DataFrame(semipro_cnt)\nsemipro_cnt.reset_index(inplace=True)\nsemipro_cnt.rename(columns={'Industry':'Semiprofessional'},inplace=True)\nnew_cnt = pd.DataFrame(new_cnt)\nnew_cnt.reset_index(inplace=True)\nnew_cnt.rename(columns={'Industry':'Newbie'},inplace=True)\nexp_cnt = pd.DataFrame(exp_cnt)\nexp_cnt.reset_index(inplace=True)\nexp_cnt.rename(columns={'Industry':'Expert'},inplace=True)\nmerged = new_cnt.merge(semipro_cnt, on = \"index\", how = \"left\")\nmerged = merged.merge(pro_cnt, on = \"index\", how = \"left\")\nmerged = merged.merge(exp_cnt, on = \"index\", how = \"left\")\nmerged.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2). Convert Nan to 0 and label correct name for columns and check dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"merged = merged.fillna(0)\nmerged.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3). Convert number to percentage in order to find out which industry prefer professional, semiprofessional or newbie. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"total, per_semi, per_pro, per_new, per_exp= [], [], [], [], []\n\nfor i in range(len(merged)):\n    sub_t = merged[\"Semiprofessional\"][i] + merged[\"Professional\"][i] + merged[\"Newbie\"][i]+merged['Expert'][i]\n    total.append(sub_t)\n    per_semi.append(merged['Semiprofessional'][i] / sub_t)\n    per_pro.append(merged['Professional'][i] / sub_t)\n    per_new.append(merged['Newbie'][i] / sub_t)\n    per_exp.append(merged['Expert'][i] / sub_t)\nmerged[\"Total Number of Jobs\"] = total\nmerged[\"Percent of Semipro\"] = per_semi\nmerged[\"Percent of Pro\"] = per_pro\nmerged[\"Percent of New\"] = per_new\nmerged[\"Percent of Exp\"] = per_exp\nmerged.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note: As some jobs is available for two or more experience categories, total number of jobs may increase for each industry\n#### 4). Let's plot the recruitment pattern for top ten industries¶","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(5, 2, figsize=(15, 20))\nfor i in range(5):\n    for j in range(2):\n        val = [merged.iloc[i*2+j, k] for k in range(6, 10)]\n        index = ['Percent of Semipro', 'Percent of Pro', 'Percent of New', 'Percent of Exp']\n        tmp = pd.DataFrame({\"Val\":val}, index = index)\n        axs[i, j].pie(tmp, autopct='%.0f%%', labels=tmp.index)\n        axs[i, j].set_title(merged.iloc[i*2+j,0] + ' Recruitment Pattern')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged = merged.sort_values(\"Percent of New\", ascending=False)\nprint('<', merged.iloc[0][0], '> is The industry that recruits most Newbies','\\nPercent of recruitment is', '{:.1%}'.format(merged.iloc[0][8]))\nmerged = merged.sort_values(\"Percent of Semipro\",ascending=False)\nprint('<', merged.iloc[0][0], '> is The industry that recruits most Semiprofessionals','\\nPercent of recruitment is', '{:.1%}'.format(merged.iloc[0][6]))\nmerged = merged.sort_values(\"Percent of Pro\",ascending=False)\nprint('<', merged.iloc[0][0], '> is The industry that recruits most Professionals','\\nPercent of recruitment is', '{:.1%}'.format(merged.iloc[0][7]))\nmerged = merged.sort_values(\"Percent of Exp\",ascending=False)\nprint('<', merged.iloc[0][0], '> is The industry that recruits most Experts','\\nPercent of recruitment is', '{:.1%}'.format(merged.iloc[0][9]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('<', merged.iloc[0][0], '> is The industry that recruits least Newbies','\\nPercent of recruitment is', '{:.1%}'.format(merged.iloc[-1][8]))\nprint('<', merged.iloc[0][0], '> is The industry that recruits least Semiprofessionals','\\nPercent of recruitment is', '{:.1%}'.format(merged.iloc[-1][6]))\nprint('<', merged.iloc[0][0], '> is The industry that recruits least Professionals','\\nPercent of recruitment is', '{:.1%}'.format(merged.iloc[-1][7]))\nprint('<', merged.iloc[0][0], '> is The industry that recruits least Experts','\\nPercent of recruitment is', '{:.1%}'.format(merged.iloc[-1][9]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note: there're multiple industries whose recruitment percent may be the same","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Skills for Top 10 Industries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\ndef topSkills(Industry):\n    ind = data_df[data_df['Industry'] == Industry]\n    keySkill = ind['Key Skills'].value_counts()\n    keySkill.head()\n    skillCnt = {}\n    wcloud = []\n    for row, cnt in keySkill.iteritems():\n        skill_arr = row.split('|')\n        for skill in skill_arr:\n            skill = skill.strip().lower()\n            skillCnt[skill] = skillCnt.get(skill, 0) + cnt\n            for i in range(cnt):\n                wcloud.append(skill)\n    skillCnt = pd.Series(skillCnt).to_frame('Count')\n    skillCnt.reset_index(inplace=True)\n    skillCnt.rename(columns={'index':'Skill'},inplace=True)\n    skillCnt.head()\n    #print(skillCnt)\n    skillCnt = skillCnt.sort_values(\"Count\",ascending=False)\n    skillRange = 10 if len(skillCnt) >= 10 else len(skillCnt)\n    ax = skillCnt.head(skillRange).plot(kind='bar', figsize=(9, 5))\n    plt.xticks(range(skillRange), skillCnt.head(skillRange)['Skill'])\n    ax.set_ylabel(\"Total Number of Skill\")\n    ax.set_xlabel(\"Skill\")\n    t = Industry+\" Industry Top Skills\"\n    plt.title(t)\n    wordcloud = WordCloud(width = 500, height = 500, \n                    background_color ='white', \n                    min_font_size = 10).generate(str(wcloud))\n    plt.figure(figsize = (8, 8), facecolor = None) \n    plt.imshow(wordcloud) \n    plt.axis(\"off\") \n    plt.tight_layout(pad = 0) \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1. Let's see what are the top 10 key skills in IT industry¶","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"topSkills('IT-Software, Software Services')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Let's see what are the top 10 key skills in Recuitment industry","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"topSkills('Recruitment, Staffing')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Let's see what are the top 10 key skills in BPO Call Center industry","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"topSkills('BPO, Call Centre, ITeS')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. Let's see what are the top 10 key skills in Banking, Finanacial Services, Broking industry¶","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"topSkills('Banking, Financial Services, Broking')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5. Let's see what are the top 10 key skills in Education, Teaching, Training industry","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"topSkills('Education, Teaching, Training')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6. Let's see what are the top 10 key skills in Medical, Healthcare, Hospitals industry¶","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"topSkills('Medical, Healthcare, Hospitals')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 7. Let's see what are the top 10 key skills in Strategy, Management Consulting Firms industry¶","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"topSkills(\"Strategy, Management Consulting Firms\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 8. Let's see what are the top 10 key skills in Internet, Ecommerce industry¶","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"topSkills(\"Internet, Ecommerce\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 9. Let's see what are the top 10 key skills in Meida, Intertainment, Internet industry","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"topSkills(\"Media, Entertainment, Internet\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 10. Let's see what are the top 10 key skills in Travel , Hotels , Restuarants , Airlines , Railways industry","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"topSkills(\"Travel , Hotels , Restaurants , Airlines , Railways\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Job Title\n### 1. Let's see the number of different type of Job Title","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"jobTitle = data_df['Job Title']\ndic = {}\nfor job in jobTitle:\n    dic[job] = dic.get(job, 0) + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def findTop(arr, key, val, num):\n    arr.append((val, key))\n    arr.sort(reverse=True)\n    if len(arr) > num:\n        arr.pop()\n    \nuniequeJobTitle = []\ntopTenJobTitle = []\nfor key, val in dic.items():\n    findTop(topTenJobTitle, key, val, 10)\n    if val == 1:\n        uniequeJobTitle.append(key)\nprint(len(uniequeJobTitle), \"number of unique Job Title\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_pos = [i for i in range(len(topTenJobTitle))]\nnums = [words[0] for words in topTenJobTitle]\nx = [words[1] for words in topTenJobTitle]\nax = sns.barplot(x=x, y=nums)\nax.set(xlabel=\"Top 10 Job Title\", ylabel = \"Occurence of the Top 10 Job Title\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"OK，some recruiters put the industry into the job. Let's take IT industry out.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"uniequeJobTitle = []\ntopTenJobTitle = []\nfor key, val in dic.items():\n    findTop(topTenJobTitle, key, val, 11)\n    if val == 1:\n        uniequeJobTitle.append(key)\nx_pos = [i for i in range(10)]\nnums = [words[0] for words in topTenJobTitle[1:11]]\nx = [words[1] for words in topTenJobTitle[1:11]]\nax = sns.barplot(x=x, y=nums)\nax.set(xlabel=\"Top 10 Job Title\", ylabel = \"Occurence of the Top 10 Job Title\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Keywords in job title","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"keywords = {}\nwordFilter = [\"for\", \"in\", \"opening\", \"\"]\nfor key, val in dic.items():\n    for sub in key.split():\n        if sub in \"~!@#$%^&*()-=+~\\|]}[{';: /?.>,<.\" or sub.lower() in wordFilter:\n            continue\n        keywords[sub] = keywords.get(sub, 0) + val\nprint(\"Number of keywords\", len(keywords))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"topTwentyKeywords = []\nfor key, val in keywords.items():\n    findTop(topTwentyKeywords, key, val, 20)\nx_pos = [i for i in range(len(topTwentyKeywords))]\nnums = [words[0] for words in topTwentyKeywords]\nx = [words[1] for words in topTwentyKeywords]\nax = sns.barplot(x=x, y=nums)\nax.set(xlabel=\"Top 20 Keywords\", ylabel = \"Occurence of the top 20 keywords in Job Title\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. \"Urgent\" stands for job that needs people immediately. Let's find out what kind of job is urgent and where these jobs are.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"jobTypeInUrgent = {}\ncounter = 0\nfor index, job in data_df.iterrows():\n    if job['Job Title'].lower().find(\"urgent\") >= 0 and job['Role Category']:\n        jobTypeInUrgent[job['Role Category']] = jobTypeInUrgent.get(job['Role Category'], 0) + 1\n        \ntopTwentyJobInUrgent = []\nfor key, val in jobTypeInUrgent.items():\n    findTop(topTwentyJobInUrgent, key, val, 10)\n\nx_pos = [i for i in range(len(topTwentyJobInUrgent))]\nnums = [words[0] for words in topTwentyJobInUrgent]\nx = [words[1] for words in topTwentyJobInUrgent]\nax = sns.barplot(x=x, y=nums)\nax.set(xlabel=\"Top 20 Urgent Roles\", ylabel = \"Occurence of the top 20 Urgent Role\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that Programming & Design has the highest demands and there's still a lot of needs on voice people.\nI was suprised that teacher is also in top twenty urgent roles.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### IT industry is definitely the most popular and needed jobs in India. I hope this analysis provides sufficient information on location, skill set requirements, experience requirements, etc, that may help job seekers to pursue professional interests.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}