{"cells":[{"metadata":{"id":"I3sEhaF537L2","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"id":"mPowpJOi37MH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":79},"outputId":"11ce5e35-7807-4591-bc36-1812c46ffe37","trusted":true},"cell_type":"code","source":"from keras.layers import Input, Dense\nfrom keras.models import Model\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"id":"CVQ-4T_TKLWn","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')\n# from google.colab import files\n# uploaded = files.upload()","execution_count":null,"outputs":[]},{"metadata":{"id":"azGx-WAN37MT","colab_type":"code","outputId":"bec5a5a5-7bda-4b38-df9a-281aac331b08","colab":{"base_uri":"https://localhost:8080/","height":436},"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/wholesale-customers-data-set/Wholesale customers data.csv')\n\nX = df.iloc[:,1:] # Features\ny = df.iloc[:,:-7] # Target variable\nprint(X)\nprint(y)","execution_count":null,"outputs":[]},{"metadata":{"id":"w5RYPmFd37Mg","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"normalized_X = preprocessing.normalize(X)","execution_count":null,"outputs":[]},{"metadata":{"id":"EYUUrk2S37Mr","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(normalized_X, y, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"id":"NoJ12RDy37M2","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"encoding_dim = 4\ninput_dim = 7\n\n# this is our input placeholder\ninput_img = Input(shape=(input_dim,))\n# \"encoded\" is the encoded representation of the input\nencoded = Dense(encoding_dim)(input_img)\n# \"decoded\" is the lossy reconstruction of the input\ndecoded = Dense(input_dim)(encoded)\n\n# this model maps an input to its reconstruction\nautoencoder = Model(input_img, decoded)\n\n# this model maps an input to its encoded representation\nencoder = Model(input_img, encoded)\n\n# create a placeholder for an encoded (2-dimensional) input\nencoded_input = Input(shape=(encoding_dim,))\n# retrieve the last layer of the autoencoder model\ndecoder_layer = autoencoder.layers[-1]\n# create the decoder model\ndecoder = Model(encoded_input, decoder_layer(encoded_input))\n\nautoencoder.compile(loss='mean_squared_logarithmic_error', optimizer='adam',metrics=['accuracy'])\n\nautoencoder.fit(X_train, X_train,\n                epochs=150,\n                batch_size=40,\n                shuffle=True,\n                validation_data=(X_test, X_test))\n\n# encode and decode some data points\n# note that we take them from the *test* set\nencoded_datapoints = encoder.predict(X_test)\ndecoded_datapoints = decoder.predict(encoded_datapoints)","execution_count":null,"outputs":[]},{"metadata":{"id":"ZBHpZQ5C37NC","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# print('Original Datapoints :')\n# print(X_test)\n# print('Reconstructed Datapoints :')\n# print(decoded_datapoints)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"id":"Ism4sfPc37NJ","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans","execution_count":null,"outputs":[]},{"metadata":{"id":"f2_xHvCY37NO","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Display the results of the clustering from implementation for 2 clusters\nclusterer = KMeans(n_clusters = 2 ,init='k-means++', n_init = 10 ,max_iter=300, \n                        tol=0.0001,  random_state=111, algorithm='elkan')\nclusterer.fit(decoded_datapoints)\npreds = clusterer.predict(decoded_datapoints)\ncenters = clusterer.cluster_centers_\nprint(preds)","execution_count":null,"outputs":[]},{"metadata":{"id":"hqzfGWhe37NT","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score,classification_report,confusion_matrix\nle = LabelEncoder()\nnew_y = le.fit_transform(y_test)\nprint(accuracy_score(new_y,preds))\nprint(confusion_matrix(new_y,preds))\nprint(classification_report(new_y,preds))","execution_count":null,"outputs":[]},{"metadata":{"id":"10Qv0RgF37NZ","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# for i in range(len(preds)):\n#     print(str(new_y[i])+\" : \"+str(preds[i]))","execution_count":null,"outputs":[]},{"metadata":{"id":"A30j708B37Nc","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"plt.scatter(decoded_datapoints[:,0],decoded_datapoints[:,1],c=clusterer.labels_,cmap='viridis')\nplt.scatter(clusterer.cluster_centers_[:,0],clusterer.cluster_centers_[:,1],marker='p',c='r',linewidths=7)\nplt.xlabel(\"Cluster Coefficients\")\nplt.title(\"KMeans Clustering\")\nplt.ylabel(\"Clustering Values\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"EXPT3A.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":1}