{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import accuracy_score, matthews_corrcoef, f1_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split, KFold\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the dataset\ndataset = pd.read_csv('../input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv')\nx = dataset.iloc[:, :-2]\ny = dataset.iloc[:,-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Ranking\nplt.rcParams['figure.figsize']=15,6 \nsns.set_style(\"darkgrid\")\n\nmodel = ExtraTreesClassifier()\nmodel.fit(x,y)\nprint(model.feature_importances_) \nfeat_importances = pd.Series(model.feature_importances_, index=x.columns)\nfeat_importances.nlargest(12).plot(kind='barh')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature Ranking\nplt.rcParams['figure.figsize']=15,6 \nsns.set_style(\"darkgrid\")\n\nmodel = RandomForestClassifier()\nmodel.fit(x,y)\nprint(model.feature_importances_) \nfeat_importances = pd.Series(model.feature_importances_, index=x.columns)\nfeat_importances.nlargest(12).plot(kind='barh')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using different variations of factors\n#Some indexes (4-ejection fraction,7-serum_creatinine,0-age,2-creatinine_phosphokinase,6-platelets,8-serum_sodium)\nx = dataset.iloc[:,[4,7,0]].values\ny = dataset.iloc[:,-1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining function which takes model, x, y and returns accuracy, f1score, matthews_correlation_coefficient\ndef get_model_results(model,x,y):\n    \n    model_confusion_matrix = np.array([[0,0],[0,0]])\n    acclist, f1slist = [],[]\n    \n    # Splitting the dataset into training set and test set\n    kf = KFold(n_splits=10)\n    for train_index, test_index in kf.split(x):\n        #print(\"train:\",train_index,\"test:\",test_index)\n        x_train, x_test = x[train_index], x[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n\n        # Feature Scaling\n        sc = StandardScaler()\n        x_train = sc.fit_transform(x_train)\n        x_test = sc.transform(x_test)\n\n        #Model training\n        model.fit(x_train, y_train)\n        y_pred = model.predict(x_test)\n        model_confusion_matrix += confusion_matrix(y_test,y_pred)\n        acclist.append(accuracy_score(y_test,y_pred))\n        f1slist.append(f1_score(y_test,y_pred))\n    \n    [[tp,fp],[tn,fn]] = model_confusion_matrix\n    mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n    metriclist = [np.mean(acclist),np.mean(f1slist),mcc]\n    return metriclist\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modellist = []\nmodellist.append()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"cfm = []\nmodel_confusion_matrix = np.array([[0,0],[0,0]])\nacclist, f1slist, mcclist = [],[],[]\n# Splitting the dataset into training set and test set\nfrom sklearn.model_selection import train_test_split\nfor i in range(0,100):\n    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2,random_state=i)\n\n    # Feature Scaling\n    from sklearn.preprocessing import StandardScaler\n    sc = StandardScaler()\n    x_train = sc.fit_transform(x_train)\n    x_test = sc.transform(x_test)\n\n    #Logistic Regression\n    from sklearn.linear_model import LogisticRegression\n    classifier = LogisticRegression()\n    classifier.fit(x_train, y_train)\n    y_pred = classifier.predict(x_test)\n    model_confusion_matrix += confusion_matrix(y_test,y_pred)\n    calc_acc_mcc_f1s(y_test,y_pred)\n    append_eval()\n[[tp,fp],[tn,fn]] = model_confusion_matrix\nmcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\nlrlist = [mean(acclist),mean(f1slist),mcc]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using 10-fold cross validation\nmodel_confusion_matrix = np.array([[0,0],[0,0]])\nacclist, f1slist, mcclist = [],[],[]\n# Splitting the dataset into training set and test set\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.metrics import matthews_corrcoef, confusion_matrix, f1_score, accuracy_score\nimport numpy as np\n\nkf = KFold(n_splits=10)\nfor train_index, test_index in kf.split(x):\n    #print(\"train:\",train_index,\"test:\",test_index)\n    x_train, x_test = x[train_index], x[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    \n    #x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2,random_state=i)\n\n    # Feature Scaling\n    from sklearn.preprocessing import StandardScaler\n    sc = StandardScaler()\n    x_train = sc.fit_transform(x_train)\n    x_test = sc.transform(x_test)\n\n    #Logistic Regression\n    from sklearn.linear_model import LogisticRegression\n    classifier = LogisticRegression()\n    classifier.fit(x_train, y_train)\n    y_pred = classifier.predict(x_test)\n    model_confusion_matrix += confusion_matrix(y_test,y_pred)\n    acclist.append(accuracy_score(y_test,y_pred))\n    f1slist.append(f1_score(y_test,y_pred))\n    \n[[tp,fp],[tn,fn]] = model_confusion_matrix\nmcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\nlrklist = [mean(acclist),mean(f1slist),mcc]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(lrlist)\nprint(lrklist)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nget_model_results(lr,x,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"K Nearest Neighbour"},{"metadata":{"trusted":true},"cell_type":"code","source":"acclist, f1slist, mcclist = [],[],[]\n# Splitting the dataset into training set and test set\nfrom sklearn.model_selection import train_test_split\nfor i in range(0,100):\n    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2,random_state=i)\n\n    # Feature Scaling\n    from sklearn.preprocessing import StandardScaler\n    sc = StandardScaler()\n    x_train = sc.fit_transform(x_train)\n    x_test = sc.transform(x_test)\n\n    #K Nearest Neighbor\n    from sklearn.neighbors import KNeighborsClassifier\n    classifier = KNeighborsClassifier()\n    classifier.fit(x_train, y_train)\n    y_pred = classifier.predict(x_test)\n    calc_acc_mcc_f1s(y_test,y_pred)\n    append_eval()\nknnlist = [mean(acclist),mean(f1slist),mean(mcclist)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knnlist","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Support Vector Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"acclist, f1slist, mcclist = [],[],[]\n# Splitting the dataset into training set and test set\nfrom sklearn.model_selection import train_test_split\nfor i in range(0,100):\n    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2,random_state=i)\n\n    # Feature Scaling\n    from sklearn.preprocessing import StandardScaler\n    sc = StandardScaler()\n    x_train = sc.fit_transform(x_train)\n    x_test = sc.transform(x_test)\n\n    #Support Vector Classifier\n    from sklearn.svm import SVC\n    classifier = SVC()\n    classifier.fit(x_train, y_train)\n    y_pred = classifier.predict(x_test)\n    calc_acc_mcc_f1s(y_test,y_pred)\n    append_eval()\n\nsvclist = [mean(acclist),mean(f1slist),mean(mcclist)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svclist","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Decision Tree Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"acclist, f1slist, mcclist = [],[],[]\n# Splitting the dataset into training set and test set\nfrom sklearn.model_selection import train_test_split\nfor i in range(0,100):\n    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2,random_state=i)\n\n    # Feature Scaling\n    from sklearn.preprocessing import StandardScaler\n    sc = StandardScaler()\n    x_train = sc.fit_transform(x_train)\n    x_test = sc.transform(x_test)\n\n    #Decision Tree Classifier\n    from sklearn.tree import DecisionTreeClassifier\n    classifier = DecisionTreeClassifier(max_leaf_nodes=10,max_depth=3,criterion='entropy')\n    classifier.fit(x_train, y_train)\n    y_pred = classifier.predict(x_test)\n    calc_acc_mcc_f1s(y_test,y_pred)\n    append_eval()\n\ndtclist = [mean(acclist),mean(f1slist),mean(mcclist)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtclist","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"acclist, f1slist, mcclist = [],[],[]\n# Splitting the dataset into training set and test set\nfrom sklearn.model_selection import train_test_split\nfor i in range(0,100):\n    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2,random_state=i)\n\n    # Feature Scaling\n    from sklearn.preprocessing import StandardScaler\n    sc = StandardScaler()\n    x_train = sc.fit_transform(x_train)\n    x_test = sc.transform(x_test)\n\n    from sklearn.ensemble import RandomForestClassifier\n    classifier = RandomForestClassifier(criterion='gini', random_state=0)\n    classifier.fit(x_train, y_train)\n    y_pred = classifier.predict(x_test)\n    calc_acc_mcc_f1s(y_test,y_pred)\n    append_eval()\n\nrfclist = [mean(acclist),mean(f1slist),mean(mcclist)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfclist","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"XGBoost Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"acclist, f1slist, mcclist = [],[],[]\n# Splitting the dataset into training set and test set\nfrom sklearn.model_selection import train_test_split\nfor i in range(0,100):\n    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2,random_state=i)\n\n    # Feature Scaling\n    from sklearn.preprocessing import StandardScaler\n    sc = StandardScaler()\n    x_train = sc.fit_transform(x_train)\n    x_test = sc.transform(x_test)\n\n    from xgboost import XGBClassifier\n    classifier = XGBClassifier()\n    classifier.fit(x_train, y_train)\n    y_pred = classifier.predict(x_test)\n    calc_acc_mcc_f1s(y_test,y_pred)\n    append_eval()\n\nxgbclist = [mean(acclist),mean(f1slist),mean(mcclist)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgbclist","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CatBoost Classifier"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"acclist, f1slist, mcclist = [],[],[]\n# Splitting the dataset into training set and test set\nfrom sklearn.model_selection import train_test_split\nfor i in range(0,10):\n    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2,random_state=i)\n\n    # Feature Scaling\n    from sklearn.preprocessing import StandardScaler\n    sc = StandardScaler()\n    x_train = sc.fit_transform(x_train)\n    x_test = sc.transform(x_test)\n\n    from catboost import CatBoostClassifier\n    classifier = CatBoostClassifier()\n    classifier.fit(x_train, y_train)\n    y_pred = classifier.predict(x_test)\n    calc_acc_mcc_f1s(y_test,y_pred)\n    append_eval()\n\ncbclist = [mean(acclist),mean(f1slist),mean(mcclist)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cbclist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mylist2 = [\"Logistic Regression\", \"KNearestNeighbours\",\"SupportVector\",\"DecisionTree\",\"RandomForest\", \"XGBOOST\",\"CATBOOST\"]\nmyacclist = [lrlist[0],knnlist[0],svclist[0],dtclist[0],rfclist[0],xgbclist[0],cbclist[0]]\nmymcclist = [lrlist[1],knnlist[1],svclist[1],dtclist[1],rfclist[1],xgbclist[1],cbclist[1]]\nmyf1slist = [lrlist[2],knnlist[2],svclist[2],dtclist[2],rfclist[2],xgbclist[2],cbclist[2]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize']=15,6 \nsns.set_style(\"darkgrid\")\nax = sns.barplot(x=mylist2, y=mymcclist, palette = \"rocket\", saturation =1.5)\nplt.xlabel(\"Classifier Models\", fontsize = 20 )\nplt.ylabel(\"MCC\", fontsize = 20)\nplt.title(\"MCC of different Classifier Models\", fontsize = 20)\nplt.xticks(fontsize = 12, horizontalalignment = 'center', rotation = 8)\nplt.yticks(fontsize = 13)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(f'{height:.2}', (x + width/2, y + height*1.02), ha='center', fontsize = 'x-large')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}