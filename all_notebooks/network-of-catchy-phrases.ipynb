{"cells":[{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:palatino linotype,serif;font-size:25px;\">\n    Intro\n   <p style = \"font-family:palatino linotype,serif;font-size:20px;\">\n    This notebook contains wordcloud of 150 catch phrases from movies as well as network of most frequent words with others so one can make catchy phrase by themselfðŸ˜‰"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\ndf=pd.read_csv('/kaggle/input/150-famous-movie-catchphrases-with-context/Catchphrase.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:palatino linotype,serif;font-size:25px;\">\n    Let us make a Wordcloud and some plots"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\ntext = df.Catchphrase.sum()\nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2', collocations=False, stopwords = STOPWORDS).generate(text)\nplt.figure(figsize=(40, 30))\nplt.imshow(wordcloud) \nplt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from nltk import FreqDist\nimport nltk\n\nwords=[]\nfiltered=[]\nfor i in df.Catchphrase:\n    words.append(nltk.tokenize.word_tokenize(i))\n    \nfor i in words:\n    for a in i:\n        if len(a)>1:\n            filtered.append(a)\n            \nwords_2=nltk.tokenize.word_tokenize(text)\nfdist = FreqDist(words_2)\n\nlength=pd.DataFrame([len(i) for i in words])\nlength.hist(bins=20, figsize=(20,10))\nplt.grid(b=None)\nplt.title('Length of catch phrases',family='serif', size=40)\nplt.yticks(family='serif', size=40)\nplt.xticks(family='serif', size=40)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fdf=pd.DataFrame(fdist, index=['freq']).transpose()\nfdf.sort_values(by='freq',ascending=False,inplace=True)\nfdf=fdf.drop(axis=0,labels=['.',',','!','...'])\nfdf['word']=fdf.index\nfdf[0:50].plot(x='word',y='freq',kind='bar',figsize=(45,10))\nplt.grid(b=None)\nplt.xticks(rotation=45,family='serif', size=40)\nplt.title('Most frequent words ',family='serif', size=40)\nplt.yticks(family='serif', size=40)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:palatino linotype,serif;font-size:25px;\">\n    "},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:palatino linotype,serif;font-size:25px;\">\n    So, let us make network of words. \n    \n<p style = \"font-family:palatino linotype,serif;font-size:20px;\">\n    All phrases were tokenized and fetch to a df. Then the df sliced by 2 columns and these slices were concatenated, thus we saved connections of nearby words in phrases. After, I made edges of a network from each pair of words and visualise it with networkx package.\n    "},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"words_df=pd.DataFrame(words)\nslices=[]\nfor i in range(words_df.shape[1]-1):\n    slices.append(pd.DataFrame(words_df.iloc[:,range(i,2+i)]))\nfor i in slices:\n    i.columns=[1,2]\nlisti=pd.concat(slices)\nlisti=listi.dropna().reset_index().drop(axis=1,labels='index')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"!pip install networkx","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport networkx as nx\n\nG = nx.Graph()\nfor i in range(listi.shape[0]):\n    G.add_edge(listi.iloc[i,0], listi.iloc[i,1])\nplt.figure(figsize=(30, 30))    \npos = nx.spring_layout(G)\nnx.draw(G, pos, font_size=16, with_labels=False)\nfor p in pos:  \n    pos[p][1] += 0.02\nnx.draw_networkx_labels(G, pos)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:palatino linotype,serif;font-size:25px;\">\n    Please, leave comments on how to make this network better and thanks a lot for reading!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}