{"cells":[{"metadata":{"id":"view-in-github"},"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/ishgirwan/omdena_hdi/blob/master/training_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"},{"metadata":{"id":"iRuhZ485rw74","outputId":"647d43b9-c92f-4c46-ab5f-8f7d3537940b","trusted":false},"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/drive')","execution_count":null,"outputs":[]},{"metadata":{"id":"zA_oBu5p5MVR","trusted":false},"cell_type":"code","source":"#!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n#!python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev","execution_count":null,"outputs":[]},{"metadata":{"id":"RpV-DVFz1Hvm","trusted":false},"cell_type":"code","source":"!nvidia-smi ","execution_count":null,"outputs":[]},{"metadata":{"id":"W35Y6SeysC1Q","trusted":false},"cell_type":"code","source":"!pip install rasterio\n!pip install pytorch-lightning-bolts\n!pip install git+https://github.com/PytorchLightning/pytorch-lightning.git@master --upgrade","execution_count":null,"outputs":[]},{"metadata":{"id":"gsgOsjXXwWhp","trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport rasterio\n\nimport torch\nimport torchvision\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset, sampler\nfrom torchvision import transforms\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning import Trainer\nfrom pl_bolts.callbacks import PrintTableMetricsCallback\nfrom pytorch_lightning.metrics import MeanAbsoluteError\n#import albumentations as A\n\n#from sklearn.preprocessing import MinMaxScaler    \nfrom sklearn.metrics import r2_score\n\nimport glob\nimport os\n\n# visualisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"id":"HYk3QE2Ynvg7","trusted":false},"cell_type":"code","source":"csv_path = '/content/drive/My Drive/hdi_with_geometry.csv'\nroot_dir = '/content/drive/My Drive/Images/'","execution_count":null,"outputs":[]},{"metadata":{"id":"PobXyZ3sXXDf","trusted":false},"cell_type":"code","source":"model =  torchvision.models.resnet18(pretrained=False, progress=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"m5-pqivEYKdG","trusted":false},"cell_type":"code","source":"model.conv1 = nn.Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), bias=False)\nmodel.fc = nn.Sequential(nn.Linear(in_features=512, out_features=1000, bias=True), nn.Sigmoid())","execution_count":null,"outputs":[]},{"metadata":{"id":"nie2HAucPCp0","trusted":false},"cell_type":"code","source":"class MyDataset(Dataset):\n    \"\"\"\n    Generate normalized, rescaled and transformed datasets\n    \"\"\"\n\n    def __init__(self, dataset, transform=None):\n        \n        super().__init__()\n        self.df = dataset\n        self.transform = transform\n\n    def __len__(self):\n        \n        return len(self.df)\n    \n    def __getitem__(self, idx):\n       \n        if torch.is_tensor(idx):\n              idx = idx.tolist()\n\n        # generate image sample\n        image_path = self.df['image_path'].iloc[idx] \n        image_sample = rasterio.open(str(image_path), \"r\")\n        bands = [i for i in range(1, image_sample.count+1)]\n        image_sample = image_sample.read(bands)\n        image_sample = image_sample.astype('float32')\n\n        # generate hdi sample\n\n        hdi_sample = self.df['HDI'].iloc[idx]\n\n        # Normalize the image sample and rescale it between 0 and 1\n        for ch in range(image_sample.shape[0]):\n            channel_mean = np.nanmean(image_sample[ch])\n            channel_stdev = np.nanstd(image_sample[ch])\n            image_sample[ch] = (image_sample[ch] - channel_mean)\n\n            if channel_stdev != 0:\n\n                # standardize\n                image_sample[ch] = image_sample[ch] / channel_stdev\n                \n                # normalize\n                image_sample[ch] = (image_sample[ch] - np.nanmin(image_sample[ch])) / (np.nanmax(image_sample[ch]) - np.nanmin(image_sample[ch]))\n        \n        # convet nan to 0\n        image_sample[np.isnan(image_sample)] = 0\n\n        if self.transform:\n            image_sample = self.transform(image_sample)\n\n        else:\n            return [image_sample.permute(1, 0, 2),  hdi_sample.astype('float32')]\n    ","execution_count":null,"outputs":[]},{"metadata":{"id":"8ahO2P-jeIhc","trusted":false},"cell_type":"code","source":"from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor,  ModelCheckpoint\n\n# default used by the Trainer\nearly_stop = EarlyStopping(\n    monitor='val_loss',\n    patience=10,\n    strict=False,\n    verbose=True,\n    mode='min')\n\n\n# DEFAULTS used by the Trainer\ncheckpoint_callback = ModelCheckpoint(\n    filepath='/content/drive/My Drive/ckpt/model.ckpt',\n    save_top_k=1,\n    verbose=True,\n    monitor='val_loss',\n    mode='min',\n    prefix=''\n)\n\nlr_monitor = LearningRateMonitor(logging_interval='step')\n","execution_count":null,"outputs":[]},{"metadata":{"id":"TcRISG57HcvO","trusted":false},"cell_type":"code","source":"# custome collate to pad images for each batch\ndef my_collate(batch):\n\n    max_wh = 0\n\n    for item in batch:\n        image = item[0]\n        w = image.shape[1]\n        h = image.shape[2]\n        max_i = np.max([w, h])\n        if max_i > max_wh:\n            max_wh = max_i\n    \n    #print(max_wh)\n\n    data = []\n\n    for item in batch:\n        image = item[0]\n        rows = image.shape[1]\n        cols = image.shape[2]\n        rows_diff = max_wh - rows\n        cols_diff = max_wh - cols\n        cols_half = int(cols_diff / 2)\n        rows_half = int(rows_diff / 2)\n        padding = (cols_half, cols_diff-cols_half, rows_half, rows_diff-rows_half)\n        image_pad = F.pad(image, padding, 'constant', 0)\n        data.append(image_pad)\n\n    target = [item[1] for item in batch]\n    return [data, target]","execution_count":null,"outputs":[]},{"metadata":{"id":"elEmnDp5qA80"},"cell_type":"markdown","source":""},{"metadata":{"id":"zyzLyuj1KjSw","trusted":false},"cell_type":"code","source":"\nclass Model(pl.LightningModule):\n\n    def __init__(self, model, batch_size=1, learning_rate=.001):\n        super().__init__()\n        self.learning_rate = learning_rate\n        self.save_hyperparameters()\n        self.model = model\n        self.batch_size = batch_size\n        self.ser_y = pd.Series(dtype='float32', name='y')\n        self.ser_y_hat = pd.Series(dtype='float32', name='y_pred')\n\n    def forward(self, x):\n        x = self.model(x)\n        x = torch.mean(x, 1)\n        return x\n\n    def prepare_data(self):\n\n        df = pd.read_csv(csv_path)\n        df['image_path'] = root_dir + df['unique code'].astype(str) + '.tif' \n        df = df.sample(frac=1, random_state=1).reset_index(drop=True)\n        # split the dataset\n        train, validate, test = np.split(df, [int(.9*len(df)), int(.95*len(df))]) \n\n        # transforms\n        train_transform = transforms.Compose([\n                                transforms.ToTensor()\n                                ])\n\n        validate_transform = transforms.Compose([\n                                transforms.ToTensor()\n                                ])\n        # create datasets for training, validation and test\n        self.train_dataset = MyDataset(dataset=train, transform=train_transform)\n        self.validate_dataset = MyDataset(dataset=validate, transform=validate_transform)\n        self.test_dataset = MyDataset(dataset=test, transform=validate_transform) \n\n        return test\n    \n    def train_dataloader(self):\n        return DataLoader(self.train_dataset, self.batch_size, shuffle=True, num_workers=4, collate_fn=my_collate, pin_memory=True, drop_last=True)\n\n    def val_dataloader(self):\n        return DataLoader(self.validate_dataset, self.batch_size, num_workers=4,collate_fn=my_collate, pin_memory=True, drop_last=True) \n\n    def test_dataloader(self):\n        return DataLoader(self.test_dataset, self.batch_size, num_workers=4, collate_fn=my_collate, pin_memory=True, drop_last=True) \n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n        return {'optimizer': optimizer, 'lr_scheduler': scheduler, 'monitor': 'val_loss'}\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        x = torch.stack(x)\n        y = torch.cuda.FloatTensor(y)\n        y_hat = self(x)\n        loss = F.mse_loss(y_hat, y)\n        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n\n\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        x = torch.stack(x)\n        y = torch.cuda.FloatTensor(y)\n        y_hat = self(x)\n        #print(y, y_hat)\n        loss = F.mse_loss(y_hat, y)\n        r2 = r2_score(y.cpu().detach().numpy(), y_hat.cpu().detach().numpy())\n        self.log('val_loss', loss)\n        self.log('val_R-square', r2)\n        #return {\"loss\": loss, 'R-square': r2_score}\n\n\n    def test_step(self, batch, batch_idx):\n        x, y = batch\n\n        y_series = pd.Series(y)\n        \n        x = torch.stack(x)\n        y = torch.cuda.FloatTensor(y)\n        y_hat = self(x)\n        loss = F.mse_loss(y_hat, y)\n        r2 = r2_score(y.cpu().detach().numpy(), y_hat.cpu().detach().numpy())\n        \n        self.log('test_loss', loss)\n        self.log('test_R-square', r2)\n\n        y_hat = y_hat.cpu().detach().numpy()\n        y_hat_series = pd.Series(y_hat)\n\n        self.ser_y = self.ser_y.append(y_series, ignore_index=True)\n        self.ser_y_hat = self.ser_y_hat.append(y_hat_series, ignore_index=True)\n    \n\n    def backward(self, loss, optimizer, optimizer_idx):\n        loss.backward()\n\n    def optimizer_step(self, current_epoch, batch_idx, optimizer, \n      optimizer_idx, second_order_closure=None, \n       on_tpu=False, using_native_amp=False, using_lbfgs=False):\n        optimizer.step()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"MHJbx9hdL13d","trusted":false},"cell_type":"code","source":"# init model\nmodel_one = Model(model, batch_size=16)\n#from pytorch_lightning.core.memory import ModelSummary\n#ModelSummary(model_one, mode='full')\nfrom pytorch_lightning.loggers import TensorBoardLogger\nlogger = TensorBoardLogger('/content/drive/My Drive/tb_logs', name='my_model')\n\n#train\nroot_path = '/content/drive/My Drive/'","execution_count":null,"outputs":[]},{"metadata":{"id":"8r9EaWfmmIDT","outputId":"c47a5c85-ae98-4a9a-b36a-da1f6c0ccd6f","trusted":false},"cell_type":"code","source":"#seed\nresume_ckpt_path =  '/content/drive/My Drive/ckpt/model_t3.ckpt'\n#resume_from_checkpoint=resume_ckpt_path,\npl.seed_everything(1)\n\ntrainer = pl.Trainer(gpus=1,resume_from_checkpoint=resume_ckpt_path, logger=logger, checkpoint_callback=checkpoint_callback, progress_bar_refresh_rate=50, accumulate_grad_batches=2, fast_dev_run=False,\\\n                    default_root_dir=root_path, auto_lr_find=True,\\\n                    profiler=True, max_epochs=1000, callbacks=[lr_monitor, early_stop, PrintTableMetricsCallback()])\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"uw_LiPdReciL","trusted":false},"cell_type":"code","source":"trainer.fit(model_one)","execution_count":null,"outputs":[]},{"metadata":{"id":"zj0U-Zx1xlIa","trusted":false},"cell_type":"code","source":"#!nvidia-smi ","execution_count":null,"outputs":[]},{"metadata":{"id":"lOAMKL4wbLWA","trusted":false},"cell_type":"code","source":"# Start tensorboard.\n%reload_ext tensorboard\n%tensorboard --logdir='/content/drive/My Drive/tb_logs'","execution_count":null,"outputs":[]},{"metadata":{"id":"Y9r8rxWAa4h7","trusted":false},"cell_type":"code","source":"# test\ntrainer.test(ckpt_path='/content/drive/My Drive/ckpt/model.ckpt-v0.ckpt', model=model_one, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analysis","execution_count":null,"outputs":[]},{"metadata":{"id":"dtX_1tJ2_nKE","trusted":false},"cell_type":"code","source":"df_pred = pd.concat([model_one.ser_y, model_one.ser_y_hat], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"P4MtnBYiAtdm","trusted":false},"cell_type":"code","source":"df_pred = df_pred.set_axis(['y', 'y_pred'], axis=1, inplace=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"jZeZP85dDqKO","trusted":false},"cell_type":"code","source":"df_pred['diff'] = (df_pred.y - df_pred.y_pred).abs()","execution_count":null,"outputs":[]},{"metadata":{"id":"A84KHwGqFfpP","outputId":"85cac4aa-aa09-47b3-c746-4d7a5edde0bc","trusted":false},"cell_type":"code","source":"df_pred","execution_count":null,"outputs":[]},{"metadata":{"id":"NJLMddx6im9O","trusted":false},"cell_type":"code","source":"df = pd.read_csv(csv_path)\ndf['image_path'] = root_dir + df['unique code'].astype(str) + '.tif' \ndf = df.sample(frac=1, random_state=1).reset_index(drop=True)\n# split the dataset\ntrain, validate, test = np.split(df, [int(.9*len(df)), int(.95*len(df))]) ","execution_count":null,"outputs":[]},{"metadata":{"id":"yNy4-PBPz_AB","outputId":"1c7f6eda-f7da-453a-a040-fd012c1f33c8","trusted":false},"cell_type":"code","source":"test.head(10)","execution_count":null,"outputs":[]},{"metadata":{"id":"CYRmjrPmH1tI","trusted":false},"cell_type":"code","source":"test.reset_index(inplace=True, drop=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"1waaF4dmH9sB","trusted":false},"cell_type":"code","source":"df_final = pd.concat([test, df_pred], axis =1)","execution_count":null,"outputs":[]},{"metadata":{"id":"lxosnW8nIjZe","trusted":false},"cell_type":"code","source":"df_final = df_final[df_final['y_pred'].notna()]","execution_count":null,"outputs":[]},{"metadata":{"id":"ZVZaQgt_L84Q","trusted":false},"cell_type":"code","source":"df_final.sort_values(by=['diff'], ascending=False, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"8NRoCjwGOPOg","trusted":false},"cell_type":"code","source":"df_final['num_pixel'] = df['SHAPE_Area'] / 900","execution_count":null,"outputs":[]},{"metadata":{"id":"61K2laOPVhsI","trusted":false},"cell_type":"code","source":"df_final.reset_index(inplace=True, drop=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"7TWBSFMwOrpS","outputId":"edf289cc-2eaf-472e-aa80-60b2c13518a6","trusted":false},"cell_type":"code","source":"df_final.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"Woep-luMTtG4","outputId":"1257e70c-57a3-4004-85e8-0b69374801af","trusted":false},"cell_type":"code","source":"df_final.tail()","execution_count":null,"outputs":[]},{"metadata":{"id":"BOhgu_MmhpzG","trusted":false},"cell_type":"code","source":"df_final.to_csv('/content/drive/My Drive/post_training_analysis.csv')","execution_count":null,"outputs":[]},{"metadata":{"id":"wjUo91cviNI9","trusted":false},"cell_type":"code","source":"df_final = pd.read_csv('/content/drive/My Drive/post_training_analysis.csv')","execution_count":null,"outputs":[]},{"metadata":{"id":"J4l3oaHbOtYv","outputId":"c73209e4-c879-43e7-9c17-b817b663089b","trusted":false},"cell_type":"code","source":"df_final.describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"tmWOqXOrQLhg","outputId":"28dffc6e-e741-4ec5-ec37-567bd4937af8","trusted":false},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom rasterio.plot import show\n\nplt.figure(figsize=(10,8))\n# the file has been downloaded from drive to show here\nimage_h = rasterio.open(df_final['image_path'].iloc[4])\nshow(image_h, adjust='linear')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"_-E9Y0bIVu2w","outputId":"41c2fd31-095a-4646-d41a-84fa31620646","trusted":false},"cell_type":"code","source":"plt.figure(figsize=(10,8))\n# the file has been downloaded from drive to show here\nimage = rasterio.open(df_final['image_path'].iloc[-2])\nshow(image, adjust='linear')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"hg2EdXXTQqQ2","outputId":"b3e898ca-2646-4956-acb3-b4c044e0d3d5","trusted":false},"cell_type":"code","source":"sns.distplot(df_final['y'])","execution_count":null,"outputs":[]},{"metadata":{"id":"h7GyqYGfSx7_","outputId":"fc7c0442-037d-4a11-95f8-842b9dfa672a","trusted":false},"cell_type":"code","source":"sns.distplot(df_final['y_pred']);","execution_count":null,"outputs":[]},{"metadata":{"id":"7fzkdZ0gS2do","outputId":"2f829e8d-c93c-4e91-d9e6-15dd1f351231","trusted":false},"cell_type":"code","source":"sns.distplot(df_final['diff'])","execution_count":null,"outputs":[]},{"metadata":{"id":"topbuywzTeHO","outputId":"e3e317f5-57fb-48dd-a790-c3d11d5379c7","trusted":false},"cell_type":"code","source":"df_corr = df_final.corr()# irrelevant fields\nfields = ['unique code', 'HDI']# drop rows\ndf_corr.drop(fields, inplace=True)# drop cols\ndf_corr.drop(fields, axis=1, inplace=True)\ndf_corr","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}