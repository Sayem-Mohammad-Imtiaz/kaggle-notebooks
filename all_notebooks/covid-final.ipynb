{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Import necessary packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install segmentation_models_pytorch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install livelossplot","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset\nfrom torch.optim.lr_scheduler import StepLR\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, utils\nfrom torch.optim.lr_scheduler import StepLR\nfrom torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\nimport os\nfrom PIL import Image\nfrom PIL import ImageFile\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom livelossplot import PlotLosses \nimport numpy as np\nfrom datetime import datetime\nimport pandas as pd\nimport random \nfrom shutil import copyfile\nimport re\nimport albumentations as albu\nfrom albumentations.pytorch import ToTensor\nfrom albumentations import Compose,Resize,OneOf,RandomBrightness,RandomContrast,Normalize,HorizontalFlip,Blur,ElasticTransform,GridDistortion,OpticalDistortion,GaussNoise \nfrom sklearn.metrics import roc_auc_score\nfrom skimage.io import imread, imsave\nimport skimage\nimport nibabel as nib\nimport time\nimport cv2\nimport copy\nimport segmentation_models_pytorch as smp\nfrom tqdm import tqdm_notebook as tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 271\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.cuda.empty_cache()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load dataset and perform augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"imgsize = 224\ntransforms1 = {\n    'both': Compose([\n                    Resize(imgsize,imgsize),\n                    HorizontalFlip(p=0.5), \n                    OneOf([ElasticTransform(alpha=120, sigma=120*0.05, alpha_affine=120*0.03), GridDistortion(), OpticalDistortion(distort_limit=2, shift_limit=0.5)], p=0.3),\n                    ]),\n    \n    'image': Compose([\n                    OneOf([RandomBrightness(limit=0.1, p=0.4), RandomContrast(limit=0.1, p=0.4)]),\n                    GaussNoise(),\n                    Blur(p=0.1, blur_limit = 3),\n                    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n                    ]),\n        \n\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Covid19_CT_Dataset(torch.utils.data.Dataset):\n    def __init__(self, ct_path, masks_path, transform1=None, transform2=None):\n        self.transforms1 = transform1\n        self.transforms2 = transform2\n        self.ct_path = ct_path\n        self.masks_path = masks_path\n        self.len = np.array(nib.load(self.ct_path).get_fdata()).shape[-1]\n        \n    def __getitem__(self,index):\n        ct = nib.load(self.ct_path)\n        ct = np.rot90(np.array(ct.get_fdata()))\n        image = ct[:,:,index]\n        image = Image.fromarray(image)\n        image = np.array(image.convert('RGB'))\n        \n        ct_mask = nib.load(self.masks_path)\n        ct_mask = np.rot90(np.array(ct_mask.get_fdata()))\n        mask = ct_mask[:,:,index]\n        \n        labels = np.unique(mask).astype(\"uint8\")\n        labels = labels[1:]\n        target_mask = np.zeros((mask.shape[0], mask.shape[1], 3))\n        for label in labels:\n            target_mask[:,:, label-1 : label] = np.expand_dims(mask, -1)==label\n        \n        if self.transforms1 is not None:\n            augument = self.transforms1(image=image,mask=target_mask)\n            image = augument['image']\n            target_mask = augument['mask']\n            \n        if self.transforms2 is not None:\n            image = self.transforms2(image=image)['image']\n        \n        target_mask = ToTensor()(image=target_mask)['image']\n        \n        image = ToTensor()(image=image)['image']\n        \n        return image, target_mask\n    \n    def __len__(self):\n        return self.len","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"csv_file = r'../input/covid19-ct-scans/metadata.csv'\ndf = pd.read_csv(csv_file)\nct_path = df['ct_scan'].tolist()\nmasks_path = df['lung_and_infection_mask'].tolist()\ndataset = Covid19_CT_Dataset(ct_path[0],masks_path[0],transform1=transforms1['both'], transform2=transforms1['image'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_id = 100\nplt.figure(figsize=(8,8))\nplt.imshow(dataset[img_id][0].permute(1,2,0).numpy(), cmap='bone')\nplt.imshow(dataset[img_id][1].permute(1,2,0).numpy(), alpha=0.5, cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"csv_file = r'../input/covid19-ct-scans/metadata.csv'\ndf = pd.read_csv(csv_file)\nct_path = df['ct_scan'].tolist()\nmasks_path = df['lung_and_infection_mask'].tolist()\ndataset_list = []\nfor i in range(20):\n    dataset_list.append(Covid19_CT_Dataset(ct_path[i],masks_path[i],transform1=transforms1['both'], transform2=transforms1['image']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_train = torch.utils.data.ConcatDataset(dataset_list[:16])\ndataset_val = torch.utils.data.ConcatDataset(dataset_list[16:])\nprint(dataset_train.__len__())\nprint(dataset_val.__len__())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Save transformed image tensors"},{"metadata":{},"cell_type":"markdown","source":"By saving and loading the transformed tensors the runtime for each eopch is reduced considerably."},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir('/kaggle/working/new_train')\nos.mkdir('/kaggle/working/new_val')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir('/kaggle/working/new_train/img')\nos.mkdir('/kaggle/working/new_val/img')\nos.mkdir('/kaggle/working/new_train/mask')\nos.mkdir('/kaggle/working/new_val/mask')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, data in enumerate(dataset_val):\n  torch.save(data[0], '/kaggle/working/new_val/img/val_transformed_img{}'.format(i))\n  torch.save(data[1], '/kaggle/working/new_val/mask/val_transformed_mask{}'.format(i))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, data in enumerate(dataset_train):\n  torch.save(data[0], '/kaggle/working/new_train/img/val_transformed_img{}'.format(i))\n  torch.save(data[1], '/kaggle/working/new_train/mask/val_transformed_mask{}'.format(i))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create new dataset to load the transformed tensors"},{"metadata":{"trusted":true},"cell_type":"code","source":"class transformed_data(Dataset):\n  def __init__(self, img, mask):\n    self.img = img  #img path\n    self.mask = mask  #mask path\n    self.len = len(os.listdir(self.img))\n\n  def __getitem__(self, index):\n    ls_img = sorted(os.listdir(self.img))\n    ls_mask = sorted(os.listdir(self.mask))\n\n    img_file_path = os.path.join(self.img, ls_img[index])\n    img_tensor = torch.load(img_file_path)\n\n    mask_file_path = os.path.join(self.mask, ls_mask[index])\n    mask_tensor = torch.load(mask_file_path)\n\n    return img_tensor, mask_tensor\n\n  def __len__(self):\n    return self.len   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_train = transformed_data('/kaggle/working/new_train/img', '/kaggle/working/new_train/mask')\ndataset_val = transformed_data('/kaggle/working/new_val/img', '/kaggle/working/new_val/mask')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unet_train_loader = DataLoader(dataset_train, batch_size=10, shuffle=True, num_workers=2)\nunet_val_loader = DataLoader(dataset_val, batch_size=5, shuffle=False, num_workers=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"ENCODER = 'se_resnext50_32x4d'\nENCODER_WEIGHTS = 'imagenet'\nACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multicalss segmentation\n\n# create segmentation model with pretrained encoder\nmodel = smp.FPN(\n    encoder_name=ENCODER, \n    encoder_weights=ENCODER_WEIGHTS, \n    activation=ACTIVATION,\n)\n\npreprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = smp.utils.losses.DiceLoss()\nmetrics = [\n    smp.utils.metrics.IoU(threshold=0.5),\n]\n\noptimizer = torch.optim.Adam([ \n    dict(params=model.parameters(), lr=0.0001),\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_epoch = smp.utils.train.TrainEpoch(\n    model, \n    loss=loss, \n    metrics=metrics, \n    optimizer=optimizer,\n    device=device,\n    verbose=True,\n)\n\nvalid_epoch = smp.utils.train.ValidEpoch(\n    model, \n    loss=loss, \n    metrics=metrics, \n    device=device,\n    verbose=True,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_score = 0\n\nliveloss = PlotLosses()\nfor i in range(0, 20):\n\n    print('\\nEpoch: {}'.format(i))\n    logs = {}\n    train_logs = train_epoch.run(unet_train_loader)\n    valid_logs = valid_epoch.run(unet_val_loader)\n    # do something (save model, change lr, etc.)\n\n    if max_score < valid_logs['iou_score']:\n        max_score = valid_logs['iou_score']\n        torch.save(model, './best_model.pth')\n        print('Model saved!')\n        \n    #if i == 25:\n    #    optimizer.param_groups[0]['lr'] = 1e-5\n    #    print('Decrease decoder learning rate to 1e-5!')\n    \n    logs['train dice loss'],logs['val dice loss'] = train_logs['dice_loss'], valid_logs['dice_loss']\n    #logs[prefix + 'iou_score'] = train_logs['iou_score'], valid_logs['iou_score']\n    \n    liveloss.update(logs)\n    liveloss.send()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}