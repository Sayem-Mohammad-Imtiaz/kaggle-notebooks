{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport seaborn as sns  \nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/datacsv/data.csv') \ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col= data.columns\nprint(col)\ncol.size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data.diagnosis                          # M or B \nlist = ['Unnamed: 32','id','diagnosis']\nx = data.drop(list,axis = 1 )\nx.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.countplot(y,label=\"Count\")       # M = 212, B = 357\nB, M = y.value_counts()\nprint('Number of Benign: ',B)\nprint('Number of Malignant : ',M)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dia = y\ndata = x\ndata_n_2 = (data - data.mean()) / (data.std())          \ndata = pd.concat([y,data_n_2.iloc[:,0:10]],axis=1)\ndata = pd.melt(data,id_vars=\"diagnosis\",\n                    var_name=\"features\",\n                    value_name='value')\nplt.figure(figsize=(10,10))\nsns.violinplot(x=\"features\", y=\"value\", hue=\"diagnosis\", data=data,split=True, inner=\"quart\")\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(6,6))\nsns.boxplot(x=\"features\", y=\"value\",hue=\"diagnosis\", data=data)\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax = plt.subplots(figsize=(12, 12))\nsns.heatmap(x.corr(), annot=True, linewidths=.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_list1 = ['perimeter_mean','radius_mean','compactness_mean','concave points_mean','radius_se','perimeter_se','radius_worst','perimeter_worst','compactness_worst','concave points_worst','compactness_se','concave points_se','texture_worst','area_worst']\nx_1 = x.drop(drop_list1,axis = 1 )       \nx_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax = plt.subplots(figsize=(20, 20))\nsns.heatmap(x_1.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score,confusion_matrix\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x_1, y, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_rf = RandomForestClassifier(random_state=43)      \nclr_rf = clf_rf.fit(x_train,y_train)\n\nac = accuracy_score(y_test,clf_rf.predict(x_test))\nprint('Accuracy is: ',ac)\ncm = confusion_matrix(y_test,clf_rf.predict(x_test))\nsns.heatmap(cm,annot=True,fmt=\"d\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n\nclf_rf_2 = RandomForestClassifier(random_state=43)      \nclr_rf_2 = clf_rf.fit(x_train,y_train)\n\nac = accuracy_score(y_test,clf_rf.predict(x_test))\nprint('Accuracy is: ',ac)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\n# find best scored 5 features\nselect_feature = SelectKBest(chi2, k=5).fit(x_train, y_train)\nprint('Score list:', select_feature.scores_)\nprint('Feature list:', x_train.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_2 = select_feature.transform(x_train)\nx_test_2 = select_feature.transform(x_test)\n#random forest classifier with n_estimators=10 (default)\nclf_rf_2 = RandomForestClassifier()      \nclr_rf_2 = clf_rf_2.fit(x_train_2,y_train)\nac_2 = accuracy_score(y_test,clf_rf_2.predict(x_test_2))\nprint('Accuracy is: ',ac_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFE\n# Create the RFE object and rank each pixel\nclf_rf_3 = RandomForestClassifier()      \nrfe = RFE(estimator=clf_rf_3, n_features_to_select=5, step=1)\nrfe = rfe.fit(x_train, y_train)\nprint('Chosen best 5 feature by rfe:',x_train.columns[rfe.support_])\n\nx_train_3 = rfe.transform(x_train)\nx_test_3 = rfe.transform(x_test)\nclf_rf_3 = RandomForestClassifier()      \nclr_rf_3 = clf_rf_3.fit(x_train_3,y_train)\nac_3 = accuracy_score(y_test,clf_rf_3.predict(x_test_3))\nprint('Accuracy is: ',ac_3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFECV\n\n# The \"accuracy\" scoring is proportional to the number of correct classifications\nclf_rf_4 = RandomForestClassifier() \nrfecv = RFECV(estimator=clf_rf_4, step=1, cv=5,scoring='accuracy')   #5-fold cross-validation\nrfecv = rfecv.fit(x_train, y_train)\n\nprint('Optimal number of features :', rfecv.n_features_)\nprint('Best features :', x_train.columns[rfecv.support_])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score of number of selected features\")\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\nplt.show()\nmax(rfecv.grid_scores_)\nrfecv.grid_scores_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tree based feature selection\nclf_rf_5 = RandomForestClassifier()      \nclr_rf_5 = clf_rf_5.fit(x_train,y_train)\nimportances = clr_rf_5.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in clf_rf.estimators_],\n             axis=0)\nindices = np.argsort(importances)[::-1]\n\n# Print the feature ranking\nprint(\"Feature ranking:\")\n\nfor f in range(x_train.shape[1]):\n    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n\n# Plot the feature importances of the forest\n\nplt.figure(1, figsize=(14, 13))\nplt.title(\"Feature importances\")\nplt.bar(range(x_train.shape[1]), importances[indices],\n       color=\"g\", yerr=std[indices], align=\"center\")\nplt.xticks(range(x_train.shape[1]), x_train.columns[indices],rotation=90)\nplt.xlim([-1, x_train.shape[1]])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n#normalization\nx_train_N = (x_train-x_train.mean())/(x_train.max()-x_train.min())\nx_test_N = (x_test-x_test.mean())/(x_test.max()-x_test.min())\n\nfrom sklearn.decomposition import PCA\npca = PCA()\npca.fit(x_train_N)\n\nplt.figure(1, figsize=(8, 8))\nplt.clf()\nplt.axes([.2, .2, .7, .7])\nplt.plot(pca.explained_variance_ratio_, linewidth=2)\nplt.axis('tight')\nplt.xlabel('n_components')\nplt.ylabel('explained_variance_ratio_')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}