{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Sign Language : "},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image\nImage(\"../input/sign-language-mnist/amer_sign2.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing Packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"%pylab inline\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n# from matplotlib.pyplot import imread\n# import imageio\nfrom matplotlib import image\nimport seaborn as sns\n\nfrom sklearn.metrics import accuracy_score\n\n# import tensorflow as tf\nimport tensorflow.keras as keras\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Dropout, Convolution2D, Flatten, MaxPooling2D, Reshape, InputLayer\nfrom tensorflow.keras.preprocessing.image import load_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/sign-language-mnist/sign_mnist_train/sign_mnist_train.csv\")\ntest = pd.read_csv(\"../input/sign-language-mnist/sign_mnist_test/sign_mnist_test.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Analysis of Training Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=train.iloc[:,1:]\ny=train.iloc[:,:1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = train['label'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (18,8))\nsns.countplot(x =labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=keras.utils.to_categorical(train['label'].values)\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"pd.DataFrame(y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalize the data\nX_train = X_train / 255\nX_val = X_val / 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Each letter indicates a sign produced by our fingers. We will apply deep learning to these images to make sure our model can understand what sign indicated what letter"},{"metadata":{},"cell_type":"markdown","source":"# Now Using CNN Model: "},{"metadata":{},"cell_type":"markdown","source":"pandas.dataframe doesn't have a built-in reshape method, but you can use .values to access the underlying numpy array object and call reshape on it"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.values\nX_val = X_val.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reshaping the data from 1-D to 3-D \nX_train = X_train.reshape(-1,28,28,1)\nX_val = X_val.reshape(-1,28,28,1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Visualizing the image after normalizing"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(X_train[0].reshape(28,28))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time\n# # reshape data\n\n# train_x_temp = train_x.reshape(-1, 28, 28, 1)\n# val_x_temp = val_x.reshape(-1, 28, 28, 1)\n\n# define vars\ninput_shape = (784,)\ninput_reshape = (28, 28, 1)\n\n# conv_num_filters = 5\n# conv_filter_size = 5\n\npool_size = (2, 2)\n\nhidden_num_units = 265\noutput_num_units = 25\n\nepochs = 10\nbatch_size = 128\n\nmodel = Sequential([\n\nConvolution2D(75,(2,2), activation='relu',input_shape=input_reshape),\nMaxPooling2D((2,2)),\n\nConvolution2D(50,(2,2), activation='relu'),\nMaxPooling2D((2,2)),\n\nConvolution2D(25,(2,2), activation='relu'),\n\nFlatten(),\n\nDense(hidden_num_units, 'relu'),\n\nDense(output_num_units,'softmax'),\n ])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\ntrained_model_conv = model.fit(X_train, y_train, epochs =epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(trained_model_conv.history['loss'],label='Train Loss')\nplt.plot(trained_model_conv.history['val_loss'],label='Val Loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see, the number of epochs increase the accuracy also increases.\n\nLet's validate with the test data"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Let's validate with the test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test=test.iloc[:,1:]\ny_test=test.iloc[:,:1]\n\n\ny_test=keras.utils.to_categorical(test['label'].values)\n\n\n# Normalize the data\nX_test = X_test / 255\n\nX_test = X_test.values\n\n# Reshaping the data from 1-D to 3-D \nX_test = X_test.reshape(-1,28,28,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images = X_test.reshape(X_test.shape[0], 28, 28, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(test_images)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predecting with test images"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test, y_pred.round())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntested_model_conv = model.fit(X_test, y_test, epochs =epochs, batch_size=batch_size, validation_data=(X_test, y_test))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(tested_model_conv.history['loss'],label='Test Loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}