{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Introduction**\n* Bu çalışma Udemy kursu ödevi için hazırlanmıştır.\n* Alınan tümör verileri kullanılarak bir Yapay Sinir Ağı eğitilmiştir. Eğitimde kullanılmayan başka bir tümör verisi ile bu YSA test edilmiştir.\n* An Artificial Neural Network was trained using the tumor data obtained. This ANN was tested with another tumor data not used in training."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#%% veri kümesini içeri aktarma/import dataset\n#ilk olarak verimizi 'data' isimli değişkene atıyoruz.\n#before of all we read the data that is we will use\ndata=pd.read_csv(\"/kaggle/input/breast-cancer-wisconsin-data/data.csv\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sütunlar hakkında genel bilgi almak için 'info' komutunu kullanıyoruz.\n#we use the 'info' command to get general information about columns/features.\nprint(data.info())\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 33 sütundan oluşan 569 adet veri olduğunu öğrendik.\n* Sütunlar içerisinde 'id' ve 'Unnamed: 32' isimli sütunlar işimize yaramayacak bilgiler içeriyor. Diğer sütunlardan 'diagnosis' sütunu hariç hepsi float64 türünde verilerdir. \n* Kullanacağımız verinin bazı sütunları büyük sayılar içerirken bazı sütunları tamamen küsurattan oluşmaktadır. Bütün veriler kendi sütunları baz alınarak 0 ile 1 arasına oranlanır. Böylece bütün özellikler adil şekilde değerlendirilmiş olur. Bu işleme normalizasyon denmektedir."},{"metadata":{"trusted":true},"cell_type":"code","source":"#etkisiz sütunları silip bütün verileri sayısal formata dönüştürüyoruz.\n#we delete ineffective columns and convert all data to numeric format. eg. int\ndata.drop([\"Unnamed: 32\",\"id\"],axis=1,inplace=True) # 'Unnamed: 32' ve 'id' isimli sütunları siliyoruz.\ndata.diagnosis = [1 if each == \"M\" else 0 for each in data.diagnosis] #M=1 B=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sütun seçme ve normalizasyon\n#column selection and normalization\ny=data.diagnosis.values #adı geçen sütunu y değişkenine atadık. 0 ve 1'lerden oluşan hedef matrisimizi oluşturduk.\nx_data=data.drop([\"diagnosis\"],axis=1) #adı geçen sütun haricini x_data değişkenine atadık.\nx=(x_data-np.min(x_data))/(np.max(x_data)-np.min(x_data)).values #normalizasyon yaptık. 0-1 arasına oranladık","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%%train test split\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42) \n#x ve y'yi rastgele(random) olarak eğitim ve test veriyeri ayırdık. \n#We randomly divided x and y into training and test data.\n#'test_size=0.2' kodunun manası %80 eğitim %20 test verisi olarak ayırmaktır.\n#The code 'test_size = 0.2' means separating the data as 80% training and 20% testing.\nprint(\"x_train: \", x_train.shape)\nprint(\"x_test: \", x_test.shape)\nprint(\"y_train: \", y_train.shape)\nprint(\"y_test: \", y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr=LogisticRegression() \nlr.fit(x_train,y_train) #lr isimli YSA eğitildi.\nprint(\"test accuracy: {}\".format(lr.score(x_test,y_test)))\nprint(\"test doğruluğu: {}\".format(lr.score(x_test,y_test))) #lr isimli YSA test edildi.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Eğitim ve test olarak ayırdığımız verileri sci-kit learn kütüphanesinde kullanarak YSA'yı önce eğitip sonra test ediyoruz.\n* Test sonucu bize, oluşturduğumuz modelin %97,368 oranında başarıya ulaştığını söylemektedir."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}