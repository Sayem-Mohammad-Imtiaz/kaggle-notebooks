{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"text-align:center\">   \n      <font color = pink >\n                Breast Cancer Prediction with KNN \n        </font>    \n</h1>   \n<hr style=\"width:100%;height:5px;border-width:0;color:gray;background-color:gray\">\n<center><img style = \"height:450px;\" src=\"https://static-01.hindawi.com/styles/hindawi_wide/s3/2019-11/Cancer_Awareness-2019_blog_v1.0_noText.jpg?itok=CR034IE-\"></center>\n\n# Introduction\n\nThe aim of the project, to determine whether the breast cancer cell is malignant or benign.\n\n**Content:**\n\n1. [Load and Check Data](#1)\n1. [Variable Description](#2)\n1. [Data Analysis](#3)\n1. [Outlier Deteciton](#4)    \n1. [Modeling](#5)\n    * [Train - Test Split](#6)\n    * [Standrization](#7)\n    * [K-Nearest Neighbors Classifier](#8)\n    * [KNN Best Parameters](#9) \n1. [Principal Component Analysis (PCA)](#10)\n1. [Neighborhood Component Analysis (NCA)](#11)\n1. [Result](#12)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"1\" ></a>\n# Load and Check Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/breast-cancer-wisconsin-data/data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We drop the features which we do not want\ndata.drop(['Unnamed: 32','id'], inplace = True, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We change the title of the properties\ndata = data.rename(columns = {\"diagnosis\":\"target\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"2\"></a>\n# Variable Description \nTarget (M = malignant, B = benign)\n\nTen real-valued features are computed for each cell nucleus:\n1. radius (mean of distances from center to points on the perimeter)\n1. texture (standard deviation of gray-scale values)\n1. perimeter\n1. area\n1. smoothness (local variation in radius lengths)\n1. compactness (perimeter^2 / area - 1.0)\n1. concavity (severity of concave portions of the contour)\n1. concave points (number of concave portions of the contour)\n1. symmetry\n1. fractal dimension (\"coastline approximation\" - 1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Data Shape:\", data.shape) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data[\"target\"])\nprint(data.target.value_counts()) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We convert string expressions to int because it will be necessary when making trains.(Bening = 0 , Malignant = 1)\ndata[\"target\"] = [1 if i.strip() == \"M\" else 0 for i in data.target] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We look at the data need for standardization, if there are big differences between the data, standardization is required.\ndescribe = data.describe()\ndescribe","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"3\"></a>\n# Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = data.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nsns.heatmap(corr_matrix,annot = True, fmt = \".2f\")\nplt.title(\"Correlation Between Features\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold = 0.75 \nfiltre = np.abs(corr_matrix[\"target\"]) > threshold \ncorr_features = corr_matrix.columns[filtre].tolist()\nsns.heatmap(data[corr_features].corr(), annot = True, fmt = \".2f\")\nplt.title(\"Correlation Between Features w Corr Theshold 0.75\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First, we set a limit value. Here we set it to 0.75.\nWe bring the ones whose relationship between properties is greater than 0.75."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_melted = pd.melt(data, id_vars = \"target\",\n                      var_name = \"features\",\n                      value_name = \"value\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\nsns.boxplot(x = \"features\", y = \"value\", hue = \"target\", data = data_melted)\nplt.xticks(rotation = 90) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data[corr_features], diag_kind = \"kde\", markers = \"+\", hue = \"target\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data.target\nx = data.drop([\"target\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = x.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"4\" ></a>\n# Outlier Deteciton"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import LocalOutlierFactor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = LocalOutlierFactor()\ny_pred = clf.fit_predict(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_score = clf.negative_outlier_factor_\noutlier_score = pd.DataFrame()\noutlier_score[\"score\"] = X_score\nthreshold = -2.5\nfiltre = outlier_score[\"score\"] < threshold\noutlier_index = outlier_score[filtre].index.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\nplt.scatter(x.iloc[outlier_index,0],x.iloc[outlier_index,1],color = \"blue\", s = 50, label = \"outliers\")\nplt.scatter(x.iloc[:,0],x.iloc[:,1],color = \"k\", s = 3, label = \"Data Points\")\nradius = (X_score.max()- X_score) / (X_score.max() - X_score.min())\noutlier_score[\"radius\"] = radius\nplt.scatter(x.iloc[:,0],x.iloc[:,1],s = 1000*radius, edgecolors = \"r\", facecolors = \"none\", label = \"Outlier Scores\")\nplt.legend() \nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop outlier\nx = x.drop(outlier_index)\ny = y.drop(outlier_index).values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"5\"></a><br>\n# Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV \nfrom sklearn.metrics import accuracy_score, confusion_matrix \nfrom sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis\nfrom sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"6\"></a><br>\n## Train - Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_size = 0.3\nX_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = test_size, random_state = 42)\nprint(\"X_train\",len(X_train))\nprint(\"X_test\",len(X_test))\nprint(\"Y_train\",len(Y_train))\nprint(\"Y_test\",len(Y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"7\"></a><br>\n## Standrization"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_df = pd.DataFrame(X_train, columns = columns)\nX_train_df_describe = X_train_df.describe()\nX_train_df_describe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_df[\"target\"] = Y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_melted = pd.melt(X_train_df, id_vars = \"target\",\n                      var_name = \"features\",\n                      value_name = \"value\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\nsns.boxplot(x = \"features\", y = \"value\", hue = \"target\", data = data_melted)\nplt.xticks(rotation = 90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(X_train_df[corr_features], diag_kind = \"kde\", markers = \"+\",hue = \"target\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"8\"></a><br>\n## Simple K-Nearest Neighbors Classifier "},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors = 2)\nknn.fit(X_train, Y_train)\ny_pred = knn.predict(X_test)\ncm = confusion_matrix(Y_test, y_pred)\nacc = accuracy_score(Y_test, y_pred)\nscore = knn.score(X_test, Y_test)\n\nprint(\"Basic KNN Accuracy: % {}\".format(acc))\nprint(\"Score : \", score)\nprint(\"CM : \", cm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"9\"></a><br>\n## KNN Best Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"def KNN_Best_Params(x_train, x_test, y_train, y_test):\n    \n    k_range = list(range(1,31))\n    weight_options = [\"uniform\",\"distance\"]\n    print()\n    param_grid = dict(n_neighbors = k_range, weights = weight_options)\n     \n    knn = KNeighborsClassifier()\n    \n    grid = GridSearchCV(knn, param_grid, cv = 10, scoring = \"accuracy\")\n    grid.fit(x_train, y_train)\n    \n    print(\"Best training score : {} with paremeters : {}\".format(grid.best_score_, grid.best_params_))\n    print()\n    \n    knn = KNeighborsClassifier(**grid.best_params_) # best paremetre olarak gelen değerlerimiz.\n    knn.fit(x_train, y_train)\n    \n    y_pred_test = knn.predict(x_test)\n    y_pred_train = knn.predict(x_train)\n    \n    cm_test = confusion_matrix(y_test, y_pred_test)\n    cm_train = confusion_matrix(y_train, y_pred_train)\n    \n    acc_test = accuracy_score(y_test, y_pred_test) \n    acc_train = accuracy_score(y_train, y_pred_train)\n    print(\"Test Score: {}, Train Score: {}\".format(acc_test, acc_train))\n    print()\n    print(\"CM Test: \",cm_test)\n    print(\"CM Train: \",cm_train)\n    \n    return grid\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = KNN_Best_Params(X_train, X_test, Y_train, Y_test) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"10\"></a><br>\n# Principal Component Analysis (PCA)"},{"metadata":{},"cell_type":"markdown","source":"PCA :\n* Linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space.\n* Unsupervised Machine Learning"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nx_scaled = scaler.fit_transform(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We reduce 30 featurs to 2 \npca = PCA(n_components = 2)\npca.fit(x_scaled)\nX_reduced_pca = pca.transform(x_scaled)\npca_data = pd.DataFrame(X_reduced_pca, columns = [\"p1\",\"p2\"])\npca_data[\"target\"] = y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\nsns.scatterplot(x = \"p1\", y = \"p2\", hue = \"target\", data = pca_data)\nplt.title(\"PCA : p1 vs p2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_pca, X_test_pca, Y_train_pca, Y_test_pca = train_test_split(X_reduced_pca, y, test_size = test_size, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We send our data by calling the function we wrote.\ngrid_pca = KNN_Best_Params(X_train_pca, X_test_pca, Y_train_pca, Y_test_pca)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap_light = ListedColormap(['orange',  'cornflowerblue'])\ncmap_bold = ListedColormap(['darkorange', 'darkblue'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"h = .05 # step size in the mesh\nX = X_reduced_pca\nx_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\ny_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Z = grid_pca.predict(np.c_[xx.ravel(), yy.ravel()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Z = Z.reshape(xx.shape)\nplt.figure(figsize=(10,7))\nplt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n# Plot also the training points\nplt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold,\n            edgecolor='k', s=20)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.title(\"%i-Class classification (k = %i, weights = '%s')\"\n          % (len(np.unique(y)),grid_pca.best_estimator_.n_neighbors, grid_pca.best_estimator_.weights))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"11\"></a><br>\n# Neighborhood Component Analysis (NCA)"},{"metadata":{},"cell_type":"markdown","source":"NCA is a machine learning algorithm for metric learning. It learns a linear transformation in a supervised fashion to improve the classification accuracy of a stochastic nearest neighbors rule in the transformed space."},{"metadata":{"trusted":true},"cell_type":"code","source":"nca = NeighborhoodComponentsAnalysis(n_components = 2, random_state = 42)\nnca.fit(x_scaled, y)\nX_reduced_nca = nca.transform(x_scaled)\nnca_data = pd.DataFrame(X_reduced_nca, columns = [\"p1\",\"p2\"])\nnca_data[\"target\"] = y\nplt.figure(figsize=(10,7))\nsns.scatterplot(x = \"p1\",  y = \"p2\", hue = \"target\", data = nca_data)\nplt.title(\"NCA: p1 vs p2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_nca, X_test_nca, Y_train_nca, Y_test_nca = train_test_split(X_reduced_nca, y, test_size = test_size, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_nca = KNN_Best_Params(X_train_nca, X_test_nca, Y_train_nca, Y_test_nca)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"h = .2 # step size in the mesh\nX = X_reduced_nca\nx_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\ny_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Z = grid_nca.predict(np.c_[xx.ravel(), yy.ravel()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Z = Z.reshape(xx.shape)\nplt.figure(figsize=(10,7))\nplt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n\n# Plot also the training points\nplt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold,\n            edgecolor='k', s=20)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.title(\"%i-Class classification (k = %i, weights = '%s')\"\n          % (len(np.unique(y)),grid_nca.best_estimator_.n_neighbors, grid_nca.best_estimator_.weights))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id = \"12\"></a><br>\n# Result"},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's find the wrong classifications we made.\nknn = KNeighborsClassifier(**grid_nca.best_params_)\nknn.fit(X_train_nca,Y_train_nca)\ny_pred_nca = knn.predict(X_test_nca)\nacc_test_nca = accuracy_score(y_pred_nca,Y_test_nca)\nprint(\"Score --> {}\".format(knn.score(X_test_nca,Y_test_nca)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.DataFrame()\ntest_data[\"X_test_nca_p1\"] = X_test_nca[:,0]\ntest_data[\"X_test_nca_p2\"] = X_test_nca[:,1]\ntest_data[\"y_pred_nca\"] = y_pred_nca\ntest_data[\"Y_test_nca\"] = Y_test_nca","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\ndiff = np.where(y_pred_nca!=Y_test_nca)[0]\nplt.scatter(test_data.iloc[diff,0],test_data.iloc[diff,1],label = \"Wrong Classified\",alpha = 0.2,color = \"red\",s = 1000)\n\nsns.scatterplot(x=\"X_test_nca_p1\", y=\"X_test_nca_p2\", hue=\"Y_test_nca\",data=test_data)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}