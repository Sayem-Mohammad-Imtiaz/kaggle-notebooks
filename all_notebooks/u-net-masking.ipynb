{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Image Masking by U-NET Architecture From Scratch","metadata":{"execution":{"iopub.status.busy":"2021-08-06T09:06:05.634862Z","iopub.execute_input":"2021-08-06T09:06:05.635244Z","iopub.status.idle":"2021-08-06T09:06:05.641911Z","shell.execute_reply.started":"2021-08-06T09:06:05.635206Z","shell.execute_reply":"2021-08-06T09:06:05.641028Z"}}},{"cell_type":"markdown","source":"![Masking Demo_image](https://analyticsindiamag.com/wp-content/uploads/2020/07/u-net-segmentation-e1542978983391.png)","metadata":{}},{"cell_type":"markdown","source":"**U-net Research Paper available at [unetpaper](https://arxiv.org/abs/1505.04597)**","metadata":{}},{"cell_type":"markdown","source":"**Blog on Image Segmentation and U-net. [check here](https://analyticsindiamag.com/my-experiment-with-unet-building-an-image-segmentation-model/)**","metadata":{}},{"cell_type":"code","source":"# Importing Libraries\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport random\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nseed = 42\nnp.random.seed = seed\nfrom sklearn.model_selection import train_test_split\nfrom skimage.io import imread, imshow\nfrom skimage.transform import resize","metadata":{"execution":{"iopub.status.busy":"2021-08-06T09:32:52.933994Z","iopub.execute_input":"2021-08-06T09:32:52.934375Z","iopub.status.idle":"2021-08-06T09:32:53.908622Z","shell.execute_reply.started":"2021-08-06T09:32:52.934345Z","shell.execute_reply":"2021-08-06T09:32:53.907769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining Shape and Size of Image\nIMG_WIDTH = 128\nIMG_HEIGHT = 128\nIMG_CHANNELS = 3\n\nTRAIN_PATH = '/kaggle/input/clothing-coparsing-dataset'","metadata":{"execution":{"iopub.status.busy":"2021-08-06T09:32:55.522989Z","iopub.execute_input":"2021-08-06T09:32:55.523389Z","iopub.status.idle":"2021-08-06T09:32:55.528221Z","shell.execute_reply.started":"2021-08-06T09:32:55.523355Z","shell.execute_reply":"2021-08-06T09:32:55.526989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Listing all image and mask name from file\n\nX_imageid = os.listdir(os.path.join(TRAIN_PATH,'images'))\ny_imageid = os.listdir(os.path.join(TRAIN_PATH,'labels','pixel_level_labels_colored'))\nX_imageid.sort()\ny_imageid.sort()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T09:32:57.924148Z","iopub.execute_input":"2021-08-06T09:32:57.924463Z","iopub.status.idle":"2021-08-06T09:32:58.182694Z","shell.execute_reply.started":"2021-08-06T09:32:57.924436Z","shell.execute_reply":"2021-08-06T09:32:58.181865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating zeros tensor of Input and output sizes. Later it will be filled with data.\nX = np.zeros((len(X_imageid),IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS),dtype = np.uint8)\ny = np.zeros((len(X_imageid),IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS),dtype = np.uint8)\nprint(X.shape,y.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T09:40:39.924229Z","iopub.execute_input":"2021-08-06T09:40:39.924555Z","iopub.status.idle":"2021-08-06T09:40:39.934152Z","shell.execute_reply.started":"2021-08-06T09:40:39.924528Z","shell.execute_reply":"2021-08-06T09:40:39.933256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# No. of Mask available as samplesize\n\nsamplesize = 1003\nX_imageid = X_imageid[:samplesize]\ny_imageid = y_imageid[:samplesize]\nX = X[:samplesize]\ny = y[:samplesize]","metadata":{"execution":{"iopub.status.busy":"2021-08-06T09:40:44.023577Z","iopub.execute_input":"2021-08-06T09:40:44.023912Z","iopub.status.idle":"2021-08-06T09:40:44.029989Z","shell.execute_reply.started":"2021-08-06T09:40:44.023883Z","shell.execute_reply":"2021-08-06T09:40:44.027515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading data into zeros tensor variable as created above\nfor i,id_ in tqdm(enumerate(X_imageid),total = len(X_imageid)):\n    path = os.path.join(TRAIN_PATH,'images',id_)\n    img = imread(path)\n    img = resize(img,(IMG_HEIGHT,IMG_WIDTH),mode='constant',preserve_range = True)\n    X[i] =img\n        \n    mask_path = os.path.join(TRAIN_PATH,'labels','pixel_level_labels_colored',id_.split('.')[0]+'.png')\n\n    img = imread(mask_path)\n  \n    img = resize(img,(IMG_HEIGHT,IMG_WIDTH),mode='constant',preserve_range = True)\n    y[i] = img\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-06T09:41:09.374271Z","iopub.execute_input":"2021-08-06T09:41:09.374644Z","iopub.status.idle":"2021-08-06T09:44:13.058021Z","shell.execute_reply.started":"2021-08-06T09:41:09.374597Z","shell.execute_reply":"2021-08-06T09:44:13.056952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scaling by Normalizing data between 0 to 1\nX = X/255.0\ny = y/255.0","metadata":{"execution":{"iopub.status.busy":"2021-08-06T09:44:24.874219Z","iopub.execute_input":"2021-08-06T09:44:24.874582Z","iopub.status.idle":"2021-08-06T09:44:25.1434Z","shell.execute_reply.started":"2021-08-06T09:44:24.87455Z","shell.execute_reply":"2021-08-06T09:44:25.14243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Spliting into train and valid data\nX_train,X_valid,y_train,y_valid = train_test_split(X,y,random_state = seed,test_size = 0.2)\nprint(X_train.shape,X_valid.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T09:44:41.203971Z","iopub.execute_input":"2021-08-06T09:44:41.204322Z","iopub.status.idle":"2021-08-06T09:44:41.452333Z","shell.execute_reply.started":"2021-08-06T09:44:41.204291Z","shell.execute_reply":"2021-08-06T09:44:41.451365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Sample View of image and image mask\nimage_x = random.randint(0, len(X_train)-1)\nimshow(X_train[image_x])\nplt.show()\nimshow(np.squeeze(y_train[image_x]))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T09:44:44.314723Z","iopub.execute_input":"2021-08-06T09:44:44.315043Z","iopub.status.idle":"2021-08-06T09:44:44.745439Z","shell.execute_reply.started":"2021-08-06T09:44:44.315006Z","shell.execute_reply":"2021-08-06T09:44:44.744614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Building U-Net Architecture Model\ndef build_model():\n    tf.keras.backend.clear_session()\n    inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n\n    #Contraction path\n    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n    c1 = tf.keras.layers.Dropout(0.1)(c1)\n    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n\n    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n    c2 = tf.keras.layers.Dropout(0.1)(c2)\n    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n\n    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n    c3 = tf.keras.layers.Dropout(0.2)(c3)\n    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n    p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n\n    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n    c4 = tf.keras.layers.Dropout(0.2)(c4)\n    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n    p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n\n    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n    c5 = tf.keras.layers.Dropout(0.3)(c5)\n    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n\n    #Expansive path \n    u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n    u6 = tf.keras.layers.concatenate([u6, c4])\n    c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n    c6 = tf.keras.layers.Dropout(0.2)(c6)\n    c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n\n    u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n    u7 = tf.keras.layers.concatenate([u7, c3])\n    c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n    c7 = tf.keras.layers.Dropout(0.2)(c7)\n    c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n\n    u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n    u8 = tf.keras.layers.concatenate([u8, c2])\n    c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n    c8 = tf.keras.layers.Dropout(0.1)(c8)\n    c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n\n    u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n    u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n    c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n    c9 = tf.keras.layers.Dropout(0.1)(c9)\n    c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n\n    outputs = tf.keras.layers.Conv2D(3, (1, 1), activation='sigmoid')(c9)\n\n    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-08-06T09:44:49.976143Z","iopub.execute_input":"2021-08-06T09:44:49.976478Z","iopub.status.idle":"2021-08-06T09:44:50.154046Z","shell.execute_reply.started":"2021-08-06T09:44:49.97645Z","shell.execute_reply":"2021-08-06T09:44:50.152604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel = build_model()\nprint(\"Input Shape :  \",model.input_shape)\nprint(\"Output Shape:  \",model.output_shape)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T09:45:57.144405Z","iopub.execute_input":"2021-08-06T09:45:57.14474Z","iopub.status.idle":"2021-08-06T09:45:57.408726Z","shell.execute_reply.started":"2021-08-06T09:45:57.144705Z","shell.execute_reply":"2021-08-06T09:45:57.407773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpointer = tf.keras.callbacks.ModelCheckpoint('cloth_model.h5', verbose=1, save_best_only=True)\ncallbacks = [\n        tf.keras.callbacks.TensorBoard(log_dir='logs')]","metadata":{"execution":{"iopub.status.busy":"2021-08-06T09:46:02.748318Z","iopub.execute_input":"2021-08-06T09:46:02.74864Z","iopub.status.idle":"2021-08-06T09:46:03.050544Z","shell.execute_reply.started":"2021-08-06T09:46:02.748612Z","shell.execute_reply":"2021-08-06T09:46:03.049482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training\nresults = model.fit(X_train, y_train, validation_split=0.1, batch_size=16, epochs=50, callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T09:46:05.293493Z","iopub.execute_input":"2021-08-06T09:46:05.293838Z","iopub.status.idle":"2021-08-06T09:47:10.766882Z","shell.execute_reply.started":"2021-08-06T09:46:05.293792Z","shell.execute_reply":"2021-08-06T09:47:10.765898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing Data on Training Set\nimage_x = random.randint(0, len(X_train)-1)\nimshow(X_train[image_x])\nplt.show()\nX_testing = np.expand_dims(X_train[image_x],axis = 0)\n\nimshow(np.squeeze(y_train[image_x]))\nplt.show()\n\nprediction = model.predict(X_testing)\n\nimshow(np.squeeze(prediction))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T09:47:13.923672Z","iopub.execute_input":"2021-08-06T09:47:13.924037Z","iopub.status.idle":"2021-08-06T09:47:14.810919Z","shell.execute_reply.started":"2021-08-06T09:47:13.923998Z","shell.execute_reply":"2021-08-06T09:47:14.810114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Testing Data on Validation Set","metadata":{}},{"cell_type":"code","source":"images_x = set()\nwhile(len(images_x)!=10):\n    images_x.add(random.randint(0, len(X_valid)-1))\n\nfor num,image_x in enumerate(images_x):\n    plt.figure(figsize=(9,9))\n    plt.subplot(1,3,1)\n    plt.title(\"Real Image\")\n    imshow(X_valid[image_x])\n    \n    plt.subplot(1,3,2)\n    plt.title(\"Labeled Output\")\n    imshow(np.squeeze(y_valid[image_x]))\n    \n    X_testing = np.expand_dims(X_valid[image_x],axis = 0)\n    prediction = model.predict(X_testing)\n    plt.subplot(1,3,3)\n    plt.title('Predcted Output')\n    imshow(np.squeeze(prediction))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T09:59:57.544443Z","iopub.execute_input":"2021-08-06T09:59:57.544763Z","iopub.status.idle":"2021-08-06T10:00:02.111826Z","shell.execute_reply.started":"2021-08-06T09:59:57.544735Z","shell.execute_reply":"2021-08-06T10:00:02.110984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('model_unet.h5')","metadata":{"execution":{"iopub.status.busy":"2021-08-06T10:03:22.781707Z","iopub.execute_input":"2021-08-06T10:03:22.782092Z","iopub.status.idle":"2021-08-06T10:03:23.176586Z","shell.execute_reply.started":"2021-08-06T10:03:22.782038Z","shell.execute_reply":"2021-08-06T10:03:23.175751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def try_out_own_image(image_path):\n    img = imread(image_path)\n    img = resize(img,(IMG_HEIGHT,IMG_WIDTH),mode='constant',preserve_range = True)\n    img = img/255.0\n    print(img.shape)\n    \n    X_testing = np.expand_dims(img,axis = 0)\n    prediction = model.predict(X_testing)\n    plt.figure(figsize=(6,9))\n    plt.subplot(1,2,1)\n    plt.title('Real Image')\n    imshow(img)\n    plt.subplot(1,2,2)\n    imshow(np.squeeze(prediction))\n    plt.title('Predicted Output')\n    plt.show()\n    \n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2021-08-06T10:08:21.421525Z","iopub.execute_input":"2021-08-06T10:08:21.421864Z","iopub.status.idle":"2021-08-06T10:08:21.428034Z","shell.execute_reply.started":"2021-08-06T10:08:21.421832Z","shell.execute_reply":"2021-08-06T10:08:21.42719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path = '../input/clothing-coparsing-dataset/images/1009.jpg'\ntry_out_own_image(image_path)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T10:08:29.981313Z","iopub.execute_input":"2021-08-06T10:08:29.981647Z","iopub.status.idle":"2021-08-06T10:08:30.416888Z","shell.execute_reply.started":"2021-08-06T10:08:29.981619Z","shell.execute_reply":"2021-08-06T10:08:30.416119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path = '../input/clothing-coparsing-dataset/images/2067.jpg'\ntry_out_own_image(image_path)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T10:09:04.190586Z","iopub.execute_input":"2021-08-06T10:09:04.190923Z","iopub.status.idle":"2021-08-06T10:09:04.65665Z","shell.execute_reply.started":"2021-08-06T10:09:04.190892Z","shell.execute_reply":"2021-08-06T10:09:04.655749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path = '../input/clothing-coparsing-dataset/images/1888.jpg'\ntry_out_own_image(image_path)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T10:09:23.400906Z","iopub.execute_input":"2021-08-06T10:09:23.401271Z","iopub.status.idle":"2021-08-06T10:09:23.849323Z","shell.execute_reply.started":"2021-08-06T10:09:23.40124Z","shell.execute_reply":"2021-08-06T10:09:23.848533Z"},"trusted":true},"execution_count":null,"outputs":[]}]}