{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport pandas as pd\nimport os\nimport bokeh.io\n# from bokeh.layouts import row, column\nfrom bokeh.models import ColumnDataSource, Label\nfrom bokeh.plotting import figure, show\n\nimport umap\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport ast\nimport re\n\nbokeh.io.output_notebook()\n\n# Any results you write to the current directory are saved as output.\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the previous version I used the ingredients. I will use the 'steps' to have more texts. I checked the data and some steps do not have the ingredients. It just says for example \"mix all the ingredients.\". In this version I will not join the ingredients to the steps.\nI only keep the text as per the regex."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"r_rcp = pd.read_csv('/kaggle/input/food-com-recipes-and-user-interactions/RAW_recipes.csv', delimiter=',')\ningrdt = r_rcp.loc[:, ['steps']]\ning_all = r_rcp.loc[:, ['ingredients']]\nfood_data = ingrdt.values.tolist()\nall_them = ing_all.values.tolist()\n\nonly_chicken = []\npos = 0\nfor ig in all_them:\n    if 'chicken' in ig[0]:\n        only_chicken.append(pos)\n    pos+=1                  \nprint(\"CHICKEN {}\".format(len(only_chicken)))\n#raise ValueError(\"look\")\nlist_stps = []\n\nfor f in range(len(food_data)-1):\n    stps = ast.literal_eval(food_data[f][0])\n    stps_stgr = ' '.join(stps)\n    stps_clean = re.sub(\"[^a-zA-Z]\", \" \", stps_stgr)\n    list_stps.append(stps_clean)\n\nstps_chicken = [list_stps[oc] for oc in only_chicken]\nprint(stps_chicken[0:50])      ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I used 100 for the n_neighbors in a previous version on the full load but the calculation is taking way too long."},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = TfidfVectorizer(min_df=10,max_features=None)                                         \nvz = vectorizer.fit_transform(stps_chicken)\nprint(\"VZ done\")\n\nclusterable_embedding = umap.UMAP(\n    n_neighbors=30,  \n    min_dist=0.0,\n    n_components=2,\n    random_state=42,\n).fit_transform(vz)\nprint(\"umap done\")\n\nlabels = DBSCAN(\n    eps=0.18,\n    min_samples=30).fit_predict(clusterable_embedding)\nprint(\"dbscan done\")\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get the x y position for each datapoint. Separate the clusters and the noise."},{"metadata":{"trusted":true},"cell_type":"code","source":"clustered = (labels >= 0)\nxtx = clusterable_embedding[clustered, 0]\nytx = clusterable_embedding[clustered, 1]\n\nxtx_n = clusterable_embedding[~clustered, 0]\nytx_n = clusterable_embedding[~clustered, 1]\n\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\nprint(\"Number of clusters {}\".format(n_clusters_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Color each datapoint. Any cluster labeled above 8 will be the same color."},{"metadata":{"trusted":true},"cell_type":"code","source":"llbl = list(labels[clustered])\ncolor_YlOrRd = ['#ffffcc','#ffeda0','#fed976','#feb24c','#fd8d3c','#fc4e2a#','e31a1c','#bd0026','#800026']\ncol = [color_YlOrRd[i] if (i>=0 and i < 9) else '#9119e6' for i in llbl]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's display the datapoints."},{"metadata":{"trusted":true},"cell_type":"code","source":"sourcetx = ColumnDataSource(data=dict(xtx=xtx, ytx=ytx, col=col))\nsource_noise = ColumnDataSource(data=dict(xtx_n=xtx_n, ytx_n=ytx_n))\n\nptx = figure(plot_width=800, plot_height=600,\n             title=\"Ingredients: Python, umap, Dbscan, Bokeh.\",\n             tools=\"pan,wheel_zoom,reset\",\n             active_scroll=\"wheel_zoom\",\n             toolbar_location=\"above\"\n             )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# output_file(\"recipe.html\")\n\nptx.scatter('xtx', 'ytx', size=3, alpha=0.8, line_dash='solid', color=\"col\", source=sourcetx,\n                     legend='clustered')\nptx.scatter('xtx_n', 'ytx_n', size=3, alpha=0.8, line_dash='solid', color='#CDCDCD',\n                         source=source_noise, legend='noise') \nptx.legend.click_policy = \"hide\"\nptx.legend.background_fill_alpha = 0.4\nptx.legend.location = \"bottom_right\"\n\nshow(ptx)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}