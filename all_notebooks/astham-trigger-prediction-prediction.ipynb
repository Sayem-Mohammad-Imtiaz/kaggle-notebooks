{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q efficientnet\n\nimport os\nimport numpy as np \nimport pandas as pd\nimport random\nimport math\n\nimport warnings\nfrom shutil import copyfile\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.applications as tfka\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing import image\nimport tensorflow_hub as hub\nimport tensorflow_datasets as tfds\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport efficientnet.tfkeras as efn\nfrom tqdm import tqdm\nimport gc\nimport cv2\nfrom tensorflow.keras import backend as K","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-17T16:46:19.614676Z","iopub.execute_input":"2021-06-17T16:46:19.615067Z","iopub.status.idle":"2021-06-17T16:46:35.330834Z","shell.execute_reply.started":"2021-06-17T16:46:19.614986Z","shell.execute_reply":"2021-06-17T16:46:35.329947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Configuration\n# For tf.dataset\nAUTO = tf.data.experimental.AUTOTUNE\n\nEPOCHS = 10\nBATCH_SIZE = 32\nIMAGE_SIZE = [256, 256]\n# Seed\nSEED = 9527\nseed = 9527\n# Learning rate\nLR = 0.0005\n# Verbosity\nVERBOSE = 2\n# Label_dim\nlabel_dim = 1\nN_CLASSES = 2\n\n# dataset path\nimg_path = '../input/food-ingredients-and-recipe-dataset-with-images/Food Images/Food Images/'\n\n\ncommon_allergens = {\n    'cows milk': {'Cheese', 'Butter', 'Margarine', 'Yogurt', 'Cream', 'Ice cream'},\n    'eggs': {'egg'},\n    'tree nuts': {'Brazil nut', 'Almond', 'Cashew', 'Macadamia nut', 'Pistachio','Pine nut','Walnut'},\n    'peanuts': {'peanut'},\n    'shellfish': {'Shrimp','Prawn','Crayfish', 'Lobster', 'Squid', 'Scallops'},\n    'wheat': {'flour', 'wheat', 'pasta', 'noodle', 'bread', 'crust'},\n    'soy': {'soy', 'tofu', 'soya'},\n    'fish': {'fish', 'seafood'}\n}","metadata":{"execution":{"iopub.status.busy":"2021-06-17T16:46:35.332392Z","iopub.execute_input":"2021-06-17T16:46:35.332733Z","iopub.status.idle":"2021-06-17T16:46:35.343105Z","shell.execute_reply.started":"2021-06-17T16:46:35.332699Z","shell.execute_reply":"2021-06-17T16:46:35.342297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)\n\ndef image_mapping_check(dataset):\n    counter = 0\n    record = []\n    while counter < dataset.shape[0]-1:\n        row = dataset.loc[counter]\n        img_name = row['Image_Name']\n        img = cv2.imread(img_path+img_name+'.jpg')\n        try:\n            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) \n        except:\n            record.append(counter)\n        counter+= 1\n    new = dataset.drop(record, axis = 0)\n    new = new.reset_index(drop = True)\n    return new\n\ndef allergens_mapping(row, types):\n    for item in common_allergens[types]:\n        if item.lower() in row.lower():\n                return 1\n    return 0\n\ndef combination(row):\n    return(row['cows_milk'], row['eggs'], row['tree nuts'], row['peanuts'], row['shellfish'], row['wheat'], row['soy'], row['fish'])\n\n\ndef load_dataset():\n    path = \"../input/food-ingredients-and-recipe-dataset-with-images/Food Ingredients and Recipe Dataset with Image Name Mapping.csv\"\n    df = pd.read_csv(path)\n    df = image_mapping_check(df)\n    df['image_path'] = img_path + df['Image_Name'] + '.jpg'\n    df['cows_milk'] = df['Cleaned_Ingredients'].apply(lambda x: allergens_mapping(x, types = 'cows milk'))\n    df['eggs'] = df['Cleaned_Ingredients'].apply(lambda x: allergens_mapping(x, types = 'eggs'))\n    df['tree nuts'] = df['Cleaned_Ingredients'].apply(lambda x: allergens_mapping(x, types = 'tree nuts'))\n    df['peanuts'] = df['Cleaned_Ingredients'].apply(lambda x: allergens_mapping(x, types = 'peanuts'))\n    df['shellfish'] = df['Cleaned_Ingredients'].apply(lambda x: allergens_mapping(x, types = 'shellfish'))\n    df['wheat'] = df['Cleaned_Ingredients'].apply(lambda x: allergens_mapping(x, types = 'wheat'))\n    df['soy'] = df['Cleaned_Ingredients'].apply(lambda x: allergens_mapping(x, types = 'soy'))\n    df['fish'] = df['Cleaned_Ingredients'].apply(lambda x: allergens_mapping(x, types = 'fish'))\n    df['total'] = df.apply(combination, axis = 1)\n    x_train, x_val, y_train, y_val = train_test_split(df[['image_path']], df.iloc[:,7:16], shuffle = True, random_state = seed, test_size = 0.25)\n    train_df = pd.concat([x_train, y_train], axis = 1).reset_index(drop = True)\n    val_df = pd.concat([x_val, y_val], axis = 1).reset_index(drop = True)\n    train_df.head()\n    return df, train_df, val_df\n\n# Function to decode our images\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels = 3)\n    image = tf.image.resize(image, IMAGE_SIZE)\n    image = tf.cast(image, tf.float32) / 255.0\n    return image\n\n# Function to read our test image and return image\ndef read_image(image):\n    image = tf.io.read_file(image)\n    image = decode_image(image)\n    return image\n\n# Function to get our dataset that read images\ndef get_dataset(image):\n    dataset = tf.data.Dataset.from_tensor_slices(image)\n    dataset = dataset.map(read_image, num_parallel_calls = AUTO)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2021-06-17T16:46:35.34706Z","iopub.execute_input":"2021-06-17T16:46:35.347303Z","iopub.status.idle":"2021-06-17T16:46:35.368398Z","shell.execute_reply.started":"2021-06-17T16:46:35.34728Z","shell.execute_reply":"2021-06-17T16:46:35.367526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Arcmarginproduct class keras layer\nclass ArcMarginProduct(tf.keras.layers.Layer):\n    '''\n    Implements large margin arc distance.\n\n    Reference:\n        https://arxiv.org/pdf/1801.07698.pdf\n        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n            blob/master/src/modeling/metric_learning.py\n    '''\n    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n                 ls_eps=0.0, **kwargs):\n\n        super(ArcMarginProduct, self).__init__(**kwargs)\n\n        self.n_classes = n_classes\n        self.s = s\n        self.m = m\n        self.ls_eps = ls_eps\n        self.easy_margin = easy_margin\n        self.cos_m = tf.math.cos(m)\n        self.sin_m = tf.math.sin(m)\n        self.th = tf.math.cos(math.pi - m)\n        self.mm = tf.math.sin(math.pi - m) * m\n\n    def get_config(self):\n\n        config = super().get_config().copy()\n        config.update({\n            'n_classes': self.n_classes,\n            's': self.s,\n            'm': self.m,\n            'ls_eps': self.ls_eps,\n            'easy_margin': self.easy_margin,\n        })\n        return config\n\n    def build(self, input_shape):\n        super(ArcMarginProduct, self).build(input_shape[0])\n\n        self.W = self.add_weight(\n            name='W',\n            shape=(int(input_shape[0][-1]), self.n_classes),\n            initializer='glorot_uniform',\n            dtype='float32',\n            trainable=True,\n            regularizer=None)\n\n    def call(self, inputs):\n        X, y = inputs\n        y = tf.cast(y, dtype=tf.int32)\n        cosine = tf.matmul(\n            tf.math.l2_normalize(X, axis=1),\n            tf.math.l2_normalize(self.W, axis=0)\n        )\n        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = tf.where(cosine > 0, phi, cosine)\n        else:\n            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n        one_hot = tf.cast(\n            tf.one_hot(y, depth=self.n_classes),\n            dtype=cosine.dtype\n        )\n        if self.ls_eps > 0:\n            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output *= self.s\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-06-17T16:46:35.372091Z","iopub.execute_input":"2021-06-17T16:46:35.372384Z","iopub.status.idle":"2021-06-17T16:46:35.388702Z","shell.execute_reply.started":"2021-06-17T16:46:35.37236Z","shell.execute_reply":"2021-06-17T16:46:35.387962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function for a custom learning rate scheduler with warmup and decay\ndef get_lr_callback():\n    # lr_start   = 0.0000001\n    # lr_max     = 0.000005 * BATCH_SIZE\n    lr_min     = 0.0000001\n    lr_ramp_ep = 5\n    lr_sus_ep  = 0\n    lr_decay   = 0.8\n   \n    def lrfn(epoch):\n        if epoch < EPOCHS/2:\n            lr = 0.00001 * (BATCH_SIZE - epoch)\n        #elif epoch < EPOCHS/3 * 2:\n        #    lr = 0.000001 * (BATCH_SIZE - epoch)\n        else:\n            lr = lr_min\n        return lr\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\n    return lr_callback","metadata":{"execution":{"iopub.status.busy":"2021-06-17T16:46:35.391835Z","iopub.execute_input":"2021-06-17T16:46:35.392114Z","iopub.status.idle":"2021-06-17T16:46:35.401186Z","shell.execute_reply.started":"2021-06-17T16:46:35.392087Z","shell.execute_reply":"2021-06-17T16:46:35.400391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model(mode):\n    \n    inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp')\n    if mode == 'eff0':\n        x = efn.EfficientNetB0(weights = 'imagenet', include_top = False)(inp)\n    elif mode == 'eff1':\n        x = efn.EfficientNetB1(weights = 'imagenet', include_top = False)(inp)\n    elif mode == 'eff2':\n        x = efn.EfficientNetB2(weights = 'imagenet', include_top = False)(inp)\n    elif mode == 'eff3':\n        x = efn.EfficientNetB3(weights = 'imagenet', include_top = False)(inp)\n    elif mode == 'eff4':\n        x = efn.EfficientNetB4(weights = 'imagenet', include_top = False)(inp)\n    elif mode == 'eff5':\n        x = efn.EfficientNetB5(weights = 'imagenet', include_top = False)(inp)\n    elif mode == 'eff6':\n        x = efn.EfficientNetB6(weights = 'imagenet', include_top = False)(inp)\n    elif mode == 'eff7':\n        x = efn.EfficientNetB7(weights = 'imagenet', include_top = False)(inp)\n    elif mode == 'ICPV2':\n        x = tfka.InceptionResNetV2(weights = 'imagenet', include_top = False)(inp)\n    elif mode == 'ICPV3':\n        x = tfka.InceptionV3(weights = 'imagenet', include_top = False)(inp)\n    elif mode == 'XCP':\n        x = tfka.Xception(weights = 'imagenet', include_top = False)(inp)\n    elif mode == 'RN50':\n        x = tfka.ResNet50(weights = 'imagenet', include_top = False)(inp)\n    else:\n        # 'RN101'\n        x = tfka.ResNet101(weights = 'imagenet', include_top = False)(inp)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    output = tf.keras.layers.Dense(label_dim, activation='sigmoid')(x)\n    model = tf.keras.models.Model(inputs = [inp], outputs = [output])\n    return model\n\ndef model_prediction(image_paths,target, mode):\n    model = get_model(mode)\n    weight_path = '../input/asthma-allenger-prediction-model-weights/'f'Model_{mode}_{target}_{SEED}.h5'\n    print(weight_path)\n    model.load_weights(weight_path)   \n    img = get_dataset(image_paths)\n    pred = model.predict(img)\n    return pred","metadata":{"execution":{"iopub.status.busy":"2021-06-17T17:02:33.299242Z","iopub.execute_input":"2021-06-17T17:02:33.29957Z","iopub.status.idle":"2021-06-17T17:02:33.318806Z","shell.execute_reply.started":"2021-06-17T17:02:33.299539Z","shell.execute_reply":"2021-06-17T17:02:33.318005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_report(targets, models, thresholds):\n    seed_everything(seed)\n    df, train_df, val_df = load_dataset()\n    final_target = []\n    final_model = []\n    final_acc = []\n    final_acc_threshold = []\n    final_f1s = []\n    final_f1s_threshold = []\n    for target in targets:\n        for mode in models:\n            acc = []\n            f1s = []\n            pred = model_prediction(val_df.image_path.values,target = target, mode = mode)\n            y_true = val_df[target].values\n            for threshold in thresholds:\n                y_pred = np.array([1 if x > threshold else 0 for x in pred])\n                accuracy = accuracy_score(y_true,y_pred)\n                f1s_score = f1_score(y_true, y_pred, pos_label = 0)\n                acc.append(accuracy)\n                f1s.append(f1s_score)\n            best_acc = max(acc)\n            best_acc_threshold = thresholds[acc.index(best_acc)]\n            best_f1s = max(f1s)\n            best_f1s_threshold = thresholds[f1s.index(best_f1s)]\n\n            print('\\n')\n            print(f'Allenger: {target}, Model: {mode}')\n            print(f'Our best accuracy is {best_acc} with threshold {best_acc_threshold}')\n            print(f'Our best f1 score is {best_f1s} with threshold {best_f1s_threshold}')\n            final_target.append(target)\n            final_model.append(mode)\n            final_acc.append(best_acc)\n            final_acc_threshold.append(best_acc_threshold)\n            final_f1s.append(best_f1s)\n            final_f1s_threshold.append(best_f1s_threshold)\n    result = pd.DataFrame({\n        'Allergens': final_target,\n        'Model': final_model,\n        'Accuracy': final_acc,\n        'Accuracy_threshold': final_acc_threshold,\n        'F1_score': final_f1s,\n        'F1_score_threshold': final_f1s_threshold\n    })\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-06-17T17:02:35.930091Z","iopub.execute_input":"2021-06-17T17:02:35.930431Z","iopub.status.idle":"2021-06-17T17:02:35.940117Z","shell.execute_reply.started":"2021-06-17T17:02:35.930399Z","shell.execute_reply":"2021-06-17T17:02:35.939282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = ['eff0','eff1','eff2','eff3','eff4','eff5','eff6','eff7','ICPV2','ICPV3', 'XCP', 'RN50', 'RN101']\ntargets = [\"cows_milk\", \"eggs\", \"tree nuts\", \"peanuts\", \"shellfish\", \"wheat\", \"soy\", \"fish\"]\nthresholds = list(np.arange(0, 0.8, 0.01))","metadata":{"execution":{"iopub.status.busy":"2021-06-17T16:46:35.445376Z","iopub.execute_input":"2021-06-17T16:46:35.445813Z","iopub.status.idle":"2021-06-17T16:46:35.46127Z","shell.execute_reply.started":"2021-06-17T16:46:35.445776Z","shell.execute_reply":"2021-06-17T16:46:35.46047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = get_report(targets = targets, models = models, thresholds = thresholds)\nresult.to_csv('Single_model_results.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T17:02:49.304375Z","iopub.execute_input":"2021-06-17T17:02:49.304721Z","iopub.status.idle":"2021-06-17T17:15:54.526605Z","shell.execute_reply.started":"2021-06-17T17:02:49.304689Z","shell.execute_reply":"2021-06-17T17:15:54.524411Z"},"trusted":true},"execution_count":null,"outputs":[]}]}