{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom warnings import filterwarnings\nfrom mpl_toolkits.mplot3d import Axes3D\nimport statsmodels.api as sm\nimport missingno as msno\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import scale\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom scipy.stats import levene\nfrom scipy.stats import shapiro\nfrom scipy.stats.stats import pearsonr\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\nfrom sklearn.preprocessing import scale\nfrom sklearn.model_selection import ShuffleSplit, GridSearchCV\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn import model_selection\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\nfrom sklearn import linear_model\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\nimport xgboost as xgb\nfrom xgboost import XGBRegressor, XGBClassifier\nfrom lightgbm import LGBMRegressor, LGBMClassifier\nfrom catboost import CatBoostRegressor, CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn import tree\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Group --> Class\n* Age --> Age\n* EDUC --> Years of Education\n* SES --> Socioeconomic Status / 1-5\n* MMSE --> Mini Mental State Examination\n* CDR --> Clinical Dementia Rating\n* eTIV --> Estimated total intracranial volume\n* nWBV --> Normalize Whole Brain Volume\n* ASF --> Atlas Scaling Factor"},{"metadata":{},"cell_type":"markdown","source":"# DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"AlzheimerData = pd.read_csv(\"../input/alzheimer-features/alzheimer.csv\")\ndata = AlzheimerData.copy() # for VISUALIZATION\ndata[\"Group\"] = pd.Categorical(data[\"Group\"])\ndata[\"M/F\"] = pd.Categorical(data[\"M/F\"])\ndata[\"SES\"] = pd.Categorical(data[\"SES\"])\ndata[\"CDR\"] = pd.Categorical(data[\"CDR\"])\ndata[\"EDUC\"] = pd.Categorical(data[\"EDUC\"])\ndata[\"Age\"] = pd.Categorical(data[\"Age\"])\n\ndf = data.select_dtypes(include=[\"float64\",\"int64\",\"int32\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# INFORMATIONS"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.shape)\nprint(\"-.\"*40)\nprint(data.columns)\nprint(\"-.\"*40)\nprint(data.info())\nprint(\"-.\"*40)\nprint(data.describe().T)\nprint(\"-.\"*40)\nprint(data.groupby([\"Group\",\"SES\"])[\"MMSE\"].mean())\nprint(\"-.\"*40)\nprint(data.groupby([\"Group\",\"SES\"])[\"eTIV\"].mean())\nprint(\"-.\"*40)\nprint(data.groupby([\"Group\",\"SES\"])[\"nWBV\"].mean())\nprint(\"-.\"*40)\nprint(data.groupby([\"Group\",\"SES\"])[\"ASF\"].mean())\nprint(\"-.\"*40)\nprint(data.groupby([\"Group\",\"CDR\"])[\"MMSE\"].mean())\nprint(\"-.\"*40)\nprint(data.groupby([\"Group\",\"CDR\"])[\"eTIV\"].mean())\nprint(\"-.\"*40)\nprint(data.groupby([\"Group\",\"CDR\"])[\"nWBV\"].mean())\nprint(\"-.\"*40)\nprint(data.groupby([\"Group\",\"CDR\"])[\"ASF\"].mean())\nprint(\"-.\"*40)\nprint(data[\"Group\"].value_counts())\nprint(\"-.\"*40)\nprint(data[\"EDUC\"].value_counts())\nprint(\"-.\"*40)\nprint(data[\"M/F\"].value_counts())\nprint(\"-.\"*40)\nprint(df.corr())\nprint(\"-.\"*40)\nprint(data.isnull().sum())\nprint(\"-.\"*40)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MISSING VALUES VISUALIZATION"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"msno.heatmap(data)\nmsno.matrix(data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# VISUALIZATION"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"data[\"Group\"].hist(figsize=(5,5))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"data[\"M/F\"].hist(figsize=(5,5))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"data[\"SES\"].hist(figsize=(5,5))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"data[\"CDR\"].hist(figsize=(5,5))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"data[\"Age\"].hist(figsize=(5,5))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"fig = plt.figure()\nax = Axes3D(fig)\nax.scatter(data[\"MMSE\"], data[\"eTIV\"], data[\"nWBV\"], c=\"green\", s=20, alpha=0.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"sns.scatterplot(x=\"SES\",y=\"MMSE\",hue=\"Group\",data=data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"sns.scatterplot(x=\"SES\",y=\"eTIV\",hue=\"Group\",data=data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"sns.scatterplot(x=\"SES\",y=\"nWBV\",hue=\"Group\",data=data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"sns.scatterplot(x=\"SES\",y=\"ASF\",hue=\"Group\",data=data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"sns.lineplot(x=\"SES\", y=\"MMSE\",hue=\"Group\", data=data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"sns.lineplot(x=\"SES\", y=\"eTIV\",hue=\"Group\", data=data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"sns.lineplot(x=\"SES\", y=\"nWBV\",hue=\"Group\", data=data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"sns.lineplot(x=\"SES\", y=\"ASF\",hue=\"Group\", data=data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CORRELATION VISUALIZATION"},{"metadata":{"trusted":true},"cell_type":"code","source":"Features = [\"MMSE\",\"eTIV\",\"nWBV\",\"ASF\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrPearson = data[Features].corr(method=\"pearson\")\ncorrSpearman = data[Features].corr(method=\"spearman\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,8))\nsns.heatmap(corrPearson,annot=True,cmap='RdYlGn', vmin=-1, vmax=+1)\n\nplt.title(\"Pearson Correlation\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,8))\nsns.heatmap(corrSpearman,annot=True,cmap='RdYlGn', vmin=-1, vmax=+1)\n\nplt.title(\"Spearman Correlation\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# NORMALITY"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"for i in Features:\n    print(i,\"-----------\")\n    print(shapiro(data[i]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# HOMOGENEITY"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"print(levene(data[\"MMSE\"],data[\"eTIV\"],data[\"nWBV\"],data[\"ASF\"]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CONVERSION"},{"metadata":{"trusted":true},"cell_type":"code","source":"Columns = [\"Group\",\"M/F\"]\nencode = LabelEncoder()\nfor i in Columns:\n    print(data[i].value_counts())\n    print(\"----\")\n    data[i] = encode.fit_transform(data[i])\n    print(data[i].value_counts())\n    print(\"----\"*30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Group\n* Converted (0)\n* Demented (1)\n* Nondemented (2)\n\n#M/F\n* F (0)\n* M (1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"SES\"] = AlzheimerData[\"SES\"]\ndata[\"CDR\"] = AlzheimerData[\"CDR\"]\ndata[\"EDUC\"] = AlzheimerData[\"EDUC\"]\ndata[\"Age\"] = AlzheimerData[\"Age\"]\n\nprint(data.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# AGAINIST VALUES"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"DataForA = data.dropna()\nclf = LocalOutlierFactor()\nclf.fit_predict(DataForA)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"score = clf.negative_outlier_factor_\nscoreSort = np.sort(score)\nprint(scoreSort[0:50])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"point = scoreSort[3]\nprint(DataForA[score == point])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"againstvalues = DataForA < point\nprint(DataForA[againstvalues])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"normalvalues = DataForA > point\nprint(data[normalvalues])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MISSING VALUES PROCESS"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"SES\"].fillna(data[\"SES\"].mean(), inplace=True)\ndata[\"MMSE\"].fillna(data[\"MMSE\"].mean(), inplace=True)\nprint(data.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# X & Y FOR MODELS"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = data.drop(\"Group\",axis=1)\ny = data[\"Group\"]\n\nxTrain, xTest, yTrain, yTest = train_test_split(x,y,test_size=0.20,random_state=42)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# OLS MODELS & ERROR & TUNING & PREDICT"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"ols = sm.OLS(yTrain,xTrain).fit()\npredict = ols.predict(xTest)\nprint(ols.summary())\n# R2 -- 0.89","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LINEAR MODELS & ERROR & TUNING & PREDICT"},{"metadata":{"trusted":true},"cell_type":"code","source":"lm = LinearRegression().fit(xTrain,yTrain)\npredict = lm.predict(xTest)\n\nR2CV = cross_val_score(lm,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CV)\n# 0.13\nerrorCV = -cross_val_score(lm,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCV))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PCR MODELS & ERROR & TUNING & PREDICT"},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA()\nxRTrain = pca.fit_transform(scale(xTrain))\n\nlm = LinearRegression().fit(xRTrain,yTrain)\npredict = lm.predict(xTest)\n\nR2CV = cross_val_score(lm,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CV)\n# 0.13\nerrorCV = -cross_val_score(lm,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCV))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PLS MODELS & ERROR & TUNING & PREDICT"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"pls = PLSRegression().fit(xTrain,yTrain)\npredict = pls.predict(xTest)\n\nR2CV = cross_val_score(pls,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CV)\n# 0.13\nerrorCV = -cross_val_score(pls,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCV))\n\nfor i in range(1,20):\n    plstuned = PLSRegression(n_components=i).fit(xTrain,yTrain)\n    print(f\"{i}\",\"--\"*20)\n    predicttuned = plstuned.predict(xTest)\n    R2CVtuned = cross_val_score(plstuned,xTest,yTest,cv=10,scoring=\"r2\").mean()\n    print(R2CVtuned)\n    # BEST IS 6 -- 0.15\n    errorCVtuned = -cross_val_score(plstuned,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\n    print(np.sqrt(errorCVtuned))\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RIDGE MODELS & ERROR & TUNING & PREDICT"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"ridge = Ridge().fit(xTrain,yTrain)\npredict = ridge.predict(xTest)\n\nR2CV = cross_val_score(ridge,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CV)\nerrorCV = -cross_val_score(ridge,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCV))\n\nalpha = np.random.uniform(0.1,10,50)\n\ncv = RidgeCV(alphas=alpha,scoring=\"r2\",cv=10,normalize=True).fit(xTrain,yTrain)\nprint(cv.alpha_)\n\nridgetuned = Ridge(alpha=cv.alpha_).fit(xTrain,yTrain)\nR2CVtuned = cross_val_score(ridgetuned,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CVtuned)\n# 0.15\nerrorCVtuned = -cross_val_score(ridgetuned,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCVtuned))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LASSO MODELS & ERROR & TUNING & PREDICT"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"lasso = Lasso().fit(xTrain,yTrain)\npredict = lasso.predict(xTest)\n\nR2CV = cross_val_score(lasso,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CV)\nerrorCV = -cross_val_score(lasso,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCV))\n\ncv = LassoCV(alphas=None,max_iter=100000,normalize=True).fit(xTrain,yTrain)\nprint(cv.alpha_)\n\nlassotuned = Lasso(alpha=cv.alpha_,normalize=True).fit(xTrain,yTrain)\n\nR2CVtuned = cross_val_score(lassotuned,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CVtuned)\n# 0.14\nerrorCVtuned = -cross_val_score(lassotuned,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCVtuned))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ENET MODELS & ERROR & TUNING & PREDICT"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"elastic = ElasticNet().fit(xTrain,yTrain)\npredict = elastic.predict(xTest)\n\nR2CV = cross_val_score(elastic,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CV)\nerrorCV = -cross_val_score(elastic,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCV))\n\ncv = ElasticNetCV(alphas=None,random_state=0).fit(xTrain,yTrain)\nprint(cv.alpha_)\n\nelastictuned = ElasticNet(alpha=cv.alpha_).fit(xTrain,yTrain)\n\nR2CVtuned = cross_val_score(elastictuned,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CVtuned)\n# 0.15\nerrorCVtuned = -cross_val_score(elastictuned,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCVtuned))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# KNN MODELS & ERROR & TUNING & PREDICT"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"knn = KNeighborsRegressor().fit(xTrain,yTrain)\npredict = knn.predict(xTest)\n\nR2CV = cross_val_score(knn,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CV)\nerrorCV = -cross_val_score(knn,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCV))\n\nneighbor = {\"n_neighbors\":np.arange(1,10)}\n\ncv = GridSearchCV(knn,neighbor,cv=10,verbose=False,n_jobs=-1).fit(xTrain,yTrain)\nprint(cv.best_params_)\n# 7\n\nknntuned = KNeighborsRegressor(n_neighbors=7).fit(xTrain,yTrain)\n\nR2CVtuned = cross_val_score(knntuned,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CVtuned)\n# -0.15\nerrorCVtuned = -cross_val_score(knntuned,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCVtuned))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ARTIFICIAL NEURAL NETWORKS MODELS & ERROR & TUNING & PREDICT"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"scaler = StandardScaler().fit(xTrain,yTrain)\nxRTrain = scaler.transform(xTrain)\n\nmlp = MLPRegressor().fit(xRTrain,yTrain)\npredict = mlp.predict(xTest)\n\nR2CV = cross_val_score(mlp,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CV)\nerrorCV = -cross_val_score(mlp,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCV))\n\nparams = {\"alpha\":[0.0001,0.001,0.01,0.1,0.2],\n         \"hidden_layer_sizes\": [(20,20),(100,200,150),(300,200,250)],\n         \"activation\": [\"relu\",\"logistic\"]}\n\n# cv = GridSearchCV(mlp,params,cv=10,verbose=False,n_jobs=-1).fit(xRTrain,yTrain)\n# print(cv.best_params_)\n# {'activation': 'relu', 'alpha': 0.2, 'hidden_layer_sizes': (300, 200, 250)}\n\nmlptuned = MLPRegressor(activation=\"relu\",alpha=0.2,hidden_layer_sizes=(300,200,250))\n\nR2CVtuned = cross_val_score(mlptuned,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CVtuned)\n# -83\nerrorCVtuned = -cross_val_score(mlptuned,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCVtuned))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# REGRESSION TREES(CART) MODELS & ERROR & TUNING & PREDICT"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"cart = DecisionTreeRegressor().fit(xTrain,yTrain)\npredict = cart.predict(xTest)\n\nR2CV = cross_val_score(cart,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CV)\nerrorCV = -cross_val_score(cart,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCV))\n\nparams = {\"min_samples_split\":range(2,100),\n         \"max_leaf_nodes\":range(2,10)}\n\n\n# cv = GridSearchCV(cart,params,cv=10,verbose=False,n_jobs=-1).fit(xTrain,yTrain)\n# print(cv.best_params_)\n# {'max_leaf_nodes': 2, 'min_samples_split': 2}\n\ncarttuned = DecisionTreeRegressor(max_leaf_nodes=2,min_samples_split=2).fit(xTrain,yTrain)\n\nR2CVtuned = cross_val_score(carttuned,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CVtuned)\n# 0.19\nerrorCVtuned = -cross_val_score(carttuned,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCVtuned))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# BAGGING MODELS & ERROR & TUNING & PREDICT"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"bagg = BaggingRegressor(random_state=42,bootstrap_features=True).fit(xTrain,yTrain)\npredict = bagg.predict(xTest)\n\nR2CV = cross_val_score(bagg,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CV)\n# 0.14\nerrorCV = -cross_val_score(bagg,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCV))\n\nestimators = {\"n_estimators\": range(2,30)}\n\n# cv = GridSearchCV(bagg,estimators,cv=10,verbose=False,n_jobs=-1).fit(xTrain,yTrain)\n# print(cv.best_params_)\n# {'n_estimators': 9}\n\nbaggtuned = BaggingRegressor(bootstrap_features=True,random_state=42, n_estimators=9).fit(xTrain,yTrain)\n\nR2CVtuned = cross_val_score(baggtuned,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CVtuned)\n# 0.10\nerrorCVtuned = -cross_val_score(baggtuned,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCVtuned))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RANDOM FORESTS (RF) MODELS & ERROR & TUNING & PREDICT"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"rf = RandomForestRegressor().fit(xTrain,yTrain)\npredict = rf.predict(xTest)\n\nR2CV = cross_val_score(rf,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CV)\n# 0.15\nerrorCV = -cross_val_score(rf,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCV))\n\nparams = {\"max_depth\":range(1,20),\n         \"max_features\":[3,5,10,15, 20],\n         \"n_estimators\": [200,300,500,1000,2000]}\n\n# cv = GridSearchCV(rf,params,cv=10,verbose=False,n_jobs=-1).fit(xTrain,yTrain)\n# print(cv.best_params_)\n# {'max_depth': 14, 'max_features': 3, 'n_estimators': 300}\n\nfrtuned = RandomForestRegressor(max_depth=14,max_features=3,n_estimators=300).fit(xTrain,yTrain)\n\nR2CVtuned = cross_val_score(frtuned,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CVtuned)\n# 0.20\nerrorCVtuned = -cross_val_score(frtuned,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCVtuned))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# GRADIENT BOOSTING MACHINES (GBM) MODELS & ERROR & TUNING & PREDICT"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"gbm = GradientBoostingRegressor().fit(xTrain,yTrain)\npredict = gbm.predict(xTest)\n\nR2CV = cross_val_score(gbm,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CV)\n# 0.05\nerrorCV = -cross_val_score(gbm,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCV))\n\nparams = {\"learning_rate\": [0.001, 0.01, 0.1, 0.2],\n          \"max_depth\": [3, 5, 8, 10],\n          \"n_estimators\": [200, 300, 500, 1000, 2000],\n          \"subsample\": [1, 0.5, 0.75]}\n\n# cv = GridSearchCV(gbm,params,cv=10,verbose=False,n_jobs=-1).fit(xTrain,yTrain)\n# print(cv.best_params_)\n# {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.5}\n\ngbmtuned = GradientBoostingRegressor(learning_rate=0.01,max_depth=3,\n                                     n_estimators=200,subsample=0.5).fit(xTrain,yTrain)\n\nR2CVtuned = cross_val_score(gbmtuned,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CVtuned)\n# 0.23\nerrorCVtuned = -cross_val_score(gbmtuned,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCVtuned))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EXTREME GRADIENT BOOSTING (XGBOOST) MODELS & ERROR & TUNING & PREDICT"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"xgb = XGBRegressor().fit(xTrain,yTrain)\npredict = xgb.predict(xTest)\n\nR2CV = cross_val_score(xgb,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CV)\n# 0.15\nerrorCV = -cross_val_score(xgb,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCV))\n\nparams = {\"colsample_bytree\": [0.4, 0.5, 0.6, 0.9, 1],\n          \"n_estimators\": [100, 200, 500, 1000],\n          \"max_depth\": [2, 3, 4, 5, 6],\n          \"learning_rate\": [0.1, 0.01, 0.5]}\n\n# cv = GridSearchCV(xgb,params,cv=10,verbose=False,n_jobs=-1).fit(xTrain,yTrain)\n# print(cv.best_params_)\n# {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100, 'colsample_bytree': 0.9}\n\nxgbtuned = XGBRegressor(colsample_bytree=0.9,\n                        n_estimators=100, learning_rate=0.1, max_depth=2).fit(xTrain, yTrain)\n\nR2CVtuned = cross_val_score(xgbtuned,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CVtuned)\n# 0.14\nerrorCVtuned = -cross_val_score(xgbtuned,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCVtuned))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LIGHT GRADIENT BOOSTING (lIGHT GBM) MODELS & ERROR & TUNING & PREDICT"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"lgbm = LGBMRegressor().fit(xTrain,yTrain)\npredict = lgbm.predict(xTest)\n\nR2CV = cross_val_score(lgbm,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CV)\n# 0.16\nerrorCV = -cross_val_score(lgbm,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCV))\n\nparams = {\n    \"n_estimators\": [100, 200, 500, 1000],\n    \"max_depth\": [2, 3, 4, 5, 6],\n    \"learning_rate\": [0.1, 0.01, 0.5]\n}\n\n\n# cv = GridSearchCV(lgbm,params,cv=10,verbose=False,n_jobs=-1).fit(xTrain,yTrain)\n# print(cv.best_params_)\n# {'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 200}\n\nlgbmtuned = LGBMRegressor(learning_rate=0.01,max_depth=2,n_estimators=200).fit(xTrain,yTrain)\n\nR2CVtuned = cross_val_score(lgbmtuned,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CVtuned)\n# 0.19\nerrorCVtuned = -cross_val_score(lgbmtuned,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCVtuned))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CATEGORY BOOSTING (CATBOOST) MODELS & ERROR & TUNING & PREDICT"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"catb = CatBoostRegressor(verbose=False).fit(xTrain,yTrain)\npredict = catb.predict(xTest)\n\nR2CV = cross_val_score(catb,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CV)\n# 0.06\nerrorCV = -cross_val_score(catb,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCV))\n\nparams = {\"depth\": [2,3,4,5,6,7],\n         \"learning_rate\": [0.1,0.01,0.001,0.5]}\n\n# cv = GridSearchCV(catb,params,cv=10,verbose=False,n_jobs=-1).fit(xTrain,yTrain)\n# print(cv.best_params_)\n# {'depth': 4, 'learning_rate': 0.01}\n\ncatbtuned = CatBoostRegressor(verbose=False,depth=4,learning_rate=0.01).fit(xTrain,yTrain)\n\nR2CVtuned = cross_val_score(catbtuned,xTest,yTest,cv=10,scoring=\"r2\").mean()\nprint(R2CVtuned)\n# 0.20\nerrorCVtuned = -cross_val_score(catbtuned,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\").mean()\nprint(np.sqrt(errorCVtuned))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# COMPARISON REGRESSOR"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"models = [lm,pls,ridgetuned,elastictuned,knntuned,mlp,\n          carttuned,bagg,frtuned,gbmtuned,xgb,lgbmtuned,catbtuned]\n\n\nfor model in models:\n    name = model.__class__.__name__\n    predict = model.predict(xTest)\n    accuracy = r2_score(yTest, predict)\n    print(\"-\" * 28)\n    print(name + \": \")\n    print(f\"Accuracy: {accuracy}\")\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# REGRESSOR MODELS FOR TRAIN"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [lm,pls,ridgetuned,elastictuned,knntuned,mlp,\n          carttuned,bagg,frtuned,gbmtuned,xgb,lgbmtuned,catbtuned]\n\nfor model in models:\n    name = model.__class__.__name__\n    predict = model.predict(xTrain)\n    accuracy = r2_score(yTrain, predict)\n    print(\"-\" * 28)\n    print(name + \": \")\n    print(f\"Accuracy: {accuracy}\")\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LOGISTIC REGRESSION MODELS & ERROR & TUNING & PREDICT"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"lj = LogisticRegression(solver=\"liblinear\").fit(xTrain,yTrain)\npredict = lj.predict(xTest)\n\nprint(accuracy_score(yTest,predict))\nR2CV = cross_val_score(lj,xTest,yTest,cv=10).mean()\nprint(R2CV)\n# 0.82\nerror = mean_squared_error(yTest,predict)\nprint(np.sqrt(error))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# GAUSSIAN NAIVE BAYES MODELS & ERROR & TUNING & PREDICT"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"gnb = GaussianNB().fit(xTrain,yTrain)\npredict = gnb.predict(xTest)\n\nprint(accuracy_score(yTest,predict))\nR2CV = cross_val_score(gnb,xTest,yTest,cv=10).mean()\nprint(R2CV)\n# 0.82\nerror = mean_squared_error(yTest,predict)\nprint(np.sqrt(error))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# KNN MODELS & ERROR & TUNING & PREDICT"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"kn = KNeighborsClassifier().fit(xTrain,yTrain)\npredict = kn.predict(xTest)\n\nprint(accuracy_score(yTest,predict))\nR2CV = cross_val_score(kn,xTest,yTest,cv=10).mean()\nprint(R2CV)\n# 0.43\nerror = mean_squared_error(yTest,predict)\nprint(np.sqrt(error))\n\nparams = {\"n_neighbors\": np.arange(1,50)}\n\n# cv = GridSearchCV(kn,params,cv=10).fit(xTrain,yTrain)\n# print(cv.best_params_)\n# print(cv.best_score_)\n# 'n_neighbors': 1\n\nkntuned = KNeighborsClassifier(n_neighbors=1).fit(xTrain,yTrain)\npredicttuned = kntuned.predict(xTest)\n\nprint(accuracy_score(yTest,predicttuned))\nR2CVtuned = cross_val_score(kntuned,xTest,yTest,cv=10).mean()\nprint(R2CVtuned)\n# 0.65\nerrortuned = mean_squared_error(yTest,predicttuned)\nprint(np.sqrt(errortuned))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# NEURAL NETWORKS CLASSIFIER MODELS & ERROR & TUNING & PREDICT"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"scaler = StandardScaler().fit(xTrain, yTrain)\nxRTrain = scaler.transform(xTrain)\nxRTest = scaler.transform(xTest)\n\nmlpc = MLPClassifier().fit(xRTrain,yTrain)\npredict = mlpc.predict(xRTest)\n\nprint(accuracy_score(yTest,predict))\nR2CV = cross_val_score(mlpc,xRTest,yTest,cv=10).mean()\nprint(R2CV)\n# 0.79\nerror = mean_squared_error(yTest,predict)\nprint(np.sqrt(error))\n\nparams = {\"alpha\": [0.01,0.02,0.005,0.001,0.0001],\n         \"hidden_layer_sizes\": [(3,5),(5,3),(10,10,10),(100,200,150),(100,100,100)],\n         \"solver\": [\"lbfgs\",\"adam\",\"sgd\"],\n         \"activation\": [\"relu\",\"logistic\"]}\n\n# cv = GridSearchCV(mlpc,params,cv=10,verbose=False,n_jobs=-1).fit(xRTrain,yTrain)\n# print(cv.best_params_)\n\nmlpctuned = MLPClassifier(alpha=0.1,solver=\"adam\",\n                          activation=\"relu\",hidden_layer_sizes=(100,100,100)).fit(xRTrain,yTrain)\n\npredicttuned = mlpctuned.predict(xRTest)\n\nprint(accuracy_score(yTest,predicttuned))\nR2CVtuned = cross_val_score(mlpctuned,xRTest,yTest,cv=10).mean()\nprint(R2CVtuned)\n# 0.72\nerrortuned = mean_squared_error(yTest,predicttuned)\nprint(np.sqrt(errortuned))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# REGRESSION CLASSIFIER TREES(CART) MODELS & ERROR & TUNING & PREDICT"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"cartc = DecisionTreeClassifier().fit(xTrain,yTrain)\npredict = cartc.predict(xTest)\n\nprint(accuracy_score(yTest,predict))\nR2CV = cross_val_score(cartc,xTest,yTest,cv=10).mean()\nprint(R2CV)\n# 0.74\nerror = mean_squared_error(yTest,predict)\nprint(np.sqrt(error))\n\nparams = {\"max_depth\":range(1,20),\n         \"min_samples_split\":range(2,50)}\n\n# cv = GridSearchCV(cartc,params,cv=10,verbose=False,n_jobs=-1).fit(xTrain,yTrain)\n# print(cv.best_params_)\n# {'max_depth': 1, 'min_samples_split': 2}\n\ncartctuned = DecisionTreeClassifier(max_depth=1,min_samples_split=2).fit(xTrain,yTrain)\npredicttuned = cartctuned.predict(xTest)\nprint(accuracy_score(yTest,predicttuned))\nR2CVtuned = cross_val_score(cartctuned,xTest,yTest,cv=10).mean()\nprint(R2CVtuned)\n# 0.83\nerrortuned = mean_squared_error(yTest,predicttuned)\nprint(np.sqrt(errortuned))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RANDOM FOREST CLASSIFIER (RF) MODELS & ERROR & TUNING & PREDICT"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"rfc = RandomForestClassifier(random_state=42).fit(xTrain,yTrain)\npredict = rfc.predict(xTest)\n\nprint(accuracy_score(yTest,predict))\nR2CV = cross_val_score(rfc,xTest,yTest,cv=10).mean()\nprint(R2CV)\n# 0.81\nerror = mean_squared_error(yTest,predict)\nprint(np.sqrt(error))\n\nparams = {\"max_depth\": [2, 5, 8, 10],\n          \"max_features\": [2, 5, 8],\n          \"n_estimators\": [10, 500, 1000],\n          \"min_samples_split\": [2, 5, 10]}\n\n# cv = GridSearchCV(rfc,params,cv=10,verbose=False,n_jobs=-1).fit(xTrain,yTrain)\n# print(cv.best_params_)\n\nrfctuned = RandomForestClassifier(max_depth=10, max_features=8,\n                                      min_samples_split=10, n_estimators=1000).fit(xTrain, yTrain)\n\npredicttuned = rfctuned.predict(xTest)\nprint(accuracy_score(yTest,predicttuned))\nR2CVtuned = cross_val_score(rfctuned,xTest,yTest,cv=10).mean()\nprint(R2CVtuned)\n# 0.83\nerrortuned = mean_squared_error(yTest,predicttuned)\nprint(np.sqrt(errortuned))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# GBM CLASSIFIER MODELS & ERROR & TUNING & PREDICT"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"gbmc = GradientBoostingClassifier().fit(xTrain,yTrain)\npredict = gbmc.predict(xTest)\n\nprint(accuracy_score(yTest,predict))\nR2CV = cross_val_score(gbmc,xTest,yTest,cv=10).mean()\nprint(R2CV)\n# 0.82\nerror = mean_squared_error(yTest,predict)\nprint(np.sqrt(error))\n\nparams = {\"learning_rate\": [0.001,0.01,0.1,0.05],\n         \"max_depth\": [3,5,10],\n         \"n_estimators\": [100,300,500,1000],\n         \"min_samples_split\":[2,5,10]}\n\n# cv = GridSearchCV(gbmc,params,cv=10,verbose=False,n_jobs=-1).fit(xTrain,yTrain)\n# print(cv.best_params_)\n\ngbmctuned = GradientBoostingClassifier(learning_rate=0.1, max_depth=3,\n                                           min_samples_split=10, n_estimators=1000).fit(xTrain, yTrain)\n\npredicttuned = gbmctuned.predict(xTest)\nprint(accuracy_score(yTest,predicttuned))\nR2CVtuned = cross_val_score(gbmctuned,xTest,yTest,cv=10).mean()\nprint(R2CVtuned)\n# 0.81\nerrortuned = mean_squared_error(yTest,predicttuned)\nprint(np.sqrt(errortuned))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGBOOST CLASSIFIER MODELS & ERROR & TUNING & PREDICT"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"xgbc = XGBClassifier(verbose=False).fit(xTrain,yTrain)\npredict = xgbc.predict(xTest)\n\nprint(accuracy_score(yTest,predict))\nR2CV = cross_val_score(xgbc,xTest,yTest,cv=10).mean()\nprint(R2CV)\n# 0.84\nerror = mean_squared_error(yTest,predict)\nprint(np.sqrt(error))\n\nparams = {\"n_estimators\": [100, 500, 1000, 2000],\n          \"subsample\": [0.6, 0.8, 1.0],\n          \"max_depth\": [3, 4, 5, 6],\n          \"learning_rate\": [0.1, 0.01, 0.02, 0.05],\n          \"min_samples_split\": [2, 5, 10]}\n\n# cv = GridSearchCV(xgbc,params,cv=10,verbose=False,n_jobs=-1).fit(xTrain,yTrain)\n# print(cv.best_params_)\n\nxgbctuned = XGBClassifier(learning_rate=0.01, max_depth=6, min_samples_split=2,\n                              n_estimators=100, subsample=0.8).fit(xTrain, yTrain)\n\npredicttuned = xgbctuned.predict(xTest)\nprint(accuracy_score(yTest,predicttuned))\nR2CVtuned = cross_val_score(xgbctuned,xTest,yTest,cv=10).mean()\nprint(R2CVtuned)\n# 0.82\nerrortuned = mean_squared_error(yTest,predicttuned)\nprint(np.sqrt(errortuned))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LIGHTGBM CLASSIFIER MODELS & ERROR & TUNING & PREDICT"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"lgbmc = LGBMClassifier().fit(xTrain,yTrain)\npredict = lgbmc.predict(xTest)\n\nprint(accuracy_score(yTest,predict))\nR2CV = cross_val_score(lgbmc,xTest,yTest,cv=10).mean()\nprint(R2CV)\n# 0.77\nerror = mean_squared_error(yTest,predict)\nprint(np.sqrt(error))\n\nparams = {\"n_estimators\": [100, 500, 1000, 2000],\n          \"subsample\": [0.6, 0.8, 1.0],\n          \"max-depth\": [3, 4, 5, 6],\n          \"learning_rate\": [0.1, 0.01, 0.02, 0.05],\n          \"min_child_samples\": [5, 10, 20]}\n\n# cv = GridSearchCV(lgbmc,params,cv=10,verbose=False,n_jobs=-1).fit(xTrain,yTrain)\n# print(cv.best_params_)\n\nlgbmctuned = LGBMClassifier(learning_rate=0.01, max_depth=3, min_child_samples=20,\n                           n_estimators=500, subsample=0.5).fit(xTrain, yTrain)\n\npredicttuned = lgbmctuned.predict(xTest)\nprint(accuracy_score(yTest,predicttuned))\nR2CVtuned = cross_val_score(lgbmctuned,xTest,yTest,cv=10).mean()\nprint(R2CVtuned)\n# 0.81\nerrortuned = mean_squared_error(yTest,predicttuned)\nprint(np.sqrt(errortuned))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CATBOOST CLASSIFIER MODELS & ERROR & TUNING & PREDICT"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"catbc = CatBoostClassifier(verbose=False).fit(xTrain,yTrain)\npredict = catbc.predict(xTest)\n\nprint(accuracy_score(yTest,predict))\nR2CV = cross_val_score(catbc,xTest,yTest,cv=10).mean()\nprint(R2CV)\n# 0.80\nerror = mean_squared_error(yTest,predict)\nprint(np.sqrt(error))\n\nparams = {\"iterations\": [200, 500],\n          \"learning_rate\": [0.01, 0.05, 0.1],\n          \"depth\": [3, 5, 8]}\n\n# cv = GridSearchCV(catbc,params,cv=10,verbose=False,n_jobs=-1).fit(xTrain,yTrain)\n# rint(cv.best_params_)\n\ncatbctuned = CatBoostClassifier(depth=5, iterations=200, learning_rate=0.05,verbose=False).fit(xTrain, yTrain)\npredicttuned = catbctuned.predict(xTest)\nprint(accuracy_score(yTest,predicttuned))\nR2CVtuned = cross_val_score(catbctuned,xTest,yTest,cv=10).mean()\nprint(R2CVtuned)\n# 0.83\nerrortuned = mean_squared_error(yTest,predicttuned)\nprint(np.sqrt(errortuned))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# COMPARISON CLASSIFIERS"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [lj,gnb,kntuned,mlpc,cartctuned,rfctuned,gbmc,xgbc,lgbmctuned,catbctuned]\nr = pd.DataFrame(columns=[\"MODELS\",\"ACC\"])\n\nfor model in models:\n    name = model.__class__.__name__\n    predict = model.predict(xTest)\n    accuracy = accuracy_score(yTest, predict)\n    print(\"-\" * 28)\n    print(name + \": \")\n    print(f\"Accuracy: {accuracy}\")\n    result = pd.DataFrame([[name,accuracy*100]],columns=[\"MODELS\",\"ACC\"])\n    r = r.append(result)\n    \nsns.barplot(x=\"ACC\",y=\"MODELS\",data=r,color=\"r\")\nplt.xlabel(\"ACC\")\nplt.title(\"MODEL ACCURACY COMPARISON\")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}