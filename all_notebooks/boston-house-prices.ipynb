{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"d803f997-f3dc-df7b-c686-d73bdb14ec06"},"source":"Copy of a tutorial on ML using the boston housing prices dataset. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"15383d22-5aae-f765-b623-a77393539a7f"},"outputs":[],"source":"from sys import version as py_version\nfrom scipy import __version__ as sp_version\nfrom numpy import __version__ as np_version\nfrom pandas import __version__ as pd_version\nfrom matplotlib import __version__ as mplib_version\nfrom sklearn import __version__ as skl_version\n\nprint('python: {}'.format(py_version))\nprint('scipy: {}'.format(sp_version))\nprint('numpy: {}'.format(np_version))\nprint('pandas: {}'.format(pd_version))\nprint('matplotlib: {}'.format(mplib_version))\nprint('sklearn: {}'.format(skl_version))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"05fd849a-577b-8856-87db-e8eeee71d4b4"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot\nfrom pandas.tools.plotting import scatter_matrix\nfrom sklearn.datasets import load_boston\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\nfrom sklearn.linear_model import LinearRegression, Lasso, ElasticNet\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, AdaBoostRegressor\nfrom sklearn.metrics import mean_squared_error"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"765ea7f3-a37f-54e8-e020-ebbd43138039"},"outputs":[],"source":"# Load dataset\n#filename = 'https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data'\nnames = ['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT','MEDV']\n#dataset = pd.read_csv(filename, delim_whitespace=True, names=names)\nboston = load_boston()\ndataset = pd.DataFrame(data=np.c_[boston['data'], boston['target']], columns=names )"},{"cell_type":"markdown","metadata":{"_cell_guid":"5ae58fb9-58f4-32d2-682d-642f89eb8c4b"},"source":"# Analyze Data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9a90340b-6339-0481-31c6-5fd60aed7920"},"outputs":[],"source":"# shape\ndataset.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4aa4f2a2-c8bd-dbd6-6d69-adb6ffa04ef5"},"outputs":[],"source":"# types\ndataset.dtypes"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8321eb08-ff35-8ab6-9cdc-95c46fc97a4b"},"outputs":[],"source":"# peek at data\ndataset.head(20)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"323558c0-132d-4f7c-c277-0aca5cf0b80d"},"outputs":[],"source":"# descriptions\npd.set_option('precision', 1)\ndataset.describe()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a4cfe8d5-a6d3-0882-1239-9c2a5a0ea1d7"},"outputs":[],"source":"# correlation\npd.set_option('precision',2)\ndataset.corr(method='pearson')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0fab2a66-fb10-c01f-2062-db6879cba023"},"outputs":[],"source":"# histograms\ndataset.hist(sharex=False, sharey=False, xlabelsize=1, ylabelsize=1, figsize=(12,6))\npyplot.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dd874285-69d6-33de-f505-7d361be4e1aa"},"outputs":[],"source":"# density\ndataset.plot(kind='density', subplots=True, layout=(4,4), sharex=False, legend=False, fontsize=1, figsize=(12,6))\npyplot.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a7c700aa-8972-3d7b-8b35-da6ec211c7dc"},"outputs":[],"source":"# box and whisker\ndataset.plot(kind='box', subplots=True, layout=(4,4), sharex=False, sharey=False, fontsize=8, figsize=(12,10))\npyplot.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0bf54284-b82d-3676-ebfe-4a38b485ee5b"},"outputs":[],"source":"# scatter plot matrix\nscatter_matrix(dataset, figsize=(12,12))\npyplot.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bef4ff52-8005-8006-e4c3-76eb20e70ee3"},"outputs":[],"source":"# correlation matrix\nfig = pyplot.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(dataset.corr(), vmin=-1, vmax=1, interpolation='none')\nfig.colorbar(cax)\nticks = np.arange(0,14,1)\nax.set_xticks(ticks)\nax.set_yticks(ticks)\nax.set_xticklabels(names)\nax.set_yticklabels(names)\nfig.set_size_inches(10,10)\npyplot.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"a391b1c6-2fae-9cda-e971-1902628b8470"},"source":"Evaluate algorithms\n==============="},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5b0bb7c4-1413-0faf-c932-603dfbe1885f"},"outputs":[],"source":"# validation dataset\narray = dataset.values\nX = array[:,0:-1]\nY = array[:,-1]\nvalidation_size = 0.2\nseed = 7\nX_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size, random_state=seed)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c7085a6c-6111-7077-c8b5-70b95cace29f"},"outputs":[],"source":"# test options and evaluation metric\nnum_folds = 10\nseed = 7\nscoring = 'neg_mean_squared_error' # 0 is best"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"061520ff-ad41-1902-3f13-5e84d20dea43"},"outputs":[],"source":"# spot check algorithms\nmodels = []\n# Linear algorithms\nmodels.append(('LR', LinearRegression()))\nmodels.append(('LASSO', Lasso()))\nmodels.append(('EN', ElasticNet()))\n# Nonlinear algorithms\nmodels.append(('KNN', KNeighborsRegressor()))\nmodels.append(('CART', DecisionTreeRegressor()))\nmodels.append(('SVR', SVR()))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"43630c60-6957-da71-4431-a94c9cde003b"},"outputs":[],"source":"# evaluate each model \nresults = []\nnames = []\nfor name, model in models:\n    kfold = KFold(n_splits=num_folds, random_state=seed)\n    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7af08ca1-15d7-7052-7233-73a306e8614b"},"outputs":[],"source":"# compare algorithms\nfig = pyplot.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\npyplot.boxplot(results)\nax.set_xticklabels(names)\nfig.set_size_inches(8,6)\npyplot.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"68d6c858-e470-6dad-73a1-0a2f0cf4f4ba"},"source":"Differing units might be hurting some of the algorithms especially KNN and SVR. Try some standardization."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1d8511ec-81bb-22fa-7baf-93fcfd3b0a16"},"outputs":[],"source":"# standardized the dataset\npipelines = []\npipelines.append(('ScaledLR', Pipeline([('Scaler', StandardScaler()), ('LR', LinearRegression())])))\npipelines.append(('ScaledLASSO', Pipeline([('Scaler', StandardScaler()), ('LASSO', Lasso())])))\npipelines.append(('ScaledEN', Pipeline([('Scaler', StandardScaler()), ('EN', ElasticNet())])))\npipelines.append(('ScaledKNN', Pipeline([('Scaler', StandardScaler()), ('KNN', KNeighborsRegressor())])))\npipelines.append(('ScaledCART', Pipeline([('Scaler', StandardScaler()), ('CART', DecisionTreeRegressor())])))\npipelines.append(('ScaledSVR', Pipeline([('Scaler', StandardScaler()), ('SVR', SVR())])))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"918c3fda-0154-8a0f-a520-5dab7fa933d2"},"outputs":[],"source":"results = []\nnames = []\nfor name, model in pipelines:\n    kfold = KFold(n_splits=num_folds, random_state=seed)\n    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f01748d1-abd8-fcb2-e003-51e2dc42dfad"},"outputs":[],"source":"# compare scaled algorithms\nfig = pyplot.figure()\nfig.suptitle('Scaled Algorithm Comparison')\nax = fig.add_subplot(111)\npyplot.boxplot(results)\nax.set_xticklabels(names)\nfig.set_size_inches(8,6)\npyplot.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"67f509ff-9b5e-d9a8-7e7c-20ff1df69651"},"source":"Now KNN is looking best with highest mean and tight distribution. Can we improve it?"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ba24f9ff-a7e3-efb8-c8b4-edffcf7c4ad0"},"outputs":[],"source":"# KNN algorithm tuning\nscaler = StandardScaler().fit(X_train)\nrescaledX = scaler.transform(X_train)\nk_values = np.array([1,3,5,7,9,11,13,15,17,19,21])\nparam_grid = dict(n_neighbors=k_values)\nmodel = KNeighborsRegressor()\nkfold = KFold(n_splits=num_folds, random_state=seed)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\ngrid_result = grid.fit(rescaledX, Y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fb96e530-d74f-b286-42c7-84d9408c105e"},"outputs":[],"source":"print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nranks = grid_result.cv_results_['rank_test_score']\nfor mean, stdev, param, rank in zip(means, stds, params, ranks):\n    print(\"#%d %f (%f) with: %r\" % (rank, mean, stdev, param))"},{"cell_type":"markdown","metadata":{"_cell_guid":"6df0f790-f495-dca2-f178-e07c0ccafd26"},"source":"KNN mean squared error went from 20.1 (using default of 5 neighbors) to 18.17 with 3 neighbors.\n\nTry some ensemble techniques to see if we can improve more."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aaa22cdc-4822-afed-4f01-920d4c4e2c18"},"outputs":[],"source":"# ensembles\nensembles = []\n# Boosting methods\nensembles.append(('ScaledAB', Pipeline([('Scalar', StandardScaler()), ('AB', AdaBoostRegressor())])))\nensembles.append(('ScaledGBM', Pipeline([('Scalar', StandardScaler()), ('GBM', GradientBoostingRegressor())])))\n# Bagging methods\nensembles.append(('ScaledRF', Pipeline([('Scalar', StandardScaler()), ('RF', RandomForestRegressor())])))\nensembles.append(('ScaledET', Pipeline([('Scalar', StandardScaler()), ('ET', ExtraTreesRegressor())])))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"20cca379-c64e-97c5-bdb9-7f8464a6c5fe"},"outputs":[],"source":"results = []\nnames = []\nfor name, model in ensembles:\n    kfold = KFold(n_splits=num_folds, random_state=seed)\n    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c390e906-3c67-5b13-6c00-72e4e3befed4"},"outputs":[],"source":"# compare ensemble algorithms\nfig = pyplot.figure()\nfig.suptitle('Scaled Ensemble Algorithm Comparison')\nax = fig.add_subplot(111)\npyplot.boxplot(results)\nax.set_xticklabels(names)\nfig.set_size_inches(8,6)\npyplot.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"812adbab-06ce-5c61-b9e3-8203a85d515b"},"source":"Both Gradient Boost and Random Forest look pretty good. See if we can tune GB given it has best overall mean score."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"10aa587c-8dd2-49a1-c007-35edc05d047d"},"outputs":[],"source":"# tune scaled GBM\nscaler = StandardScaler().fit(X_train)\nrescaledX = scaler.transform(X_train)\nparam_grid = {'n_estimators': np.array([50, 100, 150, 200, 250, 300, 350, 400])}\nmodel = GradientBoostingRegressor(random_state=seed)\nkfold = KFold(n_splits=num_folds, random_state=seed)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\ngrid_result = grid.fit(rescaledX, Y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"abc718cc-f7a9-2e9a-4f3d-921d769cf05d"},"outputs":[],"source":"print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nranks = grid_result.cv_results_['rank_test_score']\nfor mean, stdev, param, rank in zip(means, stds, params, ranks):\n    print(\"#%d %f (%f) with: %r\" % (rank, mean, stdev, param))"},{"cell_type":"markdown","metadata":{"_cell_guid":"933dd012-a5a2-5f76-3f13-c598b8e236f2"},"source":"# Finalize Model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a8f733d4-85da-f4d9-2da9-09fdb51fc750"},"outputs":[],"source":"# prepare the model\nscaler = StandardScaler().fit(X_train)\nrescaledX = scaler.transform(X_train)\nmodel = GradientBoostingRegressor(random_state=seed, n_estimators=250)\nmodel.fit(rescaledX, Y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5a16e95c-df53-ffdb-731f-1fe8a270e65b"},"outputs":[],"source":"# apply to our validation set to double check against over-fitting\nrescaledValidationX = scaler.transform(X_validation)\npredictions = model.predict(rescaledValidationX)\nmean_squared_error(Y_validation, predictions)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}