{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Task for Today  \n\n***\n\n## Soft Drink Sales Prediction  \n  \nGiven *data about soft drinks*, let's try to predict the **quantity sold** of a given drink.  \n  \nWe will use a variety of regression models to make our predictions."},{"metadata":{},"cell_type":"markdown","source":"# Getting Started"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.svm import LinearSVR, SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n\nimport warnings\nwarnings.filterwarnings(action='ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/predict-demand/train.csv')\ntest_df = pd.read_csv('../input/predict-demand/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def onehot_encode(df, column):\n    df = df.copy()\n    dummies = pd.get_dummies(df[column], prefix=column)\n    df = pd.concat([df, dummies], axis=1)\n    df = df.drop(column, axis=1)\n    return df\n\ndef encode_dates(df, column):\n    df = df.copy()\n    df[column] = pd.to_datetime(df[column])\n    df[column + '_year'] = df[column].apply(lambda x: x.year)\n    df[column + '_month'] = df[column].apply(lambda x: x.month)\n    df[column + '_day'] = df[column].apply(lambda x: x.day)\n    df = df.drop(column, axis=1)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop id column\n    df = df.drop('id', axis=1)\n    \n    # Remove missing rows\n    missing_rows = df.loc[df.isna().all(axis=1), :].index\n    df = df.drop(missing_rows, axis=0).reset_index(drop=True)\n    \n    # Fill numeric missing values with mean\n    for column in ['lat', 'long']:\n        df[column] = df[column].fillna(df[column].mean())\n    \n    # Fill ordinal missing values with mode\n    df['capacity'] = df['capacity'].fillna(df['capacity'].mode()[0])\n    \n    # One-hot encode nominal features\n    for column in ['city', 'shop', 'brand', 'container']:\n        df = onehot_encode(df, column=column)\n    \n    # Ordinal encode capacity column\n    capacity_ordering = ['330ml', '500ml', '1.5lt']\n    df['capacity'] = df['capacity'].apply(lambda x: capacity_ordering.index(x))\n    \n    # Extract date features\n    df = encode_dates(df, column='date')\n    \n    # Split df into X and y\n    y = df['quantity']\n    X = df.drop('quantity', axis=1)\n    \n    return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, y_train = preprocess_inputs(train_df)\nX_test, y_test = preprocess_inputs(test_df)\n\nscaler = StandardScaler()\nscaler.fit(X_train)\n\nX_train = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)\nX_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = {\n    \"                   K-Nearest Neighbors\": KNeighborsRegressor(),\n    \"                     Linear Regression\": LinearRegression(),\n    \"                 Ridge (L2) Regression\": Ridge(),\n    \"Support Vector Machine (Linear Kernel)\": LinearSVR(),\n    \"   Support Vector Machine (RBF Kernel)\": SVR(),\n    \"                         Decision Tree\": DecisionTreeRegressor(),\n    \"                        Neural Network\": MLPRegressor(),\n    \"                         Random Forest\": RandomForestRegressor(),\n    \"                     Gradient Boosting\": GradientBoostingRegressor()\n}\n\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    print(name + \" trained.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"for name, model in models.items():\n    print(name + \" R^2: {:.5f}\".format(model.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps://youtu.be/E1aJk9Z4usM"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}