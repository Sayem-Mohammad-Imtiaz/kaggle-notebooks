{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns \nfrom sklearn.metrics import r2_score, explained_variance_score\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-15T21:35:53.058102Z","iopub.execute_input":"2021-07-15T21:35:53.058544Z","iopub.status.idle":"2021-07-15T21:35:54.21655Z","shell.execute_reply.started":"2021-07-15T21:35:53.058454Z","shell.execute_reply":"2021-07-15T21:35:54.215601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#                                            **Data exploration**   - - - - - - - - - - - - - Exploración de los datos ","metadata":{}},{"cell_type":"code","source":"dataset = pd.read_csv('../input/predict-test-scores-of-students/test_scores.csv')\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T21:35:54.218239Z","iopub.execute_input":"2021-07-15T21:35:54.218639Z","iopub.status.idle":"2021-07-15T21:35:54.271213Z","shell.execute_reply.started":"2021-07-15T21:35:54.218597Z","shell.execute_reply":"2021-07-15T21:35:54.270272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.drop(['school', 'classroom', 'student_id'], axis = 1, inplace = True)\nsns.pairplot(dataset, hue = \"gender\")\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T21:35:54.273929Z","iopub.execute_input":"2021-07-15T21:35:54.274376Z","iopub.status.idle":"2021-07-15T21:35:58.067309Z","shell.execute_reply.started":"2021-07-15T21:35:54.27433Z","shell.execute_reply":"2021-07-15T21:35:58.066571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dividing the data set between X and Y - - - - - - - - Dividiendo el dataset entre los valores de X y Y","metadata":{}},{"cell_type":"code","source":"x = dataset.iloc[:,0:7].values\ny = dataset.iloc[:, -1].values","metadata":{"execution":{"iopub.status.busy":"2021-07-15T21:35:58.068598Z","iopub.execute_input":"2021-07-15T21:35:58.069077Z","iopub.status.idle":"2021-07-15T21:35:58.074261Z","shell.execute_reply.started":"2021-07-15T21:35:58.06904Z","shell.execute_reply":"2021-07-15T21:35:58.073551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"converting categorical variables to numeric  - - - - - - - - - - - - - Convirtiendo variables categoricas a numericas","metadata":{}},{"cell_type":"code","source":"from sklearn import preprocessing\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nlbl_X = preprocessing.LabelEncoder()\nx[:,0] = lbl_X.fit_transform(x[:,0])\nx[:,1] = lbl_X.fit_transform(x[:,1])\nx[:, 2] = lbl_X.fit_transform(x[:, 2])\nx[:, 4] = lbl_X.fit_transform(x[:, 4])\nx[:,5] = lbl_X.fit_transform(x[:,5])","metadata":{"execution":{"iopub.status.busy":"2021-07-15T21:35:58.075418Z","iopub.execute_input":"2021-07-15T21:35:58.075925Z","iopub.status.idle":"2021-07-15T21:35:58.098182Z","shell.execute_reply.started":"2021-07-15T21:35:58.075882Z","shell.execute_reply":"2021-07-15T21:35:58.097086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ct = ColumnTransformer(\n    [('one_hot_encoder', OneHotEncoder(categories='auto'),[0])],\n                        remainder = 'passthrough')\nx = np.array(ct.fit_transform(x), dtype = float)\n\nx = x[:, 1:]","metadata":{"execution":{"iopub.status.busy":"2021-07-15T21:35:58.099343Z","iopub.execute_input":"2021-07-15T21:35:58.099638Z","iopub.status.idle":"2021-07-15T21:35:58.111748Z","shell.execute_reply.started":"2021-07-15T21:35:58.099609Z","shell.execute_reply":"2021-07-15T21:35:58.110784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dividing between training and testing   - - - - - - Dividiendo el conjunto entre entrenamiento y test","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 5)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T21:35:58.113096Z","iopub.execute_input":"2021-07-15T21:35:58.113374Z","iopub.status.idle":"2021-07-15T21:35:58.133589Z","shell.execute_reply.started":"2021-07-15T21:35:58.113348Z","shell.execute_reply":"2021-07-15T21:35:58.132862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Variable scaling  - - - - - - - - - - - -  Escalado de variables","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc_x = StandardScaler()\nx_train, x_test = sc_x.fit_transform(x_train), sc_x.transform(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T21:35:58.13538Z","iopub.execute_input":"2021-07-15T21:35:58.135824Z","iopub.status.idle":"2021-07-15T21:35:58.14073Z","shell.execute_reply.started":"2021-07-15T21:35:58.135794Z","shell.execute_reply":"2021-07-15T21:35:58.140075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Regression models**   Modelos de Regresion","metadata":{}},{"cell_type":"markdown","source":"**Support Vector Regressor**","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVR\nregressor = SVR(gamma = 0.1).fit(x_train, y_train)\ny_pred = regressor.predict(x_test)\n#r2_score(y_test, y_pred)\nprint (explained_variance_score(y_test, y_pred), y_pred.std())","metadata":{"execution":{"iopub.status.busy":"2021-07-15T21:46:32.4765Z","iopub.execute_input":"2021-07-15T21:46:32.476873Z","iopub.status.idle":"2021-07-15T21:46:32.72522Z","shell.execute_reply.started":"2021-07-15T21:46:32.476843Z","shell.execute_reply":"2021-07-15T21:46:32.724149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**XGBRegressor**","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBRegressor\nregressor2 = XGBRegressor().fit(x_train, y_train)\ny_pred2 = regressor2.predict(x_test)\nprint (explained_variance_score(y_test, y_pred2), y_pred2.std())","metadata":{"execution":{"iopub.status.busy":"2021-07-15T21:35:58.477584Z","iopub.execute_input":"2021-07-15T21:35:58.477878Z","iopub.status.idle":"2021-07-15T21:35:58.705331Z","shell.execute_reply.started":"2021-07-15T21:35:58.477851Z","shell.execute_reply":"2021-07-15T21:35:58.704299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**XGBRFRegressor**","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBRFRegressor\nregressor3 = XGBRFRegressor(n_estimators  = 200, booster = 'gbtree', gamma = 0.1).fit(x_train, y_train)\ny_pred3 = regressor3.predict(x_test)\nprint (explained_variance_score(y_test, y_pred3), y_pred3.std())\n","metadata":{"execution":{"iopub.status.busy":"2021-07-15T21:35:58.706724Z","iopub.execute_input":"2021-07-15T21:35:58.707072Z","iopub.status.idle":"2021-07-15T21:35:58.959906Z","shell.execute_reply.started":"2021-07-15T21:35:58.70704Z","shell.execute_reply":"2021-07-15T21:35:58.958918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Linear Regression**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nregressor4 = LinearRegression().fit(x_train, y_train)\ny_pred4 = regressor4.predict(x_test)\nprint (explained_variance_score(y_test, y_pred), y_pred4.std())","metadata":{"execution":{"iopub.status.busy":"2021-07-15T21:46:16.37341Z","iopub.execute_input":"2021-07-15T21:46:16.373823Z","iopub.status.idle":"2021-07-15T21:46:16.383766Z","shell.execute_reply.started":"2021-07-15T21:46:16.37378Z","shell.execute_reply":"2021-07-15T21:46:16.38198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Logistic Regression**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nregressor5 = LogisticRegression(n_jobs= 4, random_state = 5).fit(x_train, y_train)\ny_pred5 = regressor5.predict(x_test)\nprint (explained_variance_score(y_test, y_pred5), y_pred5.std())","metadata":{"execution":{"iopub.status.busy":"2021-07-15T21:47:07.480115Z","iopub.execute_input":"2021-07-15T21:47:07.480699Z","iopub.status.idle":"2021-07-15T21:47:09.424215Z","shell.execute_reply.started":"2021-07-15T21:47:07.480644Z","shell.execute_reply":"2021-07-15T21:47:09.423139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusions    - - - - - - - - - - - - - Conclusiones","metadata":{}},{"cell_type":"markdown","source":"We can observe that the 3 main models resemble their explained variation and have a good prediction percentage, however (even if it is very little) we can observe that some models have a greater explained variation but in turn we must take into account their standard deviation that will indicate to us how much the model can go wrong\n\n-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nPodemos observar que los 3 principales modelos se asemejan a su variacion explicada y tienen un buen porcentaje de predicción, sin embargo (aunque sea muy poco) podemos observar que algunos modelos tienen una mayor variacion explicada pero a su vez debemos tener en cuenta su desviación estandar que nos indicara que tanto puede llegar a equivocarse el modelo","metadata":{}}]}