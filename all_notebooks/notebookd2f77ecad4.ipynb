{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n#boost\nimport lightgbm as lgb \nfrom sklearn.metrics import mean_squared_error\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv(\"../input/craigslist-carstrucks-data/vehicles.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualisation of null values\ndata.isna().sum()\n#index of columns that have over than 0.25 null values \nnull_columns=data.columns[data.isna().mean()>0.25]\n#axis=1 for columns axis=0 for rows  \ndata=data.drop(null_columns,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unneded_columns=['id','url','region_url','image_url','description','posting_date']\ndata=data.drop(unneded_columns,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(data.corr())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#serching for numb of unique values in categorical columns\n{column:len(data[column].unique()) for column in data.columns if data.dtypes[column]=='object'} ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=data.drop('model',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encodeCategories(data,columns,prefix):\n    df=data.copy()\n    for column,prefix in zip(columns,prefix):\n        #representing categories in dummie variabes [458213,1]\n        dummies=pd.get_dummies(data[column],prefix=prefix)\n        df=pd.concat([df,dummies],axis=1)\n        df=df.drop(column,axis=1)\n    return(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=encodeCategories(data,['region', 'manufacturer', 'fuel','title_status','transmission', 'type', 'state'],\n                      ['reg','manuf','fuel','tit_stat','transm','type','state'])\ndata\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fill in all null values with mean value\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in data.columns:\n    data[column]=data[column].fillna(data[column].mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Splitting and Scaling\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"y=data.loc[:,'price']\nX=data.drop('price',axis=1)\n#StandardScaler for transforming values to v Â£[-1,1]\nscaler=StandardScaler()\nX=scaler.fit_transform(X)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test=train_test_split(X,y,train_size=0.7,random_state=34)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor=LinearRegression()\nregressor.fit(X_train,y_train)\ny_pred=regressor.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lightModel=lgb.LGBMRegressor(boosting_type='gbdt', num_leaves=31, n_estimators=100,reg_lambda=1.0)\nlightModel.fit(X_train,y_train)\nlight_y_pred=lightModel.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lin_loss=np.sqrt(mean_squared_error(y_test,y_pred))\nlightloss=np.sqrt(mean_squared_error(y_test,light_y_pred))\nprint(\"linear:\",lin_loss)\nprint(\"light:\",lightloss)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}