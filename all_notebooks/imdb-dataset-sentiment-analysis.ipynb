{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from keras.models import Sequential \nfrom keras.layers import Dense \nimport matplotlib.pyplot as plt\n\nfrom textblob import TextBlob\nfrom sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn import decomposition, ensemble\nfrom sklearn import metrics\nimport textblob, string\nfrom keras.preprocessing import text, sequence\nfrom keras import layers, models, optimizers\n\nimport nltk\nfrom nltk.corpus import stopwords\n\n\nimport pandas as pd\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/imdb-dataset-sentiment-analysis-in-csv-format/Test.csv')\ntrain = pd.read_csv('../input/imdb-dataset-sentiment-analysis-in-csv-format/Train.csv')\nvalid = pd.read_csv('../input/imdb-dataset-sentiment-analysis-in-csv-format/Valid.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('fivethirtyeight')\nsns.countplot(data=train,x='label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data=test,x='label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data=valid,x='label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def transformations(dataframe):\n    # upper to lower character\n    dataframe['text'] = dataframe['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n    #punctuations\n    dataframe['text'] = dataframe['text'].str.replace('[^\\w\\s]','')\n    #numbers\n    dataframe['text'] = dataframe['text'].str.replace('\\d','')\n    # \n    sw = stopwords.words('english')\n    dataframe['text'] = dataframe['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))\n    #rare characters deleting\n    sil = pd.Series(' '.join(dataframe['text']).split()).value_counts()[-1000:]\n    dataframe['text'] = dataframe['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in sil))\n    \n    #lemmi\n    from textblob import Word\n    #nltk.download('wordnet')\n    dataframe['text'] = dataframe['text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()])) \n    return dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = transformations(train)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = transformations(test)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid = transformations(valid)\nvalid.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = train['text']\nvalid_x = valid[\"text\"]\ntrain_y = train[\"label\"]\nvalid_y = valid[\"label\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = CountVectorizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer.fit(train_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_count = vectorizer.transform(train_x)\nx_valid_count = vectorizer.transform(valid_x)\nx_test_count  = vectorizer.transform(test[\"text\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential() \nmodel.add(Dense(50,input_dim=x_train_count.shape[1], kernel_initializer=\"uniform\", activation=\"relu\")) \n#model.add(Dense(6, kernel_initializer=\"uniform\", activation=\"relu\")) \nmodel.add(Dense(1, kernel_initializer=\"uniform\", activation=\"sigmoid\")) \nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n# Fit the model\nhistory = model.fit(x_train_count, train_y.values.reshape(-1,1), validation_data=(x_valid_count,valid_y), nb_epoch=2, batch_size=128)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate\nloss, acc = model.evaluate(x_test_count, test[\"label\"], verbose=0)\nprint('Test Accuracy: %f' % (acc*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"comments = pd.Series(test[\"text\"])\ncomments = vectorizer.transform(comments)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict_classes(comments)\nnn_cm = metrics.confusion_matrix(test[\"label\"],y_pred)\nprint(nn_cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"comment_1 = pd.Series(\"this film is very nice and good i like it\")\ncomment_2 = pd.Series(\"no not good look at that shit very bad\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"comment_1  = vectorizer.transform(comment_1)\ncomment_2 = vectorizer.transform(comment_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.predict_classes(comment_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.predict_classes(comment_2)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}