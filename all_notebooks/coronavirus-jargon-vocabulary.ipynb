{"cells":[{"metadata":{},"cell_type":"markdown","source":"## A lot of jargon come in the papers which are difficult to track as to what it means. In this kernel, I am trying to create a dictionary of jargons with their short hand notation"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport json\nfrom multiprocessing import Pool\nimport random\nimport pickle\nimport re\nfrom functools import reduce\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames_list = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for each_filename in filenames:\n        filenames_list.append(os.path.join(dirname, each_filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames_list[:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(filenames_list)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\n# for filename in random.sample(filenames_list, 2):\n#     if filename.split(\".\")[-1] == \"json\":\n#         ifp = open(os.path.join(dirname, filename))\n#         research_paper = json.load(ifp)\n#         title = research_paper[\"metadata\"][\"title\"]\n#         print(title, \"\\n\\n\")\n#         abstract_text = \" \".join([each[\"text\"] for each in research_paper[\"abstract\"]])\n#         print(abstract_text, \"\\n\\n\")\n#         body_text = \" \".join([each[\"text\"] for each in research_paper[\"body_text\"]])\n#         print(body_text)\n\n            ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I have taken the stopwords from here:\nhttps://gist.github.com/sebleier/554280#gistcomment-2838837"},{"metadata":{"trusted":true},"cell_type":"code","source":"ifp = open(\"/kaggle/input/stopwords-compiled/stopwords_compiled.txt\", \"r\")\nstopwords = ifp.read().split(\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stopwords[:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_phrase(phrase_str):\n    phrase_split = phrase_str.strip().split(\".\")\n    if len(phrase_split) == 1:\n        return phrase_split[0]\n    else:\n        return phrase_split[-1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## In Jargons extractor:\nI have noticed that often the short hand notation of a jargon is in the form **stopword** **jargon** (**short-hand-notation**) **stopword**\nSo I i first find those pairs as candidates and then apply filtering \n*     such that short-hand-notation is not all numeric, in one word (might be in a combination of alpha, numeric, hyphen, etc) but not a percentage value\n*     the jargon is atleast two words"},{"metadata":{"trusted":true},"cell_type":"code","source":"def jargons_extractor(text):\n    abbreviation_jargon_pairs = []\n    potential_phrases = re.split(\" \" + \" | \".join(list(stopwords)), text)\n#     print(potential_phrases)\n    for each_phrase in potential_phrases:\n        phrase_jargon_splits = re.split(\"\\(|\\)\", each_phrase)\n        if len(phrase_jargon_splits) >= 2 and len(phrase_jargon_splits[0]) > 1 and len(phrase_jargon_splits[1]) > 1 and len(phrase_jargon_splits[1].split(\" \")) == 1 and len(clean_phrase(phrase_jargon_splits[0]).split(\" \")) > 1 and phrase_jargon_splits[1].isnumeric() == False and phrase_jargon_splits[1][-1] != \"%\":\n#             print(clean_phrase(phrase_jargon_splits[0]).strip(), \" -> \", phrase_jargon_splits[1].strip())\n            abbreviation_jargon_pairs.append((phrase_jargon_splits[1].strip(), clean_phrase(phrase_jargon_splits[0]).strip()))\n    return abbreviation_jargon_pairs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_research_paper(filename_path):\n    if filename_path.split(\".\")[-1] == \"json\":\n#         print(filename_path)\n        ifp = open(filename_path, \"r\")\n        research_paper = json.load(ifp)\n        title = research_paper[\"metadata\"][\"title\"]\n        abstract_text = \" \".join([each[\"text\"] for each in research_paper[\"abstract\"]])\n        body_text = \" \".join([each[\"text\"] for each in research_paper[\"body_text\"]])\n        all_text = \" {} {} {} \".format(title, abstract_text, body_text)\n#         print(all_text[:10])\n        return jargons_extractor(all_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with Pool(processes=100) as pool:\n    lists_of_jargon_lists = pool.map(process_research_paper, filenames_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(lists_of_jargon_lists)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lists_of_jargon_lists[90:92]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"short_hand_jargon_pairs = reduce(lambda x, y: x + y, [each_list for each_list in lists_of_jargon_lists if each_list])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(short_hand_jargon_pairs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random.sample(short_hand_jargon_pairs, 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"short_hand_set = set([each_pair[0] for each_pair in short_hand_jargon_pairs])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(short_hand_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"short_hand_pair_dict = dict(zip(list(short_hand_set), [[]] * len(short_hand_set)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# short_hand_pair_dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## I create a combined list of jargons for each short-hand-notation so that the exact jargon can be extracted by finding the common part of the phrase among all jargons for that short-hand-notation"},{"metadata":{"trusted":true},"cell_type":"code","source":"for each_pair in short_hand_jargon_pairs:\n    short_hand_pair_dict[each_pair[0]] = short_hand_pair_dict[each_pair[0]] + [each_pair[1]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"short_hand_pair_dict['gp41']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for each_key in random.sample(short_hand_pair_dict.keys(), 100):\n    print(each_key, \" -> \", short_hand_pair_dict[each_key])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"short_hand_pair_dict[\"aa\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## observe above amino acid can be extracted by analysing the different jargons associated with \"aa\".\n## I leave the further cleaning for later"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}