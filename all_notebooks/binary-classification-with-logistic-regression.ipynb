{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Heart Attack Analysis and Prediction - Binary Classification with Logistic Regression","metadata":{}},{"cell_type":"markdown","source":"About dataset\n\n* Age : Age of the patient\n* Sex : Sex of the patient\n* exang: exercise induced angina (1 = yes; 0 = no)\n* ca: number of major vessels (0-3)\n* cp : Chest Pain type chest pain type \n    * Value 1: typical angina\n    * Value 2: atypical angina\n    * Value 3: non-anginal pain\n    * Value 4: asymptomatic\n* trtbps : resting blood pressure (in mm Hg)\n* chol : cholestoral in mg/dl fetched via BMI sensor\n* fbs : (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n* rest_ecg : resting electrocardiographic results \n    * Value 0: normal\n    * Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n    * Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n* thalach : maximum heart rate achieved\n* **target : 0= less chance of heart attack 1= more chance of heart attack**","metadata":{}},{"cell_type":"markdown","source":"### **This notebook proceeds with the steps below:)**\n```\nStep 1. Data Description\nStep 2. EDA\nStep 3. Correlation Check\nStep 4. Test Data Split and Standard Scaling\nStep 5. Modeling and Prediction (sklearn-LogisticRegression)\n```","metadata":{}},{"cell_type":"markdown","source":"## Step 1. Data Description","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd Heart_Attack_Analysis_and_Prediction","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/heart-attack-analysis-prediction-dataset/heart.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import missingno as msno","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msno.bar(df);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"------------\n1. All Columns are numeric\n2. Null value isn't exist\n3. colums -> x : 13, y : 1\n4. rows -> 14\n5. it need to be normalized","metadata":{}},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 2. EDA","metadata":{}},{"cell_type":"code","source":"df.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----------\nThere are some categorical columns(but int type). Let's EDA that first","metadata":{}},{"cell_type":"code","source":"df['sex'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_cols = ['sex','cp','fbs','restecg','exng','slp','caa','thall']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(cat_cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,  ax = plt.subplots(nrows=4, ncols=2, figsize=(20,16))\nt = 0\n\nfor i in range(4):\n    for j in range(2):\n        cat_bar = [df[col].value_counts() for col in cat_cols]\n        axes = ax[i][j]\n        sns.barplot(x=cat_bar[t].index, y=cat_bar[t].values, ax=axes)\n        axes.set_title(cat_cols[t])\n        t += 1\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-------\nLet's see data info again - about categorical columns\n* Sex : Sex of the patient\n    * Value 0: Women\n    * Value 1: Man\n    \n    \n* exang: exercise induced angina \n    * Value 0: no (False)\n    * Value 1: yes (True)\n    \n    \n* ca: number of major vessels\n    * Value 0: NOthing\n    * Value 1: 1 vessel\n    * Value 2: 2 vessel\n    * Value 3: 3 vessel\n    * Value 4: 4 vessel\n    \n    \n* cp : Chest Pain type chest pain type \n    * Value 1: typical angina\n    * Value 2: atypical angina\n    * Value 3: non-anginal pain\n    * Value 4: asymptomatic\n    \n    \n* fbs : (fasting blood sugar > 120 mg/dl) \n    * Value 0: fasting blood sugar =< 120 (False)\n    * Value 1: fasting blood sugar > 120 (True)\n    \n        \n* rest_ecg : resting electrocardiographic results \n    * Value 0: normal\n    * Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n    * Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n\n\n* **target : 0= less chance of heart attack 1= more chance of heart attack","metadata":{}},{"cell_type":"markdown","source":"-----------\n- We don't have information about ['slp','thall','caa']\n- We have information below (around)\n    * Sex : Man - 70%\n    * cp : Typical angina - 50%\n    * fbs : fasting blood sugar <= 120(low) 85%\n    * rest_ecg : 'Value 0 and 1' are 90% (normal or ST-T wave abnormal)\n    * exang(exercise induced angina) : 0(False) 70%\n    ","metadata":{}},{"cell_type":"code","source":"df.output.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = df.output.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(x=output.index, y=output.values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Well Classified 'Y(Output)'","metadata":{}},{"cell_type":"markdown","source":"# Step 3. Correlation Check","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colormap = plt.cm.RdBu\nplt.figure(figsize=(20,16))\nsns.heatmap(df.corr())\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.corr()['output']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.corr()['output'].sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Output = pd.DataFrame(df.corr()['output'].sort_values(ascending=False))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(Output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"------------\n**There are high relation - Output and ['cp','thalachh','slp','restecg']**","metadata":{}},{"cell_type":"markdown","source":"# Step 4. Test Data Split and Standard Scaling","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = df.iloc[:,:-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = df.iloc[:,-1:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(train,test, test_size=0.3, random_state=32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape, X_test.shape)\nprint(y_train.shape, y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----------\nWell split, rows=212, cols=(x:13, y:1)","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train_raw = scaler.fit_transform(X_train)\nX_test_raw = scaler.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = pd.DataFrame(X_train_raw, columns=X_train.columns, index=X_train.index)\nX_test = pd.DataFrame(X_test_raw, columns=X_test.columns, index=X_test.index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-------------\nOK, Well Scaled! Let's Build a Model","metadata":{}},{"cell_type":"markdown","source":"# Step 5. Modeling and Prediction","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = LogisticRegression()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr.fit(X_train, y_train.values.ravel()) # ravel() : 1d - array transform\ny_pred = lr.predict(X_test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-----------------\n!. Let's See more about ravel()","metadata":{}},{"cell_type":"code","source":"y_train.values.ravel()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This difference make important warning!","metadata":{}},{"cell_type":"code","source":"(y_pred == y_test.values.ravel()).sum() / len(y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code is same like ..","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_pred, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}