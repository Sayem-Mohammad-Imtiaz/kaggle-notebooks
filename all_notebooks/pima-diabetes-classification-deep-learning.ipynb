{"cells":[{"metadata":{},"cell_type":"markdown","source":"# TODO\n- ✅ add unblacend class\n- ⬜ batch norm\n- ⬜ regularizer\n- ✅ train/dev/test\n- ⬜ lr tuner\n- ✅ add normalizing \n\n\n\n"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","scrolled":true,"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf \nimport matplotlib.pyplot as plt\nimport sklearn as sk","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%matplotlib inline\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter('ignore')\nsns.set(rc={'figure.figsize' : (10, 5)})\nsns.set_style(\"darkgrid\", {'axes.grid' : True})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading csv files and showing first and last 5 records. "},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","scrolled":true,"trusted":false},"cell_type":"code","source":"diabetes = pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')\ndia = diabetes.copy()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"diabetes.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# diabetes.Pregnancies = diabetes.Pregnancies.replace(0,333)\n# diabetes.Outcome = diabetes.Outcome.replace(0,333)\n# diabetes\n\n# diabetes = diabetes.replace(0, np.nan)\n# diabetes = diabetes.dropna()\n# # df = df.replace(np.nan, 0.0)\n\n# diabetes.Pregnancies = diabetes.Pregnancies.replace(333,0)\n# diabetes.Outcome = diabetes.Outcome.replace(333,0)\n# diabetes","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"corrMatrix = diabetes.corr()\nsns.heatmap(corrMatrix, annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"from sklearn.dummy import DummyClassifier\nx = diabetes.drop(columns = 'Outcome')\ny = diabetes['Outcome']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"x.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dummy = DummyClassifier('most_frequent') #returining most frequent class in this case 1/\nresults = dummy.fit(x,y)\nresults.score(x,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"len( # Number of recrds that have at least one zero in it\n    x[(x.Glucose == 0) |\n    (x.BloodPressure ==0) |\n    (x.SkinThickness==0) |\n    (x.Insulin==0) |\n    (x.BMI==0) |\n    (x.DiabetesPedigreeFunction==0) |\n    (x.Age==0)]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Some Funcs"},{"metadata":{"trusted":false},"cell_type":"code","source":"from tensorflow import keras\nimport tensorflow.keras.backend as K\n\ndef get_f1(y_true, y_pred): #taken from old keras source code\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    recall = true_positives / (possible_positives + K.epsilon())\n    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n    return f1_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def max_metric (history):\n    max_acc = max(history.history['accuracy'])\n    max_f1 = max(history.history['get_f1'])\n    min_loss = min(history.history['loss'])\n    max_val_acc = max(history.history['val_accuracy'])\n    max_val_f1 = max(history.history['val_get_f1'])\n    min_val_loss = min(history.history['val_loss'])\n    print(f\"Maximum Accuracy: {max_acc} \\nMaximum F1 Score: {max_f1} \\nMinimum Binary CrossEntropy Loss: {min_loss} \\nMaximum Validation Accuracy: {max_val_acc} \\nMaximum Validation F1 Score: {max_val_f1} \\nMaximum Validation Binary CrossEntropy Loss: {min_val_loss} \\n\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def plot_this(history):\n    # summarize history for accuracy\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('model accuracy')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.legend(['train', 'validation'], loc='upper left')\n    plt.show()\n    \n    # summarize history for f1\n    plt.plot(history.history['get_f1'])\n    plt.plot(history.history['val_get_f1'])\n    plt.title('model f1')\n    plt.ylabel('f1')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n    \n    # summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Normalization"},{"metadata":{"trusted":false},"cell_type":"code","source":"diabetes.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# normalize the data\n# we do not want to modify our label column Exited\ncols_to_norm = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI',\n       'DiabetesPedigreeFunction', 'Age']\n\n# copy churn dataframe to churn_norm to do not affect the original data\ndia_norm = diabetes.copy()\n\n# normalize churn_norm dataframe \ndia_norm[cols_to_norm] = diabetes[cols_to_norm].apply(lambda x: (x - x.min())/ (x.max() - x.min()) )\n\nx = dia_norm.drop(columns = 'Outcome')\ny = dia_norm['Outcome']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dia_norm","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dia_norm.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression"},{"metadata":{"trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import preprocessing\nimport warnings","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"min_max_scaler = preprocessing.MinMaxScaler()\nX_train_minmax = min_max_scaler.fit_transform(x)\nX_train, X_test, y_train, y_test = train_test_split(X_train_minmax, y, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"parameters = {'C': np.linspace(0.0001, 100, 40)}\ngrid_search = GridSearchCV(LogisticRegression(max_iter=3000, class_weight={0:0.35, 1:0.65}), parameters, n_jobs=-1)\ngrid_search.fit(X_train, y_train)\n\nprint('best parameters: ', grid_search.best_params_)\nprint('best scrores: ', grid_search.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lr_clf = LogisticRegression(C=2.5642, max_iter=3000, class_weight={0:0.35, 1:0.65})\nlr_clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"lr_clf.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import f1_score\ny_hat = lr_clf.predict(X_test)\nf1 = f1_score(y_test, y_hat)\nprint (f\"f1 socre is: {f1} \")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#lr_clf.predict_proba(x.iloc[[700]]) #FOR PREDICtion","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVM"},{"metadata":{"trusted":false},"cell_type":"code","source":"parameters = {'C': np.linspace(0.0001, 100, 40)}\ngrid_search = GridSearchCV(svm.SVC(probability=True, max_iter=300, class_weight={1: 0.65, 0:0.35}), parameters, n_jobs=-1)\ngrid_search.fit(X_train, y_train)\n\nprint('best parameters: ', grid_search.best_params_)\nprint('best scrores: ', grid_search.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn import svm\n\nclf = svm.SVC(C=28.205199999999998, gamma='auto', probability=True, verbose=True, max_iter=3000, class_weight={1: 0.65, 0:0.35})\nclf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"clf.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import f1_score\ny_hat = clf.predict(X_test)\nf1 = f1_score(y_test, y_hat)\nprint (f\"f1 socre is: {f1} \")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Naive Bayes"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\ngnb = GaussianNB()\ny_pred = gnb.fit(X_train, y_train).predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import f1_score\nf1 = f1_score(y_test, y_pred)\nprint (f\"f1 socre is: {f1} \")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Neural net"},{"metadata":{"trusted":false},"cell_type":"code","source":"model2 = tf.keras.Sequential()\nmodel2.add(tf.keras.layers.Dense(16, input_dim=x.shape[1], kernel_regularizer=tf.keras.regularizers.l2(0.001)))#activation = 'relu' ))\nmodel2.add(tf.keras.layers.ELU(alpha=1))\nmodel2.add(tf.keras.layers.Dropout(0.2))\nmodel2.add(tf.keras.layers.Dense(16,kernel_regularizer=tf.keras.regularizers.l2(0.001)))# activation='relu'))\nmodel2.add(tf.keras.layers.ELU(alpha=1))\nmodel2.add(tf.keras.layers.Dropout(0.2))\nmodel2.add(tf.keras.layers.Dense(16,kernel_regularizer=tf.keras.regularizers.l2(0.001)))# activation='relu'))\nmodel2.add(tf.keras.layers.ELU(alpha=1))\nmodel2.add(tf.keras.layers.Dropout(0.2))\nmodel2.add(tf.keras.layers.Dense(16,kernel_regularizer=tf.keras.regularizers.l2(0.001)))# activation='relu'))\nmodel2.add(tf.keras.layers.ELU(alpha=1))\nmodel2.add(tf.keras.layers.Dense(1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model2.compile(optimizer='rmsprop', loss='MSE', metrics=['accuracy', get_f1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"history2 = model2.fit(X_train, y_train, validation_split=0.20, batch_size=64, workers=-1, epochs=100, verbose=2, class_weight={0:0.35, 1:0.65})","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"max_metric(history2)\nplot_this(history2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# model2.save(\"model2.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# from  tensorflow.keras.utils import plot_model\n# plot_model(model2, to_file='model.png', show_shapes=True, rankdir=\"LR\", expand_nested=False ,dpi=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import f1_score\n\ny_pred = model2.predict(X_test, verbose=1)\ny_pred = y_pred>0.5\nf1 = f1_score(y_test, y_pred)\nprint (f\"f1 socre is: {f1} \")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# apply(lambda x: (x - x.min())/ (x.max() - x.min()) \n# normalize the data\n# we do not want to modify our label column Exited\n# Pregnancies                  0.000\n# Glucose                      0.000\n# BloodPressure                0.000\n# SkinThickness                0.000\n# Insulin                      0.000\n# BMI                          0.000\n# DiabetesPedigreeFunction     0.078\n# Age                         21.000\n\n\n# Pregnancies                  17.00\n# Glucose                     199.00\n# BloodPressure               122.00\n# SkinThickness                99.00\n# Insulin                     846.00\n# BMI                          67.10\n# DiabetesPedigreeFunction      2.42\n# Age                          81.00\n\n\n## Sorry for hardcoding, i wll fix it ASAP!\n\ndef norm_a_data(data):\n    data[0] = (data[0] - 0)    / (17 - 0)\n    data[1] = (data[1] - 0)    / (199 - 0)\n    data[2] = (data[2] - 0)    / (122 - 0)\n    data[3] = (data[3] - 0)    / (99 - 0)\n    data[4] = (data[4] - 0)    / (846 - 0)\n    data[5] = (data[5] - 0)    / (67 - 0)\n    data[6] = (data[6] - 0.078) / (2 - 0.078)\n    data[7] = (data[7] - 21)    / (81 - 21)\n    return data[:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"my_data = [6, 148, 72, 35, 0, 33.6, 0.627, 50]\nmy_data = diabetes.iloc[245].values[:8]\nmy_data = norm_a_data(my_data)\nmy_data=np.array(my_data)\nmy_data = my_data.reshape(8,1)\n# pd.DataFrame(my_data, columns=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI',\n#        'DiabetesPedigreeFunction', 'Age'])\nmodel2.predict(my_data.transpose())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"diabetes.iloc[245].values[-1]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"nbformat":4,"nbformat_minor":4}