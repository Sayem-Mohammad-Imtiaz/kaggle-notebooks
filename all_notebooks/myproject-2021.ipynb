{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/lifestyle-and-wellbeing-data/Wellbeing_and_lifestyle_data.csv')\nprint(data.shape)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['GENDER'] = data['GENDER'].map({'Female':0, 'Male':1})\ndata = data[data.DAILY_STRESS.apply(lambda x: x.isnumeric())]\ndata['DAILY_STRESS'] = data['DAILY_STRESS'].astype(int)\ndata['AGE'] = data['AGE'].map({'Less than 20':0, '21 to 35':1, '36 to 50':2, '51 or more':3})\ndata = data.drop(columns =['Timestamp'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plot\ndata['BMI_RANGE'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1- A proper weight\n2 - overweight**\n\n**we can see that the population consist of more people that have proper weight**\n\n**now let's see differences between Categories**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\nax = sns.catplot(x=\"BMI_RANGE\", kind=\"count\", hue=\"AGE\", col = \"GENDER\", data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Less than 20: 0, 21 to 35: 1, 36 to 50: 2, 51 or more: 3\n\nFemale: 0, Male: 1**"},{"metadata":{},"cell_type":"markdown","source":"**We see that there is more womans with overweight in the population than mans.\nAnd the overweight over the years tend to change more in mans population than in women's**\n\n**A big change can be seen in men between the ages of 21 to 35 and 36 and up (probably because it is an age after marriage and good food awaits him at home)** :D\n\n"},{"metadata":{},"cell_type":"markdown","source":"# Now let's see data about daily stress "},{"metadata":{"trusted":true},"cell_type":"code","source":"x = data[['DAILY_STRESS', 'GENDER']].groupby(['GENDER'])['DAILY_STRESS'].agg(['mean']).reset_index().set_index('GENDER')\nx = x.rename({'mean':'Daily Stress Mean'}, axis=1)\nx.plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We see that womans are more daily stressed than mans in average**\n\nquote from report \"Some 200,000 men reported work-related stress averaged over the past three years compared to 272,000 women, according to the HSEâ€™s figures. This means women were 1.4 times more likely to suffer from stress, anxiety and depression\""},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.catplot(x=\"TIME_FOR_PASSION\", kind=\"count\", col = \"GENDER\", data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can see here that womans take less time for passions durring the day**\n\n**Maybe this could affects their daily stress**"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.catplot(x=\"DAILY_MEDITATION\", kind=\"count\", col = \"GENDER\", data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**And womans does daily meditation more than mans**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"print(data.isnull().sum())\n   \ndata.info()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Find corelation between features "},{"metadata":{},"cell_type":"markdown","source":"**This chart i take from another notebook to show the overall correlation between features and how each feature affect another**\nhere is the link https://www.kaggle.com/fatoubd/3-things-to-do-for-a-work-life-balance#4.-Evaluate-the-results"},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat = data.corr() \nmap_corr= sns.clustermap(corrmat, cmap =\"YlGnBu\", linewidths = 0.1)\nplot.setp(map_corr.ax_heatmap.yaxis.get_majorticklabels(), rotation = 0) \nmap_corr.ax_heatmap.set_xticklabels(map_corr.ax_heatmap.get_xmajorticklabels(), fontsize = 16)\nmap_corr.ax_heatmap.set_yticklabels(map_corr.ax_heatmap.get_ymajorticklabels(), fontsize = 16)\n\nmap_corr\nplot.savefig('heatmap.png', dpi=300, bbox_inches='tight')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is interesting to see that among the highest correlation there is :\n\nTime for passion- Flow\n\nPersonal Awards - Achievement\n\n'time for passion' is the time we dedicate to what we enjoy doing. It can be work, hobbies or volunteering. It is important to have time for passion in our busy lives because it is highly correlated with the 'flow' which is ,as described in the survey: \"Flow is defined as the mental state, in which you are fully immersed in performing an activity. You then experience a feeling of energized focus, full involvement, and enjoyment in the process of this activity.\" Mihaly Csikszentmihalyi decribed it as \" the secret to happiness\"\n\nAccording to the correlation maps people doing what they are passionate about have more personal awards and achivements in their life. and it correlate to todo completed as well. in overall we can say that they are more successfull"},{"metadata":{"trusted":true},"cell_type":"code","source":"to_pred = data['BMI_RANGE']\n\nprint('BMI corr: ')\nprint(data.corr()['BMI_RANGE'].sort_values(ascending = False))\n\nprint('Stress corr: ')\nprint(data.corr()['DAILY_STRESS'].sort_values(ascending = False))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# drop column to predict and checks values of data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_for_prediction = data.drop(columns =['BMI_RANGE'])\ndata_for_prediction.info()\n\nprint(len(data_for_prediction.columns))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random forest classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\nX_train, X_test, y_train, y_test = train_test_split(data_for_prediction,to_pred,test_size =0.2)\nmodel = RandomForestClassifier()\nmodel.fit(X_train,y_train)\nprediction = model.predict(X_test)\nscore = accuracy_score(y_test, prediction)\nscore","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I changed the max depth many times and it was better without"},{"metadata":{},"cell_type":"markdown","source":"# Select 9 best features"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectPercentile, f_classif, chi2, SelectKBest, SelectFpr\ndata_new = SelectKBest(f_classif,k=9).fit_transform(data_for_prediction,to_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(data_new,to_pred,test_size =0.2)\nmodel = RandomForestClassifier()\nmodel.fit(X_train,y_train)\nprediction = model.predict(X_test)\nscore = accuracy_score(y_test, prediction)\nscore","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"it seems that it does not help improve the model accuracy, there is 9 features that correlate with BMI"},{"metadata":{},"cell_type":"markdown","source":"# Took all the features who has most relevent correlation - 9 features"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_after_corr = data[['AGE','DAILY_STRESS','DONATION','DAILY_SHOUTING','LOST_VACATION','SUPPORTING_OTHERS','SOCIAL_NETWORK','PERSONAL_AWARDS','FLOW']] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_X_train, new_X_test, new_y_train, new_y_test = train_test_split(data_after_corr,to_pred,test_size =0.2)\nmodel = RandomForestClassifier()\nmodel.fit(new_X_train,new_y_train)\nnew_prediction_corr = model.predict(new_X_test)\nscore = accuracy_score(new_y_test, new_prediction_corr)\nscore","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict with different accuracy function "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\nnew_X_train, new_X_test, new_y_train, new_y_test = train_test_split(data_for_prediction,to_pred,test_size =0.2)\nmodel = RandomForestClassifier()\nmodel.fit(new_X_train,new_y_train)\nnew_prediction_corr = model.predict(new_X_test)\nscore = f1_score(new_y_test, new_prediction_corr,zero_division=1)\nscore","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that the accuracy function for imbalance dataset improve the accuracy score.\nthis accuracy function is (1/2)*(TP/(TP+FN)+TN/(TN+FP)) where TP, TN, FP, and FN refers to true positive, true negative,false positive,and false negative, respectively\nIt maybe usefull here because there is more population(data) with proper weight than overweight"},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nnew_X_train, new_X_test, new_y_train, new_y_test = train_test_split(data_for_prediction,to_pred,test_size =0.2)\nx = DecisionTreeClassifier(max_depth = 4)\nx.fit(new_X_train,new_y_train)\npred = x.predict(new_X_test)\nscore = f1_score(new_y_test, pred,zero_division=1)\nscore","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RandomForest is better"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}