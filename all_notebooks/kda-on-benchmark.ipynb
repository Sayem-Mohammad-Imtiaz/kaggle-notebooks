{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":" <table><tr><td bgcolor=#ffccff> <font color=#1a001a size=7 face=\"black body\">This is KDA applied on benchmark dataset </font> </td></tr></table>","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <table><tr><td bgcolor=#99ff99> <font color=#3333ff size=10 face=\"black body\">Preprocessing of dataset </font> </td></tr></table>\n ","metadata":{}},{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n\"\"\"\nCreated on %(date)s\n\n@author: %(username)s\n\"\"\"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom keras.layers import BatchNormalization\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\ndata=pd.read_csv(r'../input/keystroke-dynamics-benchmark-data-set/DSL-StrongPasswordData.csv')\ndata.drop(columns=['sessionIndex','rep'],axis=1,inplace=True)\nvisual_data=data\n#One Hot encoding the subject column. seperating the label from the rest of columns\nct=ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[0])],remainder='passthrough')\nunique_cols=data['subject'].nunique()\n\ndata=np.array(ct.fit_transform(data))\nX=data[:,unique_cols:]\ny=data[:,:unique_cols]\nprint(y.shape)\n\n\n#splitting the dataset into train and test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n#training:validation:test=70:0:30\n\n#applying feature scaling\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nX_train=sc.fit_transform(X_train)\n\nX_test=sc.transform(X_test)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visual_data=pd.read_csv(r'../input/keystroke-dynamics-benchmark-data-set/DSL-StrongPasswordData.csv')\nvisual_data.drop(columns=['sessionIndex','rep'],axis=1,inplace=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <table><tr><td bgcolor=#ffffcc> <font color=#9900cc size=10 face=\"black body\">Training Model </font> </td></tr></table>","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\ncnn=tf.keras.models.Sequential()\n\n#cnn.add(tf.keras.layers.Flatten())\n#\n'''cnn.add(tf.keras.layers.Dense(\nunits=256,activation='relu'\n))'''\ncnn.add(tf.keras.layers.Dense(\nunits=256,activation='relu'\n))\n\ncnn.add(BatchNormalization())\n\ncnn.add(tf.keras.layers.Dense(\nunits=512,activation='relu'\n))\n\ncnn.add(BatchNormalization())\n\ncnn.add(tf.keras.layers.Dense(\nunits=1024,activation='relu'\n))\n\ncnn.add(BatchNormalization())\n\ncnn.add(tf.keras.layers.Dense(\nunits=512,activation='relu'\n))\ncnn.add(BatchNormalization())\n\ncnn.add(tf.keras.layers.Dense(\n    units=unique_cols,activation='sigmoid'\n))\n\ncnn.compile(\noptimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n\nbatch_size = 32\n\n\nepochs=50","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import datetime\n%load_ext tensorboard\n\nlog_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n#callback=tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',model='auto',patience=15,verbose=1,restore_best_weights=True)\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n\n\nhist=cnn.fit(X_train, y_train, epochs = epochs, batch_size=batch_size, validation_split = 0.0, verbose = 1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(cnn.summary())\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(hist.history['loss'])\n\nscore,acc = cnn.evaluate(X_test, y_test, verbose = 1, batch_size = batch_size)\nprint(\"score: \"+str(score)+\" accuracy: \"+str(acc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <table><tr><td bgcolor=#ffff99> <font color=#b30059 size=10 face=\"black body\">Insights into Training the Dataset </font> </td></tr></table>\n","metadata":{}},{"cell_type":"code","source":"train_loss = hist.history['loss']\n#val_loss   = hist.history['val_loss']\nacc = hist.history['accuracy']\n#val_acc = hist.history['val_accuracy']\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(range(1,epochs+1),train_loss)\n#plt.plot(range(1,epochs+1),val_loss)\nplt.title('Losses vs Epochs')\nplt.xlabel('Epoch Number')\nplt.ylabel('Losses')\nplt.legend([\"Training loss\"])\n#plt.legend([\"Training loss\", \"Validation loss\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(range(1,epochs+1),acc)\n#plt.plot(range(1,epochs+1),val_acc)\nplt.title('Accuracies vs Epochs')\nplt.xlabel('Epoch Number')\nplt.ylabel('Accuracy')\nplt.legend([\"Training accuracy\"]) \n#plt.legend([\"Training accuracy\", \"Validation accuracy\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=cnn.predict(X_test)\n'''as the softmax outputs probability of each class there is need for conversion from  probability to 0s and 1s\nwhere the class corresponding to highest probability will be set to 1 and the rest to 0s.\ny_pred is an array of probabilities where y_pred_binary is an array of 0s and 1s.'''\ny_pred_binary=np.zeros(shape=y_pred.shape)\nexamples=y_pred.shape[0]\nprint(examples)\nfor i in range(examples):\n    index=np.argmax(y_pred[i])\n    y_pred_binary[i][index]=1\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" # <table><tr><td bgcolor=#b3ffff> <font color= #990099 size=10 face=\"black body\">ROC Curve</font> </td></tr></table>\n","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, roc_curve, auc\nfrom scipy.optimize import brentq\nfrom scipy.interpolate import interp1d\n\ndef plotROC():\n        \n    predictions = cnn.predict(X_test)\n    \n    fpr, tpr, thresholds = roc_curve(y_test.flatten(), predictions.flatten())\n    eer = brentq(lambda x : 1.0 - x - interp1d(fpr, tpr)(x), 0.0, 1.0)\n    \n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.plot(fpr, tpr, label='AUC for {:5s} = {:.3f}, EER = {:.3f}'.format(\n        \"Multiclass FCNN\", auc(fpr, tpr), eer))\n    plt.xlabel('False positive rate')\n    plt.ylabel('True positive rate')\n    plt.title('ROC curve')\n    plt.legend(loc='best')\n\nplotROC()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <table><tr><td bgcolor=#99ff99> <font color= #0080ff size=10 face=\"black body\">**Data Visualization**</font> </td></tr></table>\n\n\n","metadata":{"trusted":true}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sn # statistical graphs\nimport matplotlib.pyplot as plt # data visualization / graphs\nplt.style.use('seaborn-dark')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visual_data.iloc[:,:-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <table><tr><td bgcolor=#99ff99> <font color= #0080ff size=10 face=\"black body\">Correlation Plot</font> </td></tr></table>","metadata":{}},{"cell_type":"code","source":"corrMatrix = visual_data[['H.period', 'DD.period.t',\n       'UD.period.t', 'H.t', 'DD.t.i', 'UD.t.i', 'H.i', 'DD.i.e', 'UD.i.e',\n       'H.e', 'DD.e.five', 'UD.e.five', 'H.five', 'DD.five.Shift.r',\n       'UD.five.Shift.r', 'H.Shift.r', 'DD.Shift.r.o', 'UD.Shift.r.o', 'H.o',\n       'DD.o.a', 'UD.o.a', 'H.a', 'DD.a.n', 'UD.a.n', 'H.n', 'DD.n.l',\n       'UD.n.l', 'H.l', 'DD.l.Return', 'UD.l.Return', 'H.Return']].corr()\nfig, ax = plt.subplots(figsize=(10,10))\nsn.heatmap(corrMatrix, linewidths=0.1, cmap=\"BuPu\")\nplt.show()","metadata":{"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visual_data.columns\nh_cols=['subject']\nud_cols=['subject']\ndd_cols=['subject']\nuu_cols=['subject']\nfor column in visual_data.columns:\n    if 'H' in column:\n        \n        h_cols.append(str(column))\n    if 'UD' in column:\n        ud_cols.append(str(column))\n    if 'DD' in column:\n        dd_cols.append(str(column))\n    if 'UU' in column:\n        uu_cols.append(str(column))    \nprint(dd_cols)\nprint(uu_cols)\nprint(h_cols)\nprint(ud_cols)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <table><tr><td bgcolor=#ffb3d1> <font color= #0080ff size=10 face=\"black body\"> Average Inter subject variation</font> </td></tr></table>\n\n","metadata":{}},{"cell_type":"markdown","source":"# <table><tr><td bgcolor=#ffb3d1> <font color=#0066ff size=10 face=\"black body\">1.H Plots</font> </td></tr></table>\n\n","metadata":{}},{"cell_type":"code","source":"keyHoldLatency = visual_data[h_cols]\nkeyHoldLatency = keyHoldLatency.where((keyHoldLatency['subject']=='s002') | (keyHoldLatency['subject']=='s003') | (keyHoldLatency['subject']=='s004') | (keyHoldLatency['subject']=='s005') | (keyHoldLatency['subject']=='s007') | (keyHoldLatency['subject']=='s008'))\nkeyHoldLatency = keyHoldLatency.groupby('subject').agg('mean')\nkeyHoldLatency.T.plot(figsize=(8,5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <table><tr><td bgcolor=#ffb3d1> <font color=#ff1a1a size=10 face=\"black body\">2.UD Plots</font> </td></tr></table>\n\n\n","metadata":{}},{"cell_type":"code","source":"keyUDLatency = visual_data[ud_cols]\nkeyUDLatency = keyUDLatency.where((keyUDLatency['subject']=='s002') | (keyUDLatency['subject']=='s003') | (keyUDLatency['subject']=='s004') | (keyUDLatency['subject']=='s005') | (keyUDLatency['subject']=='s007') | (keyUDLatency['subject']=='s008'))\nkeyUDLatency = keyUDLatency.groupby('subject').agg('mean')\nkeyUDLatency.T.plot(figsize=(8,5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <table><tr><td bgcolor=#ffb3d1> <font color= #33ccff size=10 face=\"black body\">3.DD Plots</font> </td></tr></table>\n\n\n\n","metadata":{}},{"cell_type":"code","source":"keyDDLatency = visual_data[dd_cols]\nkeyDDLatency = keyDDLatency.where((keyDDLatency['subject']=='s002') | (keyDDLatency['subject']=='s003') | (keyDDLatency['subject']=='s004') | (keyDDLatency['subject']=='s005') | (keyDDLatency['subject']=='s007') | (keyDDLatency['subject']=='s008'))\nkeyDDLatency = keyDDLatency.groupby('subject').agg('mean')\nkeyDDLatency.T.plot(figsize=(8,5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <table><tr><td bgcolor=#ffff80> <font color=#800080 size=10 face=\"black body\">Intrasubject variation</font> </td></tr></table>\n","metadata":{}},{"cell_type":"markdown","source":"# <table><tr><td bgcolor=#ffff80> <font color=#0044cc size=10 face=\"black body\">1.H plot</font> </td></tr></table>\n","metadata":{}},{"cell_type":"code","source":"subKeyHoldLatency =visual_data.where((visual_data['subject']=='s021')).dropna().sample(n=12)\nsubKeyHoldLatency = subKeyHoldLatency[['subject','H.period','H.t','H.i', 'H.e','H.five','H.Shift.r','H.o','H.a','H.n','H.l','H.Return']]\nsubKeyHoldLatency = subKeyHoldLatency.set_index('subject')\nsubKeyHoldLatency.T.plot(figsize=(8,5), legend=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <table><tr><td bgcolor=#ffff80> <font color=#0044cc size=10 face=\"black body\">2.UD plot</font> </td></tr></table>\n\n\n","metadata":{}},{"cell_type":"code","source":"subKeyUDLatency = visual_data.where((visual_data['subject']=='s021')).dropna().sample(n=12)\nsubKeyUDLatency = subKeyUDLatency[['subject','UD.period.t','UD.t.i','UD.i.e','UD.e.five','UD.five.Shift.r','UD.Shift.r.o','UD.o.a','UD.a.n','UD.n.l','UD.l.Return']]\nsubKeyUDLatency = subKeyUDLatency.set_index('subject')\nsubKeyUDLatency.T.plot(figsize=(8,5), legend=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <table><tr><td bgcolor=#ffff80> <font color=#0044cc size=10 face=\"black body\">3.DD plot</font> </td></tr></table>\n\n\n","metadata":{}},{"cell_type":"code","source":"subKeyDDLatency = visual_data.where((visual_data['subject']=='s021')).dropna().sample(n=12)\nsubKeyDDLatency = subKeyDDLatency[['subject','DD.period.t','DD.t.i','DD.i.e','DD.e.five','DD.five.Shift.r', 'DD.Shift.r.o','DD.o.a','DD.a.n', 'DD.n.l','DD.l.Return']]\nsubKeyDDLatency = subKeyDDLatency.set_index('subject')\nsubKeyDDLatency.T.plot(figsize=(8,5), legend=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}