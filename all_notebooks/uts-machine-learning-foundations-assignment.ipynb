{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Building a Perceptron and Decision Tree Classifier from Scratch\nI will be using the [Heart Disease](https://archive.ics.uci.edu/ml/datasets/Heart+Disease) & [Absenteeism at work](https://archive.ics.uci.edu/ml/datasets/Absenteeism+at+work) datasets from the UCI Machine Learning Repository.\n\nThe objective of this notebook is to build the Perceptron and Decision tree from scratch to show how each of the models work to create their predictions. Each model will be tested on each dataset with a binary classification problem.\n\nThe structure of this notebook is as follows;\n\n* Load the libaries and datasets\n* View the Heart Disease dataset\n* Create the Perceptron model\n* Run the Percepton model on the Heart Disease dataset\n* Create the Decision Tree\n* Run the Decision Tree model on the Heart Disease dataset\n* View the Absenteeism at work dataset\n* Run the Percepton model on the Absenteeism at work dataset\n* Run the Decision Tree model on the Absenteeism at work dataset","metadata":{}},{"cell_type":"markdown","source":"# Load the libaries and datasets","metadata":{}},{"cell_type":"code","source":"# Install additional packages used within the code\n# QuickDA will be used to look at feature importance of the datasets\n!pip install quickda","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:21.09819Z","iopub.execute_input":"2021-07-14T12:08:21.098699Z","iopub.status.idle":"2021-07-14T12:08:28.591464Z","shell.execute_reply.started":"2021-07-14T12:08:21.098588Z","shell.execute_reply":"2021-07-14T12:08:28.589974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the python packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom quickda.explore_numeric_categoric import *\nimport warnings\n\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:28.593692Z","iopub.execute_input":"2021-07-14T12:08:28.594047Z","iopub.status.idle":"2021-07-14T12:08:29.991855Z","shell.execute_reply.started":"2021-07-14T12:08:28.594007Z","shell.execute_reply":"2021-07-14T12:08:29.990154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the input files into dataframes\nheart_path = '../input/heart-disease-uci/heart.csv'\nabsent_path = '../input/absenteeism-at-work-uci-ml-repositiory/Absenteeism_at_work.csv'\ndf1 = pd.read_csv(heart_path, header=0) # this is for the initial build of the model\ndf2 = pd.read_csv(absent_path, sep=';', header=0) # this is to check that the model runs on an additional dataset","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:29.994854Z","iopub.execute_input":"2021-07-14T12:08:29.99532Z","iopub.status.idle":"2021-07-14T12:08:30.026254Z","shell.execute_reply.started":"2021-07-14T12:08:29.995273Z","shell.execute_reply":"2021-07-14T12:08:30.025025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# View the Heart Disease dataset","metadata":{}},{"cell_type":"code","source":"# Data Exploration of the Heart Disease dataset\n# What's the structure and the descriptive statistics for the input file\ndf1.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:30.028312Z","iopub.execute_input":"2021-07-14T12:08:30.028694Z","iopub.status.idle":"2021-07-14T12:08:30.049298Z","shell.execute_reply.started":"2021-07-14T12:08:30.028656Z","shell.execute_reply":"2021-07-14T12:08:30.048308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:30.050762Z","iopub.execute_input":"2021-07-14T12:08:30.051063Z","iopub.status.idle":"2021-07-14T12:08:30.068426Z","shell.execute_reply.started":"2021-07-14T12:08:30.051034Z","shell.execute_reply":"2021-07-14T12:08:30.06708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.describe().T","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:30.069747Z","iopub.execute_input":"2021-07-14T12:08:30.070029Z","iopub.status.idle":"2021-07-14T12:08:30.133257Z","shell.execute_reply.started":"2021-07-14T12:08:30.070002Z","shell.execute_reply":"2021-07-14T12:08:30.131988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Understand the baseline of the target attribute\ndf1['target'].value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:30.13453Z","iopub.execute_input":"2021-07-14T12:08:30.134872Z","iopub.status.idle":"2021-07-14T12:08:30.148129Z","shell.execute_reply.started":"2021-07-14T12:08:30.13484Z","shell.execute_reply":"2021-07-14T12:08:30.147446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the distribution of the target values of each dataset\nfig, ax = plt.subplots(figsize=(6,4))\n\nax.bar(df1['target'].unique(), df1['target'].value_counts())\nax.set_title('Heart Disease Target Distrbution')\nax.set_xticks([0,1])\nax.set_xlabel('Target')\nax.set_ylabel('Count');","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:30.149384Z","iopub.execute_input":"2021-07-14T12:08:30.149912Z","iopub.status.idle":"2021-07-14T12:08:30.351207Z","shell.execute_reply.started":"2021-07-14T12:08:30.14988Z","shell.execute_reply":"2021-07-14T12:08:30.350293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Visualisation**","metadata":{}},{"cell_type":"code","source":"# Plot the predictive power score (pps) of the features\neda_numcat(df1, method='pps', x='target')","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:30.354226Z","iopub.execute_input":"2021-07-14T12:08:30.354658Z","iopub.status.idle":"2021-07-14T12:08:30.833623Z","shell.execute_reply.started":"2021-07-14T12:08:30.354623Z","shell.execute_reply":"2021-07-14T12:08:30.832407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create separate dataframes for discrete and continuous variables\ndiscrete_df = df1[['sex','cp','fbs','restecg','exang','slope','ca','thal','target']].copy()\ncontinuous_df = df1[['age','trestbps','chol','thalach','oldpeak','target']].copy()","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:30.83652Z","iopub.execute_input":"2021-07-14T12:08:30.836989Z","iopub.status.idle":"2021-07-14T12:08:30.847262Z","shell.execute_reply.started":"2021-07-14T12:08:30.836938Z","shell.execute_reply":"2021-07-14T12:08:30.845202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Change the target variable to a catagorical value\ndiscrete_df['target'].replace({0:'No',1:'Yes'}, inplace=True)\ncontinuous_df['target'].replace({0:'No',1:'Yes'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:30.848932Z","iopub.execute_input":"2021-07-14T12:08:30.849245Z","iopub.status.idle":"2021-07-14T12:08:30.863185Z","shell.execute_reply.started":"2021-07-14T12:08:30.849209Z","shell.execute_reply":"2021-07-14T12:08:30.861906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a pairplot for the continuous variables to understand the relationship between the variables\nsns.pairplot(continuous_df, hue='target', diag_kind='hist', corner=True, plot_kws={'alpha': 0.2});","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:30.864775Z","iopub.execute_input":"2021-07-14T12:08:30.865243Z","iopub.status.idle":"2021-07-14T12:08:36.241729Z","shell.execute_reply.started":"2021-07-14T12:08:30.865205Z","shell.execute_reply":"2021-07-14T12:08:36.24063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using the scatter plots from the pairplot explore some of the more promising pairings\n# Create 6 subplots and have each pairing coloured by the target variable\nfig, axes = plt.subplots(nrows=2, ncols=3, figsize=(18,12))\n\naxes[0][0].scatter(x=df1['chol'],y=df1['thalach'],c=df1['target'],cmap='coolwarm',alpha=0.2)\naxes[0][0].set_xlabel('chol')\naxes[0][0].set_ylabel('thalach')\naxes[0][0].set_title('chol vs thalach')\n\naxes[0][1].scatter(x=df1['chol'],y=df1['age'],c=df1['target'],cmap='coolwarm',alpha=0.2)\naxes[0][1].set_xlabel('chol')\naxes[0][1].set_ylabel('age')\naxes[0][1].set_title('chol vs age')\n\naxes[0][2].scatter(x=df1['thalach'],y=df1['age'],c=df1['target'],cmap='coolwarm',alpha=0.2)\naxes[0][2].set_xlabel('thalach')\naxes[0][2].set_ylabel('age')\naxes[0][2].set_title('age vs thalach')\n\naxes[1][0].scatter(x=df1['oldpeak'],y=df1['thalach'],c=df1['target'],cmap='coolwarm',alpha=0.2)\naxes[1][0].set_xlabel('oldpeak')\naxes[1][0].set_ylabel('thalach')\naxes[1][0].set_title('oldpeak vs thalach')\n\naxes[1][1].scatter(x=df1['chol'],y=df1['oldpeak'],c=df1['target'],cmap='coolwarm',alpha=0.2)\naxes[1][1].set_xlabel('chol')\naxes[1][1].set_ylabel('oldpeak')\naxes[1][1].set_title('chol vs oldpeak')\n\naxes[1][2].scatter(x=df1['trestbps'],y=df1['thalach'],c=df1['target'],cmap='coolwarm',alpha=0.2)\naxes[1][2].set_xlabel('trestbps')\naxes[1][2].set_ylabel('thalach')\naxes[1][2].set_title('trestbps vs thalach')\n\nfig.tight_layout();","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:36.243201Z","iopub.execute_input":"2021-07-14T12:08:36.243516Z","iopub.status.idle":"2021-07-14T12:08:37.849131Z","shell.execute_reply.started":"2021-07-14T12:08:36.243482Z","shell.execute_reply":"2021-07-14T12:08:37.848063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create histograms for the discrete attributes coloured by the target to identify any key splits\nfig, ax = plt.subplots(nrows=2, ncols=4, figsize=(16,8))\n\nax[0][0].hist(discrete_df[discrete_df.target == 'Yes']['sex'], color='r', alpha=0.5, label='Yes')\nax[0][0].hist(discrete_df[discrete_df.target == 'No']['sex'], color='b', alpha=0.5, label='No')\nax[0][0].set_title('Distribution of sex')\nax[0][0].set_xlabel('sex')\nax[0][0].set_ylabel('count')\nax[0][0].legend()\n\nax[0][1].hist(discrete_df[discrete_df.target == 'Yes']['cp'], color='r', alpha=0.5, label='Yes')\nax[0][1].hist(discrete_df[discrete_df.target == 'No']['cp'], color='b', alpha=0.5, label='No')\nax[0][1].set_title('Distribution of cp')\nax[0][1].set_xlabel('cp')\nax[0][1].set_ylabel('count')\nax[0][1].legend()\n\nax[0][2].hist(discrete_df[discrete_df.target == 'Yes']['fbs'], color='r', alpha=0.5, label='Yes')\nax[0][2].hist(discrete_df[discrete_df.target == 'No']['fbs'], color='b', alpha=0.5, label='No')\nax[0][2].set_title('Distribution of fbs')\nax[0][2].set_xlabel('fbs')\nax[0][2].set_ylabel('count')\nax[0][2].legend()\n\nax[0][3].hist(discrete_df[discrete_df.target == 'Yes']['restecg'], color='r', alpha=0.5, label='Yes')\nax[0][3].hist(discrete_df[discrete_df.target == 'No']['restecg'], color='b', alpha=0.5, label='No')\nax[0][3].set_title('Distribution of restecg')\nax[0][3].set_xlabel('restecg')\nax[0][3].set_ylabel('count')\nax[0][3].legend()\n\nax[1][0].hist(discrete_df[discrete_df.target == 'Yes']['exang'], color='r', alpha=0.5, label='Yes')\nax[1][0].hist(discrete_df[discrete_df.target == 'No']['exang'], color='b', alpha=0.5, label='No')\nax[1][0].set_title('Distribution of exang')\nax[1][0].set_xlabel('exang')\nax[1][0].set_ylabel('count')\nax[1][0].legend()\n\nax[1][1].hist(discrete_df[discrete_df.target == 'Yes']['slope'], color='r', alpha=0.5, label='Yes')\nax[1][1].hist(discrete_df[discrete_df.target == 'No']['slope'], color='b', alpha=0.5, label='No')\nax[1][1].set_title('Distribution of slope')\nax[1][1].set_xlabel('slope')\nax[1][1].set_ylabel('count')\nax[1][1].legend()\n\nax[1][2].hist(discrete_df[discrete_df.target == 'Yes']['ca'], color='r', alpha=0.5, label='Yes')\nax[1][2].hist(discrete_df[discrete_df.target == 'No']['ca'], color='b', alpha=0.5, label='No')\nax[1][2].set_title('Distribution of ca')\nax[1][2].set_xlabel('ca')\nax[1][2].set_ylabel('count')\nax[1][2].legend()\n\nax[1][3].hist(discrete_df[discrete_df.target == 'Yes']['thal'], color='r', alpha=0.5, label='Yes')\nax[1][3].hist(discrete_df[discrete_df.target == 'No']['thal'], color='b', alpha=0.5, label='No')\nax[1][3].set_title('Distribution of thal')\nax[1][3].set_xlabel('thal')\nax[1][3].set_ylabel('count')\nax[1][3].legend()\n\nplt.tight_layout();","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:37.850943Z","iopub.execute_input":"2021-07-14T12:08:37.851297Z","iopub.status.idle":"2021-07-14T12:08:40.31421Z","shell.execute_reply.started":"2021-07-14T12:08:37.851264Z","shell.execute_reply":"2021-07-14T12:08:40.313023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**EDA Observations**\nThere is no clear spearation in any of the pairings that I have focused on so 100% accuracy is not expected using a perceptron. I will pair up some of the attributes and check how they perform against the perceptron.\n\nThere are some separations in the discrete attributes so a decision tree may be more accurate.","metadata":{}},{"cell_type":"markdown","source":"# Create the Perceptron model\nPerceptron model code adapted from Tutorial: Implementing a Linear Model from the course material.","metadata":{}},{"cell_type":"code","source":"class MyPerceptron:\n    \n    def __init__(self, max_iterations=1000,n_dimensions=2):\n        # Default max iterations in the case of not being 100% accurate is 100 but can be set as an input by the user\n        # Default dimensions is 2 for when X has two attributes and can be manually adjusted, the number of demensions is used to set the random weights\n        np.random.RandomState(42) # Set the random state so results can be replicated       \n        self.max_iterations = max_iterations \n        self.W = np.random.random(n_dimensions) # Set the weights as random numbers, the number of weights created are based on the shape of X\n        self.b = np.random.random() # Set the bias as a random number\n        \n    def predict(self, X):\n        # Predict y as 1 or -1 using X\n        X = np.array(X) # Set X as an array\n        hval = (self.W * X).sum(axis=1) + self.b # Sum of weights array multiplied by X array and add the bias\n        return np.sign(hval) # Returns -1 or 1 as the prediction\n\n    def fit(self, X, y):\n        # Find the best weights and bias using X and y\n\n        # Create the defaults     \n        self.counter = 0 # Counter for iterations\n        self.best_corr = 0 # Best accuracy set as 0, this will be updated through the loop\n        self.best_params = {} # Empty dictionary for the weights and bias for the best accuracy\n        \n        # Set X and y as a numpy array\n        X = np.array(X)\n        y = np.array(y)\n        \n        while True:\n            pred = self.predict(X) # Run the predict function using X\n            is_pred_corr = y == pred # Create a bool array for correct predictions\n            is_pred_wrong = np.logical_not(is_pred_corr) # Create an array for if the prediction is wrong\n            error_indexes = is_pred_wrong.nonzero()[0] # Return the first instance of the array to create an index\n            accu = np.sum(is_pred_corr) / len(X) # Calculate the accuracy as a percentage\n            if accu > self.best_corr:\n                # If the accuracy for the current loop is greater than previous loops record the accuracy as best_corr \n                # and add the weights and bias to the best_params dictionary\n                self.best_corr = accu\n                self.best_params = {'w':self.W, 'bias':self.b}\n            if len(error_indexes) > 0:\n                # Use the length of the error indexes to find a misclassified X and use X and y to update the weights and bias\n                next_i = error_indexes[0]\n                W_update = X[next_i] * y[next_i]\n                self.W = self.W + W_update\n                self.b = self.b + y[next_i]\n            else:\n                # If there are no entries in error index break as accuracy is 100%\n                break\n                \n            self.counter += 1 # If the accuracy is less than 100% (error_indexes > 0) then add to the counter\n            \n            if self.counter >= self.max_iterations:\n                # If the loop has run more than the max_iterations then set the weights as the best weights and the bias as the best bias\n                self.W = self.best_params['w']\n                self.b = self.best_params['bias']\n                break\n                \n    def compute_linear_score_with_(self, X):\n        # Function used for viualisation of the decision boundary\n        s = None\n        X = np.array(X) # Set X as a numpy array\n        h = np.append(self.W, self.b) # Create a numpy array using the weights bias \n        s = (X * h[:-1]).sum(axis=1) + h[-1] # Sum of weights array multiplied by X array and add the bias\n        return s\n\n    def predict_with_(self, X):\n        # Function used for viualisation of the decision boundary\n        X = np.array(X) # Set X as a numpy array\n        h = np.append(self.W, self.b) # Create a numpy array using the weights bias\n        return (self.compute_linear_score_with_(X) > 0).astype(int)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:40.315758Z","iopub.execute_input":"2021-07-14T12:08:40.316052Z","iopub.status.idle":"2021-07-14T12:08:40.332742Z","shell.execute_reply.started":"2021-07-14T12:08:40.316022Z","shell.execute_reply":"2021-07-14T12:08:40.331774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualisation of decision boandary. Adapted from the Code Exercise 4 from the course material.","metadata":{}},{"cell_type":"code","source":"def viz_hypo(pred_func, X_samples, y_samples, correct, incorrect):\n    \"\"\"\n    X_samples is to provide a range\n    \"\"\"\n    #  Visualisation of the model behaviour\n    x0_min, x1_min = np.min(X_samples, axis=0)\n    x0_max, x1_max = np.max(X_samples, axis=0)\n\n    xx, yy = np.meshgrid(np.arange(x0_min - 0.1, x0_max + 0.1, 0.02),\n                        np.arange(x1_min - 0.1, x1_max + 0.1, 0.02))\n    \n    grid_coord = np.stack((xx.flatten(), yy.flatten())).T\n    zz = pred_func(grid_coord).reshape(xx.shape)\n\n    fig, ax = plt.subplots(constrained_layout=True)\n\n    C = ax.contourf(xx, yy, zz, cmap='Pastel1') \n    C2 = ax.contour(xx, yy, zz, colors=('k', ), linewidths=2)\n    ax.clabel(C2, inline=True, fontsize=10)\n\n    # Use masks to subset X_samples into a correctly classified and misclassified datasets\n    X_samples1 = X_samples[correct]\n    X_samples2 = X_samples[incorrect]\n\n    # Add the samples to the plot as a scatter\n    ax.scatter(x=np.array(X_samples1)[:,0], y=np.array(X_samples1)[:,1], c='g', alpha=0.5, marker='o', edgecolor='k', label='correctly classified')\n    ax.scatter(x=np.array(X_samples2)[:,0], y=np.array(X_samples2)[:,1], c='r', alpha=0.5, marker='x', label='misclassified')\n\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:40.333813Z","iopub.execute_input":"2021-07-14T12:08:40.334093Z","iopub.status.idle":"2021-07-14T12:08:40.349485Z","shell.execute_reply.started":"2021-07-14T12:08:40.334067Z","shell.execute_reply":"2021-07-14T12:08:40.348419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run the Perceptron on the Heart Disease dataset","metadata":{}},{"cell_type":"code","source":"def perceptron_pipeline(X,y):\n    '''\n    Pipeline for Percepton model\n    '''\n    # Initiate the model\n    my_model = MyPerceptron(n_dimensions=X.shape[1])\n\n    # Split the data into training and validation set\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\n    # Fit the model to the training data\n    my_model.fit(X_train, y_train)\n\n    # Predict with the validation data\n    pred = my_model.predict(X_valid)\n\n    # Compute the accuracy of the prediction\n    accu = np.sum(pred==y_valid) / len(y_valid)\n\n    weights = my_model.W\n    bias = my_model.b\n    training_accu = my_model.best_corr\n\n    return weights, bias, accu, training_accu","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:40.350781Z","iopub.execute_input":"2021-07-14T12:08:40.351063Z","iopub.status.idle":"2021-07-14T12:08:40.365556Z","shell.execute_reply.started":"2021-07-14T12:08:40.351036Z","shell.execute_reply":"2021-07-14T12:08:40.364513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the different iterations of feature pairs as the X variable\nX1 = df1[['thalach','chol']].copy() # From the scatter plots\nX2 = df1[['thalach','age']].copy() # From the scatter plots\nX3 = df1[['thalach','oldpeak']].copy() # From the scatter plots\nX4 = df1[['oldpeak','chol']].copy() # From the scatter plots\nX5 = df1[['trestbps','thalach']].copy() # From the scatter plots\nX6 = df1[['chol','age']].copy() # From the scatter plots\nX_top = df1[['thal','cp']].copy() # From the feature importance plot","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:40.366856Z","iopub.execute_input":"2021-07-14T12:08:40.367128Z","iopub.status.idle":"2021-07-14T12:08:40.382515Z","shell.execute_reply.started":"2021-07-14T12:08:40.367102Z","shell.execute_reply":"2021-07-14T12:08:40.381826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the y variable from the target column \ndf1.loc[df1['target']==0,'target'] = -1 # Change the zero values to -1 so we can use misclassified points to adjust the weights and bias\ny = df1['target'] # Set the target column as y","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:40.383735Z","iopub.execute_input":"2021-07-14T12:08:40.384158Z","iopub.status.idle":"2021-07-14T12:08:40.400492Z","shell.execute_reply.started":"2021-07-14T12:08:40.384113Z","shell.execute_reply":"2021-07-14T12:08:40.399302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dictionary of the X variables\nX_dict = {'X1':X1, 'X2':X2, 'X3':X3, 'X4':X4, 'X5':X5, 'X6':X6, 'X_top':X_top}","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:40.402345Z","iopub.execute_input":"2021-07-14T12:08:40.402788Z","iopub.status.idle":"2021-07-14T12:08:40.410831Z","shell.execute_reply.started":"2021-07-14T12:08:40.402746Z","shell.execute_reply":"2021-07-14T12:08:40.409797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create empty lists for training and validation accuracy scores to be used for plotting\nX_list = []\ntrain_accu = []\nvalid_accu = []","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:40.412344Z","iopub.execute_input":"2021-07-14T12:08:40.412797Z","iopub.status.idle":"2021-07-14T12:08:40.421546Z","shell.execute_reply.started":"2021-07-14T12:08:40.412767Z","shell.execute_reply":"2021-07-14T12:08:40.420428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loop through the dictionary running the Perceptron pipeline\nfor X_key, X_value in X_dict.items():\n\n    # Run the Perceptron pipeline\n    weights, bias, accu, training_accu = perceptron_pipeline(X_value,y)\n\n    # Add the training and validation accuracy to the lists\n    X_list.append(X_key)\n    train_accu.append(training_accu)\n    valid_accu.append(accu)\n\n    print(f'X variable: {X_key} - Training accuracy: {training_accu}, Validation accuracy: {accu}')\n    print(f'Perceptron Equation: ({weights[0]} x x1) + ({weights[1]} x x2) + {bias}')\n    print('\\n')","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:40.423695Z","iopub.execute_input":"2021-07-14T12:08:40.424215Z","iopub.status.idle":"2021-07-14T12:08:40.723394Z","shell.execute_reply.started":"2021-07-14T12:08:40.424083Z","shell.execute_reply":"2021-07-14T12:08:40.722422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dataframe from the training and validation scores\naccu_df = pd.DataFrame(list(zip(train_accu, valid_accu)), index=X_list, columns=['Train', 'Validation'])\n\n# Plot the accuracy datafram\naccu_df.plot()\nplt.title('Training vs Validation scores by X')\nplt.xlabel('X')\nplt.ylabel('Accuracy %');","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:40.724837Z","iopub.execute_input":"2021-07-14T12:08:40.725136Z","iopub.status.idle":"2021-07-14T12:08:41.020103Z","shell.execute_reply.started":"2021-07-14T12:08:40.725107Z","shell.execute_reply":"2021-07-14T12:08:41.019144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"X2 and X5 have identical training and validation accuracy so I will plot the decision boandary for X2","metadata":{}},{"cell_type":"code","source":"# Split X and y into training and validation data\nX_train, X_valid, y_train, y_valid = train_test_split(X2, y, test_size=0.2, stratify=y, random_state=42)\n\n# Initiate the model\nmy_model = MyPerceptron()\n\n# Fit the model to the training data\nmy_model.fit(X_train, y_train)\n\n# Create masks for correctly and incorrectly classified data points\npred = my_model.predict(X_train)\ncorrect = pred==y_train\nincorrect = pred!=y_train\n\n# Visualise the decision boundary\nviz_hypo(my_model.predict_with_, X_train, y_train, correct, incorrect)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:41.021375Z","iopub.execute_input":"2021-07-14T12:08:41.02169Z","iopub.status.idle":"2021-07-14T12:08:45.914062Z","shell.execute_reply.started":"2021-07-14T12:08:41.021659Z","shell.execute_reply":"2021-07-14T12:08:45.913026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test the same X values against the standard scikit-learn Perceptron model","metadata":{}},{"cell_type":"code","source":"# Import the Percepton\nfrom sklearn.linear_model import Perceptron\n\n# Initiate the model\nclf = Perceptron()\n\n# Loop through the dictionary of X pairings\nfor X_key, X_value in X_dict.items():\n\n    # Split X and y into training and validation data\n    X_train, X_valid, y_train, y_valid = train_test_split(X_value, y, test_size=0.2, stratify=y, random_state=42)\n\n    # Fit the training data to the model\n    clf.fit(X_train, y_train)\n\n    # Print the accuracy scores\n    print(f'X variable: {X_key} - Training score: {clf.score(X_train, y_train)}, validation score: {clf.score(X_valid, y_valid)}')","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:45.915347Z","iopub.execute_input":"2021-07-14T12:08:45.915673Z","iopub.status.idle":"2021-07-14T12:08:46.112888Z","shell.execute_reply.started":"2021-07-14T12:08:45.915641Z","shell.execute_reply":"2021-07-14T12:08:46.111742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Run the Perceptrons using all attributes for X","metadata":{}},{"cell_type":"code","source":"# Create an X_all by dropping target from the dataframe\nX_all = df1.drop('target', axis=1)\n\n# Split X_all and y into training and validation data\nX_all_train, X_all_valid, y_all_train, y_all_valid = train_test_split(X_all, y, test_size=0.2, stratify=y, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:46.114534Z","iopub.execute_input":"2021-07-14T12:08:46.114964Z","iopub.status.idle":"2021-07-14T12:08:46.124897Z","shell.execute_reply.started":"2021-07-14T12:08:46.114913Z","shell.execute_reply":"2021-07-14T12:08:46.123361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run the data through the scikit-learn Perceptron\n# Initiate the model\nclf = Perceptron()\n\n# Fit the training data to the model\nclf.fit(X_all_train, y_all_train)\n\n# Return the training and validation accuracy\nclf.score(X_all_train, y_all_train), clf.score(X_all_valid, y_all_valid)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:46.132073Z","iopub.execute_input":"2021-07-14T12:08:46.132395Z","iopub.status.idle":"2021-07-14T12:08:46.14846Z","shell.execute_reply.started":"2021-07-14T12:08:46.132368Z","shell.execute_reply":"2021-07-14T12:08:46.14776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initiate the model\nmy_model_all = MyPerceptron(n_dimensions=X_all_train.shape[1])\n\n# Fit the training data to the model\nmy_model_all.fit(X_all_train, y_all_train)\n\n# Predict y using the X validation data\npred_valid = my_model_all.predict(X_all_valid)\n\n# Return the training and validation accuracy\nmy_model_all.best_corr, np.sum(pred_valid==y_all_valid) / len(y_all_valid)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:46.151199Z","iopub.execute_input":"2021-07-14T12:08:46.15172Z","iopub.status.idle":"2021-07-14T12:08:46.204463Z","shell.execute_reply.started":"2021-07-14T12:08:46.151687Z","shell.execute_reply":"2021-07-14T12:08:46.203475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Return the weights and bias for my Perceptron model\nmy_model_all.best_params","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:46.20593Z","iopub.execute_input":"2021-07-14T12:08:46.206242Z","iopub.status.idle":"2021-07-14T12:08:46.213288Z","shell.execute_reply.started":"2021-07-14T12:08:46.206213Z","shell.execute_reply":"2021-07-14T12:08:46.212066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create the Decision Tree\nCode adapted from [Let’s Write a Decision Tree Classifier from Scratch - Machine Learning Recipes #8](https://www.youtube.com/watch?v=LDRbO9a6XPU)","metadata":{}},{"cell_type":"code","source":"def unique_vals(rows, col):\n    \"\"\"Find the unique values for a column in a dataset.\"\"\"\n    return set([row[col] for row in rows])","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:46.214808Z","iopub.execute_input":"2021-07-14T12:08:46.215091Z","iopub.status.idle":"2021-07-14T12:08:46.224459Z","shell.execute_reply.started":"2021-07-14T12:08:46.215063Z","shell.execute_reply":"2021-07-14T12:08:46.223334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def class_counts(rows):\n    \"\"\"Counts the number of each type of example in a dataset.\"\"\"\n    counts = {}  # a dictionary of label -> count.\n    for row in rows:\n        # in our dataset format, the label is always the last column\n        label = row[-1]\n        if label not in counts:\n            counts[label] = 0\n        counts[label] += 1\n    return counts","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:46.226092Z","iopub.execute_input":"2021-07-14T12:08:46.226423Z","iopub.status.idle":"2021-07-14T12:08:46.236221Z","shell.execute_reply.started":"2021-07-14T12:08:46.226394Z","shell.execute_reply":"2021-07-14T12:08:46.235135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def is_numeric(value):\n    \"\"\"Test if a value is numeric.\"\"\"\n    return isinstance(value, int) or isinstance(value, float)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:46.23753Z","iopub.execute_input":"2021-07-14T12:08:46.237871Z","iopub.status.idle":"2021-07-14T12:08:46.246037Z","shell.execute_reply.started":"2021-07-14T12:08:46.237842Z","shell.execute_reply":"2021-07-14T12:08:46.244981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Question:\n    \"\"\"A Question is used to partition a dataset.\n\n    This class just records a 'column number' (e.g., 0 for Color) and a\n    'column value' (e.g., Green). The 'match' method is used to compare\n    the feature value in an example to the feature value stored in the\n    question. See the demo below.\n    \"\"\"\n\n    def __init__(self, column, value):\n        self.column = column\n        self.value = value\n\n    def match(self, example):\n        # Compare the feature value in an example to the\n        # feature value in this question.\n        val = example[self.column]\n        if is_numeric(val):\n            return val >= self.value\n        else:\n            return val == self.value\n\n    def __repr__(self):\n        # This is just a helper method to print\n        # the question in a readable format.\n        condition = \"==\"\n        if is_numeric(self.value):\n            condition = \">=\"\n        return \"Is %s %s %s?\" % (\n            header[self.column], condition, str(self.value))","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:46.247671Z","iopub.execute_input":"2021-07-14T12:08:46.248011Z","iopub.status.idle":"2021-07-14T12:08:46.257927Z","shell.execute_reply.started":"2021-07-14T12:08:46.247978Z","shell.execute_reply":"2021-07-14T12:08:46.25685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def partition(rows, question):\n    \"\"\"Partitions a dataset.\n\n    For each row in the dataset, check if it matches the question. If\n    so, add it to 'true rows', otherwise, add it to 'false rows'.\n    \"\"\"\n    true_rows, false_rows = [], []\n    for row in rows:\n        if question.match(row):\n            true_rows.append(row)\n        else:\n            false_rows.append(row)\n    return true_rows, false_rows","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:46.259324Z","iopub.execute_input":"2021-07-14T12:08:46.25966Z","iopub.status.idle":"2021-07-14T12:08:46.273164Z","shell.execute_reply.started":"2021-07-14T12:08:46.25963Z","shell.execute_reply":"2021-07-14T12:08:46.27234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gini(rows):\n    \"\"\"Calculate the Gini Impurity for a list of rows.\n\n    There are a few different ways to do this, I thought this one was\n    the most concise. See:\n    https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity\n    \"\"\"\n    counts = class_counts(rows)\n    impurity = 1\n    for lbl in counts:\n        prob_of_lbl = counts[lbl] / float(len(rows))\n        impurity -= prob_of_lbl**2\n    return impurity","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:46.274279Z","iopub.execute_input":"2021-07-14T12:08:46.274695Z","iopub.status.idle":"2021-07-14T12:08:46.284327Z","shell.execute_reply.started":"2021-07-14T12:08:46.274663Z","shell.execute_reply":"2021-07-14T12:08:46.283635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def info_gain(left, right, current_uncertainty):\n    \"\"\"Information Gain.\n\n    The uncertainty of the starting node, minus the weighted impurity of\n    two child nodes.\n    \"\"\"\n    p = float(len(left)) / (len(left) + len(right))\n    return current_uncertainty - p * gini(left) - (1 - p) * gini(right)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:46.285338Z","iopub.execute_input":"2021-07-14T12:08:46.285726Z","iopub.status.idle":"2021-07-14T12:08:46.297475Z","shell.execute_reply.started":"2021-07-14T12:08:46.285696Z","shell.execute_reply":"2021-07-14T12:08:46.296498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_best_split(rows, threshold=0):\n    \"\"\"Find the best question to ask by iterating over every feature / value\n    and calculating the information gain.\"\"\"\n    best_gain = 0  # keep track of the best information gain\n    best_question = None  # keep train of the feature / value that produced it\n    current_uncertainty = gini(rows)\n    n_features = len(rows[0]) - 1  # number of columns\n\n    for col in range(n_features):  # for each feature\n\n        values = set([row[col] for row in rows])  # unique values in the column\n\n        for val in values:  # for each value\n\n            question = Question(col, val)\n\n            # try splitting the dataset\n            true_rows, false_rows = partition(rows, question)\n\n            # Skip this split if it doesn't divide the\n            # dataset.\n            if len(true_rows) == 0 or len(false_rows) == 0:\n                continue\n\n            # Calculate the information gain from this split\n            gain = info_gain(true_rows, false_rows, current_uncertainty)\n\n            # You actually can use '>' instead of '>=' here\n            # but I wanted the tree to look a certain way for our\n            # toy dataset.\n            if gain > best_gain + threshold:\n                best_gain, best_question = gain, question\n\n    return best_gain, best_question","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:46.298544Z","iopub.execute_input":"2021-07-14T12:08:46.298835Z","iopub.status.idle":"2021-07-14T12:08:46.313395Z","shell.execute_reply.started":"2021-07-14T12:08:46.298808Z","shell.execute_reply":"2021-07-14T12:08:46.312672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Leaf:\n    \"\"\"A Leaf node classifies data.\n\n    This holds a dictionary of class (e.g., \"Apple\") -> number of times\n    it appears in the rows from the training data that reach this leaf.\n    \"\"\"\n\n    def __init__(self, rows):\n        self.predictions = class_counts(rows)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:46.314769Z","iopub.execute_input":"2021-07-14T12:08:46.315241Z","iopub.status.idle":"2021-07-14T12:08:46.324945Z","shell.execute_reply.started":"2021-07-14T12:08:46.31521Z","shell.execute_reply":"2021-07-14T12:08:46.324225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Decision_Node:\n    \"\"\"A Decision Node asks a question.\n\n    This holds a reference to the question, and to the two child nodes.\n    \"\"\"\n\n    def __init__(self,\n                 question,\n                 true_branch,\n                 false_branch):\n        self.question = question\n        self.true_branch = true_branch\n        self.false_branch = false_branch","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:46.326271Z","iopub.execute_input":"2021-07-14T12:08:46.326764Z","iopub.status.idle":"2021-07-14T12:08:46.336264Z","shell.execute_reply.started":"2021-07-14T12:08:46.326731Z","shell.execute_reply":"2021-07-14T12:08:46.335211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_tree(rows, threshold):\n    \"\"\"Builds the tree.\n\n    Rules of recursion: 1) Believe that it works. 2) Start by checking\n    for the base case (no further information gain). 3) Prepare for\n    giant stack traces.\n    \"\"\"\n\n    # Try partitioing the dataset on each of the unique attribute,\n    # calculate the information gain,\n    # and return the question that produces the highest gain.\n    gain, question = find_best_split(rows, threshold)\n\n    # Base case: no further info gain\n    # Since we can ask no further questions,\n    # we'll return a leaf.\n    if gain == 0:\n        return Leaf(rows)\n\n    # If we reach here, we have found a useful feature / value\n    # to partition on.\n    true_rows, false_rows = partition(rows, question)\n\n    # Recursively build the true branch.\n    true_branch = build_tree(true_rows, threshold)\n\n    # Recursively build the false branch.\n    false_branch = build_tree(false_rows, threshold)\n\n    # Return a Question node.\n    # This records the best feature / value to ask at this point,\n    # as well as the branches to follow\n    # dependingo on the answer.\n    return Decision_Node(question, true_branch, false_branch)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:46.337748Z","iopub.execute_input":"2021-07-14T12:08:46.338048Z","iopub.status.idle":"2021-07-14T12:08:46.351356Z","shell.execute_reply.started":"2021-07-14T12:08:46.338015Z","shell.execute_reply":"2021-07-14T12:08:46.35028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_tree(node, spacing=\"\"):\n    \"\"\"World's most elegant tree printing function.\"\"\"\n\n    # Base case: we've reached a leaf\n    if isinstance(node, Leaf):\n        print (spacing + \"Predict\", node.predictions)\n        return\n\n    # Print the question at this node\n    print (spacing + str(node.question))\n\n    # Call this function recursively on the true branch\n    print (spacing + '--> True:')\n    print_tree(node.true_branch, spacing + \"  \")\n\n    # Call this function recursively on the false branch\n    print (spacing + '--> False:')\n    print_tree(node.false_branch, spacing + \"  \")","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:46.35304Z","iopub.execute_input":"2021-07-14T12:08:46.353717Z","iopub.status.idle":"2021-07-14T12:08:46.361858Z","shell.execute_reply.started":"2021-07-14T12:08:46.353624Z","shell.execute_reply":"2021-07-14T12:08:46.360837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def classify(row, node):\n    \"\"\"See the 'rules of recursion' above.\"\"\"\n\n    # Base case: we've reached a leaf\n    if isinstance(node, Leaf):\n        return node.predictions\n\n    # Decide whether to follow the true-branch or the false-branch.\n    # Compare the feature / value stored in the node,\n    # to the example we're considering.\n    if node.question.match(row):\n        return classify(row, node.true_branch)\n    else:\n        return classify(row, node.false_branch)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:46.363053Z","iopub.execute_input":"2021-07-14T12:08:46.363501Z","iopub.status.idle":"2021-07-14T12:08:46.375231Z","shell.execute_reply.started":"2021-07-14T12:08:46.36345Z","shell.execute_reply":"2021-07-14T12:08:46.37439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_leaf(counts):\n    \"\"\"A nicer way to print the predictions at a leaf.\"\"\"\n    total = sum(counts.values()) * 1.0\n    probs = {}\n    for lbl in counts.keys():\n        probs[lbl] = str(int(counts[lbl] / total * 100)) + \"%\"\n    return probs","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:46.376654Z","iopub.execute_input":"2021-07-14T12:08:46.377174Z","iopub.status.idle":"2021-07-14T12:08:46.385655Z","shell.execute_reply.started":"2021-07-14T12:08:46.377138Z","shell.execute_reply":"2021-07-14T12:08:46.384892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tree_predict(data, tree):\n    '''\n    Predict target using the Decision Tree\n    '''\n\n    # Create empty lists for prediction and actual\n    pred = []\n    actual = []\n\n    # Loop through the data and append to the actual and predition list \n    for row in data:\n        pred.append(list(classify(row, tree).keys())[0])\n        actual.append(row[-1])\n\n    return actual, pred","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:46.386927Z","iopub.execute_input":"2021-07-14T12:08:46.387547Z","iopub.status.idle":"2021-07-14T12:08:46.395522Z","shell.execute_reply.started":"2021-07-14T12:08:46.387453Z","shell.execute_reply":"2021-07-14T12:08:46.39485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tree_accuracy(actual, pred):\n    '''\n    Return the accuracy of the Decision Tree\n    '''\n\n    # Compare each item in the list\n    accu = [1 if p==a else 0 for p,a in zip(pred, actual)]\n\n    return np.sum(accu) / len(accu)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:46.396759Z","iopub.execute_input":"2021-07-14T12:08:46.397278Z","iopub.status.idle":"2021-07-14T12:08:46.40632Z","shell.execute_reply.started":"2021-07-14T12:08:46.397245Z","shell.execute_reply":"2021-07-14T12:08:46.405392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run the Decision Tree on the Heart Disease dataset","metadata":{}},{"cell_type":"code","source":"def prepare_tree_data(df, target):\n    '''\n    Function to prepare the data for use in the Decision Tree\n    '''\n\n    # Create the X and y values for splitting into training and validation set\n    X = df.copy()\n    y = df[target].copy()\n\n    # Split the data into 80% training and 20% validation stratifying the data using y\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\n    # Create a list of lists of the training and validation_data for use in the Decision Tree\n    training_data = X_train.values.tolist()\n    validation_data = X_valid.values.tolist()\n\n    # Create headers using the columns\n    header = df.columns\n\n    return training_data, validation_data, header","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:46.407805Z","iopub.execute_input":"2021-07-14T12:08:46.40817Z","iopub.status.idle":"2021-07-14T12:08:46.416971Z","shell.execute_reply.started":"2021-07-14T12:08:46.408135Z","shell.execute_reply":"2021-07-14T12:08:46.416249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare the data from df1 for use in the Decision Tree\ntraining_data, validation_data, header = prepare_tree_data(df1, 'target')","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:46.418125Z","iopub.execute_input":"2021-07-14T12:08:46.418455Z","iopub.status.idle":"2021-07-14T12:08:46.437199Z","shell.execute_reply.started":"2021-07-14T12:08:46.418425Z","shell.execute_reply":"2021-07-14T12:08:46.435626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run the Decsion Tree for different thresholds to pre-prune tree\n\n# Set the empty lists\ntrain_accu = []\nvalid_accu = []\nthold = []\n\n# Loop through the different thresholds\nfor threshold in np.linspace(0,0.1,num=500, endpoint=True):\n    # Build the Decision Tree\n    my_tree = build_tree(training_data,threshold)\n\n    # Compute the Decision Tree Accuracy\n    train_actual, train_pred = tree_predict(training_data, my_tree)\n    valid_actual, valid_pred = tree_predict(validation_data, my_tree)\n\n    # Add the accuracy to the list\n    train_accu.append(tree_accuracy(train_actual, train_pred))\n    valid_accu.append(tree_accuracy(valid_actual, valid_pred))\n    thold.append(threshold)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:08:46.438685Z","iopub.execute_input":"2021-07-14T12:08:46.439006Z","iopub.status.idle":"2021-07-14T12:11:03.84534Z","shell.execute_reply.started":"2021-07-14T12:08:46.438974Z","shell.execute_reply":"2021-07-14T12:11:03.844486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dataframe from the training and validation scores\naccu_df_heart = pd.DataFrame(list(zip(train_accu, valid_accu)), index=thold, columns=['Training','Validation'])\n\n# Plot the accuracy datafram\naccu_df_heart.plot()\nplt.title('Training & Validation Accuracy scores by Threshold')\nplt.xlabel('Threshold')\nplt.ylabel('Accuracy %');","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:03.846507Z","iopub.execute_input":"2021-07-14T12:11:03.846927Z","iopub.status.idle":"2021-07-14T12:11:04.174657Z","shell.execute_reply.started":"2021-07-14T12:11:03.846895Z","shell.execute_reply":"2021-07-14T12:11:04.173934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the threshold for the most accurate tree\naccu_df_heart['difference'] = abs(accu_df_heart['Training'] - accu_df_heart['Validation'])\naccu_df_heart = accu_df_heart[accu_df_heart['Validation']>0.75].copy()\nbest_threshold = accu_df_heart[['difference']].idxmin()[0]\nprint(f'Most accurate threshold: {best_threshold}')","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:04.17572Z","iopub.execute_input":"2021-07-14T12:11:04.1761Z","iopub.status.idle":"2021-07-14T12:11:04.187212Z","shell.execute_reply.started":"2021-07-14T12:11:04.176071Z","shell.execute_reply":"2021-07-14T12:11:04.186118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build the Decsion Tree with the best threshold\nmy_tree = build_tree(training_data,best_threshold)\n\n# Compute the Decision Tree Accuracy\ntrain_actual, train_pred = tree_predict(training_data, my_tree)\nvalid_actual, valid_pred = tree_predict(validation_data, my_tree)\ntree_accuracy(train_actual, train_pred), tree_accuracy(valid_actual, valid_pred)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:04.188397Z","iopub.execute_input":"2021-07-14T12:11:04.188846Z","iopub.status.idle":"2021-07-14T12:11:04.44149Z","shell.execute_reply.started":"2021-07-14T12:11:04.188809Z","shell.execute_reply":"2021-07-14T12:11:04.440327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the Decision Tree\nprint_tree(my_tree)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:04.443177Z","iopub.execute_input":"2021-07-14T12:11:04.443659Z","iopub.status.idle":"2021-07-14T12:11:04.456745Z","shell.execute_reply.started":"2021-07-14T12:11:04.443611Z","shell.execute_reply":"2021-07-14T12:11:04.454409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test the dataset against the standard scikit-learn Decision Tree model","metadata":{}},{"cell_type":"code","source":"# Compare results with the standard libary from scikit-learn\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Create the X and y values for splitting into training and validation set\nX = df1.drop('target', axis=1).copy()\ny = df1['target'].copy()\n\n # Split the data into 80% training and 20% validation stratifying the data using y\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\n# Initiate the Decision Tree\nt = DecisionTreeClassifier()\n\n# Fit the model to the data\nt.fit(X_train, y_train)\n\n# Calculate the tree accuracy on the training and validation data\nt.score(X_train, y_train), t.score(X_valid, y_valid)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:04.459878Z","iopub.execute_input":"2021-07-14T12:11:04.460362Z","iopub.status.idle":"2021-07-14T12:11:04.486308Z","shell.execute_reply.started":"2021-07-14T12:11:04.460316Z","shell.execute_reply":"2021-07-14T12:11:04.485501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import tree to print the scikit-learn tree\nfrom sklearn import tree\n\n# Initiate the DT Classifier\nclf = tree.DecisionTreeClassifier()\n\n# Fit the tree to the data\nclf = clf.fit(X_train, y_train)\n\n# Print the tree\ntree.plot_tree(clf) ","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:04.487266Z","iopub.execute_input":"2021-07-14T12:11:04.487516Z","iopub.status.idle":"2021-07-14T12:11:10.106891Z","shell.execute_reply.started":"2021-07-14T12:11:04.48749Z","shell.execute_reply":"2021-07-14T12:11:10.10568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# View the Absenteeism at work dataset","metadata":{}},{"cell_type":"code","source":"# Data Exploration of the Absenteeism dataset\n# What's the structure and the descriptive statistics for the input file\ndf2.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:10.108613Z","iopub.execute_input":"2021-07-14T12:11:10.109023Z","iopub.status.idle":"2021-07-14T12:11:10.129309Z","shell.execute_reply.started":"2021-07-14T12:11:10.10898Z","shell.execute_reply":"2021-07-14T12:11:10.128159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:10.131069Z","iopub.execute_input":"2021-07-14T12:11:10.131513Z","iopub.status.idle":"2021-07-14T12:11:10.150336Z","shell.execute_reply.started":"2021-07-14T12:11:10.131468Z","shell.execute_reply":"2021-07-14T12:11:10.149135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.describe().T","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:10.151525Z","iopub.execute_input":"2021-07-14T12:11:10.15187Z","iopub.status.idle":"2021-07-14T12:11:10.221885Z","shell.execute_reply.started":"2021-07-14T12:11:10.151839Z","shell.execute_reply":"2021-07-14T12:11:10.220698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the distribution of the target values of dataset\nfig, ax = plt.subplots(figsize=(6,4))\n\nn_bins = round(1 + (3.322 * np.log(len(df2['Absenteeism time in hours']))))\n\nax.hist(df2['Absenteeism time in hours'], bins=n_bins)\nax.set_title('Absenteeism at work Target Distrbution')\nax.set_xlabel('Target (hrs)')\nax.set_ylabel('Count');","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:10.223181Z","iopub.execute_input":"2021-07-14T12:11:10.223468Z","iopub.status.idle":"2021-07-14T12:11:10.493836Z","shell.execute_reply.started":"2021-07-14T12:11:10.223441Z","shell.execute_reply":"2021-07-14T12:11:10.492394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a histogram of a subset of the Absenteeism at work target variable\nsubset_df2 = df2[df2['Absenteeism time in hours'] < 20]\nsubset_df2['Absenteeism time in hours'].hist()\nplt.title('Absenteeism at work Target < 20 hrs Distrbution')\nplt.xlabel('Target (hrs)')\nplt.ylabel('Count');","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:10.4951Z","iopub.execute_input":"2021-07-14T12:11:10.495361Z","iopub.status.idle":"2021-07-14T12:11:10.795245Z","shell.execute_reply.started":"2021-07-14T12:11:10.495335Z","shell.execute_reply":"2021-07-14T12:11:10.794163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Change the target variable in the Absenteeism at work dataset from a continuous variable to a binary classification\nbin_names = [0,1]\nranges = [-np.inf,7.99,np.inf] # using the split found in the histogram\ndf2['target'] = pd.cut(df2['Absenteeism time in hours'], bins=ranges, labels=bin_names)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:10.796557Z","iopub.execute_input":"2021-07-14T12:11:10.796861Z","iopub.status.idle":"2021-07-14T12:11:10.804903Z","shell.execute_reply.started":"2021-07-14T12:11:10.796833Z","shell.execute_reply":"2021-07-14T12:11:10.80382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove columns not required\ndf2.drop(columns=['ID','Absenteeism time in hours'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:10.806081Z","iopub.execute_input":"2021-07-14T12:11:10.806347Z","iopub.status.idle":"2021-07-14T12:11:10.818421Z","shell.execute_reply.started":"2021-07-14T12:11:10.806321Z","shell.execute_reply":"2021-07-14T12:11:10.817428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the predictive power score (pps) of the features\neda_numcat(df2, method='pps', x='target')","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:10.819755Z","iopub.execute_input":"2021-07-14T12:11:10.820079Z","iopub.status.idle":"2021-07-14T12:11:12.028537Z","shell.execute_reply.started":"2021-07-14T12:11:10.820051Z","shell.execute_reply":"2021-07-14T12:11:12.027383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2['target'] = df2['target'].astype('int')","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:12.030271Z","iopub.execute_input":"2021-07-14T12:11:12.030739Z","iopub.status.idle":"2021-07-14T12:11:12.037069Z","shell.execute_reply.started":"2021-07-14T12:11:12.030694Z","shell.execute_reply":"2021-07-14T12:11:12.036114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Understand the baseline of the target attribute of the Absenteeism at work dataset\ndf2['target'].value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:12.038517Z","iopub.execute_input":"2021-07-14T12:11:12.03911Z","iopub.status.idle":"2021-07-14T12:11:12.055533Z","shell.execute_reply.started":"2021-07-14T12:11:12.039067Z","shell.execute_reply":"2021-07-14T12:11:12.054546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create separate dataframes for discrete and continuous variables\ndiscrete_df = df2[['Reason for absence', 'Month of absence', 'Day of the week', 'Seasons','Work load Average/day ', 'Hit target',\n                   'Disciplinary failure', 'Education', 'Son', 'Social drinker','Social smoker', 'Pet', 'target']].copy()\ncontinuous_df = df2[['Transportation expense', 'Distance from Residence to Work','Service time', 'Age',\n                     'Weight', 'Height', 'Body mass index', 'target']].copy()","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:12.057294Z","iopub.execute_input":"2021-07-14T12:11:12.057672Z","iopub.status.idle":"2021-07-14T12:11:12.06614Z","shell.execute_reply.started":"2021-07-14T12:11:12.057641Z","shell.execute_reply":"2021-07-14T12:11:12.065384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a pairplot for the continuous variables to understand the relationship between the variables\nsns.pairplot(continuous_df, hue='target', diag_kind='hist', corner=True, plot_kws={'alpha': 0.2});","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:12.067288Z","iopub.execute_input":"2021-07-14T12:11:12.067745Z","iopub.status.idle":"2021-07-14T12:11:22.191356Z","shell.execute_reply.started":"2021-07-14T12:11:12.067706Z","shell.execute_reply":"2021-07-14T12:11:22.19036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discrete_hist(row, col, column_name):\n    '''\n    Function to plot histogram as a subplot\n    '''\n    # Add distribution of the attribute where target = 1\n    ax[row][col].hist(discrete_df[discrete_df.target == 1][column_name], color='r', alpha=0.5, label='1')\n\n    # Add distribution of the attribute where target = 0\n    ax[row][col].hist(discrete_df[discrete_df.target == 0][column_name], color='b', alpha=0.5, label='0')\n\n    # Set title and axis labels\n    ax[row][col].set_title(f'Distribution of {column_name}')\n    ax[row][col].set_xlabel(column_name)\n    ax[row][col].set_ylabel('count')\n\n    # Add legend\n    ax[row][col].legend()","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:22.19264Z","iopub.execute_input":"2021-07-14T12:11:22.192921Z","iopub.status.idle":"2021-07-14T12:11:22.200168Z","shell.execute_reply.started":"2021-07-14T12:11:22.192893Z","shell.execute_reply":"2021-07-14T12:11:22.199013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create histograms for the discrete attributes coloured by the target to identify any key splits\nfig, ax = plt.subplots(nrows=3, ncols=4, figsize=(16,8))\n\n# Run the histogram function for each variable\ndiscrete_hist(0,0,'Reason for absence')\ndiscrete_hist(0,1,'Month of absence')\ndiscrete_hist(0,2,'Day of the week')\ndiscrete_hist(0,3,'Seasons')\ndiscrete_hist(1,0,'Work load Average/day ')\ndiscrete_hist(1,1,'Hit target')\ndiscrete_hist(1,2,'Disciplinary failure')\ndiscrete_hist(1,3,'Education')\ndiscrete_hist(2,0,'Son')\ndiscrete_hist(2,1,'Social drinker')\ndiscrete_hist(2,2,'Social smoker')\ndiscrete_hist(2,3,'Pet')\n\nplt.tight_layout();","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:22.202039Z","iopub.execute_input":"2021-07-14T12:11:22.202672Z","iopub.status.idle":"2021-07-14T12:11:25.909042Z","shell.execute_reply.started":"2021-07-14T12:11:22.202615Z","shell.execute_reply":"2021-07-14T12:11:25.907823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**EDA Observations**\nThere doesn't appear to be any clear separations on the continuous attributes so the Perceptron may not be too accurate. I will use the attributes identified in the feature importance graph for the pairings here.\n\nLooking at the discrete attributes though there seems to be instances where there may be some information gain so a decision tree may fair well.","metadata":{}},{"cell_type":"markdown","source":"# Run the Perceptron on the Absenteeism at work dataset","metadata":{}},{"cell_type":"code","source":"# Create the different iterations of feature pairs as the X variable usinmg the feature importance plot\nX1 = df2[['Reason for absence','Service time']].copy()\nX2 = df2[['Reason for absence','Transportation expense']].copy()\nX3 = df2[['Reason for absence','Weight']].copy()\nX4 = df2[['Reason for absence','Distance from Residence to Work']].copy()\nX5 = df2[['Reason for absence','Age']].copy()\nX6 = df2[['Reason for absence','Son']].copy()\nX_all = df2.drop('target', axis=1).copy()","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:25.910544Z","iopub.execute_input":"2021-07-14T12:11:25.910872Z","iopub.status.idle":"2021-07-14T12:11:25.92382Z","shell.execute_reply.started":"2021-07-14T12:11:25.910843Z","shell.execute_reply":"2021-07-14T12:11:25.92253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the y variable from the target column \ndf2.loc[df2['target']==0,'target'] = -1 # Change the zero values to -1 so we can use misclassified points to adjust the weights and bias\ny = df2['target'] # Set the target column as y","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:25.925215Z","iopub.execute_input":"2021-07-14T12:11:25.925526Z","iopub.status.idle":"2021-07-14T12:11:25.940531Z","shell.execute_reply.started":"2021-07-14T12:11:25.925495Z","shell.execute_reply":"2021-07-14T12:11:25.93918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dictionary of the X variables\nX_dict = {'X1':X1, 'X2':X2, 'X3':X3, 'X4':X4, 'X5':X5, 'X6':X6, 'X_all':X_all}","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:25.94164Z","iopub.execute_input":"2021-07-14T12:11:25.941916Z","iopub.status.idle":"2021-07-14T12:11:25.953639Z","shell.execute_reply.started":"2021-07-14T12:11:25.941888Z","shell.execute_reply":"2021-07-14T12:11:25.952518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create empty lists for training and validation accuracy scores to be used for plotting\nX_list = []\ntrain_accu = []\nvalid_accu = []","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:25.955061Z","iopub.execute_input":"2021-07-14T12:11:25.955736Z","iopub.status.idle":"2021-07-14T12:11:25.971765Z","shell.execute_reply.started":"2021-07-14T12:11:25.955686Z","shell.execute_reply":"2021-07-14T12:11:25.970866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loop through the dictionary running the Perceptron pipeline\nfor X_key, X_value in X_dict.items():\n\n    # Run the Perceptron pipeline\n    weights, bias, accu, training_accu = perceptron_pipeline(X_value,y)\n\n    # Add the training and validation accuracy to the lists\n    X_list.append(X_key)\n    train_accu.append(training_accu)\n    valid_accu.append(accu)\n\n    print(f'X variable: {X_key} - Training accuracy: {training_accu}, Validation accuracy: {accu}')\n    print(f'Perceptron Equation: ({weights[0]} x x1) + ({weights[1]} x x2) + {bias}')\n    print('\\n')","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:25.972954Z","iopub.execute_input":"2021-07-14T12:11:25.973381Z","iopub.status.idle":"2021-07-14T12:11:26.334754Z","shell.execute_reply.started":"2021-07-14T12:11:25.97335Z","shell.execute_reply":"2021-07-14T12:11:26.333448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test the same X values against the standard scikit-learn Perceptron model","metadata":{}},{"cell_type":"code","source":"# Initiate the model\nclf = Perceptron()\n\n# Loop through the dictionary of X pairings\nfor X_key, X_value in X_dict.items():\n\n    # Split X and y into training and validation data\n    X_train, X_valid, y_train, y_valid = train_test_split(X_value, y, test_size=0.2, stratify=y, random_state=42)\n\n    # Fit the training data to the model\n    clf.fit(X_train, y_train)\n\n    # Print the accuracy scores\n    print(f'X variable: {X_key} - Training score: {clf.score(X_train, y_train)}, validation score{clf.score(X_valid, y_valid)}')","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:26.336228Z","iopub.execute_input":"2021-07-14T12:11:26.336511Z","iopub.status.idle":"2021-07-14T12:11:26.416835Z","shell.execute_reply.started":"2021-07-14T12:11:26.336483Z","shell.execute_reply":"2021-07-14T12:11:26.415469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dataframe from the training and validation scores\naccu_df = pd.DataFrame(list(zip(train_accu, valid_accu)), index=X_list, columns=['Train', 'Validation'])\n\n# Plot the accuracy datafram\naccu_df.plot()\nplt.title('Training vs Validation scores by X')\nplt.xlabel('X')\nplt.ylabel('Accuracy %');","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:26.418538Z","iopub.execute_input":"2021-07-14T12:11:26.418997Z","iopub.status.idle":"2021-07-14T12:11:26.748656Z","shell.execute_reply.started":"2021-07-14T12:11:26.418953Z","shell.execute_reply":"2021-07-14T12:11:26.74758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split X and y into training and validation data\nX_train, X_valid, y_train, y_valid = train_test_split(X3, y, test_size=0.2, stratify=y, random_state=42)\n\n# Initiate the model\nmy_model = MyPerceptron()\n\n# Fit the model to the training data\nmy_model.fit(X_train, y_train)\n\n# Create masks for correctly and incorrectly classified data points\npred = my_model.predict(X_train)\ncorrect = pred==y_train\nincorrect = pred!=y_train\n\n# Visualise the decision boundary\nviz_hypo(my_model.predict_with_, X_train, y_train, correct, incorrect)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:26.749911Z","iopub.execute_input":"2021-07-14T12:11:26.750188Z","iopub.status.idle":"2021-07-14T12:11:28.324431Z","shell.execute_reply.started":"2021-07-14T12:11:26.750162Z","shell.execute_reply":"2021-07-14T12:11:28.323321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run the Decision Tree on the Absenteeism at work dataset","metadata":{}},{"cell_type":"code","source":"# Prepare the data from df2 for use in the Decision Tree\ntraining_data, validation_data, header = prepare_tree_data(df2, 'target')","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:28.326788Z","iopub.execute_input":"2021-07-14T12:11:28.327239Z","iopub.status.idle":"2021-07-14T12:11:28.338582Z","shell.execute_reply.started":"2021-07-14T12:11:28.327178Z","shell.execute_reply":"2021-07-14T12:11:28.337513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run the Decsion Tree for different thresholds to pre-prune tree\n\n# Set the empty lists\ntrain_accu = []\nvalid_accu = []\nthold = []\n\n# Loop through the different thresholds\nfor threshold in np.linspace(0,0.1,num=500, endpoint=True):\n    # Build the Decision Tree\n    my_tree = build_tree(training_data,threshold)\n\n    # Compute the Decision Tree Accuracy\n    train_actual, train_pred = tree_predict(training_data, my_tree)\n    valid_actual, valid_pred = tree_predict(validation_data, my_tree)\n\n    # Add the accuracy to the list\n    train_accu.append(tree_accuracy(train_actual, train_pred))\n    valid_accu.append(tree_accuracy(valid_actual, valid_pred))\n    thold.append(threshold)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:11:28.340323Z","iopub.execute_input":"2021-07-14T12:11:28.340646Z","iopub.status.idle":"2021-07-14T12:16:16.458453Z","shell.execute_reply.started":"2021-07-14T12:11:28.340614Z","shell.execute_reply":"2021-07-14T12:16:16.457338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dataframe from the training and validation scores\naccu_df_work = pd.DataFrame(list(zip(train_accu, valid_accu)), index=thold, columns=['Training','Validation'])\n\n# Plot the accuracy datafram\naccu_df_work.plot()\nplt.title('Training & Validation Accuracy scores by Threshold')\nplt.xlabel('Threshold')\nplt.ylabel('Accuracy %');","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:16:16.460059Z","iopub.execute_input":"2021-07-14T12:16:16.460371Z","iopub.status.idle":"2021-07-14T12:16:16.788921Z","shell.execute_reply.started":"2021-07-14T12:16:16.460342Z","shell.execute_reply":"2021-07-14T12:16:16.787921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the threshold for the most accurate tree\naccu_df_work['difference'] = accu_df_work['Training'] - accu_df_work['Validation']\naccu_df_work = accu_df_work[accu_df_work['Validation'] > 0.8].copy()\nbest_threshold = accu_df_work[['difference']].idxmin()[0]\nprint(f'Most accurate threshold: {best_threshold}')","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:16:16.790506Z","iopub.execute_input":"2021-07-14T12:16:16.791094Z","iopub.status.idle":"2021-07-14T12:16:16.803846Z","shell.execute_reply.started":"2021-07-14T12:16:16.791048Z","shell.execute_reply":"2021-07-14T12:16:16.802527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build the Decsion Tree with the best threshold\nmy_tree = build_tree(training_data,best_threshold)\n\n# Compute the Decision Tree Accuracy\ntrain_actual, train_pred = tree_predict(training_data, my_tree)\nvalid_actual, valid_pred = tree_predict(validation_data, my_tree)\ntree_accuracy(train_actual, train_pred), tree_accuracy(valid_actual, valid_pred)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:16:16.811561Z","iopub.execute_input":"2021-07-14T12:16:16.811891Z","iopub.status.idle":"2021-07-14T12:16:17.359311Z","shell.execute_reply.started":"2021-07-14T12:16:16.811862Z","shell.execute_reply":"2021-07-14T12:16:17.358226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the Decision Tree\nprint_tree(my_tree)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:16:17.36106Z","iopub.execute_input":"2021-07-14T12:16:17.361345Z","iopub.status.idle":"2021-07-14T12:16:17.370223Z","shell.execute_reply.started":"2021-07-14T12:16:17.361318Z","shell.execute_reply":"2021-07-14T12:16:17.368665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test the dataset against the standard scikit-learn Decision Tree model","metadata":{}},{"cell_type":"code","source":"# Create the X and y values for splitting into training and validation set\nX = df2.drop('target', axis=1)\ny = df2['target'].copy()\n\n # Split the data into 80% training and 20% validation stratifying the data using y\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\n# Initiate the Decision Tree\nt = DecisionTreeClassifier()\n\n# Fit the model to the data\nt.fit(X_train, y_train)\n\n# Calculate the tree accuracy on the training and validation data\nt.score(X_train, y_train), t.score(X_valid, y_valid)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:16:17.372274Z","iopub.execute_input":"2021-07-14T12:16:17.372809Z","iopub.status.idle":"2021-07-14T12:16:17.404704Z","shell.execute_reply.started":"2021-07-14T12:16:17.372769Z","shell.execute_reply":"2021-07-14T12:16:17.403436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import tree to print the scikit-learn tree\nfrom sklearn import tree\n\n# Initiate the DT Classifier\nclf = tree.DecisionTreeClassifier()\n\n# Fit the tree to the data\nclf = clf.fit(X_train, y_train)\n\n# Print the tree\ntree.plot_tree(clf) ","metadata":{"execution":{"iopub.status.busy":"2021-07-14T12:16:17.407267Z","iopub.execute_input":"2021-07-14T12:16:17.407698Z","iopub.status.idle":"2021-07-14T12:16:32.761756Z","shell.execute_reply.started":"2021-07-14T12:16:17.407656Z","shell.execute_reply":"2021-07-14T12:16:32.760827Z"},"trusted":true},"execution_count":null,"outputs":[]}]}