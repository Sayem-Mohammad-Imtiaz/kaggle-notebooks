{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Deep Learning Grid Search\n\nIn this project, we will learn how to use the scikit-learn grid search capability.\n\nWe are going to learn the following topics:\n\n* How to use Keras models in scikit-learn.\n* How to use grid search in scikit-learn.\n* How to tune batch size and training epochs.\n* How to tune learning rate\n* How to tune network weight initialization.\n* How to tune activation functions.\n* How to tune dropout regularization.\n* How to tune the number of neurons in the hidden layer."},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nimport pandas\nimport numpy\nimport sklearn\nimport keras\n\nprint('Python: {}'.format(sys.version))\nprint('Pandas: {}'.format(pandas.__version__))\nprint('Numpy: {}'.format(numpy.__version__))\nprint('Sklearn: {}'.format(sklearn.__version__))\nprint('Keras: {}'.format(keras.__version__))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# import the uci pima indians diabetes dataset\n# url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\nnames = ['n_pregnant', 'glucose_concentration', 'blood_pressuer (mm Hg)', 'skin_thickness (mm)', 'serum_insulin (mu U/ml)',\n        'BMI', 'pedigree_function', 'age', 'class']\ndf = pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv',names=names)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Describe the dataset\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(df.index[0])\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['glucose_concentration'] == 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess the data, mark zero values as NaN and drop\ncolumns = ['glucose_concentration', 'blood_pressuer (mm Hg)', 'skin_thickness (mm)', 'serum_insulin (mu U/ml)', 'BMI']\n\nfor col in columns:\n    df[col].replace(0, np.NaN, inplace=True)\n    \ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop rows with missing values\ndf.dropna(inplace=True)\n\n# summarize the number of rows and columns in df\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert dataframe to numpy array\ndataset = df.values\nprint(dataset.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split into input (X) and an output (Y)\nX = dataset[1:,:8]\nY = dataset[1:, 8].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.shape)\nprint(Y.shape)\nprint(Y[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalize the data using sklearn StandardScaler\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler().fit(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(scaler)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform and display the training data\nX_standardized = scaler.transform(X)\n\ndata = pd.DataFrame(X_standardized)\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import necessary sklearn and keras packages\nfrom sklearn.model_selection import GridSearchCV, KFold\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Start defining the model\ndef create_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(8, input_dim = 8, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(4, input_dim = 8, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    # compile the model\n    adam = Adam(lr = 0.01)\n    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n    return model\n\nmodel = create_model()\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Do a grid search for the optimal batch size and number of epochs\n# import necessary packages\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.optimizers import Adam\n\n# Define a random seed\nseed = 6\nnp.random.seed(seed)\n\n# Start defining the model\ndef create_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(8, input_dim = 8, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(4, input_dim = 8, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    # compile the model\n    adam = Adam(lr = 0.01)\n    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n    return model\n\n# create the model\nmodel = KerasClassifier(build_fn = create_model, verbose = 1)\n\n# define the grid search parameters\nbatch_size = [10, 20, 40]\nepochs = [10, 50, 100]\n\n# make a dictionary of the grid search parameters\nparam_grid = dict(batch_size=batch_size, epochs=epochs)\n\n# build and fit the GridSearchCV\ngrid = GridSearchCV(estimator = model, param_grid = param_grid, cv = KFold(random_state=seed), verbose = 10)\ngrid_results = grid.fit(X_standardized, Y)\n\n# summarize the results\nprint(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\nmeans = grid_results.cv_results_['mean_test_score']\nstds = grid_results.cv_results_['std_test_score']\nparams = grid_results.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print('{0} ({1}) with: {2}'.format(mean, stdev, param))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Do a grid search for learning rate and dropout rate\n# import necessary packages\nfrom keras.layers import Dropout\n\n# Define a random seed\nseed = 6\nnp.random.seed(seed)\n\n# Start defining the model\ndef create_model(learn_rate, dropout_rate):\n    # create model\n    model = Sequential()\n    model.add(Dense(8, input_dim = 8, kernel_initializer='normal', activation='relu'))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(4, input_dim = 8, kernel_initializer='normal', activation='relu'))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    # compile the model\n    adam = Adam(lr = learn_rate)\n    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n    return model\n\n# create the model\nmodel = KerasClassifier(build_fn = create_model, epochs = 100, batch_size = 20, verbose = 0)\n\n# define the grid search parameters\nlearn_rate = [0.001, 0.01, 0.1]\ndropout_rate = [0.0, 0.1, 0.2]\n\n# make a dictionary of the grid search parameters\nparam_grid = dict(learn_rate=learn_rate, dropout_rate=dropout_rate)\n\n# build and fit the GridSearchCV\ngrid = GridSearchCV(estimator = model, param_grid = param_grid, cv = KFold(random_state=seed), verbose = 10)\ngrid_results = grid.fit(X_standardized, Y)\n\n# summarize the results\nprint(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\nmeans = grid_results.cv_results_['mean_test_score']\nstds = grid_results.cv_results_['std_test_score']\nparams = grid_results.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print('{0} ({1}) with: {2}'.format(mean, stdev, param))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Do a grid search to optimize kernel initialization and activation functions\n# import necessary packages\n\n# Define a random seed\nseed = 6\nnp.random.seed(seed)\n\n# Start defining the model\ndef create_model(activation, init):\n    # create model\n    model = Sequential()\n    model.add(Dense(8, input_dim = 8, kernel_initializer= init, activation= activation))\n    model.add(Dense(4, input_dim = 8, kernel_initializer= init, activation= activation))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    # compile the model\n    adam = Adam(lr = 0.001)\n    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n    return model\n\n# create the model\nmodel = KerasClassifier(build_fn = create_model, epochs = 100, batch_size = 20, verbose = 0)\n\n# define the grid search parameters\nactivation = ['softmax', 'relu', 'tanh', 'linear']\ninit = ['uniform', 'normal', 'zero']\n\n# make a dictionary of the grid search parameters\nparam_grid = dict(activation = activation, init = init)\n\n# build and fit the GridSearchCV\ngrid = GridSearchCV(estimator = model, param_grid = param_grid, cv = KFold(random_state=seed), verbose = 10)\ngrid_results = grid.fit(X_standardized, Y)\n\n# summarize the results\nprint(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\nmeans = grid_results.cv_results_['mean_test_score']\nstds = grid_results.cv_results_['std_test_score']\nparams = grid_results.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print('{0} ({1}) with: {2}'.format(mean, stdev, param))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Do a grid search to find the optimal number of neurons in each hidden layer\n# import necessary packages\n\n# Define a random seed\nseed = 6\nnp.random.seed(seed)\n\n# Start defining the model\ndef create_model(neuron1, neuron2):\n    # create model\n    model = Sequential()\n    model.add(Dense(neuron1, input_dim = 8, kernel_initializer= 'uniform', activation= 'linear'))\n    model.add(Dense(neuron2, input_dim = neuron1, kernel_initializer= 'uniform', activation= 'linear'))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    # compile the model\n    adam = Adam(lr = 0.001)\n    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n    return model\n\n# create the model\nmodel = KerasClassifier(build_fn = create_model, epochs = 100, batch_size = 20, verbose = 0)\n\n# define the grid search parameters\nneuron1 = [4, 8, 16]\nneuron2 = [2, 4, 8]\n\n# make a dictionary of the grid search parameters\nparam_grid = dict(neuron1 = neuron1, neuron2 = neuron2)\n\n# build and fit the GridSearchCV\ngrid = GridSearchCV(estimator = model, param_grid = param_grid, cv = KFold(random_state=seed), refit = True, verbose = 10)\ngrid_results = grid.fit(X_standardized, Y)\n\n# summarize the results\nprint(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\nmeans = grid_results.cv_results_['mean_test_score']\nstds = grid_results.cv_results_['std_test_score']\nparams = grid_results.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print('{0} ({1}) with: {2}'.format(mean, stdev, param))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# generate predictions with optimal hyperparameters\ny_pred = grid.predict(X_standardized)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pred.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pred[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate a classification report\nfrom sklearn.metrics import classification_report, accuracy_score\n\nprint(accuracy_score(Y, y_pred))\nprint(classification_report(Y, y_pred))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python [default]","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.13"}},"nbformat":4,"nbformat_minor":4}