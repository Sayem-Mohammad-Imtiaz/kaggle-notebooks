{"nbformat_minor":2,"nbformat":4,"cells":[{"source":"## SMS Spam Detection\n#### 2017/8/8 Weiying Wang\n\nThis is a complete guide of using language model to perform spam detection. The objective is straightforward: Given a labeled data, where one column is text message, and another column is the label: `spam` or `ham` (i.e. not spam), build a model to detect spam message. The data consists 5572 entries, and 13% of them are spam. The text will be featured using tf-idf.\n\nI will cover most of the machine learning tools, as you can see in the **table of content**. And compare them.\n\nThe winner, here, is SVM, who gives acuracy **98.9%** and F1 score 0.957 on the 20% test set, LR, MNB(multinomial Naive Bayes), and RF, are slightly trailed behind.\n\n### Table of Content:\n\n#### 0. Import Data and Module\n \n#### 1. From Text To Features\n \n#### 2. Prediction\n \n    2.1 Support vector classifier\n    \n    2.2 Naive Bayes\n    \n    2.3 Decision Tree\n    \n    2.4 Logistic Regression\n    \n    2.5 Random Forest\n    \n    2.6 Adaboost\n    \n    2.7 Gradient Boost Machine (XGBoost)\n    \n#### 4. Comparison Between Models\n    \n    4.1 Accuracy and F1 Score\n    \n    4.2 Confusion Matrices\n    \n    4.3 Misclassified samples from SVM","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"a06b35c55e9cda0cd2aa34827b1c9f71cc37006c","_cell_guid":"32bace17-c3f1-4557-9a75-5093c4c45e60"},"execution_count":null},{"source":"## 0. Import Data and Module","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"d81885f91ed70ce55388425fd4438b3d47335b27","_cell_guid":"98429bd4-a89f-4664-9aba-28db23d0b7d1"},"execution_count":null},{"source":"import pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nimport string\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score,f1_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nimport xgboost as xgb\n%matplotlib inline","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"4b54a35fc2c26b009acaf40924554d158e8ebcc8","_cell_guid":"8a10a7d8-2677-4cfd-a955-d2db9129f196"},"execution_count":1},{"source":"df = pd.read_csv('../input/spam.csv', encoding='latin-1')\ndf = df.loc[:,['v1','v2']]\ndf.tail()","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"9bd0405c0f4add203f464fa2c171723355327c2a","_cell_guid":"163b0003-f5c2-48a5-8efc-a9f97277a368"},"execution_count":2},{"source":"Let's first transform column `v1`, where `ham=0`, `spam=1`.","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"66762f42d3552f336d9cc305c2b8d714e6b9384c","_cell_guid":"0f114464-61f1-4f06-bddb-22d6878d7026"},"execution_count":null},{"source":"d={'spam':1,'ham':0}\ndf.v1 = list(map(lambda x:d[x],df.v1))","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"225a0c8d183f1f019e09a50efa386dd732a7043d","_cell_guid":"5f2b3684-5a88-4e84-a478-25d877133dfb"},"execution_count":3},{"source":"I will going to use nltk module, if this is your first time use nltk, please run the following in your Python environment:\n```\nimport nltk\nnltk.download()\n```\nThen you can install all the requirement from the application interface.","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"67693b25b2371d5ac384ac6cb00024a1b7dd1375","_cell_guid":"1a218f0d-27e3-4092-b93c-e84ba702dafc"},"execution_count":null},{"source":"## 1. From Text To Features\n\nI am going to use tf-idf model on the text. The text will be \n\n1. lower: No captal appeared.\n2. remove punctuation: No punctuation appeared.\n3. stemmed: collect similar words (i.e. `words` will be transformed to `word`,etc.)\n\nThe convert the cleaned text to tf-idf features (5000 features for an entry).","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"46d773b45b47e15f8ca908c398dfbc8d8a9fb72e","_cell_guid":"060b20ef-5ff5-4e64-98c6-46b8cb59a721"},"execution_count":null},{"source":"import re\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nclass stemmed_tfidf():\n    def __init__(self,max_features=5000):\n        self.ps = PorterStemmer()\n        self.vc = TfidfVectorizer(analyzer='word',#{‘word’, ‘char’}  Whether the feature should be made of word or character n-grams\n                             stop_words = 'english',\n                             max_features = max_features)\n    def tfidf(self,ListStr):\n        '''\n        return: sklearn.feature_extraction.text.TfidfVectorizer\n        '''\n        table = self.vc.fit_transform([self.stem_string(s) for s in ListStr])\n        return table\n    def stem_string(self,s):\n        '''\n        s:str, e.g. s = \"Get strings with string. With. Punctuation?\"\n        ps: stemmer from nltk module\n        return: bag of words.e.g. 'get string with string with punctuat'\n        '''    \n        s = re.sub(r'[^\\w\\s]',' ',s)# remove punctuation.\n        tokens = word_tokenize(s) # list of words.\n        #a = [w for w in tokens if not w in stopwords.words('english')]# remove common no meaning words\n        return ' '.join([self.ps.stem(w) for w in tokens])# e.g. 'desks'->'desk'","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"2741a086a5253f4a0dfa6ca2822886096c537bde","_cell_guid":"306e323c-4cf1-4bf6-aa68-fd88f2d73bba"},"execution_count":4},{"source":"stf = stemmed_tfidf()\nfeature = stf.tfidf(df.v2) # this will be a sparse matrix of size (n,5000)","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"1458904ce7a8299cb143594f80f4861694d31adf","_cell_guid":"85b960e6-b130-4520-bfe3-21df71cfdcc2"},"execution_count":5},{"source":"## 2. Prediction\n\nBefore doing analysis, we have to decide the metric to compare between different models. The following calculate the percentage of spam data. As you can see, We have an inbalanced data set, in which only about 13% of the data is spam. The way to deal with it is to **increase their weight** (the spam samples) and **use F1 score** instead of accuracy.","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"c6767206dca552e32084c0a52e040e3abdcfaabc","_cell_guid":"d32c7786-d497-4899-80f9-eb73c98efcc7"},"execution_count":null},{"source":"print('%2.2f percent of data is spam: We have an inbalanced data set.'%round(100*sum(df.v1)/len(df),2))","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"4a1dcb2074f80fa3edebac92807d6cc3a8a377cd","_cell_guid":"9bb9c4d7-bcff-4d69-a139-2b4a4e0b14ed"},"execution_count":9},{"source":"To be able to compare between models, we will separate the data set into training and test set. Also,some models requires paramter tunning, one must be careful that all the tunning (cross-validation) should be performed in the training set.","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"26626368f98c19898588167213d794b66e5a8fe6","_cell_guid":"8acd4f19-bfd5-44cd-a0f4-1cd1d2cc3346"},"execution_count":null},{"source":"Xtrain, Xtest, ytrain, ytest = train_test_split(feature, df.v1, test_size=0.2, random_state=1)","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"c90a190002a6f1847c860ec6688c107863c15d32","_cell_guid":"31663d3d-06f3-4a32-8964-f5470d320d34"},"execution_count":10},{"source":"I will going to use a lot of tools to analysis, and the results will be put into the folloing three dictionary.","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"b4f829511c13c732091113e21679adc0595a2962","_cell_guid":"385e2b7c-0d64-4869-bc98-c57004ded9ce"},"execution_count":null},{"source":"Acc = {}\nF1score = {}\nconfusion_mat={}\npredictions = {}","outputs":[],"cell_type":"code","metadata":{"collapsed":true,"trusted":false,"_uuid":"09f6c308facca079e4c9373e5da3daf7f3285676","_cell_guid":"f34bd0c0-b43c-471c-8890-70bd33583c71"},"execution_count":11},{"source":"### 2.1 Support vector classifier\n\nSeveral caveat to use SVM:\n\n1. SVM is sensitive to scaling, which is not an issue here since tf-idf generated from `TfidfVectorizer` has already be normalized to 0 and 1.\n\n2. I will use 3-fold (default) cross validation to determine the two hyperparameter `C` anc `gamma`:\n\n a. `C`:lower C lead to underfitting, and higher C lead to overfit.\n \n b. `gamma`: parameter that controls `rbf`,`poly`, and `sigmoid` kernel. See [SVM document](http://scikit-learn.org/stable/modules/svm.html#svm-classification).\n \nThe cross validation step is slow, let's split that into two cross validations.","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"1b23fe1fa76d0601294dfd86579cff012b934681","_cell_guid":"bfe9a68c-8e27-446e-8e6f-96ce0382bfc3"},"execution_count":null},{"source":"val_scores = []\nlistc = np.linspace(0.5,3,num=4)\nlistgamma = np.linspace(0.5,3,num=4)\nkernel = ['rbf','sigmoid']# 'poly' is doing bad here, let's save some time.\nfor v in kernel:\n    for c in listc:\n        for gamma in listgamma:\n            svc = SVC(kernel=v, C=c, gamma=gamma,class_weight='balanced')\n            #3. The “balanced” mode uses the values of y to automatically adjust weights inversely \n            #   proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y))\n            scores = cross_val_score(svc, Xtrain, ytrain,scoring='f1')\n            val_scores.append([np.mean(scores),v, c,gamma])","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"e27d0d002ccbc5236685679d9c14b35fc633b22d","_cell_guid":"05e98b0a-71ce-4be8-b8f1-ac0dc361ab28"},"execution_count":22},{"source":"val_scores = np.array(val_scores)\nprint('The best scores happens on:',val_scores[val_scores[:,0]==max(val_scores[:,0]),1:],\n      ', where F1 =',val_scores[val_scores[:,0]==max(val_scores[:,0]),0])","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"d95d20ca5ccf16c71aa748a999df53d69870a7a6","_cell_guid":"f5f61fd1-8788-4b38-936b-0ce0a8e11e4d"},"execution_count":24},{"source":"After this we see that `kernel='sigmoid', C=1.3, gamma=0.5]` gives best result in F1 (look at `val_score`). Let's continue to see if any refinement of `C` and `gamma` make it better.","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"44d6e79f9e54129d17903fdbd0c52eb9d0b415e5","_cell_guid":"fa398a30-c940-404b-9a6b-ee8b992b3d8c"},"execution_count":null},{"source":"val_scores = []\nlistc = np.linspace(0.5,2,num=5)\nlistgamma = np.linspace(0.3,1,num=5)\nfor c in listc:\n    for gamma in listgamma:\n        svc = SVC(kernel='sigmoid', C=c, gamma=gamma,class_weight='balanced')\n        scores = cross_val_score(svc, Xtrain, ytrain,scoring='f1')\n        val_scores.append([np.mean(scores),v, c,gamma])\nval_scores = np.array(val_scores)\nprint('The best scores happens on:',val_scores[val_scores[:,0]==max(val_scores[:,0]),1:],\n      ', where F1 =',val_scores[val_scores[:,0]==max(val_scores[:,0]),0])","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"4b367a54116ab4baf85a6cad964576a9ee2ca52e","_cell_guid":"9a5acdb8-f7a6-4262-ae4e-e19845d318f9"},"execution_count":27},{"source":"After look at the `val_scores`, I decide to use `kernel='sigmoid', C=1.25, gamma=0.825]`, which gives the highest F1 score.","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"77bfa239849df76f367508ab916727b0e3347bdd","_cell_guid":"13b53e3b-6a93-4f92-b372-0d19047fd177"},"execution_count":null},{"source":"name = 'SVM'\nsvc = SVC(kernel='sigmoid', C=1.25, gamma=0.825,class_weight='balanced')\nsvc.fit(Xtrain,ytrain)\npred = svc.predict(Xtest.toarray())\nF1score[name]= f1_score(ytest,pred)\nAcc[name] = accuracy_score(ytest,pred)\nconfusion_mat[name] = confusion_matrix(ytest,pred)\npredictions[name]=pred\nprint(name+': Accuracy=%1.3f, F1=%1.3f'%(Acc[name],F1score[name]))","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"d1905571d9f06929f677bd02a40af152d7fadd1e","_cell_guid":"674d64cb-aee7-46c9-9fd2-a3284e6f9d14"},"execution_count":28},{"source":"### 2.2 Naive Bayes\n\nYou probably heard that Naive Bayes (NB) works surprising well in the text classification. But you still need to be careful.\n\nSince our tf-idf feature is continuous (within 0 and 1), the probability model $P(x_k|y)$  for kth feature will be modeled as Gaussian, i.e. GDA. This will be a **bad idea** since our feature will not look like Gaussian (the value is within 0 and 1). Let's run it anyway, and after that I will tell you **a better way** to do it.","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"d30a214972f91d44e6c8ab0e2fb0c7ad267aabf7","_cell_guid":"c37cc081-abe4-4c7a-945d-9ff826054088"},"execution_count":null},{"source":"GNB = GaussianNB()\nGNB.fit(Xtrain.toarray(), ytrain)# Since our Xtrain is a sparse matrix, need to use .toarray() to convert it to dense one.\naccuracy_score(ytest,GNB.predict(Xtest.toarray()))","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"284bd40e31faebfcf13fbd751c6a65d6e6fa73e4","_cell_guid":"784855ad-3332-4ae7-8c79-79bbc4d134e4"},"execution_count":223},{"source":"As you can see, it is not good. Let's use a better way, **multinominal Naive Bayes (MNB)**.\n\nUsually, to apply NB, people **quantize** the continuous feature value and model $P(x_k|y)$ as a multinominal distribution. So we are going to do that. The following gives a simple way to quantize an array, or list of array.","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"c4de48ed1eda56b5c31514db161a1fb9c3df49c2","_cell_guid":"77fdf381-32e6-4224-aa2c-f9f0eef2559c"},"execution_count":null},{"source":"np.digitize([[0.1,0.22,0.33,0.8],[0.1,0.22,0.05,0.8]],bins = [.15,.25])","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"0a489dec460ac53d568852c803e300b2a405577f","_cell_guid":"d6c94972-ecf8-4bf0-b92e-465f89756075"},"execution_count":214},{"source":"bins = [.2,.4,.6,.8] # so every feature will end up 0,1,2,3,4\nXqtrain = np.digitize(Xtrain.toarray(),bins = bins)\nXqtest = np.digitize(Xtest.toarray(),bins = bins)","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"4d6c7935eb10ffd7b6e512ed0794805beb17a2e5","_cell_guid":"3b2bbc9d-edfb-49cf-b3eb-573d330747fd"},"execution_count":37},{"source":"As SVM, there are tunning parameter in NB for using multinominal distribution here, called the Lapalace smoothing parameter,  `alpha`. Again, we use 3-fold cross validation to decide what `alpha` is.","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"19bf4c215ebdaa40f39fadb6f09d0dd1946ed525","_cell_guid":"34e3e018-e449-4629-b53b-ee431bac96d8"},"execution_count":null},{"source":"from sklearn.naive_bayes import MultinomialNB\nval_scores = []\nlistalpha = np.linspace(0.01,1,num=20)\nfor i in listalpha:\n    MNB = MultinomialNB(alpha=i)# alpha is Laplace smoothing parameter\n    scores = cross_val_score(MNB, Xtrain, ytrain,scoring='f1')\n    val_scores.append([np.mean(scores),i])\nval_scores = np.array(val_scores)\nprint('The best scores happens on:',val_scores[val_scores[:,0]==max(val_scores[:,0]),1:],\n      ', where F1 =',val_scores[val_scores[:,0]==max(val_scores[:,0]),0])","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"45e982d92f89e439a4f038e487f88a7fffcd48ad","_cell_guid":"a587a28b-ae6f-4d8e-a132-29444bd649b9"},"execution_count":29},{"source":"I will use `alpha = 0.27052632`, which gives the maximum F1 scores among all.","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"33da38d326a3f9aba9c742500f7f9f535e9ee8b7","_cell_guid":"1be74f51-739a-4bcb-97b1-c28c034bff68"},"execution_count":null},{"source":"name = 'MNB'\nMNB = MultinomialNB(alpha=0.27052632)\nMNB.fit(Xtrain,ytrain)\npred = MNB.predict(Xtest.toarray())\nF1score[name]= f1_score(ytest,pred)\nAcc[name] = accuracy_score(ytest,pred)\nconfusion_mat[name] = confusion_matrix(ytest,pred)\npredictions[name]=pred\nprint(name+': Accuracy=%1.3f, F1=%1.3f'%(Acc[name],F1score[name]))","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"a896567d99faf2622d29c84a8db85eaa8aea99c7","_cell_guid":"ead705e0-d17a-456f-b66d-1e0347641bf7"},"execution_count":30},{"source":"This result is much better than using Gaussian NB.","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"9f50e006dadd9343068b369e85dd9cfddbb6b55e","_cell_guid":"b73daabb-55ff-45b4-a6d5-0c555ac82c82"},"execution_count":null},{"source":"### 2.3 Decision Tree\n\nDecistion Tree(DT) is one of the baseline model for classification. Since it doesn't require scaling, and no need to worry about multicollinearity, it is very easy to apply.\n\nBasically, DT binary splits one of the feature (optimally selected) in each iteration, this partitions feature space. After several iteration, we have a lot of partition in the feature space. The algorithm will first overfit the sample, then use some criterion to 'pruning' the overfitted tree.\n\nAn advanced version of DT will be method that use ensumble, i.e. Adaboost, Random Forest, and Gradient Boost Machine, there basic learner are (almost all) DT.\n\nOne of the important parameter of DT is `min_samples_split`, an interger value>=1, which determine the sample size in the smallest leaf. We are going to use cross validation to determine that.","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"3a859bfabec0cb4024d86bd7eb3db3dcf0b2b601","_cell_guid":"6d52455b-364e-470b-a705-0858160a9526"},"execution_count":null},{"source":"val_scores = []\nfor i in range(2,21):\n    DT = DecisionTreeClassifier(min_samples_split=i, random_state=1,class_weight='balanced')\n    scores = cross_val_score(DT, Xtrain, ytrain,scoring='f1')\n    val_scores.append([np.mean(scores),i])\nval_scores = np.array(val_scores)\nprint('The best scores happens on:',val_scores[val_scores[:,0]==max(val_scores[:,0]),1:],\n      ', where F1 =',val_scores[val_scores[:,0]==max(val_scores[:,0]),0])","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"5b95e5a744d812ed3ecd25ef86dd3a60b2979a51","_cell_guid":"de68a7a2-b499-4365-aa69-41c2c1baa2df"},"execution_count":31},{"source":"So, I will use `min_samples_split=4`, which gives best F1 score during cross validataion, to run the test set.","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"5ec6938c12d15e7151cb5847f42a0821d510b0ee","_cell_guid":"f9e26f5b-6a1b-4b4b-8b38-8e2b80034235"},"execution_count":null},{"source":"name = 'DT'\nDT = DecisionTreeClassifier(min_samples_split=4, random_state=1,class_weight='balanced')\nDT.fit(Xtrain,ytrain)\npred = DT.predict(Xtest.toarray())\nF1score[name]= f1_score(ytest,pred)\nAcc[name] = accuracy_score(ytest,pred)\nconfusion_mat[name] = confusion_matrix(ytest,pred)\npredictions[name]=pred\nprint(name+': Accuracy=%1.3f, F1=%1.3f'%(Acc[name],F1score[name]))","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"5a209f85bab5f751e84f3ae41165bf954fe13ac1","_cell_guid":"e70390ab-c451-46d6-a207-dae958af4a0e"},"execution_count":32},{"source":"### 2.4 Logistic Regression\n\nThe most famous model for classification, one of the baseline model. One needs to be care about:\n \n 1. If there is multicoliearity, it will affect LR. Since it calculate inverse of (X'X) in the algorithm and strong multicolinearity will make the matrix ill-condition.\n \n 2. To prevent overfitting, one usually puts L1 or L2 regularity here. A parameter `C` will help control overfit or not. Smaller `C` leads to underfit and vise versa.","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"35500482137eb7e455d839331f0b4227d8a4d354","_cell_guid":"8a3b364b-656d-44cf-95da-8d1669446d47"},"execution_count":null},{"source":"list_C = np.linspace(0.1,3,num=20)\nval_scores = []\nfor p in ('l1','l2'):\n    for c in list_C:\n        LR = LogisticRegression(penalty=p,C=c,class_weight='balanced')\n        scores = cross_val_score(LR, Xtrain, ytrain,scoring='f1')\n        val_scores.append([np.mean(scores),p,c])\nval_scores = np.array(val_scores)\nprint('The best scores happens on:',val_scores[val_scores[:,0]==max(val_scores[:,0]),1:],\n      ', where F1 =',val_scores[val_scores[:,0]==max(val_scores[:,0]),0])            ","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"060da49982314498a54b02739366c2469b383036","_cell_guid":"a0a71e95-c582-46b9-82d8-d700b76eec04"},"execution_count":33},{"source":"Let's use the parameter `penalty='l2',C=0.863157894737`","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"1d7bd9dee66e337e1eb7981060c02dda5ec3e49a","_cell_guid":"a7dfc032-7676-4e61-9ff7-ad477e3b9681"},"execution_count":null},{"source":"name = 'LR'\nLR = LogisticRegression(penalty='l2',C=0.863157894737,class_weight='balanced')\nLR.fit(Xtrain,ytrain)\npred = LR.predict(Xtest)\nF1score[name]= f1_score(ytest,pred)\nAcc[name] = accuracy_score(ytest,pred)\nconfusion_mat[name] = confusion_matrix(ytest,pred)\npredictions[name]=pred\nprint(name+': Accuracy=%1.3f, F1=%1.3f'%(Acc[name],F1score[name]))","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"1d4a513a9b5dbed8fbf2204b2a7ced53b1a01223","_cell_guid":"67d21f22-1e30-4e96-8e0a-7391b759c1df"},"execution_count":34},{"source":"### 2.5 Random Forest\n\nRandom Forest(RF) is a very popular method. Basically, it will generate several boostrap samples (the number is `n_estimator`, as you will see, the higher of this, the better), and with the boostrap sample, it generate a decision tree. The subtlety is that when deciding the split, it chooses from **subsets** of features to split the tree (This will help prevent overfitting, for example, think about doing some mathematic problem without using some big theorems, if you learn this technique, you will be, or maybe, clever on different kind of harsh environment.) \n\nSo in the end you will get `n_estimator` of trees. The final decision can be made by majority vote from them.","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"9cf7f654a9faf972554d53e1dfa743125e8b0724","_cell_guid":"25098acd-6e32-4245-bb54-a97366d91b7e"},"execution_count":null},{"source":"name = 'RF'\nRF = RandomForestClassifier(n_estimators =80,class_weight ='balanced')\nRF.fit(Xtrain,ytrain)\npred = RF.predict(Xtest)\nF1score[name]= f1_score(ytest,pred)\nAcc[name] = accuracy_score(ytest,pred)\nconfusion_mat[name] = confusion_matrix(ytest,pred)\npredictions[name]=pred\nprint(name+': Accuracy=%1.3f, F1=%1.3f'%(Acc[name],F1score[name]))","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"cc4c5d1f1c172e6c89cd411aecf6cb6e6def84c0","_cell_guid":"5923592a-efd9-4e25-8a22-cc473230e362"},"execution_count":35},{"source":"### 2.6 Adaboost\n\nAdaboost is probably the first way using boostrap to enhance the model. The procedure can be described as: given a uniform weight $$w = (w_1,...,w_1)$$\n\n1. Re-sampling a sample set from training set according to the weight w.\n\n2. Use tree (default) or other method to induce a classification rule, say $$f_{m}(x).$$\n\n3. Estimate the training error rate by $$\\epsilon_{m}\\propto\\sum_{i=1}^{n}w_{i}\\mathbb{I}_{\\{y_{i}\\neq f_m(x_{i})\\}}.$$\n\n4. For i in correct index set, put the weight down by $$w_{i}=w_{i}\\cdot\\frac{\\epsilon_{m}}{1-\\epsilon_{m}}.$$ And normalize the weight, so that incorrect sample will receive higher weight next time.\n\nRepeat 1,2,3,4 for M times, and get M rules,say $$f_{1},\\cdots,f_{M}$$. The final master rule is $$sign[\\sum_{m=1}^{M}\\beta_{m}f_{m}(x)],$$ where $$\\beta_{m}=\\log(\\frac{1-\\epsilon_{m}}{\\epsilon_{m}}).$$ \n\nBriefly speaking, \n\n1. the hard to classified entries will receive more weight when preforming the next boostrap (so they will tend to be drawn more often next time).\n\n2. the weak learner will receive smaller weight when doing the majority vote in the end.","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"dcef6b1f87fc26a54890b3366b32bf186285a932","_cell_guid":"ed1001f1-ba86-4dd7-bacb-dabb47358521"},"execution_count":null},{"source":"name = 'AdaBoost'\nAda = AdaBoostClassifier(n_estimators=80, random_state=1)\nAda.fit(Xtrain,ytrain)\npred = Ada.predict(Xtest)\nF1score[name]= f1_score(ytest,pred)\nAcc[name] = accuracy_score(ytest,pred)\nconfusion_mat[name] = confusion_matrix(ytest,pred)\npredictions[name]=pred\nprint(name+': Accuracy=%1.3f, F1=%1.3f'%(Acc[name],F1score[name]))","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"96bff0958999179f43c5ac258178e8ada9f720ec","_cell_guid":"e26b8b9c-5016-4307-ac57-79517bcb7aaa"},"execution_count":36},{"source":"### 2.7 Gradient Boost Machine\n\nThe Gradient Boost Machine (GBM) is basically:\n\n1. Let fT=0\n\n2. Obtain a boostrap sample set from $$(x_{i},y_{i})_{i=1}^{n}$$\n\n2. Using the Boostrap sample set to build **binary tree** till a certain depth (parameter `max_depth`). The tree is denote as f, or say f(x).\n\n3. Update fT, i.e. fT = fT + f.\n\n4. repeat step 1 again.\n\nAnd use the final tree fT to do the classification. Note that in step 2, we use binary tree so there is no need to rescale feature values. And no need to worry about multicollinearity. Also note that, in step 3, it renders an **additive** model, where the difficult samples will receive higher weight (inherently) in the next iteration.\n\nThe following gives the code for doing cross validataion on XGBoost, a faster and more efficient version of GBM. Note that I didn't try a lot of parameters since it would take too long. Note that it might not give GBM a fair fight here by not finding best parameters here.","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"911b5e2507d19c248965301b7ec1fbef909f5118","_cell_guid":"be06626d-bd04-4111-aa52-763fc1ad039b"},"execution_count":null},{"source":"data_tr  = xgb.DMatrix(Xtrain, label=ytrain)\nval_scores = []\nlist_max_depth =[6,9,14]\nlist_subsample = [0.8,1]\nfor max_depth in list_max_depth:\n    for subsample in list_subsample:\n        parms = {'max_depth':max_depth, #maximum depth of a tree\n                 'objective':'binary:logistic',\n                 'eta'      :0.1,\n                 'subsample':subsample,#SGD will use this percentage of data\n                 'lambda '  :1.5, #L2 regularization term,>1 more conservative\n                 'colsample_bytree ':0.8,\n                 'nthread'  :3}  #number of cpu core to use\n        result = xgb.cv(parms, data_tr, \n                            num_boost_round=1000,\n                            early_stopping_rounds=20,# early stop if cv result is not improving\n                            nfold=3,metrics=\"error\")\n        val_scores.append([result['test-error-mean'].iloc[-1],max_depth,subsample,len(result)-20])\n        #len(result) will be our num_boot_round in the test set\nval_scores = np.array(val_scores)\nprint('The best scores happens on:',val_scores[val_scores[:,0]==min(val_scores[:,0]),1:],\n      ', where accuracy =',val_scores[val_scores[:,0]==min(val_scores[:,0]),0])","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"be42151d4d642b3e48f9831cd79f98d885608e74","_cell_guid":"7231fd12-436d-4892-a3ea-dc1c83a450a0"},"execution_count":38},{"source":"Let's using the parameter that produce the smallest error. Note that don't apply early stop on the test set, since the `num_boost_round` should only be decided in the training data.","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"47744cf66ff7790e21bcf89afd67a42c657efcab","_cell_guid":"a204b58a-7bdc-4f63-ad3c-691d7d30e130"},"execution_count":null},{"source":"data_tr  = xgb.DMatrix(Xtrain, label=ytrain)\ndata_val  = xgb.DMatrix(Xtest, label=ytest)\nevallist = [(data_tr, 'train'), (data_val, 'test')]\n\nparms = {'max_depth':9, #maximum depth of a tree\n         'objective':'binary:logistic',\n         'eta'      :0.1,\n         'subsample':0.8,#SGD will use this percentage of data\n         'lambda '  :1.5, #L2 regularization term,>1 more conservative\n         'colsample_bytree ':0.8,\n         'nthread'  :3}  #number of cpu core to use\n\nGBM = xgb.train(parms, data_tr, num_boost_round=118, evals = evallist,\n                maximize=False, verbose_eval=False)","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"0faad71d8f2e2c306536e003522444c751d830b9","_cell_guid":"ea25f95b-572e-4b5f-a868-20d6f8f5abd2"},"execution_count":39},{"source":"name = 'GBM'\npred = GBM.predict(xgb.DMatrix(Xtest)) # note that this is float value between 0 and 1. This is the probability of y=1.\npred = [int(round(p)) for p in pred]\nF1score[name]= f1_score(ytest,pred)\nAcc[name] = accuracy_score(ytest,pred)\nconfusion_mat[name] = confusion_matrix(ytest,pred)\npredictions[name]=pred\nprint(name+': Accuracy=%1.3f, F1=%1.3f'%(Acc[name],F1score[name]))","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"3db9d11d309114caae47385eb5099de5e70f15e0","_cell_guid":"9dee7623-711b-4c85-860a-0a18392bffc4"},"execution_count":40},{"source":"Let's save the result for latter use.","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"fb7587cda742b9b9307fef10b0c2942d19993282","_cell_guid":"d6e680b1-8bf3-4f86-b707-381335828443"},"execution_count":null},{"source":"'''\nimport pickle\nwith open('spam_result.pickle', 'wb') as handle:\n    pickle.dump([Acc,F1score,confusion_mat,predictions], handle, protocol=pickle.HIGHEST_PROTOCOL)\n'''","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"3aa93e3f476d8b12521d551c429d85b40e729165","_cell_guid":"45bf7264-17b6-45c5-8c82-06ded53f1740"},"execution_count":42},{"source":"## 4. Comparison Between Models","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"9784534e490e5379170bdc2b617160c0aebf4fbe","_cell_guid":"971bb417-e509-4a32-b3a4-d6ba6c3ae38b"},"execution_count":null},{"source":"'''import pickle\nwith open('spam_result.pickle', 'rb') as handle:\n    b = pickle.load(handle)\nAcc,F1score,confusion_mat,predictions = b[0],b[1],b[2],b[3]\n'''","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"7081e983a1c3eed97b6bfa42274b50a0fc4b0b25","_cell_guid":"b686ff89-fcee-45e7-9bfd-41b3c58953c4"},"execution_count":46},{"source":"### 4.1 Accuracy and F1 Score","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"6ac20b7496e4cd58096270bfff30a08df0791245","_cell_guid":"338be4c5-54b5-4825-b7cd-01a25fd10f1d"},"execution_count":null},{"source":"Results = pd.DataFrame([v for v in Acc.values()], columns = ['Acc'],\n                    index = [k for k in Acc.keys()])\nResults = Results.assign(F1_score=[v for v in F1score.values()])\n\nfig = plt.figure(figsize=(16,5))\nylim = [[0.96,1],[0.8,1]]\nx_offset = -0.35; y_offset = 0.001\nfor i,(a,yl) in enumerate(zip(list(Results.keys()),ylim)):\n    plt.subplot(1,2,i+1)\n    Results[a].plot(kind='bar')\n    plt.ylabel(a); plt.ylim(yl)\n    for p in plt.gca().patches:\n        b = p.get_bbox()\n        val = \"{:1.4f}\".format(b.y1 + b.y0)        \n        plt.gca().annotate(val, ((b.x0 + b.x1)/2 + x_offset, b.y1 + y_offset))\n","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"5a9b457796fd0e9cef88bc0c912eb2a34fa4e10d","_cell_guid":"fe3c8ab1-f544-4c3b-88fb-5755fe15f47b"},"execution_count":125},{"source":"As we can see SVM gives a very good Accuracy and F1 score on the test set, LR,MNB, and RF, are slightly trail behind.\n\n### 4.2 Confusion Matrices\n\nThe following code, obtained from [scikit](http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html) webpage, plots the confusion matrix.","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"7805a349bfd54eeacc13b8e6a4779f58e9f693fb","_cell_guid":"70e045c5-d7e9-41da-9ae7-607565bce86c"},"execution_count":null},{"source":"import itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    #plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, round(cm[i, j],4),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout();plt.ylabel('True label');plt.xlabel('Predicted label')","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"b2a7943eeabad3acf9bba631df30177616fc0735","_cell_guid":"708316d6-2ffd-4475-b9c8-413de0e846ac"},"execution_count":197},{"source":"fig = plt.figure(figsize=(18,16))\ni=1\nfor key,val in confusion_mat.items():\n    plt.subplot(3,3,i);i+=1\n    plot_confusion_matrix(val, classes=['ham','spams'], normalize=False,\n                      title=key)","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"0217dbcf3d2e34ab7627a3b5f05c574e94302230","_cell_guid":"8fc3b139-24d1-4517-be56-167922408463"},"execution_count":198},{"source":"### 4.3 Misclassified samples from SVM\n\nThe following code shows the miss-classified text message (model SVM). I can tell some of them are spam, like entry 3528. I guess there is still some place to do better.","outputs":[],"cell_type":"markdown","metadata":{"_uuid":"fb86d286f6cf234a4f0eee084824bf4775893479","_cell_guid":"7a7eb1b5-adf8-4983-b442-38b2faa75c71"},"execution_count":null},{"source":"missclassified = np.nonzero(pred!=ytest)[0]\nind_miss = ytest.index[missclassified]\ndf.iloc[ind_miss,:]","outputs":[],"cell_type":"code","metadata":{"trusted":false,"_uuid":"a618e4639c53a15d0558210c0402d565cd3744b4","_cell_guid":"7cd1c659-4343-43cf-93a2-706f7b9bcf9b"},"execution_count":190}],"metadata":{"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.1","file_extension":".py","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","mimetype":"text/x-python"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}}}