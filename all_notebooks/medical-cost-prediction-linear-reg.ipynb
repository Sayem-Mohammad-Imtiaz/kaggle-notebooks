{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this kernal I will solve the \"*Medical Cost Personal Datasets*\" using Linear Regression.\n\nI will use my own LR implementation vs Scikit learn one\n\n\n**FOR ANY QUESTIONS OR NEEDED EXPLANATIONS JUST COMMENT AND I WILL REPLY ASAP**\n"},{"metadata":{},"cell_type":"markdown","source":"**Import all needed libraries**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport h5py\nimport scipy\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read the csv features file"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/insurance/insurance.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"view data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"view data information"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"show all categorical data that need to be handeled"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical = [var for var in df.columns if df[var].dtype=='O']\nprint(\"The categorical features are : \",categorical)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"use get dummies function to fo the hot encoding to convert categorical data to numirical one in a way that is not give extra weight for any above others "},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat(      [df,\n                     pd.get_dummies(df.sex), \n                     pd.get_dummies(df.smoker),\n                     pd.get_dummies(df.region)], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"show data frame"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"remove the old categorical data columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['sex'], axis=1, inplace=True)\ndf.drop(['smoker'], axis=1, inplace=True)\ndf.drop(['region'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"show data frame"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"use charges as target (labels) data and remove it from data frame\nconvert the Yes/No results to 0/1"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df[\"charges\"]\ndf.drop(['charges'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"split data into training and testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_set_x,  test_set_x, train_set_y,test_set_y = train_test_split(df, y, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"scalling the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler  \nscaler = StandardScaler()  \nscaler.fit(train_set_x)  \ntrain_set_x = scaler.transform(train_set_x)  \ntest_set_x = scaler.transform(test_set_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_set_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"view data shape"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"train_set_x\",train_set_x.shape)\nprint(\"train_set_y\",train_set_y.shape)\nprint(\"test_set_x\",test_set_x.shape)\nprint(\"test_set_y\",test_set_y.shape)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"reshape the labels to elemenate rank one arraies"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set_y=train_set_y.values.reshape(train_set_y.shape[0],1)\ntest_set_y=test_set_y.values.reshape(test_set_y.shape[0],1)\nprint(\"train_set_x\",train_set_x.shape)\nprint(\"train_set_y\",train_set_y.shape)\nprint(\"test_set_x\",test_set_x.shape)\nprint(\"test_set_y\",test_set_y.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**My LR implementation start here:**\n\n"},{"metadata":{},"cell_type":"markdown","source":"Initialize weights and bias with zeros"},{"metadata":{"trusted":true},"cell_type":"code","source":"def initialize(dim):\n    w = np.zeros((dim,1))\n    b = 0  \n    return w, b","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"start the propagate, forward and backward to compute the activations/Cost and gradients respictivly"},{"metadata":{"trusted":true},"cell_type":"code","source":"def propagate(w, b, X, Y):\n    m = X.shape[1]\n    # FORWARD \n    A = np.dot(w.T,X)+b \n    cost = (1/(2*m))*np.sum((A - Y) ** 2)\n    # BACKWARD \n    dz = A-Y\n    dw = (1/m)*np.dot(X,dz.T)\n    db = (1/m)*np.sum(dz)\n    \n    grads = {\"dw\": dw,\n             \"db\": db}\n\n    return grads, cost","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"optimizing the weights and bias using the gradieent at each iteration"},{"metadata":{"trusted":true},"cell_type":"code","source":"def optimize(w, b, X, Y,print_cost, num_iterations, learning_rate):\n    costs = []\n    for i in range(num_iterations):\n        grads, cost = propagate(w, b, X, Y)\n        \n        dw = grads[\"dw\"]\n        db = grads[\"db\"]\n\n        w = w-learning_rate*dw\n        b = b-learning_rate*db\n\n        if i % 100 == 0:\n            costs.append(cost)\n        \n        if print_cost and i % 100 == 0:\n            print (\"Cost after iteration %i: %f\" %(i, cost))\n    \n    params = {\"w\": w,\n              \"b\": b}\n    grads = {\"dw\": dw,\n             \"db\": db}\n    \n    return params, grads, costs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"use the final weights and bias to predict the results for new unseen testing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(w, b, X):\n    m = X.shape[1]\n    Y_prediction = np.zeros((1,m))\n    w = w.reshape(X.shape[0], 1)\n    \n    Y_prediction = np.dot(w.T,X)+b\n    \n    return Y_prediction ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the main model Implementation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score\ndef model(X_train, Y_train, X_test, Y_test,print_cost, num_iterations = 2000, learning_rate = 0.5 ):\n    w, b = initialize(X_train.shape[0])\n\n    parameters, grads, costs = optimize(w, b, X_train, Y_train,print_cost, num_iterations, learning_rate)\n\n    w = parameters[\"w\"]\n    b = parameters[\"b\"]\n\n    Y_prediction_test = predict(w, b, X_test)\n    Y_prediction_train = predict(w, b, X_train)\n    \n    print(\"train accuracy: {} %\".format(r2_score(Y_train.T, Y_prediction_train.T)))\n    print(\"test accuracy: {} %\".format(r2_score(Y_test.T, Y_prediction_test.T)))\n\n    \n    d = {\"costs\": costs,\n         \"Y_prediction_test\": Y_prediction_test, \n         \"Y_prediction_train\" : Y_prediction_train, \n         \"w\" : w, \n         \"b\" : b,\n         \"learning_rate\" : learning_rate,\n         \"num_iterations\": num_iterations}\n    \n    return d","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calling the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = model(train_set_x.T, train_set_y.T, test_set_x.T, test_set_y.T,print_cost = True, num_iterations = 1000, learning_rate = 0.01)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the results with multible Learning Rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rates = [0.1, 0.01, 0.001, 0.0001]\nmodels = {}\nfor i in learning_rates:\n    print (\"learning rate is: \" + str(i))\n    models[str(i)] = model(train_set_x.T, train_set_y.T, test_set_x.T, test_set_y.T,print_cost = False, num_iterations = 2000, learning_rate = i)\n    print ('\\n' + \"-------------------------------------------------------\" + '\\n')\n\nfor i in learning_rates:\n    plt.plot(np.squeeze(models[str(i)][\"costs\"]), label= str(models[str(i)][\"learning_rate\"]))\n\nplt.ylabel('cost')\nplt.xlabel('iterations (hundreds)')\n\nlegend = plt.legend(loc='upper center', shadow=True)\nframe = legend.get_frame()\nframe.set_facecolor('0.90')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"scikit learn LR implementation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nlr = LinearRegression().fit(train_set_x,train_set_y)\ny_train_pred = lr.predict(train_set_x)\ny_test_pred = lr.predict(test_set_x)\nprint(lr.score(train_set_x,train_set_y))\nprint(lr.score(test_set_x,test_set_y))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"check if we have overfitted the results, using L2 regularization (Ridge)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge\nreg = Ridge(alpha=.5).fit(train_set_x,train_set_y)\ny_train_pred = lr.predict(train_set_x)\ny_test_pred = lr.predict(test_set_x)\nprint(reg.score(train_set_x,train_set_y))\nprint(reg.score(test_set_x,test_set_y))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our results and scikit learn results are almost the same\n"},{"metadata":{},"cell_type":"markdown","source":"big thanks for coursera and deeplearning.ai for the knowledge "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}