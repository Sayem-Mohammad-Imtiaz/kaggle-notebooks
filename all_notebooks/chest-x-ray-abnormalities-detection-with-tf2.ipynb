{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pathlib\nimport tarfile\nimport re\n\nimport numpy as np \nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Install Tensorflow Object Detection 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nprint(\"The TensorFlow version installed in the Notebook is TensorFlow {}\".format(tf.__version__))\nprint(\"The TensorFlow version of Keras installed in the Notebook is Keras {}\".format(keras.__version__))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install tf_slim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pycocotools\n!pip install lvis\n!pip install numba ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Clone the Tensorflow models repository"},{"metadata":{"trusted":true},"cell_type":"code","source":"if \"models\" in pathlib.Path.cwd().parts:\n    while \"models\" in pathlib.Path.cwd().parts:\n        os.chdir('..')\nelif not pathlib.Path('models').exists():\n    !git clone --depth 1 https://github.com/tensorflow/models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%bash\ncd models/research\n\n# Compile protos.\nprotoc object_detection/protos/*.proto --python_out=.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Environment variables\nos.environ['PYTHONPATH'] += \":/kaggle/working/models:/kaggle/working/models/research/slim/:/kaggle/working/models/research:\"\n\nimport sys\nsys.path.append(\"/kaggle/working/models\")\nsys.path.append(\"/kaggle/working/models/research\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%bash\ncd models/research\n\n# Test the installation.\npython object_detection/builders/model_builder_tf2_test.py","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Read the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv = pd.read_csv('../input/vinbigdata-original-image-dataset/vinbigdata/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Take the pictures with findings:\ntrain_with_findings = train_csv[train_csv['class_name'] != 'No finding']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Transform Files to TF Records"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport io\nimport pandas as pd\nimport tensorflow.compat.v1 as tf\n\nfrom PIL import Image\nfrom object_detection.utils import dataset_util\nfrom collections import namedtuple, OrderedDict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"flags = tf.app.flags\nFLAGS = flags.FLAGS\n\ndebug = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split(df, group):\n    data = namedtuple('data', ['image_id', 'object'])\n    gb = df.groupby(group)\n    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_tf_example(group, path):\n    \n    # Read the file (jpg)\n    with tf.gfile.GFile(os.path.join(path, '{}.jpg'.format(group.image_id)), 'rb') as fid:\n        encoded_jpg = fid.read()\n        \n    encoded_jpg_io = io.BytesIO(encoded_jpg)\n    image = Image.open(encoded_jpg_io)\n    # TODO CHANGE\n    width, height = image.size\n\n    filename = group.image_id.encode('utf8')\n    image_format = b'jpg'\n    xmins = []\n    xmaxs = []\n    ymins = []\n    ymaxs = []\n    classes_text = []\n    classes = []\n\n    for index, row in group.object.iterrows():\n        xmins.append(row['x_min'] / width)\n        xmaxs.append(row['x_max'] / width)\n        ymins.append(row['y_min'] / height)\n        ymaxs.append(row['y_max'] / height)\n        classes_text.append(row['class_name'].encode('utf8'))\n        classes.append(row['class_id'])\n\n    tf_example = tf.train.Example(features=tf.train.Features(feature={\n        'image/height': dataset_util.int64_feature(height),\n        'image/width': dataset_util.int64_feature(width),\n        'image/filename': dataset_util.bytes_feature(filename),\n        'image/source_id': dataset_util.bytes_feature(filename),\n        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n        'image/format': dataset_util.bytes_feature(image_format),\n        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n        'image/object/class/label': dataset_util.int64_list_feature(classes),\n    }))\n    \n    return tf_example","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped = split(train_with_findings, 'image_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TODO: Do the split right\n# Split the train data into training and validation: \n# 70 % Train, 30 % validation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped_train = grouped[0:3076]\ngrouped_val = grouped[3077:4393]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = os.path.join('../input/vinbigdata-original-image-dataset/vinbigdata/train')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generating TRAINING TF Records\nwriter = tf.python_io.TFRecordWriter('/kaggle/working/train.record')\n\nfor group in grouped:\n    tf_example = create_tf_example(group, path)\n    writer.write(tf_example.SerializeToString())\n    \nwriter.close()\noutput_path = os.path.join(os.getcwd(), '/kaggle/working/train.record')\nprint('Successfully created the TFRecords: {}'.format(output_path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generating VALIDATION TF Records\nwriter = tf.python_io.TFRecordWriter('/kaggle/working/validation.record')\n\nfor group in grouped_train:\n    tf_example = create_tf_example(group, path)\n    writer.write(tf_example.SerializeToString())\n    \nwriter.close()\noutput_path = os.path.join(os.getcwd(), '/kaggle/working/validation.record')\nprint('Successfully created the TFRecords: {}'.format(output_path))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Generate the Label Map File"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function taken from https://www.kaggle.com/sreevishnudamodaran/vbd-efficientdet-tf2-object-detection-api\n\nfrom object_detection.protos.string_int_label_map_pb2 import StringIntLabelMap, StringIntLabelMapItem\nfrom google.protobuf import text_format\n\ndef convert_classes(classes, start=1):\n    \n    msg = StringIntLabelMap()\n    for id, name in enumerate(classes, start=start):\n        msg.item.append(StringIntLabelMapItem(id=id, name=name))\n    text = str(text_format.MessageToBytes(msg, as_utf8=True), 'utf-8')\n    return text\n\nlabels =  [\n            \"Aortic_enlargement\",\n            \"Atelectasis\",\n            \"Calcification\",\n            \"Cardiomegaly\",\n            \"Consolidation\",\n            \"ILD\",\n            \"Infiltration\",\n            \"Lung_Opacity\",\n            \"Nodule_Mass\",\n            \"Other_lesion\",\n            \"Pleural_effusion\",\n            \"Pleural_thickening\",\n            \"Pneumothorax\",\n            \"Pulmonary_fibrosis\"\n            ]\n\ntxt = convert_classes(labels)\nprint(txt)\nwith open('/kaggle/working/label_map.pbtxt', 'w') as f:\n    f.write(txt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Model Configuration"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_record_fname = '/kaggle/working/train.record'\nvalidation_record_fname = '/kaggle/working/validation.record'\nlabel_map_pbtxt_fname = '/kaggle/working/label_map.pbtxt'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MODELS_CONFIG = {\n    'efficientdet-d0': {\n        'model_name': 'efficientdet_d0_coco17_tpu-32',\n        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n        'batch_size': 8\n    },\n    'efficientdet-d1': {\n        'model_name': 'efficientdet_d1_coco17_tpu-32',\n        'base_pipeline_file': 'ssd_efficientdet_d1_640x640_coco17_tpu-8.config',\n        'pretrained_checkpoint': 'efficientdet_d1_coco17_tpu-32.tar.gz',\n        'batch_size': 16\n    },\n    'efficientdet-d2': {\n        'model_name': 'efficientdet_d2_coco17_tpu-32',\n        'base_pipeline_file': 'ssd_efficientdet_d2_768x768_coco17_tpu-8.config',\n        'pretrained_checkpoint': 'efficientdet_d2_coco17_tpu-32.tar.gz',\n        'batch_size': 16\n    },\n    'efficientdet-d3': {\n        'model_name': 'efficientdet_d3_coco17_tpu-32',\n        'base_pipeline_file': 'ssd_efficientdet_d3_896x896_coco17_tpu-32.config',\n        'pretrained_checkpoint': 'efficientdet_d3_coco17_tpu-32.tar.gz',\n        'batch_size': 16\n    },\n    'faster-rcnn-resnet50_v1': {\n        'model_name': 'faster_rcnn_resnet50_v1_640x640_coco17_tpu-8',\n        'base_pipeline_file': 'faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.config',\n        'pretrained_checkpoint': 'faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz',\n        'batch_size': 4\n    }\n}\n\nchosen_model = 'faster-rcnn-resnet50_v1'\n\nnum_steps = 3000 #The more steps, the longer the training. Increase if your loss function is still decreasing and validation metrics are increasing. \nnum_eval_steps = 500 #Perform evaluation after so many steps\n\nmodel_name = MODELS_CONFIG[chosen_model]['model_name']\npretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\nbase_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\nbatch_size = MODELS_CONFIG[chosen_model]['batch_size'] #if you can fit a large batch in memory, it may speed up your training","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Download the pre-trained weights"},{"metadata":{"trusted":true},"cell_type":"code","source":"%mkdir /kaggle/working/deploy\n%cd /kaggle/working/deploy\n\ndownload_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n\n!wget {download_tar}\ntar = tarfile.open(pretrained_checkpoint)\ntar.extractall()\ntar.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Download base training configuration file"},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd /kaggle/working/deploy\n\ndownload_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n!wget {download_config}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Write custom configuration file by slotting our dataset, model checkpoint, and training parameters into the base pipeline file"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_fname = '/kaggle/working/deploy/' + base_pipeline_file\nfine_tune_checkpoint = '/kaggle/working/deploy/' + model_name + '/checkpoint/ckpt-0'\n\ndef get_num_classes(pbtxt_fname):\n    from object_detection.utils import label_map_util\n    label_map = label_map_util.load_labelmap(pbtxt_fname)\n    categories = label_map_util.convert_label_map_to_categories(\n        label_map, max_num_classes=90, use_display_name=True)\n    category_index = label_map_util.create_category_index(categories)\n    return len(category_index.keys())\n\nnum_classes = get_num_classes(label_map_pbtxt_fname)\nnum_classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd /kaggle/working/deploy/\nprint('writing custom configuration file')\n\nwith open(pipeline_fname) as f:\n    s = f.read()\nwith open('pipeline_file.config', 'w') as f:\n    \n    # fine_tune_checkpoint\n    s = re.sub('fine_tune_checkpoint: \".*?\"',\n               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n    \n    # tfrecord files train and test.\n    s = re.sub(\n        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n    s = re.sub(\n        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(validation_record_fname), s)\n\n    # label_map_path\n    s = re.sub(\n        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n\n    # Set training batch_size.\n    s = re.sub('batch_size: [0-9]+',\n               'batch_size: {}'.format(batch_size), s)\n\n    # Set training steps, num_steps\n    s = re.sub('num_steps: [0-9]+',\n               'num_steps: {}'.format(num_steps), s)\n    \n    # Set number of classes num_classes.\n    s = re.sub('num_classes: [0-9]+',\n               'num_classes: {}'.format(num_classes), s)\n    \n    #fine-tune checkpoint type\n    s = re.sub(\n        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n        \n    f.write(s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%cat /kaggle/working/deploy/pipeline_file.config","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Train the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"%mkdir /kaggle/working/training/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_file = '/kaggle/working/deploy/pipeline_file.config'\nmodel_dir = '/kaggle/working/training/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python /kaggle/working/models/research/object_detection/model_main_tf2.py \\\n    --pipeline_config_path={pipeline_file} \\\n    --model_dir={model_dir} \\\n    --alsologtostderr \\\n    --num_train_steps={num_steps} \\\n    --sample_1_of_n_eval_examples=1 \\\n    --num_eval_steps={num_eval_steps}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Evaluate the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"!python /kaggle/working/models/research/object_detection/model_main_tf2.py \\\n    --pipeline_config_path={pipeline_file} \\\n    --model_dir={model_dir} \\\n    --checkpoint_dir={model_dir} \\\n    --eval_timeout=60","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 8. Run Inference on Test Images with Custom TensorFlow2 Object Detector"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt\n\nimport io\nimport scipy.misc\nimport numpy as np\nfrom six import BytesIO\nfrom PIL import Image, ImageDraw, ImageFont\nimport glob\n\nimport tensorflow as tf\n\nfrom object_detection.utils import label_map_util\nfrom object_detection.utils import config_util\nfrom object_detection.utils import visualization_utils as viz_utils\nfrom object_detection.builders import model_builder\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_image_into_numpy_array(path):\n    \"\"\"Load an image from file into a numpy array.\n\n    Puts image into numpy array to feed into tensorflow graph.\n    Note that by convention we put it into a numpy array with shape\n    (height, width, channels), where channels=3 for RGB.\n\n    Args:\n    path: the file path to the image\n\n    Returns:\n    uint8 numpy array with shape (img_height, img_width, 3)\n    \"\"\"\n    img_data = tf.io.gfile.GFile(path, 'rb').read()\n    image = Image.open(BytesIO(img_data))\n    \n    (im_width, im_height) = image.size\n    rgb_img = image.convert('RGB')\n    return np.array(rgb_img.getdata()).reshape(\n      (im_height, im_width, 3)).astype(np.uint8), (im_width, im_height)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%ls '/kaggle/working/training/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#recover our saved model\npipeline_file = '/kaggle/working/deploy/pipeline_file.config'\npipeline_config = pipeline_file\n\n#generally you want to put the last ckpt from training in here\nmodel_dir = '/kaggle/working/training/ckpt-4'\n\nconfigs = config_util.get_configs_from_pipeline_file(pipeline_config)\nmodel_config = configs['model']\ndetection_model = model_builder.build(\n      model_config=model_config, is_training=False)\n\n# Restore checkpoint\nckpt = tf.compat.v2.train.Checkpoint(\n      model=detection_model)\nckpt.restore(os.path.join('/kaggle/working/training/ckpt-4'))\n\ndef get_model_detection_function(model):\n  \"\"\"Get a tf.function for detection.\"\"\"\n\n  @tf.function\n  def detect_fn(image):\n    \"\"\"Detect objects in image.\"\"\"\n\n    image, shapes = model.preprocess(image)\n    prediction_dict = model.predict(image, shapes)\n    detections = model.postprocess(prediction_dict, shapes)\n\n    return detections, prediction_dict, tf.reshape(shapes, [-1])\n\n  return detect_fn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detect_fn = get_model_detection_function(detection_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#map labels for inference decoding\nlabel_map_path = configs['eval_input_config'].label_map_path\nlabel_map = label_map_util.load_labelmap(label_map_path)\ncategories = label_map_util.convert_label_map_to_categories(\n    label_map,\n    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n    use_display_name=True)\ncategory_index = label_map_util.create_category_index(categories)\nlabel_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_np, size = load_image_into_numpy_array('/kaggle/input/vinbigdata-original-image-dataset/vinbigdata/test/002a34c58c5b758217ed1f584ccbcfe9.jpg')\n\ninput_tensor = tf.convert_to_tensor(\n  np.expand_dims(image_np, 0), dtype=tf.float32)\ndetections, predictions_dict, shapes = detect_fn(input_tensor)\n\nlabel_id_offset = 1\nimage_np_with_detections = image_np.copy()\n\nviz_utils.visualize_boxes_and_labels_on_image_array(\n    image_np_with_detections,\n    detections['detection_boxes'][0].numpy(),\n    (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n    detections['detection_scores'][0].numpy(),\n    category_index,\n    use_normalized_coordinates=True,\n    max_boxes_to_draw=200,\n    min_score_thresh=.5,\n    agnostic_mode=False\n)\n\nplt.figure(figsize=(8,8))\nplt.imshow(image_np_with_detections)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detection_scores = detections['detection_scores'][0].numpy()\ndetection_classes = np.array([category_index[x]['name'] for x in (detections['detection_classes'][0].numpy()  + label_id_offset).astype(int)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detection_threshold_class = detection_classes[detection_scores >= .5]\ndetection_threshold_class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detection_threshold_score = detection_scores[detection_scores >= 0.5]\ndetection_threshold_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# References"},{"metadata":{},"cell_type":"markdown","source":"https://www.kaggle.com/awsaf49/vinbigdata-original-image-dataset\n\nhttps://www.kaggle.com/sreevishnudamodaran/vbd-efficientdet-tf2-object-detection-api"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}