{"cells":[{"metadata":{},"cell_type":"markdown","source":"# CORD-19: Parse Data to Flat Format\n## Data Structure\nParsed data is a `pd.DataFrame` with the ff. format:  \n  \n| column | type | description |\n|---------------|------|---------------------------------------------------|\n| paper_id | str |  |\n| supsec_order | int | supersection order (as it appears in the paper) |\n| supersection | str | values = {\"title\", \"abstract\", \"body_text\", \"back_matter\"} |\n| section_order | int | section order (as it appears in the paper) |\n| section | str | based on provided \"section\" value |\n| text | str | parsed text of the section |  \n<br>  \n\n**Notes**\n* Supersection and Section are captured \n    * *I think text in certain sections may need to be given more weight for a better model?*\n* Supersection and Section order are also captured\n    * count starts from 0 (excluding title)\n    * Proxy for \"section\" when unavailable?\n* The following information are ignored: Author, Citations, References\n    * *I don't think this will be needed for the tasks, but I might be wrong...*\n    * Please see [this helpful notebook](https://www.kaggle.com/xhlulu/cord-19-eda-parse-json-and-generate-clean-csv) for parsing these attributes \n* Title is encoded as a row\n    * supersection and section = `\"title\"`, with \\*\\_order = `None`\n"},{"metadata":{},"cell_type":"markdown","source":"***Optional***: Use `ujson` instead of stdlib `json`"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"!pip install ujson","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Imports and Functions\n  \nHelper functions to parse data. Please use `help` for more info.\n* `parse_paper_json` : parses JSON data into a `pd.DataFrame`\n* `parse_section` : parses individual sections found in \"abstract\", \"body_text\", and \"back_matter\"\n* `remove_span_text`: remove spans based on \"\\*_span\" keys in each section\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import logging\nimport gc\nimport glob\nimport multiprocessing as mp\nimport os\nfrom typing import Tuple\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\n\ntry:\n    import ujson as json\nexcept ImportError:\n    import json\n\n\ndef remove_span_text(text: str, spans: list, validate: bool = False) -> str:\n    \"\"\"Remove 'cite/ref/eqn/..._span' from 'text'\n    \n    Parameters\n    ----------\n    text : str\n    spans: list of dict\n        list of `span` JSONs\n    validate: bool, optional\n        Check if span extracted are the same as specified; defaults to `False`\n    \n    Returns\n    -------\n    str\n        text without spans\n    \"\"\"\n    if spans:\n        # TODO: vectorize...?\n        chars = np.array(list(text))\n        span_df = pd.DataFrame(spans)\n        if validate:\n            assert (\n                span_df[\"text\"]\n                == span_df.apply(\n                    lambda row: \"\".join(chars[row[\"start\"] : row[\"end\"]]), axis=1\n                )\n            ).all(), \"Extracted text from `spans` is not the same!\"\n\n        mask = np.full_like(chars, True, dtype=bool)\n        for _, row in span_df.iterrows():\n            mask[row[\"start\"] : row[\"end\"]] = False\n\n        return \"\".join(chars[mask])\n    else:\n        return text\n    \n\ndef parse_section(\n    section: str, text: str, remove_spans: bool = True, **kwargs\n) -> Tuple[str, str]:\n    \"\"\"\n    Parse 'abstract' and 'body_text' sections \n    \n    Parameters\n    ----------\n    **section data\n    remove_spans: bool, optional\n        Remove cite/ref/eqn/... span strings; defaults to `True`\n\n    Returns\n    -------\n    tuple[str, str]\n        (section, cleaned text)\n    \"\"\"\n    spans = []\n    for key, val in kwargs.items():\n        if key.endswith(\"_spans\"):\n            spans.extend(val)\n        else:\n            logging.warning(\"unexpected field: `%s`\", key)\n\n    clean_str = remove_span_text(text, spans) if remove_spans else text\n    return (section, clean_str)\n\n\ndef parse_paper_json(json_data, sup_secs: list = None) -> pd.DataFrame:\n    \"\"\"Parse Paper in JSON format\n    \n    Parameters\n    ----------\n    json_data:\n        if not a `dict` will set as `json.load(open(json_data))`\n    sup_secs: list[str], optional\n        supersections to parse; defaults to `[\"abstract\", \"body_text\", \"back_matter\"]`\n\n    Returns\n    -------\n    pd.DataFrame\n    \"\"\"\n    if not isinstance(json_data, dict):\n        json_data = json.load(open(json_data))\n    \n    sup_secs = [\"abstract\", \"body_text\", \"back_matter\"]\n    title_info = {\n        \"supsec_order\": np.nan,\n        \"supersection\": \"title\",\n        \"section_order\": np.nan,\n        \"section\": \"title\",\n        \"text\": json_data[\"metadata\"][\"title\"],\n    }\n    dfs = [pd.DataFrame([title_info])]\n    for ss_idx, sup_sec in enumerate(sup_secs):\n        df = pd.DataFrame(\n            [parse_section(**section) for section in json_data[sup_sec]],\n            columns=[\"section\", \"text\"],\n        )\n        df.insert(0, \"section_order\", df.index)\n        df.insert(0, \"supersection\", sup_sec)\n        df.insert(0, \"supsec_order\", ss_idx)\n        dfs.append(df)\n\n    res_df = pd.concat(dfs, axis=0).reset_index(drop=True)\n    res_df.insert(0, \"paper_id\", json_data[\"paper_id\"])\n\n    return res_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"# source directory; most likely = \"/kaggle/input\"\nSOURCE_DIR = \"/kaggle/input\"\n\n# source name : source path mapping\nSOURCES = {\n    \"biorxiv\": \"./CORD-19-research-challenge/biorxiv_medrxiv/biorxiv_medrxiv\",\n    \"comm_use\": \"./CORD-19-research-challenge/comm_use_subset/comm_use_subset\",\n    \"noncomm_use\": \"./CORD-19-research-challenge/noncomm_use_subset/noncomm_use_subset\",\n    \"custom_license\": \"./CORD-19-research-challenge/custom_license/custom_license\",\n}\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Process JSON data and Export as csv\nfor source, path in tqdm(SOURCES.items(), desc=\"sources\"):\n    with mp.Pool() as pool:\n        files = list(glob.glob(os.path.join(SOURCE_DIR, path, \"*.json\")))\n        src_dfs = list(\n            tqdm(\n                pool.imap(parse_paper_json, files),\n                total=len(files),\n                desc=\"{} files\".format(source),\n            )\n        )\n\n    src_df = pd.concat(src_dfs).reset_index(drop=True)\n    src_df[\"source\"] = source\n    \n    src_df.to_csv(\"{}-parsed.csv.gz\".format(source), index=False, compression='gzip')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}