{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, cohen_kappa_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/health-insurance-cross-sell-prediction/train.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No null values present in the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style='whitegrid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['Response'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can clearly see that the dataset is highly unbalanced in nature. We shall need to take the correct steps to ensure that this unbalanced nature  does not affect our final model."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['Driving_License'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['Driving_License'] == 0].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that it's mostly the retired citizens (age>65) who do not possess a driving license."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['Response'], hue=df['Previously_Insured'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus everyone who gave a positive (1) reponse was a new customer or was getting insured the first time"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['Age'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.violinplot(df['Age'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Most of the people buy a car from the age-group (20-30) and get their insurance done.\n2. Again in age-group (40-50) people buy cars (After saving money, or a part of their retirement plan)"},{"metadata":{},"cell_type":"markdown","source":"Taking a look at the 'Gender' column"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['Gender'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['Gender'], hue=df['Response'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['Response'] ,hue=df['Previously_Insured'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the customers who gave a positive response were not previously insured. This can also be a good point to research on."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['Vehicle_Damage'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['Response'], hue=df['Vehicle_Damage'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From this plot we can see that all customers which gave a postive response had a **Vehical Damage**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['Response'], hue=df['Vehicle_Age'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We cannot make any good guess from the 'Vehicle_Age' column.\n#### Let's try looking at the numeric(continuous) features"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('Region_Code')['Response'].agg('mean').sort_values().head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['Annual_Premium'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df['Annual_Premium'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The annual premium has a lot of outliers, let's check if they are interesting"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Annual_Premium'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"high_premium = df[df['Annual_Premium'] >39400.00]\nhigh_premium.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['Response'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(high_premium['Response'].value_counts())\nsns.countplot(high_premium['Response'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, we can see that nearly 30% customers who gave a positive response are high premium customers.\nThus we can include a feature that checks if a customer is having high premium or not."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(df['Annual_Premium'], df['Response'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# gender\ndf['Gender'] = df['Gender'].map({'Female':0, 'Male':1}).astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.get_dummies(df, drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.rename(columns = {'Vehicle_Age_< 1 Year':'AgeOneYear',\n                          'Vehicle_Age_> 2 Years':'AgeTwoYears',\n                          'Vehicle_Damage_Yes':'Vehicle_Damage'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['AgeOneYear'] = df['AgeOneYear'].astype('int')\ndf['AgeTwoYears'] = df['AgeTwoYears'].astype('int')\ndf['Vehicle_Damage'] = df['Vehicle_Damage'].astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['HighPremium'] = np.where(df['Annual_Premium'] > 39400.00, 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(['id', 'Response'], axis=1)\ny = df['Response']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y, random_state = 0, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\nX_train_sc = scaler.fit_transform(X_train)\nX_test_sc = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Building"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1. Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression()\nsolvers = ['newton-cg', 'lbfgs', 'liblinear']\npenalty = ['l1','l2']\nc_values = [100, 10, 1.0, 0.1, 0.01]\n# define grid search\ngrid = dict(solver=solvers,penalty=penalty,C=c_values)\n\ngrid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=3, scoring='f1',error_score=0)\ngrid_result = grid_search.fit(X_train_sc, y_train)\n\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(C=10, class_weight='balanced')\nlr.fit(X_train_sc, y_train)\n\ny_pred = lr.predict(X_test_sc)\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get importance\nimportance = lr.coef_[0]\n# summarize feature importance\nfor i,v in enumerate(importance):\n    print('Feature: %0d, Score: %.5f' % (i,v))\n# plot feature importance\nplt.bar([x for x in X_train.columns], importance)\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import auc\n\n\n# plot no skill and model precision-recall curves\ndef plot_pr_curve(y_test, model_probs):\n    # calculate the no skill line as the proportion of the positive class\n    no_skill = len(y_test[y_test==1]) / len(y_test)\n    # plot the no skill precision-recall curve\n    plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n    # plot model precision-recall curve\n    precision, recall, thresholds = precision_recall_curve(y_test, model_probs)\n    # convert to f score\n#     fscore = (2 * precision * recall) / (precision + recall)\n#     # locate the index of the largest f score\n#     ix = np.argmax(fscore)\n#     print('Best Threshold=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))\n    plt.plot(recall, precision, marker='.', label='Logistic')\n    #plt.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best')\n    # axis labels\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    # show the legend\n    plt.legend()\n    # show the plot\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yhat = lr.predict_proba(X_test_sc)\nmodel_probs = yhat[:, 1]\n# calculate the precision-recall auc\nprecision, recall, _ = precision_recall_curve(y_test, model_probs)\nauc_score = auc(recall, precision)\nprint('Logistic PR AUC: %.3f' % auc_score)\n# plot precision-recall curves\nplot_pr_curve(y_test, model_probs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, roc_curve\n\nprint('Area under curve score for Logistic Regression is: ', roc_auc_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Random Forests"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf1 = RandomForestClassifier(n_estimators=300, max_depth=8, min_samples_split=4,\n                             max_features='auto', bootstrap=True, min_samples_leaf=4,\n                            class_weight='balanced_subsample')\nrf1.fit(X_train, y_train)\ny_pred = rf1.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_train, rf1.predict(X_train)))\nprint('Accuracy of our model is: ', accuracy_score(y_train, rf1.predict(X_train)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test, y_pred))\nprint('Accuracy of our model is: ', accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))\nprint('Area under curve score for Random Forests is: ', roc_auc_score(y_test, y_pred))\nprint('Kappa score for Random Forests',cohen_kappa_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yhat = rf1.predict_proba(X_test)\nmodel_probs = yhat[:, 1]\n# calculate the precision-recall auc\nprecision, recall, _ = precision_recall_curve(y_test, model_probs)\nauc_score = auc(recall, precision)\nprint('Logistic PR AUC: %.3f' % auc_score)\n# plot precision-recall curves\nplot_pr_curve(y_test, model_probs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = pd.DataFrame()\nfeatures['Feature'] = X_train.columns\nfeatures['Importance'] = rf1.feature_importances_\nfeatures.sort_values(by=['Importance'], ascending=False, inplace=True)\nfeatures.set_index('Feature', inplace=True)\nfeatures.plot(kind='bar', figsize=(20, 10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting AUC-ROC curves for both Random Forest and Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict probabilities\npred_prob1 = lr.predict_proba(X_test_sc)\npred_prob2 = rf1.predict_proba(X_test)\n\n# roc curve for models\nfpr1, tpr1, thresh1 = roc_curve(y_test, pred_prob1[:,1], pos_label=1)\nfpr2, tpr2, thresh2 = roc_curve(y_test, pred_prob2[:,1], pos_label=1)\n\n# roc curve for tpr = fpr \nrandom_probs = [0 for i in range(len(y_test))]\np_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)\n\n# auc scores\nauc_score1 = roc_auc_score(y_test, pred_prob1[:,1])\nauc_score2 = roc_auc_score(y_test, pred_prob2[:,1])\n\nprint('AUC for Logistic Regression', auc_score1, \n      'AUC for Random Forests', auc_score2)\n\n# plot roc curves\nplt.plot(fpr1, tpr1, linestyle='--',color='orange', label='Logistic Regression')\nplt.plot(fpr2, tpr2, linestyle='--',color='green', label='Random Forests')\nplt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n# title\nplt.title('ROC curve')\n# x label\nplt.xlabel('False Positive Rate')\n# y label\nplt.ylabel('True Positive rate')\n\nplt.legend(loc='best')\nplt.savefig('ROC',dpi=300)\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's also try a simple Gradient Boost classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\nclf = GradientBoostingClassifier(n_estimators=200, min_samples_split=5,max_depth=6,\n                                max_features = 'auto')\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test, y_pred))\nprint('Accuracy of our model is: ', accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\nprint('Area under curve score for GBM is: ', roc_auc_score(y_test, y_pred))\nprint('Kappa score for GBM',cohen_kappa_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The End"},{"metadata":{},"cell_type":"markdown","source":"Please upvote if this notebook was of any use to you. Feel free to comment."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}