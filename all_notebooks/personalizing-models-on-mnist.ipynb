{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Overview\nThe idea is to train a model that is 'personalizable' basically where we learn a feature representation of an input, independently from the source of that input. We then use a simple 'rotation' (matrix-multiplication) to transform the feature vector into a prediction. The goal would be for the the rotation can be easily learned with a few samples from the dataset using logistic regression (and doesn't require the entire training infrastructure necessary for the model). \n\n$$ \\vec{y} = \\hat{W}*\\textrm{DNN}_{input}(\\vec{x})+\\vec{b} $$\n$$ W, b = \\textrm{DNN}_{src}(\\vec{s}) $$"},{"metadata":{},"cell_type":"markdown","source":"# Setup"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport seaborn as sns\nplt.rcParams[\"figure.figsize\"] = (10, 10)\nplt.rcParams[\"figure.dpi\"] = 125\nplt.rcParams[\"font.size\"] = 14\nplt.rcParams['font.family'] = ['sans-serif']\nplt.rcParams['font.sans-serif'] = ['DejaVu Sans']\nplt.style.use('ggplot')\nsns.set_style(\"whitegrid\", {'axes.grid': False})\nfrom itertools import cycle\nprop_cycle = plt.rcParams['axes.prop_cycle']\ncolors = prop_cycle.by_key()['color']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from pathlib import Path\nimport numpy as np\nimport pandas as pd\nimport doctest\nimport copy\nimport functools\nimport zipfile as zf\nfrom skimage.io import imread\nfrom skimage.util import montage as montage2d\nfrom skimage.color import label2rgb\nfrom functools import lru_cache\nfrom shutil import copyfile\nfrom tqdm import tqdm_notebook\n# tests help notebooks stay managable\n\ndef autotest(func):\n    globs = copy.copy(globals())\n    globs.update({func.__name__: func})\n    doctest.run_docstring_examples(\n        func, globs, verbose=True, name=func.__name__)\n    return func","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data\nTo test this we use MNIST, FashionMNIST and GestureMNIST. Lukcily all of them are 28x28 images stored as `label, pixel values...`"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_path = Path('..') / 'input'\ndef read_minst_csv(in_path, src_cat):\n    c_df = pd.read_csv(in_path).assign(src=in_path.parent.stem).assign(src_cat=src_cat)\n    c_df.columns = ['label']+['pix_{:03d}'.format(i) for i in range(784)]+['src', 'src_cat']\n    return c_df\nall_input_dict = {c_path.parent.stem: read_minst_csv(c_path, idx) for idx, c_path in enumerate(base_path.glob('*/*train*.csv'))}\nall_df = pd.concat(all_input_dict.values())\nall_df.sample(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Format Images and Show Examples\nHere we format the results as images and show examples"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom keras.utils.np_utils import to_categorical\nfrom skimage.feature import canny\nfrom skimage.filters import sobel\n\nimage_df = pd.DataFrame({\n    'src': all_df['src'].values,\n    'label': all_df['label'].map(lambda x: 9 if x==10 else x).values, # remap 10 to 9\n    # run edge detection to make the images more similar\n    'image': all_df.iloc[:, 1:-2].apply(lambda x: \n                                        np.expand_dims(sobel(np.reshape(x.values, (28, 28)).astype('float')), -1)\n                                        , 1)\n}).query('label<=9')\n\n\nsrc_encoder = LabelEncoder()\nimage_df['src_cat'] = src_encoder.fit_transform(image_df['src'])\nimage_df['src_cat_oh'] = to_categorical(image_df['src_cat']).tolist()\nimage_df['label_oh'] = to_categorical(image_df['label']).tolist()\nimage_df.sample(3)\n\nfig, m_axs = plt.subplots(3, 3)\nfor (_, c_row), c_ax in zip(image_df.sample(9).iterrows(), m_axs.flatten()):\n    c_ax.imshow(c_row['image'][:, :, 0])\n    c_ax.set_title('{src}-{label}'.format(**c_row))\n    c_ax.axis('off')\n\nimage_df.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_df['image_mean'] = image_df['image'].map(np.mean)\nimage_df.groupby(['src', 'label']).agg({'image_mean': 'mean'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Splits\nIf our approach is really better than we should try some simple existing approaches. Basically we want to train the model on 2 sources and see how well it works on the third using just a few examples. So we create the training and validation datasets accordingly."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = image_df[image_df['src'].isin(['fashionmnist', 'sign-language-mnist'])].copy()\ntest_df = image_df[~image_df['src'].isin(['fashionmnist', 'sign-language-mnist'])].copy()\nprint(train_df.shape, test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Baseline Model\nHere we use a simple siamese network and train using triplets"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import layers, models\nfrom keras.utils import vis_utils\nfrom keras import backend as K\nfrom IPython.display import SVG, display","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encoder_model():\n    in_lay = layers.Input((28, 28, 1), name='Image_Input')\n    x = layers.BatchNormalization()(in_lay)\n    for i in range(3):\n        x = layers.Conv2D(8, (3,3), activation='relu')(x)\n        if i<2:\n            x = layers.MaxPool2D((2,2))(x)\n    x = layers.Flatten()(x)\n    x = layers.Dropout(0.5)(x)\n    x = layers.Dense(16, name='Feature_Vector', activation='tanh')(x)\n    return models.Model(inputs=[in_lay], outputs=[x], name='CNN_Encoder')\nenc_model = encoder_model()\ndisplay(SVG(vis_utils.model_to_dot(enc_model, show_shapes=True).create_svg()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _triplet_func(x):\n    a_min_b, a_min_c, b_min_c = x\n    return K.mean(K.square(a_min_b), axis=1)-K.mean(K.square(a_min_c)+K.square(b_min_c), axis=1)/2\n    \ndef create_triplet_model(enc_model):\n    img_a = layers.Input((28, 28, 1), name='Image_Same_A')\n    img_b = layers.Input((28, 28, 1), name='Image_Same_B')\n    img_diff = layers.Input((28, 28, 1), name='Image_Different')\n    feat_a = enc_model(img_a)\n    feat_b = enc_model(img_b)\n    feat_diff = enc_model(img_diff)\n    a_min_b = layers.subtract([feat_a, feat_b])\n    a_min_c = layers.subtract([feat_a, feat_diff])\n    b_min_c = layers.subtract([feat_b, feat_diff])\n    trip_score = layers.Lambda(_triplet_func, name='TripletLoss')([a_min_b, a_min_c, b_min_c])\n    return models.Model(inputs=[img_a, img_b, img_diff], outputs=[trip_score])\n\ntriplet_model = create_triplet_model(enc_model)\ndisplay(SVG(vis_utils.model_to_dot(triplet_model, show_shapes=True).create_svg()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def triplet_loss(y_true, y_pred):\n    return y_pred\ntriplet_model.compile(optimizer='adam', loss=triplet_loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gen_trip_batch(in_df):\n    while True:\n        for _, c_df in in_df.groupby('src'):\n            label = c_df.sample(1)['label'].iloc[0]\n            pos_rows = c_df[c_df['label'].isin([label])].sample(2)\n            a_row, b_row = pos_rows.iloc[0], pos_rows.iloc[1]\n            c_row = c_df[~c_df['label'].isin([label])].sample(1).iloc[0]\n            yield {'Image_Same_A': a_row['image'], 'Image_Same_B': b_row['image'], 'Image_Different': c_row['image']}, {'TripletLoss': [0]}\nfig, m_axs = plt.subplots(3, 3)\nfor c_axs, (t_x, t_y) in zip(m_axs, gen_trip_batch(train_df)):\n    for c_ax, (k,v) in zip(c_axs, t_x.items()):\n        c_ax.imshow(v[:, :, 0], cmap='gray')\n        c_ax.set_title(k)\n        c_ax.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@autotest\ndef batch_it(in_gen, batch_size=64):\n    \"\"\"Collect and batch output from a generator\n    >>> gen_obj = [({'x': [i]}, {'y': [4-i]}) for i in range(3)]\n    >>> b_gen = batch_it(gen_obj, 2)\n    >>> x, y = next(b_gen)\n    >>> for k,v in x.items(): print(k, v) # doctest: +NORMALIZE_WHITESPACE\n    x [[0]\n     [1]]\n    >>> for k,v in y.items(): print(k, v) # doctest: +NORMALIZE_WHITESPACE\n    y [[4]\n     [3]]\n    \"\"\"\n    out_vals = []\n    for c_vals in in_gen:\n        out_vals += [c_vals]\n        if len(out_vals)==batch_size:\n            yield tuple([{k: np.stack([c_row[i][k] for c_row in out_vals], 0) \n                       for k in c_vals[i].keys()}\n                       for i in range(len(c_vals))])\n            out_vals = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_model(in_model, epochs=1, steps_per_epoch=100, validation_steps=10):\n    return triplet_model.fit_generator(batch_it(gen_trip_batch(train_df)),\n                           steps_per_epoch=steps_per_epoch,\n                           validation_data=batch_it(gen_trip_batch(test_df)),\n                           validation_steps=validation_steps,\n                           epochs=epochs)\n\ndef show_triplet_batch(n=5):\n    \"\"\"Shows a batch of n images from all datasets\"\"\"\n    fig, m_axs = plt.subplots(3, n, figsize=(12, 12))\n    for c_axs, (t_x, t_y) in zip(m_axs.T, gen_trip_batch(image_df)):\n        vec_out = {}\n        for c_ax, (k,v) in zip(c_axs, t_x.items()):\n            c_ax.imshow(v[:, :, 0], cmap='gray')\n            vec_out[k] = enc_model.predict(np.expand_dims(v, 0))[0]\n            c_ax.set_title(k)\n            c_ax.axis('off')\n        a_min_b = np.sqrt(np.mean(np.square(vec_out['Image_Same_A']-vec_out['Image_Same_B'])))\n        a_min_c = np.sqrt(np.mean(np.square(vec_out['Image_Same_A']-vec_out['Image_Different'])))\n        c_ax.set_title('A-B={:2.1%}\\nA-C={:2.1%}'.format(a_min_b, a_min_c))\nshow_triplet_batch()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fit_model(triplet_model, 1)\nshow_triplet_batch()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fit_model(triplet_model, 9)\nshow_triplet_batch()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_df['feature_vec'] = enc_model.predict(np.stack(image_df['image'].values, 0)).tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\nfeat_pca = PCA(n_components=2)\nfeat_pca.fit(np.stack(image_df['feature_vec'].values, 0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, m_axs = plt.subplots(1, 3, figsize=(10, 3))\nfor (c_src, src_df), c_ax in zip(image_df.groupby('src'), m_axs):\n    for k, c_rows in src_df.groupby('label'):\n        xy_vec = feat_pca.transform(np.stack(c_rows['feature_vec'], 0))\n        c_ax.plot(xy_vec[:, 0], xy_vec[:, 1], '.', label='#{}'.format(k), ms=0.5, alpha=0.5)\n    c_ax.set_title(c_src)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfig, m_axs = plt.subplots(1, 3, figsize=(15, 5))\nfor (c_src, src_df), c_ax in zip(image_df.groupby('src'), m_axs):\n    src_train_df, src_test_df = train_test_split(src_df, random_state=2019, test_size=0.8)\n    lr = LogisticRegression()\n    lr.fit(np.stack(src_train_df['feature_vec'], 0), src_train_df['label'])\n    pred_lr = lr.predict(np.stack(src_test_df['feature_vec'], 0))\n    conf_mat = confusion_matrix(pred_lr, src_test_df['label'])\n    sns.heatmap(conf_mat, ax=c_ax)\n    c_ax.set_title('{} {:2.2%}'.format(c_src, accuracy_score(pred_lr, src_test_df['label'])))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}