{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Objective\n* To develop a model that can identify all actual positive case, i.e. 100% recall rate is the ideal case\n* False positive is okay \n* False negative is NOT okay"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n\nimport sklearn.model_selection as ms\nimport sklearn.metrics as m\nimport sklearn.tree as tree\nimport sklearn.ensemble as ensemble\nimport sklearn.svm as svm\nimport sklearn.linear_model as lm\nimport sklearn.preprocessing as pp\nimport sklearn.compose as compose\nimport sklearn.pipeline as pipe\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/credit-card-customers/BankChurners.csv')\ndata.drop(['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\\\n           'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2', 'CLIENTNUM'], inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Basic EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.iloc[:, :11].head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.iloc[:, 11:].head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Attrition_Flag'].value_counts(normalize=True) * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# display all unique values from all the columns\nfor col in data.columns:\n    print(col)\n    print(data[col].unique())\n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.iloc[:, :11].head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.iloc[:, 11:].head(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Attrition_Flag'].replace({'Attrited Customer': 1, 'Existing Customer': 0}, inplace=True)\ndata['Gender'].replace({'M': 1, 'F': 0}, inplace=True) # do not need to one-hot encode","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_attribute_2b_encoded = ['Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category']\n\nnum_attribute_2b_transform = [i for i in data.columns if i not in cat_attribute_2b_encoded]\nnum_attribute_2b_transform = [i for i in num_attribute_2b_transform if i not in ['Attrition_Flag', 'Gender']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'No of numercial attribute: {len(num_attribute_2b_transform)}')\nprint(f'No of categorical attribute: {len(cat_attribute_2b_encoded)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data['Attrition_Flag'].copy()\n\nX = data.copy()\nX.drop('Attrition_Flag', inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Transformation Pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_pipeline = pipe.Pipeline([\n                            ('scaler', pp.StandardScaler())\n])\n\n\nfull_pipeline = compose.ColumnTransformer([\n                            ('num', num_pipeline, num_attribute_2b_transform),\n                            ('cat', pp.OneHotEncoder(), cat_attribute_2b_encoded)\n                                        ], remainder='passthrough', sparse_threshold=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_transform = full_pipeline.fit_transform(X)\n\nprint(X_transform.shape)\nprint(full_pipeline.named_transformers_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_transform_feature_names = list(full_pipeline.named_transformers_['cat'].get_feature_names())\nlen(cat_transform_feature_names)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_val, X_test, y_train_val, y_test = ms.train_test_split(\\\n                                    X_transform, y, train_size=0.75, random_state=42, stratify=y, shuffle=True)\nX_train, X_validation, y_train, y_validation = ms.train_test_split(\\\n                                    X_train_val, y_train_val, train_size=0.75, random_state=42, stratify=y_train_val, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Total number of Instances: {X_transform.shape[0]}')\nprint(f'Size of Training Dataset: {X_train.shape[0]}')\nprint(f'Size of Validation Dataset: {X_validation.shape[0]}')\nprint(f'Size of Testing Dataset: {X_test.shape[0]}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Candidates Models & Ensemble (BASELINE)"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_clf = ensemble.RandomForestClassifier(random_state=42)\ndt_clf = tree.DecisionTreeClassifier(random_state=42)\next_clf = ensemble.ExtraTreesClassifier(random_state=42)\ngb_clf = ensemble.GradientBoostingClassifier(random_state=42)\n\nvoting_classifier = ensemble.VotingClassifier([\n                    ('rf_clf', ensemble.RandomForestClassifier(random_state=42)),\n                    ('dt_clf', tree.DecisionTreeClassifier(random_state=42)),\n                    ('ext_clf', ensemble.ExtraTreesClassifier(random_state=42)),\n                    ('gb_clf', ensemble.GradientBoostingClassifier(random_state=42))\n                    ], voting='hard')\n\nestimators = [rf_clf, dt_clf, ext_clf, gb_clf, voting_classifier]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Performance on Training Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = ms.RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)\n\nfor estimator in estimators:\n    estimator.fit(X_train, y_train)\n    cv_accuracy = ms.cross_val_score(estimator, X_train, y_train, cv=cv, n_jobs=-1, scoring='accuracy')\n    cv_recall = ms.cross_val_score(estimator, X_train, y_train, cv=cv, n_jobs=-1, scoring='recall')\n    cv_f1 = ms.cross_val_score(estimator, X_train, y_train, cv=cv, n_jobs=-1, scoring='f1')\n    \n    print(estimator.__class__.__name__)\n    print(f'Avg Accuracy: {round(np.mean(cv_accuracy) * 100,2)}')\n    print(f'Std Accuracy: {round(np.std(cv_accuracy) * 100,2)}')\n    \n    print(f'Avg Recall: {round(np.mean(cv_recall) * 100,2)}')\n    print(f'Std Rcall: {round(np.std(cv_recall) * 100,2)}')\n    \n    print(f'Avg F1: {round(np.mean(cv_f1) * 100,2)}')\n    print(f'Std F1: {round(np.std(cv_f1) * 100,2)}')\n    print()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Performance on Validation Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"for estimator in estimators:\n    prediction = estimator.predict(X_validation)\n\n    print(estimator.__class__.__name__)\n    print(f'Accuracy score: {round(m.accuracy_score(y_validation, prediction) * 100,2)}')\n    print(f'Precision score: {round(m.precision_score(y_validation, prediction) * 100,2)}')\n    print(f'Recall score: {round(m.recall_score(y_validation, prediction) * 100,2)}')\n    print(f'F1 score: {round(m.f1_score(y_validation, prediction) * 100,2)}')\n    print()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# New Voting Model and Performance on Training and Validation Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# From a recall perspective, ExtraTreesClassifier does not seems to be performing well as compared to the other models\n# Let's remove ExtraTreesClassifier from the ensemble VotingClassifier and see if the performance of the voting classifier improves\n\nnew_voting_classifier = ensemble.VotingClassifier([\n                    ('rf_clf', ensemble.RandomForestClassifier(random_state=42)),\n                    ('dt_clf', tree.DecisionTreeClassifier(random_state=42)),\n                    ('gb_clf', ensemble.GradientBoostingClassifier(random_state=42))\n                    ], voting='hard')\n\nnew_voting_classifier_list = [new_voting_classifier]\n\ncv = ms.RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)\nprint('Performance on Training Data')\nprint()\nfor estimator in new_voting_classifier_list:\n    estimator.fit(X_train, y_train)\n    cv_accuracy = ms.cross_val_score(estimator, X_train, y_train, cv=cv, n_jobs=-1, scoring='accuracy')\n    cv_recall = ms.cross_val_score(estimator, X_train, y_train, cv=cv, n_jobs=-1, scoring='recall')\n    cv_f1 = ms.cross_val_score(estimator, X_train, y_train, cv=cv, n_jobs=-1, scoring='f1')\n    \n    print(estimator.__class__.__name__)\n    print(f'Avg Accuracy: {round(np.mean(cv_accuracy) * 100,2)}')\n    print(f'Std Accuracy: {round(np.std(cv_accuracy) * 100,2)}')\n    print(f'Avg Recall: {round(np.mean(cv_recall) * 100,2)}')\n    print(f'Std Rcall: {round(np.std(cv_recall) * 100,2)}')\n    print(f'Avg F1: {round(np.mean(cv_f1) * 100,2)}')\n    print(f'Std F1: {round(np.std(cv_f1) * 100,2)}')\n    print()\n    \n    print('Performance on Validation Dataset')\n    prediction = estimator.predict(X_validation)\n    print(f'Accuracy score: {round(m.accuracy_score(y_validation, prediction) * 100,2)}')\n    print(f'Precision score: {round(m.precision_score(y_validation, prediction) * 100,2)}')\n    print(f'Recall score: {round(m.recall_score(y_validation, prediction) * 100,2)}')\n    print(f'F1 score: {round(m.f1_score(y_validation, prediction) * 100,2)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Result Commentary on Models from Training and Validation Dataset\n* While the recall performance of the new voting classifier on the validation dataset improves from 77.1% to 85.9%, it is still lower than the performance result from GB Classifier\n\n\n* Based on the validation dataset, GB Classifier seems to the best performing estimator\n    * Highest recall score of 86.9% and 83.8% in validation and training dataset\n\n\n* Let's fine-tuned the GB Classifier model \n\n                                                             \n\n| Models              \t| Recall Score on Training Set \t| Recall Score on Validation Set \t|\n|---------------------\t|------------------------------\t|--------------------------------\t|\n| RandomForest        \t| 75.11                        \t| 80.66                          \t|\n| DecisionTree        \t| 79.12                        \t| 81.31                          \t|\n| ExtraTrees          \t| 58.07                        \t| 63.28                          \t|\n| GradientBoosting    \t| 83.79                        \t| 86.89                          \t|\n| Old Voting Ensemble \t| 70.13                        \t| 77.05                          \t|\n| New Voting Ensemble \t| 81.97                        \t| 85.9                           \t|"},{"metadata":{},"cell_type":"markdown","source":"# Hyperparameter Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"gb_clf.get_params()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parameter_grid = [\n                {'n_estimators': [50,75,100,125,150],\n                'learning_rate': np.arange(0.1,1.0,0.1),\n                }, \n                {'ccp_alpha': np.arange(0.1,1.0,0.1)   \n                },\n                {'max_leaf_nodes': [25,50,75,100],\n                 'min_samples_split': [25,50,75,100],\n                 'min_samples_leaf': [25,50,75,100]\n                }, \n                {'max_depth': [3,5,10,20,25,50,75,100],\n                 'max_features': [None, 5, 10,15,20,25,36]\n                }\n                ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb_clf_grid_search_cv = ms.GridSearchCV(gb_clf, parameter_grid, scoring=\"recall\", cv=3, return_train_score= True)\ngb_clf_grid_search_cv.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb_clf_grid_search_cv.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb_clf_grid_search_cv.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Best Estimator Training and Performance on Test Data\n* Best Estimator will be trained on the full training set\n* We then proceed to test it on the testing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"best_gb_clf = gb_clf_grid_search_cv.best_estimator_\nbest_gb_clf.fit(X_train_val, y_train_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Performance on testing data\n\ntraining_prediction = best_gb_clf.predict(X_test)\n\nprint(m.accuracy_score(y_test, training_prediction) * 100)\nprint(m.precision_score(y_test, training_prediction) * 100)\nprint(m.recall_score(y_test, training_prediction) * 100)\nprint(m.f1_score(y_test, training_prediction) * 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}