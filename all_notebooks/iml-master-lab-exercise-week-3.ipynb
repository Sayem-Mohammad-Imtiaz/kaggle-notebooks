{"cells":[{"metadata":{},"cell_type":"markdown","source":"#  **Logistic Regression & Numerical Transformations**\nLab Exercises - Week 3\n\n----------"},{"metadata":{},"cell_type":"markdown","source":"## **Notebook Contents:**\n1. Regression Parameters: Adjusted R-Squared & P-value.\n2. Analysing numerical transformations with Statsmodels.  \n3. Numerical transformations (Polynomial) with Scikit-Learn.\n4. Model evaluation with Linear Regression (Using R-squared).\n5. Logistic Regression with Scikit-Learn.\n6. Multiple Logistic Regression with Scikit-Learn (Categorical Predictors).\n\n---------"},{"metadata":{},"cell_type":"markdown","source":"### **Python Libraries:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Installing libraries\n!pip install regressors","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom regressors import stats\nfrom sklearn import linear_model as lm\nimport statsmodels.formula.api as sm\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression \nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **1. Regression Parameters: Adjusted R-Squared & P-value:**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#Data Preprocessing \nd = pd.read_csv(\"../input/survey.csv\")\nd = d.rename(index=str,columns={\"Wr.Hnd\":\"WrHnd\"})\nd = d[[\"WrHnd\",\"Height\"]]\nd = d.dropna()\n\n#Model Fit \ninputDF = d[[\"WrHnd\"]]\noutcomeDF = d[[\"Height\"]]\nmodel = lm.LinearRegression()\nresults = model.fit(inputDF,outcomeDF)\n\n#Regression coefficients\nprint(model.intercept_, model.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Adjusted R-Squared:\\n\",stats.adj_r2_score(model, inputDF, outcomeDF))\n\nprint(\"P-value:\\n\",stats.coef_pval(model, inputDF, outcomeDF))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **2. Analysing numerical transformations with Statsmodels:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data Preprocessing \nd = pd.read_csv(\"../input/survey.csv\")\nd = d.rename(index=str,columns={\"Wr.Hnd\":\"WrHnd\"})\nd = d[[\"WrHnd\",\"Height\"]]\nd = d.dropna()\n\n#Adjusted R-Squared & P-vlaue genarated using Statsmodels\nres = sm.ols(formula=\"Height ~ WrHnd\",data=d).fit()\nprint(res.summary())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Linear Regression:**\n![](https://i.ibb.co/yPtV2Jp/img2.png)![](https://i.ibb.co/znrYMMv/img1.png) \n**Polynomial Regression:**\n![](https://i.ibb.co/k9pCyZ7/img4.png)![](https://i.ibb.co/V2zckr1/img3.png) "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adjusted R-Squared & P-vlaue genarated for cubic polynomial transformation\nres = sm.ols(formula=\"Height ~ WrHnd + I(WrHnd*WrHnd)+ I(WrHnd*WrHnd*WrHnd)\",data=d).fit()\nprint(res.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adjusted R-Squared & P-vlaue genarated for logarithmic transformation\nres = sm.ols(formula = \"Height ~ np.log(WrHnd)\",data=d).fit()\nprint(res.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **3. Numerical transformations (Polynomial) with Scikit-Learn:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Declaring a dataframe\nd = {'sno': [1,2,3,4,5,6],\n     'Temperature': [0, 20, 40, 60, 80, 100], \n     'Pressure': [0.0002, 0.0012, 0.0060, 0.0300, 0.0900, 0.2700]}\n\ndf = pd.DataFrame(d)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Fit - Linear Regression\ninputDF = df.iloc[:, 1:2].values \noutputDF = df.iloc[:, 2].values\n\nlin = LinearRegression()  \nlin.fit(inputDF, outputDF)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Fit - Polynomial Regression\npoly = PolynomialFeatures(degree = 4) \ninputDF_poly = poly.fit_transform(inputDF) \n\npoly.fit(inputDF_poly, outputDF) \nlin2 = LinearRegression() \nlin2.fit(inputDF_poly, outputDF) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scatter Plot - Linear Regression\nplt.scatter(inputDF, outputDF, color = 'blue') \n  \nplt.plot(inputDF, lin.predict(inputDF), color = 'red') \nplt.title('Linear Regression') \nplt.xlabel('Temperature') \nplt.ylabel('Pressure') \n  \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scatter Plot - Polynomial Regression\nplt.scatter(inputDF, outputDF, color = 'blue') \n  \nplt.plot(inputDF, lin2.predict(poly.fit_transform(inputDF)), color = 'red') \nplt.title('Polynomial Regression') \nplt.xlabel('Temperature') \nplt.ylabel('Pressure') \n  \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **4. Model evaluation with Linear Regression (Using R-squared):**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model 1 - Evaluation using train_test_split\ndf = pd.read_csv(\"../input/mtcars.csv\")\n\ninputDF = df[[\"hp\",\"am\"]]\noutputDF = df[[\"mpg\"]]\n\nX_train, X_test, y_train, y_test = train_test_split(inputDF, outputDF, test_size=0.2, random_state=0) \n\nmodel = lm.LinearRegression()\nresults = model.fit(X_train,y_train)\n\nprint(\"R - Squared value:\\n\",stats.adj_r2_score(model, X_train, y_train)) \n\nprint(model.intercept_, model.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model 1 - Prediction\ny_pred = model.predict(X_test) \nprint(\"Predicted value:\\n\", y_pred) \nprint(\"Originial value:\\n\", y_test) \nprint(\"RMSE:\\n\", np.sqrt(metrics.mean_squared_error(y_test, y_pred)))      ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model 2 - Evaluation using train_test_split\ninputDF = df[[\"hp\"]]\noutputDF = df[[\"mpg\"]]\n\nX_train, X_test, y_train, y_test = train_test_split(inputDF, outputDF, test_size=0.2, random_state=0) \nregressor = LinearRegression()  \nregressor.fit(X_train, y_train) \nprint(\"R - Squared value:\\n\",stats.adj_r2_score(regressor, X_train, y_train)) \nprint(regressor.intercept_)\nprint(regressor.coef_)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model 2 - Prediction\ny_pred = regressor.predict(X_test)\nprint(\"Predicted value:\\n\", y_pred) \nprint(\"Originial value:\\n\", y_test) \nprint(\"RMSE:\\n\", np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **5. Logistic Regression with Scikit-Learn:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"d=pd.read_csv(\"../input/default.csv\")\nd.head()\nd[\"balance\"].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add a new column DefaultYes which is 1 for Yes and 0 for No\nd['DefaultYes'] = d['default'].map({'Yes': 1, 'No': 0})\nd.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scikit-learn - Linear Regression\nregressor = LinearRegression()  \ninputDf = d[['balance']]\noutputDf = d[['DefaultYes']]\nregressor.fit(inputDf, outputDf) \nprint(regressor.intercept_)\nprint(regressor.coef_[0]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Input Dataframe\nx1new = pd.DataFrame(np.hstack((np.arange(0,3000))))\nx1new.columns=[\"balance\"]\nyp2new = regressor.predict(x1new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scatter Plot\nplt.scatter(d[\"balance\"],d[\"DefaultYes\"])\nplt.plot(x1new,yp2new,color=\"red\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Logistic Regression\ninputDf = d[['balance']]\noutputDf = d[['DefaultYes']].values.ravel()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Fit - Logistic Regression\nlogisticRegr = LogisticRegression(solver='lbfgs')\nlogisticRegr.fit(inputDf, outputDf)\nprint(logisticRegr.intercept_)\nprint(logisticRegr.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#New Dataframe and prediction\nx1new = pd.DataFrame(np.hstack((np.arange(0,3000))))\nx1new.columns=[\"balance\"]\nyp2new = logisticRegr.predict(x1new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot\nplt.scatter(d[\"balance\"],d[\"DefaultYes\"])\nplt.plot(x1new,yp2new,color=\"red\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **6. Multiple Logistic Regression with Scikit-Learn (Categorical Predictors):**"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = pd.read_csv(\"../input/default.csv\")\nd = d[[\"default\",\"balance\",\"income\",\"student\"]]\nd.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add a new column DefaultYes which is 1 for Yes and 0 for No\nd['DefaultYes'] = d['default'].map({'Yes': 1, 'No': 0})\nd.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d = d.drop(['default'], axis=1)\nd.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Categorical Predictors\nd = pd.get_dummies(d, prefix=['student'], columns=['student'])\nd.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model - 1 Fit\ninputDF = d[[\"balance\",\"income\",\"student_No\",\"student_Yes\"]]\noutputDF = d[[\"DefaultYes\"]].values.ravel()\n\nlogisticRegr = LogisticRegression(solver='lbfgs')\nx_train, x_test, y_train, y_test = train_test_split(inputDF, outputDF, test_size=0.25, random_state=0)\nlogisticRegr.fit(inputDF, outputDF)\n\nprint(logisticRegr.intercept_)\nprint(logisticRegr.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model - 1 Validation\ny_pred = logisticRegr.predict(x_test)\n#print(r2_score(y_test, y_pred)) \nprint(\"R - Squared value:\\n\",stats.adj_r2_score(logisticRegr, x_train, y_train)) \nprint(\"RMSE:\\n\", np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model - 2 Fit\ninputDF = d[[\"income\",\"student_No\",\"student_Yes\"]]\noutputDF = d[[\"DefaultYes\"]].values.ravel()\n\nlogisticRegr = LogisticRegression(solver='lbfgs')\nx_train, x_test, y_train, y_test = train_test_split(inputDF, outputDF, test_size=0.25, random_state=0)\nlogisticRegr.fit(x_train, y_train)\n\nprint(logisticRegr.intercept_)\nprint(logisticRegr.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model - 2 Validation\ny_pred = logisticRegr.predict(x_test)\nprint(\"R - Squared value:\\n\",stats.adj_r2_score(logisticRegr, x_train, y_train)) \nprint(\"RMSE:\\n\", np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n#print(r2_score(y_test, y_pred)) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Voilà! This is the end of the lab session for week 3.** <br>\nDo not forget to commit your notebook and set the access to private. Share the notebook with Prof. Karim (Kaggle id: karimshaikh) and Manish Varma (Kaggle id: manishvarma)."},{"metadata":{},"cell_type":"markdown","source":"**References:** <br>\n1. Galarnyk, Michael, and Michael Galarnyk. “Logistic Regression Using Python (Scikit-Learn).” Towards Data Science, Towards Data Science, 13 Sept. 2017, towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a.\n2. Damian, Mihai DamianMihai. “Polynomial Regression Using Scikit-Learn.” Cross Validated, stats.stackexchange.com/questions/58739/polynomial-regression-using-scikit-learn.\n3. “Understanding Logistic Regression in Python.” DataCamp Community, datacamp.com/community/tutorials/understanding-logistic-regression-python.\n4. “Python | Implementation of Polynomial Regression.” GeeksforGeeks, 3 Oct. 2018, geeksforgeeks.org/python-implementation-of-polynomial-regression/.\n\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}