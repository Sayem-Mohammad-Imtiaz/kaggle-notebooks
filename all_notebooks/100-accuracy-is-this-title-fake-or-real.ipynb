{"cells":[{"metadata":{},"cell_type":"markdown","source":"---\n\n<h1 style=\"text-align: center;font-size: 30px; color: #013b86;\">Fake or Real. Two sides of the same coin?</h1>\n\n---\n\n<center><img style=\"width: 700px;\" src=\"https://images.ctfassets.net/yqezig6gzu6c/5ur280lovm0DKoHmlEGe1P/9779c9555ebed3dbd7e3445d0a666843/https___cdn2.hubspot.net_hubfs_656775_Fact_20Fake_201200_20x_20627px_2x-100_20copy.jpg?w=900&q=100\"></center>\n\n---\n<i>Source: Image from Google</i>"},{"metadata":{},"cell_type":"markdown","source":"<h4>Oh please don't be surprised about this title. This title represents only this notebook. Actually this notebook is divided into two parts. </h4>\n<h4>In the first part we predict the use of this dataset where we get almost 100% accuracy and in the second part we try to examine this dataset. Whether it is biased or not.</h4>\n<h4>So when we get almost 100% accuracy you can say yes this title is true. However, after observing this dataset, your observation may or may not change. If you think I can't see anything wrong with this dataset, you can say this title is ok. Or if you see some biased material in this dataset, you can change your mind. So this is a question to you, what do you think?</h4>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport nltk\nimport re\nimport string\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"real_data = pd.read_csv('/kaggle/input/fake-and-real-news-dataset/True.csv')\nfake_data = pd.read_csv('/kaggle/input/fake-and-real-news-dataset/Fake.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"font-size: 30px;color: #ae2e28;\">Part - 1</h2>"},{"metadata":{},"cell_type":"markdown","source":"## Basic EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"real_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real_data['target'] = 1\nfake_data['target'] = 0 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake_data.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combine_data = pd.concat([real_data, fake_data], ignore_index=True, sort=False)\ncombine_data.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(7, 7))\nsns.set(style=\"darkgrid\")\n\ncolor = sns.color_palette(\"Set2\")\nax = sns.countplot(x=\"target\", data=combine_data, palette=color)\n\nax.set(xticklabels=['fake', 'real'])\n\nplt.title(\"Data distribution of fake and real data\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nsns.set(style=\"darkgrid\")\n\ncolor = sns.color_palette(\"Set2\")\nax = sns.countplot(x=\"subject\",  hue='target', data=combine_data, palette=color)\n\n# ax.set(xticklabels=['fake', 'real'])\n\nplt.title(\"Data distribution of fake and real data\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combine_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_train_data(x):\n    text = x\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text) # remove square brackets\n    text = re.sub(r'[^\\w\\s]','',text) # remove punctuation\n    text = re.sub('\\w*\\d\\w*', '', text) # remove words containing numbers\n    text = re.sub(r'http\\S+', '', text)\n    text = re.sub('\\n', '', text)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clean_combine_data = combine_data.copy()\nclean_combine_data['text'] = combine_data.text.apply(lambda x : clean_train_data(x))\nclean_combine_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clean_combine_data.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clean_combine_data[clean_combine_data['target'] == 0]['text'][21417]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fake_data['text'][0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Stopword Removal"},{"metadata":{"trusted":true},"cell_type":"code","source":"eng_stopwords = nltk.corpus.stopwords.words(\"english\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_eng_stopwords(text):\n    token_text = nltk.word_tokenize(text)\n    remove_stop = [word for word in token_text if word not in eng_stopwords]\n    join_text = ' '.join(remove_stop)\n    return join_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stopword_combine_data = clean_combine_data.copy()\nstopword_combine_data['text'] = clean_combine_data.text.apply(lambda x : remove_eng_stopwords(x))\nstopword_combine_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Find out common words"},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import chain\nfrom collections import Counter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_words = stopword_combine_data['text'].str.split()\nlist_words_merge = list(chain(*list_words))\n\nd = Counter(list_words_merge)\ndf = pd.DataFrame(data=d, index=['count'])\ntop_common_words = df.T.sort_values(by=['count'], ascending=False).reset_index().head(50)\ntop_common_words.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,7))\nsns.set(style=\"darkgrid\")\nsns.barplot(x=\"index\", y='count', data=top_common_words)\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lemmatization"},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lemm = WordNetLemmatizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def word_lemmatizer(text):\n    token_text = nltk.word_tokenize(text)\n    remove_stop = [lemm.lemmatize(w) for w in token_text]\n    join_text = ' '.join(remove_stop)\n    return join_text\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lemmatize_data = stopword_combine_data.copy()\nlemmatize_data['text'] = stopword_combine_data.text.apply(lambda x : word_lemmatizer(x))\nlemmatize_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# N-Gram Analysis"},{"metadata":{},"cell_type":"markdown","source":"---\n\n<center><img style=\"width: 700px;\" src=\"https://images.deepai.org/glossary-terms/867de904ba9b46869af29cead3194b6c/8ARA1.png\"></center>\n\n---\n<i>Source: Image from Google</i>"},{"metadata":{"trusted":true},"cell_type":"code","source":"string = ' '.join(lemmatize_data['text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"str_val = string.split(\" \")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Unigram Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_unigram=(pd.Series(nltk.ngrams(str_val, 1)).value_counts())[:30]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_unigram_df=pd.DataFrame(data_unigram)\ndata_unigram_df = data_unigram_df.reset_index()\ndata_unigram_df = data_unigram_df.rename(columns={\"index\": \"key\", 0: \"value\"})\ndata_unigram_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,9))\nsns.barplot(x='value',y='key', data=data_unigram_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bigram Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_bigram=(pd.Series(nltk.ngrams(str_val, 2)).value_counts())[:30]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_bigram_df=pd.DataFrame(data_bigram)\ndata_bigram_df = data_bigram_df.reset_index()\ndata_bigram_df = data_bigram_df.rename(columns={\"index\": \"key\", 0: \"value\"})\ndata_bigram_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,9))\nsns.barplot(x='value',y='key', data=data_bigram_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Trigram Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_trigram=(pd.Series(nltk.ngrams(str_val, 3)).value_counts())[:30]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_trigram_df=pd.DataFrame(data_trigram)\ndata_trigram_df = data_trigram_df.reset_index()\ndata_trigram_df = data_trigram_df.rename(columns={\"index\": \"key\", 0: \"value\"})\ndata_trigram_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,9))\nsns.barplot(x='value',y='key', data=data_trigram_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Wow they incredibly use Donald Trump too many times. What u think is this ok?"},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_data = stopword_combine_data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_data['combine_text'] = model_data['subject'] + \" \" + model_data['title'] + \" \" + model_data['text']\ndel model_data['title']\ndel model_data['subject']\ndel model_data['date']\ndel model_data['text']\nmodel_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(model_data['combine_text'], model_data['target'], random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bag of Words"},{"metadata":{},"cell_type":"markdown","source":"---\n\n<center><img style=\"width: 700px;\" src=\"https://3.bp.blogspot.com/-4pxORQAgAFI/XMNZhEssXtI/AAAAAAAAGmA/SuQGsp-GyT4jKlUZieg_A5lnTza_GujfwCLcBGAs/s1600/bag_of_words.png\"></center>\n\n---\n<i>Source: Image from Google</i>"},{"metadata":{},"cell_type":"markdown","source":"## Vectorizing"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vec_train = CountVectorizer().fit(X_train)\nX_vec_train = vec_train.transform(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_vec_test = vec_train.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression()\nmodel.fit(X_vec_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_value = model.predict(X_vec_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_value = roc_auc_score(y_test, predicted_value)\nprint(accuracy_value)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ohh you see this result it is 99.86 means this title is almost real. but actually is it? u might be found somethings wrong in model execution. ok lets do some in modeling to do more reliable. "},{"metadata":{},"cell_type":"markdown","source":"# Modeling -2"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_2_data = lemmatize_data.copy()\nmodel_2_data['combine_text'] = model_2_data['title'] + \" \" + model_2_data['text']\ndel model_2_data['title']\ndel model_2_data['subject']\ndel model_2_data['date']\ndel model_2_data['text']\nmodel_2_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(model_2_data['combine_text'], model_2_data['target'], test_size=0.33, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vec_train = CountVectorizer().fit(X_train)\nX_vec_train = vec_train.transform(X_train)\nX_vec_test = vec_train.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression()\nmodel.fit(X_vec_train, y_train)\npredicted_value = model.predict(X_vec_test)\naccuracy_value = roc_auc_score(y_test, predicted_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(accuracy_value)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### so our new predicted result is 99.66, not much difference from previous one. though im not doing much work in modeling. but i can assure you this dataset always given u above 90% accuracy."},{"metadata":{},"cell_type":"markdown","source":"### why this is. is it really easy to find out which news are fake and which are real. i don't know. but i want to show u something about this dataset. "},{"metadata":{},"cell_type":"markdown","source":"### I'm much inspired from this notebook. You can check also. Im getting some idea from this notebook to knowing you about this dataset.\n[https://www.kaggle.com/josutk/only-one-word-99-2](https://www.kaggle.com/josutk/only-one-word-99-2)"},{"metadata":{},"cell_type":"markdown","source":"<h2 style=\"font-size: 30px;color: #ae2e28;\">Part - 2</h2>"},{"metadata":{},"cell_type":"markdown","source":"# Deep drive in this Dataset"},{"metadata":{},"cell_type":"markdown","source":"## Fact-1: Subject Distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"ex_combine_data = combine_data.copy()\nex_combine_data = ex_combine_data.replace([\"politicsNews\"], 'politics')\nex_combine_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nsns.set(style=\"darkgrid\")\n\ncolor = sns.color_palette(\"Set2\")\nax = sns.countplot(x=\"subject\",  hue='target', data=ex_combine_data, palette=color)\n\n# ax.set(xticklabels=['fake', 'real'])\n\nplt.title(\"Data distribution of fake and real data\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Subjects are not well distributed The real data contains only two subjects and the fake data contains the remaining subjects. Only Politics are common.\n\n#### So the question is, does this description follow their titles? Otherwise we can say that any news we get about the US or the Middle East is completely fake. Does it make sense?"},{"metadata":{},"cell_type":"markdown","source":"## Fact-2: Text Length"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(17,8))\n\nword = ex_combine_data[ex_combine_data['target']==1]['text'].str.split().apply(lambda x : [len(i) for i in x])\nsns.distplot(word.map(lambda x: np.mean(x)),ax=ax1,color='blue')\nax1.set_title('Real text')\n\nword = ex_combine_data[ex_combine_data['target']==0]['text'].str.split().apply(lambda x : [len(i) for i in x])\nsns.distplot(word.map(lambda x: np.mean(x)),ax=ax2,color='red')\nax2.set_title('Fake text')\n\nfig.suptitle('Average word length in each text')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Average text length are not same for both. And the difference are really remarkable. Yes length can not be same but this difference is huge. Maybe it can be hamper some training model."},{"metadata":{},"cell_type":"markdown","source":"## Fact-3: Unique Words"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_words_after = real_data['text'].str.split()\nmerged = list(chain(*all_words_after))\nd = Counter(merged)\ndf = pd.DataFrame(data=d, index=['count'])\ntop_count_words = df.T.sort_values(by=['count'], ascending=False).reset_index().head(50)\ntop_count_words.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\nresults = Counter()\nreal_data['text'].str.lower().str.split().apply(results.update)\nreal_unq_count = len(results)\nprint(real_unq_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = Counter()\nfake_data['text'].str.lower().str.split().apply(results.update)\nfake_unq_count = len(results)\nprint(fake_unq_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nplt.bar([1, 2], [real_unq_count, fake_unq_count], color=['#72b6a1', '#e99675'])\nplt.xticks([1,2], ('real', 'fake'))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Earlier we saw that the average text length of fake information is not very long, but in unique words it appears higher than the real data. That's mean, the ratio of same words is too much. What Do you think is this okay for prediction?"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## So What is yours finding, is this title real or fake?"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}