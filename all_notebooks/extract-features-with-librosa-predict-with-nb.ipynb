{"cells":[{"metadata":{},"cell_type":"markdown","source":"You can find the dataset using the extracted features [here](https://www.kaggle.com/fleanend/birds-songs-numeric-dataset)."},{"metadata":{"trusted":true,"_uuid":"3d5d8bc2adb1416bf1685231d44130a5929f8112"},"cell_type":"code","source":"!pip install soundfile librosa","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom librosa import core, onset, feature, display\nimport soundfile as sf\nimport umap\nfrom IPython.display import Audio\nimport sklearn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4cb88e3f48ea25207af908ebd757e7f2802c8654"},"cell_type":"code","source":"df = pd.read_csv(\"../input/birdsong_metadata.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_audio(file_id):\n    data, samplerate = sf.read(\"../input/songs/songs/xc\"+str(file_id)+\".flac\")\n    s = len(data)/samplerate\n    sg = feature.melspectrogram(data, sr=samplerate, hop_length=512)\n    \n    # Take mean amplitude M from frame with highest energy\n    centerpoint = np.argmax(sg.mean(axis=0))\n    M = sg[:,centerpoint].mean()\n    \n    # Filter out all frames with energy less than 5% of M\n    mask = sg.mean(axis=0)>=M/20\n\n    audio_mask = np.zeros(len(data), dtype=bool)\n    for i in range(0,len(mask)):\n        audio_mask[i*512:] = mask[i]\n    return sg, mask, data, audio_mask, samplerate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f077e8ac28c9886115e0a6ea373322606cc0a86","_kg_hide-output":false,"_kg_hide-input":false},"cell_type":"code","source":"df['length'] = np.zeros(len(df))\n\nwaves = {}\n\n\nfor file_id in df['file_id']:\n    sg, mask, data, audio_mask, sample_rate = load_audio(file_id)\n    waves[file_id] = data[audio_mask]\n    df.loc[df['file_id'] == file_id,'length'] = len(data[audio_mask])\n    #print(len(data[audio_mask])/sample_rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9ddf9fc6a8d192086641441ac74e66370319de7"},"cell_type":"code","source":"df['length'].hist()\nplt.show()\ndf['length'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We set window to 6.144000e+03 frames as it's the minimum length among our audio files\ndf['windows'] = df['length'].apply(lambda x: int(x/6.144000e+03))\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To relax the problem we'll consider the genus as the label instead of the species\n# We use 23 windows per genus to have a balanced data set\n\nn_windows = df.groupby('species')['windows'].sum().min()\nn_windows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First we create all windows for each file and partition them by species\n\nwindows = {}\n\nfor file_id in df['file_id']:\n    wave = waves[file_id]\n    species = df[df['file_id']==file_id]['genus'].values[0] + \"_\" + df[df['file_id']==file_id]['species'].values[0]\n    if species not in windows:\n        windows[species] = []\n    for i in range(0, int(len(wave)/6.144000e+03)):\n        windows[species].append(wave[i:int(i+6.144000e+03)])\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We randomly pick 20 windows for each species\n\n# Save other samples for testing\n\nwindows_fixed = {}\nwindows_fixed_test = {}\n\nfor species in windows.keys():\n    windows_fixed[species] = []\n    windows_fixed_test[species] = []\n    ws = windows[species]\n    index = np.random.choice(len(ws), n_windows, replace=False)\n    for i in range(0, len(ws)):\n        if i in index:\n            windows_fixed[species].append(ws[i])\n        else:\n            windows_fixed_test[species].append(ws[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract Features from Window\nnew_dataset = pd.DataFrame()\n\nfor species in windows_fixed.keys():\n    for i in range(0,n_windows):\n        data_point = {'species':species.split('_')[1], 'genus':species.split('_')[0]}\n        spec_centroid = feature.spectral_centroid(windows_fixed[species][i])[0]\n        chroma = feature.chroma_stft(windows_fixed[species][i], sample_rate)\n        for j in range(0,13):\n            data_point['spec_centr_'+str(j)] = spec_centroid[j]\n            for k in range(0,12):\n                data_point['chromogram_'+str(k)+\"_\"+str(j)] = chroma[k,j]\n        new_dataset = new_dataset.append(data_point,ignore_index=True)\n\nnew_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract Features from Window for test\nnew_dataset_test = pd.DataFrame()\n\nfor species in windows_fixed_test.keys():\n    for i in range(0,len(windows_fixed_test[species])):\n        data_point = {'species':species.split('_')[1], 'genus':species.split('_')[0]}\n        spec_centroid = feature.spectral_centroid(windows_fixed_test[species][i])[0]\n        chroma = feature.chroma_stft(windows_fixed_test[species][i], sample_rate)\n        for j in range(0,13):\n            data_point['spec_centr_'+str(j)] = spec_centroid[j]\n            for k in range(0,12):\n                data_point['chromogram_'+str(k)+\"_\"+str(j)] = chroma[k,j]\n        new_dataset_test = new_dataset_test.append(data_point,ignore_index=True)\n\nnew_dataset_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare dataset to fit a simple model\n\nfeatures= list(new_dataset.columns)\nfeatures.remove('species')\nfeatures.remove('genus')\n\nX = new_dataset[features].values\ny = new_dataset['species'].values\n\nX_test = new_dataset_test[features].values\ny_test = new_dataset_test['species'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use Naive Bayes as benchmark \n\nfrom sklearn import naive_bayes\nNB = naive_bayes.GaussianNB()\n\nSSS = sklearn.model_selection.StratifiedShuffleSplit(n_splits=5, test_size=0.2)\n\naccs = [] \n\nfor train_index, val_index in SSS.split(X, y):\n    X_train, X_val = X[train_index], X[val_index]\n    y_train, y_val = y[train_index], y[val_index]\n    \n    NB.fit(X_train, y_train)\n    \n    y_pred = NB.predict(X_val)\n    \n    accs.append(sklearn.metrics.accuracy_score(y_pred=y_pred, y_true=y_val))\n    \nprint(accs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = NB.predict(X_test)\nsklearn.metrics.accuracy_score(y_pred=y_pred, y_true=y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The data can be used to predict, let's export the newly created datasets\n\nnew_dataset.to_csv(\"train.csv\")\nnew_dataset_test.to_csv(\"test.csv\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}