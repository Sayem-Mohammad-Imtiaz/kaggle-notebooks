{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Goal"},{"metadata":{},"cell_type":"markdown","source":"You work for Spark Funds, an asset management company. Spark Funds wants to make investments in a few sectors.\nThe CEO of Spark Funds wants to understand the global trends in investments so that she can take the investment decisions effectively."},{"metadata":{},"cell_type":"markdown","source":"# Business and Data Understanding"},{"metadata":{},"cell_type":"markdown","source":"Spark Funds has two minor constraints for investments:\n\nIt wants to invest between 5 to 15 million USD per round of investment\n\nIt wants to invest only in English-speaking countries because of the ease of communication with the companies it would invest in\n\nFor your analysis, consider a country to be English speaking only if English is one of the official languages in that country"},{"metadata":{},"cell_type":"markdown","source":"# Goals of data analysis:"},{"metadata":{},"cell_type":"markdown","source":"**Files:** \n    \n    -companies.txt: A table with basic data of companies\n    \n    -rounds2.csv: A table with all the rounds details\n    \n    -mapping.csv: This file maps the numerous category names in the companies table (such 3D printing, aerospace, agriculture, etc.) to eight broad sector names. The purpose is to simplify the analysis into eight sector buckets, rather than trying to analyse hundreds of them.\n\n**Investment type analysis:** Comparing the typical investment amounts in the venture, seed, angel, private equity etc. so that Spark Funds can choose the type that is best suited for their strategy.\n\n**Country analysis:** Identifying the countries which have been the most heavily invested in the past. These will be Spark Funds’ favourites as well.\n\n**Sector analysis:** Understanding the distribution of investments across the eight main sectors. (Note that we are interested in the eight 'main sectors' provided in the mapping file. The two files — companies and rounds2 — have numerous sub-sector names; hence, you will need to map each sub-sector to its main sector.)\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing libries\nimport numpy as np\nimport pandas as pd\nimport string\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading data files\n# using encoding = \"ISO-8859-1\" to avoid pandas encoding error\n\ncompanies = pd.read_csv(\"../input/investment-analysis/companies.txt\", sep=\"\\t\", encoding = \"ISO-8859-1\")\nrounds = pd.read_csv(\"../input/investment-analysis/rounds2.csv\", encoding = \"ISO-8859-1\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Overview of the data in companies file\ncompanies.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The variables funding_round_code and raised_amount_usd contain some missing values, as shown above. We'll deal with them after we're done with understanding the data - column names, primary keys of tables etc."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the shape of the DataFrames\nprint(\"Companies File: \", companies.shape)\nprint(\"Rounds File\", rounds.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Find Primary Key in both data Frames.\nprint(\"Shape of companies: \", companies.shape)\nfor col in companies.columns:\n    print(\"Unique values in {}:{}\".format(col, companies[col].nunique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Shape of Rounds: \", rounds.shape)\nfor col in rounds.columns:\n    print(\"Unique value in column: {} is {}\".format(col, rounds[col].nunique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Compare values(Primary Key)\n\nthe ```permalink``` column in the companies dataframe should be the unique_key of the table, having 66368 unique company names (links, or permalinks). Also, these 66368 companies should be present in the rounds file.\n\nLet's first confirm that these 66368 permalinks (which are the URL paths of companies' websites) are not repeating in the column, i.e. they are unique.\n\n\t\ta.  present in companiesDataFrame and not in roundsDataFrame.\n\t\tb.  present in roundsDataFrame and not in companiesDataFrame."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Also, let's convert all the entries to lowercase (or uppercase) for uniformity.\n# converting all permalinks to lowercase\ncompanies['permalink'] = companies['permalink'].str.lower()\nrounds['company_permalink'] = rounds['company_permalink'].str.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# identify the unique number of permalinks in companies\nlen(companies.permalink.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# look at unique company names in rounds master\n# note that the column name in rounds file is different (company_permalink)\nlen(rounds.company_permalink.unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There seem to be 2 extra permalinks in the rounds file which are not present in the companies file. Let's hope that this is a data quality issue, since if this were genuine, we have two companies whose investment round details are available but their metadata (company name, sector etc.) is not available in the companies table.\n"},{"metadata":{},"cell_type":"markdown","source":"##### There are tow way that we can find the mismatch in columns"},{"metadata":{},"cell_type":"markdown","source":"###### Method 1:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# will use this columns to find the mismatch in it, \n# Present in companies but not in rounds\nset(companies.permalink) - set(rounds.company_permalink )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# companies present in rounds master but not in companies master\nset(rounds.company_permalink ) - set(companies.permalink)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Method 2:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# companies present in companies master but not in rounds master\ncompanies.loc[~companies['permalink'].isin(rounds['company_permalink']), :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# companies present in rounds file but not in (~) companies file\nrounds.loc[~rounds['company_permalink'].isin(companies['permalink']), :]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The company weird characters appear when you import the data file. To confirm whether these characters are actually present in the given data or whether python has introduced them while importing into pandas, let's have a look at the original CSV file in Excel."},{"metadata":{},"cell_type":"markdown","source":"Thus, this is most likely a data quality issue we have introduced while reading the data file into python. Specifically, this is most likely caused because of encoding.\n\nFirst, let's try to figure out the encoding type of this file. Then we can try specifying the encoding type at the time of reading the file. The ```chardet``` library shows the encoding type of a file."},{"metadata":{"trusted":true},"cell_type":"code","source":"import chardet\n\nrawdata = open('../input/investment-analysis/rounds2.csv', 'rb').read()\nresult = chardet.detect(rawdata)\ncharenc = result['encoding']\nprint(charenc)\n\n# print(result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's try telling pandas (at the time of importing) the encoding type. Here's a list of various encoding types python can handle: https://docs.python.org/2/library/codecs.html#standard-encodings."},{"metadata":{"trusted":true},"cell_type":"code","source":"# trying different encodings\n# encoding=\"cp1254\" throws an error\n# rounds_original = pd.read_csv(\"rounds2.csv\", encoding=\"cp1254\")\n# rounds_original.iloc[[29597, 31863, 45176], :]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apparently, pandas cannot decode \"cp1254\" in this case.\n\nAfter trying various other encoding types (in vain), this answer suggested an alternate (and a more intelligent) way: https://stackoverflow.com/questions/45871731/removing-special-characters-in-a-pandas-dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove encoding from companies master\ncompanies['permalink'] = companies.permalink.str.encode('utf-8').str.decode('ascii', 'ignore')\n\n# remove encoding from rounds master\nrounds['company_permalink'] = rounds.company_permalink.str.encode('utf-8').str.decode('ascii', 'ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus, the encoding issue seems resolved now."},{"metadata":{},"cell_type":"markdown","source":"## Missing Value Treatment\n\nLet's now move to missing value treatment. \n\nLet's have a look at the number of missing values in both the dataframes."},{"metadata":{"trusted":true},"cell_type":"code","source":"# missing values in companies master\ncompanies.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# missing values in rounds master\nrounds.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since there are no misisng values in the permalink or company_permalink columns, let's merge the two and then work on the master dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"# merging the two masters\nmaster = pd.merge(companies, rounds, how=\"inner\", left_on=\"permalink\", right_on=\"company_permalink\")\nmaster.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since the columns ```company_permalink``` and ```permalink``` are the same, let's remove one of them.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# print column names\nmaster.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing redundant columns\nmaster =  master.drop(['company_permalink'], axis=1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# column-wise missing values \nmaster.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at the fraction of missing values in the columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"# summing up the missing values (column-wise) and displaying fraction of NaNs\nround(100*(master.isnull().sum()/len(master.index)), 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clearly, the column ```funding_round_code``` is useless (with about 73% missing values). Also, for the business objectives given, the columns ```homepage_url```, ```founded_at```, ```state_code```, ```region``` and ```city``` need not be used.\n\nThus, let's drop these columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping columns \nmaster = master.drop(['funding_round_code', 'homepage_url', 'founded_at', 'state_code', 'region', 'city'], axis=1)\nmaster.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summing up the missing values (column-wise) and displaying fraction of NaNs\nround(100*(master.isnull().sum()/len(master.index)), 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that the column ```raised_amount_usd``` is an important column, since that is the number we want to analyse (compare, means, sum etc.). That needs to be carefully treated. \n\nAlso, the column ```country_code``` will be used for country-wise analysis, and ```category_list``` will be used to merge the dataframe with the main categories.\n\nLet's first see how we can deal with missing values in ```raised_amount_usd```.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# summary stats of raised_amount_usd\nmaster['raised_amount_usd'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The mean is somewhere around USD 10 million, while the median is only about USD 1m. The min and max values are also miles apart. \n\nIn general, since there is a huge spread in the funding amounts, it will be inappropriate to impute it with a metric such as median or mean. Also, since we have quite a large number of observations, it is wiser to just drop the rows. \n\nLet's thus remove the rows having NaNs in ```raised_amount_usd```."},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing NaNs in raised_amount_usd\nmaster = master[~np.isnan(master['raised_amount_usd'])]\nround(100*(master.isnull().sum()/len(master.index)), 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's now look at the column ```country_code```. To see the distribution of the values for categorical variables, it is best to convert them into type 'category'."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"country_codes = master['country_code'].astype('category')\n\n# displaying frequencies of each category\ncountry_codes.value_counts().head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# displaying frequencies of each category\ncountry_codes.value_counts().tail(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By far, the most number of investments have happened in American countries. We can also see the fractions."},{"metadata":{"trusted":true},"cell_type":"code","source":"# viewing fractions of counts of country_codes\n100*(master['country_code'].value_counts()/len(master.index)).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# viewing fractions of counts of country_codes\n100*(master['country_code'].value_counts()/len(master.index)).tail(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we can either delete the rows having ```country_code``` missing (about 6% rows), or we can impute them by ```USA```. Since the number 6 is quite small, and we have a decent amount of data, it may be better to just remove the rows.\n\n**Note that** ```np.isnan``` does not work with arrays of type 'object', it only works with native numpy type (float). Thus, you can use ```pd.isnull()``` instead."},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing rows with missing country_codes\nmaster = master[~pd.isnull(master['country_code'])]\n\n# look at missing values\nround(100*(master.isnull().sum()/len(master.index)), 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that the fraction of missing values in the remaining dataframe has also reduced now - only 0.65% in ```category_list```. Let's thus remove those as well.\n\n**Note**\nOptionally, you could have simply let the missing values in the dataset and continued the analysis. There is nothing wrong with that. But in this case, since we will use that column later for merging with the 'main_categories', removing the missing values will be quite convenient (and again - we have enough data)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing rows with missing category_list values\nmaster = master[~pd.isnull(master['category_list'])]\n\n# look at missing values\nround(100*(master.isnull().sum()/len(master.index)), 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Funding Type Analysis\n\nLet's compare the funding amounts across the funding types. Also, we need to impose the constraint that the investment amount should be between 5 and 15 million USD. We will choose the funding type such that the average investment amount falls in this range."},{"metadata":{"trusted":true},"cell_type":"code","source":"# first, let's filter the master so it only contains the four specified funding types\nmaster = master[(master.funding_round_type == \"venture\") | \n        (master.funding_round_type == \"angel\") | \n        (master.funding_round_type == \"seed\") | \n        (master.funding_round_type == \"private_equity\") ]\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we have to compute a **representative value of the funding amount** for each type of invesstment. We can either choose the mean or the median - let's have a look at the distribution of ```raised_amount_usd``` to get a sense of the distribution of data.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# distribution of raised_amount_usd\nsns.boxplot(y=master['raised_amount_usd'])\nplt.yscale('log')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's also look at the summary metrics."},{"metadata":{"trusted":true},"cell_type":"code","source":"# summary metrics\nmaster['raised_amount_usd'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that there's a significant difference between the mean and the median - USD 9.5m and USD 2m. Let's also compare the summary stats across the four categories."},{"metadata":{"trusted":true},"cell_type":"code","source":"# comparing summary stats across four categories\nsns.boxplot(x='funding_round_type', y='raised_amount_usd', data=master)\nplt.yscale('log')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compare the mean and median values across categories\nmaster.pivot_table(values='raised_amount_usd', columns='funding_round_type', aggfunc=[np.median, np.mean])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that there's a large difference between the mean and the median values for all four types. For type venture, for e.g. the median is about 20m while the mean is about 70m. \n\nThus, the choice of the summary statistic will drastically affect the decision (of the investment type). Let's choose median, since there are quite a few extreme values pulling the mean up towards them - but they are not the most 'representative' values.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# compare the median investment amount across the types\nmaster.groupby('funding_round_type')['raised_amount_usd'].median().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The median investment amount for type 'private_equity' is approx. USD 20m, which is beyond Spark Funds' range of 5-15m. The median of 'venture' type is about USD 5m, which is suitable for them. The average amounts of angel and seed types are lower than their range.\n\nThus, 'venture' type investment will be most suited to them."},{"metadata":{},"cell_type":"markdown","source":"## Country Analysis\n\nLet's now compare the total investment amounts across countries. Note that we'll filter the data for only the 'venture' type investments and then compare the 'total investment' across countries."},{"metadata":{},"cell_type":"markdown","source":"######Group by country(Another Method)\n-  country_group = master_frame.groupby('country_code')\n\n######data frame named top9 with the top nine countries (based on the total investment amount each country has received)\n-  top9 = country_group['raised_amount_usd'].sum().nlargest(9)\n-  top9 = top9.reset_index()\n-  top9.rename(columns = {'raised_amount_usd':'Total_Investment'},inplace = True)\n\n######Updating Top9 tables \n-  top9['Eng_as_Offical'] = [True,False,True,True,True,False,True,False,False]\n\n######Creating Top3 Tabels Where english is the official language\n-  top3 = top9.loc[top9['Eng_as_Offical'] == True].nlargest(3,'Total_Investment').copy()\n-  top3.reset_index(inplace = True,drop=True)\n-  top3"},{"metadata":{"trusted":true},"cell_type":"code","source":"# filter the master for private equity type investments\nmaster = master[master.funding_round_type==\"venture\"]\n\n# group by country codes and compare the total funding amounts\ncountry_wise_total = master.groupby('country_code')['raised_amount_usd'].sum().sort_values(ascending=False)\ncountry_wise_total.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's now extract the top 9 countries from ```country_wise_total```."},{"metadata":{"trusted":true},"cell_type":"code","source":"# top 9 countries\ntop_9_countries = country_wise_total[:9]\ntop_9_countries","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Among the top 9 countries, USA, GBR and IND are the top three English speaking countries. Let's filter the dataframe so it contains only the top 3 countries."},{"metadata":{"trusted":true},"cell_type":"code","source":"# filtering for the top three countries\nmaster = master[(master.country_code=='USA') | (master.country_code=='GBR') | (master.country_code=='IND')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After filtering for 'venture' investments and the three countries USA, Great Britain and India, the filtered master looks like this."},{"metadata":{"trusted":true},"cell_type":"code","source":"# filtered master has about 38800 observations\nmaster.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One can visually analyse the distribution and the total values of funding amount."},{"metadata":{"trusted":true},"cell_type":"code","source":"# boxplot to see distributions of funding amount across countries\nplt.figure(figsize=(8, 5))\nsns.boxplot(x='country_code', y='raised_amount_usd', data=master)\nplt.yscale('log')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we have shortlisted the investment type (venture) and the three countries. Let's now choose the sectors."},{"metadata":{},"cell_type":"markdown","source":"## Sector Analysis\n\nFirst, we need to extract the main sector using the column ```category_list```. The category_list column contains values such as 'Biotechnology|Health Care' - in this, 'Biotechnology' is the 'main category' of the company, which we need to use.\n\nLet's extract the main categories in a new column."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# extracting the main category\nmaster.loc[:, 'main_category'] = master['category_list'].apply(lambda x: x.split(\"|\")[0])\nmaster.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can now drop the ```category_list``` column."},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop the category_list column\nmaster = master.drop('category_list', axis=1)\nmaster.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we'll read the ```mapping.csv``` file and merge the main categories with its corresponding column. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# read mapping file\nmapping = pd.read_csv(\"../input/investment-analysis/mapping.csv\", sep=\",\")\nmapping.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Firstly, let's get rid of the missing values since we'll not be able to merge those rows anyway. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# missing values in mapping file\nmapping.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove the row with missing values\nmapping = mapping[~pd.isnull(mapping['category_list'])]\nmapping.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, since we need to merge the mapping file with the main dataframe (master), let's convert the common column to lowercase in both."},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting common columns to lowercase\nmapping['category_list'] = mapping['category_list'].str.lower()\nmaster['main_category'] = master['main_category'].str.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# look at heads\nmapping.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"master.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's have a look at the ```category_list``` column of the mapping file. These values will be used to merge with the main master."},{"metadata":{"trusted":true},"cell_type":"code","source":"mapping['category_list'][:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To be able to merge all the ```main_category``` values with the mapping file's ```category_list``` column, all the values in the  ```main_category``` column should be present in the ```category_list``` column of the mapping file.\n\nLet's see if this is true."},{"metadata":{"trusted":true},"cell_type":"code","source":"# values in main_category column in master which are not in the category_list column in mapping file\nmaster[~master['main_category'].isin(mapping['category_list'])].head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notice that values such as 'analytics', 'business analytics', 'finance', 'nanatechnology' etc. are not present in the mapping file.\n\nLet's have a look at the values which are present in the mapping file but not in the main dataframe master."},{"metadata":{"trusted":true},"cell_type":"code","source":"# values in the category_list column which are not in main_category column \nmapping.loc[mapping.category_list.str.contains('0')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you see carefully, you'll notice something fishy - there are sectors named *alter0tive medicine*, *a0lytics*, *waste ma0gement*, *veteri0ry*, etc. This is not a *random* quality issue, but rather a pattern. In some strings, the 'na' has been replaced by '0'. This is weird - maybe someone was trying to replace the 'NA' values with '0', and ended up doing this. \n\nLet's treat this problem by replacing '0' with 'na' in the ```category_list``` column."},{"metadata":{"trusted":true},"cell_type":"code","source":"# replacing '0' with 'na'\nmapping['category_list'] = mapping['category_list'].apply(lambda x: x.replace('0', 'na'))\nmapping['category_list'].head(20)\n\n#This can be Done Using Regex;\n# mapping.loc[mapping['category_list'].str.match('.*\\d+[\\w\\s]'),'category_list'] = mapping.category_list.str.replace('0','na')\n# mapping.loc[mapping.category_list.str.contains('0')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This looks fine now. Let's now merge the two dataframes."},{"metadata":{"trusted":true},"cell_type":"code","source":"# merge the masters\nmaster = pd.merge(master, mapping, how='inner', left_on='main_category', right_on='category_list')\nmaster.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# let's drop the category_list column since it is the same as main_category\nmaster = master.drop('category_list', axis=1)\nmaster.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# look at the column types and names\nmaster.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Converting the 'wide' dataframe to 'long'\n\nYou'll notice that the columns representing the main category in the mapping file are originally in the 'wide' format - Automotive & Sports, Cleantech / Semiconductors etc.\n\nThey contain the value '1' if the company belongs to that category, else 0. This is quite redundant. We can as well have a column named 'sub-category' having these values. \n\nLet's convert the master into the long format from the current wide format. First, we'll store the 'value variables' (those which are to be melted) in an array. The rest will then be the 'index variables'."},{"metadata":{"trusted":true},"cell_type":"code","source":"### help(pd.melt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# store the value and id variables in two separate arrays\n\n# store the value variables in one Series\nvalue_vars = master.columns[9:18]\n\n# take the setdiff() to get the rest of the variables\nid_vars = np.setdiff1d(master.columns, value_vars)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert into long\nlong_master = pd.melt(master, \n        id_vars=list(id_vars), \n        value_vars=list(value_vars))\n\nlong_master.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can now get rid of the rows where the column 'value' is 0 and then remove that column altogether."},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove rows having value=0\nlong_master = long_master[long_master['value']==1]\nlong_master = long_master.drop('value', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# look at the new master\nlong_master.head()\nlen(long_master)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# renaming the 'variable' column\nlong_master = long_master.rename(columns={'variable': 'sector'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dataframe now contains only venture type investments in countries USA, IND and GBR, and we have mapped each company to one of the eight main sectors (named 'sector' in the dataframe). \n\nWe can now compute the sector-wise number and the amount of investment in the three countries."},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarising the sector-wise number and sum of venture investments across three countries\n\n# first, let's also filter for investment range between 5 and 15m\nmaster = long_master[(long_master['raised_amount_usd'] >= 5000000) & (long_master['raised_amount_usd'] <= 15000000)]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# groupby country, sector and compute the count and sum\nmaster.groupby(['country_code', 'sector']).raised_amount_usd.agg(['count', 'sum'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This will be much more easy to understand using a plot."},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting sector-wise count and sum of investments in the three countries\nplt.figure(figsize=(16, 14))\n\nplt.subplot(2, 1, 1)\np = sns.barplot(x='sector', y='raised_amount_usd', hue='country_code', data=master, estimator=np.sum)\np.set_xticklabels(p.get_xticklabels(),rotation=30)\nplt.title('Total Invested Amount (USD)')\n\nplt.subplot(2, 1, 2)\nq = sns.countplot(x='sector', hue='country_code', data=master)\nq.set_xticklabels(q.get_xticklabels(),rotation=30)\nplt.title('Number of Investments')\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus, the top country in terms of the number of investments (and the total amount invested) is the USA. The sectors 'Others', 'Social, Finance, Analytics and Advertising' and 'Cleantech/Semiconductors' are the most heavily invested ones.\n\nIn case you don't want to consider 'Others' as a sector, 'News, Search and Messaging' is the next best sector."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}