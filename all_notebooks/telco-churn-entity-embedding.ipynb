{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd\nimport keras\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.callbacks import *\nfrom keras.losses import *\nfrom keras.losses import *\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndata = pd.read_csv(\"../input/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data['sentence'] = data.apply(lambda row: 'gender:'+str(row['gender'])+'|'\n                              + 'SeniorCitizen:'+str(row['SeniorCitizen'])+'|'\n                              + 'Partner:'+str(row['Partner'])+'|'\n                              + 'Dependents:'+str(row['Dependents'])+'|'\n                              + 'PhoneService:'+str(row['PhoneService'])+'|'\n                              + 'MultipleLines:'+str(row['MultipleLines'])+'|'\n                              + 'InternetService:'+str(row['InternetService'])+'|'\n                              + 'OnlineSecurity:'+str(row['OnlineSecurity'])+'|'\n                              + 'OnlineBackup:'+str(row['OnlineBackup'])+'|'\n                              + 'DeviceProtection:'+str(row['DeviceProtection'])+'|'\n                              + 'TechSupport:'+str(row['TechSupport'])+'|'\n                              + 'StreamingTV:'+str(row['StreamingTV'])+'|'\n                              + 'StreamingMovies:'+str(row['StreamingMovies'])+'|'\n                              + 'Contract:'+str(row['Contract'])+'|'\n                              + 'PaperlessBilling:'+str(row['PaperlessBilling'])+'|'\n                              + 'PaymentMethod:'+str(row['PaymentMethod'])\n                              ,axis=1)\ndata_proc = data[['customerID','sentence','tenure','MonthlyCharges','TotalCharges','Churn']]\ndata_proc['TotalCharges'] = data_proc['TotalCharges'].apply(lambda x: float(x) if x!=' ' else 0.0)\ndata_proc.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff5e87b65547b836858cbf1be92ea1524e5fc712"},"cell_type":"markdown","source":"Because customers that do not churn are more valuable for the business, we should give class 'No' a higher weight, or oversample it. But as the dataset is already imbalanced in favor of the class, we leave it alone."},{"metadata":{"trusted":true,"_uuid":"5517107cf805dbec9d83060eb044a581db31bafc"},"cell_type":"code","source":"sns.countplot(x=\"Churn\", data=data);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e05775ba94fe48eef93f8fd078c502c27ea2ee0","scrolled":true,"collapsed":true},"cell_type":"code","source":"X_cat = data_proc['sentence'].values\nX_num = StandardScaler().fit_transform(data_proc[['tenure','MonthlyCharges','TotalCharges']].astype(np.float).values)\ny = data_proc['Churn'].apply(lambda x: 1 if x=='Yes' else 0).values\n\ntokenizer = Tokenizer(filters='',lower=False,split='|')\ntokenizer.fit_on_texts(X_cat)\nX_cat_seq = pad_sequences(tokenizer.texts_to_sequences(X_cat))\nSEQ_LEN = len(X_cat_seq[0])\nMAX_ID = np.max(X_cat_seq)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"010b19faee83ff7e348c62f58b83765a98a070b2","collapsed":true},"cell_type":"code","source":"def make_model():\n    cat_in = Input((SEQ_LEN,))\n    num_in = Input((3,))\n    embedding = Embedding(input_dim=MAX_ID+1, output_dim=20)(cat_in)\n    x = SpatialDropout1D(0.5)(embedding)\n    x = GlobalAveragePooling1D()(x)\n    x = concatenate([x, num_in])\n    x = Dense(50, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    x = Dense(1, activation='sigmoid')(x)\n\n    return Model(cat_in, embedding), Model([cat_in, num_in], x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc8d8a71c064ea7428aaeea2230a80fcc5461cf0"},"cell_type":"code","source":"embedding, model = make_model()\nmodel.summary()\n\nX_cat_seq_train,X_cat_seq_test,X_num_train,X_num_test,y_train,y_test = train_test_split(X_cat_seq, X_num, y, test_size=0.1)\nmodel.compile(optimizer='adam', loss='binary_crossentropy',metrics=['acc'])\nhistory = model.fit([X_cat_seq_train, X_num_train], y_train,\n                    epochs=100,\n                    validation_data=([X_cat_seq_test, X_num_test], y_test),\n                    callbacks=[EarlyStopping(monitor='val_loss',patience=1,verbose=2)],\n                    verbose=2)\n    \ny_pred = np.round(model.predict([X_cat_seq_test, X_num_test]))\n    \n#plt.figure()\n#plt.plot(history.history['loss'], 'r')\n#plt.plot(history.history['val_loss'], 'b')\n    \n#plt.figure()\n#plt.plot(history.history['acc'], 'r')\n#plt.plot(history.history['val_acc'], 'b')\n    \nplt.figure()\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True)\n    \nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"33f2eed91ffa423526280b1391c9ab7b7bc30fbd"},"cell_type":"markdown","source":"## Visualizing Embedding Vectors\n\nSimilar categories in terms of the classification power are clustered together. Generally speaking, no causality should be drawn from any ML result, but I take the freedom to do so here. Factors close to `Contract:Two Years` means they retain customers effectively, while factors, like `Electric Check`, `Contract:Month-to-Month`, `TechSupport:No`, that 'repels' customers, cluster together at another cornor. See [the EDA done by GauravJoshi](https://www.kaggle.com/gauravjoshi1986/retain-customers-exploratory-analysis) for better explanations ."},{"metadata":{"trusted":true,"_uuid":"3f4327fee9dccf7aa2e6028beb9afb55385d1104"},"cell_type":"code","source":"keys = list(tokenizer.word_index.keys())\nkey_seq = tokenizer.texts_to_sequences(keys)\nvecs = embedding.predict(pad_sequences(key_seq,SEQ_LEN,padding='post'))\n\nplt.figure(figsize=(20,20))\nx = []\ny = []\nfor v in vecs:\n    x.append(v[0][0])\n    y.append(v[0][1])\nplt.scatter(x,y)\nfor i,k in enumerate(keys):\n    plt.text(x[i],y[i],k)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}