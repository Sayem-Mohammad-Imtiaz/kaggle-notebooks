{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/employee-attrition/employee_attrition_train.csv')\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# UNDERSTANDING DATA DISTRIBUTION","metadata":{}},{"cell_type":"code","source":"# check for imbalanced data\nprint(data['Attrition'].unique())\nplt.pie(data['Attrition'].value_counts(), autopct='%1.1f%%', labels=['No', 'Yes']);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_category(feature, figsize=None):\n    yes_count = data[data['Attrition']=='Yes'].groupby([feature]).size()\n    no_count = data[data['Attrition']=='No'].groupby([feature]).size()\n    labels = no_count.index\n\n    x = np.arange(len(labels)) # the label locations\n    width = 0.35  # the width of the bars\n\n    if figsize:\n        fig, ax = plt.subplots(figsize=figsize)\n    else:\n        fig, ax = plt.subplots()\n    rects1 = ax.bar(x-width/2, round(yes_count*100/data.groupby([feature]).size(), 2), \n                    width, label='Yes')\n    rects2 = ax.bar(x+width/2, round(no_count*100/data.groupby([feature]).size(), 2), \n                    width, label='No')\n\n    ax.set_ylabel('Count')\n    ax.set_title('Based on %s'%feature)\n    ax.set_xticks(x)\n    ax.set_xticklabels(labels, rotation=80)\n    ax.legend();\n\n    ax.bar_label(rects1, padding=1)\n    ax.bar_label(rects2, padding=1)\n\n    fig.tight_layout()\n    plt.show()\n    \ndef plot_numerical(feature, figsize=None):\n    # Attrition vs Age Distribution\n    fig = plt.figure(figsize=(10,6))\n\n    sns.kdeplot(data[data['Attrition']=='No'][feature])\n    sns.kdeplot(data[data['Attrition']=='Yes'][feature])\n\n    fig.legend(labels=['Attrition No', 'Attrition Yes'])\n    plt.title('Based on %s'%feature)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in ['Age']:\n    plot_numerical(feature)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in ['DailyRate', 'HourlyRate', 'MonthlyRate']:\n    plot_numerical(feature)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in ['BusinessTravel']:\n    plot_category(feature)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So More you travel higher the chances of attrition","metadata":{}},{"cell_type":"code","source":"for feature in ['Department', 'JobRole', 'Education', 'EducationField']:\n    plot_category(feature, figsize=(8,5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in ['DistanceFromHome']:\n    plot_numerical(feature)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in ['EnvironmentSatisfaction', 'JobInvolvement', 'JobSatisfaction']:\n    plot_category(feature, figsize=(8,5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in ['Gender']:\n    plot_category(feature)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in ['JobLevel']:\n    plot_category(feature)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in ['MaritalStatus', 'Over18']:\n    plot_category(feature)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in ['MonthlyIncome', 'TotalWorkingYears']:\n    plot_numerical(feature)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in ['NumCompaniesWorked']:\n    plot_numerical(feature, figsize=(8,5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in ['OverTime', 'StandardHours', 'WorkLifeBalance']:\n    plot_category(feature)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in ['PercentSalaryHike']:\n    plot_numerical(feature)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in ['PerformanceRating']:\n    plot_category(feature)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in ['YearsSinceLastPromotion', 'YearsInCurrentRole', 'YearsAtCompany', \n                'YearsWithCurrManager']:\n    plot_numerical(feature)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for feature in [ 'RelationshipSatisfaction', 'StockOptionLevel', 'TrainingTimesLastYear']:\n    plot_category(feature)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Columns that seem to contribute towards Attrition:**<br>\n1. YearsWithCurrManager < 5\n2. YearsAtCompany < 5\n3. YearsInCurrentRole < 4\n4. TotalWorkingHours < 10\n6. DailyRate < 1000\n7. NumCompaniesWorked > 5\n8. MonthlyIncome < 5000\n9. Age < 35\n10. TrainingTimeLastYear - 0\n11. StockOptionLevel - 0 \n12. OverTime - yes \n13. JobRole - Sales Representative\n14. Married - Single\n15. JobLevel - 1\n16. BusinessTravel - travel frequently\n17. EducationField - Technical Field, Human Resources\n18. WorkLifeBalance - 1\n19. EnvironmentSatisfaction - 1\n20. JobInvolvement - 1\n21. JobSatisfaction - 1","metadata":{}},{"cell_type":"code","source":"categorical_features = ['BusinessTravel', 'Department', 'JobRole', 'Education', \n                        'EducationField', 'Gender', 'MaritalStatus', 'OverTime']\nnumerical_features = ['Age', 'DailyRate', 'DistanceFromHome', 'EnvironmentSatisfaction',\n                      'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobSatisfaction',\n                      'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', 'PercentSalaryHike',\n                      'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel',\n                      'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n                      'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n                      'YearsWithCurrManager']\n\nto_drop = ['StandardHours', 'Over18', 'EmployeeCount', 'EmployeeNumber'] # contain only single unique value","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Label Encoding Categorical Features for Correlation (includes missing values)","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\nimport os\nimport joblib","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = data.copy()\npath = '/kaggle/working'\nfor i, feature in enumerate(categorical_features):\n    le = LabelEncoder()\n\n    # create directory to save label encoding models\n    if not os.path.exists(os.path.join(path, \"TextEncoding\")):\n        os.makedirs(os.path.join(path, \"TextEncoding\"))\n\n    # perform label encoding\n    le.fit(df[feature])\n    \n    # save the encoder\n    joblib.dump(le, open(os.path.join(path, \"TextEncoding/le_{}.sav\".format(feature)), 'wb'))\n    \n    # transfrom training data\n    df[feature] = le.transform(df[feature])\n\n    # get classes & remove first column to elude from dummy variable trap\n    columns = list(map(lambda x: feature+' '+str(x), list(le.classes_)))[1:]\n    \n    # save classes\n    joblib.dump(columns, \n                open(os.path.join(path, \"TextEncoding/le_{}_classes.sav\".format(feature)), 'wb'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CORRELATION","metadata":{}},{"cell_type":"code","source":"# Bivariate Analysis Correlation plot with the Numeric variables\nplt.figure(figsize=(15, 15))\nsns.heatmap(round(data[numerical_features].corr(), 2), annot=True,\n            mask=None, cmap='GnBu')\ncorr_mat = data[numerical_features].corr()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlated Features\ns = corr_mat.unstack()\nso = s.sort_values(kind=\"quicksort\").drop_duplicates()\nres1 = so[so>=0.5]\nprint(res1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations:**\n\n1. As age increases the TotalWorkingYears(experience) increases.\n2. Monthly Income is directly proportional to Job level & TotalWorkingYears. Employees at Higher position & more experience gets more income.\n3. Higher performance rating bring higher percent salary hikes\n4. TotalWorkingYears-YearsAtCompany shows that people who have more experience might be liking to continue their association with the company\n5. YearsAtCompany, YearsWithCurrManager, YearsInCurrentRole shows a positive correlation among each other.","metadata":{}},{"cell_type":"code","source":"# Bivariate Analysis Correlation plot with the Categorical variables\nplt.figure(figsize=(20, 20))\nsns.heatmap(round(df[categorical_features+numerical_features].corr(method='spearman'), 2), annot=True,\n            mask=None, cmap='GnBu')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations:**\n\n1. Department - JobRole\n2. MaritalStatus - StockOptionLevel (-)","metadata":{}},{"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculating VIF\nvif = pd.DataFrame()\ntemp = df.dropna()\nvif[\"variables\"] = [feature for feature in categorical_features+numerical_features if feature not in ['PerformanceRating', 'JobLevel',\n                                                                                                     'Age', 'PercentSalaryHike',\n                                                                                                     'WorkLifeBalance', 'JobInvolvement',\n                                                                                                     'Department', 'YearsAtCompany']]\nvif[\"VIF\"] = [variance_inflation_factor(temp[vif['variables']].values, i) for i in range(len(vif[\"variables\"]))]\nprint(vif)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Handling Missing Values","metadata":{}},{"cell_type":"code","source":"missingValueFeatures = pd.DataFrame({'missing %': data.isnull().sum()*100/len(data)})\nmissingValueFeatures[missingValueFeatures['missing %']>0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"|Column|Correlation|\n|---|---|\n|Age|TotalWorkingYears| \n|BusinessTravel|NA| \n|DailyRate|   NA|\n|DistanceFromHome|NA|\n|MaritalStatus|StockOptionLevel|","metadata":{}},{"cell_type":"markdown","source":"We can impute missing values as per the correlation table above. Columns with NA values can be replaced by mean, mode, median or back fill methods","metadata":{}},{"cell_type":"code","source":"# Imputing BusinessTravel with Back fill\nprint('Before Imputation:')\nprint(data[['BusinessTravel']].value_counts())\ndata['BusinessTravel'].fillna(method='bfill', inplace=True)\nprint('\\nAfter Imputation:')\nprint(data[['BusinessTravel']].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Imputing DailyRate and DistanceFromHome with Mean values\nprint('Before Imputation:')\nprint(data[['DailyRate', 'DistanceFromHome']].describe().T)\ndata[['DailyRate', 'DistanceFromHome']] = data[['DailyRate', 'DistanceFromHome']].fillna(data[['DailyRate', 'DistanceFromHome']].mean())\nprint('\\nAfter Imputation:')\nprint(data[['DailyRate', 'DistanceFromHome']].describe().T)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Imputing Age as per TotalWorkingYears\n\nprint('Before Imputation:')\nprint(data[['Age']].describe().T)\n\ndata.sort_values(by='TotalWorkingYears', inplace=True)\n\n# now use backfill method to replace Age\ndata['Age'].fillna(method='bfill', inplace=True)\n\nprint('\\nAfter Imputation:')\nprint(data[['Age']].describe().T)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Imputing MaritalStatus as per StockOptionLevel\nprint(pd.crosstab(data['MaritalStatus'], data['StockOptionLevel']))\nprint('\\nStockOptionLevel Distribution across missing MaritalStatus values:')\nprint(data[data['MaritalStatus'].isna()]['StockOptionLevel'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For StockOptionLevel 1 & 2 mode of MaritalStatus is Married\nprint('\\nBefore Imputation:')\nprint(data[['MaritalStatus']].value_counts())\ndata['MaritalStatus'].fillna(data['MaritalStatus'].mode()[0], inplace=True)\nprint('\\nAfter Imputation:')\nprint(data[['MaritalStatus']].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# verifying missing values\ndata.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Looking at Outliers","metadata":{}},{"cell_type":"code","source":"NumericData = data[[feature for feature in numerical_features if feature not in ['MonthlyIncome', \n                                                                               'MonthlyRate', \n                                                                               'DailyRate',\n                                                                              'HourlyRate']]]\nNumericMelt = NumericData.melt()\nplt.figure(figsize=(15,10))\nplt.title(\"Boxplots for Numerical variables\")\nbp = sns.boxplot(x='variable', y='value', data=NumericMelt)\nbp.set_xticklabels(bp.get_xticklabels(), rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NumericData = data[['DailyRate', 'HourlyRate']]\n# skipping 'MonthlyIncome', 'MonthlyRate', 'DailyRate' \n# due to very different range of values compared to others\nNumericMelt = NumericData.melt()\nplt.figure(figsize=(8,5))\nplt.title(\"Boxplots for Numerical variables\")\nbp = sns.boxplot(x='variable', y='value', data=NumericMelt)\nbp.set_xticklabels(bp.get_xticklabels(), rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NumericData = data[['MonthlyIncome', 'MonthlyRate']]\n# skipping 'MonthlyIncome', 'MonthlyRate', 'DailyRate' \n# due to very different range of values compared to others\nNumericMelt = NumericData.melt()\nplt.figure(figsize=(8,5))\nplt.title(\"Boxplots for Numerical variables\")\nbp = sns.boxplot(x='variable', y='value', data=NumericMelt)\nbp.set_xticklabels(bp.get_xticklabels(), rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Columns with Outlier values:**<br>\n1. TotalWorkingYears\n2. YearsAtCompany\n3. YearsInCurrentRole\n4. YearsSinceLastPromotion\n5. YearsWithCurrManager\n6. TrainingTimesLastYear\n7. NumCompaniesWorked\n8. MonthlyIncome<br>\nOther columns like PerformanceRating are not considered in outliers as they have very few unique values","metadata":{}},{"cell_type":"code","source":"# Percentage of outliers present in each variable\noutlier_percentage = {}\nfor feature in ['TotalWorkingYears', 'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n                'YearsWithCurrManager', 'TrainingTimesLastYear', 'NumCompaniesWorked', 'MonthlyIncome']:\n    tempData = data.sort_values(by=feature)[feature]\n    Q1, Q3 = tempData.quantile([0.25, 0.75])\n    IQR = Q3 - Q1\n    Lower_range = Q1 - (1.5 * IQR)\n    Upper_range = Q3 + (1.5 * IQR)\n    outlier_percentage[feature] = round((((tempData<(Q1 - 1.5 * IQR)) | (tempData>(Q3 + 1.5 * IQR))).sum()/tempData.shape[0])*100,2)\noutlier_percentage","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Outlier treatment with more thatn 4% outlier values\ndf_outlier = data.copy()\nfor feature in ['TotalWorkingYears', 'YearsAtCompany', 'YearsSinceLastPromotion', 'TrainingTimesLastYear', 'MonthlyIncome']:\n    tempData = df_outlier.sort_values(by=feature)[feature]\n    Q1, Q3 = tempData.quantile([0.25, 0.75])\n    IQR = Q3 - Q1\n    Lower_range = Q1 - (1.5 * IQR)\n    Upper_range = Q3 + (1.5 * IQR)    \n    df_outlier.loc[(df_outlier[feature]<(Q1 - 1.5 * IQR))|(df_outlier[feature]>(Q3 + 1.5 * IQR)), \n                   feature] = Upper_range","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Handling Categorical Features (Label and One Hot Encoding)","metadata":{}},{"cell_type":"code","source":"df = df_outlier.copy()\npath = '/kaggle/working'\nfor i, feature in enumerate(categorical_features):\n    \n    le = LabelEncoder()\n    ohe = OneHotEncoder(sparse=False)\n\n    # create directory to save label encoding models\n    if not os.path.exists(os.path.join(path, \"TextEncoding\")):\n        os.makedirs(os.path.join(path, \"TextEncoding\"))\n\n    # perform label encoding\n    le.fit(df[feature])\n    # save the encoder\n    joblib.dump(le, open(os.path.join(path, \"TextEncoding/le_{}.sav\".format(feature)), 'wb'))\n    \n    # transfrom training data\n    df[feature] = le.transform(df[feature])\n\n    # get classes & remove first column to elude from dummy variable trap\n    columns = list(map(lambda x: feature+' '+str(x), list(le.classes_)))[1:]\n    \n    # save classes\n    joblib.dump(columns, \n                open(os.path.join(path, \"TextEncoding/le_{}_classes.sav\".format(feature)), 'wb'))\n    # load classes\n    columns = joblib.load(\n        open(os.path.join(path, \"TextEncoding/le_{}_classes.sav\".format(feature)), 'rb'))\n\n    if len(le.classes_)>2:\n        # perform one hot encoding\n        ohe.fit(df[[feature]])\n        # save the encoder\n        joblib.dump(ohe, \n                    open(os.path.join(path, \"TextEncoding/ohe_{}.sav\".format(feature)), 'wb'))\n\n        # transfrom training data\n        # removing first column of encoded data to elude from dummy variable trap\n        tempData = ohe.transform(df[[feature]])[:, 1:]\n\n        # create Dataframe with columns as classes\n        tempData = pd.DataFrame(tempData, columns=columns)\n    else:\n        tempData = df[feature]\n    \n    # create dataframe with all the label encoded categorical features along with hot encoding\n    if i==0:\n        encodedData = pd.DataFrame(data=tempData, columns=tempData.columns.values.tolist())\n    else:\n        encodedData = pd.concat([encodedData, tempData], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merge numerical features and categorical encoded features\ndf = df[numerical_features+['Attrition']]\ndf = pd.concat([df, encodedData], axis=1)\ndf.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Model","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics, preprocessing\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.svm import SVC","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = df.copy()\nfeature_cols = [feature for feature in train_data.columns if feature not in(['Attrition', 'PerformanceRating', 'JobLevel',\n                                                                             'Age', 'PercentSalaryHike',\n                                                                             'WorkLifeBalance', 'JobInvolvement',\n                                                                             'YearsAtCompany', 'Department Research & Development',\n                                                                             'Department Sales'])]\n\n''' Rescaling to [0,1] '''\nscaler = MinMaxScaler()\nscaler.fit(train_data[feature_cols])\ntrain_data[feature_cols] = scaler.transform(train_data[feature_cols])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_data[feature_cols]\ny = train_data['Attrition']\ny.replace('No', 0, inplace=True)\ny.replace('Yes', 1, inplace=True)\n\nvalidation_size = 0.25\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=validation_size, \n                                                    random_state=4, stratify=y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 1: Logistic Regression","metadata":{}},{"cell_type":"code","source":"model = LogisticRegression(class_weight={0:1, 1:10})\nmodel.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_train)\n\nprint('Train metrics...')\nprint(confusion_matrix(y_train, y_pred))\nprint(classification_report(y_train, y_pred))\n\ny_pred = model.predict(X_test)\n\nprint('Validation metrics...')\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"''' metrics on original data '''\ny_pred = model.predict(train_data[feature_cols])\n\ndef make_cm(matrix, columns):\n    n = len(columns)\n    act = ['actual Attrition'] * n\n    pred = ['prediction Attrition'] * n\n\n    cm = pd.DataFrame(matrix, \n        columns=[pred, columns], index=[act, columns])\n    return cm\n\ndf_matrix=make_cm(\n    confusion_matrix(train_data['Attrition'], y_pred),['No','Yes'])\n\ndisplay(df_matrix)\nprint(classification_report(train_data['Attrition'], y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 2: SVM","metadata":{}},{"cell_type":"code","source":"model = SVC(class_weight={0: 1, 1: 10})\nmodel.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_train)\n\nprint('Train metrics...')\nprint(confusion_matrix(y_train, y_pred))\nprint(classification_report(y_train, y_pred))\n\ny_pred = model.predict(X_test)\n\nprint('Test metrics...')\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"''' metrics on original data '''\ny_pred = model.predict(train_data[feature_cols])\n\ndef make_cm(matrix, columns):\n    n = len(columns)\n    act = ['actual Attrition'] * n\n    pred = ['prediction Attrition'] * n\n\n    cm = pd.DataFrame(matrix, \n        columns=[pred, columns], index=[act, columns])\n    return cm\n\ndf_matrix=make_cm(\n    confusion_matrix(train_data['Attrition'], y_pred),['No','Yes'])\n\ndisplay(df_matrix)\nprint(classification_report(train_data['Attrition'], y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}