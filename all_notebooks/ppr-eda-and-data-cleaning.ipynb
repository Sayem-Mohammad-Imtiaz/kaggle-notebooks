{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Property Price Register EDA\n***\nAIM : perform exploratory data analysis to better understand the story that the data is providing\n***\nTasks\n* Review each of the input variables\n* Understand the key trends emerging\n* Begin to perform some data cleaning to help with future analysis\n***\nTODO\n* Complete address cleaning process\n* Develop automated visualizations\n* Include external data sources (location details, House Price Indices)","metadata":{}},{"cell_type":"markdown","source":"## 1 Setup Notebook","metadata":{}},{"cell_type":"code","source":"# Import packages and modules\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport re\nimport plotly.express as px\n\n# Review the dataset's stored in the input library\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Switch on setting to allow all outputs to be displayed\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\n# Adjust options for displaying the float columns\npd.options.display.float_format = '{:,.2f}'.format","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-07T07:38:40.531283Z","iopub.execute_input":"2021-07-07T07:38:40.531715Z","iopub.status.idle":"2021-07-07T07:38:40.543956Z","shell.execute_reply.started":"2021-07-07T07:38:40.531682Z","shell.execute_reply":"2021-07-07T07:38:40.542908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2 Import data","metadata":{}},{"cell_type":"markdown","source":"### 2a. Initial dataset review\n***\nAiming to understand what parameters are required to ensure that the initial import performs as much initial data cleaning as possible.","metadata":{}},{"cell_type":"code","source":"# Import the dataset\ndf = pd.read_csv('/kaggle/input/residential-property-prices-2020/PPR-2020.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-07T07:38:40.545828Z","iopub.execute_input":"2021-07-07T07:38:40.54617Z","iopub.status.idle":"2021-07-07T07:38:40.706256Z","shell.execute_reply.started":"2021-07-07T07:38:40.546126Z","shell.execute_reply":"2021-07-07T07:38:40.705179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preview the data\ndf.head()\ndf.shape\ndf.dtypes\ndf.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2021-07-07T07:38:40.708425Z","iopub.execute_input":"2021-07-07T07:38:40.70892Z","iopub.status.idle":"2021-07-07T07:38:40.926092Z","shell.execute_reply.started":"2021-07-07T07:38:40.708872Z","shell.execute_reply":"2021-07-07T07:38:40.925089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Review columns and rename to remove the spaces\ndf.columns # columns before adjustment\ndf.columns = df.columns.str.replace(' ', '_') # changing the spaces into underscores\ndf.columns # columns after adjustment","metadata":{"execution":{"iopub.status.busy":"2021-07-07T07:38:40.927597Z","iopub.execute_input":"2021-07-07T07:38:40.928038Z","iopub.status.idle":"2021-07-07T07:38:40.938948Z","shell.execute_reply.started":"2021-07-07T07:38:40.927987Z","shell.execute_reply":"2021-07-07T07:38:40.9378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rename specific columns\ndf = df.rename(columns={'Date_of_Sale_(dd/mm/yyyy)':'Date_of_Sale',\n                        'Price_(ï¿½)':'Price'\n                       })\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-07T07:38:40.941105Z","iopub.execute_input":"2021-07-07T07:38:40.941459Z","iopub.status.idle":"2021-07-07T07:38:40.965558Z","shell.execute_reply.started":"2021-07-07T07:38:40.94141Z","shell.execute_reply":"2021-07-07T07:38:40.964473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reviewing memory usage aims to show the size and type of each column. Understanding if a better column format can be used will help with future analysis\n# if the dataset increases in size. Also it allows us to make more efficient use of the memory\ndf.info(memory_usage='deep')","metadata":{"execution":{"iopub.status.busy":"2021-07-07T07:38:40.966999Z","iopub.execute_input":"2021-07-07T07:38:40.967408Z","iopub.status.idle":"2021-07-07T07:38:41.104311Z","shell.execute_reply.started":"2021-07-07T07:38:40.967376Z","shell.execute_reply":"2021-07-07T07:38:41.103218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the variables to more efficient versions of data type\ndf['Price'] = df['Price'].str[1:]\ndf['Price'] = df['Price'].str.replace(',','').astype(float)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-07T07:38:41.105381Z","iopub.execute_input":"2021-07-07T07:38:41.105686Z","iopub.status.idle":"2021-07-07T07:38:41.200691Z","shell.execute_reply.started":"2021-07-07T07:38:41.105659Z","shell.execute_reply":"2021-07-07T07:38:41.199588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check to see if the price data type has been changed correctly\ndf.dtypes\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-07T07:39:32.701893Z","iopub.execute_input":"2021-07-07T07:39:32.702275Z","iopub.status.idle":"2021-07-07T07:39:32.725655Z","shell.execute_reply.started":"2021-07-07T07:39:32.702243Z","shell.execute_reply":"2021-07-07T07:39:32.724406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check to see if the columns can be converted to categories. If there is a low cardinality (proportion of unique values) then it \n# makes sense to convert the column data type\ncardinality = df.apply(pd.Series.nunique) # Display the cardinality for each column\ncardinality","metadata":{"execution":{"iopub.status.busy":"2021-07-07T07:39:40.916466Z","iopub.execute_input":"2021-07-07T07:39:40.916838Z","iopub.status.idle":"2021-07-07T07:39:41.002938Z","shell.execute_reply.started":"2021-07-07T07:39:40.916806Z","shell.execute_reply":"2021-07-07T07:39:41.001615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From this output it makes sense to convert the final four columns to category data types","metadata":{}},{"cell_type":"code","source":"# Extract the column name which matches the column index value being reviewed\ncat_val = [i for i in (df.apply(pd.Series.nunique)) if i <= 3]\ncat_cols = [df.columns[i] for i, n in enumerate(df.apply(pd.Series.nunique)) if n <=3] # adding the enumerate method provides an index value\ncat_val\ncat_cols\n\n# Convert the cat_cols list to category data type\ndf[cat_cols] = df[cat_cols].astype('category')\ndf.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-07-07T07:39:46.364066Z","iopub.execute_input":"2021-07-07T07:39:46.364423Z","iopub.status.idle":"2021-07-07T07:39:46.567109Z","shell.execute_reply.started":"2021-07-07T07:39:46.364384Z","shell.execute_reply":"2021-07-07T07:39:46.566086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Review the new size of the dataset\ndf.info(memory_usage='deep')","metadata":{"execution":{"iopub.status.busy":"2021-07-07T07:39:49.960263Z","iopub.execute_input":"2021-07-07T07:39:49.960643Z","iopub.status.idle":"2021-07-07T07:39:50.036228Z","shell.execute_reply.started":"2021-07-07T07:39:49.960609Z","shell.execute_reply":"2021-07-07T07:39:50.03479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the Date_of_Sale to date\ndf['Date_of_Sale'] = df['Date_of_Sale'].apply(pd.to_datetime)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T07:39:56.939028Z","iopub.execute_input":"2021-07-07T07:39:56.939556Z","iopub.status.idle":"2021-07-07T07:40:01.887829Z","shell.execute_reply.started":"2021-07-07T07:39:56.939502Z","shell.execute_reply":"2021-07-07T07:40:01.886646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()\ndf.dtypes\ndf.info(memory_usage='deep')","metadata":{"execution":{"iopub.status.busy":"2021-07-07T07:40:03.776348Z","iopub.execute_input":"2021-07-07T07:40:03.776713Z","iopub.status.idle":"2021-07-07T07:40:03.853588Z","shell.execute_reply.started":"2021-07-07T07:40:03.776682Z","shell.execute_reply":"2021-07-07T07:40:03.852751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2b. Missing value review","metadata":{}},{"cell_type":"code","source":"# Understand the missing values by column\ndf.isnull().sum()\n\n# Create method to review the proportion of missing values by each column\ndef missing_columns(df):\n    for col in df.columns:\n        miss = df.isnull().sum()\n        miss_per = miss / len(df)\n    return miss_per\n\nmissing_columns(df)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T07:40:11.20513Z","iopub.execute_input":"2021-07-07T07:40:11.205491Z","iopub.status.idle":"2021-07-07T07:40:11.373575Z","shell.execute_reply.started":"2021-07-07T07:40:11.20546Z","shell.execute_reply":"2021-07-07T07:40:11.372506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Can drop the Property_Size_Description column as this has a large number of missing values. Will have to review the counties which are showing the largest number of available values for the Postal_Code column.","metadata":{}},{"cell_type":"code","source":"# Drop the columns not required\ndf = df.drop(columns=['Property_Size_Description'])\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-07T07:40:26.022842Z","iopub.execute_input":"2021-07-07T07:40:26.023203Z","iopub.status.idle":"2021-07-07T07:40:26.044301Z","shell.execute_reply.started":"2021-07-07T07:40:26.023172Z","shell.execute_reply":"2021-07-07T07:40:26.043335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Initial EDA visualizations","metadata":{}},{"cell_type":"code","source":"# Price by the date of sale\nfig = px.bar(df, x='Date_of_Sale', y='Price', title='Price by Time')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-07T07:41:14.969282Z","iopub.execute_input":"2021-07-07T07:41:14.969679Z","iopub.status.idle":"2021-07-07T07:41:18.122917Z","shell.execute_reply.started":"2021-07-07T07:41:14.969648Z","shell.execute_reply":"2021-07-07T07:41:18.122019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Price grouped by month and county\nprice_county = df.groupby([df['Date_of_Sale'].dt.month, 'County'])['Price'].mean()\nprice_county = price_county.reset_index()\nprice_county","metadata":{"execution":{"iopub.status.busy":"2021-07-07T07:41:48.404844Z","iopub.execute_input":"2021-07-07T07:41:48.405196Z","iopub.status.idle":"2021-07-07T07:41:48.437638Z","shell.execute_reply.started":"2021-07-07T07:41:48.405166Z","shell.execute_reply":"2021-07-07T07:41:48.436593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the price by date of sale with county applied as a color\nfig = px.bar(price_county, x='Date_of_Sale', y='Price', color='County', title='Average Price by Time')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-07T07:41:52.090051Z","iopub.execute_input":"2021-07-07T07:41:52.09046Z","iopub.status.idle":"2021-07-07T07:41:52.278299Z","shell.execute_reply.started":"2021-07-07T07:41:52.09041Z","shell.execute_reply":"2021-07-07T07:41:52.277073Z"},"trusted":true},"execution_count":null,"outputs":[]}]}