{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nimport glob\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from pathlib import Path\nfrom fastai import *\nfrom fastai.vision import *\nimport torch\nfrom fastai.callbacks.hooks import *\nfrom tqdm import tqdm_notebook","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_folder = Path(\"../input/hackerearth-dl-challengeautotag-images-of-gala/dataset\")\ndata_path = \"../input/hackerearth-dl-challengeautotag-images-of-gala/dataset/Train Images\"\npath = os.path.join(data_path , \"*jpg\")\npath","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files = glob.glob(path)\ndata=[]\nname_img_mapper = {}\nfor file in tqdm_notebook(files):\n    fn = file.split('/')[-1]\n    image = cv2.imread(file)\n    data.append(file)\n    name_img_mapper[fn] = image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## read the csv data files\ntrain_df = pd.read_csv('../input/hackerearth-dl-challengeautotag-images-of-gala/dataset/train.csv')\ntest_df = pd.read_csv('../input/hackerearth-dl-challengeautotag-images-of-gala/dataset/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.groupby('Class').count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Class' , data=train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images = data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"category = {'Food': 1, \n'misc': 2, \n'Attire': 3, \n'Decorationandsignage': 4}\n\ntrain_df.loc[train_df['Class']== 'Food']['Image'][:3].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.loc[train_df['Class']== 'Food']['Image'][:3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_class(cat):\n    \n    fetch = train_df.loc[train_df['Class']== cat][:3]\n    images_names = train_df.loc[train_df['Class']== cat]['Image'][:3].tolist()\n#     print(images_names)\n    fig = plt.figure(figsize=(20,15))\n    \n    for i, img_name in enumerate(images_names):\n#         print(i, img_name)\n        plt.subplot(1,3 ,i+1)\n        plt.imshow(name_img_mapper[img_name])\n#         plt.xlabel(cat + \" (Index:\" +str()+\")\" )\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(name_img_mapper['image7042.jpg'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_class('Decorationandsignage')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##transformations to be done to images\ntfms = get_transforms(do_flip=True,flip_vert=False ,max_rotate=15.0, max_zoom=1.2, max_lighting=0.5, max_warp=0.1, p_affine=0.2,\n                      p_lighting=0.55)\n#, xtra_tfms=zoom_crop(scale=(0.9,1.8), do_rand=True, p=0.8))\n\n## create databunch of test set to be passed\ntest_img = ImageList.from_df(test_df, path=data_folder, folder='Test Images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(145)\n## create source of train image databunch\nsrc = (ImageList.from_df(train_df, path=data_folder, folder='Train Images')\n       .split_by_rand_pct(0.15)\n       #.split_none()\n       .label_from_df()\n       .add_test(test_img))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = (src.transform(tfms, size=299,padding_mode='reflection',resize_method=ResizeMethod.SQUISH)\n        .databunch(path='.', bs=32, device= torch.device('cuda:0')).normalize(imagenet_stats))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.show_batch(rows=3, figsize=(12,12))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = cnn_learner(data=data, base_arch=models.densenet201, metrics=[FBeta(beta=1, average='macro'), accuracy],\n                    callback_fns=ShowGraph)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets find the correct learning rate to be used from lr finder\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 1e-03\n#learn.fit_one_cycle(10, slice(lr))\nlearn.fit_one_cycle(8, slice(lr), wd=0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lr = 1.2e-03\n# #learn.fit_one_cycle(10, slice(lr))\n# learn.fit_one_cycle(8, slice(lr), wd=0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets plot the lr finder record\nlearn.unfreeze()\nlearn.lr_find()\n\nlearn.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(10,slice(1e-06,lr/8),wd=0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets see the most mis-classified images (on validation set)\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_top_losses(9, figsize=(15,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn.recorder.plot_losses()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##learn.TTA improves score further. lets see for the validation set\npred_val,y = learn.TTA(ds_type=DatasetType.Valid)\nfrom sklearn.metrics import f1_score, accuracy_score\nvalid_preds = [np.argmax(pred_val[i])+1 for i in range(len(pred_val))]\nvalid_preds = np.array(valid_preds)\ny = np.array(y+1)\naccuracy_score(valid_preds,y),f1_score(valid_preds,y, average='weighted')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds,_ = learn.TTA(ds_type=DatasetType.Test)\n#preds,_ = learn.get_preds(ds_type = DatasetType.Test)\nlabelled_preds = [np.argmax(preds[i])+1 for i in range(len(preds))]\n\nlabelled_preds = np.array(labelled_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({'Image':test_df['Image'], 'Class':labelled_preds})\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"category = {'Food': 3, \n'misc': 4, \n'Attire': 1, \n'Decorationandsignage': 2}\nrev_category = {val: key for key, val in category.items()}\ndf['Class'] = df['Class'].map(rev_category)\ndf.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Class.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import HTML\ndef create_download_link(title = \"Download CSV file\", filename = \"data.csv\"):  \n    html = '<a href={filename}>{title}</a>'\n    html = html.format(title=title,filename=filename)\n    return HTML(html)\n\ncreate_download_link(filename = 'submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}