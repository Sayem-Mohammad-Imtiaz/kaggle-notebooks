{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# Exoplanets confirmation values and habitability"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/phl-exoplanet-catalog/phl_exoplanet_catalog_2019.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Null_values=list(zip(df.columns.values.tolist(),df.isnull().sum().tolist()))\nNull_values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"j=0\nfor i in df.columns.values.tolist():\n    if Null_values[j][1]>=df.shape[0]*0.1225:      \n        df = df.drop(columns=i)\n    j=j+1\n\nm = np.core.defchararray.find(df.columns.values.astype(str), 'ERROR') >= 0\ndf=df.loc[:,~m]\n\ndf=df.dropna()\ndf[df != 'nan']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlations"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,9))\n\nheatmap = sns.heatmap(df.corr(), vmin=-1,vmax=1, annot=False, cmap='viridis')\n\nheatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here is observed that the P_HABITABLE which confirm the exoplanet as non-habitable(0), conservatively habitable (1), optmistically habitable(2) is strongly correlated to:\n* P_HABZONE_OPT\n* P_HABZONE_CON\n* P_ESI\n\nIn the other hand, the predictor components have correlations of 1 in some cases so the information obtained is duplicated. That ones are:\n\n* P_SEMI_MAJOR_AXIS_EST, P_DISTANCE, P_APASTRON, P_DISTANCE_EFF\n* P_FLUX, P_FLUX_MAX, P_FLUX_MIN\n* P_TEMP_EQUIL, P_TEMP_EQUIL_MAX, P_TEMP_EQUIL_MIN\n* S_RA, S_RA_H\n* S_RADIUS, S_RADIUS_EST, S_HZ_OPT_MIN, S_HZ_OPT_MAX, S_HZ_CON0_MIN, S_HZ_CON0_MAX, S_HZ_CON1_MIN, S_HZ_CON1_MAX, S_SNOW_LINE\n\nIs worth keeping only one of each group.\nWill drop the coordenates of the Star because that doesn't give information of habitability just location:\n\n* S_RA, S_RA_H, S_DEC, S_RA_T, S_DEC_T"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(columns=['P_DISTANCE', 'P_APASTRON', 'P_DISTANCE_EFF', 'P_FLUX_MAX', 'P_FLUX_MIN',\n                      'P_TEMP_EQUIL_MAX', 'P_TEMP_EQUIL_MIN','S_RA','S_DEC','S_RA_H','S_RA_T','S_DEC_T', 'S_RADIUS_EST', 'S_HZ_OPT_MIN',\n                      'S_HZ_OPT_MAX', 'S_HZ_CON_MIN', 'S_HZ_CON_MAX','S_HZ_CON0_MIN', 'S_HZ_CON0_MAX',\n                      'S_HZ_CON1_MIN', 'S_HZ_CON1_MAX', 'S_SNOW_LINE'])\ndf[\"P_TYPE_TEMP\"] = LabelEncoder().fit_transform(df[\"P_TYPE_TEMP\"])\ndf[\"P_TYPE\"] = LabelEncoder().fit_transform(df[\"P_TYPE\"])\ndf[\"S_TYPE_TEMP\"] = LabelEncoder().fit_transform(df[\"S_TYPE_TEMP\"])\ndf[\"P_DETECTION\"] = LabelEncoder().fit_transform(df[\"P_DETECTION\"])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,9))\n\nheatmap = sns.heatmap(df.corr(), vmin=-1,vmax=1, annot=False, cmap='viridis')\n\nheatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With the known correlations of 'P_HABITABLE' and 'P_ESI' is accurate to say that the most important factors for habitability are:\n\n* S_MAG\n* S_LOG_G\n* S_TYPE_TEMP // S_TEMPERATURE\n* P_TYPE_TEMP // P_TEMP_EQUIL\n* P_TYPE\n\nAdded to the three previous values the most important factors are some properties of the star and type and temperature of the planet. "},{"metadata":{},"cell_type":"markdown","source":"## Visualzation"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig1 = px.density_heatmap(df, x='S_MAG', y='S_LOG_G', z='P_HABITABLE')\nfig2 = px.density_heatmap(df,x='P_TYPE',y='P_TYPE_TEMP',z='P_HABITABLE')\nfig3 = px.scatter(df,x='P_TEMP_EQUIL',y='P_ESI',color='P_HABITABLE')\nfig4 = px.density_heatmap(df,x='P_SEMI_MAJOR_AXIS_EST',y='S_TYPE_TEMP',z='P_HABITABLE')\n\nfig1.show()\nfig2.show()\nfig3.show()\nfig4.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classification"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns.values.tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"Target = df.P_HABITABLE\nPredictors = df.drop(columns=['P_NAME','P_YEAR','P_DETECTION','S_NAME','S_ALT_NAMES','S_CONSTELLATION','S_CONSTELLATION_ABR',\n                              'S_CONSTELLATION_ENG','P_UPDATED','P_HABITABLE'])\n\nX_tr1, X_tst1, Y_tr1, Y_tst1 = train_test_split(Predictors,Target, random_state=0)\nX_tr2, X_tst2, Y_tr2, Y_tst2 = train_test_split(Predictors,Target, random_state=10)\nX_tr3, X_tst3, Y_tr3, Y_tst3 = train_test_split(Predictors,Target, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decission Tree Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"DTR = DecisionTreeClassifier()\n\nDTR.fit(X_tr1,Y_tr1)\nY_pred1 = DTR.predict(X_tst1)\nDTR.fit(X_tr2,Y_tr2)\nY_pred2 = DTR.predict(X_tst2)\nDTR.fit(X_tr3,Y_tr3)\nY_pred3 = DTR.predict(X_tst3)\n\nconf_mat1 = confusion_matrix(Y_tst1,Y_pred1, normalize='all')\nconf_mat2 = confusion_matrix(Y_tst2,Y_pred2, normalize='all')\nconf_mat3 = confusion_matrix(Y_tst3,Y_pred3, normalize='all')\n\nsns.set_style(style='dark')\nfig, (ax1,ax2,ax3)=plt.subplots(1,3,figsize=(16,4))\nsns.heatmap(ax=ax1, data=conf_mat1, vmin=np.min(conf_mat1.all()),vmax=np.max(conf_mat1), annot=True,annot_kws={\"fontsize\":20},cmap='Spectral')\nax1.set_title('Confusion Matrix 1', fontdict={'fontsize':12}, pad=12)\nsns.heatmap(ax=ax2,data=conf_mat2, vmin=np.min(conf_mat2.all()),vmax=np.max(conf_mat2), annot=True,annot_kws={\"fontsize\":20},cmap='Spectral')\nax2.set_title('Confusion Matrix 2', fontdict={'fontsize':12}, pad=12)\nsns.heatmap(ax=ax3,data=conf_mat3, vmin=np.min(conf_mat3.all()),vmax=np.max(conf_mat3), annot=True,annot_kws={\"fontsize\":20},cmap='Spectral')\nax3.set_title('Confusion Matrix 3', fontdict={'fontsize':12}, pad=12)\n\nerror1= (1-np.diag(conf_mat1).sum())*100\nerror2= (1-np.diag(conf_mat2).sum())*100\nerror3= (1-np.diag(conf_mat3).sum())*100\nmean_error = np.mean([error1,error2,error3])\nprint(\"Errors = ({0:.2f}, {1:.2f}, {2:.2f})%\".format(error1,error2,error3))\nprint(\"Mean Error = {:.2f} %\".format(mean_error))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"RFC = RandomForestClassifier(n_jobs=2)\n\nRFC.fit(X_tr1,Y_tr1)\nY_pred1 = RFC.predict(X_tst1)\nRFC.fit(X_tr2,Y_tr2)\nY_pred2 = RFC.predict(X_tst2)\nRFC.fit(X_tr3,Y_tr3)\nY_pred3 = RFC.predict(X_tst3)\n\nconf_mat1 = confusion_matrix(Y_tst1,Y_pred1, normalize='all')\nconf_mat2 = confusion_matrix(Y_tst2,Y_pred2, normalize='all')\nconf_mat3 = confusion_matrix(Y_tst3,Y_pred3, normalize='all')\n\nsns.set_style(style='dark')\nfig, (ax1,ax2,ax3)=plt.subplots(1,3,figsize=(16,4))\nsns.heatmap(ax=ax1, data=conf_mat1, vmin=np.min(conf_mat1.all()),vmax=np.max(conf_mat1), annot=True,annot_kws={\"fontsize\":20},cmap='Spectral')\nax1.set_title('Confusion Matrix 1', fontdict={'fontsize':12}, pad=12)\nsns.heatmap(ax=ax2,data=conf_mat2, vmin=np.min(conf_mat2.all()),vmax=np.max(conf_mat2), annot=True,annot_kws={\"fontsize\":20},cmap='Spectral')\nax2.set_title('Confusion Matrix 2', fontdict={'fontsize':12}, pad=12)\nsns.heatmap(ax=ax3,data=conf_mat3, vmin=np.min(conf_mat3.all()),vmax=np.max(conf_mat3), annot=True,annot_kws={\"fontsize\":20},cmap='Spectral')\nax3.set_title('Confusion Matrix 3', fontdict={'fontsize':12}, pad=12)\n\nerror1= (1-np.diag(conf_mat1).sum())*100\nerror2= (1-np.diag(conf_mat2).sum())*100\nerror3= (1-np.diag(conf_mat3).sum())*100\nmean_error = np.mean([error1,error2,error3])\nprint(\"Errors = ({0:.2f}, {1:.2f}, {2:.2f})%\".format(error1,error2,error3))\nprint(\"Mean Error = {:.2f} %\".format(mean_error))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## KNN Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"KNNC = KNeighborsClassifier(n_jobs=3)\n\nKNNC.fit(X_tr1,Y_tr1)\nY_pred1 = KNNC.predict(X_tst1)\nKNNC.fit(X_tr2,Y_tr2)\nY_pred2 = KNNC.predict(X_tst2)\nKNNC.fit(X_tr3,Y_tr3)\nY_pred3 = KNNC.predict(X_tst3)\n\nconf_mat1 = confusion_matrix(Y_tst1,Y_pred1, normalize='all')\nconf_mat2 = confusion_matrix(Y_tst2,Y_pred2, normalize='all')\nconf_mat3 = confusion_matrix(Y_tst3,Y_pred3, normalize='all')\n\nsns.set_style(style='dark')\nfig, (ax1,ax2,ax3)=plt.subplots(1,3,figsize=(16,4))\nsns.heatmap(ax=ax1, data=conf_mat1, vmin=np.min(conf_mat1.all()),vmax=np.max(conf_mat1), annot=True,annot_kws={\"fontsize\":20},cmap='Spectral')\nax1.set_title('Confusion Matrix 1', fontdict={'fontsize':12}, pad=12)\nsns.heatmap(ax=ax2,data=conf_mat2, vmin=np.min(conf_mat2.all()),vmax=np.max(conf_mat2), annot=True,annot_kws={\"fontsize\":20},cmap='Spectral')\nax2.set_title('Confusion Matrix 2', fontdict={'fontsize':12}, pad=12)\nsns.heatmap(ax=ax3,data=conf_mat3, vmin=np.min(conf_mat3.all()),vmax=np.max(conf_mat3), annot=True,annot_kws={\"fontsize\":20},cmap='Spectral')\nax3.set_title('Confusion Matrix 3', fontdict={'fontsize':12}, pad=12)\n\nerror1= (1-np.diag(conf_mat1).sum())*100\nerror2= (1-np.diag(conf_mat2).sum())*100\nerror3= (1-np.diag(conf_mat3).sum())*100\nmean_error = np.mean([error1,error2,error3])\nprint(\"Errors = ({0:.2f}, {1:.2f}, {2:.2f})%\".format(error1,error2,error3))\nprint(\"Mean Error = {:.2f} %\".format(mean_error))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Support Vector Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"SVCC = SVC(kernel='linear',C=100)\n\nSVCC.fit(X_tr1,Y_tr1)\nY_pred1 = SVCC.predict(X_tst1)\nSVCC.fit(X_tr2,Y_tr2)\nY_pred2 = SVCC.predict(X_tst2)\nSVCC.fit(X_tr3,Y_tr3)\nY_pred3 = SVCC.predict(X_tst3)\n\nconf_mat1 = confusion_matrix(Y_tst1,Y_pred1, normalize='all')\nconf_mat2 = confusion_matrix(Y_tst2,Y_pred2, normalize='all')\nconf_mat3 = confusion_matrix(Y_tst3,Y_pred3, normalize='all')\n\nsns.set_style(style='dark')\nfig, (ax1,ax2,ax3)=plt.subplots(1,3,figsize=(16,4))\nsns.heatmap(ax=ax1, data=conf_mat1, vmin=np.min(conf_mat1.all()),vmax=np.max(conf_mat1), annot=True,annot_kws={\"fontsize\":20},cmap='Spectral')\nax1.set_title('Confusion Matrix 1', fontdict={'fontsize':12}, pad=12)\nsns.heatmap(ax=ax2,data=conf_mat2, vmin=np.min(conf_mat2.all()),vmax=np.max(conf_mat2), annot=True,annot_kws={\"fontsize\":20},cmap='Spectral')\nax2.set_title('Confusion Matrix 2', fontdict={'fontsize':12}, pad=12)\nsns.heatmap(ax=ax3,data=conf_mat3, vmin=np.min(conf_mat3.all()),vmax=np.max(conf_mat3), annot=True,annot_kws={\"fontsize\":20},cmap='Spectral')\nax3.set_title('Confusion Matrix 3', fontdict={'fontsize':12}, pad=12)\n\nerror1= (1-np.diag(conf_mat1).sum())*100\nerror2= (1-np.diag(conf_mat2).sum())*100\nerror3= (1-np.diag(conf_mat3).sum())*100\nmean_error = np.mean([error1,error2,error3])\nprint(\"Errors = ({0:.2f}, {1:.2f}, {2:.2f})%\".format(error1,error2,error3))\nprint(\"Mean Error = {:.2f} %\".format(mean_error))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Methods and errors given:\n* Random Forest Classifier: 0.12 % error\n* Support Vector Classifier: 0.20 % error\n* Decission Tree Classifier: 0.28 % error\n* K Nearest Neighbours Classifier: 0.88 % error"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}