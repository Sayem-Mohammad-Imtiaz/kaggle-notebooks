{"cells":[{"metadata":{},"cell_type":"markdown","source":"This [dataset](https://www.kaggle.com/rushikeshlavate/mncs-stock-dataset-for-the-last-20-years) contains 20 years of various MNC's stocks now you need to predict the stock price for the next 30 days.\n\nYou can play with this dataset as you wish and create a notebook to better understand your performance to others and if you are wrong you can correct yourself"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". format(sys.version))\nimport numpy as np # linear algebra\nprint(\"NumPy version: {}\". format(np.__version__))\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nprint(\"pandas version: {}\". format(pd.__version__))\nimport matplotlib # collection of functions for scientific and publication-ready visualization\nprint(\"matplotlib version: {}\". format(matplotlib.__version__))\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport sklearn\nfrom sklearn.linear_model import LinearRegression\nimport warnings # ignore warnings\nwarnings.filterwarnings('ignore')\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/mncs-stock-dataset-for-the-last-20-years/Facebook Inc.stock.csv')\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df.shape[0]\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Variable transformation is a way to make the data work better in your model. Compare before and after.\ndf['Close'] = np.log(df['Close'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\nX = df.index.values\ny = df['Close']\nslope, intercept, r, p, std_err = stats.linregress(X, y) # scipy\ndef modelPrediction(x):\n  return slope * x + intercept\nlabel = 'Predict the price of stocks for the next 30 days'\nmodel = list(map(modelPrediction, X)) # scipy\nx_pred = x + 30\ny_pred = modelPrediction(x_pred)\nprint(label)\nap_organic_chi = round(y_pred, 2)\nprint('${} USD'.format(y_pred))\nplt.scatter(X, y) # Scatter Plot\nplt.plot(X, model, color='red')\n# plt.ylim(ymin=0) # starts at zero\nplt.legend(['Predict the price of stocks for the next 30 days'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Linear Regression](https://towardsdatascience.com/a-summary-of-the-basic-machine-learning-models-e0a65627ecbe) tends to be the Machine Learning algorithm that all teachers explain first, most books start with, and most people end up learning to start their career with.\n\nIt is a very simple algorithm that takes a vector of features (the variables or characteristics of our data) as an input, and gives out a numeric, continuous output.\n\nAs its name and the previous explanation outline, it is a regression algorithm, and the main member and father of the family of linear algorithms where Generalised Linear Models (GLMs) come from.\n\nIt can be trained using a closed form solution, or, as it is normally done in the Machine Learning world, using an iterative optimisation algorithm like Gradient Descent.\n\nLinear Regression is a parametric machine learning model (with a fixed number of parameters that depend on the nº of features of our data and that trains quite quickly) that works well for data that is linearly correlated with our target variable (the continuous numeric feature that we want to later predict), that is very intuitive to learn, and easy to explain.\n\nIt is what we call an ‘explainable AI model’, as the predictions it makes are very easy to explain knowing the model weights.\n\nAn example of a Linear Regression model could be a model that predicts house prices taking into account the characteristics of each home like the surface area, location, number of rooms, or if it has an elevator or not.\n\nThe following figure shows how Linear Regression would predict the price of a certain house using only 1 feature:\n\nThe surface area in squared meters of the house.\n\nIn the case of more variables being included in our model, the X axis would reflect a weighted linear combination of these features.\n\nThe line from the previous figure would have been fit in the training process using an optimisation algorithm, like gradient descent, that iteratively changes the slope of the line until the best possible line for our task is obtained."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}