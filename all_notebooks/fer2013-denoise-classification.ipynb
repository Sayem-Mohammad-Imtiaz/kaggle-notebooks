{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"* Image denoising is to remove noise from a noisy image, so as to restore the true image\n* In this notebook FER2013 dataset is used which contains approx 35 thousand images of 7 different emotions\n* Image is grayscale of size 48*48","metadata":{}},{"cell_type":"markdown","source":"# Importing libraries","metadata":{}},{"cell_type":"code","source":"from keras.datasets import fashion_mnist, mnist\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Dropout\nfrom keras.models import Model\n\nimport os,cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 20, 10\n\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd# Any results you write to the current directory are saved as output.\nfrom IPython.display import display, Image\n\nfrom keras.preprocessing.image import load_img\nfrom keras import Model\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.models import load_model\nfrom keras.optimizers import Adam\nfrom keras.utils.vis_utils import plot_model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout, BatchNormalization\nfrom keras.optimizers import SGD,RMSprop,adam\n\n# Any results you write to the current directory are saved as output.\nfrom IPython.display import display, Image\n\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-16T13:51:13.364449Z","iopub.execute_input":"2021-06-16T13:51:13.366476Z","iopub.status.idle":"2021-06-16T13:51:15.360365Z","shell.execute_reply.started":"2021-06-16T13:51:13.364854Z","shell.execute_reply":"2021-06-16T13:51:15.359453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extract data from CSV","metadata":{}},{"cell_type":"code","source":"# get the data\nfilname = '../input/facial-expression/fer2013/fer2013.csv'\n\n#different labels of images(not useful known about for current problem)\nlabel_map = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n\n#different features names\nnames=['emotion','pixels','usage']\n\n#Reading data in dataframe\ndf=pd.read_csv('../input/facial-expression/fer2013/fer2013.csv',names=names, na_filter=False)\nim=df['pixels']\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T13:51:15.364063Z","iopub.execute_input":"2021-06-16T13:51:15.364396Z","iopub.status.idle":"2021-06-16T13:51:17.633996Z","shell.execute_reply.started":"2021-06-16T13:51:15.36435Z","shell.execute_reply":"2021-06-16T13:51:17.633135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Adding labels and images(pixel values) in respective array","metadata":{}},{"cell_type":"code","source":"#reading data and labels from dataset and appending in list\n\ndef getData(filname):\n    # images are 48x48\n    # N = 35887\n    Y = []\n    X = []\n    first = True\n    for line in open(filname):\n        if first:\n            first = False\n        else:\n            row = line.split(',')\n            Y.append(int(row[0]))\n            X.append([int(p) for p in row[1].split()])\n\n    X, Y = np.array(X), np.array(Y)\n    return X, Y","metadata":{"execution":{"iopub.status.busy":"2021-06-16T13:51:17.635374Z","iopub.execute_input":"2021-06-16T13:51:17.635727Z","iopub.status.idle":"2021-06-16T13:51:17.643568Z","shell.execute_reply.started":"2021-06-16T13:51:17.635676Z","shell.execute_reply":"2021-06-16T13:51:17.642607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#extracting data from dataset\nX, Y = getData(filname)\nnum_class = len(set(Y))\n#print(num_class)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T13:51:17.645033Z","iopub.execute_input":"2021-06-16T13:51:17.645673Z","iopub.status.idle":"2021-06-16T13:51:51.189773Z","shell.execute_reply.started":"2021-06-16T13:51:17.645615Z","shell.execute_reply":"2021-06-16T13:51:51.188898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reshaping images","metadata":{}},{"cell_type":"code","source":"# keras with tensorflow backend\nN, D = X.shape\n\n#reshaping the dataset\nX = X.reshape(N, 48, 48, 1)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T13:51:51.193348Z","iopub.execute_input":"2021-06-16T13:51:51.193932Z","iopub.status.idle":"2021-06-16T13:51:51.19881Z","shell.execute_reply.started":"2021-06-16T13:51:51.193878Z","shell.execute_reply":"2021-06-16T13:51:51.197697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_gaussain = X\nX_poission = X\nX_saltpepper = X","metadata":{"execution":{"iopub.status.busy":"2021-06-16T13:51:51.20216Z","iopub.execute_input":"2021-06-16T13:51:51.202658Z","iopub.status.idle":"2021-06-16T13:51:51.210347Z","shell.execute_reply.started":"2021-06-16T13:51:51.202496Z","shell.execute_reply":"2021-06-16T13:51:51.209292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"#adding noise in data\nnoise_factor = 0.1","metadata":{"execution":{"iopub.status.busy":"2021-06-16T13:51:51.211791Z","iopub.execute_input":"2021-06-16T13:51:51.212358Z","iopub.status.idle":"2021-06-16T13:51:51.220809Z","shell.execute_reply.started":"2021-06-16T13:51:51.212133Z","shell.execute_reply":"2021-06-16T13:51:51.219934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Gaussian Noise","metadata":{}},{"cell_type":"code","source":"#NOrmalizing the images\nX_gaussain = X_gaussain.astype('float32') / 255.\n\n#reshaping the images\nX_gaussain = np.reshape(X_gaussain, (len(X_gaussain), 48, 48, 1))  # adapt this if using `channels_first` image data format\n\nfrom skimage.util import random_noise\n\nX_gaussain_noisy = X_gaussain + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_gaussain.shape)\n\n#clipping put data near to 0--->0 aand data near to 1-->1(eg=0.3-->0 or 0.7-->1)\nX_gaussain_noisy = np.clip(X_gaussain_noisy, 0., 1.)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-06-16T13:51:51.222599Z","iopub.execute_input":"2021-06-16T13:51:51.22318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Poission Noise ","metadata":{}},{"cell_type":"code","source":"#NOrmalizing the images\nX_poission = X_poission.astype('float32') / 255.\n\n#reshaping the images\nX_poission = np.reshape(X_poission, (len(X_gaussain), 48, 48, 1))  # adapt this if using `channels_first` image data format\n\nfrom skimage.util import random_noise\n\nX_poission_noisy = X_poission + noise_factor * np.random.poisson(lam=(0,1), size=X_poission.shape) \n\n#clipping put data near to 0--->0 aand data near to 1-->1(eg=0.3-->0 or 0.7-->1)\nX_poission_noisy = np.clip(X_poission_noisy, 0., 1.)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Salt_Pepper Noise ","metadata":{}},{"cell_type":"code","source":"#NOrmalizing the images\nX_saltpepper = X_saltpepper.astype('float32') / 255.\n\n#reshaping the images\nX_saltpepper = np.reshape(X_saltpepper, (len(X_saltpepper), 48, 48, 1))  # adapt this if using `channels_first` image data format\n\n\nfrom skimage.util import random_noise\n\n#noisy = random_noise(img, mode=\"poisson\")\n#just change the mode pf the noise to-->'gaussain', \nX_saltpepper_noisy = random_noise(X_saltpepper, mode=\"s&p\",clip=True, amount=noise_factor)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Adding noise images and also creating their labels","metadata":{}},{"cell_type":"markdown","source":"1. gaussain-->0\n1. poission-->1\n1. saltpepper-->2","metadata":{}},{"cell_type":"code","source":"Y_gaussain_noisy = np.zeros(X_gaussain_noisy.shape[0])\nY_poission_noisy = np.ones(X_poission_noisy.shape[0])\nY_saltpepper_noisy = np.ones(X_saltpepper_noisy.shape[0])*2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Adding whole dataset together","metadata":{}},{"cell_type":"code","source":"X_final = np.concatenate((X_gaussain_noisy, X_poission_noisy, X_saltpepper_noisy))\nY_final = np.concatenate((Y_gaussain_noisy, Y_poission_noisy, Y_saltpepper_noisy))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_final.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extracting Data and splitting train and test","metadata":{}},{"cell_type":"code","source":"from keras.utils import to_categorical\nY_final = to_categorical(Y_final)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#splitting data in train, test\nx_train, x_test, y_train, y_test = train_test_split(X_final, Y_final, test_size=0.2, random_state=42, shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Taking 500 images seperate for final testing","metadata":{}},{"cell_type":"code","source":"x_test_final = x_test[-500:]\ny_test_final = y_test[-500:]\n\nx_test = x_test[:-500]\ny_test = y_test[:-500]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization of 10 Data","metadata":{}},{"cell_type":"code","source":"n = 10","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(48, 48))\nfor i in range(n):\n    ax = plt.subplot(1, n, i+1)\n    plt.imshow(x_train[i].reshape(48, 48))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Construction of Model","metadata":{}},{"cell_type":"code","source":"def create_model():\n    input_shape=(48,48,1)\n\n    model = Sequential()\n    model.add(Conv2D(6, (5, 5), input_shape=input_shape, padding='same', activation = 'relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(16, (5, 5), padding='same', activation = 'relu'))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(64, (3, 3), activation = 'relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Flatten())\n    model.add(Dense(128, activation = 'relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(3, activation = 'softmax'))\n\n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='Adam')\n    \n    return model\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_model()\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import callbacks\nfile_path = \"weights_best_.h5\"\ncheckpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=0, save_best_only=True, mode='min')\nearly = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=3)\ncallbacks_list = [checkpoint, early]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BS = 64 \nEPOCHS = 20","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    x_train, y_train, \n    validation_data=(x_test, y_test),\n    epochs=EPOCHS, verbose=1,\n    callbacks = callbacks_list \n    ,shuffle = True\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Visualization","metadata":{}},{"cell_type":"code","source":"from keras.utils import plot_model\n\nplot_model(model, \"my_first_model.png\", show_shapes=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing Train,Test--->Accuracy,Loss","metadata":{}},{"cell_type":"code","source":"# visualizing losses and accuracy\n%matplotlib inline\n\ntrain_loss=history.history['loss']\nval_loss=history.history['val_loss']\ntrain_acc=history.history['accuracy']\nval_acc=history.history['val_accuracy']\n\nepochs = range(len(train_acc))\n\nplt.plot(epochs,train_loss,'r-o', label='train_loss')\nplt.plot(epochs,val_loss,'b-o', label='val_loss')\nplt.title('Training loss vs Validation loss')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs,train_acc,'r-o', label='train_acc')\nplt.plot(epochs,val_acc,'b-o', label='val_acc')\nplt.title('Train Accuracy vs Validation Accuracy')\nplt.legend()\nplt.figure()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving Model","metadata":{}},{"cell_type":"code","source":"#Model Save\nmodel.save_weights('model_weights.h5')\nmodel.save('model_keras.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Confusion Matrix","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nresults = model.predict_classes(x_test_final)\n\ncm = confusion_matrix(np.where(y_test_final == 1)[1], results)\ncm = cm.astype(np.float) / cm.sum(axis=1)[:, np.newaxis]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport pandas as pd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label = ['Gaussian', 'Poission', 'Salt&Pepper']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Transform to df for easier plotting\ncm_df = pd.DataFrame(cm, index = label,\n                     columns = label\n                    )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (5,5))\nsns.heatmap(cm_df, annot = True,cmap='Greys',cbar=False,linewidth=2)\nplt.title('Noise Classify')\nplt.ylabel('True class')\nplt.xlabel('Prediction class')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating model","metadata":{}},{"cell_type":"code","source":"y_true = np.argmax(y_test_final, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_true, results)\n\nprint(\"Accuracy \",accuracy*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing output","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(48, 48))\nfor i in range(3,8):\n    ax = plt.subplot(1, n, i+1)\n    plt.imshow(x_test_final[i].reshape(48, 48))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y__true = np.argmax(y_test_final[3:8], axis=1)\n\nprint(\"True Label: \", y__true)\nprint(\"Predicted label: \", results[3:8])","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}