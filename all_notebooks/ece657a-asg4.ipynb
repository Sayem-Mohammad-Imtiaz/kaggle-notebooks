{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Assignment 4 - Coronavirus\n\nCreated by _Waterloo Warriors_\n\nMohammad Dib\n\nDaniel Weber"},{"metadata":{},"cell_type":"markdown","source":"This kernel is created to face some of the current challenges about the Coronavirus related to time series data and machine learning. It provides some basic visualizations and compares different deep learning approaches to predict the confirmed cases caused by COVID-19. In detail, Long Short Term Memory (LSTM) and Gated Recurrent Unit (GRU) models are considered."},{"metadata":{},"cell_type":"markdown","source":"## Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n# Visualization\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Configure visualisations\n%matplotlib inline\nmpl.style.use( 'ggplot' )\nplt.style.use('fivethirtyeight')\nsns.set(context=\"notebook\", palette=\"dark\", style = 'whitegrid' , color_codes=True)\n\n# Prediction tasks\nimport datetime\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\nfrom keras.optimizers import SGD\nimport math\nfrom sklearn.metrics import mean_squared_error\nfrom keras.preprocessing.sequence import TimeseriesGenerator\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data import"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Global confirmed cases\nconfirmed_file = \"/kaggle/input/ece657aw20asg4coronavirus/time_series_covid19_confirmed_global.csv\"\nconfirmed = pd.read_csv(confirmed_file)\n\n# Global deaths\ndeaths_file = \"../input/ece657aw20asg4coronavirus/time_series_covid19_deaths_global.csv\"\ndeaths = pd.read_csv(deaths_file)\n\n# Global recovered\nrecovered_file = \"../input/ece657aw20asg4coronavirus/time_series_covid19_recovered_global.csv\"\nrecovered = pd.read_csv(recovered_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmed.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"deaths.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recovered.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Some visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Some functions to help out with\ndef plot_predictions(test,predicted):\n    plt.plot(test, color='red',label='Real Confirmed')\n    plt.plot(predicted, color='blue',label='Predicted Confirmed')\n    plt.title('Confirmed Cases')\n    plt.xlabel('Time')\n    plt.ylabel('Confirmed Cases')\n    plt.legend()\n    plt.show()\n\ndef return_rmse(test,predicted):\n    rmse = math.sqrt(mean_squared_error(test, predicted))\n    print(\"The root mean squared error is {}.\".format(rmse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"countries=['Brazil', 'Canada', 'Germany']\ny = confirmed.loc[confirmed['Country/Region']=='Italy'].iloc[0,4:]\ns = pd.DataFrame({'Italy':y})\nfor c in countries:    \n    #pyplot.plot(range(y.shape[0]),y,'r--')\n    s[c] = confirmed.loc[confirmed['Country/Region']==c].iloc[0,4:]\n#pyplot.plot(range(y.shape[0]),y,'g-')\ns.plot.line()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country = 'Italy'\ny1 = confirmed.loc[confirmed['Country/Region']==country].iloc[0,4:]\ny2 = deaths.loc[confirmed['Country/Region']==country].iloc[0,4:]\ny3 = recovered.loc[confirmed['Country/Region']==country].iloc[0,4:]\n\ndf = pd.DataFrame({'Confirmed':y1, 'Deaths':y2, 'Recovered':y3})\ndf.plot.line()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predictions of confirmed cases using LSTM\n\nAccording to https://www.kaggle.com/thebrownviking20/intro-to-recurrent-neural-networks-lstm-gru, https://www.kaggle.com/vanshjatana/machine-learning-on-coronavirus and https://www.kaggle.com/azizovitic/sarima-lstm-for-novel-corona-virus-2019-dataset\n\n### Confirmed Cases in Italy"},{"metadata":{"trusted":true},"cell_type":"code","source":"# choose country and build data\ncountry = 'Italy'\n\ndata = confirmed.loc[confirmed['Country/Region']==country].iloc[0,4:]\ndti = pd.date_range('2020-01-22', periods=data.shape[0], freq='D')\ndata = pd.DataFrame(data=data.values,columns=['Confirmed'],index=dti)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There will always be a number of 5 days to be predicted."},{"metadata":{"trusted":true},"cell_type":"code","source":"# do train/test split\nn_days_toPredict = 5\n\ntrain_data = data[:len(data)-n_days_toPredict]\ntest_data = data[len(data)-n_days_toPredict:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot train/test data\ndata['Confirmed'][:train_data.index[-1]].plot(figsize=(16,4),legend=True)\ndata['Confirmed'][train_data.index[-1]:].plot(figsize=(16,4),legend=True)\nplt.legend(['Training set','Test set'])\nplt.title('Confirmed Cases')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LSTM architechture\n\nscaler = MinMaxScaler()\nscaler.fit(train_data)\nscaled_train_data = scaler.transform(train_data)\nscaled_test_data = scaler.transform(test_data)\nn_input = 7\nn_features = 1\n                             \ngenerator = TimeseriesGenerator(scaled_train_data,scaled_train_data, length=n_input, batch_size=1)\n\nlstm_model = Sequential()\nlstm_model.add(LSTM(units = 50, return_sequences = True, input_shape = (n_input, n_features)))\nlstm_model.add(Dropout(0.2))\nlstm_model.add(LSTM(units = 50, return_sequences = True))\nlstm_model.add(Dropout(0.2))\nlstm_model.add(LSTM(units = 50))\nlstm_model.add(Dropout(0.2))\nlstm_model.add(Dense(units = 1))\nlstm_model.compile(optimizer = 'adam', loss = 'mean_squared_error')\nlstm_model.fit(generator, epochs = 30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot loss \nlosses_lstm = lstm_model.history.history['loss']\nplt.figure(figsize = (30,4))\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.xticks(np.arange(0,100,1))\nplt.plot(range(len(losses_lstm)), losses_lstm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# do predictions \nlstm_predictions_scaled = []\n\nbatch = scaled_train_data[-n_input:]\ncurrent_batch = batch.reshape((1, n_input, n_features))\n\nfor i in range(len(test_data)):   \n    lstm_pred = lstm_model.predict(current_batch)[0]\n    lstm_predictions_scaled.append(lstm_pred) \n    current_batch = np.append(current_batch[:,1:,:],[[lstm_pred]],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transform predictions\nprediction = pd.DataFrame(scaler.inverse_transform(lstm_predictions_scaled),columns=['PREDICTED Confirmed'],index=test_data.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"return_rmse(test_data,prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_predictions(test_data,prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train_data, label='Historical Confirmed')\nplt.plot(prediction, label='Predicted Confirmed')\nplt.plot(test_data, label='Actual Confirmed')\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Global Confirmed Cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"global_cases = confirmed.iloc[:,4:].sum(axis=0)\ndti = pd.date_range('2020-01-22', periods=data.shape[0], freq='D')\ndata2 = pd.DataFrame(data=global_cases.values,columns=['Confirmed'],index=dti)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# do train/test split\nn_days_toPredict = 5\n\ntrain_dataG = data2[:len(data2)-n_days_toPredict]\ntest_dataG = data2[len(data2)-n_days_toPredict:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot train/test data\ndata2['Confirmed'][:train_dataG.index[-1]].plot(figsize=(16,4),legend=True)\ndata2['Confirmed'][train_dataG.index[-1]:].plot(figsize=(16,4),legend=True)\nplt.legend(['Training set','Test set'])\nplt.title('Confirmed Cases')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LSTM architechture\n\nscaler = MinMaxScaler()\nscaler.fit(train_dataG)\nscaled_train_dataG = scaler.transform(train_dataG)\nscaled_test_dataG = scaler.transform(test_dataG)\nn_input = 7\nn_features = 1\n                             \ngenerator = TimeseriesGenerator(scaled_train_dataG,scaled_train_dataG, length=n_input, batch_size=1)\n\nlstm_model = Sequential()\nlstm_model.add(LSTM(units = 50, return_sequences = True, input_shape = (n_input, n_features)))\nlstm_model.add(Dropout(0.2))\nlstm_model.add(LSTM(units = 50, return_sequences = True))\nlstm_model.add(Dropout(0.2))\nlstm_model.add(LSTM(units = 50))\nlstm_model.add(Dropout(0.2))\nlstm_model.add(Dense(units = 1))\nlstm_model.compile(optimizer = 'adam', loss = 'mean_squared_error')\nlstm_model.fit(generator, epochs = 30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot loss \nlosses_lstm = lstm_model.history.history['loss']\nplt.figure(figsize = (30,4))\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.xticks(np.arange(0,100,1))\nplt.plot(range(len(losses_lstm)), losses_lstm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# do predictions \nlstm_predictions_scaledG = []\n\nbatch = scaled_train_dataG[-n_input:]\ncurrent_batch = batch.reshape((1, n_input, n_features))\n\nfor i in range(len(test_dataG)):   \n    lstm_pred = lstm_model.predict(current_batch)[0]\n    lstm_predictions_scaledG.append(lstm_pred) \n    current_batch = np.append(current_batch[:,1:,:],[[lstm_pred]],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transform predictions\nprediction_global = pd.DataFrame(scaler.inverse_transform(lstm_predictions_scaledG),columns=['PREDICTED Confirmed'],index=test_dataG.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"return_rmse(test_dataG,prediction_global)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_predictions(test_dataG,prediction_global)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train_dataG, label='Historical Confirmed')\nplt.plot(prediction_global, label='Predicted Confirmed')\nplt.plot(test_dataG, label='Actual Confirmed')\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The LSTM model can achieve reasonable accuracy, but differs significantly between several runs. It tends to show a more flattening effect than the actual development. Also, the global data tends to perform better on several runs."},{"metadata":{},"cell_type":"markdown","source":"### Using the whole dataset and doing the forecast for global cases\n\n**CAUTION:** Update daterange index for predicitons, if data is updated before."},{"metadata":{"trusted":true},"cell_type":"code","source":"# forecast length\nforecast_length = 5\n\ntrain_data_forecast = data2\n\n# LSTM architechture\n\nscaler = MinMaxScaler()\nscaler.fit(train_data_forecast)\nscaled_train_data_forecast = scaler.transform(train_data_forecast)\nn_input = 7\nn_features = 1\n                             \ngenerator = TimeseriesGenerator(scaled_train_data_forecast,scaled_train_data_forecast, length=n_input, batch_size=1)\n\nlstm_model = Sequential()\nlstm_model.add(LSTM(units = 50, return_sequences = True, input_shape = (n_input, n_features)))\nlstm_model.add(Dropout(0.2))\nlstm_model.add(LSTM(units = 50, return_sequences = True))\nlstm_model.add(Dropout(0.2))\nlstm_model.add(LSTM(units = 50))\nlstm_model.add(Dropout(0.2))\nlstm_model.add(Dense(units = 1))\nlstm_model.compile(optimizer = 'adam', loss = 'mean_squared_error')\nlstm_model.fit(generator, epochs = 30)\n\n# predictions\n\nlstm_predictions_scaled_forecast = []\n\nbatch = scaled_train_data_forecast[-n_input:]\ncurrent_batch = batch.reshape((1, n_input, n_features))\n\nfor i in range(forecast_length):   \n    lstm_pred = lstm_model.predict(current_batch)[0]\n    lstm_predictions_scaled_forecast.append(lstm_pred) \n    current_batch = np.append(current_batch[:,1:,:],[[lstm_pred]],axis=1)\n    \nprediction_forecast = pd.DataFrame(scaler.inverse_transform(lstm_predictions_scaled_forecast),columns=['PREDICTED Confirmed'],index=pd.date_range('2020-04-18', periods=forecast_length, freq='D'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train_data_forecast, label='Historical Confirmed')\nplt.plot(prediction_forecast, label='Predicted Confirmed')\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predictions of confirmed cases using GRU\n"},{"metadata":{},"cell_type":"markdown","source":"### Italy"},{"metadata":{"trusted":true},"cell_type":"code","source":"# choose country and build data\ncountry = 'Italy'\n\ndata = confirmed.loc[confirmed['Country/Region']==country].iloc[0,4:]\ndti = pd.date_range('2020-01-22', periods=data.shape[0], freq='D')\ndata = pd.DataFrame(data=data.values,columns=['Confirmed'],index=dti)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There will always be a number of 5 days to be predicted."},{"metadata":{"trusted":true},"cell_type":"code","source":"# do train/test split\nn_days_toPredict = 5\n\ntrain_data = data[:len(data)-n_days_toPredict]\ntest_data = data[len(data)-n_days_toPredict:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot train/test data\ndata['Confirmed'][:train_data.index[-1]].plot(figsize=(16,4),legend=True)\ndata['Confirmed'][train_data.index[-1]:].plot(figsize=(16,4),legend=True)\nplt.legend(['Training set','Test set'])\nplt.title('Confirmed Cases')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GRU architechture\n\nscaler = MinMaxScaler()\nscaler.fit(train_data)\nscaled_train_data = scaler.transform(train_data)\nscaled_test_data = scaler.transform(test_data)\nn_input = 7\nn_features = 1\n                             \ngenerator = TimeseriesGenerator(scaled_train_data,scaled_train_data, length=n_input, batch_size=1)\n\ngru_model = Sequential()\ngru_model.add(GRU(units = 50, return_sequences = True, input_shape = (n_input, n_features)))\ngru_model.add(Dropout(0.2))\ngru_model.add(GRU(units = 50, return_sequences = True))\ngru_model.add(Dropout(0.2))\ngru_model.add(GRU(units = 50))\ngru_model.add(Dropout(0.2))\ngru_model.add(Dense(units = 1))\ngru_model.compile(optimizer = 'adam', loss = 'mean_squared_error')\ngru_model.fit(generator, epochs = 30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot loss \nlosses_gru = gru_model.history.history['loss']\nplt.figure(figsize = (30,4))\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.xticks(np.arange(0,100,1))\nplt.plot(range(len(losses_gru)), losses_gru)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# do predictions \ngru_predictions_scaled = []\n\nbatch = scaled_train_data[-n_input:]\ncurrent_batch = batch.reshape((1, n_input, n_features))\n\nfor i in range(len(test_data)):   \n    gru_pred = gru_model.predict(current_batch)[0]\n    gru_predictions_scaled.append(gru_pred) \n    current_batch = np.append(current_batch[:,1:,:],[[gru_pred]],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transform predictions\nprediction_gru = pd.DataFrame(scaler.inverse_transform(gru_predictions_scaled),columns=['PREDICTED Confirmed'],index=test_data.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"return_rmse(test_data,prediction_gru)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_predictions(test_data,prediction_gru)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train_data, label='Historical Confirmed')\nplt.plot(prediction_gru, label='Predicted Confirmed')\nplt.plot(test_data, label='Actual Confirmed')\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Global Confirmed Cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"global_cases = confirmed.iloc[:,4:].sum(axis=0)\ndti = pd.date_range('2020-01-22', periods=data.shape[0], freq='D')\ndata2 = pd.DataFrame(data=global_cases.values,columns=['Confirmed'],index=dti)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# do train/test split\nn_days_toPredict = 5\n\ntrain_dataG = data2[:len(data2)-n_days_toPredict]\ntest_dataG = data2[len(data2)-n_days_toPredict:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot train/test data\ndata2['Confirmed'][:train_dataG.index[-1]].plot(figsize=(16,4),legend=True)\ndata2['Confirmed'][train_dataG.index[-1]:].plot(figsize=(16,4),legend=True)\nplt.legend(['Training set','Test set'])\nplt.title('Confirmed Cases')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GRU architechture\n\nscaler = MinMaxScaler()\nscaler.fit(train_dataG)\nscaled_train_dataG = scaler.transform(train_dataG)\nscaled_test_dataG = scaler.transform(test_dataG)\nn_input = 7\nn_features = 1\n                             \ngenerator = TimeseriesGenerator(scaled_train_dataG,scaled_train_dataG, length=n_input, batch_size=1)\n\ngru_model = Sequential()\ngru_model.add(GRU(units = 50, return_sequences = True, input_shape = (n_input, n_features)))\ngru_model.add(Dropout(0.2))\ngru_model.add(GRU(units = 50, return_sequences = True))\ngru_model.add(Dropout(0.2))\ngru_model.add(GRU(units = 50))\ngru_model.add(Dropout(0.2))\ngru_model.add(Dense(units = 1))\ngru_model.compile(optimizer = 'adam', loss = 'mean_squared_error')\ngru_model.fit(generator, epochs = 30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot loss \nlosses_gru = gru_model.history.history['loss']\nplt.figure(figsize = (30,4))\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.xticks(np.arange(0,100,1))\nplt.plot(range(len(losses_gru)), losses_gru)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# do predictions \ngru_predictions_scaledG = []\n\nbatch = scaled_train_dataG[-n_input:]\ncurrent_batch = batch.reshape((1, n_input, n_features))\n\nfor i in range(len(test_dataG)):   \n    gru_pred = gru_model.predict(current_batch)[0]\n    gru_predictions_scaledG.append(gru_pred) \n    current_batch = np.append(current_batch[:,1:,:],[[gru_pred]],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transform predictions\nprediction_global_gru = pd.DataFrame(scaler.inverse_transform(gru_predictions_scaledG),columns=['PREDICTED Confirmed'],index=test_dataG.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"return_rmse(test_dataG,prediction_global_gru)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_predictions(test_dataG,prediction_global_gru)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train_dataG, label='Historical Confirmed')\nplt.plot(prediction_global_gru, label='Predicted Confirmed')\nplt.plot(test_dataG, label='Actual Confirmed')\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The GRU model achieved high accuracy, also the global data performed better."},{"metadata":{},"cell_type":"markdown","source":"## Using the whole dataset and doing the forecast for global cases\n\n**CAUTION:** Update daterange index for predicitons, if data is updated before."},{"metadata":{"trusted":true},"cell_type":"code","source":"# forecast length\nforecast_length = 5\n\ntrain_data_forecast = data2\n\n# GRU architechture\n\nscaler = MinMaxScaler()\nscaler.fit(train_data_forecast)\nscaled_train_data_forecast = scaler.transform(train_data_forecast)\nn_input = 7\nn_features = 1\n                             \ngenerator = TimeseriesGenerator(scaled_train_data_forecast,scaled_train_data_forecast, length=n_input, batch_size=1)\n\ngru_model = Sequential()\ngru_model.add(GRU(units = 50, return_sequences = True, input_shape = (n_input, n_features)))\ngru_model.add(Dropout(0.2))\ngru_model.add(GRU(units = 50, return_sequences = True))\ngru_model.add(Dropout(0.2))\ngru_model.add(GRU(units = 50))\ngru_model.add(Dropout(0.2))\ngru_model.add(Dense(units = 1))\ngru_model.compile(optimizer = 'adam', loss = 'mean_squared_error')\ngru_model.fit(generator, epochs = 30)\n\n# predictions\n\ngru_predictions_scaled_forecast = []\n\nbatch = scaled_train_data_forecast[-n_input:]\ncurrent_batch = batch.reshape((1, n_input, n_features))\n\nfor i in range(forecast_length):   \n    gru_pred = gru_model.predict(current_batch)[0]\n    gru_predictions_scaled_forecast.append(gru_pred) \n    current_batch = np.append(current_batch[:,1:,:],[[gru_pred]],axis=1)\n    \nprediction_forecast_gru = pd.DataFrame(scaler.inverse_transform(gru_predictions_scaled_forecast),columns=['PREDICTED Confirmed'],index=pd.date_range('2020-04-18', periods=forecast_length, freq='D'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train_data_forecast, label='Historical Confirmed')\nplt.plot(prediction_forecast_gru, label='Predicted Confirmed')\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Comparison"},{"metadata":{},"cell_type":"markdown","source":"### Visual Comparison"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Italy\nplt.plot(train_data['2020-03-22':], label='Historical Confirmed')\nplt.plot(prediction, label='Predicted Confirmed by LSTM')\nplt.plot(prediction_gru, label='Predicted Confirmed by GRU')\nplt.plot(test_data, label='Actual Confirmed')\nplt.title(\"Italy\")\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# global\nplt.plot(train_dataG['2020-03-22':], label='Historical Confirmed')\nplt.plot(prediction_global, label='Predicted Confirmed by LSTM')\nplt.plot(prediction_global_gru, label='Predicted Confirmed by GRU')\nplt.plot(test_dataG, label='Actual Confirmed')\nplt.title(\"Global\")\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Numerical Comparison"},{"metadata":{"trusted":true},"cell_type":"code","source":"results = pd.DataFrame(data=np.zeros((2,4)),columns=['RMSE Italy LSTM','RMSE Italy GRU','RMSE Global LSTM','RMSE Globale GRU'],index=['Absolute RMSE','Relative RMSE'])\n# Absolute RMSE\n# LSTM\nresults.iloc[0,0] = resultsrmse_Italy_lstm = math.sqrt(mean_squared_error(prediction,test_data))\nresults.iloc[0,2] = math.sqrt(mean_squared_error(prediction_global,test_dataG))\n# GRU\nresults.iloc[0,1] = resultsrmse_Italy_gru = math.sqrt(mean_squared_error(prediction_gru,test_data))\nresults.iloc[0,3] = math.sqrt(mean_squared_error(prediction_global_gru,test_dataG))\n\n# LSTM\nresults.iloc[1,0] = results.iloc[0,0] / test_data.mean().values[0]\nresults.iloc[1,2] = results.iloc[0,2] / test_dataG.mean().values[0]\n# GRU\nresults.iloc[1,1] = results.iloc[0,1] / test_data.mean().values[0]\nresults.iloc[1,3] = results.iloc[0,3] / test_dataG.mean().values[0]\n\nresults","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The results in the table above shows that in both cases (Italy and Global) the GRU model gave better results. Additionally, it is worth noting the best results, by a significent margin, were achieved using the global data and the GRU model.     "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}