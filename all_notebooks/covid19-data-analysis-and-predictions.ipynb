{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# import basic libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read Data from  \ndf = pd.read_csv('/kaggle/input/covid19-in-india/StatewiseTestingDetails.csv',parse_dates=['Date'])\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## check how many nan values in each columns\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"## here negative is string type we have to convert into float\n## remmeber one thing don't try to convert into int because Nan values can't be converted into int.\n\n# if we try to convert type of Negative column into float then we got following error \n# df['Negative'] = pd.to_numeric(df['Negative'])\n# error : ValueError: Unable to parse string \" \" at position 4838\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"here we face an error bcz there is any row in dataset which contains \" \" string in negative column.\n\nlet's drop that column.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['Negative']==\" \"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's remove this one\ndf = df.drop(index=[4838])\ndf['Negative'] = df['Negative'].astype('float')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## sort data by date column\ndf = df.sort_values('Date').reset_index(drop=True)\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Visualization \n### here i uploaded pdf of visuals you can check i had use power bi tool fo visualization."},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import IFrame\nIFrame('/kaggle/input/corona-report/corona report.pdf',900,700)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### due to some issues above pdf is not visible. i have uploaded the ppt version of data visualization you can download it from my input data attachments. :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%html\n### below is html code to show my power bi report you can view this if you have power bi account\n<iframe width=\"1140\" height=\"541.25\" src=\"https://app.powerbi.com/reportEmbed?reportId=5f6f63fe-bd4a-4563-8330-c6e389d8d83a&autoAuth=true&ctid=4bc9df11-1291-4d7a-9015-aa308945e8dd&config=eyJjbHVzdGVyVXJsIjoiaHR0cHM6Ly93YWJpLWluZGlhLWNlbnRyYWwtYS1wcmltYXJ5LXJlZGlyZWN0LmFuYWx5c2lzLndpbmRvd3MubmV0LyJ9\" frameborder=\"0\" allowFullScreen=\"true\"></iframe>","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## check how many rows have negative and positive both values are nan\ndf[(pd.isnull(df['Negative'])) & (pd.isnull(df['Positive']))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are many nans values and we can't drop all those nan values.\n\ni have one idea to fill nan values.\n\npositive value = total samples * (Average of ratio of positive/total samples values)\n\nnegative value = total samples * (Average of ratio of negative/total samples values)\n\nand this average of ratio of ... its depend on state.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"## let's find avg positive and negative ratio for all states\nstates_ratios = {}\nfor i in df['State'].unique():\n    # get data of particular state\n    t = df[df['State']==i]\n    ## first drop all nan values and then after find ratios\n    t = t.dropna(subset=['Negative','Positive','TotalSamples'])\n    t['ratio_pos'] = t['Positive']/t['TotalSamples']\n    t['ratio_neg'] = t['Negative']/t['TotalSamples']\n#     if(pd.isnull(t['ratio_pos'].mean()) or pd.isnull(t['ratio_neg'].mean())):\n#         pass\n#     else:\n    states_ratios[i] = [t['ratio_pos'].mean() , t['ratio_neg'].mean()]\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"states_ratios","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## make copy of df for future usecase\ndf2 = df.copy()\ndf2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = df2.reset_index(drop=True)\ndf2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fill nan values in df2\nfor i in range(len(df2)):\n    \n    if(pd.isnull(df2.loc[i,'Negative'])):\n        df2.loc[i,'Negative'] = df2.loc[i,'TotalSamples'] * states_ratios[df2.loc[i,'State']][1]\n    \n    if(pd.isnull(df2.loc[i,\"Positive\"])):\n        df2.loc[i,'Positive'] = df2.loc[i,'TotalSamples'] * states_ratios[df2.loc[i,'State']][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## after filling nan values if we show data set so there are something nan values\ndf2[pd.isnull(df2['Negative'])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## for manipur we have nan values of both the ratios in states_dict \n## to fill nan in manipur we consider ratios of mizoram \n## bcz they both states have same (Not exactly) number of cases and they both are neighbor states.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"states_ratios['Mizoram']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df2[df['State']=='Manipur'].index:\n    if(pd.isnull(df2.loc[i,'Negative'])):\n        df2.loc[i,'Negative'] = df2.loc[i,'TotalSamples'] * 0.0001\n    \n    if(pd.isnull(df2.loc[i,\"Positive\"])):\n        df2.loc[i,'Positive'] = df2.loc[i,'TotalSamples'] * 0.017241379310344827","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.isnull().sum()\n\n## Now all nan values are filled.\n## we did great job !!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## convert positive and negative values int0 int bcz float values (ex 234.67) are not valid.\ndf2['Negative'] = df2['Negative'].astype('int')\ndf2['Positive'] = df2['Positive'].astype('int')\ndf2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3 = df2.copy()\n# here we replace our index with date \n# its make our work easy whenever we want to plot any graph or chart\ndf3.index = df3['Date']\ndf3.drop('Date',axis=1)\ndf3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## just plot demo chart\ndf3[df3['State']=='Gujarat']['Positive'].plot()\ndf3[df3['State']=='Gujarat']['Negative'].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save our data into storage.\ndf2.to_csv(\"CleanedCovidData.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## read csv data\ndata = pd.read_csv('CleanedCovidData.csv',parse_dates=['Date'])\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## check for total null values in each columns\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check distribution for state column\ndata['State'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## date type is not acceptable when we go for building model so split date columns into 3 columns(year,month,day)\n\ndata['year'] = data['Date'].apply(lambda x: x.year)\ndata['month'] = data['Date'].apply(lambda x: x.month)\ndata['day'] = data['Date'].apply(lambda x: x.day)\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## just copy data bcz in future if want to plotprediction at that time we take date columns as x axis so copy it\n# for future refrences\ndata1 = data.copy()\n## just drop date column\ndata = data.drop('Date',axis=1)\n## reorder our columns so its easy to analyse data\ndata = data[['year','month','day','State','TotalSamples','Negative','Positive']]\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## here we are using labelencoder to deal with categorical features.\nfrom sklearn.preprocessing import LabelEncoder\n# use train_test_split to categorized our data into train and test\nfrom sklearn.model_selection import train_test_split,cross_val_score\n## import some well known models\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor,RandomForestRegressor\nfrom xgboost import XGBRegressor\n\nle_state = LabelEncoder()\n\n\ndata['State'] = le_state.fit_transform(data['State'])\n\n\nx_train,x_test,y_train,y_test = train_test_split(data.drop(['Negative','Positive'],axis=1),data[['Negative','Positive']],stratify=data['State'])\nx_train.shape , x_test.shape,y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## check correlation \n\nplt.figure(figsize=(10,8))\nsns.heatmap(data.corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## fit linear model\nlrmd = LinearRegression()\nlrmd.fit(x_train,y_train)\nlrmd.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit decision model\ndcmd = DecisionTreeRegressor()\ndcmd.fit(x_train,y_train)\ndcmd.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# if your decision tree model gives good accuracy then you should also check for ExtraTreeRegressor model.\nexmd = ExtraTreesRegressor()\nexmd.fit(x_train,y_train)\nexmd.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit xgboost regressor\n## here i seperately fit xg model on positive data and negative data , bcz when we fit xg model target values must be in single array .\n# and i fit xg model on multi target labels then its shown an error.\n# we have to fit xg model \nxgmd_pos = XGBRegressor(n_estimators = 40)\nxgmd_pos.fit(x_train,y_train['Positive'])\nxgmd_pos.score(x_test,y_test['Positive'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgmd_neg = XGBRegressor()\nxgmd_neg.fit(x_train,y_train['Negative'])\nxgmd_neg.score(x_test,y_test['Negative'])\n# xg model gives very nice accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getStateData(s):\n    return data1[data1['State']==s]\n\ndef predictForState(d,s):\n    s1 = le_state.transform([s])[0]\n    d1 = d.copy()\n    d1.loc[:,'State'] = s1\n    preds = xgmd_pos.predict(d1[['year','month','day','State','TotalSamples']])\n    return preds\n\n\n\ndef plotPredictionsForState(s):\n    guj = getStateData(s)\n    plt.figure(figsize=(12,8))\n    plt.plot(guj['Date'],guj['Positive'],label=\"Actual\")\n    plt.plot(guj['Date'],predictForState(guj,s),label=\"Predicted\")\n    plt.legend()\n    plt.title(f\"ACtual and Predicted plot for {s}\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotPredictionsForState('Gujarat')\nplotPredictionsForState('Kerala')\nplotPredictionsForState('Maharashtra')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.barplot(y= x_train.columns ,x =xgmd_pos.feature_importances_)\nplt.title(\"Feature importances for XGBoostRegressor model\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import joblib\n\njoblib.dump(xgmd_pos,\"XGBoost_Positive.pkl\")\njoblib.dump(xgmd_neg,\"XGBoost_Negative.pkl\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For Year columns its show feature importances is 0 because value of year columns is 2020 its same for whole data\nwe can delete that columns for now but infuture when we work on data of year 2021 at that time we have to consider this year column.\n\nI hope its helpful for and if you learn something new from this then please UpVote me\n\nThank You :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}