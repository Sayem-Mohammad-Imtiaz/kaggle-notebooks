{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport re\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom collections import Counter\n\nfrom datetime import datetime, timedelta\n\nfrom sklearn.model_selection import train_test_split\n\npd.set_option('display.max_columns', 90)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\nRANDOM_SEED = 42 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Подгрузим необходимые для работы файлы"},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_DIR = '/kaggle/input/restaurant-rating-prediction/'\ndf_train = pd.read_csv(DATA_DIR+'main_task.csv')\n#df_test = pd.read_csv(DATA_DIR+'kaggle_task.csv')\ndf_cit = pd.read_csv('/kaggle/input/world-cities/worldcities.csv')\ndf_cost=pd.read_csv('/kaggle/input/2020-cost-of-living/cost of living 2020.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Посмотрим на все файлы, чтобы представлять, с чем мы будем оперировать"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Приведем к более привычному для меня виду\ndf_train.rename(columns={'Price Range' : 'Price_Range',\n                     'Cuisine Style':'Cuisine_Style',\n                    'Number of Reviews':'Num_of_Revs'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_test.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cit.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cit.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cit.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cost.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cost.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_train['sample'] = 1 # помечаем где у нас трейн\n#df_test['sample'] = 0 # помечаем где у нас тест\n#df_test['Rating'] = 0\n#df_train = df_test.append(df_train, sort=False).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  Restaurant_id"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.Restaurant_id.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## City"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.City.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.City.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cityes=set()\ndf_train['City'].apply(lambda x: cityes.add(x))\ncityes\nlen(cityes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cit.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Уберем лишние колонки, а так же заметим, что европейские города как-то попали в столбец country в United States, \n#это надо будет исправить\ndf_cit = df_cit.drop(['city_ascii', 'lat', 'lng', 'iso2',\n                      'iso3', 'admin_name', 'capital', 'id'], axis='columns')\ndf_cit = df_cit.loc[df_cit.city.isin(cityes)]\ndf_cit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cit=df_cit.loc[df_cit['country']!='United States']\nnew_city=set()\ndf_cit.city.apply(lambda x: new_city.add(x))\n\n#Все ли города совпадают? Проверим\ncityes-new_city ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Указанных выше городов нет, добавим их вручную\ndf_cit.loc[2586]=['Krakow', 'Poland',779115]\ndf_cit.loc[2587]=['Oporto', 'Portugal',240000]\ndf_cit.loc[2588]=['Zurich', 'Germany',1300000]\ndf_cit.tail(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cost.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Уберем часть лишних колонок, оставим индекс цен в ресторанах, индекс бигмака, Индекс местной покупательной способности\ndf_cost = df_cost.drop(['Rank 2020', 'Cost of Living Index', 'Cost of Living Plus Rent Index', 'Groceries Index',\n                        'Unnamed: 9', 'Rent Index'], axis='columns')\ndf_cost = df_cost.loc[df_cost.Country.isin(df_cit['country'])]\ndf_cost.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cost.rename(columns={'Restaurant Price Index':'Rest_pr_index', 'Local Purchasing Power Index':'Loc_Purch_Pow'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cost.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Объединим два небольших датафрейма между собой\ndf_cit=df_cit.merge(df_cost, left_on='country',right_on= 'Country', how='inner')\ndf_cit=df_cit.drop(['country','Country'], axis='columns')\ndf_cit.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Объединим теперь с большим фреймом\ndf_train=df_train.merge(df_cit, left_on='City',right_on= 'city', how='inner')\ndf_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cuisine Style"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Cuisine_Style']=df_train['Cuisine_Style'].fillna(\"['no_info']\") #заменяем пропуск \ndef make_a_list (x):\n    x=x[1:-1]\n    x=x.replace(\"'\", \"\")\n    x=x.split(', ')\n    return (x)\ncousine_list=[]\ndf_train['Cuisine_Style']=df_train['Cuisine_Style'].apply(make_a_list)\ndf_train['Cuisine_Style'].apply(lambda x: cousine_list.extend(x))\nCounter(cousine_list).most_common(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def change_cuisine(x):\n    if x == ['no_info']:\n        return ['European', 'Vegetarian Friendly']\n    else:\n        return x\ndf_train['Cuisine_Style']=df_train['Cuisine_Style'].apply(change_cuisine)\ncousine_list=[]\ndf_train['Cuisine_Style'].apply(lambda x: cousine_list.extend(x))\nCounter(cousine_list).most_common(5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Cuisine_Style']=df_train['Cuisine_Style'].apply(lambda x: len(x))\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Price Range"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.Price_Range.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Price_Range']=df_train['Price_Range'].fillna('$$ - $$$')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def replace_price(x):\n    if x == \"$$ - $$$\":\n        return 'medium price'\n    elif x == \"$$$$\":\n        return 'high price'\n    elif x == \"$\":\n        return 'low price'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Price_Range'] = df_train['Price_Range'].apply(replace_price)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_price = pd.get_dummies(df_train['Price_Range'])\ndf_train['high price'] = data_price['high price']\ndf_train['low price'] = data_price['low price']\ndf_train['medium price'] = data_price['medium price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def replace_price_to_value(x):\n    if x == \"medium price\":\n        return '2'\n    elif x == \"high price\":\n        return '3'\n    elif x == \"low price\":\n        return '1'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Price_Range'] = df_train['Price_Range'].apply(replace_price_to_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Price_Range'].dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Как-то очень хитро заверуто получилось, но по ходу анализа приходили разные мысли, поэтому пришлось ставить \"костыль\""},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Number of Reviews"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Num_of_Revs'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Num_of_Revs'].hist(bins=100)\ndf_train['Num_of_Revs'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mode=df_train['Num_of_Revs'].mode()\nmean=df_train['Num_of_Revs'].mean()\nmedian=df_train['Num_of_Revs'].median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Mode: {}, \\n\\nMean: {},\\nMedian: {}\".format(mode,mean,median))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"median = df_train['Num_of_Revs'].median()\nIQR = df_train['Num_of_Revs'].quantile(0.75) - df_train['Num_of_Revs'].quantile(0.25)\nperc25 = df_train['Num_of_Revs'].quantile(0.25)\nperc75 = df_train['Num_of_Revs'].quantile(0.75)\nprint('25-й перцентиль: {},'.format(perc25), '75-й перцентиль: {},'.format(perc75)\n      , \"IQR: {}, \".format(IQR),\"Границы выбросов: [{f}, {l}].\".format(f=perc25 - 1.5*IQR, l=perc75 + 1.5*IQR))\ndf_train['Num_of_Revs'].loc[df_train['Num_of_Revs'].between(perc25 - 1.5*IQR, perc75 + 1.5*IQR)].hist(bins = 50, range = (0, 40), \n                                                                                             label = 'IQR')\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Num_of_Revs'] = df_train['Num_of_Revs'][df_train['Num_of_Revs'].between(perc25 - 1.5*IQR, perc75 + 1.5*IQR)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_val = round(df_train['Num_of_Revs'].mean(), 0)\ndf_train['Num_of_Revs'] = df_train['Num_of_Revs'].fillna(mean_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Num_of_Revs'].hist()\ndf_train['Num_of_Revs'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reviews"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, cell in enumerate(df_train['Reviews']):\n    print(cell)\n    if i == 20:\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Reviews'].fillna('', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count = 0\nfor i in df_train['Reviews']:\n    if i == '[[], []]':\n        count +=1\nprint(count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count = 0\nfor i in df_train['Reviews']:\n    if i == '[[], []]':\n        df_train.drop(index = count, inplace = True, axis = 0)\n    count +=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Reviews'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Reviews_date_1'] = df_train['Reviews'].apply(lambda x: re.findall(r'\\d\\d\\/\\d\\d\\/\\d{4}', x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Reviews_date_2'] = df_train['Reviews_date_1']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Reviews_date_1'] = df_train['Reviews_date_1'].apply(lambda x: x[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Reviews_date_2'] = df_train['Reviews_date_2'].apply(\n    lambda x: x[1] if len(x) > 1 else x[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Reviews_date_1'] = df_train['Reviews_date_1'].apply(\n    lambda x: datetime.strptime(x, '%m/%d/%Y'))\ndf_train['Reviews_date_2'] = df_train['Reviews_date_2'].apply(\n    lambda x: datetime.strptime(x, '%m/%d/%Y'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Dif_Reviews_date'] = df_train['Reviews_date_1'] - \\\n    df_train['Reviews_date_2']\ndf_train['Dif_Reviews_date'] = df_train['Dif_Reviews_date'].dt.days.astype(\n    'int16')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Dif_Reviews_date'].hist()\ndf_train['Dif_Reviews_date'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"median = df_train['Dif_Reviews_date'].median()\nIQR = df_train['Dif_Reviews_date'].quantile(0.75) - df_train['Dif_Reviews_date'].quantile(0.25)\nperc25 = df_train['Dif_Reviews_date'].quantile(0.25)\nperc75 = df_train['Dif_Reviews_date'].quantile(0.75)\nprint('25-й перцентиль: {},'.format(perc25), '75-й перцентиль: {},'.format(perc75)\n      , \"IQR: {}, \".format(IQR),\"Границы выбросов: [{f}, {l}].\".format(f=perc25 - 1.5*IQR, l=perc75 + 1.5*IQR))\ndf_train['Dif_Reviews_date'].loc[df_train['Dif_Reviews_date'].between(perc25 - 1.5*IQR, perc75 + 1.5*IQR)].hist(bins = 50, range = (0, 40), \n                                                                                             label = 'IQR')\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Dif_Reviews_date'] = df_train['Dif_Reviews_date'][df_train['Dif_Reviews_date'].between(perc25 - 1.5*IQR, perc75 + 1.5*IQR)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_val = round(df_train['Dif_Reviews_date'].mean(), 0)\ndf_train['Dif_Reviews_date'] = df_train['Dif_Reviews_date'].fillna(mean_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Dif_Reviews_date'].hist()\ndf_train['Dif_Reviews_date'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Добавим новых признаков"},{"metadata":{"trusted":true},"cell_type":"code","source":"Jan_temp={'Paris':4.8, 'Stockholm':-1.4, 'London':5.0, 'Berlin':1.3, 'Munich':0, 'Oporto':11.4,\n       'Milan':4.8, 'Bratislava':0.4, 'Vienna':0.7, 'Rome':8.8, 'Barcelona':10.7, 'Madrid':7.6,\n       'Dublin':6, 'Brussels':4.1, 'Zurich':0.9, 'Warsaw':-1.1, 'Budapest':0.6, 'Copenhagen':2.4,\n       'Amsterdam':5, 'Lyon':3.4, 'Hamburg':2, 'Lisbon':12.7, 'Prague':0, 'Oslo':-4.5,\n       'Helsinki':-2.8, 'Edinburgh':4.1, 'Geneva':0.1, 'Ljubljana':0.6, 'Athens':10.1,\n       'Luxembourg':1.7, 'Krakow':-1.2}\nApr_temp={'Paris':11.7, 'Stockholm':5.9, 'London':10.8, 'Berlin':10.8, 'Munich':9.6, 'Oporto':14.9,\n       'Milan':13.7, 'Bratislava':11.9, 'Vienna':11.9, 'Rome':15.1, 'Barcelona':15.3, 'Madrid':14,\n       'Dublin':8.5, 'Brussels':11.1, 'Zurich':10, 'Warsaw':10.3, 'Budapest':13.5, 'Copenhagen':7.8,\n       'Amsterdam':10.1, 'Lyon':11.5, 'Hamburg':9.2, 'Lisbon':16.3, 'Prague':10.2, 'Oslo':5,\n       'Helsinki':3.9, 'Edinburgh':7.8, 'Geneva':11.7, 'Ljubljana':10.8, 'Athens':16.4,\n       'Luxembourg':9.8, 'Krakow':10.1}\nJul_temp={'Paris':20.1, 'Stockholm':17.7, 'London':19.1, 'Berlin':20.5, 'Munich':18.4, 'Oporto':21.6,\n       'Milan':24.5, 'Bratislava':22.1, 'Vienna':21.8, 'Rome':26.6, 'Barcelona':26, 'Madrid':28.1,\n       'Dublin':15.5, 'Brussels':19.1, 'Zurich':19, 'Warsaw':20.9, 'Budapest':23.6, 'Copenhagen':18.1,\n       'Amsterdam':18.3, 'Lyon':20.7, 'Hamburg':18, 'Lisbon':22.4, 'Prague':19.7, 'Oslo':16.3,\n       'Helsinki':17.7, 'Edinburgh':14.7, 'Geneva':18, 'Ljubljana':20.5, 'Athens':28.2,\n       'Luxembourg':17.9, 'Krakow':19.6}\nOct_temp={'Paris':13.5, 'Stockholm':8.1, 'London':13.1, 'Berlin':11.6, 'Munich':9.8, 'Oporto':18.8,\n       'Milan':16.1, 'Bratislava':12, 'Vienna':12, 'Rome':19, 'Barcelona':19.7, 'Madrid':18.3,\n       'Dublin':11.5, 'Brussels':12.3, 'Zurich':10.5, 'Warsaw':10.8, 'Budapest':13.6, 'Copenhagen':11.3,\n       'Amsterdam':12.7, 'Lyon':13, 'Hamburg':10.9, 'Lisbon':20.3, 'Prague':10.7, 'Oslo':6.1,\n       'Helsinki':7.5, 'Edinburgh':10.1, 'Geneva':10.3, 'Ljubljana':10.9, 'Athens':20.7,\n       'Luxembourg':10.5, 'Krakow':10.5}\nMean_sal={'Paris':2900, 'Stockholm':4329, 'London':2507, 'Berlin':2596, 'Munich':2500, 'Oporto':1200,\n       'Milan':1916, 'Bratislava':1176, 'Vienna':3406, 'Rome':1847, 'Barcelona':2000, 'Madrid':2000,\n       'Dublin':784, 'Brussels':3200, 'Zurich':7839, 'Warsaw':887, 'Budapest':682, 'Copenhagen':3100,\n       'Amsterdam':2152, 'Lyon':1691, 'Hamburg':2500, 'Lisbon':852, 'Prague':1275, 'Oslo':4400,\n       'Helsinki':2600, 'Edinburgh':3698, 'Geneva':7600, 'Ljubljana': 1172, 'Athens':2700,\n       'Luxembourg':3300, 'Krakow':757}\nMin_sal={'Paris':1219, 'Stockholm':1101, 'London':1237, 'Berlin':646, 'Munich':646, 'Oporto':649,\n       'Milan':800, 'Bratislava':335, 'Vienna':1500, 'Rome':800, 'Barcelona':600, 'Madrid':580,\n       'Dublin':480, 'Brussels':1594, 'Zurich':1762, 'Warsaw':523, 'Budapest':582, 'Copenhagen':2000,\n       'Amsterdam':1653, 'Lyon':1200, 'Hamburg':1496, 'Lisbon':600, 'Prague':562, 'Oslo':2200,\n       'Helsinki':1900, 'Edinburgh':432, 'Geneva':1660, 'Ljubljana':0.6, 'Athens':758,\n       'Luxembourg':2300, 'Krakow':509}\ntourists={'Paris':19.0, 'Stockholm':2.7, 'London':19.5, 'Berlin':6.2, 'Munich':4.2, 'Oporto':2.8,\n       'Milan':6.6, 'Bratislava':1, 'Vienna':6.6, 'Rome':10.3, 'Barcelona':7.0, 'Madrid':5.6,\n       'Dublin':5.4, 'Brussels':4.2, 'Zurich':1.5, 'Warsaw':2.8, 'Budapest':4.0, 'Copenhagen':3.2,\n       'Amsterdam':8.8, 'Lyon':3.5, 'Hamburg':6.8, 'Lisbon':3.6, 'Prague': 9.1, 'Oslo':0.7,\n       'Helsinki':0.4, 'Edinburgh':4.4, 'Geneva':1.3, 'Ljubljana':0.4, 'Athens':0.24,\n       'Luxembourg':0.9, 'Krakow':8.1}\nrains={'Paris':6.37, 'Stockholm':5.27, 'London':6.21, 'Berlin':5.7, 'Munich':6.22, 'Oporto':11.78,\n       'Milan':10.13, 'Bratislava':6.94, 'Vienna':10.31, 'Rome':9.34, 'Barcelona':6.12, 'Madrid':4.5,\n       'Dublin':7.67, 'Brussels':7.82, 'Zurich':10.85, 'Warsaw':10.02, 'Budapest':5.64, 'Copenhagen':11.64,\n       'Amsterdam':8.05, 'Lyon':7.63, 'Hamburg':7.38, 'Lisbon':6.91, 'Prague': 4.86, 'Oslo':7.40,\n       'Helsinki':6.5, 'Edinburgh':7.06, 'Geneva':9.34, 'Ljubljana':12.90, 'Athens':3.97,\n       'Luxembourg':8.31, 'Krakow':6.78}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def january_temp_column(C):\n    for  city in Jan_temp:\n        if city==C:\n            return(Jan_temp[city])\ndf_train['January_temp']=df_train['city'].apply(january_temp_column)\n\ndef april_temp_column(C):\n    for  city in Apr_temp:\n        if city==C:\n            return(Apr_temp[city])\ndf_train['April_temp']=df_train['city'].apply(april_temp_column)\n\ndef july_temp_column(C):\n    for  city in Jul_temp:\n        if city==C:\n            return(Jul_temp[city])\ndf_train['July_temp']=df_train['city'].apply(july_temp_column)\n\ndef october_temp_column(C):\n    for  city in Oct_temp:\n        if city==C:\n            return(Oct_temp[city])\ndf_train['October_temp']=df_train['city'].apply(october_temp_column)\n\ndef mean_salary_column(C):\n    for  city in Mean_sal:\n        if city==C:\n            return(Mean_sal[city])\ndf_train['Mean_salary']=df_train['city'].apply(mean_salary_column)\n\ndef min_sal_column(C):\n    for  city in Min_sal:\n        if city==C:\n            return(Min_sal[city])\ndf_train['Min_salary']=df_train['city'].apply(min_sal_column)\n\ndef tourist_flow_column(C):\n    for  city in tourists:\n        if city==C:\n            return(tourists[city])\ndf_train['tourists_flow']=df_train['city'].apply(tourist_flow_column)\n\ndef rain_column(C):\n    for  city in tourists:\n        if city==C:\n            return(rains[city])\ndf_train['rains']=df_train['city'].apply(rain_column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Уберем все нечисловые колонки\ndf_train.drop(columns=['Restaurant_id','City','Reviews','URL_TA','ID_TA','city','Reviews_date_1','Reviews_date_2'], inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Сделаем несколько копиф обработанного файла, чтобы не было конфликтов при дальнейшем анализе"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train1=df_train\ndf_train2=df_train\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Самое интересное**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Сначала посмотрим на данные, которые мы получили на входе. Какие МАЕ было?"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\ndf = pd.read_csv(DATA_DIR+'main_task.csv')\ndf=df.dropna(axis=1)\ndf=df.fillna(0)\ndf.drop(columns=['City','Reviews', 'URL_TA','ID_TA'],  inplace=True)\nX0 = df.drop(['Restaurant_id', 'Rating'], axis = 1)\ny0 = df['Rating']\nX0_train, X0_test, y0_train, y0_test = train_test_split(X0, y0, test_size=0.25)\nregr = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)\nregr.fit(X0_train, y0_train)\ny0_pred = regr.predict(X0_test)\nprint('MAE:', metrics.mean_absolute_error(y0_test, y0_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Теперь приступим к построению предсказания для обработанного файла"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_train.drop(['Rating'], axis = 1)\ny = df_train['Rating']\n# Загружаем специальный инструмент для разбивки:\nfrom sklearn.model_selection import train_test_split\n# Наборы данных с меткой \"train\" будут использоваться для обучения модели, \"test\" - для тестирования.\n# Для тестирования мы будем использовать 25% от исходного датасета.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n# Импортируем необходимые библиотеки:\nfrom sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\nfrom sklearn import metrics # инструменты для оценки точности модели\n# Создаём модель\nregr = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)\n\n# Обучаем модель на тестовом наборе данных\nregr.fit(X_train, y_train)\n\n# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n# Предсказанные значения записываем в переменную y_pred\ny_pred = regr.predict(X_test)\n# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\nprint('MAE:', metrics.mean_absolute_error(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Обработаем данные с помощь одного из Скейлеров (MinMaxScaler)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nnames = df_train1.columns.values\nscaler=MinMaxScaler()\ndf_train1 = pd.DataFrame(scaler.fit_transform(df_train1))\ndf_train1.columns=names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1 = df_train1.drop(['Rating'], axis = 1)\ny1 = df_train1['Rating']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2)\n\nregr1 = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)\n\nregr1.fit(X1_train, y1_train)\n\ny1_pred = regr1.predict(X1_test)\nprint('MAE:', metrics.mean_absolute_error(y1_test, y1_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Теперь применим StandardScaler к обработанным данным"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nnames = df_train2.columns.values\nscaler = StandardScaler()\ndf_train2 = pd.DataFrame(scaler.fit_transform(df_train2))\ndf_train2.columns = names\nX2 = df_train2.drop(['Rating'], axis=1)\ny2 = df_train2['Rating']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.25)\n\nregr2 = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)\n\nregr2.fit(X2_train, y2_train)\n\ny2_pred = regr2.predict(X2_test)\nprint('MAE:', metrics.mean_absolute_error(y2_test, y2_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Посмотрим на наши МАЕ"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"МАЕ для сырых данных: {}, \\nМАЕ для обработанных данных: {}, \\nМАЕ для MinMaxScaler: {}, \\nМАЕ для StandardScaler: {}.\".format(metrics.mean_absolute_error(y0_test, y0_pred), metrics.mean_absolute_error(\n    y_test, y_pred), metrics.mean_absolute_error(y1_test, y1_pred), metrics.mean_absolute_error(y2_test, y2_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Посмотрим на тепловую карту"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(16, 16))\ncorrelation = df_train1.corr()\nsns.heatmap(correlation, annot=True, cmap='coolwarm', linewidth=0.7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Выделим самые значимые признаки\nplt.rcParams['figure.figsize'] = (11,11)\nfeat_importances = pd.Series(regr.feature_importances_, index=X.columns)\nfeat_importances.nlargest(15).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Теперь поработаем с предсказаниями"},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_DIR_1 = '/kaggle/input/submissioncsv/sample_submission (1).csv'\nsample_submission = pd.read_csv(DATA_DIR_1)\nsample_submission1 = pd.read_csv(DATA_DIR_1)\nsample_submission2 = pd.read_csv(DATA_DIR_1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Пройдемся по обработанным данным"},{"metadata":{"trusted":true},"cell_type":"code","source":"tdata = df_train.drop(['Rating'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission = regr.predict(tdata)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['Rating'] = predict_submission[:10000]\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Посмотрим на результаты с MinMaxScaler "},{"metadata":{"trusted":true},"cell_type":"code","source":"tdata1 = df_train1.drop(['Rating'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission1 = regr1.predict(tdata1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission1['Rating'] = predict_submission1[:10000]\nsample_submission1.to_csv('submission1.csv', index=False)\nsample_submission1.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Посмотрим на результаты с StandardScaler "},{"metadata":{"trusted":true},"cell_type":"code","source":"tdata2 = df_train2.drop(['Rating'], axis=1)\npredict_submission2 = regr2.predict(tdata2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission2['Rating'] = predict_submission2[:10000]\nsample_submission2.to_csv('submission2.csv', index=False)\nsample_submission2.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Промежуточный итог"},{"metadata":{},"cell_type":"markdown","source":"На данный момент для обработанных данных МАЕ получилось 0.193(.......), однако и количество колонок довольно большое. В тестовых выриантах в своем ноутбуке получилось добиться значения немного меньшего. Попробуем полуить его и здесь, убрав часть колонок из анализа."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train3=df_train\ndf_train3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X3 = df_train3.drop(['Rating','Loc_Purch_Pow','McMeal($)','rains','tourists_flow'], axis = 1)\ny3 = df_train3['Rating']\n\nX3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.25)\n\nregr3 = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)\n\nregr3.fit(X3_train, y3_train)\n\ny3_pred = regr3.predict(X3_test)\n\nprint('MAE:', metrics.mean_absolute_error(y3_test, y3_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}