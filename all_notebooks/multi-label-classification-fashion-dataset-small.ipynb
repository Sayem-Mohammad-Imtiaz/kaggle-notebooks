{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#loading in the csv data\ndf = pd.read_csv('/kaggle/input/fashion-product-images-small/myntradataset/styles.csv',error_bad_lines=False)\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.dropna()\ndf.nunique()\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at all the unique labels in all categorical columns \ncat_columns = ['gender', 'masterCategory', 'subCategory', 'articleType','baseColour', 'season', 'year', 'usage']\n\nfor col in cat_columns:\n    print(col)\n    print(df[col].unique())\n    print('-------------------------')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The images in this Dataset are very low resolution (80x60). We will be using the categories that are visually distinct even at such a low resolution.\n\nThe categories year, usage, season, and gender mighht not be clearly visually distinct in some cases, so we wont be using them.\n\nThe categories, masterCategory and subCategory are distinct enough groups, but they are not specific enough for practical use. \n\nThe categories we will use are articleType and baseColour(You can use more categories if you want).\n\nThere are many unique labels in these categories, we will only be using the ones with more than 1000 examples, since we would need a good number of samples for proper classifcation."},{"metadata":{"trusted":true},"cell_type":"code","source":"value_counts = df['articleType'].value_counts()\n\nindexes = value_counts.index\n\nvalues = value_counts.values\n\nfor i in range(len(value_counts)):\n\n    if values[i] <1000:\n        break\n\ntypes_used = indexes[:i]\nprint('Article types used: ',types_used)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"value_counts = df['baseColour'].value_counts()\n\nindexes = value_counts.index\n\nvalues = value_counts.values\n\nfor i in range(len(value_counts)):\n\n    if values[i] <1000:\n        break\n\ncolours_used = indexes[:i]\nprint('Base Colours used: ',colours_used)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing all the examples with labels other than the selected ones\n \ndf = df[df['articleType'].isin(types_used)]\ndf = df[df['baseColour'].isin(colours_used)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#number of examples we are left with\nlen(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will load in all the images from the remaining rows, and convert them to numpy arrays with img_to_array function in keras."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = []\n\n# Reading all the images and processing the data in them \n\nfrom tensorflow.keras.preprocessing.image import img_to_array\nimport cv2\n\nIX = 80\nIY = 60\n\ninvalid_ids = []\n\nfor name in df.id:\n\n    try:\n        image = cv2.imread('/kaggle/input/fashion-product-images-small/myntradataset/images/'+str(name)+'.jpg')\n        image = cv2.resize(image, (IX,IY) )\n        image = img_to_array(image)\n        data.append(image)        \n    except: \n        # Images for certain ids are missing, so they are not added to the dataset  \n        invalid_ids.append(name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ids of missing images\nprint('invalid ids:')\nprint(invalid_ids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = []\n\nused_columns = ['subCategory','baseColour']\n\n# getting labels for the columns used\n\nfor index, row in df.iterrows():\n\n    if row['id'] in invalid_ids:\n        continue\n\n    tags = []\n\n    for col in used_columns:\n        tags.append(row[col])\n\n    labels.append(tags)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\n# converting data into numpy arrays\n\ndata = np.array(data, dtype=\"float\") / 255.0\nlabels = np.array(labels)\n\nprint(labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will create binary vectors as the outputs of the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MultiLabelBinarizer\n\n# creating a binary vector for the input labels \n\nmlb = MultiLabelBinarizer()\nlabels = mlb.fit_transform(labels)\n\nprint(mlb.classes_)\nprint(labels[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n\ninputShape = (IY, IX, 3)\n\n# A very simple sequential model is used since the images are very low resolution and the categories are fiarly distinct\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten()) \n\nmodel.add(Dense(128))\nmodel.add(Activation('sigmoid'))\n\n\nout = len(mlb.classes_)\n\nmodel.add(Dense(out))\nmodel.add(Activation('sigmoid')) # activation function for the final layer has to be sigmoid, since mutiple output labels can have value 1\n                    \nmodel.compile(loss='binary_crossentropy', # loss function has to be binary_crossentropy, it is calculated seperately for each of the outputs\n              optimizer='adam',\n              metrics=['mse'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# splitting data into testing and training set \n\n(trainX, testX, trainY, testY) = train_test_split(data,labels, test_size=0.1, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch = 32\nE = 50\n\n#training the model \nmodel.fit(x=trainX,y=trainY,\n          epochs=E ,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict(testX)\n\n\n# since the predictions of the model are sigmoid, we will first binarize them to 0 or 1\npred_binarized = []\n\nfor pred in preds:\n    vals = []\n    for val in pred:\n        if val > 0.5:\n            vals.append(1)\n        else:\n            vals.append(0)\n    pred_binarized.append(vals) \n\npred_binarized = np.array(pred_binarized)   \n\n\n# we convert the output vectors to the predicted labels\ntrue_test_labels = mlb.inverse_transform(testY)\npred_test_labels = mlb.inverse_transform(pred_binarized)\n\ncorrect = 0\nwrong = 0\n\n# Evaluating the predictions of the model\n\nfor i in range(len(testY)):\n\n    true_labels = list(true_test_labels[i])\n\n    pred_labels = list(pred_test_labels[i])\n\n    label1 = true_labels[0]\n    label2 = true_labels[1]\n\n    if label1 in pred_labels:\n        correct+=1\n    else:\n        wrong+=1\n\n    if label2 in pred_labels:\n        correct+=1\n    else:\n        wrong+=1    \n\n\n\nprint('correct: ', correct)\nprint('missing/wrong: ', wrong)\nprint('Accuracy: ',correct/(correct+wrong))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that this model identifies 84.61% of the labels correctly, let us see what that looks like in practice"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(20):\n    print('True labels: ',true_test_labels[i],' Predicted labels: ',pred_test_labels[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"While we did not classify the images into based on all the category classes, we were able to classify them into more than one labels at the same time. "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}