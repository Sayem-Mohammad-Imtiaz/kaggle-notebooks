{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook contains\n- Data Preparation: quick view towards the dataset, replacing value with mean value\n- Data Exploration: finding duplicates/ similar words by using cosine similarity\n- Data Visualization","metadata":{}},{"cell_type":"markdown","source":"# Import Library","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport re\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_theme(style=\"whitegrid\")\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-04T05:23:27.903605Z","iopub.execute_input":"2021-06-04T05:23:27.903957Z","iopub.status.idle":"2021-06-04T05:23:27.914825Z","shell.execute_reply.started":"2021-06-04T05:23:27.903923Z","shell.execute_reply":"2021-06-04T05:23:27.913541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"code","source":"# import data\ndf = pd.read_csv(r\"/kaggle/input/amazon-top-50-bestselling-books-2009-2019/bestsellers with categories.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:23:27.916581Z","iopub.execute_input":"2021-06-04T05:23:27.917188Z","iopub.status.idle":"2021-06-04T05:23:27.930405Z","shell.execute_reply.started":"2021-06-04T05:23:27.91714Z","shell.execute_reply":"2021-06-04T05:23:27.929536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# quick view about the table\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:23:27.932146Z","iopub.execute_input":"2021-06-04T05:23:27.93246Z","iopub.status.idle":"2021-06-04T05:23:27.952936Z","shell.execute_reply.started":"2021-06-04T05:23:27.932428Z","shell.execute_reply":"2021-06-04T05:23:27.951773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"There are {np.shape(df)[0]} rows and {np.shape(df)[1]} columns\")","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:23:27.954936Z","iopub.execute_input":"2021-06-04T05:23:27.955402Z","iopub.status.idle":"2021-06-04T05:23:27.967044Z","shell.execute_reply.started":"2021-06-04T05:23:27.955343Z","shell.execute_reply":"2021-06-04T05:23:27.965909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the numeric columns\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:23:27.968695Z","iopub.execute_input":"2021-06-04T05:23:27.969002Z","iopub.status.idle":"2021-06-04T05:23:28.003877Z","shell.execute_reply.started":"2021-06-04T05:23:27.968971Z","shell.execute_reply":"2021-06-04T05:23:28.002642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot three figures to show the details of \"User Rating\", \"Reviews\", \"Price\".","metadata":{}},{"cell_type":"code","source":"ax = sns.boxplot(x=df[\"User Rating\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:23:28.005819Z","iopub.execute_input":"2021-06-04T05:23:28.006242Z","iopub.status.idle":"2021-06-04T05:23:28.188303Z","shell.execute_reply.started":"2021-06-04T05:23:28.006195Z","shell.execute_reply":"2021-06-04T05:23:28.187183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.boxplot(x=df[\"Reviews\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:23:28.189957Z","iopub.execute_input":"2021-06-04T05:23:28.190238Z","iopub.status.idle":"2021-06-04T05:23:28.344504Z","shell.execute_reply.started":"2021-06-04T05:23:28.19021Z","shell.execute_reply":"2021-06-04T05:23:28.343725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.boxplot(x=df[\"Price\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:23:28.345992Z","iopub.execute_input":"2021-06-04T05:23:28.346573Z","iopub.status.idle":"2021-06-04T05:23:28.497774Z","shell.execute_reply.started":"2021-06-04T05:23:28.346529Z","shell.execute_reply":"2021-06-04T05:23:28.496772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some question I have after reading the figures:\n* (1) Which book got average 3.3 user rating?\n* (2) Which book got only 37 reviews while other books have thousands of reviews?\n* (3) The minimun price is 0? >> seems that we need to take a detailed look at it","metadata":{}},{"cell_type":"markdown","source":"(1) Which book got average 3.3 user rating?","metadata":{}},{"cell_type":"code","source":"df[df[\"User Rating\"] == 3.3]","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:23:28.499345Z","iopub.execute_input":"2021-06-04T05:23:28.499765Z","iopub.status.idle":"2021-06-04T05:23:28.512167Z","shell.execute_reply.started":"2021-06-04T05:23:28.499722Z","shell.execute_reply":"2021-06-04T05:23:28.511505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">Okay. Reasonable.","metadata":{}},{"cell_type":"markdown","source":"(2) Which book got only 37 reviews?","metadata":{}},{"cell_type":"code","source":"df[df[\"Reviews\"] == 37]","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:23:28.513151Z","iopub.execute_input":"2021-06-04T05:23:28.513575Z","iopub.status.idle":"2021-06-04T05:23:28.535179Z","shell.execute_reply.started":"2021-06-04T05:23:28.513546Z","shell.execute_reply":"2021-06-04T05:23:28.534075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    It just seem unreasonable that one of the best selling books in amazon only got 37 review on that year. Anyway, I dont have way to check the validity.","metadata":{}},{"cell_type":"markdown","source":"(3) The minimun price is 0? ","metadata":{}},{"cell_type":"code","source":"df[df[\"Price\"] == 0]","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:23:28.537936Z","iopub.execute_input":"2021-06-04T05:23:28.538267Z","iopub.status.idle":"2021-06-04T05:23:28.557822Z","shell.execute_reply.started":"2021-06-04T05:23:28.538236Z","shell.execute_reply":"2021-06-04T05:23:28.556813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"    We can also find books with low price (eg. 1,2,3). As long as the price is not 0, we can accept the validity of the table. I will replace the 0 with average price grouped by year and genre. ","metadata":{}},{"cell_type":"markdown","source":"Price that equals to 0 is replaced with the average price.\nCode:","metadata":{}},{"cell_type":"code","source":"# Seperate the dataframe into two dataframes\ndf_not_zero = df[df[\"Price\"] != 0]\ndf_equal_zero = df[df[\"Price\"] == 0]\n\n# calculate the mean price, grouped by year and genre\nprice_groubpy_year_genre = df_not_zero.groupby([\"Year\", \"Genre\"])[\"Price\"].mean()\n\n# Drop the \"Price\" column\ndf_equal_zero.drop(columns=['Price'], inplace = True)\n\n# Left join the average price and concate the two dataframes.\ndf_replaced_zero = pd.merge(df_equal_zero,price_groubpy_year_genre,on=[\"Year\", \"Genre\"])\ndf_new = pd.concat([df_not_zero, df_replaced_zero])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-04T05:23:28.559944Z","iopub.execute_input":"2021-06-04T05:23:28.560606Z","iopub.status.idle":"2021-06-04T05:23:28.58278Z","shell.execute_reply.started":"2021-06-04T05:23:28.56056Z","shell.execute_reply":"2021-06-04T05:23:28.58175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To check if the code is correct:","metadata":{}},{"cell_type":"code","source":"print(f\"There are {np.shape(df_new)[0]} rows and {np.shape(df_new)[1]} columns\")","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:23:28.584227Z","iopub.execute_input":"2021-06-04T05:23:28.584818Z","iopub.status.idle":"2021-06-04T05:23:28.59Z","shell.execute_reply.started":"2021-06-04T05:23:28.584763Z","shell.execute_reply":"2021-06-04T05:23:28.589026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration - checking duplicate names","metadata":{}},{"cell_type":"code","source":"print(f\"There are {len(df_new.Name.unique())} books and {len(df_new.Author.unique())} arthurs\")","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:23:28.591206Z","iopub.execute_input":"2021-06-04T05:23:28.591605Z","iopub.status.idle":"2021-06-04T05:23:28.603706Z","shell.execute_reply.started":"2021-06-04T05:23:28.591566Z","shell.execute_reply":"2021-06-04T05:23:28.602533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The actual number of unique books or arthurs may be less due to typing difference in name. For example, ","metadata":{}},{"cell_type":"markdown","source":"    \"The Girl Who Played with Fire (Millennium Series)\" and \n    \"The Girl Who Played with Fire (Millennium)\" ","metadata":{}},{"cell_type":"markdown","source":"Below I will use word similarity to check all the unique books name and arthurs name. ","metadata":{}},{"cell_type":"code","source":"# Import libries:\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:23:28.605138Z","iopub.execute_input":"2021-06-04T05:23:28.605571Z","iopub.status.idle":"2021-06-04T05:23:28.614624Z","shell.execute_reply.started":"2021-06-04T05:23:28.605527Z","shell.execute_reply":"2021-06-04T05:23:28.613649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Code to find similar names:","metadata":{}},{"cell_type":"code","source":"# Find all the Unique names, and transform to lower case:\nunique_name = df_new.Name.unique()\nunique_name = [word.lower() for word in unique_name]\n# Vectorize words:\ncount_vectorizer = CountVectorizer()\nsparse_matrix = count_vectorizer.fit_transform(unique_name)\n\n# Calculate the similarity between each other\nresult = (cosine_similarity(sparse_matrix, sparse_matrix))\n\n# Only get similar names with score > 0.7 and < 1. \n# Similarity Score is a hyperparameter can be set by ourselves.\n# I have tried several similarity score. 0.7 give a good result.\nsimilar_name = np.argwhere(result > 0.7)\nsimilar_name_filter = similar_name[similar_name[:,0] != similar_name[:,1]]\n\n# Some result is repeated. The below code filter them out\nsimilar_name_filter_not_repeat = similar_name_filter[similar_name_filter[:,1] > similar_name_filter[:,0]]\n\n# Make a dataframe for easier comparison\nleft = np.array(similar_name_filter_not_repeat[:,0])\nright = np.array(similar_name_filter_not_repeat[:,1])\ndf_similar = pd.DataFrame({'col1': np.take(unique_name, left), 'col2': np.take(unique_name, right)}) ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-04T05:23:28.615997Z","iopub.execute_input":"2021-06-04T05:23:28.616281Z","iopub.status.idle":"2021-06-04T05:23:28.64237Z","shell.execute_reply.started":"2021-06-04T05:23:28.616253Z","shell.execute_reply":"2021-06-04T05:23:28.641126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set pandas to show more rows\npd.set_option('display.max_rows', 100)\n# Result that some books have similar with another books\ndf_similar","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-04T05:23:28.643777Z","iopub.execute_input":"2021-06-04T05:23:28.64418Z","iopub.status.idle":"2021-06-04T05:23:28.664895Z","shell.execute_reply.started":"2021-06-04T05:23:28.644149Z","shell.execute_reply":"2021-06-04T05:23:28.664026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The meaning of Similarity Score:\n* (1) It gives us a fast and easy way to check if there are similar words in the dataset. Here, we find that some books' names are different but they are acturally representing the same book.","metadata":{}},{"cell_type":"markdown","source":"The meaning of Similarity Score:\n* (2) It gives us another view to look into the dataset. We found some Series of books by using the above method. For example: heroes of olympus,harry potter, heroes of olympus, diary of a wimpy kid, dog man, etc. This gives us another perspective to drive into the dataset.","metadata":{}},{"cell_type":"markdown","source":"We can change the book name, if we want to explore the data in the perspective of book name. \nHere, I just leave it unchanged now.","metadata":{}},{"cell_type":"markdown","source":"I made some changes to the above code.\nWe can now find the similar authors' names by the following code:","metadata":{}},{"cell_type":"code","source":"# Find all the Unique names, and transform to lower case:\nunique_name = df_new.Author.unique()\nunique_name = [word.lower() for word in unique_name]\n# Vectorize words into vectors:\ncount_vectorizer = CountVectorizer(ngram_range=(1, 3))\nsparse_matrix = count_vectorizer.fit_transform(unique_name)\n\n# Calculate the similarity between each other\nresult = (cosine_similarity(sparse_matrix, sparse_matrix))\n\n# Only get similar names with score > 0.7 and < 1. \n# Similarity Score is a hyperparameter can be set by ourselves.\n# I have tried several similarity score. 0.7 give a good result.\nsimilar_name = np.argwhere(result > 0.7)\nsimilar_name_filter = similar_name[similar_name[:,0] != similar_name[:,1]]\n\n# Some result is repeated. The below code filter them out\nsimilar_name_filter_not_repeat = similar_name_filter[similar_name_filter[:,1] > similar_name_filter[:,0]]\n\n# Make a dataframe for easier comparison\nleft = np.array(similar_name_filter_not_repeat[:,0])\nright = np.array(similar_name_filter_not_repeat[:,1])\ndf_similar = pd.DataFrame({'col1': np.take(unique_name, left), 'col2': np.take(unique_name, right)}) ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-04T05:23:28.666199Z","iopub.execute_input":"2021-06-04T05:23:28.666629Z","iopub.status.idle":"2021-06-04T05:23:28.685762Z","shell.execute_reply.started":"2021-06-04T05:23:28.666601Z","shell.execute_reply":"2021-06-04T05:23:28.684502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_similar","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:23:28.687054Z","iopub.execute_input":"2021-06-04T05:23:28.687317Z","iopub.status.idle":"2021-06-04T05:23:28.701779Z","shell.execute_reply.started":"2021-06-04T05:23:28.687292Z","shell.execute_reply":"2021-06-04T05:23:28.70109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correct the authors' names in the dataframe\n# Remember that authors' names were transformed to lower case. Here, I hard code to change the dataframe.\ndf_new = df_new.replace([\"George R. R. Martin\", \"J. K. Rowling\"], [\"George R.R. Martin\",\"J.K. Rowling\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:23:28.702927Z","iopub.execute_input":"2021-06-04T05:23:28.70343Z","iopub.status.idle":"2021-06-04T05:23:28.716105Z","shell.execute_reply.started":"2021-06-04T05:23:28.703398Z","shell.execute_reply":"2021-06-04T05:23:28.715308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"There are {len(df_new.Name.unique())} books and {len(df_new.Author.unique())} arthurs. There are 248 arthurs' names before correction.\")","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:23:28.717159Z","iopub.execute_input":"2021-06-04T05:23:28.7176Z","iopub.status.idle":"2021-06-04T05:23:28.729415Z","shell.execute_reply.started":"2021-06-04T05:23:28.71757Z","shell.execute_reply":"2021-06-04T05:23:28.728662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization","metadata":{}},{"cell_type":"code","source":"# We can see there are different series of books.\n# I use \"dog man series\" as an example and to \n# see if we can find some insight from it.\ndf_new = df_new.reset_index()\nname_list = []\nname_lower = df_new[\"Name\"].apply(lambda x: x.lower())\nfor i in range(len(name_lower)):\n    if \"dog man\" in name_lower[i]:\n        name_list.append(i)\ndf_series = df_new.iloc[name_list, :]","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:23:28.730485Z","iopub.execute_input":"2021-06-04T05:23:28.730913Z","iopub.status.idle":"2021-06-04T05:23:28.74535Z","shell.execute_reply.started":"2021-06-04T05:23:28.730883Z","shell.execute_reply":"2021-06-04T05:23:28.744585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_series","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:23:28.747741Z","iopub.execute_input":"2021-06-04T05:23:28.748208Z","iopub.status.idle":"2021-06-04T05:23:28.768689Z","shell.execute_reply.started":"2021-06-04T05:23:28.748176Z","shell.execute_reply":"2021-06-04T05:23:28.767699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets see how is the performace of the Dog Man series (by comparing with the average review of all books at different years).\nCode:","metadata":{}},{"cell_type":"code","source":"df_series_avg = df_series.groupby([\"Year\"]).mean().reset_index()\ndf_fiction_avg = df[df[\"Genre\"] == \"Fiction\"].groupby([\"Year\", \"Genre\"]).mean()\n\ndf_fiction_avg = df_fiction_avg.reset_index()[[\"Year\", \"Reviews\"]]\ndf_fiction_avg = df_fiction_avg.iloc[-3:]\n\ndf_series_avg[\"Legend\"] = \"Dog Man\"\ndf_fiction_avg[\"Legend\"] = \"Total\"\n\ndog_man_df = pd.concat([df_series_avg, df_fiction_avg])\ndog_man_df = dog_man_df.astype({\"Year\": \"string\"})","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-04T05:23:28.770019Z","iopub.execute_input":"2021-06-04T05:23:28.770291Z","iopub.status.idle":"2021-06-04T05:23:28.794189Z","shell.execute_reply.started":"2021-06-04T05:23:28.770264Z","shell.execute_reply":"2021-06-04T05:23:28.79309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.lineplot(data = dog_man_df, x=\"Year\", y=\"Reviews\", hue=\"Legend\", style=\"Legend\")\nax.set(xlim=(2017, 2019))","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:23:28.795183Z","iopub.execute_input":"2021-06-04T05:23:28.795575Z","iopub.status.idle":"2021-06-04T05:23:28.999561Z","shell.execute_reply.started":"2021-06-04T05:23:28.795542Z","shell.execute_reply":"2021-06-04T05:23:28.998582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, we can take a look at the data in the perspective of author.","metadata":{}},{"cell_type":"code","source":"# First, I find which author had most bestselling books in amazon\ndf_author = df_new.groupby([\"Author\"]).count().reset_index()\ndf_author.sort_values(by=['index']).tail(1)[\"Author\"]","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:23:29.000916Z","iopub.execute_input":"2021-06-04T05:23:29.001321Z","iopub.status.idle":"2021-06-04T05:23:29.017754Z","shell.execute_reply.started":"2021-06-04T05:23:29.001286Z","shell.execute_reply":"2021-06-04T05:23:29.016797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Jeff Kinney published most books that are the bestselling books. Code to draft the figure:","metadata":{}},{"cell_type":"code","source":"JK_df = df_new[df_new[\"Author\"] == \"Jeff Kinney\"]\nJK_df = JK_df.groupby([\"Year\"]).mean()\nJK_df[\"Legend\"] = \"Jeff Kinney\"\nJK_df = JK_df[[\"Legend\", \"User Rating\"]]\nJK_df.reset_index(inplace=True)\n\ndf_fiction_avg = df[df[\"Genre\"] == \"Fiction\"].groupby([\"Year\", \"Genre\"]).mean()\ndf_fiction_avg = df_fiction_avg.reset_index()[[\"Year\", \"User Rating\"]]\ndf_fiction_avg[\"Legend\"] = \"Total\"\n\nJK_df = pd.concat([JK_df, df_fiction_avg])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-04T05:23:29.019564Z","iopub.execute_input":"2021-06-04T05:23:29.020081Z","iopub.status.idle":"2021-06-04T05:23:29.043819Z","shell.execute_reply.started":"2021-06-04T05:23:29.020028Z","shell.execute_reply":"2021-06-04T05:23:29.042672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.lineplot(data = JK_df, x=\"Year\", y=\"User Rating\", hue=\"Legend\", style=\"Legend\")","metadata":{"execution":{"iopub.status.busy":"2021-06-04T05:23:29.045156Z","iopub.execute_input":"2021-06-04T05:23:29.045598Z","iopub.status.idle":"2021-06-04T05:23:29.306305Z","shell.execute_reply.started":"2021-06-04T05:23:29.045563Z","shell.execute_reply":"2021-06-04T05:23:29.305231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Feel free to upvote it if you think this notebook is useful for you! Thank You!","metadata":{}}]}