{"cells":[{"metadata":{"_uuid":"148cee4542473cd6ff1caee9ea31d1a11571f5cc"},"cell_type":"markdown","source":"# Summary\n\n###### I. Exploration\n\n    1.1 Missing values\n    \n    1.2 Number of films per year\n    \n    1.3 Genres\n    \n    1.4 Keywords\n    \n    1.5 IMDB Score\n    \n    1.6 Director name\n    \n    1.7 Movie Facebook likes\n    \n    1.8 Duration, IMDB Score and Language\n\n###### II. Movie Recommender Systems\n\n    1.1 Cleaning\n    \n    1.2 CountVectorizer\n    \n    1.3 KMeans\n    \n    1.4 Recommender System"},{"metadata":{"_uuid":"9c431eb737fb3d96002b9fbb1d268ececbaa8d74"},"cell_type":"markdown","source":"# I. Exploration"},{"metadata":{"trusted":false,"_uuid":"7dfd290f4923bf4daa07330241d5aa9a8f805ede"},"cell_type":"code","source":"#import packages\n\n%matplotlib inline\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom wordcloud import WordCloud, STOPWORDS\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"61b9dcbaf9304bd53707c5a133ca00658874e6b0"},"cell_type":"code","source":"#read data file\ndata = pd.read_csv('../input/movie_metadata.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a324a079fbc3aafa39eaa00a9b327514dc4b226e"},"cell_type":"code","source":"pd.set_option('display.max_columns',None)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"09b609c2b53659e934b82342a3ca826a557abe38"},"cell_type":"code","source":"data.tail(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"659983b0b87463177b27462e76098117498bc1ac"},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa0a5c6669f0b59e8405b67f4624839633d82537"},"cell_type":"markdown","source":"__We have 5043 movies described by 28 variables__"},{"metadata":{"trusted":false,"_uuid":"d3b33c760e8e4193e2f1f109bbc43c956286df20"},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"94fcd266d6d6672cac5f78f716e534f202ca407d"},"cell_type":"markdown","source":"__Some key point from this table\nAvg movie duration is 107.2 minuts\navg imdb is 6.64\navg number of users revies is 272__"},{"metadata":{"trusted":false,"_uuid":"c19690724cbbd366247d0ef1b43d9df28399179a"},"cell_type":"code","source":"data.info(verbose=False)  # check what kind of data are","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7503b66787018a4a5196c685ba2a67bfc3bb8922"},"cell_type":"markdown","source":"__so we have int, float , string all type of mixtures.__"},{"metadata":{"scrolled":true,"trusted":false,"_uuid":"06057fe7130a5e77c96d8e97033a9678667ce479"},"cell_type":"code","source":"#Check how many values are null in each column\ndata[data.columns[:]].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e92f41533622ebc2d5aa2789bda3f83e62d3b0c0"},"cell_type":"code","source":"data[data['imdb_score']>7.5].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fcb88c465c8d6936ef82a984acff4c1d283781cd"},"cell_type":"markdown","source":"__747 out of 5043 movies are having more than 7.5 imdb rating.\nGenrally people watch this king of rating movies__"},{"metadata":{"trusted":false,"_uuid":"563d2b0fc118776a195e5dec533c1ef814e7ebfd"},"cell_type":"code","source":"plt.rcParams['figure.figsize']=(18,9)\n\ndata_groupby_ratings = data.groupby(['imdb_score'])['movie_title'].count()\ndata_groupby_ratings.plot()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"48fa80e12cee83216fa64e84fd5535c01383a4c0"},"cell_type":"markdown","source":"__we can see more than 200  movies have rating of around 6.5__"},{"metadata":{"trusted":false,"_uuid":"8a31afc7b4f63b5848843d0550871221e5833cfd"},"cell_type":"code","source":"data_groupby_duration = data.groupby(['duration'])['movie_title'].count()\ndata_groupby_duration.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d85b9762f2bb9809280dd3b98e7b4b5d3c3b2e3f"},"cell_type":"code","source":"data[data['duration'] <= 100].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"24dcf8ff1ea4acf356406faadb4e89e08aab4ead"},"cell_type":"code","source":"data[data['duration'] >= 180].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"41a684b07b8c1ef6af264b8e774fd5619b873aa6"},"cell_type":"markdown","source":"__68 movies have time duration more than equal to 3 hr.\naverage movie time duration is 107 min__"},{"metadata":{"scrolled":true,"trusted":false,"_uuid":"3d6c09dccde5804a008a0d8a267a8843646b8293"},"cell_type":"code","source":"# use a visualization to detect whether there is a relationship between duration and star rating\ndata.boxplot(column='duration', by='imdb_score');","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"fa1ead1e5f88189edf583210099e3dcafd3c6906"},"cell_type":"code","source":"# visualize the relationship between content rating and duration\ndata.boxplot(column='duration', by='content_rating')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"cbfae5e7f1d2ebbf8a85be3314d02f9e794b5e5b"},"cell_type":"code","source":"data['language'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"bd632fa4650dbf2d00cabd4865b49f465aa61314"},"cell_type":"code","source":"sns.set(style=\"darkgrid\")\nplt.figure(figsize = (12, 6))\nsns.countplot(x=\"language\", data = data)\nax = plt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"23921d35471ca75791377f47bf2cba8e909a2f84"},"cell_type":"code","source":"sns.set(style=\"darkgrid\")\nsns.countplot(x=\"color\", data = data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f3c542cbb20e23a927b9460db873dca55d46e90"},"cell_type":"markdown","source":"__Many movies are in English and in color__"},{"metadata":{"trusted":false,"_uuid":"d5bfcdfaff238ca738ef881e5d25be1a0f4ab3cb"},"cell_type":"code","source":"# plot title year vs gross\ndata_groupby_gross = data.groupby(['title_year'])['gross'].count()\ndata_groupby_gross.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"7a0e00e8dfad9acef098ec7efcf13a3f7459b2b5"},"cell_type":"code","source":"#ploting buget vs title_year\ndata_groupby_gross = data.groupby(['title_year'])['budget'].count()\ndata_groupby_gross.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"06db7e79494abac7769e1bf1ecb7177142fb1f5e"},"cell_type":"code","source":"data[data['language'] == 'English'].shape[0] # number of english movies","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8df0febc5fdb3b2912e825ba293cb194ffdeb937"},"cell_type":"markdown","source":"__4704 movies are in english__"},{"metadata":{"_uuid":"fc17a656a1a95696b68bcf5f1c9fded683d3636a"},"cell_type":"markdown","source":"# top 10 imdb rating movies "},{"metadata":{"trusted":false,"_uuid":"595d63b33458e8faf6a12134b568d7cee268d7f0"},"cell_type":"code","source":"highest_imdb = data.sort_values('imdb_score', ascending = False)\nhigh = highest_imdb.loc[:,['movie_title', 'imdb_score','title_year', 'language', 'country', 'budget', 'director_name', 'duration', 'gross' ]]\nhigh.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"c539fce7a40b353acfb5b3472c6a7433ce58a20a"},"cell_type":"code","source":"#French top 5 rated movies\nfrench = high[high['language']== 'French']\nfrench.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0d1288eba4378e81ea3ab47d98c0c97fb91b3af1"},"cell_type":"markdown","source":"###### 1.1. Missing Values"},{"metadata":{"_uuid":"14b8abf5030517ad5c991e4dc2e95b2618e3ad14"},"cell_type":"markdown","source":"__As in every analysis, at some point, we will have to deal with the missing values and as a first step, I determine the amount of data which is missing in every variable:__"},{"metadata":{"scrolled":true,"trusted":false,"_uuid":"77815273f7423d111b4180c94aab6bd139cb6993"},"cell_type":"code","source":"#find proportion of missing values\nprop_missing = round((data[data.columns[:]].isnull().sum()/data.shape[0])*100,2)\nprop_missing","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false,"_uuid":"72bcaa93e311a2f1f514c78170c4e896465df36a"},"cell_type":"code","source":"col_filling = []\nfor s in data.columns:\n    ratio = (len(data[s])-data[s].isnull().sum()) / len(data[s])*100\n    number = data[s].notnull().sum()\n    col_filling.append([ratio, s, number])\ncol_filling.sort(key = lambda x:x[0])\n#------------------------------------\nfor ratio, s, number in col_filling:\n    print(\"{:<30} -> {:<6}%\".format(s, round(ratio,2)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"294582364e2bff41df39438be0d099d811823fd8"},"cell_type":"markdown","source":"__We can see that most of the variables are well filled since only 2 of them have a filling factor below 93%.__"},{"metadata":{"trusted":false,"_uuid":"747bf6d495a32c2168a01778492c77af98349489"},"cell_type":"code","source":"#Remove the missing data with title year missing\nclean_data = data[data.title_year.notnull() & data.duration.notnull()]\nlen(clean_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"40d5eb00f58d3c3dfaaecea0cb31fc2e69ee5085"},"cell_type":"code","source":"clean_data.loc[:, 'title_year'] = clean_data['title_year'].astype(int).astype(str)\nclean_data.loc[:, 'year'] = pd.to_datetime(clean_data['title_year'], format='%Y')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"724d99809ecce6cc6c1cf75bbcf33a032bb2cf2b"},"cell_type":"code","source":"#describe the dataset\nclean_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fbe2ffc98126ca27bbfc3c98706444178d4b0c6a"},"cell_type":"markdown","source":"###### 1.2 Number of films per year\n\nThe variable 'title_year' deals with the year the films came out. In order to have a global look at the way films are distributed according to this variable, I group the films by decades:"},{"metadata":{"trusted":false,"_uuid":"06b1f5cb64e5ade4b0179f0a4592f9b873379b0f"},"cell_type":"code","source":"#Get data required for the plot\ndf_1 = clean_data[['title_year', 'movie_title']]\nser = df_1.groupby(df_1.title_year.astype(int) // 10 * 10).size()\ndf = pd.DataFrame({'decade':ser.index, 'movies':ser.values})","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"aabef9c7ac6bc36de06e93312dad9c0da2e85092"},"cell_type":"code","source":"#Plot using plt.subplots\nfig,ax = plt.subplots()\nax.bar(df.decade, df.movies, width=2.6, color='b')\nax.set_xticks(df.decade+1.3)  # set the x ticks to be at the middle of each bar since the width of each bar is 2.6\nax.set_xticklabels(df.decade)  #replace the name of the x ticks with your Groups name\nax.grid(False) #remove gridlines\nplt.xlabel('Decade', fontsize=16)\nplt.ylabel('No of movies released', fontsize=16)\nplt.title('Movies released by decade', fontsize=24)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d09fbb7c10a00e66eb253cd4b38bccc71b7149d4"},"cell_type":"markdown","source":"__This shows a growing trend of movies created every decade. The amount of movies created is growing exponentially. The last decade data is only available for 4 years (2010-2014) so it obviously shows a drop in movies created in the last decade__"},{"metadata":{"trusted":false,"_uuid":"6a3ff4e2eef7740228b04d8c5c5625565479fd24"},"cell_type":"code","source":"data['decade'] = data['title_year'].apply(lambda x:((x-1900)//10)*10)\n#__________________________________________________________________\n# function that extract statistical parameters from a grouby objet:\ndef get_stats(group):\n    return {'min': group.min(), 'max': group.max(),\n            'count': group.count(), 'mean': group.mean()}\n#______________________________________________________________\n# Creation of a dataframe with statitical infos on each decade:\ntest = data['title_year'].groupby(data['decade']).apply(get_stats).unstack()['decade'] = data['title_year'].apply(lambda x:((x-1900)//10)*10)\n#__________________________________________________________________\n# function that extract statistical parameters from a grouby objet:\ndef get_stats(group):\n    return {'min': group.min(), 'max': group.max(),\n            'count': group.count(), 'mean': group.mean()}\n#______________________________________________________________\n# Creation of a dataframe with statitical infos on each decade:\ntest = data['title_year'].groupby(data['decade']).apply(get_stats).unstack()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb83cbfe6535b01a2c25974681471a6c9ed3a8f5"},"cell_type":"markdown","source":"__I represent the results in a pie chart:__"},{"metadata":{"trusted":false,"_uuid":"5d56f92b7fa83e8deaf3324a01b6958eb252f07e"},"cell_type":"code","source":"sns.set_context(\"poster\", font_scale=0.85)\n#_______________________________\n# funtion used to set the labels\ndef label(s):\n    val = (1900 + s, s)[s < 100]\n    chaine = '' if s < 50 else \"{}'s\".format(val)\n    return chaine\n#    if s < 50:        \n#        return ''\n#    elif s < 100:\n#        return \"{}'s\".format(int(s))\n#    else:\n#        return \"{}'s\".format(int(1900+s))\n#____________________________________\nplt.rc('font', weight='bold')\nf, ax = plt.subplots(figsize=(14, 6))\nlabels = [label(s) for s in  test.index]\nsizes  = test['count'].values\nexplode = [0.2 if sizes[i] < 100 else 0.01 for i in range(11)]\nax.pie(sizes, explode = explode, labels=labels,\n       autopct = lambda x:'{:1.0f}%'.format(x) if x > 1 else '',\n       shadow=False, startangle=0)\nax.axis('equal')\nax.set_title('% of films per decade',\n             bbox={'facecolor':'k', 'pad':5},color='w', fontsize=16);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9fd2748c4cc1748a5c1410ee6f7f371f3b18d0ec"},"cell_type":"markdown","source":"###### 1.3 Genres\n\nThe __genres__ variable describes the content of the film (i.e. Drama, Comedy, Action, ...). To see exactly which genres are the most popular, I use the same approach than for the keywords (hence using similar lines of code), first making a census of the genres:"},{"metadata":{"trusted":false,"_uuid":"ca0b49ac1f062565e75a91b18e307a5ac4c92f04"},"cell_type":"code","source":"genre_labels = set()\nfor s in data['genres'].str.split('|').values:\n    genre_labels = genre_labels.union(set(s))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c7f749de57f46a8c312e4e7b0d2135aecd2db71"},"cell_type":"markdown","source":"and then counting how many times each of them occur:"},{"metadata":{"trusted":false,"_uuid":"95a636eea19328ab2da37c83eaf85b55a641a0be"},"cell_type":"code","source":"def count_word(df, ref_col, liste):\n    keyword_count = dict()\n    for s in liste: keyword_count[s] = 0\n    for liste_keywords in df[ref_col].str.split('|'):\n        if type(liste_keywords) == float and pd.isnull(liste_keywords): continue\n        for s in liste_keywords: \n            if pd.notnull(s): keyword_count[s] += 1\n    #______________________________________________________________________\n    # convert the dictionary in a list to sort the keywords by frequency\n    keyword_occurences = []\n    for k,v in keyword_count.items():\n        keyword_occurences.append([k,v])\n    keyword_occurences.sort(key = lambda x:x[1], reverse = True)\n    return keyword_occurences, keyword_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a954598d3c0bad691aeeca78e95d0a1c9b2a4e3b"},"cell_type":"code","source":"keyword_occurences, dum = count_word(data, 'genres', genre_labels)\nkeyword_occurences[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"657fd4b7343421c827be041891b25dc08234e4c6"},"cell_type":"code","source":"# Function that control the color of the words\n\ndef random_color_func(word=None, font_size=None, position=None,\n                      orientation=None, font_path=None, random_state=None):\n    h = int(360.0 * tone / 255.0)\n    s = int(100.0 * 255.0 / 255.0)\n    l = int(100.0 * float(random_state.randint(70, 120)) / 255.0)\n    return \"hsl({}, {}%, {}%)\".format(h, s, l)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"af6ee37d49ad4b65d8a80804e90dc79215cee7d7"},"cell_type":"markdown","source":"Finally, the results is shown as a wordcloud:"},{"metadata":{"trusted":false,"_uuid":"87a3fbd8c86b32ec7b5acfc884b5aa061c29159e"},"cell_type":"code","source":"words = dict()\ntrunc_occurences = keyword_occurences[0:50]\nfor s in trunc_occurences:\n    words[s[0]] = s[1]\ntone = 100 # define the color of the words\nf, ax = plt.subplots(figsize=(14, 6))\nwordcloud = WordCloud(width=550,height=300, background_color='black', \n                      max_words=1628,relative_scaling=0.7,\n                      color_func = random_color_func,\n                      normalize_plurals=False)\nwordcloud.generate_from_frequencies(words)\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad4c4e18bf2a04a8106d0132a806cbf97ff0940e"},"cell_type":"markdown","source":"###### 1.4 Keywords\n\nI think, a basic assumption is that films described by similar keywords should have similar contents. Hence, I plan to have a close look at the way keywords are defined and as a first step, I quickly characterize what's already in there. To do so, I first list the keywords which are in the dataset:"},{"metadata":{"trusted":false,"_uuid":"766fb60ccc7aae56258952047227a20615635a21"},"cell_type":"code","source":"set_keywords = set()\nfor liste_keywords in data['plot_keywords'].str.split('|').values:\n    if type(liste_keywords) == float: continue  # only happen if liste_keywords = NaN\n    set_keywords = set_keywords.union(liste_keywords)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"7e84fd47ad95437b8964e0b7e1f787295d595ae7"},"cell_type":"code","source":"keyword_occurences, dum = count_word(data, 'plot_keywords', set_keywords)\nkeyword_occurences[:5]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d335d46fe2d9c6181c968fca542a9d2d48d14060"},"cell_type":"markdown","source":"At this stage, the list of keywords has been created and we know the number of times each of them appear in the dataset. In fact, this list can be used to have a feeling of the content of the most popular movies. A fancy manner to give that information makes use of the wordcloud package. In this kind of representation, all the words are arranged in a figure with sizes that depend on their respective frequencies. Instead of a wordcloud, we can use histograms to give the same information. This allows to have a figure where the keywords are ordered by occurence and most importantly, this gives the number of times they appear, an information that can not be retrieved from the wordcloud representation. In the following figure, I compare both types of representations:"},{"metadata":{"trusted":false,"_uuid":"795e3f180b8e55b376ca18f083720500b1db8e8c"},"cell_type":"code","source":"#_____________________________________________\n# UPPER PANEL: WORDCLOUD\nfig = plt.figure(1, figsize=(18,13))\nax1 = fig.add_subplot(2,1,1)\n#_______________________________________________________\n# I define the dictionary used to produce the wordcloud\nwords = dict()\ntrunc_occurences = keyword_occurences[0:50]\nfor s in trunc_occurences:\n    words[s[0]] = s[1]\ntone = 55.0 # define the color of the words\n#________________________________________________________\nwordcloud = WordCloud(width=1000,height=300, background_color='black', \n                      max_words=1628,relative_scaling=1,\n                      color_func = random_color_func,\n                      normalize_plurals=False)\nwordcloud.generate_from_frequencies(words)\nax1.imshow(wordcloud, interpolation=\"bilinear\")\nax1.axis('off')\n#_____________________________________________\n# LOWER PANEL: HISTOGRAMS\nax2 = fig.add_subplot(2,1,2)\ny_axis = [i[1] for i in trunc_occurences]\nx_axis = [k for k,i in enumerate(trunc_occurences)]\nx_label = [i[0] for i in trunc_occurences]\nplt.xticks(rotation=85, fontsize = 15)\nplt.yticks(fontsize = 15)\nplt.xticks(x_axis, x_label)\nplt.ylabel(\"Nb. of occurences\", fontsize = 18, labelpad = 10)\nax2.bar(x_axis, y_axis, align = 'center', color='g')\n#_______________________\nplt.title(\"Keywords popularity\",bbox={'facecolor':'k', 'pad':5},color='w',fontsize = 25)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b3e9f5c5f80178128848a33bef8ee3c210a0abdf"},"cell_type":"markdown","source":"###### 1.5 IMDB Score "},{"metadata":{"trusted":false,"_uuid":"f0d2c43c857021e969c58398a0187630ab51a166"},"cell_type":"code","source":"#get data\ntemp2 = clean_data[['title_year', 'imdb_score']]\n#plot\ntemp2 = temp2.groupby(temp2.title_year.astype(int)).imdb_score.mean().plot(kind ='line', grid =False, title ='IMDB Average Score Trend', xlim=((1950, 2016)))\ntemp2.xaxis.set_ticks(np.arange(1950, 2016, 7))\nplt.xlabel('Year', fontsize=18)\nplt.ylabel('Average IMDB Score', fontsize=18)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b5a08802ae9c5e4c26fb44bcfcf63a91cfc59cc"},"cell_type":"markdown","source":"It looks like the average score of movies is decreasing over time, However, this could be due to an increase in no of movies being created over time"},{"metadata":{"_uuid":"008081a7141b57d9f17a9ddc4dd18efb4a097423"},"cell_type":"markdown","source":"Below plot shows comparison of movies created vs average imdb score over time"},{"metadata":{"trusted":false,"_uuid":"ac3054a17cf122e7ab08eb56b28ca1bd45884b29"},"cell_type":"code","source":"#create new table with grouped information\ntemp = clean_data[['title_year', 'imdb_score', 'movie_imdb_link']]\ntemp = temp[temp.title_year.astype(int)>1949]\nres = temp.groupby(temp.title_year.astype(int)).agg({'imdb_score': 'mean', 'movie_imdb_link': 'count'}).reset_index()\nres.columns = ['title_year', 'avg_imdb_score', 'movies_created']\nrows = res.title_year\n\nfig = plt.figure()\nax1 = fig.add_subplot(111)\nax1.plot(res.title_year, res.avg_imdb_score, color = 'blue')\nax1.set_ylabel('Average IMDB Score', color = 'blue')\nax1.set_xlabel('Year')\nax1.grid(False)\n#ax1.legend(loc = 'upper right')\n\n\nax2 = ax1.twinx()\nax2.plot(res.title_year, res.movies_created, color='green')\nax2.set_ylabel('Movies Released', color = 'green')\nax2.grid(False)\nfor tl in ax2.get_yticklabels():\n    tl.set_color('r')\n#ax2.legend(loc = 'upper right')\nplt.title('Avg IMDB Score vs Movies Released ~ Trend')\n\nplt.show()\n#plt.savefig('images/two-scales-5.png')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2612c998e2f4677ce33e161e73d3e8b60612295d"},"cell_type":"markdown","source":"As we can see, the decrease in average movie scores can be attributed to the increase in amount of movies created in recent times, the increase in amount of movies will lead to more outliers affecting the mean for the duration."},{"metadata":{"trusted":false,"_uuid":"542f534ceb13b03225e5f28d80e0589d4f4410a3"},"cell_type":"code","source":"#Get data required for the plot\ntemp = clean_data[['content_rating', 'imdb_score']]\ntemp = temp.groupby(temp.content_rating.astype(str)).imdb_score.mean()\ndf = pd.DataFrame({'Content_Rating':temp.index, 'IMDB_Score':temp.values})\n#sort data by score descending\ndf = df.sort_values(['IMDB_Score'], ascending=[False])\n#plot\ndf.plot('Content_Rating','IMDB_Score', kind='bar')\nplt.tick_params(axis='both', which='major', labelsize=12)\nplt.tick_params(axis='both', which='minor', labelsize=10)\nplt.xticks(rotation=0)\nplt.grid(False)\nplt.xlabel('Content Rating', fontsize=14)\nplt.ylabel('Average IMDB Score', fontsize=14)\nplt.title('Average IMDB Score per Content Rating')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c62bd8ac1580df8c1c15564aacb9decd59cbdf66"},"cell_type":"markdown","source":"Overall, Approved and Passed content has highest score but there isnt much difference in scores for different content rating types, however TV-14 has lowest IMDB Score"},{"metadata":{"_uuid":"22e58bc4607d91cceb44ae3dc90acbd6c166220c"},"cell_type":"markdown","source":"###### 1.6 Director name"},{"metadata":{"trusted":false,"_uuid":"ecca384a1a7da7b2090dc52619e2f1052dfc2d05"},"cell_type":"code","source":"#Get data required for the plot\ntemp = clean_data[['director_name', 'imdb_score']]\ntemp = temp.groupby(temp.director_name.astype(str)).imdb_score.mean()\ndf = pd.DataFrame({'Director_Name':temp.index, 'Avg_IMDB_Score':temp.values})\n#sort data by score descending\ndf = df.sort_values(['Avg_IMDB_Score'], ascending=[False])\ndf = df.head(10)\n#plot while sorting plot\ndf.sort_values('Avg_IMDB_Score').plot('Director_Name','Avg_IMDB_Score', kind='barh')\nplt.tick_params(axis='both', which='major', labelsize=12)\nplt.tick_params(axis='both', which='minor', labelsize=10)\nplt.xticks(rotation=0)\nplt.grid(False)\nplt.xlabel('Director', fontsize=14)\nplt.ylabel('Average IMDB Score', fontsize=14)\nplt.title('Top 10 high scoring directors')\nplt.tight_layout()\nplt.legend().set_visible(False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e422b8ba885885c5b6666ae401b03d3524441de9"},"cell_type":"markdown","source":"###### 1.7 Movie Facebook likes"},{"metadata":{"trusted":false,"_uuid":"b7a91e0ac1b573793414c1f164cf64bea48ef2d4"},"cell_type":"code","source":"##scatterplot average_imdb_score vs movie_facebook_likes\ntemp = clean_data[['movie_facebook_likes', 'imdb_score']]\ntemp = temp[temp.imdb_score > 0]\nx = temp.plot(x='movie_facebook_likes', y = 'imdb_score',kind='scatter', xlim = (0, 100000), title='IMDB Score VS Movie facebook likes', legend=[True])\nplt.tick_params(axis='both', which='major', labelsize=12)\nplt.tick_params(axis='both', which='minor', labelsize=10)\nplt.grid(False)\nplt.xlabel('Movie Facebook Likes', fontsize=14)\nplt.ylabel('Average IMDB Score', fontsize=14)\nplt.title('Movie FB Likes VS IMDB Score')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"3e1bff5f3d3d1fa4fde7781c4508393b07bfccfb"},"cell_type":"code","source":"temp[['imdb_score','movie_facebook_likes']].corr()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e2e3ece741e5eb4d24d043c807e60ace15098005"},"cell_type":"markdown","source":"These is weak positive correlation between imdb score and movie facebook likes"},{"metadata":{"_uuid":"8eae100d82e34057ba5c45590e771d8c396d3145"},"cell_type":"markdown","source":"###### 1.8 Duration, IMDB Score and Language"},{"metadata":{"trusted":false,"_uuid":"2c5e3c8c07ca100cf0fdfd9624380db08233a411"},"cell_type":"code","source":"temp = clean_data[['duration', 'imdb_score']]\ntemp = temp.plot('duration', 'imdb_score', kind ='scatter', title ='Duration VS Mean IMDB Score')\nplt.xlabel('Duration', fontsize=12)\nplt.ylabel('Avg IMDB Score', fontsize=12)\nplt.title('Duration VS Avg IMDB Score')\nplt.grid(False)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"92b2a809a6451196adf9bbbfd8f691e1400aa6b0"},"cell_type":"code","source":"clean_data[['imdb_score','duration']].corr()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4ea287aba6917dc115e4be91a31c63305ecdc87"},"cell_type":"markdown","source":"There is weak positive correlation between imdb_score and duration of movie"},{"metadata":{"trusted":false,"_uuid":"186174895a7b2df8c4a1d4a82975b62f58b85ed9"},"cell_type":"code","source":"temp = clean_data[['duration', 'imdb_score']]\nsns.regplot(x=\"duration\", y=\"imdb_score\", data=temp);\nplt.xlabel('Duration', fontsize=12)\nplt.ylabel('Avg IMDB Score', fontsize=12)\nplt.title('Duration VS Avg IMDB Score')\nplt.grid(False)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ed34aaffeb5de558e6a3b22b9ba7966db8de882"},"cell_type":"markdown","source":"This shows that there is weak positive correlation between imdb_score and duration, we can use this to find an optimum range of duration that gives the best scores."},{"metadata":{"trusted":false,"_uuid":"9bb1bc5a13902e502ad3a975ba8fc83301455dc9"},"cell_type":"code","source":"temp = clean_data[['language', 'duration', 'title_year']]\ntemp1 = temp[temp.title_year.astype(int) >= 2000]\ntemp1 = temp1.loc[temp1['language'].isin(['English','Hindi'])]\n# temp1 = temp1[temp1.language == 'English' | temp1.language == 'Hindi']\ntemp1.groupby(temp1.language).duration.mean().plot(kind='bar')\nplt.xticks(rotation=0)\nplt.xlabel('Language')\nplt.ylabel('Avg Duration')\nplt.title('Duration of movie by Language')\nplt.grid(False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"46405a0c6dce160dd146da8771a5a43a69bdca1d"},"cell_type":"code","source":"hindi = temp1[temp1.language == 'Hindi']\nenglish = temp1[temp1.language == 'English'] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d5c172b7e7630b516f04160d79e0c5ab658dea0d"},"cell_type":"code","source":"print(\"The dataset has {} Hindi and {} English movies\".format(len(hindi), len(english)) )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8788c919163cd02e600f34d7117dc5df05ea6c69"},"cell_type":"markdown","source":"As we can see from the above plot, Hindi movies are longer than English movies, however the Hindi movie dataset only has 26 movies while the English movie dataset has 3308 movies (all realeased since year 2000). We need more data for Hindi movies in order to draw a comparison. Below we plot the histogram for these two datasets:"},{"metadata":{"trusted":false,"_uuid":"d6af469369c8bb55a5d27b1733a2894186a1699f"},"cell_type":"code","source":"#plot histogram for hindi movie durations\nhindi.duration.plot(kind='hist',color='0.5', bins = 10, title = 'Histogram for duration of Hindi movies').set_xlabel('Duration')\nhindi_mean = round(hindi[\"duration\"].mean(),2)\nhindi_sd = round((hindi[\"duration\"]).std(),2)\nprint(\"The mean duration of the Hindi movies is {} and standard deviation is {}\".format(hindi_mean, hindi_sd))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"2920c5aa68809eae69b3feae761f2c60c31edc0c"},"cell_type":"code","source":"#plot histogram for english movie durations\nenglish.duration.plot(kind='hist',color='0.5', bins = 10, title = 'Histogram for duration of English movies').set_xlabel('duration')\nenglish_mean = round(english[\"duration\"].mean(),2)\nenglish_sd = round((english[\"duration\"]).std(),2)\nprint(\"The mean duration of the English movies is {} and standard duration is {}\".format(english_mean, english_sd) )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce4bbf11966a7131a6b9bd3451c90531720a3e20"},"cell_type":"markdown","source":" - We see that the amount of movies created over time is increasing exponentially while the average IMDB score for the movies is decreasing over time\n - We see a positive correlation between IMDB Score and Movie facebook likes and between Duration of movie and its IMDB Score\n - We see a difference in mean duration of movies created since 2000 between groups of Hindi and English movies, this leads of us formulate a Hypothesis test to test if the durations are similar between the groups or not"},{"metadata":{"_uuid":"8f401c4bea78c298228b8115a39d6ee9f24a957c"},"cell_type":"markdown","source":"# II. Movie Recommender Systems"},{"metadata":{"trusted":false,"_uuid":"42a91de4b3d95152872c9fe4f93ef660fba8f76f"},"cell_type":"code","source":"data_use = data.loc[:,['genres','plot_keywords','movie_title','actor_1_name',\n                      'actor_2_name','actor_3_name','director_name','imdb_score']]\n\ndata_use['movie_title'] = [i.replace(\"\\xa0\",\"\") for i in list(data_use['movie_title'])]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6df790a7dcdfc861dad54e51e9e30613322dd4cd"},"cell_type":"markdown","source":"###### 1.1 Cleaning"},{"metadata":{"trusted":false,"_uuid":"c84e296aa00577bd6e4be73a6a510df02d4639d3"},"cell_type":"code","source":"print(data_use.shape)\nclean_data = data_use.dropna(axis = 0)\nprint(clean_data.shape)\nclean_data = clean_data.drop_duplicates(['movie_title'])\nclean_data = clean_data.reset_index(drop=True)\nprint(clean_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"23c4a7b1eb5b48d7fc4528a71731574a79bacc96"},"cell_type":"code","source":"people_list = []\nfor i in range(clean_data.shape[0]):\n    name1 = clean_data.loc[i,'actor_1_name'].replace(\" \",\"_\")\n    name2 = clean_data.loc[i,'actor_2_name'].replace(\" \",\"_\")\n    name3 = clean_data.loc[i,'actor_3_name'].replace(\" \",\"_\")\n    name4 = clean_data.loc[i,'director_name'].replace(\" \",\"_\")\n    people_list.append(\"|\".join([name1,name2,name3,name4]))\nclean_data['people'] = people_list","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"92b00a128549fb0d9bc4a911c704bb878c4afa1a"},"cell_type":"markdown","source":"###### 1.2 CountVectorizer"},{"metadata":{"trusted":false,"_uuid":"935d338691aeabb39738565747d8b1ae039a4223"},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\ndef token(text):\n    return(text.split(\"|\"))\n\n\ncv_kw=CountVectorizer(max_features=100,tokenizer=token )\nkeywords = cv_kw.fit_transform(clean_data[\"plot_keywords\"])\nkeywords_list = [\"kw_\" + i for i in cv_kw.get_feature_names()]\n\ncv_ge=CountVectorizer(tokenizer=token )\ngenres = cv_ge.fit_transform(clean_data[\"genres\"])\ngenres_list = [\"genres_\"+ i for i in cv_ge.get_feature_names()]\n\ncv_pp=CountVectorizer(max_features=100,tokenizer=token )\npeople = cv_pp.fit_transform(clean_data[\"people\"])\npeople_list = [\"pp_\"+ i for i in cv_pp.get_feature_names()]\n\ncluster_data = np.hstack([keywords.todense(),genres.todense(),people.todense()*2])\ncriterion_list = keywords_list+genres_list+people_list","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"24b4e6be276ad812391fc1bfd2e28a05ca7f99f4"},"cell_type":"markdown","source":"###### 1.3 KMeans"},{"metadata":{"trusted":false,"_uuid":"23c84618f1f5e0d9d9c989e30fe64016f7a3b9f7"},"cell_type":"code","source":"from sklearn.cluster import KMeans\n\nmod = KMeans(n_clusters=100)\ncategory = mod.fit_predict(cluster_data)\ncategory_dataframe = pd.DataFrame({\"category\":category},index = clean_data['movie_title'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d135496152fb21a62de9049a747efb54e818703e"},"cell_type":"code","source":"clean_data.loc[list(category_dataframe['category'] == 0),['genres','movie_title','people']]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e6abd9ebe948ad408fc2a4d3d6c3c9429777a123"},"cell_type":"markdown","source":"###### 1.4 Recommender System"},{"metadata":{"trusted":false,"_uuid":"3d0d83436af4b8953f0e15bd58909ed25e262973"},"cell_type":"code","source":"def recommend(movie_name,recommend_number = 5):\n    if movie_name in list(clean_data['movie_title']):\n        movie_cluster = category_dataframe.loc[movie_name,'category']\n        score = clean_data.loc[list(category_dataframe['category'] == movie_cluster),['imdb_score','movie_title']]\n        sort_score = score.sort_values(['imdb_score'],ascending=[0])\n        sort_score = sort_score[sort_score['movie_title'] != movie_name]\n        recommend_number = min(sort_score.shape[0],recommend_number)\n        recommend_movie = list(sort_score.iloc[range(recommend_number),1])\n        print(recommend_movie)\n    else:\n        print(\"Can't find this movie!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a29ca226fefa0fb3244a725efafe9a30a30054cb"},"cell_type":"code","source":"recommend('Avatar')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":1}