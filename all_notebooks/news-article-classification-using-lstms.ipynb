{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score\nfrom mlxtend.plotting import plot_confusion_matrix\n\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, GlobalMaxPooling1D, Bidirectional\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.utils import plot_model\n\nphysical_devices = tf.config.list_physical_devices('GPU')\ntf.config.experimental.set_memory_growth(physical_devices[0], enable=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load and prep data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"TRAIN_FILE_PATH = '/kaggle/input/ag-news-classification-dataset/train.csv'\nTEST_FILE_PATH = '/kaggle/input/ag-news-classification-dataset/test.csv'\n\ndata = pd.read_csv(TRAIN_FILE_PATH)\ntestdata = pd.read_csv(TEST_FILE_PATH)\n\nX_train = data['Title'] + \" \" + data['Description'] # Combine title and description (better accuracy than using them as separate features)\ny_train = data['Class Index'].apply(lambda x: x-1).values # Class labels need to begin from 0\n\nx_test = testdata['Title'] + \" \" + testdata['Description'] # Combine title and description (better accuracy than using them as separate features)\ny_test = testdata['Class Index'].apply(lambda x: x-1).values # Class labels need to begin from 0\n\nmaxlen = X_train.map(lambda x: len(x.split())).max() # max length of sentences in train dataset\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tokenize and pad loaded text","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = 10000 # arbitrarily chosen\nembed_size = 32 # arbitrarily chosen\n\n# Create and fit tokenizer\ntok = Tokenizer(num_words=vocab_size)\ntok.fit_on_texts(X_train.values)\n\n# Tokenize data\nX_train = tok.texts_to_sequences(X_train)\nx_test = tok.texts_to_sequences(x_test)\n\n# Pad data\nX_train = pad_sequences(X_train, maxlen=maxlen)\nx_test = pad_sequences(x_test, maxlen=maxlen)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(vocab_size, embed_size, input_length=maxlen))\nmodel.add(Bidirectional(LSTM(128, return_sequences=True))) # bidirectional LSTMs since this isn't a timeseries problem\nmodel.add(Bidirectional(LSTM(64, return_sequences=True)))\nmodel.add(GlobalMaxPooling1D())\nmodel.add(Dense(1024))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(512))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(256))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(4, activation='softmax'))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Compile and fit model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks = [\n    EarlyStopping(\n        monitor='val_accuracy',\n        min_delta=1e-4,\n        patience=4,\n        verbose=1\n    ),\n    ModelCheckpoint(\n        filepath='weights.h5',\n        monitor='val_accuracy', \n        mode='max', \n        save_best_only=True,\n        save_weights_only=True,\n        verbose=1\n    )\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # sparse categorical crossentropy loss because data is not one-hot encoded\nmodel.fit(X_train, y_train, batch_size=256, validation_data=(x_test, y_test), epochs=20, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load weights with best val accuracy","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('weights.h5')\nmodel.save('model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test model with some arbitrary data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['World News', 'Sports News', 'Business News', 'Science-Technology News']\n\ntest = ['New evidence of virus risks from wildlife trade', 'Coronavirus: Bank pumps £100bn into UK economy to aid recovery', \n        'Trump\\'s bid to end Obama-era immigration policy ruled unlawful', 'David Luiz’s future with Arsenal to be decided this week']\ntest_seq = pad_sequences(tok.texts_to_sequences(test), maxlen=maxlen)\ntest_preds = [labels[np.argmax(i)] for i in model.predict(test_seq)]\n\nfor news, label in zip(test, test_preds):\n    print('{} - {}'.format(news, label))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plot confusion matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = [np.argmax(i) for i in model.predict(x_test)]\ncm  = confusion_matrix(y_test, preds)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(16,12), hide_ticks=True, cmap=plt.cm.Blues)\nplt.xticks(range(4), labels, fontsize=12)\nplt.yticks(range(4), labels, fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get precision and recall scores","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Recall of the model is {:.2f}\".format(recall_score(y_test, preds, average='micro')))\nprint(\"Precision of the model is {:.2f}\".format(precision_score(y_test, preds, average='micro')))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}