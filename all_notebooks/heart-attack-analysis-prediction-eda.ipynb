{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.set()\nimport matplotlib.pyplot as plt ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_o2 = pd.read_csv('/kaggle/input/heart-attack-analysis-prediction-dataset/o2Saturation.csv')\ndf_o2.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(df_o2.iloc[:, 0].values, 'o')\nplt.xlabel('id')\nplt.ylabel('SPO2')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/heart-attack-analysis-prediction-dataset/heart.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(df['output'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# let us see the correlation table ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(32, 16))\nheatmap = sns.heatmap(df.corr(), vmin=-1, vmax=1, annot=True)\n\nheatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# select x: input features\n\n# and y: output ","metadata":{}},{"cell_type":"code","source":"x = df.drop(columns= ['output' ]).values\ny = df['output'].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ANOVA feature selection for numeric input and categorical output\nfrom sklearn.datasets import make_classification\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\n# define feature selection: 8 from the correlation table\nfs = SelectKBest(score_func=f_classif, k=8)\n# apply feature selection\nX_selected = fs.fit_transform(x, y)\nprint(X_selected.shape)\nfrom sklearn import svm\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# devide the dataset into training and testing dataset","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.33, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# calculate the class weights","metadata":{}},{"cell_type":"code","source":"# class weight \n(len(y_train) / (2 * np.bincount(y_train)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# initiate the model","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclf1 = RandomForestClassifier(n_estimators=100, max_depth=30, random_state=0, min_samples_split=4,class_weight={0:1.05729167, 1:0.94859813} )\nclf1.fit(X_train, y_train)\n\n# for testing \ny_predicted1 = clf1.predict(X_test)\nprint('testing accuracy: ', accuracy_score(y_test, y_predicted1))\n\n#\nprint('confusion martrix: ')\n\n\n\n\nplt.figure(figsize=(14,4))\nplt.subplot(121)\nheatmap = sns.heatmap(confusion_matrix(y_test, y_predicted1), annot=True)\n\nheatmap.set_title('confusion  matrix for testing', fontdict={'fontsize':12}, pad=12);\n\n\n\n\n# for training dataset\n\ny_predicted1 = clf1.predict(X_train)\nprint('training accuracy: ', accuracy_score(y_train, y_predicted1))\n\n#\nprint('confusion martrix: ')\n\n#plt.figure(figsize=(4,4))\nplt.subplot(122)\nheatmap = sns.heatmap(confusion_matrix(y_train, y_predicted1), annot=True)\n\nheatmap.set_title('confusion  matrix for training', fontdict={'fontsize':12}, pad=12);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fine tune the model further: Randomized search","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nfrom pprint import pprint\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 20, stop = 200, num = 5)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(1, 45, num = 3)]\n# Minimum number of samples required to split a node\nmin_samples_split = [5, 10]\n\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split}\n\npprint(random_grid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use the random grid to search for best hyperparameters\n\n# Random search of parameters, using 3 fold cross validation, \n# search across 100 different combinations, and use all available cores\nrf_random = RandomizedSearchCV(estimator = clf1, param_distributions = random_grid, n_iter = 10, cv = 10, verbose=2, random_state=42, n_jobs = -1, scoring='neg_mean_squared_error')\n# Fit the random search model\nrf_random.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#now let's how the RMSE changes for each parameter configuration\ncvres2 = rf_random.cv_results_\nfor mean_score, params in zip(cvres2[\"mean_test_score\"], cvres2[\"params\"]):\n    print(np.sqrt(-mean_score), params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_random.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_random.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# for testing \ny_predicted1 = rf_random.best_estimator_.predict(X_test)\nprint('testing accuracy: ', accuracy_score(y_test, y_predicted1))\n\n#\nprint('confusion martrix: ')\n\n\n\n\nplt.figure(figsize=(14,4))\nplt.subplot(121)\nheatmap = sns.heatmap(confusion_matrix(y_test, y_predicted1), annot=True)\n\nheatmap.set_title('confusion  matrix for testing', fontdict={'fontsize':12}, pad=12);\n\n\n\n\n# for training dataset\n\ny_predicted2 = rf_random.best_estimator_.predict(X_train)\nprint('training accuracy: ', accuracy_score(y_train, y_predicted2))\n\n#\nprint('confusion martrix: ')\n\nplt.subplot(122)\nheatmap = sns.heatmap(confusion_matrix(y_train, y_predicted2), annot=True)\n\nheatmap.set_title('confusion  matrix for training', fontdict={'fontsize':12}, pad=12);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}