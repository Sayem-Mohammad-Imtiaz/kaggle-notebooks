{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Customer Segmentation by RFM model and K-Means\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;It was my first day as a data analyst in a cosmetics online store. My supervisor sent me a link to a shared folder that contained 5 medium-sized csv files. “We may launch a marketing campaign soon, take a look at these files and see if you can group our customers,” he said to me a few minutes before he left for a business trip.\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;After taking a deep breath, I glanced through the files. Each file contained customer behavior data for a month. The data were collected from Oct 2019 to Feb 2020.  Next, I combined these files in python and added a column “month”."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# import modules\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime\nfrom datetime import timedelta\nimport os\n\nimport random\nfrom scipy import stats\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom mpl_toolkits.mplot3d import Axes3D\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# read data\nfiles_csv=[]\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        files_csv.append(os.path.join(dirname, filename))\nframe=[]\nfor i in range(len(files_csv)):\n    df_i=pd.read_csv(files_csv[i])\n    df_i['month']=files_csv[i][-7:-4]\n    frame.append(df_i)\ndf=pd.concat(frame,ignore_index=True,sort=False)\nprint(\"The dataframe has {} rows and {} columns.\\n\".format(df.shape[0],df.shape[1]))\nprint(\"Shown below are the first 3 rows of the dataframe:\\n\")\npd.set_option('display.max_columns', 100)\ndisplay(df.head(3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Part I: Initial Dataset Preparation and Data Exploration"},{"metadata":{},"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Since the goal was to segment customers to help with marketing campaigns, I decided to start with the simple but very effective RFM model. Briefly, the RFM analysis is based on 3 factors – how recently (Recency), how often (Frequency), and how much (Monetary Value) did the customer buy. Next, I selected the rows and columns needed, and cleaned the data."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# data preparation\n\n# step 1: select customers who purchased\ndf_sales=df.loc[df.event_type=='purchase',:]\n\n# step 2: drop \"category_code\", \"brand\", \"product_id\", \"category_id\", and \"user_session\"\ndf_sales=df_sales.drop(columns=['category_code','brand','product_id','category_id','user_session'])\n\n# step 3: drop duplicates\ndf_sales=df_sales.drop_duplicates()\n\n# step 4: convert \"event_time\" to DateTime format\ndf_sales['event_time']=pd.to_datetime(df_sales['event_time'],infer_datetime_format=True)\n\nnullcolumns=df_sales.isnull().sum()\nnullnumbers=len(nullcolumns[nullcolumns!=0])\nprint(\"After data selection and cleansing, the dataframe has {} rows, {} columns, and {} null value.\\n\".format(df_sales.shape[0],df_sales.shape[1],nullnumbers))\nprint(\"Shown below are the first 3 rows of the cleaned dataframe:\\n\")\ndisplay(df_sales.head(3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Initial exploration of the cleaned data showed that (1) the number of customers spiked in Nov 2019 and the end of Jan 2020. There was a big drop in customer numbers on New Year’s Eve; (2) sales went up from ~0.95 million dollars in Oct 2019 to ~1.3 million dollars in Nov 2019, fell to ~0.85 million dollars in Dec 2019, and then remained ~1 million dollars/month in the following 2 months; (3) the average spend per customer didn’t change much over the 5 months."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# initial data exploration\n\nplt.figure(figsize=(10,8))\n\n# plot the number of customers each day \nplt.axes([0.08, 0.4, 0.87, 0.4])\ndf_sales_n_user=df_sales.resample(\"D\",on='event_time')['user_id'].size()\ndf_sales_n_user.plot(kind='line')\nplt.xlabel('')\nplt.ylabel('customer #')\n\n# plot total sales/month \nplt.axes([0.08,0,0.4,0.32])\na=df_sales.resample('M',on='event_time')['price'].sum().to_frame()\na['month']=['Oct','Nov','Dec',\"Jan\\n2020\", \"Feb\"]\na['price']=a['price']/1000000\nsns.barplot(x='month',y='price',data=a,color=\"lightgreen\")\nplt.xlabel('month')\nplt.ylabel('total sales (million $)')\n\n# plot average spend/customer\nplt.axes([0.55,0,0.4,0.32])\ndf_sales_p_day=df_sales.resample('D',on='event_time')['price'].sum()\ndf_sales_spent=df_sales_p_day/df_sales_n_user\ndf_sales_spent.plot(kind='area',color=\"orange\")\nplt.xlabel('date')\nplt.ylabel('average spend/customer ($)');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Next, I grouped the data by user_id, and calculated each customer’s Recency (how many months until Feb 29, 2020 had it been since the customer’s last purchase), Frequency (how often had the customer made a purchase from Oct 2019 to Feb 2020), and Monetary Value(how much did the customer spend from Oct 2019 to Feb 2020). I got this:"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# group the data by \"user_id\", and calcualte each customer's recency, frequency, and monetary value\n\n# step 1: calculate \"Recency\", set Feb 2020 as the reference month, and use \"month\" as the unit\nd=con={\"Oct\":4,\"Nov\":3,\"Dec\":2,\"Jan\":1,\"Feb\":0}\ndf_sales.loc[:,'Recency']=df_sales['month'].map(d)\ndf_R=df_sales.groupby('user_id')['Recency'].min().reset_index().rename(columns={\"0\":\"Recency\"})\n\n# step 2: calculate \"Frequency\"\ndf_F=df_sales.groupby('user_id')['event_type'].count().reset_index().rename(columns={\"event_type\":\"Frequency\"})\n\n# step 3: calculate \"Monetary\"\ndf_M=df_sales.groupby('user_id')['price'].sum().reset_index().rename(columns={\"price\":\"Monetary\"})\n\n# step 4: merge \"Recency\", \"Frequency\", and \"Monetary\"\ndf_RF=pd.merge(df_R,df_F,on='user_id')\ndf_RFM=pd.merge(df_RF,df_M,on='user_id')\n\n# step 5: remove outliers before K-Means clustering\nconditions=np.abs(stats.zscore(df_RFM.loc[:,['Recency','Frequency','Monetary']]) < 3).all(axis=1)\ndf_RFM2=df_RFM.loc[conditions,:]\n\ndf_RFM2.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Initial examination of the RFM data revealed: (1) customers were somewhat evenly distributed along the recency curve; (2) most customers made purchases fewer than 10 times; (3) most customers spent less than 100 dollars."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# visualize the distribution of \"Recency\", \"Frequency\", and \"Monetary\"\nfig,(ax1,ax2,ax3)=plt.subplots(1,3,figsize=(10,4))\n\n# plot \"Recency\"\nax1.hist(df_RFM2['Recency'],bins=5,color='lightsteelblue')\nax1.set_xticks(np.arange(0,5,1))\nax1.set_xlabel('recency (month)')\nax1.set_ylabel('customer #')\n\n# plot \"Frequency\"\nax2.hist(df_RFM2['Frequency'],bins=5,color='lightsteelblue')\nax2.set_xlabel('frequency')\nax2.set_ylabel('customer#')\n\n# plot \"Monetary\"\nax3.hist(df_RFM2['Monetary'],bins=5,color='lightsteelblue')\nax3.set_xlabel('monetary value ($)')\nax3.set_ylabel('customer#')\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Part II: Customer Segmentation by RFM-Based K-Means Clustering"},{"metadata":{},"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Traditionally, in RFM models, each customer is assigned a score for each RFM factor. These scores are then combined and used for segmentation. Inspired by Chen (2012), I decided to do RFM analysis by K-Means clustering. The first thing I did was to find the optimal number of clusters by the elbow method."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# k-means clustering: using recency, frequency, and monetary as clustering varaibles\n\n# step 1: standardize data\ndf_RFM3=df_RFM2.drop(columns=['user_id'])\nX = StandardScaler().fit_transform(df_RFM3)\n\n# step 2: find the optimal number of clusters\nSSE=[]\nfor i in range(1,8,1):\n    kmeans=KMeans(n_clusters=i)\n    kmeans.fit(X)\n    SSE.append(kmeans.inertia_)\nsns.set()\nplt.plot(range(1,8,1),SSE,marker='o')\nplt.xlabel('number of clusters')\nplt.ylabel('squared error') \nplt.title('Optimal number of clusters');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Based on the graph above, I decided to group our customers into 4 clusters. The 3D scatter plot showed that the customers were well separated."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# k-means clustering: using recency, frequency, and monetary as clustering varaibles\n\n# step 3: group customers into 4 clusters\nrandom.seed(8)\nkm=KMeans(n_clusters=4,random_state=0)\nkm.fit(X)\nrandom.seed(8)\npred=km.predict(X)\ndf_RFM2=df_RFM2.assign(clusters=pred)\n\n# step 4: visualize the 4 clusters\n\n# step 4_1: data preparation\nR=[]\nF=[]\nM=[]\nmycolors=['navajowhite','lightsteelblue','mediumaquamarine','thistle']\ncluster_orders=[3,2,0,1]\nfor i in [0,1,2,3]:\n    R.append(df_RFM2.loc[df_RFM2.clusters==cluster_orders[i],'Recency'].values.tolist())\n    F.append(df_RFM2.loc[df_RFM2.clusters==cluster_orders[i],'Frequency'].values.tolist())\n    M.append(df_RFM2.loc[df_RFM2.clusters==cluster_orders[i],'Monetary'].values.tolist())\n    \n# step 4_2: 3D scatter plot\nfig=plt.figure(figsize=(8,5))\nax=Axes3D(fig)\nfor i in [0,1,2,3]:\n    ax.scatter(R[i], F[i], M[i], c=mycolors[i], marker='o',alpha=0.5,label='cluster '+str(cluster_orders[i]))\nax.set_xlabel('Recency')\nax.set_ylabel('Frequency')\nax.set_zlabel('Monetary Value($)')\nax.set_xlim(0,4)\nax.set_xticks(list(range(5)))\nax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I must admit that I’ve never liked 3D graphs. I don’t want to call my customer segments neither “cluster 1” nor “cluster 2”. So, I replaced the old cluster names with more meaning segment names and re-plotted the data."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# replace k-means cluster names with more meaningful names\nd1={0:\"New Customers\", 2:\"Potential Loyalist\", 1: \"At-Risk\", 3:\"Loyal Customers\"}\ndf_RFM2.loc[:,\"segments\"]=df_RFM2.loc[:,\"clusters\"].map(d1)\n\n# calculate the number of customers, median recency, median frequency, \n# and average customer spend in each customer segment\ndf_RFM3=df_RFM2.groupby('segments').agg(Recency=('Recency',np.median),Frequency=('Frequency',np.median),MonetarySum=('Monetary',np.sum),size=(\"clusters\",'size'))\ndf_RFM3.loc[:,'Sales/Customer']=round(df_RFM3.loc[:,'MonetarySum']/df_RFM3.loc[:,'size'])\ndf_RFM3=df_RFM3.astype({'Sales/Customer':int}).reset_index()\n\n# visualize\nplt.figure(figsize=(10,4))\nseg_names=['Loyal Customers','Potential Loyalist','New Customers','At-Risk']\n\n# plot the number of customers in each segment\nsns.set_style(\"white\")\nplt.axes([0, 0, 0.38, 0.9])\nseg=df_RFM2.groupby('segments').size().to_frame().rename(columns={0:'number of customers'}).reset_index()\nsns.barplot(x='number of customers',y='segments',data=seg,order=seg_names,palette=mycolors)\nfor i in [0,1,2,3]:\n    number=int(seg.loc[seg.segments==seg_names[i],'number of customers'])\n    x_pos=round(number,-2)\n    plt.text(x_pos,i,number)\nplt.ylabel(\"\")\nsns.despine()\n\n# plot recency, frequency, and average spend/customer of the 4 segments\nplt.axes([0.5,0,0.42,0.9])\nsns.scatterplot(x='Recency',y='Frequency',hue='segments',hue_order=seg_names,palette=mycolors,size='Sales/Customer',sizes=(200,1000),legend=False,data=df_RFM3)\nplt.ylim(0,35)\nplt.xticks(list(range(5)))\nplt.text(1,29,'average \"Loyal Customer\": $146')\nplt.text(2,16,'average \"Potential Loyalist\": $72')\nplt.text(0,6,'average \"New Customer\": $24')\nplt.text(3,6,'average \"At-Risk\": $24')\nplt.xlabel('Median Recency (month)')\nplt.ylabel('Median Frequency')\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Taken together, our customers were grouped into 4 segments:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1)\tLoyal Customers: These customers purchased very often and spent the highest amount of money. They shopped from Oct 2019 to Feb 2020 with a median recency of 1 month. \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(2)\tPotential Loyalist: This group shopped quite often (though not as frequent as the loyal customers) and spent reasonable amount of money (though not as high as the loyal customers). \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(3)\tNew Customers: I was so surprised that we had such a large group of new customers. They started shopping very recently and as a result, they didn’t make purchases often nor spent much money.\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(4)\tAt-Risk: This is the largest-sized group!!! These customers have high recency, low frequency, and low monetary."},{"metadata":{},"cell_type":"markdown","source":"### Part III: Examine the Relationship between Probability of Purchasing and RFM"},{"metadata":{},"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;As a very curious data analyst, I always like to dig a little deeper. I wanted to find out how a customer’s recency, frequency, and monetary value would affect his or her repurchase probability. To address my own question, I did the following things:\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(1) I calculated the Recency, Frequency, and Monetary Value of each customer using data from Oct 2019 to Jan 2020; \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(2)\nI assigned the customers who made >=1 purchase in Feb 2020 to the “buy” (1) group, and those who didn’t buy in Feb 2020 to the “no-buy” (0) group; \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(3) I grouped the data by recency, frequency, and monetary, respectively, and calculated the percentage of the “buy” group in each recency/frequency/monetary bin; \n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(4) I plotted the percentage (purchase probability in Feb 2020) against recency/frequency/monetary."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# explore the relationship between customers' purchase probability in Feb 2020 and their Recency,Frequency,\n# and Monetary in previous months\n\n# step 1: calculate recency, Frequency, and Monetary in Oct 2019-Jan 2020\ndf_sales1=df_sales.loc[df_sales.month!='Feb',:].copy()\nd={\"Oct\":3,\"Nov\":2,\"Dec\":1,\"Jan\":0}\ndf_sales1.loc[:,'Recency']=df_sales1.loc[:,'month'].map(d)\ndf_sales1_R=df_sales1.groupby('user_id')['Recency'].min().reset_index()\ndf_sales1_F=df_sales1.groupby('user_id')['event_type'].count().reset_index().rename(columns={'event_type':'Frequency'})\ndf_sales1_RF=pd.merge(df_sales1_R,df_sales1_F,on='user_id')\ndf_sales1_M=df_sales1.groupby('user_id')['price'].sum().reset_index().rename(columns={'price':\"Monetary\"})\ndf_sales2=pd.merge(df_sales1_RF,df_sales1_M,on='user_id')\n                   \n# step 2_1: find out customers who made purchases in Feb 2020\ndf_sales_feb_buyers=df_sales.loc[df_sales.month=='Feb','user_id'].unique().tolist()\n\n# step 2_2: combine step 1 and step 2 results and remove outliers\ndf_sales2.loc[:,'Buy']=np.where(df_sales2['user_id'].isin(df_sales_feb_buyers),1,0)\nconditions=np.abs(stats.zscore(df_sales2[['Recency','Frequency','Monetary']]) < 3).all(axis=1)\ndf_sales2=df_sales2.loc[conditions,:]\nprint(\"Shown below are the first 3 rows of the cleaned dataframe:\\n\")\ndisplay(df_sales2.head(3))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Step 3 and 4: calculate and visualize the relationship between the probability of purchasing and RFM \nsns.set()\nplt.figure(figsize=(12,4))\n\n# plot purchase probability and Recency \nplt.axes([0,0,0.25,0.8])\ndf_Buy_R=df_sales2.groupby('Recency').agg(Number=('Buy','count'),Buy=('Buy','sum'))\ndf_Buy_R['Probability']=df_Buy_R['Buy']/df_Buy_R['Number']\nplt.scatter(x=df_Buy_R.index,y=df_Buy_R.Probability)\nplt.xlim(-0.1,4)\nplt.xticks(np.arange(0,4,1))\nplt.xlabel('Recency(month)')\nplt.ylabel('probability of purchase')\n\n# plot purchase probability and Frequency\nplt.axes([0.32,0,0.25,0.8])\ndf_Buy_F=df_sales2.groupby('Frequency').agg(Number=('Buy','count'),Buy=('Buy','sum'))\ndf_Buy_F['Probability']=df_Buy_F['Buy']/df_Buy_F['Number']\nplt.scatter(x=df_Buy_F.index,y=df_Buy_F.Probability,alpha=0.5)\nplt.xlabel('Frequency')\nplt.ylabel('probability of purchase')\n\n# plot purchase probability and Monetary\nplt.axes([0.63,0,0.25,0.8])\ndf_Buy_M=df_sales2.groupby('Monetary').agg(Number=('Buy','count'),Buy=('Buy','sum'))\ndf_Buy_M['Probability']=df_Buy_M['Buy']/df_Buy_M['Number']\nplt.scatter(x=df_Buy_M.index,y=df_Buy_M.Probability,alpha=0.5)\nplt.xlabel('Monetary Value ($)')\nplt.ylabel(\"probability of purchase\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The probability of repurchasing in Feb 2020 increased as the customers’ recency decreased. For example, customers who were active in Jan 2020 had about 4 times as high probability of repurchasing as those who made their last order in Oct 2019. There was somewhat of a linear relationship between the probability of purchase and frequency. Customers with higher number of transactions were more likely to repurchase. However, how much a customer spent over the past 4 months didn’t seem to have any obvious relationships with his or her purchase probability.\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In summary, using the RFM-based K-Means clustering method, I grouped customers into 4 segments: (1) Loyal Customers; (2) Potential Loyalist; (3) New Customers; (4) At-Risk. Additionally, I found a negative association between recency and purchase probability, and a positive relationship between frequency and purchase probability. I hope my work could help our marketing team design effective campaigns.\n\n\n\n\n\n__References__\n\nChen Daqing (2012). Data mining for the online retail industry: A case study of RFM model-based customer segmentation using data mining. Database Marketing & Customer Strategy Management 19, 197-208\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}