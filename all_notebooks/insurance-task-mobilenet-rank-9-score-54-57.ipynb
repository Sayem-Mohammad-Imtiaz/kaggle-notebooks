{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-06T14:34:44.935646Z","iopub.execute_input":"2021-06-06T14:34:44.935933Z","iopub.status.idle":"2021-06-06T14:34:46.191379Z","shell.execute_reply.started":"2021-06-06T14:34:44.935863Z","shell.execute_reply":"2021-06-06T14:34:46.183309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading required packages","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics \nfrom sklearn import preprocessing\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nimport cv2\nfrom keras.preprocessing.image import img_to_array\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom keras.layers import Dense,GlobalAveragePooling2D\nfrom keras.applications import MobileNet\nfrom keras.applications.mobilenet import preprocess_input\nfrom keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2021-06-06T14:34:58.016574Z","iopub.execute_input":"2021-06-06T14:34:58.016909Z","iopub.status.idle":"2021-06-06T14:35:03.686965Z","shell.execute_reply.started":"2021-06-06T14:34:58.016875Z","shell.execute_reply":"2021-06-06T14:35:03.686119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading training data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/fast-furious-and-insured/Fast_Furious_Insured/train.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T14:35:07.886641Z","iopub.execute_input":"2021-06-06T14:35:07.886968Z","iopub.status.idle":"2021-06-06T14:35:07.927729Z","shell.execute_reply.started":"2021-06-06T14:35:07.886936Z","shell.execute_reply":"2021-06-06T14:35:07.926798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading testing data","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv('../input/fast-furious-and-insured/Fast_Furious_Insured/test.csv')\ndf_test","metadata":{"execution":{"iopub.status.busy":"2021-06-06T14:35:12.482255Z","iopub.execute_input":"2021-06-06T14:35:12.482577Z","iopub.status.idle":"2021-06-06T14:35:12.645686Z","shell.execute_reply.started":"2021-06-06T14:35:12.482546Z","shell.execute_reply":"2021-06-06T14:35:12.644697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pre-processing","metadata":{}},{"cell_type":"code","source":"# Get the number of missing data points per column\nmissing_values_count_train = df.isnull().sum()\nprint(missing_values_count_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T14:35:17.9518Z","iopub.execute_input":"2021-06-06T14:35:17.952112Z","iopub.status.idle":"2021-06-06T14:35:17.95943Z","shell.execute_reply.started":"2021-06-06T14:35:17.952081Z","shell.execute_reply":"2021-06-06T14:35:17.95832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the number of missing data points per column\nmissing_values_count_test = df_test.isnull().sum()\nprint(missing_values_count_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T14:35:22.951605Z","iopub.execute_input":"2021-06-06T14:35:22.951924Z","iopub.status.idle":"2021-06-06T14:35:22.958124Z","shell.execute_reply.started":"2021-06-06T14:35:22.951892Z","shell.execute_reply":"2021-06-06T14:35:22.957085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filling missing values\ndf = df.fillna(method='bfill', axis=0).fillna(0)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T14:35:25.436029Z","iopub.execute_input":"2021-06-06T14:35:25.436465Z","iopub.status.idle":"2021-06-06T14:35:25.446227Z","shell.execute_reply.started":"2021-06-06T14:35:25.436431Z","shell.execute_reply":"2021-06-06T14:35:25.445127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking different values in Insurance company in the training set\ndf['Insurance_company'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T14:35:30.229395Z","iopub.execute_input":"2021-06-06T14:35:30.229718Z","iopub.status.idle":"2021-06-06T14:35:30.239711Z","shell.execute_reply.started":"2021-06-06T14:35:30.229686Z","shell.execute_reply":"2021-06-06T14:35:30.238938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking different values in Insurance company in the testing set\ndf_test['Insurance_company'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T14:35:32.796846Z","iopub.execute_input":"2021-06-06T14:35:32.797186Z","iopub.status.idle":"2021-06-06T14:35:32.804918Z","shell.execute_reply.started":"2021-06-06T14:35:32.797133Z","shell.execute_reply":"2021-06-06T14:35:32.803887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Label encoding and scaling","metadata":{}},{"cell_type":"code","source":"features_num = ['Cost_of_vehicle', 'Min_coverage', 'Max_coverage']\nfeatures_cat = ['Insurance_company']\n\nle= LabelEncoder()   \ndf['Insurance_company'] = le.fit_transform(df['Insurance_company'])\ndf_test['Insurance_company'] = le.transform(df_test['Insurance_company'])\n\npreprocessor = make_column_transformer(\n    (StandardScaler(), features_num),\n)\n\ny = df['Amount']\ntrain_imputed = df.loc[:,['Cost_of_vehicle', 'Min_coverage', 'Max_coverage', 'Insurance_company']]\nX = preprocessor.fit_transform(train_imputed)\n\ntest_imputed = df_test.loc[:,['Cost_of_vehicle', 'Min_coverage',  'Max_coverage', 'Insurance_company']]\ntest_X = preprocessor.transform(test_imputed)\n\ntrain_imputed.columns","metadata":{"execution":{"iopub.status.busy":"2021-06-06T14:35:40.213708Z","iopub.execute_input":"2021-06-06T14:35:40.214036Z","iopub.status.idle":"2021-06-06T14:35:40.237181Z","shell.execute_reply.started":"2021-06-06T14:35:40.213998Z","shell.execute_reply":"2021-06-06T14:35:40.236233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train-test split\ntrain_X, val_X, train_y, val_y = train_test_split(X,y,random_state=1,test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T14:35:45.918237Z","iopub.execute_input":"2021-06-06T14:35:45.918546Z","iopub.status.idle":"2021-06-06T14:35:45.926166Z","shell.execute_reply.started":"2021-06-06T14:35:45.918517Z","shell.execute_reply":"2021-06-06T14:35:45.92491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train a random forest regressor","metadata":{}},{"cell_type":"code","source":"rf_model = RandomForestRegressor(random_state=1, n_estimators = 1000, max_depth=3)\n# fit your model\nrf_model.fit(train_X,train_y)\nval_preds = rf_model.predict(val_X)\n# Calculate the mean absolute error of your Random Forest model on the validation data\nrf_val_mae = mean_absolute_error(val_y,val_preds)\n\nprint(\"Validation MAE for Random Forest Model: {}\".format(rf_val_mae))","metadata":{"execution":{"iopub.status.busy":"2021-06-06T14:36:20.558641Z","iopub.execute_input":"2021-06-06T14:36:20.558964Z","iopub.status.idle":"2021-06-06T14:36:22.282495Z","shell.execute_reply.started":"2021-06-06T14:36:20.558933Z","shell.execute_reply":"2021-06-06T14:36:22.281623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get the predictions for amount","metadata":{}},{"cell_type":"code","source":"amount_predictions = rf_model.predict(test_X)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T14:36:33.518937Z","iopub.execute_input":"2021-06-06T14:36:33.519276Z","iopub.status.idle":"2021-06-06T14:36:33.603092Z","shell.execute_reply.started":"2021-06-06T14:36:33.519235Z","shell.execute_reply":"2021-06-06T14:36:33.602335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare the images","metadata":{}},{"cell_type":"code","source":"X = df.loc[:,['Image_path']]\ny = df.loc[:,['Condition']]    \nX_test = df.loc[:,['Image_path']]\nprint('train set shape:', X.shape)\nprint('test set shape:', X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T14:36:38.210359Z","iopub.execute_input":"2021-06-06T14:36:38.210696Z","iopub.status.idle":"2021-06-06T14:36:38.219207Z","shell.execute_reply.started":"2021-06-06T14:36:38.210665Z","shell.execute_reply":"2021-06-06T14:36:38.218166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = []\nlabels = []\nfor (index_label, row_series) in df.iterrows():\n        img_path = row_series.values[0]\n        condition = row_series.values[-2]\n        labels.append(int(condition))\n        # load the image, pre-process it, and store it in the data list\n        originalImage = cv2.imread('/kaggle/input/fast-furious-and-insured/Fast_Furious_Insured/trainImages/' + img_path)\n        image = cv2.resize(originalImage, (224, 224))\n        image = img_to_array(image)\n        data.append(image)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T14:36:42.818482Z","iopub.execute_input":"2021-06-06T14:36:42.818803Z","iopub.status.idle":"2021-06-06T14:36:57.820067Z","shell.execute_reply.started":"2021-06-06T14:36:42.81877Z","shell.execute_reply":"2021-06-06T14:36:57.81923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transfer learning with MobileNet","metadata":{}},{"cell_type":"code","source":"base_model=MobileNet(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\nx=base_model.output\nx=GlobalAveragePooling2D()(x)\nx=Dense(256,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\npreds=Dense(2,activation='softmax')(x) #final layer with softmax activation\nmodel=Model(inputs=base_model.input,outputs=preds)\n   # we want to set the first 20 layers of the network to be non-trainable\nfor layer in model.layers[:80]:\n    layer.trainable=False\nfor layer in model.layers[80:]:\n    layer.trainable=True","metadata":{"execution":{"iopub.status.busy":"2021-06-06T14:37:04.753834Z","iopub.execute_input":"2021-06-06T14:37:04.754172Z","iopub.status.idle":"2021-06-06T14:37:07.516042Z","shell.execute_reply.started":"2021-06-06T14:37:04.754122Z","shell.execute_reply":"2021-06-06T14:37:07.515232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import optimizers\n\nprint(len(data),len(labels))\ndata = np.array(data, dtype=\"float\")\nlabels = np.array(labels)\n    \n# partition the data into training and testing splits using 80% of\n# the data for training and the remaining 20% for testing\n(train_images, test_images, train_labels, test_labels) = train_test_split(data,labels, test_size=0.2, random_state=42)\n\n#(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n# Normalize pixel values to be between 0 and 1\ntrain_images, test_images = (train_images / 255.0)-0.5, (test_images / 255.0) -0.5\n\ntrain_labels = to_categorical(train_labels, 2)\ntest_labels = to_categorical(test_labels, 2)\n\n#compile and train the model\nadam=optimizers.Adam(\n                lr=0.002,\n                beta_1=0.9,\n                beta_2=0.999,\n                epsilon=None,\n                decay=0.0001,\n                amsgrad=False\n                )\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n#callback = callbacks.LearningRateScheduler(scheduler)\nhistory = model.fit(train_images, train_labels, batch_size=32,epochs=5,shuffle=True, validation_data=(test_images, test_labels))","metadata":{"execution":{"iopub.status.busy":"2021-06-06T14:37:14.569628Z","iopub.execute_input":"2021-06-06T14:37:14.569954Z","iopub.status.idle":"2021-06-06T14:37:29.633847Z","shell.execute_reply.started":"2021-06-06T14:37:14.569923Z","shell.execute_reply":"2021-06-06T14:37:29.632931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Getting the test prediction","metadata":{}},{"cell_type":"code","source":"condition_predictions = []\nfor (index_label, row_series) in df_test.iterrows():\n        img_path = row_series.values[0]\n        # load the image, pre-process it, and store it in the data list\n        originalImage = cv2.imread('/kaggle/input/fast-furious-and-insured/Fast_Furious_Insured/testImages/' + img_path)\n        image = cv2.resize(originalImage, (224, 224))\n        image = img_to_array(image)\n        image = image.reshape((1,224, 224, 3))\n        image = np.array(image, dtype=\"float\") / 255.0 - 0.5\n        prediction = model.predict(image)\n        prediction = prediction[0]\n        condition_predictions.append(np.argmax(prediction))\n       ","metadata":{"execution":{"iopub.status.busy":"2021-06-06T14:37:41.718259Z","iopub.execute_input":"2021-06-06T14:37:41.718588Z","iopub.status.idle":"2021-06-06T14:38:09.541532Z","shell.execute_reply.started":"2021-06-06T14:37:41.718556Z","shell.execute_reply":"2021-06-06T14:38:09.540707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing the submission","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame({'Image_path': df_test.Image_path, 'Condition': condition_predictions, \n                          'Amount': amount_predictions})\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T14:38:12.946674Z","iopub.execute_input":"2021-06-06T14:38:12.946993Z","iopub.status.idle":"2021-06-06T14:38:13.180864Z","shell.execute_reply.started":"2021-06-06T14:38:12.946963Z","shell.execute_reply":"2021-06-06T14:38:13.180109Z"},"trusted":true},"execution_count":null,"outputs":[]}]}