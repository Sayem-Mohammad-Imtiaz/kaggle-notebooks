{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random as rnd\nimport sklearn as sk\nfrom tqdm.notebook import tqdm\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Data & Preprocess"},{"metadata":{"trusted":true},"cell_type":"code","source":"full_table = (pd.read_csv(\"/kaggle/input/covid19factorsimpact/fullCOVIDtable.csv\",sep=\";\").\n        drop(columns=\"Unnamed: 0\").\n        loc[:,[\"SCHOOL\",\n               \"WORK\",\n               \"EVENTS\",\n               \"GATHERINGS\",\n               \"TRANSPORTATION\",\n               \"ATHOME\",\n               \"NATIONAL\",\n               \"INTERNATIONAL\",\n               \"INFORMATION\",\n               \"TESTING\",\n               \"TRACING\",\n               \"DAY\",\n               \"COUNTRY\",\n               \"OLD\",\n               \"YOUNG\",\n               \"URBAN\",\n               \"DENSITY\",\n               \"POPULATION\",\n               \"PHYSICIANS\",\n               \"BEDS\",\n               \"REFF\",\n               \"INFECTED\",\n               \"INFECTEDINCREASE\",\n               \"MORTALITY\",\n               \"FATALITYINCREASE\",\n               \"TEMPERATURE\",\n               \"HUMIDITY\",\n               \"WIND\",\n               \"CONTINENT\",\n               \"DATE\"]].\n        dropna()\n       )\n\nfull_table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop all countries with less than 30 days of useful data\n# create columns representing relevant data in the past by means of shift.\n\ndaysPerCountry = full_table.groupby(by=\"COUNTRY\")[\"REFF\"].count()\ndaysPerCountry[daysPerCountry<30]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"factorsTS = [\"SCHOOL\",\n               \"WORK\",\n               \"EVENTS\",\n               \"GATHERINGS\",\n               \"TRANSPORTATION\",\n               \"ATHOME\",\n               \"NATIONAL\",\n               \"INTERNATIONAL\",\n               \"INFORMATION\",\n               \"TESTING\",\n               \"TRACING\",\n               \"INFECTED\",\n               \"INFECTEDINCREASE\",\n               \"MORTALITY\",\n               \"FATALITYINCREASE\",\n               \"TEMPERATURE\",\n               \"HUMIDITY\",\n               \"WIND\"]\n\nfor factor in factorsTS:\n    for daysInPast in range(1,31):\n        full_table[factor+\"-\"+str(daysInPast)] = full_table.groupby(\"COUNTRY\")[factor].shift(daysInPast)\n        \n        \nfull_table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def binReff(reff):\n    binnedReff = 0\n    if reff >= 1 and reff <1.5:\n        binnedReff = 1\n    elif reff>= 1.5 and reff <=2:\n        binnedReff = 2\n    elif reff>2:\n        binnedReff = 3\n        \n    return binnedReff\n\n\ndef binMortality(mort):\n    binMort = 0\n    if mort <=1:\n        binMort = 1\n    elif mort <=5:\n        binMort = 5\n    elif mort <=10:\n        binMort = 10\n    elif mort >10:\n        binMort = 15\n        \n    return binMort","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_table[\"REFFBINNED\"] = full_table[\"REFF\"].apply(binReff)\nfull_table[\"MORTALITYBINNED\"] = full_table[\"MORTALITY\"].apply(binMortality)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_table.to_csv(\"preppedData.csv\",sep=\";\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rnd.seed(574638)\n\ncountryList = full_table[\"COUNTRY\"].drop_duplicates().to_list()\n\nprint(countryList)\n\nrnd.shuffle(countryList)\n\nprint(\"\\nShuffled country list :\")\nprint(countryList)\n\ntestCountries = countryList[0:20]\nvalidationCountries = countryList[20:30]\ntrainingCountries = countryList[30:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"factors = [\n    \"SCHOOL\",\n    \"WORK\",\n    \"EVENTS\",\n    \"GATHERINGS\",\n    \"TRANSPORTATION\",\n    \"ATHOME\",\n    \"NATIONAL\",\n    \"INTERNATIONAL\",\n    \"INFORMATION\",\n    \"TESTING\",\n    \"TRACING\",\n    \"DAY\",\n    \"OLD\",\n    \"YOUNG\",\n    \"URBAN\",\n    \"DENSITY\",\n    \"POPULATION\",\n    \"PHYSICIANS\",\n    \"BEDS\",\n    \"INFECTED\",\n    \"INFECTEDINCREASE\",\n    \"FATALITYINCREASE\",\n    \"TEMPERATURE\",\n    \"HUMIDITY\",\n    \"WIND\"\n]\n\nfor factorTS in factorsTS:\n    for daysInPast in range(1,31):\n        factors += [factor+\"-\"+str(daysInPast)]\n\n\ntestSet = full_table[full_table[\"COUNTRY\"].isin(testCountries)].dropna()\nX_testPropagation = testSet.loc[:,factors+[\"MORTALITY\"]].to_numpy()\nX_testMortality = testSet.loc[:,factors].to_numpy()\nY_testPropagation = testSet[\"REFFBINNED\"].to_numpy()\nY_testMortality = testSet[\"MORTALITYBINNED\"].to_numpy()\n\nvalidationSet = full_table[full_table[\"COUNTRY\"].isin(validationCountries)].dropna()\nX_valPropagation = validationSet.loc[:,factors+[\"MORTALITY\"]].to_numpy()\nX_valMortality = validationSet.loc[:,factors].to_numpy()\nY_valPropagation = validationSet[\"REFFBINNED\"].to_numpy()\nY_valMortality = validationSet[\"MORTALITYBINNED\"].to_numpy()\n\n\ntrainingSet = full_table[full_table[\"COUNTRY\"].isin(trainingCountries)].dropna()\nX_trainPropagation = trainingSet.loc[:,factors+[\"MORTALITY\"]].to_numpy()\nX_trainMortality = trainingSet.loc[:,factors].to_numpy()\nY_trainPropagation = trainingSet[\"REFFBINNED\"].to_numpy()\nY_trainMortality = trainingSet[\"MORTALITYBINNED\"].to_numpy()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_trainPropagation.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision trees"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hyperTreeParamGrid = {\n    \"max_depth\" : [None,3,5,10,15,30],\n    \"min_samples_split\" : [2,3,5,7,10,20,50],\n    \"min_samples_leaf\" : [1,5,10,20,50],\n    \"max_leaf_nodes\" : [None, 2,5,10,15],\n    \"criterion\" : [\"gini\",\"entropy\"]\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm.notebook import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"treeClassifiers = pd.DataFrame(columns=[\n    \"max_depth\",\n    \"min_samples_split\",\n    \"min_samples_leaf\",\n    \"max_leaf_nodes\",\n    \"criterion\",\n    \"train_score\",\n    \"val_score\"\n])\n\ncounter = tqdm(total=2100)\nfor max_depth in hyperTreeParamGrid[\"max_depth\"] :\n    for min_samples_split in hyperTreeParamGrid[\"min_samples_split\"] :\n        for min_samples_leaf in hyperTreeParamGrid[\"min_samples_leaf\"] :\n            for max_leaf_nodes in hyperTreeParamGrid[\"max_leaf_nodes\"] :\n                for criterion in hyperTreeParamGrid[\"criterion\"] :\n                    clf = tree.DecisionTreeClassifier(\n                       max_depth = max_depth,\n                       min_samples_split = min_samples_split,\n                       min_samples_leaf = min_samples_leaf,\n                       max_leaf_nodes = max_leaf_nodes, \n                       criterion = criterion\n                    )\n                    \n                    clf = clf.fit(X_trainPropagation,Y_trainPropagation)\n                    train_score  = clf.score(X_trainPropagation,Y_trainPropagation)\n                    val_score = clf.score(X_valPropagation,Y_valPropagation)\n                    \n                    treeClassifiers = treeClassifiers.append({\n                        \"max_depth\":max_depth,\n                        \"min_samples_split\":min_samples_split,\n                        \"min_samples_leaf\":min_samples_leaf,\n                        \"max_leaf_nodes\":max_leaf_nodes,\n                        \"criterion\":criterion,\n                        \"train_score\":train_score,\n                        \"val_score\":val_score\n                    }, ignore_index=True)\n                    \n                    counter.update(1)\n\ntreeClassifiers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"treeClassifiers.to_csv(\"trainedTrees.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"topTreeParams = treeClassifiers[treeClassifiers[\"val_score\"]==treeClassifiers[\"val_score\"].max()]\n\nfirstBest = min(topTreeParams.index) \n\nclf = tree.DecisionTreeClassifier(\n    max_depth = topTreeParams.loc[firstBest,\"max_depth\"],\n    min_samples_split = topTreeParams.loc[firstBest,\"min_samples_split\"],\n    min_samples_leaf = topTreeParams.loc[firstBest,\"min_samples_leaf\"],\n    max_leaf_nodes = topTreeParams.loc[firstBest,\"max_leaf_nodes\"], \n    criterion = topTreeParams.loc[firstBest,\"criterion\"]\n)\n\nclf = clf.fit(X_trainPropagation,Y_trainPropagation)\ntrain_score = clf.score(X_trainPropagation,Y_trainPropagation)\nval_score = clf.score(X_valPropagation,Y_valPropagation)\ntest_score = clf.score(X_testPropagation,Y_testPropagation)\n\nprint(train_score)\nprint(val_score)\nprint(test_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Ensemble Methods"},{"metadata":{},"cell_type":"markdown","source":"## Gradient Boosted Trees"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hyperGradientParamGrid = {\n    \"loss\":[\"deviance\"],\n    \"n_estimators\":[10,20,25,50],\n    \"min_samples_split\" : [2],\n    \"min_samples_leaf\" : [50],\n    \"max_leaf_nodes\" : [None],\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bufort suggests xgboost, catboost\ngradientClassifiers = pd.DataFrame(columns=[\n    \"loss\",\n    \"n_estimators\",\n    \"min_samples_split\",\n    \"min_samples_leaf\",\n    \"max_leaf_nodes\",\n    \"train_score\",\n    \"val_score\"\n])\n\ncounter = tqdm(total=4)\nfor loss in hyperGradientParamGrid[\"loss\"] :\n    for n_estimators in hyperGradientParamGrid[\"n_estimators\"] :\n            for min_samples_split in hyperGradientParamGrid[\"min_samples_split\"] :\n                for min_samples_leaf in hyperGradientParamGrid[\"min_samples_leaf\"] :\n                    for max_leaf_nodes in hyperGradientParamGrid[\"max_leaf_nodes\"] :\n                            clf = GradientBoostingClassifier(\n                                loss=loss,\n                                n_estimators=n_estimators,\n                                min_samples_split=min_samples_split,\n                                min_samples_leaf=min_samples_leaf,\n                                max_leaf_nodes=max_leaf_nodes\n                            )\n\n                            clf = clf.fit(X_trainPropagation,Y_trainPropagation)\n                            train_score  = clf.score(X_trainPropagation,Y_trainPropagation)\n                            val_score = clf.score(X_valPropagation,Y_valPropagation)\n\n                            gradientClassifiers = gradientClassifiers.append({\n                                \"loss\":loss,\n                                \"n_estimators\":n_estimators,\n                                \"min_samples_split\":min_samples_split,\n                                \"min_samples_leaf\":min_samples_leaf,\n                                \"max_leaf_nodes\":max_leaf_nodes,\n                                \"train_score\":train_score,\n                                \"val_score\":val_score\n                            }, ignore_index=True)\n                            counter.update(1)\n                            \ngradientClassifiers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gradientClassifiers.to_csv(\"trainedPropagationGradBoost.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"topGradParams = gradientClassifiers[gradientClassifiers[\"val_score\"]==gradientClassifiers[\"val_score\"].max()]\n\nfirstBest = min(topGradParams.index) \n\n\nclf = GradientBoostingClassifier(\n    loss=topGradParams.loc[firstBest,\"loss\"],\n    n_estimators=topGradParams.loc[firstBest,\"n_estimators\"],\n    min_samples_split=topGradParams.loc[firstBest,\"min_samples_split\"],\n    min_samples_leaf=topGradParams.loc[firstBest,\"min_samples_leaf\"],\n    max_leaf_nodes=topGradParams.loc[firstBest,\"max_leaf_nodes\"]\n)\n\nclf = clf.fit(X_trainPropagation,Y_trainPropagation)\ntrain_score = clf.score(X_trainPropagation,Y_trainPropagation)\nval_score = clf.score(X_valPropagation,Y_valPropagation)\ntest_score = clf.score(X_testPropagation,Y_testPropagation)\n\nprint(train_score)\nprint(val_score)\nprint(test_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Multi Layer Peceptron"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\n# bufort suggests tabnet https://pypi.org/project/tabnet/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nFeats = X_trainPropagation.shape[1]\nprint(nFeats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inLayerN = X_trainPropagation.shape[1]\n\nhyperMLP = {\n    \"alpha\":[1e-3,1,1e4],\n    \"solver\":[\"lbfgs\",\"adam\"],\n    \"layers\":[(inLayerN),(inLayerN,inLayerN),(inLayerN,inLayerN,inLayerN),(inLayerN,inLayerN,inLayerN,inLayerN)]\n    \n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mlpClassifiers = pd.DataFrame(columns=[\n    \"alpha\",\n    \"solver\",\n    \"layers\",\n    \"train_score\",\n    \"val_score\"\n])\n\ncounter = tqdm(total=30)\n\nfor alpha in hyperMLP[\"alpha\"] :\n    for solver in hyperMLP[\"solver\"] :\n        for layers in hyperMLP[\"layers\"] :\n            clf = MLPClassifier(\n                alpha = alpha,\n                solver=solver,\n                hidden_layer_sizes=layers\n            )\n\n            clf = clf.fit(X_trainPropagation,Y_trainPropagation)\n            train_score  = clf.score(X_trainPropagation,Y_trainPropagation)\n            val_score = clf.score(X_valPropagation,Y_valPropagation)\n\n            mlpClassifiers = mlpClassifiers.append({\n                \"alpha\":alpha,\n                \"solver\":solver,\n                \"layers\":layers,\n                \"train_score\":train_score,\n                \"val_score\":val_score\n            }, ignore_index=True)\n\n\n            counter.update(1)\n\nmlpClassifiers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mlpClassifiers.to_csv(\"trainedMLP.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"topMLPParams = mlpClassifiers[mlpClassifiers[\"val_score\"]==mlpClassifiers[\"val_score\"].max()]\n\nfirstBest = min(topMLPParams.index) \n\nclf = MLPClassifier(\n    alpha = topMLPParams.loc[firstBest,\"alpha\"],\n    solver=topMLPParams.loc[firstBest,\"solver\"],\n    hidden_layer_sizes=topMLPParams.loc[firstBest,\"layers\"]\n)\n\nclf = clf.fit(X_trainPropagation,Y_trainPropagation)\ntrain_score = clf.score(X_trainPropagation,Y_trainPropagation)\nval_score = clf.score(X_valPropagation,Y_valPropagation)\ntest_score = clf.score(X_testPropagation,Y_testPropagation)\n\nprint(train_score)\nprint(val_score)\nprint(test_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ridge Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import RidgeClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hyperRidge = {\n    \"alpha\":[1e-3,1e-2,1e-1,1,10,100,1000,10000,1e5,1e6,1e7]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bufort suggests xgboost, catboost\nridgeClassifiers = pd.DataFrame(columns=[\n    \"alpha\",\n    \"train_score\",\n    \"val_score\"\n])\n\ncounter = tqdm(total=len(hyperRidge[\"alpha\"]))\nfor alpha in hyperRidge[\"alpha\"] :\n    clf = RidgeClassifier(\n        alpha = alpha\n    )\n\n    clf = clf.fit(X_trainPropagation,Y_trainPropagation)\n    train_score  = clf.score(X_trainPropagation,Y_trainPropagation)\n    val_score = clf.score(X_valPropagation,Y_valPropagation)\n\n    ridgeClassifiers = ridgeClassifiers.append({\n        \"alpha\":alpha,\n        \"train_score\":train_score,\n        \"val_score\":val_score\n    }, ignore_index=True)\n    counter.update(1)\n\nridgeClassifiers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ridgeClassifiers.to_csv(\"trainedRidge.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"topRidgeParams = ridgeClassifiers[ridgeClassifiers[\"val_score\"]==ridgeClassifiers[\"val_score\"].max()]\n\nfirstBest = min(topRidgeParams.index) \n\nclf = RidgeClassifier(\n    alpha=topRidgeParams.loc[firstBest,\"alpha\"],\n)\n\nclf = clf.fit(X_trainPropagation,Y_trainPropagation)\ntrain_score = clf.score(X_trainPropagation,Y_trainPropagation)\nval_score = clf.score(X_valPropagation,Y_valPropagation)\ntest_score = clf.score(X_testPropagation,Y_testPropagation)\n\nprint(train_score)\nprint(val_score)\nprint(test_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}