{"cells":[{"metadata":{},"cell_type":"markdown","source":"<a id=\"top\"></a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h1 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:#005097; border:0' role=\"tab\" aria-controls=\"home\"><center>RFM Segmentation and CLV modeling </center></h1>"},{"metadata":{},"cell_type":"markdown","source":"### Table of Contents\n\n* [1. Theoretical concepts](#section_1)\n    * [RFM segmentation](#section_1_1)\n    * [Customer Lifetime Value](#section_1_2) \n    ___\n* [2. Data Preprocessing](#section_2)\n    * [Feature engineering](#section_2_1)\n    * [Statistical summary](#section_2_2)\n    \n    ___\n* [3. RFM Segmentation](#section_3)\n    * [Recency calculation](#section_3_1)\n    * [Frequency calculation](#section_3_2)\n    * [Monetary calculation](#section_3_3)\n    * [Segment creation](#section_3_4)\n    \n    ___\n* [4. CLV modeling](#section_4)\n    * [Deriving RFM Metrics](#section_4_1)\n    * [Retention Model fitting](#section_4_2)\n    * [Value Model fitting](#section_4_3)\n    * [CLV estimates](#section_4_4)\n        \n    ___\n* [5. Conclusion](#section_5)\n    \n    ___"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!pip install Lifetimes\n!pip install scikit-learn-extra","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport datetime\nfrom datetime import timedelta\nfrom datetime import date\nimport squarify\nfrom lifetimes.plotting import *\nfrom lifetimes.utils import *\nfrom lifetimes import BetaGeoFitter\nfrom lifetimes import GammaGammaFitter\nfrom scipy.stats import gamma, beta\nfrom sklearn_extra.cluster import KMedoids\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ndata_folder = \"/kaggle/input/arketing-campaign/\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Theoretical concepts <a class=\"anchor\" id=\"section_1\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### A. RFM Segmentation <a class=\"anchor\" id=\"section_1_1\"></a>"},{"metadata":{},"cell_type":"markdown","source":"RFM segmentation is a scoring technique used to better quantify customer behavior. During marketing campaigns, not all customers should be contacted with the same effort. Direct marketing segmentation enables to group customers in different segments and anayze their profitability accordingly.\n\nRFM metrics are closely related to the Customer Lifetime Value as frequency and monetary value affect directly **CLV** and recency affects **retention**\n>- **Recency** : Time since last order  \n>- **Frequency** : Total number of transactions\n>- **Monetary** : Total transactions value\n\nThese metrics are very important to understand customer behavior :\n- The more **recent** the purchase, the more **responsive** the customer is to promotions\n- The more **frequently** customers buy, the more **engaged** they are"},{"metadata":{},"cell_type":"markdown","source":"### B. Customer Lifetime Value <a class=\"anchor\" id=\"section_1_2\"></a>"},{"metadata":{},"cell_type":"markdown","source":"- **CLV definition**"},{"metadata":{},"cell_type":"markdown","source":"Customer Lifetime Value can be viewed as the economic value derived from the firm's relationship with its customers. \nCLV is defined as a measure of the present value of future cash flows attributed to the customer relationship.In other words, CLV measure the net profit a customer will bring to the firm over the future periods. Hence past customer transactions may be used as a predictive driver of the economic value of a firm's customer relationship.\n\nThe CLV formula can be written as :\n\n$$CLV = \\sum_{n=1}^{N} \\frac {Value_{n}*Retention^{n}}{ (1+ DiscountRate)^{n}}$$\n"},{"metadata":{},"cell_type":"markdown","source":"- **Buy Till You Die model (BTYD model)**"},{"metadata":{},"cell_type":"markdown","source":"BTYD model is built on 4 metrics which are closely related to the ones used for RFM segmentation :\n- **Frequency** : The number of repeated purchases the customer made after his first date of first purchase\n- **Age** (Time) : The period the customer has been enrolled in the company, expressed in days, weeks or even months. \n   $\\textit{Age = Last date in dataset - first customer purchase date }$\n- **Recency** : The age of the customer when he made its last purchase  \n    $\\textit{Recency = Last customer purchase date - first customer purchase date }$\n- **Monetary value** : The average  amount spent by a customer"},{"metadata":{},"cell_type":"markdown","source":"While it exists several version of BTYD models, I will here use the BG/NBD model.  \nBG/NBD was introduced in 2004 by Peter Fader and stands for Beta Geometric/Negative Binomial Distribution.   \nThe model distinguish customer behaviour in two parts:\n- The buying process which models the probability a customer makes a purchase\n- The dying process (or dropout) which models the probability a customer quit and never purchase again\n\nBG/NBD model is based on 5 assumptions :\n>1. While active, the number of transactions made by a customer follows a **Poisson distribution** with transaction rate $\\lambda$\n>2. Heterogenity in transaction rate $\\lambda$ follows a **Gamma distribution** (each customer has its own probability of buying)\n>3. After any transaction, a customer becomes inactive with probability $p$. The point at which a customer \"drops out\" (or \"die\") is distributed across the transactions according to a **Geometric distribution**\n>4. Heterogeneity in $p$ (dropout probability) follows a **Beta distribution** \n>5. The transaction rate $\\lambda$ and the dropout probability $p$ vary independently across customers\n\nOnce these probability distributions have been fitted, we obtain for each customer :\n- $P(X(t)=x| \\lambda ,p) $ : the probability of observing $x$ transactions in a time period of lenght $t$\n- $E(X(t)| \\lambda ,p) $ : the expected number of transactions in a time period of lenght $t$\n- $P(\\tau>t) $ : the probability of a customer becoming inactive at period $\\tau$"},{"metadata":{},"cell_type":"markdown","source":"# 2. Data Preprocessing <a class=\"anchor\" id=\"section_2\"></a>"},{"metadata":{},"cell_type":"markdown","source":"We covered in the <a href=\"https://www.kaggle.com/raphael2711/data-prep-visual-eda-and-statistical-hypothesis\">previous notebooks</a> the data discovery steps (data types, data shape, data completeness, etc..)  \nWe will therefore directly start with the feature engineering step and the analysis of the statistical metrics relevant for this usecase."},{"metadata":{},"cell_type":"markdown","source":"### A. Feature Engineering <a class=\"anchor\" id=\"section_2_1\"></a>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dataset=pd.read_csv(data_folder+'marketing_campaign.csv',header=0,sep=';') \ndataset.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dataset already have all the variables needed to create the RFM metrics. We just need to prepare the data.\n\nWe wrill create two variables :\n\n>- Variable __*Spending*__ as the sum of the amount spent on the 6 product categories.\n>- Variable __*Transactions*__ as the total number of purchases made by the customer.\n\n\nWe will remove the unused variables for this analysis and keep only the customers who made more than 1 repeat purchase in order to calculate the Customer Lifetime Value."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dataset['Spending']=dataset['MntWines']+dataset['MntFruits']+dataset['MntMeatProducts']+dataset['MntFishProducts']+dataset['MntSweetProducts']+dataset['MntGoldProds']\ndataset['Transactions']=dataset['NumWebPurchases']+dataset['NumCatalogPurchases']+dataset['NumStorePurchases']\ndataset=dataset[['ID','Spending','Transactions','Recency','Dt_Customer']]\ndataset = dataset[dataset['Transactions'] > 1] #We keep customers with repeated purchases, implying number of transactions must be at least 2\ndataset = dataset[dataset['Spending'] > 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### B. Statistical Summary <a class=\"anchor\" id=\"section_2_2\"></a>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"Summary of the last 2 years spending\")\nprint(\"Number of transactions: \", dataset['Transactions'].sum())\nprint(\"Total sales: \",dataset['Spending'].sum())\nprint(\"Number of customers:\", dataset['ID'].nunique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. RFM Segmentation <a class=\"anchor\" id=\"section_3\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### A. Recency calculation <a class=\"anchor\" id=\"section_3_1\"></a>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"recency_df = dataset[['ID','Recency']]\nrecency_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### B. Frequency calculation <a class=\"anchor\" id=\"section_3_2\"></a>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"frequency_df = dataset[['ID','Transactions']]\ntemp_df = recency_df.merge(frequency_df,on='ID')\nfrequency_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### C. Monetary calculation <a class=\"anchor\" id=\"section_3_3\"></a>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"monetary_df = dataset[['ID','Spending']]\nmonetary_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### DataFrame aggregation"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"tx_user  = temp_df.merge(monetary_df,on='ID')\ntx_user.columns = ['ID','Recency','Frequency','Monetary']\ntx_user","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Elbow method"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Select number of clusters for each attributes\n#Step 1 : Clusters for Recency\nsse={}\ntx_recency = tx_user[['Recency']]\nfor k in range(1, 10):\n    kmedoids = KMedoids(n_clusters=k, random_state=0, max_iter=1000,init='k-medoids++',metric='euclidean').fit(tx_recency)\n    tx_recency[\"clusters\"] = kmedoids.labels_\n    sse[k] = kmedoids.inertia_\nplt.figure()\nplt.plot(list(sse.keys()), list(sse.values()))\nplt.xlabel(\"Number of cluster\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this analysis we will divide our customers in 5 clusters for each RFM metrics leading to 5x5x5 clusters"},{"metadata":{},"cell_type":"markdown","source":"#### Recency clusters creation"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"kmedoids = KMedoids(n_clusters=5, random_state=0, max_iter=1000,init='k-medoids++',metric='euclidean').fit(tx_recency)\ntx_user['RecencyCluster'] = kmedoids.predict(tx_recency)\n\n#function for ordering cluster numbers\ndef order_cluster(cluster_field_name, target_field_name,df,ascending):\n    new_cluster_field_name = 'new_' + cluster_field_name\n    df_new = df.groupby(cluster_field_name)[target_field_name].mean().reset_index()\n    df_new = df_new.sort_values(by=target_field_name,ascending=ascending).reset_index(drop=True)\n    df_new['index'] = df_new.index\n    df_final = pd.merge(df,df_new[[cluster_field_name,'index']], on=cluster_field_name)\n    df_final = df_final.drop([cluster_field_name],axis=1)\n    df_final = df_final.rename(columns={\"index\":cluster_field_name})\n    return df_final\n\ntx_user = order_cluster('RecencyCluster', 'Recency',tx_user,False)\n#see details of each cluster\ntx_user.groupby('RecencyCluster')['Recency'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Frequency clusters creation"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"tx_frequency = tx_user[['Frequency']]\n\nkmedoids = KMedoids(n_clusters=5, random_state=0, max_iter=1000,init='k-medoids++',metric='euclidean').fit(tx_frequency)\ntx_user['FrequencyCluster'] = kmedoids.predict(tx_frequency)\n\n#order the frequency cluster\ntx_user = order_cluster('FrequencyCluster', 'Frequency',tx_user,True)\n\n#see details of each cluster\ntx_user.groupby('FrequencyCluster')['Frequency'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Monetary clusters creation"},{"metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"tx_monetary = tx_user[['Monetary']]\n\nkmedoids = KMedoids(n_clusters=5, random_state=0, max_iter=1000,init='k-medoids++',metric='euclidean').fit(tx_monetary)\ntx_user['MonetaryCluster'] = kmedoids.predict(tx_monetary)\n\n#order the cluster numbers\ntx_user = order_cluster('MonetaryCluster', 'Monetary',tx_user,True)\n\n#show details of the dataframe\ntx_user.groupby('MonetaryCluster')['Monetary'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### D. Segment creation <a class=\"anchor\" id=\"section_3_4\"></a>"},{"metadata":{},"cell_type":"markdown","source":"In order to keep a manageable number of segments, the segments are created using only the recency and frequency scores.  \nThe monetary score is often viewed as an aggregation metric for summarizing transactions."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"segt_map = {\n    r'30': 'Promising',\n    r'23': 'Loyal customers',\n    r'24': 'Loyal customers',\n    r'33': 'Loyal customers',\n    r'34': 'Loyal customers',\n    r'43': 'Loyal customers',\n    r'32': 'Potential loyalist',\n    r'31': 'Potential loyalist',\n    r'42': 'Potential loyalist',\n    r'41': 'Potential loyalist',\n    r'21': 'Need attention',\n    r'22': 'Need attention',\n    r'12': 'Need attention',\n    r'11': 'Need attention',\n    r'40': 'New customers',\n    r'20': 'About to sleep',\n    r'14': 'Cant loose them',\n    r'04': 'Cant loose them',\n    r'10': 'Lost',\n    r'00': 'Lost',\n    r'01': 'Lost',\n    r'02': 'At risk',\n    r'03': 'At risk',\n    r'13': 'At risk',\n    r'44': 'Champions',\n}\n\ntx_user['Segment'] = tx_user['RecencyCluster'].map(str) + tx_user['FrequencyCluster'].map(str)\ntx_user['Segment'] = tx_user['Segment'].replace(segt_map, regex=True)\ntx_user.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# count the number of customers in each segment\nsegments_counts = tx_user['Segment'].value_counts().sort_values(ascending=True)\n\nfig, ax = plt.subplots()\n\nbars = ax.barh(range(len(segments_counts)),\n              segments_counts,\n              color='silver')\nax.set_frame_on(False)\nax.tick_params(left=False,\n               bottom=False,\n               labelbottom=False)\nax.set_yticks(range(len(segments_counts)))\nax.set_yticklabels(segments_counts.index)\n\nfor i, bar in enumerate(bars):\n        value = bar.get_width()\n        if segments_counts.index[i] in ['Champions', 'Loyal customers']:\n            bar.set_color('firebrick')\n        ax.text(value,\n                bar.get_y() + bar.get_height()/2,\n                '{:,} ({:}%)'.format(int(value),\n                                   int(value*100/segments_counts.sum())),\n                va='center',\n                ha='left'\n               )\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Metrics analysis per segment "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Calculate average values for each RFM segment, and return a size of each segment \ntx_user_viz = tx_user.groupby('Segment').agg({\n    'Recency': 'mean',\n    'Frequency': 'mean',\n    'Monetary': ['mean', 'count'],\n}).round(1)\n# Print the aggregated dataset\ntx_user_viz","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Segment visualization"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"tx_user_viz.columns = ['Recencymean','Frequencymean', 'Monetarymean','Count']\nfig = plt.gcf()\nax = fig.add_subplot()\nfig.set_size_inches(16, 9)\nsquarify.plot(sizes=tx_user_viz['Count'], \n              label=['Lost',\n                     'About to Sleep',\n                     'Cant loose them',\n                     'Promising',\n                     'New Customers',\n                     'Need Attention',\n                     'Potential Loyalists',\n                     'At risk',\n                     'Loyal Customers',\n                     'Champions',\n                     ], alpha=.6 )\nplt.title(\"RFM Segments\",fontsize=22,fontweight=\"bold\")\nax.set_xlabel('Recency',fontsize=12)\nax.set_ylabel('Frequency',fontsize=12)\nplt.axis('on')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. CLV modeling <a class=\"anchor\" id=\"section_4\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### A. Deriving RFM Metrics <a class=\"anchor\" id=\"section_4_1\"></a>"},{"metadata":{},"cell_type":"markdown","source":"To calculate CLV, we will retrieve the \"DT_Customer\" which will help us calculate the Recency and Age variables in our BTYD model.  \n`Note that Recency that we will use in our BTYD model is different that the one we used in our RFM segmentation `"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"tx_user  = tx_user.merge(dataset[['ID','Dt_Customer']],on='ID')\ntx_user.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Metrics calculation"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"last_date = date(2014,10, 4)\ntx_user['Age']=pd.to_datetime(tx_user['Dt_Customer'], dayfirst=True,format = '%Y-%m-%d')\ntx_user['Age'] = pd.to_numeric(tx_user['Age'].dt.date.apply(lambda x: (last_date - x)).dt.days, downcast='integer')\n\ntx_user['Recency']=(tx_user['Age']-tx_user['Recency'])\n\ntx_user['Monetary_value']=tx_user['Monetary']/tx_user['Frequency']\ntx_user['Frequency']=tx_user['Frequency']-1","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"tx_user=tx_user[['ID','Frequency','Recency','Age','Monetary_value','Segment']]\ntx_user","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### B. Retention Model fitting <a class=\"anchor\" id=\"section_4_2\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"bgf = BetaGeoFitter(penalizer_coef=0.000000005)\nbgf.fit(tx_user['Frequency'], tx_user['Recency'], tx_user['Age'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the estimated gamma distribution of λ (customers' propensities to purchase)\nplot_transaction_rate_heterogeneity(bgf);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bgf.summary","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The summary above shows the estimated distribution parameter values from the dataset.   \nThe model can now use this parameters to predict the future number of transactions for each customer and their churn rate."},{"metadata":{},"cell_type":"markdown","source":"#### The Frequency/Recency Heatmap helps us better understanding how the model estimates the  probability of a customer still being alive and their expected number of future purchases"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# visualize our frequency/recency matrix\nfig = plt.figure(figsize=(12,8))\nplot_frequency_recency_matrix(bgf, T = 30);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">- We can easily understand from the above heatmap that if a customer has made 30 transactions and their latest purchase as when they were 700 days old, then they are considered as the **best customers** and are more likely to buy in the following 30 days. (bottom right)  \n>- We can also notice the interesting area in light blue around (5 ; 500) which represents customers who buy infrequently but we have seen them recently. We are not sure if they are dead or if they might purchase again soon. (probability around 0.5) "},{"metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,8))\nplot_probability_alive_matrix(bgf);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The second interesing heatmap is the probability of a customer of still being alive.\n>- If a customer has a high number of transactions (frequency) and the time between their first and last transaction is hight (recency), his/her probability of still being alive is high. (bottom right)  \n>- If a customer has a small number of transactions but the recency is low, then his/her probability of still being alive is also high (top left)"},{"metadata":{},"cell_type":"markdown","source":"#### Estimates the expected number of repeat purchases for each customer"},{"metadata":{},"cell_type":"markdown","source":"In this step, we will predict the number of repeat purchase each customer will make in the next 30 days"},{"metadata":{"trusted":true},"cell_type":"code","source":"t = 30 # to calculate the number of expected repeat purchases over the next 30 days\ntx_user['Predicted_purchases'] = bgf.conditional_expected_number_of_purchases_up_to_time(t, tx_user['Frequency'], tx_user['Recency'], tx_user['Age'])\ntx_user.sort_values(by='Predicted_purchases').tail(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Estimates the probability of a customer still being alive"},{"metadata":{"trusted":true},"cell_type":"code","source":"tx_user['p_alive'] = bgf.conditional_probability_alive(tx_user['Frequency'], tx_user['Recency'], tx_user['Age'])\ntx_user.sort_values(by='Predicted_purchases').tail(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(tx_user['p_alive']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### C. Value Model fitting <a class=\"anchor\" id=\"section_4_3\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We fit the Gamma-Gamma model to our data\nggf = GammaGammaFitter(penalizer_coef=0.00005)\nggf.fit(frequency = tx_user['Frequency'], monetary_value = tx_user['Monetary_value'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Estimates the average transaction value for each customer"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"tx_user['predicted_Sales'] = ggf.conditional_expected_average_profit(tx_user['Frequency'], tx_user['Monetary_value'])\ntx_user.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can quickly check if the predicted sales and the actual sales are not "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Expected Average sales: {tx_user['predicted_Sales'].mean()}\")\nprint(f\"Actual Average sales: {tx_user['Monetary_value'].mean()}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The results we got are fine. We can now calculate the Customer Lifetime Values"},{"metadata":{},"cell_type":"markdown","source":"### D. CLV estimates <a class=\"anchor\" id=\"section_4_4\"></a>"},{"metadata":{},"cell_type":"markdown","source":"In this final step, we calculate the Long Term Value for each customer over the next 12 months. As explained in the theorical part, we will assume a monthly discount rate of 1%"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"tx_user['LTV'] = ggf.customer_lifetime_value(bgf,tx_user['Frequency'], tx_user['Recency'], tx_user['Age'], tx_user['Monetary_value'],\n    time = 12,freq='D',discount_rate = 0.01)\ntx_user.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can plot our top 10 customers based on LTV.  \nWe can see that these 10 customers all belong to the Champions/Loyal customers/Potential loyalist segments"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"pd.options.display.float_format = \"{:.2f}\".format\nbest_projected_cust_LTV = tx_user.sort_values('LTV').tail(10)\nbest_projected_cust_LTV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Conclusion <a class=\"anchor\" id=\"section_5\"></a>"},{"metadata":{},"cell_type":"markdown","source":"We can now calculate the average Long Term Value of each RFM segment we define earlier for the next 12 months"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"pd.options.display.float_format = \"{:.0f}\".format\n# Calculate average values for each RFM segment\ntx_user_clv = tx_user.groupby('Segment').agg({'LTV': 'mean',}).sort_values('LTV',ascending=False)\ntx_user_clv","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that segments with the highest LTV values are the **Champions**, followed just after by the **Loyal customers**.  \nWe can use our new RFM segmentation along the LTV to develop a classification model and determine wich customers are most likely to be receptive to our next promotionnal marketing campaign"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}