{"cells":[{"metadata":{},"cell_type":"markdown","source":"This is just my collection of seaborn practice. Most of the code is almost the same as the original owner, which can be accessed from this link: https://www.kaggle.com/cwthompson/shootings-understanding-us-police-shootings/comments.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.gridspec import GridSpec\nimport seaborn as sns\nimport plotly.graph_objects as go\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/police-deadly-force-usage-us/fatal-police-shootings-data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows = 2, ncols = 2, figsize = (12, 8))\n\nsns.countplot(x = \"race\", orient = \"v\", ax = ax1, data = data)\nsns.countplot(x = \"gender\", orient = \"v\", ax = ax2, data = data)\nsns.countplot(x = \"signs_of_mental_illness\", orient = \"v\", ax = ax3, data = data)\nsns.countplot(x = \"age\", orient = \"v\", ax = ax4, data = data)\nax4.set_xticks(range(0, 100, 10)) #changing the range for x axis, 100 is the max lim, 0 is min limit, and by 10\nax4.set_xticklabels(range(0, 100, 10)) # we have to manually change the limits and jumps as well\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Are African-Americans Disproportionately killed?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading data\nus_census_data = pd.read_csv(\"../input/us-census-demographic-data/acs2015_county_data.csv\")\n\nus_census_data.head(6)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"lambda function guide: https://stackabuse.com/lambda-functions-in-python/","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the population proportions\ntotal_population = us_census_data['TotalPop'].sum()\nprint(total_population)\n\n\nrace_proportions = pd.DataFrame(['White', 'Hispanic', 'Black', 'Asian', 'Native'], columns = ['Race'])\n\nrace_proportions['Population'] = race_proportions['Race'].apply(\n    lambda y:us_census_data.apply(lambda x: x['TotalPop'] * x[y] / total_population, axis = 1).sum())\n\nrace_proportions['Killed In Police Shootings'] = race_proportions['Race'].apply(\n    lambda x:data[data['race'] == x[0]].shape[0] * 100 / data.shape[0])\n\nprint(race_proportions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the proportions\nrace_proportions = race_proportions.melt(id_vars = \"Race\") \n#melt unpivots data frame from wide to long format, id_vars: column(s) to use as identifier variables\nprint(race_proportions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting our data\nfig, ax = plt.subplots(1, 1, figsize = (10, 6)) # 1 row and 1 column\nsns.barplot(x = 'value', \n            y = 'Race', \n            data = race_proportions, \n            hue = \"variable\", #seperates the bars into the blue & orange\n            ax = ax,\n            palette = ['#0390fc', '#ff3321'])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize = (10, 6)) # 1 row and 1 column\nsns.barplot(x = 'value', \n            y = 'Race', \n            data = race_proportions, \n            hue = \"variable\", #seperates the bars into the blue & orange\n            ax = ax,\n            palette = ['#0390fc', '#ff3321'])\n\n# Annotations\nfor p in ax.patches:\n    width = p.get_width()\n    plt.text(8 + p.get_width(), #the distance the 5 figures are from the end of the bar, i.e. dist between 61.63% and the bar\n             p.get_y() + 0.4 * p.get_height(), # the placing of the % alignment with the bars, try tuning it\n             '{:.2f}%'.format(width), #{:.2}: format float to 2 decimal places, i.e 3.14151296 -> 3.14\n            ha = 'center', va = 'center')\n    \n    \n# Customise\nax.set_title('% of deaths from police shootings/ncompared to percentage of population by Race', fontsize = 16)\nax.tick_params(axis = 'both', labelsize = 12)\nfor spine in ax.spines.values():\n    spine.set_visible(False)\nax.set_xlabel('')\nax.set_ylabel('')\nax.set_xticks([])\nplt.legend(frameon=False, fontsize=12, ncol=2)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Choropleth map to see the number of shooting within each State","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"state_counts = data.groupby(by = \"state\").agg({'id': 'count'}).reset_index()\nstate_counts\n\n#dataframe.agg = aggregate using one or more operations over the specified axis.\n#details: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure(data = go.Choropleth(\n    locations = state_counts['state'],\n    z = state_counts['id'],\n    locationmode = \"USA-states\",\n    colorscale = \"Viridis\",\n    colorbar_title = \"Deaths\"))\n\nfig.update_layout(\n    title_text = \"Police Shooting Deaths by US States\",\n    geo_scope = \"usa\")\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"However, our first map does not take into the level of population within each state into consideration, i.e. higher population higher no. of deaths. Therefore, we import the US state populations from 2018 dataset and factor that into our choropleth.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"state_pops = pd.read_csv('../input/us-state-populations-2018/State Populations.csv')\n\nstate_codes = {'California' : 'CA', 'Texas' : 'TX', 'Florida' : 'FL', 'New York' : 'NY', 'Pennsylvania' : 'PA',\n       'Illinois' : 'IL', 'Ohio' : 'OH', 'Georgia' : 'GA', 'North Carolina' : 'NC', 'Michigan' : 'MI',\n       'New Jersey' : 'NJ', 'Virginia' : 'VA', 'Washington' : 'WA', 'Arizona' : 'AZ', 'Massachusetts' : 'MA',\n       'Tennessee' : 'TN', 'Indiana' : 'IN', 'Missouri' : 'MO', 'Maryland' : 'MD', 'Wisconsin' : 'WI',\n       'Colorado' : 'CO', 'Minnesota' : 'MN', 'South Carolina' : 'SC', 'Alabama' : 'AL', 'Louisiana' : 'LA',\n       'Kentucky' : 'KY', 'Oregon' : 'OR', 'Oklahoma' : 'OK', 'Connecticut' : 'CT', 'Iowa' : 'IA', 'Utah' : 'UT',\n       'Nevada' : 'NV', 'Arkansas' : 'AR', 'Mississippi' : 'MS', 'Kansas' : 'KS', 'New Mexico' : 'NM',\n       'Nebraska' : 'NE', 'West Virginia' : 'WV', 'Idaho' : 'ID', 'Hawaii' : 'HI', 'New Hampshire' : 'NH',\n       'Maine' : 'ME', 'Montana' : 'MT', 'Rhode Island' : 'RI', 'Delaware' : 'DE', 'South Dakota' : 'SD',\n       'North Dakota' : 'ND', 'Alaska' : 'AK', 'District of Columbia' : 'DC', 'Vermont' : 'VT',\n       'Wyoming' : 'WY'}\n\nstate_pops['State Codes'] = state_pops['State'].apply(lambda x:state_codes[x])\nstate_counts['Pop'] = state_counts['state'].apply(\n    lambda x:state_pops[state_pops['State Codes'] == x].reset_index()['2018 Population'][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"state_counts.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure(data = go.Choropleth(\n    locations = state_counts['state'],\n    z = state_counts['id'] / state_counts['Pop'] * 100000,\n    locationmode = 'USA-states',\n    colorscale = 'Viridis',\n    colorbar_title = \"Deaths per 100,000\"))\n\nfig.update_layout(\n    title_text = 'Police Shooting Deaths by US States per 100,000 People',\n    geo_scope = \"usa\")\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Are Police Shooting Deaths Increasing?\n- Using seaborn's regplot to create a regression line through our data.\n- Grouping is needed first, by months","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import date\n\ndata['date'] = pd.to_datetime(data['date'])\nnewd = data.groupby(pd.Grouper(key = 'date', # Groupby key\n                               freq = 'M')).count().reset_index()[['date',  'id']]\n# freq: This will groupby the specified frequency if the target selection is a datetime-like object\nnewd.head()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newd['date_ordinal'] = newd['date'].apply(lambda x:x.toordinal())\n# The reason the date is changed to gregorian calender is that later when we plot the regplot, seaborn does not recognize \n# the original date format, but does recognise the gregorian format.\nnewd.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize = (12,4))\nsns.regplot(x = 'date_ordinal', y = 'id', ci = 95, ax = ax, data = newd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize = (12,4))\nsns.regplot(x = 'date_ordinal', y = 'id', ci = 95, ax = ax, data = newd)\n\nyear_labels = [newd['date_ordinal'].min() + (x * 365) for x in range(6)]\nax.set_xticks(year_labels)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize = (12,4))\nsns.regplot(x = 'date_ordinal', y = 'id', ci = 95, ax = ax, data = newd)\n\nyear_labels = [newd['date_ordinal'].min() + (x * 365) for x in range(6)]\nax.set_xticks(year_labels)\nax.set_xticklabels([2015, 2016, 2017, 2018, 2019, 2020])\nax.set_xlabel('Year')\nax.set_ylabel('Deaths')\n\nplt.title('US Police Shooting Deaths over Time', fontsize = 14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There isn't much difference throughout the years from what the plot shows.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Were the victims armed or unarmed?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"unarmed = ['unarmed', 'toy weapon', np.nan, 'undetermined', 'flashlight'] #creating a list of what exactly is unarmed to be applied later\n           \ndata['is_armed'] = data['armed'].apply(lambda x:'Armed' if x not in unarmed else 'Unarmed')\nunarmed_data = data[data['is_armed'] == 'Unarmed']\narmed_data = data[data['is_armed'] == 'Armed']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"armed_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unarmed_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (12, 12))\ngs = GridSpec(4, 2)\nax0 = fig.add_subplot(gs[0, :])\nax1 = fig.add_subplot(gs[1, 0])\nax2 = fig.add_subplot(gs[1, 1])\nax3 = fig.add_subplot(gs[2, 0])\nax4 = fig.add_subplot(gs[2, 1])\nax5 = fig.add_subplot(gs[3, 0])\nax6 = fig.add_subplot(gs[3, 1])\n\n\nfig.suptitle('Unarmed vs Armed', y = 1.03, fontsize = 18)\n\nsns.countplot('is_armed', ax = ax0, data = data, order = ['Unarmed', 'Armed'])\nax0.set_xlabel('')\n\n# Race\nsns.barplot(x = 'race', y = 'race', orient = 'v', ax = ax1, data = unarmed_data, \n           estimator = lambda x:len(x) / len(unarmed_data) * 100,\n           order = ['W', 'B', 'H', 'A', 'N', 'O'])\nsns.barplot(x = 'race', y = 'race', orient = 'v', ax = ax2, data = armed_data,\n           estimator = lambda x:len(x) / len(armed_data) * 100,\n           order = ['W', \"B\", \"H\", \"A\", 'N', 'O'])\nfor ax in [ax1, ax2]:\n    ax.set_ylabel('percent')\n    \n# Gender\nsns.barplot(x = 'gender', y = 'gender', orient = 'v', ax = ax3, data = unarmed_data, \n           estimator = lambda x:len(x) / len(unarmed_data) * 100,\n           order = ['M', 'F'])\nsns.barplot(x = 'gender', y = 'gender', orient = 'v', ax = ax4, data = armed_data, \n           estimator = lambda x: len(x) / len(armed_data) * 100,\n           order = ['M', 'F'])\n\n# Age\nsns.barplot(x = 'age', y = 'age', data = unarmed_data, ax = ax5, \n           estimator = lambda x:len(x) / len(unarmed_data) * 100)\nsns.barplot(x = 'age', y = 'age', data = armed_data, ax = ax6,\n           estimator = lambda x:len(x) / len(armed_data) * 100)\n\nfor ax in [ax5, ax6]:\n    ax.set_xticks(range(0, 90, 10))\n    ax.set_xticklabels(range(0, 90, 10))\n    ax.set_ylabel('percent')\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Who were the unarmed victims?\n- To visually display the names of the victims, we need to create a wordcloud first,\n- Secondly, we need to obtain an image mask, the map of the USA, and the mask must be binarised for this to work\n- Thirdly, we create the dictionary of the names, with the frequency that they appeared (each name appears once so we get 1 each time \n- Lastly, use the wordcloud package to create wordcloud.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\nimport requests\nfrom PIL import Image\nfrom io import BytesIO\n\n# Obtain image mask\nresponse = '../input/state-outline-png/672-6720557_us-outline-usa-map-vector-png-transparent-png.png'\nusa_mask = np.array(Image.open(response))[:,:,2]\nusa_mask = 255 * (usa_mask > 50)\n\n# Get a dict of unarmed names\nunarmed_names = data[data['armed'] == 'unarmed']['name'].values\nunarmed_names_dict = dict()\nfor name in unarmed_names:\n    unarmed_names_dict[name] = 1\n\n# Create wordcloud\nwc = WordCloud(background_color='white', mask=usa_mask, max_words=1000, contour_width=10, max_font_size=20, colormap='plasma').generate_from_frequencies(unarmed_names_dict)\n\n# Display wordcloud\nplt.figure(figsize=(10, 10))\nplt.imshow(wc, interpolation='bilinear')\nplt.axis('off')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"FInally! =D","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}