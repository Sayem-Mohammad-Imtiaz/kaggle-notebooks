{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Cancer prediction using Machine Learning"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nimport json   \nfrom pandas.io.json import json_normalize  \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## About this dataset\n\nFeatures are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. n the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n\nThis database is also available through the UW CS ftp server: ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd \n\nlocal = '../input/breast-cancer-wisconsin-data/data.csv'\ndf = pd.read_csv(local, encoding='latin-1', index_col=0)\n\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparing the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape\npd.isnull(df).sum() > 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['Unnamed: 32'], axis=1)\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#my_plot = df.plot(\"diagnosis\", \"radius_mean\", kind=\"scatter\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#my_plot = df.plot(\"diagnosis\", \"perimeter_mean\", kind=\"scatter\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.hist(figsize=(20, 20), color='green')\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.isnull(df).sum() > 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Categorization"},{"metadata":{"trusted":true},"cell_type":"code","source":"dfX = df.as_matrix(df.columns[2:])\ndfY = df.as_matrix(['diagnosis'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['diagnosis'] = df.diagnosis.astype(\"category\").cat.codes\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training machine learning models"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Length X:', dfX.shape)\nprint('Length Y:', dfY.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(dfX, dfY, test_size=0.20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def KNN(neighbors, X, y):\n    model_KNN = KNeighborsClassifier(n_neighbors = 3)\n    model_KNN.fit(X , y)\n    \n    return model_KNN\n\nnp.random.seed(1000)\nKNN_predict = KNN(4, X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def machine_learning_algorithms(train_X, train_y):   \n    n = 4\n    estimador = 100\n    \n    model_SVC = SVC()\n    model_SVC.fit(train_X , train_y)\n\n    model_GBC = GradientBoostingClassifier()\n    model_GBC.fit(train_X , train_y)\n    \n    model_KNN = KNeighborsClassifier(n_neighbors = n)\n    model_KNN.fit(train_X , train_y)\n    \n\n    return [model_SVC,\n            model_GBC,\n            model_KNN]\n    \n\nnp.random.seed(1000)\nalgoritms = machine_learning_algorithms(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = []\ntotal = []\nclassifier = ['SVG', 'GBC','KNN']\n\nfor index, name in enumerate(classifier):\n    score_train = algoritms[index].score(X_train, y_train) * 100\n    score_tests = algoritms[index].score(X_test, y_test) * 100\n    \n    total.append([name, score_train, score_tests])\n    \ndf_result = pd.DataFrame(total, columns = ['Model', 'Train score', 'Test score'])\nprint(df_result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = df_result.plot.bar(x='Model', y='Train score')\nax.set_ylabel(\"Score\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = df_result.plot.bar(x='Model', y='Test score')\nax.set_ylabel(\"Score\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}