{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\nHello people, welcome to my kernel. In this kernel I'll examine the dataset and after that, I will train a neural network using the dataset. Before the start, let's take a look at the content\n\n# Content\n1. Importing Libraries and The Data\n1. Data Overview\n1. Simple Data Analyses\n    * Examining Pragnancies Feature\n    * Examining Glucose Feature\n    * Examining Blood Pressure Feature\n    * Examining Skin Thickness Feature\n    * Examining Insulin Feature\n    * Examining BMI Feature\n    * Examining DiabetesPedigreeFunction Feature\n    * Examining Age Feature\n    * Examining Outcome Feature\n1. Outlier Detection\n    * Defining Function\n    * Dropping Outliers\n1. Detailed Data Analyses\n    * Correlation Heatmap\n    * Glucose - Outcome\n    * BMI - Outcome\n    * Age - Outcome\n1. Preprocessing\n    * Preparing Pregnancies Feature\n    * Normalization\n    * Train Test Split\n1. Modeling\n1. Predictinig\n1. Conclusion"},{"metadata":{},"cell_type":"markdown","source":"# Importing Libraries and The Dataset\n\nIn this section I will import the libraries and the dataset. I am not going to import deep learning libraries, I am going to import them when I will need. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings as wrn\n\nwrn.filterwarnings('ignore')\nsns.set_style(\"whitegrid\")\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* And now I'll import the data."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Overview\nIn this section I will get a general idea about the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* There are 9 features in the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* All of the features are numerical. 6 of them are int and the rest are float.\n* There is no missing values.\n* There are 768 rows in the dataset."},{"metadata":{},"cell_type":"markdown","source":"# Simple Data Analyses\n\nIn this section I will examine each feature's value's distribution. In order to do this I am going to use distplots and count plots."},{"metadata":{},"cell_type":"markdown","source":"## Examining Pregnancies Feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Pregnancies\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Although there are 17 unique values, most of them is 1,0 and 2. \n* We can join 11,12,13,14,15 and 17.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(10,7))\nsns.countplot(data[\"Pregnancies\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Examining Glucose Feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Glucose\"].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* As we can see, glucose data is not categorical, so we should use a distplot for examining it."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(figsize = (10,7))\nsns.distplot(data[\"Glucose\"],color=\"#FE5205\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Most of the values are between 70 and 130. "},{"metadata":{},"cell_type":"markdown","source":"## Examining Blood Pressure Feature"},{"metadata":{},"cell_type":"markdown","source":"* Let's start with reminding the feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"BloodPressure\"].head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* This is not a categorical feature as well. \n* So let's use a distplot."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(10,7))\nsns.distplot(data[\"BloodPressure\"],color=\"#00B037\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* An interesting chart. There are may 0 values in the dataset. However values that between 0 and 40 are very rare.\n* And most of the dataset is between 40 and 100 especially 60 and 80\n"},{"metadata":{},"cell_type":"markdown","source":"## Examining Skin Thickness Feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"SkinThickness\"].head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* This feature is not a categorical like the Blood Pressure and Glucose"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(10,7))\nsns.distplot(data[\"SkinThickness\"],color=\"#C0F714\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The values are between 0 and 60. Most of the dataset's value is 0. "},{"metadata":{},"cell_type":"markdown","source":"## Examining Insulin Feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Insulin\"].head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Most of the dataset's value must be 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(10,7))\nsns.distplot(data[\"Insulin\"],color=\"#077F8F\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Most of the dataset is 0\n* Although they are rare, there are values between 0 and 400.\n"},{"metadata":{},"cell_type":"markdown","source":"## Examining BMI Feature\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"BMI\"].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(10,7))\nsns.distplot(data[\"BMI\"],color=\"#DB6A14\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Not an interesting distplot\n* Most of the values are between 20 and 50."},{"metadata":{},"cell_type":"markdown","source":"## DiabetesPedigreeFunction Feature\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"DiabetesPedigreeFunction\"].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(10,7))\nsns.distplot(data[\"DiabetesPedigreeFunction\"],color=\"#8F105A\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Although most of the dataset between 0 and 1, there are values between 1 and 2.5"},{"metadata":{},"cell_type":"markdown","source":"## Examining Age Feature\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Age\"].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(10,7))\nsns.distplot(data[\"Age\"],color=\"#DB620D\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Most of the dataset between 20 and 40."},{"metadata":{},"cell_type":"markdown","source":"## Examining Outcome Feature"},{"metadata":{},"cell_type":"markdown","source":"* Outcome feature is our label.\n* It is a categorical feature, so we can use count plot."},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Outcome\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(10,7))\nsns.countplot(data[\"Outcome\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* This is an unbalanced data.\n* Most of the values are 0 \n* They are 500 0 values and 268 1 values."},{"metadata":{},"cell_type":"markdown","source":"# Outlier Detection\nIn this section I will drop the outliers, because you know, outliers can cause trouble. I am going to drop outliers using a handwritten function so let's start with defining the function."},{"metadata":{},"cell_type":"markdown","source":"## Defining Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def outlier_dropper(dataset):\n    check_index = []\n    final_index = []\n    for feature in dataset: # Each iteration is a different feature\n        \n        Q1 = dataset[feature].describe()[\"25%\"] # Lower Quartile\n        Q3 = dataset[feature].describe()[\"75%\"] # Upper Quartile\n        \n        IQR = Q3-Q1\n        STEP = IQR*1.5\n        \n        \n        indexes = data[(data[feature]<Q1-IQR) | (data[feature]>Q3+IQR)].index.values # Taking outlier's indexes.\n        \n        for i in indexes:  \n            check_index.append(i) # Appending each index into the check_index list.\n    \n    for i in check_index:        \n        check_index.remove(i)\n        if i in check_index: # If i still exists (If there is two outliers in the i index)\n            final_index.append(i) # Append it.\n    \n    return np.unique(final_index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* And now let's use our function."},{"metadata":{},"cell_type":"markdown","source":"## Dropping Outliers\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"indexes = outlier_dropper(data)\nprint(indexes)\nprint(\"------------------------------------------------------------------------------\")\nprint(len(indexes))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* There are 47 rows in the dataset that have outliers more than one."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(indexes,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Now we have 721 entries."},{"metadata":{},"cell_type":"markdown","source":"# Detailed Data Analyses\nIn this section I am going to examine the correlations between the features. I am going to start with examining the correlation heatmap."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(8,8))\nsns.heatmap(data.corr(),annot=True,fmt=\".2f\",linewidths=1.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* They are three strong correlation between outcome and other features\n\n* Glucose - Outcome (0.46)\n* Age - Outcome (0.24)\n* BMI - Outcome (0.29)\n\nLet's examine them using different plots."},{"metadata":{},"cell_type":"markdown","source":"## Glucose - Outcome"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(7,5))\nfig.add_subplot(1,2,1)\nsns.kdeplot(data[\"Glucose\"],data[\"Outcome\"])\nfig.add_subplot(1,2,2)\nsns.scatterplot(data[\"Glucose\"],data[\"Outcome\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* When outcome is 1, glucose is bigger than 100. "},{"metadata":{},"cell_type":"markdown","source":"## Age - Outcome"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(7,5))\nfig.add_subplot(1,2,1)\nsns.kdeplot(data[\"Outcome\"],data[\"Age\"])\nfig.add_subplot(1,2,2)\nsns.scatterplot(data[\"Outcome\"],data[\"Age\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## BMI - Outcome"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(7,5))\nfig.add_subplot(1,2,1)\nsns.kdeplot(data[\"BMI\"],data[\"Outcome\"])\nfig.add_subplot(1,2,2)\nsns.scatterplot(data[\"BMI\"],data[\"Outcome\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing\nIn this section I am going to preapre the dataset for modeling. In order to prepare the dataset. I will follow these steps:\n\n* Preparing Pregnancies Feature\n    * Joinining 11,12,13,14,15,17\n    * One Hot Encoding\n* Normalization\n* Train Test Splitting"},{"metadata":{},"cell_type":"markdown","source":"## Preparing Pregnancies Feature\n\n### Joining 11,12,13,14,15,17 "},{"metadata":{},"cell_type":"markdown","source":"* Before the joining, let's remind the countplot of pregnancies feature."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(10,7))\nsns.countplot(data[\"Pregnancies\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pregnancies = []\n\nfor i in data[\"Pregnancies\"]:\n    \n    if i==11 or i==12 or i==13 or i==14 or i==15 or i==17:\n        pregnancies.append(11)\n    \n    else:\n        pregnancies.append(i)\n\ndata.Pregnancies = pregnancies","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* And now I will check countplot again."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(10,7))\nsns.countplot(data[\"Pregnancies\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Okey, we are ready one hot encoding"},{"metadata":{},"cell_type":"markdown","source":"### One Hot Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.get_dummies(data,columns=[\"Pregnancies\"])\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Normalization (Scaling)\n\nAnd now I am going to normalize data because if we normalize the data, training time will be better."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range=(0,1))\n\nx = data.drop(\"Outcome\",axis=1)\ny = data.Outcome\n\nx = scaler.fit_transform(x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I've created x and y in this section, because I don't want to normalize y axis."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Shape of x\",x.shape)\ny = y.values\nprint(\"Shape of y\",y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = y.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Test Splitting\nIn this section I will split the data into train and test. In order to do this I will use SKLearn library's train_test_split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Finally we are ready for modeling!"},{"metadata":{},"cell_type":"markdown","source":"# Modeling\nIn this section I'll build the model using Keras library and after that I will fit it using our x_train and y_train."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Dropout,Dense\nfrom keras.models import Sequential","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(units=16,kernel_initializer=\"uniform\",activation=\"tanh\",input_dim=19)) # Layer 1\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(units=16,kernel_initializer=\"uniform\",activation=\"tanh\")) # Layer 2\nmodel.add(Dropout(0.50))\n\nmodel.add(Dense(units=32,kernel_initializer=\"uniform\",activation=\"tanh\")) # Layer 3\nmodel.add(Dropout(0.50))\n\nmodel.add(Dense(units=32,kernel_initializer=\"uniform\",activation=\"tanh\")) # Layer 4 \nmodel.add(Dropout(0.50))\n\nmodel.add(Dense(units=32,kernel_initializer=\"uniform\",activation=\"tanh\")) # Layer 5\nmodel.add(Dropout(0.50))\n\nmodel.add(Dense(units=32,kernel_initializer=\"uniform\",activation=\"tanh\")) # Layer 6\nmodel.add(Dropout(0.50))\n\nmodel.add(Dense(units=32,kernel_initializer=\"uniform\",activation=\"tanh\")) # Layer 7\nmodel.add(Dropout(0.50))\n\nmodel.add(Dense(units=1,kernel_initializer=\"uniform\",activation=\"sigmoid\")) # Output Layer\nmodel.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Our frame is ready, let's fit it using our train arrays."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_train,y_train,epochs=250)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predicting\nIn this section I will predict the values using our model and after that I will take a look at the confusion matrix and the score."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ny_head = model.predict_classes(x_test)\n\nprint(\"The score is \",accuracy_score(y_test,y_head))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Not bad but not good."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix = confusion_matrix(y_test,y_head)\n\nfig,ax = plt.subplots(figsize=(6,6))\nsns.heatmap(confusion_matrix,annot=True,fmt=\"0.1f\",cmap=\"Greens_r\",linewidths=1.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Model had difficulty when it predict 1 values. \n* It is a predictible result, because you will remember, the number of 1 values in the dataset is lower than 0 values."},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\n\nThanks for your attention, if you have any questions in your mind, you can ask me in the comment section. I am waiting for your comments, questions and upvotes. \n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}