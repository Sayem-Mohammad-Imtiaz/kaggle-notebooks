{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Retinal Multi Disease Classification\n<img src=\"https://i.ibb.co/6szKmbL/Folder-Organisation.jpg\" alt=\"data\" style=\"width: 800px;\">","metadata":{"id":"6HSr9WDZ4Znm"}},{"cell_type":"markdown","source":"<img src=\"https://i.ibb.co/pxFk0TG/composition.jpg\" alt=\"data\" style=\"width: 300px;\">","metadata":{"id":"eYmVGMUFsxK_"}},{"cell_type":"markdown","source":"**Notebook and GPU preparation with Google Colab**","metadata":{"id":"SsRFS9EOtqrO"}},{"cell_type":"code","source":"gpu_info = !nvidia-smi\ngpu_info = '\\n'.join(gpu_info)\nif gpu_info.find('failed') >= 0:\n  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator,')\n  print('and then re-execute this cell.')\nelse:\n  print(gpu_info)","metadata":{"id":"qWpVfUu5oTmO","outputId":"3b95f753-5480-4716-a74f-13d366970fe1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/drive', force_remount=True)","metadata":{"id":"pRuT9vhIqusm","outputId":"e86b8ba4-5ace-4e42-a90c-82992b5aa956"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from psutil import virtual_memory\nram_gb = virtual_memory().total / 1e9\nprint('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n\nif ram_gb < 20:\n  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n  print('re-execute this cell.')\nelse:\n  print('You are using a high-RAM runtime!')","metadata":{"id":"uRt-RQIVqwxU","outputId":"e32e57e6-69ff-4a9f-90bf-66c9ee911013"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\nwith zipfile.ZipFile('/content/drive/MyDrive/Retinal_Disease/retinal_disease.zip', 'r') as zip_ref:\n    zip_ref.extractall('/content')","metadata":{"id":"BWWfilzAq3Ft","outputId":"22ff609b-266f-4a9f-bab5-a55f58b39a42"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nprint(sys.executable)\nprint(sys.version)\nprint(sys.version_info)","metadata":{"id":"_84hWxDfrA1c","outputId":"17130e9b-f64b-45db-e0ff-5b3a823e426b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Packages and data preprocessing**","metadata":{"id":"Pp_x_psEty8M"}},{"cell_type":"code","source":"#Importation of packages and datasets\nimport os \nfrom tqdm import tqdm\nfrom glob import glob\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport numpy as np\nimport tensorflow as tf\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n\n\nprint(os.getcwd())\npath_cwd = os.getcwd()\n\nX_train = pd.read_csv('/content/Training_Labels.csv')\nX_val = pd.read_csv('/content/Validation_Labels.csv')\nX_test = pd.read_csv('/content/Test_Labels.csv')","metadata":{"id":"p-BOet9PrCgd","outputId":"258c7072-5f27-476e-f7b8-2bc71cdf88c7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"id":"KOWOE7D7pGJY","outputId":"9e88622d-5bba-4a98-c349-65d713e3571e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.describe()\n#No missing value","metadata":{"id":"Pu9zLg54qHPH","outputId":"4369b563-439f-4f88-ca4e-907c7e90324d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reconstituion link image + drop ID feature\nX_train['filename'] = X_train.apply(lambda x : \"/content/Training/\" +str(x['ID']) + \".png\", axis=1)\nX_val['filename'] = X_val.apply(lambda x : \"/content/Validation/\" +str(x['ID']) + \".png\", axis=1)\nX_test['filename'] = X_test.apply(lambda x : \"/content/Test/\" +str(x['ID']) + \".png\", axis=1)\n\nX_train = X_train.drop('ID', axis=1)\nX_val = X_val.drop('ID', axis=1)\nX_test = X_test.drop('ID', axis=1)","metadata":{"id":"f6JFvyJLosaR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.head(1))\nprint(X_train.shape)\n#46 class + risk evaluation (47 features)","metadata":{"id":"BmBvTNIFrwcu","outputId":"d26d7cf7-aba8-4f27-b0d8-758ed1a46352"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#datasets\nX_train_img = X_train['filename']\nX_val_img = X_val['filename']\ny_train = X_train.drop(['filename'], axis=1)\ny_val = X_val.drop(['filename'], axis=1)\n\nprint('shape of X_train:', X_train_img.shape)\nprint('shape of Validation:', X_val_img.shape)\nprint('shape of y_train:', y_train.shape)\nprint('shape of y_val:', y_val.shape)","metadata":{"id":"yyP20BwExLWT","outputId":"880a0f2c-bfdb-4a9e-eab4-24fc972a96c2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot some random images\nimport cv2\nimport random\ndef plotImages():\n    i=1\n    plt.figure(figsize=(15,10))\n    for r in random.sample(glob(path_cwd + '/Training/**'), 15):\n      plt.subplot(3,5,i)\n      img = cv2.imread(r)\n      img = tf.reverse(img, axis=[-1])\n      img =  tf.image.adjust_contrast(img, 1.5)\n      plt.imshow(img)\n      i+=1\n      plt.axis('off')","metadata":{"id":"RYBSN3Oi9lxG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotImages() #Seems we have to convert to RGB format","metadata":{"id":"dromFwjw96lM","outputId":"f1f68009-b8da-4d63-9017-9fa097bec119"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing images","metadata":{"id":"Yt7zpW8M0woJ"}},{"cell_type":"code","source":"IMG_SHAPE = (300, 450)\nBATCH_SIZE = 64","metadata":{"id":"1aOunvgA0-B-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\n\n#Fonction pour prprocessing des images\ndef scale_down(img):\n    img = tf.cast(img, dtype=tf.float32)\n    img = tf.image.resize(img, (300, 450), method='nearest')\n    img = (img / 255)\n    \n    return img\n\n#Preprocessing du jeu d'entrainement\ndef preprocessing_data(img):\n   \n    #Lecture et d√©codage des images:\n    img = tf.io.read_file(img)\n    img = tf.io.decode_png(img, channels=3)\n\n    #adjust contrast\n    img =  tf.image.adjust_contrast(img, 1.35)\n\n    #Resize\n    img = scale_down(img)\n\n    return img\n","metadata":{"id":"Nc90BUQD2A-I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Datasets preprocessing\nAUTO = tf.data.experimental.AUTOTUNE\n\ny_train = np.array(y_train).astype('float32')\ny_val = np.array(y_val).astype('float32')\n\ndataset_train = tf.data.Dataset.from_tensor_slices((X_train_img, y_train))\ndataset_val = tf.data.Dataset.from_tensor_slices((X_val_img, y_val))\n\ndataset_train=(dataset_train\n               .shuffle(1000)\n               .map(lambda x, y: [preprocessing_data(x), y], num_parallel_calls=AUTO)\n               .batch(BATCH_SIZE, drop_remainder=True)\n               .prefetch(AUTO)\n               )\n\ndataset_val=(dataset_val\n             .map(lambda x, y: [preprocessing_data(x), y], num_parallel_calls=AUTO)\n             .batch(BATCH_SIZE, drop_remainder=True)\n             .prefetch(AUTO)\n             )\n\n\nprint(dataset_train)\nprint(dataset_val)","metadata":{"id":"6tcDiKcXdlIJ","outputId":"c60fc1ac-aef6-457f-f263-d9a8b78868c5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize(original, augmented):\n    fig = plt.figure()\n    plt.subplot(1,2,1)\n    plt.title('Original image')\n    plt.imshow(original)\n    plt.axis('off')\n\n    plt.subplot(1,2,2)\n    plt.title('Augmented image')\n    plt.imshow(augmented)\n    plt.axis('off')\n","metadata":{"id":"59_JZb_I2qvI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image, label = next(iter(dataset_train))\nimage, label = image.numpy()[0], label.numpy()[0]\n\n\nflipped = tf.image.flip_left_right(image)\nflipped =  tf.image.adjust_contrast(flipped, 1.35)\nvisualize(image, flipped)","metadata":{"id":"RP1Is4ji2sZW","outputId":"a9ad09b5-5bd9-4a88-b9a2-a9f33c155a32"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"```\nfrom keras.utils.data_utils import Sequence\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.tensorflow import balanced_batch_generator\n\n\nclass BalancedDataGenerator(Sequence):\n    \"\"\"ImageDataGenerator + RandomOversampling\"\"\"\n    def __init__(self, x, y, datagen, batch_size=64):\n        self.datagen = datagen\n        self.batch_size = min(batch_size, x.shape[0])\n        datagen.fit(x)\n        self.gen, self.steps_per_epoch = balanced_batch_generator(x.reshape(x.shape[0], -1), y, sampler=RandomOverSampler(), batch_size=self.batch_size, keep_sparse=True)\n        self._shape = (self.steps_per_epoch * batch_size, *x.shape[1:])\n        \n    def __len__(self):\n        return self.steps_per_epoch\n\n\n    def __getitem__(self, idx):\n        x_batch, y_batch = self.gen.__next__()\n        x_batch = x_batch.reshape(-1, *self._shape[1:])\n        return self.datagen.flow(x_batch, y_batch, batch_size=self.batch_size).next()\n\nbalanced_gen = BalancedDataGenerator(X_train_path, y_train, train_generator, batch_size=64)\n#balanced_gen_val = BalancedDataGenerator(X_val, y_val, train_generator, batch_size=64)\nsteps_per_epoch = balanced_gen.steps_per_epoch\n\n```\n\n","metadata":{"id":"YudwlOWpUls7"}},{"cell_type":"code","source":"#API keras preparation\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, Dropout, BatchNormalization, Activation, MaxPool2D, Dense, Flatten, GlobalAvgPool2D\nfrom keras import backend as K\nfrom tensorflow.keras.applications import VGG16\nvgg16 = VGG16()\n\n#for layer in xception.layers:\n#    print(layer.name, layer)","metadata":{"id":"-tK-31cE3YMT","outputId":"07352639-47b7-44a3-e1da-584b2a240ea3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Global architecture VGG16:\n________________________________________________________________________________\n<img src=\"https://datascientest.com/wp-content/uploads/2021/04/illu_VGG-02.png\" alt=\"data2\" align=\"top\" style=\"width: 800px;\">\n","metadata":{"id":"yvKiDs5s7Wzv"}},{"cell_type":"markdown","source":"## Classification model","metadata":{"id":"5ZbKSepW7kHc"}},{"cell_type":"code","source":"shape = (250, 400,3)\n\ndef Layers(inputs, trainable=False):\n    global vgg16_model\n    vgg16_model = VGG16(weights='imagenet',\n                        include_top=False,\n                        input_tensor=inputs)\n    \n    if trainable == True:\n        for layer in vgg16_model.layers:\n            layer.trainable = True\n            \n    else:\n        vgg16_model.trainable = False\n            \n    return vgg16_model.output\n    \n        \ndef Build_VGG16(trainable=False):\n    \n    inputs = Input(shape=shape)\n    vgg16 = Layers(inputs, trainable)\n\n    conv1 = Flatten()(vgg16_model.output)\n    \n    dense2 = Dense(256,activation='relu')(conv1)\n    dense2 = Dropout(rate=0.2)(dense2)\n    \n    dense3 = Dense(128,activation='relu')(dense2)\n    dense3 = Dropout(rate=0.2)(dense3)\n    \n    model = Dense(46,activation= 'sigmoid')(dense3)\n    \n    return Model(inputs=inputs, outputs = model)\n\nmodel = Build_VGG16()\nmodel.summary()","metadata":{"id":"y9EDITPj877b","outputId":"9d395dd5-c528-4b09-ef3b-83c54e28c20a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n*   use a LR function to adapt Gradient\n*   Class imbalanced, we create a loss fonction to adjust weight \n\n","metadata":{"id":"utde5o_BF5py"}},{"cell_type":"code","source":"class LossLearningRateScheduler(tf.keras.callbacks.History):\n    \"\"\"\n    base_lr: the starting learning rate\n    lookback_epochs: the number of epochs in the past to compare with the loss function at the current epoch to determine if progress is being made.\n    decay_threshold / decay_multiple: if loss function has not improved by a factor of decay_threshold * lookback_epochs, then decay_multiple will be applied to the learning rate.\n    spike_epochs: list of the epoch numbers where you want to spike the learning rate.\n    spike_multiple: the multiple applied to the current learning rate for a spike.\n    \"\"\"\n\n    def __init__(self, base_lr, lookback_epochs, spike_epochs = None, spike_multiple = 10, decay_threshold = 0.002, decay_multiple = 0.7, loss_type = 'val_loss'):\n\n        super(LossLearningRateScheduler, self).__init__()\n        self.base_lr = base_lr\n        self.lookback_epochs = lookback_epochs\n        self.spike_epochs = spike_epochs\n        self.spike_multiple = spike_multiple\n        self.decay_threshold = decay_threshold\n        self.decay_multiple = decay_multiple\n        self.loss_type = loss_type\n\n\n    def on_epoch_begin(self, epoch, logs=None):\n\n        if len(self.epoch) > self.lookback_epochs:\n            current_lr = tf.keras.backend.get_value(self.model.optimizer.lr)\n            target_loss = self.history[self.loss_type] \n            loss_diff =  target_loss[-int(self.lookback_epochs)] - target_loss[-1]\n\n\n            if loss_diff <= np.abs(target_loss[-1]) * (self.decay_threshold * self.lookback_epochs):\n                print(' '.join(('Changing learning rate from', str(current_lr), 'to', str(current_lr * self.decay_multiple))))\n                tf.keras.backend.set_value(self.model.optimizer.lr, current_lr * self.decay_multiple)\n                current_lr = current_lr * self.decay_multiple\n\n            else:\n                print(' '.join(('Learning rate:', str(current_lr))))\n\n            if self.spike_epochs is not None and len(self.epoch) in self.spike_epochs:\n                print(' '.join(('Spiking learning rate from', str(current_lr), 'to', str(current_lr * self.spike_multiple))))\n                tf.keras.backend.set_value(self.model.optimizer.lr, current_lr * self.spike_multiple)\n\n        else:\n            print(' '.join(('Setting learning rate to', str(self.base_lr))))\n            tf.keras.backend.set_value(self.model.optimizer.lr, self.base_lr)\n\n        return tf.keras.backend.get_value(self.model.optimizer.lr)\n\ncallback_lr = LossLearningRateScheduler(base_lr=0.001, lookback_epochs=2)","metadata":{"id":"MtAyPNC0YlxM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Re-Weighting classes binary crossentropy\n\ndef dyn_weighted_bincrossentropy(true, pred):\n\n    # get the total number of inputs\n    num_pred = K.sum(K.cast(pred < 0.5, true.dtype)) + K.sum(true)\n    # get weight of values in 'pos' category\n    zero_weight =  K.sum(true)/ num_pred +  K.epsilon() \n    # get weight of values in 'false' category\n    one_weight = K.sum(K.cast(pred < 0.5, true.dtype)) / num_pred +  K.epsilon()\n    # calculate the weight vector\n    weights =  (1.0 - true) * zero_weight +  true * one_weight \n    # calculate the binary cross entropy\n    bin_crossentropy = K.binary_crossentropy(true, pred)\n    # apply the weights\n    weighted_bin_crossentropy = weights * bin_crossentropy \n\n    return K.mean(weighted_bin_crossentropy)\n\n\ndef weighted_bincrossentropy(true, pred, weight_zero = 0.25, weight_one = 1):\n\n    # calculate the binary cross entropy\n    bin_crossentropy = K.binary_crossentropy(true, pred)\n    # apply the weights\n    weights = true * weight_one + (1. - true) * weight_zero\n    weighted_bin_crossentropy = weights * bin_crossentropy \n\n    return K.mean(weighted_bin_crossentropy)","metadata":{"id":"97hEQDUOhNk5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.metrics import AUC\npr_metric = AUC(curve='PR', num_thresholds=5000, from_logits=True, name='pr_metric') # The higher the threshold value, the more accurate it is calculated.\nroc_metric = AUC(curve='ROC', num_thresholds=5000, from_logits=True, name='roc_metric') \n","metadata":{"id":"ycYqRxWMG2JZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss=dyn_weighted_bincrossentropy,\n              optimizer =tf.keras.optimizers.Adam(),\n              metrics= [roc_metric, pr_metric])\n\n#weighted_binary_crossentropy","metadata":{"id":"YH4YEjiuAL8Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, 'retinal_output_model.png', show_shapes=True, dpi=100)","metadata":{"id":"q3AaM8SbAium","outputId":"c45beb16-6764-4b5a-e5aa-fe190a55599d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(dataset_train,\n                    validation_data=dataset_val,\n                    epochs=15, \n                    verbose=1, \n                   callbacks=callback_lr)","metadata":{"id":"vJ2VfM1cAp_Z","outputId":"5b16cf6b-eacf-45be-9fc3-f3f8fd181690"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import model_from_json\n\nmodel_archtecture = model.to_json()\n\nwith open('retinal_model.json', 'w') as json_file:\n    json_file.write(model_archtecture)\n\nmodel.save('./retinal_model')\nmodel.save_weights('./retinal_model.h5')","metadata":{"id":"UuKKLGhBf19D","outputId":"103a5cf9-3ff2-4eed-fdc8-8ac0357f9089"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" !zip -r /content/retinal_model.zip /content/retinal_model","metadata":{"id":"q8cjA6SyhGxn","outputId":"80f64acd-7ef7-44ba-b882-cc900765201b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predictions and ROC/PR curves on X_test","metadata":{"id":"rYBSNaewOTPc"}},{"cell_type":"code","source":"#preparation and preprocesing\nX_test_path = X_test['filename']\ny_test = X_test.drop(['filename'], axis=1)\ny_test = np.array(y_test).astype('float32')\n\nprint('shape of X_test:', X_test_img.shape)\nprint('shape of y_test:', y_test.shape)\n\nX_test_img  = []\nfor filepath in tqdm(X_test_path):\n\n  #Read and decode\n  img = tf.io.read_file(filepath)\n  img = tf.io.decode_png(img, channels=3)\n\n  #adjust contrast\n  img =  tf.image.adjust_contrast(img, 1.5)\n\n  #Resize\n  img = scale_down(img)\n  X_test_img.append([img])\n","metadata":{"id":"KHFHG-VpOYrB","outputId":"d7be2d06-0bc6-4ef0-f4cb-9c3b5c8bcb5f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#transform to array numpy\nX_test_img = np.array(X_test_img)\nX_test_img = X_test_img[:,0,:,:]\nX_test_img.shape","metadata":{"id":"5z8Bpd42XUn5","outputId":"84939e7a-fd81-41e1-c810-a08dd4a78523"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test_img)","metadata":{"id":"kjZH5agGYFWo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\nauc_scores = []\nfor i in range(46):\n  try:\n    auc = roc_auc_score(y_test[:,i], y_pred[:,i])\n    auc_scores.append(auc)\n  except:\n    pass\n\n\ndef Average(lst):\n    return sum(lst) / len(lst)\n  \navg_auc = Average(auc_scores)\n  \n# Printing average of the list\nprint(\"Average auc score available classes =\", round(avg_auc, 2),'%')","metadata":{"id":"PA_rT9GJc4y0","outputId":"a254b014-e8bd-4437-ee71-7b0a271b077c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"XRs6TgmypdXd"},"execution_count":null,"outputs":[]}]}