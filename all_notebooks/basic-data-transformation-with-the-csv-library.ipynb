{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Basic Data Transformation\n\nThis is a basic ressource for data transformation and information about loading it in different ways. I simply do this, because I am an absolute beginner and need this anyaway to look such information up. I am pretty sure there are far better ressources out there. \n\nThe comments in the code build upon each other. I tried to remove all comments from previous blocks, if I started a new code block. In order to use this notebook, the first code blocks need to be executed."},{"metadata":{},"cell_type":"markdown","source":"## Kaggle Standard Code\nStandard code that came shipped with this notebook. Imports most important libraries and can print the data files you've added to this kernel."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n'''\nInput data files are available in the read-only \"../input/\" directory\nFor example, running this (by clicking run or pressing Shift+Enter) will list all files \nunder the input directory if you change /kaggle to /kaggle/inpuit. Else it will list all files in /kaggle\n'''\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# print directories in /kaggle/\nfor dirname, _, filenames in os.walk('/kaggle'):\n    print(dirname)\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import the CSV file"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Good library for working with csv files\nimport csv\n\n#    Open the csv      'r' for read        write into variable csv_file (not the content of the file, but the opened csv file is called by using this variable)\nwith open('../input/chess/games.csv', 'r') as csv_file:\n    csv_reader = csv.reader(csv_file) # The reader module reads the csv file, it expects a comma separated file, but can also work with other separators if you give it the right argument.\n    \n    print(csv_reader) # Prints information on the standard variable in it's object form\n\n    row_count = sum(1 for row in csv_reader)\n    print(row_count) # Prints the row count + header, e.g. 20.059 = 1 header row + 20.058 records","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('../input/chess/games.csv', 'r') as csv_file:\n    csv_reader = csv.reader(csv_file)\n        \n    # This prints all the content from the file. Do not do this \n    for line in csv_reader:\n        print(line)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('../input/chess/games.csv', 'r') as csv_file:\n    csv_reader = csv.reader(csv_file)\n    \n    # This prints out only the first column / field / index \n    for line in csv_reader:\n        print(line[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('../input/chess/games.csv', 'r') as csv_file:\n    csv_reader = csv.reader(csv_file)\n        \n    next(csv_reader) # jumps over the first value (in this case, the header)\n\n    for line in csv_reader:\n        print(line[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split Data by Column and Field\n"},{"metadata":{},"cell_type":"markdown","source":"As a first step, we only want to learn, how we can write into another file. "},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('../input/chess/games.csv', 'r') as csv_file:\n    csv_reader = csv.reader(csv_file)\n    \n    # We create or open here a new csv file and tell the new_file variable, that we want to write in here something.\n    with open('game_over.csv', 'w') as new_file:\n    \n        csv_writer = csv.writer(new_file, delimiter='-') # We want to write the content of the csv file into a new file, with another delimiter. In this case, dashes.\n        # The csv writer knows what are values and what are delimiters, as it puts dashes around values, that contain the delimiter choosen\n        # another delimiter would be \\t for tab separation\n        for line in csv_reader:\n            csv_writer.writerow(line)\n\ndata = pd.read_csv('game_over.csv') \nprint(data.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Doing the same thing with the `DictReader` method has the advantage, that we can control the output of the fieldnames much better. It is also easier to just read a certain field, because instead of using and index, you just enter the field name, e.g. `print(line['email'])`."},{"metadata":{"trusted":true},"cell_type":"code","source":"# I do not know the fieldnames\ndata = pd.read_csv('../input/chess/games.csv') \nprint(data.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Split Data by Field"},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('../input/chess/games.csv', 'r') as csv_file:\n    csv_reader = csv.DictReader(csv_file)\n    \n    # We create or open here a new csv file and tell the new_file variable, that we want to write in here something.\n    with open('game_over.csv', 'w') as new_file:\n        # If I do not mention all field names, it will only take the choosen field names in this variable. Rated and Winner are missing here\n        fields = ['id', 'increment_code', 'opening_ply', 'black_rating', 'victory_status', 'white_id', 'created_at', \n                  'last_move_at', 'opening_name', 'turns', 'black_id', 'opening_eco', 'white_rating', 'moves']\n        \n        csv_writer = csv.DictWriter(new_file, fieldnames=fields, delimiter=',') # here we add the fieldnames\n        \n        csv_writer.writeheader() # Writes the first line as headers\n        \n        for line in csv_reader:\n            # An error that comes in handy here: You just choose the desired field names \n            # you want and put them in the variable fields above. After running the code, \n            # you got an error that lists all lines you forogtot to choose.  If you do not want\n            # those lines, just copy and paste them in the line below, like I did.\n            # I am sure there are better ways, to do this. \n            del line['rated']\n            del line['winner']\n            csv_writer.writerow(line)\n\n# Print the head of the new file\ndata = pd.read_csv('game_over.csv') \nprint(data.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Split Data by Column"},{"metadata":{},"cell_type":"markdown","source":"After we've understood the basics of reading and writing a csv file, we learn to split the file after certain lines and add headers to both files. The idea comes out of the need for separate training, test data and in case of big data sets also some demo data, to just build the model and not to load the several gb file, just to find out, the rest of the code does not work. "},{"metadata":{"trusted":true},"cell_type":"code","source":"import math \n\nwith open('../input/chess/games.csv', 'r') as csv_file:\n    csv_reader = csv.DictReader(csv_file)\n    \n    # get the split\n    row_count = sum(1 for row in csv_reader) # counts all lines\n    row_count = row_count - 1 # -1 because I only want the records\n    split_level = math.ceil(row_count * 0.8) \n        # how big should the first file be relative to the total record count\n        # math.ceil, because we want an integer\n        # you might also change this to 0.2 or something else. If the\n        # training data is smaller then 0.5, you might change names, as I do\n        # use always use more data for training, then for testing\n\n# Somehow the csv file did not work, when I did not open it again\nwith open('../input/chess/games.csv', 'r') as csv_file:\n    csv_reader = csv.DictReader(csv_file)\n\n    with open('game_over_training.csv', 'w') as new_file:\n        fields = ['id', 'rated', 'winner', 'increment_code', 'opening_ply', 'black_rating', 'victory_status', 'white_id', \n                    'created_at', 'last_move_at', 'opening_name', 'turns', 'black_id', 'opening_eco', 'white_rating', 'moves']\n        \n        csv_writer = csv.DictWriter(new_file, fieldnames=fields, delimiter=',')\n        csv_writer.writeheader()\n        \n        count = 1 # start the counter at 1\n        for line in csv_reader:\n            if count < split_level: # only write in the csv file for items below the split level\n                csv_writer.writerow(line)\n            count = count + 1\n\ndata = pd.read_csv('game_over_training.csv') \nprint(data.head())\n\n# Let's write the test data\nwith open('../input/chess/games.csv', 'r') as csv_file:\n    csv_reader = csv.DictReader(csv_file)\n\n    with open('game_over_test.csv', 'w') as new_file:\n        fields = ['id', 'rated', 'winner', 'increment_code', 'opening_ply', 'black_rating', 'victory_status', 'white_id', \n                    'created_at', 'last_move_at', 'opening_name', 'turns', 'black_id', 'opening_eco', 'white_rating', 'moves']\n        \n        csv_writer = csv.DictWriter(new_file, fieldnames=fields, delimiter=',')\n        csv_writer.writeheader()\n        \n        count = 1 # start the counter at 1 again, needs always to be equal, so the first lines are now ignored until we are at the split level\n        for line in csv_reader:\n            if count >= split_level: # only write in the csv file for items below and equal the split level\n                csv_writer.writerow(line)\n            count = count + 1\n\ndata = pd.read_csv('game_over_test.csv') \nprint('\\n------------------------------------------------------------')\nprint(data.head())\n\n# The last one is the demo data\nwith open('../input/chess/games.csv', 'r') as csv_file:\n    csv_reader = csv.DictReader(csv_file)\n\n    with open('game_over_demo.csv', 'w') as new_file:\n        fields = ['id', 'rated', 'winner', 'increment_code', 'opening_ply', 'black_rating', 'victory_status', 'white_id', \n                    'created_at', 'last_move_at', 'opening_name', 'turns', 'black_id', 'opening_eco', 'white_rating', 'moves']\n        \n        csv_writer = csv.DictWriter(new_file, fieldnames=fields, delimiter=',')\n        csv_writer.writeheader()\n        \n        count = 1 # start the counter at 1 again\n        for line in csv_reader:\n            if count < 1000: # for demo data to play around with, 1.000 lines should be fine\n                csv_writer.writerow(line)\n            count = count + 1\n\ndata = pd.read_csv('game_over_demo.csv')\nprint('\\n------------------------------------------------------------')\nprint(data.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we have created three files:\n* The first files ist my training data file\n* The second is my test data file\n* The third I will use to develop in my notebook, to avoid loading all the data, until the code is not clean\n\nWith panda I guess, you could achieve similar things, but csv worked out well and it felt more natural to me, to work with a dedicated csv package here. Hope this helps also others. If someone knows better solution and is willing to explain them in a reproducable way here, you are free to do so."},{"metadata":{},"cell_type":"markdown","source":"## Sources\nThe following helped to develop this notebook:\n* In this training, we used the games.csv dataset, which is taken from [here](https://www.kaggle.com/datasnaek/chess).\n* [YT Python Tutorial on working with csv files](https://www.youtube.com/watch?v=q5uM4VKywbA)\n\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}