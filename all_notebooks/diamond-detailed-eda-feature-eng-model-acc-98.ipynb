{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this kernel I have tried to find out first which feature is catergorical and which feature is numerical. Then in categorical , using EDA I have divided it into ordinal and nominal. For ordinal I have mapped it seperately and for nominal I have used one hot encoding.\n\nMoving forward checking the skewness of the dependent variable, I have used log of the dependent variable. Taking the log reduces the skewness.\n\nFruther I have introduced a new feature called volume, using feature x,y,z and removed this 3 features. This new feature introduced has helped to reach better accuracy.\n\nFinally I have fed the data into model, and getting a accuracy of around 98%."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ignore warnings :\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n# Handle table-like data and matrices :\nimport numpy as np\nimport pandas as pd\nimport math \n\n\n\n# Modelling Algorithms :\n\n# Classification\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis , QuadraticDiscriminantAnalysis\n\n# Regression\nfrom sklearn.linear_model import LinearRegression,Ridge,Lasso,RidgeCV, ElasticNet\nfrom sklearn.ensemble import RandomForestRegressor,BaggingRegressor,GradientBoostingRegressor,AdaBoostRegressor \nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neural_network import MLPRegressor\n\n\n\n\n# Modelling Helpers :\nfrom sklearn.preprocessing import Imputer , Normalizer , scale\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.model_selection import GridSearchCV , KFold , cross_val_score\n\n\n\n#preprocessing :\nfrom sklearn.preprocessing import MinMaxScaler , StandardScaler, Imputer, LabelEncoder\n\n#evaluation metrics :\n\n# Regression\nfrom sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error \n\n# Classification\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score  \n\n\n\n# Visualisation\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\n#import missingno as msno\n\n\n\n# Configure visualisations\n%matplotlib inline\nmpl.style.use( 'ggplot' )\nplt.style.use('fivethirtyeight')\nsns.set(context=\"notebook\", palette=\"dark\", style = 'whitegrid' , color_codes=True)\nparams = { \n    'axes.labelsize': \"large\",\n    'xtick.labelsize': 'x-large',\n    'legend.fontsize': 20,\n    'figure.dpi': 150,\n    'figure.figsize': [25, 7]\n    \n}\nplt.rcParams.update(params)    \n%matplotlib inline\nfrom sklearn.metrics import r2_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/diamonds/diamonds.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idsUnique = len(set(data['Unnamed: 0']))\nidsTotal = data.shape[0]\nidsdupe = idsTotal - idsUnique\nprint(idsdupe)\n#drop id col\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=data.drop(['Unnamed: 0'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_nas = data.isnull().sum()\ndata_nas = data_nas[data_nas>0]\ndata_nas.sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of rows with x == 0: {} \".format((data.x==0).sum()))\nprint(\"Number of rows with y == 0: {} \".format((data.y==0).sum()))\nprint(\"Number of rows with z == 0: {} \".format((data.z==0).sum()))\nprint(\"Number of rows with depth == 0: {} \".format((data.depth==0).sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[['x','y','z']] = data[['x','y','z']].replace(0,np.NaN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features = data.select_dtypes(include=['object']).columns\ncategorical_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_features = data.select_dtypes(exclude = [\"object\"]).columns\nnumerical_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_num = data[numerical_features]\ndata_cat = data[categorical_features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_num.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['cut'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='cut',data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g=sns.catplot(x='cut',y='price',data=data,kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['cut'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cat['color'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='color',data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p=sns.catplot(x='color',y='price',data=data,kind='bar')\np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['color'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cat['clarity'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='clarity',data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='clarity',y='price',data=data,kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['clarity'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamond_onehot=data_cat.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(data_cat.shape[1]):\n    diamond_onehot=pd.get_dummies(diamond_onehot,columns=[data_cat.columns[i]],prefix=[data_cat.columns[i]])\ndiamond_onehot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\nfrom scipy.stats import norm, skew #for some statistics\n\nsns.distplot(data['price'] , fit=norm);\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(data['price'])\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('Price distribution')\n\nfig = plt.figure()\nres = stats.probplot(data['price'], plot=plt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['price'] = np.log1p(data['price'] )\ny=data['price']\n\nsns.distplot(data['price'] , fit=norm);\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(data['price'])\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('Price distribution')\n\nfig = plt.figure()\nres = stats.probplot(data['price'], plot=plt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['price'] = np.log1p(data['price'] )\ny=data['price']\n\nsns.distplot(data['price'] , fit=norm);\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(data['price'])\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('Price distribution')\n\nfig = plt.figure()\nres = stats.probplot(data['price'], plot=plt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_num=data_num.drop(['price'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import skew \nskewness = data_num.apply(lambda x: skew(x))\nskewness.sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(skewness)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skewness = skewness[abs(skewness)>0.1]\nskewness.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_skew = data_num[skewness.index]\ndata_skew .columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_skew = np.log1p(data_skew )","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data_skew ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_num","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_num1=data_num.drop(['carat', 'table', 'x', 'y', 'z'],axis=1)\ndata_numerical=pd.concat([data_skew ,data_num1],axis=1)\ndata_numerical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_final=pd.concat([data_numerical,diamond_onehot],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_normal=data_final","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_normal.describe()\ndata_final=pd.concat([data_normal,y],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_final","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Find most important features relative to target\")\ncorr = data_final.corr()\ncorr.sort_values([\"price\"], ascending = False, inplace = True)\ncorr\nprint(corr['price'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abc = corr['price'][abs(corr['price'])>0.05]\nabc.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(corr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_model=data_final[abc.index]\ndata_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_model['volume'] = data_model['x']*data_model['y']*data_model['z']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x='volume', y='price' , data=data_model, size=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_model.drop(['x','y','z'], axis=1, inplace= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Data_out=data_model['price']\ninput_data=data_model.drop(['price'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(input_data,Data_out,test_size=0.2, random_state=66)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Collect all R2 Scores.\nR2_Scores = []\nmodels = ['Linear Regression' , 'AdaBoost Regression' , 'Ridge Regression' , 'GradientBoosting Regression',\n          'RandomForest Regression' ,\n         'KNeighbours Regression']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_lr = LinearRegression()\nclf_lr.fit(X_train , y_train)\naccuracies = cross_val_score(estimator = clf_lr, X = X_train, y = y_train, cv = 5,verbose = 1)\ny_pred = clf_lr.predict(X_test)\nprint('')\nprint('####### Linear Regression #######')\nprint('Score : %.4f' % clf_lr.score(X_test, y_test))\nprint(accuracies)\n\nmse = mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred)**0.5\nr2 = r2_score(y_test, y_pred)\n\nprint('')\nprint('MSE    : %0.2f ' % mse)\nprint('MAE    : %0.2f ' % mae)\nprint('RMSE   : %0.2f ' % rmse)\nprint('R2     : %0.2f ' % r2)\n\nR2_Scores.append(r2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_ar = AdaBoostRegressor(n_estimators=1000)\nclf_ar.fit(X_train , y_train)\naccuracies = cross_val_score(estimator = clf_ar, X = X_train, y = y_train, cv = 5,verbose = 1)\ny_pred = clf_ar.predict(X_test)\nprint('')\nprint('###### AdaBoost Regression ######')\nprint('Score : %.4f' % clf_ar.score(X_test, y_test))\nprint(accuracies)\n\nmse = mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred)**0.5\nr2 = r2_score(y_test, y_pred)\n\nprint('')\nprint('MSE    : %0.2f ' % mse)\nprint('MAE    : %0.2f ' % mae)\nprint('RMSE   : %0.2f ' % rmse)\nprint('R2     : %0.2f ' % r2)\n\nR2_Scores.append(r2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_rr = Ridge(normalize=True)\nclf_rr.fit(X_train , y_train)\naccuracies = cross_val_score(estimator = clf_rr, X = X_train, y = y_train, cv = 5,verbose = 1)\ny_pred = clf_rr.predict(X_test)\nprint('')\nprint('###### Ridge Regression ######')\nprint('Score : %.4f' % clf_rr.score(X_test, y_test))\nprint(accuracies)\n\nmse = mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred)**0.5\nr2 = r2_score(y_test, y_pred)\n\nprint('')\nprint('MSE    : %0.2f ' % mse)\nprint('MAE    : %0.2f ' % mae)\nprint('RMSE   : %0.2f ' % rmse)\nprint('R2     : %0.2f ' % r2)\n\nR2_Scores.append(r2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1,max_depth=1, random_state=0, loss='ls',verbose = 1)\nclf_gbr.fit(X_train , y_train)\naccuracies = cross_val_score(estimator = clf_gbr, X = X_train, y = y_train, cv = 5,verbose = 1)\ny_pred = clf_gbr.predict(X_test)\nprint('')\nprint('###### Gradient Boosting Regression #######')\nprint('Score : %.4f' % clf_gbr.score(X_test, y_test))\nprint(accuracies)\n\nmse = mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred)**0.5\nr2 = r2_score(y_test, y_pred)\n\nprint('')\nprint('MSE    : %0.2f ' % mse)\nprint('MAE    : %0.2f ' % mae)\nprint('RMSE   : %0.2f ' % rmse)\nprint('R2     : %0.2f ' % r2)\n\nR2_Scores.append(r2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_rf = RandomForestRegressor()\nclf_rf.fit(X_train , y_train)\naccuracies = cross_val_score(estimator = clf_rf, X = X_train, y = y_train, cv = 5,verbose = 1)\ny_pred = clf_rf.predict(X_test)\nprint('')\nprint('###### Random Forest ######')\nprint('Score : %.4f' % clf_rf.score(X_test, y_test))\nprint(accuracies)\n\nmse = mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred)**0.5\nr2 = r2_score(y_test, y_pred)\n\nprint('')\nprint('MSE    : %0.2f ' % mse)\nprint('MAE    : %0.2f ' % mae)\nprint('RMSE   : %0.2f ' % rmse)\nprint('R2     : %0.2f ' % r2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"no_of_test=[100]\nparams_dict={'n_estimators':no_of_test,'n_jobs':[-1],'max_features':[\"auto\",'sqrt','log2']}\nclf_rf=GridSearchCV(estimator=RandomForestRegressor(),param_grid=params_dict,scoring='r2')\nclf_rf.fit(X_train,y_train)\nprint('Score : %.4f' % clf_rf.score(X_test, y_test))\npred=clf_rf.predict(X_test)\nr2 = r2_score(y_test, pred)\nprint('R2     : %0.2f ' % r2)\nR2_Scores.append(r2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_knn = KNeighborsRegressor()\nclf_knn.fit(X_train , y_train)\naccuracies = cross_val_score(estimator = clf_knn, X = X_train, y = y_train, cv = 5,verbose = 1)\ny_pred = clf_knn.predict(X_test)\nprint('')\nprint('###### KNeighbours Regression ######')\nprint('Score : %.4f' % clf_knn.score(X_test, y_test))\nprint(accuracies)\n\nmse = mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nrmse = mean_squared_error(y_test, y_pred)**0.5\nr2 = r2_score(y_test, y_pred)\n\nprint('')\nprint('MSE    : %0.2f ' % mse)\nprint('MAE    : %0.2f ' % mae)\nprint('RMSE   : %0.2f ' % rmse)\nprint('R2     : %0.2f ' % r2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_neighbors=[]\nfor i in range (0,50,5):\n    if(i!=0):\n        n_neighbors.append(i)\nparams_dict={'n_neighbors':n_neighbors,'n_jobs':[-1]}\nclf_knn=GridSearchCV(estimator=KNeighborsRegressor(),param_grid=params_dict,scoring='r2')\nclf_knn.fit(X_train,y_train)\nprint('Score : %.4f' % clf_knn.score(X_test, y_test))\npred=clf_knn.predict(X_test)\nr2 = r2_score(y_test, pred)\nprint('R2     : %0.2f ' % r2)\nR2_Scores.append(r2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compare = pd.DataFrame({'Algorithms' : models , 'R2-Scores' : R2_Scores})\ncompare.sort_values(by='R2-Scores' ,ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='R2-Scores' , y='Algorithms' , data=compare)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.factorplot(x='Algorithms', y='R2-Scores' , data=compare, size=6 , aspect=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}