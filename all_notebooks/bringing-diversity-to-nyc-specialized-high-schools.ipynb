{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np\nimport pandas as pd \nimport re #regular expressions\nimport folium\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns #plotting\nsns.set()\nimport scipy\nimport math\nimport json\n#import branca\nfrom typing import List, Tuple, Dict, Union\nfrom textwrap import wrap\nimport ipywidgets as widgets\nfrom IPython.display import Markdown\nfrom statsmodels.sandbox.stats.multicomp import multipletests\n\npd.set_option('display.max_columns', None)\n\nHSDir_2017 = pd.read_csv('../input/nyc-high-school-directory/2017-doe-high-school-directory.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd8c04836193df8df026489f1ba6c705098d7f85"},"cell_type":"markdown","source":"# Table of Contents:\n* [Specialized High Schools and the SHSAT](#sec1)\n* [Disparity in the Specialized High Schools](#sec2)\n    * [Quantifying Diversity](#sec21)\n    * [Visualization](#sec22)\n    * [Hypothesis Testing](#sec23)\n* [Looking at the SHSAT](#sec3)\n    * [High Performing Middle Schools](#sec31)\n    * [Middle Schools with Undertested Black/Hispanic Students](#sec32)\n* [Conclusion](#sec4)"},{"metadata":{"_uuid":"401c0e23ff6bbff0d29a8e3dafdb5c952d02e038"},"cell_type":"markdown","source":"# Specialized High Schools and the SHSAT <a class=\"anchor\" id=\"sec1\"></a>\n"},{"metadata":{"_uuid":"9dd26764a651efc6d7f499c8997e471d013cf7d0"},"cell_type":"markdown","source":"According to a directory that the New York City Department of Education provides <sup><a href='#1'>1</a></sup> , NYC has 440 public high schools. Nine of these high schools are classified as \"specialized\" and are targeted specifically towards gifted students. "},{"metadata":{"trusted":true,"_uuid":"1eaa23d090e9073ec364c59acc08875d31263c52","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"#Creating a dictionary of specialized high schools and their district borough numbers, a helpful ID variable\nspecialized_dict = {dbn:school for dbn, school in HSDir_2017.query('specialized==1')[['dbn', 'school_name']].values}\n\nfor school in specialized_dict.values():\n    print(school)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"be2393155f59e098637b73ec2c116276dea9d593"},"cell_type":"markdown","source":"The only criteria for admission to most specialized high schools is a student's score on the Specialized High Schools Admissions Test (SHSAT), a test consisting of an English Language Arts section and a math section. The only specialized high school that does not consider the SHSAT is Fiorello H. LaGuardia High School of Music & Art and Performing Arts. According to its website:\n>\"Acceptance to LaGuardia Arts is based on a competitive audition and review of student records to ensure success in both the demanding studio work and the challenging academic programs.\" <sup><a href='#2'>2</a></sup>"},{"metadata":{"trusted":true,"_uuid":"cc517b6b17f641a6db37a59eda4788f7ebebf347","_kg_hide-input":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"#Removing Fiorello from the specialized high school dictionary\nspecialized_dict.pop('03M485', None)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79d1dfdc94d5ac642abc820d4fcf6b92acd1d7ad"},"cell_type":"markdown","source":"The SHSAT is optionally offered every fall for 8th and 9th graders. Only 18% of the students who took the SHSAT in 2016 ended up receiving an offer, making these schools notoriously difficult to get into. <sup><a href='#3'>3</a></sup> \n \nPASSNYC (Promoting Access to Specialized Schools in New York City) is a non-profit company based in NYC. Their purpose is to provide outreach programs for kids in under-served areas to help them prepare for the SHSAT. By giving the kids opportunities to succeed, PASSNYC aims to bring more diversity to the specialized high schools. The organization already has methods in place to identify kids and schools suited for their outreach programs. But they believe that they can do better."},{"metadata":{"_uuid":"8f46f25bf21b0d04ae00a2e2e265a7c305571cdc"},"cell_type":"markdown","source":"The purpose of this notebook is to:\n\n<ul>\n    <li>Quantify the diversity issue in specialized high schools</li><br/>\n    <li>Identify schools that could use PASSNYC's help</li>\n"},{"metadata":{"_uuid":"7099951db4cb585a48ff197eb962b82939562139"},"cell_type":"markdown","source":"# Disparity in the Specialized High Schools <a class=\"anchor\" id=\"sec2\"></a>"},{"metadata":{"_uuid":"2ae3a3747a7c2e83fd09674e2bc57a55f113e31e"},"cell_type":"markdown","source":"On PASSNYC's website, they state: \n>\"In recent years, the City’s specialized high schools—institutions with historically transformative impact on student outcomes—have seen a shift toward more homogenous [sic] student body demographics.\" <sup><a href='#4'>4</a></sup>\n\nTo validify this statement, demographic data is needed from a range of school years. Thankfully, a NYC Department of Education dataset labeled \"2013 - 2018 Demographic Snapshot School\" contains demographic information for students from 2013-2018. <sup><a href='#5'>5</a></sup> "},{"metadata":{"trusted":true,"_uuid":"a184c20d367ad1fccfbd9a44b6b556882946e482","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"#Import the datasets\ndemographics_df = pd.read_csv('../input/2013-2018-demographic-snapshot-district/2013_-_2018_Demographic_Snapshot_School.csv')\ndemographics_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"694f4de435c39aca46405195af02deee569400ca"},"cell_type":"markdown","source":"Looking at the dataset, there appears to be demographic data for ethnicity, gender, whether a student has a disability, whether a student is a non-native English speaker, and whether a student is in poverty."},{"metadata":{"trusted":true,"_uuid":"92e6106852352effb44ee745076e4e35ec8c1380","collapsed":true,"_kg_hide-input":true},"cell_type":"code","source":"ethnicity_list = ['ASIAN', 'BLACK', 'HISPANIC', 'WHITE', 'OTHER']\ngender_list = ['FEMALE', 'MALE']\ndisability_list = ['STUDENTS WITH DISABILITIES', 'STUDENTS WITH NO DISABILITIES']\nELL_list = ['ENGLISH LANGUAGE LEARNERS', 'NOT ENGLISH LANGUAGE LEARNERS']\npoverty_list = ['POVERTY', 'NO POVERTY']\ndemographic_dict = {'Ethnicity': ethnicity_list, 'Gender': gender_list,\n                    'Disabilities': disability_list, 'Poverty': poverty_list,\n                    'English Language Learners': ELL_list}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5e210f4c992f7df0243653196881ddb6d6280288"},"cell_type":"markdown","source":"After processing the dataset, it will possible to start testing PASSNYC's claim about school homogeneity."},{"metadata":{"trusted":true,"_uuid":"a765aead088199efaa221e2becc425d5b9115c11","_kg_hide-input":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"#PREPROCESSING\n\n#Making the Year column an integer\ndemographics_df['Year'] = demographics_df['Year'].str.slice(0,4).astype('int64')\n\n#Adding a column for Borough\ndemographics_df['borough'] = demographics_df['DBN'].str.slice(2,3)\ndemographics_df.loc[demographics_df['borough']=='X','borough'] = 'Bronx'\ndemographics_df.loc[demographics_df['borough']=='K','borough'] = 'Brooklyn'\ndemographics_df.loc[demographics_df['borough']=='Q','borough'] = 'Queens'\ndemographics_df.loc[demographics_df['borough']=='M','borough'] = 'Manhattan'\ndemographics_df.loc[demographics_df['borough']=='R','borough'] = 'Staten Island'\n\n#Changing 'No Data' results in the Economic Need Index to be np.NaN\ndemographics_df.loc[demographics_df['Economic Need Index']=='No Data', 'Economic Need Index'] = np.NaN\n\n#Changing percentage columns to float type\nfor column in [column for column in demographics_df.columns if '%' in column] + ['Economic Need Index']:\n    demographics_df.loc[-demographics_df[column].isnull(), column] = \\\n    demographics_df.loc[-demographics_df[column].isnull(), column].str.slice(0,-1).astype('float64')/100\n    \n#Making all column names in dataset capitalized\ndemographics_df.columns = demographics_df.columns.str.upper()\n\n#Rename \"MULTIPLE RACE CATEGORIES NOT REPRESENTED\" to \"OTHER\" to keep succinct\ndemographics_df.rename(columns = {'# MULTIPLE RACE CATEGORIES NOT REPRESENTED': '# OTHER',\n                                        '% MULTIPLE RACE CATEGORIES NOT REPRESENTED': '% OTHER',\n                                        'SCHOOL NAME': 'SCHOOL_NAME'}, inplace=True)\n\n#Adding columns for demographic inverses\ndemographics_df['# NO POVERTY'] = demographics_df['TOTAL ENROLLMENT'] - demographics_df['# POVERTY']\ndemographics_df['% NO POVERTY'] = 1 - demographics_df['% POVERTY']\n    \ndemographics_df['# NOT ENGLISH LANGUAGE LEARNERS'] = demographics_df['TOTAL ENROLLMENT'] - demographics_df['# ENGLISH LANGUAGE LEARNERS']  \ndemographics_df['% NOT ENGLISH LANGUAGE LEARNERS'] = 1 - demographics_df['% ENGLISH LANGUAGE LEARNERS']\n\ndemographics_df['# STUDENTS WITH NO DISABILITIES'] = demographics_df['TOTAL ENROLLMENT'] - demographics_df['# STUDENTS WITH DISABILITIES']  \ndemographics_df['% STUDENTS WITH NO DISABILITIES'] = 1 - demographics_df['% STUDENTS WITH DISABILITIES']  \n\n#Updating specialized school names in the datasets\nfor DBN, school_name in specialized_dict.items():\n    demographics_df.loc[demographics_df['DBN']==DBN, 'SCHOOL_NAME'] = school_name\n    \n#Year range to work with\nyears = (2013,2017)\n\n#Only specialized schools\nspecialized_df = demographics_df.query('DBN in @specialized_dict.keys()').copy()\nspecialized_df.set_index(['SCHOOL_NAME', 'YEAR'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c3390440e05bcd0bb8332456e0410578632bccc9"},"cell_type":"markdown","source":"## Quantifying Diversity <a class=\"anchor\" id=\"sec21\"></a>"},{"metadata":{"_uuid":"0fbb65bc26c17c2d76bb0488c47d7d433d0d43bd"},"cell_type":"markdown","source":"One way to test the accuracy of this statement is to use the Shannon Index. The Shannon Index, \\\\(H\\\\), is one of the most widely used diversity indices <sup><a href='#6'>6</a></sup> , which are used to quantify diversity in a sample. The Shannon Index is defined by\n\n$$ H = -\\sum_{i=1}^{R}{\\frac{n_{i}}{N}\\log{\\big(\\frac{n_{i}}{N}\\big)}} $$ \n\nwhere \n* \\\\(R\\\\) is the total number of categories\n* \\\\(n_i\\\\) is the count of observations from category \\\\(i\\\\)\n* \\\\(N\\\\) is the total number of observations. \n\nThis is the same equation for entropy, used in information theory, physics, and statistics. Claude Shannon published this result in 1948 in \"A Mathematical Theory of Communication\". <sup><a href='#7'>7</a> , <a href='#8'>8</a></sup> The Shannon Index takes a minimum value at 0 and a maximum value at \\\\(\\log{(R)}\\\\). Higher indices signify higher diversity. \n\nThe sample variance of the Shannon Index is given by\n\n$$ s^{2}_{H} = \\frac{\\sum_{i=1}^{R}{\\frac{n_{i}}{N}\\big(\\log{\\frac{n_{i}}{N}}\\big)^{2}} - \\big(\\sum_{i=1}^{R}{\\frac{n_{i}}{N}\\log{\\frac{n_{i}}{N}}}\\big)^{2}}{N} + \\frac{R-1}{2N^{2}} $$\n\nThis will come in use later.\n\nWhile the Shannon Index will give a measure of diversity, it increases non-linearly, making it difficult to compare indices. One way to fix this is to transform the Shannon Index with the exponential function, \\\\(e^{H}\\\\). The result is scaled linearly and is known as a Hill Number. <sup><a href='#9'>9</a></sup> Hill Numbers can be explained as the effective number of categories for a demographic. <sup><a href='#10'>10</a></sup> If \\\\(R\\\\) different categories had equal frequencies \\\\(\\frac{1}{R}\\\\), then the Hill Number would be \\\\(R\\\\). As the frequencies get less similar, there are fewer effective categories.\n\nUsing Hill Numbers, the change in specialized high school diversity can be visualized."},{"metadata":{"_uuid":"0a91e5bfab0fa0b47d427168bda7d6f9f3750e42"},"cell_type":"markdown","source":"## Visualization <a class=\"anchor\" id=\"sec22\"></a>"},{"metadata":{"trusted":true,"_uuid":"45330ee344488bb3dd5000a6deb72d1f8d200d90","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"def percentage_table(date_range: Tuple[int, int], demographic_list: List[str], demographic_df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Creates a view of each schools' demographic percentages for 2 years\n    \n    Args:\n        date_range (Tuple[int,int]): The year range of demographic data to include.\n        demographic_list (List[str]): A list of demographic categories.\n        demographic_df (pd.DataFrame): A pandas dataframe of demographic values.\n\n    Returns:\n        pd.DataFrame: demographic dataframe filtered view.\n    \"\"\"\n    df = demographic_df.query('YEAR in [2013,2017]')[[' '.join(['%', demographic]) for demographic in demographic_list]]\n\n    overall_df = demographic_df.query('YEAR in [2013,2017]')[[' '.join(['#', demographic]) for demographic in demographic_list]]\\\n                               .groupby(level=1).agg(sum)\\\n                               .apply(lambda x: x/x.sum(), axis=1)\\\n                               .set_index(pd.MultiIndex.from_product([['OVERALL'], [2013,2017]]))\\\n                               .sort_index(axis=1)\n                \n    return df.append(overall_df.rename(columns = dict(zip(overall_df.columns, df.columns))))\n\n\ndef highlight_rows(x):\n    colors = []\n    for school in x.index.get_level_values(0):\n        if x[school,x.index.unique(level='YEAR')[1]] > x[school,x.index.unique(level='YEAR')[0]]:\n            colors.append('background-color: lightgreen')\n        elif x[school,x.index.unique(level='YEAR')[1]] < x[school,x.index.unique(level='YEAR')[0]]:\n            colors.append('background-color: #FDB5A6')\n        else:\n            colors.append('')\n    return colors\n\n\noutputs = [widgets.Output() for _ in demographic_dict.keys()]\ntab = widgets.Tab(children = outputs)\nfor i, demographic in enumerate(demographic_dict.keys()):\n    tab.set_title(i, demographic)\ndisplay(tab)    \n\nfor i, demographic in enumerate(demographic_dict.keys()):\n    with outputs[i]:\n        display(Markdown('### {}'.format(demographic)));\n        display(percentage_table(years, demographic_dict[demographic], specialized_df).style.apply(highlight_rows, axis=0));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d835f322bded04b397166dd8f7e106976bb4870","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"def log(n: float) -> float:\n    \"\"\"\n    Allows math.log to return 0 for log(0) instead of undefined for the purpose of calculating a Shannon Index.\n    \"\"\"\n    if n==0:\n        return 0\n    else:\n        return math.log(n)\n    \n    \ndef shannon_index(categories: List[int]) -> Tuple[float, float, int]: \n    \"\"\"\n    Calculates Shannon Index numbers for a demographic list.\n    \n    Args:\n        categories (List[int]): A list of demographic categories.\n\n    Returns:\n        Tuple[float, float, int]: (Shannon Index expected value, Shannon Index variance, total number of observations)\n    \"\"\"\n    N = sum(categories)\n    expected_value = -sum((x/N)*log(x/N) for x in categories)\n    variance = ((sum((x/N)*(log(x/N)**2) for x in categories) - ((sum((x/N)*log(x/N) for x in categories))**2))/N) + ((len(categories)-1)/(2*(N**2)))\n    return (expected_value, variance, N)\n\n\ndef shannon_list(date_range: Tuple[int, int], demographic_list: List[str], demographic_df: pd.DataFrame) -> List[Union[float, str]]:\n    \"\"\"\n    Creates a list of the yearly overall Shannon Index information for the specialized high schools.\n    \n    Args:\n        date_range (Tuple[int,int]): The year range of demographic data to include.\n        demographic_list (List[str]): A list of demographic categories.\n        demographic_df (pd.DataFrame): A pandas dataframe of demographic values.\n\n    Returns:\n        List[int, float, float, int]: A list of school year, Shannon expected value, Shannon variance, \n                                      and total number of observations as the value.\n    \"\"\"\n    shannon = []\n    for year in range(date_range[0], date_range[1]+1):\n        shannon.append([year, *shannon_index(list(demographic_df.xs(year, level='YEAR')[[' '.join(['#', demographic]) for demographic in demographic_list]].sum().values))])\n    return shannon\n\n\ndef hill_graphs(date_range: Tuple[int, int], demographic_list: List[str], demographic_name: str, demographic_df: pd.DataFrame) -> None:\n    \"\"\"\n    Creates a set of bar charts and lineplots visualizing the change in diversity for a date range\n    \n    Args:\n        date_range (Tuple[int,int]): The year range of demographic data to include.\n        demographic_list (List[str]): A list of demographic categories.\n        demographic_name (str): The name of the demographic to be included in graph text.\n        demographic_df (pd.DataFrame): A pandas dataframe of demographic values.\n\n    Returns:\n        None: Multiple graphs.\n    \"\"\"\n    shannon = shannon_list(date_range, demographic_list, demographic_df)\n    \n    fig = plt.figure(figsize=(20, 8*(len(specialized_dict)+1)))\n    grid = plt.GridSpec(len(specialized_dict)+1, 3, hspace=0.4, wspace=0.4)\n\n    barcharts = fig.add_subplot(grid[i,:2])\n    barcharts.set_ylabel('Percentage')\n    barcharts.set_ylim(0,1)\n    barcharts.set_title(demographic_name + ' Distribution')\n    \n    demographic_df.query('YEAR in @date_range')[[' '.join(['#', demographic]) for demographic in demographic_list]]\\\n                   .groupby(level=1).sum().apply(lambda x: x/x.sum(), axis=1)\\\n                   .sort_index().T\\\n                   .plot(kind='bar', ax=barcharts, rot=0)\n\n\n    lineplots = fig.add_subplot(grid[i,2:])\n    lineplots.set_ylabel('Effective ' + demographic_name + ' Number')\n    lineplots.set_xlabel('Year')\n    lineplots.set_ylim(1, len(demographic_list))\n    lineplots.set_title('Hill Numbers Over Time')\n\n\n\n    lineplots.plot(*zip(*[[x[0], math.exp(x[1])] for x in shannon]), color=\"red\")\n\n    \n    \n    plt.show(fig);\n\n    \nfor i, demographic in enumerate(demographic_dict.keys()):\n    display(Markdown('### {}'.format(demographic)))\n    hill_graphs(years, demographic_dict[demographic], demographic, specialized_df);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f7cedfa53684f4adbf455a3bc6decea78afc39f"},"cell_type":"markdown","source":"Some observations about the visualizations:"},{"metadata":{"_uuid":"87bd3cd0f3dc6f00bb118b3937c49655c80bf214"},"cell_type":"markdown","source":"**Ethnicity**:\n* The multiple ethnicities not represented have increased in overall frequency since 2013. They've noticingly become more present at the High School for Mathematics, Science, and Engineering at City College (HSMSE) and The Brooklyn Latin School, where both have \"other\" ethnicities make up more than 10% of their student body. \n* The proportion of Hispanic and black students has gone down in seven of the eight specialized high schools. \n* The proportion of Asian and white students has gone up in most high schools. "},{"metadata":{"_uuid":"5ac4785d8301a1528f94974dc9de4ef144bf4d3a"},"cell_type":"markdown","source":"**Gender**:\n* Since 2013, half of the high schools have increased in female proportion and half of the high schools have decreased in female proportion.\n* Overall, the proportions have changed less than a tenth of a percent."},{"metadata":{"_uuid":"c9a7cf821102f0b6ce9ab1afde2edbbd64aeeb20"},"cell_type":"markdown","source":"**Disability**:\n* Most high schools maintained a low number of students of disabilities, either increasing or decreasing by a relatively small amount. \n* High School for Mathematics, Science, and Engineering at City College (HSMSE) went from about 3.1% of its students having disabilities in 2013/2014 to 4.8% in 2017/2018."},{"metadata":{"_uuid":"0acd71d120afeb2ba0ab413c4e48b540e6468c61"},"cell_type":"markdown","source":"**Poverty**:\n* Overall, the percentage of students with poverty has gone down from 53.3% to 50.7%. Since this is closer to 50/50 though, the diversity has technically increased. If this trend continues, the diversity will start dropping once the proportion of students with poverty drops below 50%.\n* The proportion of students with poverty has gone down in every high school except for one. \n* The high school where the proportion of students with poverty increased was Staten Island Technical High School, where it went from 31.7% to 40.8%. "},{"metadata":{"_uuid":"f2d2d3387e88d228d5e6fade831d1ff04e243853"},"cell_type":"markdown","source":"**English Language Learners**\n* In 2013, 5 of the high schools had students who were English Language Learners. By 2017, only the High School for Mathematics, Science and Engineering at City College (HSMSE) did."},{"metadata":{"_uuid":"0683abbf5a9e372ad1abc72f82d97d4b1d6d7289"},"cell_type":"markdown","source":"## Hypothesis testing <a class=\"anchor\" id=\"sec23\"></a>"},{"metadata":{"_uuid":"e8c035a4ab45b408644284a760e898b57c41dcd7"},"cell_type":"markdown","source":"Seeing the diversity visualized gives some initial details of how demographics have changed over the years. However, since some of the changes are subtle, it would be helpful if there was a way to see if any changes were statistically significant. One way to compare diversity is to use Hutcheson's t-test. <sup><a href='#11'>11</a> , <a href='#12'>12</a></sup> Created by Kermit Hutcheson in a letter to the editor in a 1970 issue of the Journal of Theoretical Biology, Hutcheson's t-test is an unpooled two-sample t-test specifically adapted for Shannon Indices.\n\nFor this test, the null and alternative hypotheses are \\\\(H_0: H_a = H_b\\\\) and \\\\(H_1: H_a \\ne H_b\\\\) respectively, with \\\\(H_a\\\\) and \\\\(H_b\\\\) being the two Shannon Indices. The null hypothesis assumes equal diversity in the two samples. The test statistic is calculated as\n$$ t = \\frac{H_a - H_b}{\\sqrt{s^{2}_{H_a} + s^{2}_{H_b}}} $$\n\nwith \\\\(s^{2}_{H}\\\\) being the sample variance of the Shannon Index. The degrees of freedom are given by\n\n$$ \\frac{\\big(s^{2}_{H_a} + s^{2}_{H_b}\\big)^2}\n{\\Bigg(\\frac{\\big(s^{2}_{H_a}\\big)^2}{N_a} + \\frac{\\big(s^{2}_{H_b}\\big)^2}{N_b}\\Bigg)} $$\n\nThere will be five hypotheses tests ran: one for each demographic (ethnicity, gender, disability, poverty, English Language Learner). Each demographic will be tested on the specialized schools grouped together instead of individually. This will allow fewer hypotheses tests and answers the question at hand: have specialized schools become less diverse over the years. \n\nSince multiple tests are being conducted, the False Discovery Rate (the proportion of false rejections of the null hypothesis compared to the total number of rejections) will be controlled using the Benjamini-Hochberg procedure. <sup><a href='#13'>13</a></sup>"},{"metadata":{"trusted":true,"_uuid":"01cbebf537346fcdfe0194e07285f9ca1eed8bdb","collapsed":true,"_kg_hide-output":false,"_kg_hide-input":true},"cell_type":"code","source":"def t_test(a: float, var_a: float, N_a: int, b: float, var_b: float, N_b: int) -> Tuple[float, int, float]:\n    \"\"\"\n    Calculates the Hutcheson t-test statistics to compare two Shannon Indices\n    \n    Args:\n        a (float): Shannon Index #1\n        var_a (float): Shannon Index #1 variance\n        N_a (float): total observations #1\n        b (float): Shannon Index #2\n        var_b (float): Shannon Index #2 variance\n        N_b: total observations #2\n\n    Returns:\n        Tuple[float, int, float]: A tuple of (t-statistic, degrees of freedom, p-value)\n    \"\"\"\n    t = (a - b)/math.sqrt(var_a + var_b)\n    df = math.ceil(((var_a + var_b)**2)/(((var_a**2)/N_a)+((var_b**2)/N_b)))\n    return (t, df, 1 - scipy.stats.t.cdf(math.fabs(t), df))\n\ndef shannon_t_tests(date_range: Tuple[int, int]) -> pd.DataFrame:\n    \"\"\"\n    Creates table displaying multiple t-tests adjusted with the Benjamini-Hochberg procedure\n    \n    Args:\n        date_range (Tuple[int,int]): The year range of demographic data to include.\n        \n    Returns:\n        None: A pandas dataframe.\n    \"\"\"\n    significance_df = pd.DataFrame(data=None, columns = ['Name', \"Shannon Index \" + str(date_range[0]), \"Shannon Index \" + str(date_range[1]), 't', 'df', 'pval'])\n    for i, demographic in enumerate(demographic_dict.keys()):\n        shannon = shannon_list(date_range, demographic_dict[demographic], specialized_df)\n        significance_df.loc[i] = (demographic, shannon[0][1], shannon[-1][1], *t_test(*shannon[0][1:],*shannon[-1][1:]))\n    is_reject, corrected_pvals, _, _ = multipletests(significance_df[\"pval\"], alpha=0.05, method='fdr_bh')\n    significance_df[\"reject\"] = is_reject\n    significance_df[\"adj_pval\"] = corrected_pvals\n    return significance_df","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"141d5b415aec5020fcd772856699e91c787e96a7","collapsed":true},"cell_type":"code","source":"shannon_t_tests(years)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"864d66b7bd085f7e6a7e8393ca7643a4bdf74a8a"},"cell_type":"markdown","source":"After adjusting for multiple tests, the null hypotheses for ethnicity, poverty, and English Language Learners are rejected at a rejection level of \\\\(\\alpha=0.05\\\\). Therefore, there is evidence that the diversity of these demographics in specialized high schools between the 2013/2014 school year and the 2017/2018 school year is not equal. In the cases of ethnicity and English Language Learners, it appears that the diversity has decreased. With poverty, it appears that the diversity has actually increased. Looking at the visualizations of the data again, this makes some sense. \n\n* Ethnicity appears not to have changed too much, but since the total enrollment of students in specialized high schools is 14,876 in the 2013/2014 school year and 15,540 in the 2017/2018, the variance is lower. Even a small change is significant.\n* Both gender and disability seem to have not changed at all, so it is not surprising that the difference in their proportions was not big enough to warrant a rejection of the null hypothesis. \n* The proportion of students with poverty at the specialized high schools shifted by +/- 2.5. Since the proportions converged near 50%, the diversity is close to it's maximum Hill Number value. \n* The English Language Learner percentages in 2013 and 2017 look nearly identical, but since there were 14 students who were English Language Learners in 2013 and only 1 in 2017, it decreased significantly. In retrospect, it may be difficult to quantify students as English Language Learners. Since one of the two components of the SHSAT is English Language Arts<sup>1</sup>,  a student needs to be adept at the English language to score well. If a student scores well enough to pass, they might not consider themselves an English Language Learner. \n\n\nWith that being said, the only quantifiable demographic that has gone down in diversity in the specialized high schools is ethnicity. In regards to ethnicity, PASSNYC is correct in saying that the student bodies have become more homogeneous over the past few years. The second part of this project will aim to find ways to fix that. "},{"metadata":{"_uuid":"eea0ade662f02f096f2d87dedec3c0b9d73d8493"},"cell_type":"markdown","source":"# Looking at the SHSAT <a class=\"anchor\" id=\"sec3\"></a>"},{"metadata":{"_uuid":"cf0554fc44b2bdaadbd7cef9f9aac20bd8eba12e"},"cell_type":"markdown","source":"To help identify schools that need assistance with SHSAT preparation, PASSNYC provided two datasets to work with:\n* '2016 School Explorer.csv' is a dataset that gives several characteristics of public elementary and middle schools in NYC. \n* 'D5 SHSAT Registrations and Testers.csv' is a dataset that gives SHSAT registration information for schools in the D5 district (Central Harlem)."},{"metadata":{"trusted":true,"_uuid":"eefdef20086fcee1ca452be5e20fa25c3527c31f","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"school_explorer = pd.read_csv('../input/data-science-for-good/2016 School Explorer.csv')\nregistration = pd.read_csv('../input/data-science-for-good/D5 SHSAT Registrations and Testers.csv')\n\n#Processing for school_explorer dataset\n\n#Capitalize column names\nschool_explorer.columns = school_explorer.columns.str.upper()\n\n#Change percent columns from strings to usable integers\nfor column in [column for column in school_explorer.columns if ('%' in column) or ('PERCENT' in column) or ('RATE' in column)]:\n    school_explorer.loc[-school_explorer[column].isnull(), column] = school_explorer.loc[-school_explorer[column].isnull(), column].str.strip('%').astype('float64')/100\n    school_explorer[column] = school_explorer[column].astype('float64')\n    \n#Change dollars to floats\nschool_explorer['SCHOOL INCOME ESTIMATE'] = school_explorer['SCHOOL INCOME ESTIMATE'].str.replace('[\\$, ]', '').astype('float64')\n\n#Change location code column name to DBN\nschool_explorer.rename(columns = {'LOCATION CODE': 'DBN'}, inplace=True)\n\nschool_explorer.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b785b6cfdb0fb209453a801425fb378ead54aef"},"cell_type":"markdown","source":"Looking at the `school_explorer` dataset, it appears to have demographic columns, metrics on the school itself, and information on test results from the New York State Testing Program (NYSTP) <sup>1</sup>.  The dataset is titled \"2016 School Explorer\", which could be either the 2015/2016 school year or the 2016/2017 school year. To find out which one it is, the demographic dataset from Part 1 can be used since it had the school years labeled as \"2015/2016\", etc. "},{"metadata":{"trusted":true,"_uuid":"82b345b97e9d75532bb6a7917d7aaf3b81470538","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"#testing 2015/2016 vs. 2016/2017\ntesting = pd.merge(school_explorer[['PERCENT BLACK', 'DBN']], demographics_df.query('YEAR in (2015,2016)')[['% BLACK', 'DBN', 'YEAR']], on='DBN')\nfor year in (2015,2016):\n    print('Year {} Error: {}'.format(year, (testing.loc[testing['YEAR']==year, 'PERCENT BLACK'] - testing.loc[testing['YEAR']==year, '% BLACK']).sum()))\ndel testing","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d028b6edc160db6e031408de2e4effee2818fdb"},"cell_type":"markdown","source":"It looks like the data provided is for the 2015/2016 year. Since it will be helpful to have the demographics columns included in this dataset, the datasets will be merged."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f60f4defe95f0b5e8154984443364445bc77f03b","_kg_hide-input":true},"cell_type":"code","source":"redundant_columns = ['SCHOOL NAME', 'ECONOMIC NEED INDEX']\nredundant_columns.extend(['PERCENT ' + demographic for demographic in ['ELL', 'ASIAN', 'BLACK', 'HISPANIC', 'WHITE', 'BLACK / HISPANIC']])\n\nschool_explorer = pd.merge(school_explorer[[column for column in school_explorer.columns if column not in redundant_columns]], \n         demographics_df.query('YEAR==2015'), on='DBN')\nschool_explorer['PERCENT BLACK/HISPANIC'] = school_explorer['% BLACK'] + school_explorer['% HISPANIC']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3103715ab0c72d52fdd1e06b9ab3c1fc574c2a40"},"cell_type":"markdown","source":"To get extra metrics regarding the NYSTP, a dataset from the NYC DOE website can be merged into the existing dataset as well. "},{"metadata":{"trusted":true,"_uuid":"1346ad72409152e4c504e9d97f5c7013e6e88202","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"test_results = pd.read_csv('../input/nyc-ela-and-math-results-20152016/3-8_ELA_AND_MATH_RESEARCHER_FILE_2016.csv')\n\n#Dropping nan values\ntest_results.replace('-', np.nan, inplace=True)\ntest_results.dropna(subset=[column for column in test_results.columns if ('_COUNT' in column) or ('_PCT' in column)], inplace=True)\n\n#Converting percent columns into float64 types\npercentage_columns = [column for column in test_results.columns if 'PCT' in column]\nfor column in percentage_columns:\n    test_results[column] = test_results[column].str.strip('%').astype('float64')/100\n    \n#Create grade column\ntest_results['GRADE'] = test_results['ITEM_DESC'].str.slice(6,7).astype('int64')\n    \n#Get test averages\ntest_results['SUBGROUP_AVERAGE'] = test_results[percentage_columns[:-2]].apply(lambda x: sum(percentage * score for percentage, score in zip(x, range(1,5))), axis=1)\nsubgroup_avgs = test_results.groupby(['BEDSCODE', 'GRADE', 'SUBGROUP_NAME']).sum()['SUBGROUP_AVERAGE'].reset_index()\nsubgroup_avgs.rename(columns = {'SUBGROUP_AVERAGE': 'SUBGROUP_AVERAGE_TOTAL'}, inplace=True)\ntest_results = test_results.merge(subgroup_avgs, on=['BEDSCODE', 'GRADE', 'SUBGROUP_NAME'])\ndel subgroup_avgs\ntest_results['TOTAL_TESTED'] = test_results['TOTAL_TESTED'].astype('int64')\navg_df = test_results.groupby(['BEDSCODE', 'ITEM_SUBJECT_AREA']).apply(lambda x: sum(count * score for count, score in zip(x['TOTAL_TESTED'], x['SUBGROUP_AVERAGE']))/x['TOTAL_TESTED'].sum()).to_frame()\ntest_results = test_results.join(avg_df, on=['BEDSCODE', 'ITEM_SUBJECT_AREA'])\ntest_results = test_results.merge(test_results.groupby(['BEDSCODE', 'ITEM_SUBJECT_AREA']).first().unstack()[0].reset_index().copy(),\n                   on='BEDSCODE')\ntest_results.rename(columns = {'ELA': 'ELA_SCHOOL_AVERAGE', 'Mathematics': 'MATH_SCHOOL_AVERAGE'}, inplace=True)\ndel avg_df\n\n#Drop unnecessary columns\ntest_results.drop([0, 'SY_END_DATE', 'ITEM_DESC', 'MEAN_SCALE_SCORE'], axis=1, inplace=True)\n\n#Merge\nschool_explorer = pd.merge(school_explorer[[column for column in school_explorer.columns if 'GRADE' not in column and 'AVERAGE' not in column]], \n                           test_results, left_on='SED CODE', right_on='BEDSCODE')\n\ndel test_results\n\n#Just 8th grade results are wanted as they are the ones taking the SHSAT\nschool_explorer = school_explorer.query('GRADE==8')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"702dd3a1b4f47e21348822ff7dc32197ae9839d1"},"cell_type":"markdown","source":"Knowing that ethnic diversity has decreased in the specialized high schools, the goal is to increase the number of qualified underrepresented students taking the SHSAT. In order to find out which middle schools have qualified and underrepresented students, there need to be two classifications performed:\n* An identification of high performing middle schools\n* An identification of middle schools that have both a high percentage of Black/Hispanic students (the most underrepresented ethnically) and a low percentage of SHSAT test taking."},{"metadata":{"_uuid":"a93a09434c4d617269db793f1f42079f3b4f8ad5"},"cell_type":"markdown","source":"## High Performing Middle Schools <a class=\"anchor\" id=\"sec31\"></a>"},{"metadata":{"_uuid":"764da6364cda518f227126365635e6cff1df362e"},"cell_type":"markdown","source":"To find high performing middle schools, the NYSTP results can be looked at."},{"metadata":{"_uuid":"10d76def50c7d46f88206c810a1c12d580e92257","trusted":true,"_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"from scipy import stats\n\nfig = plt.figure(figsize=(10,10))\nNYSTP_results = school_explorer.query('SUBGROUP_NAME==\"All Students\"').set_index(['BEDSCODE', 'ITEM_SUBJECT_AREA']).unstack()['SUBGROUP_AVERAGE'].dropna()\nplt.scatter(NYSTP_results['ELA'],NYSTP_results['Mathematics'])\nplt.title('NYSTP Results for the 2015/2016 School Year')\nplt.xlabel('English Language Arts results')\nplt.ylabel('Mathematics results');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9c1e52825dfee70eb0615dfff4bb98fed1a55194"},"cell_type":"markdown","source":"Students' mathematics results and ELA results appear positively correlated. The top right corner contains schools that have good candidates for the SHSAT. To find a suitable cutoff point, K-means clustering<sup><a href='#14'>14</a></sup> will be used to segment the schools into custers. To find an optimal number of clusters, the \"elbow method\" will be used. "},{"metadata":{"trusted":true,"_uuid":"743e61a88866fccced97084e3777aaede4442305","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn import metrics\nfrom scipy.spatial.distance import cdist\n\ndef elbow_method(df: pd.DataFrame, kmax: int) -> pd.DataFrame:\n    \"\"\"\n    Creates graph to find optimal k-value for k-means clustering and returns a standardized dataframe.\n         \n    Args:\n        df (pd.DataFrame): Dataframe to perform elbow method and standardization on\n        kmax (int): Number of k values to try\n\n    Returns:\n        pd.DataFrame: A standardized version of df\n    \"\"\"\n    df_norm = stats.zscore(df)\n    k_values = []\n    k_range = range(1,kmax)\n    for k in k_range:\n        kmeanModel = KMeans(n_clusters=k).fit(df_norm)\n        kmeanModel.fit(df_norm)\n        k_values.append(sum(np.min(cdist(df_norm, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / df_norm.shape[0])\n\n    plt.plot(k_range, k_values, 'bx-')\n    plt.xlabel('k')\n    plt.ylabel('Sum of squares')\n    plt.title('Elbow Method for finding an optimal k')\n    plt.show()\n    return df_norm\nNYSTP_results_norm = elbow_method(NYSTP_results, 10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"11fe9b25b3a61d42a20d269357c28f598e1cf0dc"},"cell_type":"markdown","source":"It appears that 3 clusters will work well."},{"metadata":{"trusted":true,"_uuid":"80c199d01cf60f4400bb35f6b08feeabb689e2d1","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"def cluster(df: pd.DataFrame, n: int) -> np.ndarray:\n    \"\"\"\n    Returns k-means labels.\n         \n    Args:\n        df (pd.DataFrame): Dataframe to cluster\n        n (int): Number of clusters\n\n    Returns:\n        pd.DataFrame: A standardized version of df\n    \"\"\"\n    kmeans = KMeans(n_clusters=n, random_state=0)\n    fit = kmeans.fit(df)\n    labels = kmeans.predict(df)\n    return labels\n\nlabels = cluster(NYSTP_results_norm, 3)\ncolmap = {1: '#a6cee3', 2: '#1f78b4', 3: '#b2df8a', 4: '#33a02c', 5: '#fb9a99',\n          6: '#e31a1c', 7: '#fdbf6f', 8: '#ff7f00', 9: '#cab2d6', 10: '#6a3d9a'}\ncolors = list(map(lambda x: colmap[x+1], labels))\n\nfig = plt.figure(figsize=(10, 10))\nplt.scatter(NYSTP_results['ELA'],NYSTP_results['Mathematics'], color=colors, alpha=0.5, edgecolor='k')\nplt.title('NYSTP Results for the 2015/2016 School Year Clustered')\nplt.xlabel('English Language Arts results')\nplt.ylabel('Mathematics results');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ecde4cb9b35f5922ed73acbaed43ed8d4a4a7fde","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"NYSTP_results['TEST_CLUSTER'] = labels\nschool_explorer = school_explorer.merge(NYSTP_results['TEST_CLUSTER'].reset_index(), on='BEDSCODE')\nschool_explorer['HIGH_PERFORMER'] = (school_explorer['TEST_CLUSTER'] == 2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"78363a80bfa124a4cdb86398d8dedcbae315b58d"},"cell_type":"markdown","source":"## Middle Schools with Undertested Black/Hispanic Students <a class=\"anchor\" id=\"sec32\"></a>"},{"metadata":{"_uuid":"c4904a3d28a2ee13b7a8ea71357285ea707e9d3e"},"cell_type":"markdown","source":"To find middle schools who have a low percentage of test takers, registration information will be needed. The registration dataset that PASSNYC provided only has information on the D5 school district (Central Harlem). Fortunately, more data has been provided by the Department of Education that includes how many offers were made."},{"metadata":{"trusted":true,"_uuid":"8b1299bd4f0f72bf54ac9faf36d7a851f51ed606","collapsed":true,"_kg_hide-input":true},"cell_type":"code","source":"offers = pd.read_csv('../input/2015-2016-shsat-results/2015-2016_SHSAT_Admissions_Test_Offers_By_Sending_School.csv')\n\n#Rename columns\noffers.rename(columns = {'Feeder School DBN': 'DBN', 'Feeder School Name': 'SCHOOL_NAME',\n                   'Count of Students in HS Admissions': 'OLD_COUNT',\n                   'Count of Testers': 'TESTED', 'Count of Offers': 'OFFERED'}, inplace=True)\noffers.set_index('DBN', inplace=True)\n\n#Add actual student enrollments\neligible_testers = demographics_df.query('YEAR==2015')[['GRADE 8', 'GRADE 9', 'DBN']].set_index('DBN').apply(lambda x: pd.Series({'ELIGIBLE': x.sum()}), axis=1)\noffers = pd.merge(offers, eligible_testers,\n                left_index=True, right_index=True)\noffers.drop('OLD_COUNT', axis=1, inplace=True)\n\n#Make columns float64 type\nfor column in ['TESTED', 'OFFERED']:\n    offers.loc[offers[column]=='0-5',column] = np.nan\n    offers[column] = offers[column].astype('float64')\n\n#Calculate relevant percentages\noffers['% TESTED'] = (offers['TESTED']/offers['ELIGIBLE']).fillna(0)\noffers['% SUCCESSFUL'] = offers['OFFERED']/offers['TESTED']\n\n#Merge offers into school_explorer dataset\nschool_explorer = pd.merge(school_explorer.query('GRADE==8'), offers.drop('SCHOOL_NAME', axis=1), on='DBN')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9dde4b5f10fb213dd7198e0f9617cf0d00267f30","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"tested_df = school_explorer.groupby('BEDSCODE').first()[['% TESTED', 'PERCENT BLACK/HISPANIC']].dropna()\nfig = plt.figure(figsize=(10, 10))\nplt.scatter(tested_df['% TESTED'],tested_df['PERCENT BLACK/HISPANIC'])\nplt.title('Scatterplot Comparing SHSAT Test Participation and Proportion of Black/Hispanic Students')\nplt.xlabel('Percent Tested')\nplt.ylabel('Proportion of Black and Hispanic Students');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"92f3a784bd3e8013252b7f425ca581d7eb51b3d1"},"cell_type":"markdown","source":"Looking at the percent of students who took the SHSAT versus the proportion of black/Hispanic students, there is a significant amount of predominantly black/Hispanic middle schools that have less than 20% of their students taking the SHSAT. Using k-means clustering again, the top left corner group will be of interest. "},{"metadata":{"trusted":true,"_uuid":"d410cac490bac86a8131dba628f5f2eca4a634b2","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"tested_df_norm = elbow_method(tested_df, 10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4399762f79728a940e6597272cfc1ee74ae6cbd4"},"cell_type":"markdown","source":"This time, it looks like 5 clusters will be optimal."},{"metadata":{"trusted":true,"_uuid":"d22968fbe8d669522e15f241d38722c1ee35c92f","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"labels = cluster(tested_df_norm, 5)\n\ncolors = list(map(lambda x: colmap[x+1], labels))\n\nfig = plt.figure(figsize=(10, 10))\nplt.scatter(tested_df['% TESTED'],tested_df['PERCENT BLACK/HISPANIC'], color=colors, alpha=0.5, edgecolor='k');\nplt.title('Scatterplot Comparing SHSAT Test Participation and Proportion of Black/Hispanic Students \\n with K-means Clusters')\nplt.xlabel('Percent Tested')\nplt.ylabel('Proportion of Black and Hispanic Students');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"663e45724adaf4cda426a3e0ac1a0cf291dddfc2","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"tested_df['DIVERSITY_CLUSTER'] = labels\nschool_explorer = school_explorer.merge(tested_df['DIVERSITY_CLUSTER'].reset_index(), on='BEDSCODE')\nschool_explorer['UNDERTESTED'] = (school_explorer['DIVERSITY_CLUSTER'] == 0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ffff5654844c73243412d2676239975d39097748"},"cell_type":"markdown","source":"# Conclusion <a class=\"anchor\" id=\"sec4\"></a>"},{"metadata":{"_uuid":"aae17b1935a77b1d19ee9510762918fa2e5c8ca1"},"cell_type":"markdown","source":"Looking at the intersection of high performing middle schools and middle schools with a high percentage of black/Hispanic students but few taking the SHSAT, there are 10 middle schools that meet these criteria. "},{"metadata":{"trusted":true,"_uuid":"67fd61467f92e2ac34711c7b428b608fe2e0b59d","collapsed":true},"cell_type":"code","source":"display(school_explorer.query('HIGH_PERFORMER & UNDERTESTED').groupby('BEDSCODE').first()[['SCHOOL_NAME', 'SUBGROUP_AVERAGE_TOTAL', '% TESTED']])\nschool_explorer.query('HIGH_PERFORMER & UNDERTESTED').groupby('BEDSCODE').first().shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbab790c455092852125a18d464ef9cda272c31d","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"m = folium.Map(\n    location=[40.777488, -73.879681],\n    tiles='Stamen Toner',\n    zoom_start=11,)\n\nfor index,row in school_explorer.query('HIGH_PERFORMER & UNDERTESTED').groupby('BEDSCODE').first().iterrows():\n    folium.Marker(\n        location=[row['LATITUDE'], row['LONGITUDE']],\n        popup=folium.Popup(row['SCHOOL_NAME'], parse_html=True)\n    ).add_to(m)\nm","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4d235eafe80bf54f563d4d16e8d8dc1eae3f9f33"},"cell_type":"markdown","source":"If PASSNYC focuses efforts on these 10 middle schools (e.g. after-school programs to encourage a higher SHSAT testing rate), it could be effective in making the specialized high schools more diverse."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8c9ed805d49bba73620141204daced6fc344a721"},"cell_type":"markdown","source":"# Bibliography <a class=\"anchor\" id=\"sec5\"></a>\n<br/>\n<a id='1'> 1. </a> <a href='https://www.kaggle.com/new-york-city/nyc-high-school-directory/home'> \"NYC High School Directory\" on Kaggle</a><br/>\n\n<a id='2'> 2. </a> <a href='https://laguardiahs.org/apps/pages/index.jsp?uREC_ID=314119&type=d'>Fiorello H. LaGuardia High School Website</a><br/>\n\n<a id='3'> 3. </a> <a href='https://www.princetonreview.com/k12/shsat-information'>SHSAT Information from The Princeton Review</a><br/>\n\n<a id='4'> 4. </a> <a href='http://www.passnyc.org/'>PASSNYC Website</a><br/>\n\n<a id='5'> 5. </a> <a href='https://data.cityofnewyork.us/Education/2013-2018-Demographic-Snapshot-School/s52a-8aq6'> \"2013-2018 Demographic Snapshot School\" on NYC Open Data</a><br/>\n\n<a id='6'> 6. </a> <a href='https://en.wikipedia.org/wiki/Diversity_index#Simpson_index'> Wikipedia article on diversity indices </a><br/>\n\n<a id='7'> 7. </a> <a href='http://eebweb.arizona.edu/courses/Ecol206/shannon%20weaver-wiener.pdf'> Ian F. Spellerberg and Peter J. Fedor \"A tribute to Claude Shannon (1916–2001) and a plea for\nmore rigorous use of species richness, species diversity\nand the ‘Shannon–Wiener’ Index\", 2003 </a><br/>\n\n<a id='8'> 8. </a> <a href='http://math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf'>Claude Shannon \"A Mathematical Theory of Communication\", 1948 </a><br/>\n\n<a id='9'> 9. </a> <a href='https://www.uvm.edu/~ngotelli/manuscriptpdfs/ChaoHill.pdf'>Anne Chao \"Rarefaction and extrapolation with Hill numbers: a framework\nfor sampling and estimation in species diversity studies\", 2014</a><br/>\n\n<a id='10'> 10. </a> <a href='http://www.loujost.com/Statistics%20and%20Physics/Diversity%20and%20Similarity/EffectiveNumberOfSpecies.htm'>Lou Jost on \"Effective Number of Species\"</a><br/>\n\n<a id='11'> 11. </a> <a href='https://www.sciencedirect.com/science/article/pii/0022519370901244'>Kermit Hutcheson \"A test for comparing diversities based on the shannon formula\", 1970 </a><br/>\n\n<a id='12'> 12. </a> <a href='http://www.dataanalytics.org.uk/Publications/S4E2e%20Support/exercises/Comparing%20shannon%20diversity.htm'>Post by Mark Gardener on DataAnalytics.org.uk about calculating the Hutcheson's t-test</a><br/>\n\n<a id='13'> 13. </a> <a href='https://multithreaded.stitchfix.com/blog/2015/10/15/multiple-hypothesis-testing/'>More reading about Benjamini</a><br/>\n\n<a id='14'> 14. </a> <a href='https://en.wikipedia.org/wiki/K-means_clustering'>K-means clustering</a> <br/>"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}