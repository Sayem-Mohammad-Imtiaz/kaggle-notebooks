{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Read the dataset from CSV file\ndf =pd.read_csv('/kaggle/input/spam.csv',encoding= 'latin-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Display first 5 rows of the data frame\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove unneccessary columns\ndf.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1, inplace= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Display Data Frame\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Rename colums\ndata=df.rename(columns={'v1':'class','v2':'text'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Display data frame\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Define features & target variable. Split train & test data\nx= data['text']\ny=data['class']\nx_train,x_test, y_train,y_test= train_test_split(x,y,test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The text must be parsed to remove words, called tokenization. \n#Then the words need to be encoded as integers or floating point values for use as input to a machine learning algorithm,\n#called feature extraction (or vectorization). So, for this purpose, CountVectorizer() is used.\n\nv=CountVectorizer()\nv.fit(x_train)\nvec_x_train= v.transform(x_train).toarray()\nvec_x_test= v.transform(x_test).toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Display the encoded array of the train data\nvec_x_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display the encoded form of first row of the data\nvec_x_train[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display the actual tokenized word of first row of the data\nv.inverse_transform(vec_x_train[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display the original form of first row of the data\nx_train.iloc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Here it uses Naive Bayes Classifiers for binary classification(SPAM or HAM) of text\nm= GaussianNB()\nm.fit(vec_x_train,y_train)\nprint(m.score(vec_x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Give the actual input here\nsample = \"Thank you for your donation We need your Complete address for Statutory purposes. Since you did not provide your complete address while donating, we are sending this communication again.  We will be grateful if you can spare 2 minutes of your valuable time to send the details.We value your continued support.  Please refer to the donation details below.\"\nvec = v.transform([sample]).toarray()\nm.predict(vec)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":4}