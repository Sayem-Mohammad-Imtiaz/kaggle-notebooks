{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install keras==2.4.3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nprint(keras.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T13:35:07.034706Z","iopub.execute_input":"2021-07-10T13:35:07.035205Z","iopub.status.idle":"2021-07-10T13:35:09.079786Z","shell.execute_reply.started":"2021-07-10T13:35:07.035101Z","shell.execute_reply":"2021-07-10T13:35:09.078149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Rice Grain Multi-Classification: IN this Project i will be using SVM layer instead of Logistic regression layer for final output.I'm using deep learning for feature extraction and at the end using SVM model for classificationÂ¶\n","metadata":{}},{"cell_type":"markdown","source":"Initialization & Importing libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import train_test_split\nimport itertools\n\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Activation, Flatten, Dropout, concatenate, Input, Conv2D, MaxPooling2D\nfrom keras.optimizers import Adam, Adadelta\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.utils.np_utils import to_categorical","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train DIR: 3249 Images\nTest DIR: Random Images from every class.\nsample_submission.csv - a sample submission file in the correct format","metadata":{}},{"cell_type":"code","source":"train_dir = '../input/rice-train/train'\ntest_dir = '../input/rice-grain-multiclassification/test'\nsample_submission = pd.read_csv('../input/sample/sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Different Species: Rice Grain Classification.","metadata":{}},{"cell_type":"code","source":"SPECIES = ['Broken rice', 'Chalky', 'Damaged rice', 'Discolored rice', 'Grade1', 'Grade2', 'Grade3', 'Grade4', 'Grade5', 'Premium','Standard rice']\n\nfor species in SPECIES:\n    print('{} {} images'.format(species, len(os.listdir(os.path.join(train_dir, species)))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training Data Files","metadata":{}},{"cell_type":"code","source":"train = []\n\nfor species_num, species in enumerate(SPECIES):\n    for file in os.listdir(os.path.join(train_dir, species)):\n        if file == 'Thumbs.db':\n            continue\n        train.append(['../input/rice-train/train/{}/{}'.format(species, file), species_num, species])\n        \ntrain = pd.DataFrame(train, columns=['file', 'species_num', 'species'])\n\nprint('Training Data: ',train.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Image Pre-Processing","metadata":{}},{"cell_type":"code","source":"def create_mask_for_plant(image):\n    image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n\n    sensitivity = 35\n    lower_hsv = np.array([60 - sensitivity, 100, 50])\n    upper_hsv = np.array([60 + sensitivity, 255, 255])\n\n    mask = cv2.inRange(image_hsv, lower_hsv, upper_hsv)\n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n    \n    return mask\n\ndef segment_plant(image):\n    mask = create_mask_for_plant(image)\n    output = cv2.bitwise_and(image, image, mask = mask)\n    return output\n\ndef sharpen_image(image):\n    image_blurred = cv2.GaussianBlur(image, (0, 0), 3)\n    image_sharp = cv2.addWeighted(image, 1.5, image_blurred, -0.5, 0)\n    return image_sharp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Loading Train Data","metadata":{}},{"cell_type":"code","source":"%%time\n\nx_train = []\ntemp = []\n\nfor i in range(len(train)):\n    img = cv2.imread(train['file'][i])\n\n    img = cv2.resize(img,dsize=(256,256))\n    img_stack = segment_plant(img)\n    img_stack = sharpen_image(img_stack)\n    img_stack = cv2.cvtColor( img_stack, cv2.COLOR_RGB2GRAY )\n    img_stack = np.reshape(img_stack,(256,256,1))\n    x_train.append(np.concatenate((np.array(img),np.array(img_stack)),axis=2))\n\nx_train = np.array(x_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sample Images\n","metadata":{}},{"cell_type":"code","source":"\n\n# Input image\nInput_image = cv2.imread(train['file'][len(train)-1])\n\nplt.imshow(Input_image)\nplt.title('Input image, Shape: '+str(Input_image.shape))\nplt.show()\n\n# Resized image\nplt.imshow(img)\nplt.title('Resized image, Shape: '+str(img.shape))\nplt.show()\n        \n# Processed image to Stack\nplt.imshow(np.reshape(img_stack,(256,256)))\nplt.title('Processed image, Shape: '+str(img_stack.shape))\nplt.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One-hot Encoding","metadata":{}},{"cell_type":"code","source":"labels = train['species_num']\nlabels = to_categorical(labels, num_classes = len(SPECIES))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CV-Partition","metadata":{}},{"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(x_train, labels, test_size = 0.1, random_state=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Input Shape","metadata":{}},{"cell_type":"code","source":"input_shape = x_train[1].shape\nprint('Input Shape is :', input_shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CNN Model Architecture","metadata":{}},{"cell_type":"code","source":"def fire_incept(x, fire=16, intercept=64):\n    x = Conv2D(fire, (5,5), strides=(2,2))(x)\n    x = LeakyReLU(alpha=0.15)(x)\n    \n    left = Conv2D(intercept, (3,3), padding='same')(x)\n    left = LeakyReLU(alpha=0.15)(left)\n    \n    right = Conv2D(intercept, (5,5), padding='same')(x)\n    right = LeakyReLU(alpha=0.15)(right)\n    \n    x = concatenate([left, right], axis=3)\n    return x\n\ndef fire_squeeze(x, fire=16, intercept=64):\n    x = Conv2D(fire, (1,1))(x)\n    x = LeakyReLU(alpha=0.15)(x)\n    \n    left = Conv2D(intercept, (1,1))(x)\n    left = LeakyReLU(alpha=0.15)(left)\n    \n    right = Conv2D(intercept, (3,3), padding='same')(x)\n    right = LeakyReLU(alpha=0.15)(right)\n    \n    x = concatenate([left, right], axis=3)\n    return x\n\nimage_input=Input(shape=input_shape)\n\nx = fire_incept((image_input), fire=16, intercept=16)\n\nx = fire_incept(x, fire=32, intercept=32)\nx = fire_squeeze(x, fire=32, intercept=32)\n\nx = fire_incept(x, fire=64, intercept=64)\nx = fire_squeeze(x, fire=64, intercept=64)\n\nx = fire_incept(x, fire=64, intercept=64)\nx = fire_squeeze(x, fire=64, intercept=64)\n\nx = Conv2D(64, (3,3))(x)\nx = LeakyReLU(alpha=0.1)(x)\n\nx = Flatten()(x)\n\nx = Dense(512)(x)\nx = LeakyReLU(alpha=0.1)(x)\nx = Dropout(0.1)(x)\n\nout = Dense(len(SPECIES), activation='softmax')(x)\n\nmodel_new = Model(image_input, out)\nmodel_new.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Compile the model","metadata":{}},{"cell_type":"code","source":"\n\nmodel_new.compile(optimizer = Adam(lr=.00025) , loss = 'categorical_crossentropy', metrics=['accuracy'])\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Learning rate","metadata":{}},{"cell_type":"code","source":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, \n                                            factor=0.5, min_lr=0.00001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data Augmentation","metadata":{}},{"cell_type":"code","source":"datagen = ImageDataGenerator(rotation_range=40, zoom_range = 0.2, width_shift_range=0.2, height_shift_range=0.2,\n                             horizontal_flip=True, vertical_flip=True)\ndatagen.fit(x_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Batch Size & Epochs","metadata":{}},{"cell_type":"code","source":"\n\nbatch_size = 32\nepochs = 40\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training of the model","metadata":{}},{"cell_type":"code","source":"\n\n\nhistory = model_new.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size), epochs = epochs,\n                                  validation_data = (x_val,y_val), verbose = 1, \n                                  steps_per_epoch=x_train.shape[0] // batch_size, \n                                  callbacks=[learning_rate_reduction])\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot Graph","metadata":{}},{"cell_type":"markdown","source":"Plot Val_loss Graph:","metadata":{}},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Training for ' +str(epochs)+ ' epochs')\nplt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot Val_accuracy Graph:","metadata":{}},{"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Training for ' +str(epochs)+ ' epochs')\nplt.legend(['Training accuracy', 'Validation accuracy'], loc='lower right')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model_Save : Rice.h5(OutPut)\n","metadata":{}},{"cell_type":"code","source":"filepath = './newupdatedrice.h5'\nmodel_new.save(filepath)\n\n#Model.save(model, './Rice.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Predictions","metadata":{}},{"cell_type":"code","source":"%%time\n\ntest = []\nfor file in os.listdir(os.path.join(test_dir)):\n    test.append(['../input/rice-grain-multiclassification/test/{}'.format(file)])\n\ntest = pd.DataFrame(test, columns=['file'])\nprint(test.head(5))\n\n\nx_test = []\n\nfor i in range(len(test)):\n    img = cv2.imread(test['file'][i])\n    if img is None:\n        continue\n    img = cv2.resize(img,dsize=(256,256))\n    img_stack = segment_plant(img)\n    img_stack = sharpen_image(img_stack)\n    img_stack = cv2.cvtColor( img_stack, cv2.COLOR_RGB2GRAY )\n    img_stack = np.reshape(img_stack,(256,256,1))\n    x_test.append(np.concatenate((np.array(img),np.array(img_stack)),axis=2))\n\nx_test = np.array(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sample Test Images","metadata":{}},{"cell_type":"code","source":"randm = np.random.randint(0,len(test))\n\nimg = cv2.imread(test['file'][randm])\nplt.imshow(img)\nplt.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prediction Score [ Validation Set ]","metadata":{}},{"cell_type":"code","source":"score = model_new.evaluate(x_val,y_val)\nprint('Accuracy on Validation Set',score[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prediction on Test Set","metadata":{}},{"cell_type":"code","source":"Pred_labels = np.argmax(model_new.predict(x_test),axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Applying Suppot Vector Machine**","metadata":{}},{"cell_type":"markdown","source":"Extracting Features from last Layer","metadata":{}},{"cell_type":"code","source":"model_feat = Model(inputs=model_new.input,outputs=model_new.get_layer('dense_1').output)\n\nfeat_train = model_feat.predict(x_train)\nprint(feat_train.shape)\n\nfeat_val = model_feat.predict(x_val)\nprint(feat_val.shape)\n\nfeat_test = model_feat.predict(x_test)\nprint(feat_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Applying SVM","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm = SVC(kernel='rbf')\n\nsvm.fit(feat_train,np.argmax(y_train,axis=1))\n\nprint('fitting done !!!')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SVM: Prediction Score [Training Features]","metadata":{}},{"cell_type":"code","source":"svm.score(feat_train,np.argmax(y_train,axis=1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prediction Score [Validation Features]","metadata":{}},{"cell_type":"code","source":"svm.score(feat_val,np.argmax(y_val,axis=1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Pred_labels = svm.predict(feat_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CNN & SVM : Predict on [Test Features]","metadata":{}},{"cell_type":"code","source":"Pred_labels = pd.DataFrame(Pred_labels,index =None,columns=['species_num'])\n\ntest_id = []\nfor file in os.listdir(test_dir):\n    test_id.append(['{}'.format(file)])\n\ntest_id = pd.DataFrame(test_id, columns=['file'])\n\ntest_df = pd.DataFrame()\ntest_df['species_num'] = Pred_labels['species_num']\ntest_df['file'] = test_id['file']\ntest_df['species'] = [SPECIES[i] for i in Pred_labels['species_num']]\n\nsubmission = pd.merge(left=sample_submission, right=test_df[['file', 'species']], on=\"file\", how=\"right\")\nsubmission.drop(['species_x'], axis = 1, inplace = True)\nsubmission.columns = ['file','species']\n\nsubmission.to_csv('submission.csv', index=False)\nprint(submission.head())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}