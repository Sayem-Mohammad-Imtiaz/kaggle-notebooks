{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# DETECTANDO NORMALIDAD Y AJUSTE DE DISTRIBUCION\nIMPORTANDO LIBRERIAS","metadata":{"id":"gXjcmT5nFs-E"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom statsmodels.graphics.gofplots import qqplot\nfrom scipy.stats import shapiro\nfrom scipy.stats import normaltest\nimport warnings\nimport scipy.stats as st\nimport statsmodels as sm\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.axes\n\n\n\n","metadata":{"id":"DSWuNBy97U3C","execution":{"iopub.status.busy":"2021-06-14T17:39:02.221221Z","iopub.execute_input":"2021-06-14T17:39:02.22163Z","iopub.status.idle":"2021-06-14T17:39:02.941143Z","shell.execute_reply.started":"2021-06-14T17:39:02.221546Z","shell.execute_reply":"2021-06-14T17:39:02.940317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LEYENDO DATASET","metadata":{"id":"SzBoNLMIF66f"}},{"cell_type":"code","source":"df=pd.read_csv('../input/diabetes-diagnosis/diabetesdiagnosis.csv', sep=',')\n","metadata":{"id":"6UJKRpCmFzMP","execution":{"iopub.status.busy":"2021-06-14T17:39:02.942578Z","iopub.execute_input":"2021-06-14T17:39:02.942889Z","iopub.status.idle":"2021-06-14T17:39:02.960273Z","shell.execute_reply.started":"2021-06-14T17:39:02.942854Z","shell.execute_reply":"2021-06-14T17:39:02.959507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"DETECTANDO NORMALIDAD APLICANDO CUANTILES TEÓRICOS","metadata":{"id":"sQy4NwNkGr_8"}},{"cell_type":"code","source":"def qqplotJona(datos):\n    headers=list(datos.columns.values)\n    for i in range(0,len(headers)):   \n        try:\n            with warnings.catch_warnings():\n                warnings.filterwarnings('ignore')\n                print(headers[i])        \n                qqplot(df[headers[i]] , line='s')\n                plt.show()\n        except Exception:\n            pass\n            ","metadata":{"id":"UtDSZTEoGCVm","execution":{"iopub.status.busy":"2021-06-14T17:39:02.962512Z","iopub.execute_input":"2021-06-14T17:39:02.963002Z","iopub.status.idle":"2021-06-14T17:39:02.969743Z","shell.execute_reply.started":"2021-06-14T17:39:02.962963Z","shell.execute_reply":"2021-06-14T17:39:02.968656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"qqplotJona(df)","metadata":{"id":"QiPLSfobGluU","outputId":"9e34659b-46db-4269-f253-50ffc5cadf91","execution":{"iopub.status.busy":"2021-06-14T17:39:02.971658Z","iopub.execute_input":"2021-06-14T17:39:02.972295Z","iopub.status.idle":"2021-06-14T17:39:04.189706Z","shell.execute_reply.started":"2021-06-14T17:39:02.972258Z","shell.execute_reply":"2021-06-14T17:39:04.188679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"DETECTANDO NORMALIDAD APLICANDO SHAPIRO-WILK","metadata":{"id":"3GjLlY7jMi1v"}},{"cell_type":"code","source":"def shapiroJona(datos):\n    headers=list(datos.columns.values)\n    for i in range(0,len(headers)):    \n        print(headers[i])        \n        stat, p = shapiro(df[headers[i]].to_numpy())\n        print('Estadisticos=%.3f, p=%.3f' % (stat, p))            \n        print('Estadisticos=',stat)            \n        print('p=',p)            \n        alpha = 0.05\n        if p > alpha:\n           print('La muestra parece Gaussiana o Normal (no se rechaza la hipótesis nula H0)')\n        else:\n           print('La muestra no parece Gaussiana o Normal(se rechaza la hipótesis nula H0)')\n","metadata":{"id":"k4COUAAdGj-z","execution":{"iopub.status.busy":"2021-06-14T17:39:04.191323Z","iopub.execute_input":"2021-06-14T17:39:04.191689Z","iopub.status.idle":"2021-06-14T17:39:04.199282Z","shell.execute_reply.started":"2021-06-14T17:39:04.191652Z","shell.execute_reply":"2021-06-14T17:39:04.198335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shapiroJona(df)","metadata":{"id":"wQm426t1K7zh","outputId":"d0cad563-ee52-4378-e84d-7658573973ea","execution":{"iopub.status.busy":"2021-06-14T17:39:04.200814Z","iopub.execute_input":"2021-06-14T17:39:04.201209Z","iopub.status.idle":"2021-06-14T17:39:04.228495Z","shell.execute_reply.started":"2021-06-14T17:39:04.201173Z","shell.execute_reply":"2021-06-14T17:39:04.22752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"DETECTANDO NORMALIDAD APLICANDO K^2 de D’Agostino","metadata":{"id":"HcD6iCfvNKEH"}},{"cell_type":"code","source":"def dAgostinoJona(datos):\n    headers=list(datos.columns.values)\n    for i in range(0,len(headers)):    \n        print(headers[i])        \n        stat, p = normaltest(df[headers[i]].to_numpy())\n        print('Estadisticos=%.3f, p=%.3f' % (stat, p))            \n        print('Estadisticos=',stat)            \n        print('p=',p)            \n        alpha = 0.05\n        if p > alpha:\n           print('La muestra parece Gaussiana o Normal (no se rechaza la hipótesis nula H0)')\n        else:\n           print('La muestra no parece Gaussiana o Normal(se rechaza la hipótesis nula H0)')","metadata":{"id":"IyjpbfMQMyWZ","execution":{"iopub.status.busy":"2021-06-14T17:39:04.229859Z","iopub.execute_input":"2021-06-14T17:39:04.230232Z","iopub.status.idle":"2021-06-14T17:39:04.237358Z","shell.execute_reply.started":"2021-06-14T17:39:04.230196Z","shell.execute_reply":"2021-06-14T17:39:04.236239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dAgostinoJona(df)","metadata":{"id":"3yLx1_RPNTlL","outputId":"65852dee-7bfe-4291-fd61-ce25a684880c","execution":{"iopub.status.busy":"2021-06-14T17:39:04.240111Z","iopub.execute_input":"2021-06-14T17:39:04.240507Z","iopub.status.idle":"2021-06-14T17:39:04.278642Z","shell.execute_reply.started":"2021-06-14T17:39:04.240471Z","shell.execute_reply":"2021-06-14T17:39:04.277831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"AJUSTE DE DISTRIBUCIÓN A TRAVÉS DE Kolmogorov-Smirnov","metadata":{"id":"Wiikve8-wHJx"}},{"cell_type":"code","source":"def getBestDistributionJona(data):\n    dist_names = [\n        \"norm\",\"invgauss\",\"johnsonsu\",\"cauchy\",\"vonmises_line\",\"cauchy\",\"vonmises_line\",\"exponnorm\",\"hypsecant\"\n        # \"alpha\",\"anglit\",\"arcsine\",\"beta\",\"betaprime\",\"bradford\",\"burr\",\"cauchy\",\"chi\",\"chi2\",\"cosine\",\"dgamma\",\"dweibull\",\"erlang\",\"expon\",\"exponnorm\",\"exponweib\",\"exponpow\",\"f\",\"fatiguelife\",\"fisk\",\"foldcauchy\",\"foldnorm\",\"frechet_r\",\"frechet_l\",\"genlogistic\",\"genpareto\",\"gennorm\",\"genexpon\",\"genextreme\",\"gausshyper\",\"gamma\",\"gengamma\",\"genhalflogistic\",\"gilbrat\",\"gompertz\",\"gumbel_r\",\"gumbel_l\",\"halfcauchy\",\"halflogistic\",\"halfnorm\",\"halfgennorm\",\"hypsecant\",\"invgamma\",\"invgauss\",\"invweibull\",\"johnsonsb\",\"johnsonsu\",\"ksone\",\"kstwobign\",\"laplace\",\"levy\",\"levy_l\",\"levy_stable\",\"logistic\",\"loggamma\",\"loglaplace\",\"lognorm\",\"lomax\",\"maxwell\",\"mielke\",\"nakagami\",\"ncx2\",\"ncf\",\"nct\",\"norm\",\"pareto\",\"pearson3\",\"powerlaw\",\"powerlognorm\",\"powernorm\",\"rdist\",\"reciprocal\",\"rayleigh\",\"rice\",\"recipinvgauss\",\"semicircular\",\"t\",\"triang\",\"truncexpon\",\"truncnorm\",\"tukeylambda\",\"uniform\",\"vonmises\",\"vonmises_line\",\"wald\",\"weibull_min\",\"weibull_max\",\"wrapcauchy\"\n    ]\n    dist_results = []\n    params = {}\n    for dist_name in dist_names:\n      # Try to fit the distribution\n        try:\n            # Ignore warnings from data that can't be fit\n            with warnings.catch_warnings():\n                warnings.filterwarnings('ignore')\n                dist = getattr(st, dist_name)\n                param = dist.fit(data)\n\n                params[dist_name] = param\n                # Applying the Kolmogorov-Smirnov test\n                D, p = st.kstest(data, dist_name, args=param)\n                print(\"p value for \"+dist_name+\" = \"+str(p))\n                dist_results.append((dist_name, p))\n        except Exception:\n            pass\n    # select the best fitted distribution\n    best_dist, best_p = (max(dist_results, key=lambda item: item[1]))\n    # store the name of the best fit and its p value\n\n    print(\"Best fitting distribution: \"+str(best_dist))\n    print(\"Best p value: \"+ str(best_p))\n    print(\"Parameters for the best fit: \"+ str(params[best_dist]))\n\n    return best_dist, best_p, params[best_dist]","metadata":{"id":"2VZK-ZP5iYyA","execution":{"iopub.status.busy":"2021-06-14T17:39:04.280125Z","iopub.execute_input":"2021-06-14T17:39:04.280445Z","iopub.status.idle":"2021-06-14T17:39:04.289695Z","shell.execute_reply.started":"2021-06-14T17:39:04.280414Z","shell.execute_reply":"2021-06-14T17:39:04.288668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#getBestDistributionJona(df['Pregnancies']) ejemplo de uso\ndef KolmogorovSmirnov(datos):    \n    headers=list(datos.columns.values)\n    for i in range(0,len(headers)):    \n        print(headers[i]) \n        getBestDistributionJona(df[headers[i]])","metadata":{"id":"EvHbVx75w6Vv","execution":{"iopub.status.busy":"2021-06-14T17:39:04.291236Z","iopub.execute_input":"2021-06-14T17:39:04.291649Z","iopub.status.idle":"2021-06-14T17:39:04.302122Z","shell.execute_reply.started":"2021-06-14T17:39:04.291616Z","shell.execute_reply":"2021-06-14T17:39:04.300957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KolmogorovSmirnov(df)","metadata":{"id":"GFUTHu6rxd14","execution":{"iopub.status.busy":"2021-06-14T17:39:04.30351Z","iopub.execute_input":"2021-06-14T17:39:04.303916Z","iopub.status.idle":"2021-06-14T17:39:23.739408Z","shell.execute_reply.started":"2021-06-14T17:39:04.30387Z","shell.execute_reply":"2021-06-14T17:39:23.736657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"AJUSTE DE DISTRIBUCIÓN USANDO SUMA DE CUADRADOS DEL ERROR","metadata":{"id":"oppCakIdd-pv"}},{"cell_type":"code","source":"def best_fit_distribution(data, bins=200, ax=None):\n    \"\"\"Model data by finding best fit distribution to data\"\"\"\n    # Get histogram of original data\n    y, x = np.histogram(data, bins=bins, density=True)\n    x = (x + np.roll(x, -1))[:-1] / 2.0\n\n    # Distributions to check\n    DISTRIBUTIONS = [        \n        st.norm,st.invgauss,st.johnsonsu,st.cauchy,st.vonmises_line,st.cauchy,st.vonmises_line,st.exponnorm,st.hypsecant\n        #st.alpha,st.anglit,st.arcsine,st.beta,st.betaprime,st.bradford,st.burr,st.cauchy,st.chi,st.chi2,st.cosine,st.dgamma,st.dweibull,st.erlang,st.expon,st.exponnorm,st.exponweib,st.exponpow,st.f,st.fatiguelife,st.fisk,st.foldcauchy,st.foldnorm,st.frechet_r,st.frechet_l,st.genlogistic,st.genpareto,st.gennorm,st.genexpon,st.genextreme,st.gausshyper,st.gamma,st.gengamma,st.genhalflogistic,st.gilbrat,st.gompertz,st.gumbel_r,st.gumbel_l,st.halfcauchy,st.halflogistic,st.halfnorm,st.halfgennorm,st.hypsecant,st.invgamma,st.invgauss,st.invweibull,st.johnsonsb,st.johnsonsu,st.ksone,st.kstwobign,st.laplace,st.levy,st.levy_l,st.levy_stable,st.logistic,st.loggamma,st.loglaplace,st.lognorm,st.lomax,st.maxwell,st.mielke,st.nakagami,st.ncx2,st.ncf,st.nct,st.norm,st.pareto,st.pearson3,st.powerlaw,st.powerlognorm,st.powernorm,st.rdist,st.reciprocal,st.rayleigh,st.rice,st.recipinvgauss,st.semicircular,st.t,st.triang,st.truncexpon,st.truncnorm,st.tukeylambda,st.uniform,st.vonmises,st.vonmises_line,st.wald,st.weibull_min,st.weibull_max,st.wrapcauchy\n    ]\n\n    # Best holders\n    best_distribution = st.norm\n    best_params = (0.0, 1.0)\n    best_sse = np.inf\n\n    # Estimate distribution parameters from data\n    for distribution in DISTRIBUTIONS:\n\n        # Try to fit the distribution\n        try:\n            # Ignore warnings from data that can't be fit\n            with warnings.catch_warnings():\n                warnings.filterwarnings('ignore')\n\n                # fit dist to data\n                params = distribution.fit(data)\n\n                # Separate parts of parameters\n                arg = params[:-2]\n                loc = params[-2]\n                scale = params[-1]\n\n                # Calculate fitted PDF and error with fit in distribution\n                pdf = distribution.pdf(x, loc=loc, scale=scale, *arg)\n                sse = np.sum(np.power(y - pdf, 2.0))\n\n                # if axis pass in add to plot\n                try:\n                    if ax:\n                        pd.Series(pdf, x).plot(ax=ax)\n                    end\n                except Exception:\n                    pass\n\n                # identify if this distribution is better\n                if best_sse > sse > 0:\n                    best_distribution = distribution\n                    best_params = params\n                    best_sse = sse\n\n        except Exception:\n            pass\n\n    return (best_distribution.name, best_params)","metadata":{"id":"6r6uzeaUTHMI","execution":{"iopub.status.busy":"2021-06-14T17:39:23.740744Z","iopub.execute_input":"2021-06-14T17:39:23.741095Z","iopub.status.idle":"2021-06-14T17:39:23.754417Z","shell.execute_reply.started":"2021-06-14T17:39:23.741057Z","shell.execute_reply":"2021-06-14T17:39:23.753374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_pdf(dist, params, size=10000):\n    \"\"\"Generate distributions's Probability Distribution Function \"\"\"\n\n    # Separate parts of parameters\n    arg = params[:-2]\n    loc = params[-2]\n    scale = params[-1]\n\n    # Get sane start and end points of distribution\n    start = dist.ppf(0.01, *arg, loc=loc, scale=scale) if arg else dist.ppf(0.01, loc=loc, scale=scale)\n    end = dist.ppf(0.99, *arg, loc=loc, scale=scale) if arg else dist.ppf(0.99, loc=loc, scale=scale)\n\n    # Build PDF and turn into pandas Series\n    x = np.linspace(start, end, size)\n    y = dist.pdf(x, loc=loc, scale=scale, *arg)\n    pdf = pd.Series(y, x)\n\n    return pdf","metadata":{"id":"fT0GDhIafjLz","execution":{"iopub.status.busy":"2021-06-14T17:39:23.756012Z","iopub.execute_input":"2021-06-14T17:39:23.756559Z","iopub.status.idle":"2021-06-14T17:39:23.767602Z","shell.execute_reply.started":"2021-06-14T17:39:23.756353Z","shell.execute_reply":"2021-06-14T17:39:23.766564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ajustarDistribucionSSE(datos):\n    headers=list(datos.columns.values)\n    for i in range(0,len(headers)):   \n        try: \n            with warnings.catch_warnings():\n                warnings.filterwarnings('ignore')\n                titulo=headers[i]\n                print(titulo)\n                matplotlib.rcParams['figure.figsize'] = (16.0, 12.0)\n                matplotlib.style.use('ggplot')\n                data=df[headers[i]]\n                plt.figure(figsize=(12,8))\n                ax = data.plot(kind='hist', bins=50, density=True, alpha=0.5, color='#aabbcc')\n                dataYLim = ax.get_ylim()\n                # Find best fit distribution\n                best_fit_name, best_fit_params = best_fit_distribution(data, 200, ax)\n                best_dist = getattr(st, best_fit_name)\n                # Update plots\n                ax.set_ylim(dataYLim)\n                ax.set_title(titulo)\n                ax.set_xlabel(titulo)\n                ax.set_ylabel('Frequency')\n                # Make PDF with best params\n                pdf = make_pdf(best_dist, best_fit_params)\n                # Display\n                plt.figure(figsize=(12,8))\n                ax = pdf.plot(lw=2, label='PDF', legend=True)\n                data.plot(kind='hist', bins=50, density=True, alpha=0.5, label='Data', legend=True, ax=ax)\n                param_names = (best_dist.shapes + ', loc, scale').split(', ') if best_dist.shapes else ['loc', 'scale']\n                param_str = ', '.join(['{}={:0.2f}'.format(k,v) for k,v in zip(param_names, best_fit_params)])\n                dist_str = '{}({})'.format(best_fit_name, param_str)\n                ax.set_title(titulo+' \\n' + dist_str)\n                ax.set_xlabel(titulo)\n                ax.set_ylabel('Frequency')\n        except Exception:\n            pass","metadata":{"id":"bzhmd5DHTv_e","execution":{"iopub.status.busy":"2021-06-14T17:39:23.769261Z","iopub.execute_input":"2021-06-14T17:39:23.769852Z","iopub.status.idle":"2021-06-14T17:39:23.784779Z","shell.execute_reply.started":"2021-06-14T17:39:23.769813Z","shell.execute_reply":"2021-06-14T17:39:23.783756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ajustarDistribucionSSE(df)","metadata":{"id":"Bu5Jw6h0YJm-","outputId":"ea7b752a-6401-4795-964b-3b8cc8e737be","execution":{"iopub.status.busy":"2021-06-14T17:39:23.786173Z","iopub.execute_input":"2021-06-14T17:39:23.786559Z","iopub.status.idle":"2021-06-14T17:39:46.38767Z","shell.execute_reply.started":"2021-06-14T17:39:23.786521Z","shell.execute_reply":"2021-06-14T17:39:46.386695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LINKOGRAFÍA\n[https://hub.mybinder.turing.ac.uk/user/relopezbriega-blog-8r7y7cqu/notebooks/content/notebooks/DistStatsPy.ipynb](https://hub.mybinder.turing.ac.uk/user/relopezbriega-blog-8r7y7cqu/notebooks/content/notebooks/DistStatsPy.ipynb)\n[https://machinelearningparatodos.com/como-saber-si-una-variable-sigue-una-distribucion-normal-en-python/](https://machinelearningparatodos.com/como-saber-si-una-variable-sigue-una-distribucion-normal-en-python/)\n[https://www.cienciadedatos.net/documentos/pystats01-ajuste-distribuciones-python.html](https://www.cienciadedatos.net/documentos/pystats01-ajuste-distribuciones-python.html)\n[https://stackoverflow.com/questions/37487830/how-to-find-probability-distribution-and-parameters-for-real-data-python-3](https://stackoverflow.com/questions/37487830/how-to-find-probability-distribution-and-parameters-for-real-data-python-3)\n[https://stackoverflow.com/questions/6620471/fitting-empirical-distribution-to-theoretical-ones-with-scipy-python](https://stackoverflow.com/questions/6620471/fitting-empirical-distribution-to-theoretical-ones-with-scipy-python)\n[https://stackoverflow.com/questions/6615489/fitting-distributions-goodness-of-fit-p-value-is-it-possible-to-do-this-with/16651524#16651524](https://stackoverflow.com/questions/6615489/fitting-distributions-goodness-of-fit-p-value-is-it-possible-to-do-this-with/16651524#16651524)\n[https://glowingpython.blogspot.com/2012/07/distribution-fitting-with-scipy.html](https://glowingpython.blogspot.com/2012/07/distribution-fitting-with-scipy.html)\n[https://docs.scipy.org/doc/scipy/reference/stats.html](https://docs.scipy.org/doc/scipy/reference/stats.html)\n[https://www.statsmodels.org/devel/datasets/generated/elnino.html#el-nino-sea-surface-temperatures](https://www.statsmodels.org/devel/datasets/generated/elnino.html#el-nino-sea-surface-temperatures)\n","metadata":{"id":"zAdHp2rNNan6"}}]}