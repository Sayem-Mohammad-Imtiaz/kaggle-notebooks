{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nimport sklearn\nfrom datetime import date, timedelta\nfrom sklearn.model_selection import train_test_split\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change your location\ntrain = pd.read_csv('/kaggle/input/womenintheloop-data-science-hackathon/train.csv')\ntest = pd.read_csv('/kaggle/input/womenintheloop-data-science-hackathon/test_QkPvNLx.csv')\nsample = pd.read_csv('/kaggle/input/womenintheloop-data-science-hackathon/sample_submission_pn2DrMq.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Columns of the data set\nprint(list(train.columns))\nprint(list(test.columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We notice that User Traffic in the train set is missing in the test data\n# Lets analyse each parameter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.ID.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.apply(lambda x : len(x.unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Notice that ID is unique for each data point, So removing can remove it ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train['ID']\ndel test['ID']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sales is the target variable and its a regression problem, lets further analyse sales","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Sales.describe() # ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From the description of sales, we find that minimum sales is 0 which is not possible","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[['Sales']].boxplot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train['Sales'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From the distribution of we can find that\n# Sales do not follow normal distribution\n# Sales is postively skewed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Skewness= \", train['Sales'].skew())\nprint(\"Kurtosis= \", train['Sales'].kurt())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since kutosis is > 3, we can conclude that Distribution is longer, has Many Outliers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analysis of Day_Number","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting on sample of dataset coz data is huge \nsampletrain= train.sample(1000)\nsns.regplot(x='Day_No',y='Sales',data= sampletrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As we can see from the above graph, We can say that Day_No is not a good estimator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[['Course_ID','Sales']].boxplot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[['Course_Domain','Sales']].boxplot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[['Short_Promotion','Sales']].boxplot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From the above graphs we can conclude that data can be normalised before fiting it into a models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets find the correlation\nplt.subplots(figsize=(10,8))\nsns.heatmap(train.corr(), annot= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.corr().unstack().sort_values().drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train['Course_Domain'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train['Long_Promotion'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train['Short_Promotion'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_train = train[train.Sales>0] # Sales cannot be zero\nsample_train[sample_train['Course_ID']==132][['Day_No','Sales']].plot(x='Day_No',y='Sales',figsize=(16,4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_sales = train.groupby(['Course_ID','Course_Domain','Course_Type','Short_Promotion','Public_Holiday','Long_Promotion'])['Sales'].mean().reset_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"Adding a new feature by using Day_No "},{"metadata":{"trusted":true},"cell_type":"code","source":"def day_to_date(dataset):\n    start = date(2018,12,31)\n    dataset['Date'] = dataset['Day_No'].apply(lambda x: start + timedelta(x)) \n\ndef day_month_year(dataset): \n    dataset['Day'] = dataset['Date'].apply(lambda x: x.day)\n    dataset['Month'] = dataset['Date'].apply(lambda x: x.month)\n    dataset['Year'] = dataset['Date'].apply(lambda x: x.year)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"day_to_date(train)\nday_month_year(train)\nday_to_date(test)\nday_month_year(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since test doesnt contain User Traffic, we are removing it"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop('User_Traffic',axis =1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.columns)\nprint(test.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merge train and test\ndf = train.append(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Competition_Metric'].fillna(df['Competition_Metric'].median(), inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=pd.get_dummies(df,columns=['Course_Domain','Course_Type'],drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.columns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.drop(['Day_No','Date'],axis = 1,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#splitting train and test from df\ntrain1= df1[df1['Sales'].isnull()!= True]\ntest1= df1[df1['Sales'].isnull()== True].drop(['Sales'], axis=1)\nprint(train1.shape)\nprint(test1.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train1.columns)\nprint(test1.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train1.drop('Sales',axis = 1)\nY_train = train.Sales\nX_test = test1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.columns)\nprint(Y_train)\nprint(X_test.columns)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_tr, X_val, y_tr, y_val = train_test_split(X_train, Y_train, test_size = 0.2, random_state = 890)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.columns)\nprint(X_test.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_train = lgb.Dataset(X_tr, y_tr)\nlgb_val = lgb.Dataset(X_val, y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from hyperopt import STATUS_OK \nfrom hyperopt import hp \nfrom hyperopt import tpe \nfrom hyperopt import fmin \nfrom hyperopt import Trials\n\nN_FOLDS = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" from sklearn.metrics import mean_squared_log_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmsle(preds, lgb_train): \n    eval_name = 'rmsle' \n    eval_result = np.sqrt(mean_squared_log_error(preds, lgb_train.get_label())) \n    return (eval_name, eval_result*1000, False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def objective(params, n_folds = N_FOLDS): \n    cv_results = lgb.cv(params, lgb_train, num_boost_round = 1000, nfold = 5, feval = rmsle, early_stopping_rounds = 10, seed = 50) \n    best_score = min(cv_results['rmsle-mean']) \n    return {'loss': best_score, 'params': params, 'status': STATUS_OK}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"space = { 'task': hp.choice('task', ['train']), 'objective': hp.choice('objective', ['gamma']), 'metric' : hp.choice('metric', ['None']), 'boosting': hp.choice('boosting', ['gbdt']), 'learning_rate': hp.loguniform('learning_rate',np.log(0.003), np.log(0.5)), 'num_leaves': hp.choice('num_leaves', range(2, 100, 5)), 'max_depth': hp.choice('max_depth', range(1, 30, 5)), 'bagging_fraction': hp.uniform('bagging_fraction', 0.1, 1.0), 'bagging_freq': hp.choice('bagging_freq', range(1, 10, 1)), 'feature_fraction': hp.uniform('feature_fraction', 0.1, 1.0), 'max_bin': hp.choice('max_bin', range(200, 256, 5)), 'min_data_in_leaf': hp.choice('min_data_in_leaf', range(10, 1000, 1)), 'subsample': hp.uniform('subsample', 0.1, 1.0), 'bagging_seed': hp.choice('bagging_seed', range(1, 10, 1)), 'feature_fraction_seed': hp.choice('feature_fraction_seed', range(1, 10, 1)), }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evals_result = {} \nparams = {\n        'task': 'train',\n        'objective': 'gamma',\n        'metric' : 'None',\n        'boosting': 'gbdt',\n        'learning_rate': 0.03,\n        'num_leaves': 100,\n        'bagging_fraction': 0.85,\n        'bagging_freq': 1,\n        'bagging_seed': 1,\n        'feature_fraction': 0.9,\n        'feature_fraction_seed': 1,\n        'max_bin': 256,\n        'n_estimators': 1000,\n    }\ndef rmsle(preds, lgb_train):\n    eval_name = \"rmsle\"\n    eval_result = np.sqrt(mean_squared_log_error(preds, lgb_train.get_label()))\n    return (eval_name, eval_result*1000, False)\n\n\ncv_results = lgb.cv(params, lgb_train, num_boost_round = 1000, nfold = 5, feval = rmsle, early_stopping_rounds = 10, verbose_eval = 100, seed = 50)\n\nlgbm_model = lgb.train(params, train_set = lgb_train, valid_sets = lgb_val, feval = rmsle,  evals_result = evals_result, verbose_eval = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = lgbm_model.predict(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample['Sales'] = predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample # Submission 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmsle1000(y_true, y_pred):\n    return np.sqrt(np.mean(np.power(np.log1p(y_true + 1) - np.log1p(y_pred + 1), 2))) *1000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV,StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#xgb\nkf = StratifiedKFold(n_splits=5,shuffle=True,random_state=123)\n\nX_train = train1.drop('Sales',axis = 1)\nY_train = train.Sales\nX_test = test1\n\ncv_score =[]\ni=1\nfor train_index,test_index in kf.split(X_train, Y_train):\n    print('Fold no. = ', i)\n    \n    x_train, x_test = X_train.loc[train_index], X_train.loc[test_index]\n    y_train, y_test = Y_train.loc[train_index], Y_train.loc[test_index]\n    \n    #model\n    xgb = XGBRegressor(n_estimators= 500)\n    xgb.fit(x_train, y_train)\n    y_pred= xgb.predict(x_test)\n    score = rmsle1000(y_test, y_pred)\n    print('RMSLE score:',score)\n    cv_score.append(score)    \n    \n    i+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBRegressor(n_estimators= 500)\nxgb.fit(X_train,Y_train)\nxgb_preds = xgb.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for submission\nlgbm = LGBMRegressor(n_estimators= 500)\nlgbm.fit(X_train, Y_train)\nlgbm_preds = lgbm.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(xgb_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(lgbm_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train1.columns)\nprint(test1.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import h2o\nfrom h2o.automl import H2OAutoML\nh2o.init()\ntrain = h2o.H2OFrame(train1)\ntest = h2o.H2OFrame(test1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = \"Sales\"\nx = list(X_train.columns)\naml = H2OAutoML(max_models = 30, max_runtime_secs=300, seed = 1)\naml.train(x = x, y = y, training_frame = train)\nlb = aml.leaderboard\nlb.head()\nlb.head(rows=lb.nrows)\npreds = aml.predict(test)\nwater_preds=h2o.as_list(preds) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"water_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.rename(columns = {'Sales':'Sales_by_lgbm'},inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample['XG Boost'] = xgb_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample['LightGBM'] = lgbm_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample['H20'] = water_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predictions of various modles\nsample","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":4}