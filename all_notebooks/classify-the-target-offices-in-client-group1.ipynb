{"cells":[{"metadata":{},"cell_type":"markdown","source":"For our group project client criteria 1ï¼š **Break and Holiday schedule <or = Regular schedule**. At that time, there was no in-depth analysis of the office situation in this range. Therefore, when conducting market research, it is necessary to classify offices with similar consumption and estimate their office types and consumption methods. This is what I do in my individual project.\n\nIn fact, I am not very talented in programming, so I did not use pandas to do very diversified analysis. Part of the code comes from the contributions of groupwork members."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta = pd.read_csv('../input/building-data-genome-project-v1/meta_open.csv',index_col='uid') \nmeta.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_phoenix=meta.loc[meta['timezone']=='America/Phoenix']\nmeta_phoenix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_office=meta_phoenix[meta_phoenix['primaryspaceusage']=='Office']\nmeta_office.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_office.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_office['uid'] = meta_office.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Officename = meta_office['uid'].tolist()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_list_normalized = []\nfor officename in Officename:\n    \n  rawdata = pd.read_csv(\"../input/building-data-genome-project-v1/\"+officename+\".csv\", parse_dates=True, index_col='timestamp')\n  floor_area = meta.loc[officename][\"sqm\"]\n\n  normalized_data = rawdata/floor_area\n\n  data_list_normalized.append(normalized_data)\nnormalize_office = pd.concat(data_list_normalized,axis=1)\nnormalize_office","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"schedule = pd.read_csv('../input/building-data-genome-project-v1/schedule2.csv',header = None, parse_dates=True) \nschedule.columns = ['timestamp','schedule']\nschedule['timestamp']=pd.to_datetime(schedule['timestamp'],format='%Y-%m-%d')\nschedule.set_index(['timestamp'],inplace = True)\nschedule","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"schedule['schedule'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#set the same column of 'Date'\nnormalize_office['Time'] = normalize_office.index.map(lambda t: t.time())\nnormalize_office['Date'] = normalize_office.index.map(lambda t: t.date())\nschedule['Date'] = schedule.index.map(lambda t: t.date())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#combine normalize_office and schedule\nnormalize_office_schedule = pd.merge(schedule, normalize_office, how='left', on='Date')\nnormalize_office_schedule","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#break.max>regular.max,holiday.max>regular.max\nnormalized_result = normalize_office_schedule.groupby(['schedule','Time']).mean()\ntmp = normalized_result.groupby(['schedule'])\ntmp.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#select clients\nclients1 = []\nfor i in Officename:\n  if tmp.max().loc['Break'][i]>=tmp.max().loc['Regular'][i] or tmp.max().loc['Holiday'][i]>=tmp.max().loc['Regular'][i]: \n    clients1.append(i)\nclients1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Very important!!!!!!!!\nnormalized_result = normalize_office_schedule.groupby(['schedule','Time']).mean()\ndf_clients1 = normalized_result[clients1]\ndf_clients1.plot.area(figsize=(25,8),stacked=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From this picture, we can make a rough classification analysis of offices with similar consumption patterns. The next step is to compile the plot of office_Alannah, and the rest are analyzed with pictures (all screenshots after being generated on this page) to reduce the corresponding time of Kaggle running."},{"metadata":{"trusted":true},"cell_type":"code","source":"clients1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are three typical and different consumption patterns in these nine offices, and I will analyze them one by one next."},{"metadata":{"trusted":true},"cell_type":"code","source":"def clients1_pivot_plot(clients1):\n  reset_index = df_clients1[[clients1]].reset_index()\n  pivot = reset_index.pivot(index='Time',columns='schedule',values=clients1)\n  pivot.plot(figsize=(18,8)) \n  plt.title('24 load profile')\n  plt.tick_params(labelsize=20)\n  return plt.ylabel('Energy Consumption')\nclients1_pivot_plot('Office_Alannah')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clients1_pivot_plot('Office_Amelia')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The first type: office Alannah and Amelia have similar consumption patterns. The first peak appeared at around 5:30, and consumption changed rapidly, as can be seen from the slope. Then the second peak of electricity consumption was around 14:00. \n\nThe consumption waveform structure of the two offices is very similar, and the electricity consumption during working hours follows the rule of Summer>Regular>Holiday>Break."},{"metadata":{},"cell_type":"markdown","source":"What's interesting is that at the first peak, the two offices showed a state that the consumption of holiday and break was greater than regular. It can be inferred that the company's working mode is that regular time works according to normal working hours. During holidays or breaks, they will work overtime in the morning because they need to improve efficiency. Electricity consumption has been very low since the morning, so the duties performed by the office should be management of transportation and delivery. Overtime work in the early morning is likely to require expedited delivery, after which the employees can return to their holiday life normally."},{"metadata":{"trusted":true},"cell_type":"code","source":"clients1_pivot_plot('Office_Angelina')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clients1_pivot_plot('Office_Alyson')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The second type: office_Angelina and Alyson have unique consumption patterns. The first peak occurred between 5:00-5:30, and the consumption changes during the rest of the time were not very obvious. It is worth noting that the consumption patterns of Break and Holiday are the same, and the consumption patterns of Regular and Summer are the same. \n\nAnd the electricity consumption of the two offices as a whole follows the rule of Break>Holiday>Regular>Summer."},{"metadata":{},"cell_type":"markdown","source":"Obviously, a normal office consumption in Break and Holiday is lower than Regular. The consumption of this type of office seems abnormal, so it can be inferred that this office is a service-type holiday-driven profit model. During holidays, the workload is increased as needed and the power consumption of the equipment is increased. In the off-season (Regular), electricity consumption is not so frequent."},{"metadata":{"trusted":true},"cell_type":"code","source":"clients1_pivot_plot('Office_Allyson')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clients1_pivot_plot('Office_Ava')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clients1_pivot_plot('Office_Abbey')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The third type: I call it a regular office type. The consumption performance of Ava, Allyson and Abbey all belong to this mode. The first peak occurs around 9:00, which is the prime time for work, and the second small peak will follow after sunset. All electricity consumption is concentrated in regular working hours (7:30-21:00). \n\nOffice Ava and Allyson do not seem to have a strict holiday concept, because the electricity consumption under different schedules is almost similar. Abbey is a little different from them. At least during Holiday, the employees seem to take a break because the overall electricity consumption is maintained at a very low level. If it were me, I might prefer to go to Abbey (LOL)."},{"metadata":{},"cell_type":"markdown","source":"After investigation, the Phoenix City of the United States is in the leading position in the field of solar energy and semiconductors in the United States. Perhaps future energy-saving projects can be combined with solar power for intelligent power control."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}