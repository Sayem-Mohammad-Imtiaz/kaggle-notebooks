{"cells":[{"metadata":{},"cell_type":"markdown","source":"This code is for Loan Prediction practice problem organized by Analytics Vidhya. Competition link is:\nhttps://datahack.analyticsvidhya.com/contest/practice-problem-loan-prediction-iii/#ProblemStatement"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have 3 files. Let's get them using pandas!"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df=pd.read_csv('/kaggle/input/loan-prediction-practice-av-competition/train_csv.csv')\ntest_df=pd.read_csv('/kaggle/input/loan-prediction-practice-av-competition/test.csv.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check their shapes."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_df.shape)\nprint(test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that their are 13 features each containing 614 training examples and 614 test examples. Let's analyze them."},{"metadata":{},"cell_type":"markdown","source":"<h1>Data Preprocessing and EDA</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For non-numerical features,\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe(include=['object'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's understand what we got from here one by one. <br>\n**Features** Gender(1),Married(2), Dependents(3), Education(4), Self_Employed(5), Property_Area(11), and Loan_Status(12) are object data type. <br>\n**Features** Gender(1), Married(2), Dependents(3), Self_Employed(5), LoanAmount(8), Loan_Amount_Term(9), Credit_History(10) have some of their data missing.<br>\nWe can also see that some of the features may be categorical."},{"metadata":{},"cell_type":"markdown","source":"Let's check the number of features containing NaN and number of unique values in each feature."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.isnull().sum(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that not only train but also some data is missing in case of test datasets."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Property_Area'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Categorical Data</h2>"},{"metadata":{},"cell_type":"markdown","source":"We can see that the  following features are categorical:\n* Gender\n* Married\n* Dependents\n* Education\n* Self_Employed\n* Credit_History\n* Property_Area\n<br>and, <br>\n* Loan_Status"},{"metadata":{},"cell_type":"markdown","source":"The most thing we can understand, even from the data description, that our target variable (Loan_Status) contains 2 possibility. Thus, it is a binary classification problem."},{"metadata":{},"cell_type":"markdown","source":"From the data description, as well as on checking some data, we can see that under what categories they are divided. Let's first set the target variable which either 'Yes' or 'No' to 1 or 0. "},{"metadata":{"trusted":true},"cell_type":"code","source":"target_map={\"Y\":1, \"N\": 0}\ndataset=[train_df]\nfor data in dataset:\n    data['Loan_Status']=data['Loan_Status'].map(target_map)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to map the rest of the categorical variables but this time to both training and test dataset. But before \ndoing it, we should fill the missing values with the mode of the corresponding features."},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols=['Gender','Married','Dependents','Self_Employed','Credit_History']\nfor col in cat_cols:\n    train_df[col].fillna(train_df[col].mode()[0],inplace=True)\n    test_df[col].fillna(test_df[col].mode()[0],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check if there are any missing values left for categorical features"},{"metadata":{},"cell_type":"markdown","source":"Now, all that is left is to convert the object categorical data to numeric form"},{"metadata":{"trusted":true},"cell_type":"code","source":"target=train_df['Loan_Status']\ntrain_df=train_df.drop('Loan_Status',1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gender_map={\"Male\": 1,\"Female\": 0}\nmarry_map={\"Yes\":1,\"No\":0}\neducation_map={\"Graduate\": 1,\"Not Graduate\":0}\nproperty_map={\"Semiurban\":2,\"Urban\":1,\"Rural\":0}\ndataset=[train_df]\nfor data in dataset:\n    data['Gender']=data['Gender'].map(gender_map)\n    data['Married']=data['Married'].map(marry_map)\n    data['Self_Employed']=data['Self_Employed'].map(marry_map)\n    data['Education']=data['Education'].map(education_map)\n    data['Property_Area']=data['Property_Area'].map(property_map)\n#dependents contains numeric value except 3+, so we just need to replace 3+ with 3 and then  convert their type to numeric\ntrain_df = train_df.replace({'Dependents': r'3+'}, {'Dependents': 3}, regex=True)\ntrain_df['Dependents']=train_df['Dependents'].astype('float64')\n#test_df = train_df.replace({'Dependents': r'3+'}, {'Dependents': 3},regex=True)\n#test_df['Dependents']=test_df['Dependents'].astype('float64')\ntrain_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gender_map={\"Male\": 1,\"Female\": 0}\nmarry_map={\"Yes\":1,\"No\":0}\neducation_map={\"Graduate\": 1,\"Not Graduate\":0}\nproperty_map={\"Semiurban\":2,\"Urban\":1,\"Rural\":0}\ndataset=[test_df]\nfor data in dataset:\n    data['Gender']=data['Gender'].map(gender_map)\n    data['Married']=data['Married'].map(marry_map)\n    data['Self_Employed']=data['Self_Employed'].map(marry_map)\n    data['Education']=data['Education'].map(education_map)\n    data['Property_Area']=data['Property_Area'].map(property_map)\n#dependents contains numeric value except 3+, so we just need to replace 3+ with 3 and then  convert their type to numeric\ntest_df = test_df.replace({'Dependents': r'3+'}, {'Dependents': 3},regex=True)\ntest_df['Dependents']=test_df['Dependents'].astype('float64')\ntest_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we have worked with our categorical data for both training and our test datasets"},{"metadata":{},"cell_type":"markdown","source":"Let's check if there are any missing data that is left"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Only LoanAmount and Loan_Amount_Term is left, let's see them."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Loan_Amount_Term'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that Loan_Amount_Term has majority of data containing value 360, so it would be better if we replace the missing values with 360(most frequent value)."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['LoanAmount'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"But we cannot say the same for LoanAmount data, so it's better to replace it's missing value with it's median."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Loan_Amount_Term'].fillna(360,inplace=True)\ntrain_df['LoanAmount'].fillna(train_df['LoanAmount'].median(),inplace=True)\ntrain_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that training set has now no missing values and that all features are numeric type( except Loan_ID, which I think, for now, provides less information)<br>\nLet's complete our test data too."},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['Loan_Amount_Term'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['LoanAmount'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well, like training set, we need to do the same in case of test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['Loan_Amount_Term'].fillna(360,inplace=True)\ntest_df['LoanAmount'].fillna(test_df['LoanAmount'].median(),inplace=True)\ntest_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, our test set is ready"},{"metadata":{},"cell_type":"markdown","source":"Let's see a correlation heatmap to visualize how are features correlated."},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inLine","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr=train_df.corr()\ncolormap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr,cmap=colormap,xticklabels=corr.columns,yticklabels=corr.columns,annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that features are not correlated to each other as much."},{"metadata":{},"cell_type":"markdown","source":"Before fitting the model, let's normalize the features of LoanAmount and Loan_Amount_term"},{"metadata":{"trusted":true},"cell_type":"code","source":"features=['Gender','Married','Dependents','Education','Self_Employed','ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term','Credit_History','Property_Area']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for fea in features:\n    print(train_df[fea].value_counts(sort=True))\n    print('---------------------------')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The features whose values are to be normalized are--"},{"metadata":{"trusted":true},"cell_type":"code","source":"fea_normalize=['Dependents','ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term','Property_Area']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for fea in fea_normalize:\n    train_df[fea]=(train_df[fea])/(train_df[fea].max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Base Model</h1>"},{"metadata":{},"cell_type":"markdown","source":"Since, it is a binary classification problem, we would be solving using Decision Tree Classifier and Logisitics Regression. Let's see one by one. But before, let's split our training data to training and validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df=train_df.drop('Loan_ID',1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train,y_val= train_test_split(train_df,target,test_size=0.30, random_state=np.random.randint(0,100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logitics Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr=LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=lr.predict(X_val)\nacc = metrics.accuracy_score(y_val,y_pred)\nprint(acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With Logistics Regression, the accuracy came to be 0.8108"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = GridSearchCV(LogisticRegression(penalty='l2'), param_grid)\nclf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_cv=clf.predict(X_val)\nacc = metrics.accuracy_score(y_val,y_pred_cv)\nprint(acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Decision Tree Classifier</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_base=DecisionTreeClassifier(max_depth=10,random_state=4)\ndt_base.fit(X_train,y_train)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The evaluation metric here is accuracy. So, let's check it's accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=dt_base.predict(X_val)\nacc = metrics.accuracy_score(y_val,y_pred)\nprint(acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that our base model is 72% accurate. "},{"metadata":{},"cell_type":"markdown","source":"<h3>HyperParameter Tuning</h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_base.tree_.node_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {\n    'max_depth' : range(4,25),\n    'min_samples_leaf' : range(20,200,10),\n    'min_samples_split' : range(20,200,10),\n    'criterion' : ['gini','entropy'] \n}\nn_folds = 5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are using GridSearchCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = DecisionTreeClassifier(random_state=np.random.randint(0,100))\ngrid = GridSearchCV(dt, param_grid, cv = n_folds, return_train_score=True,verbose=3)\n#grid.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's train our best model and find it's accuracy."},{"metadata":{"trusted":true},"cell_type":"code","source":"best_tree=DecisionTreeClassifier(criterion='gini',max_depth=4,min_samples_leaf=20,min_samples_split=80,random_state=np.random.randint(0,100))\nbest_tree.fit(X_train,y_train)\ny_pred_best=best_tree.predict(X_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = metrics.accuracy_score(y_val,y_pred)\nprint(acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our accuracy score is increased to 78.9%"},{"metadata":{},"cell_type":"markdown","source":"Let's predict the results for test file and store in csv file"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loanID=test_df['Loan_ID']\ntest_df=test_df.drop('Loan_ID',1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_t=lr.predict(test_df)\ny_final=[]\nfor y in y_pred_t:\n    if y==1:\n        y_final.append(\"Y\")\n    elif y==0:\n        y_final.append(\"N\")\ny_best=np.array(y_final)\ntype(y_best)\n      ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\n        \"Loan_ID\": loanID,\n        \"Loan_Status\": y_best\n    })\nsubmission.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission_lr.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}