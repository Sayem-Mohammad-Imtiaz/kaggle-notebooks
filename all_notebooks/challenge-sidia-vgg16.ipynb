{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# SIDIA Challenge Amazonas do Espa√ßo üåèüå≤üå≥\n## Autor: Douglas Queiroz G B.\n","metadata":{}},{"cell_type":"markdown","source":"### Objetivo do Challenge\n\nO desafio apresentado √© criar um modelo que rotule essas imagens com base nas condi√ß√µes atmosf√©ricas e no uso do solo, com o objetivo geral de rastrear a pegada de carbono humana na maior floresta tropical do mundo. Vod√™ pode encontrar a competi√ß√£o original [aqui](http://www.kaggle.com/c/planet-understanding-the-amazon-from-space).\n\n### Entendendo o Dataset\n\nA cada minuto, o mundo perde uma √°rea de floresta do tamanho de 48 campos de futebol. E o desmatamento na Bacia Amaz√¥nica √© respons√°vel pela maior parte, contribuindo para a redu√ß√£o da biodiversidade, perda de habitat, mudan√ßa clim√°tica e outros efeitos devastadores. Por√©m, dados melhores sobre a localiza√ß√£o do desmatamento e invas√£o humana nas florestas podem ajudar os governos e as partes interessadas locais a responder com mais rapidez e efic√°cia.\n\nOs chips para esta competi√ß√£o foram derivados dos produtos de cena anal√≠tica full-frame da Planet usando nossos sat√©lites de 4 bandas em √≥rbita sincronizada com o sol (SSO) e a √≥rbita da Esta√ß√£o Espacial Internacional (ISS).\n\nOs r√≥tulos podem ser amplamente divididos em tr√™s grupos: **_condi√ß√µes atmosf√©ricas, fen√¥menos comuns de uso do solo / cobertura do solo e fen√¥menos raros de uso do solo / cobertura do solo_**. Cada chip ter√° um e potencialmente mais de um r√≥tulo atmosf√©rico e zero ou mais r√≥tulos comuns e raros. **Chips rotulados como turvos n√£o devem ter outros r√≥tulos, mas pode haver erros de rotulagem.**\n\nAs nuvens s√£o um grande desafio para imagens passivas de sat√©lite, e a cobertura de nuvens e pancadas de chuva di√°rias na bacia amaz√¥nica podem complicar significativamente o monitoramento na √°rea. Por esse motivo, optamos por incluir uma etiqueta de cobertura de nuvens para cada chip. Esses r√≥tulos refletem de perto o que se veria em uma previs√£o do tempo local: claro, parcialmente nublado, nublado e neblina.\n\nNota lateral: Os r√≥tulos comuns neste conjunto de dados s√£o floresta tropical, agricultura, rios, vilas/cidades e estradas.\n\n### Estrutura Dataset\n\nQuadrados de imagens de alta resolu√ß√£o (256 x 256) em quatro bandas (RGB + IR) do Planet Flock 2 Satellites. Cada bloco pode ter v√°rios r√≥tulos (comuns e menos comuns), mas apenas um dos r√≥tulos de cobertura de nuvem.\n\nR√≥tulos comuns | R√≥tulos menos comuns | Cloud Cover Labels\n------------ | ------------- | -------------\nPrimary Rain Forest | Slash and Burn | Clear\nWater (Rivers & Lakes) | Selective Logging | Partly cloudy\nHabitation | Blooming | Cloudy\nAgriculture | Conventional Mining | Haze\nRoad | Artisinal Mining |\nCultivation | Blow Down |\nBare Ground | |\n\n### File formats\n\nEste √© um conjunto de dados de competi√ß√£o que foi contribu√≠do pela Planet. O conjunto de dados cont√©m arquivos csv de treinamento e imagens de treinamento / teste de chips de imagem de sat√©lite da floresta amaz√¥nica.\n\n- **rain.csv** - a list of training file names and their labels, the labels are space-delimited\n- **sample_submission.csv** - correct format of submission, contains all the files in the test set. For more information about the submission file, please go to the Evaluation page.\n- **[train/test]-tif-v2.tar.7z** - tif files for the training/test set (updated: May 5th, 2017)\n- **[train/test]-jpg[-additional].tar.7z** - jpg files for the trainin/test set (updated: May 5th, 2017)\n- **Kaggle-planet-[train/test]-tif.torrent** - a BitTorrent file for downloading [train/test]-tif-v2.tar.7z \n\n","metadata":{}},{"cell_type":"markdown","source":"## Arquiteturas Implementadas\n\n### VGG-16 \n\nA rede VGG √© uma rede neural convolucional inventada por [Simonyan e Zisserman do Visual Geometry Group (VGG)](https://www.robots.ox.ac.uk/~vgg/research/very_deep/) da University of Oxford em 2014. Tornou-se mais versada na comunidade de vis√£o computacional ap√≥s ser nomeada vice-campe√£ da tarefa de classifica√ß√£o ILSVRC de 2014 . √â frequentemente associado ao VGG-19, com a diferen√ßa de que o VGG-16 tem 16 camadas com pesos trein√°veis em vez de 19, da√≠ o nome. ","metadata":{}},{"cell_type":"code","source":"# Executando jupyter com acesso root caso vc este encontrando dificuldade em instalar as depend√™ncias\n# sudo -E env \"PATH=$PATH\" jupyter notebook --allow-root","metadata":{"execution":{"iopub.status.busy":"2021-07-26T17:50:53.252989Z","iopub.execute_input":"2021-07-26T17:50:53.253318Z","iopub.status.idle":"2021-07-26T17:50:53.258198Z","shell.execute_reply.started":"2021-07-26T17:50:53.253244Z","shell.execute_reply":"2021-07-26T17:50:53.256694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Importando e baixando bibliotecas necess√°ris","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport pathlib\nimport numpy as np \nimport pandas as pd \nfrom tqdm import tqdm\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom keras import models\nfrom keras.models import Sequential\nfrom keras.applications.vgg16 import VGG16\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import fbeta_score\nfrom sklearn.model_selection import train_test_split \n\nimport cv2\n%matplotlib inline\nimport matplotlib.pyplot as plt\n","metadata":{"execution":{"iopub.status.busy":"2021-07-26T17:50:53.280303Z","iopub.execute_input":"2021-07-26T17:50:53.280545Z","iopub.status.idle":"2021-07-26T17:50:58.498166Z","shell.execute_reply.started":"2021-07-26T17:50:53.280522Z","shell.execute_reply":"2021-07-26T17:50:58.497316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if tf.test.gpu_device_name():\n    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\nelse:\n    print(\"Please install GPU version of TF\")","metadata":{"execution":{"iopub.status.busy":"2021-07-26T17:50:58.49957Z","iopub.execute_input":"2021-07-26T17:50:58.499879Z","iopub.status.idle":"2021-07-26T17:51:00.169533Z","shell.execute_reply.started":"2021-07-26T17:50:58.499845Z","shell.execute_reply":"2021-07-26T17:51:00.168275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Baixando e extraindo Dataset","metadata":{}},{"cell_type":"markdown","source":"O dataset j√° existe no kaggle","metadata":{}},{"cell_type":"markdown","source":"# Pr√© Procesamento","metadata":{}},{"cell_type":"markdown","source":"### Data Visualization + Exploration","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/planets-dataset/planet/planet/train_classes.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/planets-dataset/planet/planet/sample_submission.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2021-07-26T17:51:00.171699Z","iopub.execute_input":"2021-07-26T17:51:00.172217Z","iopub.status.idle":"2021-07-26T17:51:00.303712Z","shell.execute_reply.started":"2021-07-26T17:51:00.172161Z","shell.execute_reply":"2021-07-26T17:51:00.302823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_classes = train_df[:]['tags']\n\nno_classes = len(train_classes.unique())\nprint(f'Given {len(train_classes)} samples, there are {no_classes} unique classes.', '\\n')\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T17:51:00.305383Z","iopub.execute_input":"2021-07-26T17:51:00.305749Z","iopub.status.idle":"2021-07-26T17:51:00.33763Z","shell.execute_reply.started":"2021-07-26T17:51:00.30571Z","shell.execute_reply":"2021-07-26T17:51:00.336671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalizando nomes das tags\nflatten = lambda l: [item for sublist in l for item in sublist]\nlabels = list(set(flatten([l.split(' ') for l in train_df['tags'].values])))\n\n# Criando uma cole√ß√£o key, value para categorizar de forma numerica nossos labels\nlabel_map = {l: i for i, l in enumerate(labels)}\nprint(f'labels = {labels},\\n length = {len(labels)}', '\\n')\n\nprint(f'label_map = {label_map},\\n length = {len(label_map)}')","metadata":{"execution":{"iopub.status.busy":"2021-07-26T17:51:00.33915Z","iopub.execute_input":"2021-07-26T17:51:00.339528Z","iopub.status.idle":"2021-07-26T17:51:00.528504Z","shell.execute_reply.started":"2021-07-26T17:51:00.339492Z","shell.execute_reply":"2021-07-26T17:51:00.527489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A maioria das imagens tem dois r√≥tulos, tr√™s e quatro r√≥tulos s√£o bastante iguais em n√∫mero e um, cinco, e seis r√≥tulos n√£o aparecem com muita frequ√™ncia. Imagens que podem ser classificadas sob sete, oito ou nove r√≥tulos raramente aparecem no conjunto de dados. Interessante; h√° um grande desequil√≠brio aqui.\n\nSeguindo em frente, √© uma boa ideia visualizar algumas das imagens para obter uma vis√£o de como esses r√≥tulos devem ser:","metadata":{}},{"cell_type":"code","source":"\nnew_style = {'grid': False}\nplt.rc('axes', **new_style)\n_, ax = plt.subplots(3, 3, sharex='col', sharey='row', figsize=(15, 15))\ni = 0\nfor f, tags in train_df[:9].values:\n    img = cv2.imread('/kaggle/input/planets-dataset/planet/planet/train-jpg/{}.jpg'.format(f))\n    ax[i // 3, i % 3].imshow(img)\n    ax[i // 3, i % 3].set_title('{} - {}'.format(f, tags))\n  \n    i += 1\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T17:51:00.530002Z","iopub.execute_input":"2021-07-26T17:51:00.530378Z","iopub.status.idle":"2021-07-26T17:51:01.866195Z","shell.execute_reply.started":"2021-07-26T17:51:00.530338Z","shell.execute_reply":"2021-07-26T17:51:01.865143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the train-jpg file path\n\ntrain_img_dir = pathlib.Path('/kaggle/input/planets-dataset/planet/planet/train-jpg')\ntest_img_dir = pathlib.Path('/kaggle/input/planets-dataset/planet/planet/test-jpg')\ntest_add_img_dir = pathlib.Path('/kaggle/input/planets-dataset/test-jpg-additional/test-jpg-additional')\n\ntrain_img_path = sorted(list(train_img_dir.glob('*.jpg')))\n\ntrain_img_count = len(train_img_path)\nprint('Quantidade de imgs chips para treino: ',str(train_img_count))","metadata":{"execution":{"iopub.status.busy":"2021-07-26T17:51:01.86736Z","iopub.execute_input":"2021-07-26T17:51:01.867661Z","iopub.status.idle":"2021-07-26T17:51:03.088656Z","shell.execute_reply.started":"2021-07-26T17:51:01.86763Z","shell.execute_reply":"2021-07-26T17:51:03.087636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# first test jpg file path\n\ntest_img_path = sorted(list(test_img_dir.glob('*.jpg')))\n\ntest_img_count = len(test_img_path)\nprint('Quantidade de imgs chips para testes: ',str(test_img_count))","metadata":{"execution":{"iopub.status.busy":"2021-07-26T17:51:03.091514Z","iopub.execute_input":"2021-07-26T17:51:03.09207Z","iopub.status.idle":"2021-07-26T17:51:04.171701Z","shell.execute_reply.started":"2021-07-26T17:51:03.092028Z","shell.execute_reply":"2021-07-26T17:51:04.170814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# second test jpg file path\n\ntest_add_img_path = sorted(list(test_add_img_dir.glob('*.jpg')))\n\ntest_add_img_count = len(test_add_img_path)\nprint('Quantidade de imgs chips para testes adicional: ',str(test_add_img_count))","metadata":{"execution":{"iopub.status.busy":"2021-07-26T17:51:04.173851Z","iopub.execute_input":"2021-07-26T17:51:04.174263Z","iopub.status.idle":"2021-07-26T17:51:04.933043Z","shell.execute_reply.started":"2021-07-26T17:51:04.174218Z","shell.execute_reply":"2021-07-26T17:51:04.931959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# verifica se o n√∫mero de imagens jpg seja igual ao n√∫mero de amostras no arquivo csv para cada conjunto de dados\n\n# train\nif len(train_img_path) == len(train_df):\n    print('Dataset de treino com a mesma quantidade de samples listada no csv')\n#caso n√£o seja igual a execu√ß√£o para aqui\nassert len(train_img_path) == len(train_df) \n\n\n# test\nif len(test_img_path)+len(test_add_img_path) == len(test_df):\n    print('Dataset de testes com a mesma quantidade de samples listada no csv')\n#caso n√£o seja igual a execu√ß√£o para aqui\nassert len(test_img_path)+len(test_add_img_path) == len(test_df)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T17:51:04.934778Z","iopub.execute_input":"2021-07-26T17:51:04.935167Z","iopub.status.idle":"2021-07-26T17:51:04.941525Z","shell.execute_reply.started":"2021-07-26T17:51:04.935123Z","shell.execute_reply":"2021-07-26T17:51:04.940694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Preprocessing","metadata":{}},{"cell_type":"code","source":"input_size = 64\ninput_channels = 3\n\nbatch_size = 64","metadata":{"execution":{"iopub.status.busy":"2021-07-26T17:51:04.942742Z","iopub.execute_input":"2021-07-26T17:51:04.943267Z","iopub.status.idle":"2021-07-26T17:51:04.951529Z","shell.execute_reply.started":"2021-07-26T17:51:04.943228Z","shell.execute_reply":"2021-07-26T17:51:04.950705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = []\ny_train = []\n\nfor f, tags in tqdm(train_df.values, miniters=1000):\n    img = cv2.imread('../input/planets-dataset/planet/planet/train-jpg/{}.jpg'.format(f))\n    img = cv2.resize(img, (input_size, input_size))\n    targets = np.zeros(17)\n    for t in tags.split(' '):\n        targets[label_map[t]] = 1\n    x_train.append(img)\n    y_train.append(targets)\n        \nx_train = np.array(x_train, np.float32)\ny_train = np.array(y_train, np.uint8)\n\nprint(x_train.shape)\nprint(y_train.shape)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-26T17:51:04.954067Z","iopub.execute_input":"2021-07-26T17:51:04.954615Z","iopub.status.idle":"2021-07-26T17:54:36.006654Z","shell.execute_reply.started":"2021-07-26T17:51:04.954577Z","shell.execute_reply":"2021-07-26T17:54:36.005577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test = []\n\ntest_image_names = os.listdir(test_img_dir)\n\nn_test = len(test_image_names)\ntest_classes = test_df.iloc[:n_test, :]\nadd_classes = test_df.iloc[n_test:, :]\n\ntest_add_image_names = os.listdir(test_add_img_dir)\n\nfor img_name, _ in tqdm(test_classes.values, miniters=1000):\n    img = cv2.imread(str(test_img_dir) + '/{}.jpg'.format(img_name))\n    x_test.append(cv2.resize(img, (64, 64)))\n    \nfor img_name, _ in tqdm(add_classes.values, miniters=1000):\n    img = cv2.imread(str(test_add_img_dir) + '/{}.jpg'.format(img_name))\n    x_test.append(cv2.resize(img, (64, 64)))\n\nx_test = np.array(x_test, np.float32)\nprint(x_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T17:54:36.0081Z","iopub.execute_input":"2021-07-26T17:54:36.008516Z","iopub.status.idle":"2021-07-26T17:59:59.790079Z","shell.execute_reply.started":"2021-07-26T17:54:36.008473Z","shell.execute_reply":"2021-07-26T17:59:59.788794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_valid, Y_train, Y_valid = train_test_split(x_train, y_train, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T17:59:59.791912Z","iopub.execute_input":"2021-07-26T17:59:59.792317Z","iopub.status.idle":"2021-07-26T18:00:00.380265Z","shell.execute_reply.started":"2021-07-26T17:59:59.792276Z","shell.execute_reply":"2021-07-26T18:00:00.379272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Construindo o modelo","metadata":{}},{"cell_type":"code","source":"base_model = VGG16(include_top=False,\n                   weights='imagenet',\n                   input_shape=(input_size, input_size, input_channels))\n\nmodel = Sequential()\nmodel.add(BatchNormalization(input_shape=(input_size, input_size, input_channels)))\n\nmodel.add(base_model)\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(17, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2021-07-26T18:00:00.381561Z","iopub.execute_input":"2021-07-26T18:00:00.381955Z","iopub.status.idle":"2021-07-26T18:00:01.727176Z","shell.execute_reply.started":"2021-07-26T18:00:00.38191Z","shell.execute_reply":"2021-07-26T18:00:01.726318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel.compile(loss='binary_crossentropy',optimizer=\"SGD\", metrics=['accuracy'])\n    \ncallbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0),\n                ModelCheckpoint(filepath='weights/best_weights',\n                                 save_best_only=True,\n                                 save_weights_only=True)]\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T18:00:01.728428Z","iopub.execute_input":"2021-07-26T18:00:01.728765Z","iopub.status.idle":"2021-07-26T18:00:01.748878Z","shell.execute_reply.started":"2021-07-26T18:00:01.72873Z","shell.execute_reply":"2021-07-26T18:00:01.747894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x=X_train, y=Y_train, validation_data=(X_valid, Y_valid),\n                  batch_size=batch_size,verbose=2, epochs=15,callbacks=callbacks,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T18:00:01.750052Z","iopub.execute_input":"2021-07-26T18:00:01.750582Z","iopub.status.idle":"2021-07-26T18:03:58.051661Z","shell.execute_reply.started":"2021-07-26T18:00:01.750544Z","shell.execute_reply":"2021-07-26T18:03:58.050778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('./models/vgg16-amazon2')","metadata":{"execution":{"iopub.status.busy":"2021-07-26T18:03:58.053478Z","iopub.execute_input":"2021-07-26T18:03:58.05384Z","iopub.status.idle":"2021-07-26T18:04:00.999463Z","shell.execute_reply.started":"2021-07-26T18:03:58.053798Z","shell.execute_reply":"2021-07-26T18:04:00.998548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_back = models.load_model(\"./models/vgg16-amazon2\")","metadata":{"execution":{"iopub.status.busy":"2021-07-26T18:04:01.005034Z","iopub.execute_input":"2021-07-26T18:04:01.005319Z","iopub.status.idle":"2021-07-26T18:04:02.407596Z","shell.execute_reply.started":"2021-07-26T18:04:01.005291Z","shell.execute_reply":"2021-07-26T18:04:02.406753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_valid = model_back.predict(X_valid, batch_size = batch_size, verbose=1)\n\nprint('Acur√°cia: ',fbeta_score(Y_valid, np.array(p_valid) > 0.18, beta=2, average='samples'))","metadata":{"execution":{"iopub.status.busy":"2021-07-26T18:04:02.409656Z","iopub.execute_input":"2021-07-26T18:04:02.410002Z","iopub.status.idle":"2021-07-26T18:04:04.544789Z","shell.execute_reply.started":"2021-07-26T18:04:02.409966Z","shell.execute_reply":"2021-07-26T18:04:04.543992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T18:04:04.546002Z","iopub.execute_input":"2021-07-26T18:04:04.546354Z","iopub.status.idle":"2021-07-26T18:04:04.677132Z","shell.execute_reply.started":"2021-07-26T18:04:04.546317Z","shell.execute_reply":"2021-07-26T18:04:04.676336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = []\np_test = model_back.predict(x_test, batch_size=batch_size, verbose=2)\ny_pred.append(p_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T18:04:04.678333Z","iopub.execute_input":"2021-07-26T18:04:04.678681Z","iopub.status.idle":"2021-07-26T18:04:18.898005Z","shell.execute_reply.started":"2021-07-26T18:04:04.678645Z","shell.execute_reply":"2021-07-26T18:04:18.897133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = np.array(y_pred[0])\nfor i in range(1, len(y_pred)):\n    result += np.array(y_pred[i])\nresult = pd.DataFrame(result, columns=labels)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T18:04:18.902963Z","iopub.execute_input":"2021-07-26T18:04:18.903243Z","iopub.status.idle":"2021-07-26T18:04:18.915218Z","shell.execute_reply.started":"2021-07-26T18:04:18.903215Z","shell.execute_reply":"2021-07-26T18:04:18.914272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Translating the probability predictions to the unique labels\npreds = []\nfor i in tqdm(range(result.shape[0]), miniters=1000):\n    a = result.loc[[i]]\n    a = a.apply(lambda x: x>0.2, axis=1)\n    a = a.transpose()\n    a = a.loc[a[i] == True]\n    ' '.join(list(a.index))\n    preds.append(' '.join(list(a.index)))","metadata":{"execution":{"iopub.status.busy":"2021-07-26T18:04:18.91686Z","iopub.execute_input":"2021-07-26T18:04:18.917469Z","iopub.status.idle":"2021-07-26T18:06:33.940846Z","shell.execute_reply.started":"2021-07-26T18:04:18.917431Z","shell.execute_reply":"2021-07-26T18:06:33.940047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replacing the tags columns with the predicted labels\ntest_df['tags'] = preds\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T18:06:33.943615Z","iopub.execute_input":"2021-07-26T18:06:33.943881Z","iopub.status.idle":"2021-07-26T18:06:33.9734Z","shell.execute_reply.started":"2021-07-26T18:06:33.943852Z","shell.execute_reply":"2021-07-26T18:06:33.972193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting the dataframe to a csv file for submission\ntest_df.to_csv('sample_testes_results.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T18:07:18.685945Z","iopub.execute_input":"2021-07-26T18:07:18.6863Z","iopub.status.idle":"2021-07-26T18:07:18.874191Z","shell.execute_reply.started":"2021-07-26T18:07:18.686266Z","shell.execute_reply":"2021-07-26T18:07:18.873184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclus√£o\n\nO modelo proposto obteve uma acur√°cia de 91%, o mesmo conseguiu rotular de forma satisfat√≥ria os chips do dataset de testes. Foi observado que itera√ß√µes acima de 15 passos ocasionava overfit e come√ßava a convergir. Vale ressaltar que a acur√°cia obtida foi relativamente boa, levando em considera√ß√£o que foi utilizado chips/imagens JPG com baixa qualidade, n√£o foi poss√≠vel utilizar os datastes com imagens TIF com maior qualidade, pois o Hardware usado n√£o suportou todo o processamento. ","metadata":{}}]}