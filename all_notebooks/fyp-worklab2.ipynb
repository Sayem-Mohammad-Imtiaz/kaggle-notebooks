{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-25T08:34:03.276237Z","iopub.execute_input":"2021-05-25T08:34:03.276548Z","iopub.status.idle":"2021-05-25T08:34:03.304469Z","shell.execute_reply.started":"2021-05-25T08:34:03.276514Z","shell.execute_reply":"2021-05-25T08:34:03.303623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom keras.preprocessing import text\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nimport re\nimport datetime\nfrom sklearn import metrics\n!pip install tensorflow_text==2.4.3\nimport tensorflow_text as text","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:34:03.307333Z","iopub.execute_input":"2021-05-25T08:34:03.30759Z","iopub.status.idle":"2021-05-25T08:34:10.362182Z","shell.execute_reply.started":"2021-05-25T08:34:03.307564Z","shell.execute_reply":"2021-05-25T08:34:10.361137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\n\n# plotting\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# read data\ndf = pd.read_csv('../input/mbti-type/mbti_1.csv') ","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:34:10.364136Z","iopub.execute_input":"2021-05-25T08:34:10.364545Z","iopub.status.idle":"2021-05-25T08:34:12.263581Z","shell.execute_reply.started":"2021-05-25T08:34:10.364499Z","shell.execute_reply":"2021-05-25T08:34:12.262507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_types(row):\n    t=row['type']\n\n    I = 0; N = 0\n    T = 0; J = 0\n    \n    if t[0] == 'I': I = 1\n    elif t[0] == 'E': I = 0\n    else: print('I-E incorrect')\n        \n    if t[1] == 'N': N = 1\n    elif t[1] == 'S': N = 0\n    else: print('N-S incorrect')\n        \n    if t[2] == 'T': T = 1\n    elif t[2] == 'F': T = 0\n    else: print('T-F incorrect')\n        \n    if t[3] == 'J': J = 1\n    elif t[3] == 'P': J = 0\n    else: print('J-P incorrect')\n    return pd.Series( {'IE':I, 'NS':N , 'TF': T, 'JP': J }) \n\ndf = df.join(df.apply (lambda row: get_types (row),axis=1))\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:34:12.26479Z","iopub.execute_input":"2021-05-25T08:34:12.265146Z","iopub.status.idle":"2021-05-25T08:34:15.22716Z","shell.execute_reply.started":"2021-05-25T08:34:12.265107Z","shell.execute_reply":"2021-05-25T08:34:15.226322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#转换成00001111\nb_Pers = {'I':0, 'E':1, 'N':0, 'S':1, 'F':0, 'T':1, 'J':0, 'P':1}\nb_Pers_list = [{0:'I', 1:'E'}, {0:'N', 1:'S'}, {0:'F', 1:'T'}, {0:'J', 1:'P'}]\n\ndef translate_personality(personality):\n    # transform mbti to binary vector\n    \n    return [b_Pers[l] for l in personality]\n\ndef translate_back(personality):\n    # transform binary vector to mbti personality\n    \n    s = \"\"\n    for i, l in enumerate(personality):\n        s += b_Pers_list[i][l]\n    return s\n\n# Check ...\nd = df.head(4)\nlist_personality_bin = np.array([translate_personality(p) for p in d.type])\nprint(\"Binarize MBTI list: \\n%s\" % list_personality_bin)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:34:15.229726Z","iopub.execute_input":"2021-05-25T08:34:15.230254Z","iopub.status.idle":"2021-05-25T08:34:15.238741Z","shell.execute_reply.started":"2021-05-25T08:34:15.230216Z","shell.execute_reply":"2021-05-25T08:34:15.237814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##### Compute list of subject with Type | list of comments \nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nfrom nltk.corpus import stopwords \nfrom nltk import word_tokenize\n\n# We want to remove these from the psosts\nunique_type_list = ['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP',\n       'ISFP', 'ISTP', 'ISFJ', 'ISTJ', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ']\n  \n\n\n\n# Lemmatize\nstemmer = PorterStemmer()\nlemmatiser = WordNetLemmatizer()\n\n# Cache the stop words for speed \ncachedStopWords = stopwords.words(\"english\")\n\ndef pre_process_data1(data, remove_stop_words=True, remove_mbti_profiles=True):\n\n    list_personality = []\n    list_posts = []\n    len_data = len(data)\n    i=0\n    \n    for row in data.iterrows():\n        i+=1\n        if (i % 500 == 0 or i == 1 or i == len_data):\n            print(\"%s of %s rows\" % (i, len_data))\n\n        ##### Remove and clean comments\n        posts = row[1].posts\n        temp = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', posts)\n        temp = re.sub(\"[^a-zA-Z]\", \" \", temp)\n        temp = re.sub(' +', ' ', temp).lower()\n        if remove_stop_words:\n            temp = \" \".join([lemmatiser.lemmatize(w) for w in temp.split(' ') if w not in cachedStopWords])\n        else:\n            temp = \" \".join([lemmatiser.lemmatize(w) for w in temp.split(' ')])\n            \n        if remove_mbti_profiles:\n            for t in unique_type_list:\n                temp = temp.replace(t,\"\")\n\n        type_labelized = translate_personality(row[1].type)\n        list_personality.append(type_labelized)\n        list_posts.append(temp)\n\n    list_posts = np.array(list_posts)\n    list_personality = np.array(list_personality)\n    return list_posts, list_personality","metadata":{"execution":{"iopub.status.busy":"2021-05-24T13:32:52.156315Z","iopub.execute_input":"2021-05-24T13:32:52.156896Z","iopub.status.idle":"2021-05-24T13:32:52.183205Z","shell.execute_reply.started":"2021-05-24T13:32:52.156858Z","shell.execute_reply":"2021-05-24T13:32:52.182476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_posts2, list_personality2  = pre_process_data1(df, remove_stop_words=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T13:32:52.184337Z","iopub.execute_input":"2021-05-24T13:32:52.18484Z","iopub.status.idle":"2021-05-24T13:33:44.221401Z","shell.execute_reply.started":"2021-05-24T13:32:52.184803Z","shell.execute_reply":"2021-05-24T13:33:44.220372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.manifold import TSNE\n\n# Posts to a matrix of token counts\ncntizer = CountVectorizer(analyzer=\"word\", \n                             max_features=1500, \n                             tokenizer=None,    \n                             preprocessor=None, \n                             stop_words=None,  \n                             max_df=0.7,\n                             min_df=0.1) \n#max_df :ignore terms that have a document frequency strictly higher \n\n# Learn the vocabulary dictionary and return term-document matrix\nprint(\"CountVectorizer...\")\nX_cnt = cntizer.fit_transform(list_posts2)\n\n# Transform the count matrix to a normalized tf or tf-idf representation\ntfizer = TfidfTransformer()\n\nprint(\"Tf-idf...\")\n# Learn the idf vector (fit) and transform a count matrix to a tf-idf representation\nX_tfidf =  tfizer.fit_transform(X_cnt).toarray()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T13:33:44.222803Z","iopub.execute_input":"2021-05-24T13:33:44.223299Z","iopub.status.idle":"2021-05-24T13:33:49.841097Z","shell.execute_reply.started":"2021-05-24T13:33:44.223259Z","shell.execute_reply":"2021-05-24T13:33:49.840168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ntype_indicators = [ \"IE: Introversion (I) / Extroversion (E)\", \"NS: Intuition (N) – Sensing (S)\", \n                   \"FT: Feeling (F) - Thinking (T)\", \"JP: Judging (J) – Perceiving (P)\"  ]\n\nfor l in range(len(type_indicators)):\n    print(type_indicators[l])\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:40:23.436281Z","iopub.execute_input":"2021-05-25T08:40:23.436651Z","iopub.status.idle":"2021-05-25T08:40:23.442508Z","shell.execute_reply.started":"2021-05-25T08:40:23.43662Z","shell.execute_reply":"2021-05-25T08:40:23.441336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numpy import loadtxt\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Posts in tf-idf representation\nX = X_tfidf\nparam = {}\nparam['n_estimators'] = 1000\nparam['max_depth'] = 2\nparam['learning_rate'] = 0.2\n\n\n# Let's train type indicator individually\n\nstarttime = datetime.datetime.now()\n#long running\n\nfor l in range(len(type_indicators)):\n    print(\"%s ...\" % (type_indicators[l]))\n    \n    \n    # Let's train type indicator individually\n    Y = list_personality2[:,l]\n\n    # split data into train and test sets\n    seed = 7\n    test_size = 0.33\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n\n    # fit model on training data\n    model = XGBClassifier(eval_metric=\"auc\",use_label_encoder=False,**param)\n    model.fit(X_train, y_train)\n\n    # make predictions for test data\n    y_pred = model.predict(X_test)\n    predictions = [round(value) for value in y_pred]\n    # evaluate predictions\n    accuracy = accuracy_score(y_test, predictions)\n    roc = metrics.roc_auc_score(y_test, predictions)\n    print(\"* %s Accuracy: %.2f%%\" % (type_indicators[l], accuracy * 100.0))\n    print(\"* %s roc: %.2f%%\" % (type_indicators[l], roc * 100.0))\nendtime = datetime.datetime.now()\nprint (endtime - starttime)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T14:05:50.875982Z","iopub.execute_input":"2021-05-24T14:05:50.876458Z","iopub.status.idle":"2021-05-24T14:07:26.492558Z","shell.execute_reply.started":"2021-05-24T14:05:50.876414Z","shell.execute_reply":"2021-05-24T14:07:26.490285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nfrom numpy import loadtxt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics\nimport joblib \nmodel_lgbm = lgb.LGBMClassifier(objective='binary', metric = 'auc',\n\nlearning_rate=0.2, n_estimators=1000, max_depth=2, is_unbalance=True,verbosity=-1)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T14:04:50.979775Z","iopub.execute_input":"2021-05-24T14:04:50.980091Z","iopub.status.idle":"2021-05-24T14:04:50.98468Z","shell.execute_reply.started":"2021-05-24T14:04:50.980063Z","shell.execute_reply":"2021-05-24T14:04:50.983874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nfrom numpy import loadtxt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics\n\nstarttime = datetime.datetime.now()\nlgb_predict_result = []\nlgb_predict_test = []\ntype_ORDER = [\"IE\",\"NS\",\"FT\",\"JP\"]\nfor l in range(len(type_indicators)):\n    print(\"%s ...\" % (type_indicators[l]))\n    \n    \n    # Let's train type indicator individually\n    Y = list_personality2[:,l]\n    modeltype = \"TF-IDF\"\n    modelOrder = modeltype+type_ORDER[l]+\".pkl\"\n    print(modelOrder)\n    \n\n    # split data into train and test sets\n    seed = 7\n    test_size = 0.33\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n    X_train2, X_test2, y_train2, y_test2 = train_test_split(X, Y, test_size=test_size, random_state=42)\n    #lgb_train = lgb.Dataset(X_train, y_train, free_raw_data=False)\n    #lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train,free_raw_data=False)\n    \n    \n    # fit model on training data\n    evals_result = {}\n    \n    #LGBModel = lgb.train(LGBMparams2, lgb_train, 50000, \n    #                      valid_sets=[lgb_train, lgb_eval], \n    #                      early_stopping_rounds=100, \n    #                      verbose_eval=500, \n    #                      evals_result=evals_result)\n    \n    LGBModel = model_lgbm\n    LGBModel.fit(X_train, y_train,eval_set=(X_test2, y_test2),eval_metric = 'auc',early_stopping_rounds = 100, verbose = 1000)\n    \n    joblib.dump(LGBModel, modelOrder)\n\n    # make predictions for test data\n    \n    starttime2 = datetime.datetime.now()\n    y_pred = LGBModel.predict(X_test, num_iteration=LGBModel.best_iteration_)\n    endtime2 = datetime.datetime.now()\n    \n    print (endtime2 - starttime2)\n    \n    lgb_predict_result.append(y_pred)\n    lgb_predict_test.append(y_test)\n    predictions = [round(value) for value in y_pred]\n    # evaluate predictions\n    accuracy = accuracy_score(y_test, predictions)\n    roc = metrics.roc_auc_score(y_test, predictions)\n    print(\"* %s Accuracy: %.2f%%\" % (type_indicators[l], accuracy * 100.0))\n    print(\"* %s roc: %.2f%%\" % (type_indicators[l], roc * 100.0))\n    \nendtime = datetime.datetime.now()\nprint (endtime - starttime)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T14:04:53.528482Z","iopub.execute_input":"2021-05-24T14:04:53.528843Z","iopub.status.idle":"2021-05-24T14:05:22.929203Z","shell.execute_reply.started":"2021-05-24T14:04:53.528812Z","shell.execute_reply":"2021-05-24T14:05:22.928456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* IE: Introversion (I) / Extroversion (E) Accuracy: 86.45%\n* IE: Introversion (I) / Extroversion (E) roc: 75.83%\n\n* NS: Intuition (N) – Sensing (S) Accuracy: 89.77%\n* NS: Intuition (N) – Sensing (S) roc: 69.13%\n\n* FT: Feeling (F) - Thinking (T) Accuracy: 84.88%\n* FT: Feeling (F) - Thinking (T) roc: 84.79%\n\n* JP: Judging (J) – Perceiving (P) Accuracy: 80.79%\n* JP: Judging (J) – Perceiving (P) roc: 78.98%\n\n* 0:01:21.022334","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostClassifier\nimport lightgbm as lgb\nfrom numpy import loadtxt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics\nX = X_tfidf\n\ncat_params = {\n                'eval_metric':'AUC',\n                'task_type':'GPU',\n                'random_seed':42,\n                'learning_rate':0.2,\n                'depth':2\n                #'colsample_bylevel':0.7,\n                } \npredict_result = []\npredict_test = []\nstarttime = datetime.datetime.now()\n\nfor l in range(len(type_indicators)):\n    print(\"%s ...\" % (type_indicators[l]))\n    \n    \n    # Let's train type indicator individually\n    Y = list_personality2[:,l]\n    \n    \n    \n\n    # split data into train and test sets\n    seed = 7\n    test_size = 0.33\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n    \n    # fit model on training data\n    cb_model = CatBoostClassifier(**cat_params)\n    cb_model.fit(X_train, y_train,\n             eval_set=(X_test, y_test),\n             use_best_model=True,\n             verbose=200,\n                plot=True)\n    \n\n    # make predictions for test data\n    y_pred = cb_model.predict(X_test)\n    predict_result.append(y_pred)\n    predict_test.append(y_test)\n    predictions = [round(value) for value in y_pred]\n    # evaluate predictions\n    accuracy = accuracy_score(y_test, predictions)\n    roc = metrics.roc_auc_score(y_test, predictions)\n    print(\"* %s Accuracy: %.2f%%\" % (type_indicators[l], accuracy * 100.0))\n    print(\"* %s roc: %.2f%%\" % (type_indicators[l], roc * 100.0))\nendtime = datetime.datetime.now()\nprint (endtime - starttime)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T14:07:39.025954Z","iopub.execute_input":"2021-05-24T14:07:39.02628Z","iopub.status.idle":"2021-05-24T14:09:38.865485Z","shell.execute_reply.started":"2021-05-24T14:07:39.026251Z","shell.execute_reply":"2021-05-24T14:09:38.864249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n!pip install tensorflow_text==2.4.3\nimport tensorflow_text as text","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:34:15.240706Z","iopub.execute_input":"2021-05-25T08:34:15.24132Z","iopub.status.idle":"2021-05-25T08:34:21.142102Z","shell.execute_reply.started":"2021-05-25T08:34:15.241278Z","shell.execute_reply":"2021-05-25T08:34:21.141115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def creatmodel():\n\n    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n    preprocessor = hub.KerasLayer(\n        \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n    encoder_inputs = preprocessor(text_input)\n    encoder = hub.KerasLayer(\n        \"https://tfhub.dev/tensorflow/bert_en_wwm_uncased_L-24_H-1024_A-16/4\",\n        trainable=True)\n    outputs = encoder(encoder_inputs)\n    pooled_output = outputs[\"pooled_output\"]      # [batch_size, 1024].\n    sequence_output = outputs[\"sequence_output\"]  # [batch_size, seq_length, 1024].\n    embedding_model = tf.keras.Model(text_input, pooled_output)\n    return embedding_model\nmodel = creatmodel()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:34:21.145426Z","iopub.execute_input":"2021-05-25T08:34:21.145707Z","iopub.status.idle":"2021-05-25T08:34:44.482469Z","shell.execute_reply.started":"2021-05-25T08:34:21.145676Z","shell.execute_reply":"2021-05-25T08:34:44.481567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##### Compute list of subject with Type | list of comments \nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nfrom nltk.corpus import stopwords \nfrom nltk import word_tokenize\n\n# We want to remove these from the psosts\nunique_type_list = ['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP',\n       'ISFP', 'ISTP', 'ISFJ', 'ISTJ', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ']\nunique_type_list = [x.lower() for x in unique_type_list]\n\n\n\n\n# Lemmatize\nstemmer = PorterStemmer()\nlemmatiser = WordNetLemmatizer()\n\n# Cache the stop words for speed \ncachedStopWords = stopwords.words(\"english\")\n\ndef pre_process_data(data, remove_stop_words=True, remove_mbti_profiles=True):\n\n    list_personality = []\n    list_posts = []\n    len_data = len(data)\n    i=0\n    \n    for row in data.iterrows():\n        i+=1\n        if (i % 1000 == 0 or i == 1 or i == len_data):\n            print(\"%s of %s rows\" % (i, len_data))\n\n        ##### Remove and clean comments\n        posts = row[1].posts        \n        if remove_mbti_profiles:\n            for t in unique_type_list:\n                temp = posts.replace(t,\"\")\n                \n        temp = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', posts)\n        temp = re.sub(\"[^a-zA-Z]\", \" \", temp)\n        temp = re.sub(' +', ' ', temp).lower()\n        if remove_stop_words:\n            temp = \" \".join([lemmatiser.lemmatize(w) for w in temp.split(' ') if w not in cachedStopWords])\n        else:\n            temp = \" \".join([lemmatiser.lemmatize(w) for w in temp.split(' ')])\n        \n        sentences = tf.constant([temp])\n        temp = model(sentences)\n\n        type_labelized = translate_personality(row[1].type)\n        list_personality.append(type_labelized)\n        list_posts.append(temp)\n\n    list_posts = np.array(list_posts)\n    list_personality = np.array(list_personality)\n    return list_posts, list_personality","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:34:44.483769Z","iopub.execute_input":"2021-05-25T08:34:44.484143Z","iopub.status.idle":"2021-05-25T08:34:44.510634Z","shell.execute_reply.started":"2021-05-25T08:34:44.484104Z","shell.execute_reply":"2021-05-25T08:34:44.509859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_posts, list_personality  = pre_process_data(df, remove_stop_words=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:34:44.511818Z","iopub.execute_input":"2021-05-25T08:34:44.512181Z","iopub.status.idle":"2021-05-25T08:38:54.22173Z","shell.execute_reply.started":"2021-05-25T08:34:44.512141Z","shell.execute_reply":"2021-05-25T08:38:54.220888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_posts = list_posts.reshape(8675,1024)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:38:54.22311Z","iopub.execute_input":"2021-05-25T08:38:54.223432Z","iopub.status.idle":"2021-05-25T08:38:54.228611Z","shell.execute_reply.started":"2021-05-25T08:38:54.223397Z","shell.execute_reply":"2021-05-25T08:38:54.227395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numpy import loadtxt\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Posts in tf-idf representation\nX = list_posts\nparam = {}\nparam['n_estimators'] = 1000\nparam['max_depth'] = 2\nparam['learning_rate'] = 0.2\n\nstarttime = datetime.datetime.now()\n# Let's train type indicator individually\nfor l in range(len(type_indicators)):\n    print(\"%s ...\" % (type_indicators[l]))\n    \n    \n    # Let's train type indicator individually\n    Y = list_personality[:,l]\n\n    # split data into train and test sets\n    seed = 7\n    test_size = 0.33\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n\n    # fit model on training data\n    model = XGBClassifier(eval_metric=\"auc\",use_label_encoder=False,**param)\n    model.fit(X_train, y_train)\n\n    # make predictions for test data\n    y_pred = model.predict(X_test)\n    predictions = [round(value) for value in y_pred]\n    # evaluate predictions\n    accuracy = accuracy_score(y_test, predictions)\n    roc = metrics.roc_auc_score(y_test, predictions)\n    print(\"* %s Accuracy: %.2f%%\" % (type_indicators[l], accuracy * 100.0))\n    print(\"* %s roc: %.2f%%\" % (type_indicators[l], roc * 100.0))\nendtime = datetime.datetime.now()\nprint (endtime - starttime)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nfrom numpy import loadtxt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nX = list_posts\n\n\n    \nlgb_predict_result_bert = []\nlgb_predict_test_bert = []\ntype_ORDER = [\"IE\",\"NS\",\"FT\",\"JP\"]\nstarttime = datetime.datetime.now()\nfor l in range(len(type_indicators)):\n    print(\"%s ...\" % (type_indicators[l]))\n    \n    \n    # Let's train type indicator individually\n    Y = list_personality[:,l]\n    modeltype = \"BERT\"\n    modelOrder = modeltype+type_ORDER[l]+\".pkl\"\n    print(modelOrder)\n    \n    \n\n    # split data into train and test sets\n    seed = 7\n    test_size = 0.33\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n    X_train2, X_test2, y_train2, y_test2 = train_test_split(X, Y, test_size=test_size, random_state=42)\n    #lgb_train = lgb.Dataset(X_train, y_train, free_raw_data=False)\n    #lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train,free_raw_data=False)\n    \n    \n    # fit model on training data\n    evals_result = {}\n   # LGBModel = lgb.train(LGBMparams2, lgb_train, 50000, \n    #                      valid_sets=[lgb_train, lgb_eval], \n     #                     early_stopping_rounds=100, \n      #                    verbose_eval=500, \n       #                   evals_result=evals_result)\n    LGBModel = model_lgbm\n    LGBModel.fit(X_train, y_train,eval_set=(X_test2, y_test2),eval_metric = 'auc',early_stopping_rounds = 100, verbose = 250)\n    \n    \n    joblib.dump(LGBModel, modelOrder)\n    # make predictions for test data\n    \n    starttime2 = datetime.datetime.now()\n    y_pred = LGBModel.predict(X_test, num_iteration=LGBModel.best_iteration_)\n    endtime2 = datetime.datetime.now()\n    \n    print (endtime2 - starttime2)\n    \n    lgb_predict_result_bert.append(y_pred)\n    lgb_predict_test_bert.append(y_test)\n    predictions = [round(value) for value in y_pred]\n    \n    \n    # evaluate predictions\n    accuracy = accuracy_score(y_test, predictions)\n    roc = metrics.roc_auc_score(y_test, predictions)\n    print(\"* %s Accuracy: %.2f%%\" % (type_indicators[l], accuracy * 100.0))\n    print(\"* %s roc: %.2f%%\" % (type_indicators[l], roc * 100.0))\n\nendtime = datetime.datetime.now()\nprint (endtime - starttime)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from catboost import CatBoostClassifier\nimport lightgbm as lgb\nfrom numpy import loadtxt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics\nX = list_posts\n\ncat_params = {\n                'eval_metric':'AUC',\n                'task_type':'GPU',\n                'random_seed':42,\n                'learning_rate':0.2,\n                'depth':2\n                #'colsample_bylevel':0.7,\n                } \nstarttime = datetime.datetime.now()\npredict_result_bert = []\npredict_test_bert = []\nfor l in range(len(type_indicators)):\n    print(\"%s ...\" % (type_indicators[l]))\n    \n    \n    # Let's train type indicator individually\n    Y = list_personality[:,l]\n    \n    \n    \n\n    # split data into train and test sets\n    seed = 7\n    test_size = 0.33\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n    \n    # fit model on training data\n    cb_model = CatBoostClassifier(**cat_params)\n    cb_model.fit(X_train, y_train,\n             eval_set=(X_test, y_test),\n             use_best_model=True,\n             verbose=200,\n                plot=True)\n    \n\n    # make predictions for test data\n    y_pred = cb_model.predict(X_test)\n    predict_result_bert.append(y_pred)\n    predict_test_bert.append(y_test)\n    predictions = [round(value) for value in y_pred]\n    # evaluate predictions\n    accuracy = accuracy_score(y_test, predictions)\n    roc = metrics.roc_auc_score(y_test, predictions)\n    print(\"* %s Accuracy: %.2f%%\" % (type_indicators[l], accuracy * 100.0))\n    print(\"* %s roc: %.2f%%\" % (type_indicators[l], roc * 100.0))\n    \nendtime = datetime.datetime.now()    \nprint (endtime - starttime)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:40:35.259616Z","iopub.execute_input":"2021-05-25T08:40:35.25995Z","iopub.status.idle":"2021-05-25T08:43:24.970787Z","shell.execute_reply.started":"2021-05-25T08:40:35.259917Z","shell.execute_reply":"2021-05-25T08:43:24.969821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#no bert LGBM\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\ndef getconfusion_matrix(dimension):\n    Y = list_personality[:,dimension]\n    y_pred = predict_result_bert[dimension]\n    y_test = predict_test_bert[dimension]\n    \n    \n    \n   \n    C2= confusion_matrix(y_test, y_pred)\n    plt.matshow(C2, cmap=plt.cm.Blues, alpha=0.5)\n    plt.show\n    sns.heatmap(C2,annot=True,fmt=\"d\")","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:43:24.97247Z","iopub.execute_input":"2021-05-25T08:43:24.973118Z","iopub.status.idle":"2021-05-25T08:43:24.980836Z","shell.execute_reply.started":"2021-05-25T08:43:24.973074Z","shell.execute_reply":"2021-05-25T08:43:24.979773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"getconfusion_matrix(1)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T08:43:24.985209Z","iopub.execute_input":"2021-05-25T08:43:24.985557Z","iopub.status.idle":"2021-05-25T08:43:25.344094Z","shell.execute_reply.started":"2021-05-25T08:43:24.985521Z","shell.execute_reply":"2021-05-25T08:43:25.342377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"import lightgbm as lgb\nfrom numpy import loadtxt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics\n\nstarttime = datetime.datetime.now()\nlgb_predict_result = []\nlgb_predict_test = []\ntype_ORDER = [\"TF-IDFIE.pkl\",\"TF-IDFNS.pkl\",\"TF-IDFFT.pkl\",\"TF-IDFJP.pkl\"]\nfor l in range(len(type_indicators)):\n    print(\"%s ...\" % (type_indicators[l]))\n    \n    \n    # Let's train type indicator individually\n    Y = list_personality2[:,l]\n    modeltype = \"TF-IDF\"\n    modelOrder = modeltype+type_ORDER[l]+\".pkl\"\n    print(modelOrder)\n    \n\n    # split data into train and test sets\n    seed = 7\n    test_size = 0.33\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n    X_train2, X_test2, y_train2, y_test2 = train_test_split(X, Y, test_size=test_size, random_state=42)\n    #lgb_train = lgb.Dataset(X_train, y_train, free_raw_data=False)\n    #lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train,free_raw_data=False)\n    \n\n    \n    LGBModel = joblib.load(type_ORDER[l])\n\n    # make predictions for test data\n    \n    starttime2 = datetime.datetime.now()\n    y_pred = LGBModel.predict(X_test, num_iteration=LGBModel.best_iteration_)\n    endtime2 = datetime.datetime.now()\n    \n    print (endtime2 - starttime2)\n    \n    lgb_predict_result.append(y_pred)\n    lgb_predict_test.append(y_test)\n    predictions = [round(value) for value in y_pred]\n    # evaluate predictions\n    accuracy = accuracy_score(y_test, predictions)\n    roc = metrics.roc_auc_score(y_test, predictions)\n    print(\"* %s Accuracy: %.2f%%\" % (type_indicators[l], accuracy * 100.0))\n    print(\"* %s roc: %.2f%%\" % (type_indicators[l], roc * 100.0))\n    \nendtime = datetime.datetime.now()\nprint (endtime - starttime)","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb\nfrom numpy import loadtxt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics\nimport joblib \nimport datetime\nX = X_tfidf\nstarttime = datetime.datetime.now()\nlgb_predict_result = []\nlgb_predict_test = []\ntype_ORDER = [\"TF-IDFIE.pkl\",\"TF-IDFNS.pkl\",\"TF-IDFFT.pkl\",\"TF-IDFJP.pkl\"]\nfor l in range(len(type_indicators)):\n    print(\"%s ...\" % (type_indicators[l]))\n    \n    \n    # Let's train type indicator individually\n    Y = list_personality2[:,l]\n    modeltype = \"TF-IDF\"\n    modelOrder = modeltype+type_ORDER[l]+\".pkl\"\n    print(modelOrder)\n    \n\n    # split data into train and test sets\n    seed = 7\n    test_size = 0.33\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n    X_train2, X_test2, y_train2, y_test2 = train_test_split(X, Y, test_size=test_size, random_state=42)\n    #lgb_train = lgb.Dataset(X_train, y_train, free_raw_data=False)\n    #lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train,free_raw_data=False)\n    \n\n    \n    LGBModel = joblib.load(\"/kaggle/input/fyp-worklab2/\"+type_ORDER[l])\n\n    # make predictions for test data\n    \n    starttime2 = datetime.datetime.now()\n    y_pred = LGBModel.predict(X_test, num_iteration=LGBModel.best_iteration_)\n    endtime2 = datetime.datetime.now()\n    \n    print (endtime2 - starttime2)\n    \n    lgb_predict_result.append(y_pred)\n    lgb_predict_test.append(y_test)\n    predictions = [round(value) for value in y_pred]\n    # evaluate predictions\n    accuracy = accuracy_score(y_test, predictions)\n    roc = metrics.roc_auc_score(y_test, predictions)\n    print(\"* %s Accuracy: %.2f%%\" % (type_indicators[l], accuracy * 100.0))\n    print(\"* %s roc: %.2f%%\" % (type_indicators[l], roc * 100.0))\n    \nendtime = datetime.datetime.now()\nprint (endtime - starttime)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:35:29.270299Z","iopub.execute_input":"2021-05-24T06:35:29.271061Z","iopub.status.idle":"2021-05-24T06:35:38.5187Z","shell.execute_reply.started":"2021-05-24T06:35:29.271011Z","shell.execute_reply":"2021-05-24T06:35:38.517529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#no bert LGBM\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\ndef lgb_getconfusion_matrix(dimension):\n    Y = list_personality2[:,dimension]\n    y_pred = lgb_predict_result[dimension]\n    y_test = lgb_predict_test[dimension]\n    \n    \n    \n   \n    C2= confusion_matrix(y_test, y_pred)\n    plt.matshow(C2, cmap=plt.cm.Blues, alpha=0.5)\n    plt.show\n    sns.heatmap(C2,annot=True,fmt=\"d\")\n    ","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:35:38.520383Z","iopub.execute_input":"2021-05-24T06:35:38.520863Z","iopub.status.idle":"2021-05-24T06:35:38.528407Z","shell.execute_reply.started":"2021-05-24T06:35:38.520816Z","shell.execute_reply":"2021-05-24T06:35:38.52715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_getconfusion_matrix(0)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:35:38.530227Z","iopub.execute_input":"2021-05-24T06:35:38.531149Z","iopub.status.idle":"2021-05-24T06:35:38.933836Z","shell.execute_reply.started":"2021-05-24T06:35:38.5311Z","shell.execute_reply":"2021-05-24T06:35:38.932474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_getconfusion_matrix(1)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:35:38.938059Z","iopub.execute_input":"2021-05-24T06:35:38.942375Z","iopub.status.idle":"2021-05-24T06:35:39.28341Z","shell.execute_reply.started":"2021-05-24T06:35:38.942316Z","shell.execute_reply":"2021-05-24T06:35:39.282032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_getconfusion_matrix(2)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:35:39.296434Z","iopub.execute_input":"2021-05-24T06:35:39.299737Z","iopub.status.idle":"2021-05-24T06:35:39.862357Z","shell.execute_reply.started":"2021-05-24T06:35:39.299678Z","shell.execute_reply":"2021-05-24T06:35:39.860962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_getconfusion_matrix(3)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:35:39.86456Z","iopub.execute_input":"2021-05-24T06:35:39.86503Z","iopub.status.idle":"2021-05-24T06:35:40.25307Z","shell.execute_reply.started":"2021-05-24T06:35:39.864983Z","shell.execute_reply":"2021-05-24T06:35:40.251943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nfrom numpy import loadtxt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics\nimport joblib \nimport datetime\nX = list_posts\nstarttime = datetime.datetime.now()\nlgb_predict_result_bert = []\nlgb_predict_test_bert = []\ntype_ORDER = [\"BERTIE.pkl\",\"BERTNS.pkl\",\"BERTFT.pkl\",\"BERTJP.pkl\"]\nfor l in range(len(type_indicators)):\n    print(\"%s ...\" % (type_indicators[l]))\n    \n    \n    # Let's train type indicator individually\n    Y = list_personality2[:,l]\n    modeltype = \"BERT\"\n    modelOrder = modeltype+type_ORDER[l]+\".pkl\"\n    print(modelOrder)\n    \n\n    # split data into train and test sets\n    seed = 7\n    test_size = 0.33\n    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n    X_train2, X_test2, y_train2, y_test2 = train_test_split(X, Y, test_size=test_size, random_state=42)\n    #lgb_train = lgb.Dataset(X_train, y_train, free_raw_data=False)\n    #lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train,free_raw_data=False)\n    \n\n    \n    LGBModel = joblib.load(\"/kaggle/input/fyp-worklab2/\"+type_ORDER[l])\n\n    # make predictions for test data\n    \n    starttime2 = datetime.datetime.now()\n    y_pred = LGBModel.predict(X_test, num_iteration=LGBModel.best_iteration_)\n    endtime2 = datetime.datetime.now()\n    \n    print (endtime2 - starttime2)\n    \n    lgb_predict_result_bert.append(y_pred)\n    lgb_predict_test_bert.append(y_test)\n    predictions = [round(value) for value in y_pred]\n    # evaluate predictions\n    accuracy = accuracy_score(y_test, predictions)\n    roc = metrics.roc_auc_score(y_test, predictions)\n    print(\"* %s Accuracy: %.2f%%\" % (type_indicators[l], accuracy * 100.0))\n    print(\"* %s roc: %.2f%%\" % (type_indicators[l], roc * 100.0))\n    \nendtime = datetime.datetime.now()\nprint (endtime - starttime)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:41:40.665784Z","iopub.execute_input":"2021-05-24T06:41:40.666562Z","iopub.status.idle":"2021-05-24T06:41:53.416938Z","shell.execute_reply.started":"2021-05-24T06:41:40.666506Z","shell.execute_reply":"2021-05-24T06:41:53.415548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\ndef lgb_getconfusion_matrix_bert(dimension):\n    Y = list_personality[:,dimension]\n    y_pred = lgb_predict_result_bert[dimension]\n    y_test = lgb_predict_test_bert[dimension]\n   \n    \n    \n    \n   \n    C2= confusion_matrix(y_test, y_pred)\n    plt.matshow(C2, cmap=plt.cm.Blues, alpha=0.5)\n    plt.show\n    sns.heatmap(C2,annot=True,fmt=\"d\")","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:41:53.418729Z","iopub.execute_input":"2021-05-24T06:41:53.41956Z","iopub.status.idle":"2021-05-24T06:41:53.433211Z","shell.execute_reply.started":"2021-05-24T06:41:53.419497Z","shell.execute_reply":"2021-05-24T06:41:53.430374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_getconfusion_matrix_bert(0)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:47:11.721144Z","iopub.execute_input":"2021-05-24T06:47:11.721543Z","iopub.status.idle":"2021-05-24T06:47:12.069975Z","shell.execute_reply.started":"2021-05-24T06:47:11.721508Z","shell.execute_reply":"2021-05-24T06:47:12.068664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_getconfusion_matrix_bert(1)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:47:15.889931Z","iopub.execute_input":"2021-05-24T06:47:15.890302Z","iopub.status.idle":"2021-05-24T06:47:16.224397Z","shell.execute_reply.started":"2021-05-24T06:47:15.890269Z","shell.execute_reply":"2021-05-24T06:47:16.222963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_getconfusion_matrix_bert(2)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:47:18.190164Z","iopub.execute_input":"2021-05-24T06:47:18.190541Z","iopub.status.idle":"2021-05-24T06:47:18.537379Z","shell.execute_reply.started":"2021-05-24T06:47:18.190507Z","shell.execute_reply":"2021-05-24T06:47:18.535886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_getconfusion_matrix_bert(3)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T06:47:20.610053Z","iopub.execute_input":"2021-05-24T06:47:20.610428Z","iopub.status.idle":"2021-05-24T06:47:20.939454Z","shell.execute_reply.started":"2021-05-24T06:47:20.610393Z","shell.execute_reply":"2021-05-24T06:47:20.938076Z"},"trusted":true},"execution_count":null,"outputs":[]}]}