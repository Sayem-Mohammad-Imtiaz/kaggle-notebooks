{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\n\nimport numpy as np\nimport pandas as pd \nfrom skimage import io, color\nimport skimage\nimport matplotlib.pyplot as plt\nimport cv2\nimport numpy as np\n\nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**UTILS**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def display(img):\n    plt.figure()\n    plt.set_cmap('gray')\n    plt.imshow(img)\n    plt.show()\n\n\ndef combineLAB(l, a, b):\n    shape = (l.shape[0], l.shape[1], 3)\n    zeros = np.zeros(shape)\n    zeros[:, :, 0] = l\n    zeros[:, :, 1] = a\n    zeros[:, :, 2] = b\n    return zeros\n\n\ndef combineAB(a, b):\n    shape = (a.shape[0], b.shape[1], 2)\n    zeros = np.zeros(shape)\n    zeros[:, :, 0] = a\n    zeros[:, :, 1] = b\n    return zeros\n\n\ndef combineL_AB(l, ab):\n    shape = (l.shape[0], l.shape[1], 3)\n    zeros = np.zeros(shape)\n    zeros[:, :, 0] = l\n    zeros[:, :, 1] = ab[:, :, 0]\n    zeros[:, :, 2] = ab[:, :, 1]\n    return zeros\n\n\ndef make3channels(gray):\n    shape = (gray.shape[0], gray.shape[1], 3)\n    zeros = np.zeros(shape)\n    zeros[:, :, 0] = gray\n    zeros[:, :, 1] = gray\n    zeros[:, :, 2] = gray\n    return zeros\n\n\ndef get_l_from_gray(img_path):\n    img = io.imread(img_path)\n    img = skimage.transform.resize(img,(64,64))\n    gray = color.rgb2gray(img)\n    gray = make3channels(gray)\n    lgray = color.rgb2lab(gray, illuminant='D50')[:, :, 0]\n    return lgray\n\n\ndef get_ab_from_file(file):\n    img = io.imread(file)\n    ab = np.zeros((64, 64, 2))\n    ab[:, :, 0] = img[:, :, 1]\n    ab[:, :, 1] = img[:, :, 2]\n    return ab\n\n\ndef lab_normal_image(path):\n    l, ab = load_img_for_training(path)\n    l, ab = (l-127.5)/127.5, (ab-127.5)/127.5\n    return l, ab\n\n\ndef rgb_image(l, ab):\n    shape = (l.shape[0],l.shape[1],3)\n    img = np.zeros(shape)\n    img[:,:,0] = l[:,:,0]\n    img[:,:,1:]= ab\n    img = img.astype('uint8')\n    img = cv2.cvtColor(img, cv2.COLOR_LAB2RGB)\n    return img\n\n\ndef load_img_for_training(img_path):\n    img = io.imread(img_path)\n    img = skimage.transform.resize(img,(64,64))\n    lab = color.rgb2lab(img, illuminant='D50')\n    l, a, b = lab[:, :, 0], lab[:, :, 1], lab[:, :, 2]\n    ab = combineAB(a, b)\n    lgray = get_l_from_gray(img_path)\n    return lgray, ab\n\n\ndef save_ab_file(image, filepath):\n    # add in 0zeros to its first component\n    shape = (image.shape[0], image.shape[1], 3)\n    new_ab_image = np.zeros(shape)\n    new_ab_image[:, :, 1] = image[:, :, 0]\n    new_ab_image[:, :, 2] = image[:, :, 1]\n    save_file(new_ab_image, filepath)\n\n\ndef save_file(image, filepath):\n    io.imsave(filepath, image)\n\n\ndef load_ab_image(path):\n    img = io.imread(path)\n    shape = (img.shape[0], img.shape[1], 2)\n    ab = np.zeros(shape)\n    ab[:, :, 0] = img[:, :, 1]\n    ab[:, :, 1] = img[:, :, 2]\n    return ab\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Loading**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize(image):\n    # convert image from range 0-256 to \n    #image = cv2.resize(image, dsize=(64, 64), interpolation=cv2.INTER_CUBIC)\n    image = image/255\n    return image\n\ndef unnormalize(image):\n    image = (image*255)\n    return image.astype('uint8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gray_scale = np.load('/kaggle/input/image-colorization/l/gray_scale.npy')[:6000]\nab_scale = np.load('/kaggle/input/image-colorization/ab/ab/ab1.npy')[:6000]\nprint(gray_scale.shape)\nprint(ab_scale.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index = 4579\nl_sample,ab_sample = gray_scale[index].reshape((224,224,1)),ab_scale[index]\nrgb_sample = rgb_image(l_sample,ab_sample)\ndisplay(rgb_sample)\ndisplay(l_sample[:,:,0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.zeros((6000,224,224,3), dtype='uint8')\n\nfor i in range(6000):\n    l_sample = (gray_scale[i]).reshape((224,224,1))\n    ab_sample = (ab_scale[i])\n    x[i] = rgb_image(l_sample, ab_sample)\n    \ndisplay(x[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = x/256.0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Architecture**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import *\nfrom keras.layers import *\nfrom keras.activations import *\nfrom keras.optimizers import *\nfrom matplotlib import pyplot as plt\nfrom utils import *\nfrom keras.initializers import RandomNormal, Zeros","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose, concatenate\nfrom keras.models import Model\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.optimizers import Adam\nfrom keras.applications.vgg16 import VGG16","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = VGG16(input_shape = (224, 224, 3), # Shape of our images\ninclude_top = False, # Leave out the last fully connected layer\nweights = 'imagenet')\n\nfor layer in base_model.layers:\n    layer.trainable = False\n\nbase_model.summary()\nencoder = base_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import *\n\ndec_input = Input((7,7,512))\n\ndec_x = ReLU()(dec_input)\n\nlayer_dim = [512, 256, 128, 64, 32]\n\nfor i in layer_dim:\n    dec_x = Conv2DTranspose(i, (2, 2), strides=(2, 2), padding='same', activation='relu')(dec_x)\n    dec_x = Conv2D(i, 2, padding='same', activation='relu')(dec_x)\n\n    \ndec_x = Conv2D(3,2,padding='same',activation='sigmoid')(dec_x)\n\ndecoder = Model(inputs=[dec_input], outputs=[dec_x])\ndecoder.compile(optimizer='adam', loss='mse', metrics=['acc'])\ndecoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_out = decoder(encoder.output)\nencoder.trainable=False\nmodel = Model(encoder.input, model_out)\nmodel.compile(optimizer='adam', loss='mae', metrics=['acc'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"samples = x.shape[0]\nepochs = 100\nhistory = model.fit(x,x,validation_split=0.1,epochs=epochs,batch_size=64,)\nmodel.save('model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"h = history\nplt.plot(h.history['acc'])\nplt.plot(h.history['val_acc'])\nplt.title('Model accuracy')\nplt.show()\n\nplt.plot(h.history['loss'])\nplt.plot(h.history['val_loss'])\nplt.title('Model Loss')\nplt.show()\n\nplt.plot(h.history['acc'])\nplt.title('Model accuracy')\nplt.show()\n\nplt.plot(h.history['loss'])\nplt.title('Model Loss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_images(generator, samples):\n    ab_values = generator.predict(samples)\n    plt.figure()\n    plt.set_cmap('gray')\n    for i in range(ab_values.shape[0]):\n        rgb = unnormalize(ab_values[i])\n        display(rgb)\n        display(samples[i])\n        ax = plt.subplot(64, 64, i+1)\n        im = ax.imshow(rgb)\n        plt.tight_layout()\n        plt.title(i)\n    plt.show()\n    plt.savefig('gan_generated_image.png')\n\nsamples = x[0:10]\nsave_images(model,samples)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"enc_x = encoder.predict(samples)\nprint(enc_x.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dec_x = decoder.predict(enc_x)\nprint(dec_x.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(samples[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(dec_x[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder.save('enc.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoder.save('dec.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder.layers[-1].output.shape.as_list()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoder.layers[0].input.shape.as_list()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoder.layers[0].input.shape.as_list() == encoder.layers[-1].output.shape.as_list()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}