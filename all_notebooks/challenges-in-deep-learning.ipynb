{"nbformat":4,"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.3","nbconvert_exporter":"python","pygments_lexer":"ipython3","name":"python","mimetype":"text/x-python"}},"nbformat_minor":1,"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"0753d8bb-6464-441c-9733-bc9f3b85de57","_uuid":"672f0d8104943bbe6e30c0f8b8161454d29d6e15"},"source":"# Preamble\n\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"217dbeef-57c2-4b78-bd3a-a6d696b59bca","_uuid":"2ffbdd8504f7b20de025218283605a4fe4950e25"},"source":"I'm conducting research on data science and its methods. Meta-data-science, so to speak.\n\nHere, I tried to analyze the current state of and challenges in Deep Learning. Since the results stand-alone may be a bit hard to interpret, I try to show how it compares to \"classical\" machine learning.\n\nCaveat emptor: I'm not a data scientist and very unexperienced. I have no idea what I'm doing."},{"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"d7bbede5-f2f4-405d-b30f-76ddaffdb5aa","_uuid":"777393b6263da93285574560ba6607ba85ecbd5b"},"source":"import os\nimport glob\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n#import pandasql as pdsql # *schnüff*\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport scipy.stats as sst\nfrom functools import reduce\nimport pylab\nimport seaborn as sns\nimport math\nimport re\ncolor = sns.color_palette()\n%matplotlib inline","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"3376b971-f46d-477d-b6bc-20a89fa4b6ac","_uuid":"ab511951cd0d8432920725c10fad6cbeee76fde0"},"source":"from subprocess import check_output\nprint(check_output([\"ls\", \"../input/\"]).decode(\"utf8\"))","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"2f016904-fccd-445f-913b-f27005f06b46","_uuid":"9a89fcc1f8c25ba8e0c8f7daab7a1791d2216b4c"},"source":"# Read each of the file\n#cvRates = pd.read_csv('../input/conversionRates.csv', encoding=\"ISO-8859-1\")\nff = pd.read_csv('../input/freeformResponses.csv', encoding=\"ISO-8859-1\")\nmc = pd.read_csv('../input/multipleChoiceResponses.csv', encoding=\"ISO-8859-1\")\nschema = pd.read_csv('../input/schema.csv', encoding=\"ISO-8859-1\")","cell_type":"code"},{"cell_type":"markdown","metadata":{"_cell_guid":"027e0a7a-5e9c-4c64-8b81-2d3886a41d05","_uuid":"691049e11acc16eeae3d29f36153e7aa26b5d78a"},"source":"## Defining what deep learning is"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"5ead46f2-3967-4da7-ba8b-864ed8685aeb","_uuid":"82c3a20bc1d84e7042991d79f83c8048a08393d1"},"source":"dnnerfilt = reduce(lambda a,b: a | b, (mc[\"WorkMethodsFrequency\" + a] == v \n       for a in (\"CNNs\", \"GANs\", \"RNNs\")\n       for v in (\"Often\", \"Most of the time\")))\ndnners = mc[dnnerfilt]\nnondnn = mc[~dnnerfilt]\nprint((len(dnners), len(nondnn)))","cell_type":"code"},{"cell_type":"markdown","metadata":{"_cell_guid":"f1e1af89-04ed-4eaf-a878-925e7b34a32e","_uuid":"32d30045a8fac64d5874679525195d8284d0bb65"},"source":"The code above defines Deep Learning practicioners as people who picked \"Often\" or \"Most of the time\" in their answers for at least one of CNNs, GANs, or RNNs.\n\nNow, I'm entirely aware that Deep Learning is a term that was made up entirely to sound cool (someone needed to get a paper published — hence Deep Belief Networks were born). It is not in any way scientifically or canonically defined. I feel like this somewhat captures current use of the term, but I'm open for input on this (or adding interactivity/dropdowns so you can pick?)."},{"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"6c673849-9266-4e46-859a-f85e080bd9ae","_uuid":"7141d5e9a91c50a1f05be487c3ba642c09a525d7"},"source":"# method to handle those nasty selects\ndef splitcounts(df,name=\"frac\",splitchr=','):\n    chalsel = df.dropna()\n    flat = pd.Series((i for l in chalsel.str.split(splitchr) for i in l))\n    return flat.value_counts().apply(lambda x: x/len(chalsel)).to_frame(name=name)","cell_type":"code"},{"cell_type":"markdown","metadata":{"_cell_guid":"a505a9f9-c6fb-451f-95e7-0b43dd3318df","_uuid":"dcc09defb4eacf0bbb8359b32c24123b0d031175"},"source":"Let's check for unwanted by-catch:"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"4767cfb4-0c76-4573-9bdc-817819dcba81","_uuid":"f9bf87b96cd9ea6f55c14279ae04b303bf1a4823"},"source":"splitcounts(dnners.WorkMethodsSelect).head(10)","cell_type":"code"},{"cell_type":"markdown","metadata":{"_cell_guid":"d213a878-f220-4404-875d-3a2b79537330","_uuid":"3059be592b4f5e359ac763febb855da20593c331"},"source":"It seems that around half of the people I selected to be \"Deep Learners\" also use methods like PCA and kNN, but I think that excluding everyone who uses other methods would not leave enough data. Since CNNs came out on top, I'm content with my selection for now."},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"40135a9d-eb3b-4753-afbb-31f13f1bff42","_uuid":"f8731f5eb2236b1feeb42faa241f361b02082af6"},"source":"dnners.filter(items=['EmploymentStatus']).apply(lambda x: x.value_counts())","cell_type":"code"},{"cell_type":"markdown","metadata":{"_cell_guid":"5e860940-6f62-4bc1-8f8a-5e132e8139f2","_uuid":"90dcce69302efda7f8dd4c1747d13dffc419f013"},"source":"Sanity check: they're all employed. That's a precondition for being shown the WorkMethods question.\n(One thing I don't get about the survey is that it entirely, even for part-timers, denies the possibility to be a student. I get the feeling that part-time work is the rule, not the exception for university students. And even full-time employed university students are not unherd of. So…?)"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"45216cc9-c601-4b23-979d-1e2302ce021f","_uuid":"8893ead382f05a767b11442fdc60a43f224a1a46"},"source":"# Let's exclude answers that were not from people in the CodingWorker category.\nworker_label = [\n    \"Employed full-time\",\n    \"Employed part-time\",\n    \"Independent contractor, freelancer, or self-employed\"\n]\ncodingworker = reduce(lambda a,b: a | b, (mc.EmploymentStatus == l for l in worker_label)) & \\\n  (mc.CodeWriter == \"Yes\")\n\nmc.loc[dnnerfilt & codingworker, 'MLType'] = 'Deep'\nmc.loc[~dnnerfilt & codingworker, 'MLType'] = 'Classic'\ndnners = mc[dnnerfilt & codingworker] # this should not change anything…\nnondnn = mc[~dnnerfilt & codingworker] # These would have probably been filtered out as nans anyway\n# but better safe than sorry.\nshow_dlgroups = lambda df: df.MLType.fillna('Excluded').value_counts().to_frame(name='Σ')\nshow_dlgroups(mc)","cell_type":"code"},{"cell_type":"markdown","metadata":{"_cell_guid":"832d903f-ee11-4ec0-8a57-8cd599f5de3d","_uuid":"054684fe4d1cf43f2b26557c7c7740919d36dd83"},"source":"# Challenge Analsysis"},{"outputs":[],"execution_count":null,"metadata":{"scrolled":true,"_cell_guid":"78324be4-f14e-473c-a440-a6b2a56de58d","_uuid":"8f60691a42a7a1f493cef2dd94cf706a9f19fd44"},"source":"dnners.filter(regex='^WorkChallenge').head()","cell_type":"code"},{"cell_type":"markdown","metadata":{"_cell_guid":"526ade71-3d6e-4baa-8ed1-af7756c3b368","_uuid":"c0f911fa43515f4d751affdba45dba5e4b6265c7"},"source":"We'll work with that."},{"cell_type":"markdown","metadata":{"_cell_guid":"27ba473a-bfc6-4370-9b4f-a481d693a3d1","_uuid":"8bed54c47204e113de160a87d55d55390c597c34"},"source":"## Challenge Selection"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"f59acf67-07aa-4ec2-9886-8eb46380596c","_uuid":"7e9386db41fa95e913001abc8b26a214eaca4cf0"},"source":"len(dnners.WorkChallengesSelect.dropna())","cell_type":"code"},{"cell_type":"markdown","metadata":{"_cell_guid":"d2735436-f200-4d60-b49e-30d1d280ed47","_uuid":"67265dcdeebba7374ef2b6449a5d459ba28fffb1"},"source":"Yay, only 40 did not answer. It is possible that no answer means that they have no problems in data science, but I'll be so frank and assume that they ignored the question."},{"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"scrolled":false,"_cell_guid":"dfc0703b-f4e9-45b5-83fe-635a602f781b","_uuid":"61a40df2725e5c78635a4a75e9fdb6075509d450"},"source":"def compare_bar_plot_prep(col, tran=lambda x: x):\n    f = splitcounts(dnners[col].apply(tran), name=\"DNNers\")\n    f = f.merge(splitcounts(nondnn[col].apply(tran), name=\"Others\"),left_index=True, right_index=True)\n    f = f.reset_index().melt(id_vars=['index'],value_vars=['DNNers','Others'])\n    return f\nchallenge_sel = compare_bar_plot_prep('WorkChallengesSelect')","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"a528f174-040c-4e37-ba9f-d287a60c99bd","_uuid":"bad536d8b1d36f29aa780e1e59834aec973b1fae"},"source":"plt.figure(figsize=(10,20))\nsns.barplot(data=challenge_sel, y='index', x='value', hue='variable', orient='h')\nplt.title('Frequency of problem mentions', fontsize=16)\nplt.xlabel('Fraction', fontsize=16)\nplt.ylabel('Problem', fontsize=16)\nplt.show()","cell_type":"code"},{"cell_type":"markdown","metadata":{"collapsed":true,"_cell_guid":"7df774d0-1ddf-4c2b-87a2-0ce57f731b40","_uuid":"58fa629ca4045acb45200c01686b0b464952a1c6"},"source":"Now here are a few things I did not expect. (Correct me if I'm misinterpreting my results.)\n - It seems that dirty data is no less of a problem for DNN practicioners.\n  (And here I thought deep learning was better at ignoring noise, at least. So what kind of dirt is the problem?)\n - State of the art is an a lot bigger limitation in Deep Learning.\n - Deep Learning results can be more easily integrated.\n  (Maybe I should have expected that. The things that Deep Learning promises to solve are after all usually problems that get integrated into a technical application, not int a abusiness process.)"},{"cell_type":"markdown","metadata":{"_cell_guid":"fa10505c-ddfc-4da2-8a44-a8bced37b6ec","_uuid":"cfc3ba7153b3fd577903a3af70e3b948c7d5496f"},"source":"This entirely ignored the picked frequencies. We could now ignore those answers where the frequency was picked to be Rarely or Sometimes, but I want a deeper look."},{"cell_type":"markdown","metadata":{"_cell_guid":"027775c8-e117-4755-a3c6-d4540270a9a5","_uuid":"7c1033978a272408a123f2702c7a16ceab9b28ec"},"source":"## Frequencies"},{"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"scrolled":true,"_cell_guid":"fc3ee554-6acb-4d0d-af5c-f482b454ad12","_uuid":"7f9b803c0e59e6827e95a167c51cf50c535f7ec5"},"source":"# (One way to visualize the frequencies might be to use stacks. \n# But I don't want to spend a day to find out how to do stacked grouped bar plots \n#  which might be hard to interpret in the end. \n# If you know an easy way: tell me.)","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"de8e2071-2c95-41f9-8912-e696c5dfb444","_uuid":"7f340a865de82d2bd9cb4b26962928ad1e18b890"},"source":"def freqfreq(df): return df \\\n    .filter(regex='^WorkChallengeFrequency') \\\n    .fillna('Never') \\\n    .apply(lambda col: col.value_counts())\nfreqfreq(dnners)","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_kg_hide-output":true,"collapsed":true,"_cell_guid":"7330796d-f9ef-4baf-94f9-edad1daffdc4","_uuid":"b3c3471dc1f2688c29cd8815994423e9d9a1688a"},"source":"# Here is some bllllrgh:\n# I want the plots in this section to be in order of the plot before.\n# Now, the plot before directly used the human-readable values from the Select field,\n#  but the plots in this setion will use the column names. Fun time translating…\ndnn_challenge_sel = challenge_sel[challenge_sel.variable == 'DNNers']\nfreqschema = schema[schema.Column.apply(lambda name: name.startswith(\"WorkChallengeFrequency\"))].copy()\nfreqschema['Question'] = freqschema['Question'].apply(lambda x: x.replace(\n    'At work, how often did you experience these barriers or challenges within the past year? - ', ''))\ndnn_challenge_sel = dnn_challenge_sel.merge(freqschema, left_on='index', right_on='Question')\nsel_order = dnn_challenge_sel.set_index('Column').index\n# Seriously, why is the data set this way?","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"8a85e316-ffad-40ef-95aa-ec779c511399","_uuid":"6633b4422b5aa56dfd38fa195bef6aab44cda74d"},"source":"dnners.filter(regex='^WorkChallengeFrequency').melt().value.value_counts().to_frame(name='Σ')","cell_type":"code"},{"cell_type":"markdown","metadata":{"_cell_guid":"06c27af3-1a47-45f7-a313-736a7afe2839","_uuid":"a609fd81d72a8f81403f3a8e15672455ff7ba861"},"source":"So guess what, if you have a problem rarely, you don't pick that you have it in the first place. Who else is worried that Sometime may be a little bit biased towards a lower value because of the same effect? Let's proceed with caution. "},{"cell_type":"markdown","metadata":{"_cell_guid":"a54aa1c3-1980-4327-958b-4924da8b524d","_uuid":"03788f1db8cf42b5bfbac5d360ec86768eb3c25f"},"source":"Let's first have a look at the relative frequencies:"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"37782b2a-3f46-4af9-9e85-9c2459899ff4","_uuid":"205cae76a8326f3cacc2a900a5deb31744aa93af"},"source":"plt.figure(figsize=(5,10))\nm = lambda df: freqfreq(df).apply(lambda x: x / len(df))\nrelfreq = m(dnners).transpose()\norfreq = relfreq[['Rarely','Sometimes','Often','Most of the time']].reindex(sel_order) # let's ignore nevers since they go into extremes\norfreq = orfreq.drop('WorkChallengeFrequencyPass')\nax = sns.heatmap(orfreq, linewidths=.5, cmap=\"Blues\")","cell_type":"code"},{"cell_type":"markdown","metadata":{"_cell_guid":"1e894541-834a-4b89-a442-55d958910137","_uuid":"b8af8f3a1c8aab9ff93b96784111e8a99ed724b1"},"source":"I see nothing extraordinary here. Maybe the tendency that if money is a problem, it's a problem all the time."},{"cell_type":"markdown","metadata":{"_cell_guid":"bf50bf63-97e4-4200-9fc5-bf97a91151cf","_uuid":"23ee6c12f0d87997ac196a80053c0a3014b3d272"},"source":"Now, what I really want to know is whether that bar plot in the previous subsection got affected by some skew between how frequent selections are."},{"outputs":[],"execution_count":null,"metadata":{"scrolled":true,"_cell_guid":"83cf5ecd-cf3c-48a4-a71a-ee99b0e3aba7","_uuid":"8a091a913660d76ef21e79ab453037dd34cb8646"},"source":"plt.figure(figsize=(5,10))\nm = lambda df: freqfreq(df).apply(lambda x: x / len(df))\nrelfreq = (m(dnners) - m(nondnn)).transpose()\norfreq = relfreq[['Rarely','Sometimes','Often','Most of the time']].reindex(sel_order)\nscalefac = dnn_challenge_sel.set_index('Column').value\norfreq = orfreq.apply(lambda c: c / scalefac)\norfreq = orfreq.drop('WorkChallengeFrequencyPass')\nax = sns.heatmap(orfreq, linewidths=.5, cmap=\"coolwarm\")","cell_type":"code"},{"cell_type":"markdown","metadata":{"_cell_guid":"38b4742c-9534-41e7-8dba-411b34bdb3c0","_uuid":"578ce2587e7a5a30207693b4a66f2960fc76de61"},"source":"To interpret this plot: a strong color indicates that a large part of the change between Deep and Classic practicioners comes from people answering with a certain frequency. Since there are no rows with a strong red in one column and a strong blue in another, I think the results from the previous section can be taken to be sane.\n\nThe only other thing I want to interpret into this plot is that problems that were not part of this survey occur with higher intensity in Deep Learning (i.e. Other)."},{"cell_type":"markdown","metadata":{"_cell_guid":"2c71eba2-777d-4685-8bff-a451ce758ec8","_uuid":"bfc082681f54258a844a39d18ffcc960d732c6dd"},"source":"# Time use"},{"cell_type":"markdown","metadata":{"_cell_guid":"bfb2c114-6842-484d-91f5-baf2be950d25","_uuid":"c637d991ada0d072159351f27d915fd81b75829b"},"source":"I'm interested in what costs each group the most time. First, let's see how often that question was actually answered properly:"},{"outputs":[],"execution_count":null,"metadata":{"scrolled":true,"_cell_guid":"1cb5e75b-4446-48c3-95bc-4213424b0df4","_uuid":"668a381cdac9b3ad9612f42e00313e430c5fef7f"},"source":"cis = schema.set_index('Column')\ntxt_n = lambda n: cis.Question[n]\n# careful, we don't want TimeSpentStudying\ncols = [q for q in mc.filter(regex='^Time').columns if 'Total must equal 100%' in txt_n(q)]\n\ntime_answered = lambda df: df[cols].apply(lambda r: r.sum(), axis=1) == 100.0\ntime_answer_counts = show_dlgroups(mc[time_answered(mc)])\ntime_answer_counts / show_dlgroups(mc)","cell_type":"code"},{"cell_type":"markdown","metadata":{"_cell_guid":"5f312010-5716-4084-80f0-e48adb14c8f0","_uuid":"f40dd306744a062d34c30cc6225fefe0a60890df"},"source":"Most for deep learning, around ⅔ for \"classic\". While that's slightly odd, we didn't lose anything where it hurts (in the smaller dataset)."},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"3ec953ae-0527-494b-81e7-e59602bbd1db","_uuid":"63efd05e4817355473e372067fbfdb93619e690b"},"source":"times_means = pd.DataFrame([\n    dnners[time_answered(dnners)][cols].mean(),\n    nondnn[time_answered(nondnn)][cols].mean()\n], index=['DNNers', 'Others'])\npl=times_means.plot(kind='bar',stacked=True, fontsize=10,figsize=(10,10)) \npass","cell_type":"code"},{"cell_type":"markdown","metadata":{"_cell_guid":"64b88fff-1041-43fa-9e60-f05cc6238d38","_uuid":"869ed89439d82d698ff5a2d545f61d8bcede3789"},"source":"I don't unerstand how people find it anything to read from this kind of stacked plot. But now I know that at least the sums of the means add up to 100 (percent)."},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"6819d392-09e2-4e82-af4e-e0294c7a158f","_uuid":"c68f02c12c0b6e664752db35ad6222e508ffe8cc"},"source":"times_means.transpose().plot(kind='barh')\npass","cell_type":"code"},{"cell_type":"markdown","metadata":{"_cell_guid":"cb09e24f-e72f-4d85-b974-2d147624f3f9","_uuid":"811efa2d1aeaf2e2166be45339c6b430da044532"},"source":"No surprises here. Model building takes a more time for Deep Learning, which fits to training being immensely expensive. Everything else is proportionally reduced. (Except the time for getting things production-ready, but I feel like that's not significant enough.)"},{"cell_type":"markdown","metadata":{"_cell_guid":"45c469e3-0a8c-4812-b4e0-68c270b80dd9","_uuid":"6125b6be387ac4827d7d3d741fed49c9d542287d"},"source":"# Dataset Size"},{"cell_type":"markdown","metadata":{"_cell_guid":"158ffc4e-c8f2-42c9-a1b6-9ae63859a76b","_uuid":"3f4be4522c3b94524b6a0da96603451985bfccab"},"source":"[rickvenadata](https://www.kaggle.com/rickvenadata) analyzed [how big typical used datasets are](https://www.kaggle.com/rickvenadata/big-data-or-big-hype-part-deux). If the cant about Deep Learning being able to handle bigger big data holds true, we should see something interesting here.\n\n"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"d2b35175-a1e0-49ed-94b2-c9e8afffec66","_uuid":"1c6ec1b4eab6c3d2ee8ab8e93dabbf4404c1ddd7"},"source":"size_order = ['<1MB', '1MB', '10MB', '100MB', '1GB', '10GB', '100GB', '1TB',\n              '10TB', '100TB', '1PB', '10PB', '100PB', '1EB', '>1EB']\nplt.figure(figsize=(10,5))\nwork_dataset_sizes = compare_bar_plot_prep('WorkDatasetSize')\nsns.barplot(data=work_dataset_sizes, order=size_order,\n            y='index', x='value', hue='variable', orient='h')\n            #palette=['#3274a1', '#e1812c'])\nplt.title('Frequency of \"Most common dataset size\"', fontsize=16)\nplt.xlabel('Fraction', fontsize=16)\nplt.ylabel('Size', fontsize=16)\nplt.show()","cell_type":"code"},{"cell_type":"markdown","metadata":{"_cell_guid":"6e5dd8ce-f4a3-4614-9eec-0b127a91ebee","_uuid":"76de8874b2ba9ecef9939edd3ae3a8a33c1e6257"},"source":"This result looks more significant than I would have expected. So while \"classic\" ML focuses on data around 1GB insize, the typical size for a DNNer is around 10GB (and 100GB is fairly common, still). I'd be so frank to say that Deep Learning datasets are around one order of magnitude bigger, but the difference may be understated because of how I separated Deep Learning practicioners."},{"cell_type":"markdown","metadata":{"_cell_guid":"77b223c1-cac0-40b4-9e0c-07ad2ddb5c50","_uuid":"495d076049982a868b30c0fe61c10d6beba492a0"},"source":"Maybe side-by-side is easier to look at:"},{"outputs":[],"execution_count":null,"metadata":{"scrolled":true,"_cell_guid":"f13cd3f2-910c-468b-aecf-196190d6ff5b","_uuid":"990f1a4bb22805e14b571a0a1707f4c8f07973df"},"source":"#### I'll be stealing this from rickvenadata\ndef parse_size(size):\n    if size.endswith(\"MB\"):\n        if size.startswith(\"<\"):\n            size = float(size.rstrip(\"MB\").lstrip(\"<\")) * 1e5\n        else:\n            size = float(size.rstrip(\"MB\")) * 1e6\n    elif size.endswith(\"GB\"):\n        size = float(size.rstrip(\"GB\")) * 1e9\n    elif size.endswith(\"TB\"):\n        size = float(size.rstrip(\"TB\")) * 1e12\n    elif size.endswith(\"PB\"):\n        size = float(size.rstrip(\"PB\")) * 1e15\n    elif size.endswith(\"EB\"):\n        if size.startswith(\">\"):\n            size = int(size.rstrip(\"EB\").lstrip(\">\")) * 1e19\n        else:\n            size = int(size.rstrip(\"EB\")) * 10**18\n    return float(size)\nfig,axs = plt.subplots(1,2,figsize=(10,4))\nsns.distplot(dnners.WorkDatasetSize.dropna().apply(lambda v: math.log(parse_size(v), 10)),\n             ax=axs[0],vertical=True,kde_kws={'bw': 0.45})\nplt.setp(axs[0],title='DNNers')\nsns.distplot(nondnn.WorkDatasetSize.dropna().apply(lambda v: math.log(parse_size(v), 10)),\n             ax=axs[1],vertical=True,kde_kws={'bw': 0.45})\nplt.setp(axs[1],title='Others')\npass","cell_type":"code"},{"cell_type":"markdown","metadata":{"_cell_guid":"0347db98-910f-4ea0-8f31-9ab9f3d8d2d3","_uuid":"051f889181897b9f66039c0e987c1157ee0f273c"},"source":"# Data Sharing and Storage"},{"cell_type":"markdown","metadata":{"_cell_guid":"862511d9-75b6-480c-8478-2cf892ff1a52","_uuid":"5dda06c993d4d596afcd09485b252247a1332c5e"},"source":"I think you understood the drill, by now."},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"6613b1e0-79d5-4f29-b2c0-15dd1345890a","_uuid":"893295862ebc2a4904e1a1ee23808480f90c3b64"},"source":"re_noeg = re.compile(' ?\\(e.g.[^)]*\\)') # argh, those e.g. contain commata. commata in a comma separated list\nstoretype_freqs = compare_bar_plot_prep('WorkDataStorage',\n                                        tran=lambda s: re_noeg.sub('', s) if type(s) == str else s)\nplt.figure(figsize=(10,5))\nsns.barplot(data=storetype_freqs, y='index', x='value', hue='variable', orient='h')\nplt.title('Frequency of storage type mention', fontsize=16)\nplt.xlabel('Fraction', fontsize=16)\nplt.ylabel('Storage type', fontsize=16)\nplt.show()","cell_type":"code"},{"cell_type":"markdown","metadata":{"_cell_guid":"15e1810d-cca1-477a-894c-a508fc8293f4","_uuid":"94b32b9c70017f473d0aa633b5c5b36e4262902d"},"source":"Since I don't think that  Deep Learning is done from relational databases, I guess my separation of Deep Learning practicioners isn't that good."},{"cell_type":"markdown","metadata":{"_cell_guid":"5f43a85d-05a5-44c7-9af3-592525b350a4","_uuid":"c4413a47a7823c49230567fe0144ca074db2795f"},"source":"Unfortunately, we can't do this comparison with the free form answers since they were shuffled, but I still want to have a peek:"},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"12876e92-bb13-43ee-81b9-42322b6110d4","_uuid":"1f2da1c4221dbe6bcd5133ee42437998c7238f40"},"source":"splitcounts(ff.WorkDataStorageFreeForm.dropna().apply(lambda s: s.lower()), splitchr=' ').head(10)","cell_type":"code"},{"cell_type":"markdown","metadata":{"_cell_guid":"004ea8e5-0e8c-4f7e-bb42-b52afb6a1fbe","_uuid":"bd06994c9a7ce8e4dd3879b0de25df40db0a0ffd"},"source":"Maybe I didn't want to have a peek. Next."},{"outputs":[],"execution_count":null,"metadata":{"_cell_guid":"42519b84-c2a3-402e-9be7-9a3abb4a119d","_uuid":"5e84c8ce32d57d5ee886f95ae3604f91f202d9a0"},"source":"plt.figure(figsize=(10,4))\nsns.barplot(data=compare_bar_plot_prep('WorkDataSharing'), y='index', x='value', hue='variable', orient='h')\nplt.title('Frequency of storage type mention', fontsize=16)\nplt.xlabel('Fraction', fontsize=16)\nplt.ylabel('Storage type', fontsize=16)\nplt.show()","cell_type":"code"},{"cell_type":"markdown","metadata":{"_cell_guid":"920f8a53-c240-493c-aff1-989f0c8444c2","_uuid":"3456ca2c44943d95fb222d92c4a4baab424f9368"},"source":"# Closure "},{"cell_type":"markdown","metadata":{"_cell_guid":"f2b08848-b9a4-4064-a260-952a8b7e5917","_uuid":"f7f553436fd3d7fee62ab6f6127729e7939e08c0"},"source":"It may be a focused analysis of a single aspect, but I hope you found it interesting. Please tell me what you think. Are there any other aspects I could analyze like this? Any difference between Deep Learning and \"classic\" ML that may be interesting?"},{"cell_type":"markdown","metadata":{"_cell_guid":"dc0fbc01-9116-475c-8c1b-e2b207e548c8","_uuid":"e214cd7442e1bca182d48fe1c3a6cbec4b6ba129"},"source":"While the results look like they have significance in many cases, I'm not sure they actually do. I'd be pleased if someone could suggest a method of analyzing the significance."}]}