{"cells":[{"source":"# Exploring Monster.com Job Postings\n\nMonster.com is one of the largest job sites in the United States, providing a huge clearinghouse for employers and employee prospects to find one another on.\n\nIn this notebook we will explore this dataset, a sample of all Monster.com job postings in the United States. We will hopefully learn a thing or two about what a job listing looks like in the modern day. We will probe the basic dataset attributes and hopefully uncover some interesting observations from the data! This exploratory data analytics notebook is recommended for beginners and those interested in probing this dataset further. Feel free to fork this notebook and/or copy the code here and explore further on your own!\n\n![](https://media.wired.com/photos/593288b126780e6c04d2c7ec/master/w_999,c_limit/Palm_Monster.jpg)","metadata":{},"cell_type":"markdown"},{"execution_count":null,"outputs":[],"source":"import numpy as np\nimport pandas as pd","metadata":{"_cell_guid":"dab092f3-a770-47e6-ba74-f2966f0e445c","_uuid":"b8711f2e7e65e17e928546d997427eb17157a7e7","collapsed":true},"cell_type":"code"},{"execution_count":null,"outputs":[],"source":"jobs = pd.read_csv(\"../input/monster_com-job_sample.csv\")","metadata":{"_cell_guid":"9047783d-dbdb-4016-a864-d3143aa3297e","_uuid":"a6293019871cbe3922a4a23f8ad21a23786e4947","collapsed":true},"cell_type":"code"},{"source":"## Munging the data\n\nMany of the fields are not interesting (some as a function of the filtering applied to this dataset) and can be dropped. Some of the rest of the fields are very sparse.","metadata":{"_cell_guid":"3af73570-03b8-46b9-840a-33500b6a4d37","_uuid":"7534bb1a42993aec49fd62bd57314aaaf2269ce1"},"cell_type":"markdown"},{"execution_count":null,"outputs":[],"source":"# Clean up the fields a bit\njobs = (jobs.drop([\"job_board\", \"has_expired\", \"country\", \"country_code\", \"uniq_id\"],\n                  axis='columns'))","metadata":{"_cell_guid":"bd0036ca-05fe-4c51-ac48-e3b7ac764aca","_uuid":"bbeb7eaf29e7a551d71ee8a8de7eaa4e1b14f586","collapsed":true},"cell_type":"code"},{"source":"The `location` field often has a copy of the `job_description` in it, for some reason; these need to be filtered out. The information in the `salary` varies by a lot in terms of formatting, in addition to being left blank most of the time anyway.","metadata":{"_cell_guid":"54d6f4f7-09ce-4e58-8eab-1733595c5a56","_uuid":"1f318f5bf5d0ba7e0147290a110ac84c6da277c1"},"cell_type":"markdown"},{"execution_count":null,"outputs":[],"source":"jobs = jobs[jobs['location'].str.len() < 40]\n\ndef map_yearly_salary_range(val):\n    if pd.isnull(val):\n        return np.nan\n    elif \"/year\" in val:\n        part = val.split(\"/year\")[0].replace(\"$\", \" \").strip()\n        if \"-\" in part:\n            mn, mx = part.split(\"-\")[0:2]\n            try:\n                mn = float(mn.replace(\",\", \"\").strip())\n                mx = float(mx.replace(\",\", \"\").strip())\n            except:\n                return np.nan\n            return mn, mx\n        \ndef map_hourly_salary_range(val):\n    if pd.isnull(val):\n        return np.nan\n    elif \"/hour\" in val:\n        part = val.split(\"/hour\")[0].replace(\"$\", \" \").strip()\n        if \"-\" in part:\n            mn, mx = part.split(\"-\")[0:2]\n            try:\n                mn = float(mn.replace(\",\", \"\").strip())\n                mx = float(mx.replace(\",\", \"\").strip())\n            except:\n                return np.nan\n            return mn, mx\n        \njobs = jobs.assign(yearly_salary_range=jobs['salary'].map(map_yearly_salary_range),\n                   hourly_salary_range=jobs['salary'].map(map_hourly_salary_range))\n\nprint(\"We found {0} yearly and {1} hourly salaries in the dataset.\".format(\n    jobs['yearly_salary_range'].notnull().sum(), jobs['hourly_salary_range'].notnull().sum()\n))","metadata":{"_cell_guid":"91734ad9-4afe-4c54-a45d-22a8296fe10f","_uuid":"3d5afd9cc3dd7c32064a0a9d7e8449c984f56fde","collapsed":true},"cell_type":"code"},{"source":"`job_type` ought to be distilled into full-time, part-time, and other.","metadata":{"_cell_guid":"00d6da8c-c89c-4c2c-a791-eac8620c304d","_uuid":"9d0bc2dca16079c5320a80f4efc619d56ddac2f8"},"cell_type":"markdown"},{"execution_count":null,"outputs":[],"source":"jobs['job_type'] = jobs['job_type'].map(\n    lambda j: j if pd.isnull(j) else 'Full Time' if 'Full Time' in j else 'Part Time' if 'Part Time' in j else 'Other'\n)","metadata":{"_cell_guid":"a6a7b11b-cb39-4e22-83d1-10a15530b67a","_uuid":"2a00fb6d2afa9be16e00b86b5b71af2c9bde3118","collapsed":true},"cell_type":"code"},{"source":"## Types and sectors of jobs listed in Monster.com","metadata":{"_cell_guid":"7b4eebca-5f74-421f-a40e-d2a6fad2cae0","_uuid":"4694595c5260aa8bb137e668da0c6e65dc116988"},"cell_type":"markdown"},{"execution_count":null,"outputs":[],"source":"# Creating the plot.\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"white\")\n\nf, axarr = plt.subplots(1, 2, figsize=(12, 5))\nf.subplots_adjust(hspace=1)\nplt.suptitle('Monster Top 10 Jobs by...', fontsize=18)\n\nbar_kwargs = {'fontsize': 14, 'color': 'darkgray'}\n\njobs['organization'].value_counts().head(10).plot.bar(ax=axarr[0], **bar_kwargs,\n                                                      title='Industry Sector')\njobs['sector'].value_counts().head(10).plot.bar(ax=axarr[1], **bar_kwargs,\n                                                         title='Job Type')\n\nsns.despine()\n\nfor n in [0, 1]:\n    axarr[n].title.set_fontsize(16)\n    axarr[n].set_xticklabels(axarr[n].get_xticklabels(), \n                             rotation=45, ha='right', fontsize=14)","metadata":{"_cell_guid":"128e4f43-20ba-4973-a647-636973994b9c","_uuid":"5a1fa33589904f71c5fffc0eeeaf9b546e8db879","collapsed":true},"cell_type":"code"},{"source":"Healthcare services seems to make heavy use of Monster.com, as does Retail and a few others. Non-managerial experience seems to have an imposing presence on the platform, but that seems quite aspirational...\n\n## Median salaries\n\nSplitting between yearly and hourly pay rates, what are the salaries that are on tap?","metadata":{"_cell_guid":"daa5d188-5c72-42b8-8caa-be5aa05162e9","_uuid":"403f2b70178f328bfecd8796b6036e3704240b35"},"cell_type":"markdown"},{"execution_count":null,"outputs":[],"source":"f, axarr = plt.subplots(2, 1, figsize=(12, 8))\nf.subplots_adjust(hspace=1)\n\nbar_kwargs = {'fontsize': 14, 'color': 'darkgray'}\n\njobs = jobs.assign(\n    median_yearly_salary = jobs['yearly_salary_range'].map(\n        lambda r: (r[0] + r[1]) / 2 if pd.notnull(r) else r\n    ),\n    median_hourly_salary = jobs['hourly_salary_range'].map(\n        lambda r: (r[0] + r[1]) / 2 if pd.notnull(r) else r\n    )\n)\n\nsns.kdeplot(jobs[pd.notnull(jobs.median_yearly_salary)]['median_yearly_salary']\\\n                .where(lambda v: v < 200000), \n            ax=axarr[0]\n)\nsns.kdeplot(jobs[pd.notnull(jobs.hourly_salary_range)]['median_hourly_salary']\\\n                .where(lambda v: v < 100), \n            ax=axarr[1]\n)\n\naxarr[0].set_title(\"Median Yearly Salary Offered\", fontsize=16)\naxarr[1].set_title(\"Median Hourly Salary Offered\", fontsize=16)\n\nsns.despine()","metadata":{"_cell_guid":"e3cdaf31-bffc-401b-a1cb-cee55d284885","_uuid":"54eeb5bcd115f694afb27d75756c0102fb472761","collapsed":true},"cell_type":"code"},{"source":"The salaries on tap on Monster.com are probably below the US distribution, in my estimation. Are all of those `Experienced (Non-Manager)` jobs seem rather aspirational...\n\nTo dig in further, I would suggest you try breaking this data down by sector!","metadata":{"_cell_guid":"0aae097c-0243-46c7-bfa5-9414d00e0b60","_uuid":"d54fbb363f36ec56c2b9ec550ef8dff4f44d0377"},"cell_type":"markdown"},{"source":"## Summarizing job descriptions\n\nOf course the most important field in the dataset is the job descriptions. But the job descriptions tend to be very long, including a preppy, mostly useless bit about what the company does and why it's awesome. We can do better by slimming the document down to the most important sentences.\n\nThere are a bunch of different text summarization schemes for doing this sort of thing, but let's do a simple and fun one: sentence ranking. In this scheme, we will weigh each sentence by how recurrent non-stopwords in that sentence is: the most times it appears in the overall document, the more important the sentence in question is (stopwords are words like \"by\", \"if\", \"when\"). We average this by the length of the sentence to get the sentence's overall interestingness, and pick the `n` sentences with the highest score. Simple!\n\nThe following block of code implements this scheme. It uses the `nltk` library; you can see the original source, with documentation, [here](https://glowingpython.blogspot.com/2014/09/text-summarization-with-nltk.html).","metadata":{"_cell_guid":"6b463647-d30c-4f6f-8d36-91eee7cf784b","_uuid":"bfca24784524798ec295fd55457bda434077b0f9"},"cell_type":"markdown"},{"execution_count":null,"outputs":[],"source":"from nltk.tokenize import sent_tokenize,word_tokenize\nfrom nltk.corpus import stopwords\nfrom collections import defaultdict\nfrom string import punctuation\nfrom heapq import nlargest\n\nclass FrequencySummarizer:\n  def __init__(self, min_cut=0.1, max_cut=0.9):\n    \"\"\"\n     Initilize the text summarizer.\n     Words that have a frequency term lower than min_cut \n     or higer than max_cut will be ignored.\n    \"\"\"\n    self._min_cut = min_cut\n    self._max_cut = max_cut \n    self._stopwords = set(stopwords.words('english') + list(punctuation))\n\n  def _compute_frequencies(self, word_sent):\n    \"\"\" \n      Compute the frequency of each of word.\n      Input: \n       word_sent, a list of sentences already tokenized.\n      Output: \n       freq, a dictionary where freq[w] is the frequency of w.\n    \"\"\"\n    freq = defaultdict(int)\n    for s in word_sent:\n      for word in s:\n        if word not in self._stopwords:\n          freq[word] += 1\n    # frequencies normalization and fitering\n    m = float(max(freq.values()))\n    for w in list(freq.keys()):\n      freq[w] = freq[w]/m\n      if freq[w] >= self._max_cut or freq[w] <= self._min_cut:\n        del freq[w]\n    return freq\n\n  def summarize(self, text, n):\n    \"\"\"\n      Return a list of n sentences \n      which represent the summary of text.\n    \"\"\"\n    sents = sent_tokenize(text)\n    \n    try:\n        assert n <= len(sents)\n    except AssertionError:\n        return \"\"\n        \n    word_sent = [word_tokenize(s.lower()) for s in sents]\n    self._freq = self._compute_frequencies(word_sent)\n    ranking = defaultdict(int)\n    for i,sent in enumerate(word_sent):\n      for w in sent:\n        if w in self._freq:\n          ranking[i] += self._freq[w]\n    sents_idx = self._rank(ranking, n)    \n    return [sents[j] for j in sents_idx]\n\n  def _rank(self, ranking, n):\n    \"\"\" return the first n sentences with highest ranking \"\"\"\n    return nlargest(n, ranking, key=ranking.get)","metadata":{"_cell_guid":"e4346f4c-e26f-4422-830e-bd23ee03c1e4","_uuid":"5dce5c3c438451365f143948ee6b08484b2f93c6","collapsed":true},"cell_type":"code"},{"source":"Unfortunately the corpus of descriptions is pretty badly formatted, and the sentences in this document are obnoxiously long.  Still, applying this technique can show up something interesting about the kinds of words that matter in a job description.","metadata":{"_cell_guid":"79fab73a-e823-4fcb-80ac-b544f71d6027","_uuid":"4880c780a50dcf6512c307a224601ccbe75d3804"},"cell_type":"markdown"},{"execution_count":null,"outputs":[],"source":"\" \".join(FrequencySummarizer().summarize(\n    jobs.iloc[0].job_description.replace(\".\", \". \").replace(\"•\", \" \"), 2)\n)","metadata":{"_cell_guid":"a686c29a-4988-4571-8163-fe62aafb7a09","_uuid":"a7efda816141509de8c7771aaeaa71afeb0bd9d3","collapsed":true},"cell_type":"code"},{"execution_count":null,"outputs":[],"source":"stops = set(stopwords.words('english') + list(punctuation))","metadata":{"_cell_guid":"3efcb56f-cb98-40fd-9830-2d34a885b749","_uuid":"b1ad82402ec1f0d65b32468cc6499bde75bf54da","collapsed":true},"cell_type":"code"},{"execution_count":null,"outputs":[],"source":"summary_words = jobs.head(1000).job_description.map(lambda desc: set(\n    word_tokenize(\n        \" \".join(\n            FrequencySummarizer().summarize(desc.replace(\".\", \". \").replace(\"•\", \" \"), 2)\n        )\n    )\n) - stops\n                                                     )\nimport itertools\n# non_summary = pd.Series(list(itertools.chain.from_iterable(non_summary_words.values)))\nsummary = pd.Series(list(itertools.chain.from_iterable(summary_words.values)))","metadata":{"_cell_guid":"fae9f188-8ed4-4b77-b62f-864c49136123","_uuid":"ee61416d16c598e97ab503f704f68864be3616cf","collapsed":true},"cell_type":"code"},{"execution_count":null,"outputs":[],"source":"import seaborn as sns\nsns.set_style(\"white\")\n\n(summary\n     .value_counts(ascending=False)\n     .head(12)\n     .drop(['Qualifications', 'meet', 'including'])\n     .plot.bar(fontsize=16, figsize=(14, 6)))\nplt.gcf().suptitle('Top 10 Most Occurent Important Words in Job Descriptions', fontsize=20)","metadata":{"_cell_guid":"4ce5af1c-c1ae-4263-97df-703cb725e07b","_uuid":"4e385312b64c4e2061900e28fcb44b73cfe9bb91","collapsed":true},"cell_type":"code"},{"source":"## Further inquiry\n\nThat's all for here folks!\n\nTry applying more cleaning and more (and more sophisticated!) NLP techniques to the job descriptions in this dataset. What further can you learn about the US job market by seeing what comes up on Monster.com?","metadata":{},"cell_type":"markdown"}],"nbformat_minor":1,"nbformat":4,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"mimetype":"text/x-python","pygments_lexer":"ipython3","file_extension":".py","version":"3.6.1","nbconvert_exporter":"python","name":"python","codemirror_mode":{"name":"ipython","version":3}}}}