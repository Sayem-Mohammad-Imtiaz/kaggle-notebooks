{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport time\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle \nimport pprint\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#from sklearn.cluster import DBSCAN, KMeans, OPTICS, SpectralClustering\nfrom sklearn.cluster import  KMeans,  SpectralClustering # DBSCAN, OPTICS,\nimport umap\nimport numpy as np\nfrom sklearn.neighbors import kneighbors_graph\nfrom scipy.sparse.csgraph import minimum_spanning_tree\nfrom sklearn.decomposition import PCA\n\ndef create_tree_by_cluster_knn_mst(X, n_clusters='sqrt', n_neighbors= 10,   verbose =  0, clustering_method = 'Kmeans' ):\n  '''\n  # Calcuates a tree approximation for given dataset X, by kmeans+knn+mst\n  # \n  #' @param n_clusters number of clusters for clustering or 'sqrt' - square root of dataset size\n  #' @param n_neighbors used by knn-graph step\n  #\n  #' @return\n  # dict_result - dictionary with results:\n  #   dict_result['csr_mst'] # adjancy matrix of MST graph in csr format (column sparse matrix - scipy )\n  #   dict_result['edges_mst'] # edges matrix of MST graph, shape = n_nodes X 2 , each row contains ends of the correspoding edges\n  #   dict_result['nodes_positions']  graph nodes positions\n  #   dict_result['predicted_clusters'] vector with cluster number for each point of  input X\n  #   dict_result['csr_knn'] same as 'csr_mst', but for intermediate knn-graph  \n  #   dict_result['edges_knn'] same as 'edges_mst', but for intermediate knn-graph \n  # \n  #' @examples\n  # X = np.random.rand(1000,10)\n  # dict_result =  create_tree_by_cluster_knn_mst(X)# - Calcuates a tree for given dataset, by kmeans+knn+mst\n  # edges =  dict_result['edges_mst']\n  # nodes_positions = dict_result['nodes_positions']\n  # plot_graph(edges, nodes_positions, data = X)\n  # plt.show()  \n  '''\n  if n_clusters == 'sqrt':\n    n_clusters = int( np.sqrt(X.shape[0] ) ) \n\n  #print(\"clustering_method.lower() == 'Spectral'.lower()\", clustering_method.lower() == 'Spectral'.lower() )\n  if isinstance(clustering_method ,str) and ( clustering_method.lower() == 'Spectral'.lower() ):\n    clustering = SpectralClustering(n_clusters=n_clusters, random_state=0).fit(X)\n    predicted_clusters = clustering.labels_ # kmeans.predict(X)\n    # Get cluster centers by averaging:\n    l = len(np.unique(predicted_clusters))\n    cluster_centers_ = np.zeros( (l, X.shape[1]))\n    for i,v in  enumerate(np.unique(predicted_clusters)):\n      m = predicted_clusters==v \n      cluster_centers_[i,:] = np.mean(X[m,:],axis = 0 )\n  else: # Kmeans clustering by defualt:\n    clustering = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n    cluster_centers_ = clustering.cluster_centers_\n  predicted_clusters = clustering.labels_ # kmeans.predict(X)\n\n  if verbose >= 100:\n    print('cluster_centers_[:2,:]', cluster_centers_[:2,:])\n    print('predicted_clusters.shape', predicted_clusters.shape)\n    print('predicted_clusters[:2]', predicted_clusters[:2])\n\n  # sklearn.neighbors.kneighbors_graph(X, n_neighbors, mode='connectivity', metric='minkowski', p=2, metric_params=None, include_self=False, n_jobs=None)[source]Â¶\n  if n_neighbors > len(cluster_centers_):\n    n_neighbors = len(cluster_centers_) # To avoid exception for small number of clusters \n  csr_knn = kneighbors_graph(cluster_centers_, n_neighbors= n_neighbors, mode= 'distance', include_self=True) # mode=  'connectivity'\n  if verbose >= 100:\n    print('csr_knn', type(csr_knn), csr_knn.shape)\n\n  csr_mst = minimum_spanning_tree(csr_knn)\n  if verbose >= 100:\n    print('csr_mst', type(csr_mst),csr_mst.shape)\n\n  dict_result = {}\n  dict_result['csr_mst'] = csr_mst\n  dict_result['csr_knn'] = csr_knn\n  dict_result['nodes_positions'] = cluster_centers_\n  dict_result['predicted_clusters'] = predicted_clusters\n  dict_result['edges_mst'] = get_edges_from_adj_matrix( csr_mst )\n  dict_result['edges_knn'] = get_edges_from_adj_matrix( csr_knn )\n\n  return dict_result\n\ndef get_edges_from_adj_matrix( adj_matrix ):\n  '''\n  #' From adjacency matrix construct an edge list\n  #' either [k1,k2]!=0 or [k2,k1]!=0, causes edge (k1,k2)\n  #'\n  #' @param  adj_matrix - adjacency matrix of an unoriented graph\n  #'\n  #' @return numpy.ndarray of shape Nx2, containing vertices for each edge \n  #'    \n  #' @examples\n  #' adj_matrix = np.array([[0,1,1],[0,0,0],[0,2,0]])\n  #' edges = get_edges_from_adj_matrix( adj_matrix )\n  '''\n  list_edges = []\n  n_vertex = adj_matrix.shape[0]\n  for k1 in range(  n_vertex  ) :\n    for k2 in range(k1, n_vertex ) :\n      if ( adj_matrix[k1,k2] != 0) or (adj_matrix[k2,k1] != 0):\n          list_edges.append( (k1,k2) )\n  return np.array(list_edges)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\ntry :\n    import umap\nexcept:\n    print('cannot import umap')\n\ndef plot_graph(edges, nodes_positions, data = None, dim_reduction = 'PCA', graph_color = 'black', graph_linewidth=2, \n               plot_data = True, data_linewidth = 1,  data_color = 'tab:red', data_transparency_alpha = 0.9,\n               umap_n_neighbors = 50, umap_min_dist = 0.99):\n  '''\n  #' Plots graphs defined by edges and nodes_positions, optionally - scatter plot the \"data\" on the same plot,\n  #' Optionally performs PCA/etc (depending on dim_reduction)\n  #'\n  #' @param edges Nx2-shape matrix with edges ends, i.e. edges[k,0], edges[k,1] - ends of k-th edge  \n  #' @param nodes_positions  matrix of nodes positions \n  #' @param data  \"original dataset\", basically arbitrary dataset for scatter plot, it should have same shape[1] as nodes_positions\n  #' @param plot_data  True/False - to scatterplot or not data\n  #' @param dim_reduction  'PCA', 'plot_first2axis', 'umap'\n  #' @param data_color can be a vector or predefined color - argument for c = data_color in scatter\n\n  #' @examples\n  # edges = np.array([ [0,1],[1,2],[2,0] ] )\n  # nodes_positions = np.random.rand(3,10) # 3 points in 10d space\n  # plot_graph(edges, nodes_positions)\n  #\n  # t = elpigraph_output\n  # edges = t[0]['Edges'][0]\n  # nodes_positions = t[0]['NodePositions']\n  # plot_graph(edges, nodes_positions)\n  '''\n  str_dim_reduction = dim_reduction\n  if dim_reduction in ['PCA', 'umap' ]: #  not 'plot_first2axis':\n    if dim_reduction.upper() == 'PCA':\n      reducer = PCA()\n    elif dim_reduction.lower() == 'umap':\n      n_neighbors = umap_n_neighbors#  50\n      min_dist= umap_min_dist # 0.99\n      #n_components=n_components\n      reducer = umap.UMAP( n_neighbors=n_neighbors,        min_dist=min_dist, n_components = 2)\n\n    if data is not None:\n      data2 = reducer.fit_transform(data)\n      if plot_data == True:\n        if data_color is None:\n          plt.scatter(data2[:,0],data2[:,1], linewidth = data_linewidth , alpha = data_transparency_alpha)# ,cmap=plt.cm.Paired) # ,c=np.array(irx) \n          plt.xlabel(str_dim_reduction+'1')\n          plt.ylabel(str_dim_reduction+'2')\n        else:\n          plt.scatter(data2[:,0],data2[:,1] ,cmap=plt.cm.Paired,c= data_color, linewidth = data_linewidth, alpha = data_transparency_alpha ) \n          plt.xlabel(str_dim_reduction+'1')\n          plt.ylabel(str_dim_reduction+'2')\n    else:\n      reducer.fit(nodes_positions)\n\n    nodes_positions2 = reducer.transform( nodes_positions )\n  else:\n    if plot_data == True:\n      if data is not None:\n        if data_color is None:\n          plt.scatter(data[:,0],data[:,1] , linewidth = linewidth, alpha = data_transparency_alpha )# ,cmap=plt.cm.Paired) # ,c=np.array(irx) \n        else:\n          plt.scatter(data[:,0],data[:,1] ,cmap=plt.cm.Paired,c= data_color , linewidth = data_linewidth, alpha = data_transparency_alpha ) \n    nodes_positions2 = nodes_positions\n\n  plt.scatter(nodes_positions2[:,0],nodes_positions2[:,1],c = graph_color, linewidth = graph_linewidth)#, cmap=plt.cm.Paired)\n\n  edgeCount = edges.shape[0]\n  for k in range(edgeCount):\n    n0 = edges[k,0]\n    n1 = edges[k,1]\n    x_line = [ nodes_positions2[n0,0],  nodes_positions2[n1,0] ]\n    y_line = [ nodes_positions2[n0,1],  nodes_positions2[n1,1] ]\n    plt.plot(x_line, y_line, graph_color, linewidth = graph_linewidth) # 'black')\n\n    \nedges = np.array([ [0,1],[1,2],[2,0] ] )\nnodes_positions = np.random.rand(3,10) # 3 points in 10d space\nplot_graph(edges, nodes_positions)    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Examples of MST trajectories on different dataset "},{"metadata":{},"cell_type":"markdown","source":"## Random uniform data in various dimensions"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20, 6))\nn_subplots_x = 3\nc = 0\n\nfor dim in [2,3,100]:\n    c+=1; fig.add_subplot(1, n_subplots_x , c) \n    X = np.random.rand(1000,dim )\n    dict_result =  create_tree_by_cluster_knn_mst(X)# - Calcuates a tree for given dataset, by kmeans+knn+mst\n    edges =  dict_result['edges_mst']\n    nodes_positions = dict_result['nodes_positions']\n    plot_graph(edges, nodes_positions, data = X, dim_reduction = 'PCA', data_transparency_alpha = 0.3 )\n    plt.title('MST trajectories for: data - random uniform points in '+str(dim)+' dims')\n\nplt.show()  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dumbell like data - tree 5 edges 2 branch points"},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_dumbbell(n_layers = 1, n_features = 2,  sigma_noise = 10.0, n_samples4base = 200,\n                  n_samples4branches = [100,100,100,100] , angles = [np.pi/4,-np.pi/4,3*np.pi/4,-3*np.pi/4] ):\n  '''\n  '''\n\n  \"\"\"\n  n_layers = 2\n  n_features = 2\n  sigma_noise = 10.0\n  plot_mode = 'PCA'\n  n_samples4base = 200\n  n_samples4branches = [100,100,100,100]\n  angles = [np.pi/4,-np.pi/4,3*np.pi/4,-3*np.pi/4]\n  \"\"\"\n\n  X_noiseless = np.zeros( (0,n_features))\n  y_final = np.zeros( 0 )\n  for layer in range(n_layers):\n    current_label = 0 \n    X = np.zeros( (n_samples4base, n_features) )\n    X[:,0] = np.arange(n_samples4base)\n    y = current_label * np.ones( n_samples4base )\n    v_last_base_point_save = X[-1,:].copy()\n    v_first_base_point_save = X[0,:].copy()\n\n    # Make branches\n    n_branches = len ( n_samples4branches )\n    for c_branch in range( n_branches ) : # n_branches\n      n_sample4branch = n_samples4branches[c_branch]\n      current_label += 1\n      y_branch = current_label * np.ones( n_sample4branch )\n      angle = angles[c_branch] \n      if c_branch < n_branches/ 2:\n        v_initial = v_last_base_point_save\n      else:\n        v_initial = v_first_base_point_save  \n      X_branch = np.zeros( (n_sample4branch,  n_features)  ) #  [:2] = (np.cos(angle), np.sin(angle) )  \n      v_direction = np.zeros( n_features)\n      v_direction[0] = np.cos(angle)\n      v_direction[1] = np.sin(angle)\n      X_branch += v_direction # Broadcast vector to the whole array over axis 0 \n      X_branch *= np.arange( 1, X_branch.shape[0] +1 ).reshape(X_branch.shape[0], 1 ) # Broadcast - mutiply each column by  by column = 1,2,3, ... \n      X_branch += v_initial # \n      X = np.concatenate( (X,X_branch) , axis = 0 )\n      y = np.concatenate( (y, y_branch ))\n    X_noiseless = np.concatenate( (X_noiseless,X) , axis = 0 )\n    y_final = np.concatenate( (y_final,y) ) \n    \n  X_noisy = X_noiseless + sigma_noise * np.random.randn( X_noiseless.shape[0], X_noiseless.shape[1] )\n\n\n  y = y_final\n  X = X_noisy\n\n  if 0:\n    print(X.shape, y.shape)\n    r = X_noisy\n    plt.scatter(r[:,0],r[:,1], c =y)\n    plt.show()\n  \n  return X,y\n\nX,y = make_dumbbell(n_layers = 1, n_features = 2,  sigma_noise = 10.0, n_samples4base = 200,\n                  n_samples4branches = [100,100,100,100] , angles = [np.pi/4,-np.pi/4,3*np.pi/4,-3*np.pi/4] )\nif 1:\n  print(X.shape, y.shape)\n  r = X\n  plt.scatter(r[:,0],r[:,1], c =y)\n  plt.axis(\"equal\")\n  plt.grid()\n  plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X,y = make_dumbbell(n_layers = 1, n_features = 2,  sigma_noise = 10.0, n_samples4base = 200,\n                  n_samples4branches = [100,100,100,100] , angles = [np.pi/4,-np.pi/4,3*np.pi/4,-3*np.pi/4] )\n\nfig = plt.figure(figsize=(20, 6))\nc = 0\nlist_nodes_number =[20,40,60,100 ] #  [2,3,4,5,6,7,8,9,10,20,30,40,50, 60, 100, 200 ]\nn_subplots_x = len(list_nodes_number)\n\nfor nodes_number in list_nodes_number:\n    c+=1; fig.add_subplot(1, 4 , c ) \n    dict_result =  create_tree_by_cluster_knn_mst(X, n_clusters= nodes_number )# - Calcuates a tree for given dataset, by kmeans+knn+mst\n    edges =  dict_result['edges_mst']\n    nodes_positions = dict_result['nodes_positions']\n    plot_graph(edges, nodes_positions, data = X, dim_reduction = 'plot_first2axis', data_transparency_alpha = 0.3 , data_color = y)\n    plt.title('MST trajectories with '+str(nodes_number)+' nodes')\n    if (c%4 == 0) :\n        plt.show() \n        fig = plt.figure(figsize=(20, 6))\n        c = 0\n         \n        \nplt.show()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X,y = make_dumbbell(n_layers = 1, n_features = 2,  sigma_noise = 10.0, n_samples4base = 200,\n                  n_samples4branches = [100,100,100,100] , angles = [np.pi/4,-np.pi/4,3*np.pi/4,-3*np.pi/4] )\n\nfig = plt.figure(figsize=(20, 6))\nc = 0\nlist_nodes_number = [2,3,4,5,6,7,8,9,10,20,30,40,50, 60, 100, 200 ]\nn_subplots_x = len(list_nodes_number)\n\nfor nodes_number in list_nodes_number:\n    c+=1; fig.add_subplot(1, 4 , c ) \n    dict_result =  create_tree_by_cluster_knn_mst(X, n_clusters= nodes_number )# - Calcuates a tree for given dataset, by kmeans+knn+mst\n    edges =  dict_result['edges_mst']\n    nodes_positions = dict_result['nodes_positions']\n    plot_graph(edges, nodes_positions, data = X, dim_reduction = 'plot_first2axis', data_transparency_alpha = 0.3 , data_color = y)\n    plt.title('MST trajectories with '+str(nodes_number)+' nodes')\n    if (c%4 == 0) :\n        plt.show() \n        fig = plt.figure(figsize=(20, 6))\n        c = 0\n         \n        \nplt.show()  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tree like - 7 edges 3 branch points"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import  PCA\n\ntry:\n    import umap \nexcept:\n    print('cannot import umap - do not use plot_mode = \"umap\"')\n\ndef make_multi_level_fork(n_teeth = 2, len_tooth=100,\n        n_components = 2, n_levels_of_branching = 2, inertia_coef = 0, \n        sigma_noise = 10.0,  teeth_start_distance = 0,  plot_mode = 'PCA',\n        step_from_previous_branch = 0 , return_X_y = True ): \n  '''\n  Returns numpy array containing image for multi-teeth fork,\n  its shape is (len_tooth*(n_teeth+1) , 2  ) , \n  output y  - contains labels, which is teath number and zero for base of the fork\n  \n  @examples\n  X = make_multi_level_fork()\n  X = makemake_multi_level_fork_fork(n_teeth = 3, plot_mode = 'PCA' )\n  '''\n\n  \"\"\"\n  n_components = 5\n  n_levels_of_branching = 2\n  inertia_coef = 0\n  n_teeth = 2\n  len_tooth=100 \n  tangent_step_between_teeth = 1 \n  sigma_noise = 20.0\n  teeth_start_distance = 0  \n  plot_mode = 'PCA'\n  \"\"\"\n\n  ## Prepare output variable - it is outputed if return_X_y = False and dicitionary is returned\n  list_branch_points = []\n\n  ################################################################################################\n  # Prepare the \"hand of fork\" - the first branch which goes i*(1,0,0...0)+noise\n  ################################################################################################\n  current_label = 0\n  n = len_tooth\n  X = sigma_noise* np.random.randn(n, n_components) #np.zeros((n,n_components))\n  X[:,0] = X[:,0] + np.arange(n)\n  y = np.ones(n) * current_label\n  current_label += 1\n  X_final = X.copy()\n  y_final = y.copy()\n\n  ################################################################################################\n  # Intialize \"previous step\" datum for main loop\n  ################################################################################################\n  last_point_of_previous_branch = np.zeros(n_components)\n  last_point_of_previous_branch[0] = n-1  \n  list_branch_points.append( last_point_of_previous_branch   )\n  direction_vector = np.zeros(n_components)\n  direction_vector[0] = 1\n\n  list_last_point_of_previous_branch = []\n  list_last_point_of_previous_branch.append( last_point_of_previous_branch  )\n  list_previous_direction_vector = []\n  list_previous_direction_vector.append( direction_vector  )\n\n  new_list_last_point_of_previous_branch = [] \n  new_list_previous_direction_vector = []\n\n  ################################################################################################\n  # Main loop\n  ################################################################################################\n  for current_level in range(1,n_levels_of_branching):\n    for i,last_point_of_previous_branch in enumerate(list_last_point_of_previous_branch):\n      previous_direction_vector = list_previous_direction_vector[i]\n      for teeth in range( int(n_teeth) ):# range( int(n_teeth/2)+1):\n        v = np.random.randn(n_components)\n        v = v / np.sqrt( np.sum(v**2) ) # Normilize\n        v = v + inertia_coef*previous_direction_vector\n        v = v / np.sqrt( np.sum(v**2) ) # Normilize\n\n        X = np.zeros( (n, n_components) )\n        X[0,:] = last_point_of_previous_branch + v + v*step_from_previous_branch\n        for i in range(1, X.shape[0]):\n          X[i,:] += X[i-1,:] + v\n\n        new_list_last_point_of_previous_branch.append(  X[n-1, :] )\n        if current_level < n_levels_of_branching - 1: # Last level is end , not branching\n          list_branch_points.append( X[n-1, :]   )\n        new_list_previous_direction_vector.append(v)\n\n        X += sigma_noise* np.random.randn(n, n_components) #np.zeros((n,n_components))\n        y = np.ones(n) * current_label\n        current_label += 1\n\n        X_final = np.concatenate((X_final,X), axis = 0)\n        y_final = np.concatenate( (y_final, y) )\n\n    list_last_point_of_previous_branch = new_list_last_point_of_previous_branch.copy() # n_levels_of_branching\n    new_list_last_point_of_previous_branch = []\n    list_previous_direction_vector = new_list_previous_direction_vector.copy()\n    new_list_previous_direction_vector = []\n\n  X = X_final\n  y = y_final\n\n  ################################################################################################\n  # Plotters\n  ################################################################################################\n  if isinstance(plot_mode, str) and (plot_mode.lower() in ['pca'] ):\n    try:\n      from sklearn.decomposition import  PCA\n      r = PCA().fit_transform(X)\n      print(X.shape,'shape of output array X.', y.shape, 'shape of output y' )\n      plt.scatter(r[:,0],r[:,1], c = y, cmap= plt.cm.Paired )  # cmp = 'viridis'\n      plt.axis(\"equal\")\n      plt.xlabel('PCA1')\n      plt.ylabel('PCA2')\n      plt.grid()\n      #plt.show()\n    except:\n      print('Exception - cannot plot PCA')\n  elif isinstance(plot_mode, str) and (plot_mode.lower() in ['first_two_components'] ):\n    print(X.shape,'shape of output array X.', y.shape, 'shape of output y' )\n    plt.scatter(X[:,0],X[:,1], c = y, cmap= plt.cm.Paired )  # cmp = 'viridis'\n    plt.axis(\"equal\")\n    plt.grid()\n    #plt.show()\n  elif isinstance(plot_mode, str) and (plot_mode.lower() in ['umap'] ):\n    try:\n      import umap\n      r = umap.UMAP().fit_transform(X)\n      print(X.shape,'shape of output array X.', y.shape, 'shape of output y' )\n      plt.scatter(r[:,0],r[:,1], c = y, cmap= plt.cm.Paired )  # cmp = 'viridis'\n      plt.axis(\"equal\")\n      plt.xlabel('UMAP1')\n      plt.ylabel('UMAP2')\n      plt.grid()\n      #plt.show()\n    except:\n      print('Exception - cannot plot umap')\n  elif isinstance(plot_mode, str) and (plot_mode.lower() in ['tsne'] ):\n    try:\n      from sklearn.manifold import TSNE\n      r = TSNE().fit_transform(X)\n      print(X.shape,'shape of output array X.', y.shape, 'shape of output y' )\n      plt.scatter(r[:,0],r[:,1], c = y, cmap= plt.cm.Paired )  # cmp = 'viridis'\n      plt.axis(\"equal\")\n      plt.grid()\n      #plt.show()\n    except:\n      print('Exception - cannot plot TSNE')\n\n  if return_X_y == True:\n    return X,y\n  else: # return \"data\" dictionary similar to sklearn load_iris, load_digits ... \n    data = {}\n    data['data'] = X\n    data['target'] = y\n    data['DESCR'] = 'multi level fork'\n    data['branch points'] = np.array( list_branch_points )\n    return data\n\n#####################################################################################\n# First (simple ) use example \n#####################################################################################\n\nX, y = make_multi_level_fork(sigma_noise = 5.0, len_tooth=150, n_components = 20, n_levels_of_branching = 3,\n                                  inertia_coef = 0, step_from_previous_branch = 0, plot_mode = 'PCA') # 'PCA'\nprint(X.shape, y.shape)\n\n\n#####################################################################################\n# Second use example - show branch points \n#####################################################################################\n\ndata = make_multi_level_fork(sigma_noise = 1.0, len_tooth=150, n_components = 2, n_levels_of_branching = 3,\n                                  inertia_coef = 1, step_from_previous_branch = 0, plot_mode = None, return_X_y = False) # 'PCA'\nX = data['data']\ny = data['target']\nbranch_points =  data['branch points']\nprint( branch_points )\nif 1:\n  r = X\n  plt.figure()\n  plt.scatter(r[:,0],r[:,1], c =y)\n  for i in range(branch_points.shape[0]):\n    p = branch_points[i,:]\n    plt.scatter( p[0],p[1]  , c = 'red')\n  plt.title('Showing branch points')\n  plt.axis(\"equal\")  \n  plt.grid()\n  plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tree like - 3 edges 1 branch point"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfig = plt.figure(figsize=(20, 6))\nc = 0\nlist_sigma_noise = [2,10, 20 ,30  ]\nn_subplots_x = len(list_sigma_noise)\n\nfor sigma_noise in list_sigma_noise:\n    c+=1; fig.add_subplot(1, 4 , c ) \n    X,y = make_multi_level_fork(sigma_noise = sigma_noise, len_tooth=150, n_components = 2, n_levels_of_branching = 3,\n                                  inertia_coef = 1, step_from_previous_branch = 0, plot_mode = None, return_X_y = True) \n    \n    dict_result =  create_tree_by_cluster_knn_mst(X)# , n_clusters= nodes_number )# - Calcuates a tree for given dataset, by kmeans+knn+mst\n    edges =  dict_result['edges_mst']\n    nodes_positions = dict_result['nodes_positions']\n    plot_graph(edges, nodes_positions, data = X, dim_reduction = 'plot_first2axis', data_transparency_alpha = 0.3 , data_color = y)\n    plt.title('MST trajectories \\n data: tree with 7 edges with noise sigma: '+str(sigma_noise) )\n    if (c%4 == 0) :\n        plt.show() \n        fig = plt.figure(figsize=(20, 6))\n        c = 0\n         \n        \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20, 6))\nc = 0\nlist_sigma_noise = [2,10, 20 ,30  ]\nn_subplots_x = len(list_sigma_noise)\n\nfor sigma_noise in list_sigma_noise:\n    c+=1; fig.add_subplot(1, 4 , c ) \n    X,y = make_multi_level_fork(sigma_noise = sigma_noise, len_tooth=150, n_components = 2, n_levels_of_branching = 2,\n                                  inertia_coef = 1, step_from_previous_branch = 0, plot_mode = None, return_X_y = True) \n    \n    dict_result =  create_tree_by_cluster_knn_mst(X)# , n_clusters= nodes_number )# - Calcuates a tree for given dataset, by kmeans+knn+mst\n    edges =  dict_result['edges_mst']\n    nodes_positions = dict_result['nodes_positions']\n    plot_graph(edges, nodes_positions, data = X, dim_reduction = 'plot_first2axis', data_transparency_alpha = 0.3 , data_color = y)\n    plt.title('MST trajectories \\n data: tree with 7 edges with noise sigma: '+str(sigma_noise) )\n    if (c%4 == 0) :\n        plt.show() \n        fig = plt.figure(figsize=(20, 6))\n        c = 0\n         \n        \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}