{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\ndata_train = pd.read_csv('../input/titanic/train.csv')\ndata_test = pd.read_csv('../input/titanic/test.csv')\ndata_gen = pd.read_csv('../input/titanic/gender_submission.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train = data_train.merge(data_gen, on='PassengerId', how = 'left')\ndata_train = data_train.drop('Survived_y', axis = 1)\ndata_train = data_train.drop('Name', axis = 1)\ndata_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_test = data_test.drop('Name', axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train.Age.fillna(round(data_train.Age.mean()), inplace = True)\ndata_test.Age.fillna(round(data_train.Age.mean()), inplace = True)\ndata_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train = pd.concat(\n    [\n        data_train,\n        pd.get_dummies(data_train[\"Embarked\"], prefix=\"Embarked\"),\n        pd.get_dummies(data_train[\"Sex\"], prefix=\"Sex\"),\n    ],\n    axis=1,\n)\ndata_test = pd.concat(\n    [\n        data_test,\n        pd.get_dummies(data_test[\"Embarked\"], prefix=\"Embarked\"),\n        pd.get_dummies(data_test[\"Sex\"], prefix=\"Sex\"),\n    ],\n    axis=1,\n)\ndata_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train = data_train.drop(['Embarked','Embarked_C','Embarked_Q', 'Sex','Ticket','Sex_male', 'Cabin'], axis = 1)\ndata_test = data_test.drop(['Embarked','Embarked_C','Embarked_Q', 'Sex','Ticket','Sex_male', 'Cabin'], axis = 1)\ndata_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_test.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data_train.drop('Survived_x', axis=1), data_train.Survived_x, train_size = 0.8, random_state = 322)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {'max_depth':7, #глубина деревьев\n    'boosting_type': 'gbdt', #модель для бустинга, в данном случае - gradient bosting decision tree\n    'objective': 'binary', #задача\n    'metric': ['auc'], #метрика качества\n    'learning_rate': 0.07, #\n     'seed': 322}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_train = lgb.Dataset(X_train, y_train)\nlgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbm = lgb.train(params, lgb_train,\n    num_boost_round=1000,\n    valid_sets=[lgb_train, lgb_eval],\n    early_stopping_rounds=75)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_titanic_prediction = gbm.predict(data_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ttp = []\nfor i in train_titanic_prediction:\n    if i < 0.5:\n        ttp.append(0)\n    else:\n        ttp.append(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_test['Survived'] = ttp\ndata_test = data_test.drop(['Pclass','Age','SibSp','Parch','Fare','Embarked_S','Sex_female'], axis = 1)\ndata_test.to_csv('./file1.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Анекдот для тех, кто досмотрел решение до конца (и учит пендосский):\n— Эй, зачем ты пьешь эту грязную воду с озера, со всей деревни говносток сюда выходит!\n— Whаt did уou sау?\n— Я говорю: двумя руками черпай!","metadata":{}},{"cell_type":"markdown","source":"И еще немного актуалочки: Сидят два программиста в кафе. Мимо идет шикарная телка. — Классные у нее properties, — говорит один. — Вчера проверял... Все read only, — с грустью отвечает другой.","metadata":{}}]}