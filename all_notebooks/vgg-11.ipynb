{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nprint(os.getcwd()) \nprint(os.listdir(os.getcwd()))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%writefile setting.py\n# 样本图片目录\nimport os\n\nSAMPLE_FILE_PATH = \"../input/face-data/icml_face_data.csv\"\nprint(SAMPLE_FILE_PATH)\n\n# 分类数量\nNUM_CLASSES = 7  \n\nTRAIN_HDF5 = \"./train.hdf5\"\nVAL_HDF5 = \"./val.hdf5\"\nTEST_HDF5 = \"./test.hdf5\"\n\n# 每批次样本数量\nBATCH_SIZE = 128\n\n# 项目输出文件保存目录\nOUTPUT_PATH = \"./\"\n\n# 数据集样本RGB平均值存位置及文件名称\nDATASET_MEAN_FILE = OUTPUT_PATH + \"/rgb_mean.json\"\n\n# 模型保存位置及文件名称\nMODEL_FILE =  \"./model.h5\"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# %%writefile EpochCheckpoint.py\nimport os\nfrom tensorflow.keras.callbacks import Callback\n\n\n# 模型存盘检查点，每训练5趟保存一次模型\nclass EpochCheckpoint(Callback):\n    def __init__(self, output_path, every=5, start_at=0):\n        # 调用父类的构造函数\n        super(Callback, self).__init__()\n        self.output_path = output_path  # 模型保存目录\n        # 间隔趟数\n        self.every = every\n        # 起始趟数（当前趟数）\n        self.start_epoch = start_at\n\n    def on_epoch_end(self, epoch, logs={}):\n        # 检查是否要向磁盘保存模型\n        if (self.start_epoch + 1) % self.every == 0:\n            p = os.path.sep.join([self.output_path,\n                                  \"epoch_{}.hdf5\".format(self.start_epoch + 1)])\n            self.model.save(p, overwrite=True)\n        # 增加内部的趟数计数器\n        self.start_epoch += 1\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ***EpochCheckpoint***","metadata":{}},{"cell_type":"code","source":"# %%writefile ImageToArrayPreprocessor.py\n# 图像样本维度重置预处理器\nfrom tensorflow.keras.preprocessing.image import img_to_array\n\n# 定义ImageToArrayPreprocessor类\nclass ImageToArrayPreprocessor:\n    def __init__(self, data_format=None):\n        # 保存图像数据的格式\n        self.data_format = data_format\n\n    def preprocess(self, image):\n        \"\"\"\n        重置图像image的维度\n        :param image: 要预处理的图像\n        :return: 维度重置后的图像\n        \"\"\"\n\n        # 调用tensorflow.keras的img_to_array方法正确重置图像的维度\n        return img_to_array(image, data_format=self.data_format)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%writefile HDF5DatasetWriter.py\n# 定义HDF5DatasetWriter类\nimport os\nimport h5py\n\n# HDF5数据集生成器\nclass HDF5DatasetWriter:\n\n    # dims参数用来控制将要保存到数据集中的数据维度，类似于numpy数组的shape\n    # 如果我们要保存扁平化的28×28 = 784 MNIST数据集原始像素数据，则dims = (70000，784)，\n    # 因为NNIST数据集共有70000个样本，每个样本的维度是784。\n    # 如果我们要存储原始CIFAR-10图像，则dims = (60000，32，32，3)\n    # 因为CIFAR-10数据集共有60000图像，每个样本表示为一个 32×32×3 RGB图像。\n\n    def __init__(self, dims, output_path, data_key=\"images\", buf_size=1000):\n        \"\"\"\n\n        :param dims: 用来控制将要保存到数据集中的数据维度，类似于numpy数组的shape。\n        :param output_path: 生成的HDF5文件存储在磁盘上的路径\n        :param data_key: 数据集的名称，默认值为\"images\"\n        :param buf_size: 缓存大小，默认值1000\n\n        \"\"\"\n        # 检查输出路径是否存在，如果存在则抛出异常\n        if os.path.exists(output_path):\n            raise ValueError(\"您提供的输出文件{}已经存在，请先手工删除！\".format(output_path))\n        # 创建并打开可写入HDF5文件\n        # 然后在其中创建两个数据集\n        # dataset : 类似数组组织的数据的集合，像 numpy 数组一样工作\n        self.db = h5py.File(output_path, \"w\")  # 读取文件\n        # 用于存储图像/特征\n        self.data = self.db.create_dataset(data_key, dims, dtype=\"float\")\n        # 用于存储分类标签\n        self.labels = self.db.create_dataset(\"labels\", (dims[0],), dtype=\"int\")\n\n        # 保存缓存大小，然后初始化存缓和数据集索引\n        self.buf_size = buf_size\n        self.buffer = {\"data\": [], \"labels\": []}\n        self.idx = 0\n\n    def add(self, raw, label):\n        \"\"\"\n        将数据和标签添加到缓存\n        :param raw: 图像\n        :param label: 对应的标签\n        :return:\n        \"\"\"\n        self.buffer[\"data\"].extend(raw)\n        self.buffer[\"labels\"].extend(label)\n\n        if len(self.buffer[\"data\"]) >= self.buf_size:  # 缓存小桶盛满了，放入水池\n            self.flush()  # 刷新缓冲区\n\n    def flush(self):\n        # 将缓存内容写入磁盘文件，然后清空缓存\n        # 块状文件，顺序读写\n        i = self.idx + len(self.buffer[\"data\"])\n        self.data[self.idx:i] = self.buffer[\"data\"]\n        self.labels[self.idx:i] = self.buffer[\"labels\"]\n        self.idx = i\n        self.buffer = {\"data\": [], \"labels\": []}  # 清空缓存\n\n    def store_class_labels(self, class_labels):\n        # dataset 是类 numpy array 所以，你能写进的数据只能是数组\n        # 创建一个数据集用来存储分类标签名称，然后保存分类标签\n        dt = h5py.special_dtype(vlen=str)\n        label_dim = (len(class_labels),)\n        label_set = self.db.create_dataset(\"label_names\", label_dim, dtype=dt)\n        label_set[:] = class_labels\n\n    def close(self):\n        # 检查缓存中是否有记录，如果有，则必须写入磁盘文件\n        if len(self.buffer[\"data\"]) > 0:\n            self.flush()\n\n        # 关闭数据集\n        self.db.close()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%writefile HDF5DatasetGenerator.py\nimport h5py\nimport numpy as np\nfrom keras.utils.np_utils import to_categorical\n\n# 生成HDF5文件\nclass HDF5DatasetGenerator:\n    def __init__(self, db_file, batch_size,\n                 preprocessors=None, aug=None,\n                 binarize=True, classes=2):\n        \"\"\"\n        :param db_file: 数据集文件\n        :param batch_size: 样本数量\n        :param preprocessors: 预处理器列表\n        :param aug: 数据增强处理器列表\n        :param binarize: 标签是否二值化\n        :param classes: 分类数，这里为二，我们只有猫狗两个分类\n        \"\"\"\n        # 每批次样本数量\n        self.batchSize = batch_size\n\n        # 预处理器列表\n        self.preprocessors = preprocessors\n\n        # 数据增强处理器列表，可以使用 Keras ImageDataGenerator实现的数据增强算法\n        self.aug = aug\n\n        # 标签是否二值化，我们在HDF5数据集中保存的类别标签为单个整型的列表，\n        # 然而，当我们使用分类交叉熵(categorical cross-entropy)或二值交叉熵(binary cross-entropy)\n        # 作为计算损失的方法： 我们必须将标签二值化为独热编码向量组(one-hot encoded vectors)\n        self.binarize = binarize\n\n        # 不重复的类别数量，在计算标签二值化独热编码向量组时需要该值\n        self.classes = classes\n\n        # 打开HDF5数据集文件\n        self.db = h5py.File(db_file,'r')\n\n        # 数据集样本数量\n        self.numImages = self.db[\"labels\"].shape[0]\n\n    def generator(self, passes=np.inf):\n        # hdf5中的数据分批读取到内存中\n        # 初始化训练趟数计数器\n        epochs = 0\n\n        # 执行无限循环，一旦达到规定的训练趟数,模型会自动停止训练\n        while epochs < passes:\n            # 遍历HDF5数据集\n            for i in np.arange(0, self.numImages, self.batchSize):\n\n                # 从HDF5数据集取出一批样本和标签\n                images = self.db[\"images\"][i:i + self.batchSize]\n                labels = self.db[\"labels\"][i:i + self.batchSize]\n\n                # 检查标签是否有转化为独热编码向量组\n                if self.binarize:\n                    labels = to_categorical(labels, self.classes)\n\n                # 如果有预处理器\n                if self.preprocessors is not None:\n                    # 初始化预处理结果图像列表\n                    processed_images = []\n\n                    # 遍历图像\n                    for image in images:\n                        # 遍历预处理器，对每个图像执行全部预处理\n                        for p in self.preprocessors:\n                            image = p.preprocess(image)\n\n                        # 更新预处理结果图像列表\n                        processed_images.append(image)\n\n                    # 将图像数组更新为预处理结果图像\n                    images = np.array(processed_images)\n\n                # 如果指定了数据增强器，则实施之\n                if self.aug is not None:\n                    (images, labels) = next(self.aug.flow(images, labels,\n                                                          batch_size=self.batchSize))\n\n                # 生成图像和标记元组\n                yield images, labels\n\n            # 增加训练趟数计数器\n            epochs += 1\n\n    def close(self):\n        # 关闭HDF5数据集\n        self.db.close()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%writefile TrainingMonitor.py\n#TrainingMonitor类\nfrom tensorflow.keras.callbacks import BaseLogger\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport json\nimport os\n\n\n# 定义TrainingMonitor类\nclass TrainingMonitor(BaseLogger):\n    def __init__(self, fig_path, json_path=None, start_at=0):\n        super(TrainingMonitor, self).__init__()\n        self.fig_path = fig_path  # 绘图文件保存路径\n        self.json_path = json_path  # Json文件保存路径\n        self.start_at = start_at  # 开始的趟数\n        self.history = {}  # 训练日志历史字典\n\n    def on_train_begin(self, logs={}):\n\n        # 若json日志文件存在，则加载训练日志字典\n        if self.json_path is not None:\n            if os.path.exists(self.json_path):\n                self.history = json.loads(open(self.json_path).read())  # append 4 value after each epoch\n                # 如果指定了训练趟数起点\n                if self.start_at > 0:\n                    # 遍历训练日志字典，解掉起点趟数之后的日志\n                    for k in self.history.keys():\n                        self.history[k] = self.history[k][:self.start_at]\n\n    def on_epoch_end(self, epoch, logs={}):\n\n        # 针对整个训练过程，遍历日志，更新训练损失、训练准确度等\n        for (k, v) in logs.items():\n            log = self.history.get(k, [])\n            log.append(float(v))\n            self.history[k] = log\n\n        if self.json_path is not None:\n            f = open(self.json_path, 'w')\n            f.write(json.dumps(self.history, skipkeys=True))  # 序列化为json文件\n            f.close()\n\n        # 训练两趟后开始绘图\n        if len(self.history[\"loss\"]) > 1:\n            # 绘图训练损失和准确度趋势图\n            N = np.arange(0, len(self.history[\"loss\"]))\n            plt.style.use(\"ggplot\")\n            plt.figure()\n            plt.plot(N, self.history[\"loss\"], label=\"train_loss\")\n            plt.plot(N, self.history[\"val_loss\"], label=\"val_loss\")\n            # plt.plot(N,self.history[\"acc\"],label=\"train_acc\")  # GPU version\n            plt.plot(N, self.history[\"accuracy\"], label=\"train_acc\")  # CPU version\n            # plt.plot(N,self.history[\"val_acc\"],label=\"val_acc\") # GPU version\n            plt.plot(N, self.history[\"val_accuracy\"], label=\"val_acc\")  # CPU version\n            epochs = len(self.history[\"loss\"])\n            plt.title(\"Training Loss & Accuracy [Epoch {}]\".format(epochs))\n            plt.xlabel(\"Epoch #\")\n            plt.ylabel(\"Loss/Accuracy\")\n            plt.legend()\n            plt.savefig(self.fig_path)\n            plt.close()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%writefile build_hdf5.py\n# 导入必要的包\nimport numpy as np\n# import HDF5DatasetWriter\n# import setting\n\nprint(\"[信息] 加载csv格式数据集文件...\")\n\n# 打开csv格式数据集文件\nfile = open(SAMPLE_FILE_PATH)\n\n# 跳过第一行(表头）\nfile.__next__()\n\n# 声明训练、校验、测试数据集\n(train_images, train_labels) = ([], [])\n(val_images, val_labels) = ([], [])\n(test_images, test_labels) = ([], [])\n\n# 存储数据集样本类别分布的字典\ncount_by_label_train = {}\ncount_by_label_val = {}\ncount_by_label_test = {}\n\n# 遍历一遍文件的每一行\nfor row in file:\n    # 提取每一行的标签(label),用途(usage)以及图像(image)。\n    (label, usage, image) = row.strip().split(\",\")\n    # 标签转整数\n    label = int(label)\n    # 将一维像素列表变维成48x48灰度图像\n    image = np.array(image.split(\" \"), dtype=\"uint8\")\n    image = image.reshape((48, 48))\n\n    # 如果用途为training，添加到训练样本集\n    if usage == \"Training\":\n        train_images.append(image)\n        train_labels.append(label)\n        count = count_by_label_train.get(label, 0)\n        count_by_label_train[label] = count + 1\n    # 如果用途为publicTest，添加到校验样本集\n    elif usage == \"PublicTest\":\n        val_images.append(image)\n        val_labels.append(label)\n        count = count_by_label_val.get(label, 0)\n        count_by_label_val[label] = count + 1\n        # 如果用途为PrivateTest，添加到测试样本集\n    elif usage == \"PrivateTest\":\n            test_images.append(image)\n            test_labels.append(label)\n            count = count_by_label_test.get(label, 0)\n            count_by_label_test[label] = count + 1\n\n# 关闭CVS样本文件\nfile.close()\n# 输出训练、校验、测试样本数量\nprint(\"[信息] 训练样本数量：{}\".format(len(train_images)))\nprint(\"[信息]校验样本数量：{}\".format(len(val_images)))\nprint(\"[信息]测试样本数量：{}\".format(len(test_images)))\n# 输出训练、校验、测试样本数量分布\nprint(count_by_label_train)\nprint(\"[信息]校验样本分布：\")\nprint(count_by_label_val)\nprint(\"[信息]测试样本分布：\")\nprint(count_by_label_test)\n# 构建一个训练、校验、测试数据集列表，\n# 每个元素由数据集类型名称、全部样本文件名称、全部样本整型标签、HDF5输出文件构成\ndatasets = [(train_images, train_labels, TRAIN_HDF5),\n(val_images, val_labels, VAL_HDF5),\n(test_images, test_labels, TEST_HDF5)]\n\n# 遍历数据集元组\nfor (images, labels, outputPath) in datasets:\n    # 创建HDF5写入器\n    print(\"[信息]构建{}...\".format(outputPath))\n    writer = HDF5DatasetWriter((len(images), 48, 48), outputPath)\n    # 遍历每个图像，将其加入数据集\n    for (image, label) in zip(images, labels):\n        writer.add([image], [label])\n    # 关闭HDF5写入器\n    writer.close()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ***生成hdf5文件***","metadata":{}},{"cell_type":"code","source":"# %%writefile VGG11.py\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras import backend\nfrom tensorflow.keras.regularizers import l1,l2\n\n\nclass VGG11:\n    @staticmethod\n    def build(width, height, channel, classes, reg=0.0002):\n        \"\"\"\n\n        :param width: 输入样本的宽度\n        :param height: 输入样本的高度\n        :param channel: 输入样本的通道\n        :param classes:分类数量\n        :param reg:正则化因子\n        :return:VGG网络模型\n        \"\"\"\n\n        model = Sequential(name=\"VGG11\")\n        # 缺省输入格式为通道后首 (\"channels-last\")\n        shape = (height, width, channel)\n\n        channel_dimension = -1\n        # 如果输入格式为通道前罱\n        # 重新设首输入格式和通道位首指示\n        if backend.image_data_format() == \"channels_first\":\n            shape = (channel, height, width)\n            channel_dimension = 1\n\n        # 第一卷积块\n        model.add(Conv2D(64, (3, 3), input_shape=shape, padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n        # 第二卷积块\n        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n        # 第三卷积块\n        model.add(Conv2D(256, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Conv2D(256, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n        # 第四卷积块\n        model.add(Conv2D(512, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Conv2D(512, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n        # 第五卷积块\n        model.add(Conv2D(512, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Dropout(0.5))\n        model.add(Conv2D(512, (3, 3), padding=\"same\"))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Dropout(0.5))\n        model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\", strides=(1, 1)))\n\n        # 第一全连接层\n        model.add(Flatten())\n        model.add(Dense(256, kernel_regularizer=l2(reg)))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Dropout(0.5))\n\n        # 第二全连接层\n        model.add(Dense(128, kernel_regularizer=l2(reg)))\n        model.add(BatchNormalization(axis=channel_dimension))\n        model.add(Activation(\"relu\"))\n        model.add(Dropout(0.5))\n\n        # 第三全连接层\n        model.add(Dense(classes, kernel_regularizer=l1(reg)))\n        model.add(Activation(\"softmax\"))\n\n        return model\n\n\n# 测 试 VGG11\nif __name__ == '__main__':\n    my_model = VGG11.build(width=48, height=48, channel=1, classes=7, reg=0.0002)\n    print(my_model.summary())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ***VGG_11***","metadata":{}},{"cell_type":"code","source":"# %%writefile training.py\nimport argparse\nimport os\n\nimport matplotlib\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# from VGG11 import VGG11\n# import setting\n# from EpochCheckpoint import EpochCheckpoint\n# from HDF5DatasetGenerator import HDF5DatasetGenerator\n# from ImageToArrayPreprocessor import ImageToArrayPreprocessor\n# from TrainingMonitor import TrainingMonitor\n\n\n# 设置matplotlib可以在后台保存绘图\nmatplotlib.use(\"Agg\")\n\n# # # 构造命令行参数解析器\n# ap = argparse.ArgumentParser()\n# ap.add_argument(\"-c\", \"--checkpoints\", required=True, help=\"检查点输出目录\")\n# ap.add_argument(\"-m\", \"--model\", required=False, type=str, help=\"要加载的检查点模型文件\")\n# ap.add_argument(\"-s\", \"--start-epoch\", type=int, default=0, help=\"重新训练的趟数起点\")\n# args = vars(ap.parse_args())\n\n# 训练集数据增强生成器\ntrain_aug = ImageDataGenerator(rotation_range=10,\n                               zoom_range=0.1,\n                               horizontal_flip=True,\n                               rescale=1 / 255.0,\n                               fill_mode=\"nearest\")\n\n# 校验集数据增强生成器\nval_aug = ImageDataGenerator(rescale=1 / 255.0)\n\n# 初始化图像预处理器\niap = ImageToArrayPreprocessor()\n\n# 初始化训练数据集生成器\ntrain_gen = HDF5DatasetGenerator(TRAIN_HDF5,\n                                 BATCH_SIZE,\n                                 aug=train_aug,\n                                 preprocessors=[iap],\n                                 classes=NUM_CLASSES)\n\n# 初始化校验数据集生成器\nval_gen = HDF5DatasetGenerator(VAL_HDF5,\n                               BATCH_SIZE,\n                               aug=val_aug,\n                               preprocessors=[iap],\n                               classes=NUM_CLASSES)\n\n\nprint(\"[信息] 编译模型...\")\n# 初始化优化器\nopt = Adam(lr=1e-3)\nmodel = VGG11.build(width=48, height=48, channel=1, classes=NUM_CLASSES)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n\n\n# 构造训练回调列表，这里主要是绘图回调\nfig_path = os.path.sep.join([OUTPUT_PATH, \"VGG11.png\"])\n# json_path = os.path.sep.join([OUTPUT_PATH, \"VGG11.json\"])\ncallbacks = [TrainingMonitor(fig_path=fig_path)]\n\n# 训练网络\nmodel.fit_generator(train_gen.generator(),\n                    steps_per_epoch=train_gen.numImages // BATCH_SIZE,\n                    validation_data=val_gen.generator(),\n                    validation_steps=val_gen.numImages // BATCH_SIZE,\n                    epochs=100,\n                    max_queue_size=BATCH_SIZE * 2,\n                    callbacks=callbacks,\n                    verbose=1)\n# 将训练得到的模型保存到文件\nprint(\"[信息] 保存模型...\")\nmodel.save(MODEL_FILE, overwrite=True)\n\n# 关闭HDF5数据集\ntrain_gen.close()\nval_gen.close()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ***train***","metadata":{}},{"cell_type":"code","source":"# %%writefile evaluating.py\n# import setting\n# from ImageToArrayPreprocessor import  ImageToArrayPreprocessor\n# from HDF5DatasetGenerator import HDF5DatasetGenerator\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import load_model\n\n# 初始化图像预处理器\ntestAug = ImageDataGenerator(rescale=1 / 255.0)\niap = ImageToArrayPreprocessor()\n\n# 初始化测试数据集生成器\ntestGen = HDF5DatasetGenerator(TEST_HDF5,\n                               BATCH_SIZE,\n                               aug = testAug,\n                               preprocessors=[iap],\n                               classes=NUM_CLASSES)\n\n# 加载前面训练好的网络\nprint(\"[信息] 加载网络模型...\")\nmodel = load_model(MODEL_FILE)\n\n# 评估网络模型\n(loss, acc) = model.evaluate_generator(testGen.generator(),\n                                       steps=testGen.numImages // BATCH_SIZE,\n                                       max_queue_size=BATCH_SIZE * 2)\nprint(\"[信息] 测试集准确率: {:.2f}%\".format(acc * 100))\n\n# 关闭HDF5数据集\ntestGen.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%writefile emotion_detector.py\nimport cv2\nimport imutils\nimport numpy as np\n\nfrom tensorflow.keras.models import load_model\n\nfrom tensorflow.keras.preprocessing.image import img_to_array\n\n#加载opencv级联分类器\n\nface_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n#加训练好的表情识别网络模型\n\nmodel = load_model('output/model.h5')\n#面部表情分类\n\nEMOTIONS = ['Angry','Disgust', 'Scared','Happy','Sad','Surprise','Neutral']\n#打开第一个摄像头\ncapture = cv2.VideoCapture(0,cv2.CAP_DSHOW)\n\n#持续采集摄像头图像帧\nwhile True:\n    ret,frame = capture.read()\n    #帧图像缩小并转化为灰度图像\n    frame = imutils.resize(frame,width=300)\n    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n\n    #初始化显示使用的画布\n    canvas = np.zeros((240,300,3),dtype=\"uint8\")\n\n    frameClone = frame.copy()\n\n    rects = face_detector.detectMultiScale(\n        gray,scaleFactor=1.1,\n        minNeighbors=5,\n        minSize=(30,30),\n        flags=cv2.CASCADE_SCALE_IMAGE\n    )\n\n    if len(rects)>0:\n        rect = sorted(rects,reverse=True,\n                      key=lambda x:(x[2]-x[0])*(x[3]-x[1]))[0]\n\n        #抠出脸部图像，预处理以适合分类网络模型的输入要求\n        (fX,fY,fW,fH) = rect\n        roi = gray[fY:fY+fH,fX:fX+fH] #灰度化\n        roi =cv2.resize(roi,(48,48)) #缩小\n        roi = roi.astype(\"float\") / 255.0\n        roi = img_to_array(roi)    #转换为np数组\n        roi = np.expand_dims(roi,axis=0)  #增加样本数量维度\n\n        #使用模型进行推断\n        predicts = model.predict(roi)[0]\n\n        label = EMOTIONS[predicts.argmax()]\n\n        cv2.putText(frameClone,label,(fX,fY-10),\n                    cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,255),1,cv2.LINE_AA)\n        cv2.rectangle(frameClone,(fX,fY),(fX+fW,fY+fH),\n                      (0,0,255),1,cv2.LINE_AA)\n\n        for (i,(emotion,prob)) in enumerate(zip(EMOTIONS,predicts)):\n            text = \"{}:{:.2f}%\".format(emotion,prob*100)\n\n            w = int(prob*300)\n            cv2.rectangle(canvas,(5,(i*32)+5),\n                          (5+w,(i*32)+32),(0,0,255),-1)\n            cv2.putText(canvas,\n                        text,(10,(i*32)+23),\n                        cv2.FONT_HERSHEY_SIMPLEX,\n                        0.5,\n                        (255,255,255),\n                        1,\n                        cv2.LINE_AA)\n\n    cv2.imshow(\"Emotion Detection\",frameClone)\n    cv2.imshow(\"Result\",canvas)\n\n    if cv2.waitKey(1) == 27:\n        break\n\ncapture.release()\ncv2.destoryAllWindows()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}