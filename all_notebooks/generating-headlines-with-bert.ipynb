{"cells":[{"metadata":{},"cell_type":"markdown","source":"## 1.0 importing the data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/news-headlines-summary-from-select-12-sources/full_data.csv')\ncolumns = ['source','author', 'description', 'url', 'requested_date', 'publishedAt',]\ndf.drop(columns, inplace=True, axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.1 cleaning the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop nan values\ndf = df.dropna()\n# resetting the index\ndf = df.reset_index(drop=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove noise\nfor i in range(0,len(df['content'])):\n    if type(df['content'][i]) == str:\n        df['content'][i] = df['content'][i].replace('\\n','').replace('\\r','').replace('/','')\n        df['title'][i] = df['title'][i].replace('\\n','').replace('\\r','').replace('/','')\n    else:\n        print(str(df['content'][i]))\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.3 splitting train data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_data_length = int(len(df['content'])*0.95)\nimport sklearn.model_selection as model_selection\ntrain_df, test_df = model_selection.train_test_split(df, train_size = 0.997)\ntrain_data = []\nfor i in range(0,len(train_df['content'])):\n    train_data.append((df['content'][i], df['title'][i]))\ntrain_data[2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install headliner\n!pip install tensorflow_datasets","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2 preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"from headliner.preprocessing.bert_preprocessor import BertPreprocessor\nfrom spacy.lang.en import English\n\n# use BERT-specific start and end token\npreprocessor = BertPreprocessor(nlp=English())\ntrain_prep = [preprocessor(t) for t in train_data]\ntargets_prep = [t[1] for t in train_prep]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.3 training "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from tensorflow_datasets.core.features.text import SubwordTextEncoder\nfrom transformers import BertTokenizer\nfrom headliner.model.bert_summarizer import BertSummarizer\nfrom headliner.preprocessing.bert_vectorizer import BertVectorizer\nfrom headliner.trainer import Trainer\n\n# Use a pre-trained BERT embedding and BERT tokenizer for the encoder \ntokenizer_input = BertTokenizer.from_pretrained('bert-base-uncased')\ntokenizer_target = SubwordTextEncoder.build_from_corpus(\n    targets_prep, target_vocab_size=2**13,  reserved_tokens=[preprocessor.start_token, preprocessor.end_token])\n\nvectorizer = BertVectorizer(tokenizer_input, tokenizer_target)\nsummarizer = BertSummarizer(num_heads=2,\n                            feed_forward_dim=512,\n                            num_layers_encoder=0,\n                            num_layers_decoder=4,\n                            bert_embedding_encoder='bert-base-uncased',\n                            embedding_size_encoder=768,\n                            embedding_size_decoder=768,\n                            dropout_rate=0.1,\n                            max_prediction_len=50)\nsummarizer.init_model(preprocessor, vectorizer)\n\ntrainer = Trainer(batch_size=2)\ntrainer.train(summarizer, train_data, num_epochs=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = test_df.reset_index(drop=True)\nfor i in range(0, len(test_df['content'])):\n    print('t:',test_df['title'][i])\n    prediction = summarizer.predict(test_df['content'][i])\n    print('p:',prediction)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}