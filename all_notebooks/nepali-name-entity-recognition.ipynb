{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm, trange\n\ndata = pd.read_csv(\"../input/nepali-ner/data.csv\", encoding=\"utf-8\")\ndata.tail(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:15:04.351288Z","iopub.execute_input":"2021-06-24T09:15:04.351801Z","iopub.status.idle":"2021-06-24T09:15:04.51759Z","shell.execute_reply.started":"2021-06-24T09:15:04.351669Z","shell.execute_reply":"2021-06-24T09:15:04.516712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SentenceGetter(object):\n\n    def __init__(self, data):\n        self.n_sent = 1\n        self.data = data\n        self.empty = False\n        agg_func = lambda s: [(w, t) for w,  t in zip(s[\"Word\"].values.tolist(),\n                                                        #    s[\"POS\"].values.tolist(),\n                                                           s[\"Tag\"].values.tolist())]\n        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n        self.sentences = [s for s in self.grouped]\n\n    def get_next(self):\n        try:\n            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n            self.n_sent += 1\n            return s\n        except:\n            return None","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:15:04.521625Z","iopub.execute_input":"2021-06-24T09:15:04.52368Z","iopub.status.idle":"2021-06-24T09:15:04.533269Z","shell.execute_reply.started":"2021-06-24T09:15:04.523639Z","shell.execute_reply":"2021-06-24T09:15:04.532505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"getter = SentenceGetter(data)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:15:04.537834Z","iopub.execute_input":"2021-06-24T09:15:04.540015Z","iopub.status.idle":"2021-06-24T09:15:04.932471Z","shell.execute_reply.started":"2021-06-24T09:15:04.539977Z","shell.execute_reply":"2021-06-24T09:15:04.931655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentences = [[word[0] for word in sentence] for sentence in getter.sentences]\nsentences[99]","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:15:04.936933Z","iopub.execute_input":"2021-06-24T09:15:04.938876Z","iopub.status.idle":"2021-06-24T09:15:04.959567Z","shell.execute_reply.started":"2021-06-24T09:15:04.938837Z","shell.execute_reply":"2021-06-24T09:15:04.95887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = [[s[1] for s in sentence] for sentence in getter.sentences]\nprint(labels[99])","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:15:04.963043Z","iopub.execute_input":"2021-06-24T09:15:04.964956Z","iopub.status.idle":"2021-06-24T09:15:04.983274Z","shell.execute_reply.started":"2021-06-24T09:15:04.964919Z","shell.execute_reply":"2021-06-24T09:15:04.982341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tag_values = list(set(data[\"Tag\"].values))\ntag_values.append(\"PAD\")\ntag2idx = {t: i for i, t in enumerate(tag_values)}","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:15:04.98717Z","iopub.execute_input":"2021-06-24T09:15:04.989071Z","iopub.status.idle":"2021-06-24T09:15:04.998347Z","shell.execute_reply.started":"2021-06-24T09:15:04.989033Z","shell.execute_reply":"2021-06-24T09:15:04.997604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom transformers import BertTokenizer, BertConfig\n\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\n\ntorch.__version__","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:15:05.002251Z","iopub.execute_input":"2021-06-24T09:15:05.004587Z","iopub.status.idle":"2021-06-24T09:15:08.257845Z","shell.execute_reply.started":"2021-06-24T09:15:05.004548Z","shell.execute_reply":"2021-06-24T09:15:08.257055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 128\nbs = 32\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nn_gpu = torch.cuda.device_count()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:15:08.263385Z","iopub.execute_input":"2021-06-24T09:15:08.265979Z","iopub.status.idle":"2021-06-24T09:15:08.282513Z","shell.execute_reply.started":"2021-06-24T09:15:08.265939Z","shell.execute_reply":"2021-06-24T09:15:08.281831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizer\nvocab_file_dir = '../input/nepalibert/' \ntokenizer = BertTokenizer.from_pretrained(vocab_file_dir,\n                                        strip_accents=False,\n                                         clean_text=False )\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:15:08.295478Z","iopub.execute_input":"2021-06-24T09:15:08.296136Z","iopub.status.idle":"2021-06-24T09:15:08.389652Z","shell.execute_reply.started":"2021-06-24T09:15:08.296097Z","shell.execute_reply":"2021-06-24T09:15:08.388691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize_and_preserve_labels(sentence, text_labels):\n    tokenized_sentence = []\n    labels = []\n\n    for word, label in zip(sentence, text_labels):\n\n        # Tokenize the word and count # of subwords the word is broken into\n        tokenized_word = tokenizer.tokenize(word)\n        n_subwords = len(tokenized_word)\n\n        # Add the tokenized word to the final tokenized word list\n        tokenized_sentence.extend(tokenized_word)\n\n        # Add the same label to the new list of labels `n_subwords` times\n        labels.extend([label] * n_subwords)\n\n    return tokenized_sentence, labels","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:15:08.394806Z","iopub.execute_input":"2021-06-24T09:15:08.397901Z","iopub.status.idle":"2021-06-24T09:15:08.406643Z","shell.execute_reply.started":"2021-06-24T09:15:08.39786Z","shell.execute_reply":"2021-06-24T09:15:08.405845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_texts_and_labels = [\n    tokenize_and_preserve_labels(sent, labs)\n    for sent, labs in zip(sentences, labels)\n]","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:15:08.410496Z","iopub.execute_input":"2021-06-24T09:15:08.410876Z","iopub.status.idle":"2021-06-24T09:15:18.693513Z","shell.execute_reply.started":"2021-06-24T09:15:08.410837Z","shell.execute_reply":"2021-06-24T09:15:18.692661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_texts = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels]\nlabels = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels]\n","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:15:18.694722Z","iopub.execute_input":"2021-06-24T09:15:18.695402Z","iopub.status.idle":"2021-06-24T09:15:18.701701Z","shell.execute_reply.started":"2021-06-24T09:15:18.695363Z","shell.execute_reply":"2021-06-24T09:15:18.700993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n                          truncating=\"post\", padding=\"post\")","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:15:18.70297Z","iopub.execute_input":"2021-06-24T09:15:18.703439Z","iopub.status.idle":"2021-06-24T09:15:18.917475Z","shell.execute_reply.started":"2021-06-24T09:15:18.703386Z","shell.execute_reply":"2021-06-24T09:15:18.916714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n                     dtype=\"long\", truncating=\"post\")\n","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:15:18.918591Z","iopub.execute_input":"2021-06-24T09:15:18.919044Z","iopub.status.idle":"2021-06-24T09:15:18.996833Z","shell.execute_reply.started":"2021-06-24T09:15:18.919009Z","shell.execute_reply":"2021-06-24T09:15:18.99588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"attention_masks = [[float(i != 0.0) for i in ii] for ii in input_ids]","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:15:19.000188Z","iopub.execute_input":"2021-06-24T09:15:19.000659Z","iopub.status.idle":"2021-06-24T09:15:20.86905Z","shell.execute_reply.started":"2021-06-24T09:15:19.000623Z","shell.execute_reply":"2021-06-24T09:15:20.868216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags,\n                                                            random_state=2018, test_size=0.1)\ntr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\n                                             random_state=2018, test_size=0.1)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:15:20.870242Z","iopub.execute_input":"2021-06-24T09:15:20.87071Z","iopub.status.idle":"2021-06-24T09:15:20.888679Z","shell.execute_reply.started":"2021-06-24T09:15:20.870673Z","shell.execute_reply":"2021-06-24T09:15:20.887957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr_inputs = torch.tensor(tr_inputs)\nval_inputs = torch.tensor(val_inputs)\ntr_tags = torch.tensor(tr_tags)\nval_tags = torch.tensor(val_tags)\ntr_masks = torch.tensor(tr_masks)\nval_masks = torch.tensor(val_masks)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:15:20.889898Z","iopub.execute_input":"2021-06-24T09:15:20.890332Z","iopub.status.idle":"2021-06-24T09:15:20.949081Z","shell.execute_reply.started":"2021-06-24T09:15:20.890297Z","shell.execute_reply":"2021-06-24T09:15:20.948282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n\nvalid_data = TensorDataset(val_inputs, val_masks, val_tags)\nvalid_sampler = SequentialSampler(valid_data)\nvalid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:15:20.950206Z","iopub.execute_input":"2021-06-24T09:15:20.950659Z","iopub.status.idle":"2021-06-24T09:15:20.956473Z","shell.execute_reply.started":"2021-06-24T09:15:20.950623Z","shell.execute_reply":"2021-06-24T09:15:20.955498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertForMaskedLM,AdamW\nmodel = BertForMaskedLM.from_pretrained('../input/nepalibert',\n                                            num_labels=len(tag2idx),\n                                            output_attentions = False,\n                                            output_hidden_states = False\n                                       )","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:15:20.960638Z","iopub.execute_input":"2021-06-24T09:15:20.961061Z","iopub.status.idle":"2021-06-24T09:15:26.414319Z","shell.execute_reply.started":"2021-06-24T09:15:20.961019Z","shell.execute_reply":"2021-06-24T09:15:26.413271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.cuda();","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:15:26.418639Z","iopub.execute_input":"2021-06-24T09:15:26.41899Z","iopub.status.idle":"2021-06-24T09:15:31.45387Z","shell.execute_reply.started":"2021-06-24T09:15:26.418955Z","shell.execute_reply":"2021-06-24T09:15:31.453029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FULL_FINETUNING = True\nif FULL_FINETUNING:\n    param_optimizer = list(model.named_parameters())\n    no_decay = ['bias', 'gamma', 'beta']\n    optimizer_grouped_parameters = [\n        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n         'weight_decay_rate': 0.01},\n        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n         'weight_decay_rate': 0.0}\n    ]\nelse:\n    param_optimizer = list(model.classifier.named_parameters())\n    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n\noptimizer = AdamW(\n    optimizer_grouped_parameters,\n    lr=3e-5,\n    eps=1e-8\n)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:15:31.455206Z","iopub.execute_input":"2021-06-24T09:15:31.455755Z","iopub.status.idle":"2021-06-24T09:15:31.466324Z","shell.execute_reply.started":"2021-06-24T09:15:31.455716Z","shell.execute_reply":"2021-06-24T09:15:31.46559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import get_linear_schedule_with_warmup\n\nepochs = 3\nmax_grad_norm = 1.0\n\n# Total number of training steps is number of batches * number of epochs.\ntotal_steps = len(train_dataloader) * epochs\n\n# Create the learning rate scheduler.\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=0,\n    num_training_steps=total_steps\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:15:31.469868Z","iopub.execute_input":"2021-06-24T09:15:31.472069Z","iopub.status.idle":"2021-06-24T09:15:31.482546Z","shell.execute_reply.started":"2021-06-24T09:15:31.472032Z","shell.execute_reply":"2021-06-24T09:15:31.481574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install seqeval\n","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:15:31.486719Z","iopub.execute_input":"2021-06-24T09:15:31.488944Z","iopub.status.idle":"2021-06-24T09:15:40.352881Z","shell.execute_reply.started":"2021-06-24T09:15:31.488906Z","shell.execute_reply":"2021-06-24T09:15:40.351956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom seqeval.metrics import f1_score, accuracy_score\n","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:15:40.357426Z","iopub.execute_input":"2021-06-24T09:15:40.359357Z","iopub.status.idle":"2021-06-24T09:15:40.370412Z","shell.execute_reply.started":"2021-06-24T09:15:40.359315Z","shell.execute_reply":"2021-06-24T09:15:40.369556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Store the average loss after each epoch so we can plot them.\nloss_values, validation_loss_values = [], []\n\nfor _ in trange(epochs, desc=\"Epoch\"):\n    # ========================================\n    #               Training\n    # ========================================\n    # Perform one full pass over the training set.\n\n    # Put the model into training mode.\n    model.train()\n    # Reset the total loss for this epoch.\n    total_loss = 0\n\n    # Training loop\n    for step, batch in enumerate(train_dataloader):\n        # add batch to gpu\n        batch = tuple(t.to(device) for t in batch)\n        b_input_ids, b_input_mask, b_labels = batch\n        # Always clear any previously calculated gradients before performing a backward pass.\n        model.zero_grad()\n        # forward pass\n        # This will return the loss (rather than the model output)\n        # because we have provided the `labels`.\n        outputs = model(b_input_ids, token_type_ids=None,\n                        attention_mask=b_input_mask, labels=b_labels)\n        # get the loss\n        loss = outputs[0]\n        # Perform a backward pass to calculate the gradients.\n        loss.backward()\n        # track train loss\n        total_loss += loss.item()\n        # Clip the norm of the gradient\n        # This is to help prevent the \"exploding gradients\" problem.\n        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n        # update parameters\n        optimizer.step()\n        # Update the learning rate.\n        scheduler.step()\n\n    # Calculate the average loss over the training data.\n    avg_train_loss = total_loss / len(train_dataloader)\n    print(\"Average train loss: {}\".format(avg_train_loss))\n\n    # Store the loss value for plotting the learning curve.\n    loss_values.append(avg_train_loss)\n\n\n    # ========================================\n    #               Validation\n    # ========================================\n    # After the completion of each training epoch, measure our performance on\n    # our validation set.\n\n    # Put the model into evaluation mode\n    model.eval()\n    # Reset the validation loss for this epoch.\n    eval_loss, eval_accuracy = 0, 0\n    nb_eval_steps, nb_eval_examples = 0, 0\n    predictions , true_labels = [], []\n    for batch in valid_dataloader:\n        batch = tuple(t.to(device) for t in batch)\n        b_input_ids, b_input_mask, b_labels = batch\n\n        # Telling the model not to compute or store gradients,\n        # saving memory and speeding up validation\n        with torch.no_grad():\n            # Forward pass, calculate logit predictions.\n            # This will return the logits rather than the loss because we have not provided labels.\n            outputs = model(b_input_ids, token_type_ids=None,\n                            attention_mask=b_input_mask, labels=b_labels)\n        # Move logits and labels to CPU\n        logits = outputs[1].detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n\n        # Calculate the accuracy for this batch of test sentences.\n        eval_loss += outputs[0].mean().item()\n        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n        true_labels.extend(label_ids)\n\n    eval_loss = eval_loss / len(valid_dataloader)\n    validation_loss_values.append(eval_loss)\n    print(\"Validation loss: {}\".format(eval_loss))\n    pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n                                 for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\n    valid_tags = [tag_values[l_i] for l in true_labels\n                                  for l_i in l if tag_values[l_i] != \"PAD\"]\n    print(\"Validation Accuracy: {}\".format(accuracy_score(pred_tags, valid_tags)))\n#     print(\"Validation F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))\n    print()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:15:40.37497Z","iopub.execute_input":"2021-06-24T09:15:40.37688Z","iopub.status.idle":"2021-06-24T09:19:07.853362Z","shell.execute_reply.started":"2021-06-24T09:15:40.376845Z","shell.execute_reply":"2021-06-24T09:19:07.852596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\n\n# Use plot styling from seaborn.\nsns.set(style='darkgrid')\n\n# Increase the plot size and font size.\nsns.set(font_scale=1.5)\nplt.rcParams[\"figure.figsize\"] = (12,6)\n\n# Plot the learning curve.\nplt.plot(loss_values, 'b-o', label=\"training loss\")\nplt.plot(validation_loss_values, 'r-o', label=\"validation loss\")\n\n# Label the plot.\nplt.title(\"Learning curve\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:19:07.85706Z","iopub.execute_input":"2021-06-24T09:19:07.858934Z","iopub.status.idle":"2021-06-24T09:19:08.219758Z","shell.execute_reply.started":"2021-06-24T09:19:07.858893Z","shell.execute_reply":"2021-06-24T09:19:08.218994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_sentence = \"\"\"\nप्रधानमन्त्री केपी शर्मा ओलीले बिहीबार मन्त्रिपरिषद विस्तार गर्दा मुगुका एमाले नेता तथा निवर्तमान सांसद मोहन बानियाँ मन्त्रीमा समेटिए । दिउँसो ४ बजे शपथ ग्रहणको समय तोकिए पनि मन्त्री हुनेहरुको नाम सार्वजनिक भएपछि उनीहरु शुभेच्छुक र कार्यकर्ताको बधाई थापिरहेका छन् । बानियाँलाई प्रधानमन्त्री तथा मन्त्रिपरिषदको कार्यालय हेर्ने गरी मन्त्री बनाइएको छ ।\n\"\"\"\n","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:19:08.223287Z","iopub.execute_input":"2021-06-24T09:19:08.225167Z","iopub.status.idle":"2021-06-24T09:19:08.231067Z","shell.execute_reply.started":"2021-06-24T09:19:08.225127Z","shell.execute_reply":"2021-06-24T09:19:08.230019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_sentence = tokenizer.encode(test_sentence)\ninput_ids = torch.tensor([tokenized_sentence]).cuda()\n\nwith torch.no_grad():\n    output = model(input_ids)\nlabel_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:19:08.23518Z","iopub.execute_input":"2021-06-24T09:19:08.23793Z","iopub.status.idle":"2021-06-24T09:19:08.274844Z","shell.execute_reply.started":"2021-06-24T09:19:08.237892Z","shell.execute_reply":"2021-06-24T09:19:08.273885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# join bpe split tokens\ntokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\nnew_tokens, new_labels = [], []\nfor token, label_idx in zip(tokens, label_indices[0]):\n    if token.startswith(\"##\"):\n        new_tokens[-1] = new_tokens[-1] + token[2:]\n    else:\n        new_labels.append(tag_values[label_idx])\n        new_tokens.append(token)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:19:08.276241Z","iopub.execute_input":"2021-06-24T09:19:08.27657Z","iopub.status.idle":"2021-06-24T09:19:08.284378Z","shell.execute_reply.started":"2021-06-24T09:19:08.276535Z","shell.execute_reply":"2021-06-24T09:19:08.282706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for token, label in zip(new_tokens, new_labels):\n    print(\"{}\\t{}\".format(label, token))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:19:08.285792Z","iopub.execute_input":"2021-06-24T09:19:08.286188Z","iopub.status.idle":"2021-06-24T09:19:08.307199Z","shell.execute_reply.started":"2021-06-24T09:19:08.286151Z","shell.execute_reply":"2021-06-24T09:19:08.306359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}