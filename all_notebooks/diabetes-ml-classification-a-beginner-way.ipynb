{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As a beginner in ML and python, probably this is my 3rd data project. And any feedback would be appretiated. Anyway here's my shot."},{"metadata":{},"cell_type":"markdown","source":"First of all, import packages to use later.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Packages for reading, visualization and manipulating data\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nimport numpy as np\nfrom scipy import stats\n\n#scaling and spliting\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n#ML algorythms\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\n\n\n#performance metrics\nfrom sklearn.metrics import classification_report, confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#read data ,Data examination, clearing NaN values\nfile_path = '/kaggle/input/pima-indians-diabetes-database/diabetes.csv'\ndf = pd.read_csv(file_path)\n\ndf.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No missing values in the dataset. However, it is not possible that someone has 0 glucose,bloodpressue, skinthickness , insulin and BMI scores. Therefore it is needed to remove outliners (by changing 0's to NaN and refilling with the column value or by removing Z values below 3; I choose removing Z treshhold method)"},{"metadata":{"trusted":true},"cell_type":"code","source":"z = np.abs(stats.zscore(df))\nthreshold = 3\nnp.where(z>threshold)\ndf = df[(z < threshold).all(axis=1)]\ndf.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now all columns except Insulin and SkinThickness have no 0 values. Replaces 0's with means of the columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[(df.SkinThickness<5)& (df.Outcome==0), 'SkinThickness']=int(df[(df.Outcome==0)]['SkinThickness'].mean())\ndf.loc[(df.SkinThickness<5)& (df.Outcome==1), 'SkinThickness']=int(df[(df.Outcome==1)]['SkinThickness'].mean())\ndf.loc[(df.Insulin==0)& (df.Outcome==0), 'Insulin']=int(df[(df.Outcome==0)]['Insulin'].mean())\ndf.loc[(df.Insulin==0)& (df.Outcome==1), 'Insulin']=int(df[(df.Outcome==1)]['Insulin'].mean())\ndf.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I think we are good to go."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visiuals\nfor i in df.columns:\n    sns.histplot(x=i, hue= 'Outcome', data=df)\n    plt.title(i)\n    plt.show()\n    \nsns.countplot(df['Outcome'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the histplots it can be considered that the data is not distributed normally. For the data not disturbed normally, StandardScaler could be used."},{"metadata":{"trusted":true},"cell_type":"code","source":"ss = StandardScaler()\ntrain = df.iloc[:,0:8]\ntrain = ss.fit_transform(train)\ntest = df['Outcome']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlations between variables\ncorr = df.corr()\nsns.heatmap(corr)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#split file for testing and training\nx_train, x_test, y_train, y_test = train_test_split(train,test, train_size=0.7,\n                                                    random_state= 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Machine Learning models and testing\nmodels = {\"LR\": LogisticRegression(),\n          \"NB\": GaussianNB(),\n          \"KNN\" : KNeighborsClassifier(),\n          \"DT\" : DecisionTreeClassifier(),\n          \"SVM rbf\": SVC(),\n          \"SVM linear\" : SVC(kernel='linear'),\n          'LDA' : LinearDiscriminantAnalysis(),\n          'RFC' : RandomForestClassifier(),\n          'BGC' : BaggingClassifier(),\n          'ABC' : AdaBoostClassifier(),\n          'GBC' : GradientBoostingClassifier(),\n          'DTC' : DecisionTreeClassifier(),\n          }\nfor test, clf in models.items():\n    clf.fit(x_train, y_train)\n    y_pred = clf.predict(x_test)\n    acc = accuracy_score(y_test,y_pred)\n    print( test + ' scores')\n    print(acc)\n    print(classification_report(y_test, y_pred))\n    print(confusion_matrix(y_test, y_pred))\n    print('*' * 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It can be assumed that Random Forest Classifier is a good option to predict Diabetus Mellitus. \n\nPS: Please rekt me for me to learn. Thank you"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}