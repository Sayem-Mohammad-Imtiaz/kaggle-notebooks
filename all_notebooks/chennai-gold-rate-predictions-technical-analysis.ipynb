{"cells":[{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://www.goldsmart.co.nz/wp-content/uploads/2019/07/gs-1.png\" width=\"400\">"},{"metadata":{},"cell_type":"markdown","source":"# Technical Analysis of Chennai Gold Rate for Forecasting/Predictions\n\nPredicting how the gold-rate will perform is one of the most difficult things to do. There are so many factors involved in the prediction – physical factors vs. psychological (rational / irrational behaviour etc.). All these aspects combine to make gold prices volatile and very difficult to predict with a high degree of accuracy.\n\nHowever we can make an attempt to predict the prices using machine learning. Using features like the latest announcements about an organization, their quarterly revenue results, etc., machine learning techniques have the potential to unearth patterns and insights we didn’t see before, and these can be used to make unerringly accurate predictions.\n\nIn this notebook/tutorial, we will work with historical [gold-rate data](https://www.kaggle.com/narendrageek/gold-rate-history-in-tamilnadu-india). We will implement a mix of machine learning algorithms to predict the future gold rate, starting with simple algorithms like linear regression, and then move on to advanced techniques like Auto ARIMA and Prophet. The core idea is to showcase how these algorithms are implemented. \n\nHere, I have performed **Technical Analysis** on the gold rates, which basically includes reading the charts and using statistical figures to identify the trends in the gold market.\n\n"},{"metadata":{},"cell_type":"markdown","source":"## Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pmdarima -q","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generic\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport gc, warnings, re\nwarnings.filterwarnings(\"ignore\")\n\n# Plotting\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\nfrom tabulate import tabulate\n\n# Sklearn\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics as mt\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import neighbors\nfrom sklearn.model_selection import GridSearchCV\n\n# Arima Model\nimport pmdarima as pm\n\n# Prophet\nfrom fbprophet import Prophet\n\n# Keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, LSTM","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Load\nurl = '../input/gold-rate-history-in-tamilnadu-india/gold_rate_history.csv'\ndf = pd.read_csv(url,index_col='Date', header='infer', parse_dates=True, infer_datetime_format=True)\n\n# Dropping Unwanted Columns\nunwanted_cols = ['Country','State','Location']\ndf.drop(unwanted_cols, axis=1, inplace=True)\n\n# Renaming Columns\ndf.rename(columns={\"Pure Gold (24 k)\": \"Pure_Gold_24k\",\n                   \"Standard Gold (22 K)\": \"Std_Gold_22k\",\n                  },inplace=True)\n\n# Total Records\nprint(\"Total Records: \", df.shape[0])\n\n# Inspect\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scaling Data\ncols = df.columns\nidx = df.index\nscaler = MinMaxScaler(feature_range=(0,1))\n\ndf_scaled = pd.DataFrame(scaler.fit_transform(df), columns=cols, index=idx)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualisation"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Visualisation\n\nfig = px.line(df, x=df.index, y=df.columns,\n              title='Gold Prices in Chennai (2006-2020)')\n\nfig.update_xaxes(tickangle=45)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.scatter(df, x=df.index, y=df.columns, marginal_x=\"box\", marginal_y=\"violin\", title=\"Chennai Gold Rate Marginal Distribution Plot\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Linear Regression\n\nThe most basic machine learning algorithm that can be implemented on this data is linear regression. The linear regression model returns an equation that determines the relationship between the independent variables and the dependent variable.\n\nFor our Gold Rate dataset, we do not have a set of independent variables. We have only the dates instead. Let us use the date column to extract features like – day, month, year,  mon/fri etc. and then fit a linear regression model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a seperate dataframe\ndf_lr = df_scaled.copy()\n\n# Converting Date Index to Column for Feature Extraction\ndf_lr.reset_index(level=0, inplace=True)\n\n# Time Feature Extraction\ndf_lr['year']=df_lr['Date'].dt.year \ndf_lr['month']=df_lr['Date'].dt.month \ndf_lr['day']=df_lr['Date'].dt.day\ndf_lr['quarter']=df_lr['Date'].dt.quarter\ndf_lr['weekofyear']=df_lr['Date'].dt.weekofyear\ndf_lr['weekday']=df_lr['Date'].dt.weekday\n\n# Dropping Date Column\ndf_lr.drop('Date',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Engineering & Split\nfeatures = ['year','month','day','quarter','weekofyear','weekday']\n\ntarget_24k = ['Pure_Gold_24k']\ntarget_22k = ['Std_Gold_22k']\n\nX = df_lr[features]\ny_24k = df_lr[target_24k]\ny_22k = df_lr[target_22k]\n\nsize = 0.1  #validation size\n\nX_train_24k, X_val_24k, y_train_24k, y_val_24k = train_test_split(X, y_24k, test_size=size, random_state=42)\nX_train_22k, X_val_22k, y_train_22k, y_val_22k = train_test_split(X, y_22k, test_size=size, random_state=42)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tab_data = []\n\n# Modeling, Training & Prediction\nlr_model = LinearRegression()\n\n'''24k Gold'''\nlr_model.fit(X_train_24k,y_train_24k)\ny_pred_24k = lr_model.predict(X_val_24k)\n\n# Evaluate\nrmse = mt.mean_squared_error(y_val_24k,y_pred_24k)\nr2_score = mt.r2_score(y_val_24k,y_pred_24k)\n\ntab_data.append(['PureGold_24k','{:.2}'.format(rmse), '{:.2}'.format(r2_score)])\n\n'''22k Gold'''\nlr_model.fit(X_train_22k,y_train_22k)\ny_pred_22k = lr_model.predict(X_val_22k)\n\n# Evaluate\nrmse = mt.mean_squared_error(y_val_22k,y_pred_22k)\nr2_score = mt.r2_score(y_val_22k,y_pred_22k)\n\ntab_data.append(['StdGold_22k','{:.2}'.format(rmse), '{:.2}'.format(r2_score)])\n\nprint(tabulate(tab_data, headers=['RMSE','R2_Score'], tablefmt=\"pretty\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### As we can see, our Linear Regression model that was trained on both Pure Gold & Std. Gold data has performed quite well with a low RMSE (Root Mean Squared Error) & a good R2_score (ideally should be close to 1)\n\nLinear regression is a simple technique and quite easy to interpret, but there are a few obvious disadvantages. One problem in using regression algorithms is that the model overfits to the date and month column. Instead of taking into account the previous values from the point of prediction, the model will consider the value from the same date a month ago, or the same date/month a year ago"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Free Memory\ngc.collect()\ntab_data.clear()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## KNN\n\nAnother interesting ML algorithm that one can use here is kNN (k nearest neighbours). Based on the independent variables, kNN finds the similarity between new data points and old data points\n\nWe'll use the same training & validation dataset that we used above."},{"metadata":{"trusted":true},"cell_type":"code","source":"#using gridsearch to find the best parameter\n\nparams = {'n_neighbors':[2,3,4,5,6,7,8,9]}\n\nknn = neighbors.KNeighborsRegressor()\nknn_model = GridSearchCV(knn, params, cv=5)\n\n'''24k Gold'''\nknn_model.fit(X_train_24k,y_train_24k)\ny_pred_24k = knn_model.predict(X_val_24k)\n\n# Evaluate\nrmse = mt.mean_squared_error(y_val_24k,y_pred_24k)\nr2_score = mt.r2_score(y_val_24k,y_pred_24k)\n\ntab_data.append(['PureGold_24k','{:.2}'.format(rmse), '{:.2}'.format(r2_score)])\n\n\n'''22k Gold'''\nknn_model.fit(X_train_22k,y_train_22k)\ny_pred_22k = knn_model.predict(X_val_22k)\n\n# Evaluate\nrmse = mt.mean_squared_error(y_val_22k,y_pred_22k)\nr2_score = mt.r2_score(y_val_22k,y_pred_22k)\n\ntab_data.append(['StdGold_22k','{:.2}'.format(rmse), '{:.2}'.format(r2_score)])\n\nprint(tabulate(tab_data, headers=['RMSE','R2_Score'], tablefmt=\"pretty\"))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Using KNN Regressor, the RMSE is even lower as compared to Linear Regression & the R2_Score is closer to 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Free Memory\ngc.collect()\ntab_data.clear()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ARIMA\n\nARIMA is a very popular statistical method for time series forecasting. ARIMA models take into account the past values to predict the future values. There are three important parameters in ARIMA:\n\n* p (past values used for forecasting the next value)\n* q (past forecast errors used to predict the future values)\n* d (order of differencing)\n\nParameter tuning for ARIMA consumes a lot of time. So we will use auto ARIMA which automatically selects the best combination of (p,q,d) that provides the least error. To read more about how auto ARIMA works, refer to this article:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ar = df.copy()\n\n# Split\ntr_pct = int(0.9 * len(df_ar))  # 90% for training\n\ntrain_df = df_ar[:tr_pct]\nval_df = df_ar[tr_pct:]\n\n'''Pure Gold 24k'''\ntr_24k = train_df['Pure_Gold_24k']\nval_24k = val_df['Pure_Gold_24k']\n\n'''Std Gold 22k'''\ntr_22k = train_df['Std_Gold_22k']\nval_22k = val_df['Std_Gold_22k']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''Forecasting'''\n\n# Fit & Forecasting (Pure Gold 24k)\narima_model = pm.auto_arima(tr_24k, seasonal=True, m=12)\nforecast_24k = arima_model.predict(val_24k.shape[0])\n\n# Fit & Forecasting (Pure Gold 22k)\narima_model = pm.auto_arima(tr_22k, seasonal=True, m=12)\nforecast_22k = arima_model.predict(val_22k.shape[0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataframe\nforecast24 = pd.DataFrame(forecast_24k, index=val_df.index,columns=['Forecast24k'])\nforecast22 = pd.DataFrame(forecast_22k, index=val_df.index,columns=['Forecast22k'])\n\n# Merge Dataframe\nforecast = pd.merge(forecast22,forecast24, left_index=True, right_index=True)\n\n# Inspect\nforecast.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.line(forecast, x=forecast.index, y=forecast.columns, title='Chennai Gold Rate Forecasting (ARIMA)')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\nfig.suptitle('Chennai Gold Rate Forecast (ARIMA)', fontsize=20)\n\nax1.plot(train_df['Pure_Gold_24k'])\nax1.plot(val_df['Pure_Gold_24k'])\nax1.plot(forecast['Forecast24k'])\nax1.set_title(\"Pure Gold 24k\", fontsize=10)\n\nax2.plot(train_df['Std_Gold_22k'])\nax2.plot(val_df['Std_Gold_22k'])\nax2.plot(forecast['Forecast22k'])\nax2.set_title(\"Std Gold 22k\", fontsize=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we saw earlier, an auto ARIMA model uses past data to understand the pattern in the time series. Using these values, the model captured an increasing trend in the series. Although the predictions using this technique are far better than that of the previously implemented machine learning models, these predictions are still not close to the real values.\n\nAs its evident from the plot, the model has captured a trend in the series, but does not focus on the seasonal part."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Free Memory\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prophet\n\nThere are a number of time series techniques that can be implemented on the price prediction dataset, but most of these techniques require a lot of data preprocessing before fitting the model. Prophet, designed and pioneered by Facebook, is a time series forecasting library that requires no data preprocessing and is extremely simple to implement. The input for Prophet is a dataframe with two columns: date and target (ds and y).\n\nProphet tries to capture the seasonality in the past data and works well when the dataset is large. Here is an interesting article that explains Prophet in a simple and intuitive manner"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a copy\ndf_pr = df.copy()\n\n# Converting Date Index to Column for Feature Extraction\ndf_pr.reset_index(level=0, inplace=True)\n\n# Splitting the dataframe into two\ndf_pr_24k = df_pr[['Date','Pure_Gold_24k']]\ndf_pr_22k = df_pr[['Date','Std_Gold_22k']]\n\n# Renaming Columns\ndf_pr_24k.rename(columns={'Date':'ds','Pure_Gold_24k':'y'},inplace=True)\ndf_pr_22k.rename(columns={'Date':'ds','Std_Gold_22k':'y'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''Pure Gold 24k dataset'''\n\n# Split\ntr_pct = int(0.9 * len(df_pr))  # 90% for training\n\ntrain_df_24k = df_pr_24k[:tr_pct]\nval_df_24k = df_pr_24k[tr_pct:]\n\n'''Std Gold 22k dataset'''\n\n# Split\n\ntrain_df_22k = df_pr_22k[:tr_pct]\nval_df_22k = df_pr_22k[tr_pct:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instantiating Model\nproph = Prophet()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''Forecasting'''\n\n# Pure Gold 24k\nproph.fit(train_df_24k)\n\ngold24k_price = proph.make_future_dataframe(periods=len(val_df_24k))\nforecast24 = proph.predict(gold24k_price)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Re-Instantiating Model\nproph = Prophet()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''Forecasting'''\n\n# Std Gold 22k\nproph.fit(train_df_22k)\n\ngold22k_price = proph.make_future_dataframe(periods=len(val_df_22k))\nforecast22 = proph.predict(gold22k_price)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding Predictions to the Validation Dataset\nval_df_24k['Predictions'] = 0\nval_df_24k['Predictions'] = forecast24['yhat']\n\nval_df_22k['Predictions'] = 0\nval_df_22k['Predictions'] = forecast22['yhat']","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Plot\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\nfig.suptitle('Chennai Gold Rate Forecast (Prophet)', fontsize=20)\n\nax1.plot(train_df_24k['y'])\nax1.plot(val_df_24k[['y', 'Predictions']])\nax1.set_title(\"Pure Gold 24k\", fontsize=10)\n\nax2.plot(train_df_22k['y'])\nax2.plot(val_df_22k[['y', 'Predictions']])\nax2.set_title(\"Std Gold 22k\", fontsize=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Free Memory\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### I hope this technical analysis on the Chennai Gold Rate has given you some insights and helped you understand the regression modelling & forecasting (ARIMA & Prophet). Please do consider to UPVOTE."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}