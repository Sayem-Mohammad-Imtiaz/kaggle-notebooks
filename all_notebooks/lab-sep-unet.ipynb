{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as T\nfrom torchvision import datasets\nfrom torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\nimport torchvision.utils as vutils\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision.models import vgg19\n%matplotlib inline\nimport pickle\nfrom skimage import io, color","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cuda = True if torch.cuda.is_available() else False\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display(img):\n    plt.figure()\n    plt.set_cmap('gray')\n    plt.imshow(img)\n    plt.show()\n\ndef combineLAB(l, a, b):\n    shape = (l.shape[0], l.shape[1], 3)\n    zeros = np.zeros(shape)\n    zeros[:, :, 0] = l\n    zeros[:, :, 1] = a\n    zeros[:, :, 2] = b\n    return zeros\n\ndef lab_normal_image(path):\n    l, a ,b = load_img_for_training(path)\n    return l, a ,b\n\ndef l_image(l):\n    l=l.reshape(256,256)\n    l=(l*50)+50\n    shape = (l.shape[0], l.shape[1], 3)\n    zeros = np.zeros(shape)\n    zeros[:, :, 0] = l\n    rgb = color.lab2rgb(zeros)\n    return rgb\n\ndef a_image(a):\n    a=a.reshape(256,256)\n    a=a*100\n    shape = (a.shape[0], a.shape[1], 3)\n    zeros = np.zeros(shape)\n    zeros[:, :, 1] = a\n    rgb = color.lab2rgb(zeros)\n    return rgb\n\ndef b_image(b):\n    b=b.reshape(256,256)\n    b=b*100\n    shape = (b.shape[0], b.shape[1], 3)\n    zeros = np.zeros(shape)\n    zeros[:, :, 2] = b\n    rgb = color.lab2rgb(zeros)\n    return rgb\n\n\ndef rgb_image(l, a ,b):\n    l=l.reshape(256,256)\n    a=a.reshape(256,256)\n    b=b.reshape(256,256)\n    l=(l*50)+50\n    a,b=a*100 , b*100\n    lab = combineLAB(l, a ,b)\n    rgb = color.lab2rgb(lab)\n    return rgb\n\ndef load_img_for_training(img):\n    #img = io.imread(img_path)\n    #img = skimage.transform.resize(img,(256,256))\n    lab = color.rgb2lab(img)\n    l, a, b = (lab[:, :, 0]-50)/50, lab[:, :, 1]/100, lab[:, :, 2]/100 \n    #lgray = get_l_from_gray(img)\n    return l, a ,b\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = \"../input/flowers-recognition/flowers\"\ndataset_color = datasets.ImageFolder(root= PATH, transform=T.Compose([\n                               T.Resize([256,256]),\n                               ]))\n\nprint(len(dataset_color))\n#print(len(dataset_color2))\n#dataset_color=dataset_color1 +dataset_color2\n#print(len(dataset_color))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GAN_dataset(Dataset):\n    def __init__(self, dataset_input,n):\n        self.dataset1 = dataset_input\n        self.n=n\n\n    def __getitem__(self, index):\n        x1,l1 = self.dataset1[index]\n        l_dat,a_dat,b_dat=lab_normal_image(x1)\n        l_dat=l_dat.reshape(1,256,256)\n        a_dat=a_dat.reshape(1,256,256)\n        b_dat=b_dat.reshape(1,256,256)\n        l_dat = l_dat.astype('float32') \n        a_dat = a_dat.astype('float32')\n        b_dat = b_dat.astype('float32')  \n        l_dat=torch.from_numpy(l_dat)\n        a_dat=torch.from_numpy(a_dat)\n        b_dat=torch.from_numpy(b_dat)\n        return l_dat,a_dat,b_dat\n\n    def __len__(self):\n        return len(self.dataset1)\n        #return self.n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = GAN_dataset(dataset_color,1360)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_split = .05\nshuffle_dataset = True\nrandom_seed= 42\n\n# Creating data indices for training and validation splits:\ndataset_size = len(dataset)\nindices = list(range(dataset_size))\nsplit = int(np.floor(validation_split * dataset_size))\nif shuffle_dataset :\n    np.random.seed(random_seed)\n    np.random.shuffle(indices)\ntrain_indices, val_indices = indices[split:], indices[:split]\n\n# Creating PT data samplers and loaders:\ntrain_sampler = SubsetRandomSampler(train_indices)\nvalid_sampler = SubsetRandomSampler(val_indices)\n\ntrain_loader = torch.utils.data.DataLoader(dataset, batch_size=10,\n                                           sampler=train_sampler,num_workers=2)\nvalidation_loader = torch.utils.data.DataLoader(dataset, batch_size=5,\n                                                sampler=valid_sampler,num_workers=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def double_conv(in_c, out_c):\n  conv = nn.Sequential(\n      nn.Conv2d(in_c, out_c, kernel_size = 3, padding = 1),\n      nn.BatchNorm2d(out_c),\n      nn.ReLU(inplace  = True),\n      nn.Conv2d(out_c, out_c, kernel_size = 3, padding = 1),\n      nn.BatchNorm2d(out_c),\n      nn.ReLU(inplace  = True),\n  )\n  return conv\n\ndef crop_img(tensor, target_tensor):\n  target_size = target_tensor.size()[2]\n  tensor_size = tensor.size()[2]\n  delta = tensor_size - target_size\n  delta = delta//2\n  return tensor[:,:, delta:tensor_size-delta, delta:tensor_size-delta]\n\nclass Unet(nn.Module):\n  def __init__(self):\n      \n    super(Unet, self).__init__()\n\n    self.max_pool_2x2 = nn.MaxPool2d(kernel_size = 1, stride  =2)\n    self.down_conv_1 = double_conv(1, 64)\n    self.down_conv_2 = double_conv(64, 128)\n    self.down_conv_3 = double_conv(128, 256)\n    self.down_conv_4 = double_conv(256, 512)\n    self.down_conv_5 = double_conv(512, 1024)\n\n    self.up_trans_1 = nn.ConvTranspose2d(in_channels = 1024, out_channels = 512, kernel_size = 2, stride = 2)\n    self.up_conv_1 = double_conv(1024, 512)\n    self.up_trans_2 = nn.ConvTranspose2d(in_channels = 512, out_channels = 256, kernel_size = 2, stride = 2)\n    self.up_conv_2 = double_conv(512, 256)\n    self.up_trans_3 = nn.ConvTranspose2d(in_channels = 256, out_channels = 128, kernel_size = 2, stride = 2)\n    self.up_conv_3 = double_conv(256, 128)\n    self.up_trans_4 = nn.ConvTranspose2d(in_channels = 128, out_channels = 64, kernel_size = 2, stride = 2)\n    self.up_conv_4 = double_conv(128, 64)\n    self.out = nn.Sequential(\n        nn.Conv2d(in_channels = 64, out_channels = 1, kernel_size = 1),\n        nn.BatchNorm2d(1),\n        nn.Tanh()\n        )\n\n\n    \n\n  def forward(self, image):\n    #encoder\n    x1 = self.down_conv_1(image)   #input 64x5x64x64\n    #print(x1.shape)\n    x2 = self.max_pool_2x2(x1)\n    #print(x2.shape)\n    x3 = self.down_conv_2(x2)     #  64x128x32x32\n    #print(x3.shape)\n    x4 = self.max_pool_2x2(x3)\n    #print(x4.shape)\n    x5 = self.down_conv_3(x4)     #  64x256x16x16\n    #print(x5.shape)\n    x6 = self.max_pool_2x2(x5)\n    #print(x6.shape)\n    x7 = self.down_conv_4(x6)     #  64x512x8x8\n    #print(x7.shape)\n    x8 = self.max_pool_2x2(x7)\n    #print(x8.shape)\n    x9 = self.down_conv_5(x8)    #   64x1024x4x4\n    #print(x9.shape)\n\n    #decoder\n    x = self.up_trans_1(x9)\n    y = crop_img(x7, x)\n    x = self.up_conv_1(torch.cat([x, y], 1))\n\n    x = self.up_trans_2(x)\n    y = crop_img(x5, x)\n    x = self.up_conv_2(torch.cat([x, y], 1))\n\n    x = self.up_trans_3(x)\n    y = crop_img(x3, x)\n    x = self.up_conv_3(torch.cat([x, y], 1))\n\n    x = self.up_trans_4(x)\n    y = crop_img(x1, x)\n    x = self.up_conv_4(torch.cat([x, y], 1))\n\n    x = self.out(x)      #output size : 64x3x64x64\n\n\n    return x\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modela = Unet()\nif  cuda:\n  modela  = modela.cuda()\n\nmodelb = Unet()\nif  cuda:\n  modelb  = modelb.cuda()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criteriona = nn.MSELoss()\ncriterionb = nn.MSELoss()\ncriterionl = nn.L1Loss()\nif cuda:\n  criterionl = criterionl.cuda()\nif cuda:\n  criteriona = criteriona.cuda()\nif cuda:\n  criterionb = criterionb.cuda()\n# specify loss function\noptimizera = torch.optim.Adam(modela.parameters(), lr=0.002)\noptimizerb = torch.optim.Adam(modelb.parameters(), lr=0.002)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenamea =  \"../input/lab-sep-unet/final_modela.sav\"\nfilenameb = \"../input/lab-sep-unet/final_modelb.sav\"\nmodela = pickle.load(open(filenamea, 'rb'))\nmodelb = pickle.load(open(filenameb, 'rb'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_epochs = 40\nlamb = 50\nfor epoch in range(1, n_epochs+1):\n    train_loss = 0.0\n    for inp, outa ,outb in train_loader:\n        batch = inp.size(0)\n        inp = inp.to(device)\n        outa = outa.to(device)\n        outb = outb.to(device)\n        modela.zero_grad()       \n        rta = modela(inp)   \n        lossA = criteriona(rta, outa) + lamb * criterionl(rta,outa)\n        lossA.backward()\n        optimizera.step()\n        train_loss += lossA.item()*inp.size(0)\n        modelb.zero_grad()       \n        rtb = modelb(inp)\n        lossB = criterionb(rtb, outb) +lamb * criterionl(rtb,outb)\n        lossB.backward()\n        optimizerb.step()\n        train_loss += lossB.item()*inp.size(0)\n    filenamea = 'final_modela.sav'\n    pickle.dump(modela, open(filenamea, 'wb'))\n    filenameb = 'final_modelb.sav'\n    pickle.dump(modelb, open(filenameb, 'wb'))\n    filenamec = 'opta.sav'\n    pickle.dump(optimizera, open(filenamec, 'wb'))\n    filenamed = 'optd.sav'\n    pickle.dump(optimizerb, open(filenamed, 'wb'))\n    # print avg training statistics \n    train_loss = train_loss/len(train_loader)\n    print('Epoch: {} \\tTraining Loss A: {:.6f}'.format(epoch, train_loss))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valiter = iter(train_loader)\nval_l,val_a,val_b = valiter.next()\ni_l = val_l.numpy()\no_a = val_a.numpy()\no_b = val_b.numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_l=val_l.to(device)\noutput_A = modela(val_l)\n\noutput_A = output_A.cpu()\noutput_A = output_A.detach().numpy()\noutput_B = modelb(val_l)\n\noutput_B = output_B.cpu()\noutput_B = output_B.detach().numpy()\nprint(o_a.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def imshow(img):\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(35,8))\nfor idx in range(0,5):\n    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n    a=l_image(i_l[idx])\n    plt.imshow(a)\n\nfig = plt.figure(figsize=(35,8))\nfor idx in range(0,5):\n    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n    a=rgb_image(i_l[idx],o_a[idx],o_b[idx])\n    plt.imshow(a)\nfig = plt.figure(figsize=(35,8))\n# display 20 images\nfor idx in range(0,5):\n    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n    a=rgb_image(i_l[idx],output_A[idx],output_B[idx])\n    plt.imshow(a)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(35,8))\nfor idx in range(5,10):\n    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n    a=l_image(i_l[idx])\n    plt.imshow(a)\n\nfig = plt.figure(figsize=(35,8))\nfor idx in range(5,10):\n    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n    a=rgb_image(i_l[idx],o_a[idx],o_b[idx])\n    plt.imshow(a)\nfig = plt.figure(figsize=(35,8))\n# display 20 images\nfor idx in range(5,10):\n    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n    a=rgb_image(i_l[idx],output_A[idx],output_B[idx])\n    plt.imshow(a)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(35,8))\nfor idx in range(10,15):\n    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n    a=l_image(i_l[idx])\n    plt.imshow(a)\n\nfig = plt.figure(figsize=(35,8))\nfor idx in range(10,15):\n    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n    a=rgb_image(i_l[idx],o_a[idx],o_b[idx])\n    plt.imshow(a)\nfig = plt.figure(figsize=(35,8))\n# display 20 images\nfor idx in range(10,15):\n    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n    a=rgb_image(i_l[idx],output_A[idx],output_B[idx])\n    plt.imshow(a)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(35,8))\nfor idx in range(15,20):\n    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n    a=l_image(i_l[idx])\n    plt.imshow(a)\n\nfig = plt.figure(figsize=(35,8))\nfor idx in range(15,20):\n    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n    a=rgb_image(i_l[idx],o_a[idx],o_b[idx])\n    plt.imshow(a)\nfig = plt.figure(figsize=(35,8))\n# display 20 images\nfor idx in range(15,20):\n    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n    a=rgb_image(i_l[idx],output_A[idx],output_B[idx])\n    plt.imshow(a)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(45,8))\nfor idx in range(20,25):\n    ax = fig.add_subplot(2, 30/2, idx+1, xticks=[], yticks=[])\n    a=l_image(i_l[idx])\n    plt.imshow(a)\n\nfig = plt.figure(figsize=(45,8))\nfor idx in range(20,25):\n    ax = fig.add_subplot(2, 30/2, idx+1, xticks=[], yticks=[])\n    a=rgb_image(i_l[idx],o_a[idx],o_b[idx])\n    plt.imshow(a)\nfig = plt.figure(figsize=(45,8))\n# display 20 images\nfor idx in range(20,25):\n    ax = fig.add_subplot(2, 30/2, idx+1, xticks=[], yticks=[])\n    a=rgb_image(i_l[idx],output_A[idx],output_B[idx])\n    plt.imshow(a)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(45,8))\nfor idx in range(25,30):\n    ax = fig.add_subplot(2, 30/2, idx+1, xticks=[], yticks=[])\n    a=l_image(i_l[idx])\n    plt.imshow(a)\n\nfig = plt.figure(figsize=(45,8))\nfor idx in range(25,30):\n    ax = fig.add_subplot(2, 30/2, idx+1, xticks=[], yticks=[])\n    a=rgb_image(i_l[idx],o_a[idx],o_b[idx])\n    plt.imshow(a)\nfig = plt.figure(figsize=(45,8))\n# display 20 images\nfor idx in range(25,30):\n    ax = fig.add_subplot(2, 30/2, idx+1, xticks=[], yticks=[])\n    a=rgb_image(i_l[idx],output_A[idx],output_B[idx])\n    plt.imshow(a)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for val_l,val_a, val_b in validation_loader:\n        \n        i_l = val_l.numpy()\n        o_a = val_a.numpy()\n        o_b = val_b.numpy()\n        val_l=val_l.to(device)\n        output_A = modela(val_l)\n\n        output_A = output_A.cpu()\n        output_A = output_A.detach().numpy()\n        output_B = modelb(val_l)\n\n        output_B = output_B.cpu()\n        output_B = output_B.detach().numpy()\n        fig = plt.figure(figsize=(35, 8))\n        for idx in range(0,5):\n            ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n            a=l_image(i_l[idx])\n            plt.imshow(a)\n        fig = plt.figure(figsize=(35, 8))\n        for idx in range(0,5):\n            ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n            plt.imshow(rgb_image(i_l[idx],o_a[idx],o_b[idx]))\n        fig = plt.figure(figsize=(35, 8))    \n        for idx in range(0,5):\n            ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n            plt.imshow(rgb_image(i_l[idx],output_A[idx],output_B[idx]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}