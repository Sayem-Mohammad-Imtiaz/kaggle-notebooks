{"cells":[{"metadata":{},"cell_type":"markdown","source":"# The Dataset contains transactions made by credit cards."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport sklearn\nimport scipy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report,accuracy_score\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.svm import OneClassSVM\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 14, 8\nRANDOM_SEED = 42\nLABELS = [\"Nonfraudulent\", \"Fraudulent\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Reading the data."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/credit-card-anomaly-detection/creditcard.csv',sep=',')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking to see the number of rows and columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Credit Card Fraud Detection data -  rows:\",data.shape[0],\" columns:\", data.shape[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Summary statistics (Mean,median,standard deviation) of the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> From the above, I can see that there are 284,807 transactions."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Checking to see if there are any null values in the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> There are no null or missing values from the dataset."},{"metadata":{},"cell_type":"markdown","source":"# Frequency of normal and fraudulent transactions using a histogram."},{"metadata":{"trusted":true},"cell_type":"code","source":"count_classes = pd.value_counts(data['Class'], sort = True)\n\ncount_classes.plot(kind = 'bar', rot=0)\n\nplt.title(\"Transaction Class Distribution\")\n\nplt.xticks(range(2), LABELS)\n\nplt.xlabel(\"Class\")\n\nplt.ylabel(\"Frequency\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking to see the total amount of Fraudulent and Nonfraudulent transactions."},{"metadata":{"trusted":true},"cell_type":"code","source":"fraudulent = data[data['Class']==1]\n\nnonfraudulent = data[data['Class']==0]\n\nprint(f'fraudulent{fraudulent.shape}  nonfraudulent{nonfraudulent.shape}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> From the above, we can see that the fraudulent transactions are 492 and the non fraudulent are 284,315."},{"metadata":{},"cell_type":"markdown","source":"Checking the summary statistics of the Fraudulent transactions."},{"metadata":{"trusted":true},"cell_type":"code","source":"fraudulent.Amount.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the mean, the money transactions for the fraudulent ones are more. "},{"metadata":{},"cell_type":"markdown","source":"Checking the summary statistics of the NonFraudulent transactions."},{"metadata":{"trusted":true},"cell_type":"code","source":"nonfraudulent.Amount.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking to see how the transactions are occurring in respect to amount."},{"metadata":{"trusted":true},"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\nf.suptitle('Amount per transaction by class')\nbins = 50\nax1.hist(fraudulent.Amount, bins = bins)\nax1.set_title('Fraud')\nax2.hist(nonfraudulent.Amount, bins = bins)\nax2.set_title('Nonfraudulent')\nplt.xlabel('Amount ($)')\nplt.ylabel('Number of Transactions')\nplt.xlim((0, 20000))\nplt.yscale('log')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scatter plot showing transactions occurrence verses Time"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We Will check Do fraudulent transactions occur more often during certain time frame ? Let us find out with a visual representation.\n\nf, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\nf.suptitle('Time of transaction vs Amount by class')\nax1.scatter(fraudulent.Time, fraudulent.Amount)\nax1.set_title('Fraud')\nax2.scatter(nonfraudulent.Time, nonfraudulent.Amount)\nax2.set_title('Normal')\nplt.xlabel('Time (in Seconds)')\nplt.ylabel('Amount')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Boxplots showing summary statistics for the Amount column"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6))\ns = sns.boxplot(ax = ax1, x=\"Class\", y=\"Amount\", hue=\"Class\",data=data, palette=\"PRGn\",showfliers=False)\ns = sns.boxplot(ax = ax2, x=\"Class\", y=\"Amount\", hue=\"Class\",data=data, palette=\"PRGn\",showfliers=True)\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Correlation matrix that contains a heatmap showing the relationship between the different variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (14,14))\nplt.title('Credit Card Transactions features correlation plot')\ncorr = data.corr()\nsns.heatmap(corr,xticklabels=corr.columns,yticklabels=corr.columns,linewidths=.1,cmap=\"Blues\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the above HeatMap most of the features do not correlate to other features but there are some features that either has a positive or a negative correlation with each other. For example 'V20' and Amount have some correlation."},{"metadata":{},"cell_type":"markdown","source":"# Scatterplot for Amount and V2 showing a line of best fit using the equation of a straight line y = mx + c, where m is the slope of the line and c is the y intercept."},{"metadata":{"trusted":true},"cell_type":"code","source":"s = sns.lmplot(x='V2', y='Amount',data=data, hue='Class', fit_reg=True,scatter_kws={'s':2})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building an outlier detection model for the data using the Isolation Forest and the Local Outlier Factor"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Checking Fraud and the normal dataset \nFraud = data[data['Class']==1]\n\nValid = data[data['Class']==0]\n\noutlier_fraction = len(Fraud)/float(len(Valid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(outlier_fraction)\n\nprint(\"Fraud Cases : {}\".format(len(Fraud)))\n\nprint(\"Valid Cases : {}\".format(len(Valid)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create independent and Dependent Features\ncolumns = data.columns.tolist()\n\n# Filter the columns to remove data we do not want \ncolumns = [c for c in columns if c not in [\"Class\"]]\n\n# Store the variable we are predicting \ntarget = \"Class\"\n\n# Define a random state \nstate = np.random.RandomState(42)\nX = data[columns]\nY = data[target]\nX_outliers = state.uniform(low=0, high=1, size=(X.shape[0], X.shape[1]))\n\n# Print the shapes of X & Y\nprint(X.shape)\nprint(Y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifiers = {\n    \"Isolation Forest\":IsolationForest(n_estimators=100, max_samples=len(X),contamination=outlier_fraction,random_state=state, verbose=0),\n    \"Local Outlier Factor\":LocalOutlierFactor(n_neighbors=20, algorithm='auto',leaf_size=30, metric='minkowski', p=2, metric_params=None, contamination=outlier_fraction)\n}\ntype(classifiers)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analyzing the models using Errors, Confusion Matrix, Accuracy Score and Classification Report"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nn_outliers = len(Fraud)\nfor i, (clf_name,clf) in enumerate(classifiers.items()):\n    #Fit the data and tag outliers\n    if clf_name == \"Local Outlier Factor\":\n        y_pred = clf.fit_predict(X)\n        scores_prediction = clf.negative_outlier_factor_\n    elif clf_name == \"Isolation Forest\":\n        clf.fit(X)\n        scores_prediction = clf.decision_function(X)\n        y_pred = clf.predict(X)\n    else:    \n       print ('No other model')\n    \n    #Reshape the prediction values to 0 for Valid transactions , 1 for Fraud transactions\n    y_pred[y_pred == 1] = 0\n    y_pred[y_pred == -1] = 1\n    n_errors = (y_pred != Y).sum()\n    # Run Classification Metrics\n    print(\"{}: {}\".format(clf_name,n_errors))\n    print(\"Accuracy Score :\")\n    print(accuracy_score(Y,y_pred))\n    print(\"Classification Report :\")\n    print(classification_report(Y,y_pred))\n    conf_matrix = confusion_matrix(Y, y_pred)\n    sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt='d');\n    plt.title('Confusion Matrix for ' + clf_name)\n    plt.ylabel('Actual class')\n    plt.xlabel('Predicted class')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analysis"},{"metadata":{},"cell_type":"markdown","source":"* The Isolation Forest model detected 675 errors while the Local Outlier Factor detected 675 errors vs.\n* Isolation Forest has a 99.76% more accuracy than Local Outlier Factor of 99.67%\n* The Isolation Forest Method performed much better in determining the fraud cases.\n* To improve on the accuracy, the sample size can be increased.\n* We can also use complex anomaly detection models to get better accuracy in determining more fraudulent cases"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}