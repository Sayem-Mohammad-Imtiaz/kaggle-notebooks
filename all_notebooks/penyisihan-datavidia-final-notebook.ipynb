{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Preprocessing\nExternal data for preprocesing and EDA:\n1. https://github.com/okkyibrohim/id-multi-label-hate-speech-and-abusive-language-detection\n2. https://www.kaggle.com/oswinrh/indonesian-stoplist\n\n\nSteps:\n1. Lower casing all text, \n2. Remove non alpha-numeric characters \n3. Remove unnecessary characters such as\"\\n\" \"\\r\"\n4. Normalization using 'Alay' dictionary \n5. Remove Emojis\n\nReferences:\n\n[1] Muhammad Okky Ibrohim and Indra Budi. 2019. Multi-label Hate Speech and Abusive Language Detection in Indonesian Twitter. In ALW3: 3rd Workshop on Abusive Language Online, 46-57.  \n[2] Tala, F. Z. (2003). A Study of Stemming Effects on Information Retrieval in Bahasa Indonesia. M.Sc. Thesis. Master of Logic Project. Institute for Logic, Language and Computation. Universiteit van Amsterdam, The Netherlands.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"!git clone https://github.com/okkyibrohim/id-multi-label-hate-speech-and-abusive-language-detection.git","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n!ls '../input'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ./*","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/penyisihan-datavidia-7-0/train.csv')\ndata_test = pd.read_csv('../input/penyisihan-datavidia-7-0/test.csv')\n\nalay_dict = pd.read_csv('id-multi-label-hate-speech-and-abusive-language-detection/new_kamusalay.csv', encoding='latin-1', header=None)\nalay_dict = alay_dict.rename(columns={0: 'original', \n                                      1: 'replacement'})\n\nid_stopword_dict = pd.read_csv('../input/indonesian-stoplist/stopwordbahasa.csv', header=None)\nid_stopword_dict = id_stopword_dict.rename(columns={0: 'stopword'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Text Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### \"Alay\" Dictionary"},{"metadata":{"trusted":true},"cell_type":"code","source":"alay_dict.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Indonesian Stopwords"},{"metadata":{"trusted":true},"cell_type":"code","source":"id_stopword_dict.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing The Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\ndef lowercase(text):\n    return text.lower()\n\ndef remove_unnecessary_char(text):\n    text = re.sub('\\n',' ',text) # Remove every '\\n'\n    text = re.sub('\\r', ' ', text)\n    text = re.sub('  +', ' ', text) # Remove extra spaces\n    return text\n    \ndef remove_nonaplhanumeric(text):\n    text = re.sub('[^0-9a-zA-Z]+', ' ', text) \n    return text\n\nalay_dict_map = dict(zip(alay_dict['original'], alay_dict['replacement']))\ndef normalize_alay(text):\n    return ' '.join([alay_dict_map[word] if word in alay_dict_map else word for word in text.split(' ')])\n\n\nprint(\"remove_nonaplhanumeric: \", remove_nonaplhanumeric(\"Halooo,,,,, duniaa!!\"))\nprint(\"lowercase: \", lowercase(\"Halooo, duniaa!\"))\nprint(\"remove_unnecessary_char: \", remove_unnecessary_char(\"Hehe\\n\\n \\r\\r apa kabs  hehe\"))\nprint(\"normalize_alay: \", normalize_alay(\"aamiin adek abis\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import emoji\ndef emoji_cleaning(text):\n    \n    # Change emoji to text\n    text = emoji.demojize(text).replace(\":\", \" \")\n    \n    # Delete repeated emoji\n    tokenizer = text.split()\n    repeated_list = []\n    \n    for word in tokenizer:\n        if word not in repeated_list:\n            repeated_list.append(word)\n    \n    text = ' '.join(text for text in repeated_list)\n    text = text.replace(\"_\", \" \").replace(\"-\", \" \")\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(text):\n    text = lowercase(text) # 1\n    text = remove_nonaplhanumeric(text) # 2\n    text = remove_unnecessary_char(text) # 2\n    text = normalize_alay(text) # 3\n    text = emoji_cleaning(text) # 6\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['review_text'] = data['review_text'].apply(preprocess)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test['review_text'] = data_test['review_text'].apply(preprocess)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.to_csv('preprocessed_review_train.csv', index=False)\ndata_test.to_csv('preprocessed_review_test.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.concat([data['review_text'],data_test['review_text']]).reset_index(drop=True).to_csv('all_text.txt', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos_len = data[data['category']==1].shape[0]\nneg_len = data[data['category']==0].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (7, 5)\nplt.bar(10,pos_len,3, label=\"Positive Reviews\", color='blue')\nplt.bar(15,neg_len,3, label=\"Negative Reviews\", color='red')\nplt.legend()\nplt.ylabel('Number of examples')\nplt.title('Propertion of examples')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['length'] = data['review_text'].apply(lambda x: len(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (18.0, 6.0)\nbins = 150\nplt.hist(data[data['category'] == 0]['length'], alpha = 0.6, bins=bins, label='Negative Reviews')\nplt.hist(data[data['category'] == 1]['length'], alpha = 0.8, bins=bins, label='Postive Reviews')\nplt.xlabel('length')\nplt.ylabel('numbers')\nplt.legend(loc='upper right')\nplt.title('Characters in review')\nplt.xlim(0,150)\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\ntweet_len=data[data['category']==1]['review_text'].str.len()\nax1.hist(tweet_len,color='blue')\nax1.set_title('Positive Reviews')\ntweet_len=data[data['category']==0]['review_text'].str.len()\nax2.hist(tweet_len,color='red')\nax2.set_title('Negative Reviews')\nfig.suptitle('Characters in review')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\ntweet_len=data[data['category']==1]['review_text'].str.split().map(lambda x: len(x))\nax1.hist(tweet_len,color='blue')\nax1.set_title('Positive Reviews')\ntweet_len=data[data['category']==0]['review_text'].str.split().map(lambda x: len(x))\nax2.hist(tweet_len,color='red')\nax2.set_title('Negative Reviews')\nfig.suptitle('Words in a Review')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\nword=data[data['category']==1]['review_text'].str.split().apply(lambda x : [len(i) for i in x])\nsns.distplot(word.map(lambda x: np.mean(x)),ax=ax1,color='blue')\nax1.set_title('Positive Reviews')\nword=data[data['category']==0]['review_text'].str.split().apply(lambda x : [len(i) for i in x])\nsns.distplot(word.map(lambda x: np.mean(x)),ax=ax2,color='red')\nax2.set_title('Negative Reviews')\nfig.suptitle('Average word length in each review')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import defaultdict\ndef create_corpus(target):\n    corpus=[]\n    \n    for x in data[data['category']==target]['review_text'].str.split():\n        for i in x:\n            corpus.append(i)\n    return corpus","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop = list(id_stopword_dict['stopword'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus=create_corpus(0)\n\ndic=defaultdict(int)\nfor word in corpus:\n    if word in stop:\n        dic[word]+=1\n        \ntop=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10]\n\nplt.rcParams['figure.figsize'] = (18.0, 6.0)\nplt.title('Top Words for negative reviews')\nx,y=zip(*top)\nplt.bar(x,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus=create_corpus(1)\n\ndic=defaultdict(int)\nfor word in corpus:\n    if word in stop:\n        dic[word]+=1\n        \ntop=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10]\n\nplt.rcParams['figure.figsize'] = (18.0, 6.0)\nplt.title('Top Words for positive reviews')\nx,y=zip(*top)\nplt.bar(x,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pretraining Language Model with MLM Training\nPretraining LM sebenarnya dilakukan di notebook terpisah, karena membutuhkan waktu yang lama. Berikut Kode yang digunakan untuk pretraining tetapi dimodifikasi untuk waktu running.\n\nPretraining dilakukan untuk mengadaptasi Language Model ke domain dari text yang diberikan.\nPretraining menggunakan initial weight dari  https://github.com/indobenchmark/indonlu\n\nReference:\n\n[1] Bryan Wilie, Karissa Vincentio, Genta Indra Winata, Samuel Cahyawijaya, X. Li, Zhi Yuan Lim, S. Soleman, R. Mahendra, Pascale Fung, Syafri Bahar, & A. Purwarianti (2020). IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding. In Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing."},{"metadata":{"trusted":true},"cell_type":"code","source":"import os, sys\n\nimport random\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch import optim\nimport torch.nn.functional as F\nfrom tqdm import tqdm\n\nfrom transformers import BertForMaskedLM, BertForSequenceClassification, BertConfig, BertTokenizer\nfrom nltk.tokenize import TweetTokenizer\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer\n\nfrom sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set_seed(25012021)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\nconfig = BertConfig.from_pretrained('indobenchmark/indobert-base-p1')\nconfig.num_labels = 2\n\n# Instantiate model\nmodel = BertForMaskedLM.from_pretrained('indobenchmark/indobert-base-p1', config=config)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import LineByLineTextDataset\n\ndataset = LineByLineTextDataset(\n    tokenizer=tokenizer,\n    file_path=\"./all_text.txt\",\n    block_size=128,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import DataCollatorForLanguageModeling\n\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"./datavidia_lm\",\n    overwrite_output_dir=True,\n    num_train_epochs=1, #100, di notebook aslinya dilakukan 100 epoch training\n    per_gpu_train_batch_size=16,\n    save_steps=10_000,\n    save_total_limit=2,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=dataset,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrainer.train()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainer.save_model(\"./datavidia_lm\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classifier Training"},{"metadata":{},"cell_type":"markdown","source":"## Indobert"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('./preprocessed_review_train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_split, valid_split = train_test_split(df_train.index, test_size=0.1, stratify=df_train['category'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\ndef count_param(module, trainable=False):\n    if trainable:\n        return sum(p.numel() for p in module.parameters() if p.requires_grad)\n    else:\n        return sum(p.numel() for p in module.parameters())\n    \n\ndef metrics_to_string(metric_dict):\n    string_list = []\n    for key, value in metric_dict.items():\n        string_list.append('{}:{:.2f}'.format(key, value))\n    return ' '.join(string_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set_seed(25012021)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\nconfig = BertConfig.from_pretrained('../input/lm-training/datavidia_lm/')\nconfig.num_labels = 2\n\n# Instantiate model\nmodel = BertForSequenceClassification.from_pretrained('../input/lm-training/datavidia_lm/', config=config)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DocumentSentimentDataset(Dataset):\n    # Static constant variable\n    NUM_LABELS = 2\n    \n    def load_dataset(self, path, split): \n        df = pd.read_csv(path)\n        if split is not None:\n            df = df.iloc[split].reset_index(drop=True)\n        df['review_text'] = df['review_text'].values.astype('U')\n        df['review_text'] = df['review_text'].apply(lambda x: x.lower())\n        return df\n    \n    def __init__(self, dataset_path, tokenizer, no_special_token=False, train=True, split=None, *args, **kwargs):\n        self.data = self.load_dataset(dataset_path, split)\n        self.tokenizer = tokenizer\n        self.no_special_token = no_special_token\n        if not train:\n            self.data['category'] = 0\n    \n    def __getitem__(self, index):\n        data = self.data.loc[index,:]\n        text, sentiment = data['review_text'], data['category']\n        subwords = self.tokenizer.encode(text, add_special_tokens=not self.no_special_token)\n        return np.array(subwords), np.array(sentiment), data['review_text']\n    \n    def __len__(self):\n        return len(self.data)    \n        \nclass DocumentSentimentDataLoader(DataLoader):\n    def __init__(self, max_seq_len=512, *args, **kwargs):\n        super(DocumentSentimentDataLoader, self).__init__(*args, **kwargs)\n        self.collate_fn = self._collate_fn\n        self.max_seq_len = max_seq_len\n        \n    def _collate_fn(self, batch):\n        batch_size = len(batch)\n        max_seq_len = max(map(lambda x: len(x[0]), batch))\n        max_seq_len = min(self.max_seq_len, max_seq_len)\n        \n        subword_batch = np.zeros((batch_size, max_seq_len), dtype=np.int64)\n        mask_batch = np.zeros((batch_size, max_seq_len), dtype=np.float32)\n        sentiment_batch = np.zeros((batch_size, 1), dtype=np.int64)\n        \n        seq_list = []\n        for i, (subwords, sentiment, raw_seq) in enumerate(batch):\n            subwords = subwords[:max_seq_len]\n            subword_batch[i,:len(subwords)] = subwords\n            mask_batch[i,:len(subwords)] = 1\n            sentiment_batch[i,0] = sentiment\n            \n            seq_list.append(raw_seq)\n            \n        return subword_batch, mask_batch, sentiment_batch, seq_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = DocumentSentimentDataset('./preprocessed_review_train.csv', tokenizer, split=train_split)\nvalid_dataset = DocumentSentimentDataset('./preprocessed_review_train.csv', tokenizer, split=valid_split)\ntest_dataset = DocumentSentimentDataset('./preprocessed_review_test.csv', tokenizer, train=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DocumentSentimentDataLoader(dataset=train_dataset, max_seq_len=512, batch_size=32, num_workers=16, shuffle=True)  \nvalid_loader = DocumentSentimentDataLoader(dataset=valid_dataset, max_seq_len=512, batch_size=32, num_workers=16, shuffle=False)\ntest_loader = DocumentSentimentDataLoader(dataset=test_dataset, max_seq_len=512, batch_size=32, num_workers=16, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=3e-6)\nmodel = model.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def forward_sequence_classification(model, batch_data, is_test=False, device='cpu', **kwargs):\n    # Unpack batch data\n    if len(batch_data) == 3:\n        (subword_batch, mask_batch, label_batch) = batch_data\n        token_type_batch = None\n    elif len(batch_data) == 4:\n        (subword_batch, mask_batch, token_type_batch, label_batch) = batch_data\n    \n    # Prepare input & label\n    subword_batch = torch.LongTensor(subword_batch)\n    mask_batch = torch.FloatTensor(mask_batch)\n    token_type_batch = torch.LongTensor(token_type_batch) if token_type_batch is not None else None\n    label_batch = torch.LongTensor(label_batch)\n            \n    if device == \"cuda\":\n        subword_batch = subword_batch.cuda()\n        mask_batch = mask_batch.cuda()\n        token_type_batch = token_type_batch.cuda() if token_type_batch is not None else None\n        label_batch = label_batch.cuda()\n\n    # Forward model\n    outputs = model(subword_batch, attention_mask=mask_batch, token_type_ids=token_type_batch, labels=label_batch)\n    loss, logits = outputs[:2]\n    probs = F.softmax(logits)\n    \n    # generate prediction & label list\n    list_hyp = []\n    list_label = []\n    list_probs = []\n    hyp = torch.topk(logits, 1)[1]\n    for j in range(len(hyp)):\n        list_hyp.append(hyp[j].item())\n        list_label.append(label_batch[j][0].item())\n        list_probs.append(probs[j][1].item())\n        \n    return loss, list_hyp, list_label, list_probs\ndef document_sentiment_metrics_fn(list_hyp, list_label):\n    metrics = {}\n    metrics[\"ACC\"] = accuracy_score(list_label, list_hyp)\n    metrics[\"F1\"] = f1_score(list_label, list_hyp, average='macro')\n    metrics[\"REC\"] = recall_score(list_label, list_hyp, average='macro')\n    metrics[\"PRE\"] = precision_score(list_label, list_hyp, average='macro')\n    return metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_epochs = 1\n#n_epochs = 25 # sebenarnya kami menggunakan 25 epoch untuk training classifier Indobert\nfor epoch in range(n_epochs):\n    model.train()\n    torch.set_grad_enabled(True)\n \n    total_train_loss = 0\n    list_hyp, list_label, list_probs = [], [], []\n\n    train_pbar = tqdm(train_loader, leave=True, total=len(train_loader))\n    for i, batch_data in enumerate(train_pbar):\n        # Forward model\n        loss, batch_hyp, batch_label, batch_probs = forward_sequence_classification(model, batch_data[:-1], device='cuda')\n\n        # Update model\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        tr_loss = loss.item()\n        total_train_loss = total_train_loss + tr_loss\n\n        # Calculate metrics\n        list_hyp += batch_hyp\n        list_label += batch_label\n        list_probs += batch_probs\n        train_pbar.set_description(\"(Epoch {}) TRAIN LOSS:{:.4f} LR:{:.8f}\".format((epoch+1),\n            total_train_loss/(i+1), get_lr(optimizer)))\n\n    # Calculate train metric\n    metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n    print(\"(Epoch {}) TRAIN LOSS:{:.4f} {} LR:{:.8f}\".format((epoch+1),\n        total_train_loss/(i+1), metrics_to_string(metrics), get_lr(optimizer)))\n\n    # Evaluate on validation\n    model.eval()\n    torch.set_grad_enabled(False)\n    \n    total_loss, total_correct, total_labels = 0, 0, 0\n    list_hyp, list_label, list_probs = [], [], []\n\n    pbar = tqdm(valid_loader, leave=True, total=len(valid_loader))\n    for i, batch_data in enumerate(pbar):\n        batch_seq = batch_data[-1]        \n        loss, batch_hyp, batch_label, batch_probs = forward_sequence_classification(model, batch_data[:-1], device='cuda')\n        \n        # Calculate total loss\n        valid_loss = loss.item()\n        total_loss = total_loss + valid_loss\n\n        # Calculate evaluation metrics\n        list_hyp += batch_hyp\n        list_label += batch_label\n        list_probs += batch_probs\n        metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n\n        pbar.set_description(\"VALID LOSS:{:.4f} {}\".format(total_loss/(i+1), metrics_to_string(metrics)))\n        \n    metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n    print(\"(Epoch {}) VALID LOSS:{:.4f} {}\".format((epoch+1),\n        total_loss/(i+1), metrics_to_string(metrics)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.eval()\ntorch.set_grad_enabled(False)\n\ntotal_loss, total_correct, total_labels = 0, 0, 0\nlist_hyp, list_label = [], []\nlist_prob = []\n\npbar = tqdm(test_loader, leave=True, total=len(test_loader))\nfor i, batch_data in enumerate(pbar):\n    _, batch_hyp, _, batch_prob = forward_sequence_classification(model, batch_data[:-1], device='cuda')\n    list_hyp += batch_hyp\n    list_prob += batch_prob\n\n# Save prediction\nsub = pd.read_csv('../input/penyisihan-datavidia-7-0/sample_submission.csv')\nsub['category'] = list_hyp\nsub.to_csv('submission.csv', index=False)\nsub = pd.read_csv('../input/penyisihan-datavidia-7-0/sample_submission.csv')\nsub['category'] = list_prob\nsub.to_csv('submission_prob.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"OOF_dataset = DocumentSentimentDataset('./preprocessed_review_train.csv', tokenizer)\nOOF_loader = DocumentSentimentDataLoader(dataset=OOF_dataset, max_seq_len=512, batch_size=32, num_workers=16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.eval()\ntorch.set_grad_enabled(False)\n\ntotal_loss, total_correct, total_labels = 0, 0, 0\nlist_hyp, list_label = [], []\nlist_prob_train = []\n\npbar = tqdm(OOF_loader, leave=True, total=len(OOF_loader))\nfor i, batch_data in enumerate(pbar):\n    _, batch_hyp, _, batch_prob = forward_sequence_classification(model, batch_data[:-1], device='cuda')\n    list_hyp += batch_hyp\n    list_prob_train += batch_prob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_probs = df_train[['review_id', 'review_text', 'category']].copy()\ntrain_probs['category'] = list_prob_train\ntrain_probs.to_csv('train_probability_indobert_pretrained.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XLM-Roberta\nKarena batasan waktu, kami tidak melakukan pretraining MLM pada model XLM Roberta"},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import XLMRobertaForSequenceClassification, XLMRobertaConfig, XLMRobertaTokenizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\nconfig = XLMRobertaConfig.from_pretrained('xlm-roberta-base')\nconfig.num_labels = 2\n\n# Instantiate model\nmodel = XLMRobertaForSequenceClassification.from_pretrained('xlm-roberta-base', config=config)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=3e-6)\nmodel = model.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_epochs = 1\n#n_epochs = 5 # sebenarnya kami menggunakan 5 epoch untuk training classifier XLM\nfor epoch in range(n_epochs):\n    model.train()\n    torch.set_grad_enabled(True)\n \n    total_train_loss = 0\n    list_hyp, list_label, list_probs = [], [], []\n\n    train_pbar = tqdm(train_loader, leave=True, total=len(train_loader))\n    for i, batch_data in enumerate(train_pbar):\n        # Forward model\n        loss, batch_hyp, batch_label, batch_probs = forward_sequence_classification(model, batch_data[:-1], device='cuda')\n\n        # Update model\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        tr_loss = loss.item()\n        total_train_loss = total_train_loss + tr_loss\n\n        # Calculate metrics\n        list_hyp += batch_hyp\n        list_label += batch_label\n        list_probs += batch_probs\n        train_pbar.set_description(\"(Epoch {}) TRAIN LOSS:{:.4f} LR:{:.8f}\".format((epoch+1),\n            total_train_loss/(i+1), get_lr(optimizer)))\n\n    # Calculate train metric\n    metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n    print(\"(Epoch {}) TRAIN LOSS:{:.4f} {} LR:{:.8f}\".format((epoch+1),\n        total_train_loss/(i+1), metrics_to_string(metrics), get_lr(optimizer)))\n\n    # Evaluate on validation\n    model.eval()\n    torch.set_grad_enabled(False)\n    \n    total_loss, total_correct, total_labels = 0, 0, 0\n    list_hyp, list_label, list_probs = [], [], []\n\n    pbar = tqdm(valid_loader, leave=True, total=len(valid_loader))\n    for i, batch_data in enumerate(pbar):\n        batch_seq = batch_data[-1]        \n        loss, batch_hyp, batch_label, batch_probs = forward_sequence_classification(model, batch_data[:-1], device='cuda')\n        \n        # Calculate total loss\n        valid_loss = loss.item()\n        total_loss = total_loss + valid_loss\n\n        # Calculate evaluation metrics\n        list_hyp += batch_hyp\n        list_label += batch_label\n        list_probs += batch_probs\n        metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n\n        pbar.set_description(\"VALID LOSS:{:.4f} {}\".format(total_loss/(i+1), metrics_to_string(metrics)))\n        \n    metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n    print(\"(Epoch {}) VALID LOSS:{:.4f} {}\".format((epoch+1),\n        total_loss/(i+1), metrics_to_string(metrics)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.eval()\ntorch.set_grad_enabled(False)\n\ntotal_loss, total_correct, total_labels = 0, 0, 0\nlist_hyp, list_label = [], []\nlist_prob = []\n\npbar = tqdm(test_loader, leave=True, total=len(test_loader))\nfor i, batch_data in enumerate(pbar):\n    _, batch_hyp, _, batch_prob = forward_sequence_classification(model, batch_data[:-1], device='cuda')\n    list_hyp += batch_hyp\n    list_prob += batch_prob\n\n# Save prediction\nsub = pd.read_csv('../input/penyisihan-datavidia-7-0/sample_submission.csv')\nsub['category'] = list_hyp\nsub.to_csv('submission.csv', index=False)\nsub = pd.read_csv('../input/penyisihan-datavidia-7-0/sample_submission.csv')\nsub['category'] = list_prob\nsub.to_csv('submission_prob.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.eval()\ntorch.set_grad_enabled(False)\n\ntotal_loss, total_correct, total_labels = 0, 0, 0\nlist_hyp, list_label = [], []\nlist_prob_train = []\n\npbar = tqdm(OOF_loader, leave=True, total=len(OOF_loader))\nfor i, batch_data in enumerate(pbar):\n    _, batch_hyp, _, batch_prob = forward_sequence_classification(model, batch_data[:-1], device='cuda')\n    list_hyp += batch_hyp\n    list_prob_train += batch_prob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_probs = df_train[['review_id', 'review_text', 'category']].copy()\ntrain_probs['category'] = list_prob_train\ntrain_probs.to_csv('train_probability_xlm_pretrained.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## TF-IDF dengan SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('./preprocessed_review_train.csv')\ndf_train['review_text'] = df_train['review_text'].values.astype('U')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, valid = train_test_split(df_train, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom mlxtend.feature_selection import ColumnSelector\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.svm import SVC\n\nsvm = Pipeline([\n    ('col_selector', ColumnSelector(cols=('review_text'),drop_axis=True)),\n    ('tfidf', TfidfVectorizer()),\n    ('classifier', SVC(kernel='rbf', probability=True)),\n])\n\n\nsvm.fit(train,train['category'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## TF-IDF dengan XGB"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\nxgb = Pipeline([\n    ('col_selector', ColumnSelector(cols=('review_text'),drop_axis=True)),\n    ('tfidf', TfidfVectorizer()),\n    ('classifier', XGBClassifier()),\n])\nxgb.fit(train,train['category'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ensemble Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xlm_proba = pd.read_csv('../input/datavidia-xlm-roberta/train_probability_xlm_pretrained.csv')\nindobert_proba = pd.read_csv('../input/datavidia-bert-pretrained/train_probability_indobert_pretrained.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_meta = pd.DataFrame({\n    'svc': svm.predict_proba(train)[:, -1],\n    'xgb': xgb.predict_proba(train)[:, -1],\n    'indobert': list(train[['review_id']].merge(indobert_proba)['category']),\n    'xlm': list(train[['review_id']].merge(xlm_proba)['category'])\n})\ndf_meta_valid = pd.DataFrame({\n    'svc': svm.predict_proba(valid)[:, -1],\n    'xgb': xgb.predict_proba(valid)[:, -1],\n    'indobert': list(valid[['review_id']].merge(indobert_proba)['category']),\n    'xlm': list(valid[['review_id']].merge(xlm_proba)['category'])\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_learner = LogisticRegression()\nmeta_learner.fit(df_meta, train['category'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluasi Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('model'.ljust(10), 'f1-score')\nfor model in df_meta_valid.columns:\n    print(model.ljust(10), f1_score((df_meta_valid[model]>0.5).astype(int), valid['category']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('ensemble'.ljust(10), f1_score(meta_learner.predict(df_meta_valid), valid['category']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hasil terbaik dari tim kami adalah ensemble dengan 3 model yaitu\n1. SVM\n2. XGBoost\n3. Indobert"},{"metadata":{},"cell_type":"markdown","source":"# Membuat Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv('./preprocessed_review_test.csv')\ndf_test['review_text'] = df_test['review_text'].values.astype('U')\nindobert_test_prob = pd.read_csv('../input/datavidia-bert-pretrained/submission_prob.csv')\nxlm_test_prob = pd.read_csv('../input/datavidia-xlm-roberta/submission_prob.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_meta_test = pd.DataFrame({\n    'svc': svm.predict_proba(df_test)[:, -1],\n    'xgb': xgb.predict_proba(df_test)[:, -1],\n    'indobert': indobert_test_prob['category'],\n    'xlm': xlm_test_prob['category']\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = df_test[['review_id']]\nsub['category'] = meta_learner.predict(df_meta_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('final_submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}