{"cells":[{"metadata":{},"cell_type":"markdown","source":" Тестовое задание «Отток клиентов»\n \nОписание\n\nИз «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи\nпосчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\nНужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены\nисторические данные о поведении клиентов и расторжении договоров с банком.\n\nИсточник данных: https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling\n\nИнструкция по выполнению задачи\n\n1. Загрузите и подготовьте данные\n2. Исследуйте баланс классов, обучите модель без учета дисбаланса\n3. Улучшите качество модели, учитывая дисбаланс классов\n4. Проведите финальное тестирование\n\nВсе преобразования и построение выполнять в Python. В результате предоставить Notebook с\nкомментариями к выполняемым шагам и выводами о проделанной работе.\nОптимальную модель для данной задачи выбирайте сами, сравнение нескольких подходов\nприветствуется. Любые дополнительные действия для улучшения качества модели также\nприветствуются.\n\nОписание данных.\nПризнаки:\n\n- RowNumber – индекс строки в данных\n- CustomerId – уникальный идентификатор клиента\n- Surname – фамилия\n- CreditScore – кредитный скоринг\n- Geography – страна проживания\n- Gender – пол\n- Age – возраст\n- Tenure – количество недвижимости у клиента\n- Balance – баланс на счете\n- NumOfProducts – количество продуктов банка, используемых клиентом\n- HasCrCard – наличие кредитной карты\n- IsActiveMember – активность клиента\n- EstimatedSalary – предполагаемая зарплата\n\nЦелевой признак:\n- Exited – факт ухода клиента"},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"# 1. Loading and preparing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv('../input/bank-customer-churn-modeling/Churn_Modelling.csv', sep=',')\ndata.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data.Surname=='Hill']","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"len(pd.unique(data.Surname))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=data.drop(['RowNumber','CustomerId', 'Surname'], axis='columns')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"def summary(data):\n    print('Shape: ' , data.shape)\n    return( pd.DataFrame({ \"Dtypes \":data.dtypes , \n                           \"NAs\":data.isnull().sum() ,\n                           \"uniques\":data.nunique() ,\n                            \"Levels\":[ data[i].unique() for i in data.columns]}))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summary(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's check if there are outliers in the data. Delete them"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,10))\nax1=fig.add_subplot(221)\nax2=fig.add_subplot(222)\n\ng=ax1.hist(data['CreditScore'], bins=500, color='y', alpha=0.9)\ng=ax2.boxplot(data['CreditScore'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=data.drop(data[data['CreditScore']<385].index)\nlen(data)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,10))\nax1=fig.add_subplot(221)\nax2=fig.add_subplot(222)\n\ng=ax1.hist(data['CreditScore'], bins=500, color='y', alpha=0.9)\ng=ax2.boxplot(data['CreditScore'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,10))\nax1=fig.add_subplot(221)\nax2=fig.add_subplot(222)\n\ng=ax1.hist(data['Age'], bins=500, color='y', alpha=0.9)\ng=ax2.boxplot(data['Age'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data=data.drop(data[data['Age']>60].index)\nlen(data)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,10))\nax2=fig.add_subplot(221)\nax3=fig.add_subplot(222)\n\ng2=ax2.hist(data['Age'], bins=500, color='y', alpha=0.9)\ng3=ax3.boxplot(data['Age'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,10))\nax1=fig.add_subplot(221)\nax2=fig.add_subplot(222)\n\ng=ax1.hist(data['Balance'], bins=500, color='y', alpha=0.9)\ng=ax2.boxplot(data['Balance'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"len(data[data.Balance==0])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,10))\nax1=fig.add_subplot(221)\nax2=fig.add_subplot(222)\n\ng=ax1.hist(data['EstimatedSalary'], bins=1000, color='y', alpha=0.9)\ng=ax2.boxplot(data['EstimatedSalary'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Checking for normality of distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"W, p = stats.shapiro(data.CreditScore.iloc[:5000])\nprint(W, p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"W, p = stats.shapiro(data.Age.iloc[:5000])\nprint(W, p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"W, p = stats.shapiro(data.EstimatedSalary.iloc[:5000])\nprint(W, p)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"corr = data.corr()\nax = sns.heatmap(\n    corr, \n    vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200),\n    square=True\n)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=45,\n    horizontalalignment='right'\n);","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### normalization"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\n\nnorm = preprocessing.StandardScaler()\nnorm.fit(data[['CreditScore','Age','Balance','EstimatedSalary','Tenure','NumOfProducts']])\nN=norm.transform(data[['CreditScore','Age','Balance','EstimatedSalary','Tenure','NumOfProducts']])\nN","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data[['CreditScore','Age','Balance','EstimatedSalary','Tenure','NumOfProducts']]=N","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Exploring the balance of classes. Training models without accounting the imbalance"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data1 = pd.get_dummies(data, columns =['Gender', 'Geography'], drop_first=True)\ndata1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data1.iloc[:, 2:].drop(['Exited'], axis='columns')\n\nY = data1.iloc[:, 8]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.1. Logistic regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify=Y, train_size=(0.7), test_size=(0.3))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"len(Y_test[Y_test==1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(Y_test[Y_test==0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier=LogisticRegression()\nclassifier.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"predicted_y = classifier.predict(X_test)\nprint('predicted_y:', predicted_y)\nprint('coef_:', classifier.coef_)\nprint('accuracy_score:',classifier.score(X_test, Y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(predicted_y[np.where(predicted_y==0)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(predicted_y[np.where(predicted_y==1)])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(Y_test, predicted_y)\ntn, fp, fn, tp=cm.ravel()\nprint(cm)\nprint(tn, fp, fn, tp)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"Re=tp/(tp+fn)\nPr=tp/(tp+fp)\nSp=tn/(tn+fp)\nBac=(Re+Sp)/2\nF=2*Re*Pr/(Re+Pr)\nprint('Accuracy (log_reg):',classifier.score(X_test, Y_test))\nprint('Recall (log_reg):', Re)\nprint('Precision (log_reg):', Pr)\nprint('F-measure (log_reg):', F)\nb=2   # приоритет у Recall # b>1(Recall), 0<b<1(Precision)\nF_b=(1+b**2)*Re*Pr/(Re+Pr*b**2)\nprint('F_2-measure (log_reg):', F_b)\nprint('Balanced accuracy (log_reg):', Bac)\nprint('Specificity_ (log_reg):', Sp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Precision and recall do not depend, in contrast to accuracy, on the ratio of classes and therefore are applicable in conditions of unbalanced samples."},{"metadata":{},"cell_type":"markdown","source":"##### We got the F-measure close to 0, so the Recall is close to 0. And this, in turn, is due to the fact that the model makes many passes.\n- The F_2-measure in which completeness is preferred (b = 2) is very small.\n- Precision is not a good value, which means that the model is good at identifying \"good\" (0) clients.\n- The specificity (Specificity_) is high, because the model has a large percentage of loyal customers (the constant algorithm will show the same accuracy for this metric).\n- Analysis of these metrics tells us about the low quality of the model."},{"metadata":{},"cell_type":"markdown","source":"##### Cross-validation regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold, cross_validate","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"clf_log = LogisticRegression()\n\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\nscores = cross_validate(clf_log, X, Y, cv=cv, n_jobs=-1, scoring=['accuracy','precision','recall'])\n\nprint(\"Accuracy_test (log_reg): {}\".format(scores['test_accuracy'].mean()), \n      \"Recall_test (log_reg): {}\".format(scores['test_recall'].mean()),\n      \"Precision_test (log_reg): {}\".format(scores['test_precision'].mean()), sep='\\n')\n\nb=2   # b>1(Recall), 0<b<1(Precision)\nF_b=(1+b**2)*scores['test_recall'].mean()*scores['test_precision'].mean()/(scores['test_recall'].mean()+scores['test_precision'].mean()*b**2)\nprint('F_2-measure_test (log_reg):', F_b)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Cross-validation did not improve model quality"},{"metadata":{},"cell_type":"markdown","source":"### 2.2 RandomForest"},{"metadata":{},"cell_type":"markdown","source":"##### To overcome the deviation from the norm (outliers), you can use randomness in the models or random forests."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"clf_forest = RandomForestClassifier(random_state=1, n_estimators=500, min_samples_split=10, min_samples_leaf=2)\n\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\nscores = cross_validate(clf_forest, X, Y, cv=cv, n_jobs=-1, scoring=['accuracy','precision','recall'], return_train_score=True)\n\nprint(\"Accuracy_test (Forest): {}\".format(scores['test_accuracy'].mean()), \n      \"Recall_test (Forest): {}\".format(scores['test_recall'].mean()),\n      \"Precision_test (Forest): {}\".format(scores['test_precision'].mean()), sep='\\n')\n\nb=2   # b>1(Recall), 0<b<1(Precision)\nF_b=(1+b**2)*scores['test_recall'].mean()*scores['test_precision'].mean()/(scores['test_recall'].mean()+scores['test_precision'].mean()*b**2)\nprint('F_2-measure_test (Forest):', F_b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_forest.fit(X_train, Y_train)\npredicted_y = clf_forest.predict(X_test)\npredicted_y","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(Y_test, predicted_y)\ntn, fp, fn, tp=cm.ravel()\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Optimize prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hyperparameter optimization using RandomizedSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#parameters\nparams = {\n    \"n_estimators\": [350, 400, 450],\n    \"min_samples_split\": [6, 8, 10],\n    \"min_samples_leaf\": [1, 2, 4]\n}","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"random_search=RandomizedSearchCV(clf_forest, param_distributions=params, n_iter=5, scoring='roc_auc',n_jobs=-1, cv=cv,verbose=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.fit(X_train,Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_forest = RandomForestClassifier(min_samples_leaf=4, min_samples_split=10,\n                       n_estimators=350, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nscore = cross_val_score(random_forest,X,Y,cv=10)\nscore.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_forest.fit(X_train, Y_train)\nY_test_preds=random_forest.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print('Accuracy (Forest): {0:.2f}'.format(accuracy_score(Y_test, Y_test_preds)))\nprint('Precision (Forest): {0:.2f}'.format(precision_score(Y_test, Y_test_preds)))\nprint('Recall (Forest): {0:.2f}'.format(recall_score(Y_test, Y_test_preds)))\nprint('F2 (Forest): {0:.2f}'.format(fbeta_score(Y_test, Y_test_preds, 2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3 XGboost"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost.sklearn import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#parameters\nparams = {\n    \"learning_rate\"    :[0.05,0.10,0.15,0.20,0.25,0.30],\n    \"max_depth\"        :[ 3,4,5,6,8,10,12,15 ],\n    \"min_child_weight\" :[ 1,3,5,7 ],\n    \"gamma\"            :[ 0.0,0.1,0.2,0.3,0.4 ],\n    \"colsample_bytree\" :[ 0.3, 0.4, 0.5, 0.7 ]\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = XGBClassifier()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Let's try to reconfigure the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search=RandomizedSearchCV(classifier, param_distributions=params, n_iter=5, scoring='roc_auc',n_jobs=-1, cv=cv,verbose=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.5, gamma=0.1,\n              learning_rate=0.25, max_delta_step=0, max_depth=4,\n              min_child_weight=5, missing=None, n_estimators=100, n_jobs=1,\n              nthread=None, objective='binary:logistic', random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n              silent=None, subsample=1, verbosity=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = cross_val_score(classifier,X,Y,cv=10)\nscore.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit(X_train, Y_train)\nY_test_preds=classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"print('Accuracy (XGboost): {0:.2f}'.format(accuracy_score(Y_test, Y_test_preds)))\nprint('Precision (XGboost): {0:.2f}'.format(precision_score(Y_test, Y_test_preds)))\nprint('Recall (XGboost): {0:.2f}'.format(recall_score(Y_test, Y_test_preds)))\nprint('F2 (XGboost): {0:.2f}'.format(fbeta_score(Y_test, Y_test_preds, 2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Improving the quality of the model, taking into account the imbalance of classes"},{"metadata":{},"cell_type":"markdown","source":"##### The data is strongly unbalanced, this could lead to problems when predicting data."},{"metadata":{},"cell_type":"markdown","source":"##### Sampling methods: artificially duplicate observations from a rare class, or throw out some observations from a popular class."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.Exited[data.Exited==0].count()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data.Exited[data.Exited==1].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.1.1 Logistic regression without cross-validation taking into account unbalance (balanced weight)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify=Y, train_size=(0.7), test_size=(0.3))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"len(Y_test[Y_test==1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(Y_test[Y_test==0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier=LogisticRegression(class_weight='balanced')\nclassifier.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"predicted_y = classifier.predict(X_test)\nprint('predicted_y:', predicted_y)\nprint('coef_:', classifier.coef_)\nprint('accuracy_score:',classifier.score(X_test, Y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(predicted_y[np.where(predicted_y==0)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(predicted_y[np.where(predicted_y==1)])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(Y_test, predicted_y)\ntn, fp, fn, tp=cm.ravel()\nprint(cm)\nprint(tn, fp, fn, tp)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"Re=tp/(tp+fn)\nPr=tp/(tp+fp)\nSp=tn/(tn+fp)\nBac=(Re+Sp)/2\nF=2*Re*Pr/(Re+Pr)\nprint('Accuracy (log_reg):',classifier.score(X_test, Y_test))\nprint('Recall (log_reg):', Re)\nprint('Precision (log_reg):', Pr)\nprint('F-measure (log_reg):', F)\nb=2   # приоритет у Recall # b>1(Recall), 0<b<1(Precision)\nF_b=(1+b**2)*Re*Pr/(Re+Pr*b**2)\nprint('F_2-measure (log_reg):', F_b)\nprint('Balanced accuracy (log_reg):', Bac)\nprint('Specificity_ (log_reg):', Sp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### After weight balancing, all metrics are aligned. The completeness (Recall) has increased and, accordingly, the F_2-measure."},{"metadata":{},"cell_type":"markdown","source":"### 3.1.2 Logistic regression on cross-validation taking into account the unbalance (balanced weight)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold, cross_validate","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"clf_log = LogisticRegression(class_weight='balanced')\n\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\nscores = cross_validate(clf_log, X, Y, cv=cv, n_jobs=-1, scoring=['accuracy','precision','recall'])\n\nprint(\"Accuracy_test (log_reg): {}\".format(scores['test_accuracy'].mean()), \n      \"Recall_test (log_reg): {}\".format(scores['test_recall'].mean()),\n      \"Precision_test (log_reg): {}\".format(scores['test_precision'].mean()), sep='\\n')\n\nb=2   # b>1(Recall), 0<b<1(Precision)\nF_b=(1+b**2)*scores['test_recall'].mean()*scores['test_precision'].mean()/(scores['test_recall'].mean()+scores['test_precision'].mean()*b**2)\nprint('F_2-measure_test (log_reg):', F_b)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### After weight balancing, all metrics are aligned. The completeness (Recall) has increased and, accordingly, the F_2-measure."},{"metadata":{},"cell_type":"markdown","source":"### 3.1.3 RandomForest on cross-validation taking into account the unbalance (balanced weight)"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"clf_forest = RandomForestClassifier(class_weight='balanced', random_state=1, n_estimators=500, min_samples_split=10, min_samples_leaf=2)\n\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\nscores = cross_validate(clf_forest, X, Y, cv=cv, n_jobs=-1, scoring=['accuracy','precision','recall'], return_train_score=True)\n\nprint(\"Accuracy_test (Forest): {}\".format(scores['test_accuracy'].mean()), \n      \"Recall_test (Forest): {}\".format(scores['test_recall'].mean()),\n      \"Precision_test (Forest): {}\".format(scores['test_precision'].mean()), sep='\\n')\n\nb=2   # b>1(Recall), 0<b<1(Precision)\nF_b=(1+b**2)*scores['test_recall'].mean()*scores['test_precision'].mean()/(scores['test_recall'].mean()+scores['test_precision'].mean()*b**2)\nprint('F_2-measure_test (Forest):', F_b)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.1.4 XGBoost on cross-validation taking into account the unbalance (balanced weight)"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.5, gamma=0.1,\n              learning_rate=0.25, max_delta_step=0, max_depth=4,\n              min_child_weight=5, missing=None, n_estimators=100, n_jobs=1,\n              nthread=None, objective='binary:logistic', random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=5, seed=None,\n              silent=None, subsample=1, verbosity=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = cross_val_score(classifier,X,Y,cv=10)\nscore.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit(X_train, Y_train)\nY_test_preds=classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print('Accuracy (XGBoost): {0:.2f}'.format(accuracy_score(Y_test, Y_test_preds)))\nprint('Precision (XGBoost): {0:.2f}'.format(precision_score(Y_test, Y_test_preds)))\nprint('Recall (XGBoost): {0:.2f}'.format(recall_score(Y_test, Y_test_preds)))\nprint('F2 (XGBoost): {0:.2f}'.format(fbeta_score(Y_test, Y_test_preds, 2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2.1 Logistic regression considering imbalance. Random undersampling and oversampling"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"num_0 = len(data1[data1['Exited']==0])\nnum_1 = len(data1[data1['Exited']==1])\nprint(num_0,num_1)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# oversampling\noversampled_data = pd.concat([ data1[data1['Exited']==0] , data1[data1['Exited']==1].sample(num_0, replace=True) ])\nprint(len(oversampled_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# undersampling\nundersampled_data = pd.concat([data1[data1['Exited']==0].sample(num_1) , data1[data1['Exited']==1] ])\nprint(len(undersampled_data))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Oversampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_o = oversampled_data.iloc[:, 2:].drop(['Exited'], axis='columns')\nY_o = oversampled_data.iloc[:, 8]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_o, X_test_o, Y_train_o, Y_test_o = train_test_split(X_o, Y_o, stratify=Y_o, train_size=(0.7), test_size=(0.3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_o=LogisticRegression()\nclassifier_o.fit(X_train_o, Y_train_o)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Testing on oversampled_data "},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"predicted_y_o = classifier_o.predict(X_test_o)\nprint('predicted_y:', predicted_y_o)\nprint('coef_:', classifier_o.coef_)\nprint('accuracy_score:',classifier_o.score(X_test_o, Y_test_o))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_o = confusion_matrix(Y_test_o, predicted_y_o)\ntn, fp, fn, tp=cm_o.ravel()\nprint(cm_o)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"Re=tp/(tp+fn)\nPr=tp/(tp+fp)\nSp=tn/(tn+fp)\nBac=(Re+Sp)/2\nF=2*Re*Pr/(Re+Pr)\nprint('Accuracy (log_reg):',classifier_o.score(X_test_o, Y_test_o))\nprint('Recall (log_reg):', Re)\nprint('Precision (log_reg):', Pr)\nprint('F-measure (log_reg):', F)\nb=2   # приоритет у Recall # b>1(Recall), 0<b<1(Precision)\nF_b=(1+b**2)*Re*Pr/(Re+Pr*b**2)\nprint('F_2-measure (log_reg):', F_b)\nprint('Balanced accuracy (log_reg):', Bac)\nprint('Specificity_ (log_reg):', Sp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Testing on data1 "},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"predicted_y_o = classifier_o.predict(X_test)\nprint('predicted_y:', predicted_y_o)\nprint('coef_:', classifier_o.coef_)\nprint('accuracy_score:',classifier_o.score(X_test, Y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_o = confusion_matrix(Y_test, predicted_y_o)\ntn, fp, fn, tp=cm_o.ravel()\nprint(cm_o)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"Re=tp/(tp+fn)\nPr=tp/(tp+fp)\nSp=tn/(tn+fp)\nBac=(Re+Sp)/2\nF=2*Re*Pr/(Re+Pr)\nprint('Accuracy (log_reg):',classifier_o.score(X_test, Y_test))\nprint('Recall (log_reg):', Re)\nprint('Precision (log_reg):', Pr)\nprint('F-measure (log_reg):', F)\nb=2   # приоритет у Recall # b>1(Recall), 0<b<1(Precision)\nF_b=(1+b**2)*Re*Pr/(Re+Pr*b**2)\nprint('F_2-measure (log_reg):', F_b)\nprint('Balanced accuracy (log_reg):', Bac)\nprint('Specificity_ (log_reg):', Sp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Undersampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_u = undersampled_data.iloc[:, 2:].drop(['Exited'], axis='columns')\nY_u = undersampled_data.iloc[:, 8]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_u, X_test_u, Y_train_u, Y_test_u = train_test_split(X_u, Y_u, stratify=Y_u, train_size=(0.7), test_size=(0.3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_u=LogisticRegression()\nclassifier_u.fit(X_train_u, Y_train_u)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Testing on undersampled_data"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"predicted_y_u = classifier_u.predict(X_test_u)\nprint('predicted_y:', predicted_y_u)\nprint('coef_:', classifier_u.coef_)\nprint('accuracy_score:',classifier_u.score(X_test_u, Y_test_u))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"cm_u = confusion_matrix(Y_test_u, predicted_y_u)\ntn, fp, fn, tp=cm_u.ravel()\nprint(cm_u)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"Re=tp/(tp+fn)\nPr=tp/(tp+fp)\nSp=tn/(tn+fp)\nBac=(Re+Sp)/2\nF=2*Re*Pr/(Re+Pr)\nprint('Accuracy (log_reg):',classifier_u.score(X_test_u, Y_test_u))\nprint('Recall (log_reg):', Re)\nprint('Precision (log_reg):', Pr)\nprint('F-measure (log_reg):', F)\nb=2   # приоритет у Recall # b>1(Recall), 0<b<1(Precision)\nF_b=(1+b**2)*Re*Pr/(Re+Pr*b**2)\nprint('F_2-measure (log_reg):', F_b)\nprint('Balanced accuracy (log_reg):', Bac)\nprint('Specificity_ (log_reg):', Sp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Testing on data1"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"predicted_y_u = classifier_u.predict(X_test)\nprint('predicted_y:', predicted_y_u)\nprint('coef_:', classifier_u.coef_)\nprint('accuracy_score:',classifier_u.score(X_test, Y_test))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"cm_u = confusion_matrix(Y_test, predicted_y_u)\ntn, fp, fn, tp=cm_u.ravel()\nprint(cm_u)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"Re=tp/(tp+fn)\nPr=tp/(tp+fp)\nSp=tn/(tn+fp)\nBac=(Re+Sp)/2\nF=2*Re*Pr/(Re+Pr)\nprint('Accuracy (log_reg):',classifier_u.score(X_test, Y_test))\nprint('Recall (log_reg):', Re)\nprint('Precision (log_reg):', Pr)\nprint('F-measure (log_reg):', F)\nb=2   # приоритет у Recall # b>1(Recall), 0<b<1(Precision)\nF_b=(1+b**2)*Re*Pr/(Re+Pr*b**2)\nprint('F_2-measure (log_reg):', F_b)\nprint('Balanced accuracy (log_reg):', Bac)\nprint('Specificity_ (log_reg):', Sp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### As a result of oversampling and undersampling, the quality of the logistic regression model has not changed much."},{"metadata":{},"cell_type":"markdown","source":"### 3.2.2 RandomForest considering the imbalance. Random undersampling and oversampling"},{"metadata":{},"cell_type":"markdown","source":"#### Oversampling. Testing on oversampled_data "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"clf_forest_o = RandomForestClassifier(random_state=1, n_estimators=500, min_samples_split=10, min_samples_leaf=2)\n\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\nscores = cross_validate(clf_forest_o, X_o, Y_o, cv=cv, n_jobs=-1, scoring=['accuracy','precision','recall'], return_train_score=True)\n\nprint(\"Accuracy_test (Forest): {}\".format(scores['test_accuracy'].mean()), \n      \"Recall_test (Forest): {}\".format(scores['test_recall'].mean()),\n      \"Precision_test (Forest): {}\".format(scores['test_precision'].mean()), sep='\\n')\n\nb=2   # b>1(Recall), 0<b<1(Precision)\nF_b=(1+b**2)*scores['test_recall'].mean()*scores['test_precision'].mean()/(scores['test_recall'].mean()+scores['test_precision'].mean()*b**2)\nprint('F_2-measure_test (Forest):', F_b)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Oversampling. Testing on data1 "},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_forest_o.fit(X_o, Y_o)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"predicted_y_o = clf_forest_o.predict(X_test)\nprint('predicted_y:', predicted_y_o)\nprint('accuracy_score:', clf_forest_o.score(X_test, Y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ncm_o = confusion_matrix(Y_test, predicted_y_o)\ntn, fp, fn, tp=cm_o.ravel()\nprint(cm_o)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"Re=tp/(tp+fn)\nPr=tp/(tp+fp)\nSp=tn/(tn+fp)\nBac=(Re+Sp)/2\nF=2*Re*Pr/(Re+Pr)\nprint('Accuracy (Forest):',clf_forest_o.score(X_test, Y_test))\nprint('Recall (Forest):', Re)\nprint('Precision (Forest):', Pr)\nprint('F-measure (Forest):', F)\nb=2   # приоритет у Recall # b>1(Recall), 0<b<1(Precision)\nF_b=(1+b**2)*Re*Pr/(Re+Pr*b**2)\nprint('F_2-measure (Forest):', F_b)\nprint('Balanced accuracy (Forest):', Bac)\nprint('Specificity_ (Forest):', Sp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Undersampling. Testing on undersampled_data1"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"clf_forest_u = RandomForestClassifier(random_state=1, n_estimators=500, min_samples_split=10, min_samples_leaf=2)\n\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\nscores = cross_validate(clf_forest_u, X_u, Y_u, cv=cv, n_jobs=-1, scoring=['accuracy','precision','recall'], return_train_score=True)\n\nprint(\"Accuracy_test (Forest): {}\".format(scores['test_accuracy'].mean()), \n      \"Recall_test (Forest): {}\".format(scores['test_recall'].mean()),\n      \"Precision_test (Forest): {}\".format(scores['test_precision'].mean()), sep='\\n')\n\nb=2   # b>1(Recall), 0<b<1(Precision)\nF_b=(1+b**2)*scores['test_recall'].mean()*scores['test_precision'].mean()/(scores['test_recall'].mean()+scores['test_precision'].mean()*b**2)\nprint('F_2-measure_test (Forest):', F_b)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Undersampling. Testing on data1"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_forest_u.fit(X_u, Y_u)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"predicted_y_u = clf_forest_u.predict(X_test)\nprint('predicted_y:', predicted_y_u)\nprint('accuracy_score:', clf_forest_u.score(X_test, Y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_u = confusion_matrix(Y_test, predicted_y_u)\ntn, fp, fn, tp=cm_u.ravel()\nprint(cm_u)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"Re=tp/(tp+fn)\nPr=tp/(tp+fp)\nSp=tn/(tn+fp)\nBac=(Re+Sp)/2\nF=2*Re*Pr/(Re+Pr)\nprint('Accuracy (Forest):',clf_forest_u.score(X_test, Y_test))\nprint('Recall (Forest):', Re)\nprint('Precision (Forest):', Pr)\nprint('F-measure (Forest):', F)\nb=2   # приоритет у Recall # b>1(Recall), 0<b<1(Precision)\nF_b=(1+b**2)*Re*Pr/(Re+Pr*b**2)\nprint('F_2-measure (Forest):', F_b)\nprint('Balanced accuracy (Forest):', Bac)\nprint('Specificity_ (Forest):', Sp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2.2 XCBoost considering the imbalance. Random undersampling and oversampling"},{"metadata":{},"cell_type":"markdown","source":"#### Oversampling. Testing on oversampled_data "},{"metadata":{"trusted":true},"cell_type":"code","source":"#parameters\nparams = {\n    \"learning_rate\"    :[0.05,0.10,0.15,0.20,0.25,0.30],\n    \"max_depth\"        :[ 3,4,5,6,8,10,12,15 ],\n    \"min_child_weight\" :[ 1,3,5,7 ],\n    \"gamma\"            :[ 0.0,0.1,0.2,0.3,0.4 ],\n    \"colsample_bytree\" :[ 0.3, 0.4, 0.5, 0.7 ]\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = XGBClassifier()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Let's try to reconfigure the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search=RandomizedSearchCV(classifier, param_distributions=params, n_iter=5, scoring='roc_auc',n_jobs=-1, cv=cv,verbose=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.fit(X_o,Y_o)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.5, gamma=0.3,\n              learning_rate=0.15, max_delta_step=0, max_depth=10,\n              min_child_weight=5, missing=None, n_estimators=100, n_jobs=1,\n              nthread=None, objective='binary:logistic', random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n              silent=None, subsample=1, verbosity=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nscore = cross_val_score(classifier,X_o,Y_o,cv=10)\nscore.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit(X_train_o, Y_train_o)\nY_test_preds=classifier.predict(X_test_o)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print('Accuracy (XCBoost): {0:.2f}'.format(accuracy_score(Y_test_o, Y_test_preds)))\nprint('Precision (XCBoost): {0:.2f}'.format(precision_score(Y_test_o, Y_test_preds)))\nprint('Recall (XCBoost): {0:.2f}'.format(recall_score(Y_test_o, Y_test_preds)))\nprint('F2 (XCBoost): {0:.2f}'.format(fbeta_score(Y_test_o, Y_test_preds, 2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Oversampling. Testing on data1 "},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit(X_train_o, Y_train_o)\nY_test_preds=classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print('Accuracy (XCBoost): {0:.2f}'.format(accuracy_score(Y_test, Y_test_preds)))\nprint('Precision (XCBoost): {0:.2f}'.format(precision_score(Y_test, Y_test_preds)))\nprint('Recall (XCBoost): {0:.2f}'.format(recall_score(Y_test, Y_test_preds)))\nprint('F2 (XCBoost): {0:.2f}'.format(fbeta_score(Y_test, Y_test_preds, 2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Undersampling. Testing on undersampled_data1"},{"metadata":{"trusted":true},"cell_type":"code","source":"#parameters\nparams = {\n    \"learning_rate\"    :[0.05,0.10,0.15,0.20,0.25,0.30],\n    \"max_depth\"        :[ 3,4,5,6,8,10,12,15 ],\n    \"min_child_weight\" :[ 1,3,5,7 ],\n    \"gamma\"            :[ 0.0,0.1,0.2,0.3,0.4 ],\n    \"colsample_bytree\" :[ 0.3, 0.4, 0.5, 0.7 ]\n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Let's try to reconfigure the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.fit(X_u,Y_u)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.7, gamma=0.3,\n              learning_rate=0.1, max_delta_step=0, max_depth=4,\n              min_child_weight=7, missing=None, n_estimators=100, n_jobs=1,\n              nthread=None, objective='binary:logistic', random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n              silent=None, subsample=1, verbosity=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = cross_val_score(classifier,X_u,Y_u,cv=10)\nscore.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit(X_train_u, Y_train_u)\nY_test_preds=classifier.predict(X_test_u)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print('Accuracy (XCBoost): {0:.2f}'.format(accuracy_score(Y_test_u, Y_test_preds)))\nprint('Precision (XCBoost): {0:.2f}'.format(precision_score(Y_test_u, Y_test_preds)))\nprint('Recall (XCBoost): {0:.2f}'.format(recall_score(Y_test_u, Y_test_preds)))\nprint('F2 (XCBoost): {0:.2f}'.format(fbeta_score(Y_test_u, Y_test_preds, 2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Undersampling. Testing on data1"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit(X_train_u, Y_train_u)\nY_test_preds=classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"print('Accuracy (XCBoost): {0:.2f}'.format(accuracy_score(Y_test, Y_test_preds)))\nprint('Precision (XCBoost): {0:.2f}'.format(precision_score(Y_test, Y_test_preds)))\nprint('Recall (XCBoost): {0:.2f}'.format(recall_score(Y_test, Y_test_preds)))\nprint('F2 (XCBoost): {0:.2f}'.format(fbeta_score(Y_test, Y_test_preds, 2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.3.1 Logistic regression considering imbalance. Oversampling with SMOTE and Undersampling with Tomek Links"},{"metadata":{},"cell_type":"markdown","source":"#### Oversampling with SMOTE:\nIn SMOTE we create elements in close proximity to existing ones in a smaller set."},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"smote = SMOTE(sampling_strategy='minority')\nX_sm, Y_sm = smote.fit_sample(X, Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(Y_sm[Y_sm==0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X_sm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_sm, X_test_sm, Y_train_sm, Y_test_sm = train_test_split(X_sm, Y_sm, random_state=0, stratify=Y_sm, train_size=(0.7), test_size=(0.3))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"len(Y_test_sm[Y_test_sm==1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(Y_test_sm[Y_test_sm==0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier=LogisticRegression()\nclassifier.fit(X_train_sm, Y_train_sm)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"predicted_y = classifier.predict(X_test_sm)\nprint('predicted_y:', predicted_y)\nprint('coef_:', classifier.coef_)\nprint('accuracy_score:',classifier.score(X_test_sm,Y_test_sm))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(Y_test_sm, predicted_y)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tn, fp, fn, tp=cm.ravel()\nRe=tp/(tp+fn)\nPr=tp/(tp+fp)\nSp=tn/(tn+fp)\nF=2*Re*Pr/(Re+Pr)\nprint(tn, fp, fn, tp)\nprint('Accuracy_score (log_reg):',classifier.score(X_test_sm,Y_test_sm))\nprint('Recall (log_reg):', Re)\nprint('Precision (log_reg):', Pr)\nprint('F-measure (log_reg):', F)\nb=2   # приоритет у Recall # b>1(Recall), 0<b<1(Precision)\nF_b=(1+b**2)*Re*Pr/(Re+Pr*b**2)\nprint('F_2-measure (Forest):', F_b)\nprint('Balanced accuracy (Forest):', Bac)\nprint('Specificity_ (log_reg):', Sp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Undersampling using Tomek Links:"},{"metadata":{},"cell_type":"markdown","source":"#### One of the provided methods is called \"Tomek Links\". \"Links\" in this case are pairs of elements from different classes that are nearby. Using the algorithm, we will eventually remove the element of the pair from the larger set, which will allow the classifier to perform better."},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.under_sampling import TomekLinks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tl = TomekLinks(sampling_strategy ='majority')\nX_tl, Y_tl = tl.fit_sample(X, Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(Y_tl[Y_tl==0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(Y_tl[Y_tl==1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_tl, X_test_tl, Y_train_tl, Y_test_tl = train_test_split(X_tl, Y_tl, random_state=0, stratify=Y_tl, train_size=(0.7), test_size=(0.3))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"len(Y_test_tl[Y_test_tl==1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(Y_test_tl[Y_test_tl==0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier=LogisticRegression()\nclassifier.fit(X_train_tl, Y_train_tl)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"predicted_y = classifier.predict(X_test_tl)\nprint('predicted_y:', predicted_y)\nprint('coef_:', classifier.coef_)\nprint('accuracy_score:',classifier.score(X_test_tl,Y_test_tl))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(predicted_y[np.where(predicted_y==0)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(predicted_y[np.where(predicted_y==1)])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(Y_test_tl, predicted_y)\ntn, fp, fn, tp=cm.ravel()\nprint(cm, tn, fp, fn, tp)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"tn, fp, fn, tp=cm.ravel()\nRe=tp/(tp+fn)\nPr=tp/(tp+fp)\nSp=tn/(tn+fp)\nF=2*Re*Pr/(Re+Pr)\nprint(tn, fp, fn, tp)\nprint('accuracy_score (log_reg):',classifier.score(X_test_tl,Y_test_tl))\nprint('Recall (log_reg):', Re)\nprint('Precision (log_reg):', Pr)\nprint('F-measure (log_reg):', F)\nb=2   # приоритет у Recall # b>1(Recall), 0<b<1(Precision)\nF_b=(1+b**2)*Re*Pr/(Re+Pr*b**2)\nprint('F_2-measure (log_reg):', F_b)\nprint('Balanced accuracy (log_reg):', Bac)\nprint('Specificity_ (log_reg):', Sp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.3.2 RandomForest considering the imbalance. Oversampling with SMOTE and Undersampling with Tomek Links"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"clf_forest_sm = RandomForestClassifier(random_state=1, n_estimators=500, min_samples_split=10, min_samples_leaf=2)\n\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\nscores = cross_validate(clf_forest_sm, X_sm, Y_sm, cv=cv, n_jobs=-1, scoring=['accuracy','precision','recall'], return_train_score=True)\n\nprint(\"Accuracy_test (Forest): {}\".format(scores['test_accuracy'].mean()), \n      \"Recall_test (Forest): {}\".format(scores['test_recall'].mean()),\n      \"Precision_test (Forest): {}\".format(scores['test_precision'].mean()), sep='\\n')\n\nb=2   # b>1(Recall), 0<b<1(Precision)\nF_b=(1+b**2)*scores['test_recall'].mean()*scores['test_precision'].mean()/(scores['test_recall'].mean()+scores['test_precision'].mean()*b**2)\nprint('F_2-measure_test (Forest):', F_b)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Oversampling with SMOTE. Testing on data1"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_forest_sm.fit(X_sm, Y_sm)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"predicted_y_sm = clf_forest_sm.predict(X_test)\nprint('predicted_y:', predicted_y_sm)\nprint('accuracy_score:', clf_forest_sm.score(X_test, Y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_sm = confusion_matrix(Y_test, predicted_y_sm)\ntn, fp, fn, tp=cm_sm.ravel()\nprint(cm_u)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"Re=tp/(tp+fn)\nPr=tp/(tp+fp)\nSp=tn/(tn+fp)\nBac=(Re+Sp)/2\nF=2*Re*Pr/(Re+Pr)\nprint('Accuracy (Forest):',clf_forest_u.score(X_test, Y_test))\nprint('Recall (Forest):', Re)\nprint('Precision (Forest):', Pr)\nprint('F-measure (Forest):', F)\nb=2   # приоритет у Recall # b>1(Recall), 0<b<1(Precision)\nF_b=(1+b**2)*Re*Pr/(Re+Pr*b**2)\nprint('F_2-measure (Forest):', F_b)\nprint('Balanced accuracy (Forest):', Bac)\nprint('Specificity_ (Forest):', Sp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Undersampling using Tomek Links. Testing on Tomek Links-data"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"clf_forest_tl = RandomForestClassifier(random_state=1, n_estimators=500, min_samples_split=10, min_samples_leaf=2)\n\ncv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\nscores = cross_validate(clf_forest_tl, X_tl, Y_tl, cv=cv, n_jobs=-1, scoring=['accuracy','precision','recall'], return_train_score=True)\n\nprint(\"Accuracy_test (Forest): {}\".format(scores['test_accuracy'].mean()), \n      \"Recall_test (Forest): {}\".format(scores['test_recall'].mean()),\n      \"Precision_test (Forest): {}\".format(scores['test_precision'].mean()), sep='\\n')\n\nb=2   # b>1(Recall), 0<b<1(Precision)\nF_b=(1+b**2)*scores['test_recall'].mean()*scores['test_precision'].mean()/(scores['test_recall'].mean()+scores['test_precision'].mean()*b**2)\nprint('F_2-measure_test (Forest):', F_b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_forest_tl.fit(X_tl, Y_tl)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"predicted_y_tl = clf_forest_tl.predict(X_test)\nprint('predicted_y:', predicted_y_tl)\nprint('accuracy_score:', clf_forest_sm.score(X_test, Y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_tl = confusion_matrix(Y_test, predicted_y_tl)\ntn, fp, fn, tp=cm_tl.ravel()\nprint(cm_u)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"Re=tp/(tp+fn)\nPr=tp/(tp+fp)\nSp=tn/(tn+fp)\nBac=(Re+Sp)/2\nF=2*Re*Pr/(Re+Pr)\nprint('Accuracy (Forest):',clf_forest_tl.score(X_test, Y_test))\nprint('Recall (Forest):', Re)\nprint('Precision (Forest):', Pr)\nprint('F-measure (Forest):', F)\nb=2   # приоритет у Recall # b>1(Recall), 0<b<1(Precision)\nF_b=(1+b**2)*Re*Pr/(Re+Pr*b**2)\nprint('F_2-measure (Forest):', F_b)\nprint('Balanced accuracy (Forest):', Bac)\nprint('Specificity_ (Forest):', Sp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.3.2 XGBoost considering the imbalance. Oversampling with SMOTE and Undersampling with Tomek Links"},{"metadata":{"trusted":true},"cell_type":"code","source":"#parameters\nparams = {\n    \"learning_rate\"    :[0.05,0.10,0.15,0.20,0.25,0.30],\n    \"max_depth\"        :[ 3,4,5,6,8,10,12,15 ],\n    \"min_child_weight\" :[ 1,3,5,7 ],\n    \"gamma\"            :[ 0.0,0.1,0.2,0.3,0.4 ],\n    \"colsample_bytree\" :[ 0.3, 0.4, 0.5, 0.7 ]\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = XGBClassifier()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Let's try to reconfigure the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search=RandomizedSearchCV(classifier, param_distributions=params, n_iter=5, scoring='roc_auc',n_jobs=-1, cv=cv,verbose=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.fit(X_sm,Y_sm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.5, gamma=0.3,\n              learning_rate=0.15, max_delta_step=0, max_depth=10,\n              min_child_weight=5, missing=None, n_estimators=100, n_jobs=1,\n              nthread=None, objective='binary:logistic', random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n              silent=None, subsample=1, verbosity=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = cross_val_score(classifier,X_sm,Y_sm,cv=10)\nscore.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit(X_train_sm, Y_train_sm)\nY_test_preds=classifier.predict(X_test_sm)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print('Accuracy (XGBoost): {0:.2f}'.format(accuracy_score(Y_test_sm, Y_test_preds)))\nprint('Precision (XGBoost): {0:.2f}'.format(precision_score(Y_test_sm, Y_test_preds)))\nprint('Recall (XGBoost): {0:.2f}'.format(recall_score(Y_test_sm, Y_test_preds)))\nprint('F2 (XGBoost): {0:.2f}'.format(fbeta_score(Y_test_sm, Y_test_preds, 2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Oversampling. Testing on data1 "},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit(X_train_sm, Y_train_sm)\nY_test_preds=classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"print('Accuracy (XGBoost): {0:.2f}'.format(accuracy_score(Y_test, Y_test_preds)))\nprint('Precision (XGBoost): {0:.2f}'.format(precision_score(Y_test, Y_test_preds)))\nprint('Recall (XGBoost): {0:.2f}'.format(recall_score(Y_test, Y_test_preds)))\nprint('F2 (XGBoost): {0:.2f}'.format(fbeta_score(Y_test, Y_test_preds, 2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Undersampling using Tomek Links. Testing on Tomek Links-data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#parameters\nparams = {\n    \"learning_rate\"    :[0.05,0.10,0.15,0.20,0.25,0.30],\n    \"max_depth\"        :[ 3,4,5,6,8,10,12,15 ],\n    \"min_child_weight\" :[ 1,3,5,7 ],\n    \"gamma\"            :[ 0.0,0.1,0.2,0.3,0.4 ],\n    \"colsample_bytree\" :[ 0.3, 0.4, 0.5, 0.7 ]\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = XGBClassifier()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Let's try to reconfigure the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search=RandomizedSearchCV(classifier, param_distributions=params, n_iter=5, scoring='roc_auc',n_jobs=-1, cv=cv,verbose=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.fit(X_tl,Y_tl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.5, gamma=0.3,\n              learning_rate=0.15, max_delta_step=0, max_depth=10,\n              min_child_weight=5, missing=None, n_estimators=100, n_jobs=1,\n              nthread=None, objective='binary:logistic', random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n              silent=None, subsample=1, verbosity=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = cross_val_score(classifier,X_tl,Y_tl,cv=10)\nscore.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit(X_train_tl, Y_train_tl)\nY_test_preds=classifier.predict(X_test_tl)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print('Accuracy (XGBoost): {0:.2f}'.format(accuracy_score(Y_test_tl, Y_test_preds)))\nprint('Precision (XGBoost): {0:.2f}'.format(precision_score(Y_test_tl, Y_test_preds)))\nprint('Recall (XGBoost): {0:.2f}'.format(recall_score(Y_test_tl, Y_test_preds)))\nprint('F2 (XGBoost): {0:.2f}'.format(fbeta_score(Y_test_tl, Y_test_preds, 2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Undersampling using Tomek Links. Testing on data1-data"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit(X_train_tl, Y_train_tl)\nY_test_preds=classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"print('Accuracy: {0:.2f}'.format(accuracy_score(Y_test, Y_test_preds)))\nprint('Precision: {0:.2f}'.format(precision_score(Y_test, Y_test_preds)))\nprint('Recall: {0:.2f}'.format(recall_score(Y_test, Y_test_preds)))\nprint('F2: {0:.2f}'.format(fbeta_score(Y_test, Y_test_preds, 2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Conclusion"},{"metadata":{},"cell_type":"markdown","source":"### In this work, the quality of the model was determined mainly by the metric F2. It is presented in the following table."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"tbl = {'Par.':[2, 3.1, 3.2, 3.2, 3.3, 3.3], \n         'Kind':['-', 'Balanced weight', 'Random oversampling', 'Random undersampling','Oversampling(SMOTE)','Undersampling(Tomek Links)'], \n         'Log_Reg':[0.02, 0.51, 0.50, 0.51, 0.63, 0.13], \n         'Forest':[0.39, 0.52, 0.92, 0.76, 0.83, 0.65], \n         'XGBoost':[0.39, 0.61, 0.79, 0.67, 0.67, 0.57]}\ntable=pd.DataFrame(tbl)\ntable","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The best quality model is Forest on Random oversampling with F_2=0.92."},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}