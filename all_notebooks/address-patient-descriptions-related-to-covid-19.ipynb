{"cells":[{"metadata":{},"cell_type":"markdown","source":"# This is a notebook for address patient descriptions related to COVID-19.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Prepare data","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport json\nimport re\nimport scipy as sc\nimport warnings\n\nimport matplotlib.pyplot as plt\nimport os\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"root_path = '/kaggle/input/CORD-19-research-challenge/'\nmetadata_path = f'{root_path}/metadata.csv'\nmeta_df = pd.read_csv(metadata_path, dtype={\n    'pubmed_id': str,\n    'Microsoft Academic Paper ID': str, \n    'doi': str\n})\nmeta_df.head()\nmeta_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_df.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -U sentence-transformers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sentence_transformers import SentenceTransformer\n\nwarnings.filterwarnings(\"ignore\")\nmodel = SentenceTransformer('bert-base-nli-mean-tokens')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\nall_json = glob.glob(f'{root_path}/**/*.json', recursive=True)\nlen(all_json)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_json[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class FileReader:\n    def __init__(self, file_path):\n        with open(file_path) as file:\n            content = json.load(file)\n            \n            self.paper_id = content['paper_id']\n            \n            self.abstract = []\n            self.body_text = []\n            # Abstract\n            for entry in content['abstract']:\n                self.abstract.append(entry['text'])\n            # Body text\n            for entry in content['body_text']:\n                self.body_text.append(entry['text'])\n            self.abstract = '\\n'.join(self.abstract)\n            self.body_text = '\\n'.join(self.body_text)\n    def __repr__(self):\n        return f'{self.paper_id}: {self.abstract[:200]}... {self.body_text[:200]}...'\ndef get_breaks(content, length):\n    data = \"\"\n    words = content.split(' ')\n    total_chars = 0\n\n    # add break every length characters\n    for i in range(len(words)):\n        total_chars += len(words[i])\n        if total_chars > length:\n            data = data + \"<br>\" + words[i]\n            total_chars = 0\n        else:\n            data = data + \" \" + words[i]\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_ = {'publish_time': [], 'url': [], 'paper_id': [], 'doi':[], 'abstract': [], 'body_text': [], 'authors': [], 'title': [], 'journal': [], 'abstract_summary': []}\nfor idx, entry in enumerate(all_json):\n    if idx % (len(all_json) // 10) == 0:\n        print(f'Processing index: {idx} of {len(all_json)}')\n    \n    try:\n        content = FileReader(entry)\n    except Exception as e:\n        continue  # invalid paper format, skip\n\n    # get metadata information\n    meta_data = meta_df.loc[meta_df['sha'] == content.paper_id]\n    # no metadata, skip this paper\n    if len(meta_data) == 0:\n        continue\n    \n    dict_['abstract'].append(content.abstract)\n    dict_['paper_id'].append(content.paper_id)\n    dict_['body_text'].append(content.body_text)\n    \n    # also create a column for the summary of abstract to be used in a plot\n    if len(content.abstract) == 0: \n        # no abstract provided\n        dict_['abstract_summary'].append(\"Not provided.\")\n    elif len(content.abstract.split(' ')) > 100:\n        # abstract provided is too long for plot, take first 100 words append with ...\n        info = content.abstract.split(' ')[:100]\n        summary = get_breaks(' '.join(info), 40)\n        dict_['abstract_summary'].append(summary + \"...\")\n    else:\n        # abstract is short enough\n        summary = get_breaks(content.abstract, 40)\n        dict_['abstract_summary'].append(summary)\n        \n    # get metadata information\n    meta_data = meta_df.loc[meta_df['sha'] == content.paper_id]\n    \n    try:\n        # if more than one author\n        authors = meta_data['authors'].values[0].split(';')\n        if len(authors) > 2:\n            # if more than 2 authors, take them all with html tag breaks in between\n            dict_['authors'].append(get_breaks('. '.join(authors), 40))\n        else:\n            # authors will fit in plot\n            dict_['authors'].append(\". \".join(authors))\n    except Exception as e:\n        # if only one author - or Null valie\n        dict_['authors'].append(meta_data['authors'].values[0])\n    \n    # add the title information, add breaks when needed\n    try:\n        title = get_breaks(meta_data['title'].values[0], 40)\n        dict_['title'].append(title)\n    # if title was not provided\n    except Exception as e:\n        dict_['title'].append(meta_data['title'].values[0])\n    \n    # add meta_data information\n    dict_['journal'].append(meta_data['journal'].values[0])\n    dict_['doi'].append(meta_data['doi'].values[0])\n    dict_['publish_time'].append(meta_data['publish_time'].values[0])\n    dict_['url'].append(meta_data['url'].values[0])\n    \n    \ndf_covid = pd.DataFrame(dict_, columns=['publish_time', 'url', 'paper_id', 'doi', 'abstract', 'body_text', 'authors', 'title', 'journal', 'abstract_summary'])\ndf_covid.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_covid.info() \ndf_covid.drop_duplicates(['abstract', 'body_text'], inplace=True)\ndf_covid['abstract'].describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_covid.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_covid.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_covid['abstract'].describe(include='all')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df_covid","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Add the language attribute.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install langdetect","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\nfrom langdetect import detect\nfrom langdetect import DetectorFactory\n\n# set seed\nDetectorFactory.seed = 1000000007\n\n# hold label - language\nlanguages = []\n\n# go through each text\nfor ii in tqdm(range(0,len(df))):\n    # split by space into list, take the first x intex, join with space\n    text = df.iloc[ii]['body_text'].split(\" \")\n    \n    lang = \"en\"\n    try:\n        if len(text) > 50:\n            lang = detect(\" \".join(text[:50]))\n        elif len(text) > 0:\n            lang = detect(\" \".join(text[:len(text)]))\n    # ught... beginning of the document was not in a good format\n    except Exception as e:\n        all_words = set(text)\n        try:\n            lang = detect(\" \".join(all_words))\n        # what!! :( let's see if we can find any text in abstract...\n        except Exception as e:\n            \n            try:\n                # let's try to label it through the abstract then\n                lang = detect(df.iloc[ii]['abstract_summary'])\n            except Exception as e:\n                lang = \"unknown\"\n                pass\n    \n    # get the language    \n    languages.append(lang)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pprint import pprint\n\nlanguages_dict = {}\nfor lang in set(languages):\n    languages_dict[lang] = languages.count(lang)\n    \nprint(\"Total: {}\\n\".format(len(languages)))\npprint(languages_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['language'] = languages\nplt.bar(range(len(languages_dict)), list(languages_dict.values()), align='center')\nplt.xticks(range(len(languages_dict)), list(languages_dict.keys()))\nplt.title(\"Distribution of Languages in Dataset\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[df['language'] == 'en'] \ndf.info()\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(inplace=True)\ndf.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check the keywords of the problems.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#Check the keywords of the problems.\n\n\n- Specifically, we want to know what the literature reports about:\n\n- **Length** of **viral shedding after illness onset**\n\n- Incubation period across **different age groups**\n\n- What is the **Incubation Period** of the Virus?\n\n- Proportion of patients who were **asymptomatic**\n\n- **Pediatric** patients who were **asymptomatic**\n\n- **Asymptomatic transmission** during **incubation**\n\n- **Natural history** of the virus from an infected person\n\n- What is the **median viral shedding duration**?\n\n- What is the **longest duration of viral shedding**?\n\n- Manifestations of COVID-19 including but not limited to possible **cardiomyopathy** and **cardiac arrest**\n\n- How does **viral load** relate to **disease presentation** which includes likelihood of a **positive diagnostic test**?\n\n- What do we know about **disease models**?\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"task1=\"\"\"Specifically, we want to know what the literature reports about:\n\nLength of viral shedding after illness onset\nIncubation period across different age groups\nWhat is the Incubation Period of the Virus?\nProportion of patients who were asymptomatic\nProportion of pediatric COVID19 patients who were asymptomatic\nAsymptomatic transmission during incubation\nNatural history of the virus from an infected person\nWhat is the median viral shedding duration?\nWhat is the longest duration of viral shedding?\nManifestations of COVID-19 including but not limited to possible cardiomyopathy and cardiac arrest\nHow does viral load relate to disease presentations and likelihood of a positive diagnostic test_.csv\nWhat do we know about disease models?\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"task=[task1]\nquery=[]\nfor i in range(len(task)):\n    task[i]=task[i].split(\"\\n\")\n    query.append(task[i][2:])\nprint(query)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"query_embeddings=[]\nfor i in range(len(query)):\n    query_embeddings.append(model.encode(query[i]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.reset_index(drop = True, inplace = True)\ndf['abstract_summary']\n#abstract_embeddings = model.encode(df['abstract'])\nabstract_summary_embeddings = model.encode(df['abstract_summary'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getfile_insensitive(path):\n    directory, filename = os.path.split(path)\n    directory, filename = (directory or '.'), filename.lower()\n    for f in os.listdir(directory):\n        newpath = os.path.join(directory, f)\n        if os.path.isfile(newpath) and f.lower() == filename:\n            return newpath\n\ndef isfile_insensitive(path):\n    return getfile_insensitive(path) is not None\n\nsample_document='3_patient_descriptions'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores=[]\ndef formatting(_topdf):\n    _topdf.rename(columns={'journal':'Journal'},inplace=True)\n    _topdf.rename(columns={'url':'Study Link'},inplace=True)\n    _topdf.rename(columns={'publish_time':'Date'},inplace=True)\n    _topdf.rename(columns={'title':'Study'},inplace=True)\n    \n    return _topdf\nfor tsk in range(len(task)):\n    \n    for prob, query_embedding in zip(query[tsk], query_embeddings[tsk]):\n        dis = sc.spatial.distance.cdist([query_embedding], abstract_summary_embeddings, \"cosine\")[0]\n        print(dis)\n        results = zip(range(len(dis)), dis)\n        results = sorted(results, key=lambda x: x[1])\n        print(\"Query:\", prob)\n        print(\"Answer:\" )\n        scores.append(1-results[0][1])\n        print(df['abstract'][results[0][0]].strip(), \"\\n(Score: %.4f)\" % (1-results[0][1]),\"\\n\")\n        k=10\n        print(results[:k])\n        topk=results[:k]\n        id,id_v=zip(*topk)\n        topData=df.iloc[1]\n        _topdf = df.iloc[list(id), :]\n        _topdf = formatting(_topdf)\n        csv_str=prob.replace('?','_')+'.csv'\n        print(csv_str)\n        path1 = f'{root_path}Kaggle/target_tables/{sample_document}/'+csv_str\n        path1 = f'{path1}'\n        print(path1)\n        if (isfile_insensitive(path1)):\n            path1=getfile_insensitive(path1)\n            q_df = pd.read_csv(path1)\n        else:      \n            path1 = f'{root_path}Kaggle/target_tables/{sample_document}/'\n            path1 = os.path.join(path1,os.listdir(path1)[-1])\n            q_df = pd.read_csv(path1)\n            q_df.drop(q_df.index,inplace=True)\n        #print('../input/CORD-19-research-challenge/Kaggle/target_tables/3_patient_descriptions/What is the incubation period of the virus_.csv')\n        #print(path1)\n        q_df.head()\n        q_df\n        #print(len(q_df))\n        #print(len(_topdf))\n        #print(q_df.columns)\n        res_df = pd.merge(q_df, _topdf, how='outer', on=['Study','Study Link','Date','Journal'])[q_df.columns[1:]]\n        #print(len(res_df))\n        res_df.info()\n        res_csv=r'/kaggle/output/'+ csv_str\n        print(res_csv)\n        res_df.to_csv( csv_str, index = True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}