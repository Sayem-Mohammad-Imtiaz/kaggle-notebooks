{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read My Article on Medium [here](https://medium.com/@taruntiwari.hp/phishing-sites-predictor-using-fastapi-2b5de0272f0)\n## Watch My Explaination Video on YouTube [here](https://youtu.be/zKNXHluHneU)"},{"metadata":{},"cell_type":"markdown","source":"### * **What is a phishing attack?**\n* Phishing is a type of social engineering attack often used to steal user data, including login credentials and credit card numbers. It occurs when an attacker, masquerading as a trusted entity, dupes a victim into opening an email, instant message, or text message. "},{"metadata":{},"cell_type":"markdown","source":"### * Phishing attack examples\n* A spoofed email ostensibly from myuniversity.edu is mass-distributed to as many faculty members as possible. The email claims that the user’s password is about to expire. Instructions are given to go to myuniversity.edu/renewal to renew their password within 24 hours.>\n<img src='https://github.com/taruntiwarihp/raw_images/blob/master/phishing-attack-email-example.png?raw=true'>"},{"metadata":{},"cell_type":"markdown","source":"* Several things can occur by clicking the link. For example:\n\n    1. The user is redirected to myuniversity.edurenewal.com, a bogus page appearing exactly like the real renewal page, where both new and existing passwords are requested. The attacker, monitoring the page, hijacks the original password to gain access to secured areas on the university network.\n    \n    2. The user is sent to the actual password renewal page. However, while being redirected, a malicious script activates in the background to hijack the user’s session cookie. This results in a reflected XSS attack, giving the perpetrator privileged access to the university network."},{"metadata":{},"cell_type":"markdown","source":"##### * Importing some useful libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install selenium","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd # use for data manipulation and analysis\nimport numpy as np # use for multi-dimensional array and matrix\n\nimport seaborn as sns # use for high-level interface for drawing attractive and informative statistical graphics \nimport matplotlib.pyplot as plt # It provides an object-oriented API for embedding plots into applications\n%matplotlib inline \n# It sets the backend of matplotlib to the 'inline' backend:\nimport plotly.express as px\nimport time # calculate time \n\nfrom sklearn.linear_model import LogisticRegression # algo use to predict good or bad\nfrom sklearn.naive_bayes import MultinomialNB # nlp algo use to predict good or bad\n\nfrom sklearn.model_selection import train_test_split # spliting the data between feature and target\nfrom sklearn.metrics import classification_report # gives whole report about metrics (e.g, recall,precision,f1_score,c_m)\nfrom sklearn.metrics import confusion_matrix # gives info about actual and predict\nfrom nltk.tokenize import RegexpTokenizer # regexp tokenizers use to split words from text  \nfrom nltk.stem.snowball import SnowballStemmer # stemmes words\nfrom sklearn.feature_extraction.text import CountVectorizer # create sparse matrix of words using regexptokenizes  \nfrom sklearn.pipeline import make_pipeline # use for combining all prerocessors techniuqes and algos\n\nfrom PIL import Image # getting images in notebook\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator# creates words colud\n\nfrom bs4 import BeautifulSoup # use for scraping the data from website\nfrom selenium import webdriver # use for automation chrome \nimport networkx as nx # for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks.\n\nimport pickle# use to dump model \n\nimport warnings # ignores pink warnings \nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading the dataset\nphish_data = pd.read_csv('/kaggle/input/phishing-site-urls/phishing_site_urls.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"phish_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"phish_data.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"phish_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **About dataset**\n* Data is containg 5,49,346 unique entries.\n* There are two columns.\n* Label column is prediction col which has 2 categories \n    A. Good - which means the urls is not containing malicious stuff and **this site is not a Phishing Site.**\n    B. Bad - which means the urls contains malicious stuffs and **this site isa Phishing Site.**\n* There is no missing value in the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"phish_data.isnull().sum() # there is no missing values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Since it is classification problems so let's see the classes are balanced or imbalances**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a dataframe of classes counts\nlabel_counts = pd.DataFrame(phish_data.Label.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualizing target_col\nfig = px.bar(label_counts, x=label_counts.index, y=label_counts.Label)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing\n* **Now that we have the data, we have to vectorize our URLs. I used CountVectorizer and gather words using tokenizer, since there are words in urls that are more important than other words e.g ‘virus’, ‘.exe’ ,’.dat’ etc. Lets convert the URLs into a vector form.**"},{"metadata":{},"cell_type":"markdown","source":"#### RegexpTokenizer\n* A tokenizer that splits a string using a regular expression, which matches either the tokens or the separators between tokens."},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = RegexpTokenizer(r'[A-Za-z]+')#to getting alpha only","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"phish_data.URL[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# this will be pull letter which matches to expression\ntokenizer.tokenize(phish_data.URL[0]) # using first row","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Getting words tokenized ...')\nt0= time.perf_counter()\nphish_data['text_tokenized'] = phish_data.URL.map(lambda t: tokenizer.tokenize(t)) # doing with all rows\nt1 = time.perf_counter() - t0\nprint('Time taken',t1 ,'sec')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"phish_data.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### SnowballStemmer\n* Snowball is a small string processing language, gives root words"},{"metadata":{"trusted":true},"cell_type":"code","source":"stemmer = SnowballStemmer(\"english\") # choose a language","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Getting words stemmed ...')\nt0= time.perf_counter()\nphish_data['text_stemmed'] = phish_data['text_tokenized'].map(lambda l: [stemmer.stem(word) for word in l])\nt1= time.perf_counter() - t0\nprint('Time taken',t1 ,'sec')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"phish_data.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Getting joiningwords ...')\nt0= time.perf_counter()\nphish_data['text_sent'] = phish_data['text_stemmed'].map(lambda l: ' '.join(l))\nt1= time.perf_counter() - t0\nprint('Time taken',t1 ,'sec')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"phish_data.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualization \n**1. Visualize some important keys using word cloud**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#sliceing classes\nbad_sites = phish_data[phish_data.Label == 'bad']\ngood_sites = phish_data[phish_data.Label == 'good']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bad_sites.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"good_sites.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* create a function to visualize the important keys from url "},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_wordcloud(text, mask=None, max_words=400, max_font_size=120, figure_size=(24.0,16.0), \n                   title = None, title_size=40, image_color=False):\n    stopwords = set(STOPWORDS)\n    more_stopwords = {'com','http'}\n    stopwords = stopwords.union(more_stopwords)\n\n    wordcloud = WordCloud(background_color='white',\n                    stopwords = stopwords,\n                    max_words = max_words,\n                    max_font_size = max_font_size, \n                    random_state = 42,\n                    mask = mask)\n    wordcloud.generate(text)\n    \n    plt.figure(figsize=figure_size)\n    if image_color:\n        image_colors = ImageColorGenerator(mask);\n        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n        plt.title(title, fontdict={'size': title_size,  \n                                  'verticalalignment': 'bottom'})\n    else:\n        plt.imshow(wordcloud);\n        plt.title(title, fontdict={'size': title_size, 'color': 'green', \n                                  'verticalalignment': 'bottom'})\n    plt.axis('off');\n    plt.tight_layout()  \nd = '../input/masks/masks-wordclouds/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = good_sites.text_sent\ndata.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"common_text = str(data)\ncommon_mask = np.array(Image.open(d+'star.png'))\nplot_wordcloud(common_text, common_mask, max_words=400, max_font_size=120, \n               title = 'Most common words use in good urls', title_size=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = bad_sites.text_sent\ndata.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"common_text = str(data)\ncommon_mask = np.array(Image.open(d+'comment.png'))\nplot_wordcloud(common_text, common_mask, max_words=400, max_font_size=120, \n               title = 'Most common words use in bad urls', title_size=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Visualize internal links, it will shows all redirect links.\n    * P> NetworkX visual links nodes are not working on kaggle, but you can see it on my Jupyter notebook <a href='https://github.com/taruntiwarihp/Projects_DS/tree/master/Phishing%20Site%20URLs%20Prediction'>here</a>"},{"metadata":{},"cell_type":"markdown","source":"### Creating Model\n#### CountVectorizer\n* CountVectorizer is used to transform a corpora of text to a vector of term / token counts."},{"metadata":{"trusted":true},"cell_type":"code","source":"#create cv object\ncv = CountVectorizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"help(CountVectorizer())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature = cv.fit_transform(phish_data.text_sent) #transform all text which we tokenize and stemed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature[:5].toarray() # convert sparse matrix into array to print transformed features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### * Spliting the data "},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX, testX, trainY, testY = train_test_split(feature, phish_data.Label)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LogisticRegression\n* Logistic Regression is a Machine Learning classification algorithm that is used to predict the probability of a categorical dependent variable. In logistic regression, the dependent variable is a binary variable that contains data coded as 1 (yes, success, etc.) or 0 (no, failure, etc.). In other words, the logistic regression model predicts P(Y=1) as a function of X."},{"metadata":{"trusted":true},"cell_type":"code","source":"# create lr object\nlr = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr.fit(trainX,trainY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr.score(testX,testY)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":".*** Logistic Regression is giving 96% accuracy, Now we will store scores in dict to see which model perform best**"},{"metadata":{"trusted":true},"cell_type":"code","source":"Scores_ml = {}\nScores_ml['Logistic Regression'] = np.round(lr.score(testX,testY),2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training Accuracy :',lr.score(trainX,trainY))\nprint('Testing Accuracy :',lr.score(testX,testY))\ncon_mat = pd.DataFrame(confusion_matrix(lr.predict(testX), testY),\n            columns = ['Predicted:Bad', 'Predicted:Good'],\n            index = ['Actual:Bad', 'Actual:Good'])\n\n\nprint('\\nCLASSIFICATION REPORT\\n')\nprint(classification_report(lr.predict(testX), testY,\n                            target_names =['Bad','Good']))\n\nprint('\\nCONFUSION MATRIX')\nplt.figure(figsize= (6,4))\nsns.heatmap(con_mat, annot = True,fmt='d',cmap=\"YlGnBu\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### MultinomialNB\n* Applying Multinomial Naive Bayes to NLP Problems. Naive Bayes Classifier Algorithm is a family of probabilistic algorithms based on applying Bayes' theorem with the “naive” assumption of conditional independence between every pair of a feature."},{"metadata":{"trusted":true},"cell_type":"code","source":"# create mnb object\nmnb = MultinomialNB()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mnb.fit(trainX,trainY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mnb.score(testX,testY)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*** MultinomialNB gives us 95% accuracy**  "},{"metadata":{"trusted":true},"cell_type":"code","source":"Scores_ml['MultinomialNB'] = np.round(mnb.score(testX,testY),2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training Accuracy :',mnb.score(trainX,trainY))\nprint('Testing Accuracy :',mnb.score(testX,testY))\ncon_mat = pd.DataFrame(confusion_matrix(mnb.predict(testX), testY),\n            columns = ['Predicted:Bad', 'Predicted:Good'],\n            index = ['Actual:Bad', 'Actual:Good'])\n\n\nprint('\\nCLASSIFICATION REPORT\\n')\nprint(classification_report(mnb.predict(testX), testY,\n                            target_names =['Bad','Good']))\n\nprint('\\nCONFUSION MATRIX')\nplt.figure(figsize= (6,4))\nsns.heatmap(con_mat, annot = True,fmt='d',cmap=\"YlGnBu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = pd.DataFrame.from_dict(Scores_ml,orient = 'index',columns=['Accuracy'])\nsns.set_style('darkgrid')\nsns.barplot(acc.index,acc.Accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*** So, Logistic Regression is the best fit model, Now we make sklearn pipeline using Logistic Regression**"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_ls = make_pipeline(CountVectorizer(tokenizer = RegexpTokenizer(r'[A-Za-z]+').tokenize,stop_words='english'), LogisticRegression())\n##(r'\\b(?:http|ftp)s?://\\S*\\w|\\w+|[^\\w\\s]+') ([a-zA-Z]+)([0-9]+)  -- these tolenizers giving me low accuray ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX, testX, trainY, testY = train_test_split(phish_data.URL, phish_data.Label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_ls.fit(trainX,trainY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_ls.score(testX,testY) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training Accuracy :',pipeline_ls.score(trainX,trainY))\nprint('Testing Accuracy :',pipeline_ls.score(testX,testY))\ncon_mat = pd.DataFrame(confusion_matrix(pipeline_ls.predict(testX), testY),\n            columns = ['Predicted:Bad', 'Predicted:Good'],\n            index = ['Actual:Bad', 'Actual:Good'])\n\n\nprint('\\nCLASSIFICATION REPORT\\n')\nprint(classification_report(pipeline_ls.predict(testX), testY,\n                            target_names =['Bad','Good']))\n\nprint('\\nCONFUSION MATRIX')\nplt.figure(figsize= (6,4))\nsns.heatmap(con_mat, annot = True,fmt='d',cmap=\"YlGnBu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pickle.dump(pipeline_ls,open('phishing.pkl','wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loaded_model = pickle.load(open('phishing.pkl', 'rb'))\nresult = loaded_model.score(testX,testY)\nprint(result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***That’s it. See, it's that simple yet so effective. We get an accuracy of 98%. That’s a very high value for a machine to be able to detect a malicious URL with. Want to test some links to see if the model gives good predictions? Sure. Let's do it**"},{"metadata":{},"cell_type":"markdown","source":"* Bad links => this are phishing sites\nyeniik.com.tr/wp-admin/js/login.alibaba.com/login.jsp.php\nfazan-pacir.rs/temp/libraries/ipad\nwww.tubemoviez.exe\nsvision-online.de/mgfi/administrator/components/com_babackup/classes/fx29id1.txt\n\n* Good links => this are not phishing sites\nwww.youtube.com/\nyoutube.com/watch?v=qI0TQJI3vdU\nwww.retailhellunderground.com/\nrestorevisioncenters.com/html/technology.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_bad = ['yeniik.com.tr/wp-admin/js/login.alibaba.com/login.jsp.php','fazan-pacir.rs/temp/libraries/ipad','tubemoviez.exe','svision-online.de/mgfi/administrator/components/com_babackup/classes/fx29id1.txt']\npredict_good = ['youtube.com/','youtube.com/watch?v=qI0TQJI3vdU','retailhellunderground.com/','restorevisioncenters.com/html/technology.html']\nloaded_model = pickle.load(open('phishing.pkl', 'rb'))\n#predict_bad = vectorizers.transform(predict_bad)\n# predict_good = vectorizer.transform(predict_good)\nresult = loaded_model.predict(predict_bad)\nresult2 = loaded_model.predict(predict_good)\nprint(result)\nprint(\"*\"*30)\nprint(result2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Protections\n#### How to Protect Your Computer \nBelow are some key steps to protecting your computer from intrusion:\n\n1. **Keep Your Firewall Turned On:** A firewall helps protect your computer from hackers who might try to gain access to crash it, delete information, or even steal passwords or other sensitive information. Software firewalls are widely recommended for single computers. The software is prepackaged on some operating systems or can be purchased for individual computers. For multiple networked computers, hardware routers typically provide firewall protection.\n\n2. **Install or Update Your Antivirus Software:** Antivirus software is designed to prevent malicious software programs from embedding on your computer. If it detects malicious code, like a virus or a worm, it works to disarm or remove it. Viruses can infect computers without users’ knowledge. Most types of antivirus software can be set up to update automatically.\n\n3. **Install or Update Your Antispyware Technology:** Spyware is just what it sounds like—software that is surreptitiously installed on your computer to let others peer into your activities on the computer. Some spyware collects information about you without your consent or produces unwanted pop-up ads on your web browser. Some operating systems offer free spyware protection, and inexpensive software is readily available for download on the Internet or at your local computer store. Be wary of ads on the Internet offering downloadable antispyware—in some cases these products may be fake and may actually contain spyware or other malicious code. It’s like buying groceries—shop where you trust.\n\n4. **Keep Your Operating System Up to Date:** Computer operating systems are periodically updated to stay in tune with technology requirements and to fix security holes. Be sure to install the updates to ensure your computer has the latest protection.\n\n5. **Be Careful What You Download:** Carelessly downloading e-mail attachments can circumvent even the most vigilant anti-virus software. Never open an e-mail attachment from someone you don’t know, and be wary of forwarded attachments from people you do know. They may have unwittingly advanced malicious code.\n\n6. **Turn Off Your Computer:** With the growth of high-speed Internet connections, many opt to leave their computers on and ready for action. The downside is that being “always on” renders computers more susceptible. Beyond firewall protection, which is designed to fend off unwanted attacks, turning the computer off effectively severs an attacker’s connection—be it spyware or a botnet that employs your computer’s resources to reach out to other unwitting users."},{"metadata":{},"cell_type":"markdown","source":"## To see How model deploy using fastapi visit my github <a href='https://github.com/taruntiwarihp/Projects_DS/tree/master/Phishing%20Site%20URLs%20Prediction'>here</a>\n* Thank you"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}