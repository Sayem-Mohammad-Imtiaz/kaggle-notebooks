{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://media.giphy.com/media/dVuyBgq2z5gVBkFtDc/giphy.gif)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Coronaviruses are a large family of viruses which may cause illness in animals or humans. In humans, several coronaviruses are known to cause respiratory infections ranging from the common cold to more severe diseases such as Middle East Respiratory Syndrome (MERS) and Severe Acute Respiratory Syndrome (SARS). The most recently discovered coronavirus causes coronavirus disease COVID-19.COVID-19 is the infectious disease caused by the most recently discovered coronavirus. This new virus and disease were unknown before the outbreak began in Wuhan, China, in December 2019.\n**\n* [Source](https://www.who.int/news-room/q-a-detail/q-a-coronaviruses)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **Coronavirus in the world**","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import pandas as pd \ncases = pd.read_csv(\"../input/novel-corona-virus-2019-dataset/covid_19_data.csv\")\nimport plotly.offline as py\nimport plotly.express as px\n\n\npy.init_notebook_mode(connected=True)\n\ngrp = cases.groupby(['ObservationDate', 'Country/Region'])['Confirmed', 'Deaths', 'Recovered'].max()\ngrp = grp.reset_index()\ngrp['Date'] = pd.to_datetime(grp['ObservationDate'])\ngrp['Date'] = grp['Date'].dt.strftime('%m/%d/%Y')\ngrp['Active'] = grp['Confirmed'] - grp['Recovered'] - grp['Deaths']\ngrp['Country'] =  grp['Country/Region']\n\nfig = px.choropleth(grp, locations=\"Country\", locationmode='country names', \n                     color=\"Confirmed\", hover_name=\"Country/Region\",hover_data = [grp.Recovered,grp.Deaths,grp.Active],projection=\"natural earth\",\n                     animation_frame=\"Date\",width=1000, height=700,\n                     color_continuous_scale='Reds',\n                     range_color=[1000,50000],\n\n                     title='World Map of Coronavirus')\n\nfig.update(layout_coloraxis_showscale=True)\npy.offline.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Related Work**\n * For Analysis and Prediction on Coronavirus(Italy), Click [here](https://www.kaggle.com/vanshjatana/analysis-and-prediction-on-coronavirus-italy?scriptVersionId=29892166)\n*  For Analysis and Prediction on Coronavirus(Iran), Click [here](https://www.kaggle.com/vanshjatana/analysis-and-prediction-on-coronavirus-iran)\n*  For Analysis and Prediction on Coronavirus(South-Korea), Click [here](https://www.kaggle.com/vanshjatana/analysis-on-coronavirus)\n*  For report on Coronavirus, Click [here](https://www.researchgate.net/publication/339738108_Analysis_On_Coronavirus)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Symtoms of Coronavirus","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"symptoms={'symptom':['Fever',\n        'Dry cough',\n        'Fatigue',\n        'Sputum production',\n        'Shortness of breath',\n        'Muscle pain',\n        'Sore throat',\n        'Headache',\n        'Chills',\n        'Nausea or vomiting',\n        'Nasal congestion',\n        'Diarrhoea',\n        'Haemoptysis',\n        'Conjunctival congestion'],'percentage':[87.9,67.7,38.1,33.4,18.6,14.8,13.9,13.6,11.4,5.0,4.8,3.7,0.9,0.8]}\n\nsymptoms=pd.DataFrame(data=symptoms,index=range(14))\nsymptoms","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Bar Plot**","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.bar(symptoms[['symptom', 'percentage']].sort_values('percentage', ascending=False), \n             y=\"percentage\", x=\"symptom\", color='symptom', \n             log_y=True, template='ggplot2', title='Symptom of  Coronavirus')\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Pie Plot**","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.pie(symptoms,\n             values=\"percentage\",\n             names=\"symptom\",\n             template=\"seaborn\")\nfig.update_traces(rotation=90, pull=0.05, textinfo=\"percent+label\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Tree Plot**","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = px.treemap(symptoms, path=['symptom'], values='percentage',\n                  color='percentage', hover_data=['symptom'],\n                  color_continuous_scale='Rainbow')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, ImageColorGenerator\nfrom matplotlib import pyplot as plt\ntext = \" \".join(str(each) for each in symptoms.symptom)\nwordcloud = WordCloud(max_words=200,colormap='Set3', background_color=\"white\").generate(text)\nplt.figure(figsize=(10,6))\nplt.figure(figsize=(15,10))\nplt.imshow(wordcloud, interpolation='Bilinear')\nplt.axis(\"off\")\nplt.figure(1,figsize=(12, 12))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Machine Learning Algorithms Applied**\n \n1. K-Mean Clustering\n2. Regression Model\n3. Prophet\n4. Arima \n5. LSTM ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Libraries**","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport plotly.express as px\nfrom datetime import date, timedelta\nfrom sklearn.cluster import KMeans\nfrom fbprophet import Prophet\nfrom fbprophet.plot import plot_plotly, add_changepoints_to_plot\nimport plotly.offline as py\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nimport statsmodels.api as sm\nfrom keras.models import Sequential\nfrom keras.layers import LSTM,Dense\nfrom keras.layers import Dropout\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Reading Data**","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_patient = pd.read_csv(\"../input/patient/patient.csv\")\ndf_route = pd.read_csv(\"../input/route/route.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Looking into patient data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_patient.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1.  **id** the ID of the patient (n-th confirmed patient)\n2.  **sex** the sex of the patient\n3.  **birth_year** the birth year of the patient\n4.  **country** the country of the patient\n5.  **region** the region of the patient\n6.  **group** the collective infection\n7.  **infection_reason** the reason of infection\n8.  **infection_order** the order of infection\n9.  **infected_by** the ID of who has infected the patient\n10. **contact_number** the number of contacts with people\n11. **confirmed_date** the date of confirmation\n12. **released_date** the date of discharge\n13. **deceased_date** the date of decease\n14. **state** isolated / released / deceased","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_patient.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_patient.isna().sum()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Preprocessing**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_patient['birth_year'] = df_patient.birth_year.fillna(0.0).astype(int)\ndf_patient['birth_year'] = df_patient['birth_year'].map(lambda val: val if val > 0 else np.nan)\ndf_patient.confirmed_date = pd.to_datetime(df_patient.confirmed_date)\ndaily_count = df_patient.groupby(df_patient.confirmed_date).id.count()\naccumulated_count = daily_count.cumsum()\ndf_patient['age'] = 2020 - df_patient['birth_year'] \nimport math\ndef group_age(age):\n    if age >= 0: # not NaN\n        if age % 10 != 0:\n            lower = int(math.floor(age / 10.0)) * 10\n            upper = int(math.ceil(age / 10.0)) * 10 - 1\n            return f\"{lower}-{upper}\"\n        else:\n            lower = int(age)\n            upper = int(age + 9) \n            return f\"{lower}-{upper}\"\n    return \"Unknown\"\n\n\ndf_patient[\"age_range\"] = df_patient[\"age\"].apply(group_age)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"patient=df_patient","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"date_cols = [\"confirmed_date\", \"released_date\", \"deceased_date\"]\nfor col in date_cols:\n    patient[col] = pd.to_datetime(patient[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"patient[\"time_to_release_since_confirmed\"] = patient[\"released_date\"] - patient[\"confirmed_date\"]\npatient[\"time_to_death_since_confirmed\"] = patient[\"deceased_date\"] - patient[\"confirmed_date\"]\npatient[\"duration_since_confirmed\"] = patient[[\"time_to_release_since_confirmed\", \"time_to_death_since_confirmed\"]].min(axis=1)\npatient[\"duration_days\"] = patient[\"duration_since_confirmed\"].dt.days\nage_ranges = sorted(set([ar for ar in patient[\"age_range\"] if ar != \"Unknown\"]))\npatient[\"state_by_gender\"] = patient[\"state\"] + \"_\" + patient[\"sex\"]\nreleased = df_patient[df_patient.state == 'released']\nisolated_state = df_patient[df_patient.state == 'isolated']\ndead = df_patient[df_patient.state == 'deceased']\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Confirmed Cases**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"accumulated_count.plot()\nplt.title('Accumulated Confirmed Count');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Checking for number of cluster**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"K_clusters = range(1,8)\nkmeans = [KMeans(n_clusters=i) for i in K_clusters]\nY_axis = df_route[['latitude']]\nX_axis = df_route[['longitude']]\nscore = [kmeans[i].fit(Y_axis).score(Y_axis) for i in range(len(kmeans))]\nplt.plot(K_clusters, score)\nplt.xlabel('Number of Clusters')\nplt.ylabel('Score')\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As in this graph, after 3 score go to constant value, so we will go with 3 clusters","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**K-Mean Clusterning**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clus=df_route.loc[:,['id','latitude','longitude']]\nkmeans = KMeans(n_clusters = 3, init ='k-means++')\nkmeans.fit(clus[clus.columns[1:3]])\nclus['cluster_label'] = kmeans.fit_predict(clus[clus.columns[1:3]])\ncenters = kmeans.cluster_centers_\nlabels = kmeans.predict(clus[clus.columns[1:3]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Graphical representation of clusters**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clus.plot.scatter(x = 'latitude', y = 'longitude', c=labels, s=50, cmap='viridis')\nplt.scatter(centers[:, 0], centers[:, 1], c='black', s=100, alpha=0.5)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**World Map**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":" import folium\nsouthkorea_map = folium.Map(location=[36.55,126.983333 ], zoom_start=7,tiles='Stamen Toner')\n\nfor lat, lon,city in zip(df_route['latitude'], df_route['longitude'],df_route['city']):\n    folium.CircleMarker([lat, lon],\n                        radius=5,\n                        color='red',\n                      popup =('City: ' + str(city) + '<br>'),\n                        fill_color='red',\n                        fill_opacity=0.7 ).add_to(southkorea_map)\nsouthkorea_map","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**World Map Daily**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cmap1 = df_route\ncmap1  = cmap1.groupby(['date', 'province','latitude','longitude'])['id'].max()\n\n\ncmap1 = cmap1.reset_index()\ncmap1.head()\ncmap1['size'] = cmap1['id']*900\ncmap1\nfig = px.scatter_mapbox(cmap1, lat=\"latitude\", lon=\"longitude\",\n                     color=\"id\", size='size',\n                     color_continuous_scale='burgyl',\n                     animation_frame=\"date\", \n                     title='Spread total cases over time')\nfig.update(layout_coloraxis_showscale=True)\nfig.update_layout(mapbox_style=\"carto-positron\",\n                  mapbox_zoom=3)\nfig.update_layout(margin={\"r\":0,\"t\":30,\"l\":0,\"b\":0})\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = daily_count.resample('D').first().fillna(0).cumsum()\ndata = data[20:]\nx = np.arange(len(data)).reshape(-1, 1)\ny = data.values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Growth Rate**","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"global_data = pd.read_csv(\"../input/novel-corona-virus-2019-dataset/covid_19_data.csv\")\n# This functions smooths data, thanks to Dan Pearson. We will use it to smooth the data for growth factor.\ndef smoother(inputdata,w,imax):\n    data = 1.0*inputdata\n    data = data.replace(np.nan,1)\n    data = data.replace(np.inf,1)\n    #print(data)\n    smoothed = 1.0*data\n    normalization = 1\n    for i in range(-imax,imax+1):\n        if i==0:\n            continue\n        smoothed += (w**abs(i))*data.shift(i,axis=0)\n        normalization += w**abs(i)\n    smoothed /= normalization\n    return smoothed\n\ndef growth_factor(confirmed):\n    confirmed_iminus1 = confirmed.shift(1, axis=0)\n    confirmed_iminus2 = confirmed.shift(2, axis=0)\n    return (confirmed-confirmed_iminus1)/(confirmed_iminus1-confirmed_iminus2)\n\ndef growth_ratio(confirmed):\n    confirmed_iminus1 = confirmed.shift(1, axis=0)\n    return (confirmed/confirmed_iminus1)\n\n# This is a function which plots (for in input country) the active, confirmed, and recovered cases, deaths, and the growth factor.\ndef plot_country_active_confirmed_recovered(country):\n    \n    # Plots Active, Confirmed, and Recovered Cases. Also plots deaths.\n    country_data = global_data[global_data['Country/Region']==country]\n    table = country_data.drop(['SNo','Province/State', 'Last Update'], axis=1)\n    table['ActiveCases'] = table['Confirmed'] - table['Recovered'] - table['Deaths']\n    table2 = pd.pivot_table(table, values=['ActiveCases','Confirmed', 'Recovered','Deaths'], index=['ObservationDate'], aggfunc=np.sum)\n    table3 = table2.drop(['Deaths'], axis=1)\n   \n    # Growth Factor\n    w = 0.5\n    table2['GrowthFactor'] = growth_factor(table2['Confirmed'])\n    table2['GrowthFactor'] = smoother(table2['GrowthFactor'],w,5)\n\n    # 2nd Derivative\n    table2['2nd_Derivative'] = np.gradient(np.gradient(table2['Confirmed'])) #2nd derivative\n    table2['2nd_Derivative'] = smoother(table2['2nd_Derivative'],w,7)\n\n\n    #Plot confirmed[i]/confirmed[i-1], this is called the growth ratio\n    table2['GrowthRatio'] = growth_ratio(table2['Confirmed'])\n    table2['GrowthRatio'] = smoother(table2['GrowthRatio'],w,5)\n    \n    #Plot the growth rate, we will define this as k in the logistic function presented at the beginning of this notebook.\n    table2['GrowthRate']=np.gradient(np.log(table2['Confirmed']))\n    table2['GrowthRate'] = smoother(table2['GrowthRate'],0.5,3)\n    \n    # horizontal line at growth rate 1.0 for reference\n    x_coordinates = [1, 100]\n    y_coordinates = [1, 1]\n    f, ax = plt.subplots(figsize=(15,5))\n    table2['Deaths'].plot(title='Deaths')\n    plt.show()\n    f, ax = plt.subplots(figsize=(15,5))\n    table2['GrowthFactor'].plot(title='Growth Factor')\n    plt.plot(x_coordinates, y_coordinates) \n    plt.show()\n    f, ax = plt.subplots(figsize=(15,5))\n    table2['2nd_Derivative'].plot(title='2nd_Derivative')\n    plt.show()\n    f, ax = plt.subplots(figsize=(15,5))\n    table2['GrowthRatio'].plot(title='Growth Ratio')\n    plt.plot(x_coordinates, y_coordinates)\n    plt.show()\n    f, ax = plt.subplots(figsize=(15,5))\n    table2['GrowthRate'].plot(title='Growth Rate')\n    plt.show()\n\n    return ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_country_active_confirmed_recovered('South Korea')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Regression Model**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPRegressor\nmodel = MLPRegressor(hidden_layer_sizes=[32, 32, 10], max_iter=50000, alpha=0.0005, random_state=26)\n_=model.fit(x, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = np.arange(len(data)+7).reshape(-1, 1)\npred = model.predict(test)\nprediction = pred.round().astype(int)\nweek = [data.index[0] + timedelta(days=i) for i in range(len(prediction))]\ndt_idx = pd.DatetimeIndex(week)\npredicted_count = pd.Series(prediction, dt_idx)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Graphical representatoin of current confirmed and predicted confirmed**","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"accumulated_count.plot()\npredicted_count.plot()\nplt.title('Prediction of Accumulated Confirmed Count')\nplt.legend(['current confirmd count', 'predicted confirmed count'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Prophet**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Making data ready for Prophet**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"prophet= pd.DataFrame(data)\nprophet\npr_data = prophet.reset_index()\npr_data.columns = ['ds','y']\npr_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model and prediction**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"m=Prophet()\nm.fit(pr_data)\nfuture=m.make_future_dataframe(periods=30)\nforecast=m.predict(future)\nforecast","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnfrm = forecast.loc[:,['ds','trend']]\ncnfrm = cnfrm[cnfrm['trend']>0]\ncnfrm=cnfrm.tail(15)\ncnfrm.columns = ['Date','Confirm']\ncnfrm.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Graphical Representation of Prediction**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plot_plotly(m, forecast)\npy.iplot(fig) \n\nfig = m.plot(forecast,xlabel='Date',ylabel='Confirmed Count')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figure=m.plot_components(forecast)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Autoregressive integrated moving average(Arima)**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Making data ready for Arima**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"confirm_cs = prophet.cumsum()\narima_data = confirm_cs.reset_index()\narima_data.columns = ['confirmed_date','count']\narima_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Model and prediction**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ARIMA(arima_data['count'].values, order=(1, 2, 1))\nfit_model = model.fit(trend='c', full_output=True, disp=True)\nfit_model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Graphical Representation for Prediction**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fit_model.plot_predict()\nplt.title('Forecast vs Actual')\npd.DataFrame(fit_model.resid).plot()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Forcast for next 6 days","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"forcast = fit_model.forecast(steps=6)\npred_y = forcast[0].tolist()\npd.DataFrame(pred_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**LSTM**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.DataFrame(data)\ndataset.columns = ['Confirmed']\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Splitting Data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = np.array(dataset).reshape(-1, 1)\ntrain_data = dataset[:len(dataset)-5]\ntest_data = dataset[len(dataset)-5:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\nscaler.fit(train_data)\nscaled_train_data = scaler.transform(train_data)\nscaled_test_data = scaler.transform(test_data)\nn_input =5\nn_features =1\n                             \ngenerator = TimeseriesGenerator(scaled_train_data,scaled_train_data, length=n_input, batch_size=1)\n\nlstm_model = Sequential()\nlstm_model.add(LSTM(units = 50, return_sequences = True, input_shape = (n_input, n_features)))\nlstm_model.add(Dropout(0.2))\nlstm_model.add(LSTM(units = 50, return_sequences = True))\nlstm_model.add(Dropout(0.2))\nlstm_model.add(LSTM(units = 50))\nlstm_model.add(Dropout(0.2))\nlstm_model.add(Dense(units = 1))\nlstm_model.summary()\nfrom tensorflow.keras.utils import plot_model\nplot_model(lstm_model, to_file='model1.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Compiling**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm_model.compile(optimizer = 'adam', loss = 'mean_squared_error')\nlstm_model.fit(generator, epochs = 30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm_model.history.history.keys()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Epochs vs Loss**","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"losses_lstm = lstm_model.history.history['loss']\nplt.figure(figsize = (30,4))\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.xticks(np.arange(0,100,1))\nplt.plot(range(len(losses_lstm)), losses_lstm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm_predictions_scaled = []\n\nbatch = scaled_train_data[-n_input:]\ncurrent_batch = batch.reshape((1, n_input, n_features))\n\nfor i in range(len(test_data)):   \n    lstm_pred = lstm_model.predict(current_batch)[0]\n    lstm_predictions_scaled.append(lstm_pred) \n    current_batch = np.append(current_batch[:,1:,:],[[lstm_pred]],axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = pd.DataFrame(scaler.inverse_transform(lstm_predictions_scaled))\nprediction.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Prevention**\nTo avoid the critical situation people are suggested to do following things\n\n* Avoid contact with people who are sick.\n* Avoid touching your eyes, nose, and mouth.\n* Stay home when you are sick.\n* Cover your cough or sneeze with a tissue, then throw the tissue in the trash.\n* Clean and disinfect frequently touched objects and surfaces using a regular household\n* Wash your hands often with soap and water, especially after going to the bathroom; before eating; and after blowing your nose, coughing, or sneezing. If soap and water are not readily available, use an alcohol-based hand sanitizer.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}