{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Loading Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport gc\nimport random\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.applications import xception\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_rows = 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Brief Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"#defining directory paths\nimage_dir = '/kaggle/input/analog-clocks/analog_clocks/images/'\nlabels_dir = '/kaggle/input/analog-clocks/analog_clocks/label.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#examining labels\nlabels = pd.read_csv(labels_dir)\nlabels.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#distribution of classes in hour column\nlabels.hour.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#distribution of classes in minute column\nlabels.minute.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#preview of dataset\nsample_dir = '/kaggle/input/analog-clocks/analog_clocks/samples/'\nfig = plt.figure(figsize=(20, 12))\nplt.suptitle('Examples from Dataset')\nfor i, file in enumerate(os.listdir(sample_dir)):\n    img = image.load_img(os.path.join(sample_dir, file),\n                         interpolation='box')\n    img = image.img_to_array(img, dtype='float32')\n    img /= 255.0\n    plt.subplot(2, 3, i+1)\n    plt.imshow(img)\n    plt.title('Sample ' + str(i+1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"#transforming labels to multi-label binary format\nlabels_df = pd.read_csv(labels_dir)\nlabels_df['tuples'] = [tuple(x) for x in labels_df.values]\nlabels_df['tuples'] = [('h' + str(x), 'm' + str(y)) for x,y in labels_df['tuples'].values]\nlabels_df = labels_df.drop(columns=['hour', 'minute'])\n# labels_df = labels_df.reset_index()\nbinarizer = MultiLabelBinarizer()\ny = binarizer.fit_transform(labels_df['tuples'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preview of dataframe\nlabels_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#distribution of unique labels\nlabels_df['tuples'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating train-test split\ntrain, test = train_test_split(labels_df, \n                               stratify=labels_df['tuples'],\n                               test_size=0.20,\n                               random_state=42\n                              )\n\ntrain_idx, test_idx = list(train.index), list(test.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate(image_directory, labels, train_idx=None, batch_size=64, size=(224, 224)):\n    \n    \"\"\"\n    Function to create generator of images and labels for the neural network. This allows for training\n    the model with the limited memory available. The images and labels are generated in batches of a given size.\n    The images are loaded, added to a batch, preprocessed and have their features extracted using a prebuilt model\n    (in this case Xception Model). \n    \n    Parameters\n    ----------\n    image_directory: str\n        The path where the images are located\n    labels: array-like or list\n        list of labels in multi-label binary format\n    batch_size: int, default=64\n        the number of images per batch\n    size: tuple, default=(224, 224)\n        the height and width to which the image is resized. \n    \n    Yields\n    ------\n    image_batch: array\n        Array of image features of size=batch_size\n    labels_batch: array\n        Array of labels in multi-label binary format of size=batch_size\n    \n    \"\"\"\n    \n   \n    prebuilt_model = xception.Xception(include_top=True,                      \n              weights='imagenet')                                            #loading prebuilt model\n    \n    xception_model = Model(inputs=prebuilt_model.input,        \n                           outputs=prebuilt_model.layers[-2].output)         #repurposing prebuilt model for feature extraction\n    \n    \n    \n    while 1:\n        \n        if train_idx==None:\n            image_filenames = os.listdir(image_directory)                    #obtaining list of image filenames\n        else:\n            image_filenames = [str(idx) + '.jpg' for idx in train_idx]\n            \n        random.shuffle(image_filenames)                                      #shuffling the list to add randomness every epoch\n\n        \n        image_batch = []                                                     #initializing empty image batch list\n        labels_batch = []                                                    #initializing empty labels batch list\n        \n        for file in image_filenames:                                         #looping over all images in directory\n\n            index = int(file.split('.')[0])                                  #extracting image number/index from filename\n            \n            img = image.load_img(os.path.join(image_directory, file),        #loading image\n                                 target_size=size,\n                                 interpolation='box')\n            \n            img_arr = image.img_to_array(img, dtype='float32')               #converting image to array\n            \n            label = labels[index]                                            #using image number/index to find correct label in dataframe\n    \n            image_batch.append(img_arr)                                      #appending the image to the batch\n            labels_batch.append(label)                                       #appending the label to the batch\n\n    \n            if len(image_batch)==batch_size:                                 #check to see if batch has required size\n                image_batch = np.array(image_batch)                          #converting image batch list to array\n                image_batch = xception.preprocess_input(image_batch)         #using xception preprocessing on image batch array\n                image_features = xception_model.predict(image_batch)         #using prebuilt xception model to extract features from batch\n                image_batch = np.array(image_features)                       #converting features to array\n                image_batch = image_batch.reshape(batch_size,                #reshaping feature array\n                                                  image_features.shape[1])   \n                labels_batch = np.array(labels_batch)                        #converting labels batch list to array\n                yield image_batch, labels_batch                              #yielding image and labels batch array\n                image_batch = []                                             #reinitializing the image batch\n                labels_batch = []                                            #reinitializing the label batch\n                gc.collect()                                                 #collecting garbage to free memory\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining training parameters\nBATCH_SIZE = 256\nIMAGE_SIZE = (299, 299) #this is the size suggested for Xception model\nEPOCHS = 10\nSTEPS = int(len(train_idx) / BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#testing generator\nsample_generator = next(generate(image_directory=image_dir, \n                                 labels=y,\n                                 train_idx=train_idx,\n                                 batch_size=1, \n                                 size=IMAGE_SIZE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#output of generator\nsample_generator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#extracting input and output dims from generator\nINPUT_DIM = sample_generator[0][0].shape\nOUTPUT_DIM = sample_generator[1].shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(INPUT_DIM, OUTPUT_DIM)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(input_shape, output_shape):\n    \n    \"\"\"\n    Function to build and compile neural network to predict analog clocks from images\n    \n    Parameters\n    ----------\n    input_shape: tuple\n        Shape tuple not including the batch_size, example: (2048, )\n    output_shape: int\n        Number of nodes in final layer\n    \n    Returns\n    -------\n    model: Keras model object\n        A compiled Keras model\n    \"\"\"\n\n    input_layer = Input(shape=input_shape)\n    norm  = BatchNormalization()(input_layer)\n    drop = Dropout(0.25)(norm)\n    fc1 = Dense(256, activation='relu')(norm)\n    fc2 = Dense(256, activation='relu')(fc1)\n    output1 = Dense(output_shape, activation='sigmoid')(fc2)\n    \n    #contructing model from layers\n    model = Model(inputs=input_layer,\n                  outputs=output1)\n    \n    #compiling model\n    model.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy']\n                  )\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating instance of model\nmodel = create_model(input_shape=INPUT_DIM,\n                     output_shape=OUTPUT_DIM)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#initializing generator for training\ngenerator = generate(image_directory=image_dir,\n                     labels=y,\n                     train_idx=train_idx,\n                     batch_size=BATCH_SIZE, \n                     size=IMAGE_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fitting model\nhistory = model.fit(generator, \n                    epochs=EPOCHS, \n                    steps_per_epoch=STEPS)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Prediction on Sample"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(image_directory, indices=None, plot=False):\n    \n    \"\"\"\n    Function to predict all images in a given path\n    \n    Parameters\n    ----------\n    image_directory: str\n        Path for images to be predicted\n    indices: list, default = None\n        Indices corresponding to image labels to predict\n    plot: boolean, default=False\n        Whether or not to create plot of predictions\n        \n    Returns\n    -------\n    predictions_list: list\n        List of predictions corresponding to the images\n    \"\"\"\n    \n    images_list = []\n    \n    prebuilt_model = xception.Xception(include_top=True,\n                                       weights='imagenet')           #loading pre-built model\n    \n    xception_model = Model(inputs=prebuilt_model.input,\n                           outputs=prebuilt_model.layers[-2].output) #repurposing pre-built model for feature extraction\n    \n    if indices!=None:\n        image_filenames = [str(idx) + '.jpg' for idx in indices]\n    else:\n        image_filenames = os.listdir(image_directory)\n    \n    if plot:\n        dim = int(np.ceil(np.sqrt(len(image_filenames))))\n        fig, axs = plt.subplots(nrows=dim, \n                                ncols=dim,\n                                figsize=(20, 14))\n        plt.suptitle('Example of Model Predictions', fontsize=32)\n        \n#         axs = axs.flatten()\n        \n    \n    #looping over all images in path\n    for i, file in enumerate(image_filenames):\n        \n\n        img = image.load_img(os.path.join(image_directory,\n                                          file))                     #loading images\n        img_arr = image.img_to_array(img, dtype='float32')           #converting images to array\n    \n        if plot:\n            axs.flat[i].imshow(img_arr/255.0)\n            \n        images_list.append(img_arr)\n        gc.collect()       \n    \n    print('preprocessing...')\n    images_list = np.array(images_list)\n    img_arr = xception.preprocess_input(images_list)                 #preprocessing image array using xception method\n    print('extracting features...')\n    img_features = xception_model.predict(img_arr)                   #extracting features from image using prebuilt xception model\n    img_features = np.array(img_features)\n    print('predicting...')\n    prediction = model.predict(img_features)                         #predicting time from image features                        \n    hour_max = np.argmax(prediction[:, :12], axis=1)                 #obtaining hour with the highest probability\n    minute_max = np.argmax(prediction[:, 12:], axis=1) + 12          #obtaining minute with the highest probability\n    prediction_list = [(binarizer.classes_[x],                       #getting labels for predictions for binarizer\n                        binarizer.classes_[y]) \n                        for (x,y) in list(zip(hour_max, minute_max))]\n\n    if plot:                                                         #setting title for plots\n        for i, v in enumerate(prediction_list):\n            axs.flat[i].set_title(str(v[0]) + ' ' + str(v[1]))\n            axs.flat[i].axis('off')\n        for j in range(i+1, dim**2):                                 #removing excess subplots\n              fig.delaxes(axs.flat[j])\n            \n    return prediction_list\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predicting samples used in earlier vizualization\npredictions = predict('/kaggle/input/analog-clocks/analog_clocks/samples/',\n                        plot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#taking sample of test set to visualize results on unseen data\n#this is done due to memory limitations\nSIZE = 64\nsample_test = list(np.random.choice(test_idx, size=SIZE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predicting sample of test set\npredictions = predict('/kaggle/input/analog-clocks/analog_clocks/images/',\n                        indices=sample_test,\n                        plot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_results = pd.DataFrame(list(zip(labels_df.loc[sample_test]['tuples'].values, pd.Series(predictions))), columns=['Actual', 'Predicted'])\nsample_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#saving model\nfor layer in model.layers:\n    layer.trainable = False\nmodel.save('model')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Take Aways\n\n- Prebuilt models are very useful to extract features in this case\n- Treating this problem as a multi-label classification achieves the best results over multi-class, possible due to lower dimensionality of labels (72 verus 720)\n    - Initially tried having two outputs to the model, one for hours and one for minutes, but the model prioritizes optimizing hours over minutes\n- Model performs well on unseen data\n    - Since hours have less categories (12) their prediction is generally more accurate than the minutes (60)\n    - The errors made by the model are reasonable\n    - Since there are no minute-marker ticks on the clocks, even human eye can struggle to tell exact minute"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}