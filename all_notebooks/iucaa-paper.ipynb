{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nnp.random.seed(69)\nimport pandas as pd\nimport random\nimport pickle as pkl\nimport matplotlib.pyplot as plt\nimport matplotlib.image as img\nimport seaborn as sns\nsns.set()\nimport tensorflow as tf\nfrom tqdm.notebook import tqdm\nfrom tensorflow.keras.utils import to_categorical, plot_model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,concatenate, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, ZeroPadding2D, LeakyReLU, ReLU, AveragePooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.models import load_model\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n# import kerastuner as kt\n# from kerastuner import HyperModel\nimport time","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-21T04:37:36.375784Z","iopub.execute_input":"2021-07-21T04:37:36.376124Z","iopub.status.idle":"2021-07-21T04:37:42.251121Z","shell.execute_reply.started":"2021-07-21T04:37:36.376092Z","shell.execute_reply":"2021-07-21T04:37:42.250335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Sets","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/paper-dataset/paperDF.csv\",index_col=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:37:42.25258Z","iopub.execute_input":"2021-07-21T04:37:42.252929Z","iopub.status.idle":"2021-07-21T04:37:44.956457Z","shell.execute_reply.started":"2021-07-21T04:37:42.252893Z","shell.execute_reply":"2021-07-21T04:37:44.955494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Already have the colours'u_g', 'g_r', 'r_i', 'i_z'\n# # MORE COLOURS CAN BE OBTAINED FROM BELOW CODE\n# def get_color(df2,c1,c2):\n#     df = df2.copy()\n#     df[f\"{c1}_{c2}\"] = (df[f\"dered_{c1}\"]+df[f\"extinction_{c1}\"]) - (df[f\"dered_{c2}\"]+df[f\"extinction_{c2}\"])\n#     return df\n\n    \n# bands = [\"u\",\"g\",\"r\",\"i\",\"z\"]\n# for c1 in bands:\n#     for c2 in bands:\n#         if c1==c2:\n#             continue\n#         df = get_color(df,c1,c2)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:37:45.2255Z","iopub.execute_input":"2021-07-21T04:37:45.225804Z","iopub.status.idle":"2021-07-21T04:37:45.231582Z","shell.execute_reply.started":"2021-07-21T04:37:45.225776Z","shell.execute_reply":"2021-07-21T04:37:45.230903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"photodf = df.loc[:,['dered_u', 'deVRad_u', 'psffwhm_u', 'extinction_u',\n       'dered_g', 'deVRad_g', 'psffwhm_g', 'extinction_g', 'dered_r',\n       'deVRad_r', 'psffwhm_r', 'extinction_r', 'dered_i', 'deVRad_i',\n       'psffwhm_i', 'extinction_i', 'dered_z', 'deVRad_z', 'psffwhm_z',\n       'extinction_z', 'u_g', 'g_r', 'r_i', 'i_z']]\n\nobjlist = np.load(\"../input/paperobjlist/paperobjlist.npy\")\n\ndnnx=[]\ndnny=[]\nfor i,objnum in tqdm(enumerate(objlist),total=len(objlist)):\n    dnny.append(df.loc[objnum,\"class\"])\n    dnnx.append(photodf.loc[objnum].values)\ndnny=np.array(dnny)\ndnnx=np.array(dnnx)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:37:45.441222Z","iopub.execute_input":"2021-07-21T04:37:45.441498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del(df,photodf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.load(\"../input/paper-dataset/paperX.npy\")\ny = dnny.copy()\ny, label_strings = pd.factorize(y,sort=True)\ny = to_categorical(y)\ndel(dnny)\nprint(label_strings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zipX = list(zip(X, dnnx))\nzipy = list(zip(y, objlist))\n\nzipX_train, zipX_test, zipy_train, zipy_test = train_test_split(zipX, zipy, test_size = 0.125,random_state=42)\nzipX_train, zipX_val, zipy_train, zipy_val = train_test_split(zipX_train, zipy_train, test_size = 0.1428, random_state=42)\n\nX_train, dnnx_train = zip(*zipX_train)\nX_val, dnnx_val = zip(*zipX_val)\nX_test, dnnx_test = zip(*zipX_test)\n\ny_train, objlist_train = zip(*zipy_train)\ny_val, objlist_val = zip(*zipy_val)\ny_test, objlist_test = zip(*zipy_test)\n\nX_train = np.array(X_train)\nX_val = np.array(X_val)\nX_test = np.array(X_test)\n\ndnnx_train = np.array(dnnx_train)\ndnnx_val = np.array(dnnx_val)\ndnnx_test = np.array(dnnx_test)\n\ny_train = np.array(y_train)\nobjlist_train = np.array(objlist_train)\ny_val = np.array(y_val)\nobjlist_val = np.array(objlist_val)\ny_test = np.array(y_test)\nobjlist_test = np.array(objlist_test)\n\n\ndel(zipX,zipX_test,zipX_train,zipX_val, X, zipy, zipy_test, zipy_train, zipy_val, objlist)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_metrics(y_pred, y_test, labels, to_print=True):\n    correct_labels = np.where(y_pred==y_test)[0]\n    accuracy = metrics.accuracy_score(y_test, y_pred)\n    precision = metrics.precision_score(y_test, y_pred,average='macro')\n    recall = metrics.recall_score(y_test, y_pred,average='macro')\n    f1score = metrics.f1_score(y_test, y_pred,average='macro')\n    # rocscore = metrics.roc_auc_score(y_test, y_pred,average='micro',multi_class=\"ovo\")\n    confusion_matrix = metrics.confusion_matrix(y_test, y_pred)  \n    classification_report = metrics.classification_report(y_test, y_pred)\n\n    if to_print:\n        print(\"Identified {} correct labels out of {} labels\".format(len(correct_labels), y_test.shape[0]))\n        print(\"Accuracy:\",accuracy)\n        print(\"Precision:\",precision)\n        print(\"Recall:\",recall)\n        print(\"F1 Score:\",f1score)\n        # print(\"ROC AUC Score:\",rocscore)\n        print(f\"Labels are: {labels}\")\n        print(\"Confusion Matrix:\\n\", confusion_matrix)\n        print(\"Classification_Report:\\n\", classification_report)\n\n    return (correct_labels, accuracy, precision, recall, confusion_matrix, classification_report)\n\ndef plot_model_change(history,fname=\"time.pdf\"):\n    # summarize history for accuracy\n    plt.plot(history.history['accuracy'],label=\"Training Acc\")\n    plt.plot(history.history['val_accuracy'],label=\"Val Acc\")\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend()\n    plt.show()\n    # summarize history for loss\n    plt.plot(history.history['loss'],label=\"Training Loss\")\n    plt.plot(history.history['val_loss'],label=\"Val Loss\")\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend()\n    plt.savefig(fname)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DNN Classifier","metadata":{}},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Dense(1024, activation=\"sigmoid\", input_dim=dnnx_train.shape[1]))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(256, activation=\"sigmoid\"))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(128, activation=\"sigmoid\"))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(64, activation=\"sigmoid\"))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(32, activation=\"sigmoid\"))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(3, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=\"adam\",\n              metrics=['accuracy'])\n\nes = EarlyStopping(monitor='val_loss', verbose=0, patience=100, restore_best_weights=True)\ncb = [es]\nhistory = model.fit(dnnx_train, y_train,\n                    batch_size=2048,\n                    epochs = 4000,\n                    validation_data = (dnnx_val,y_val),\n                    callbacks = cb,\n                    verbose = 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"DNNClassifier.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model,\"DNNMod.pdf\",show_shapes=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model_change(history,fname=\"DNNTraining.pdf\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_test = model.predict(dnnx_test,batch_size=2048, verbose = 0)\nprint(get_metrics(preds_test.argmax(axis=1), y_test.argmax(axis=1),label_strings))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = metrics.confusion_matrix(preds_test.argmax(axis=1), y_test.argmax(axis=1),normalize='true')\ndf_cm = pd.DataFrame(cm, index = label_strings,columns = label_strings)\nplt.figure(figsize = (10,7))\nsns.heatmap(df_cm, annot=True,cmap=\"Blues\",square=True,fmt='.2%')\nplt.savefig(\"dnn_cm.pdf\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del(dnnx_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN Classifier","metadata":{}},{"cell_type":"code","source":"inp_layer = tf.keras.Input(shape=X_train.shape[1:])\n\nmod = Conv2D(filters=64, kernel_size=(5,5), padding='same')(inp_layer)\nmod = ReLU()(mod)\n\n\n# mod = AveragePooling2D(pool_size=(2, 2), strides=2)(mod)\n\nc1 = Conv2D(filters=48, kernel_size=(1,1), padding='same')(mod)\nc1 = ReLU()(c1)\nc2 = Conv2D(filters=48, kernel_size=(1,1), padding='same')(mod)\nc2 = ReLU()(c2)\nc3 = Conv2D(filters=48, kernel_size=(1,1), padding='same')(mod)\nc3 = ReLU()(c3)\nc4 = Conv2D(filters=64, kernel_size=(1,1), padding='same')(c1)\nc4 = ReLU()(c4)\nc5 = Conv2D(filters=64, kernel_size=(3,3), padding='same')(c1)\nc5 = ReLU()(c5)\nc6 = Conv2D(filters=64, kernel_size=(5,5), padding='same')(c2)\nc6 = ReLU()(c6)\np1 = AveragePooling2D(pool_size=(1, 1))(c3)\nmod = concatenate([c4,c5,c6,p1])\n\nc7 = Conv2D(filters=64, kernel_size=(1,1), padding='same')(mod)\nc7 = ReLU()(c7)\nc8 = Conv2D(filters=64, kernel_size=(1,1), padding='same')(mod)\nc8 = ReLU()(c8)\nc9 = Conv2D(filters=64, kernel_size=(1,1), padding='same')(mod)\nc9 = ReLU()(c9)\nc10 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(c7)\nc10 = ReLU()(c10)\nc11 = Conv2D(filters=92, kernel_size=(3,3), padding='same')(c7)\nc11 = ReLU()(c11)\nc12 = Conv2D(filters=92, kernel_size=(5,5), padding='same')(c8)\nc12 = ReLU()(c12)\np2 = AveragePooling2D(pool_size=(1, 1))(c9)\nmod = concatenate([c10,c11,c12,p2])\nmod = AveragePooling2D(pool_size=(2, 2))(mod)\n\nc13 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(mod)\nc13 = ReLU()(c13)\nc14 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(mod)\nc14 = ReLU()(c14)\nc15 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(mod)\nc15 = ReLU()(c15)\nc16 = Conv2D(filters=128, kernel_size=(1,1), padding='same')(c13)\nc16 = ReLU()(c16)\nc17 = Conv2D(filters=128, kernel_size=(3,3), padding='same')(c13)\nc17 = ReLU()(c17)\nc18 = Conv2D(filters=128, kernel_size=(5,5), padding='same')(c14)\nc18 = ReLU()(c18)\np3 = AveragePooling2D(pool_size=(1, 1))(c15)\nmod = concatenate([c16,c17,c18,p3])\n\nc19 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(mod)\nc19 = ReLU()(c19)\nc20 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(mod)\nc20 = ReLU()(c20)\nc21 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(mod)\nc21 = ReLU()(c21)\nc22 = Conv2D(filters=128, kernel_size=(1,1), padding='same')(c19)\nc22 = ReLU()(c22)\nc23 = Conv2D(filters=128, kernel_size=(3,3), padding='same')(c19)\nc23 = ReLU()(c23)\nc24 = Conv2D(filters=128, kernel_size=(5,5), padding='same')(c20)\nc24 = ReLU()(c24)\np4 = AveragePooling2D(pool_size=(1, 1))(c21)\nmod = concatenate([c22,c23,c24,p4])\nmod = AveragePooling2D(pool_size=(2, 2))(mod)\n\nc25 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(mod)\nc25 = ReLU()(c25)\nc26 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(mod)\nc26 = ReLU()(c26)\nc27 = Conv2D(filters=128, kernel_size=(1,1), padding='same')(mod)\nc27 = ReLU()(c27)\nc28 = Conv2D(filters=128, kernel_size=(3,3), padding='same')(c25)\nc28 = ReLU()(c28)\np5 = AveragePooling2D(pool_size=(1, 1))(c26)\nmod = concatenate([c27,c28,p5])\nmod = Flatten()(mod)    #Check\nmod = Dense(1024)(mod)\nmod = Dense(1024)(mod)\nout_layer = Dense(3, activation=\"softmax\") (mod)\nmodel = tf.keras.Model(inputs=inp_layer, outputs=out_layer)\n\nmodel.compile(optimizer = 'adam' , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n","metadata":{"execution":{"iopub.status.busy":"2021-05-31T11:38:20.98728Z","iopub.execute_input":"2021-05-31T11:38:20.987843Z","iopub.status.idle":"2021-05-31T11:38:21.548088Z","shell.execute_reply.started":"2021-05-31T11:38:20.987786Z","shell.execute_reply":"2021-05-31T11:38:21.547303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True)\ndatagen.fit(X_train)\n\n\nes = EarlyStopping(monitor='val_loss', verbose=1, patience=30, restore_best_weights=True)\n\ncb = [es]\n","metadata":{"execution":{"iopub.status.busy":"2021-05-31T11:38:27.586221Z","iopub.execute_input":"2021-05-31T11:38:27.586725Z","iopub.status.idle":"2021-05-31T11:38:29.286797Z","shell.execute_reply.started":"2021-05-31T11:38:27.586677Z","shell.execute_reply":"2021-05-31T11:38:29.285543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(datagen.flow(X_train,y_train, batch_size=512),\n                              epochs = 300, validation_data = (X_val,y_val),\n                              callbacks = cb,\n                              verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T11:38:37.778449Z","iopub.execute_input":"2021-05-31T11:38:37.778813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"CNNClassifier.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model,\"CNNMod.pdf\",show_shapes=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model_change(history,fname=\"CNNTraining.pdf\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_test = model.predict(X_test,batch_size=1024, verbose = 0)\nprint(get_metrics(preds_test.argmax(axis=1), y_test.argmax(axis=1),label_strings))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = metrics.confusion_matrix(preds_test.argmax(axis=1), y_test.argmax(axis=1),normalize='true')\ndf_cm = pd.DataFrame(cm, index = label_strings,columns = label_strings)\nplt.figure(figsize = (10,7))\nsns.heatmap(df_cm, annot=True,cmap=\"Blues\",square=True,fmt='.2%')\nplt.savefig(\"cnn_cm.pdf\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ensemble","metadata":{}},{"cell_type":"code","source":"cnnclassifier = load_model(\"./CNNClassifier.h5\")\ndnnclassifier = load_model(\"./DNNClassifier.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def define_stacked_model(members):\n    # update all layers in all models to not be trainable\n    for i in range(len(members)):\n        model = members[i]\n        for layer in model.layers:\n            # make not trainable\n            layer.trainable = False\n            # rename to avoid 'unique layer name' issue\n            layer._name = 'ensemble_' + str(i+1) + '_' + layer.name\n    # define multi-headed input\n    ensemble_visible = [model.input for model in members]\n    # concatenate merge output from each model\n    ensemble_outputs = [model.output for model in members]\n    merge = tf.keras.layers.concatenate(ensemble_outputs)\n    hidden = Dense(10, activation='relu')(merge)\n    output = Dense(3, activation='softmax')(hidden)\n    model = tf.keras.Model(inputs=ensemble_visible, outputs=output)\n    # plot graph of ensemble\n    plot_model(model, show_shapes=True, to_file='model_graph.png')\n    # compile\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define ensemble model\nmembers = [cnnclassifier,dnnclassifier]\nmodel = define_stacked_model(members)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filepath=\"EnsembleClassifier.h5\"\n\ncheckpointcb = tf.keras.callbacks.ModelCheckpoint(filepath=filepath,monitor='loss',mode='min',save_best_only=True,verbose=1,save_weights_only=False)\ncb = [checkpointcb]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit([X_val, dnnx_val],\n                            y_val, epochs=100,\n                            batch_size=512,\n                            callbacks=cb,\n                            verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del(X_val, dnnx_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = load_model(\"./EnsembleClassifier.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate([X_test, dnnx_test],y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model,\"EnsembleMod.pdf\",show_shapes=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_test = model.predict([X_test, dnnx_test],batch_size=512, verbose = 0)\nprint(get_metrics(preds_test.argmax(axis=1), y_test.argmax(axis=1),label_strings))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = metrics.confusion_matrix(preds_test.argmax(axis=1), y_test.argmax(axis=1),normalize='true')\ndf_cm = pd.DataFrame(cm, index = label_strings,columns = label_strings)\nplt.figure(figsize = (10,7))\nsns.heatmap(df_cm, annot=True,cmap=\"Blues\",square=True,fmt='.2%')\nplt.savefig(\"ensemble_cm.pdf\")","metadata":{},"execution_count":null,"outputs":[]}]}