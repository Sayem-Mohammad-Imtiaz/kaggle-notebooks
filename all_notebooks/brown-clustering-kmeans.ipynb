{"cells":[{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"!pip install kneed\n!pip install raceplotly","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:courier,arial,helvetica;font-size:350%;\">\nReddit Vaccine Myths Analysis</p>"},{"metadata":{},"cell_type":"markdown","source":"![](https://media0.giphy.com/media/iFgzUCWgxj7B22ik2K/giphy.gif)"},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\nImporting Packages</p>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport colorama\nfrom colorama import Fore as F\nfrom time import sleep\nfrom nlp_package_pv import *\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom sklearn.preprocessing import normalize\nfrom sklearn.cluster import MiniBatchKMeans\nfrom sklearn.cluster import KMeans\nfrom warnings import filterwarnings\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nimport matplotlib.cm as cm\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import silhouette_samples, silhouette_score\nfrom kneed import KneeLocator\nfrom brown_clustering_yangyuan import *\nfrom sklearn.cluster import Birch\nfrom sklearn.cluster import *\nfrom sklearn.decomposition import TruncatedSVD\nimport plotly.express as px\nfrom nltk.tokenize import RegexpTokenizer\nimport umap\nimport plotly\nfrom raceplotly.plots import barplot\nplotly.offline.init_notebook_mode (connected = True)\nfilterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\nImporting Data</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(F.YELLOW+'Importing Data ....')\nsleep(2)\ndata=pd.read_csv('../input/reddit-vaccine-myths/reddit_vm.csv')\nprint(F.YELLOW+'Imported Data Successfully !!!!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for NAN values\ndata.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing URLand ID columns and removing nan values after that\ndata.drop(columns=['url','id'],axis=1,inplace=True)\ndata.dropna(inplace=True)\n\n# Changing the timestamp to datetime format\ndata['timestamp']=pd.to_datetime(data['timestamp'])\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\nPreprocessing The Data</p>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Preprocessing the data\n\ntitle=data['title'].values.copy()\n\n# Removing the word comment from the title columns since this seems to be the default value which is not needed\n\ndata['title'].replace({'Comment':''},inplace=True)\n\n# Joining both the title and the body together\n\ndata['text']=data[['title', 'body']].agg(' '.join, axis=1)\n\n# Adding the data for the title columns back to it\n\ndata['title']=title\n\n# Deleting the title variable \n\ndel title\n\n# Removing Links from the data\n\ndata['text']=data['text'].apply(lambda x:re.sub(r\"http\\S+\", \"\", x))\n\n# Code to remove the Special characters from the text \n\ndata['text']=data['text'].apply(lambda x:' '.join(re.findall(r'\\w+', x)))\n\n# Removing the stopwords and tokenizing the data\n\nrem_stopwords_tokenize(data,'text')\n\n# Lemmatizing the sentences\n\nlemmatize_all(data,'text')\n\n# Making all the tokens back to sentences\n\nmake_sentences(data,'text')\n\n\n# Having a look at the data\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:'Brush Script MT', cursive;font-size:200%;\">\nWe have succesfully preprocessed the data</p>"},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\nwhat is the length of the data ??</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# What is the length of the data we got here ??\nprint (F.YELLOW + \"The length of the dataframe is :\" , F.CYAN + str(len(data)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\nApplying Brown Clustering On The Data</p>"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"sample_data = data.text.astype('str').tolist()\n\n# toeknize\ntokenizer = RegexpTokenizer(r'\\w+')\nsample_data_tokenized = [w.lower() for w in sample_data]\nsample_data_tokenized = [tokenizer.tokenize(i) for i in sample_data_tokenized]\ncorpus = Corpus(sample_data_tokenized, 0.001)\nclustering = BrownClustering(corpus, 6)\nclustering.train()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\nClosest Word Clusters To the word Vaccine</p>"},{"metadata":{},"cell_type":"markdown","source":"![](https://img.etimg.com/thumb/width-1200,height-900,imgsize-261105,resizemode-1,msid-79592510/prime/pharma-and-healthcare/2021-is-all-about-vaccine-transportation-piramal-schott-kaisha-are-ready-with-sturdy-vials.jpg)"},{"metadata":{"trusted":true},"cell_type":"code","source":"clustering.get_similar('vaccine')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:courier,arial,helvetica;font-size:200%;\">\nBrown clustering is used for word clustering but we need to cluster the sentences ðŸ¤”ðŸ¤”ðŸ¤”ðŸ¤”\n    <br> We can just use kmeans clustering on the score we got using the brown clustering to perform the sentence clustering\n</p>"},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\nTokenizing and Padding the data </p>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Let's use both kmeans and brown clustering together :)\nfor i,j in enumerate(sample_data_tokenized) :\n    for n,m in enumerate(j):\n        sample_data_tokenized[i][n]=clustering.vocabulary[m]\n        \n# Padding the sequences\npadded_sequence=pad_sequences(sample_data_tokenized,maxlen=20,padding='post')\n\nprint(F.YELLOW+\"The vocabulary of the data is \" +F.CYAN + str(len(corpus.vocabulary))+F.YELLOW+' words long :)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\nApplying K Means </p>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Function to get the best k for the image\ndef get_k(X,print_plot=False):\n    arr=X\n    wcss=[]\n    for i in range(1,11):\n        kmeans = KMeans(n_clusters= i, init='k-means++', random_state=0)\n        kmeans.fit(arr)\n        wcss.append(kmeans.inertia_)\n    x=[i for i in range(1,11)]\n    kn = KneeLocator(x, wcss, curve='convex', direction='decreasing')\n    if print_plot==True:\n        plt.xlabel('number of clusters k')\n        plt.ylabel('Sum of squared distances')\n        plt.plot(x, wcss, 'rx-')\n        plt.vlines(kn.knee, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')\n        plt.show()\n        print('The elbow is formed at :',kn.knee)\n    else:\n        return kn.knee","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_k(padded_sequence,print_plot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clusters=KMeans(n_clusters=6,random_state=20).fit_predict(padded_sequence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def plot_tsne_pca(data, labels):\n    max_label = max(labels)+1\n    max_items = np.random.choice(range(data.shape[0]), size=1000, replace=False)\n    \n    pca = PCA(n_components=2).fit_transform(data[max_items,:])\n    tsne = TSNE().fit_transform(PCA(n_components=10).fit_transform(data[max_items,:]))\n    \n    \n    idx = np.random.choice(range(pca.shape[0]), size=320, replace=False)\n    label_subset = labels[max_items]\n    label_subset = [cm.hsv(i/max_label) for i in label_subset[idx]]\n    \n    f, ax = plt.subplots(1, 2, figsize=(14, 6))\n    \n    ax[0].scatter(pca[idx, 0], pca[idx, 1], c=label_subset)\n    ax[0].set_title('PCA Cluster Plot')\n    \n    ax[1].scatter(tsne[idx, 0], tsne[idx, 1], c=label_subset)\n    ax[1].set_title('TSNE Cluster Plot')\n    \nplot_tsne_pca(padded_sequence, clusters)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Kmeans clusters']=clusters","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\nHaving a look at cluster 2 </p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['Kmeans clusters']==2].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:courier,arial,helvetica;font-size:200%;\">\nThese looks like questions about the vaccine and kind of shows some worries and myths in the minds of the people</p>\n"},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\n A breif Look at Cluster 5</p>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['Kmeans clusters']==5].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:courier,arial,helvetica;font-size:200%;\">\nThis cluster is more about the people telling about the experience before or after the vaccine shot</p>\n\n"},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\n Using LSA for topic modelling</p>\n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":" def get_me_topics(cluster_id=1):\n    # Let's work on Cluster 1 and find topics for it :)\n    vectorizer = TfidfVectorizer()\n    X = vectorizer.fit_transform(data[data['Kmeans clusters']==cluster_id]['text'])\n    # SVD represent documents and terms in vectors \n    svd_model = TruncatedSVD(n_components=4, algorithm='randomized', n_iter=100, random_state=122)\n\n    svd_model.fit(X)\n    terms = vectorizer.get_feature_names()\n    for i, comp in enumerate(svd_model.components_):\n        terms_comp = zip(terms, comp)\n        sorted_terms = sorted(terms_comp, key= lambda x:x[1], reverse=True)[:7]\n        print()\n        print(\"Topic \"+str(i)+\": \")\n        for t in sorted_terms:\n            print(t[0],end=' ')\n            print(\" \",end=' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_me_topics(cluster_id=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\nPlotting The Clusters</p>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = TfidfVectorizer()\nX = vectorizer.fit_transform(data['text'])\nsvd_model = TruncatedSVD(n_components=4, algorithm='randomized', n_iter=100, random_state=122)\nX_topics = svd_model.fit_transform(X)\nembedding = umap.UMAP(n_neighbors=150, min_dist=0.5, random_state=12).fit_transform(X_topics)\n\nplt.figure(figsize=(7,5))\nplt.scatter(embedding[:, 0], embedding[:, 1], \nc = data['Kmeans clusters'],\ns = 10, # size\nedgecolor='none'\n)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:courier,arial,helvetica;font-size:200%;\">As you can see above, the result is quite beautiful. Each dot represents a document and the colours represent the clusters. Our LSA model seems to have done a good job.</p>\n"},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\n More Detailed Plot For Topics</p>\n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def make_topic_plot(cluster=1,topics=1,n=20) :\n    vectorizer = TfidfVectorizer()\n    X = vectorizer.fit_transform(data[data['Kmeans clusters']==cluster]['text'])\n    svd_model = TruncatedSVD(n_components=topics, algorithm='randomized', n_iter=100, random_state=122)\n    svd_model.fit(X)\n    comp=svd_model.components_\n    terms=vectorizer.get_feature_names()\n    plot_frame=pd.DataFrame(columns=['x','y','text','score','topic'])\n    for i in range(topics):\n        x=np.random.randint(10,200,n)\n        y=np.random.randint(10,200,n)\n        score=comp[i]\n        terms_comp = zip(terms, score)\n        sorted_terms = sorted(terms_comp, key= lambda x:x[1], reverse=True)[:n]\n        sorted_terms=np.array(sorted_terms)\n        sorted_terms=np.array(sorted_terms)\n        dn=pd.DataFrame()\n        dn['x']=x\n        dn['y']=y\n        dn['text']=sorted_terms[:,0]\n        dn['score']=sorted_terms[:,1].astype('float32')\n        dn['topic']=[i+1]*n\n        plot_frame=plot_frame.append(dn,ignore_index=True)\n    titl='Topic Plot For Cluster'+str(cluster)\n    fig=px.scatter(plot_frame,x='x',y='y',text='text',size='score',size_max=40,color='score',\n               color_continuous_scale='sunset',labels={'x':'','y':''},title=titl,animation_frame='topic')\n    fig.update_xaxes(showgrid=False)\n    fig.update_yaxes(showgrid=False)\n    fig.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"make_topic_plot(cluster=1,topics=4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\n How Topics Change Over Time For Different Clusters</p>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Important Topics in a cluster changing by time \ndef make_race_plot(cluster=1,top_n=4):\n    data_time=pd.DataFrame(columns=['text','score','time'])\n    for i in data[data['Kmeans clusters']==cluster].sort_values('timestamp')['timestamp'].values[4:] :\n            vectorizer = TfidfVectorizer()\n            X = vectorizer.fit_transform((data[(data['Kmeans clusters']==cluster) & (data['timestamp']<=i)].sort_values('timestamp')['text']))\n            svd_model = TruncatedSVD(n_components=1, algorithm='randomized', n_iter=100, random_state=122)\n            svd_model.fit(X)\n            comp=svd_model.components_[0]\n            terms=vectorizer.get_feature_names()\n            terms_comp = zip(terms, comp)\n            sorted_terms = sorted(terms_comp, key= lambda x:x[1], reverse=True)[:top_n]\n            sorted_terms=np.array(sorted_terms)\n            dn=pd.DataFrame()\n            dn['text']=sorted_terms[:,0]\n            dn['score']=sorted_terms[:,1].astype('float32')\n            dn['time']=[i]*top_n\n            data_time=data_time.append(dn)\n\n\n    my_raceplot = barplot(data_time,\n                          item_column='text',\n                          value_column='score',\n                          time_column='time')\n\n    fig=my_raceplot.plot(title = 'Change in most common word for a cluster over time',\n                     item_label = 'Text',\n                     value_label = 'Score',\n                     time_label='Creation Time :',\n                     frame_duration = 1600)\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"make_race_plot(cluster=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\n Relation btw clusters and number of comments</p>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cluster vs Score\ngrouped=data.groupby('Kmeans clusters').mean()\npx.bar(grouped,x=grouped.index+1,y='comms_num',labels={'x':'Cluster'},color=(grouped.index+1).astype(str))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:courier,arial,helvetica;font-size:200%;\">We can clearly see that the maximum amount of people have commented on the cluster 1 which shows how controversial that cluster may be unlike cluster 3 which seems to have the least mean amount of comments on it</p>\n\n"},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\n Relation btw clusters and score</p>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cluster vs Score\ngrouped=data.groupby('Kmeans clusters').mean()\npx.bar(grouped,x=grouped.index+1,y='score',labels={'x':'Cluster'},color=(grouped.index+1).astype(str))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:courier,arial,helvetica;font-size:200%;\">There seems to be not much relation between clusters and the score .</p>\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"<p style = \"font-family:courier,arial,helvetica;font-size:300%;\">\n Hoping you liked it :) <br> Would really like to know your feedback :) <br>\nWill try to explore this data more :) </p>\n"},{"metadata":{},"cell_type":"markdown","source":"![](https://www.icegif.com/wp-content/uploads/thank-you-icegif-10.gif)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}