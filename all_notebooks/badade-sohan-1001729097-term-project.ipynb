{"cells":[{"metadata":{},"cell_type":"markdown","source":"#INTENTION OF THE PROJECT\n\nHello!!\nThe purpose of this project is to :\n\n*   Do the indepth analysis between two classifiers.\n  1.   Multinomial Naive Bayes\n  2.   Logistic Reg.\n\n* Understand the type of data with given using visualization using given information and data file.\n\n* Build the classifier that predits the rating for the given review.\n\nI have selected Logistic Regression since it appropriate regression analysis to conduct when there are diffrent variables involved. Like all regression analyses, the logistic regression is a predictive analysis.  Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables.\n\nTo test this, I have used Multinomial Naive Bayes since it is usually used in many Natural Language Processing tasks.\n","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nfrom string import digits\nimport matplotlib.mlab as mlab\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\nfrom sklearn import svm, linear_model\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\nfrom sklearn.ensemble import VotingClassifier \nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nimport random\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data= pd.read_csv('../input/boardgamegeek-reviews/bgg-13m-reviews.csv')\ninfofile= pd.read_csv('../input/boardgamegeek-reviews/games_detailed_info.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have two files \n1. bgg-13m-reviews.csv\n2. games_detailed_info.csv\n\nThe first file is the data that contains 13 million reviews. Where we will build our model , do the analysis, and later use for do live prediction.\n\nThe second file has the aggregated deatils about the data, which will help us do the visualizations. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Now, We will check the data by doing following.\nhead() call on object returns the first 5 rows.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"infofile.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"VISUALS","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Next we can see how the ratings are distributed for all the games and number of copies that are owned by all reviewers. This way we know that the data is mostly the reviews/rating by people who own the game.\n\n\nWe can also see, Catan is most favourite boardgame ever created. We have many such games in the list as outliers.\nWe can study what made these games so popular, and use those parameters to predict the particular game-publishers game-success rate.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Set a style sheet and instantiate fig and ax\nplt.style.use('fivethirtyeight')\nfig,ax = plt.subplots()\n\n#set our basic labels\nax.set_title(label='Top 1% of Games by \\nRating and Users Who Own', \n             fontsize=16, fontweight='bold')\nax.set_xlabel('User Rating', fontsize=12)\nax.set_ylabel('# of Copies Owned', fontsize=12)\n\n#we will label some outliers\nax.text(x=6.75, y=122000, s='Catan', fontsize=10)\nax.text(x=7.00, y=115500, s='Carcassone', fontsize=10)\nax.text(x=7.60, y=121000, s='Pandemic', fontsize=10)\nax.text(x=8.35, y=31500, s='Gloomhaven', fontsize=10)\n\n#Edit tick details\nax.set(yticks=range(0,130000,25000))\nax.tick_params(axis='both', which='major', labelsize=10)\n\n#plot the data\nplt.scatter(x=infofile['bayesaverage'],\n            y=infofile['owned'],\n            s=infofile['averageweight']**4, color='blue', alpha=.5, label='Top Rated')\nplt.scatter(x=infofile['bayesaverage'],\n            y=infofile['owned'],\n            s=infofile['averageweight']**4,color = 'red', \n            alpha=.3, label='Top Owned');\n\n#Create and tweak details of the legend\nlgnd = plt.legend(loc=(.1,.2),scatterpoints=1, fontsize=10, \n                  title_fontsize=10, title='Size by Weight')\nlgnd.legendHandles[0]._sizes = [100]\nlgnd.legendHandles[1]._sizes = [210]\n\n#Save\nplt.savefig('Games_by_rating_and_owned.png', format='png', \n            dpi=300, bbox_inches='tight')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**CLEANING**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Next we will do th cleaning on the data by removing NOT REQUIRED columns.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = data.drop(columns=\"ID\")\ndata2 = data1.drop(columns=\"name\")\ndata3 = data2.drop(columns=\"user\")\ndata3.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we will remove the NULL reviews from the comment column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = data3.dropna(subset=['comment'])\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now its time to removing all the punctuation and making all the letter lower case","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":" dataset['comments'] = dataset['comment'].str.lower().apply(lambda x:''.join([i for i in x if i not in string.punctuation]))\n dataset = dataset.drop(columns=\"comment\")\n dataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will try to remove all the stopwords from english lauguage and try to add few more stopwords that we think are redundant to the dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"stpwrds = stopwords.words('english')\nstpwrds.extend(('game','people','really','board','games','play','player','one','plays','cards','would','played','players'))\ndataset['comments'] = dataset['comments'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stpwrds)]))\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we will work on the rating column.\nThere is the rounding up of values that we will do","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['rating'] = dataset['rating'].round() \ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**VISUALS (ON CLEANED DATA)**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"This is negavtive review word cloud of the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"negative = dataset.loc[dataset['rating'] < 2]\nwords = Counter([comm for comm in \" \".join(negative['comments']).split()])\nwc = WordCloud(width=400, height=350,colormap='plasma',background_color='white').generate_from_frequencies(dict(words.most_common(200)))\nplt.figure(figsize=(15,10))\nplt.imshow(wc, interpolation='bilinear')\nplt.title('Common Words in Negative Reviews', fontsize=20)\nplt.axis('off');\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is positive review word cloud of the data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"positive = dataset.loc[dataset['rating'] > 9]\nwords = Counter([w for w in \" \".join(positive['comments']).split()])\nwc = WordCloud(width=400, height=350,colormap='plasma',background_color='white').generate_from_frequencies(dict(words.most_common(200)))\nplt.figure(figsize=(15,10))\nplt.imshow(wc, interpolation='bilinear')\nplt.title('Common Words in Positive Reviews', fontsize=20)\nplt.axis('off');\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DATA SPLIT**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now that our data is ready to be processed upon, we will split the data into 70% of traning set and 30% of test set.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data, test_data = train_test_split(dataset, test_size = 0.30, random_state= 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training data look:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Test data look:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, for to facilitate the execution of the code and handling the data efficiently, we further reduce the training data into two intervals:\n1. inter1\n2. inter2","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"inter1, inter2 = train_test_split(train_data, test_size = 50, random_state= 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**MODEL SELECTION AND TRAINING:**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First, We will use the interval1 of training set to see the accuracy of the model. We have selected Multinomial naive bayes it estimates the conditional probability of a particular word given a class as the relative frequency of term t in documents belonging to class. The variation takes into account the number of occurrences of term t in training documents from class,including multiple occurrences.\n\nFollowing this code, is the accuracy of this model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(inter1.comments, inter1.rating, random_state=2,test_size=0.30)\n\nmodel1 = Pipeline([\n    ('count_vectorizer', CountVectorizer()), ('tfidf_transformer',  TfidfTransformer()),('classifier', MultinomialNB()) ])\n\n    \nmodel1.fit(X_train,y_train.astype('int'))\n\nlabels = model1.predict(X_test)\n\naccr = accuracy_score(y_test.astype('int'),labels, normalize=True) * float(100)\nprint('ACCURACY OF MULTINOMIAL NAIVE BAYES FOR FIRST PART OF TRAIN_SET IS',(accr))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we will try Logistic regression. It is the appropriate regression analysis to conduct when the dependent variable is dichotomous (binary).  Like all regression analyses, the logistic regression is a predictive analysis.  Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables.\n\n\nFollowing this code, is the accuracy of this model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nX_train, X_test, y_train, y_test = train_test_split(inter1.comments, inter1.rating, random_state=2,test_size=0.30)\n\nmodel2 = Pipeline([\n    ('count_vectorizer', CountVectorizer()), ('tfidf_transformer',  TfidfTransformer()),('classifier', LogisticRegression()) ])\n\n    \nmodel2.fit(X_train,y_train.astype('int'))\n\nlabels = model2.predict(X_test)\n\naccr = accuracy_score(y_test.astype('int'),labels, normalize=True) * float(100)\nprint('ACCURACY OF LOGISTIC REG. FOR FIRST PART OF TRAIN_SET IS',(accr))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nFrom the above two models and the comparision between their performance and accuracy we can see, \nLogistic reg is performing better than Multinomial Naive bayes.\n\nWe will try the same models on different dataset to reassure this hypothesis.\n\nFollowing this code, is the accuracy of this model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(inter2.comments, inter2.rating, random_state=2,test_size=0.30)\n\nmodel3 = Pipeline([\n    ('count_vectorizer', CountVectorizer()), ('tfidf_transformer',  TfidfTransformer()), ('classifier', MultinomialNB()) ])\n\n    \nmodel3.fit(X_train,y_train.astype('int'))\n\nlabels = model3.predict(X_test)\n\naccr = accuracy_score(y_test.astype('int'),labels, normalize=True) * float(100)\nprint('ACCURACY OF MULTINOMIAL NAIVE BAYES FOR SECOND PART OF TRAIN_SET IS',(accr))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, \nwe will again use the logistic reg. to compare them with above results.\n\nFollowing this code, is the accuracy of this model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nX_train, X_test, y_train, y_test = train_test_split(inter2.comments, inter2.rating, random_state=2,test_size=0.30)\n\nmodel4 = Pipeline([\n    ('count_vectorizer', CountVectorizer()), ('tfidf_transformer',  TfidfTransformer()), ('classifier', LogisticRegression()) ])\n\n    \nmodel4.fit(X_train,y_train.astype('int'))\n\nlabels = model4.predict(X_test)\n\naccr = accuracy_score(y_test.astype('int'),labels, normalize=True) * float(100)\nprint('ACCURACY OF LOGISTIC REG. FOR SECOND PART OF TRAIN_SET IS',(accr))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**MY CONTRIBUTION FROM THE ANALYSIS WE MADE.**\n\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"After building and running these two very efficient models on the different type of data,\nWe can see how logistic reg. performed better than Multinomial NB.\n\nTo conculude this, \nWe will run this model on entire training data, \nso the learning becomes versatile and prediction becomes more accurate in the end.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nX_train, X_test, y_train, y_test = train_test_split(train_data.comments, train_data.rating, random_state=2,test_size=0.30)\n\nmodel_final = Pipeline([\n    ('count_vectorizer', CountVectorizer()),('tfidf_transformer',  TfidfTransformer()), ('classifier', LogisticRegression()) ])\n\nmodel_final.fit(X_train,y_train.astype('int'))\n\nlabels = model_final.predict(X_test)\n\naccr = accuracy_score(y_test.astype('int'),labels, normalize=True) * float(100)\nprint('ACCURACY OF OUR FINAL MODEL OF TRAIN_SET IS',(accr))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**CONCLUSION:**\nFinally after concluding the final model for this game review data,\nWe are going to deploy to start predicting the live reviews for our customers.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"\n\n\n\n\n\n**THANK YOU**,\n\nSohan Badade\n\nID 1001729097","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"References:\n\nReference Links\nhttps://github.com/jushih/Sentiment-Analysis\n\nhttp://www.site.uottawa.ca/~stan/csi5387/DMNB-paper.pdf\n\nhttps://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n\nhttps://scikit-learn.org/stable/modules/svm.html\n\nhttps://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html\n\nhttps://monkeylearn.com/text-classification/\n\nhttps://www.geeksforgeeks.org/applying-multinomial-naive-bayes-to-nlp-problems/\n\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}