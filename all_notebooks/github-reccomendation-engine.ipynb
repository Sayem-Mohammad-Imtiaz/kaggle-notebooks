{"cells":[{"metadata":{"_uuid":"3ffe2dbde42c39ca145a3253018b4e913c6b491a","_cell_guid":"7edbc389-0804-47b9-bcd5-efec73fbb174"},"cell_type":"markdown","source":"Building a github repository recommendation engine\n====================\n\n<img src=\"https://github.com/jaimevalero/github-recommendation-engine/raw/master/views/img/webscreen_capture.gif\" width=\"1000px\">\n\n\n[Quick demo site](https://github-recommendation.herokuapp.com/char/char.html?busqueda=kaggle) for the impatient. \n\n\nWe find repositories from the stared repositories dataset, similar to your own repos.\nWe build a distance matrix from the repo list.   \nThen we load an external repo from github, to find similarities between the famous repos and yours!\n","execution_count":null},{"metadata":{"_uuid":"ef058a972653b674d73a8cc856854ba9984cddae","_cell_guid":"4f4472f5-b38d-425d-a0d4-57952396abe8"},"cell_type":"markdown","source":"Steps: \n=====\n* Load the csv file\n* Clean the csv.\n* Convert the repo list into a tags matrix list, with binary values.\n* We load a user repo from github (this part is mocked due to notebook connectivity limitations)\n* We create a distance matrix between stared repos, and the user repo\n* Print results\n\n","execution_count":null},{"metadata":{"_uuid":"f371db1c2ee3af1a21f2fe3e7cb698103e70d8cf","_cell_guid":"7ba70f2f-aa3d-45ce-9b5c-6382b442096b"},"cell_type":"markdown","source":"Load the data\n---------\n","execution_count":null},{"metadata":{"_uuid":"c1c5a48f1bb220df97851f8f45262ac0dff00c71","_cell_guid":"896510ab-44d7-4ac5-b763-e405f2a6fa44","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom subprocess import check_output\n#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n#print(check_output([\"pip\" , \"install\" ,\"requests\"]).decode(\"utf8\"))\n\n\n\n# Load data\ndf = pd.DataFrame()\n\n#This is the standar csv, with the gravatar images for each repo     \ndf = pd.read_csv('../input/TopStaredRepositories.csv')\ndf.set_index(['Repository Name'])\n\ndf.head(2)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e0a8cdb494ee2a3603eb8156bbc127c91549a8f","_cell_guid":"6d8cd6cc-4cbb-473c-8fdf-1d17aad33ddb"},"cell_type":"markdown","source":"Clean the data:\n---------\n\n    - fill empty urls.\n     - Add ',' to tags list, to be tokenizable.","execution_count":null},{"metadata":{"_uuid":"71a0ca7f3367f5780a13307b35c0f0c18fe861ec","_cell_guid":"2407bb50-a557-459b-bea3-f02d08665ae6","trusted":true},"cell_type":"code","source":"## Cleaning data\n# We fill the emptpy URL cells\ndf['Url'] = \"http://github.com/\" +         df['Username'] + \"/\" + df['Repository Name']\n# We add a final comma character for the tag string, it will be usefull when we tokenize\ndf['Tags'].fillna(\"\", inplace=True)\ndf['Tags'] = df['Tags'] + \",\"\n\n# We do not want uppercase on any label\ndf['Language'] = df.loc[:, 'Language'].str.lower()\n# Copy a backup variable, so we can change our main dataframe\ndf_backup = df.copy(deep=True)\ndf.head(2)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb4d35037d89868ba113129ab2b7f6a03a06514e","_cell_guid":"8b2ec48a-8aee-4d67-aa41-329e9c9f41c1"},"cell_type":"markdown","source":"Creating a tag matrix:\n---------\nWe hot encode the 'T[[](http://)](http://)ags' columns. \nInstead of having a list of labels, we will have n columns, with values [0,1] ","execution_count":null},{"metadata":{"_uuid":"9c4451ce94b9d3bc949d01e7705404672c164a62","_cell_guid":"a334d0b4-d4e9-4df1-8ff4-5e9079dc0afe","trusted":true},"cell_type":"code","source":"# Generate tag list\nmergedlist = []\nfor i in df['Tags'].dropna().str.split(\",\"):\n    mergedlist.extend(i)\ntags = sorted(set(mergedlist))\n# Encode languages in single column\njust_dummies = pd.get_dummies(df['Language'])\nfor column in just_dummies.columns:\n    if column not in df.columns:\n        df[column] = just_dummies[column]\ndf.head(2)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"295d905f170e59a9aa416db1bb5f4572c68ee8fb","_cell_guid":"245bfb4e-b537-4c98-8878-ed04649e8f12"},"cell_type":"markdown","source":"Cleaning tag matrix:\n---------\nWe remove non binary columns, and convert to lowercase. ","execution_count":null},{"metadata":{"_uuid":"4948aad521e29e2f4d76647bf352b1829c97e3e5","_cell_guid":"fa1ed1f7-2810-425d-952d-d7da6ac2dfa9","trusted":true},"cell_type":"code","source":"for tag in tags:\n    if tag not in df.columns:\n        df[tag] = 0\n    try:\n        if len(tag) > 4 :\n            df.loc[df['Repository Name'].str.contains(tag), tag] = 1\n            df.loc[df['Description'].str.contains(tag), tag] = 1\n        df.loc[df['Tags'].str.contains(tag + \",\"), tag] = 1\n    except Exception:\n        pass\n# Remove columns not needed\ndf.set_index(['Repository Name'])\nCOLUMNS_TO_REMOVE_LIST = ['', 'Username', 'Repository Name', 'Description',\n                          'Last Update Date', 'Language', 'Number of Stars', 'Tags', 'Url','Gravatar' ,'Unnamed: 0']\n# Stop words: links to (https://github)\nRAGE_TAGS_LIST = [ 'github','algorithms','learn','learning','http' ,'https']\n\n\n\nfor column in COLUMNS_TO_REMOVE_LIST + RAGE_TAGS_LIST:\n    try:\n        del df[column]\n    except Exception:\n        pass\n\ndf.columns = df.columns.str.lower()\n\n\nprint (\"Our final label matrix for repo list is\")\ndf.head(2)  \n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dfad08a0627d5614a35c5a83ca630cd84c86ddf5","_cell_guid":"d7c8139b-2c6c-4467-9b7f-67d4124d0bf1"},"cell_type":"markdown","source":"Tag correlation\n========\nWe create a correlation matrix to check if Tag Matrix has been created right.","execution_count":null},{"metadata":{"_uuid":"5e07ab89fa121f146659fb11333946e5d2711fda","_cell_guid":"35002eab-7f2f-4dbc-8531-23f53dde5683","trusted":true},"cell_type":"code","source":"# Create correaltion Matrix\ncorr = df.corr()\ncorr.iloc[0:5][0:5]\ncorr['machine-learning'].dropna().sort_values().tail(5).head(4)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d15c2f12ae6a9d331aacf55c993a04c332de61ce","_cell_guid":"b2354c55-a026-4939-b4f9-58e9f3346ba9"},"cell_type":"markdown","source":"\nGet repo info for a given user from github:\n---------\nNow we want to get a repo list for a given user.\nUnfortunately, kaggle notebook does not allow internet access, so I show the code and the results, but I do not execute the piece of code.\n","execution_count":null},{"metadata":{"_uuid":"bb0006b62048c93a59e7e8fa433886dbed94cc53","_cell_guid":"a5fc75cc-e41b-4a86-b498-c2d27478b9a0","trusted":true},"cell_type":"code","source":"###\n### We comment the code because kaggle kernels does not allow internet access.\n### If you decide to run from local, the code is: \n###\n\n# We ask for a given user, to find the reccomendation for this user\n\nGITHUBUSER=\"jaimevalero\"\n\n\n# import requests\n# from requests.auth import HTTPBasicAuth\n\n# github_user = GITHUBUSER\n# We have do not have internet access inside the notebook, \n# but the coude to query github api would be\n#PERSONAL_TOKEN = \"<REPLACE-FOR-YOUR-TOKEN>\"\n\n# Token is not mandatory, but there is a query rate limit, for those API calls which do not use token.  \n\n#url = 'https://api.github.com/users/%s/repos?sort=updated' % github_user\n#headers = {'content-type': 'application/json',\n#           'Accept-Charset': 'UTF-8',\n#           'Accept': 'application/vnd.github.mercy-preview+json'}\n#r = requests.get(url,  headers=headers, auth=HTTPBasicAuth(\n#    \"jaimevalero\", PERSONAL_TOKEN))\n\n# i=0 # first repo from the list\n#repo_names       = pyjq.all(\".[%s] | .name\"        % i,  json_response)\n#repo_languages   = pyjq.all(\".[%s] | .language\"    % i,  json_response)\n#repo_description = pyjq.all(\".[%s] | .description\" % i,  json_response)\n#repo_topics      = pyjq.all(\".[%s] | .topics\"      % i,  json_response)\n\n# Mocked values are\nrepo_names       = [\"github-recommendation-engine\"]\nrepo_languages   = [\"Python\"]\nrepo_description = [\"A github repository suggestion system\"]\nrepo_topics  = [\"github\",\"machine-learning\",\"recommendation-system\"]\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6be0c44f549a46a671ff9b2a6f8df892534d45e0","_cell_guid":"5a5c6a68-dffa-46e4-87cb-2cc16e17ac8d"},"cell_type":"markdown","source":"We add the info from the user repo, to the label matrix\n=============\nIn order to calculate the euclidean distance between the user repo, and the stared repo list, to find the closes stared repo from yours, we add it to the label matrix\n","execution_count":null},{"metadata":{"_uuid":"2459d0de3c5cbb7e3165df5fd9500b8ab04c3249","_cell_guid":"c3850168-9fcf-4e7a-a877-05d3672ded7d","trusted":true},"cell_type":"code","source":"# Error test, in case of no description given\nif repo_description[0] is None: repo_description = ['nodescription']\n\n# We add a new element to the end of the DataFrame\nnew_element = pd.DataFrame(0, [df.index.max() + 1], columns=df.columns)\n\nlabel_list = repo_names[0].split('-')  + repo_languages + repo_description[0].replace(\".\", \" \").replace(\",\", \" \").split() + list(repo_topics)\nprint( \"The labels from the repo are :\" , label_list)\n\nfor j in (label_list):\n    if j is not None:\n        if j.lower() in df.columns:\n            #print(\"Setting to 1\", j.lower())\n            new_element[j.lower()] = 1\n\n# Concat new user repo dataframe to stared repos dataframe\ndf = pd.concat([df, new_element])\n# Now user repo is on the last row of the label matrix\ndf.tail(2)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe03c17e03e66a25684044a355e7430c689dab67","_cell_guid":"91b277cc-e478-4fb2-9aad-5fe2cacf1337"},"cell_type":"markdown","source":"We reduce the number of dimensions\n=============\nAs we are considering similarity between an user repo and the other, we delete those dimensions which are not set to 1 in the user repo.\n","execution_count":null},{"metadata":{"_uuid":"8ee2b9c2e142e80caee40d7c9bdc093480d31ce7","_cell_guid":"5490a852-4bad-4a2e-a9e9-165ffa28cd8b","trusted":true},"cell_type":"code","source":"df_reduced = pd.DataFrame()\nNUM_ELEMENTS=len(df)-1\nuser_repo = df.iloc[NUM_ELEMENTS:]\nfor k in df.columns :\n    existe = user_repo[k].values[0]\n    if existe > 0 : df_reduced[k] = df[k]\n\ndf = df_reduced.copy(deep=True)\n\n# Remember user repo is the last one\ndf.tail(10)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6fde3201b277a5374c00efec14f61fb0c83b9b40","_cell_guid":"e8bba251-bc05-4878-9129-694d4439f0db"},"cell_type":"markdown","source":"Calculate euclidean distance\n==============\n\nNow we calculate the euclidean distance for the binary matrix, and get closest repos from the user repos.","execution_count":null},{"metadata":{"_uuid":"dddcfd188ed6c42947c86b77e3a67d700c595387","_cell_guid":"587d436f-f408-4378-9572-6128b474ac44","trusted":true},"cell_type":"code","source":"from scipy.spatial import distance\nfrom scipy.spatial.distance import squareform, pdist\n\nrepos = list(df_backup['Username'] + \"/\" + df_backup['Repository Name'])\nrepos.extend(repo_names) # We add to the csv reponame list, the repo name from github \nprint (repos[-1] ,len(repos), df.shape, df_backup.shape)\n# We calculate the euclidean distance for the binary label matrix 3\nres = pdist(df, 'euclidean')\ndf_dist = pd.DataFrame(squareform(res), index=repos, columns=repos)\n\nprint(\"\"\"This is the euclidean distance matrix for \n     - the user repo (github-recommendation-engine) \n     - other eight repos :\n      The lower the distance, stronger the similarity between repos\n      \"\"\")\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nf,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(df_dist.iloc[972:,972:] , annot=True, linewidths=.5, fmt= '.1f',ax=ax , cmap='viridis' )\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"67caf96ba12b483ce2950b7416271972d103da73","_cell_guid":"5dab60db-503e-47d3-8eb1-5c212d905c02"},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"_uuid":"8a361dcbce5c3cb7314b363e3ff708caa1cc2dac","_cell_guid":"de9cb032-89d1-441c-9746-81d514d14fed"},"cell_type":"markdown","source":"Print results: Stared repos having more similarity with given user repo.\n================================\n\nFinally, we print the lowest distance (filtering 0), prints all repos that have that distance. \n\n","execution_count":null},{"metadata":{"_uuid":"7bb4ed0481daceca3a6c964826834cc5cfa6b854","_cell_guid":"3e0ad805-d07b-4225-a182-efda3cf94d39"},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"_uuid":"91c1b5389a4fb25aa3e62d505d652a88081c58a7","_cell_guid":"e7ec55cf-67c8-4ffa-82c8-45e736373ee5","trusted":true},"cell_type":"code","source":"result_array = []\ni = df_dist.columns[-1]\n# We change 0 for 1000, to filter when calculating minimun distances \n# (because obviously, the repo that has more similarity with the repo list is itself. )\ndf_dist.loc[df_dist[i] == 0, i] = 1000\n# Get minimun distance\nmin = df_dist[i].min()\n# Filter all repo within that minimun distance\nclosest_repos = df_dist[i][df_dist[i] == min].index, i, min\n# print results\nprint (\"Similar repos to %s are: \" % repo_names )\nfor recomended_repo in (df_dist[i][df_dist[i] == min].index[0:12]):\n    print (recomended_repo)\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d24bbc4e94a4dd581dff35106f92e56d074d1a69","_cell_guid":"75e8c6e1-1846-4d90-9424-738e9f306412"},"cell_type":"markdown","source":"We can see that machine learning resource are suggested for this repo. Pretty good !\n\nConclussions\n=======\nThis is a somewhat primitive recommendation engine, based on neared neighbours, to find personalized similarity.    \nWe could further refine the engine, using colaborative filtering whit like / dislike buttons, to build an hybrid recommender system.\n\nThank you for your patience.   \n\n\nNow, find your own similar repos at demo site : https://github-recommendation.herokuapp.com/views/index.html?busqueda=jaimevalero\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}