{"cells":[{"metadata":{"_cell_guid":"45d19b03-1687-4362-a6fa-2d19b146cf47","_uuid":"858576e066d40cdeba6e34353c59fab40506fa25"},"cell_type":"markdown","source":"### Introduction:\nUsing **ANN (Artificial Neural Network) using Keras** to classify **tumors into Malignant or Benign type**, when provided with the **tumor's dimensions**. In the output we will have probability of** tumor of belonging to either Malignant or Benign class.**   \n\n**3 parts**  \n1. Data pre-processing and quick analysis\n2.  Building ANN\n3.  Making Predictions So let's get started!"},{"metadata":{"_cell_guid":"3b6584c2-853e-4da4-8450-172b7822719e","_uuid":"c3f9097ba784c6eba71123028ac90301aed51b74"},"cell_type":"markdown","source":"# 1.Preprocessing Dataset"},{"metadata":{"_cell_guid":"dd6e6e8c-3b17-4807-989a-ae3ffbac1bc9","_uuid":"464f8486582feb7dd12e268ca7c60e19d3ba98df","collapsed":true,"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndataset = pd.read_csv('../input/data.csv')","execution_count":25,"outputs":[]},{"metadata":{"_cell_guid":"7faacae3-f38f-48f8-bc21-4b5660ae4652","_uuid":"dc5a0396c1596818800fb4ed033112183230f8a3","collapsed":true,"trusted":true},"cell_type":"code","source":"def dataSetAnalysis(df):\n    #view starting values of data set\n    print(\"Dataset Head\")\n    print(df.head(3))\n    print(\"=\" * 100)\n    \n    # View features in data set\n    print(\"Dataset Features\")\n    print(df.columns.values)\n    print(\"=\" * 100)\n    \n    # View How many samples and how many missing values for each feature\n    print(\"Dataset Features Details\")\n    print(df.info())\n    print(\"=\" * 100)\n    \n    # view distribution of numerical features across the data set\n    print(\"Dataset Numerical Features\")\n    print(df.describe())\n    print(\"=\" * 100)\n    \n    # view distribution of categorical features across the data set\n    print(\"Dataset Categorical Features\")\n    print(df.describe(include=['O']))\n    print(\"=\" * 100)","execution_count":26,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51df57bb7713755a6111a445df7e6c7a7a300145"},"cell_type":"code","source":"dataSetAnalysis(dataset)","execution_count":27,"outputs":[]},{"metadata":{"_uuid":"f51bb781a666b0339f489153f1921d8ed14ec8f4"},"cell_type":"markdown","source":"So we have a total of 33 columns, the last column \"Unnamed: 32\" contains all the null values, so we will exclude it. In addition to our diagnosis, we will not include the 'id' in our training set because it has no effect on the classification. So, we started with 30 features that are all types of float64 and do not include missing values. Cool! Now, let's separate the features and labels."},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"893f9ecec7913aa4b87139d459f3d07170a3e790"},"cell_type":"code","source":"X = dataset.iloc[:,2:32] # [all rows, col from index 2 to the last one excluding 'Unnamed: 32']\ny = dataset.iloc[:,1] # [all rows, col one only which contains the classes of cancer]","execution_count":28,"outputs":[]},{"metadata":{"_uuid":"30de0193926b52ff338b41fcbc05c975900f7b37"},"cell_type":"markdown","source":"Notice that **'diagnosis'** contains **'M' or 'B'** to represent **Malignant or Benign tumor**. Let's encode them to **0** and **1.**"},{"metadata":{"trusted":true,"_uuid":"05e0caba3aa1ce26439aac0f9cc8149c9261d529"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nprint(\"Before encoding: \")\nprint(y[100:110])\n\nlabelencoder_Y = LabelEncoder()\ny = labelencoder_Y.fit_transform(y)\n\nprint(\"\\nAfter encoding: \")\nprint(y[100:110])","execution_count":29,"outputs":[]},{"metadata":{"_uuid":"16f87a51924822369d7b0ee7c8c675814d4ec96a"},"cell_type":"markdown","source":"**Splitting Dataset**  \n\nNow let's split our data into training and testing datasets."},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"3b895f51f9fa9c0cfc557a69b79b0e08fe59cef1"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","execution_count":30,"outputs":[]},{"metadata":{"_uuid":"4a76eb32b243bf0eb81611af4591d071cbdfa3d8"},"cell_type":"markdown","source":"**Features Scaling**  \n\nNow let's apply features scaling. Scaling ensures that just because some features are big, the model won't lead to using them as a main predictor [(Read more)](https://stackoverflow.com/questions/26225344/why-feature-scaling)"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"bb45e4fafa2755f31340a6162f352cffa92659a0"},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":31,"outputs":[]},{"metadata":{"_uuid":"8860b54ee5775bd4b8df0b43633eb113ff563159"},"cell_type":"markdown","source":"### 2. Preparing ANN\n\n### Importing Keras and initialising ANN\n\n\n### Building the layers\nLet's build the Layers. We can play around and change number of units but if we are not sure what number to initialize with then simply initialize the units of all layers except the last one with the (number of features + number of output nodes)/2 which equals to 15 in our case. My results were imporved by setting units = 16 for the first layer and decreasing the units in the hidden layers. Also we have to provide input dimension for the first layer only. 'relu' reffers to rectified linear unit and sigmoid reffers to sigmoid activation function. With the help of sigmoid activation function, we can get the probabilities of the classification which might be benificial in some cases to conduct further research.\n\n\n### Tuning Hyper parameters\nLet's first find the hyper parameters using which model can give more accurate predictions. Here I'll tune batch_size, epochs and optimizer. This will take some time to run so sit back and relax."},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"ae5d1347d2c32ea57b99a9ef52edea11e74e931b"},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\n\nclassifier = Sequential() # Initialising the ANN\n\nclassifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu', input_dim = 30))\nclassifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\nclassifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\nclassifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))","execution_count":32,"outputs":[]},{"metadata":{"_uuid":"343a70051df1b9060b3d3d938db3af1d1a03d023"},"cell_type":"markdown","source":"### Compiling ANN\n**Compiling classifier.** Using adam optimizer. Using **binary_crossentropy for loss function** since classification is binary, i.e. only two classes **'M' or 'B'.**"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"2139f6426fcf88b0cf26bfa4dd6a90569047587f"},"cell_type":"code","source":"classifier.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])","execution_count":33,"outputs":[]},{"metadata":{"_uuid":"79e0a9c86925df1bd3c2e59ac129bce249e7ac1b"},"cell_type":"markdown","source":"### Fitting the data\nNow let's fit the data. I trained it with batch size of 1 and 100 epochs and training accuracy was 99.12% and final predictions were 96.49% accurate."},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"77add00b196e00d804fb34753a05cf7030981464"},"cell_type":"code","source":"classifier.fit(X_train, y_train, batch_size = 128, epochs = 15, verbose = 2)","execution_count":63,"outputs":[]},{"metadata":{"_uuid":"c165ab211a70ac10718948bae189e5b84bc171fe"},"cell_type":"markdown","source":"### Saving/Loading the model"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"d4755897e9681e46d2e53001f2b8678f9583e0b9"},"cell_type":"code","source":"from keras.models import load_model\n\nclassifier.save('breast_cancer_model.h5') #Save trained ANN\n#classifier = load_model('breast_cancer_model.h5')  #Load trained ANN","execution_count":70,"outputs":[]},{"metadata":{"_uuid":"f2f828e80a16fda36f290a5fa44be501f14dcf37"},"cell_type":"markdown","source":"###  3. Making Predictions\nNow **y_pred** contains the **probability of tumor** being of type **Malignant or Benign**. We'll assign the results **true** or **false** based on their **probabilities (if probability >= 0.5 than true else false)**"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"ad9e435a6ec360e25890455750b7a22a09f07663"},"cell_type":"code","source":"y_pred = classifier.predict(X_test)\ny_pred = [ 1 if y>=0.5 else 0 for y in y_pred ]","execution_count":71,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9739366d9b94766fe609d18779e9f2e9d2e97a8"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\n\naccuracy = (cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1])\nprint(\"Accuracy: \"+ str(accuracy*100)+\"%\")","execution_count":72,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"caa979815bd7b0eeaad5f2be7c3e2b56b1c28f06"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}