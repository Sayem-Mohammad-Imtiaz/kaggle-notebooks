{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/spam.csv', encoding = 'ISO-8859-1')\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b97999794097f7c2ba1ec98a16252b4cae4ef61"},"cell_type":"code","source":"df.head(5)['v2'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a2ae44d8b0d2db32bf9884870f752e117939b24"},"cell_type":"code","source":"import nltk\n\ndef get_word_set(sentences):\n    word_set = set()\n    for sens in sentences:\n        words = nltk.word_tokenize(sens.lower())\n        word_set.update(words)\n    return word_set\n\nword_set = get_word_set(df['v2'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"94b0a56b7804738fc99f04133090264f0ad3adb4"},"cell_type":"code","source":"def words_to_feature_vector(word_set, sens):\n    feature_vector = list()\n    words = get_word_set(sens)\n    for word in word_set:\n        if word in words:\n            feature_vector.append(1)\n        else:\n            feature_vector.append(0)\n    return feature_vector\n\nX = list()\nY = list()\n\nfor index, row in df.iterrows():\n    sens = row['v2'].lower()\n    label = row['v1']\n    feature_vector = words_to_feature_vector(word_set, sens)\n    \n    X.append(feature_vector)\n    Y.append(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb511853404a13872ff4d7186b700190677227db"},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nclf = GaussianNB()\nclf.fit(X, Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c1d0b2c8a84d8d15922674ecec20dda7c1eddbc"},"cell_type":"code","source":"clf.score(X, Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"936982fa0eeccec8973ace3c742f6268b60715af"},"cell_type":"code","source":"training_prediction = clf.predict(X)\ndf['predict1'] = training_prediction\ndf[df['v1'] != df['predict1']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"436659a6be76aa54301002720b70572a3128ddd2"},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nclf1 = MultinomialNB()\nclf1.fit(X, Y)\nclf1.score(X, Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8eb040225fb56128239f2e6bbb906a173e3941ab"},"cell_type":"code","source":"training_prediction = clf1.predict(X)\ndf['predict2'] = training_prediction\ndf[df['v1'] != df['predict2']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"416b051334f1f5b177f05d94fc1954bb94776530"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}