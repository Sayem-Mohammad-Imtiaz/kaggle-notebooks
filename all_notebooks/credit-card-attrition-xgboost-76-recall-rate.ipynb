{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predict Credit Card Customer Attrition"},{"metadata":{},"cell_type":"markdown","source":"# Part 1: Import data and data exploration"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ndata = pd.read_csv('../input/credit-card-customers/BankChurners.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped1 = pd.DataFrame(data.groupby(['Attrition_Flag'])['Gender'].count()).reset_index()\n\nlabel = list(grouped1['Gender'])\nplt.bar(grouped1['Attrition_Flag'], grouped1['Gender'])\nfor i in range(len(grouped1)):\n    plt.text(x = grouped1.index[i]-0.1 , y = grouped1['Gender'][i]+0.3, s = label[i], size = 10)\n\nplt.xticks(np.arange(0, 2, 1))\nplt.title('Count of Attrition_Flag')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,5))\n\nsns.distplot( data[\"Customer_Age\"], bins=50,ax=axes[0]).set_title(\"Customer_Age\")\nviz_1=sns.violinplot(data=data, x='Attrition_Flag', y='Customer_Age', ax=axes[1])\nviz_1.set_title('Density and distribution of Customer_Age for Attrition_Flag')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(17,5))\ngrouped = pd.DataFrame({'Attrition_Flag': sorted(data['Attrition_Flag'].unique()),\n                        'Count of Gender': data['Gender'].value_counts()})\ngrouped = grouped.reset_index()\n\nax = sns.barplot(x=grouped.iloc[:,0], y=grouped.iloc[:,2],ax=axes[0])\nax.set_xticklabels(ax.get_xticklabels())\nax.set_title(\"Frequency of Gender\")\nfor index, row in grouped.iterrows():\n    ax.text(index,row[2], round(row[2],3), color='black', ha=\"center\")\n\ngrouped = pd.DataFrame(data.groupby(['Gender','Attrition_Flag'])['CLIENTNUM'].count()).reset_index()\n\nax1 = sns.barplot(x=grouped.iloc[:,1], y=grouped.iloc[:,2], hue=grouped.iloc[:,0], ax=axes[1])\nax1.set_xticklabels(ax1.get_xticklabels())\nax1.set_title('Count of credit card for Gender')\n\ngrouped","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(17,5))\ngrouped = pd.DataFrame({'Count of Dependent_count': data['Dependent_count'].value_counts()})\ngrouped = grouped.reset_index()\n\nax = sns.barplot(x=grouped.iloc[:,0], y=grouped.iloc[:,1],ax=axes[0])\nax.set_xticklabels(ax.get_xticklabels())\nax.set_title(\"Frequency of Dependent_count\")\nfor index, row in grouped.iterrows():\n    ax.text(row[0],row[1], round(row[1],3), color='black', ha=\"center\")\n\ngrouped = pd.DataFrame(data.groupby(['Dependent_count','Attrition_Flag'])['CLIENTNUM'].count()).reset_index()\ngrouped\nax1 = sns.barplot(x=grouped.iloc[:,1], y=grouped.iloc[:,2], hue=grouped.iloc[:,0], ax=axes[1])\nax1.set_xticklabels(ax1.get_xticklabels())\nax1.set_title('Count of Attrition_Flag for Dependent_count')\n\ngrouped","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(17,5))\ngrouped = pd.DataFrame(data.groupby(['Education_Level'])['CLIENTNUM'].count()).reset_index()\n\nax = sns.barplot(x=grouped.iloc[:,0], y=grouped.iloc[:,1],ax=axes[0])\nax.set_xticklabels(ax.get_xticklabels())\nax.set_title(\"Frequency of Education_Level\")\nfor index, row in grouped.iterrows():\n    ax.text(index,row[1], round(row[1],3), color='black', ha=\"center\")\n\ngrouped = pd.DataFrame(data.groupby(['Education_Level','Attrition_Flag'])['CLIENTNUM'].count()).reset_index()\ngrouped\nax1 = sns.barplot(x=grouped.iloc[:,1], y=grouped.iloc[:,2], hue=grouped.iloc[:,0], ax=axes[1])\nax1.set_xticklabels(ax1.get_xticklabels())\nax1.set_title('Count of Attrition_Flag for Education_Level')\n\ngrouped","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(17,5))\ngrouped = pd.DataFrame(data.groupby(['Marital_Status'])['CLIENTNUM'].count())\ngrouped = grouped.reset_index()\n\nax = sns.barplot(x=grouped.iloc[:,0], y=grouped.iloc[:,1],ax=axes[0])\nax.set_xticklabels(ax.get_xticklabels())\nax.set_title(\"Frequency of Marital_Status\")\nfor index, row in grouped.iterrows():\n    ax.text(index,row[1], round(row[1],3), color='black', ha=\"center\")\n\ngrouped = pd.DataFrame(data.groupby(['Marital_Status','Attrition_Flag'])['CLIENTNUM'].count()).reset_index()\ngrouped\nax1 = sns.barplot(x=grouped.iloc[:,1], y=grouped.iloc[:,2], hue=grouped.iloc[:,0], ax=axes[1])\nax1.set_xticklabels(ax1.get_xticklabels())\nax1.set_title('Count of Attrition_Flag for Marital_Status')\n\ngrouped","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(17,5))\ngrouped = pd.DataFrame(data.groupby(['Income_Category'])['CLIENTNUM'].count())\ngrouped = grouped.reset_index()\n\nax = sns.barplot(x=grouped.iloc[:,0], y=grouped.iloc[:,1],ax=axes[0])\nax.set_xticklabels(ax.get_xticklabels())\nax.set_title(\"Frequency of Income_Category\")\nfor index, row in grouped.iterrows():\n    ax.text(index,row[1], round(row[1],3), color='black', ha=\"center\")\n\ngrouped = pd.DataFrame(data.groupby(['Income_Category','Attrition_Flag'])['CLIENTNUM'].count()).reset_index()\ngrouped\nax1 = sns.barplot(x=grouped.iloc[:,1], y=grouped.iloc[:,2], hue=grouped.iloc[:,0], ax=axes[1])\nax1.set_xticklabels(ax1.get_xticklabels())\nax1.set_title('Count of Attrition_Flag for Income_Category')\n\ngrouped","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(17,5))\ngrouped = pd.DataFrame(data.groupby(['Card_Category'])['CLIENTNUM'].count())\ngrouped = grouped.reset_index()\n\nax = sns.barplot(x=grouped.iloc[:,0], y=grouped.iloc[:,1],ax=axes[0])\nax.set_xticklabels(ax.get_xticklabels())\nax.set_title(\"Frequency of Card_Category\")\nfor index, row in grouped.iterrows():\n    ax.text(index,row[1], round(row[1],3), color='black', ha=\"center\")\n\ngrouped = pd.DataFrame(data.groupby(['Card_Category','Attrition_Flag'])['CLIENTNUM'].count()).reset_index()\ngrouped\nax1 = sns.barplot(x=grouped.iloc[:,1], y=grouped.iloc[:,2], hue=grouped.iloc[:,0], ax=axes[1])\nax1.set_xticklabels(ax1.get_xticklabels())\nax1.set_title('Count of Attrition_Flag for Card_Category')\n\ngrouped","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,5))\n\nsns.distplot( data[\"Months_on_book\"], bins=50,ax=axes[0]).set_title(\"Customer_Age\")\nviz_1=sns.violinplot(data=data, x='Attrition_Flag', y='Months_on_book', ax=axes[1])\nviz_1.set_title('Density and distribution of Months_on_book for Attrition_Flag')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(17,5))\ngrouped = pd.DataFrame(data.groupby(['Total_Relationship_Count'])['CLIENTNUM'].count())\ngrouped = grouped.reset_index()\n\nax = sns.barplot(x=grouped.iloc[:,0], y=grouped.iloc[:,1],ax=axes[0])\nax.set_xticklabels(ax.get_xticklabels())\nax.set_title(\"Frequency of Total_Relationship_Count\")\nfor index, row in grouped.iterrows():\n    ax.text(index,row[1], round(row[1],3), color='black', ha=\"center\")\n\ngrouped = pd.DataFrame(data.groupby(['Total_Relationship_Count','Attrition_Flag'])['CLIENTNUM'].count()).reset_index()\ngrouped\nax1 = sns.barplot(x=grouped.iloc[:,1], y=grouped.iloc[:,2], hue=grouped.iloc[:,0], ax=axes[1])\nax1.set_xticklabels(ax1.get_xticklabels())\nax1.set_title('Count of Attrition_Flag for Total_Relationship_Count')\n\ngrouped","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(17,5))\ngrouped = pd.DataFrame(data.groupby(['Months_Inactive_12_mon'])['CLIENTNUM'].count())\ngrouped = grouped.reset_index()\n\nax = sns.barplot(x=grouped.iloc[:,0], y=grouped.iloc[:,1],ax=axes[0])\nax.set_xticklabels(ax.get_xticklabels())\nax.set_title(\"Frequency of Months_Inactive_12_mon\")\nfor index, row in grouped.iterrows():\n    ax.text(index,row[1], round(row[1],3), color='black', ha=\"center\")\n\ngrouped = pd.DataFrame(data.groupby(['Months_Inactive_12_mon','Attrition_Flag'])['CLIENTNUM'].count()).reset_index()\ngrouped\nax1 = sns.barplot(x=grouped.iloc[:,1], y=grouped.iloc[:,2], hue=grouped.iloc[:,0], ax=axes[1])\nax1.set_xticklabels(ax1.get_xticklabels())\nax1.set_title('Count of Attrition_Flag for Months_Inactive_12_mon')\n\ngrouped","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(17,5))\ngrouped = pd.DataFrame(data.groupby(['Contacts_Count_12_mon'])['CLIENTNUM'].count())\ngrouped = grouped.reset_index()\n\nax = sns.barplot(x=grouped.iloc[:,0], y=grouped.iloc[:,1],ax=axes[0])\nax.set_xticklabels(ax.get_xticklabels())\nax.set_title(\"Frequency of Contacts_Count_12_mon\")\nfor index, row in grouped.iterrows():\n    ax.text(index,row[1], round(row[1],3), color='black', ha=\"center\")\n\ngrouped = pd.DataFrame(data.groupby(['Contacts_Count_12_mon','Attrition_Flag'])['CLIENTNUM'].count()).reset_index()\ngrouped\nax1 = sns.barplot(x=grouped.iloc[:,1], y=grouped.iloc[:,2], hue=grouped.iloc[:,0], ax=axes[1])\nax1.set_xticklabels(ax1.get_xticklabels())\nax1.set_title('Count of Attrition_Flag for Contacts_Count_12_mon')\n\ngrouped","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,5))\n\nsns.distplot( data[\"Credit_Limit\"], bins=50,ax=axes[0]).set_title(\"Credit_Limit\")\nviz_1=sns.violinplot(data=data, x='Attrition_Flag', y='Credit_Limit', ax=axes[1])\nviz_1.set_title('Density and distribution of Credit_Limit for Attrition_Flag')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,5))\n\nsns.distplot( data[\"Total_Revolving_Bal\"], bins=50,ax=axes[0]).set_title(\"Total_Revolving_Bal \")\nviz_1=sns.violinplot(data=data, x='Attrition_Flag', y='Total_Revolving_Bal', ax=axes[1])\nviz_1.set_title('Density and distribution of Total_Revolving_Bal for Attrition_Flag')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,5))\n\nsns.distplot( data[\"Avg_Open_To_Buy\"], bins=50,ax=axes[0]).set_title(\"Avg_Open_To_Buy\")\nviz_1=sns.violinplot(data=data, x='Attrition_Flag', y='Avg_Open_To_Buy', ax=axes[1])\nviz_1.set_title('Density and distribution of Avg_Open_To_Buy for Attrition_Flag')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,5))\n\nsns.distplot( data[\"Total_Amt_Chng_Q4_Q1\"], bins=50,ax=axes[0]).set_title(\"Total_Amt_Chng_Q4_Q1\")\nviz_1=sns.violinplot(data=data, x='Attrition_Flag', y='Total_Amt_Chng_Q4_Q1', ax=axes[1])\nviz_1.set_title('Density and distribution of Total_Amt_Chng_Q4_Q1 for Attrition_Flag')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,5))\n\nsns.distplot( data[\"Total_Trans_Amt\"], bins=50,ax=axes[0]).set_title(\"Total_Trans_Amt\")\nviz_1=sns.violinplot(data=data, x='Attrition_Flag', y='Total_Trans_Amt', ax=axes[1])\nviz_1.set_title('Density and distribution of Total_Trans_Amt for Attrition_Flag')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,5))\n\nsns.distplot( data[\"Total_Trans_Ct\"], bins=50,ax=axes[0]).set_title(\"Total_Trans_Ct\")\nviz_1=sns.violinplot(data=data, x='Attrition_Flag', y='Total_Trans_Ct', ax=axes[1])\nviz_1.set_title('Density and distribution of Total_Trans_Ct for Attrition_Flag')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,5))\n\nsns.distplot( data[\"Total_Ct_Chng_Q4_Q1\"], bins=50,ax=axes[0]).set_title(\"Total_Ct_Chng_Q4_Q1\")\nviz_1=sns.violinplot(data=data, x='Attrition_Flag', y='Total_Ct_Chng_Q4_Q1', ax=axes[1])\nviz_1.set_title('Density and distribution of Total_Ct_Chng_Q4_Q1 for Attrition_Flag')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,5))\n\nsns.distplot( data[\"Avg_Utilization_Ratio\"], bins=50,ax=axes[0]).set_title(\"Avg_Utilization_Ratio\")\nviz_1=sns.violinplot(data=data, x='Attrition_Flag', y='Avg_Utilization_Ratio', ax=axes[1])\nviz_1.set_title('Density and distribution of Avg_Utilization_Ratio for Attrition_Flag')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part 2: Feature Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(list(data.columns)) \n\ndataset = data.iloc[:,[2,9,10,11,12,13,14,16,17,18,19,20,1]]\n\ndataset.iloc[:,-1] = dataset.iloc[:,-1].replace(\"Attrited Customer\", 1).replace(\"Existing Customer\", 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute the correlation matrix\ncorr = dataset.corr()\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(15, 15))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(250, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, cmap=cmap, mask=mask, vmax=.3, center=0, annot=True, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = dataset.drop(['Months_on_book','Total_Trans_Amt','Total_Amt_Chng_Q4_Q1','Avg_Utilization_Ratio'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute the correlation matrix\ncorr = dataset.corr()\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(15, 15))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(250, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, cmap=cmap, mask=mask, vmax=.3, center=0, annot=True, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Splitting dataset: 60% testing data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dataset.iloc[:, 0:-1].values\ny = dataset.iloc[:, -1].values\n\n# Splitting the dataset into the Training set and Validation set\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.6, random_state = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part 3: Fit Model (Random Forest and XGBoost)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_val = sc.transform(X_val)\n\n# Fitting Random Forest Classifier to the dataset\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 50, random_state = 0)\nclassifier.fit(X_train, y_train)\n# Predicting result for training set and validation set\npredict_train_rf = classifier.predict(X_train)\npredict_val_rf = classifier.predict(X_val)\n\nfrom sklearn.metrics import confusion_matrix\ncm_train = confusion_matrix(y_train, predict_train_rf)\ncm_val = confusion_matrix(y_val, predict_val_rf)\n\n# Model Performance \nfrom sklearn.metrics import accuracy_score, recall_score, precision_score\nprint(\"Train Score : \", accuracy_score(y_train, predict_train_rf) *  100) \nprint(\"Train Recall : \", recall_score(y_train, predict_train_rf) *  100) \nprint(\"Train Precision : \", precision_score(y_train, predict_train_rf) *  100) \nprint(\"Val Score : \", accuracy_score(y_val, predict_val_rf) *  100) \nprint(\"Val Recall : \", recall_score(y_val, predict_val_rf) *  100) \nprint(\"Val Precision : \", precision_score(y_val, predict_val_rf) *  100) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nclassifier = XGBClassifier()\nclassifier.fit(X_train, y_train)\npredict_train_xgb = classifier.predict(X_train)\npredict_val_xgb = classifier.predict(X_val)\n\n# Model Performance \nprint(\"Train Score : \", accuracy_score(y_train, predict_train_xgb) *  100) \nprint(\"Train Recall : \", recall_score(y_train, predict_train_xgb) *  100) \nprint(\"Train Precision : \", precision_score(y_train, predict_train_xgb) *  100) \nprint(\"Val Score : \", accuracy_score(y_val, predict_val_xgb) *  100) \nprint(\"Val Recall : \", recall_score(y_val, predict_val_xgb) *  100) \nprint(\"Val Precision : \", precision_score(y_val, predict_val_xgb) *  100) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Upsampling**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import resample\nprint('Number of class 1 samples before:',\n     X_train[y_train==1].shape[0])\n\nX_train_upsampled, y_train_upsampled = resample(X_train[y_train == 1], \n                                                y_train[y_train == 1],\n                                                replace=True,\n                                                n_samples=X_train[y_train == 0].shape[0],\n                                                random_state=123)\n\nprint('Number of class 1 samples after:',\n     X_train_upsampled.shape[0])\n\nX_train_bal = np.vstack((X_train[y_train==0], X_train_upsampled))\ny_train_bal = np.hstack((y_train[y_train==0], y_train_upsampled))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting Random Forest Classifier to the dataset\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 50, random_state = 0)\nclassifier.fit(X_train_bal, y_train_bal)\n# Predicting result for training set and validation set\npredict_train_bal_rf = classifier.predict(X_train_bal)\npredict_val_bal_rf = classifier.predict(X_val)\n\n# Model Performance \nprint(\"Train Score : \", accuracy_score(y_train_bal, predict_train_bal_rf) *  100) \nprint(\"Train Recall : \", recall_score(y_train_bal, predict_train_bal_rf) *  100) \nprint(\"Train Precision : \", precision_score(y_train_bal, predict_train_bal_rf) *  100) \nprint(\"Val Score : \", accuracy_score(y_val, predict_val_rf) *  100) \nprint(\"Val Recall : \", recall_score(y_val, predict_val_rf) *  100) \nprint(\"Val Precision : \", precision_score(y_val, predict_val_rf) *  100) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nclassifier = XGBClassifier()\nclassifier.fit(X_train_bal, y_train_bal)\npredict_train_bal_xgb = classifier.predict(X_train_bal)\npredict_val_bal_xgb = classifier.predict(X_val)\n\n# Model Performance \nprint(\"Train Score : \", accuracy_score(y_train_bal, predict_train_bal_xgb) *  100) \nprint(\"Train Recall : \", recall_score(y_train_bal, predict_train_bal_xgb) *  100) \nprint(\"Train Precision : \", precision_score(y_train_bal, predict_train_bal_xgb) *  100) \nprint(\"Val Score : \", accuracy_score(y_val, predict_val_bal_xgb) *  100) \nprint(\"Val Recall : \", recall_score(y_val, predict_val_bal_xgb) *  100) \nprint(\"Val Precision : \", precision_score(y_val, predict_val_bal_xgb) *  100) \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part 4: Result Summary"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report \nprint(\"RandomForest Model: \")\nprint(classification_report(y_val, predict_val_rf, target_names=[\"Existing Customer\",\"Attrited Customer\"]))\nprint(\"XGBoost Model: \")\nprint(classification_report(y_val, predict_val_xgb, target_names=[\"Existing Customer\",\"Attrited Customer\"]))\nprint(\"Upsampled RandomForest Model: \")\nprint(classification_report(y_val, predict_val_bal_rf, target_names=[\"Existing Customer\",\"Attrited Customer\"]))\nprint(\"Upsampled XGBoost Model: \")\nprint(classification_report(y_val, predict_val_bal_xgb, target_names=[\"Existing Customer\",\"Attrited Customer\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training Set\ntotal = len(y_train) \n  \n# Counting '1' labels in test data \none_count = np.sum(y_train) \n  \n# counting '0' lables in test data  \nzero_count = total - one_count \n  \nplt.figure(figsize = (10, 6)) \n  \n# x-axis ranges from 0 to total number of data\n# y-axis ranges from 0 to the total defaulters. \n  \nplt.plot([0, total], [0, one_count], c = 'b',  \n         linestyle = '--', label = 'Random Model') \n\n\nplt.plot([0, one_count, total], [0, one_count, one_count], \n         c = 'grey', linewidth = 2, label = 'Perfect Model') \n\nlm = [y for _, y in sorted(zip(predict_train_xgb, y_train), reverse = True)] \nx = np.arange(0, total + 1) \ny = np.append([0], np.cumsum(lm)) \nplt.plot(x, y, c = 'b', label = 'XGBoost', linewidth = 2) \n\nlm = [y for _, y in sorted(zip(predict_train_rf, y_train), reverse = True)] \nx = np.arange(0, total + 1) \ny = np.append([0], np.cumsum(lm)) \nplt.plot(x, y, c = 'red', label = 'Random Forest', linewidth = 2) \n\nplt.legend() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training Set\ntotal = len(y_train_bal) \n  \n# Counting '1' labels in test data \none_count = np.sum(y_train_bal) \n  \n# counting '0' lables in test data  \nzero_count = total - one_count \n  \nplt.figure(figsize = (10, 6)) \n  \n# x-axis ranges from 0 to total number of data\n# y-axis ranges from 0 to the total defaulters. \n  \nplt.plot([0, total], [0, one_count], c = 'b',  \n         linestyle = '--', label = 'Random Model') \n\n\nplt.plot([0, one_count, total], [0, one_count, one_count], \n         c = 'grey', linewidth = 2, label = 'Perfect Model') \n\nlm = [y for _, y in sorted(zip(predict_train_bal_xgb, y_train_bal), reverse = True)] \nx = np.arange(0, total + 1) \ny = np.append([0], np.cumsum(lm)) \nplt.plot(x, y, c = 'b', label = 'XGBoost', linewidth = 2) \n\nlm = [y for _, y in sorted(zip(predict_train_bal_rf, y_train_bal), reverse = True)] \nx = np.arange(0, total + 1) \ny = np.append([0], np.cumsum(lm)) \nplt.plot(x, y, c = 'red', label = 'Random Forest', linewidth = 2) \n\nplt.legend() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training Set\ntotal = len(y_val) \n  \n# Counting '1' labels in test data \none_count = np.sum(y_val) \n  \n# counting '0' lables in test data  \nzero_count = total - one_count \n  \nplt.figure(figsize = (10, 6)) \n  \n# x-axis ranges from 0 to total number of data\n# y-axis ranges from 0 to the total defaulters. \n  \nplt.plot([0, total], [0, one_count], c = 'b',  \n         linestyle = '--', label = 'Random Model') \n\n\nplt.plot([0, one_count, total], [0, one_count, one_count], \n         c = 'grey', linewidth = 2, label = 'Perfect Model') \n\nlm = [y for _, y in sorted(zip(predict_val_xgb, y_val), reverse = True)] \nx = np.arange(0, total + 1) \ny = np.append([0], np.cumsum(lm)) \nplt.plot(x, y, c = 'green', label = 'XGBoost', linewidth = 2) \n\nlm = [y for _, y in sorted(zip(predict_val_rf, y_val), reverse = True)] \nx = np.arange(0, total + 1) \ny = np.append([0], np.cumsum(lm)) \nplt.plot(x, y, c = 'red', label = 'Random Forest', linewidth = 2) \n\nlm = [y for _, y in sorted(zip(predict_val_bal_xgb, y_val), reverse = True)] \nx = np.arange(0, total + 1) \ny = np.append([0], np.cumsum(lm)) \nplt.plot(x, y, c = 'blue', label = 'XGBoost upsampled', linewidth = 2) \n\nlm = [y for _, y in sorted(zip(predict_val_bal_rf, y_val), reverse = True)] \nx = np.arange(0, total + 1) \ny = np.append([0], np.cumsum(lm)) \nplt.plot(x, y, c = 'purple', label = 'Random Forest upsampled', linewidth = 2) \n\nplt.legend() ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}