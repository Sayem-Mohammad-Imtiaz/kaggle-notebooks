{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Import Libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set(style=\"darkgrid\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/lead-scoring-x-online-education/Leads X Education.csv\")\npd.set_option(\"display.max_columns\",0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum().sort_values(ascending=False).head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check Numeric and Categorical Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_col = df.select_dtypes(exclude =[\"number\"]).drop(\"Prospect ID\", axis=1).columns.values\nnumerical_col = df.select_dtypes(include =[\"number\"]).drop(\"Lead Number\", axis=1).columns.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"CATEGORICAL FEATURES : \\n {} \\n\\n\".format(categorical_col))\nprint(\"NUMERICAL FEATURES : \\n {} \".format(numerical_col))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[numerical_col].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[categorical_col].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check Data and Missing Values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def Cat_info(df, categorical_column):\n    df_result = pd.DataFrame(columns=[\"columns\",\"values\",\"unique_values\",\"null_values\",\"null_percent\"])\n    \n    df_temp=pd.DataFrame()\n    for value in categorical_column:\n        df_temp[\"columns\"] = [value]\n        df_temp[\"values\"] = [df[value].unique()]\n        df_temp[\"unique_values\"] = df[value].nunique()\n        df_temp[\"null_values\"] = df[value].isna().sum()\n        df_temp[\"null_percent\"] = (df[value].isna().sum()/len(df)*100).round(1)\n        df_result = df_result.append(df_temp)\n    \n    df_result.sort_values(\"null_values\", ascending =False, inplace=True)\n    df_result.set_index(\"columns\", inplace=True)\n    return df_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cat = Cat_info(df, categorical_col)\ndf_cat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Num_info(df, numerical_column):\n    df_result = pd.DataFrame(columns=[\"columns\",\"unique_values\",\"null_values\",\"null_percent\"])\n    \n    df_temp=pd.DataFrame()\n    for value in numerical_column:\n        df_temp[\"columns\"] = [value]\n        df_temp[\"unique_values\"] = df[value].nunique()\n        df_temp[\"null_values\"] = df[value].isna().sum()\n        df_temp[\"null_percent\"] = (df[value].isna().sum()/len(df)*100).round(1)\n        df_result = df_result.append(df_temp)\n\n    df_result.sort_values(\"null_values\", ascending =False, inplace=True)\n    df_result.set_index(\"columns\", inplace=True)\n    return df_result","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df_num = Num_info(df, numerical_col)\ndf_num","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check for Class Imbalance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"No of Converted clients out of 9240: \\n{}\\n\".format(df[\"Converted\"].value_counts()))\nprint(\"Percentage of Converted clients: \\n{}\".format((df[\"Converted\"].value_counts()/9240*100).round(2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Detect Outliers in Continuous Columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def Detect_outliers(df,col):\n    df_outliers = pd.DataFrame(columns = [\"columns\", \"outliers\",\"lower_fence\",\"higher_fence\"])\n    df_temp = pd.DataFrame()\n    for column in col:\n        q1 = df[column].quantile(0.25)\n        q3 = df[column].quantile(0.75)\n        iqr = q3-q1\n        fence_low = q1 - (iqr*1.5)\n        fence_high = q3 + (iqr*1.5)\n        outlier = df[column][((df[column]>fence_high) | (df[column]<fence_low))].count() \n        df_temp[\"outliers\"] = [outlier]\n        df_temp[\"columns\"] = column\n        df_temp[\"lower_fence\"] = fence_low\n        df_temp[\"higher_fence\"] = fence_high\n        df_outliers = df_outliers.append(df_temp)\n    df_outliers.set_index(\"columns\", inplace=True)\n    df_outliers.sort_values(\"outliers\", ascending=False, inplace=True)\n    return df_outliers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"continuous_col = ['TotalVisits', 'Total Time Spent on Website',\n                 'Page Views Per Visit', 'Asymmetrique Activity Score',\n                 'Asymmetrique Profile Score']\ndf_out = Detect_outliers(df,continuous_col)\ndf_out ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Observations : \n- There are null values in majority of the columns.\n- The class distribution in the target is ~61:39. This is an indication of some imbalance.\n- As per the IQR methodology, there are outliers in 3 columns.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# EDA & DATA VISUALIZATION","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Univariate analysis of Categorical columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data =df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fill_missing_values(df,col,n):\n    for column in col:\n        if n is \"mean\":\n            df[column].fillna(df[column].mean(), inplace=True)\n        elif n is \"mode\":\n            df[column].fillna(df[column].mode(), inplace=True)\n        elif n is \"median\":\n            df[column].fillna(df[column].median(), inplace=True)\n        elif n is \"missing\":\n            df[column].fillna(\"---Missing---\", inplace=True)\n        else:\n            print(\"Enter 'mean','median','mode' or 'missing'\")\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fill_missing_values(data,categorical_col,\"missing\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_categorical(df,col,num):\n    for column in col:\n        if (df[column].nunique()<num) and (df[column].nunique()!=1) :\n            fig, (ax1, ax2)= plt.subplots(1,2, figsize=(15,5))\n            sns.countplot(df[column],ax=ax1, palette=\"husl\")\n            ax1.set_xticklabels(ax1.get_xticklabels(), rotation=90)\n            sns.countplot(df[column],hue=df[\"Converted\"],ax=ax2)\n            ax2.set_xticklabels(ax1.get_xticklabels(), rotation=90)\n            ax2.set_ylabel(\"\")\n            ax2.legend([\"NOT CONVERTED\",\"CONVERTED\"],loc=\"upper right\")\n    for column in col:\n        if df[column].nunique()>=num:\n            fig, (ax1, ax2)= plt.subplots(2,1, figsize=(15,8))\n            sns.countplot(df[column],ax=ax1, palette=\"husl\")\n            ax1.set_xticklabels([])\n            ax1.set_xlabel(\"\")\n            sns.countplot(df[column],hue=df[\"Converted\"],ax=ax2)\n            ax2.set_xticklabels(ax1.get_xticklabels(), rotation=90)\n            ax2.legend([\"NOT CONVERTED\",\"CONVERTED\"], loc=\"upper right\")","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"sns.color_palette(\"husl\")\nsns.set_context('talk')\nplot_categorical(data, categorical_col,10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Observtions\n\n##### Conversion ratio is very high for\n1. Lead Add Form : LEAD ORIGIN\n2. Working Professional: OCCUPATION\n3. Reference: LEAD SOURCE\n\n##### Other observations\n- Conversion is there but very little from people who chose “Do not Email”\n- All cities seems to have almost same conversion rate\n- People having different specialisation doesn’t seem to impact the conversion rate.\n- People who asks for mail after the call are more probable to convert.\n- Mostly all prospects are from India, therefore we will try to map every other nation to \"Abroad\".\n- Missing values are showing very different conversion rate compared to others.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot('Total Time Spent on Website',\n                 'TotalVisits',df, kind =\"reg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for columns in numerical_col:\n    fig, (ax1, ax2)= plt.subplots(1,2, figsize=(15,5))\n    #sns.hist(df[\"Converted\"],ax=ax1, palette=\"husl\")\n    #ax1.set_xticklabels(ax1.get_xticklabels(), rotation=90)\n    #sns.countplot(df[\"Total Visits\"],hue=df[\"Converted\"],ax=ax2)\n    #ax2.set_xticklabels(ax1.get_xticklabels(), rotation=90)\n    sns.boxplot(data=df, x=columns, ax=ax1)\n    sns.distplot(df[columns],ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Observation :\n\n- As we can see from the histogram, the features `Total Visits`and `Page Views Per Visit` are heavily skewed and this is due to the presence of outliers as seen in the boxplot for these features.\n- 'Asymmetrique Activity Score' and 'Asymmetrique Profile Score' are the features with no information given as per the feature description.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_context(\"paper\")\nsns.pairplot(df[numerical_col],hue=\"Converted\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CLEANING DATA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.drop([\"Prospect ID\",\"Lead Number\"], axis=1, inplace=True)\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fill_missing_values(dataset,categorical_col,\"missing\") # Replaced with \"Missing\" as missing values are showing very different characterstics\nfill_missing_values(dataset,numerical_col,\"median\") #Median as there are a lot of outliers\ndataset[\"Country\"][(dataset[\"Country\"]!=\"India\") & (dataset[\"Country\"]!=\"Missing\")]=\"Others\" # People from abroad are almost negligible in number\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.get_dummies(dataset,drop_first=True)\ndataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Applying Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import confusion_matrix,roc_auc_score, classification_report, roc_curve, precision_recall_curve\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import recall_score, f1_score, precision_score\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score\nfrom imblearn.over_sampling import SMOTE\n\n!pip install imblearn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seprating dependant and independant data\nX = dataset.iloc[:,1:]\ny = dataset.iloc[:,0]\n\nss = StandardScaler()\nss.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to analyse all model without oversampling\ndef run_model(X, y, models):\n    \n    X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2, random_state=20)\n    \n    for model in models:\n        m = model()\n        m.fit(X_train, y_train)\n        y_pred = m.predict(X_test)\n        fpr, tpr, threshold = roc_curve(y_test,y_pred)\n        print(str(model)+ \"\\n\")\n        print(\"CONFUSION MATRIX: \\n{}\\n\".format(confusion_matrix(y_test,y_pred)))\n        print(\"CLASSIFICATION REPORT: \\n{} \".format(classification_report(y_test,y_pred)))\n        print(\"MODEL SCORE: {}\".format(m.score(X_test,y_test)))\n        print(\"ROC AUC SCORE: {}\\n \".format(roc_auc_score(y_test,y_pred)))\n        \n        print(\"RECALL: \\n{}\\n \".format(cross_val_score(m,X,y,scoring=\"recall\").mean()))\n        plt.plot(fpr, tpr)\n        plt.show()\n        precision, recall, thresholds=precision_recall_curve(y_test,y_pred)\n        print(precision)\n        print(recall)\n        print(thresholds)\n        print(\"====\"*20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#models = {\"RandomForestClassifier\": RandomForestClassifier()}\nmodels = [LogisticRegression,DecisionTreeClassifier,RandomForestClassifier, \n          AdaBoostClassifier, GradientBoostingClassifier,XGBClassifier]\nrun_model(X,y,models)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### After SMOTE (upsampling)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to analyse all model with oversampling\ndef run_model_balanced(X, y, models):\n    \n    \n    X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2, random_state=20)\n    \n    \n    smote=SMOTE()\n    b_X,b_y = smote.fit_sample(X_train,y_train)\n    \n    for model in models:\n        m = model()\n        m.fit(b_X, b_y)\n        y_pred = m.predict(X_test)\n        fpr, tpr, threshold = roc_curve(y_test,y_pred)\n        print(str(model)+ \"\\n\")\n        print(\"CONFUSION MATRIX: \\n{}\\n\".format(confusion_matrix(y_test,y_pred)))\n        print(\"CLASSIFICATION REPORT: \\n{} \".format(classification_report(y_test,y_pred)))\n        print(\"MODEL SCORE: {}\".format(m.score(X_test,y_test)))\n        print(\"ROC AUC SCORE: {}\\n \".format(roc_auc_score(y_test,y_pred)))\n        print(\"RECALL: \\n{}\\n \".format(cross_val_score(m,X,y,scoring=\"recall\").mean()))\n        plt.plot(fpr, tpr)\n        plt.show()\n        print(\"====\"*20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [LogisticRegression,DecisionTreeClassifier,RandomForestClassifier, \n          AdaBoostClassifier, GradientBoostingClassifier,XGBClassifier]\nrun_model_balanced(X,y,models)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observation\n- We are using random forest classifier as it shows best recall after cross validation\n- Random forest is predicting with best recall value.(with cross validation)\n- Score with and without oversampling is almost identical. We cannot call this dataset imbalanced(ratio-39:61). So no need to oversample.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Hyperparameter tuning \n- Some details about hyperparameters and it's tuning:\nhttps://www.analyticsvidhya.com/blog/2020/03/beginners-guide-random-forest-hyperparameter-tuning/\n\nWe will analyse three models (first two only for knowledge)\n- Random Forest Classifier\n- XGB Classifier\n- Logistic Classifier (To solve the problem in hand)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"param={     \"n_estimators\":[int(x) for x in np.linspace(start = 10, stop = 190, num = 10) ],\n            #\"criterion\":['gini','entropy'],\n            \"max_depth\":[int(x) for x in np.linspace(50, 500, num = 6)],\n            # \"min_samples_split\":[2, 5, 10],\n            # \"min_samples_leaf\":[1, 2, 4],\n            \"max_features\":['sqrt',\"log2\"],\n            # \"max_samples\": [0.1,0.2,0.3],\n            # \"max_leaf_nodes\": [25,50,75]     \n      }\n\nrf_classifier = RandomForestClassifier()\ncv = RandomizedSearchCV(rf_classifier,param, verbose=2, scoring=\"recall\", refit=\"recall\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2, random_state=20)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"cv.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv.best_params_ #random","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_rf = RandomForestClassifier(n_estimators=170, max_depth= 230, max_features= \"sqrt\")\nclassifier_rf.fit(X_train,y_train)\ny_pred=classifier_rf.predict(X_test)\nfpr, tpr, threshold = roc_curve(y_test,y_pred)\nprint(\"CONFUSION MATRIX: \\n{}\\n\".format(confusion_matrix(y_test,y_pred)))\nprint(\"CLASSIFICATION REPORT: \\n{} \".format(classification_report(y_test,y_pred)))\nprint(\"MODEL SCORE: {}\".format(classifier_rf.score(X_test,y_test)))\nprint(\"ROC AUC SCORE: {}\\n \".format(roc_auc_score(y_test,y_pred)))\nprint(\"RECALL: \\n{}\\n \".format(recall_score(y_test,y_pred)))\nplt.plot(fpr, tpr)\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Series(classifier_rf.feature_importances_, index=X.columns).sort_values(ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XGB Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Hyper Parameter Optimization\nparams={\n \"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n \"min_child_weight\" : [ 1, 3, 5, 7 ],\n \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]  \n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier=XGBClassifier()\nrandom_search=RandomizedSearchCV(classifier,param_distributions=params,n_iter=5,scoring='recall', n_jobs=-1,cv=5,verbose=2)\nrandom_search.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_xgb = XGBClassifier(colsample_bytree=0.4, gamma=0.1, learning_rate=0.25,min_child_weight=3)\n\nclassifier_xgb.fit(X_train,y_train)\ny_pred=classifier_xgb.predict(X_test)\nfpr, tpr, threshold = roc_curve(y_test,y_pred)\nprint(\"CONFUSION MATRIX: \\n{}\\n\".format(confusion_matrix(y_test,y_pred)))\nprint(\"CLASSIFICATION REPORT: \\n{} \".format(classification_report(y_test,y_pred)))\nprint(\"MODEL SCORE: {}\".format(classifier_xgb.score(X_test,y_test)))\nprint(\"ROC AUC SCORE: {}\\n \".format(roc_auc_score(y_test,y_pred)))\nprint(\"RECALL: \\n{}\\n \".format(recall_score(y_test,y_pred)))\nplt.plot(fpr, tpr)\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Series(classifier_xgb.feature_importances_, index=X.columns).sort_values(ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression\n\n##### Threshold\n- We will find out the threshold for which we can get maximum recall value with precision more than 80%.\n- We will find these score on train dataset so that we dont overfit the model for predicting threshold.\n\n##### Scoring\n- Then we will generate a function to give scores to the leads.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_log = LogisticRegression()\nclassifier_log.fit(X_train, y_train)\ny_pred_prob_log = classifier_log.predict_proba(X_train)\ny_pred_prob_log = y_pred_prob_log[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_labels(pos_probs, threshold):\n    return (pos_probs >= threshold).astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thresholds = np.arange(0, 1, 0.001)\nscores_recall = [recall_score(y_train, to_labels(y_pred_prob_log, t)) for t in thresholds]\nscores_precision = [precision_score(y_train, to_labels(y_pred_prob_log, t)) for t in thresholds]\ndata = {\"thresholds\": thresholds,\"recall\":scores_recall,\"precision\":scores_precision}\nfinal_df = pd.DataFrame(data)\nfinal_df = final_df[final_df.precision>=0.8]\n\nfinal_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"THRESHOLD=0.208\nfinal_y_pred = classifier_log.predict_proba(X_test)\nfinal_y_pred = np.where(final_y_pred[:,1]>THRESHOLD,1,0)\n\nfpr, tpr, threshold = roc_curve(y_test,final_y_pred)\nprint(\"CONFUSION MATRIX: \\n{}\\n\".format(confusion_matrix(y_test,final_y_pred)))\nprint(\"CLASSIFICATION REPORT: \\n{} \".format(classification_report(y_test,final_y_pred)))\nprint(\"ROC AUC SCORE: {}\\n \".format(roc_auc_score(y_test,final_y_pred)))\nprint(\"RECALL: \\n{}\\n \".format(recall_score(y_test,final_y_pred)))\nprint(\"PRECISION: \\n{}\\n \".format(precision_score(y_test,final_y_pred)))\nplt.plot(fpr, tpr)\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Observation\n- Threshold for max recall with precision greater than 80% is 0.208\n- Precision for test dataset is approximately 79% which is very much acceptable.\n- Hence, 0.208 is the threshold we will use for Logistic Classification","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def lead_score(X):\n    score = pd.Series((classifier_log.predict_proba(X)[:,1]*100).round(), name=\"score\")\n    X = pd.concat([X,score], axis=1)\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leadscore = lead_score(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leadscore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"leadscore[\"score\"]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}