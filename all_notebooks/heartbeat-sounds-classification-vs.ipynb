{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from numpy.random import seed\nseed(9)\n# import tensorflow\n# tensorflow.random.set_seed(9)\nimport pandas as pd       \nimport numpy as np\nimport matplotlib.pyplot as plt    \nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-07-06T10:28:41.467458Z","iopub.execute_input":"2021-07-06T10:28:41.467788Z","iopub.status.idle":"2021-07-06T10:28:41.471658Z","shell.execute_reply.started":"2021-07-06T10:28:41.46776Z","shell.execute_reply":"2021-07-06T10:28:41.470955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-05T11:27:58.523058Z","iopub.execute_input":"2021-07-05T11:27:58.523606Z","iopub.status.idle":"2021-07-05T11:27:58.665317Z","shell.execute_reply.started":"2021-07-05T11:27:58.523554Z","shell.execute_reply":"2021-07-05T11:27:58.65966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us import additional packages and all the audio files from set_b folder. The files form a collection of heartbeat sounds. Hearts normally have a predictable sound pattern as they beat, but some disorders can cause the heart to beat abnormally. ","metadata":{}},{"cell_type":"code","source":"import librosa as lr\nfrom glob import glob\n\n# List all the wav files in the folder\naudio_files = glob('/kaggle/input/heartbeat-sounds/set_b/' + '/*.wav')\nlen(audio_files)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:27:58.674406Z","iopub.execute_input":"2021-07-05T11:27:58.674798Z","iopub.status.idle":"2021-07-05T11:27:58.691026Z","shell.execute_reply.started":"2021-07-05T11:27:58.674762Z","shell.execute_reply":"2021-07-05T11:27:58.688894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us inspect teh first audio file.","metadata":{}},{"cell_type":"code","source":"# First audio file\nprint(audio_files[0])\nlr.load(audio_files[0])","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:27:58.69367Z","iopub.execute_input":"2021-07-05T11:27:58.694039Z","iopub.status.idle":"2021-07-05T11:27:58.777329Z","shell.execute_reply.started":"2021-07-05T11:27:58.694004Z","shell.execute_reply":"2021-07-05T11:27:58.775751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us load the file, create tiem points and visualize.","metadata":{}},{"cell_type":"code","source":"# Read in the first audio file, create the time array\naudio, sfreq = lr.load(audio_files[0])\nprint(audio,'\\n')\nprint(len(audio),'\\n')\nprint(sfreq,'\\n')\n\nindexes = np.arange(audio.shape[-1])\ntime_points = indexes/ sfreq\nprint(time_points,'\\n')\nprint(len(time_points))","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:27:58.779312Z","iopub.execute_input":"2021-07-05T11:27:58.779636Z","iopub.status.idle":"2021-07-05T11:27:58.861682Z","shell.execute_reply.started":"2021-07-05T11:27:58.779606Z","shell.execute_reply":"2021-07-05T11:27:58.860436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot audio over time\nfig, ax = plt.subplots(figsize = (15,5))\nax.plot(time_points, audio)\nax.set(xlabel='Time (s)', ylabel='Sound Amplitude')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:27:58.863028Z","iopub.execute_input":"2021-07-05T11:27:58.863377Z","iopub.status.idle":"2021-07-05T11:27:59.088006Z","shell.execute_reply.started":"2021-07-05T11:27:58.863345Z","shell.execute_reply":"2021-07-05T11:27:59.08644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some audios are normal heartbeat activity, while others are abnormal activity. Let's see if we can spot the difference.","metadata":{}},{"cell_type":"code","source":"normal_files = glob('/kaggle/input/heartbeat-sounds/set_b/' + '/normal*.wav')\naudio0_n, sfreq0_n = lr.load(normal_files[0])\naudio1_n, sfreq1_n = lr.load(normal_files[1])\naudio2_n, sfreq2_n = lr.load(normal_files[2])\ntime_n = np.arange(0, len(audio1_n)) / sfreq1_n\nprint(len(audio0_n),sfreq0_n,'\\n', len(audio1_n),sfreq1_n,'\\n',len(audio2_n),sfreq2_n)\nprint(time_n.shape)\nprint(time_n)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:27:59.089545Z","iopub.execute_input":"2021-07-05T11:27:59.089895Z","iopub.status.idle":"2021-07-05T11:27:59.357965Z","shell.execute_reply.started":"2021-07-05T11:27:59.089862Z","shell.execute_reply":"2021-07-05T11:27:59.356723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"normal= pd.DataFrame(data=[audio0_n, audio1_n, audio2_n, time_n]).T\nnormal.columns = ['0','1', '2', 'time']\nnormal = normal.set_index('time')\n# let us consider 100000 time points only\nnormal = normal.iloc[:100000,]\ndisplay(normal.shape)\nnormal.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:27:59.359434Z","iopub.execute_input":"2021-07-05T11:27:59.35979Z","iopub.status.idle":"2021-07-05T11:28:07.602135Z","shell.execute_reply.started":"2021-07-05T11:27:59.359754Z","shell.execute_reply":"2021-07-05T11:28:07.601023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"abnormal_files = glob('/kaggle/input/heartbeat-sounds/set_b/' + '/murmur*.wav')\naudio0_an, sfreq0_an = lr.load(abnormal_files[0])\naudio1_an, sfreq1_an = lr.load(abnormal_files[1])\naudio2_an, sfreq2_an = lr.load(abnormal_files[2])\ntime_an = np.arange(0, len(audio2_an)) / sfreq2_an\nprint(len(audio0_an),sfreq0_an,'\\n', len(audio1_an),sfreq1_an,'\\n',len(audio2_an),sfreq2_an)\nprint(time_an.shape)\nprint(time_an)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:28:07.604805Z","iopub.execute_input":"2021-07-05T11:28:07.605268Z","iopub.status.idle":"2021-07-05T11:28:07.991103Z","shell.execute_reply.started":"2021-07-05T11:28:07.60523Z","shell.execute_reply":"2021-07-05T11:28:07.989896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"abnormal= pd.DataFrame(data=[audio0_an, audio1_an, audio2_an, time_an]).T\nabnormal.columns = ['0','1', '2', 'time']\nabnormal = abnormal.set_index('time')\n# let us consider 100000 time points only\nabnormal = abnormal.iloc[:100000,]\ndisplay(abnormal.shape)\nabnormal.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:28:07.993797Z","iopub.execute_input":"2021-07-05T11:28:07.994296Z","iopub.status.idle":"2021-07-05T11:28:19.411195Z","shell.execute_reply.started":"2021-07-05T11:28:07.994245Z","shell.execute_reply":"2021-07-05T11:28:19.41009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_plot_and_make_titles():\n    axs[0, 0].set(title=\"Normal Heartbeats\")\n    axs[0, 1].set(title=\"Abnormal Heartbeats\")\n    ax.set(xlabel='Time (s)', ylabel='Sound Amplitude')\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:28:19.41253Z","iopub.execute_input":"2021-07-05T11:28:19.41283Z","iopub.status.idle":"2021-07-05T11:28:19.418452Z","shell.execute_reply.started":"2021-07-05T11:28:19.4128Z","shell.execute_reply":"2021-07-05T11:28:19.41743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(3, 2, figsize=(15, 7), sharex=True, sharey=True)\n\n# Calculate the time array\ntime = np.arange(0,100000) / sfreq2_an\ndisplay(time.shape)\n\n# Stack the normal/abnormal audio so you can loop and plot\nstacked_audio = np.hstack([normal, abnormal]).T\ndisplay(stacked_audio)\ndisplay(stacked_audio.shape )\n\n# Loop through each audio file / ax object and plot\n# .T.ravel() transposes the array, then unravels it into a 1-D vector for looping\nfor iaudio, ax in zip(stacked_audio, axs.T.ravel()):\n    ax.plot(time, iaudio)\n    show_plot_and_make_titles()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:28:19.41971Z","iopub.execute_input":"2021-07-05T11:28:19.420028Z","iopub.status.idle":"2021-07-05T11:28:21.104658Z","shell.execute_reply.started":"2021-07-05T11:28:19.419996Z","shell.execute_reply":"2021-07-05T11:28:21.103422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualizing our raw data is somewhat often uninformative when it comes to discriminating between two classes of data points. Data is usually noisy or exhibits complex patterns that aren't discoverable by the naked eye.\n\nAcommon technique to find simple differences between two sets of data is to average across multiple instances of the same class. This may remove noise and reveal underlying patterns.","metadata":{}},{"cell_type":"code","source":"# Average across the audio files of each DataFrame\nmean_normal = np.mean(normal, axis=1)\nmean_abnormal = np.mean(abnormal, axis=1)\n\n# Plot each average over time\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3), sharey=True)\nax1.plot(time, mean_normal)\nax1.set(title=\"Normal Data\")\nax2.plot(time, mean_abnormal)\nax2.set(title=\"Abnormal Data\")\nax1.set(xlabel='Time (s)', ylabel='Sound Amplitude')\nax2.set(xlabel='Time (s)')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:28:21.106726Z","iopub.execute_input":"2021-07-05T11:28:21.107114Z","iopub.status.idle":"2021-07-05T11:28:21.442268Z","shell.execute_reply.started":"2021-07-05T11:28:21.107072Z","shell.execute_reply":"2021-07-05T11:28:21.441197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will use each repetition as a datapoint, and each moment in time as a feature to fit a classifier that attempts to predict abnormal vs. normal heartbeats using only the raw data. First we will start with normal files to create our required dataset.","metadata":{}},{"cell_type":"code","source":"audio_n = []\nsfreq_n = []\nfor i in range(len(normal_files)):\n    aud, sfr = lr.load(normal_files[i])\n    audio_n.append(aud)\n    sfreq_n.append(sfr)\ntime_n = np.arange(0, len(audio_n[0])) / sfreq_n[0]\nprint(time_n.shape)\nprint(len(audio_n))\nprint(len(sfreq_n))","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:28:21.443784Z","iopub.execute_input":"2021-07-05T11:28:21.444104Z","iopub.status.idle":"2021-07-05T11:29:10.483397Z","shell.execute_reply.started":"2021-07-05T11:28:21.444071Z","shell.execute_reply":"2021-07-05T11:29:10.482186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"audio_n.append(time_n)\ncols=np.arange(len(normal_files)).tolist()\ncols.append('time')\nnormal= pd.DataFrame(data=audio_n).T\nnormal.columns = cols\nnormal.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:29:10.485568Z","iopub.execute_input":"2021-07-05T11:29:10.486044Z","iopub.status.idle":"2021-07-05T11:30:50.361383Z","shell.execute_reply.started":"2021-07-05T11:29:10.486004Z","shell.execute_reply":"2021-07-05T11:30:50.358489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(normal.shape)\nmax([len(a) for a in audio_n])","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:30:50.364054Z","iopub.execute_input":"2021-07-05T11:30:50.364429Z","iopub.status.idle":"2021-07-05T11:30:50.383491Z","shell.execute_reply.started":"2021-07-05T11:30:50.364391Z","shell.execute_reply":"2021-07-05T11:30:50.379835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"normal = normal.set_index('time')\n# let us consider 50000 time points only\nnormal = normal.iloc[:50000,]\ndisplay(normal.shape)\nnormal.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:30:50.386601Z","iopub.execute_input":"2021-07-05T11:30:50.3872Z","iopub.status.idle":"2021-07-05T11:31:00.967198Z","shell.execute_reply.started":"2021-07-05T11:30:50.387126Z","shell.execute_reply":"2021-07-05T11:31:00.965837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nml = normal.T\nnml['type'] = 'Normal'\ndisplay(nml.shape)\ndisplay(nml.head())","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:31:00.969478Z","iopub.execute_input":"2021-07-05T11:31:00.970394Z","iopub.status.idle":"2021-07-05T11:31:01.029431Z","shell.execute_reply.started":"2021-07-05T11:31:00.970318Z","shell.execute_reply":"2021-07-05T11:31:01.027902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we will repeat the above steps for abnormal files too.","metadata":{}},{"cell_type":"code","source":"audio_an = []\nsfreq_an = []\nfor i in range(len(abnormal_files)):\n    aud, sfr = lr.load(abnormal_files[i])\n    audio_an.append(aud)\n    sfreq_an.append(sfr)\ntime_an = np.arange(0, len(audio_an[0])) / sfreq_an[0]\nprint(time_an.shape)\nprint(len(audio_an))\nprint(len(sfreq_an))","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:31:01.03124Z","iopub.execute_input":"2021-07-05T11:31:01.031658Z","iopub.status.idle":"2021-07-05T11:31:19.159092Z","shell.execute_reply.started":"2021-07-05T11:31:01.03162Z","shell.execute_reply":"2021-07-05T11:31:19.157909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"audio_an.append(time_an)\ncols=np.arange(len(abnormal_files)).tolist()\ncols.append('time')\nabnormal= pd.DataFrame(data=audio_an).T\nabnormal.columns = cols\nabnormal.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:31:19.160481Z","iopub.execute_input":"2021-07-05T11:31:19.160808Z","iopub.status.idle":"2021-07-05T11:32:13.000381Z","shell.execute_reply.started":"2021-07-05T11:31:19.160776Z","shell.execute_reply":"2021-07-05T11:32:12.999209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"abnormal = abnormal.set_index('time')\n# let us consider 50000 time points only\nabnormal = abnormal.iloc[:50000,]\ndisplay(abnormal.shape)\nabnormal.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:32:13.002073Z","iopub.execute_input":"2021-07-05T11:32:13.002864Z","iopub.status.idle":"2021-07-05T11:32:14.202836Z","shell.execute_reply.started":"2021-07-05T11:32:13.002806Z","shell.execute_reply":"2021-07-05T11:32:14.201287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ab_nml = abnormal.T\nab_nml['type'] = 'Abnormal'\ndisplay(ab_nml.shape)\ndisplay(ab_nml.head())","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:32:14.205039Z","iopub.execute_input":"2021-07-05T11:32:14.205923Z","iopub.status.idle":"2021-07-05T11:32:14.269068Z","shell.execute_reply.started":"2021-07-05T11:32:14.205865Z","shell.execute_reply":"2021-07-05T11:32:14.268261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us append both datasets to form our required dataset.","metadata":{}},{"cell_type":"code","source":"appended_audio = nml.append(ab_nml)\ndisplay(appended_audio.shape)\ndisplay(appended_audio)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:32:14.270307Z","iopub.execute_input":"2021-07-05T11:32:14.270738Z","iopub.status.idle":"2021-07-05T11:32:14.422351Z","shell.execute_reply.started":"2021-07-05T11:32:14.270704Z","shell.execute_reply":"2021-07-05T11:32:14.42133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"appended_audio.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:32:14.426353Z","iopub.execute_input":"2021-07-05T11:32:14.426719Z","iopub.status.idle":"2021-07-05T11:32:14.675541Z","shell.execute_reply.started":"2021-07-05T11:32:14.426685Z","shell.execute_reply":"2021-07-05T11:32:14.674169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"appended_audio = appended_audio.fillna(appended_audio.median(axis=0))","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:34:28.637194Z","iopub.execute_input":"2021-07-05T11:34:28.637659Z","iopub.status.idle":"2021-07-05T11:34:40.987793Z","shell.execute_reply.started":"2021-07-05T11:34:28.637622Z","shell.execute_reply":"2021-07-05T11:34:40.98633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"appended_audio.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:34:40.989467Z","iopub.execute_input":"2021-07-05T11:34:40.990077Z","iopub.status.idle":"2021-07-05T11:34:41.25956Z","shell.execute_reply.started":"2021-07-05T11:34:40.990015Z","shell.execute_reply":"2021-07-05T11:34:41.258141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=appended_audio.drop('type', axis=1)\ndisplay(X)\ndisplay(X.shape)\ny= appended_audio['type']\ndisplay(y.shape)\ndisplay(y)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:34:46.954957Z","iopub.execute_input":"2021-07-05T11:34:46.955352Z","iopub.status.idle":"2021-07-05T11:34:47.087385Z","shell.execute_reply.started":"2021-07-05T11:34:46.955318Z","shell.execute_reply":"2021-07-05T11:34:47.086246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will try to simple classifiers - first SVC and then Neural networks.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split as tts\nX_train, X_test, y_train, y_test = tts(X,y,test_size = 0.2, stratify = y, random_state=9)\ny_test","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:34:59.447733Z","iopub.execute_input":"2021-07-05T11:34:59.448098Z","iopub.status.idle":"2021-07-05T11:34:59.559149Z","shell.execute_reply.started":"2021-07-05T11:34:59.448065Z","shell.execute_reply":"2021-07-05T11:34:59.558351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import LinearSVC\n\n# Initialize and fit the model\nmodel = LinearSVC()\nmodel.fit(X_train, y_train)\n\n# Generate predictions and score them manually\npredictions = model.predict(X_test)\nprint(sum(predictions == y_test) / len(y_test))","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:35:03.670854Z","iopub.execute_input":"2021-07-05T11:35:03.671984Z","iopub.status.idle":"2021-07-05T11:35:07.087887Z","shell.execute_reply.started":"2021-07-05T11:35:03.671832Z","shell.execute_reply":"2021-07-05T11:35:07.086135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\ny_encoded = to_categorical(pd.factorize(y)[0])\ny_encoded[:3]","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:35:20.648658Z","iopub.execute_input":"2021-07-05T11:35:20.649209Z","iopub.status.idle":"2021-07-05T11:35:20.659894Z","shell.execute_reply.started":"2021-07-05T11:35:20.64916Z","shell.execute_reply":"2021-07-05T11:35:20.658882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = tts(X,y_encoded,test_size = 0.2, stratify = y, random_state=9)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:35:20.667406Z","iopub.execute_input":"2021-07-05T11:35:20.668559Z","iopub.status.idle":"2021-07-05T11:35:20.799783Z","shell.execute_reply.started":"2021-07-05T11:35:20.668496Z","shell.execute_reply":"2021-07-05T11:35:20.798643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import models\nfrom keras import layers\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(32, activation='relu', input_shape=(50000,)))\nmodel.add(layers.Dense(16, activation='relu'))\nmodel.add(layers.Dense(16, activation='relu'))\nmodel.add(layers.Dense(2, activation='sigmoid'))\n\nmodel.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n\nhistory=model.fit(X_train, y_train, epochs = 20, validation_split=.2, batch_size=128, verbose=0)\n\nhistory_dict = history.history\nprint(history_dict.keys())","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:35:20.804813Z","iopub.execute_input":"2021-07-05T11:35:20.805246Z","iopub.status.idle":"2021-07-05T11:35:25.325473Z","shell.execute_reply.started":"2021-07-05T11:35:20.805197Z","shell.execute_reply":"2021-07-05T11:35:25.324163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.mean(history_dict['val_loss']))\nprint(np.mean(history_dict['val_accuracy']))\nmodel.evaluate(X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:35:25.327974Z","iopub.execute_input":"2021-07-05T11:35:25.328713Z","iopub.status.idle":"2021-07-05T11:35:25.488199Z","shell.execute_reply.started":"2021-07-05T11:35:25.328657Z","shell.execute_reply":"2021-07-05T11:35:25.486933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One of the ways we can improve the features available to our model is to remove some of the noise present in the data. In audio data, a common way to do this is to rectify it and then smooth the data to produce the envelope of the data so that the total amount of sound energy over time is more distinguishable. Let us see how we can do this just to the first audio file in our normal dataset.","metadata":{}},{"cell_type":"code","source":"audio0 =normal.dropna().iloc[:22050,0]\ndisplay(audio0.shape)\naudio0.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:35:25.490055Z","iopub.execute_input":"2021-07-05T11:35:25.49045Z","iopub.status.idle":"2021-07-05T11:35:25.55958Z","shell.execute_reply.started":"2021-07-05T11:35:25.490415Z","shell.execute_reply":"2021-07-05T11:35:25.55827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the raw data first\naudio0.plot(figsize=(10, 5))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:35:25.56185Z","iopub.execute_input":"2021-07-05T11:35:25.562374Z","iopub.status.idle":"2021-07-05T11:35:25.782722Z","shell.execute_reply.started":"2021-07-05T11:35:25.562326Z","shell.execute_reply":"2021-07-05T11:35:25.781517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rectify the audio signal\naudio_rectified = audio0.apply(np.abs)\n\n# Plot the result\naudio_rectified.plot(figsize=(10, 5))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:35:25.7844Z","iopub.execute_input":"2021-07-05T11:35:25.784882Z","iopub.status.idle":"2021-07-05T11:35:25.99181Z","shell.execute_reply.started":"2021-07-05T11:35:25.784832Z","shell.execute_reply":"2021-07-05T11:35:25.990587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Smooth by applying a rolling mean\naudio_rectified_smooth = audio_rectified.rolling(200).mean()\n\n# Plot the result\naudio_rectified_smooth.plot(figsize=(10, 5))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:35:25.993245Z","iopub.execute_input":"2021-07-05T11:35:25.993563Z","iopub.status.idle":"2021-07-05T11:35:26.208597Z","shell.execute_reply.started":"2021-07-05T11:35:25.993533Z","shell.execute_reply":"2021-07-05T11:35:26.207725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us smooth out all our audio files in X.","metadata":{}},{"cell_type":"code","source":"X_env = X.T\nX_env = X_env.apply(np.abs)\nX_env = X_env.rolling(200).mean()\ndisplay(X_env.tail())\nX_env.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:35:26.210715Z","iopub.execute_input":"2021-07-05T11:35:26.21119Z","iopub.status.idle":"2021-07-05T11:35:28.289826Z","shell.execute_reply.started":"2021-07-05T11:35:26.211155Z","shell.execute_reply":"2021-07-05T11:35:28.288598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sanity Check the first audio file by revisualizing it.","metadata":{}},{"cell_type":"code","source":"X_env.dropna().iloc[:17000,0].plot(figsize=(10, 5))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:35:28.29156Z","iopub.execute_input":"2021-07-05T11:35:28.291866Z","iopub.status.idle":"2021-07-05T11:35:28.59464Z","shell.execute_reply.started":"2021-07-05T11:35:28.291838Z","shell.execute_reply":"2021-07-05T11:35:28.593407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate stats\nmeans = np.mean(X_env, axis=0)\nstds = np.std(X_env, axis=0)\nmaxs = np.max(X_env, axis=0)\n\n# Create the X and y arrays\nX1 = np.column_stack([means, stds, maxs])\nprint(X1.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:35:28.596394Z","iopub.execute_input":"2021-07-05T11:35:28.596711Z","iopub.status.idle":"2021-07-05T11:35:29.891008Z","shell.execute_reply.started":"2021-07-05T11:35:28.596682Z","shell.execute_reply":"2021-07-05T11:35:29.889787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LinearSVC()\n\n# Normalize the data\nfrom sklearn.preprocessing import normalize\nX1 = normalize(X1)\n\n# Fit the model and score on testing data\nfrom sklearn.model_selection import cross_val_score\nscore = cross_val_score(model, X1, y, cv=5)\nprint(np.mean(score))","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:35:29.892279Z","iopub.execute_input":"2021-07-05T11:35:29.892574Z","iopub.status.idle":"2021-07-05T11:35:29.922301Z","shell.execute_reply.started":"2021-07-05T11:35:29.892544Z","shell.execute_reply":"2021-07-05T11:35:29.92101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we compute tempo and rhythm features for heartbeat data, and fit a model once more.","metadata":{}},{"cell_type":"code","source":"# Calculate the tempo of the sounds\ntempos = []\nfor col, i_audio in X_env.dropna().items():\n    tempos.append(lr.beat.tempo(i_audio.values, sr=sfreq, hop_length=2**6, aggregate=None))\n\n# Convert the list to an array\ntempos = np.array(tempos)\nprint(tempos)\n\n# Calculate statistics of each tempo\ntempos_mean = tempos.mean(axis=-1)\ntempos_std = tempos.std(axis=-1)\ntempos_max = tempos.max(axis=-1)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:35:29.923558Z","iopub.execute_input":"2021-07-05T11:35:29.923986Z","iopub.status.idle":"2021-07-05T11:40:44.59308Z","shell.execute_reply.started":"2021-07-05T11:35:29.92394Z","shell.execute_reply":"2021-07-05T11:40:44.591878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LinearSVC()\n\n# Create the X and y arrays\nX2 = np.column_stack([means, stds, maxs, tempos_mean, tempos_std, tempos_max])\n\n# Normalize the data\nfrom sklearn.preprocessing import normalize\nX2 = normalize(X2)\n\n# Fit the model and score on testing data\nscore = cross_val_score(model, X2, y, cv=5)\nprint(np.mean(score))","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:40:44.594504Z","iopub.execute_input":"2021-07-05T11:40:44.594842Z","iopub.status.idle":"2021-07-05T11:40:44.625904Z","shell.execute_reply.started":"2021-07-05T11:40:44.594802Z","shell.execute_reply":"2021-07-05T11:40:44.624591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will calculate a spectrogram of the for sound for  asample audio file. This describes what spectral content (e.g., low and high pitches) are present in the sound over time.","metadata":{}},{"cell_type":"code","source":"audio_0 = normal.dropna().iloc[:,0]\n\n# Import the stft function\nfrom librosa.core import stft\n\n# Prepare the STFT\nHOP_LENGTH = 2**4\nspec = stft(np.array(audio_0), hop_length=HOP_LENGTH, n_fft=2**7)\ndisplay(spec.shape)\nspec[:2]","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:40:44.627537Z","iopub.execute_input":"2021-07-05T11:40:44.627848Z","iopub.status.idle":"2021-07-05T11:40:44.69803Z","shell.execute_reply.started":"2021-07-05T11:40:44.627818Z","shell.execute_reply":"2021-07-05T11:40:44.696285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from librosa.core import amplitude_to_db\nfrom librosa.display import specshow\n\ntime = np.arange(0, len(audio_0)) / sfreq\n\n# Convert into decibels\nspec_db = amplitude_to_db(spec)\ndisplay(spec_db.shape)\ndisplay(spec_db)\n\n# Compare the raw audio to the spectrogram of the audio\nfig, axs = plt.subplots(2, 1, figsize=(10, 10), sharex=True)\naxs[0].plot(time, audio_0)\nspecshow(spec_db, sr=sfreq, x_axis='time', y_axis='hz', hop_length=HOP_LENGTH)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-05T11:40:44.699628Z","iopub.execute_input":"2021-07-05T11:40:44.699997Z","iopub.status.idle":"2021-07-05T11:40:45.073401Z","shell.execute_reply.started":"2021-07-05T11:40:44.69996Z","shell.execute_reply":"2021-07-05T11:40:45.072596Z"},"trusted":true},"execution_count":null,"outputs":[]}]}