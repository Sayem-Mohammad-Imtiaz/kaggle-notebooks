{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#from dlnlputils.pipeline import init_random_seed\nSEED = 1234\n#init_random_seed(SEED)\nimport random","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import BertTokenizer\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"init_token_idx = tokenizer.cls_token_id\neos_token_idx = tokenizer.sep_token_id\npad_token_idx = tokenizer.pad_token_id\nunk_token_idx = tokenizer.unk_token_id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torchtext import data\n\nfrom torchtext import data\n\n\n\nmax_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\ndef tokenize_and_cut(sentence):\n    tokens = tokenizer.tokenize(sentence) \n    tokens = tokens[:max_input_length-2]\n    return tokens\n\nTEXT = data.Field(batch_first = True,\n                  use_vocab = False,\n                  tokenize = tokenize_and_cut,\n                  preprocessing = tokenizer.convert_tokens_to_ids,\n                  init_token = init_token_idx,\n                  eos_token = eos_token_idx,\n                  pad_token = pad_token_idx,\n                  unk_token = unk_token_idx)\n\nLABEL = data.LabelField(dtype = torch.float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchtext import datasets\n\ntrain_data, test_data = datasets.IMDB.splits(TEXT, LABEL)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_VOCAB_SIZE = 25_000\n\nTEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\nLABEL.build_vocab(train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(LABEL.vocab.stoi)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data, valid_data = train_data.split(random_state = random.seed(SEED))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 128\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ntrain_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n    (train_data, valid_data, test_data), \n    batch_size = BATCH_SIZE, \n    device = device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import BertTokenizer, BertModel\n\nbert = BertModel.from_pretrained('bert-base-uncased')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\n\nclass BERTGRUSentiment(nn.Module):\n    def __init__(self,\n                 bert,\n                 hidden_dim,\n                 output_dim,\n                 n_layers,\n                 bidirectional,\n                 dropout):\n        \n        super().__init__()\n        \n        self.bert = bert\n        \n        embedding_dim = bert.config.to_dict()['hidden_size']\n        \n        self.rnn = nn.GRU(embedding_dim,\n                          hidden_dim,\n                          num_layers = n_layers,\n                          bidirectional = bidirectional,\n                          batch_first = True,\n                          dropout = 0 if n_layers < 2 else dropout)\n        \n        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n        \n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, text):\n        \n        #text = [batch size, sent len]\n                \n        with torch.no_grad():\n            embedded = self.bert(text)[0]\n                \n        #embedded = [batch size, sent len, emb dim]\n        \n        _, hidden = self.rnn(embedded)\n        \n        #hidden = [n layers * n directions, batch size, emb dim]\n        \n        if self.rnn.bidirectional:\n            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n        else:\n            hidden = self.dropout(hidden[-1,:,:])\n                \n        #hidden = [batch size, hid dim]\n        \n        output = self.out(hidden)\n        \n        #output = [batch size, out dim]\n        \n        return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"HIDDEN_DIM = 256\nOUTPUT_DIM = 1\nN_LAYERS = 2\nBIDIRECTIONAL = True\nDROPOUT = 0.25\n\nmodel = BERTGRUSentiment(bert,\n                         HIDDEN_DIM,\n                         OUTPUT_DIM,\n                         N_LAYERS,\n                         BIDIRECTIONAL,\n                         DROPOUT)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.optim as optim\n\noptimizer = optim.Adam(model.parameters())\n\n\ncriterion = nn.BCEWithLogitsLoss()\n\nmodel = model.to(device)\ncriterion = criterion.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def binary_accuracy(preds, y):\n    \"\"\"\n    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n    \"\"\"\n\n    #round predictions to the closest integer\n    rounded_preds = torch.round(torch.sigmoid(preds))\n    correct = (rounded_preds == y).float() #convert into float for division \n    acc = correct.sum() / len(correct)\n    return acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model, iterator, optimizer, criterion):\n    \n    epoch_loss = 0\n    epoch_acc = 0\n    \n    model.train()\n    \n    for batch in iterator:\n        \n        optimizer.zero_grad()\n        \n        predictions = model(batch.text).squeeze(1)\n        \n        loss = criterion(predictions, batch.label)\n        \n        acc = binary_accuracy(predictions, batch.label)\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        epoch_loss += loss.item()\n        epoch_acc += acc.item()\n        \n    return epoch_loss / len(iterator), epoch_acc / len(iterator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, iterator, criterion):\n    \n    epoch_loss = 0\n    epoch_acc = 0\n    \n    model.eval()\n    \n    with torch.no_grad():\n    \n        for batch in iterator:\n\n            predictions = model(batch.text).squeeze(1)\n            \n            loss = criterion(predictions, batch.label)\n            \n            acc = binary_accuracy(predictions, batch.label)\n\n            epoch_loss += loss.item()\n            epoch_acc += acc.item()\n        \n    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\n\ndef epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\nN_EPOCHS = 5\n\nbest_valid_loss = float('inf')\n\nfor epoch in tqdm(range(N_EPOCHS), total=N_EPOCHS):\n    \n    start_time = time.time()\n    \n    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n        \n    end_time = time.time()\n        \n    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n        \n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), 'model.pt')\n    \n    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_state_dict(torch.load('model.pt'))\n\ntest_loss, test_acc = evaluate(model, test_iterator, criterion)\n\nprint(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_sentiment(model, tokenizer, sentence):\n    model.eval()\n    tokens = tokenizer.tokenize(sentence)\n    tokens = tokens[:max_input_length-2]\n    indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n    tensor = torch.LongTensor(indexed).to(device)\n    tensor = tensor.unsqueeze(0)\n    prediction = torch.sigmoid(model(tensor))\n    return prediction.item()\n\nprint(predict_sentiment(model, tokenizer, \"This film is terrible\"))\nprint(predict_sentiment(model, tokenizer, \"This film is great\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'model.pt')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}