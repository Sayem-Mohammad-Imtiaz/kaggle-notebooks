{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Task 1: Identify Features"},{"metadata":{},"cell_type":"markdown","source":"Assemble a dataset consisting of features and target (for example in a dataframe or in two arrays X and y). What features are relevant for the prediction task?\nAre there any features that should be excluded because they leak the target information? Show visualizations or statistics to support your selection.\nYou are not required to use the description column, but you can try to come up with relevant features using it. Please don’t use bag-of-word approaches for now as we’ll discuss these later in the class."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_orig = pd.read_csv('/kaggle/input/craigslist-carstrucks-data/vehicles.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_orig","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get subsample of data\ndf = df_orig.sample(frac=0.2,axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_no_outliers = df_orig[df_orig['price'] <= 100000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlation between id and price?\nimport seaborn as sb\nimport matplotlib.pyplot as plt\nax = sb.scatterplot(x=\"model\", y=\"price\", data=(df_orig))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can immediately drop several columns! The following columns are either irrelevant to the price of the vehicle (such as VIN), or convey information that is already present in other fields (url). We also chose to get ride of model because it could leak target information."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(columns = ['id',\n                   'url', \n                   'region', \n                   'region_url', \n                   'title_status', \n                   'size', \n                   'description', \n                   'vin', \n                   'lat', \n                   'long', \n                   'image_url',\n                   'county',\n                   'state',\n                    'model'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Task 2 Preprocessing and Baseline Model"},{"metadata":{},"cell_type":"markdown","source":"Create a simple minimum viable model by doing an initial selection of features, doing appropriate preprocessing and cross-validating a linear model. Feel free to exclude features or do simplified preprocessing for this task. As mentioned before, you don’t need to validate the model on the whole dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df['price']\nX = df.drop(columns=['price'])\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.get_dummies(df, columns=['boro'])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}