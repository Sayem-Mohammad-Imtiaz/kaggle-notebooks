{"cells":[{"metadata":{},"cell_type":"markdown","source":"### EDA\nWe are given a huge amount of data for customers' orders, locations of a restaurants. Let us see what insights we might from it","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport geopandas as gpd\nimport folium\nfrom folium.plugins import HeatMap\nimport re\n\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (12, 5);\nsns.set_style('whitegrid')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First, we are given some varibale explanations.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('../input/restaurant-recommendation-challenge/VariableDefinitions.txt') as f:\n    print(f.read())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"chunk_size=10000\nroot_dir = '../input/restaurant-recommendation-challenge'\ntrain_full = pd.read_csv(os.path.join(root_dir, 'train_full.csv'))\norders = pd.read_csv(os.path.join(root_dir, 'orders.csv'))\nvendors = pd.read_csv(os.path.join(root_dir, 'vendors.csv'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Files attached are realy vast, let's pick just a sample of those for performance and basic analysis.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_full = train_full.sample(chunk_size)\norders = orders.sample(chunk_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_full.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"orders.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_full.isna().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2)\ntrain_full['gender'].hist(ax=ax[0], color='yellow')\ntrain_full['location_type'].hist(ax=ax[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_full['country_id'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hm, let us see where are our locations anyway.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"locs = gpd.read_file(os.path.join(root_dir, 'train_locations.csv'))\nlocs.dropna(subset=['latitude'], inplace=True)\nlocs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def check_num(string):\n    regex = r'-?[0-9]*.[0-9]*'\n    m = re.match(regex, string)\n    if m is None:\n        return float(0)\n    return float(string[:6])\n\nlocs['latitude'] = locs['latitude'].apply(check_num)\nlocs['longitude'] = locs['longitude'].apply(check_num)\nlocs['geometry'] = gpd.points_from_xy(locs['longitude'], locs['latitude'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = folium.Map(location=[50,-85], zoom_start=2)\nfor i in list(locs.index)[:50]:\n    folium.Marker([locs.loc[i, 'latitude'], locs.loc[i, 'longitude']]).add_to(m)\nm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Needless to say there is something wrong with our location data. At least we confirmed statment from variale defenitions.\n> 'Latitude' and 'longitude': Not true latitude and longitude - locations have been masked, but nearby locations remain nearby in the new reference frame and can thus be used for clustering. However, not all locations are useful due to GPS errors and missing data - you may want to treat outliers separately.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted(train_full['location_number'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_full[['status_x', 'status_y']].hist(color='magenta')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_full['discount_percentage'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_full['commission'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_full['display_orders'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_full['target'].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_full['rank'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_full['prepration_time'].hist(color='gold')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well... we have many not really informative features here. Probably we can get better insights from orders and customers individually?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"orders.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"orders.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(orders['payment_mode']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(orders.corr(), cmap=\"YlGnBu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2)\nsns.distplot(orders['grand_total'], ax=ax[0], color='purple')\nsns.distplot(orders['item_count'], ax=ax[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2)\norders.loc[:, 'delivery_date'] = pd.to_datetime(orders['delivery_date'])\nax[0].scatter(orders.set_index('delivery_date').index, orders['item_count'], \n              label='items', alpha=0.6, color='red')\nax[0].legend();\nax[1].scatter(orders.set_index('delivery_date').index, orders['grand_total'], \n              label='total pay', alpha=0.6, color='green')\nax[1].legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"orders.loc[:, 'delivery_time'] = pd.to_datetime(orders['delivery_time'], errors='coerce')\nfor i in range(0, 24):\n    df = orders[orders['delivery_time'].dt.hour==i]\n    orders.loc[df.index, 'delivery_hour'] = i\norders['delivery_hour'].hist(bins=24, label='orders by hour of day')\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"orders.groupby('customer_id').mean()['grand_total'].plot(marker='.', linestyle='none', color='orange')\nplt.title('total cost');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Huh, we even have people how appear to pay nothing... at least according to the given data. Let's dig some more.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"orders[orders['grand_total']==0.0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"orders[orders['grand_total']==0.0]['promo_code'].isna().sum(), orders[orders['grand_total']==0.0].shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Okay, so most of these people used promo code. A bit of insight we've got.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"customers = pd.read_csv('../input/restaurant-recommendation-challenge/train_customers.csv')\ncustomers.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customers['akeed_customer_id'].nunique(), customers.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dists = ['gender', 'language', 'status', 'verified']\nd=0\nfig, ax = plt.subplots(2, 2)\nfor i in range(2):\n    for j in range(2):\n        customers[dists[d]].dropna().hist(ax=ax[i][j], label=dists[d], color='aqua')\n        if dists[d] == 'gender':\n            ax[i][j].tick_params(rotation=45)\n        ax[i][j].legend();\n        plt.tight_layout();\n        d+=1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ouch, there is some mess going on in the gender column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_string(string):\n    string = str(string)\n    if '?' in string or string=='nan' or string.strip(' ')=='':\n        return np.nan\n    string = string.strip(' ').lower()\n    return string\n\ncustomers.loc[:, 'gender'] = customers['gender'].apply(clean_string)\ncustomers['gender'].hist(color='chocolate')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calc_age(year):\n    if len(str(year))==2:\n        if str(year).startswith('0'):\n            year = '20'+str(year)\n        else:\n            year = '19'+str(year)\n        year = int(year)\n    if year is None:\n        return np.nan\n    return 2020-year\n\ncustomers.loc[:, 'age'] = customers['dob'].apply(calc_age)\ncustomers[customers['age']<16]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well... customers as young as 1 y.o. looks truely suspicious, not too mention the accounts of such customers seems to be created the same year or even earlier than they were born... That's funny but with high confidence we can tell these are mistaken records.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ages = customers[customers['age']>16]\nages = ages[ages['age']<110]\nages['age'].dropna().hist(bins=20, label='customers by age', color='brown')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That will conclude our quick look at data given. Clearly we need somewhat more effective tools to deal with high volume of data. That is what we will be doing in the <a href='https://www.kaggle.com/erelin6613/pyspark-alternating-least-squares-in-action?scriptVersionId=39511328'>next notebook</a>.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}