{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"This notebook presents the outcomes of the DATA@ANZ virtual experience program. Here is the link to the official website of the program: https://www.insidesherpa.com/show-firm-programs/AKkAyEwWc8wjPxx9n/ANZ\n\nAs stated in the program description \"*Data@ANZ is about mining and linking datasets to develop stories that matter and challenge the status quo, to deliver on ANZ’s purpose 'to shape a world where people and communities thrive'* \". This program includes two tasks:\n* Exploratory Data Analysis: Segment the dataset and draw unique insights, including visualisation of the transaction volume and assessing the effect of any outliers.\n* Predictive Analytics: Explore correlations between customer attributes, build a regression and a decision-tree prediction model based on your findings.\n\nNote that this is a “synthesised transaction dataset containing 3 months’ worth of transactions for 100 hypothetical customers.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sn\nimport matplotlib.pyplot as plt\nfrom sklearn import tree\nfrom sklearn import linear_model\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First let's take a look at what the data is like. There are 12043 data records with 23 features for each records.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv ('../input/anz-synthesised-transaction-dataset/anz.csv')\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check numerical data statistics\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check data types\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to the missing value percent table, there are some features like card_present_flag have a pretty high missing value percentage. Luckily, none of those features are needed in these project.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# check missing value ratio\ndf.isnull().sum() / len(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we check the total number of customers to verify the dataset. It turns out we do have 100 customers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# check number of customers. Assume each customer has one unique customer_id.\nprint(\"number of customer: \", len(df.customer_id.unique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Another interesting thing to notice is that one of the days is not recorded during the three month duration. It turns out that there are not transactions on 2018-08-16, which might be caused by the system maintenance of the ANZ bank.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"first day of data: \", df.date.iloc[0])\nprint(\"last day of data: \", df.date.iloc[-1])\nprint(\"duration: \", 92)\nprint(\"recorded days: \", len(df.date.unique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Data Preparation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In this section, we extract some key features from the raw data as well as some calculated features, which will be used in decision tree model and regression model. Then we build the coorelation matrix to explore the relationship between different features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# list all unique customer ids\ncustomer_list = df.customer_id.unique()\n# filter out useless information\ndf_cus_info = pd.DataFrame(columns = [\"customer_id\", \"annual salary\", \"age\", \"avg_transaction_amount\", \"transaction_number\", \"max_transaction_amount\", \"avg_balance\", \"gender\", \"state\"])\n\nfor index, id in enumerate(customer_list):\n    # extract payment information of this customer \n    df_cus = df[(df.customer_id == id) & (df.txn_description == 'PAY/SALARY')]\n    # calculate annual salary\n    pay_period = pd.to_datetime(df_cus.date).diff().mean().total_seconds() / 60 / 60 / 24\n    pay_amount = df_cus.amount.mean()\n    daily_pay = pay_amount / pay_period\n    yearly_pay = 365 * daily_pay\n    # get age\n    age = df_cus.age.mean()\n    # get average balance\n    balance = df_cus.balance.mean()\n    # get gender\n    gender = df_cus[\"gender\"].mode()[0]\n    # store all the payment related info in the dataframe\n    df_cus_info.loc[index, [\"customer_id\", \"annual salary\", \"age\", \"avg_balance\", \"gender\"]] = [id, yearly_pay, age, balance, gender]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# iterate through each customer\nfor index, id in enumerate(customer_list):\n    # extract all info of this customer\n    df_cus = df[df.customer_id == id]\n    # assume mode of transaction merchant state is the state of this customer                     \n    state = df_cus[\"merchant_state\"].mode()[0]\n    # calculate average transaction amount of this customer\n    avg_transaction_amount = df_cus[\"amount\"].mean()\n    # calculate the number of transaction during a certain time of period\n    transaction_number = df_cus[\"transaction_id\"].count() \n    # calculate the max transaction amount during a certain time of period \n    max_transaction_amount = df_cus[\"amount\"].max() \n    # put all calculted results above in the data frame\n    df_cus_info.loc[index, [\"state\", \"avg_transaction_amount\", \"transaction_number\", \"max_transaction_amount\"]] = [state, avg_transaction_amount, transaction_number, max_transaction_amount]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transform the data type\ndf_cus_info[\"annual salary\"] = df_cus_info[\"annual salary\"].astype(float)\ndf_cus_info[\"age\"] = df_cus_info[\"age\"].astype(float)\ndf_cus_info[\"avg_transaction_amount\"] = df_cus_info[\"avg_transaction_amount\"].astype(float)\ndf_cus_info[\"transaction_number\"] = df_cus_info[\"transaction_number\"].astype(float)\ndf_cus_info[\"max_transaction_amount\"] = df_cus_info[\"max_transaction_amount\"].astype(float)\ndf_cus_info[\"avg_balance\"] = df_cus_info[\"avg_balance\"].astype(float)\ndf_cus_info.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According the correlation matrix below, we can see that there is a strong correlation between annual salary and max transaction amount, as well as average transaction amount. It makes sense since people with high income tend to have high transaction amount.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate correlation matrix\ncorrMatrix = df_cus_info.loc[:, [\"annual salary\", \"age\", \"avg_balance\", \"avg_transaction_amount\", \"transaction_number\", \"max_transaction_amount\"]].astype('float64').corr(method='pearson', min_periods=1)\ncorrMatrix\nsn.heatmap(corrMatrix, annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In this section we build a decision tree model to fit the data, with estimated annual salary as the label (we mark annual salary that higher than 60 K as high 1, while lower than 60 K as low 0). It can observed that avg_transaction_amount and transaction_number are the most effective feature.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_cus_info.drop(labels=[\"customer_id\", \"annual salary\"], axis=1)\nX_OHE = pd.get_dummies(X, columns=[\"state\", \"gender\"])\nY = df_cus_info[\"annual salary\"].apply(lambda x: 1 if x >  60000 else 0)\nclf = tree.DecisionTreeClassifier(max_depth=2)\nclf = clf.fit(X_OHE, Y)\ntree.plot_tree(clf) \n\nprint()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Linear Regression","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In this section we build the linear regression model of the annual salary.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_cus_info\nX_rgr = df_cus_info[[\"age\", \"avg_transaction_amount\", \"transaction_number\", \"max_transaction_amount\", \"avg_balance\"]]\nY_rgr = df_cus_info[\"annual salary\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# build linear regression model\nrgr = linear_model.LinearRegression()\n# fit model\nrgr.fit(X_rgr, Y_rgr)\n# coefficient of determination R^2\nprint(rgr.score(X_rgr, Y_rgr))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the regression coefficient plot we can see that age is negatively correlated with annual salary while transaction amount and transaction number are negatively correlated with annual salary, which is consistent with the outcomes of correlation matrix and their impact is relatively high. Furthermore, average balance has little impact on the final prediction result in our regression model. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot regression coefficients\nnames = [\"age\", \"avg_transaction_amount\", \"transaction_number\", \"max_transaction_amount\", \"avg_balance\"]\nvalues = rgr.coef_\nplt.figure(figsize=(16,8))\nplt.bar(names, values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Consider the effect of regularization might further improve our  coefficient of determination, we try elastic net regression, which includes both L1 and L2 norm. However, it turns out the final results are almost the same even if we try adjusting the ratio between L1 and L2 norms.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# build linear regression model\nrgr_elastic = linear_model.ElasticNet(random_state=0, l1_ratio=0.5)\n# fit model\nrgr_elastic.fit(X_rgr, Y_rgr)\n# coefficient of determination R^2\nprint(rgr_elastic.score(X_rgr, Y_rgr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot regression coefficients\nnames = [\"age\", \"avg_transaction_amount\", \"transaction_number\", \"max_transaction_amount\", \"avg_balance\"]\nvalues = rgr_elastic.coef_\nplt.figure(figsize=(16,8))\nplt.bar(names, values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualization","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"This section includes some visiualizations of EDA. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Histogram of Transaction Quantity ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot\nplt.figure(figsize=(8, 5))\nplt.hist(df_cus_info.transaction_number)\nplt.xlabel('Transaction Quantity')\nplt.ylabel(\"Frequency\")\nplt.title('Histogram of Transaction Quantity')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Histogram of Transaction Amount","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 5))\nplt.hist(df_cus_info.avg_transaction_amount)\nplt.xlabel('Transaction Amount')\nplt.ylabel(\"Frequency\")\nplt.title('Histogram of Transaction Amount')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Histogram of Annual Salary","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 5))\nplt.hist(df_cus_info[\"annual salary\"])\nplt.xlabel('Annual Salary')\nplt.ylabel(\"Frequency\")\nplt.title('Histogram of Annual Salary')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}