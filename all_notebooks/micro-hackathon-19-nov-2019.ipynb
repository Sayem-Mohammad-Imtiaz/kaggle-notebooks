{"cells":[{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd\nimport re\nimport math\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn import metrics\nfrom sklearn.svm import SVC\nimport numpy as np\n\n#Data Processing Packages\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\n\n#Data Visualization Packages\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#Machine Learning Packages\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn import model_selection\nimport warnings; warnings.simplefilter('ignore')\n\n%matplotlib inline\n\n# %matplotlib tk\n\ndef plot_corr(df):\n    \"\"\"\n    Function plots a graphical correlation matrix for each pair of columns in the dataframe.\n\n    Input:\n        df: pandas DataFrame\n        size: vertical and horizontal size of the plot\n\n    Displays:\n        matrix of correlation between columns.  Blue-cyan-yellow-red-darkred => less to more correlated\n                                                0 ------------------>  1\n                                                Expect a darkred line running from top left to bottom right\n    \"\"\"\n    sns.heatmap(df.corr(), annot=True)\n\ndef plot_bar(target, df, exclude=tuple()):\n    total_plots = df.shape[1]\n    ncols=3\n    nrows = math.ceil(total_plots/ncols)\n    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(nrows*ncols, nrows*ncols))\n    i=0\n    j=0\n    for col_name in df.columns: \n#         print(col_name)\n#         print(\"{0}-{1}\".format(i,j))\n        \n        if (col_name == target) or col_name in exclude:\n            continue\n        try:\n            sns.barplot(x=target, y=col_name, data=df, ax=ax[i,j])\n        except Exception as e:\n            print(\"WARNING unable to plot for {} against {}\".format(target, col_name))\n        j += 1\n        if j == (ncols):\n            i += 1\n            j = 0\n# Function to calculate no. of null values with percentage in the dataframe\ndef null_values(DataFrame_Name):\n    \n    sum_null = DataFrame_Name.isnull().sum()\n    total_count = DataFrame_Name.isnull().count()\n    percent_nullvalues = sum_null/total_count * 100\n    df_null = pd.DataFrame()\n    df_null['Total_values'] = total_count\n    df_null['Null_Count'] = sum_null\n    df_null['Percent'] = percent_nullvalues\n    df_null = df_null.sort_values(by='Null_Count',ascending = False)\n\n    return(df_null)\n\n# Function to calculate no. of null values with percentage in the dataframe\ndef specific_values(DataFrame_Name, value=0):\n    \n    sum_by_value = (DataFrame_Name ==value).sum()\n    total_count = (DataFrame_Name ==value).count()\n    percent_byvalues = sum_by_value/total_count * 100\n    df_null = pd.DataFrame()\n    df_null['Total_values'] = total_count\n    df_null['value_Count'] = sum_by_value\n    df_null['Percent'] = percent_byvalues\n    df_null = df_null.sort_values(by='value_Count',ascending = False)\n\n    return(df_null)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\ndf = pd.read_csv(\"../mine/train2.csv\", low_memory=False)\nprint('Setup Completed')\ndf.columns\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# null_values(df)\ndf['index_col'] = df.index\n\ntruncated_df =  df[['BATHRM', 'HF_BATHRM', 'HEAT', 'AC', 'NUM_UNITS', 'ROOMS',\n       'BEDRM',  'YR_RMDL', 'EYB', 'STORIES',  'PRICE',\n       'QUALIFIED',  'GBA',  'STYLE', 'STRUCT', 'GRADE',\n       'CNDTN', 'EXTWALL', 'ROOF', 'INTWALL', 'KITCHENS', \n        'LANDAREA',   'index_col','STATE','SQUARE','QUADRANT'\n        \n       \n       ]]\ntruncated_df['YR_RMDL'] = truncated_df['YR_RMDL'].fillna(truncated_df['EYB'])\n\ndel truncated_df['EYB']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# IMPUTATIONS\n# replace 50% null values of YR_RMDL with AYB\n\n\ntruncated_df[\"STATE\"] = truncated_df[\"STATE\"].fillna(truncated_df[\"STATE\"].mode()[0])\n# truncated_df[\"CITY\"] = truncated_df[\"CITY\"].fillna(truncated_df[\"CITY\"].mode()[0])\ntruncated_df[\"STRUCT\"] = truncated_df[\"STRUCT\"].fillna(truncated_df[\"STRUCT\"].mode()[0])\ntruncated_df[\"STYLE\"] = truncated_df[\"STYLE\"].fillna(truncated_df[\"STYLE\"].mode()[0])\ntruncated_df[\"INTWALL\"] = truncated_df[\"INTWALL\"].fillna(truncated_df[\"INTWALL\"].mode()[0])\ntruncated_df[\"EXTWALL\"] = truncated_df[\"EXTWALL\"].fillna(truncated_df[\"EXTWALL\"].mode()[0])\ntruncated_df[\"GRADE\"] = truncated_df[\"GRADE\"].fillna(truncated_df[\"GRADE\"].mode()[0])\n# truncated_df[\"ZIPCODE\"] = truncated_df[\"ZIPCODE\"].fillna(truncated_df[\"ZIPCODE\"].mode()[0])\n# truncated_df.dropna(subset = ['PRICE'],inplace = True)\ntruncated_df[\"PRICE\"] = truncated_df[\"PRICE\"].fillna(truncated_df[\"PRICE\"].mean())\n# truncated_df[\"SQUARE\"][truncated_df[\"SQUARE\"]==\"PAR \"] = truncated_df[\"SQUARE\"][truncated_df[\"SQUARE\"]!=\"PAR \"].mean()\n\ntruncated_df[\"STORIES\"] = truncated_df[\"STORIES\"].fillna(truncated_df[\"STORIES\"].mode()[0])\ntruncated_df[\"KITCHENS\"] = truncated_df[\"KITCHENS\"].fillna(truncated_df[\"KITCHENS\"].mode()[0])\ntruncated_df[\"NUM_UNITS\"] = truncated_df[\"NUM_UNITS\"].fillna(truncated_df[\"NUM_UNITS\"].mode()[0])\ntruncated_df[\"GBA\"] = truncated_df[\"GBA\"].fillna(truncated_df[\"GBA\"].mode()[0])\ntruncated_df[\"SQUARE\"] = truncated_df[\"SQUARE\"].fillna(truncated_df[\"SQUARE\"].mode()[0])\ntruncated_df[\"ROOMS\"] = truncated_df[\"ROOMS\"].fillna(truncated_df[\"ROOMS\"].mode()[0])\ntruncated_df[\"BATHRM\"] = truncated_df[\"BATHRM\"].fillna(truncated_df[\"BATHRM\"].mode()[0])\ntruncated_df[\"HF_BATHRM\"] = truncated_df[\"HF_BATHRM\"].fillna(truncated_df[\"HF_BATHRM\"].mode()[0])\ntruncated_df[\"LANDAREA\"] = truncated_df[\"LANDAREA\"].fillna(truncated_df[\"LANDAREA\"].mode()[0])\n\n\nnull_values(truncated_df)\n# truncated_df[truncated_df[\"YR_RMDL\"].isnull()==1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pd.set_option('display.max_columns', 500)\nnull_values(truncated_df)\ndf.head(10)\n# truncated_df[\"SQUARE\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"truncated_df.shape\nfrom sklearn.model_selection import train_test_split\ntruncated_df[\"HAC\"] =  truncated_df[\"AC\"]\ntruncated_df[\"BBRM\"] = truncated_df[\"BATHRM\"] +truncated_df[\"HF_BATHRM\"]+truncated_df[\"BEDRM\"]  + truncated_df[\"ROOMS\"] \n\nfeature_col_names = ['HAC',   'BBRM','YR_RMDL', 'STORIES',  'STYLE',  'GRADE', 'EXTWALL', 'LANDAREA', 'NUM_UNITS',\\\n                    'INTWALL', 'STRUCT', 'GBA', 'KITCHENS','QUALIFIED','ROOF','CNDTN','HEAT','STATE','QUADRANT']\n#'GBA', 'STYLE',  'GRADE', 'CNDTN',  \n       # 'KITCHENS', 'LANDAREA', 'index_col'\npredicted_class_names = ['PRICE']\n\n\nX = truncated_df[feature_col_names]     # predictor feature columns (8 X m)\nY = truncated_df[predicted_class_names] # predicted class (1=true, 0=false) column (1 X m)\nY[\"PRICE\"] = Y[\"PRICE\"].astype(int)\nsplit_test_size = 0.30\nX['BBRM'] = pd.qcut(X['BBRM'], 4, duplicates=\"drop\")\n# X['BEDRM'] = pd.qcut(X['BEDRM'], 4, duplicates=\"drop\")\nX['NUM_UNITS'] =pd.qcut(X['NUM_UNITS'], 4, duplicates=\"drop\")\n\n\nX['STORIES'] = pd.qcut(X['STORIES'], 4, duplicates=\"drop\")\n# X['SALE_NUM'] = pd.qcut(X['SALE_NUM'], 4, duplicates=\"drop\")\nX['YR_RMDL'] = pd.qcut(X['YR_RMDL'], 4, duplicates=\"drop\")\nX['GBA'] = pd.qcut(X['GBA'], 4, duplicates=\"drop\")\nX['KITCHENS'] = pd.qcut(X['KITCHENS'], 4, duplicates=\"drop\")\nX['LANDAREA'] = pd.qcut(X['LANDAREA'], 4, duplicates=\"drop\")\n\n# X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=split_test_size, random_state=42) \ncols=['HAC',   'BBRM','YR_RMDL', 'STORIES','STYLE',  'GRADE', 'EXTWALL', 'LANDAREA','NUM_UNITS',\\\n                    'INTWALL', 'STRUCT', 'GBA', 'KITCHENS', 'QUALIFIED','ROOF','CNDTN','HEAT','STATE','QUADRANT'\n       \n         ]\nX = pd.get_dummies(X, columns=cols, prefix=cols)\nX_train=X[:2000]\nX_test=X[2300:3000]\nY_train=Y[:2000]\nY_test=Y[2300:3000]\n# del X_train['index_col']\n# del X_test['index_col']\n\n\n# X_train = pd.get_dummies(X_train, columns=['HAC',   'BBRM','YR_RMDL', 'STORIES','STYLE',  'GRADE',\n       \n#          ], \\\n#                        prefix=['HAC',   'BBRM','YR_RMDL', 'STORIES','STYLE',  'GRADE',\n#         ])\n# X_test = pd.get_dummies(X_test, columns=['HAC',   'BBRM','YR_RMDL', 'STORIES',  'STYLE',  'GRADE',\n       \n#         ], \\\n#                        prefix=['HAC',   'BBRM','YR_RMDL', 'STORIES', 'STYLE',  'GRADE',\n       \n#          ])\nX_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Modeling step Test differents algorithms \ncv_split = model_selection.ShuffleSplit(n_splits=10, test_size=.3, train_size=.7, random_state=42)\n\nclassifiers = [\n#     SVC(random_state=42, probability=True),\n#     DecisionTreeClassifier(random_state=42),\n#     AdaBoostClassifier(DecisionTreeClassifier(random_state=42),random_state=42,learning_rate=0.1),\n#     RandomForestClassifier(random_state=42),\n#     ExtraTreesClassifier(random_state=42),\n#     GradientBoostingClassifier(random_state=42),\n#     MLPClassifier(random_state=42),\n#     KNeighborsClassifier(),\n    LogisticRegression(random_state=42),\n#     LinearDiscriminantAnalysis(),\n#     XGBClassifier()\n]\n\ncv_train_mean = []\ncv_test_mean = []\ncv_score_time = []\ncv_fit_time = []\ncv_name = []\npredictions = []\n\nfor classifier in classifiers :\n    cv_results = model_selection.cross_validate(classifier, X_train, Y_train, cv=cv_split, return_train_score=True)\n    cv_train_mean.append(cv_results['train_score'].mean())\n    cv_test_mean.append(cv_results['test_score'].mean())\n    cv_score_time.append(cv_results['score_time'].mean())\n    cv_fit_time.append(cv_results['fit_time'].mean())\n    cv_name.append(str(classifier.__class__.__name__))\n    classifier.fit(X_train, Y_train)\n    predictions.append(classifier.predict(X_test))\n    \n\nperformance_df = pd.DataFrame({\"Algorithm\":cv_name, \"Train Score\":cv_train_mean, \"Test Score\":cv_test_mean, 'Score Time':cv_score_time, 'Fit Time':cv_fit_time})\nperformance_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":1}