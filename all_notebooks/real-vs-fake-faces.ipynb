{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing Libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport os\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.layers import (Conv2D, BatchNormalization, Activation, MaxPooling2D, GlobalAveragePooling2D, \n                          Dense, Flatten, Dropout)\nfrom keras.optimizers import RMSprop, Adam, SGD\nfrom keras import regularizers\nfrom keras.callbacks import CSVLogger, ModelCheckpoint, ReduceLROnPlateau","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing Dataset and Plotting Images"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake'\n\ndef plot_img(path, set_):\n    dir_ = os.path.join(path, 'train', set_)\n    k = 0\n    fig, ax = plt.subplots(3,3, figsize=(10,10))\n    fig.suptitle(set_ + 'Faces')\n    for j in range(3):\n        for i in range(3):\n            img = load_img(os.path.join(dir_, os.listdir(os.path.join(dir_))[k]))          \n            ax[j,i].imshow(img)\n            ax[j,i].set_title(\"\")\n            ax[j,i].axis('off')\n            k +=1\n  #  fig.tight_layout()\n    plt.suptitle(set_ + ' Faces')\n    return plt\n\nplot_img(path, 'real').show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fake Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_img(path, 'fake').show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train and Validation Set "},{"metadata":{"trusted":true},"cell_type":"code","source":"bs = 64\nrow, col = 224, 224\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n                                   horizontal_flip=True\n                                  )\ntraining_set = train_datagen.flow_from_directory(path + '/train',\n                                                 class_mode='binary',\n                                                 shuffle=True,\n                                                 target_size=(row,col),\n                                                 batch_size=bs\n                                                )\nval_test_datagen = ImageDataGenerator(rescale=1./255)\n\nvalidation_set = val_test_datagen.flow_from_directory(path + '/valid',\n                                                      class_mode='binary',\n                                                      shuffle=True,\n                                                      target_size=(row,col),\n                                                      batch_size=bs\n                                                     ) \ntest_set = val_test_datagen.flow_from_directory(path + '/test',\n                                                class_mode='binary',\n                                                shuffle=True,\n                                                target_size=(row,col),\n                                                batch_size=bs\n                                               )\ntraining_set.class_indices","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating Model\nI tried Different model architecture like VGG, mobilenet but DenseNet works best"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import DenseNet121\ndef get_model():\n    densenet = DenseNet121(weights='imagenet',\n                           include_top=False,\n                           input_shape=(224,224,3)\n                          )\n    model = tf.keras.models.Sequential([densenet,\n                                        GlobalAveragePooling2D(),\n                                        Dense(512, activation='relu'),\n                                        BatchNormalization(),\n                                        Dropout(0.3),\n                                        Dense(1, activation='sigmoid')\n                                      ])\n    model.compile(optimizer=Adam(lr=0.001),\n                loss='binary_crossentropy',\n                metrics=['accuracy']\n                )\n\n    return model\n\nspoofnet = get_model()\nspoofnet.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Defining Model Checkpoints"},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint(filepath='spoffnet.h5',\n                             save_best_only=True,\n                             verbose=1,\n                             mode='min',\n                             moniter='val_loss'\n                            )\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', \n                              factor=0.2, \n                              patience=3, \n                              verbose=1, \n                              min_delta=0.0001\n                             )\ncsv_logger = CSVLogger('training.log')\n\ncallbacks = [checkpoint, reduce_lr, csv_logger]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"steps_per_epoch = training_set.n // training_set.batch_size\nvalidation_steps = validation_set.n // validation_set.batch_size\n\nhist = spoofnet.fit(training_set,\n                    validation_data=validation_set,\n                    callbacks=callbacks,\n                    steps_per_epoch=steps_per_epoch,\n                    validation_steps=validation_steps,\n                    epochs=4\n                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,5))\nplt.subplot(1,2,2)\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(['train', 'val'])\n\nplt.subplot(1,2,1)\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('model Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['train', 'val'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Accuracy On test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"_, accu = spoofnet.evaluate(test_set)\nprint('Final Test Acccuracy = {:.3f}'.format(accu*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Confusion Matrix and Classification Report"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = spoofnet.predict(test_set)\ny_pred = (y_pred < 0.5).astype(np.int)\n\nfrom sklearn.metrics import confusion_matrix, classification_report\ncm = confusion_matrix(test_set.classes, y_pred)\nprint('Confusion Matrix')\nprint(cm)\n\nnames = ['fake', 'real']\nprint('Classification Report')\nprint(classification_report(test_set.classes, y_pred, target_names=names))\n\nplt.figure(figsize=(5,5))\nplt.imshow(cm)\nplt.colorbar()\ntick_mark = np.arange(len(names))\n_ = plt.xticks(tick_mark, names, rotation=90)\n_ = plt.yticks(tick_mark, names)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}