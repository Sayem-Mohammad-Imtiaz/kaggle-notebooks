{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-16T14:56:19.065973Z","iopub.execute_input":"2021-07-16T14:56:19.066358Z","iopub.status.idle":"2021-07-16T14:56:19.083056Z","shell.execute_reply.started":"2021-07-16T14:56:19.066303Z","shell.execute_reply":"2021-07-16T14:56:19.081964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## US Accidents - Applied Machine Learning","metadata":{}},{"cell_type":"markdown","source":"### 1. Understand the Problem Statement & Import Packages and Datasets :","metadata":{}},{"cell_type":"code","source":"# Warning Libraries :\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Scientific and Data Manipulation Libraries :\nimport pandas as pd\nimport numpy as np\nimport math\nimport gc\nimport os\nimport category_encoders as ce\n\n\n# ML Libraries :\nfrom sklearn.preprocessing            import LabelEncoder, OneHotEncoder \nfrom sklearn.preprocessing            import StandardScaler, MinMaxScaler, Normalizer, RobustScaler, MaxAbsScaler\nfrom sklearn.model_selection          import KFold, StratifiedKFold, train_test_split, cross_val_score\nfrom sklearn.linear_model             import LogisticRegression\nfrom sklearn                          import tree\nfrom sklearn.ensemble                 import RandomForestClassifier\nfrom sklearn.metrics                  import accuracy_score\nfrom sklearn.metrics                  import f1_score,precision_score\n#from sklearn.metrics                 import jaccard_similarity_score, jaccard_score  \n\n# Boosting Algorithms :\nfrom xgboost                          import XGBClassifier\nfrom lightgbm                         import LGBMClassifier\n\n# Data Visualization Libraries :\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.io as pio\nimport plotly.graph_objects as go\nimport plotly.express as px","metadata":{"execution":{"iopub.status.busy":"2021-07-16T14:56:36.201915Z","iopub.execute_input":"2021-07-16T14:56:36.202525Z","iopub.status.idle":"2021-07-16T14:56:38.945477Z","shell.execute_reply.started":"2021-07-16T14:56:36.202491Z","shell.execute_reply":"2021-07-16T14:56:38.944831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(0)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T14:56:41.151744Z","iopub.execute_input":"2021-07-16T14:56:41.152089Z","iopub.status.idle":"2021-07-16T14:56:41.156445Z","shell.execute_reply.started":"2021-07-16T14:56:41.15206Z","shell.execute_reply":"2021-07-16T14:56:41.155842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ### 2. Import the dataset","metadata":{}},{"cell_type":"markdown","source":"Created a list to store the state, here I have included the state Florida-FL.Since it is alist we can add multiple states in it.\n\nLet's read the data from data source and check the attribite State, whether it contains the state Florida.And it provides the information of column names","metadata":{}},{"cell_type":"code","source":"# Import the data\nstate_lst=['FL']\ndf = pd.read_csv('/kaggle/input/us-accidents/US_Accidents_Dec20_Updated.csv')\ndf = df[df.State.isin(state_lst)]\ndf.info()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-16T14:57:21.001292Z","iopub.execute_input":"2021-07-16T14:57:21.001918Z","iopub.status.idle":"2021-07-16T14:57:49.598664Z","shell.execute_reply.started":"2021-07-16T14:57:21.001878Z","shell.execute_reply":"2021-07-16T14:57:49.597649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display Descriptive Statistics of data :\n\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T14:57:55.941648Z","iopub.execute_input":"2021-07-16T14:57:55.942064Z","iopub.status.idle":"2021-07-16T14:57:56.127271Z","shell.execute_reply.started":"2021-07-16T14:57:55.942029Z","shell.execute_reply":"2021-07-16T14:57:56.126226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display No of Unqiue Values and Actual Unique Values :\n\ndef display_unique(data):\n    for column in data.columns :\n        \n        print(\"No of Unique Values in \"+column+\" Column are : \"+str(data[column].nunique()))\n        print(\"Actual Unique Values in \"+column+\" Column are : \"+str(data[column].sort_values(ascending=True,na_position='last').unique() ))\n        print(\"\")\n        \ndisplay_unique(df)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T14:58:00.076593Z","iopub.execute_input":"2021-07-16T14:58:00.077001Z","iopub.status.idle":"2021-07-16T14:58:12.794126Z","shell.execute_reply.started":"2021-07-16T14:58:00.076962Z","shell.execute_reply":"2021-07-16T14:58:12.792874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.Feature addition\n\nWe decided to decompose the Start_Time feature in year, month, day, weekday, hour and minute, in order to feed them to the models.","metadata":{}},{"cell_type":"code","source":"# Cast Start_Time to datetime \n\ndf[\"Start_Time\"] = pd.to_datetime(df[\"Start_Time\"])\n\n# Extract year, month, weekday and day\ndf[\"Year\"] = df[\"Start_Time\"].dt.year\ndf[\"Month\"] = df[\"Start_Time\"].dt.month\ndf[\"Weekday\"] = df[\"Start_Time\"].dt.weekday\ndf[\"Day\"] = df[\"Start_Time\"].dt.day\n\n# Extract hour and minute\ndf[\"Hour\"] = df[\"Start_Time\"].dt.hour\ndf[\"Minute\"] = df[\"Start_Time\"].dt.minute\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T14:58:17.821712Z","iopub.execute_input":"2021-07-16T14:58:17.822177Z","iopub.status.idle":"2021-07-16T14:58:18.274488Z","shell.execute_reply.started":"2021-07-16T14:58:17.822145Z","shell.execute_reply":"2021-07-16T14:58:18.273517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.parallel_categories(df[[\"Side\", \"City\", \"Weekday\", \"Day\",\"Hour\",\"Minute\", \"Civil_Twilight\",\n                                   \"Severity\"]], \n                             color=\"Severity\", \n                             color_continuous_scale=px.colors.sequential.Aggrnyl  )\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T14:59:04.212463Z","iopub.execute_input":"2021-07-16T14:59:04.212845Z","iopub.status.idle":"2021-07-16T14:59:11.080237Z","shell.execute_reply.started":"2021-07-16T14:59:04.212792Z","shell.execute_reply":"2021-07-16T14:59:11.079025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,10))\nsns.heatmap(df.corr(), annot = True);\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T14:59:26.042351Z","iopub.execute_input":"2021-07-16T14:59:26.042692Z","iopub.status.idle":"2021-07-16T14:59:31.442889Z","shell.execute_reply.started":"2021-07-16T14:59:26.042665Z","shell.execute_reply":"2021-07-16T14:59:31.441926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature selection:\n \n Here is the process of feature selection, in order to select the best features from which  our models can learn.\n\nFrom the observations made with the correlation matrix, we are going to drop some of the features.","metadata":{}},{"cell_type":"code","source":"features_to_drop = [\"ID\", \"Start_Time\", \"End_Time\", \"End_Lat\", \"End_Lng\",\"Description\", \"Number\", \"Street\", \"County\", \"State\", \"Zipcode\",\n                    \"Country\", \"Timezone\", \"Airport_Code\", \"Weather_Timestamp\", \"Wind_Chill(F)\", \"Turning_Loop\", \"Sunrise_Sunset\", \"Nautical_Twilight\", \"Astronomical_Twilight\",\"City\",\"Civil_Twilight\",\"Bump\",\"Give_Way\",\"No_Exit\",\"Roundabout\",\"Traffic_Calming\"]\ndf=df.drop(features_to_drop, axis=1)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:00:00.107261Z","iopub.execute_input":"2021-07-16T15:00:00.107816Z","iopub.status.idle":"2021-07-16T15:00:00.152178Z","shell.execute_reply.started":"2021-07-16T15:00:00.107772Z","shell.execute_reply":"2021-07-16T15:00:00.151306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. Check for Duplicate Rows from Data if present :","metadata":{}},{"cell_type":"code","source":"# Python Method 4 : Removes Data Duplicates while Retaining the First one - Similar to SQL DISTINCT :\n\ndef remove_duplicate(data):\n    \n    print(\"BEFORE REMOVING DUPLICATES - No. of Rows = \",data.shape[0])\n    data.drop_duplicates(keep=\"first\", inplace=True) \n    print(\"AFTER REMOVING DUPLICATES  - No. of Rows = \",data.shape[0])\n    \n    return \"Checked Duplicates\"\n\n# Remove Duplicates from data :\n\nremove_duplicate(df)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:00:06.611646Z","iopub.execute_input":"2021-07-16T15:00:06.612089Z","iopub.status.idle":"2021-07-16T15:00:06.862731Z","shell.execute_reply.started":"2021-07-16T15:00:06.612037Z","shell.execute_reply":"2021-07-16T15:00:06.861634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5. Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"If we analyze the weather conditions, we can see that there are lots of them, so it's better to reduce the number of unique conditions.","metadata":{}},{"cell_type":"code","source":"#train Data\nunique_weather = df[\"Weather_Condition\"].unique()\n\nprint(len(unique_weather))\nprint(unique_weather)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:00:21.121473Z","iopub.execute_input":"2021-07-16T15:00:21.121852Z","iopub.status.idle":"2021-07-16T15:00:21.154223Z","shell.execute_reply.started":"2021-07-16T15:00:21.121821Z","shell.execute_reply":"2021-07-16T15:00:21.153232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To do so, we are going to replace them with a more generic description:","metadata":{}},{"cell_type":"code","source":"df.loc[df[\"Weather_Condition\"].str.contains(\"Thunder|T-Storm\", na=False), \"Weather_Condition\"] = \"Thunderstorm\"\ndf.loc[df[\"Weather_Condition\"].str.contains(\"Snow|Sleet|Wintry\", na=False), \"Weather_Condition\"] = \"Snow\"\ndf.loc[df[\"Weather_Condition\"].str.contains(\"Rain|Drizzle|Shower\", na=False), \"Weather_Condition\"] = \"Rain\"\ndf.loc[df[\"Weather_Condition\"].str.contains(\"Wind|Squalls\", na=False), \"Weather_Condition\"] = \"Windy\"\ndf.loc[df[\"Weather_Condition\"].str.contains(\"Hail|Pellets\", na=False), \"Weather_Condition\"] = \"Hail\"\ndf.loc[df[\"Weather_Condition\"].str.contains(\"Fair\", na=False), \"Weather_Condition\"] = \"Clear\"\ndf.loc[df[\"Weather_Condition\"].str.contains(\"Cloud|Overcast\", na=False), \"Weather_Condition\"] = \"Cloudy\"\ndf.loc[df[\"Weather_Condition\"].str.contains(\"Mist|Haze|Fog\", na=False), \"Weather_Condition\"] = \"Fog\"\ndf.loc[df[\"Weather_Condition\"].str.contains(\"Sand|Dust\", na=False), \"Weather_Condition\"] = \"Sand\"\ndf.loc[df[\"Weather_Condition\"].str.contains(\"Smoke|Volcanic Ash\", na=False), \"Weather_Condition\"] = \"Smoke\"\ndf.loc[df[\"Weather_Condition\"].str.contains(\"N/A Precipitation\", na=False), \"Weather_Condition\"] = np.nan\n\nprint(df[\"Weather_Condition\"].unique())","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:00:26.251412Z","iopub.execute_input":"2021-07-16T15:00:26.251745Z","iopub.status.idle":"2021-07-16T15:00:28.231907Z","shell.execute_reply.started":"2021-07-16T15:00:26.251715Z","shell.execute_reply":"2021-07-16T15:00:28.230929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's check also the Wind_Direction field:","metadata":{}},{"cell_type":"code","source":"df[\"Wind_Direction\"].unique()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:00:35.801481Z","iopub.execute_input":"2021-07-16T15:00:35.801852Z","iopub.status.idle":"2021-07-16T15:00:35.832415Z","shell.execute_reply.started":"2021-07-16T15:00:35.80182Z","shell.execute_reply":"2021-07-16T15:00:35.831624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, we can group the values like we did with Weather_Condition:","metadata":{}},{"cell_type":"code","source":"df.loc[df[\"Wind_Direction\"] == \"CALM\", \"Wind_Direction\"] = \"Calm\"\ndf.loc[df[\"Wind_Direction\"] == \"VAR\", \"Wind_Direction\"] = \"Variable\"\ndf.loc[df[\"Wind_Direction\"] == \"East\", \"Wind_Direction\"] = \"E\"\ndf.loc[df[\"Wind_Direction\"] == \"North\", \"Wind_Direction\"] = \"N\"\ndf.loc[df[\"Wind_Direction\"] == \"South\", \"Wind_Direction\"] = \"S\"\ndf.loc[df[\"Wind_Direction\"] == \"West\", \"Wind_Direction\"] = \"W\"\n\ndf[\"Wind_Direction\"] = df[\"Wind_Direction\"].map(lambda x : x if len(x) != 3 else x[1:], na_action=\"ignore\")\n\ndf[\"Wind_Direction\"].unique()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:00:40.321288Z","iopub.execute_input":"2021-07-16T15:00:40.321675Z","iopub.status.idle":"2021-07-16T15:00:40.670363Z","shell.execute_reply.started":"2021-07-16T15:00:40.321639Z","shell.execute_reply":"2021-07-16T15:00:40.669503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the Missing Values in Data :\n\nprint(\"Data : \")\ndisplay(df.isnull().sum())\n","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:00:46.941081Z","iopub.execute_input":"2021-07-16T15:00:46.941469Z","iopub.status.idle":"2021-07-16T15:00:47.027981Z","shell.execute_reply.started":"2021-07-16T15:00:46.941434Z","shell.execute_reply":"2021-07-16T15:00:47.027174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split Train and Test Data","metadata":{}},{"cell_type":"code","source":"total_size=len(df)\n\ntrain_size=math.floor(0.66*total_size) \ndisplay\n#training dataset\ntrain=df.head(train_size)\n#test dataset\ntest=df.head(len(df) -train_size)\ndisplay('Total Size:',total_size)\ndisplay('Train Size:',train_size)\n\ndisplay('Train Head :',train)\ndisplay('Test Head :',test.head())","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:03:11.602175Z","iopub.execute_input":"2021-07-16T15:03:11.602577Z","iopub.status.idle":"2021-07-16T15:03:11.708353Z","shell.execute_reply.started":"2021-07-16T15:03:11.602545Z","shell.execute_reply":"2021-07-16T15:03:11.707701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Feature scaling: Split Train Data into Predictors(Independent) & Target(Dependent) :**","metadata":{}},{"cell_type":"code","source":"X_train = train[['Side','Wind_Direction','Day','Month','Year','Hour']]\n\ny_train = train['Severity']\ny_train = y_train.to_frame()\n\nX_test = test[['Side','Wind_Direction','Day','Month','Year','Hour']]\ny_test = test['Severity']\ny_test = y_test.to_frame()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:06:11.792619Z","iopub.execute_input":"2021-07-16T15:06:11.793036Z","iopub.status.idle":"2021-07-16T15:06:11.80962Z","shell.execute_reply.started":"2021-07-16T15:06:11.793005Z","shell.execute_reply":"2021-07-16T15:06:11.808586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.Data Encoding : Label Encoding, OneHot Encoding","metadata":{}},{"cell_type":"code","source":"def data_encoding( encoding_strategy , encoding_data , encoding_columns ):\n    \n    if encoding_strategy == \"LabelEncoding\":\n        print(\"IF LabelEncoding\")\n        Encoder = LabelEncoder()\n        for column in encoding_columns :\n            print(\"column\",column )\n            encoding_data[ column ] = Encoder.fit_transform(tuple(encoding_data[ column ]))\n        \n    elif encoding_strategy == \"OneHotEncoding\":\n        print(\"ELIF OneHotEncoding\")\n        encoding_data = pd.get_dummies(encoding_data)\n        \n    dtypes_list =['float64','float32','int64','int32']\n    encoding_data.astype( dtypes_list[0] ).dtypes\n    \n    return encoding_data","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:06:15.181349Z","iopub.execute_input":"2021-07-16T15:06:15.181687Z","iopub.status.idle":"2021-07-16T15:06:15.188231Z","shell.execute_reply.started":"2021-07-16T15:06:15.181659Z","shell.execute_reply":"2021-07-16T15:06:15.187009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Quote :\n# Applied One Hot Encoding - it will be applied to Object/Categorical Columns Only :\n# It's most common to one-hot encode these \"object\" columns, since they can't be plugged directly into most models. \n# Pandas offers a convenient function called \"get_dummies\" to get one-hot encodings.\n# Many machine learning algorithms cannot operate on label data directly. \n# They require all input variables and output variables to be numeric.\n# This means that categorical data must be converted to a numerical form.\n# a one-hot encoding can be applied to the integer representation. \n# This is where the integer encoded variable is removed and a new binary variable is added for each unique integer value.\n# - Jason Brownlee \n\ndata = [\"Red\",\"Blue\",\"Green\",\"Red\",\"Blue\",\"Blue\"] \n  \ndf = pd.DataFrame(data, columns = ['Color']) \n  \nprint(\"Before One Hot Encoding : \")\ndisplay(df)\nprint(\"\\nAfter One Hot Encoding : \")\ndisplay( pd.get_dummies(df) )","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:06:20.266292Z","iopub.execute_input":"2021-07-16T15:06:20.266624Z","iopub.status.idle":"2021-07-16T15:06:20.291083Z","shell.execute_reply.started":"2021-07-16T15:06:20.266596Z","shell.execute_reply":"2021-07-16T15:06:20.290018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoding_columns  = [ 'Side','Day', 'Week', 'Month', 'Hour' ]\nencoding_strategy = [ \"LabelEncoding\", \"OneHotEncoding\"]\n\nX_train_encode = data_encoding( encoding_strategy[1] , X_train , encoding_columns )\nX_test_encode =  data_encoding( encoding_strategy[1] , X_test  , encoding_columns )\n\n# Display Encoded Train and Test Features :\n\ndisplay(X_train_encode.head())\ndisplay(X_test_encode.head())","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:06:27.311726Z","iopub.execute_input":"2021-07-16T15:06:27.312121Z","iopub.status.idle":"2021-07-16T15:06:27.420182Z","shell.execute_reply.started":"2021-07-16T15:06:27.312086Z","shell.execute_reply":"2021-07-16T15:06:27.41937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Scaling : RobustScaler, StandardScaler, MinMaxScaler, MaxAbsScaler :**","metadata":{}},{"cell_type":"code","source":"def data_scaling( scaling_strategy , scaling_data , scaling_columns ):\n    \n    if    scaling_strategy ==\"RobustScaler\" :\n        scaling_data[scaling_columns] = RobustScaler().fit_transform(scaling_data[scaling_columns])\n        \n    elif  scaling_strategy ==\"StandardScaler\" :\n        scaling_data[scaling_columns] = StandardScaler().fit_transform(scaling_data[scaling_columns])\n        \n    elif  scaling_strategy ==\"MinMaxScaler\" :\n        scaling_data[scaling_columns] = MinMaxScaler().fit_transform(scaling_data[scaling_columns])\n        \n    elif  scaling_strategy ==\"MaxAbsScaler\" :\n        scaling_data[scaling_columns] = MaxAbsScaler().fit_transform(scaling_data[scaling_columns])\n        \n    else :  # If any other scaling send by mistake still perform Robust Scalar\n        scaling_data[scaling_columns] = RobustScaler().fit_transform(scaling_data[scaling_columns])\n    \n    return scaling_data","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:06:32.936607Z","iopub.execute_input":"2021-07-16T15:06:32.936973Z","iopub.status.idle":"2021-07-16T15:06:32.944182Z","shell.execute_reply.started":"2021-07-16T15:06:32.936942Z","shell.execute_reply":"2021-07-16T15:06:32.942882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RobustScaler is better in handling Outliers :\n\nscaling_strategy = [\"RobustScaler\", \"StandardScaler\",\"MinMaxScaler\",\"MaxAbsScaler\"]\nX_train = data_scaling( scaling_strategy[0] , X_train_encode , X_train_encode.columns )\nX_test  = data_scaling( scaling_strategy [0] , X_test_encode  , X_test_encode.columns )\n\n# Display Scaled Train and Test Features :\n\ndisplay(X_train.head())\ndisplay(X_test.head())","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:06:37.501266Z","iopub.execute_input":"2021-07-16T15:06:37.501609Z","iopub.status.idle":"2021-07-16T15:06:38.617928Z","shell.execute_reply.started":"2021-07-16T15:06:37.50158Z","shell.execute_reply":"2021-07-16T15:06:38.616928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7. Create Baseline ML Model for Binary Classification Problem :","metadata":{}},{"cell_type":"markdown","source":"**1. Logistic regression**","metadata":{}},{"cell_type":"code","source":"# Logistic regression with default setting.\n\nclf = LogisticRegression(max_iter=10000,random_state=42)\nclf.fit(X_train, y_train)\naccuracy_train = clf.score(X_train, y_train)\naccuracy_test = clf.score(X_test,y_test)\nprint(\"Train Accuracy: %.1f%%\"% (accuracy_train*100))\nprint(\"Test Accuracy: %.1f%%\"% (accuracy_test*100))","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:07:01.386854Z","iopub.execute_input":"2021-07-16T15:07:01.387242Z","iopub.status.idle":"2021-07-16T15:07:16.627164Z","shell.execute_reply.started":"2021-07-16T15:07:01.387207Z","shell.execute_reply":"2021-07-16T15:07:16.624561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the f1 score\n\nlr_cal = clf.predict(X_test)\n\n# Calculate the f1 score\nf1_lr = f1_score(y_test, lr_cal, average='weighted') \nprint(\"F1 Score: %3.4f\" %(f1_lr))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:07:20.421244Z","iopub.execute_input":"2021-07-16T15:07:20.421645Z","iopub.status.idle":"2021-07-16T15:07:20.490258Z","shell.execute_reply.started":"2021-07-16T15:07:20.421609Z","shell.execute_reply":"2021-07-16T15:07:20.487974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2. Decision Tree**","metadata":{}},{"cell_type":"code","source":"# Training step, on X_train with y_train\ntree_clf = tree.DecisionTreeClassifier(min_samples_split = 5)\ntree_clf = tree_clf.fit(X_train,y_train)\n\ntree_accuracy_train = tree_clf.score(X_train, y_train)\ntree_accuracy_test = tree_clf.score(X_test,y_test)\nprint(\"Train Accuracy: %.1f%%\"% (tree_accuracy_train*100))\nprint(\"Test Accuracy: %.1f%%\"% (tree_accuracy_test*100))","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:07:28.131587Z","iopub.execute_input":"2021-07-16T15:07:28.131989Z","iopub.status.idle":"2021-07-16T15:07:28.736298Z","shell.execute_reply.started":"2021-07-16T15:07:28.131959Z","shell.execute_reply":"2021-07-16T15:07:28.735128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tree_cal = tree_clf.predict(X_test)\n\n# Calculate the f1 score\nf1_tree = f1_score(y_test, tree_cal, average='weighted') \nprint(\"F1 Score: %3.4f\" %(f1_tree))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:07:33.320934Z","iopub.execute_input":"2021-07-16T15:07:33.321325Z","iopub.status.idle":"2021-07-16T15:07:33.380825Z","shell.execute_reply.started":"2021-07-16T15:07:33.32129Z","shell.execute_reply":"2021-07-16T15:07:33.3799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3. Random Forest**","metadata":{}},{"cell_type":"code","source":"%%time\n\nrf_clf=RandomForestClassifier(n_estimators=10)\nrf_clf.fit(X_train,y_train)\n\ntrain_pred =  rf_clf.predict(X_train)\ntest_pred =rf_clf.predict(X_test)\n\nrf_train_accuracy = accuracy_score(y_train, train_pred)\nrf_test_accuracy = accuracy_score(y_test, test_pred)\n\nprint(\"Train Accuracy: %.1f%%\"% (rf_train_accuracy*100))\nprint(\"Test Accuracy: %.1f%%\"% (rf_test_accuracy*100))","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:07:36.981236Z","iopub.execute_input":"2021-07-16T15:07:36.981632Z","iopub.status.idle":"2021-07-16T15:07:39.193186Z","shell.execute_reply.started":"2021-07-16T15:07:36.981597Z","shell.execute_reply":"2021-07-16T15:07:39.192255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_cal = tree_clf.predict(X_test)\n\n# Calculate the f1 score\nf1_rf = f1_score(y_test, rf_cal, average='weighted') \nprint(\"F1 Score: %3.4f\" %(f1_rf))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:07:42.266176Z","iopub.execute_input":"2021-07-16T15:07:42.266565Z","iopub.status.idle":"2021-07-16T15:07:42.324346Z","shell.execute_reply.started":"2021-07-16T15:07:42.266532Z","shell.execute_reply":"2021-07-16T15:07:42.323417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**4. XGBoost**","metadata":{}},{"cell_type":"code","source":"xgb_clf = XGBClassifier(n_estimators=100)\n\nxgb_clf.fit(X_train,y_train)\n\n# predict the target on the train & test  dataset\npredict_train = xgb_clf.predict(X_train)\npredict_test = xgb_clf.predict(X_test)\n\n# Accuracy Score on train & test dataset\n\nxgb_accuracy_train = accuracy_score(y_train,predict_train)\nxgb_accuracy_test = accuracy_score(y_test,predict_test)\n\nprint('Train Accuracy: %.1f' %(xgb_accuracy_train*100) )\nprint('Test Accuracy:%.1f' %(xgb_accuracy_test*100))","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:07:46.901398Z","iopub.execute_input":"2021-07-16T15:07:46.901784Z","iopub.status.idle":"2021-07-16T15:08:11.317968Z","shell.execute_reply.started":"2021-07-16T15:07:46.901749Z","shell.execute_reply":"2021-07-16T15:08:11.316989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_cal = xgb_clf.predict(X_test)\n\n# Calculate the f1 score\nf1_xgb = f1_score(y_test, xgb_cal, average='weighted') \nprint(\"F1 Score: %3.4f\" %(f1_xgb))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:08:14.971137Z","iopub.execute_input":"2021-07-16T15:08:14.971502Z","iopub.status.idle":"2021-07-16T15:08:15.275645Z","shell.execute_reply.started":"2021-07-16T15:08:14.971461Z","shell.execute_reply":"2021-07-16T15:08:15.274516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Report\n\nCalculated the F1_score for above algorithms. The final report table of 4 algorithm as below,\n","metadata":{}},{"cell_type":"code","source":"# Report\ntrain_data=[(accuracy_train*100), (tree_accuracy_train*100), (rf_train_accuracy*100),(xgb_accuracy_train*100)]\ntest_data=[(accuracy_test*100), (tree_accuracy_test*100), (rf_test_accuracy*100),(xgb_accuracy_test*100)]\n\n\nF1_score = [f1_lr,f1_tree,f1_rf,f1_xgb]\n\n    \ndf = {'Algorithm': ['LogisticRegression','Decision Tree','Random Forest','XGBOOST'], \\\n     'Train Data':train_data,'Test Data':test_data,'F1-score': F1_score}\n\nReport = pd.DataFrame(data=df, columns=['Algorithm','Train Data', 'Test Data', 'F1-score'], index=None)\nReport","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:08:22.592523Z","iopub.execute_input":"2021-07-16T15:08:22.592927Z","iopub.status.idle":"2021-07-16T15:08:22.609684Z","shell.execute_reply.started":"2021-07-16T15:08:22.592897Z","shell.execute_reply":"2021-07-16T15:08:22.608888Z"},"trusted":true},"execution_count":null,"outputs":[]}]}