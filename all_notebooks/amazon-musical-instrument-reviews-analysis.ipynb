{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this notebook, we are trying to do some data visualization and sentiment classification modelling on Amazon Musical Instrument Reviews dataset.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading the data and modifying some features","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/amazon-music-reviews/Musical_instruments_reviews.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some notes regarding the columns:\n* asin : product ID\n* helpful : the first number represents the number of people who vote the review as useful, the second number represents represents the number of people who vote the review as useful and not useful\n* overall : product rating given by the reviewer\n\n\nColumns to be removed: reviewerID, reviewerName, unixReviewTime, reviewTime\n\n\nNew columns to be made:\n* sentiment : rating of 5.0 and 4.0 = 'positive, 3.0 = 'neutral', 2.0 and 1.0 = 'negative'\n* helpful_pct : percentage of review's helpfulness\n* length\n* reviewYear","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['reviewerID','reviewerName'],axis=1)\ndf = df.rename(columns={'asin':'productID', 'overall':'rating', 'unixReviewTime':'unixTime'})\ndf.isnull().sum().sort_values(ascending=False)\ndf = df.dropna()\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df['reviewTime'] = pd.to_datetime(df['reviewTime'])\ndf['reviewYear'] = df['reviewTime'].dt.year\ndf = df.drop(['unixTime','reviewTime'],axis=1)\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"def length(text):\n    return len(text)\n\ndf['length'] = df['reviewText'].apply(length)\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df['sentiment'] = df['rating']\ndf['sentiment'] = df['sentiment'].replace({\n    1:'negative',\n    2:'negative',\n    3:'neutral',\n    4:'positive',\n    5:'positive'\n})\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"def help_yes1(text):\n    return text.split(',')[0]\n\ndef help_yes2(text):\n    return text.split('[')[1]\n\ndef help_yesno1(text):\n    return text.split(' ')[1]\n\ndef help_yesno2(text):\n    return text.split(']')[0]\n\ndf['helpful_yes'] = df['helpful'].apply(help_yes1).apply(help_yes2).astype(int)\ndf['helpful_yesno'] = df['helpful'].apply(help_yesno1).apply(help_yesno2).astype(int)\n\ndf['helpful_pct'] = df['helpful_yes']/df['helpful_yesno']\ndf['helpful_pct'] = df['helpful_pct'].fillna(0)\n\ndf = df.drop(['helpful_yes','helpful_yesno'],axis=1)\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[['productID','summary','reviewText','rating','sentiment','helpful','helpful_pct','length','reviewYear']]\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data visualization","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First, we are finding out the ratings given by all reviewers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=[10,5])\nsns.countplot(df['rating'],palette='Wistia').set_title('Music Instrument Ratings Countplot')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.offline as py\nimport plotly.graph_objs as go\n\nscore = df['rating'].value_counts()\n\nlabels = score.index\nvalues = score.values\n\nscores = go.Pie(labels = labels,\n               values = values,\n               hole = 0.25)\n\ndf_scores = [scores]\n\nlayout = go.Layout(\n           title = 'Percentage of Ratings for Amazon Musical Instruments')\n\nfig = go.Figure(data = df_scores,\n                 layout = layout)\n\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's define \"helpful reviews\" as ones with helpful percentage of more than 75%. Then we'll find out if the rating distribution of helpful reviews only is different with the ratings from all reviews.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_h = df[df['helpful_pct'] > 0.75]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_h = df_h['rating'].value_counts()\n\nlabels_h = score_h.index\nvalues_h = score_h.values\n\nscores_h = go.Pie(labels = labels_h,\n               values = values_h,\n               hole = 0.25)\n\ndf_scoresh = [scores_h]\n\nlayout_h = go.Layout(\n           title = 'Percentage of Ratings for Amazon Musical Instruments (helpful reviews only)')\n\nfig_h = go.Figure(data = df_scoresh,\n                 layout = layout_h)\n\npy.iplot(fig_h)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Virtually identical.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's find out some of the most reviewed products","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"color = plt.cm.plasma(np.linspace(0, 1, 15))\ndf['productID'].value_counts()[:20].plot.bar(color = color, figsize = (10, 5))\nplt.title('20 Most Reviewed Products', fontsize = 20)\nplt.xlabel('Product ID')\nplt.ylabel('Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualizing the reviews based on reviews' year","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"year = df['reviewYear'].value_counts()\n\nlabels = year.index\nvalues = year.values\n\nyears = go.Pie(labels = labels,\n               values = values,\n               hole = 0.25)\n\ndf_years = [years]\n\nlayout = go.Layout(\n           title = 'Percentage of Years for Amazon Musical Instruments Review')\n\nfig = go.Figure(data = df_years,\n                 layout = layout)\n\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=[10,5])\nsns.countplot(df['reviewYear'],hue=df['sentiment'],palette='Wistia')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is an upward trend of popularity.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Based on ratings given by individual reviews, we will generate each product's rating. We'll create a DataFrame consisting of product IDs and the respective ratings, and do some visualization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"product_rating = {}\n\nfor row, product in enumerate(df['productID'].unique()):\n    product_temp = df[df['productID'] == product]\n    product_rating[product] = product_temp['rating'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_product_rating = pd.DataFrame(list(product_rating.items()), columns=['productID','rating'])\n\ndf_product_rating.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=[10,5])\nsns.distplot(df_product_rating['rating'],bins=35,kde=False).set_title('Distribution of Musical Instrument Ratings')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like there are a few product with rating below 3. Let's find out the rating of the lowest rated product.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_product_rating[df_product_rating['rating'] == df_product_rating['rating'].min()])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2.71 is obviously a bad rating. Let's find out its reviews.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df[df['productID'] == 'B0025V1REU'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 3 negative ratings, let's read them.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bruh = df[(df['productID'] == 'B0025V1REU') & (df['sentiment'] == 'negative')]\ndf_bruh['reviewText'].iloc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bruh['reviewText'].iloc[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bruh['reviewText'].iloc[2]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yes, they are really dissapointed.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's explore the reviews' length","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['length'].plot(bins=50,kind='hist')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems that we have a very long review. Why don't we sit back and read the entirety of the longest review?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['length'] == df['length'].max()]['reviewText'].iloc[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So this is a very thorough and elaborate reviews. Do other people find it useful?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('rating: ', df[df['length'] == df['length'].max()]['rating'].iloc[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('helpful: ', df[df['length'] == df['length'].max()]['helpful'].iloc[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yes, of course.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"This is a violin plot of rating vs review text length.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=[10,5])\nsns.violinplot(df['rating'], df['length'], palette='Wistia')\nplt.title('Rating vs Length', fontsize = 20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the last visualization, let's make a word cloud.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\n\ncv = CountVectorizer(stop_words = 'english')\nwords = cv.fit_transform(df['reviewText'])\nsum_words = words.sum(axis=0)\n\n\nwords_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]\nwords_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\nfrequency = pd.DataFrame(words_freq, columns=['word', 'freq'])\n\nwordcloud = WordCloud().generate_from_frequencies(dict(words_freq))\n\nplt.figure(figsize=(10, 10))\nplt.axis('off')\nplt.imshow(wordcloud)\nplt.title(\"Most Common Words\", fontsize = 20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building a sentiment classification model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Text processing consists of removing all punctuations and removing all stopwords","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_p = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\nfrom nltk.corpus import stopwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def text_process(review):\n    \"\"\"\n    Takes in a string of text, then perform the following:\n    1. Remove all punctuations\n    2. Remove all stopwords\n    3. Return a list of cleaned text\n    \"\"\"\n    # Check characters to see if they are in punctuation\n    nopunc = [char for char in review if char not in string.punctuation]\n    \n    # Join the characters again to form the string\n    nopunc = ''.join(nopunc)\n    \n    # Remove stopwords\n    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_p['reviewText'] = df_p['reviewText'].apply(text_process)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_p['reviewText'].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train-test split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntext_train, text_test, sent_train, sent_test = train_test_split(df_p['reviewText'], df_p['sentiment'], test_size=0.3)\n\nprint(len(text_train), len(text_test), len(sent_train) + len(sent_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating a pipeline consists of CountVectorizer, TF-IDF Transformer, and classifier.\nWe are using Multinomial Naive-Bayes classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\n\npipeline = Pipeline([\n    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fitting the pipeline","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline.fit(text_train,sent_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Prediction and evaluation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = pipeline.predict(text_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(predictions,sent_test))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}