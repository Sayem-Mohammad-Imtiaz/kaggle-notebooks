{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\nimport seaborn as sns\nimport time\n\nfrom math import sqrt\nfrom numpy import loadtxt\nfrom itertools import product\nfrom tqdm import tqdm\nfrom numpy import loadtxt\n\nimport gc\nfrom sklearn import preprocessing \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_error,f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom catboost import CatBoostClassifier\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" \n    iterate through all the columns of a dataframe and \n    modify the data type to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print(('Memory usage of dataframe is {:.2f}' \n                     'MB').format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        print(str(col_type))\n        if str(col_type) == \"datetime64[ns]\":\n            continue\n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max <\\\n                  np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max <\\\n                   np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max <\\\n                   np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max <\\\n                   np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            elif str(col_type) != \"Timestamp\":\n                if c_min > np.finfo(np.float16).min and c_max <\\\n                   np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max <\\\n                   np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n    end_mem = df.memory_usage().sum() / 1024**2\n    print(('Memory usage after optimization is: {:.2f}' \n                              'MB').format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \n                                             / start_mem))\n    \n    return df\ndef df_info(df):\n    print(\"----------Top-5- Record----------\")\n    print(df.head(5))\n    print(\"-----------Information-----------\")\n    print(df.info())\n    print(\"-----------Data Types-----------\")\n    print(df.dtypes)\n    print(\"----------Missing value-----------\")\n    print(df.isnull().sum())\n    print(\"----------Null value-----------\")\n    print(df.isna().sum())\n    print(\"----------Shape of Data----------\")\n    print(df.shape)\n    print(\"----------description of Data----------\")\n    print(df.describe())\n    print(\"----------Uniques of Data----------\")\n    print(df.nunique())\n    print(\"------------Columns in data---------\")\n    print(df.columns)\n\ndef downcast_dtypes(df):\n    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n    int_cols = [c for c in df if df[c].dtype in [\"int64\", \"int32\"]]\n    df[float_cols] = df[float_cols].astype(np.float32)\n    df[int_cols] = df[int_cols].astype(np.int16)\n    return df\ndef model_performance_sc_plot( predictions, labels, title ):\n    min_val = max(max(predictions), max(labels))\n    max_val = min(min(predictions), min(labels))\n    \n    performance_df = pd.DataFrame({\"Labels\": labels})\n    performance_df[\"Predictions\"] = predictions\n    sns.jointplot(y = \"Labels\", x = \"Predictions\", data = performance_df,kind = \"reg\")\n    plt.plot([min_val,max_val],[min_val, max_val],\"m--\")\n    plt.title(title)\n    plt.show()\n    \ndef calculate_counts(column_name, ref_sets, extension_set):\n    ref_sets_ids = [set(ref[column_name]) for ref in ref_sets]\n    ext_ids = set(extension_set[column_name])\n    \n    refs_union = reduce(lambda s1, s2: s1 | s2, ref_sets_ids)\n    \n    ref_counts = [len(ref) for ref in ref_sets_ids]\n    ext_count = len(ext_ids)\n    union_count = len(refs_union)\n    intersection_count = len(ext_ids & refs_union)\n    \n    all_counts = ref_counts + [union_count, ext_count, intersection_count]\n    res_index = [\"Ref {}\".format(i) for i in range(1, len(ref_sets) + 1)] +\\\n        ['Refs Union', 'Extension', 'Union x Extension']\n    \n    return pd.DataFrame({'Count': all_counts},\n                        index=res_index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path = \"/kaggle/input/airplane-accidents-severity-dataset/train.csv\"\ntest_path = \"/kaggle/input/airplane-accidents-severity-dataset/test.csv\"\nsubmission_path = \"/kaggle/input/airplane-accidents-severity-dataset/sample_submission.csv\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(train_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_info(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"object_cols = [\"Severity\"]\n\nlb = LabelEncoder()\nlb.fit(train[object_cols])\ntrain[object_cols] = lb.transform(train[object_cols])\ntrain[\"Control_Metric\"] = train[\"Control_Metric\"].clip(25,100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Accident type code mean wrt control metric, Severity, Turbulence, Maxelevation, Adverse Weatehr"},{"metadata":{"trusted":true},"cell_type":"code","source":"means_accident_code = train.groupby([\"Accident_Type_Code\"]).agg({\"Severity\": \"mean\",\"Safety_Score\": \"mean\", \"Days_Since_Inspection\": \"mean\", \"Total_Safety_Complaints\" :\"mean\", \"Control_Metric\": \"mean\", \"Turbulence_In_gforces\" :\"mean\", \"Cabin_Temperature\": \"mean\", \"Max_Elevation\" :\"mean\",\"Violations\": \"mean\", \"Adverse_Weather_Metric\" : \"mean\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"means_accident_code = means_accident_code.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = list(means_accident_code.columns)\nfor i in range(1,len(cols)):\n    cols[i] = cols[i] + \"_mean\"\nprint(cols)\nmeans_accident_code.columns = cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.merge(means_accident_code, on = [\"Accident_Type_Code\"], how = \"left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train.groupby([\"Accident_Type_Code\", \"Severity\"])[\"Severity\"].agg({\"no\" : \"count\"})\nmask = df.groupby(level=0).agg('idxmax')\ndf_count = df.loc[mask['no']]\ndf_count.drop([\"no\"], axis = 1, inplace= True)\ndf_count = df_count.reset_index()\ndf_count.columns = [\"Accident_Type_Code\", \"Severity_max\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.merge(df_count, on = [\"Accident_Type_Code\"], how = \"left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop([\"Accident_Type_Code\"], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop([\"Severity\", \"Accident_ID\"], axis = 1)\nY = train[\"Severity\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(X,Y, test_size = 0.25)\nx_val1, x_val2, y_val1, y_val2 = train_test_split(x_val, y_val, test_size = 0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(test_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test.merge(means_accident_code, on = [\"Accident_Type_Code\"], how = \"left\")\ntest = test.merge(df_count, on = [\"Accident_Type_Code\"], how = \"left\")\ntest.drop([\"Accident_Type_Code\"], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = test.drop([\"Accident_ID\"], axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cb = CatBoostClassifier(iterations = 1000,\n                       max_ctr_complexity = 10,\n                       random_seed =  0,\n                       od_type = \"Iter\", \n                       od_wait = 50,\n                       verbose = 100,\n                       depth  = 12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nxgbRegressor = XGBClassifier(max_depth = 10, eta = 0.2,n_estimators = 500, colsample_bytree = 0.7,subsample = 0.7, seed = 0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nkf = KFold(n_splits = 5, shuffle = True)\ny_pred = np.zeros((Y.shape[0],1))\nfor train_index, test_index in kf.split(X):\n    x_train, y_train = X.loc[train_index,:] , Y[train_index]\n    x_val, y_val = X.loc[test_index,:] , Y[test_index]\n    cb.fit(x_train , y_train)\n    y_pred_cb = cb.predict(x_val)\n    y_pred[test_index] = y_pred_cb\n    print(\"F1_Score val1 : \", f1_score(y_val, y_pred_cb,average='weighted'))    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nkf = KFold(n_splits = 5, shuffle = True)\ny_pred_xg = np.zeros((Y.shape[0],1))\nfor train_index, test_index in kf.split(X):\n    x_train, y_train = X.loc[train_index,:] , Y[train_index]\n    x_val, y_val = X.loc[test_index,:] , Y[test_index]\n    xgbRegressor.fit(x_train , y_train, verbose = 100)\n    y_pred_x = xgbRegressor.predict(x_val)\n    y_pred_xg[test_index] = y_pred_x.reshape(-1,1)\n    print(\"F1_Score val1 : \", f1_score(y_val, y_pred_x,average='weighted'))    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cb.fit(X,Y)\ntest_pred_cb = cb.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgbRegressor.fit(X,Y)\ntest_pred_xg = xgbRegressor.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"first_level = pd.DataFrame(y_pred, columns = [\"catboost\"])\nfirst_level[\"XGB\"] = y_pred_xg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"first_level_test = pd.DataFrame(test_pred_cb, columns = [\"catboost\"])\nfirst_level_test[\"XGB\"] = test_pred_xg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"first_level_train, first_level_val , y_train, y_val = train_test_split(first_level, Y, test_size = 0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metamodel = XGBClassifier(max_depth = 8, eta = 0.2,n_estimators = 500, colsample_bytree = 0.7,subsample = 0.7, seed = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metamodel.fit(first_level_train, y_train, eval_set = [(first_level_train,y_train),(first_level_val, y_val)], verbose = 20, early_stopping_rounds = 120)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ensemble_pred = metamodel.predict(first_level_val)\ntest_pred = metamodel.predict(first_level_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Val F1-Score :\", f1_score(y_val, ensemble_pred, average = \"weighted\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_performance_sc_plot(ensemble_pred, y_val, \"Validation\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# xgbRegressor.fit(X, Y, eval_set = [(X,Y),(x_val1, y_val1)], verbose = 20, early_stopping_rounds = 120)\n# test_pred = xgbRegressor.predict(x_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = test_pred\ny_pred = y_pred.astype(np.int32)\ny_pred = lb.inverse_transform(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = []\nfor i in range(test.shape[0]):\n    ids.append(test.loc[i,\"Accident_ID\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame(ids, columns= [\"Accident_ID\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub[\"Severity\"] = y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv(\"Submission.csv\",index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}