{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split \nfrom imblearn import under_sampling, over_sampling\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/startup-success-prediction/startup data.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Check Dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data Preprocessing**"},{"metadata":{},"cell_type":"markdown","source":"**Check for missing values and duplicated data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_missing_value = data.isnull().sum().reset_index()\ndata_missing_value.columns = ['feature','missing_value']\ndata_missing_value['percentage'] = round((data_missing_value['missing_value']/len(data))*100,2)\ndata_missing_value = data_missing_value.sort_values('percentage', ascending=False).reset_index(drop=True)\ndata_missing_value = data_missing_value[data_missing_value['percentage']>0]\ndata_missing_value","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 5 missing value in this dataset, namely 'closed_at', 'Unnamed:6', 'age_last_milestone_year', 'age_first_milestone_year', and 'state_code.1'\n\nFirst, drop column Unnamed:6 and state_code.1 because this is useless features"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(['Unnamed: 6'], axis=1)\ndata = data.drop(['state_code.1'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"there is no duplicated data. But if we check the duplicated data with subset name, that will appear 1 duplicated data. Drop it"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.duplicated(subset=['name']).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=data.drop_duplicates(subset=['name'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we fill column 'age_first_milestone_year' and 'age_last_milestone_year' with 0. Zero is the the smallest value assumption for a company that has not passed its first milestone"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['age_first_milestone_year'] = data['age_first_milestone_year'].fillna(0)\ndata['age_last_milestone_year'] = data['age_last_milestone_year'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Add new feature 'Age'.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['closed_at'] = pd.to_datetime(data['closed_at'])\ndata['founded_at'] = pd.to_datetime(data['founded_at'])\n#convert to datetime data\n\ndata['last_date']=data['closed_at'] #copy data\ndata['last_date']=data['last_date'].fillna('2013-12-31')\ndata['last_date']=pd.to_datetime(data['last_date'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We fill column last_date with 2013-12-31 with assumption that is the last number of dataset "},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"founded_at\"] = pd.to_datetime(data[\"founded_at\"])\n\ndata[\"age\"] = (data[\"last_date\"]-data[\"founded_at\"])\ndata[\"age\"]=round(data.age/np.timedelta64(1,'Y'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we check it, there is minus number in here. Drop minus number"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[[ 'age', 'age_first_funding_year','age_last_funding_year', 'age_first_milestone_year',\n       'age_last_milestone_year']].sort_values('age').head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=data.drop(data[data.age<0].index)\ndata=data.drop(data[data.age_first_funding_year<0].index)\ndata=data.drop(data[data.age_last_funding_year<0].index)\ndata=data.drop(data[data.age_first_milestone_year<0].index)\ndata=data.drop(data[data.age_last_milestone_year<0].index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we check for distribution, there is some features with skewness disribution more than 2. Handling it with normalization."},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['age_first_funding_year', 'relationships','funding_total_usd',\n            'age_last_funding_year','age_first_milestone_year', \n            'age_last_milestone_year', 'funding_rounds', \n            'milestones','avg_participants', 'age']\ndata[features].skew(axis=0, skipna=True)>2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"norm = ['age_first_funding_year', 'relationships', 'funding_total_usd']\ndata = data\nfor var in norm:\n    data['norm_'+var]=MinMaxScaler().fit_transform(data[var].values.reshape(len(data),1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data Visualization**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_grp_3=data[data['labels']==1].groupby(['age']).agg({'labels':'count'}).reset_index()\ndata_grp_3.columns=['age','total_succes']\n\ndata_grp_4=data.groupby(['age']).agg({'labels':'count'}).reset_index()\ndata_grp_4.columns=['age','total']\n\ndata_grp_3=data_grp_3.merge(data_grp_4,\n                           on='age')\ndata_grp_3['succes_rate']=round((data_grp_3['total_succes']/data_grp_3['total'])*100,2)\n\ndata_grp_3\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,7))\n\ng = sns.barplot(x = 'age',y='succes_rate',data=data_grp_3,ax=ax, \n               palette=sns.color_palette(\"Blues_d\", n_colors=13, desat=1))\n\nx = np.arange(len(data_grp_3))\ny = data_grp_3['succes_rate']\n\nfor i, v in enumerate(y):\n    ax.text(x[i]- 0.1, v+3, str(v)+'%', fontsize = 12, color='gray', fontweight='bold')\n    \ntitle = '''\n\n'''\nax.text(2.80,30,title,horizontalalignment='left',color='black',fontsize=12,fontweight='bold')\n    \n\ntext = '''\n\n'''\nax.text(0.5,50,text,horizontalalignment='left',color='black',fontsize=16,fontweight='normal')\n    \nax.set_ylim(0,100)\n\nax.set_xticklabels(ax.get_xticklabels(),rotation=0);\nplt.tight_layout","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Business insight from age : startups that have lifespan of more than 4 years have a tendency to be successful startup (more than 52%)"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_grp_5=data[data['labels']==1].groupby(['milestones']).agg({'labels':'count'}).reset_index()\ndata_grp_5.columns=['milestones','total_succes']\n\ndata_grp_6=data.groupby(['milestones']).agg({'labels':'count'}).reset_index()\ndata_grp_6.columns=['milestones','total']\n\ndata_grp_5=data_grp_5.merge(data_grp_6,\n                           on='milestones')\ndata_grp_5['succes_rate']=round((data_grp_5['total_succes']/data_grp_5['total'])*100,2)\n\ndata_grp_5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,7))\n\ng = sns.barplot(x = 'milestones',y='succes_rate',data=data_grp_5,ax=ax, \n               palette=sns.color_palette(\"Blues_d\", n_colors=13, desat=1))\n\nx = np.arange(len(data_grp_5))\ny = data_grp_5['succes_rate']\n\nfor i, v in enumerate(y):\n    ax.text(x[i]- 0.1, v+3, str(v)+'%', fontsize = 12, color='gray', fontweight='bold')\n    \ntitle = '''\n\n'''\nax.text(2.80,30,title,horizontalalignment='left',color='black',fontsize=12,fontweight='bold')\n    \n\ntext = '''\n\n'''\nax.text(0.5,50,text,horizontalalignment='left',color='black',fontsize=16,fontweight='normal')\n    \nax.set_ylim(0,100)\n\nax.set_xticklabels(ax.get_xticklabels(),rotation=0)\nplt.tight_layout","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Business insight from milestone : Startups that have min 1 milestone has potential to be successful startup (more than 60%)"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Relationships Range'] = data['relationships'].apply(lambda x : 'relationship 0' if x==0 else 'relationships >10' if x>10 else 'relationships 1-10' )\ndata20 = data.groupby(['Relationships Range', 'labels']).agg({'id' : 'count'}).reset_index()\ndata20_pv = pd.pivot_table(data20,\n                          index=['Relationships Range'],\n                          columns=['labels'],\n                          values=['id']).reset_index()\ndata20_pv.columns = ['Relationships Range', 'Closed', 'Acquired']\ndata20_pv['Total Company'] = data20_pv['Closed']+data20_pv['Acquired']\ndata20_pv['Success Rate'] = round(data20_pv['Acquired']/data20_pv['Total Company']*100,2)\ndata20_pv\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(8,6))\n\ng = sns.barplot(x = 'Relationships Range',y='Success Rate',data=data20_pv,ax=ax, \n               palette=sns.color_palette(\"Blues_d\", n_colors=13, desat=1))\n\nx = np.arange(len(data20_pv['Relationships Range']))\ny = data20_pv['Success Rate']\n\nfor i, v in enumerate(y):\n    ax.text(x[i]- 0.1, v+3, str(v)+'%', fontsize = 20, color='gray', fontweight='bold')\n  \nax.set_xticklabels(ax.get_xticklabels(),rotation=0);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. Business insigt from relationship: startups with relationships more than 1 has potential to be successful startup (more than 61%)"},{"metadata":{},"cell_type":"markdown","source":"# **Training and Test Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split Feature Vector and Label\nX = data[['norm_relationships', 'norm_age_first_funding_year','norm_funding_total_usd',\n          \n          'age_last_funding_year',\n          'age_first_milestone_year', 'age_last_milestone_year', \n          'funding_rounds', 'milestones','age',\n\n          'is_CA', 'is_NY', 'is_MA', 'is_TX', 'is_otherstate', \n          'is_software', 'is_web', 'is_mobile', 'is_enterprise', 'is_advertising', 'is_gamesvideo', \n          'is_ecommerce', 'is_biotech', 'is_consulting','is_othercategory', \n          'has_VC', 'has_angel', 'has_roundA','has_roundB', 'has_roundC', 'has_roundD', \n          'avg_participants','is_top500'\n          ]]\ny = data['labels'] # target / label\n\n#Splitting the data into Train and Test\nX_train, X_test,y_train,y_test = train_test_split(X,\n                                                y,\n                                                test_size = 0.3,\n                                                random_state = 42)\n# Oversampling\nX_train, y_train = over_sampling.RandomOverSampler(random_state=42).fit_resample(X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Modeling with AdaBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"ab = AdaBoostClassifier(random_state=42)\nab.fit(X_train, y_train)\ny_predicted = ab.predict(X_test)\ny_predicted_train = ab.predict(X_train)\n\nprint('\\nconfusion matrix') # generate the confusion matrix\nprint(confusion_matrix(y_test, y_predicted))\nprint('\\naccuracy')\nprint(accuracy_score(y_test, y_predicted))\nprint('\\nclassification report')\nprint(classification_report(y_test, y_predicted)) # generate the precision, recall, f-1 score, num\nroc_auc_score(y_test, y_predicted)\n\nregression = AdaBoostClassifier(random_state=42)\nregression.fit(X_train, y_train)\nprint(\"Train Accuracy:\",regression.score(X_train, y_train))\nprint(\"Test Accuracy:\",regression.score(X_test, y_test))\n\nroc_auc_score(y_test, y_predicted)\nprint('AUC Score:',roc_auc_score(y_test, y_predicted))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Features Importances**"},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_importances = pd.Series(ab.feature_importances_, index=X.columns)\nax = feat_importances.nlargest(10).plot(kind='barh')\nax.invert_yaxis()\nplt.xlabel('score')\nplt.ylabel('feature')\nplt.title('feature importance score')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Business Simulation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predicted=pd.DataFrame(y_predicted)\ny_test=pd.DataFrame(y_test)\n\ny_test=y_test.reset_index()\ny_test=y_test.drop(['index'],axis=1)\n\nX_test['funding_total_usd']=data['funding_total_usd']\nX_test=X_test.reset_index()\nX_test=X_test.drop(['index'],axis=1)\n\nX_test['y_predicted']=y_predicted\nX_test['y_test']=y_test\nX_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Total Fail in start up:"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test[y_test['labels']==0].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predict True Fail Startup (True Negatif):"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test[(X_test['y_test']==0)&(X_test['y_predicted']==0)]['y_predicted'].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Total Success in startup:"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test[y_test['labels']==1].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predict True Success Startup(True Positif):"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test[(X_test['y_test']==1)&(X_test['y_predicted']==1)]['y_predicted'].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Total Invest without ML:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test['funding_total_usd'].sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we Invest without ML AdaBoost it will cost 5 Billion USD"},{"metadata":{},"cell_type":"markdown","source":"**Total Invest with ML:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test[(X_test['y_predicted']==1)]['funding_total_usd'].sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we invest with AdaBoost, it will cost 3.3 Billion USD. It's 34% effieciency invesment"},{"metadata":{},"cell_type":"markdown","source":"**Potential Loss without ML:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test[(X_test['y_test']==0)]['funding_total_usd'].sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Without AdaBoost, potential loss investment is 1.8 Billion USD"},{"metadata":{},"cell_type":"markdown","source":"**Potential Loss With ML:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test[(X_test['y_test']==0)&(X_test['y_predicted']==1)]['funding_total_usd'].sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With AdaBoost, potential loss is reducting until 82%. It just cost 300 Million USD"},{"metadata":{},"cell_type":"markdown","source":"**Saving Fund Investment with predict ML:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test[(X_test['y_test']==0)&(X_test['y_predicted']==0)]['funding_total_usd'].sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With ML AdaBoost, we are saving 1.5 Billion USD"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}