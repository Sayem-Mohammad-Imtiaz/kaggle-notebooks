{"cells":[{"metadata":{"_uuid":"2ad023b0af01c3b220112733948057a08f939c33"},"cell_type":"markdown","source":"# Exploring the WHO suicides data\n\nThis notebook employs a few simple techniques for exploring the WHO suicides dataset from Kaggle. \n### Table of Contents\n[Data preparation](#preparation)\n<br>\n[Visualizations](#visualizations)\n<br>\n[Transformations](#transformations)\n<br>\n[Predictions](#predictions)"},{"metadata":{"_uuid":"1cfb05a2f2ee2bc2860068bef02d02c5786b9cc8"},"cell_type":"markdown","source":"We'll load a few libraries that we may need in this analysis. "},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"b26c96953431a1d98e7dbc397a06c41d6694dcf6"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression, Lasso\nfrom sklearn.neighbors import KNeighborsRegressor\nimport matplotlib.pyplot as plt\nimport seaborn as sns; #sns.set()\nimport sklearn.metrics as metrics\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, cross_validate, KFold\n%matplotlib inline\nimport warnings\npd.options.mode.chained_assignment = None  # default='warn'\n# warnings.filterwarnings('ignore') # disable all warnings\nwarnings.filterwarnings(action='once') # warn only once","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10f2d0c2f52c33e99233334587a1257ee794b589"},"cell_type":"markdown","source":"<a id='preparation'></a>\n# Data preparation"},{"metadata":{"_uuid":"d51072094fbdf170bb6f1a967282e9082b43370a"},"cell_type":"markdown","source":"Let's load the data into a Pandas dataframe."},{"metadata":{"trusted":true,"_uuid":"9ab9a66aac4a290c54461973781a3c86a17fb852"},"cell_type":"code","source":"data = pd.read_csv('../input/who_suicide_statistics.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7eec3fb2d9b8c0915189bfc2d72551943af3e82b"},"cell_type":"markdown","source":"Take a peek at the first few rows of data, and view some summary statistics to get a high-level understanding of what's going on in the data."},{"metadata":{"trusted":false,"_uuid":"0f33dc2aefd128d2d550f24e1b408aa1ac769a76"},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"cd5bab328fdbc01a2306c5e9a6c2f8de3bcecb0e"},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"c51fc21b7c146fad4879bc5cafd954764dbb92c0"},"cell_type":"code","source":"data.astype('object').describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f7d9821c5e83e4b391343997cd621404ae7e5c8"},"cell_type":"markdown","source":"We saw some missing values in the first few rows (i.e. the NaNs). Let's find out how many missing values are in the data set. We'll first find how many missing values are in each column, then we'll calculate what proportion of the data points are missing."},{"metadata":{"trusted":false,"_uuid":"ed7690040cc62f5d1dd39b4d75d11cfe15d64557"},"cell_type":"code","source":"na_stats = pd.DataFrame([],columns=['count_na','prop_na'])\nna_stats['count_na'] = (data.isna().sum())\nna_stats['prop_na'] = (data.isna().sum()/data.shape[0])\nna_stats","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dddeb56b60647b05adc058e9c437cf6247b17474"},"cell_type":"markdown","source":"Ok so about 5% of the suicides_no and 12% of population data are missing. Let's see how this breaks down by country."},{"metadata":{"trusted":false,"_uuid":"179ce8085f58d1a1dbedad1d8a19bd188daee957"},"cell_type":"code","source":"nan_suicides = data.suicides_no.isnull().groupby([data['country']]).sum().astype(int).reset_index(name='count')\nnan_population = data.population.isnull().groupby([data['country']]).sum().astype(int).reset_index(name='count')\ncount_by_country = pd.DataFrame(data.groupby(data['country'])['suicides_no'].count())\ncount_by_country = count_by_country.reset_index()\n\nprop = pd.DataFrame([], columns = ['country', 'prop_suicides_nan', 'prop_population_nan'])\nprop['prop_suicides_nan'] = nan_suicides['count']/count_by_country['suicides_no']\nprop['prop_population_nan'] = nan_population['count']/count_by_country['suicides_no']\nprop['country'] = nan_suicides['country']\n\n# Only show countries that have some missing data.\nprop[prop['prop_suicides_nan'] > 0].sort_values(by=['prop_suicides_nan'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2af9655a520a2ed55f3d79e377c8259a0273e766"},"cell_type":"markdown","source":"So we can see that Mongolia, Switzerland, Denmark, San Marino, Cuba, and the Phillipines have mostly missing data for suicides, and Bermuda, the Cayman Islands, and Saint Kitts and Nevis have most of the population data missing. I'm not sure why this is, but for my porposes here, I'm OK with dropping entries missing values for now. There are methods for missing data imputation, but I've decided not going to do any imputation in this notebook.\n\nLet's go ahead and drop the missing value entries, this will make the data easier to work with."},{"metadata":{"trusted":false,"_uuid":"f61ba3df0dab3b3c98e897cecd2f33cf8218f0a1"},"cell_type":"code","source":"data_clean = data.dropna()\ndata_clean.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8fa949139686dcc2dbcd52179a8faeabe61343f1"},"cell_type":"markdown","source":"<a id='visualizations'></a>\n# Visualizations\nNow that we have the data cleaned up a bit, let's use some visualizations to get a sense of what trends and patterns might exist."},{"metadata":{"_uuid":"fb698181e47b030e70b940eb4a98d7e1eeaec119"},"cell_type":"markdown","source":"First we'll set a target country to examine, then we'll plot the number of suicides per year for each age group, and adjust the shape of the data point by gender."},{"metadata":{"trusted":false,"_uuid":"91ff189ce1c203b45a4e37203ccb57bb91564216"},"cell_type":"code","source":"target_country = \"United States\"\nfig, ax = plt.subplots(figsize=(12,6))\nax.set_title( 'Suicides by age ({})'.format(target_country))\np = sns.scatterplot(x=\"year\", y=\"suicides_no\", data=data_clean,hue='age',style='sex')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4025e2ea6aa483d8a4a8f394efe143428a94288d"},"cell_type":"markdown","source":"Now let's take a closer look at the differences in the number of suicides between men and women."},{"metadata":{"trusted":false,"_uuid":"9dbf08309e6a9614bb788287fd1fec6a2ec30724"},"cell_type":"code","source":"target_country = \"United States\"\nfig, ax = plt.subplots(figsize=(12,6))\nax.set_title( 'Suicides by sex ({})'.format(target_country))\nsui_by_sex = data_clean[data_clean[\"country\"].str.contains(target_country)].groupby(['sex','year'],as_index=False).sum()\np = sns.scatterplot(x=\"year\", y=\"suicides_no\", data=sui_by_sex,hue='sex')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70addc6342d37f9a5e498628c3e223253445c100"},"cell_type":"markdown","source":"<a id='transformations'></a>\n# Transforming the data"},{"metadata":{"_uuid":"334e7589faa22fa3a365fd1a8ca67b76c31c7141"},"cell_type":"markdown","source":"If we want to perform further analysis, it's a good idea to map the ages and genders to values."},{"metadata":{"trusted":false,"_uuid":"1cf057ba2c36767ee45ea7868685036709cb8143"},"cell_type":"code","source":"agemap = {}\ni = 0\nfor x in data.age.unique():\n    agemap[x] = i\n    i+=1\n\n# since there are only two values here, we can do a mapping for gender. If >2 types listed, we could do a one-hot encoding instead.\ngendermap = {}\ni = 0\nfor x in data.sex.unique():\n    gendermap[x] = i\n    i+=1\n    \ndata_clean['age_id'] = data['age'].map(agemap)\ndata_clean['sex_id'] = data['sex'].map(gendermap)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f26c416e07ab553d30ecbfe78151f8025221f84c"},"cell_type":"markdown","source":"Now we can drop the sex and age columns since we've completed the mapping and added it to the data set."},{"metadata":{"trusted":false,"_uuid":"fc55c5cf1683d69ce4a8aad6b64079282c717abc"},"cell_type":"code","source":"x = data_clean.drop(['sex','age'], axis = 1)\nx = pd.get_dummies(x)\ny = x[['suicides_no']]\nx = x.drop('suicides_no',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"327217f885834a187fd77442dcb51ec141f0d793"},"cell_type":"markdown","source":"Let's get a quick view of how the features of our dataset are correlated with each other."},{"metadata":{"trusted":false,"_uuid":"370963eb138483f8dfcc975ad92666450835083f"},"cell_type":"code","source":"corr = data_clean.corr()\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr, vmax=.3, cmap=cmap, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61c01cf3ad6895b6d72cc679cd638824517be2b4"},"cell_type":"markdown","source":"Population and suicides_no are correlated, which makes intuitive sense. sex_id and suicides_no are correlated as men tend to commit more suicides than women. Let's now see if male suicides are correlated with female suicides."},{"metadata":{"trusted":false,"_uuid":"7a15982ea309740432aedf71ec744809b2e546b7"},"cell_type":"code","source":"# Separate the suicides and population values by gender\ndata_by_gender = data_clean.loc[data_clean['sex_id'] == 1]\ndata_by_females = data_clean.loc[data_clean['sex_id'] == 0]\n#data_by_gender['f_suicides_no'] = data_by_gender.merge(data_by_females, on=['country', 'year', 'age'])[['suicides_no_y']]\ndata_by_gender.rename(columns={'suicides_no':'m_suicides_no'}, inplace=True)\ndata_by_gender.rename(columns={'population':'m_population'}, inplace=True)\n\n# Wrangle the data into the right format without redundant columns\ndata_by_gender = data_by_gender.merge(data_by_females, on=['country', 'year', 'age'])\ndata_by_gender = data_by_gender.drop(labels=['age','age_id_y','sex_x','sex_y','sex_id_y','sex_id_x'],axis=1)\ndata_by_gender.rename(columns={'population':'f_population', 'age_id_x': 'age_id'}, inplace=True)\ndata_by_gender.rename(columns={'suicides_no':'f_suicides_no'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"0559b4a94527cb1700e5b42085e0a7be5de6a507"},"cell_type":"code","source":"data_by_gender.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"82dabf8d8e5b32454c766f0da60502f65bc022ec"},"cell_type":"code","source":"x_s = pd.get_dummies(data_by_gender)\ny_s = x_s[['f_suicides_no','m_suicides_no']]\nx_s = x_s.drop(['f_suicides_no','m_suicides_no'],axis=1)\n\n# Just doing a sanity check to make sure the data looks the way we want it.\nx_s.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f0884c62aa0abddce01c381b5aa9ec87d7059c6c"},"cell_type":"markdown","source":"Looks good! Now that we've separated male and female suicides, let's see if they're correlated with each other."},{"metadata":{"trusted":false,"_uuid":"5947c26cf2cae120221879e67224b99a4c38fc04"},"cell_type":"code","source":"corr_by_gender = data_by_gender.corr()\nsns.heatmap(corr_by_gender, vmax=.3, cmap=cmap, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"adfa358965a5da414550a972a016820c2e030536"},"cell_type":"markdown","source":"It seems that and female suicides are slightly positively coorelated, whereas age and male suicides are slightly negatively correlated. Interesting! "},{"metadata":{"_uuid":"73298d2759c2630ee47e051da161bd5e545cabdd"},"cell_type":"markdown","source":"<a id='predictions'></a>\n# Predictions\nLet's use linear regression to try to predict the number of suicides given the rest of the data. We'll first train one model for all countries and age groups.\n"},{"metadata":{"_uuid":"f0d6fb427db2287341e41273cbe5ab27d57d31d0"},"cell_type":"markdown","source":"First, we'll split the data into training and test sets."},{"metadata":{"trusted":false,"_uuid":"210d547cfd9246d671dc5d66bb2a5c1894476d62"},"cell_type":"code","source":"# split into train/test\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=314)\n\n# and again by gender\nx_s_train, x_s_test, y_s_train, y_s_test = train_test_split(x_s, y_s, test_size=0.25, random_state=314)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bff21fe993ad7afd500960a8a8961f09b060baf3"},"cell_type":"markdown","source":"Now we can train a linear regression model to predict the number of suicides. "},{"metadata":{"scrolled":true,"trusted":false,"_uuid":"875ad46202f96c19c4a5bef33209be49b9c25106"},"cell_type":"code","source":"reg = LinearRegression().fit(x_train, y_train)\ny_hat = reg.predict(x_test)\ny_hat = pd.DataFrame(y_hat,columns=['suicides_no'])\n\n#compute metrics\n\nmse = (metrics.mean_squared_error(y_pred=y_hat, y_true=y_test ))\nr2 = metrics.r2_score(y_pred=y_hat, y_true=y_test)\nfig, ax = plt.subplots(figsize=(12,6))\nsns.scatterplot(x=y_test['suicides_no'],y=y_hat['suicides_no'])\nax.set(xlabel = 'Actual y', ylabel=\"Predicted y\")\nplt.show()\nprint('The r-squared value is: {}, and MSE is: {}'.format(r2, mse))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"698dd5cc596d703697ddd540c01302ef4fb9552d"},"cell_type":"markdown","source":"Hmm, the plot of predicted y vs actual y looks pretty scattered. The closer the alignment of points along the 45 degree line, would indicate a stronger fit. Let's use k-fold cross-validation to compare our Linear Regression model with other models such as Lasso and kNN."},{"metadata":{"scrolled":true,"trusted":false,"_uuid":"c904136aeac30f6dd0089db37e8f33dfa0af806e"},"cell_type":"code","source":"kf = KFold(5,shuffle=True)\nreg_cv = LinearRegression()\nlas_cv = Lasso()\nkn_cv = KNeighborsRegressor(n_neighbors=30)\nreg_cv_model = cross_validate(reg_cv, X=x, y=y, cv=kf, scoring=('neg_mean_squared_error', 'r2'), return_train_score=False)\nlas_cv_model = cross_validate(las_cv, X=x, y=y, cv=kf, scoring=('neg_mean_squared_error', 'r2'), return_train_score=False)\nkn_cv_model = cross_validate(kn_cv, X=x, y=y, cv=kf, scoring=('neg_mean_squared_error', 'r2'), return_train_score=False)\n\nreg_cv_scores = cross_val_score(reg_cv, X=x, y=y, cv=kf)\nlas_cv_scores = cross_val_score(las_cv, X=x, y=y, cv=kf)\nkn_cv_scores = cross_val_score(kn_cv, X=x, y=y, cv=kf)\nprint('Linear Regression: The average r-squared value from {}-fold cross-validation is: {}'.format(kf.n_splits, reg_cv_scores.mean()), ('\\nLasso: The average r-squared value from {}-fold cross-validation is: {}'.format(kf.n_splits, las_cv_scores.mean())), ('\\nk-NN Regressor: The average r-squared value from {}-fold cross-validation is: {}'.format(kf.n_splits, kn_cv_scores.mean())))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"91fb3b7db244769eeda1f33e49e5be1b04247e48"},"cell_type":"markdown","source":"Like the Linear Rergession model, this doesn't look too good. The k-NN modle fit is the worst of the three! Let's see if we can make better predictions by constraining the model by country. We'll pick the USA as an example."},{"metadata":{"trusted":false,"_uuid":"26293f7bb8b1114ee86a0bb2cd6b3de3aa2d80f1"},"cell_type":"code","source":"x_usa = data_clean.drop(['sex','age'], axis = 1)\nx_usa = x_usa[x_usa['country'].str.contains(\"United States\")]\nx_usa = x_usa.drop('country',axis=1)\nx_usa = pd.get_dummies(x_usa)\ny_usa = x_usa[['suicides_no']]\nx_usa = x_usa.drop('suicides_no',axis=1);\nx_usa_train, x_usa_test, y_usa_train, y_usa_test = train_test_split(x_usa, y_usa, test_size=0.25, random_state=314)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false,"_uuid":"655af00e688c30971e2ec4403b39899cc018bb21"},"cell_type":"code","source":"reg_usa = LinearRegression().fit(x_usa_train, y_usa_train)\ny_usa_hat = reg_usa.predict(x_usa_test)\ny_usa_hat = pd.DataFrame(y_usa_hat,columns=['suicides_no'])\n\n#compute metrics\nmse_usa = (metrics.mean_squared_error(y_pred=y_usa_hat, y_true=y_usa_test ))\nr2_usa = metrics.r2_score(y_pred=y_usa_hat, y_true=y_usa_test)\n\n#fig_usa, ax_usa = plt.subplots(figsize=(12,6))\n\nfig, ax = plt.subplots()\nax.scatter(x=y_usa_test['suicides_no'],y=y_usa_hat['suicides_no'])\nplt.xlabel('Actual y')\nplt.ylabel('Predicted y')\nplt.show()\n#ax_usa.set(xlabel = 'Actual y', ylabel=\"Predicted y\")\n\nprint('The r-squared value is: {}, and MSE is: {}'.format(r2_usa, mse_usa))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73c881610e3f7d3e650ea9d36b920e6a27da7dc2"},"cell_type":"markdown","source":"Let's perform 5-fold cross-validation to compare our country-specific Linear Regression model with the Lasso and a kNN regressor."},{"metadata":{"trusted":false,"_uuid":"310149bf1faac07556bd93df3cdbbaa56352f64b"},"cell_type":"code","source":"kf = KFold(5,shuffle=True)\nreg_cv = LinearRegression()\nlas_cv = Lasso()\nkn_cv = KNeighborsRegressor(n_neighbors=30)\nreg_cv_model = cross_validate(reg_cv, X=x_usa, y=y_usa, cv=kf, scoring=('neg_mean_squared_error', 'r2'), return_train_score=False)\nlas_cv_model = cross_validate(las_cv, X=x_usa, y=y_usa, cv=kf, scoring=('neg_mean_squared_error', 'r2'), return_train_score=False)\nkn_cv_model = cross_validate(kn_cv, X=x_usa, y=y_usa, cv=kf, scoring=('neg_mean_squared_error', 'r2'), return_train_score=False)\n\nreg_cv_scores = cross_val_score(reg_cv, X=x_usa, y=y_usa, cv=kf)\nlas_cv_scores = cross_val_score(las_cv, X=x_usa, y=y_usa, cv=kf)\nkn_cv_scores = cross_val_score(kn_cv, X=x_usa, y=y_usa, cv=kf)\nprint('Linear Regression: The average r-squared value from {}-fold cross-validation is: {}'.format(kf.n_splits, reg_cv_scores.mean()), ('\\nLasso: The average r-squared value from {}-fold cross-validation is: {}'.format(kf.n_splits, las_cv_scores.mean())), ('\\nk-NN Regressor: The average r-squared value from {}-fold cross-validation is: {}'.format(kf.n_splits, kn_cv_scores.mean())))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d74c485266dffb51ca7e73e3be6c56609a0eebf"},"cell_type":"markdown","source":"As we suspected, we see better performance when the model is restricted to a specific country."},{"metadata":{"_uuid":"54a1c61ae294fbd9526946419c751b89c6637e95"},"cell_type":"markdown","source":"Now let's try to predict by gender only. "},{"metadata":{"trusted":false,"_uuid":"910d5dac34575e525ab1a29543c20d2aae4963d2"},"cell_type":"code","source":"# Pick a target gender, m or f\ntarget = 'f_suicides_no'\nreg = LinearRegression().fit(x_s_train, y_s_train[target])\ny_s_hat = reg.predict(x_s_test)\ny_s_hat = pd.DataFrame(y_s_hat,columns=[target])\n\n#compute metrics\n\nmse = (metrics.mean_squared_error(y_pred=y_s_hat[target], y_true=y_s_test[target] ))\nr2_s = metrics.r2_score(y_pred=y_s_hat, y_true=y_s_test[target])\nfig, ax = plt.subplots(figsize=(12,6))\nsns.scatterplot(x=y_s_test[target],y=y_s_hat[target])\nax.set(xlabel = 'Actual y', ylabel=\"Predicted y\")\nplt.show()\nprint('The r-squared value is: {}, and MSE is: {}'.format(r2, mse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"8a06014d99ba6cd8bff609d1c1e5a94eb17a7ab6"},"cell_type":"code","source":"kf = KFold(5,shuffle=True)\nreg_cv = LinearRegression()\nlas_cv = Lasso()\nkn_cv = KNeighborsRegressor(n_neighbors=30)\nreg_cv_model = cross_validate(reg_cv, X=x_s, y=y_s[target], cv=kf, scoring=('neg_mean_squared_error', 'r2'), return_train_score=False)\nlas_cv_model = cross_validate(las_cv, X=x_s, y=y_s[target], cv=kf, scoring=('neg_mean_squared_error', 'r2'), return_train_score=False)\nkn_cv_model = cross_validate(kn_cv, X=x_s, y=y_s[target], cv=kf, scoring=('neg_mean_squared_error', 'r2'), return_train_score=False)\n\nreg_cv_scores_s = cross_val_score(reg_cv, X=x_s, y=y_s[target], cv=kf)\nlas_cv_scores_s = cross_val_score(las_cv, X=x_s, y=y_s[target], cv=kf)\nkn_cv_scores_s = cross_val_score(kn_cv, X=x_s, y=y_s[target], cv=kf)\nprint('Linear Regression: The average r-squared value from {}-fold cross-validation is: {}'.format(kf.n_splits, reg_cv_scores_s.mean()), ('\\nLasso: The average r-squared value from {}-fold cross-validation is: {}'.format(kf.n_splits, las_cv_scores_s.mean())), ('\\nk-NN Regressor: The average r-squared value from {}-fold cross-validation is: {}'.format(kf.n_splits, kn_cv_scores_s.mean())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"7dae9dd38481871a7ce31f06b309712bcf036ddd"},"cell_type":"code","source":"print('The results are much better. We can more accurately predict {} by {} percent over our attempt to predict suicides for both genders.'.format(target, np.round((reg_cv_scores_s.mean()/reg_cv_scores.mean())*100 - 100,2)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"9cd63c0e0bdfd7230c9ee1fd316c98510a681839"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}