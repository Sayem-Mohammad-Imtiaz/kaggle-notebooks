{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom matplotlib import colors \nfrom matplotlib.ticker import PercentFormatter \nimport numpy as np \nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport os\n\nprint(os.listdir(\"../input\"))\n\nabnormal = pd.read_csv(\"../input/ptbdb_abnormal.csv\", header = None) \nnormal = pd.read_csv(\"../input/ptbdb_normal.csv\", header = None)\n\nabnormal = abnormal.drop([187], axis=1)\nnormal = normal.drop([187], axis=1)\n\nabnormal.head","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"flatten_ab_y = (abnormal.values)\nflatten_ab_y  = flatten_ab_y[:,5:70].flatten()\n\nprint(flatten_ab_y.shape)\n\nab_x=np.arange(0,65)\nab_x = np.tile(ab_x, abnormal.shape[0])\n\nplt.hist2d(ab_x, flatten_ab_y, bins = (65,100), cmap = plt.cm.jet) \n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**From the above histogram color map for PTB data marked as abnormal, you can infer that most of the ECG features is widely distributed in the range of 0 - 0.4 and there is no fixed pattern to this data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot((abnormal.values)[0][5:70])\nplt.show()\n\nplt.plot((abnormal.values)[50][5:70])\nplt.show()\n\nplt.plot((abnormal.values)[117][5:70])\nplt.show()\n\nplt.plot((abnormal.values)[1111][5:70])\nplt.show()\n\nplt.plot((abnormal.values)[100][5:70])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**From the above, you can see that PTB data marked as abnormal donot have any fixed pattern in the data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"flatten_norm_y = normal.values\nflatten_norm_y  = flatten_norm_y[:,5:70].flatten()\n\nnorm_x=np.arange(0,65)\nnorm_x = np.tile(norm_x, normal.shape[0])\n\nplt.hist2d(norm_x,flatten_norm_y, bins=(65,100), cmap=plt.cm.jet)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**From the above histogram color map for PTB data marked as normal, you can infer that the graph of ECG features follow a standard bell shape and they peak in between the features 20-30**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot((normal.values)[0][5:70])\nplt.show()\n\nplt.plot((normal.values)[50][5:70])\nplt.show()\n\nplt.plot((normal.values)[117][5:70])\nplt.show()\n\nplt.plot((normal.values)[1111][5:70])\nplt.show()\n\nplt.plot((normal.values)[100][5:70])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**From the above, you can see that PTB data marked as normal has a fixed bell shape in the data and it peaks between the features 20-30 **"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_abnormal = np.ones((abnormal.shape[0]))\ny_abnormal = pd.DataFrame(y_abnormal)\n\ny_normal = np.zeros((normal.shape[0]))\ny_normal = pd.DataFrame(y_normal)\n\nX = pd.concat([abnormal, normal], sort=True)\ny = pd.concat([y_abnormal, y_normal] ,sort=True)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(abnormal.dtypes, normal.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abnormal.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normal.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Check any of the features have a null**"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.any(X_train.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.any(X_test.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create sequential model \nmodel = tf.keras.models.Sequential()\n\n#Dense layer as first layer with 10 neurons, input share (187,) and and leaky Relu activation\nmodel.add(tf.keras.layers.Dense(20, activation=tf.keras.layers.LeakyReLU(alpha=0.001), input_shape=(187,)))\n\n#Dense layer as second layer with 10 neurons and leaky Relu activation\nmodel.add(tf.keras.layers.Dense(20, activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n\n#Dense layer as third layer with 10 neurons and leaky Relu activation\nmodel.add(tf.keras.layers.Dense(20, activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n\n#Dense layer as fourth layer with 10 neurons and leaky Relu activation\nmodel.add(tf.keras.layers.Dense(20, activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n\n#Softmax as last layer with two outputs\nmodel.add(tf.keras.layers.Dense(2, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ann_model_history = model.fit(X_train, y_train, epochs=300, batch_size = 10, validation_data = (X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Flatten, Dense, Conv1D, MaxPool1D, Dropout\n\n\n#Reshape train and test data to (n_samples, 187, 1), where each sample is of size (187, 1)\nX_train = np.array(X_train).reshape(X_train.shape[0], X_train.shape[1], 1)\nX_test = np.array(X_test).reshape(X_test.shape[0], X_test.shape[1], 1)\n\nprint(\"Train shape: \", X_train.shape)\nprint(\"Test shape: \", X_test.shape)\n\n# Create sequential model \nclf = tf.keras.models.Sequential()\n\n#First CNN layer  with 32 filters, conv window 5, relu activation and same padding\nclf.add(Conv1D(filters=32, kernel_size=(5,), padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.001), input_shape = (X_train.shape[1],1)))\n\n#Second CNN layer  with 64 filters, conv window 5, relu activation and same padding\nclf.add(Conv1D(filters=64, kernel_size=(5,), padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n\n#Third CNN layer with 64 filters, conv window 5, relu activation and same padding\nclf.add(Conv1D(filters=128, kernel_size=(5,), padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n\n#Fourth CNN layer with Max pooling\nclf.add(MaxPool1D(pool_size=(5,), strides=2, padding='same'))\nclf.add(Dropout(0.5))\n\n#Flatten the output\nclf.add(Flatten())\n\n#Add a dense layer with 512 neurons\nclf.add(Dense(units = 512, activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n\n#Add a dense layer with 1024 neurons\nclf.add(Dense(units = 1024, activation=tf.keras.layers.LeakyReLU(alpha=0.001)))\n\n#Softmax as last layer with two outputs\nclf.add(Dense(units = 2, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = clf.fit(X_train, y_train, epochs = 10)\ny_pred = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}