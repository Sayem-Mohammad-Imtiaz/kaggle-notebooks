{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0c86b936-935f-63a4-8332-a979dc37eeca"},"outputs":[],"source":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\n#%matplotlib inline\nimport re\nfrom sklearn.naive_bayes import MultinomialNB # Naive Bayes model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\ndata = pd.read_csv(\"../input/gender-classifier-DFE-791531.csv\", encoding='latin1')\ndata.head(2)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5f3067c8-b9ae-dcc1-0b4c-e1d49c587872"},"outputs":[],"source":"data.info() # There are a lot of NaN values in the description column. Later we will see that combining the profile\n#description will increase the accuracy score"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dddd2b9c-9880-6944-5e6c-f37c612fce43"},"outputs":[],"source":"data.description = data.description.fillna('') # the missing values in the description columns were Nan floats; \n# they would throw an error when we use our cleaning function that's why we use this code."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d6606efc-953c-f5ac-1753-554df82e90cb"},"outputs":[],"source":"data['gender:confidence'].hist() # by training on the profiles that have high gender confidence, the accuracy will go up. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2e25deef-935e-ff8b-645f-df2ba8689a04"},"outputs":[],"source":"# code adapted from top kernels\n# https://www.kaggle.com/crowdflower/twitter-user-gender-classification/kernels\ndef cleaning(s):\n    s = str(s) #s.encode('utf-8').strip()\n    s = s.lower()\n    s = re.sub('\\s\\W',' ',s) \n    s = re.sub('\\W,\\s',' ',s) \n    s = re.sub(r'[^\\w]', ' ', s)\n    s = re.sub(\"\\d+\", \" \", s)\n    s = re.sub('\\s+',' ',s)\n    s = re.sub('[!@#$_]', ' ', s) \n    s = s.replace(\"co\",\" \")\n    s = s.replace(\"https\",\" \")\n    s = s.replace(\",\",\"\")\n    s = s.replace(\"[\\w*\",\" \")\n    return s\n\ndata['text_norm'] = [cleaning(s) for s in data['text']]\ndata['description_norm'] = [cleaning(s) for s in data['description']]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"28ba4f6d-2abb-331d-8d97-fd98914cf098"},"outputs":[],"source":"# 50 rows that are in the golden standard\ndata['_golden'].value_counts()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bb127738-579e-6def-2f18-958a2c1ab0b4"},"outputs":[],"source":"df = data[data['gender:confidence']==1]\ndf.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3e38f395-5986-a57d-4791-77d786b40ac4"},"outputs":[],"source":"df['gender'].value_counts()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"44a88ca3-2325-1495-5f3d-b231e1b16e03"},"outputs":[],"source":"# we take out the unknown classifier\ndf=df[df['gender'].isin(['female', 'male', 'brand'])]\ndf['gender'].value_counts()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fecf17b5-348f-1446-19b5-1a982a451a24"},"outputs":[],"source":"df['gender'][0:10]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2b4e8ec1-f4ad-d305-3dd9-0e55111570f7"},"outputs":[],"source":"encoder = LabelEncoder()\ny = encoder.fit_transform(df['gender'])\ny[0:10]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"670c07d7-75d8-a119-eb81-4b665d301faa"},"outputs":[],"source":"male=df[df['gender']=='male']\ncvec = CountVectorizer(stop_words='english')\ncvec.fit(male['text_norm'])\nX_train = pd.DataFrame(cvec.transform(male['text_norm']).todense(),\n                       columns=cvec.get_feature_names())\nword_counts = X_train.sum(axis=0)\n#word_counts.sort_values(ascending = False).head(20)\nword_counts.sort_values(ascending = False).head(10).plot.barh()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f507b540-34a2-0cd2-849c-506c5baa8870"},"outputs":[],"source":"female=df[df['gender']=='female']\ncvec = CountVectorizer(stop_words='english')\ncvec.fit(female['text_norm'])\nX_train = pd.DataFrame(cvec.transform(female['text_norm']).todense(),\n                       columns=cvec.get_feature_names())\nword_counts = X_train.sum(axis=0)\nword_counts.sort_values(ascending = False).head(20)\nword_counts.sort_values(ascending = False).head(10).plot.barh()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"48b76df2-6446-3e44-55f5-42657e4825a9"},"outputs":[],"source":"brand=df[df['gender']=='brand']\ncvec = CountVectorizer(stop_words='english')\ncvec.fit(brand['text_norm'])\nX_train = pd.DataFrame(cvec.transform(brand['text_norm']).todense(),\n                       columns=cvec.get_feature_names())\nword_counts = X_train.sum(axis=0)\nword_counts.sort_values(ascending = False).head(20)\nword_counts.sort_values(ascending = False).head(10).plot.barh()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"476a1278-e2d3-f847-746a-dc85e4acffba"},"outputs":[],"source":"data.info() # There are a lot of NaN values in the description column. Later we will see that combining the profile\n#description will increase the accuracy score"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3095baae-2c28-5858-6b74-c5ec354fc50a"},"outputs":[],"source":"data.description = data.description.fillna('') # the missing values in the description columns were Nan floats; \n# they would throw an error when we use our cleaning function that's why we use this code."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4e5415d2-78c6-afeb-e210-1b49522026ec"},"outputs":[],"source":"data['gender:confidence'].hist() # by just training on the profiles that have high gender confidence, the accuracy went up. see below"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b0752993-988d-c59d-ecdf-4d4f023f3940"},"outputs":[],"source":"# code adapted from top kernels\n# https://www.kaggle.com/crowdflower/twitter-user-gender-classification/kernels\ndef cleaning(s):\n    s = str(s)#s.encode('utf-8').strip()\n    s = s.lower()\n    s = re.sub('\\s\\W',' ',s) \n    s = re.sub('\\W,\\s',' ',s) \n    s = re.sub(r'[^\\w]', ' ', s)\n    s = re.sub(\"\\d+\", \" \", s)\n    s = re.sub('\\s+',' ',s)\n    s = re.sub('[!@#$_]', ' ', s) \n    s = s.replace(\"co\",\" \")\n    s = s.replace(\"https\",\" \")\n    s = s.replace(\",\",\"\")\n    s = s.replace(\"[\\w*\",\" \")\n    return s\n\ndata['text_norm'] = [cleaning(s) for s in data['text']]\ndata['description_norm'] = [cleaning(s) for s in data['description']]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a90e96dd-a13d-5d52-4ab6-b5104635cdb5"},"outputs":[],"source":"# there are 50 observations in the golden standard\ndata['_golden'].value_counts()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"30dd6a0d-3388-bca3-116a-af7e4d23449e"},"outputs":[],"source":"data['gender:confidence'].value_counts();"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8e058b0c-c9f1-5e79-2937-c7da4000006a"},"outputs":[],"source":"# Training with the profiles that have number 1 confidence will yield to higher accuracy\ndf = data[data['gender:confidence']==1]\ndf.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bc2bda68-31f4-a152-8833-e226d9c92bfa"},"outputs":[],"source":"df['gender'].value_counts()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c3e928b7-cbe1-b145-660c-2c5dfafce221"},"outputs":[],"source":"df=df[df['gender'].isin(['female', 'male', 'brand'])]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"58af52e0-69ad-fd5d-1b85-3909af8e461c"},"outputs":[],"source":"# We take out the unknown class\ndf['gender'].value_counts()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a1fdc00d-4fb6-1580-0d9f-7a56fd318be6"},"outputs":[],"source":"df['gender'][0:10]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"38170161-02c8-eaed-af26-b99c8db036eb"},"outputs":[],"source":"encoder = LabelEncoder()\ny = encoder.fit_transform(df['gender'])\ny[0:10]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ba3e26d5-bda3-7107-d681-ede2485e7274"},"outputs":[],"source":"male=df[df['gender']=='male']\ncvec = CountVectorizer(stop_words='english')\ncvec.fit(male['text_norm'])\nX_train = pd.DataFrame(cvec.transform(male['text_norm']).todense(),\n                       columns=cvec.get_feature_names())\nword_counts = X_train.sum(axis=0)\nword_counts.sort_values(ascending = False).head(20)\nword_counts.sort_values(ascending = False).head(10).plot.barh()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"27e764bc-3b1a-e07d-f74a-56c64ab51645"},"outputs":[],"source":"female=df[df['gender']=='female']\ncvec = CountVectorizer(stop_words='english')\ncvec.fit(female['text_norm'])\nX_train = pd.DataFrame(cvec.transform(female['text_norm']).todense(),\n                       columns=cvec.get_feature_names())\nword_counts = X_train.sum(axis=0)\nword_counts.sort_values(ascending = False).head(20)\nword_counts.sort_values(ascending = False).head(10).plot.barh()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"73e1c3d7-c16b-dc5b-7802-db18ea1590b8"},"outputs":[],"source":"brand=df[df['gender']=='brand']\ncvec = CountVectorizer(stop_words='english')\ncvec.fit(brand['text_norm'])\nX_train = pd.DataFrame(cvec.transform(brand['text_norm']).todense(),\n                       columns=cvec.get_feature_names())\nword_counts = X_train.sum(axis=0)\nword_counts.sort_values(ascending = False).head(20)\nword_counts.sort_values(ascending = False).head(10).plot.barh()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"abee432a-fb1f-00d1-4cb6-27fc52eaadf7"},"outputs":[],"source":"def docm(y_true, y_pred, labels=None):\n    \"\"\" Returns a confusion matrix as a dataframe.\n    Uses either passed in labels or integers as labels.\"\"\"\n    cm = confusion_matrix(y_true, y_pred)\n    if labels is not None:\n        cols = ['p_'+c for c in labels]\n        df = pd.DataFrame(cm, index=labels, columns=cols)\n    else:\n        cols = ['p_'+str(i) for i in xrange(len(cm))]\n        df = pd.DataFrame(cm, columns=cols)\n    return df"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bd3ee2cd-8612-b8a4-0039-2e0e4aff16a8"},"outputs":[],"source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d2bb80b2-b519-af5d-6496-24702d1c5a42"},"outputs":[],"source":"models = [KNeighborsClassifier(),\n          LogisticRegression(),\n          DecisionTreeClassifier(),\n          SVC(),\n          RandomForestClassifier(),\n          ExtraTreesClassifier()]\n\ntvec = TfidfVectorizer()\n#                        stop_words='english',\n#                        sublinear_tf=True,\n#                        max_df=0.5,\n#                        min_df=2,\n#                        max_features=1000)\n\n\nX = tvec.fit_transform(df['text_norm'])\n\nencoder = LabelEncoder()\ny = encoder.fit_transform(df['gender'])\n\n# split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3dee6e69-dd14-3ea2-803c-5d234734ae9c"},"outputs":[],"source":"names=['brand','female','male']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"84dadd62-9903-abd1-9909-7684e8df99dd"},"outputs":[],"source":"res = []\n\nfor model in models:\n    print(model)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    score = accuracy_score(y_test, y_pred)\n    print(\"\\n\")\n    print(score)\n    print(\"\\n\")\n    cm = docm(y_test, y_pred,names)\n    print(\"\\n\")\n    print(cm)\n    print(\"\\n\")\n    res.append([model, score])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3f2d4f0f-cae2-b62f-a061-f6013ce477e6"},"outputs":[],"source":"data['all_features'] = data['text_norm'].str.cat(data['description_norm'], sep=' ')\ndf = data[data['gender:confidence']==1]\n# Naive Bayes, Countvectorizer, Description and tweet\ncvec = CountVectorizer()\nX = cvec.fit_transform(df['all_features'])\n\nencoder = LabelEncoder()\ny = encoder.fit_transform(df['gender'])\n\n# split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n# take a look at the shape of each of these\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)\nnb = MultinomialNB()\nnb.fit(X_train, y_train)\n\nprint(nb.score(X_test, y_test))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4889cc4d-db68-d550-6245-6ff56de54e88"},"outputs":[],"source":"The Best score is obtained from the Naive Bayes Classifier"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b157cf5e-d683-8880-27c7-2474b6ed5a25"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}