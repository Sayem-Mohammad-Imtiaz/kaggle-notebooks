{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Step 0. Install LAMA"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"pip install lightautoml","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 0.1. Import necessary libraries "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Standard python libraries\nimport os\nimport time\n\n# Installed libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport matplotlib.pyplot as plt\nimport pickle\n\n# Imports from our package\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\nfrom lightautoml.dataset.roles import DatetimeRole\nfrom lightautoml.tasks import Task\nfrom lightautoml.report.report_deco import ReportDeco\n\n#Import h2o automl\nimport h2o\nfrom h2o.automl import H2OAutoML","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 0.2. Parameters "},{"metadata":{"trusted":true},"cell_type":"code","source":"N_THREADS = 4 # threads cnt for lgbm and linear models\nN_FOLDS = 3 # folds cnt for AutoML\nRANDOM_STATE = 42 # fixed random state for various reasons\nTEST_SIZE = 0.2 # Test size for metric check\nTIMEOUT = 300 # Time in seconds for automl run\nTARGET_NAME = 'TARGET' # Target column name","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 0.3. Fix torch number of threads and numpy seed "},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(RANDOM_STATE)\ntorch.set_num_threads(N_THREADS)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 0.4. Example data load "},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ndata = pd.read_csv('../input/lama-datasets/sampled_app_train.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 0.5. (Optional) Some user feature preparation "},{"metadata":{},"cell_type":"markdown","source":"Cell below shows some user feature preparations to create task more difficult (this block can be omitted if you don't want to change the initial data):"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ndata['BIRTH_DATE'] = (np.datetime64('2018-01-01') + data['DAYS_BIRTH'].astype(np.dtype('timedelta64[D]'))).astype(str)\ndata['EMP_DATE'] = (np.datetime64('2018-01-01') + np.clip(data['DAYS_EMPLOYED'], None, 0).astype(np.dtype('timedelta64[D]'))\n                    ).astype(str)\n\ndata['constant'] = 1\ndata['allnan'] = np.nan\n\ndata['report_dt'] = np.datetime64('2018-01-01')\n\ndata.drop(['DAYS_BIRTH', 'DAYS_EMPLOYED'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 0.6. (Optional) Data splitting for train-test "},{"metadata":{},"cell_type":"markdown","source":"Block below can be omitted if you are going to train model only or you have specific train and test files:"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntrain_data, test_data = train_test_split(data, \n                                         test_size=TEST_SIZE, \n                                         stratify=data[TARGET_NAME], \n                                         random_state=RANDOM_STATE)\nprint('Data splitted. Parts sizes: train_data = {}, test_data = {}'\n              .format(train_data.shape, test_data.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  ==== AutoML preset usage ====\n\n\n## Step 1. Create Task"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntask = Task('binary', )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 2. Setup columns roles"},{"metadata":{},"cell_type":"markdown","source":"Roles setup here set target column and base date, which is used to calculate date differences:"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nroles = {'target': TARGET_NAME,\n         DatetimeRole(base_date=True, seasonality=(), base_feats=False): 'report_dt',\n         }","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 3. Create AutoML from preset"},{"metadata":{},"cell_type":"markdown","source":"To create AutoML model here we use `TabularAutoML` preset.\n\n\nAll params we set above can be send inside preset to change its configuration:"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"%%time \nstart = time.time()\nautoml = TabularAutoML(task = task, \n                       timeout = TIMEOUT,\n                       cpu_limit = N_THREADS,\n                       general_params = {'nested_cv': False, 'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n                       reader_params = {'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n                       tuning_params = {'max_tuning_iter': 20, 'max_tuning_time': 30},\n                       verbose=0)\n\nRD = ReportDeco()\nautoml_rd = RD(automl)\n\noof_pred = automl_rd.fit_predict(train_data, roles = roles)\nprint('oof_pred:\\n{}\\nShape = {}'.format(oof_pred, oof_pred.shape))\ntime_automl = time.time() - start","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Save new config template:"},{"metadata":{"trusted":true},"cell_type":"code","source":"automl.get_config(path='bb_config.yml')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('automl.pickle', 'wb') as f:\n    pickle.dump(automl, f)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 4. Predict to test data and check scores"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntest_pred = automl_rd.predict(test_data)\nprint('Prediction for test data:\\n{}\\nShape = {}'.format(test_pred, test_pred.shape))\n\nprint('Check scores...')\nprint('OOF score: {}'.format(roc_auc_score(train_data[TARGET_NAME].values,\n                                           oof_pred.data[:, 0])))\ntest_automl = roc_auc_score(test_data[TARGET_NAME].values, test_pred.data[:, 0])\nprint('TEST score: {}'.format(test_automl))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 5. Same Preset with less available time."},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"%%time \nstart = time.time()\nautoml = TabularAutoML(task = task, \n                       timeout = 20,\n                       cpu_limit = N_THREADS,\n                       general_params = {'nested_cv': False, 'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n                       reader_params = {'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n                       tuning_params = {'max_tuning_iter': 20, 'max_tuning_time': 30},\n                       verbose=0)\n\n\noof_pred = automl.fit_predict(train_data, roles = roles)\nprint('oof_pred:\\n{}\\nShape = {}'.format(oof_pred, oof_pred.shape))\ntime_automl_fast = time.time() - start","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"OOF predictions now contains NaNs because not all folds were calculated. So, we omit OOF score."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntest_pred = automl.predict(test_data)\nprint('Prediction for test data:\\n{}\\nShape = {}'.format(test_pred, test_pred.shape))\n\nprint('Check scores...')\ntest_automl_fast = roc_auc_score(test_data[TARGET_NAME].values, test_pred.data[:, 0])\nprint('TEST score: {}'.format(test_automl_fast))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 6. Create AutoML with time utilization"},{"metadata":{},"cell_type":"markdown","source":"Below we are going to create specific AutoML preset for TIMEOUT utilization (try to spend it as much as possible):"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"%%time\nstart = time.time()\nautoml = TabularUtilizedAutoML(task = task,\n                       timeout = TIMEOUT,\n                       general_params = {'nested_cv': False, 'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n                       reader_params = {'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n                       tuning_params = {'max_tuning_iter': 20, 'max_tuning_time': 30},\n                       verbose=0)\noof_pred = automl.fit_predict(train_data, roles = roles)\ntime_automl_utilized = time.time() - start","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntest_pred = automl.predict(test_data)\nprint('Prediction for test data:\\n{}\\nShape = {}'.format(test_pred, test_pred.shape))\n\nprint('Check scores...')\nprint('OOF score: {}'.format(roc_auc_score(train_data[TARGET_NAME].values,\n                                           oof_pred.data[:, 0])))\ntest_automl_utilized = roc_auc_score(test_data[TARGET_NAME].values, test_pred.data[:, 0])\nprint('TEST score: {}'.format(test_automl_utilized))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's compare results:"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"labels = ['fast', 'base', 'utilized']\ntimes = [time_automl_fast, time_automl, time_automl_utilized]\nscores = [test_automl_fast, test_automl, test_automl_utilized]\n\ndef plot_bar(labels, times, scores):\n    x = np.arange(len(labels))  # the label locations\n    width = 0.35  # the width of the bars\n\n    fig, ax = plt.subplots(figsize=[7, 5])\n    rects = ax.bar(x, scores, width, label='Score', hatch=\"///\",edgecolor=\"#034569\", color='none')\n\n    ax2 = ax.twinx()  # instantiate a second axes that shares the same x-axis\n    color = '#FF8B00'\n    ax2.plot(x, times, color=color, label='Time', marker='o',)\n    ax2.set_ylabel('Time, seconds', color=color) \n    ax2.tick_params(axis='y', labelcolor=color)\n    ax2.grid(False)\n    ax2.set_ylim(np.min(times) * 0.8, np.max(times) * 1.1)\n\n    ax.set_ylabel('Score, ROC AUC')\n    ax.set_title('Score by available time')\n    ax.set_xticks(x)\n    ax.set_xticklabels(labels)\n    ax.set_ylim(np.min(scores) - 0.002, np.max(scores) + 0.002)\n    ax.grid(False)\n    ax.spines['top'].set_visible(False)\n    ax2.spines['top'].set_visible(False)\n\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate('{}'.format(np.round(height, 3)),\n                    xy=(rect.get_x() + rect.get_width() / 2, height),\n                    xytext=(0, 3),  # 3 points vertical offset\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\n\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n    \nplot_bar(labels, times, scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 7. H2O? "},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"h2o.init(nthreads=-1,     # number of threads when launching a new H2O server\n         max_mem_size=12  # in gigabytes\n        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.time()\n\nX_y_train_h = h2o.H2OFrame(train_data)\ntypes = X_y_train_h.types\n\naml = H2OAutoML(max_runtime_secs=(300),  # 5 minutes\n                max_models=None,  # no limit\n                seed=RANDOM_STATE)\ncols = sorted(list(set(train_data.columns) - {TARGET_NAME}))\naml.train(x=cols,y=TARGET_NAME, training_frame=X_y_train_h)\n\ntime_h2o = time.time() - start","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"h2o_predict = aml.predict(h2o.H2OFrame(test_data, column_types=types))\ntest_h2o = roc_auc_score(test_data[TARGET_NAME].values, h2o_predict.as_data_frame().values[:, 0])\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"labels.append('h2o')\ntimes.append(time_h2o)\nscores.append(test_h2o)\n\nplot_bar(labels, times, scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 8. Report"},{"metadata":{},"cell_type":"markdown","source":"* Report for base TabularAutoML is [here](./lama_report/lama_interactive_report.html)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}