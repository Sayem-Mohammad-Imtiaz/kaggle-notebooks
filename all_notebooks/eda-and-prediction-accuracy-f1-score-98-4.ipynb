{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fac27b28287cc6e2f11f712b0053e77dba805a22"},"cell_type":"code","source":"import itertools\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import svm\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics \nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import cross_val_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/data.csv\")\ndf.drop(columns=[\"Unnamed: 32\"], inplace=True)\nclass_names = df.diagnosis.unique()\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a11dcc8f3be2c493c77665548c26f6e3b1ddd0fe"},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f16940b74a4df12e9e7130b9f6b0e9240c303c1"},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"84ca953b91193a065d5bff5354575cad641d9e3d"},"cell_type":"markdown","source":"Scale data for visualization"},{"metadata":{"trusted":true,"_uuid":"7e1b4d78dd4404c3c50ce9eb202886a46d589dce"},"cell_type":"code","source":"col = [\"diagnosis\"]\nd = df\n\nnum_cols = d.columns[d.dtypes.apply(lambda c: np.issubdtype(c, np.number))]\n\nscaler = StandardScaler()\nd[num_cols] = scaler.fit_transform(d[num_cols])\n# print(scaler.mean_)\n# # scaler.transform(d)\ncolumns = d.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b4507854b4b48ee5e5172d068bb8625dbc5eb23"},"cell_type":"markdown","source":"Pair plot of all features"},{"metadata":{"trusted":true,"_uuid":"bfb424b8d92ebfbb42711b0edc03124662c56afa"},"cell_type":"code","source":"sns.pairplot(d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4edbad3e94e896bd2ecfe18da35c25509cf40bbf"},"cell_type":"code","source":"# g = sns.PairGrid(\n#     d, \n#     diag_sharey=True, \n#     height=2.5, \n#     aspect=1, \n#     despine=True, \n#     dropna=False)\n# g = g.map(plt.scatter)\n# g.map_diag(plt.hist)\n# g.map_offdiag(plt.scatter);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db044eade77d27df2bdee95cd3a35fa2be227fc7"},"cell_type":"markdown","source":"Cluster map of feature correleation  "},{"metadata":{"trusted":true,"_uuid":"5bc8dc522bc629724b650b1d2f04971242eff1a9"},"cell_type":"code","source":"sns.set(style=\"white\")\nsns.clustermap(d.corr(), \n               pivot_kws=None, \n#                method='average', \n#                metric='euclidean', \n               z_score=None, \n               standard_scale=None,\n               figsize=None,\n               cbar_kws=None, \n               row_cluster=True, \n               col_cluster=True, \n               row_linkage=None, \n               col_linkage=None,\n               row_colors=None, \n               col_colors=None, \n               mask=None,\n               center=0,\n               cmap=\"vlag\",\n               linewidths=.75, \n#                figsize=(13, 13)\n              )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1963b009ac895997961189266114c9f3a798d712"},"cell_type":"markdown","source":"Heatmap of scaled feature correleation  "},{"metadata":{"trusted":true,"_uuid":"48ed2d85607251b0472e11997b40c0eedaf53a4c"},"cell_type":"code","source":"# Compute the correlation matrix\ncorr = d.corr()\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(len(columns), len(columns)))\n\n# Generate a custom diverging colormap\n# cmap = sns.diverging_palette(220, 10, as_cmap=True)\ncmap = sns.diverging_palette(h_neg=220, h_pos=10, s=75, l=50, sep=10, n=len(columns), center='light', as_cmap=True)\n\nsns.set(style=\"white\")\nsns.heatmap(corr,\n         vmin=None,\n         vmax=None,\n         cmap=cmap,\n         center=None,\n         robust=True,\n         annot=True, \n#          fmt='.2g',\n         annot_kws=None, \n#          linewidths=0.5, \n#          linecolor='white',\n         cbar=True,\n         cbar_kws={\"shrink\": .5},\n         cbar_ax=None, \n         square=True, \n         xticklabels='auto',\n         yticklabels='auto', \n         mask=mask, \n         ax=None)\n\n\nplt.yticks(rotation=0)\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64317f924b699eacd93acfaedfdd023b57406cd4"},"cell_type":"markdown","source":"**Training**"},{"metadata":{"trusted":true,"_uuid":"7959ba228a8143178527289c2a074a98975fe24d"},"cell_type":"code","source":"target_val = set(df[\"diagnosis\"])\nm = {i:v for v,i in enumerate(target_val)}\ndf[\"diagnosis\"] = df[\"diagnosis\"].map(m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2935a6c415378a63b7b4a6360499219f63b0d3c1"},"cell_type":"code","source":"# df.dropna()\ny = df[\"diagnosis\"]\nX = df.drop(columns=[\"id\", \"diagnosis\"])\n\nX = X.values\ny = y.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9748a9972a1485c32b8ecfafa3e98108b569806f"},"cell_type":"code","source":"def print_performance(model, X_test, y_test, class_names):\n    preds = model.predict(X_test)\n\n    # accuracy_score = metrics.accuracy_score(y_test, preds)\n    # auc = metrics.auc(y_test, preds)\n    # average_precision_score = metrics.average_precision_score(y_test, preds)\n    # balanced_accuracy_score = metrics.balanced_accuracy_score(y_test, preds)\n    # brier_score_loss = metrics.brier_score_loss(y_test, preds)\n    classification_report = metrics.classification_report(y_test, preds)\n    # cohen_kappa_score = metrics.cohen_kappa_score(y_test, preds)\n    confusion_matrix = metrics.confusion_matrix(y_test, preds)\n    f1_score_ = metrics.f1_score(y_test, preds, average=\"weighted\")\n    # fbeta_score = metrics.fbeta_score(y_test, preds, average=\"weighted\")\n    # hamming_loss = metrics.hamming_loss(y_test, preds)\n    # hinge_loss = metrics.hinge_loss(y_test, preds)\n    # jaccard_similarity_score = metrics.jaccard_similarity_score(y_test, preds)\n    # log_loss = metrics.log_loss(y_test, preds)\n    # matthews_corrcoef = metrics.matthews_corrcoef(y_test, preds)\n    # precision_recall_curve = metrics.precision_recall_curve(y_test, preds)\n    # precision_recall_fscore_support = metrics.precision_recall_fscore_support(y_test, preds)\n    # precision_score = metrics.precision_score(y_test, preds, average=\"weighted\")\n    # recall_score = metrics.recall_score(y_test, preds, average=\"weighted\")\n    # roc_auc_score = metrics.roc_auc_score(y_test, preds, average=\"weighted\")\n    # roc_curve = metrics.roc_curve(y_test, preds)\n    # zero_one_loss = metrics.zero_one_loss(y_test, preds)\n    \n    print(\"-\"*55)\n    print(\"Performance\")\n    print(\"-\"*55)\n    # print(\"{} : {:.4f} \".format(\"Accuracy Score                  \", accuracy_score))\n    # print(\"{} : {:.4f} \".format(\"AUC                             \", auc))\n    # print(\"{} : {:.4f} \".format(\"Average Precision Score         \", average_precision_score))\n    # print(\"{} : {:.4f} \".format(\"Balanced Accuracy Score         \", balanced_accuracy_score))\n    # print(\"{} : {:.4f} \".format(\"Brier Score Loss                \", brier_score_loss))\n#     print(\"{} : {:.4f} \".format(\"Classification Report           \", classification_report))\n    # print(\"{} : {:.4f} \".format(\"Cohen Kappa Score               \", cohen_kappa_score))\n#     print(\"{} : {:.4f} \".format(\"Confusion Matrix                \", confusion_matrix))\n    print(\"{} : {:.4f} \".format(\"F1 Score                        \", f1_score_))\n    # print(\"{} : {:.4f} \".format(\"Fbeta Score                     \", fbeta_score))\n    # print(\"{} : {:.4f} \".format(\"Hamming Loss                    \", hamming_loss))\n    # print(\"{} : {:.4f} \".format(\"Hinge Loss                      \", hinge_loss))\n    # print(\"{} : {:.4f} \".format(\"Jaccard Similarity Score        \", jaccard_similarity_score))\n    # print(\"{} : {:.4f} \".format(\"Log Loss                        \", log_loss))\n    # print(\"{} : {:.4f} \".format(\"Matthews Corrcoef               \", matthews_corrcoef))\n    # print(\"{} : {:.4f} \".format(\"Precision Recall Curve          \", precision_recall_curve))\n    # print(\"{} : {:.4f} \".format(\"Precision Recall Fscore Support \", precision_recall_fscore_support))\n    # print(\"{} : {:.4f} \".format(\"Precision Score                 \", precision_score))\n    # print(\"{} : {:.4f} \".format(\"Recall Score                    \", recall_score))\n    # print(\"{} : {:.4f} \".format(\"Roc Auc Score                   \", roc_auc_score))\n    # print(\"{} : {:.4f} \".format(\"Roc Curve                       \", roc_curve))\n    # print(\"{} : {:.4f} \".format(\"Zero One Loss                   \", zero_one_loss))\n    print(classification_report)\n    \n    print(\"-\"*55)\n    print(\"\\n\\n\")\n    \n\n    np.set_printoptions(precision=2)\n\n    # Plot non-normalized confusion matrix\n    plt.figure()\n    plot_confusion_matrix(confusion_matrix, classes=class_names,\n                          title='Confusion matrix, without normalization')\n\n    # Plot normalized confusion matrix\n    plt.figure()\n    plot_confusion_matrix(confusion_matrix, classes=class_names, normalize=True,\n                          title='Normalized confusion matrix')\n\n    plt.show()\n    \ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    \n    \ndef print_performance_grid(clf):\n    # print(\"*\"*100)\n    # print(\"{}{}{}\".format(\"*\"*40,\"Performance\", \"*\"*40))\n    print(\"{}\".format(\"Performance\"))\n    print(\"*\"*90)\n    print(\"Score            : {}\".format(clf.score(X, y)))\n    print(\"Best Estimator   : {}\".format(clf.best_estimator_))\n    print(\"Best Score       : {}\".format(clf.best_score_))\n    print(\"Best Params      : {}\".format(clf.best_params_))\n    print(\"Best Index       : {}\".format(clf.best_index_))\n    # print(\"Scorer           : {}\".format(clf.scorer_))\n    print(\"Refit Time       : {}\".format(clf.refit_time_))\n    # print(\"CV Results       : {}\".format(clf.cv_results_))\n\n    params = clf.get_params()\n    best_estimator = clf.best_estimator_\n    cv_results = clf.cv_results_\n    \n    return params, best_estimator, cv_results","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"155e0e832fbe27720f711e597038d194bfee9059"},"cell_type":"markdown","source":"Grid search for best estimator and parameters for linear and radial kernel"},{"metadata":{"trusted":true,"_uuid":"150657267c44c950f36ef3f4a1bc740e59289ff3"},"cell_type":"code","source":"# parameters = {'kernel':('linear', 'poly', 'rbf', 'sigmoid', 'precomputed'), \n#               'degree': np.arrange(10),\n#               'C':np.arrange(10)}\n\nparameters = {'kernel':('linear', 'rbf'), \n              'degree': [1, 10],\n              'C': [1, 10]}\n\nsvc = svm.SVC(C=1.0,\n    kernel='rbf',\n    degree=3, \n    gamma='auto',\n    coef0=0.0,\n    shrinking=True, \n    probability=False,\n    tol=0.001,\n    cache_size=200,\n    class_weight=None, \n    verbose=False,\n    max_iter=-1, \n    decision_function_shape='ovr',\n    random_state=None)\n\n\nsvc = svm.SVC(gamma='auto')\n\nclf = GridSearchCV(estimator=svc, \n                   param_grid=parameters,\n                   scoring=None, \n                   fit_params=None, \n                   n_jobs=None,\n                   iid='warn',\n                   refit=True,\n                   cv=5,\n                   verbose=0,\n                   pre_dispatch='2*n_jobs',\n                   error_score='raise-deprecating',\n                   return_train_score='warn')\n\nclf.fit(X, y)\n \nparams, best_estimator, cv_results = print_performance_grid(clf)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6485e49a7ebd27e67c349d7cb79b110e9faad987"},"cell_type":"markdown","source":"Grid search for best estimator and parameters in a range - (1, 10) for linear and radial kernel"},{"metadata":{"trusted":true,"_uuid":"4455a690a1ae78af120d45429f7b3f26882c3c0f"},"cell_type":"code","source":"parameters = {'kernel':('linear', 'rbf'), \n              'degree': np.arange(1, 10),\n              'C': np.arange(1, 10)}\n\nsvc = svm.SVC(C=1.0,\n    kernel='rbf',\n    degree=3, \n    gamma='auto',\n    coef0=0.0,\n    shrinking=True, \n    probability=False,\n    tol=0.001,\n    cache_size=200,\n    class_weight=None, \n    verbose=False,\n    max_iter=-1, \n    decision_function_shape='ovr',\n    random_state=None)\n\n\nsvc = svm.SVC(gamma='auto')\n\nclf = GridSearchCV(estimator=svc, \n                   param_grid=parameters,\n                   scoring=None, \n                   fit_params=None, \n                   n_jobs=-1,\n                   iid='warn',\n                   refit=True,\n                   cv=5,\n                   verbose=1,\n                   pre_dispatch='2*n_jobs',\n                   error_score='raise-deprecating',\n                   return_train_score='warn')\n\n\nclf.fit(X, y)\n\nparams, best_estimator, cv_results = print_performance_grid(clf)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8799fec09ea8bb1532deb677b83fe78225267f8c"},"cell_type":"markdown","source":"SVM has shown much better result"},{"metadata":{"trusted":true,"_uuid":"806ea37f84acadbf76a7634cedcd41ddee26ecc6","_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\n# svc = svm.SVC(C=1.0,\n#     kernel='rbf',\n#     degree=3, \n#     gamma='auto',\n#     coef0=0.0,\n#     shrinking=True, \n#     probability=False,\n#     tol=0.001,\n#     cache_size=200,\n#     class_weight=None, \n#     verbose=False,\n#     max_iter=-1, \n#     decision_function_shape='ovr',\n#     random_state=None)\n\n# best estimator found using grid search cv\nsvc = svm.SVC(C=4, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=1, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)\n\n\nclf = svc\n\nprint(\"Cross Val Score            : {}\".format(cross_val_score(clf, X, y, cv=5)))\n\nclf.fit(X_train, y_train)\nprint(\"Score (training data only) : {}\".format(clf.score(X_train, y_train)))\n\ny_pred = clf.predict(X_test)\nprint(\"F-1 Score                  : {}\".format(f1_score(y_test, y_pred, average='weighted')))\n      ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29032ff0a8e73413ec3a7fbf3a778447093d99a9"},"cell_type":"markdown","source":"Plot of difference between actual value and predicted value without scaling"},{"metadata":{"trusted":true,"_uuid":"43b47b6fd676d61e5f9811522961e984bc9178bf"},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nprint(\"SVM\")\nmodel = clf\nmodel.fit(X_train, y_train)\nprint_performance(model, X_test, y_test, class_names)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}