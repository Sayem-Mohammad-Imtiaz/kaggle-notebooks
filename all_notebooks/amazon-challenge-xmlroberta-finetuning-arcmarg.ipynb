{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## DistilBERT finetuning with ArcMargin","metadata":{"papermill":{"duration":0.023717,"end_time":"2021-07-31T11:56:54.918587","exception":false,"start_time":"2021-07-31T11:56:54.89487","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nimport copy\nimport math\nimport pandas as pd\nimport numpy as np\nfrom tqdm.autonotebook import tqdm\nimport matplotlib.pyplot as plt\nimport random\nimport csv\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\nimport transformers\nfrom transformers import (XLMRobertaTokenizer, XLMRobertaModel,\n                          DistilBertTokenizer, DistilBertModel)","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-07-31T11:56:54.971206Z","iopub.status.busy":"2021-07-31T11:56:54.970677Z","iopub.status.idle":"2021-07-31T11:56:57.441687Z","shell.execute_reply":"2021-07-31T11:56:57.440504Z","shell.execute_reply.started":"2021-07-31T11:50:10.91206Z"},"papermill":{"duration":2.500704,"end_time":"2021-07-31T11:56:57.441872","exception":false,"start_time":"2021-07-31T11:56:54.941168","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv(\"../input/amazon-ml-challenge-2021-hackerearth/train.csv\", escapechar = \"\\\\\", quoting = csv.QUOTE_NONE)\ntrain.head()","metadata":{"execution":{"iopub.execute_input":"2021-07-31T11:56:57.501244Z","iopub.status.busy":"2021-07-31T11:56:57.500667Z","iopub.status.idle":"2021-07-31T11:57:47.700591Z","shell.execute_reply":"2021-07-31T11:57:47.701017Z","shell.execute_reply.started":"2021-07-31T11:50:13.396599Z"},"papermill":{"duration":50.233854,"end_time":"2021-07-31T11:57:47.701178","exception":false,"start_time":"2021-07-31T11:56:57.467324","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following histogram gives us an idea that roughly how many words are there in each title. It is not a precise count of the tokens fed to the model because DistilBERT tokenizer does a more sophisticated function than simply splitting the sentence from its white spaces.","metadata":{"papermill":{"duration":0.026338,"end_time":"2021-07-31T11:57:47.755018","exception":false,"start_time":"2021-07-31T11:57:47.72868","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"max_length is set to 30 according to the histogram. But you can safely change it.","metadata":{"papermill":{"duration":0.024044,"end_time":"2021-07-31T11:57:47.808825","exception":false,"start_time":"2021-07-31T11:57:47.784781","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def set_seed(seed=42):\n    os.environ['PYTHONHASHSEED']=str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)","metadata":{"execution":{"iopub.execute_input":"2021-07-31T11:57:47.8683Z","iopub.status.busy":"2021-07-31T11:57:47.86665Z","iopub.status.idle":"2021-07-31T11:57:47.868939Z","shell.execute_reply":"2021-07-31T11:57:47.869355Z","shell.execute_reply.started":"2021-07-31T11:51:02.9639Z"},"papermill":{"duration":0.033037,"end_time":"2021-07-31T11:57:47.869478","exception":false,"start_time":"2021-07-31T11:57:47.836441","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_seed()","metadata":{"execution":{"iopub.execute_input":"2021-07-31T11:57:47.922811Z","iopub.status.busy":"2021-07-31T11:57:47.922075Z","iopub.status.idle":"2021-07-31T11:57:47.929037Z","shell.execute_reply":"2021-07-31T11:57:47.928533Z","shell.execute_reply.started":"2021-07-31T11:51:02.970922Z"},"papermill":{"duration":0.035443,"end_time":"2021-07-31T11:57:47.929169","exception":false,"start_time":"2021-07-31T11:57:47.893726","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    DistilBERT = False # if set to False, BERT model will be used\n    bert_hidden_size = 768\n    num_classes=9919\n    batch_size = 192\n    epochs = 4\n    num_workers = 2\n    learning_rate = 1e-5 #3e-5\n    scheduler = \"ReduceLROnPlateau\"\n    step = 'epoch'\n    patience = 2\n    factor = 0.8\n    dropout = 0.5\n    model_path = \"/kaggle/working\"\n    max_length = 64\n    model_save_name = \"model.pt\"\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.execute_input":"2021-07-31T11:57:48.028709Z","iopub.status.busy":"2021-07-31T11:57:48.027846Z","iopub.status.idle":"2021-07-31T11:57:48.03206Z","shell.execute_reply":"2021-07-31T11:57:48.031588Z","shell.execute_reply.started":"2021-07-31T11:51:02.98461Z"},"papermill":{"duration":0.075713,"end_time":"2021-07-31T11:57:48.032221","exception":false,"start_time":"2021-07-31T11:57:47.956508","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Loading the model and its tokenizer from amazing HuggingFace model hub. As mentioned before, this model has been pre-trained on indonesian wikipedia.","metadata":{"papermill":{"duration":0.042604,"end_time":"2021-07-31T11:57:48.102881","exception":false,"start_time":"2021-07-31T11:57:48.060277","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if CFG.DistilBERT:\n    model_name='distilbert-base-uncased'\n    tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n    bert_model = DistilBertModel.from_pretrained(model_name)\nelse:\n    model_name='xlm-roberta-base'\n    tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)\n    bert_model = XLMRobertaModel.from_pretrained(model_name)","metadata":{"execution":{"iopub.execute_input":"2021-07-31T11:57:48.176674Z","iopub.status.busy":"2021-07-31T11:57:48.175868Z","iopub.status.idle":"2021-07-31T11:58:32.889889Z","shell.execute_reply":"2021-07-31T11:58:32.888711Z","shell.execute_reply.started":"2021-07-31T11:52:10.836423Z"},"papermill":{"duration":44.747202,"end_time":"2021-07-31T11:58:32.890043","exception":false,"start_time":"2021-07-31T11:57:48.142841","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"See an example","metadata":{"papermill":{"duration":0.024614,"end_time":"2021-07-31T11:58:32.939912","exception":false,"start_time":"2021-07-31T11:58:32.915298","status":"completed"},"tags":[]}},{"cell_type":"code","source":"text = train['TITLE'].values[np.random.randint(0, len(train) - 1, 1)[0]]\nprint(f\"Text of the title: {text}\")\nencoded_input = tokenizer(text, return_tensors='pt')\nprint(f\"Input tokens: {encoded_input['input_ids']}\")\ndecoded_input = tokenizer.decode(encoded_input['input_ids'][0])\nprint(f\"Decoded tokens: {decoded_input}\")\noutput = bert_model(**encoded_input)\nprint(f\"last layer's output shape: {output.last_hidden_state.shape}\")","metadata":{"execution":{"iopub.execute_input":"2021-07-31T11:58:33.002386Z","iopub.status.busy":"2021-07-31T11:58:33.001654Z","iopub.status.idle":"2021-07-31T11:58:37.771496Z","shell.execute_reply":"2021-07-31T11:58:37.771873Z","shell.execute_reply.started":"2021-07-31T11:53:25.625559Z"},"papermill":{"duration":4.807669,"end_time":"2021-07-31T11:58:37.772051","exception":false,"start_time":"2021-07-31T11:58:32.964382","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{"papermill":{"duration":0.027695,"end_time":"2021-07-31T11:58:37.826471","exception":false,"start_time":"2021-07-31T11:58:37.798776","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Encoding label_group coulmn to numeric labels so we can feed them to the model and loss function.","metadata":{"papermill":{"duration":0.027674,"end_time":"2021-07-31T11:58:37.882659","exception":false,"start_time":"2021-07-31T11:58:37.854985","status":"completed"},"tags":[]}},{"cell_type":"code","source":"id2lbl={lbl: idx for idx,lbl in enumerate(list(train[\"BROWSE_NODE_ID\"].unique()))}\nlbl2id={lbl:idx for idx,lbl in id2lbl.items()}","metadata":{"execution":{"iopub.execute_input":"2021-07-31T11:58:37.944054Z","iopub.status.busy":"2021-07-31T11:58:37.943118Z","iopub.status.idle":"2021-07-31T11:58:37.975186Z","shell.execute_reply":"2021-07-31T11:58:37.974745Z","shell.execute_reply.started":"2021-07-31T11:53:30.543091Z"},"papermill":{"duration":0.065516,"end_time":"2021-07-31T11:58:37.975367","exception":false,"start_time":"2021-07-31T11:58:37.909851","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_folds(data, num_splits):\n    data[\"kfold\"] = -1\n    data = data.sample(frac=1).reset_index(drop=True)\n    y=data[\"BROWSE_NODE_ID\"]\n    kf = StratifiedKFold(n_splits=num_splits)\n    for f, (t_, v_) in enumerate(kf.split(X=data, y=y)):\n        data.loc[v_, 'kfold'] = f\n    return data\n","metadata":{"execution":{"iopub.execute_input":"2021-07-31T11:58:38.036518Z","iopub.status.busy":"2021-07-31T11:58:38.035834Z","iopub.status.idle":"2021-07-31T11:58:38.038743Z","shell.execute_reply":"2021-07-31T11:58:38.038342Z","shell.execute_reply.started":"2021-07-31T11:53:30.85642Z"},"papermill":{"duration":0.035913,"end_time":"2021-07-31T11:58:38.038851","exception":false,"start_time":"2021-07-31T11:58:38.002938","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=create_folds(train, 5)","metadata":{"execution":{"iopub.execute_input":"2021-07-31T11:58:38.105756Z","iopub.status.busy":"2021-07-31T11:58:38.104621Z","iopub.status.idle":"2021-07-31T11:58:57.005606Z","shell.execute_reply":"2021-07-31T11:58:57.004686Z","shell.execute_reply.started":"2021-07-31T11:53:31.235948Z"},"papermill":{"duration":18.941566,"end_time":"2021-07-31T11:58:57.005755","exception":false,"start_time":"2021-07-31T11:58:38.064189","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=train.loc[train.kfold.isin([1,2,3])]\ntrain=train.reset_index(drop=True)\ntrain.head()","metadata":{"execution":{"iopub.execute_input":"2021-07-31T11:58:57.062593Z","iopub.status.busy":"2021-07-31T11:58:57.061606Z","iopub.status.idle":"2021-07-31T11:58:58.015242Z","shell.execute_reply":"2021-07-31T11:58:58.015665Z","shell.execute_reply.started":"2021-07-31T11:53:51.538785Z"},"papermill":{"duration":0.984152,"end_time":"2021-07-31T11:58:58.015812","exception":false,"start_time":"2021-07-31T11:58:57.03166","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp=train.dropna(subset=['TITLE'])\ntemp=temp.reset_index(drop=True)","metadata":{"execution":{"iopub.execute_input":"2021-07-31T11:58:58.440186Z","iopub.status.busy":"2021-07-31T11:58:58.43906Z","iopub.status.idle":"2021-07-31T11:58:59.198254Z","shell.execute_reply":"2021-07-31T11:58:59.197741Z","shell.execute_reply.started":"2021-07-31T11:53:52.519143Z"},"papermill":{"duration":1.15633,"end_time":"2021-07-31T11:58:59.198395","exception":false,"start_time":"2021-07-31T11:58:58.042065","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp.head()","metadata":{"execution":{"iopub.execute_input":"2021-07-31T11:58:59.261056Z","iopub.status.busy":"2021-07-31T11:58:59.260536Z","iopub.status.idle":"2021-07-31T11:58:59.266157Z","shell.execute_reply":"2021-07-31T11:58:59.26571Z","shell.execute_reply.started":"2021-07-31T11:53:53.676148Z"},"papermill":{"duration":0.041041,"end_time":"2021-07-31T11:58:59.266274","exception":false,"start_time":"2021-07-31T11:58:59.225233","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp[\"BROWSE_NODE_ID\"]=temp[\"BROWSE_NODE_ID\"].map(id2lbl)","metadata":{"execution":{"iopub.execute_input":"2021-07-31T11:58:59.474715Z","iopub.status.busy":"2021-07-31T11:58:59.473775Z","iopub.status.idle":"2021-07-31T11:58:59.494907Z","shell.execute_reply":"2021-07-31T11:58:59.49445Z","shell.execute_reply.started":"2021-07-31T11:53:53.695588Z"},"papermill":{"duration":0.202215,"end_time":"2021-07-31T11:58:59.495037","exception":false,"start_time":"2021-07-31T11:58:59.292822","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TextDataset(Dataset):\n  def __init__(self,data,tokenizer,mode=\"train\", max_length=None):\n    super(TextDataset, self).__init__()\n    self.sentence=data[\"TITLE\"]\n    if mode != \"test\":\n        self.label=data[\"BROWSE_NODE_ID\"]\n    self.tokenizer=tokenizer\n    self.max_length=max_length\n    self.mode=mode\n\n  def __len__(self):\n    return len(self.sentence)\n  \n  def __getitem__(self,idx):\n    inp_tokens=self.tokenizer.encode_plus(self.sentence[idx], \n                                          padding=\"max_length\", \n                                          add_special_tokens=True,\n                                          max_length=self.max_length,\n                                          truncation=True)\n    item={\n        \"input_ids\":torch.tensor(inp_tokens.input_ids,dtype=torch.long),\n        \"attention_mask\":torch.tensor(inp_tokens.attention_mask,dtype=torch.long)\n    }\n    if self.mode != \"test\":\n        item['labels'] = torch.tensor(self.label[idx], dtype=torch.long)\n\n    return item","metadata":{"execution":{"iopub.execute_input":"2021-07-31T11:58:59.55623Z","iopub.status.busy":"2021-07-31T11:58:59.555649Z","iopub.status.idle":"2021-07-31T11:58:59.559777Z","shell.execute_reply":"2021-07-31T11:58:59.55935Z","shell.execute_reply.started":"2021-07-31T11:53:53.880885Z"},"papermill":{"duration":0.038213,"end_time":"2021-07-31T11:58:59.559881","exception":false,"start_time":"2021-07-31T11:58:59.521668","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = TextDataset(temp, tokenizer, max_length=CFG.max_length)\ndataloader = DataLoader(dataset, \n                         batch_size=CFG.batch_size, \n                         num_workers=CFG.num_workers, \n                         shuffle=True)","metadata":{"execution":{"iopub.execute_input":"2021-07-31T11:58:59.617182Z","iopub.status.busy":"2021-07-31T11:58:59.616561Z","iopub.status.idle":"2021-07-31T11:58:59.619372Z","shell.execute_reply":"2021-07-31T11:58:59.618952Z","shell.execute_reply.started":"2021-07-31T11:53:53.893345Z"},"papermill":{"duration":0.033089,"end_time":"2021-07-31T11:58:59.619478","exception":false,"start_time":"2021-07-31T11:58:59.586389","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dataset)","metadata":{"execution":{"iopub.execute_input":"2021-07-31T11:58:59.676779Z","iopub.status.busy":"2021-07-31T11:58:59.675947Z","iopub.status.idle":"2021-07-31T11:58:59.679817Z","shell.execute_reply":"2021-07-31T11:58:59.679428Z","shell.execute_reply.started":"2021-07-31T11:53:53.905724Z"},"papermill":{"duration":0.033848,"end_time":"2021-07-31T11:58:59.679919","exception":false,"start_time":"2021-07-31T11:58:59.646071","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"next(iter(dataloader))","metadata":{"execution":{"iopub.execute_input":"2021-07-31T11:58:59.736495Z","iopub.status.busy":"2021-07-31T11:58:59.735882Z","iopub.status.idle":"2021-07-31T11:59:00.214927Z","shell.execute_reply":"2021-07-31T11:59:00.214444Z","shell.execute_reply.started":"2021-07-31T11:53:53.916284Z"},"papermill":{"duration":0.508619,"end_time":"2021-07-31T11:59:00.21506","exception":false,"start_time":"2021-07-31T11:58:59.706441","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# code from https://github.com/ronghuaiyang/arcface-pytorch/blob/47ace80b128042cd8d2efd408f55c5a3e156b032/models/metrics.py#L10\n\nclass ArcMarginProduct(nn.Module):\n    r\"\"\"Implement of large margin arc distance: :\n        Args:\n            in_features: size of each input sample\n            out_features: size of each output sample\n            s: norm of input feature\n            m: margin\n            cos(theta + m)\n        \"\"\"\n    def __init__(self, in_features, out_features, s=30.0, m=0.50, easy_margin=False):\n        super(ArcMarginProduct, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.s = s\n        self.m = m\n        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n\n        self.easy_margin = easy_margin\n        self.cos_m = math.cos(m)\n        self.sin_m = math.sin(m)\n        self.th = math.cos(math.pi - m)\n        self.mm = math.sin(math.pi - m) * m\n\n    def forward(self, input, label):\n        # --------------------------- cos(theta) & phi(theta) ---------------------------\n        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n        sine = torch.sqrt((1.0 - torch.pow(cosine, 2)).clamp(0, 1))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = torch.where(cosine > 0, phi, cosine)\n        else:\n            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n        # --------------------------- convert label to one-hot ---------------------------\n        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n        one_hot = torch.zeros(cosine.size(), device=CFG.device)\n        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)  # you can use torch.where if your torch.__version__ is 0.4\n        output *= self.s\n        # print(output)\n\n        return output","metadata":{"execution":{"iopub.execute_input":"2021-07-31T11:59:00.282899Z","iopub.status.busy":"2021-07-31T11:59:00.281555Z","iopub.status.idle":"2021-07-31T11:59:00.284002Z","shell.execute_reply":"2021-07-31T11:59:00.284416Z","shell.execute_reply.started":"2021-07-31T11:53:54.423127Z"},"papermill":{"duration":0.041677,"end_time":"2021-07-31T11:59:00.284543","exception":false,"start_time":"2021-07-31T11:59:00.242866","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, \n                 bert_model, \n                 num_classes=CFG.num_classes, \n                 last_hidden_size=CFG.bert_hidden_size):\n        \n        super().__init__()\n        self.bert_model = bert_model\n        self.arc_margin = ArcMarginProduct(last_hidden_size, \n                                           num_classes, \n                                           s=30.0, \n                                           m=0.50, \n                                           easy_margin=False)\n    \n    def get_bert_features(self, batch):\n        output = self.bert_model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n        last_hidden_state = output.last_hidden_state # shape: (batch_size, seq_length, bert_hidden_dim)\n        CLS_token_state = last_hidden_state[:, 0, :] # obtaining CLS token state which is the first token.\n        return CLS_token_state\n    \n    def forward(self, batch):\n        CLS_hidden_state = self.get_bert_features(batch)\n        output = self.arc_margin(CLS_hidden_state, batch['labels'])\n        return output","metadata":{"execution":{"iopub.execute_input":"2021-07-31T11:59:00.346781Z","iopub.status.busy":"2021-07-31T11:59:00.34507Z","iopub.status.idle":"2021-07-31T11:59:00.347397Z","shell.execute_reply":"2021-07-31T11:59:00.347793Z","shell.execute_reply.started":"2021-07-31T11:53:54.440076Z"},"papermill":{"duration":0.035946,"end_time":"2021-07-31T11:59:00.34791","exception":false,"start_time":"2021-07-31T11:59:00.311964","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AvgMeter:\n    def __init__(self, name=\"Metric\"):\n        self.name = name\n        self.reset()\n    \n    def reset(self):\n        self.avg, self.sum, self.count = [0]*3\n    \n    def update(self, val, count=1):\n        self.count += count\n        self.sum += val * count\n        self.avg = self.sum / self.count\n    \n    def __repr__(self):\n        text = f\"{self.name}: {self.avg:.4f}\"\n        return text\n\ndef one_epoch(model, \n              criterion, \n              loader,\n              optimizer=None, \n              lr_scheduler=None, \n              mode=\"train\", \n              step=\"batch\"):\n    \n    loss_meter = AvgMeter()\n    acc_meter = AvgMeter()\n    \n    tqdm_object = tqdm(loader, total=len(loader))\n    for batch in tqdm_object:\n        batch = {k: v.to(CFG.device) for k, v in batch.items()}\n        preds = model(batch)\n        loss = criterion(preds, batch['labels'])\n        if mode == \"train\":\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            if step == \"batch\":\n                lr_scheduler.step()\n                \n        count = batch['input_ids'].size(0)\n        loss_meter.update(loss.item(), count)\n        \n        accuracy = get_accuracy(preds.detach(), batch['labels'])\n        acc_meter.update(accuracy.item(), count)\n        if mode == \"train\":\n            tqdm_object.set_postfix(train_loss=loss_meter.avg, accuracy=acc_meter.avg, lr=get_lr(optimizer))\n        else:\n            tqdm_object.set_postfix(valid_loss=loss_meter.avg, accuracy=acc_meter.avg)\n    \n    return loss_meter, acc_meter\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group[\"lr\"]\n\ndef get_accuracy(preds, targets):\n    \"\"\"\n    preds shape: (batch_size, num_labels)\n    targets shape: (batch_size)\n    \"\"\"\n    preds = preds.argmax(dim=1)\n    acc = (preds == targets).float().mean()\n    return acc","metadata":{"execution":{"iopub.execute_input":"2021-07-31T11:59:00.427892Z","iopub.status.busy":"2021-07-31T11:59:00.42705Z","iopub.status.idle":"2021-07-31T11:59:00.440117Z","shell.execute_reply":"2021-07-31T11:59:00.438633Z","shell.execute_reply.started":"2021-07-31T11:53:54.45207Z"},"papermill":{"duration":0.065541,"end_time":"2021-07-31T11:59:00.440294","exception":false,"start_time":"2021-07-31T11:59:00.374753","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_eval(epochs, model, train_loader, valid_loader, \n               criterion, optimizer, lr_scheduler=None):\n    \n    best_loss = float('inf')\n    best_model_weights = copy.deepcopy(model.state_dict())\n    \n    for epoch in range(epochs):\n        print(\"*\" * 30)\n        print(f\"Epoch {epoch + 1}\")\n        current_lr = get_lr(optimizer)\n        \n        model.train()\n        train_loss, train_acc = one_epoch(model, \n                                          criterion, \n                                          train_loader, \n                                          optimizer=optimizer,\n                                          lr_scheduler=lr_scheduler,\n                                          mode=\"train\",\n                                          step=CFG.step)                     \n        model.eval()\n        with torch.no_grad():\n            valid_loss, valid_acc = one_epoch(model, \n                                              criterion, \n                                              valid_loader, \n                                              optimizer=None,\n                                              lr_scheduler=None,\n                                              mode=\"valid\")\n        \n        if valid_loss.avg < best_loss:\n            best_loss = valid_loss.avg\n            best_model_weights = copy.deepcopy(model.state_dict())\n            torch.save(model.state_dict(), f'{CFG.model_path}/{CFG.model_save_name}')\n            print(\"Saved best model!\")\n        \n        if isinstance(lr_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n            lr_scheduler.step(valid_loss.avg)\n            if current_lr != get_lr(optimizer):\n                print(\"Loading best model weights!\")\n                model.load_state_dict(torch.load(f'{CFG.model_path}/{CFG.model_save_name}', \n                                                 map_location=CFG.device))\n        \n        print(\"*\" * 30)","metadata":{"execution":{"iopub.execute_input":"2021-07-31T11:59:00.548207Z","iopub.status.busy":"2021-07-31T11:59:00.547396Z","iopub.status.idle":"2021-07-31T11:59:00.553927Z","shell.execute_reply":"2021-07-31T11:59:00.5526Z","shell.execute_reply.started":"2021-07-31T11:53:54.469503Z"},"papermill":{"duration":0.062526,"end_time":"2021-07-31T11:59:00.554082","exception":false,"start_time":"2021-07-31T11:59:00.491556","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(temp['TITLE'])","metadata":{"execution":{"iopub.execute_input":"2021-07-31T11:59:00.645189Z","iopub.status.busy":"2021-07-31T11:59:00.64427Z","iopub.status.idle":"2021-07-31T11:59:00.656239Z","shell.execute_reply":"2021-07-31T11:59:00.65561Z","shell.execute_reply.started":"2021-07-31T11:53:54.481916Z"},"papermill":{"duration":0.059752,"end_time":"2021-07-31T11:59:00.656387","exception":false,"start_time":"2021-07-31T11:59:00.596635","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(temp['BROWSE_NODE_ID'])","metadata":{"execution":{"iopub.execute_input":"2021-07-31T11:59:00.766309Z","iopub.status.busy":"2021-07-31T11:59:00.765467Z","iopub.status.idle":"2021-07-31T11:59:00.768795Z","shell.execute_reply":"2021-07-31T11:59:00.766989Z","shell.execute_reply.started":"2021-07-31T11:53:54.495425Z"},"papermill":{"duration":0.054951,"end_time":"2021-07-31T11:59:00.768943","exception":false,"start_time":"2021-07-31T11:59:00.713992","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, valid_df = train_test_split(temp, \n                                      test_size=0.33, \n                                      shuffle=True, \n                                      random_state=42)\ntrain_df=train_df.reset_index(drop=True)\nvalid_df=valid_df.reset_index(drop=True)\n\ntrain_dataset = TextDataset(train_df, tokenizer, max_length=CFG.max_length)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, \n                                           batch_size=CFG.batch_size, \n                                           num_workers=CFG.num_workers, \n                                           shuffle=True)\n\nvalid_dataset = TextDataset(valid_df, tokenizer, max_length=CFG.max_length)\nvalid_loader = torch.utils.data.DataLoader(valid_dataset, \n                                           batch_size=CFG.batch_size, \n                                           num_workers=CFG.num_workers, \n                                           shuffle=False)","metadata":{"execution":{"iopub.execute_input":"2021-07-31T11:59:00.867922Z","iopub.status.busy":"2021-07-31T11:59:00.867294Z","iopub.status.idle":"2021-07-31T11:59:03.636026Z","shell.execute_reply":"2021-07-31T11:59:03.635547Z","shell.execute_reply.started":"2021-07-31T11:53:54.505841Z"},"papermill":{"duration":2.82317,"end_time":"2021-07-31T11:59:03.636198","exception":false,"start_time":"2021-07-31T11:59:00.813028","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model(bert_model).to(CFG.device)\nprint(model)","metadata":{"execution":{"iopub.execute_input":"2021-07-31T11:59:03.700823Z","iopub.status.busy":"2021-07-31T11:59:03.700148Z","iopub.status.idle":"2021-07-31T11:59:09.408865Z","shell.execute_reply":"2021-07-31T11:59:09.4078Z","shell.execute_reply.started":"2021-07-31T11:53:57.090488Z"},"papermill":{"duration":5.74265,"end_time":"2021-07-31T11:59:09.409064","exception":false,"start_time":"2021-07-31T11:59:03.666414","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=CFG.learning_rate)\nif CFG.scheduler == \"ReduceLROnPlateau\":\n    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n                                                              mode=\"min\", \n                                                              factor=CFG.factor, \n                                                              patience=CFG.patience)\n\ntrain_eval(CFG.epochs, model, train_loader, valid_loader,\n           criterion, optimizer, lr_scheduler=lr_scheduler)","metadata":{"execution":{"iopub.execute_input":"2021-07-31T11:59:09.482577Z","iopub.status.busy":"2021-07-31T11:59:09.481804Z","iopub.status.idle":"2021-07-31T20:21:15.722612Z","shell.execute_reply":"2021-07-31T20:21:15.723224Z"},"papermill":{"duration":30126.280257,"end_time":"2021-07-31T20:21:15.723413","exception":false,"start_time":"2021-07-31T11:59:09.443156","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir tokenizer\ntokenizer.save_pretrained(\"./tokenizer\")\ntorch.save(model.state_dict(), \"final.pt\")","metadata":{"execution":{"iopub.execute_input":"2021-07-31T20:21:15.855089Z","iopub.status.busy":"2021-07-31T20:21:15.801944Z","iopub.status.idle":"2021-07-31T20:21:21.042804Z","shell.execute_reply":"2021-07-31T20:21:21.043546Z"},"papermill":{"duration":5.284999,"end_time":"2021-07-31T20:21:21.043805","exception":false,"start_time":"2021-07-31T20:21:15.758806","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model,'RoBERTArcFace.pth')","metadata":{"execution":{"iopub.execute_input":"2021-07-31T20:21:21.329495Z","iopub.status.busy":"2021-07-31T20:21:21.328076Z","iopub.status.idle":"2021-07-31T20:21:27.571335Z","shell.execute_reply":"2021-07-31T20:21:27.570397Z"},"papermill":{"duration":6.41806,"end_time":"2021-07-31T20:21:27.571471","exception":false,"start_time":"2021-07-31T20:21:21.153411","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":1.19817,"end_time":"2021-07-31T20:21:35.635206","exception":false,"start_time":"2021-07-31T20:21:34.437036","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}