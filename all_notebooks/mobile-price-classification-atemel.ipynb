{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"   **MOBILE PRICE CLASSIFICATION DATASET**"},{"metadata":{},"cell_type":"markdown","source":"Bu çalışma sayfasında Mobile Price Classification datası ile ilgili yeni bir çözüm örneğini paylaşıyorum. Konu hakkındaki yorumlarınız benim için önemlidir.\n\nBazı kısımlar da görüş eksikliği veya dolaylı yoldan gidilmiş olabilir yeni olan tüm önerilere açığım umarım bu örnek çalışma sizin için faydalı olur.\n\n\nMerhaba bu çalışma da \"Mobile Price Classification\" datası ile çeşitli makine öğrenmesi algoritmaları kurup bu algoritmaları iyileştirmeye çalışacağız. Aynı zamanda data da bulunan değişkenleri inceleyerek bazı değişimler yapıp modelimizi daha iyi açıklayacı hale getirmeye çalışacağız."},{"metadata":{},"cell_type":"markdown","source":"Önce datamızı tanıyarak başlayalım...\n\nMobile Price Classification datasında bizlere 20 farklı değişken veriyor. Nedir bu değişkenler?\n\n1. Battery Power (Telefona ait batarya kapasitesini göstern deişken)\n2. Blue (Bluetooth özelliğinin olup olmadığını gösteren değişken)\n3. Clock Speed (İşlemci hızını gösteren değişken)\n4. Dual Sim (Çift sim kart olup olmadığını gösteren değişken)\n5. FC (Ön kamera mp değeri)\n6. 4G (Telefonun 4G bağlantısı olup olamdığını gösteren değişken)\n7. İnt Memory (Bellek)\n8. Mobile_Wt (Telefonun kalınlığını gösteren değer)\n9. n_cores (İşlemci sayısı)\n10. PC (Arka kamera mp değeri)\n11. px_height (Çözünürlük)\n12. px_width (Çözünürlük)\n13. Ram (ram)\n14. sc_h (Ekran yüksekliği)\n15. sc_w (Ekran genişliği)\n16. talk_time (Konuşma süresi)\n17. three_g (3G özelliğinin olup olmadığını gösteren değer)\n18. touch_screen (Dokunmatik olup olamdığını gösteren değer)\n19. wifi (kablosuz internetin olup olmadığını gösteren değer)\n20. price_range (fiyat aralığı -hedef değişken)\n\nAmacımız yukarıdaki değişkenleri kullanarak hedef değişkenimiz olan price_range değerini yüksek orandan doğru tahmin etmeye çalışmak.\n\nBaşlayalım.\n"},{"metadata":{},"cell_type":"markdown","source":"İlk olarak başlangıç kütüphanelerini ve train-test datasını yükleyerek başlayalım."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/mobile-price-classification/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/mobile-price-classification/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Verinin ilk 5 satırı, veriye ait veri tipleri, boş veri olup olamdığı ve basit istatistik değerlerini inceleyelim."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()/len(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Değişkenlerin veri tipleri int ve float herhangi encode işlemi yapmamıza gerek yok aynı zaman da veri de boş satırlarda yok!\n\nŞimdi hedef değişken olan price_range içerisinde kaç farklı sınıf var ve bu sınıflara ait ne kadar değer var bunlara bakalım."},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"price_range\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"0, 1, 2 ve 3 diye 4 farklı sınıfımız var biz bunları doğru tahmin etmeye çalışcağız. İşin güzel yanı bu dataset örnek bir dataset olduğu için sınıflar eşit miktarlarda eğer düzensiz olarak dağılsalardı model ilk aşamada daha fazla sayıda örnek bulunduran sınıfa yanlı davranabilirdi. Sınıfların çok düzensiz dağıldığı örnekler resample işlemi faydalı olabilir. Örneğin hedef değişken \"evet\" ve \"hayır\" şeklinde oluşan 2 farklı sınıf olsun ve \"hayır\" cevaplarının miktarı \"evet\"'lerin 10 katı, 100 katı hatta 1000 katı olduğunu düşünelim bu tip proplemlerde modeller genellikle hayır cevabına yanlı olacaktırlar. Bu problemi çözmek için eğer elinizde yeteri kadar data olduğunu düşünüyorsanız \"hayır\" ları \"evet\" lerin sayısını inderecek kadar satırı datanızdan çıkararak düzenleyebilirsiniz yada \"evet\" leri \"hayır\" ların sayısına getirecek kadar çoğaltabilirsiniz. Örnek çalışma için --> [https://www.kaggle.com/alpertemel/fraud-data-93-accuracy](http://)"},{"metadata":{},"cell_type":"markdown","source":"**price_range değişkeni ile en fazla kolerasyona sahip olan değişkenleri bulmak**"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train.corr().abs()\nn_most_correlated = 10\nmost_correlated_feature = corr[\"price_range\"].sort_values(ascending = False)[:n_most_correlated].drop(\"price_range\")\nmost_correlated_feature_name = most_correlated_feature.index.values\n\nf, ax = plt.subplots(figsize = (15, 6))\nplt.xticks(rotation = \"90\")\nsns.barplot(x = most_correlated_feature_name, y = most_correlated_feature)\nplt.title(\"En fazle kolerasyona sahip değişkenler\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En yüksek kolerasyona sahip değişken \"ram\". Ram neredeyse tek başına price_range değerini belirleyebilecek oranda güçlü.\n\nEn fazla kolerasyona sahip 10 değişkeni gördük şimdi de tüm değişkenlerin birbirleyle olan kolerasyonlarını bakalım."},{"metadata":{"trusted":true},"cell_type":"code","source":"corr2 = train.corr()\nf, ax = plt.subplots(figsize = (15, 6))\nsns.heatmap(corr2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Görüldüğü gibi price_range ile ram'dan başka iyi bir ilişkisi olan değişken yok. Çoğu 0 değerine yakın yani hiçbir açıklayıcılıkları yok. Aynı zaman da bir iki örnek hariç (ön ve arka kamera, 3G ve 4G gibi) değişkenlerin birbirleri ile de bir ilişkisi yok fakat yine de bizim datamızdalar. \n\nBunu daha net görebilmek için price_range ile en fazla ilişkiye sahip 10 değişkeni alıp bir pair plot çizdireceğim."},{"metadata":{"trusted":true},"cell_type":"code","source":"most_correlated_feature2 = corr[\"price_range\"].sort_values(ascending = False)[:10]\nfair = most_correlated_feature2.index\n\ntrain2 = pd.DataFrame()\n\nfor i in fair:\n    train2 = pd.concat([train2, train[i]], axis = 1)\n\n    \nsns.pairplot(data = train2, hue = \"price_range\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yukarıdaki grafikler de price_range değişkeninin ram hariç diğer değişkenlerde düzensiz, ratgele dağıldı gözüküyor ve bunlar en yüksek kolerasyona sahip 10 değişken. Belki de price_range'i açıklamak için bu değişkenlerin bir çoğuna ihtiyacımız yok ve belki de kuracağımız modelde fazlalık olup daha düşük bir skor elde etmemize neden olacaklar. \n\nDenemek için şöyle bir yöntem izleyeceğim;\n\nÖnce hiçbir işlem yapmadan train ve test setini hazılayıp bir model kuracağım ardından feature selection kullanarak çıkarmam gereken değişkenleri bulup çıkardıktan sonra hiçbir değişik yapmadan aynı modeli tekrar kuracağım.\n\n** feature selection --> \n\n\"Özellik seçimi (feature selection), orijinal veri setini temsil edebilecek en iyi altkümenin seçimi olarak tanımlanmaktadır. Özellik seçimi (diğer adıyla nitelik seçimi veya değişken seçimi), kullanılan algoritmaya göre özellikleri değerlendirerek veri setindeki n adet özellik arasından en iyi k adet özelliği seçme işlemidir.\"\n\nÖzellik Seçim Yöntemleri ve Yeni Bir Yaklaşım\nHüseyin BUDAK\n\nDaha ayrıntılı bilgi --> [https://dergipark.org.tr/en/download/article-file/552933](http://)"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = train.iloc[:, 0:20]\ny = train.iloc[:, 20:21]\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33, random_state = 23)\n\n#datanın train ve test setlerine bölümü.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier()\nrf.fit(x_train, y_train)\nrf_tahmin = rf.predict(x_test)\n\nprint(\"Accuracy Score: \", accuracy_score(y_test, rf_tahmin))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"İlk sonucumuzun değeri %75.\n\nŞimdi feature selection yaparak yine random forest modeli kuralım."},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nX_1 = sm.add_constant(x)\n\nmodel = sm.OLS(y,X_1).fit()\nmodel.pvalues\n\ncols2 = list(x.columns)\npmax = 1\nwhile (len(cols2)>0):\n    p= []\n    X_1 = x[cols2]\n    X_1 = sm.add_constant(X_1)\n    model = sm.OLS(y,X_1).fit()\n    p = pd.Series(model.pvalues.values[1:],index = cols2)      \n    pmax = max(p)\n    feature_with_p_max = p.idxmax()\n    if(pmax>0.05):\n        cols2.remove(feature_with_p_max)\n    else:\n        break\nselected_features_BE = cols2\nprint(selected_features_BE)\nlen(selected_features_BE)\n\n\ntrain2 = pd.DataFrame()\n\nfor i in selected_features_BE:\n    train2 = pd.concat([train2, train[i]], axis = 1)\n    \ntrain2 = pd.concat([train2, train[\"price_range\"]], axis = 1)\n\nx2 = train2.iloc[:, 0:6]\ny2 = train2.iloc[:, 6:7]\n\nX_train, X_test, Y_train, Y_test = train_test_split(x2, y2, test_size =0.33, random_state =34)\n\nrf2 = RandomForestClassifier()\nrf2.fit(X_train, Y_train)\nrf2_tahmin = rf2.predict(X_test)\n\nprint(\"FEATURE SELECTION İLE ACCURACY SCORE: \",accuracy_score(Y_test, rf2_tahmin))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature Selection ile model %86 başarı sağladı. Eski halinden 10 puan daha iyi bu oldukça güzel bir fark."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Modele feature selection ile devam etmek daha iyi.\n\nŞimdi sırasıyla knn ve svm modellerini deneyelim ve bu modelleri tune ederek nihai sonuca ulaşalım."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\nknn.fit(X_train, Y_train)\nknn_tahmin = knn.predict(X_test)\n\naccuracy_score(Y_test, knn_tahmin)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nknn_params = {\n        \"n_neighbors\" : np.arange(2, 10, 1),\n        \"weights\" : [\"uniform\", \"distance\"],\n        \"leaf_size\" : (30, 40, 50, 20),\n        \"p\" : (1, 2)\n        }\n\nknn_ = KNeighborsClassifier()\n\nknn_grid = GridSearchCV(knn_, knn_params, cv = 10, n_jobs = -1, verbose = 2)\nknn_grid.fit(X_train, Y_train)\nknn_grid.best_params_\n\nknn_tune = KNeighborsClassifier(leaf_size = 30, n_neighbors = 9, p = 2, weights = \"uniform\")\nknn_tune.fit(X_train, Y_train)\nknn_tune_tahmin = knn_tune.predict(X_test)\n\naccuracy_score(Y_test, knn_tune_tahmin)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm = SVC(kernel = \"linear\")\nsvm.fit(X_train, Y_train)\nsvm_tahmin = svm.predict(X_test)\n\naccuracy_score(Y_test, svm_tahmin)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En yüksek skoru %97 ile SVM çıkarmış oldu."},{"metadata":{},"cell_type":"markdown","source":"Umarım bu çalışma sizin için faydalı olmuştur.\n\nTekrar görüşmek üzere.\n\nAlper Temel."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}