{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Machine Learning and Artificial Neural Network approach for COVID-19 Early Detection From Audio Recording | Part 2\nby Nasrul Hakim\n\nPart 1 : https://www.kaggle.com/nasrulhakim86/covid-19-screening-from-audio-part-1\n\n### Import Libraries","metadata":{}},{"cell_type":"code","source":"# install pycaret\n!pip install pycaret","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-09-02T08:13:08.228644Z","iopub.execute_input":"2021-09-02T08:13:08.228982Z","iopub.status.idle":"2021-09-02T08:13:52.487284Z","shell.execute_reply.started":"2021-09-02T08:13:08.228931Z","shell.execute_reply":"2021-09-02T08:13:52.486306Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# utilities\nimport os\nimport sys\nfrom tqdm import tqdm\nimport random\n\n# data manipulation\nimport numpy as np\nimport pandas as pd\nimport librosa\nimport matplotlib.pyplot as plt\n\n# pycaret\nfrom pycaret.classification import *\n\n# scipy\nfrom scipy import signal\nfrom scipy.io import wavfile\nfrom scipy.signal import butter,filtfilt\nfrom scipy.signal import cwt\nfrom scipy.signal import hilbert\nfrom scipy.signal import resample\nfrom scipy.signal import decimate\nfrom scipy.signal import spectrogram\nfrom scipy.signal.windows import get_window\n\n# Set seed for reproducibility\nseed_value= 32 \nos.environ['PYTHONHASHSEED']=str(seed_value)\nrandom.seed(seed_value)\nnp.random.seed(seed_value)\n\n# set variables\nROOT = '../input/coughvid-wav/public_dataset/'\nclass_names = ['healthy','COVID-19','symptomatic']\naudio_length = 22050\n\n# load coughvid meta\ndata_raw = pd.read_csv(ROOT+'metadata_compiled.csv')\ndata_raw.head(3)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-02T08:14:23.653655Z","iopub.execute_input":"2021-09-02T08:14:23.654092Z","iopub.status.idle":"2021-09-02T08:14:28.031717Z","shell.execute_reply.started":"2021-09-02T08:14:23.654051Z","shell.execute_reply":"2021-09-02T08:14:28.03083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_raw.status.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-02T08:14:35.620444Z","iopub.execute_input":"2021-09-02T08:14:35.620774Z","iopub.status.idle":"2021-09-02T08:14:35.637604Z","shell.execute_reply.started":"2021-09-02T08:14:35.620744Z","shell.execute_reply":"2021-09-02T08:14:35.636529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Pre-processing\n\nGiven the size of the dataset and its varied quality, it was initially filtered as follows.\n- Only data that has been observed by physicians\n- Remove data without status\n- Select only cough_detected > 0.8\n- Select only data that has been reviewed as good quality by physicians","metadata":{}},{"cell_type":"code","source":"def split_by_physicians(df):\n    column_names = ['uuid', 'datetime', 'cough_detected', 'SNR', 'latitude', 'longitude', \n                    'age', 'gender', 'respiratory_condition', 'fever_muscle_pain', 'status', \n                    'quality', 'cough_type', 'dyspnea', 'wheezing', 'stridor', 'choking', \n                    'congestion', 'nothing', 'diagnosis', 'severity' ]\n    physician_01 = df.iloc[:, 0:21]\n    physician_01 = physician_01[physician_01.quality_1.notna()].reset_index(drop=True)\n    physician_01.columns = column_names\n\n    physician_02 = pd.concat([df.iloc[:, 0:11], df.iloc[:, 21:31]], axis=1)\n    physician_02 = physician_02[physician_02.quality_2.notna()].reset_index(drop=True)\n    physician_02.columns = column_names\n\n    physician_03 = pd.concat([df.iloc[:, 0:11], df.iloc[:, 31:41]], axis=1)\n    physician_03 = physician_03[physician_03.quality_3.notna()].reset_index(drop=True)\n    physician_03.columns = column_names\n\n    physician_04 = pd.concat([df.iloc[:, 0:11], df.iloc[:, 41:51]], axis=1)\n    physician_04 = physician_04[physician_04.quality_4.notna()].reset_index(drop=True)\n    physician_04.columns = column_names\n    return physician_01, physician_02, physician_03, physician_04\n    \ndef process_csv(df):\n    #split by physicians\n    physician_01, physician_02, physician_03, physician_04 = split_by_physicians(df)\n    # combine into one dataframe\n    df = pd.concat([physician_01,physician_02,physician_03,physician_04]).reset_index(drop=True)  \n    # drop null status\n    df = df[df.status.notna()]\n    # drop cough_detected < 0.8\n    df = df[df.cough_detected >= 0.8 ]\n    # select good and ok quality\n    df = df[df.quality == 'good']\n    # shuffle\n    df = df.sample(frac=1).reset_index(drop=True) \n    df = df[['uuid', 'status','cough_type', 'dyspnea', 'wheezing', 'stridor', 'choking', 'congestion', 'severity']]\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-09-02T08:14:36.833321Z","iopub.execute_input":"2021-09-02T08:14:36.833674Z","iopub.status.idle":"2021-09-02T08:14:36.845188Z","shell.execute_reply.started":"2021-09-02T08:14:36.833643Z","shell.execute_reply":"2021-09-02T08:14:36.844254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processed_df = process_csv(data_raw)\nprocessed_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T08:14:51.49633Z","iopub.execute_input":"2021-09-02T08:14:51.49665Z","iopub.status.idle":"2021-09-02T08:14:51.587122Z","shell.execute_reply.started":"2021-09-02T08:14:51.49662Z","shell.execute_reply":"2021-09-02T08:14:51.586084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Audio Data & Feature Extraction\nBefore feeding the audio data into the model for training, a few transformations were made to it for feature extraction.\n- Normalize, lowpass filter, and downsample cough samples\n- Select only the cough portion in the audio\n- Remove short segments\n- Make all audio segments the same size.\n- Rescale the data into [-1,1]","metadata":{}},{"cell_type":"code","source":"def segment_cough(x,fs, cough_padding=0.2,min_cough_len=0.2, th_l_multiplier = 0.1, th_h_multiplier = 2):\n    #Preprocess the data by segmenting each file into individual coughs using a hysteresis comparator on the signal power                \n    cough_mask = np.array([False]*len(x))\n    \n    #Define hysteresis thresholds\n    rms = np.sqrt(np.mean(np.square(x)))\n    seg_th_l = th_l_multiplier * rms\n    seg_th_h =  th_h_multiplier*rms\n\n    #Segment coughs\n    coughSegments = []\n    padding = round(fs*cough_padding)\n    min_cough_samples = round(fs*min_cough_len)\n    cough_start = 0\n    cough_end = 0\n    cough_in_progress = False\n    tolerance = round(0.01*fs)\n    below_th_counter = 0\n    \n    for i, sample in enumerate(x**2):\n        if cough_in_progress:\n            if sample<seg_th_l:\n                below_th_counter += 1\n                if below_th_counter > tolerance:\n                    cough_end = i+padding if (i+padding < len(x)) else len(x)-1\n                    cough_in_progress = False\n                    if (cough_end+1-cough_start-2*padding>min_cough_samples):\n                        coughSegments.append(x[cough_start:cough_end+1])\n                        cough_mask[cough_start:cough_end+1] = True\n            elif i == (len(x)-1):\n                cough_end=i\n                cough_in_progress = False\n                if (cough_end+1-cough_start-2*padding>min_cough_samples):\n                    coughSegments.append(x[cough_start:cough_end+1])\n            else:\n                below_th_counter = 0\n        else:\n            if sample>seg_th_h:\n                cough_start = i-padding if (i-padding >=0) else 0\n                cough_in_progress = True\n    \n    return coughSegments, cough_mask\n\ndef extract_features(audio_data, sample_rate):\n\n    features = []\n    stft = np.abs(librosa.stft(audio_data))\n\n    mfcc = np.mean(librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40).T,axis=0)\n    features.extend(mfcc) # 40 = 40\n\n    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n    features.extend(chroma) # 12 = 52\n\n    mel = np.mean(librosa.feature.melspectrogram(audio_data, sr=sample_rate).T,axis=0)\n    features.extend(mel) # 128 = 180\n\n    fmin_val = 0.5 * sample_rate * 2**(-6)\n    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate, fmin=fmin_val).T,axis=0)\n    features.extend(contrast) # 7 = 187\n\n    return np.array(features)\n\n\ndef load_features(df):\n    all_data, all_fname = [], []\n    for idx in tqdm(range(len(df))):\n        fname = df.uuid.iloc[idx]\n        path = ROOT+fname+'.wav' \n\n        # load sound sample\n        audio, sample_rate = librosa.load(path, mono=True)\n\n        # Segment each audio into individual coughs using a hysteresis comparator on the signal power\n        cough_segments, cough_mask = segment_cough(audio, sample_rate, min_cough_len=0.1, cough_padding=0.1, th_l_multiplier = 0.1, th_h_multiplier = 2)\n\n        # For each segment, resize to the same length(11025)\n        if len(cough_segments) > 0 :\n            i = 0\n            for audio in cough_segments:\n                i+=1\n                if len(audio) > 8000:\n                    if len(audio) < audio_length:\n                        audio_pad = librosa.util.pad_center(audio, audio_length)\n                    else:\n                        audio_pad = audio[:audio_length]  \n\n                feature = extract_features(audio_pad, sample_rate)\n                #print(len(feature))\n                all_data.append(feature)\n                all_fname.append(fname)\n    \n    return np.array(all_fname), np.array(all_data)","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-02T08:17:12.811723Z","iopub.execute_input":"2021-09-02T08:17:12.812107Z","iopub.status.idle":"2021-09-02T08:17:12.830473Z","shell.execute_reply.started":"2021-09-02T08:17:12.812072Z","shell.execute_reply":"2021-09-02T08:17:12.82951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This may take some time, so go watch some Korean dramas first.\nuuid, X = load_features(processed_df)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T08:17:13.819555Z","iopub.execute_input":"2021-09-02T08:17:13.819865Z","iopub.status.idle":"2021-09-02T08:48:06.044391Z","shell.execute_reply.started":"2021-09-02T08:17:13.819836Z","shell.execute_reply":"2021-09-02T08:48:06.04333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Store each features in different dataframe so you can choose to train all features or individual\nX_mfcc = X[:, 0:40]\nX_chroma = X[:, 40:52]\nX_mel = X[:, 52:180]\nX_contrast = X[:, 180:]\n\n# mfcc only\nuuid_df = pd.DataFrame({'uuid':uuid})\nmfcc_df = pd.DataFrame(X_mfcc)\nmfcc_df.columns=[\"mfcc\"+str(i) for i in range(1, X_mfcc.shape[1]+1)]\nall_mfcc_df = pd.concat([uuid_df, mfcc_df], axis=1)\n\n# mel spectogram only\nmel_df = pd.DataFrame(X_mel)\nmel_df.columns=[\"mel\"+str(i) for i in range(1, X_mel.shape[1]+1)]\nall_mel_df = pd.concat([uuid_df, mel_df], axis=1)\n\n# chroma only\nchroma_df = pd.DataFrame(X_chroma)\nchroma_df.columns=[\"chr\"+str(i) for i in range(1, X_chroma.shape[1]+1)]\nall_chroma_df = pd.concat([uuid_df, chroma_df], axis=1)\n\n# contrast only\ncontrast_df = pd.DataFrame(X_contrast)\ncontrast_df.columns=[\"con\"+str(i) for i in range(1, X_contrast.shape[1]+1)]\nall_contrast_df = pd.concat([uuid_df, contrast_df], axis=1)\n\n# all features\nall_df = pd.concat([uuid_df, mfcc_df, mel_df, chroma_df, contrast_df ], axis=1)\nall_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T09:06:27.276903Z","iopub.execute_input":"2021-09-02T09:06:27.277255Z","iopub.status.idle":"2021-09-02T09:06:27.440602Z","shell.execute_reply.started":"2021-09-02T09:06:27.277225Z","shell.execute_reply":"2021-09-02T09:06:27.439415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instead of predicting the status (healthy/covid/symptomatic), we train a model to to identify the cough type (dry/wet)\n\n# Select what you would like to predict ('status', 'cough_type', 'dyspnea', 'wheezing', 'stridor', 'choking', 'congestion', 'severity')\nlabel_df = processed_df[['uuid', 'cough_type']].reset_index(drop=True)\n\n# merge features and label to train\ndataset = pd.merge(all_df, label_df, on='uuid')\n\n# remove null columns\ndataset = dataset[dataset.cough_type != 'unknown']\ndataset.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T09:06:37.19793Z","iopub.execute_input":"2021-09-02T09:06:37.198332Z","iopub.status.idle":"2021-09-02T09:06:37.356604Z","shell.execute_reply.started":"2021-09-02T09:06:37.198301Z","shell.execute_reply":"2021-09-02T09:06:37.355634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.cough_type.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-02T09:06:45.545974Z","iopub.execute_input":"2021-09-02T09:06:45.546306Z","iopub.status.idle":"2021-09-02T09:06:45.557312Z","shell.execute_reply.started":"2021-09-02T09:06:45.546276Z","shell.execute_reply":"2021-09-02T09:06:45.556245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fix imbalance\ndataset = dataset.groupby('cough_type').sample(n=2185)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T09:08:38.190145Z","iopub.execute_input":"2021-09-02T09:08:38.190486Z","iopub.status.idle":"2021-09-02T09:08:38.210328Z","shell.execute_reply.started":"2021-09-02T09:08:38.190456Z","shell.execute_reply":"2021-09-02T09:08:38.209458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setup pycaret environment\n\nPyCaret is a Python open source machine learning library designed to make performing standard tasks in a machine learning project easy. We will use pycaret to sweep all algorithm for a quick comparison.\n\nhttps://pycaret.org/","metadata":{}},{"cell_type":"code","source":"exp_clf102 = setup(\n    data = dataset, \n    target = 'cough_type',\n    normalize = True, \n    transformation = True, \n    silent = True,\n    ignore_features=['uuid']\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T09:08:45.296568Z","iopub.execute_input":"2021-09-02T09:08:45.296882Z","iopub.status.idle":"2021-09-02T09:08:49.789199Z","shell.execute_reply.started":"2021-09-02T09:08:45.296851Z","shell.execute_reply":"2021-09-02T09:08:49.788342Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Compare Model","metadata":{}},{"cell_type":"code","source":"compare_models()","metadata":{"execution":{"iopub.status.busy":"2021-09-02T09:08:55.657423Z","iopub.execute_input":"2021-09-02T09:08:55.657779Z","iopub.status.idle":"2021-09-02T09:24:16.45448Z","shell.execute_reply.started":"2021-09-02T09:08:55.657747Z","shell.execute_reply":"2021-09-02T09:24:16.45363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Build Model","metadata":{}},{"cell_type":"code","source":"xgboost = create_model('xgboost')","metadata":{"execution":{"iopub.status.busy":"2021-09-02T09:25:27.229314Z","iopub.execute_input":"2021-09-02T09:25:27.229698Z","iopub.status.idle":"2021-09-02T09:27:46.315754Z","shell.execute_reply.started":"2021-09-02T09:25:27.229668Z","shell.execute_reply":"2021-09-02T09:27:46.314952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluate Model Performance","metadata":{}},{"cell_type":"code","source":"plot_model(xgboost)","metadata":{"execution":{"iopub.status.busy":"2021-09-02T09:35:51.315931Z","iopub.execute_input":"2021-09-02T09:35:51.316298Z","iopub.status.idle":"2021-09-02T09:35:52.011811Z","shell.execute_reply.started":"2021-09-02T09:35:51.316268Z","shell.execute_reply":"2021-09-02T09:35:52.010955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(xgboost, plot = 'confusion_matrix')","metadata":{"execution":{"iopub.status.busy":"2021-09-02T09:35:56.668419Z","iopub.execute_input":"2021-09-02T09:35:56.668744Z","iopub.status.idle":"2021-09-02T09:35:57.231436Z","shell.execute_reply.started":"2021-09-02T09:35:56.668714Z","shell.execute_reply":"2021-09-02T09:35:57.230606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ideas to improve model performance\n* Hyperparameter tuning\n* Data augmentation - time masking, frequency masking, remove noise, add noise\n* Aggresive data cleaning\n* Ensemble model (bagging/boosting/stack)\n\n### Part 3 | Training using neural network","metadata":{}}]}