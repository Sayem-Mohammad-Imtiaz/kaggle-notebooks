{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Profitable Free Application Recommendation. Analysis of Apple and Google Play Store.\nThe goal of this guided project is to analyse applications on Apple Store and Google Play Store to find out which type of application have the most users and use that information to make a data driven recommendation for developers on the type of applications that would attract more users. (For the purpose of this project I pretend work as a data analyst in a company that creates free android and ios apps.)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"opened_1 = open('../input/google-and-apple-store/AppleStore.csv', encoding='utf8')\nopened_2 = open('../input/google-and-apple-store/googleplaystore.csv', encoding='utf8')\nfrom csv import reader\nread_file1= reader(opened_1)\nread_file2 = reader(opened_2)\nios = list(read_file1)\ngoogle_play = list(read_file2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">I created a function `explore_data()` which prints the specified part of any datasets of choice along with the number of rows and columns if the `row_and_columns` default argument is set to true.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def explore_data(dataset, start, end, rows_and_columns=False):\n    dataset_slice = dataset[start:end]\n    for row in dataset_slice:\n        print(row)\n        print('\\n')\n        \n    if rows_and_columns:\n        print('Number of rows:', len(dataset))\n        print('Number of columns:', len(dataset[0]))\n        print('----------------------------------------------------------------------------')\n        \n        \nprint('For Apple Store: ')\nexplore_data(ios[1:], 0, 2, rows_and_columns=True)\nprint('For Google Play: ')\nexplore_data(google_play[1:], 0, 2, rows_and_columns=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Here I printed the column names so we know the data_point(element) index.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ios_column_names = ios[0]\ngoogle_play_column_names = google_play[0]\n\nprint(ios_column_names)\nprint('\\n')\nprint(google_play_column_names)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">The entry in google_play dataset at row 10473 is wrong data as can be seen after printing it, so I deleted it in the next cell as I want to work with correct data to draw accurate conclusions.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(google_play[10473])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del google_play[10473] #DO NOT RUN DEL STATEMENT MORE THAN ONCE!","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true},"cell_type":"markdown","source":"## Checking for duplicate entries in Apple and Google Stores.\n**I will print an example of the duplicates and the number of duplicate entries and unique apps.**\n> I created a function `duplicate_and_unique_entries()` which collects the duplicates and unique apps in the lists; `unique_apps` and `duplicate_apps`, prints the length of both lists and an example of the duplicate app.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def duplicate_and_unique_entries(dataset, index):\n    unique_apps = []\n    duplicate_apps = []\n    \n    for apps in dataset:\n        name = apps[index]\n        if name in unique_apps:\n            duplicate_apps.append(name)\n        else:\n            unique_apps.append(name)\n            \n    print('Number of duplicate apps: ', len(duplicate_apps)) \n    print('Number of unique apps: ', len(unique_apps))\n    print('\\n')\n    print('Examples of duplicate apps: ', duplicate_apps[:3])\n   \n \nprint('For Google Play: ')\nduplicate_and_unique_entries(google_play[1:], 0)\nprint('--------------------------')\nprint('For ios:')\nduplicate_and_unique_entries(ios[1:], 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">I printed the occurences where the duplicate app example above occured.(To confirm that it is indeed a duplicate entry)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('For Google Play: ')\nfor app in google_play[1:]: \n    name = app[0]\n    if name == 'Quick PDF Scanner + OCR FREE':\n        print(app)\n        \n        \nprint('\\n')\nprint('For ios: ')\nfor app in ios[1:]:\n    name = app[1]\n    if name == 'Mannequin Challenge':\n        print(app)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">From calling the function `duplicate_and_unique_entries()` abobe we can see that the number of unique apps is the same as the expected length of the google and apple dataset(not counting the first row which contains the column names) after subtracting the number of duplicates from the original length of the google play dataset. (just to confirm).\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Expected length: ', len(google_play[1:]) - 1181)\nprint('Expected length for ios: ', len(ios[1:]) - 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Getting the cleaned datasets of Google and Apple Store.\n> By clean what I mean is that the datasets no longer contain duplicate entries and only one of the duplicates of the most recent entry is added to the list.\nFor that I used dictionaries, lists, if and elif statements and multiple conditions:\n* First I created a dictionary which contains the applications with their respective ratings or reviews.\n* Then I looped through the original dataset and for each iteration I checked if the rating or review and the name of the app is not in the dictionary and a list(to keep track of which apps have been added already).\n* I repeated the same process for the ios apps using different variables.\n* Printed the lengths of the cleaned datasets to be sure it's the same as the expected lengths after removing the duplicates.\nNow we have datasets that we can work with going forward. \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews_max = {}\nfor apps in google_play[1:]:\n    name = apps[0]\n    n_reviews = float(apps[3])\n    if name in reviews_max and reviews_max[name] < n_reviews:\n        reviews_max[name] = n_reviews\n    elif name not in reviews_max:\n        reviews_max[name] = n_reviews\n\n\n\ngoogle_play_cleaned = []\nalready_added = []\n\nfor app in google_play[1:]:\n    name = app[0]\n    n_reviews = float(app[3])\n    if n_reviews == reviews_max[name] and name not in already_added:\n        google_play_cleaned.append(app)\n        already_added.append(name)\nprint('Length of cleaned google dataset is: ', len(reviews_max))\n\nprint('-----------------------------------------------------------------------------------------------')\nios_rating_max = {}\nfor apps in ios[1:]:\n    name = apps[1]\n    n_ratings = float(apps[5])\n    if name in ios_rating_max and ios_rating_max[name] < n_ratings:\n        ios_rating_max[name] = n_ratings\n    elif name not in ios_rating_max:\n        ios_rating_max[name] = n_ratings\n\n\nios_cleaned = []\nios_already_added = []\nfor App in ios[1:]:\n    app_name = App[1]\n    N_ratings = float(App[5])\n    if N_ratings == ios_rating_max[app_name] and app_name not in ios_already_added:\n        ios_cleaned.append(App)\n        ios_already_added.append(app_name)\nprint('Length of cleaned  ios dataset is: ', len(ios_cleaned))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Removing non English apps: App targeted at English speaking audience.\n> Since the recommendation for the application I am going to make is based on english speaking audience only I would have to carry out our analysis without non English apps.\nHence the creation of `is_english()` function to check if an app is english or not.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def is_english(name):\n    count = 0\n    for char in name:\n        if ord(char) > 127:\n            count += 1\n            if count > 3:\n                return False\n        \n    return True\n    \nis_english('爱奇艺PPS -《欢乐颂2》电视剧热播')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> * First I created two lists, one for goole and ios respectively(`google_play_eng_appse` and `app_store_eng_apps`).\n* Then I looped through the cleaned datasets, and for each iteration I used the `is_english()` function to check if the name of the app is english and if it is then add to the respective list.\n* I proceeded to print the lengths of the datasets to know how many apps I have left to work with.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"google_play_eng_apps = []\napp_store_eng_apps = []\n\nfor app in ios_cleaned:\n    name = app[1]\n    if is_english(name):\n        app_store_eng_apps.append(app)\n        \nfor app in google_play_cleaned:\n    name = app[0]\n    if is_english(name):\n        google_play_eng_apps.append(app)\n        \nprint('The number of apps left in google_play dataset after removing the duplicates and non english apps are: ', len(google_play_eng_apps))\nprint('The number of apps left in ios afer removing non english apps are: ', len(app_store_eng_apps))        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Is it free? Taking away paid apps in Apple and Google Stores.\n> Since the analysis is based specifically on free applications, it would make no sense to include paid apps in our analysis. \nSo again we create new datasets `free_google_apps` and `free_ios_apps` which would only contain apps with the prices of `0.0`","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"free_google_apps = []\nfree_ios_apps = []\n\nfor apps in google_play_eng_apps:\n    price = apps[7]\n    if price == '0':\n        free_google_apps.append(apps)\n\nfor apps in app_store_eng_apps:\n    price = apps[4]\n    if price == '0.0':\n        free_ios_apps.append(apps)\n\nprint('Google apps left: ', len(free_google_apps))\nprint('ios apps left: ', len(free_ios_apps))\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true},"cell_type":"markdown","source":"## If it's popular then there is potential for success.\n### Finding popular applications\n> In the cell below I created two functions, `freq_table()` and `display_table()`, both takes a dataset and an index as argument, `freq_table()` returns an unsorted frequency table of the genre and the frequency of their apperance in percentage. The `display_table()` function displays in descending order the frequency table.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def freq_table(dataset, index):\n    freq_dict = {}\n    for apps in dataset:\n        genre = apps[index]\n        if genre not in freq_dict:\n            freq_dict[genre] = 1\n        elif genre in freq_dict:\n            freq_dict[genre] += 1\n\n    for genre in freq_dict:\n        freq_dict[genre] /= len(dataset)\n        freq_dict[genre] *= 100\n    return freq_dict\n        \n\ndef display_table(dataset, index):\n    table = freq_table(dataset, index)\n    table_display = []\n    for key in table:\n        key_value_as_tuple = (table[key], key)\n        table_display.append(key_value_as_tuple)\n    \n    table_sorted = sorted(table_display, reverse = True)\n    for entry in table_sorted:\n        print(entry[1], ':',entry[0])\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> The code below prints out the genre that has the highest average ratings in Apple Store.\nTo achieve this:\n* I created a list and a dictionary (`genres` and `genre_avg_user_ratings` respectively)\n* Looped through the dictionary generated by calling the `freq_table()` function created earlier.\n* Extracted the keys (which are the genres in the ios store) and added them to the list.\n* Looped through the `genres` list created above and for each iteration created two variables `total` and `len_genre` to store the sum of the ratings and number of apps specific to each genre. (This is so that the average for each genre can be calculated.)\n* Use a nested loop to loop through the `free_ios_app` list and for each iteration  calculated and stored the genre as a key and `average_user_rating` as a value in the `genre_avg_user_ratings` dictionary created earlier.\n* Since I can't sort a dictionary and a sorted result would make for quick analysis, I created a tuple with the contents of the dictionary,  sorted it in descending order, put it inside a list and displayed it's content","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"genres = []\ngenre_avg_user_ratings = {}\n\nfor key in freq_table(free_ios_apps, 11):\n    genres.append(key)\n\nfor genre in genres:\n    total = 0 #stores the sum of the number of ratings specific to each genre\n    len_genre = 0 #stores the number of apps specific to each genre\n    for app in free_ios_apps:\n        genre_app = app[11]\n        if genre_app == genre:\n            no_of_user_rating = float(app[5])\n            total += no_of_user_rating\n            len_genre += 1\n    average_user_rating = total / len_genre\n    genre_avg_user_ratings[genre] = average_user_rating\n\ngenre_avg_user_ratings_display = []\nfor key in genre_avg_user_ratings:\n    key_value_as_tuple = (genre_avg_user_ratings[key], key)\n    genre_avg_user_ratings_display.append(key_value_as_tuple)\n    \ngenre_avg_user_ratings_display = sorted(genre_avg_user_ratings_display, reverse=True)\nprint('The averager ratings for apps in ios store is: ')\nfor entry in genre_avg_user_ratings_display:\n    print(entry[1], ': ', entry[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">The code below prints out the most app by category with the highest average number of installs in Google Play Store in decreasing order.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"google_app_categories = []\ngoogle_app_avg_no_installs = {}\n\nfor key in freq_table(free_google_apps, 1):\n    google_app_categories.append(key)\n\n\nfor category in google_app_categories:\n    total = 0\n    len_category = 0\n    for app in free_google_apps:\n        category_app = app[1]\n        if category_app == category:\n            no_of_installs = app[5]\n            no_of_installs = no_of_installs.replace('+', '')\n            no_of_installs = no_of_installs.replace(',', '')\n            no_of_installs = float(no_of_installs)\n            total += no_of_installs\n            len_category += 1\n    avg_no_installs = total / len_category\n    google_app_avg_no_installs[category] = avg_no_installs\n\n    \nGoogle_avg_installs = []\nfor key in google_app_avg_no_installs:\n    keyValue_as_tuple = (google_app_avg_no_installs[key], key)\n    Google_avg_installs.append(keyValue_as_tuple)\n\nGoogle_avg_installs = sorted(Google_avg_installs, reverse=True)\nprint(\"The average number of installs for each app category in Google Play Store is: \")\nfor entry in Google_avg_installs:\n    print(entry[1], ': ', entry[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the results of the analysis, the niche seems to be dominated by communication and social application so I recommend a free productive social application with video communication capabilities.\n\nIt seems that there are a lot of social apps so I suggest building a free learning platform where teachers and students can meet for the purposes of learning, and it should also have video and audio capabilities to facilitate the learning experience.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Conclusions\nIn this guided project I analysed the data on Google and Apple Markets with the goal of recommending a free profitable app profile that will be successful in both markets.\n\nI concluded that building a productive and social application with video and voice communication capabilites as a learning platform where teachers and students meet. Since the niche in both markets tends towards that area, so combining the functionalities of social and networking apps as well as productive apps is an area worth looking into.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}