{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%config InlineBackend.figure_format = 'retina' # Make matplotlib render retina-quality charts\nimport seaborn as sns\nfrom IPython.display import display","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. First look at the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n\n# Some values in TotalCharges were not able to load as numeric.\n# I manually handle it by replacing them by the product of tenure and monthly charges.\ndata.TotalCharges = pd.to_numeric(data.TotalCharges, errors='coerce')\ndata.loc[data.TotalCharges.isnull(), 'TotalCharges'] = data.tenure * data.MonthlyCharges\n\nprint(\"Original dataset sample:\")\ndisplay(data.head(5))\ndisplay(data.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### What do I notice immediately:\n- The quality of data is really good. It was clear from Kaggle's preview, and now confirmed. There are no missing values, and all columns have meaningful sense and values.\n- \"customerID\" column contains unique IDs (confirmed at Kaggle's preview), so we can delete it.\n- Since a lot of feature are multi-level categorical features, we will need to do a lot of encoding."},{"metadata":{},"cell_type":"markdown","source":"## 2. Feature-by feature analysis\n**Important**: if I decide to drop or encode some features, I will consecutively add their names to special lists initialized in the cell below, and delete/encode them in 1 line in the end of the feature-by-feature analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_to_delete = [] # Here we will accumulate names of columns for deletion\ncolumns_to_encode = [] # Here we will accumulate names of columns for encoding\n\ndef plot_crosstab_and_value_counts_againts_target(categorical_feature):\n    \"\"\"This function takes a name of a categorical feature as string,\n    and plots crosstab and value_counts of it versus the target.\"\"\"\n    \n    print(\"Count of values: {} versus Churn:\".format(categorical_feature))\n    display(pd.crosstab(data.Churn, data[categorical_feature], margins=True).style.background_gradient(cmap='summer_r'))\n    print(\"Average churn rate for each {}:\".format(categorical_feature))\n    display(data.groupby(categorical_feature)['Churn'].mean().sort_values(ascending=False))\n    \ndef display_correlation_with_binned_version(numerical_feature):\n    \"\"\"This function takes a name of a numerical feature as string,\n    and plots crosstab and value_counts of it 5-binned version versus the target.\"\"\"\n    \n    feature_binned_name = numerical_feature + \"_binned\"\n    data[feature_binned_name] = pd.cut(data[numerical_feature], bins = 5)\n    plot_crosstab_and_value_counts_againts_target(feature_binned_name)\n    data.drop(feature_binned_name, axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### (Target) Churn\nThis column is binary, and contains string values \"Yes\" and \"No\". Let's encode it to boolean at the beginning, because it will allow us to calculate average churn rates per different dimensions of data."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Churn = data.Churn.map({\"Yes\": 1, \"No\": 0})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### (1/20) customerID\nAs was indicate above, this feature can be deleted."},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_to_delete.append(\"customerID\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### (2/20) gender – whether the customer is a male or a female"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_crosstab_and_value_counts_againts_target('gender')\ncolumns_to_delete.append(\"gender\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision**: this feature alone seems to have no correlation with the target. **Don't include** in the models."},{"metadata":{},"cell_type":"markdown","source":"### (3/20) SeniorCitizen – whether the customer is a senior citizen or not (1, 0)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_crosstab_and_value_counts_againts_target('SeniorCitizen')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision**: for both senior and non-senior citizens, the churn rate is <50%. However, for senior citizens it is 2 times higher than for non-senior! We will include this feature in the model. **Include** in the models."},{"metadata":{},"cell_type":"markdown","source":"### (4/20) Partner – whether the customer has a partner or not"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_crosstab_and_value_counts_againts_target('Partner')\ncolumns_to_encode.append('Partner')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision**: **Include** in the models. We see the big difference in average churn rate between the category classes."},{"metadata":{},"cell_type":"markdown","source":"### (5/20) Dependents – whether the customer has dependents or not (Yes, No)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_crosstab_and_value_counts_againts_target('Dependents')\ncolumns_to_encode.append('Dependents')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision**: **Include** in the models. We see the big difference in average churn rate between the category classes."},{"metadata":{},"cell_type":"markdown","source":"### (6/20) tenure – number of months the customer has stayed with the company"},{"metadata":{"trusted":true},"cell_type":"code","source":"display_correlation_with_binned_version('tenure')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision**: **Include** in the models. We see clear negative correlation between the tenure and the churn rate."},{"metadata":{},"cell_type":"markdown","source":"### (7/20) PhoneService – whether the customer has a phone service or not (Yes, No)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_crosstab_and_value_counts_againts_target('PhoneService')\ncolumns_to_delete.append('PhoneService')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision**: this feature alone seems to have no correlation with the target. **Don't include** in the models."},{"metadata":{},"cell_type":"markdown","source":"### (8/20) MultipleLines – whether the customer has multiple lines or not (Yes, No, No phone service)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_crosstab_and_value_counts_againts_target('MultipleLines')\ncolumns_to_delete.append('MultipleLines')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision**: this feature alone seems to have no correlation with the target. **Don't include** in the models."},{"metadata":{},"cell_type":"markdown","source":"### (9/20) InternetService – customer’s internet service provider (DSL, Fiber optic, No)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_crosstab_and_value_counts_againts_target('InternetService')\ncolumns_to_encode.append('InternetService')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision**: **Include** in the models. We see the big difference in average churn rate between the category classes."},{"metadata":{},"cell_type":"markdown","source":"### (10/20) OnlineSecurity – whether the customer has online security or not (Yes, No, No internet service)"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plot_crosstab_and_value_counts_againts_target('OnlineSecurity')\ncolumns_to_encode.append('OnlineSecurity')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision**: **Include** in the models. We see the big difference in average churn rate between the category classes."},{"metadata":{},"cell_type":"markdown","source":"### (11/20) OnlineBackup – whether the customer has online backup or not (Yes, No, No internet service)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_crosstab_and_value_counts_againts_target('OnlineBackup')\ncolumns_to_encode.append('OnlineBackup')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision**: **Include** in the models. We see the big difference in average churn rate between the category classes."},{"metadata":{},"cell_type":"markdown","source":"### (12/20) DeviceProtection – whether the customer has device protection or not (Yes, No, No internet service)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_crosstab_and_value_counts_againts_target('DeviceProtection')\ncolumns_to_encode.append('DeviceProtection')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision**: **Include** in the models. We see the big difference in average churn rate between the category classes."},{"metadata":{},"cell_type":"markdown","source":"### (13/20) TechSupport – whether the customer has tech support or not (Yes, No, No internet service)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_crosstab_and_value_counts_againts_target('TechSupport')\ncolumns_to_encode.append('TechSupport')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision**: **Include** in the models. We see the big difference in average churn rate between the category classes."},{"metadata":{},"cell_type":"markdown","source":"### (14/20) StreamingTV – whether the customer has streaming TV or not (Yes, No, No internet service)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_crosstab_and_value_counts_againts_target('StreamingTV')\ncolumns_to_delete.append('StreamingTV')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision**: this feature alone seems to have no correlation with the target. **Don't include** in the models."},{"metadata":{},"cell_type":"markdown","source":"### (15/20) StreamingMovies – whether the customer has streaming movies or not (Yes, No, No internet service)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_crosstab_and_value_counts_againts_target('StreamingMovies')\ncolumns_to_delete.append('StreamingMovies')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision**: this feature alone seems to have no correlation with the target. **Don't include** in the models."},{"metadata":{},"cell_type":"markdown","source":"### (16/20) Contract – the contract term of the customer (Month-to-month, One year, Two year)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_crosstab_and_value_counts_againts_target('Contract')\ncolumns_to_encode.append('Contract')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision**: **Include** in the models. We see the big difference in average churn rate between the category classes."},{"metadata":{},"cell_type":"markdown","source":"### (17/20) PaperlessBilling – whether the customer has paperless billing or not (Yes, No)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_crosstab_and_value_counts_againts_target('PaperlessBilling')\ncolumns_to_encode.append('PaperlessBilling')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision**: **Include** in the models. We see the big difference in average churn rate between the category classes."},{"metadata":{},"cell_type":"markdown","source":"### (18/20) PaymentMethod – the customer’s payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_crosstab_and_value_counts_againts_target('PaymentMethod')\ncolumns_to_encode.append('PaymentMethod')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision**: **Include** in the models. We see the big difference in average churn rate between the category classes."},{"metadata":{},"cell_type":"markdown","source":"### (19/20) MonthlyCharges – the amount charged to the customer monthly"},{"metadata":{"trusted":true},"cell_type":"code","source":"display_correlation_with_binned_version('MonthlyCharges')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision**: **Include** in the models. We see clear positive correlation between the monthly charges and churn rate."},{"metadata":{},"cell_type":"markdown","source":"### (20/20) TotalCharges – the total amount charged to the customer"},{"metadata":{"trusted":true},"cell_type":"code","source":"display_correlation_with_binned_version('TotalCharges')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision**: **Include** in the models. We see clear negative correlation between the total charges and churn rate."},{"metadata":{},"cell_type":"markdown","source":"## 3. Preprocessing of data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"We decided to delete columns: \" + str(columns_to_delete))\nprint(\"We decided to encode columns: \" + str(columns_to_encode))\n\n\"\"\"\n6 columns tell us similar information – whether a customer has a specific service connected {Yes, No, No internet at all}.\nHowever, we have a distinct feature (InternetService) to consider those who don't have internet, so to avoid\nmulticollinearity, we need to join \"No\" and \"No internet service\" in all six columns.\n\"\"\"\ncolumns_with_no_and_ns = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n                          'TechSupport', 'StreamingTV', 'StreamingMovies']\n\nfor column in columns_with_no_and_ns:\n    data.loc[:,column].replace(\"No internet service\", \"No\", inplace = True)\n    \n# Next, we have 2 categories in PaymentMethod with almost identical churn rate. Let's merge them.\ndata.PaymentMethod = data.PaymentMethod.map({\n    'Electronic check': 'Electronic check',\n    'Mailed check': 'Mailed check',\n    'Bank transfer (automatic)': \"Automatic\",\n    'Credit card (automatic)': \"Automatic\",\n})\n\n# Let's generate a new feature - total number of online services connected.\ndata['NumberOnlineServices'] = np.where(data.OnlineSecurity == 'Yes', 1, 0) + \\\n                               np.where(data.OnlineBackup == 'Yes', 1, 0) + \\\n                               np.where(data.DeviceProtection == 'Yes', 1, 0) + \\\n                               np.where(data.TechSupport == 'Yes', 1, 0) + \\\n                               np.where(data.StreamingTV == 'Yes', 1, 0) + \\\n                               np.where(data.StreamingMovies == 'Yes', 1, 0)\n                               \nplot_crosstab_and_value_counts_againts_target('NumberOnlineServices')\n\nprint(\"Starting the deletion and encoding, as requested...\")\n# Here we drop and encode all columns which we marked for deletion or encoding.\ndata.drop(columns_to_delete, axis = 1, inplace = True)\ndata = pd.get_dummies(data,\n                      columns = columns_to_encode,\n                      drop_first = True\n                      )\nprint(\"Deletion and encoding finished\")\n\n# Separate y and X\ny = data.Churn\nX = data.drop('Churn', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Creating 5 alternative models\nMost ML models have **hyperparameters** – parameters that should be specified before fitting the model. The process of choosing optimal hyperparameters is called **hyperparameters tuning**, and that's exactly what I do here.\n\nLet me introduce another concept – **regularization**. Regularization is the process of making a model more able to catch general trends instead of train-specific trends, by modifying the loss function. 'C' hyperparameter in logistic regression (and in many other models) is responsible for it. Low C-values lead to lower train score and higher test score, because the model becomes able to catch general trends better. However, excessively low c-values will make a model not able to catch any trends at all.\n\nFor each of the five models, my approach would be:\n1. Compare models with different key hyperparameter's values.\n1. Select the optimal value of key hyperparameter, based on highest cross-validated precision.\n1. Compare the best versions of each of the 5 models with each other.\n\nAlso, before running it, I'd like to specify that in this project my **target metric is precision**.\n**Precision** in general is the fraction of relevant instances among the retrieved instances. In this problem, it is a fraction of clients who did churn among those which were selected by the model as likely to chyrn. Precision reaches its best value at 1 and worst score at 0.\n\nI'm choosing precision for 2 reasons:\n- To provide business value for telecoms, it is better for this model to have lower recall but higher precision than vise versa. Predicting too much churn would mean losing money on ads which try to get people back while they don't plan to leave. On the other hand, we know that conversion rates of ads targeted to people who really want to churn are quite low, so we should spend them only for those who are really likely to churn.\n- We are facing a problem of imbalanced classes, and accuracy makes no sense in such problems."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import functions which will be used in all models\nfrom sklearn.model_selection import cross_val_score, ShuffleSplit\n# Create a split object – it will be used in all models.\nsplit = ShuffleSplit(n_splits=3, test_size=0.25, random_state=1111)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model 1: Logistic regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\n# Define an empty list to store precision for different hyperparameters\nlr_precisions = list()\n\n# Values of C to be checked\nlr_C_values = [0.001, 0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5, 1, 2, 3, 4, 5]\n\n# Loop over C values to find an optimal\nfor C_value in lr_C_values:\n    \n    # Create LogisticRegression object\n    lr_foropt = LogisticRegression(solver = 'liblinear', penalty = 'l1', C = C_value, max_iter=1000)\n    \n    # Fit it to the cross validator\n    lr_cv_results_list = cross_val_score(lr_foropt, X, y, cv = split, scoring = 'precision')\n    \n    # Compute the mean precision\n    lr_avg_precision = np.mean(lr_cv_results_list)\n    \n    # Append this mean to the list of precisions\n    lr_precisions.append(lr_avg_precision)\n    \n# Plot the results\nplt.plot(lr_C_values, lr_precisions)\nplt.title('C-value optimization')\nplt.ylabel('Cross-validated precision score')\nplt.xlabel('C value')\nplt.show()\n\n# Print the value of C-hyperparameter which was found optimal\nlr_optimalC = lr_C_values[lr_precisions.index(max(lr_precisions))]\nprint('Optimal c-value: ', lr_optimalC)\n\n# Create logistic regression with our optimal hyperparameter\nlr = LogisticRegression(solver = 'liblinear', penalty = 'l1', C = lr_optimalC, max_iter=1000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model 2: Decision Tree Classifier\nIn this classificator I'll tune 2 hyperparameters: criterion and max_depth of the tree. The instrument for tuning more that 1 hyperparameter is called **Grid Search**, and I apply it here:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import DecisionTreeClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Initialize a standard classifier\ndt_foropt = DecisionTreeClassifier()\n\n# Import GridSearchCV package\nfrom sklearn.model_selection import GridSearchCV\n\n# Instantiate the GridSearchCV object and run the search\nparameters_dt = {'criterion':['gini', 'entropy'],\n                 'max_depth': np.arange(3,100,2)}\n\nsearcher_dt = GridSearchCV(dt_foropt, parameters_dt, cv = split, scoring = 'precision')\nsearcher_dt.fit(X, y)\n\n# Report the best parameters and the corresponding score\nprint(\"Best CV params\", searcher_dt.best_params_)\n\n# Initialize a classifier with optimal parameters\ndt = DecisionTreeClassifier(criterion = searcher_dt.best_params_['criterion'],\n                            max_depth = searcher_dt.best_params_['max_depth'],\n                            class_weight = 'balanced')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model 3: KNN Classifier\nThe key hyperparameter of KNN is K – the number of neighbors to consider in voting."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import KNN from scikit learn\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Define an empty list to store precision for different hyperparameters\nknn_precisions = list()\n\n# Values of K to be checked\nneighbors = np.arange(1,50,2)\n\n# Loop over K values to find an optimal\nfor k in neighbors:\n    \n    # Create KNeighborsClassifier object\n    knn_foropt = KNeighborsClassifier(n_neighbors = k)\n    \n    # Fit it to the cross validator\n    knn_cv_results_list = cross_val_score(knn_foropt, X, y, cv = split, scoring = 'precision')\n    \n    # Compute the mean precision\n    knn_avg_precision = np.mean(knn_cv_results_list)\n    \n    # Append this mean to the list of precision scores\n    knn_precisions.append(knn_avg_precision)\n    \n# Plot the results\nplt.plot(neighbors, knn_precisions)\nplt.title('K value optimization')\nplt.ylabel('Cross-validated precision')\nplt.xlabel('Neighbors')\nplt.show()\n\n# Print the value of K-hyperparameter which was found optimal\nknn_optimal_k = neighbors[knn_precisions.index(max(knn_precisions))]\nprint('Optimal number of neighbors: ', knn_optimal_k)\n\n# Create a model with our optimal hyperparameter\nknn = KNeighborsClassifier(n_neighbors = knn_optimal_k)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model 4: CatBoost Classifier\nCatBoost Classifier is based on decision trees. It's key hyperparameter, according to the documentation, is the regularization strength, called \"l2_leaf_reg\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier\n\n# Define an empty list to store precision for different hyperparameters\ncbr_precisions = list()\n\n# Values of l2_leaf_reg to be checked\nl2_values = [0.01, 0.1, 0.25, 0.5, 1, 2, 3, 5, 10, 20, 50, 100, 200]\n\n# Loop over l2_leaf_reg values to find an optimal\nfor l2 in l2_values:\n    \n    # Create CatBoostClassifier object\n    cbr_foropt = CatBoostClassifier(l2_leaf_reg = l2, silent = True)\n    \n    # Fit it to the cross validator\n    cv_results_list_cbr = cross_val_score(cbr_foropt, X, y, cv = split, scoring = 'precision')\n    \n    # Compute the mean precision\n    cbr_avg_precision = np.mean(cv_results_list_cbr)\n    \n    # Append this mean to the list of precisions\n    cbr_precisions.append(cbr_avg_precision)\n    \n# Plot the results\nplt.plot(l2_values, cbr_precisions)\nplt.title('CBR optimization')\nplt.ylabel('Precision')\nplt.xlabel('l2_leaf_reg')\nplt.show()\n\n# Print the value of l2-hyperparameter which was found optimal\noptimal_l2 = l2_values[cbr_precisions.index(max(cbr_precisions))]\nprint('Optimal l2-value: ', optimal_l2)\n\n# Create CatBoostClassifier with our optimal hyperparameter\ncbr = CatBoostClassifier(l2_leaf_reg = optimal_l2, silent = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model 5. AdaBoost Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\n\nada = AdaBoostClassifier(n_estimators = 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Comparing models"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import plot_confusion_matrix, roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n\ndef print_report_for_classifier(model, model_name = 'unnamed classifier'):\n    \"\"\"This function takes and UNtrained but created model object and its verbose name as parametets,\n    and prints a report with its performance of the entire dataset.\n    Please, note, that this report assumes that we test the model on the same data as we use to train it,\n    because we've already tuned the hyperparameters in a way to aviod overfitting.\"\"\"\n    \n    model.fit(X, y)\n    y_pred = model.predict(X)\n    \n    # Calculate necessary data for ROC/AUC\n    fpr, tpr, thresholds = roc_curve(y, y_pred)\n    area = auc(fpr, tpr)\n\n    print(\"Report for {}:\".format(model_name))\n    print('-'*100)\n    \n    # The next block of code just creates a figure with 2 charts\n    fig = plt.figure(figsize = (8, 4), dpi = 100)\n\n    axes11 = fig.add_subplot(121)\n    plot_confusion_matrix(model, X, y, cmap = 'summer_r', values_format = \"1\", ax = axes11)\n    axes11.set_title('Confusion matrix')\n\n    axes12 = fig.add_subplot(122)\n    axes12.plot(fpr, tpr, color = 'orange', label = \"ROC curve (area = {:.2f})\".format(area))\n    axes12.plot([0,1], [0,1], linestyle='--', label = 'Diagonal')\n    axes12.set_xlim([0,1])\n    axes12.set_ylim([0,1.05])\n    axes12.set_xlabel('False Positive Rate')\n    axes12.set_ylabel('True Positive Rate')\n    axes12.set_title('ROC')\n    axes12.legend()\n\n    plt.tight_layout()\n    plt.show()\n    print('-'*100)\n    \n    # We include 4 key metrics in our report\n    accuracy = accuracy_score(y, y_pred)\n    precision = precision_score(y, y_pred)\n    recall = recall_score(y, y_pred)\n    f1 = f1_score(y, y_pred)\n\n    print('Accuracy: ', round(accuracy, 2))\n    print('Precision: ', round(precision, 2))\n    print('Recall: ', round(recall, 2))\n    print('F1: ', round(f1, 2))\n    print('AUC: ', round(area, 2))\n    print('-'*100)\n\ndef display_comparison_table(models_with_names):\n\n    column_names = [\"Model\", \"Precision\", \"Recall\", \"F1\", \"Accuracy\", \"AUC\"]\n    df = pd.DataFrame(columns = column_names)\n\n    for model, name in models_with_names:\n\n        model.fit(X, y)\n        y_pred = model.predict(X)\n        fpr, tpr, thresholds = roc_curve(y, y_pred)\n\n        precision = precision_score(y, y_pred)\n        recall = recall_score(y, y_pred)\n        f1 = f1_score(y, y_pred)\n        accuracy = accuracy_score(y, y_pred)\n        area = auc(fpr, tpr)\n\n        df = df.append({\n            \"Model\": name,\n            \"Precision\": precision,\n            \"Recall\": recall,\n            \"F1\": f1,\n            \"Accuracy\": accuracy,\n            \"AUC\": area\n        }, ignore_index = True)\n\n    def highlight_max_value_in_each_column(s):\n        is_max = s == s.max()\n        return ['background-color: PaleGreen' if v else '' for v in is_max]    \n\n    df = df.set_index('Model').sort_values(by = 'Precision', ascending = False)\n\n    display(\n        df.style\\\n            .apply(highlight_max_value_in_each_column)\\\n            .set_precision(2)\n    )\n\n# Declare all models which we used\nmodels_with_names = [\n    (lr, 'Logistic Regression'),\n    (dt, 'Decision Tree'),\n    (knn, 'KNN classifier'),\n    (cbr, 'CatBoost Classifier'),\n    (ada, 'AdaBoost Classifier')\n]    \n\n\ndisplay_comparison_table(models_with_names)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for model, name in models_with_names:\n    print_report_for_classifier(model, name)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. Making conclusions\nAccording to our criteria – precision, the best model is **CatBoost Classifier**. It gives us not only the best precision, but the best values for accuracy, AUC and F1 score. The optimal l2_leaf_reg value is 100."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}