{"cells":[{"metadata":{"trusted":true,"scrolled":true,"_uuid":"7cd5791683361f26438dddb298f12de018015ffc"},"cell_type":"markdown","source":"## Importing Essential Libraries"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"ed358f1b666f2b718d24c42a5f9f4b2dd3cee755"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport sklearn\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n%matplotlib inline\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import SGD\nimport tensorflow as tf\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65751479192da05c9a8f14ba99f031dd3481dfb7"},"cell_type":"code","source":"#reading the dataset\ndf = pd.read_csv(\"../input/creditcard.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e6918c3ac504873db055eaa829289f3cd70ecb2"},"cell_type":"markdown","source":"# Visualizing the dataset"},{"metadata":{"trusted":true,"_uuid":"523155d0465c5691dab04a718a73b5af2e80bc81","scrolled":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d17b032a7505b59080024c1ea51a205b0fe2b85"},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7914ff5b75257c9c3660b43c88b6b34abfab1d59"},"cell_type":"markdown","source":"## Correlation"},{"metadata":{"trusted":true,"_uuid":"4e4ea14458de43275ef07b67db738376f64a9ee9"},"cell_type":"code","source":"dataset2 = df.drop(columns = ['Class'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20af1bde78798a4859ea1849b1a6c4c14c141c92"},"cell_type":"code","source":"dataset2.corrwith(df.Class).plot.bar(\n        figsize = (20, 10), title = \"Correlation with Class\", fontsize = 20,\n        rot = 45, grid = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a1335318a84a68f07ab6f0c5502b068932ba288"},"cell_type":"markdown","source":"# PRE PROCESSING\n"},{"metadata":{"trusted":true,"_uuid":"e8c891c225ae0fe478e49dde80ab99bc5411bc00"},"cell_type":"code","source":"#As all the features from V1 to V28 are already normalized, so only normalizing the Amount\ndf['normalized_amount']=StandardScaler().fit_transform(df['Amount'].values.reshape(-1,1))\n# Dropping the actual Amount column from the dataset.\ndf=df.drop(['Amount'],axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66d5bf753c222f5cf44b4c3513bab1e678964767"},"cell_type":"code","source":"#  the dataset for changed column\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b26da07ab53feb6660decc27c78b0a0f057f928"},"cell_type":"code","source":"#Assigning x and y\nX = df.iloc[:,:-1]\ny = df['Class']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ebb82392c9c7355ea1f7009a71d619117a1330c"},"cell_type":"markdown","source":"## Splitting data into Train and Test set"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"f5232fd9bbe165c827585b316206757923e96724"},"cell_type":"code","source":"\n# splitting the data into 70% of the data into training set and 30% of the data into test set.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n\nprint(\"Size of training set: \", X_train.shape)\nprint(\"Size of training set: \", X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c486bd82bacdea049cb637e3366a87f1378d2c2"},"cell_type":"code","source":"frauds = df.loc[df['Class'] == 1]\nnon_frauds = df.loc[df['Class'] == 0]\nprint( len(frauds), \"fraud data points and\", len(non_frauds), \"non-fraud data points.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9384b6f710d29dae1cb6efcdb718429b03d5286f"},"cell_type":"code","source":"print(\"original data\")\nprint(pd.value_counts(pd.Series(y_train)))\n\nsns.set(style=\"darkgrid\")\nsns.countplot(y_train,label = \"Count\",palette=\"Set2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20196e2854f0c7e66bde20041ca0ba6948da3f76"},"cell_type":"markdown","source":"## BALANCING THE DATASET"},{"metadata":{"trusted":true,"_uuid":"6533c58770cf1e33a6fa84aca52d965ab4604d02","scrolled":false},"cell_type":"code","source":"#Synthetic Minority oversampling technique \n#define resampling method\nmethod=SMOTE(kind='regular')\n#applying resampling to train data \nX_resampled,y_resampled=method.fit_sample(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ecc3ba44abe6175a01c16cfd09a533a710f42f7"},"cell_type":"code","source":"#after resampling\nprint(\"after resampling\")\nprint(pd.value_counts(pd.Series(y_resampled)))\n\nsns.set(style=\"darkgrid\")\nsns.countplot(y_resampled,label = \"Count\",palette=\"Set2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac0c1c32c8fbff7a4b15c4cc1bbb7568c35f2103"},"cell_type":"markdown","source":"# Deep Neural Network"},{"metadata":{"trusted":true,"_uuid":"bc8d1a1e3375ed4b1458b87690dfb3df84a21235","scrolled":true},"cell_type":"code","source":"model = Sequential()\n#First Layer\nmodel.add(Dense(16, input_dim=30, activation='relu')) \n#second Layer\nmodel.add(Dense(20,activation='relu'))\n#third Layer\nmodel.add(Dense(10,activation='relu'))\n#fourth Layer\nmodel.add(Dense(1, activation='sigmoid'))   \nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"25812f7967518c8850923ddaf9cb200acec1aa1e"},"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(X_train,y_train,batch_size=15, epochs=5)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8581b44b4b6ef5b11b1d3c543aab371e2cc139c","scrolled":true},"cell_type":"code","source":"print(\"Loss: \", model.evaluate(X_test, y_test, verbose=0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f616236633f420f6deb491dba10ebdedadbda487"},"cell_type":"code","source":"y_predicted= model.predict(X_test)\ny_expected=pd.DataFrame(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ed67cdb07a3ef69b5101c3d94a0401dfdf3eeae"},"cell_type":"markdown","source":"# CONFUSION MATRIX"},{"metadata":{"_uuid":"b41249ba7aac212c56b702198083982e50d4c1e9"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"12226a538829cb332608b787f0f9fcaada8534c2"},"cell_type":"markdown","source":"## Defining the confusion matrix\n"},{"metadata":{"trusted":true,"_uuid":"61e5c63f3895b97f529e9717225405f54e96cd25"},"cell_type":"code","source":"#Defining the confusion matrix\n\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5bde33fb8852392e3c00871168268c8fdc9688a1"},"cell_type":"code","source":"#Confusion matrix of our Test set\nc_mat=confusion_matrix(y_expected,y_predicted.round())\nplot_confusion_matrix(c_mat,classes=[0,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10bdccdbe174d69630104bcf5147ba2745783f57"},"cell_type":"markdown","source":"## ACCURACY"},{"metadata":{"trusted":true,"_uuid":"9ad6bc6d4611265084d6c0a961ac3421a9aada0d"},"cell_type":"code","source":"\nacurracy = 0\nfor i in range(2):\n    acurracy += c_mat[i][i]\nprint(acurracy/len(y_test))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ff150c30e0d38e3b9549969ceab94c8edc013ef"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}