{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport plotly.graph_objects as go\nimport seaborn as sns\nimport plotly.express as px\n\n# Load libraries\n\nfrom pandas.plotting import scatter_matrix\nfrom matplotlib import pyplot\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn import  linear_model\nfrom sklearn.model_selection import KFold\n\nfrom plotly.offline import init_notebook_mode, plot, iplot\nimport plotly as py\ninit_notebook_mode(connected=True) \nimport plotly.graph_objs as go # plotly graphical object\n\n\n\n\n\n\n\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\ndatabase = pd.read_csv(\"../input/earthquake-database/database.csv\",encoding='ISO-8859-1')\nprint(database)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.DataFrame(database)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Date']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[(df['Magnitude']>5) & (df['Date'])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sort_values('Magnitude', axis = 0, ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('Date').size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Date'] = df['Date'].astype(str)\ndf.groupby('Date').size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Magnitude'].mode()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Magnitude'].std()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.cov()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.plot(x='Date', y='Magnitude', style='-')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Korelasyon Gösterim\nimport seaborn as sns\ncorr = df.corr()\nsns.heatmap(corr, \n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum().sum()\n#Toplam kaç hücrede eksik değer (NaN ya da None) var?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Özniteliklerin değer almadığı kaç satır var?\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Eksik değer tablosu\ndef eksik_deger_tablosu(df): \n    eksik_deger = df.isnull().sum()\n    eksik_deger_yuzde = 100 * df.isnull().sum()/len(df)\n    eksik_deger_tablo = pd.concat([eksik_deger, eksik_deger_yuzde], axis=1)\n    eksik_deger_tablo_son = eksik_deger_tablo.rename(\n    columns = {0 : 'Eksik Değerler', 1 : '% Değeri'})\n    return eksik_deger_tablo_son\n  \neksik_deger_tablosu(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%70 üzerinde null değer içeren kolonları sil\ntr = len(df) * .3\ndf.dropna(thresh = tr, axis = 1, inplace = True)\n\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Apply fonksiyonu kullanarak büyüklüğü 6 dan yüksek depremleri yeni öznitelik olarak ekle\ndef deprem_durumu(Magnitude):\n    return (Magnitude >= 6.0)\n\ndf['Greater than 6'] = df['Magnitude'].apply(deprem_durumu)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#6 dan büyük müdür? veri bilgisini 0 ve 1lere çevirdik.\n\nfrom sklearn import preprocessing\nlabel_encoder = preprocessing.LabelEncoder() \ndf['Greater than 6_Encoded']= label_encoder.fit_transform(df['Greater than 6'])\n\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Magnitude özniteliğini ölçeklendirmek istiyoruz\nx = df[['Magnitude']].values.astype(float)\n\n#Ölçeklendirme için MinMaxScaler fonksiyonunu kullanıyoruz.\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\ndf['Magnitude2'] = pd.DataFrame(x_scaled)\n\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Quartile (Kartiller) ve IQR ile Aykırı Değer Tespiti\n\nimport seaborn as sns\nsns.boxplot(x=df['Magnitude'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Q1 = df.Magnitude.quantile(0.25)\nQ2 = df.Magnitude.quantile(0.5)\nQ3 = df.Magnitude.quantile(0.75)\nQ4 = df.Magnitude.quantile(1)\nIQR = Q3 - Q1\n\nprint(\"Q1-->\", Q1)\nprint(\"Q3-->\", Q3)\nprint(\"Q2-->\", Q2)\nprint(\"Q4-->\", Q4)\nprint(\"IQR-->\", IQR)\nprint(\"Alt sınır: Q1 - 1.5 * IQR--->\", Q1 - 1.5 * IQR)\nprint(\"Üst sınır: Q3 + 1.5 * IQR--->\", Q3 + 1.5 * IQR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[['Date', 'Time', 'Latitude', 'Longitude', 'Depth', 'Magnitude']]\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from mpl_toolkits.basemap import Basemap\n\nm = Basemap(projection='mill',llcrnrlat=-80,urcrnrlat=80, llcrnrlon=-180,urcrnrlon=180,lat_ts=20,resolution='c')\n\nlongitudes = df[\"Longitude\"].tolist()\nlatitudes = df[\"Latitude\"].tolist()\n#m = Basemap(width=12000000,height=9000000,projection='lcc',\n            #resolution=None,lat_1=80.,lat_2=55,lat_0=80,lon_0=-107.)\nx,y = m(longitudes,latitudes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,10))\nplt.title(\"All affected areas\")\nm.plot(x, y, \"o\", markersize = 2, color = 'blue')\nm.drawcoastlines()\nm.fillcontinents(color='coral',lake_color='aqua')\nm.drawmapboundary()\nm.drawcountries()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\n\n# Extract year for filtering purpose\nyear = []\nfor index, row in df.iterrows():\n    try:\n        date = row['Date']\n        date_time_obj = datetime.datetime.strptime(date, '%m/%d/%Y')\n        y = date_time_obj.date().year\n        year.append(y)\n    except:\n        year.append(-1)\nprint (year[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#'Year' adında yeni öznitelik ekledik\ndf.insert(loc=1, column='Year', value=year)\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#yıllara göre deprem sıklığını gösteren grafik\n\ndf.Year.value_counts().plot(kind = \"bar\" , color = \"red\" , figsize = (30,10),fontsize = 20)\nplt.xlabel(\"Year\",fontsize=18,color=\"blue\")\nplt.ylabel(\"Frequency\",fontsize=18,color=\"blue\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#en yüksek  şiddetli depremin bilgileri\n\nfiltre=df.Magnitude==df.Magnitude.max()\ndf[filtre]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#derinliği en çok olan depremin bilgileri\nfiltre=df.Depth==df.Depth.max()\ndf[filtre]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#derinliği en az olan depremin bilgileri\nfiltre=df.Depth==df.Depth.min()\ndf[filtre]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#şiddeti en yüksek olan depremin yılı zamanı ve bölge bilgisi.\ndf = df[['Date', 'Time', 'Latitude', 'Longitude', 'Magnitude']]\nfiltre=df.Magnitude==df.Magnitude.max()\ndf[filtre]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# en şiddetli deprem hangi bölgede yaşanmıştır?\ndf = df[['Latitude', 'Longitude', 'Magnitude']]\nfiltre=df.Magnitude==df.Magnitude.max()\ndf[filtre]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dünya haritasında görselleştirme\nfrom mpl_toolkits.basemap import Basemap\n\nm = Basemap(projection='mill',llcrnrlat=-80,urcrnrlat=80, llcrnrlon=-180,urcrnrlon=180,lat_ts=20,resolution='c')\n\nlongitudes = df[\"Longitude\"].tolist()\nlatitudes = df[\"Latitude\"].tolist()\n#m = Basemap(width=12000000,height=9000000,projection='lcc',\n            #resolution=None,lat_1=80.,lat_2=55,lat_0=80,lon_0=-107.)\nx,y = m(longitudes,latitudes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,10))\nplt.title(\"Etkilenen Tüm Alanlar\")\nm.plot(x, y, \"o\", markersize = 2, color = 'blue')\nm.drawcoastlines()\nm.fillcontinents(color='coral',lake_color='aqua')\nm.drawmapboundary()\nm.drawcountries()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"latitude_list=[]\nlongitude_list=[]\nfor row in df.Latitude:\n     latitude_list.append(row)\nfor row in df.Longitude:\n    longitude_list.append(row)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from mpl_toolkits.basemap import Basemap\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"earthquake_map = Basemap(projection='robin', lat_0=-90,lon_0=130,resolution='c', area_thresh=1000.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"earthquake_map.drawcoastlines()\nearthquake_map.drawcountries()\nearthquake_map.drawmapboundary()\nearthquake_map.bluemarble()\nearthquake_map.drawstates()\nearthquake_map.drawmeridians(np.arange(0, 360, 30))\nearthquake_map.drawparallels(np.arange(-90, 90, 30))\n\nx,y = earthquake_map(longitude_list, latitude_list)\nearthquake_map.plot(x, y, 'ro', markersize=1)\nplt.title(\"1965 - 2016 yılları arasında EarthQuakes, Rock Bursts & Nükleer Patlamaların gerçekleştiği yerler\")\n \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(df['Magnitude'])\nplt.xlabel(' Deprem Şiddeti')\nplt.ylabel('Oluşum Sayısı')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom mpl_toolkits.basemap import Basemap \n#import matplotlib.pyplot as plt\nimport numpy as np\nimport string\nimport matplotlib.cm as cm\n\nareas = [\n    { 'label': 'İtalya',\n      'llcrnrlat': 35.57580,\n      'llcrnrlon': 6.67969,\n      'urcrnrlat': 47.55336,\n      'urcrnrlon': 19.33594},\n    { 'label': 'Yunanistan',\n      'llcrnrlat': 33.62262,\n      'llcrnrlon': 18.01758,\n      'urcrnrlat': 42.33317,\n      'urcrnrlon': 29.17969},\n    { 'label': 'Japonya',\n      'llcrnrlat': 29.65822,\n      'llcrnrlon': 127.79297,\n      'urcrnrlat': 46.41419,\n      'urcrnrlon': 151.08398},\n    { 'label': 'Güneydoğu Asya',\n      'llcrnrlat': -11.90095,\n      'llcrnrlon': 92.02148,\n      'urcrnrlat': 19.02967,\n      'urcrnrlon': 130.51758},\n]\n\nfig = plt.figure()\nfig.set_figheight(15)\nfig.set_figwidth(15)\n\nfor i, a in enumerate(areas):\n    print(i, a)\n    ax = fig.add_subplot(100*len(areas) + 20 + i+1)\n    m = Basemap(projection='cyl',\n                llcrnrlat=a['llcrnrlat'],\n                llcrnrlon=a['llcrnrlon'],\n                urcrnrlat=a['urcrnrlat'],\n                urcrnrlon=a['urcrnrlon'],\n                resolution='l')\n    m.drawcountries()\n    m.drawcoastlines()\n    m.shadedrelief()\n\n    m.scatter(df['Longitude'].values\n              ,df['Latitude'].values\n              ,s=df['Magnitude'].values*1\n              ,marker=\"o\"\n              ,cmap=cm.seismic\n              ,alpha=.5\n              ,latlon=True)\n\n    plt.title(\"%s Bölgesinde ki Sismik Olaylar\" % a['label'])\n#plt.tight_layout()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df['Magnitude'] > 8, 'Sınıf'] = 'İyi'\ndf.loc[ (df['Magnitude'] >= 7) & (df['Magnitude'] < 7.9), 'Sınıf'] = 'Önemli'\ndf.loc[ (df['Magnitude'] >= 6) & (df['Magnitude'] < 6.9), 'Sınıf'] = 'Güçlü'\ndf.loc[ (df['Magnitude'] >= 5.5) & (df['Magnitude'] < 5.9), 'Sınıf'] = 'Ilımlı'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Magnitude Class distribution\n\nsns.countplot(x=\"Sınıf\", data=df)\nplt.ylabel('Sıklık')\nplt.title('Büyüklük Sınıfı VS Sıklık')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.DataFrame(database)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\n\n# Extract year for filtering purpose\nyear = []\nfor index, row in df.iterrows():\n    try:\n        date = row['Date']\n        date_time_obj = datetime.datetime.strptime(date, '%m/%d/%Y')\n        y = date_time_obj.date().year\n        year.append(y)\n    except:\n        year.append(-1)\nprint (year[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#'Year' adında yeni öznitelik ekledik\ndf.insert(loc=1, column='Year', value=year)\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\ndf['date']=df['Date'].apply(lambda x: pd.to_datetime(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['year']=df['date'].apply(lambda x:str(x).split('-')[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25,8))\nsns.set(font_scale=1.0)\nsns.countplot(x=\"year\",data=df)\nplt.ylabel('Deprem Sayısı')\nplt.xlabel('Her Yıl Meydana Gelen Deprem Sayısı')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom mpl_toolkits.basemap import Basemap\nimport matplotlib.animation as animation\nfrom IPython.display import HTML\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Year']= df['Date'].str[6:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10, 10))\nfig.text(.8, .3, 'Soumitra', ha='right')\ncmap = plt.get_cmap('coolwarm')\n\nm = Basemap(projection='mill',llcrnrlat=-80,urcrnrlat=80, llcrnrlon=-180,urcrnrlon=180,lat_ts=20,resolution='c')\nm.drawcoastlines()\nm.drawcountries()\nm.fillcontinents(color='burlywood',lake_color='lightblue', zorder = 1)\nm.drawmapboundary(fill_color='lightblue')\n\n\nSTART_YEAR = 1965\nLAST_YEAR = 2016\n\npoints = df[['Date', 'Time', 'Latitude', 'Longitude', 'Depth', 'Magnitude']][df['Year']==str(START_YEAR)]\n\nx, y= m(list(points['Longitude']), list(points['Latitude']))\nscat = m.scatter(x, y, s = points['Magnitude']*points['Depth']*0.3, marker='o', alpha=0.3, zorder=10, cmap = cmap)\nyear_text = plt.text(-170, 80, str(START_YEAR),fontsize=15)\nplt.title(\"Earthquake visualisation (1965 - 2016)\")\nplt.close()\n\n\ndef update(frame_number):\n    current_year = START_YEAR + (frame_number % (LAST_YEAR - START_YEAR + 1))\n    year_text.set_text(str(current_year))\n    points = df[['Date', 'Time', 'Latitude', 'Longitude', 'Depth', 'Magnitude']][df['Year']==str(current_year)]\n    x, y= m(list(points['Longitude']), list(points['Latitude']))\n    color = points['Depth']*points['Magnitude'];\n    scat.set_offsets(np.dstack((x, y)))\n    scat.set_sizes(points['Magnitude']*points['Depth']*0.3)\n    \nani = animation.FuncAnimation(fig, update, interval=750, frames=LAST_YEAR - START_YEAR + 1)\nani.save('animation.gif', writer='imagemagick', fps=5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/earthquake-database/database.csv\")\ndf = df.drop([3378,7512,20650])\ndf[\"year\"]= [int(each.split(\"/\")[2]) for each in df.iloc[:,0]]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Type.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.loc[:,[\"Date\",\"Latitude\",\"Longitude\",\"Type\",\"Depth\",\"Magnitude\",\"year\"]]\nyears = [str(each) for each in list(df.year.unique())]  # str unique years\n# make list of types\ntypes = ['Earthquake', 'Nuclear Explosion', 'Explosion', 'Rock Burst']\ncustom_colors = {\n    'Earthquake': 'rgb(189, 2, 21)',\n    'Nuclear Explosion': 'rgb(52, 7, 250)',\n    'Explosion': 'rgb(99, 110, 250)',\n    'Rock Burst': 'rgb(0, 0, 0)'\n}\n# make figure\nfigure = {\n    'data': [],\n    'layout': {},\n    'frames': []\n}\n\nfigure['layout']['geo'] = dict(showframe=False, showland=True, showcoastlines=True, showcountries=True,\n               countrywidth=1, \n              landcolor = 'rgb(217, 217, 217)',\n              subunitwidth=1,\n              showlakes = True,\n              lakecolor = 'rgb(255, 255, 255)',\n              countrycolor=\"rgb(5, 5, 5)\")\nfigure['layout']['hovermode'] = 'closest'\nfigure['layout']['sliders'] = {\n    'args': [\n        'transition', {\n            'duration': 400,\n            'easing': 'cubic-in-out'\n        }\n    ],\n    'initialValue': '1965',\n    'plotlycommand': 'animate',\n    'values': years,\n    'visible': True\n}\nfigure['layout']['updatemenus'] = [\n    {\n        'buttons': [\n            {\n                'args': [None, {'frame': {'duration': 500, 'redraw': False},\n                         'fromcurrent': True, 'transition': {'duration': 300, 'easing': 'quadratic-in-out'}}],\n                'label': 'Play',\n                'method': 'animate'\n            },\n            {\n                'args': [[None], {'frame': {'duration': 0, 'redraw': False}, 'mode': 'immediate',\n                'transition': {'duration': 0}}],\n                'label': 'Pause',\n                'method': 'animate'\n            }\n        ],\n        'direction': 'left',\n        'pad': {'r': 10, 't': 87},\n        'showactive': False,\n        'type': 'buttons',\n        'x': 0.1,\n        'xanchor': 'right',\n        'y': 0,\n        'yanchor': 'top'\n    }\n]\n\nsliders_dict = {\n    'active': 0,\n    'yanchor': 'top',\n    'xanchor': 'left',\n    'currentvalue': {\n        'font': {'size': 20},\n        'prefix': 'Year:',\n        'visible': True,\n        'xanchor': 'right'\n    },\n    'transition': {'duration': 300, 'easing': 'cubic-in-out'},\n    'pad': {'b': 10, 't': 50},\n    'len': 0.9,\n    'x': 0.1,\n    'y': 0,\n    'steps': []\n}\n\n# make data\nyear = 1695\nfor ty in types:\n    dataset_by_year = df[df['year'] == year]\n    dataset_by_year_and_cont = dataset_by_year[dataset_by_year['Type'] == ty]\n    \n    data_dict = dict(\n    type='scattergeo',\n    lon = df['Longitude'],\n    lat = df['Latitude'],\n    hoverinfo = 'text',\n    text = ty,\n    mode = 'markers',\n    marker=dict(\n        sizemode = 'area',\n        sizeref = 1,\n        size= 10 ,\n        line = dict(width=1,color = \"white\"),\n        color = custom_colors[ty],\n        opacity = 0.7),\n)\n    figure['data'].append(data_dict)\n    \n# make frames\nfor year in years:\n    frame = {'data': [], 'name': str(year)}\n    for ty in types:\n        dataset_by_year = df[df['year'] == int(year)]\n        dataset_by_year_and_cont = dataset_by_year[dataset_by_year['Type'] == ty]\n\n        data_dict = dict(\n                type='scattergeo',\n                lon = dataset_by_year_and_cont['Longitude'],\n                lat = dataset_by_year_and_cont['Latitude'],\n                hoverinfo = 'text',\n                text = ty,\n                mode = 'markers',\n                marker=dict(\n                    sizemode = 'area',\n                    sizeref = 1,\n                    size= 10 ,\n                    line = dict(width=1,color = \"white\"),\n                    color = custom_colors[ty],\n                    opacity = 0.7),\n                name = ty\n            )\n        frame['data'].append(data_dict)\n\n    figure['frames'].append(frame)\n    slider_step = {'args': [\n        [year],\n        {'frame': {'duration': 300, 'redraw': False},\n         'mode': 'immediate',\n       'transition': {'duration': 300}}\n     ],\n     'label': year,\n     'method': 'animate'}\n    sliders_dict['steps'].append(slider_step)\n\n\nfigure[\"layout\"][\"autosize\"]= True\nfigure[\"layout\"][\"title\"] = \"Earthquake\"       \n\nfigure['layout']['sliders'] = [sliders_dict]\n\niplot(figure)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Year']= df['Date'].str[6:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10, 10))\nfig.text(.8, .3, 'Soumitra', ha='right')\ncmap = plt.get_cmap('coolwarm')\n\nm = Basemap(projection='mill',llcrnrlat=-80,urcrnrlat=80, llcrnrlon=-180,urcrnrlon=180,lat_ts=20,resolution='c')\nm.drawcoastlines()\nm.drawcountries()\nm.fillcontinents(color='burlywood',lake_color='lightblue', zorder = 1)\nm.drawmapboundary(fill_color='lightblue')\n\n\nSTART_YEAR = 1965\nLAST_YEAR = 2016\n\npoints = df[['Date',  'Latitude', 'Longitude', 'Depth', 'Magnitude']][df['Year']==str(START_YEAR)]\n\nx, y= m(list(points['Longitude']), list(points['Latitude']))\nscat = m.scatter(x, y, s = points['Magnitude']*points['Depth']*0.3, marker='o', alpha=0.3, zorder=10, cmap = cmap)\nyear_text = plt.text(-170, 80, str(START_YEAR),fontsize=15)\nplt.title(\"Earthquake visualisation (1965 - 2016)\")\nplt.close()\n\n\ndef update(frame_number):\n    current_year = START_YEAR + (frame_number % (LAST_YEAR - START_YEAR + 1))\n    year_text.set_text(str(current_year))\n    points = df[['Date',  'Latitude', 'Longitude', 'Depth', 'Magnitude']][df['Year']==str(current_year)]\n    x, y= m(list(points['Longitude']), list(points['Latitude']))\n    color = points['Depth']*points['Magnitude'];\n    scat.set_offsets(np.dstack((x, y)))\n    scat.set_sizes(points['Magnitude']*points['Depth']*0.3)\n    \nani = animation.FuncAnimation(fig, update, interval=750, frames=LAST_YEAR - START_YEAR + 1)\nani.save('animation.gif', writer='imagemagick', fps=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import io\nimport base64\n\nfilename = 'animation.gif'\n\nvideo = io.open(filename, 'r+b').read()\nencoded = base64.b64encode(video)\nHTML(data='''<img src=\"data:image/gif;base64,{0}\" type=\"gif\" />'''.format(encoded.decode('ascii')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sınıf özniteliği altında Magnitude gruplandırıldı."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df['Magnitude'] > 8, 'Sınıf'] = 'İyi'\ndf.loc[ (df['Magnitude'] >= 7) & (df['Magnitude'] < 7.9), 'Sınıf'] = 'Önemli'\ndf.loc[ (df['Magnitude'] >= 6) & (df['Magnitude'] < 6.9), 'Sınıf'] = 'Güçlü'\ndf.loc[ (df['Magnitude'] >= 5.5) & (df['Magnitude'] < 5.9), 'Sınıf'] = 'Ilımlı'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(how=\"any\",inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df =df.drop(columns ='year')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Veriler model seçiminde  sorun çıkardığı için, sayısal değerlere çevirildi."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn import preprocessing\nlabel_encoder = preprocessing.LabelEncoder() \ndf['Latitude_Encoded']= label_encoder.fit_transform(df['Latitude'])\ndf['Longitude_Encoded']= label_encoder.fit_transform(df['Longitude'])\ndf['Depth_Encoded']= label_encoder.fit_transform(df['Depth'])\ndf['Magnitude_Encoded']= label_encoder.fit_transform(df['Magnitude'])\ndf['Year_Encoded']= label_encoder.fit_transform(df['Year'])\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model seçiliminde string veriler sorun oluşturduğu için ve Encoded edilen değerler kullanılacağın için string veriler kaldırıldı."},{"metadata":{"trusted":true},"cell_type":"code","source":"df =df.drop(columns ='Date')\ndf =df.drop(columns ='Latitude')\ndf =df.drop(columns ='Longitude')\ndf =df.drop(columns ='Type')\ndf =df.drop(columns ='Depth')\ndf =df.drop(columns ='Magnitude')\ndf =df.drop(columns ='Year')\n\n\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Veri seti, eğitim verisi 0.80 ve test verisi 0.20 olarak ayrıldı."},{"metadata":{"trusted":true},"cell_type":"code","source":"array = df.values\nX = array[:,1:6]\ny = array[:,0:1]\nX_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=0.20, random_state=1)\n\nprint(\"Dataframe boyutu: \",df.shape)\nprint(\"Eğitim verisi boyutu: \",X_train.shape, Y_train.shape)\nprint(\"Test verisi boyutu: \",X_validation.shape, Y_validation.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nfrom sklearn import utils\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Modelleri değerlendirmek için doğruluk  metriğini kullanıldı.\nŞimdi, doğrulama setimizde modelin doğruluğu hakkında bir fikir edinmek istiyoruz.Bu bize en iyi modelin doğruluğu konusunda bağımsız bir son kontrol verecektir.\nModelleri tüm eğitim veri kümesine sığdırıp, doğrulama veri kümesiyle ilgili tahminlerde bulunuldu.\nTahminler, doğrulama kümesinde beklenen sonuçlarla karşılaştırarak değerlendirildi, ardından sınıflandırma doğruluğu, karışıklık matrisi ve sınıflandırma raporu hesaplandı.\n\nModeller arasında en başarılı sonuç :\n\nGaussian NB  ve DecisionTree den alındı.\n\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\n#Decision Trees\ncellTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\nprint(cellTree) # it shows the default parameters\n  #I fit the data with the training\ncellTree.fit(X_train,Y_train)\n  #now predictions\nyhat_dt = cellTree.predict(X_validation)\n\n  #Accuracy evaluation\nacc = metrics.accuracy_score(Y_validation, yhat_dt)\nprint('karar agaci icin accuracy: ',acc)\n\n#karar agaci icin confusion matrix ve metrik degerler\ncellTree_dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\n#train model with cv of 10 burda modeli 10 cross validasyon ile scorelari verdik\ncv_scores_dt = cross_val_score(cellTree_dt, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores_dt)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores_dt)))\nfrom sklearn.metrics import classification_report\nprec_dt = classification_report(yhat_dt,Y_validation)\nprint(prec_dt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#call the models\nfrom sklearn.neighbors import KNeighborsClassifier\nknn_model = KNeighborsClassifier(n_neighbors = 3)\n# fit the models\nneigh = knn_model.fit(X_train,Y_train)\n#predict the mode;\nyhatknn=neigh.predict(X_validation)\n\n  #Accuracy evaluation\naccknn = metrics.accuracy_score(Y_validation, yhatknn)\nprint('en yakin komsular icin accuracy',accknn)\n\n#knn=3 icin confusion matrix ve metrik degerler\nknn_knn = KNeighborsClassifier(n_neighbors = 3)\n#train model with cv of 10 burda modeli 10 cross validasyon ile scorelari verdik\ncv_scores_knn = cross_val_score(knn_knn, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores_knn)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores_knn)))\n\n#knn scores\nfrom sklearn.metrics import classification_report\nprec_knn = classification_report(yhatknn,Y_validation)\nprint(prec_knn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lojistik regresyon\nfrom sklearn.linear_model import LogisticRegression\nLR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,Y_train)\nLR\n#predict\nyhatlr = LR.predict(X_validation)\n#print('yhat', yhat)\n  #Accuracy evaluation\nacclr = metrics.accuracy_score(Y_validation, yhatlr)\nprint('lojistik regresyon icin accuracy',acclr)\n\n\n#lojistik regresyon icin confusion matrix ve metrik degerler\nlr_lr = LogisticRegression(C=0.01, solver='liblinear')\n#train model with cv of 10 burda modeli 10 cross validasyon ile scorelari verdik\ncv_scores_lr = cross_val_score(lr_lr, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores_lr)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores_lr)))\n\n\nfrom sklearn.metrics import classification_report\nprec_lr = classification_report(yhatlr,Y_validation)\nprint(prec_lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#SVM \nfrom sklearn import svm\nclf = svm.SVC(kernel='rbf')\nclf.fit(X_train, Y_train) \n#predict\nyhatsvm = clf.predict(X_validation)\n#yhat [0:5]\naccsvm = metrics.accuracy_score(Y_validation, yhatsvm)\nprint('svm icin accuracy',accsvm)\n\n\n\n#svm icin confusion matrix ve metrik degerler\nclf_svm = svm.SVC(kernel='rbf')\n#train model with cv of 10 burda modeli 10 cross validasyon ile scorelari verdik\ncv_scores_svm = cross_val_score(clf_svm, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores_svm)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores_svm)))\n\n\nfrom sklearn.metrics import classification_report\nprec_svm = classification_report(yhatsvm,Y_validation)\nprint(prec_svm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gaussian NB \n# Gaussian Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\n#call the models\ngnb = GaussianNB()\n  #fit the model\ngnb.fit(X_train, Y_train) \n  #predict\nyhatgnb = gnb.predict(X_validation)\naccgnb = metrics.accuracy_score(Y_validation, yhatgnb)\nprint('gaussian naive bayes icin accuracy',accgnb)\n\n\n#gaussian naive bayes icin confusion matrix ve metrik degerler\nclf_gnb = GaussianNB()\n#train model with cv of 10 burda modeli 10 cross validasyon ile scorelari verdik\ncv_scores_gnb = cross_val_score(clf_gnb, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores_gnb)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores_gnb)))\n\n#klasifikasyon tablosu\nfrom sklearn.metrics import classification_report\nprec_gnb = classification_report(yhatgnb,Y_validation)\nprint(prec_gnb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#linear discriminant analysis \nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nlda = LinearDiscriminantAnalysis()\n#fit the model\nlda.fit(X_train, Y_train) \n#predict\nyhatlda = lda.predict(X_validation)\nacclda = metrics.accuracy_score(Y_validation, yhatlda)\nprint('linear discriminant analiz icin accuracy',acclda)\n\n\n\n\n#linear discrimant icin confusion matrix ve metrik degerler\nclf_ld = LinearDiscriminantAnalysis()\n#train model with cv of 10 burda modeli 10 cross validasyon ile scorelari verdik\ncv_scores_ld = cross_val_score(clf_ld, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores_ld)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores_ld)))\n\n#klasifikasyon linear diskrimannt\nfrom sklearn.metrics import classification_report\nprec_lda = classification_report(yhatlda,Y_validation)\nprint(prec_lda)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nrfc = RandomForestClassifier(max_depth=5, n_estimators=100, max_features='auto')\nrfc.fit(X_train, Y_train) \n#predict\nyhat1 = rfc.predict(X_validation)\n#yhat [0:5]\n#evaluate\n\n#create a new SVM model\nrfc_cv = RandomForestClassifier(max_depth=5, n_estimators=100, max_features='auto')\n#train model with cv of 10\ncv_scores = cross_val_score(rfc_cv, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores)))\n\n\n\n\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools\nfrom sklearn.metrics import f1_score\nprint('f1_score for Random Forest Classifier:',f1_score(Y_validation, yhat1, average='weighted'))\n#print(\"Train set Accuracy for Random Forest Classifier: \", metrics.accuracy_score(Y_validation, rfc.predict(X_train)))\n#print(\"Test set Accuracy for Random Forest Classifier: \", metrics.accuracy_score(Y_validation, yhat1))\nfrom sklearn.metrics import classification_report\nprec_rec = classification_report(yhat1,Y_validation)\nprint(prec_rec)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}