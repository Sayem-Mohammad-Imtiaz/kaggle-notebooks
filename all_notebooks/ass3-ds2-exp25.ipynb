{"cells":[{"metadata":{"_uuid":"ca25a2f95f0fc9498b9b2e3a9d96607fbb682015"},"cell_type":"markdown","source":"# broken-machine challange - quite challangeable"},{"metadata":{},"cell_type":"markdown","source":"References:\n\nhttps://www.geeksforgeeks.org/using-learning-curves-ml/\n\nhttps://datascience.stackexchange.com/questions/26918/validation-curve-unlike-sklearn-sample\n\nhttps://gist.github.com/otaviomguerra/51df7a4cff28f92de7105f12a0724115\n\nhttps://datatofish.com/k-means-clustering-python/\n\nhttps://stackoverflow.com/questions/28663856/how-to-count-the-occurrence-of-certain-item-in-an-ndarray\n\nhttps://www.kaggle.com/ellecf/visualizing-multidimensional-clusters\n\nhttps://community.greatlearning.in/t/while-using-pairplot-using-seaborn-package-i-am-getting-error-as-selected-kde-bandwidth-is-0-cannot-estiamte-density-can-someone-please-help-on-this/158/7\n\nhttps://www.geeksforgeeks.org/python-seaborn-pairgrid-method/\n\nhttps://machinelearningmastery.com/expectation-maximization-em-algorithm/\n\nhttps://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n\nhttps://www.youtube.com/watch?v=85XaciPBCkw "},{"metadata":{"_uuid":"2776978fa169449d5bf3c8f036668afe10a47502"},"cell_type":"markdown","source":"# Broken Machine dataset is used with following main steps:\n* Fill missing values with mode\n* Find correlation between features\n* Undersample data set as we've got 900,000 rows of data with almost 70%-30% distribution of labels\n* Use scaling (StandardScaler)\n* Do ramdomizedSearchCV to select initialized parameters\n* Plot learning curves over multiple iterations\n* Plot validation curves over multiple iterations"},{"metadata":{"_uuid":"cc4088625ae2209899d05c70dfd7bcb108cb4c3a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\nimport time\nimport warnings\nwarnings.simplefilter(action = 'ignore', category = FutureWarning)\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import validation_curve\nfrom scipy.stats import randint\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import classification_report, confusion_matrix\n# !pip install pydotplus\n# import pydotplus\nfrom IPython.display import Image\nfrom sklearn.model_selection import learning_curve \nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score, precision_score, recall_score, roc_curve, f1_score, confusion_matrix, accuracy_score\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport lightgbm as lgb\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom joblib import dump, load\nfrom scipy import stats\nfrom scipy.stats import norm, skew #for some statistics\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nfrom sklearn.preprocessing import StandardScaler\n# !pip install --upgrade pip\n# !pip list | grep -i imb\n# !pip uninstall -y imbalanced-learn \n# !pip list | grep -i imb\n!pip install imblearn\n# !pip list | grep -i imb\n# !pip uninstall -y imbalanced-learn \n# !pip list | grep -i imb\nfrom imblearn.under_sampling import NearMiss\nfrom pandas import DataFrame\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.decomposition import PCA\nimport sklearn.metrics as metrics\nfrom sklearn.manifold import TSNE\nfrom sklearn.metrics import homogeneity_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7b1f6a694e8c78d4edff34f27514ceb06f0eb8d","trusted":true},"cell_type":"code","source":"file_path = '../input/the-broken-machine/'\nmodel_path = '../input/the-broken-machine/'\n# file_path = './the-broken-machine/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain = pd.read_csv(file_path + 'xtrain.csv')\nytrain = pd.read_csv(file_path + 'ytrain.csv')\nprint(xtrain.shape)\nprint(ytrain.shape)\nxtrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ytrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ytrain.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"1 ratio isï¼š\",ytrain[ytrain==1].count()/len(ytrain)*100)\n#Then the accuracy is less than 70% is meaningless","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.value_counts(ytrain.values.flatten())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y train percentage 1 %\npd.value_counts(ytrain.values.flatten())[1]/(pd.value_counts(ytrain.values.flatten())[0]+pd.value_counts(ytrain.values.flatten())[1])*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check data\npd.set_option('display.max_columns', None)\nxtrain.describe()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#Check missing data\nall_data_na = (xtrain.isnull().sum() / len(xtrain)) * 100\nall_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\nf, ax = plt.subplots(figsize=(8, 6))\nplt.xticks(rotation='90')\nsns.barplot(x=all_data_na.index, y=all_data_na)\nplt.xlabel('Features', fontsize=15)\nplt.ylabel('Percent of missing values', fontsize=15)\nplt.title('Percent missing data by feature', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#EDA NA processing,lgb doesn't need na processing\nfor col in xtrain.columns:\n    xtrain[col] = xtrain[col].fillna(xtrain[col].mode()[0])#mode\nxtrain.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# EDA skew\nxtrain.skew(axis=0).sort_values(ascending=False)\n#Found 37 numerical anomalies","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain['37'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain['37']=xtrain['37'].apply(lambda x:200 if x>100 else x) #Handling No. 37","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#EDA No. 37\n\ndef check_skewness(col):\n    sns.distplot(xtrain[col] , fit=norm);\n    fig = plt.figure()\n#     res = stats.probplot(xtrain[col], plot=plt) #Probplot cannot be displayed, if it is an integer index, it can be displayed\n    # Get the fitted parameters used by the function\n    (mu, sigma) = norm.fit(xtrain[col])\n    print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n    \ncheck_skewness(['37']) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check unique value\nfor i in xtrain.columns:\n    print(i,\": \",len(xtrain[i].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature distribution\n\nh = .2  # step size in the mesh\n\nx_min, x_max = xtrain.iloc[0:1000, 33].min() - .5, xtrain.iloc[0:1000, 33].max() + .5\ny_min, y_max = xtrain.iloc[0:1000, 36].min() - .5, xtrain.iloc[0:1000, 36].max() + .5\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\n# just plot the dataset first\ncm = plt.cm.RdBu\ncm_bright = ListedColormap(['#FF0000', '#0000FF'])\nax = plt.subplot()\nax.scatter(xtrain.iloc[0:1000, 33], xtrain.iloc[0:1000, 36], c=list(ytrain.iloc[0:1000,0]),cmap=cm_bright,\n           edgecolors='k')\nax.set_xlim(xx.min(), xx.max())\nax.set_ylim(yy.min(), yy.max())\nax.set_xticks(())\nax.set_yticks(())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain['1'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#corelation\ncorrmat = xtrain.corr()\ncorrmat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat[corrmat>0.01].count()\n#No clear corelation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.figure(figsize=(10,10))\n# g = sns.heatmap(train_data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")\n\n# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.check_cv.html#sklearn.model_selection.check_cv\n# from sklearn.model_selection import check_cv\n# cv = check_cv(3, xtrain, ytrain, classifier=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No clear patten for the scattering"},{"metadata":{"trusted":true},"cell_type":"code","source":"xy = xtrain.join(ytrain)\ntrain_sample = xy.sample(n=17000, random_state=0)\npd.value_counts(train_sample['x'].values.flatten())\nX = train_sample.iloc[:, :-1]\ny = train_sample.iloc[:,-1]\n!pip install imblearn -U\nfrom imblearn.under_sampling import NearMiss\nns=NearMiss()\nX_train_ns,y_train_ns=ns.fit_resample(X,y)\nX_train_ns.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.value_counts(y_train_ns.values.flatten())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training part"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold, cross_val_score, train_test_split\nX_balanced, X_test_balanced, y_balanced, y_test_balanced=train_test_split(X_train_ns[0:-1000],y_train_ns[0:-1000], test_size=0.2, random_state=3)\n# gc.collect()  \nprint(X_balanced.shape)\nprint(X_test_balanced.shape)\nprint(y_balanced.shape)\nprint(y_test_balanced.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nss = StandardScaler()\nX_balanced = pd.DataFrame(ss.fit_transform(X_balanced), columns=X_balanced.columns)\nX_test_balanced = pd.DataFrame(ss.transform(X_test_balanced), columns=X_test_balanced.columns)\n# we have now fit and transform the data into a scaler for accurate reading and results.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_balanced.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_balanced","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(X_balanced)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Algos code start here"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components=2,random_state=3)\nprincipalComponents = pca.fit_transform(X_balanced)\nprincipalDf = pd.DataFrame(data = principalComponents\n             , columns = ['principal component 1', 'principal component 2'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_balanced = y_balanced.to_frame()\n# y_balanced=y_balanced.squeeze()\ny_balanced=y_balanced.reset_index(drop=True)\ny_balanced","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finalDf = pd.concat([principalDf, y_balanced], axis = 1)\nfinalDf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=\"principal component 1\",y=\"principal component 2\",hue='x', data=finalDf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.components_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.explained_variance_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.explained_variance_ratio_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" pca.explained_variance_ratio_.cumsum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components=3,random_state=3)\nprincipalComponents = pca.fit_transform(X_balanced)\nprincipalDf = pd.DataFrame(data = principalComponents\n             , columns = ['principal component '+a for a in [str(i) for i in range(1,4)]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finalDf = pd.concat([principalDf, y_balanced], axis = 1)\nfinalDf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# df = pd.read_csv('2016.csv')\n# sns.set(style = \"darkgrid\")\n\nfig = plt.figure(figsize=(10,10))\nax = fig.add_subplot(projection = '3d')\ncolors = (\"red\", \"green\")\ngroups = (1,0) \n\n# X = finalDf['principal component 1']\n# Y = finalDf['principal component 2']\n# Z = finalDf['principal component 3']\n# data=(X,Y,Z)\n\nax.set_xlabel(\"PC1\")\nax.set_ylabel(\"PC2\")\nax.set_zlabel(\"PC3\")\n\n# ax.scatter(x, y, z)\nfor row in finalDf.iterrows():\n    x, y, z = row[1]['principal component 1'],row[1]['principal component 2'],row[1]['principal component 3']\n    if(row[1]['x']==0.0):\n#         print(\"0\")\n        ax.scatter(x, y, z,c=\"red\" )\n    else:\n#         print(\"1\")\n        ax.scatter(x, y, z, c=\"blue\")\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(finalDf, hue='x', vars=['principal component '+a for a in [str(i) for i in range(1,4)]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.components_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.explained_variance_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.explained_variance_ratio_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.explained_variance_ratio_.cumsum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components=4,random_state=3)\nprincipalComponents = pca.fit_transform(X_balanced)\nprincipalDf = pd.DataFrame(data = principalComponents\n             , columns = ['principal component '+a for a in [str(i) for i in range(1,5)]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finalDf = pd.concat([principalDf, y_balanced], axis = 1)\nfinalDf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(finalDf, hue='x', vars=['principal component '+a for a in [str(i) for i in range(1,5)]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.components_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.explained_variance_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.explained_variance_ratio_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.explained_variance_ratio_.cumsum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\nvalues={}\nvalues['x']=[]\nvalues['y']=[]\nfor i in range(1,58):\n    pca = PCA(n_components=i,random_state=3)\n    principalComponents = pca.fit_transform(X_balanced)\n#     print(pca.explained_variance_ratio_.cumsum()[-1])\n    values['x'].append(i)\n    values['y'].append(pca.explained_variance_ratio_.cumsum()[-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(values['x'],values['y'])\nplt.grid()\nplt.show()    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components=10,random_state=3)\nprincipalComponents = pca.fit_transform(X_balanced)\nprincipalDf = pd.DataFrame(data = principalComponents\n             , columns = ['principal component '+a for a in [str(i) for i in range(1,11)]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finalDf = pd.concat([principalDf, y_balanced], axis = 1)\nfinalDf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(finalDf, hue='x', vars=['principal component '+a for a in [str(i) for i in range(1,11)]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.components_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.explained_variance_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.explained_variance_ratio_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.explained_variance_ratio_.cumsum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"['principal component '+a for a in [str(i) for i in range(1,11)]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rmseQueue=[]\nvarQueue=[]\nfrom sklearn.metrics import mean_squared_error\nfor n in range(2,X_balanced.shape[1]+1):\n    pca = PCA(n_components=n, random_state=3)\n    principalComponents = pca.fit_transform(X_balanced)\n    inverse_data = np.linalg.pinv(pca.components_.T)\n    reconstructed_data = principalComponents.dot(inverse_data)\n    rmse = mean_squared_error(X_balanced, reconstructed_data,squared=True)\n#     print(\"PCA components: \"+str(n)+\", RMSE: \"+str(rmse)+ \", PCA eigen values variance: \" +str(pca.explained_variance_ratio_.cumsum()[-1]))\n    print(\"PCA components: {0:2d}, RMSE: {1:0.3f}, PCA eigen values variance: {2:0.3f}\".format(n,rmse,pca.explained_variance_ratio_.cumsum()[-1]))\n    rmseQueue.append(rmse)\n    varQueue.append(pca.explained_variance_ratio_.cumsum()[-1])\n    \nplt.plot(range(2,X_balanced.shape[1]+1), rmseQueue, 'bx-')\nplt.xlabel('PCA components')\nplt.ylabel('RMSE')\n# plt.show()    \nplt.grid()\nplt.show()    \n\nplt.plot(range(2,X_balanced.shape[1]+1), varQueue, 'bx-')\nplt.xlabel('PCA components')\nplt.ylabel('Variance')\n# plt.show()    \nplt.grid()\nplt.show()    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=52,random_state=3)\nprincipalComponents = pca.fit_transform(X_balanced)\nprincipalDf = pd.DataFrame(data = principalComponents\n             , columns = ['principal component '+a for a in [str(i) for i in range(1,principalComponents.shape[1]+1)]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"applying EM"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nimport datetime\n# sScore = []\nhScore = []\naicScore = []\nbicScore = []\nK = range(2,20)\nfor i in K:\n    model=GaussianMixture(n_components=i,random_state=3).fit(principalDf)\n    labels=model.predict(principalDf)\n#     sScore.append(metrics.silhouette_score(X_balanced,labels,random_state=3))\n#     print (\"Silhouette score for EM = \"+str(i)+\" is \" +str(metrics.silhouette_score(X_balanced,labels,random_state=3)))\n    hScore.append(homogeneity_score(y_balanced, labels))\n    aicScore.append(model.aic(principalDf))\n    bicScore.append(model.bic(principalDf))\n#     print(str(i)+\" done.\" + str(datetime.datetime.now()))\n    \n# # Plot\n# plt.plot(K, sScore, 'bx-')\n# plt.xlabel('k')\n# plt.ylabel('silhouette_score')\n# plt.grid()\n# plt.show()     \n\n# Plot\nplt.plot(K, hScore, 'bx-')\nplt.xlabel('k')\nplt.ylabel('homogeneity_score')\nplt.grid()\nplt.show()\n\n\n# Plot\nplt.plot(K, aicScore, color='red',label=\"AIC Score\")\nplt.plot(K, bicScore, color='blue',label=\"BIC Score\")\nplt.xlabel('k')\nplt.ylabel('AIC/BIC')\nplt.grid()\nplt.legend()\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = GaussianMixture(n_components=4, init_params='random', random_state=3)\nmodel.fit(principalDf)\ny_pred_gmm = model.predict(principalDf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = pd.DataFrame(y_pred_gmm)\nm=TSNE(learning_rate=50, random_state=3 )\ntsne_features = m.fit_transform(principalDf)\nprincipalDf['t1']=tsne_features[:,0]\nprincipalDf['t2']=tsne_features[:,1]\n\nfinalDf = pd.concat([principalDf, labels], axis = 1)\nfinalDf = finalDf.rename({0:'labels'},axis=1)\nsns.scatterplot(x=\"t1\",y=\"t2\",hue='labels', data=finalDf)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finalDf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finalDf = pd.concat([principalDf, y_balanced], axis = 1)\n# finalDf = finalDf.rename({0:'labels'},axis=1)\nsns.scatterplot(x=\"t1\",y=\"t2\",hue='x', data=finalDf)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"homogeneity_score(y_balanced, y_pred_gmm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}