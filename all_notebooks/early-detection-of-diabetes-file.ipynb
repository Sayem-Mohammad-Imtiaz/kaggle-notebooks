{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Early Detection of Diabetes ","metadata":{}},{"cell_type":"markdown","source":"Diabetes is a type of chronic disease which is more common among the people of all age groups. \nPredicting this disease at an early stage can help a person to take the necessary actions to either prevent the occurrence of this disease or control the disease. \n\nMachine learning models helps in early detection and the diagnosis needed. Now predicting whether a person had diabetes or not by Data preparation, Data Pre processing, Exploratory Data Analysis, Feature selection techniques and Building models.\n\nTask:\n1. Prepare the data-set\n2. Build a model which can give high accuracy of predicting the disease. \n","metadata":{}},{"cell_type":"markdown","source":"# Task 1:  Preparing the data-set","metadata":{}},{"cell_type":"markdown","source":"Importing the libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom pandas import DataFrame\nfrom pandas.plotting import scatter_matrix\nfrom pandas_profiling import ProfileReport\nimport statsmodels.api\nimport statsmodels.api as smt\nfrom sklearn.feature_selection import SelectKBest, chi2, f_regression\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will now read the data from a CSV file into a Pandas DataFrame","metadata":{}},{"cell_type":"code","source":"dbts= pd.read_csv(\"E:\\\\python\\\\Internship_Exposys\\diabetes_data.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Have a look on data and Data preprocessing ","metadata":{}},{"cell_type":"code","source":"dbts.dtypes","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dbts.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dbts.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dbts.tail()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dbts.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Descriptive Statistics","metadata":{}},{"cell_type":"code","source":"dbts.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Missing value imputation","metadata":{}},{"cell_type":"code","source":"dbts.isnull()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dbts.isnull().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dbts.isnull().nunique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dbts.value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dbts['class'].value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dbts.columns","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dbts.nunique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dbts['Age'].mode()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dbts['Age'].mean()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dbts['Polyuria'].unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dbts['Gender'].unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dbts['Polydipsia'].unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dbts['Age'].unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dbts['muscle stiffness'].unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dbts['Alopecia'].unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dbts['partial paresis'].unique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"age = dbts[dbts['Age'] >= 58]\nage","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"age1 = dbts[dbts['Age'] == 35]\nage1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"age2 = dbts[dbts['Age'] >= 48]\nage2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"age3 = dbts[dbts['Age'] >= 71]\nage3","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"age4 = dbts[dbts['Age'] >= 90]\nage4","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For numerical parameters, fields like mean, standard deviation, percentiles, and maximum have been populated. For categorical features, count, unique, and corresponding frequency have been populated. This gives us a broad idea of our dataset.","metadata":{}},{"cell_type":"code","source":"# converting text in values for better clarity and find the corelation.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dbts['Gender']                 = dbts['Gender'].map({'Male':1,'Female':0})\ndbts['class']                  = dbts['class'].map({'Positive':1,'Negative':0})\ndbts['Polyuria']               = dbts['Polyuria'].map({'Yes':1,'No':0})\ndbts['Polydipsia']             = dbts['Polydipsia'].map({'Yes':1,'No':0})\ndbts['sudden weight loss']     = dbts['sudden weight loss'].map({'Yes':1,'No':0})\ndbts['weakness']               = dbts['weakness'].map({'Yes':1,'No':0})\ndbts['Polyphagia']             = dbts['Polyphagia'].map({'Yes':1,'No':0})\ndbts['Genital thrush']         = dbts['Genital thrush'].map({'Yes':1,'No':0})\ndbts['visual blurring']        = dbts['visual blurring'].map({'Yes':1,'No':0})\ndbts['Itching']                = dbts['Itching'].map({'Yes':1,'No':0})\ndbts['Irritability']           = dbts['Irritability'].map({'Yes':1,'No':0})\ndbts['delayed healing']        = dbts['delayed healing'].map({'Yes':1,'No':0})\ndbts['partial paresis']        = dbts['partial paresis'].map({'Yes':1,'No':0})\ndbts['muscle stiffness']       = dbts['muscle stiffness'].map({'Yes':1,'No':0})\ndbts['Alopecia']               = dbts['Alopecia'].map({'Yes':1,'No':0})\ndbts['Obesity']                = dbts['Obesity'].map({'Yes':1,'No':0})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA: Exploratory Data Analysis is a process of examining or understanding the data and extracting insights or main characteristics of the data. EDA is generally classified into two methods, i.e. graphical analysis and non-graphical analysis.","metadata":{}},{"cell_type":"markdown","source":"Corelation between independent and dependent variables considering independent variables that has high correlation with the dependent variables and less correlation with other variables","metadata":{}},{"cell_type":"code","source":"corelation= dbts.corr()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,20))\nsns.heatmap(corelation, xticklabels = corelation.columns, yticklabels = corelation.columns, annot = True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Graphical Reprsentation:","metadata":{}},{"cell_type":"markdown","source":"Age vs class(dependent variable):","metadata":{}},{"cell_type":"code","source":"sns.boxplot(x='class', y='Age', data= dbts)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(x='class',y='Age', data=dbts)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Age distribution:","metadata":{}},{"cell_type":"code","source":"sns.histplot(dbts['Age'],bins=25)\nplt.figure(figsize=(5,8)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(dbts['Age'], bins=25, density=True, alpha=0.5)\nplt.figure(figsize=(5,6)) \nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(age.weakness)\nplt.figure(figsize=(5,8)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Gender:","metadata":{}},{"cell_type":"code","source":"sns.countplot(x='class',data=dbts,hue='Gender')","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Polydipsia:","metadata":{}},{"cell_type":"code","source":"sns.boxplot(x='Polydipsia',y='class',data=dbts)\nplt.figure(figsize=(5,8)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(x='Polydipsia',y='class',data=dbts)\nplt.figure(figsize=(5,8)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Polyuria:","metadata":{}},{"cell_type":"code","source":"sns.barplot(x='Polyuria',y='class',data=dbts)\nplt.figure(figsize=(5,8)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Sudden Weight loss:","metadata":{}},{"cell_type":"code","source":"sns.barplot(x='sudden weight loss',y='class',data=dbts)\nplt.figure(figsize=(5,8)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x='class',hue='sudden weight loss', data=dbts, color='Brown')\nplt.figure(figsize=(5,8)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Weakness:","metadata":{}},{"cell_type":"code","source":"sns.barplot(x='weakness',y='class',data=dbts)\nplt.figure(figsize=(5,8)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Polyphagia:","metadata":{}},{"cell_type":"code","source":"sns.countplot(x='class',hue='Polyphagia', data=dbts)\nplt.figure(figsize=(5,8)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Genital thrush:","metadata":{}},{"cell_type":"code","source":"sns.countplot(x='class',hue='Genital thrush', data=dbts, color= 'Green')\nplt.figure(figsize=(5,8)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(x='class',y='Genital thrush', data=dbts)\nplt.figure(figsize=(5,8)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(x='class',y='Genital thrush', kind= 'point', data=dbts, color='Red')\nplt.figure(figsize=(8,10)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visual blurring:","metadata":{}},{"cell_type":"code","source":"sns.countplot(x='class',hue='visual blurring', data=dbts, color='Purple')\nplt.figure(figsize=(5,8)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(y='visual blurring',x='class',data=dbts)\nplt.figure(figsize=(5,8)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Itching:","metadata":{}},{"cell_type":"code","source":"sns.barplot(y='Itching',x='class',data=dbts)\nplt.figure(figsize=(5,8)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(x='class',y='Itching', kind= 'point', data=dbts, color='Red')\nplt.figure(figsize=(8,10)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Irritability:","metadata":{}},{"cell_type":"code","source":"sns.barplot(x='Irritability',y='class',data=dbts)\nplt.figure(figsize=(5,8)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"delayed healing:","metadata":{}},{"cell_type":"code","source":"sns.barplot(x='delayed healing',y='class',data=dbts)\nplt.figure(figsize=(5,8)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"partial paresis:","metadata":{}},{"cell_type":"code","source":"sns.barplot(x='partial paresis',y='class',data=dbts)\nplt.figure(figsize=(5,8)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"muscle stiffness:","metadata":{}},{"cell_type":"code","source":"sns.barplot(x='muscle stiffness',y='class',data=dbts)\nplt.figure(figsize=(5,8)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Alopecia:","metadata":{}},{"cell_type":"code","source":"sns.barplot(x='Alopecia',y='class',data=dbts)\nplt.figure(figsize=(5,8)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Obesity:","metadata":{}},{"cell_type":"code","source":"sns.barplot(x='Obesity',y='class',data=dbts)\nplt.figure(figsize=(5,8)) ","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Distribution of all variables:","metadata":{}},{"cell_type":"code","source":"dbts.hist()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scatter_matrix(dbts)\nplt.figure(figsize=(80,100))\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Occurences of Symptoms in patients:","metadata":{}},{"cell_type":"code","source":"def plotPie(value, title, label):\n    plt.figure(figsize=(4,4))\n    plt.pie(\n        value.value_counts(),\n        startangle=90,\n        labels = label,\n        autopct=(lambda p:f'{p:.2f}%\\n{p*sum(value.value_counts())/100 :.0f} items')\n    )\n    plt.title(title)\n    plt.show()\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dbts_symptoms = dbts[dbts.columns.difference([\"Age\", \"class\", \"Gender\"])]\nplt.figure(figsize=(5,8))\n\nfor column in dbts_symptoms.columns:\n    plotPie(dbts_symptoms[column], column.capitalize(),{'Yes':1,'No':0})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Profile report in brief","metadata":{}},{"cell_type":"code","source":"profile = ProfileReport(dbts, title=\"Diabetes Profiling Report\", explorative=True)\nprofile","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"profile.to_widgets()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature selection","metadata":{}},{"cell_type":"markdown","source":"\nFeature selection is a technique where we choose those features in our data that contribute most to the target variable. In other words we choose the best predictors for the target variable. The classes in the sklearn.feature_selection module can be used for feature selection/dimensionality reduction on sample sets, either to improve estimators accuracy scores or to boost their performance on very high-dimensional datasets.\n\nAdvantages:\nReduces Overfitting: Less redundant data means less possibility of making decisions based on redundant data/noise.\nImproves Accuracy: Less misleading data means modeling accuracy improves.\nReduces Training Time: Less data means that algorithms train faster.\n","metadata":{}},{"cell_type":"markdown","source":"Feature selection using  classification and regression: ","metadata":{}},{"cell_type":"code","source":"X1 = dbts.iloc[:,0:-1]\ny1 = dbts.iloc[:,-1]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_feature = SelectKBest(score_func=chi2,k=10) #chi2= For classification\nfit = best_feature.fit(X1,y1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dbts_scores = pd.DataFrame(fit.scores_)\ndbts_cols = pd.DataFrame(X1.columns)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"featurescores = pd.concat([dbts_cols,dbts_scores],axis=1)\nfeaturescores.columns=['column','scores']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X1[:10])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These are the variables with their feature scores ,their importance/contribution towards class.","metadata":{}},{"cell_type":"code","source":"featurescores","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X1_new=SelectKBest(score_func=f_regression, k=10).fit_transform(X1,y1)   #f_regression- For regression","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X1_new=dbts.iloc[:1]\ny1_new=dbts.iloc[:,2]\nprint(X1_new[:10])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These are the variables with their feature scores ,their importance/contribution towards class","metadata":{}},{"cell_type":"code","source":"featurescores","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"X1 and X1_new both features are same from both methods, it means feature selection is carried out in right direction.","metadata":{}},{"cell_type":"markdown","source":"Top 10 features:","metadata":{}},{"cell_type":"code","source":"print(featurescores.nlargest(10,'scores'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"featureview=pd.Series(fit.scores_, index=X1.columns)\nfeatureview.plot(kind='bar')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Machine learning models","metadata":{}},{"cell_type":"code","source":"X = dbts[['Polydipsia','sudden weight loss','partial paresis','Irritability','Polyphagia','Age','visual blurring']]\ny = dbts['class']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Splitting diabetes(dbts) dataset into test and train:","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nss = StandardScaler()\nX_train = ss.fit_transform(X_train)\nX_test = ss.transform(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KnearestNeighbor","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n\ntest_scores = []\ntrain_scores = []\n\nfor i in range(1,20):\n\n    knn = KNeighborsClassifier(i)\n    knn.fit(X_train,y_train)\n    \n    train_scores.append(knn.score(X_train,y_train))\n    test_scores.append(knn.score(X_test,y_test))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_train_score = max(train_scores)\ntrain_scores_ind = [i for i, v in enumerate(train_scores) if v == max_train_score]\nprint('Max train score {} % and k = {}'.format(max_train_score*100,list(map(lambda x: x+1, train_scores_ind))))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_test_score = max(test_scores)\ntest_scores_ind = [i for i, v in enumerate(test_scores) if v == max_test_score]\nprint('Max test score {} % and k = {}'.format(max_test_score*100,list(map(lambda x: x+1, test_scores_ind))))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Max test score 98.07692307692307 % and k = [2, 3, 4, 5, 11, 13]","metadata":{}},{"cell_type":"code","source":"knn = KNeighborsClassifier(13)\n\nknn.fit(X_train,y_train)\nknn.score(X_test,y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n#let us get the predictions using the classifier we had fit above\ny_pred = knn.predict(X_test)\nconfusion_matrix(y_test,y_pred)\npd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = knn.predict(X_test)\nfrom sklearn import metrics\ncnf_matrix = metrics.confusion_matrix(y_test, y_pred)\np = sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report  #import classification_report\nprint(classification_report(y_test,y_pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve                #roc-auc curve\ny_pred_proba = knn.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr, label='Knn')\nplt.xlabel('fpr')\nplt.ylabel('tpr')\nplt.title('Knn(n_neighbors=13) ROC curve')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nroc_auc_score(y_test,y_pred_proba)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hyper Parameter optimization\nGrid search is an approach to hyperparameter tuning that will methodically build and evaluate a model for each combination of algorithm parameters specified in a grid.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n#In case of classifier like knn the parameter to be tuned is n_neighbors\nparam_grid = {'n_neighbors':np.arange(1,100)}\nknn = KNeighborsClassifier()\nknn_cv= GridSearchCV(knn,param_grid,cv=5)\nknn_cv.fit(X,y)\n\nprint(\"Best Score:\" + str(knn_cv.best_score_))\nprint(\"Best Parameters: \" + str(knn_cv.best_params_))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Logistic Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlg=LogisticRegression()\nlg.fit(X_train,y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred1=lg.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"cross validation of score","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator=lg, X=X_train ,y=y_train,cv=10)\nprint(\"accuracy is {:.2f} %\".format(accuracies.mean()*100))\nprint(\"std is {:.2f} %\".format(accuracies.std()*100))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = lg.score(X_test, y_test)                        #have a look into Score\nprint(score)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(pred1,y_test))                    #have a look into confusion matrix","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report     #classification report\nprint(classification_report(pred1,y_test))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid={\"C\":np.logspace(1,100), \"penalty\":[\"l1\",\"l2\"]}     # l1 lasso l2 ridge\nlg=LogisticRegression()\nlg_cv=GridSearchCV(lg,grid,cv=5)\nlg_cv.fit(X_train,y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Best Score:\" + str(lg_cv.best_score_))\nprint(\"Best Parameters: \" + str(lg_cv.best_params_))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lg2=LogisticRegression(C=1,penalty=\"l2\")\nlg2.fit(X_train,y_train)\nprint(\"score\",lg2.score(X_test,y_test))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_auc_score(pred1, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Support Vector Machine(SVM)","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nsv=SVC(kernel='linear',random_state=0)\nsv.fit(X_train,y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator=sv, X=X_train ,y=y_train,cv=10)\nprint(\"accuracy is {:.2f} %\".format(accuracies.mean()*100))\nprint(\"std is {:.2f} %\".format(accuracies.std()*100))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred2=sv.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(pred2,y_test))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVC\nsvrf=SVC(kernel='rbf',random_state=0)\nsvrf.fit(X_train,y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator=svrf, X=X_train ,y=y_train,cv=10)\nprint(\"accuracy is {:.2f} %\".format(accuracies.mean()*100))\nprint(\"std is {:.2f} %\".format(accuracies.std()*100))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred2=svrf.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = svrf.score(X_test, y_test)                        #have a look into Score\nprint(score)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(pred2,y_test))  ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(pred2,y_test))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_auc_score(pred2, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Decision Tree","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndct=DecisionTreeClassifier(criterion='gini')\ndct.fit(X_train,y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator=dct, X=X_train ,y=y_train,cv=10)\nprint(\"accuracy is {:.2f} %\".format(accuracies.mean()*100))\nprint(\"std is {:.2f} %\".format(accuracies.std()*100))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred3=dct.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = dct.score(X_test, y_test)                        #have a look into Score\nprint(score)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(pred3,y_test)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(pred3,y_test))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_auc_score(pred3, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Guassian Naive Bayes","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\ngnb=GaussianNB()\ngnb.fit(X_train,y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator=gnb, X=X_train ,y=y_train,cv=10)\nprint(\"accuracy is {:.2f} %\".format(accuracies.mean()*100))\nprint(\"std is {:.2f} %\".format(accuracies.std()*100))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred4=gnb.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = gnb.score(X_test, y_test)                        #have a look into Score\nprint(score)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(pred4,y_test)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(pred4,y_test))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_auc_score(pred4, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nestime=[]\nfor i in range(1,100):\n    rf=RandomForestClassifier(n_estimators=i,criterion='entropy',random_state=0)\n    rf.fit(X_train,y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator=rf, X=X_train ,y=y_train,cv=10)\nprint(\"accuracy is {:.2f} %\".format(accuracies.mean()*100))\nprint(\"std is {:.2f} %\".format(accuracies.std()*100))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred5 = rf.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = rf.score(X_test, y_test)                        #have a look into Score\nprint(score)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(pred5,y_test)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(pred5,y_test))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_auc_score(pred5, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n{'n_estimators': [25, 50], 'max_features': [5, 10], \n 'max_depth': [10, 50, None], 'bootstrap': [True, False]}\n]\n\ngrid_search_rf = GridSearchCV(rf, param_grid, cv=10, scoring='neg_mean_squared_error')\ngrid_search_rf.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cvres = grid_search_rf.cv_results_                     #now let's how the RMSE changes for each parameter configuration\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(np.sqrt(-mean_score), params)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_search_rf.best_estimator_              #find the best model of grid search","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=-1,\n                       oob_score=False, random_state=13, verbose=0,\n                       warm_start=False)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracies of all classification model overview:\n\n    \n1. KNN-                     98.07692307692307\n\n2. logistic Regression-     0.8942307692307693\n\n3. SVM-                     0.9807692307692307\n\n4. Decsion Tree-            0.9615384615384616\n\n5. Guassian NB-             0.8557692307692307\n\n6. Random Forest-           0.9807692307692307\n\n","metadata":{}},{"cell_type":"markdown","source":"# The best model is KNN, SVM and Random forest with 98.07% Accuracy","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}