{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Basic EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['quality']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Quality based on alcohol content"},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(df, hue=\"quality\",height=5)\ng = g.map(sns.distplot, \"alcohol\")\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Quality based on pH value"},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(df, hue=\"quality\",height=5)\ng = g.map(sns.distplot, \"pH\")\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ANOVA method"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.formula.api import ols      # For calculation of Ordinary least squares for ANOVA\nfrom statsmodels.stats.anova import _get_covariance,anova_lm # For n-way ANOVA\nfrom statsmodels.stats.multicomp import pairwise_tukeyhsd # For performing the Tukey-HSD test\nfrom statsmodels.stats.multicomp import MultiComparison # To compare the levels  independent variables with the \nimport scipy.stats as stats ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_melt = pd.melt(df.reset_index(), id_vars=['index'], value_vars=['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar','chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density','pH', 'sulphates', 'alcohol','quality'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_melt.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_melt['variable'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_melt.columns = ['index', 'treatments', 'value']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Calculate OLS model(ordinary least square )"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ols('value ~ C(treatments)', data=df_melt).fit()\nanova_table = anova_lm(model, typ=2)\nanova_table\n#Type 1 2 and 3 yield same result if the data is balanced","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" F values is less than 0.05 which means of all groups means are not equal.Data is statistically significant"},{"metadata":{"trusted":true},"cell_type":"code","source":"### lets check for quality and alcohol","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"formula = 'alcohol ~ C(quality)'\nmodel = ols(formula, df).fit()\naov_table = anova_lm(model)\naov_table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"formula = 'pH ~ C(quality)'\nmodel = ols(formula, df).fit()\naov_table = anova_lm(model)\naov_table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pointplot(x='quality', y='alcohol', data=df,ci=0.95,color='g');\nsns.pointplot(x='quality', y='pH', data=df,ci=0.95,color='r');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Causal relation bwetween pH and quality\nmc = MultiComparison(df['pH'], df['quality'])\nmc_results = mc.tukeyhsd(alpha=0.05)\nprint(mc_results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#causal relation bwetween alcohol and quality\nmc = MultiComparison(df['alcohol'], df['quality'])\nmc_results = mc.tukeyhsd(alpha=0.05)\nprint(mc_results)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*certain group means are not equal as per tukey HSD test for alcohol and PH.\nCan be done similarly for remaining column with respect to quality.*"},{"metadata":{},"cell_type":"markdown","source":"## Linear Regression Assumptions"},{"metadata":{},"cell_type":"markdown","source":"## Thumb rules to help interpret goodness of fit in Regression model\n1. R-sq / Adj R-sq shows Goodness of fit. More favorable to have higher value (0-1)\n2. Prob (F-statistic) Less than Alpha Reject\n3. Log-Likelihood: - Goodness of fit (Higher the better when comparing multiple models)\n4. AIC(Akaike's Information Criterion),BIC(Bayesian Information Criterion):- Goodness of fit (Lower the better the when comparing multiple models)"},{"metadata":{},"cell_type":"markdown","source":"## Assumptions tested\n1. Omnibus/Prob(Omnibus) – a test of the skewness and kurtosis of the residual Omnimbus preferably closer to Zero & Prob(Omnibus) preferably closer to 1\n2. Skew – a measure of data symmetry. We want to see something close to zero, indicating the residual distribution is normal.\n3. Kurtosis – a measure of \"peakiness\", or curvature of the data. Higher peaks lead to greater Kurtosis. Greater Kurtosis can be interpreted as a tighter clustering of residuals around zero, implying a better model with few outliers\n4. Durbin-Watson – tests for Auto correlation We hope to have a value between 1.5 and 2.5\n5. Jarque-Bera (JB)/Prob(JB) – like the Omnibus test in that it tests both skew and kurtosis.\n6. Condition Number – This test measures the sensitivity of a function's output as compared to its input. When we have multicollinearity, we can expect much higher fluctuations to small changes in the data, hence, we hope to see a relatively small number."},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop('quality',axis=1)\ny = df['quality']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = sm.OLS(y, X).fit()\npredictions = model.predict(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import pearsonr\nfrom statsmodels.compat import lzip\nimport statsmodels.stats.api as sms\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.columns].corr(method='pearson')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,6))\nsns.heatmap(df.corr(method='pearson'),annot=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Variance Inflation Factor"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Formulae = (1/1-R^2)\nvif = pd.DataFrame()\nvif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif[\"features\"] = X.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vif\n# All VIF values are different , if two or more than two values have same VIF or variability the ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.residplot(predictions,y-predictions);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"horizontal bands show homoscedasticity"},{"metadata":{},"cell_type":"markdown","source":"### Test for checking Homoscadesticity is the Goldfeldquandt test"},{"metadata":{"trusted":true},"cell_type":"code","source":"name = ['GQ', 'p-value']\ntest = sms.het_goldfeldquandt(y-predictions,X)\nlzip(name, test)\n#failed to reject null hypothesis so data is homoscedastic","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Normal Distirbution of Error term"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import shapiro\nshapiro(np.abs(y-predictions))\n# Error term is normally distributed as it rejects the null hypothesis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = model.resid\nfig = sm.qqplot(res,fit=True,line='45')\nplt.show()\n##Red line denotes normal line\n##blue dots are the error terms","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Evaluation"},{"metadata":{},"cell_type":"markdown","source":"#### R Square/Adjusted R Square"},{"metadata":{},"cell_type":"markdown","source":"* 98.7% of dependent variability explained by this model\n* Adj. R-squared:0.987\n* R-squared:0.987\n"},{"metadata":{},"cell_type":"markdown","source":"### Mean Square Error(MSE)/Root Mean Square Error(RMSE)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nimport math\nprint('MSE',mean_squared_error(y,predictions))\nprint('RMSE',math.sqrt(mean_squared_error(y,predictions)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### mean Absolute Error"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nprint('MAE',mean_absolute_error(y,predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}