{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Importing Libraries\nimport numpy as np\nimport pandas as pd\n%matplotlib inline\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nimport seaborn as sns\nimport time\nfrom BorutaShap import BorutaShap\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import f1_score,plot_confusion_matrix,accuracy_score\nfrom sklearn.feature_selection import SelectKBest,chi2,RFECV\nfrom sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Loading Data\ndata = pd.read_csv(\"../input/breastcancer-dataset/data.csv\")\ndata.info()\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Separating target from features\ncol = data.columns\ny = data['diagnosis']\ncol_drop = ['id','diagnosis','Unnamed: 32']\nx = data.drop(col_drop,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot Diagnosis Distribution\nax = sns.countplot(y,label=\"Count\",palette=\"RdBu_r\")\nB,M = y.value_counts()\nprint(\"Number of Benign Tumors: \",B)\nprint(\"Number of Malign Tumors: \",M)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Features Statistics\nx.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Normalizing Dataset\ndata = x\ndata_std = (data - data.mean())/data.std()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis (EDA)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Violin Plot\nfig,ax = plt.subplots(figsize = (15,35))\n\nplt.subplot(3,1,1)\ndata = pd.concat([y,data_std.iloc[:,:10]],axis=1)\ndata = pd.melt(data,id_vars='diagnosis',var_name='features',value_name='value')\nsns.violinplot(data=data,hue='diagnosis',x='features',y='value',split=True,inner='quartile')\nplt.xticks(rotation=45)\n\nplt.subplot(3,1,2)\ndata = pd.concat([y,data_std.iloc[:,10:20]],axis=1)\ndata = pd.melt(data,id_vars='diagnosis',var_name='features',value_name='value')\nsns.violinplot(data=data,hue='diagnosis',x='features',y='value',split=True,inner='quartile')\nplt.xticks(rotation=45)\n\nplt.subplot(3,1,3)\ndata = pd.concat([y,data_std.iloc[:,20:30]],axis=1)\ndata = pd.melt(data,id_vars='diagnosis',var_name='features',value_name='value')\nsns.violinplot(data=data,hue='diagnosis',x='features',y='value',split=True,inner='quartile')\nplt.xticks(rotation=45)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Jointplots for correlation\nsns.jointplot(x['concavity_mean'],x['concave points_mean'],kind=\"regg\")\nsns.jointplot(x['concavity_worst'],x['concave points_worst'],kind=\"regg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#SwarmPlots - To determine class separability\nfig,ax = plt.subplots(figsize = (15,40))\n\nplt.subplot(3,1,1)\ndata = pd.concat([y,data_std.iloc[:,:10]],axis=1)\ndata = pd.melt(data,id_vars='diagnosis',var_name='features',value_name='value')\nsns.swarmplot(data=data,hue='diagnosis',x='features',y='value',palette=\"cubehelix\")\nplt.xticks(rotation=45)\n\nplt.subplot(3,1,2)\ndata = pd.concat([y,data_std.iloc[:,10:20]],axis=1)\ndata = pd.melt(data,id_vars='diagnosis',var_name='features',value_name='value')\nsns.swarmplot(data=data,hue='diagnosis',x='features',y='value',palette=\"cubehelix\")\nplt.xticks(rotation=45)\n\nplt.subplot(3,1,3)\ndata = pd.concat([y,data_std.iloc[:,20:30]],axis=1)\ndata = pd.melt(data,id_vars='diagnosis',var_name='features',value_name='value')\nsns.swarmplot(data=data,hue='diagnosis',x='features',y='value',palette=\"cubehelix\")\nplt.xticks(rotation=45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Heatmap\nfig,ax = plt.subplots(figsize=(20,20))\nsns.heatmap(x.corr(),annot=True,linewidth=0.5,fmt=\".1f\",ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing cols by looking at heatmap (Minimal Feature selection)\ndrop_col = ['perimeter_mean','radius_mean','compactness_mean','concave points_mean',\n            'radius_se','perimeter_se','compactness_se','concave points_se',\n            'radius_worst','perimeter_worst','area_worst','texture_worst','compactness_worst','concave points_worst']\ndf = x.drop(drop_col,axis=1)\nx_train1,x_test1,y_train1,y_test1 = train_test_split(df,y,test_size=0.3,random_state=42)\nfig,ax = plt.subplots(figsize=(15,15))\nsns.heatmap(df.corr(),annot=True,linewidth=0.5,fmt=\".1f\",ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Univariate feature selection\nselect_feature = SelectKBest(chi2,k=10).fit(x_train1,y_train1)\nx_train2 = select_feature.transform(x_train1)\nx_test2 = select_feature.transform(x_test1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Principal Component Analysis\nx_train_norm = (x_train - x_train.mean())/(x_train.max()-x_train.min())\nx_test_norm = (x_test - x_test.mean())/(x_test.max()-x_test.min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA()\npca.fit(x_train_norm)\nplt.figure(figsize=(10,8))\nsns.lineplot(data=np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel(\"No of components\")\nplt.ylabel(\"Cumulative explained variance\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classification Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#XGBoost using Minimal feature selection\nmodel1 = xgb.XGBClassifier(random_state=42)\nmodel1.fit(x_train1,y_train1)\ny_pred1 = model1.predict(x_test1)\nprint(\"Accuracy: \",accuracy_score(y_test1,y_pred1))\nplot_confusion_matrix(model1,x_test1,y_test1,cmap=plt.cm.Blues)\nplt.grid(False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#XGBost using Univariate feature selection\nmodel2 = xgb.XGBClassifier(random_state=42)\nmodel2.fit(x_train2,y_train1)\ny_pred2 = model2.predict(x_test2)\nprint(\"Accuracy: \",accuracy_score(y_test1,y_pred2))\nplot_confusion_matrix(model2,x_test2,y_test1,cmap=plt.cm.Blues)\nplt.grid(False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#XGBost using Recursive feature selection with cross validation\nmodel3 = xgb.XGBClassifier()\nrfecv = RFECV(estimator=model3,step=1,cv=5,n_jobs=-1,min_features_to_select=10,scoring='accuracy').fit(x_train,y_train)\ny_pred3 = rfecv.predict(x_test)\nprint(\"Accuracy: \",accuracy_score(y_test,y_pred3))\nplot_confusion_matrix(rfecv,x_test,y_test,cmap=plt.cm.Blues)\nplt.grid(False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_features = [i for i in range(1,len(rfecv.grid_scores_)+1)]\ncv_scores = rfecv.grid_scores_\nsns.lineplot(num_features,cv_scores)\nprint(cv_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Forest using Boruta Shap\nfeature_selector = BorutaShap(importance_measure='shap',classification=True)\nfeature_selector.fit(x_train,y_train,random_state=0,n_trials=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_selector.plot(which_features='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_boruta = feature_selector.Subset()\nx_test_boruta = x_test[['concave points_mean', 'texture_mean', 'radius_se', 'texture_worst', 'symmetry_worst', 'perimeter_worst', 'concavity_worst', 'radius_mean', 'concavity_mean', 'area_worst', 'smoothness_worst', 'area_se', 'area_mean', 'compactness_worst', 'radius_worst', 'perimeter_se', 'concave points_worst', 'fractal_dimension_worst', 'compactness_mean', 'perimeter_mean']]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model7 = xgb.XGBClassifier(random_state=42,learning_rate=0.01,n_estimators=1000)\nmodel7.fit(x_train_boruta,y_train)\ny_pred7 = model7.predict(x_test_boruta)\nprint(\"Accuracy: \",accuracy_score(y_test,y_pred7))\nplot_confusion_matrix(model7,x_test_boruta,y_test,cmap=plt.cm.Blues)\nplt.grid(False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Logistic Regression using Univariate feature selection\nmodel4 = LogisticRegression(C=500,penalty='l2',max_iter=500)\nmodel4.fit(x_train2,y_train1)\ny_pred4 = model4.predict(x_test2)\nprint(\"Accuracy: \",accuracy_score(y_test1,y_pred4))\nplot_confusion_matrix(model4,x_test2,y_test1,cmap=plt.cm.Blues)\nplt.grid(False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#SVM using Univariate feature selection\nmodel5 = SVC(C=500,gamma='scale',kernel='poly',degree=1)\nmodel5.fit(x_train2,y_train1)\ny_pred5 = model5.predict(x_test2)\nprint(\"Accuracy: \",accuracy_score(y_test1,y_pred5))\nplot_confusion_matrix(model5,x_test2,y_test1,cmap=plt.cm.Blues)\nplt.grid(False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Forest Classifier using Univariate Linear Regression\nmodel6 = RandomForestClassifier(n_estimators=1000,max_depth=20,criterion='entropy',bootstrap=True)\nmodel6.fit(x_train2,y_train1)\ny_pred6 = model6.predict(x_test2)\nprint(\"Accuracy: \",accuracy_score(y_test1,y_pred6))\nplot_confusion_matrix(model6,x_test2,y_test1,cmap=plt.cm.Blues)\nplt.grid(False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Naive Bayes Classifier using Univariate feature selection\nmodel8 = GaussianNB()\nmodel8.fit(x_train2,y_train1)\ny_pred8 = model8.predict(x_test2)\nprint(\"Accuracy: \",accuracy_score(y_test1,y_pred8))\nplot_confusion_matrix(model8,x_test2,y_test1,cmap=plt.cm.Blues)\nplt.grid(False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#K-Nearest Neighbors using Univariate feature selection\nmodel9 = KNeighborsClassifier(n_neighbors=8)\nmodel9.fit(x_train2,y_train1)\ny_pred9 = model9.predict(x_test2)\nprint(\"Accuracy: \",accuracy_score(y_test1,y_pred9))\nplot_confusion_matrix(model9,x_test2,y_test1,cmap=plt.cm.Blues)\nplt.grid(False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}