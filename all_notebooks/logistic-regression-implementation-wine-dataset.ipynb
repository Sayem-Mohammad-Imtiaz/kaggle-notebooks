{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.datasets import load_wine\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 1 - Understanding the dataset\nwine = load_wine()\nprint(\"The dimensions of the dataset are : \",wine.data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 2 - Converting the data into a dataframe\ndatadf = pd.DataFrame(wine.data)\ndatadf.columns = wine.feature_names\ntarget_df = pd.DataFrame(wine.target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 3 - Displaying dataframe head\n\ndatadf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 4 - Creating Distribution plot of variables\n\nprint(\"-----------------DISTRIBUTION PLOT-----------------\")\nplt.figure(1, figsize=(15,15))\nplt.subplot(331)\nsns.distplot(datadf[\"alcohol\"], bins = 5).set_title(\"Distribution of Alcohol\")\nplt.subplot(332)\nsns.distplot(datadf[\"malic_acid\"], bins = 5).set_title(\"Distribution of malic_acid\")\nplt.subplot(333)\nsns.distplot(datadf[\"ash\"], bins = 5).set_title(\"Distribution of ash\")\nplt.subplot(334)\nsns.distplot(datadf[\"alcalinity_of_ash\"], bins = 5).set_title(\"Distribution of alcalinity_of_ash\")\nplt.subplot(335)\nsns.distplot(datadf[\"magnesium\"], bins = 5).set_title(\"Distribution of magnesium\")\nplt.subplot(336)\nsns.distplot(datadf[\"total_phenols\"], bins = 5).set_title(\"Distribution of total_phenols\")\nplt.subplot(337)\nsns.distplot(datadf[\"flavanoids\"], bins = 5).set_title(\"Distribution of flavanoids\")\nplt.subplot(338)\nsns.distplot(datadf[\"nonflavanoid_phenols\"], bins = 5).set_title(\"Distribution of nonflavanoid_phenols\")\nplt.subplot(339)\nsns.distplot(datadf[\"proanthocyanins\"], bins = 5).set_title(\"Distribution of proanthocyanins\")\n\nplt.suptitle(\"Distribution Plot of Variables\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1, figsize=(15,15))\nplt.subplot(231)\nsns.distplot(datadf[\"color_intensity\"], bins = 5).set_title(\"Distribution of color_intensity\")\nplt.subplot(232)\nsns.distplot(datadf[\"hue\"], bins = 5).set_title(\"Distribution of hue\")\nplt.subplot(233)\nsns.distplot(datadf[\"od280/od315_of_diluted_wines\"], bins = 5).set_title(\"Distribution of od280/od315_of_diluted_wines\")\nplt.subplot(234)\nsns.distplot(datadf[\"proline\"], bins = 5).set_title(\"Distribution of proline\")\nplt.suptitle(\"Distribution Plot of Variables\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 5 - Creating Heatmap of Correlations\n\nprint(\"-------------------------HEAT MAP-------------------------\")\nsns.heatmap(datadf.corr(), annot = True, cmap='coolwarm')\nfig = plt.gcf()\nfig.set_size_inches(10,8)\nplt.title(\"Heatmap of Correlation Between Variables\", fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 6 - Regression Pair Plot \nprint(\"----------------------------REGRESSION PAIR PLOT----------------------------\")\nsns.pairplot(datadf[['alcohol', 'malic_acid', 'ash','magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols',\n                    'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']],\n             diag_kind=\"hist\", kind='reg')\nplt.suptitle(\"Regression Pair Plot of Observations\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 7 - Checking Missing Values\n\nprint(\"Missing Values :\\n\", datadf.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 8 - Assumptions Check\n\n# Normality Assumptions: Determining Normality of Data\n\nfrom scipy import stats\nprint(\"Skewness of Data \\n\", stats.skew(datadf))\nprint(\"Kurtosis of Data \\n\", stats.kurtosis(datadf))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 9 - Determining Outliers by calculating Z-Score\nimport sys\nnp.set_printoptions(threshold=sys.maxsize)\n\nzscore = np.abs(stats.zscore(datadf))\nprint(\"The Z-Score of the data is \\n\", zscore)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 10 - Determining indexes where Z-score is greater than 3\n\noutlierlist = np.where(zscore>3)\nprint(\"The indexes of the outliers are \\n\", outlierlist[0])\nprint(\"The number of outliers is \\n\", len(outlierlist[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 11 - Feature Extraction\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\ndatadf = sc.fit_transform(datadf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting Seed\nnp.random.seed(1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 12 - Creating training, test dataset for dependent and independent variables\nX_train, X_test, y_train, y_test = train_test_split(datadf, target_df, random_state = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Dimension of training dataset: \", X_train.shape)\nprint(\"Dimension of test dataset: \", X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 13 - Creating the Logistic Regression Model\nwine_logreg_model = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 14 - Fitting the model\nwine_logreg_model.fit(X_train, y_train.values.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 15 - Predicting with the trained model and determining the accuracy\npred = wine_logreg_model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 16 - Determining the score of training and test dataset\nprint(\"Training set score :\", wine_logreg_model.score(X_train, y_train))\nprint(\"Test set score :\", wine_logreg_model.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 16 - Determining accuracy of the model using confusion matrix\nresults = confusion_matrix(y_test, pred)\nprint(\"Result of the Confusion Matrix is: \\n\", results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}