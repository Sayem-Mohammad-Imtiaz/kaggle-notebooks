{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":4,"outputs":[{"output_type":"stream","text":"['petrol-consumption', 'bank-note-authentication-uci-data']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# Random Forest Regression\n\n* Question: How to predict the gas consumption (in millions of gallons) in 48 of the US states based on petrol tax (in cents), per capita income (dollars), paved highways (in miles) and the proportion of population with the driving license.\n\n* Source: Historical Petral Consumption \n\n* Solution: Using random forest algorithm via the Scikit-Learn Python library. "},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/petrol-consumption/petrol_consumption.csv') ","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"   Petrol_tax         ...          Petrol_Consumption\n0         9.0         ...                         541\n1         9.0         ...                         524\n2         9.0         ...                         561\n3         7.5         ...                         414\n4         8.0         ...                         410\n\n[5 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Petrol_tax</th>\n      <th>Average_income</th>\n      <th>Paved_Highways</th>\n      <th>Population_Driver_licence(%)</th>\n      <th>Petrol_Consumption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9.0</td>\n      <td>3571</td>\n      <td>1976</td>\n      <td>0.525</td>\n      <td>541</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9.0</td>\n      <td>4092</td>\n      <td>1250</td>\n      <td>0.572</td>\n      <td>524</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9.0</td>\n      <td>3865</td>\n      <td>1586</td>\n      <td>0.580</td>\n      <td>561</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7.5</td>\n      <td>4870</td>\n      <td>2351</td>\n      <td>0.529</td>\n      <td>414</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8.0</td>\n      <td>4399</td>\n      <td>431</td>\n      <td>0.544</td>\n      <td>410</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.iloc[:, 0:4].values  \ny = data.iloc[:, 4].values  ","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import sklearn \nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=0)  ","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()  \nX_train = sc.fit_transform(X_train)  \nX_test = sc.transform(X_test)  ","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nregressor = RandomForestRegressor(n_estimators=20, random_state=0)  \nregressor.fit(X_train, y_train)  \ny_pred = regressor.predict(X_test)  ","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))  ","execution_count":19,"outputs":[{"output_type":"stream","text":"Mean Absolute Error: 54.583333333333336\nMean Squared Error: 4469.795833333334\nRoot Mean Squared Error: 66.85653171780102\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nregressor = RandomForestRegressor(n_estimators=100, random_state=0)  \nregressor.fit(X_train, y_train)  \ny_pred = regressor.predict(X_test)  ","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))  ","execution_count":21,"outputs":[{"output_type":"stream","text":"Mean Absolute Error: 54.68866666666667\nMean Squared Error: 4124.747753333334\nRoot Mean Squared Error: 64.22419912566707\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Classification \n\n* Question: How to predict whether a bank currency note is authentic or not based on four attributes i.e. variance of the image wavelet transformed image, skewness, entropy, and curtosis of the image.\n\n* Source: UCI Machine Learning Database \n\n* Solution: Using random forest algorithm for a binary classfication. "},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/bank-note-authentication-uci-data/BankNote_Authentication.csv')","execution_count":54,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":55,"outputs":[{"output_type":"execute_result","execution_count":55,"data":{"text/plain":"   variance  skewness  curtosis  entropy  class\n0   3.62160    8.6661   -2.8073 -0.44699      0\n1   4.54590    8.1674   -2.4586 -1.46210      0\n2   3.86600   -2.6383    1.9242  0.10645      0\n3   3.45660    9.5228   -4.0112 -3.59440      0\n4   0.32924   -4.4552    4.5718 -0.98880      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>variance</th>\n      <th>skewness</th>\n      <th>curtosis</th>\n      <th>entropy</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.62160</td>\n      <td>8.6661</td>\n      <td>-2.8073</td>\n      <td>-0.44699</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.54590</td>\n      <td>8.1674</td>\n      <td>-2.4586</td>\n      <td>-1.46210</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.86600</td>\n      <td>-2.6383</td>\n      <td>1.9242</td>\n      <td>0.10645</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.45660</td>\n      <td>9.5228</td>\n      <td>-4.0112</td>\n      <td>-3.59440</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.32924</td>\n      <td>-4.4552</td>\n      <td>4.5718</td>\n      <td>-0.98880</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.iloc[:, 0:4].values  \ny = data.iloc[:, 4].values ","execution_count":56,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)  ","execution_count":41,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()  \nX_train = sc.fit_transform(X_train)  \nX_test = sc.transform(X_test)  ","execution_count":45,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier \nrf_model = RandomForestClassifier(n_estimators=20, random_state=0)  \nrf_model.fit(X_train, y_train)  \ny_pred = rf_model.predict(X_test)  ","execution_count":50,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\nprint(confusion_matrix(y_test,y_pred))  \nprint(classification_report(y_test,y_pred))  \nprint(accuracy_score(y_test, y_pred))  ","execution_count":51,"outputs":[{"output_type":"stream","text":"[[229   3]\n [  2 178]]\n              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99       232\n           1       0.98      0.99      0.99       180\n\n   micro avg       0.99      0.99      0.99       412\n   macro avg       0.99      0.99      0.99       412\nweighted avg       0.99      0.99      0.99       412\n\n0.9878640776699029\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model2 = RandomForestClassifier(n_estimators=100, random_state=0)  \nrf_model2.fit(X_train, y_train)  \ny_pred = rf_model2.predict(X_test)  ","execution_count":52,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test,y_pred))  \nprint(classification_report(y_test,y_pred))  \nprint(accuracy_score(y_test, y_pred))  ","execution_count":53,"outputs":[{"output_type":"stream","text":"[[229   3]\n [  1 179]]\n              precision    recall  f1-score   support\n\n           0       1.00      0.99      0.99       232\n           1       0.98      0.99      0.99       180\n\n   micro avg       0.99      0.99      0.99       412\n   macro avg       0.99      0.99      0.99       412\nweighted avg       0.99      0.99      0.99       412\n\n0.9902912621359223\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# alternative way to write the feature and label dataset \nX = data.drop('class', axis = 1)\ny = data['class']","execution_count":58,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)  ","execution_count":59,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\nclt = DecisionTreeClassifier()\nclt.fit(X_train, y_train)\ny_pred = clt.predict(X_test)","execution_count":61,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test,y_pred))  \nprint(classification_report(y_test,y_pred))  \nprint(accuracy_score(y_test, y_pred))  ","execution_count":62,"outputs":[{"output_type":"stream","text":"[[226   6]\n [  3 177]]\n              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98       232\n           1       0.97      0.98      0.98       180\n\n   micro avg       0.98      0.98      0.98       412\n   macro avg       0.98      0.98      0.98       412\nweighted avg       0.98      0.98      0.98       412\n\n0.9781553398058253\n","name":"stdout"}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}