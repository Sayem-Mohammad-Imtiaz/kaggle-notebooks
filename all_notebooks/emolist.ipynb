{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Library Import**","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"\nimport numpy as np \nimport pandas as pd \nimport cv2\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Set import**","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/facial-expression/fer2013.csv')","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Preprocessing **","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iloc[0]['pixels']\nprint(df)\nlen(df.iloc[0]['pixels'].split())\n# 48 * 48","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_map = ['Anger', 'Neutral', 'Fear', 'Happy', 'Sad', 'Surprise']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = df.iloc[0]['pixels'].split()\n# img                                    img is in string","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = [int(i) for i in img]  #Conversion into integer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(img[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = np.array(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = img.reshape(48,48)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(img, cmap='gray')\nplt.xlabel(df.iloc[0]['emotion'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = []     #List of images\ny = []     #Emotions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **label_map = ['Anger', 'Neutral', 'Fear', 'Happy', 'Sad', 'Surprise']**","metadata":{}},{"cell_type":"code","source":"def getData(path):\n    anger = 0\n    fear = 0\n    sad = 0\n    happy = 0\n    surprise = 0\n    neutral = 0\n    df = pd.read_csv(path)\n    \n    X = []\n    y = []    \n    \n    for i in range(len(df)):\n        if df.iloc[i]['emotion'] != 1:     #removal of disgust images\n            if df.iloc[i]['emotion'] == 0:  #We will take 4000 images from each dataset [0] is anger emotion\n                if anger <= 4000:            \n                    y.append(df.iloc[i]['emotion'])\n                    im = df.iloc[i]['pixels']\n                    im = [int(x) for x in im.split()]\n                    X.append(im)\n                    anger += 1\n                else:\n                    pass\n                \n            if df.iloc[i]['emotion'] == 2:\n                if fear <= 4000:            \n                    y.append(df.iloc[i]['emotion'])# Fear\n                    im = df.iloc[i]['pixels']\n                    im = [int(x) for x in im.split()]\n                    X.append(im)\n                    fear += 1\n                else:\n                    pass\n                \n            if df.iloc[i]['emotion'] == 3:\n                if happy <= 4000:                  #fear\n                    y.append(df.iloc[i]['emotion'])\n                    im = df.iloc[i]['pixels']\n                    im = [int(x) for x in im.split()]\n                    X.append(im)\n                    happy += 1\n                else:\n                    pass\n                \n            if df.iloc[i]['emotion'] == 4:\n                if sad <= 4000:            \n                    y.append(df.iloc[i]['emotion'])#Sad\n                    im = df.iloc[i]['pixels']\n                    im = [int(x) for x in im.split()]\n                    X.append(im)\n                    sad += 1\n                else:\n                    pass\n                \n            if df.iloc[i]['emotion'] == 5:\n                if surprise <= 4000:            #Surprise\n                    y.append(df.iloc[i]['emotion'])\n                    im = df.iloc[i]['pixels']\n                    im = [int(x) for x in im.split()]\n                    X.append(im)\n                    surprise += 1\n                else:\n                    pass\n                \n            if df.iloc[i]['emotion'] == 6:\n                if neutral <= 4000:            #neutral\n                    y.append(df.iloc[i]['emotion'])\n                    im = df.iloc[i]['pixels']\n                    im = [int(x) for x in im.split()]\n                    X.append(im)\n                    neutral += 1\n                else:\n                    pass\n\n            \n            \n    return X, y  \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, y = getData('../input/facial-expression/fer2013.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.unique(y, return_counts=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.array(X)/255.0\ny = np.array(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape, y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_o = []\nfor i in y:\n    if i != 6:\n        y_o.append(i)\n                                            #Moving 6th to another position \n    else:\n        y_o.append(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.unique(y_o, return_counts=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    r = np.random.randint((1), 24000, 1)[0]\n    plt.figure()\n    plt.imshow(X[r].reshape(48,48), cmap='gray')\n    plt.xlabel(label_map[y_o[r]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = X.reshape(len(X), 48, 48, 1)        #If color image 3 instead of 1 ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# no_of_images, height, width, coloar_map  In Cnn data should be in 4 dimensions ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils import to_categorical\ny_new = to_categorical(y_o, num_classes=6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(y_o), y_new.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_o[150], y_new[150]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense , Activation , Dropout ,Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.metrics import categorical_accuracy\nfrom keras.models import model_from_json\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.optimizers import *\nfrom keras.layers.normalization import BatchNormalization","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()              #Exactly One input and one output (layer by layer modelling)\n\n\ninput_shape = (48,48,1)\n\n\nmodel.add(Conv2D(64, (5, 5), input_shape=input_shape,activation='relu', padding='same'))\nmodel.add(Conv2D(64, (5, 5), padding='same'))\nmodel.add(BatchNormalization())          #This has the effect of stabilizing the learning process and dramatically reducing\n                                        #the number of training epochs required to train deep networks.\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n\nmodel.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\nmodel.add(Conv2D(128, (5, 5),padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\nmodel.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n## (15, 15) --->  30\nmodel.add(Flatten())\nmodel.add(Dense(6, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n\n# fer_json = model.to_json()\n# with open(\"fer.json\", \"w\") as json_file:\n#     json_file.write(fer_json)\n# model.save_weights(\"fer.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X, y_new, epochs=200, batch_size=64, shuffle=True, validation_split=0.2)\nprint(history.history.keys())\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize history for accuracy\nplt.plot(history.history['accuracy'])\n# plt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\n# plt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize history for accuracy\n# plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\n# plt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.save('model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fer_json = model.to_json()  \n# with open(\"fer.json\", \"w\") as json_file:  \n#     json_file.write(fer_json)  \n# model.save_weights(\"fer.h5\")  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import cv2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_img = cv2.imread('../input/fer2013/train/sad/Training_10022789.jpg', 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print (test_img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_img.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_img = cv2.resize(test_img, (48,48))\n# test_img.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_img = test_img.reshape(1,48,48,1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.predict(test_img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# label_map = ['Anger', 'Neutral', 'Fear', 'Happy', 'Sad', 'Surprise']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os  \n# import cv2  \n# import numpy as np  \n# from keras.models import model_from_json  \n# from keras.preprocessing import image  \n  \n# #load model  \n# model = model_from_json(open(\"./fer.json\", \"r\").read())  \n# #load weights  \n# model.load_weights('./fer.h5')  \n  \n  \n# face_haar_cascade = cv2.CascadeClassifier('../input/harrcascade/haarcascade_frontalcatface.xml')  \n  \n  \n# cap=cv2.VideoCapture(0)  \n  \n# while True:  \n#     ret,test_img=cap.read()# captures frame and returns boolean value and captured image  \n#     if not ret:  \n#         continue  \n#     gray_img= cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)  \n  \n#     faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)  \n  \n  \n#     for (x,y,w,h) in faces_detected:  \n#         cv2.rectangle(test_img,(x,y),(x+w,y+h),(255,0,0),thickness=7)  \n#         roi_gray=gray_img[y:y+w,x:x+h]#cropping region of interest i.e. face area from  image  \n#         roi_gray=cv2.resize(roi_gray,(48,48))  \n#         img_pixels = image.img_to_array(roi_gray)  \n#         img_pixels = np.expand_dims(img_pixels, axis = 0)  \n#         img_pixels /= 255  \n  \n#         predictions = model.predict(img_pixels)  \n  \n#         #find max indexed array  \n#         max_index = np.argmax(predictions[0])  \n  \n#         emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')  \n#         predicted_emotion = emotions[max_index]  \n  \n#         cv2.putText(test_img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)  \n  \n#     resized_img = cv2.resize(test_img, (1000, 700))  \n#     cv2.imshow('Facial emotion analysis ',resized_img)  \n  \n  \n  \n#     if cv2.waitKey(10) == ord('q'):#wait until 'q' key is pressed  \n#         break  \n  \n# cap.release()  \n# cv2.destroyAllWindows  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}