{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Web Advertising PDP"},{"metadata":{},"cell_type":"markdown","source":"## *How can companies increase ad click rate?*"},{"metadata":{},"cell_type":"markdown","source":"## Loading, Viewing, Cleaning Data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/advertising/advertising.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training Model"},{"metadata":{},"cell_type":"markdown","source":"To get analysis and plots, we have to first train a proper model. Let's try out a couple of models and see which one performs the best."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.pipeline import make_pipeline\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\n\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"K-Fold Cross Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = data.drop(['Ad Topic Line','City','Country','Timestamp','Clicked on Ad'],axis=1)\ntarget = data['Clicked on Ad']\nss = StandardScaler()\n\nlog = LogisticRegression()\ndec = DecisionTreeClassifier()\nran = RandomForestClassifier()\nnn = MLPClassifier()\n\nlog_pipe = make_pipeline(ss,log)\ndec_pipe = make_pipeline(ss,dec)\nran_pipe = make_pipeline(ss,ran)\nnn_pipe = make_pipeline(ss,nn)\n\nkf = KFold(n_splits=10, shuffle=True, random_state = 1)\n\nlog_results = cross_val_score(log_pipe, features, target, cv=kf, scoring = 'accuracy')\ndec_results = cross_val_score(dec_pipe, features, target, cv=kf, scoring = 'accuracy')\nran_results = cross_val_score(ran_pipe, features, target, cv=kf, scoring = 'accuracy')\nnn_results = cross_val_score(nn_pipe, features, target, cv=kf, scoring = 'accuracy')\n\npd.DataFrame({'Algorithm':['Logistic Regression','Decision Tree','Random Forest','Neural Network'],\n             'K-Fold Accuracy':[log_results.mean(),dec_results.mean(),\n                               ran_results.mean(),nn_results.mean()]})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's use another technique for assessing accuracy:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(features,target,test_size=0.2)\n\nlog = LogisticRegression()\ndec = DecisionTreeClassifier()\nran = RandomForestClassifier()\nnn = MLPClassifier()\n\nmodels = [log,dec,ran,nn]\n\nfor model in models:\n    model.fit(X_train,y_train)\n    \nfor model in models:\n    print(model)\n    print(classification_report(y_test,model.predict(X_test)))\n    print(\"\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll use Random Forest for now, it has consistently good results."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ran","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Identifying Most Important Factors"},{"metadata":{"trusted":true},"cell_type":"code","source":"import eli5 #for purmutation importance\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(model, random_state=1).fit(X_test, y_test)\neli5.show_weights(perm, feature_names = X_test.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most important features are Daily Internet Usage and Daily Time Spent on Site. Secondly are Age and Area Income, and lastly, gender."},{"metadata":{},"cell_type":"markdown","source":"## PDPs for Factors\nA Partial Dependence Plot graphs out the impact of a single variable on the target."},{"metadata":{"trusted":true},"cell_type":"code","source":"from pdpbox import pdp, info_plots\nimport matplotlib.pyplot as plt\n\nbase_features = X_train.columns.tolist()\n\nfor feature in base_features:\n    \n    feat_name = feature\n    pdp_dist = pdp.pdp_isolate(model=model, dataset=X_test, model_features=base_features, feature=feat_name)\n\n    pdp.pdp_plot(pdp_dist, feat_name)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, for some bivariate contour PDP plots."},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_list = X_test.columns.tolist()\nfeature_list.remove('Male')\n\nstart_index = 1\nfor feature in feature_list:\n    for index in range(start_index,4):\n\n        features = [feature,feature_list[index]]\n\n        inter  =  pdp.pdp_interact(model=model, dataset=X_test, model_features=base_features, features=features)\n\n        pdp.pdp_interact_plot(pdp_interact_out=inter, feature_names=features, plot_type='contour')\n        plt.show()\n    \n    start_index += 1","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}