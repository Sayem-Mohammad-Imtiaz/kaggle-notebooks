{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\nimport keras.backend as K\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport ast\nfrom collections import Counter\nimport json\nimport os","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"annotations = []\n\nbaseLabelPath = '../input/labels/'\nlabelFiles = sorted(os.listdir(baseLabelPath))\n\nwith open(os.path.join(baseLabelPath, labelFiles[0])) as file:\n    dictionary = ast.literal_eval(list(file)[0]) # json data\n    for items in sorted(dictionary.items()):\n        annotations.append((items[0], items[1]))\n\ndata = pd.read_csv('../input/trainingdata/TrainingData.csv')\n\ndata = data.iloc[: 593360, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Data size : {data.shape}')\nlabels = []\n\ncntLabels = Counter()\n\nfor index, anno in enumerate(annotations):\n    cntLabels[anno[1]] += 1\n    li = [0.0] * 10\n    li[anno[1]] = 1\n    labels.append(li)\n\nlabels = np.array(labels)\n#labels = np.reshape(labels, (labels.shape[0] * 2, 10))\ntotal = sum(cntLabels.values())\n\n\nprint(cntLabels.most_common())\nprint(f'Total labels: {total}')\nprint(f'Training Labels size: {labels.shape}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classWeights = []\n\nfor index, num in enumerate(cntLabels):\n    prob = cntLabels[index] / total\n    classWeights.append((index, 1 / prob))\n\nclassWeights = dict(classWeights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data['label'] = labels\n#data['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_data = data.iloc[:, :]\n\nX_data = np.array(X_data)\nX_data = X_data.reshape((int(X_data.shape[0] / 16), 16 * 28))\n\ny_data = labels\n\nprint(f'Total training samples: {X_data.shape[0]}')\nprint(f'Total features: {X_data.shape[1]}')\nprint(f'Total number of labels: {y_data.shape[1]}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.1, shuffle = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n    \n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    \n    return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"METRICS = [ \n      keras.metrics.BinaryAccuracy(name='accuracy'),\n      keras.metrics.Precision(name='precision'),\n      keras.metrics.Recall(name='recall')\n]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def getModel():\n    model = Sequential()\n\n    model.add(Dense(512, input_shape=(448, ), name='dense1'))\n    model.add(Dense(512, name='dense2'))\n    model.add(Dense(512, name='dense3'))\n\n    model.add(Dropout(0.3, name='dropout1'))\n\n    model.add(Dense(256, name='dense4'))\n\n    model.add(Dropout(0.2, name='dropout2'))\n\n    model.add(Dense(128, name='dense5'))\n\n    model.add(Dense(10, activation='softmax', name='output'))\n    \n    optimizer = Adam(lr=1e-3)\n    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy', f1_m, precision_m, recall_m])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = getModel()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def stepDecay(epoch):\n    if epoch <= 20:\n        K.set_value(model.optimizer.lr, 1e-3)\n    else:\n        K.set_value(model.optimizer.lr, 1e-4)\n        \n    return K.get_value(model.optimizer.lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SnapshotCallbackBuilder:\n    def __init__(self, nb_epochs, nb_snapshots, init_lr=0.001):\n        self.T = nb_epochs\n        self.M = nb_snapshots\n        self.alpha_zero = init_lr\n\n    def get_callbacks(self, model_prefix='Model'):\n\n        callback_list = [\n            ModelCheckpoint(\"JointFC_model.h5\",monitor='val_precision_m', \n                                   mode = 'max', save_best_only=True, verbose=1),\n            swa,\n            LearningRateScheduler(stepDecay)\n        ]\n\n        return callback_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SWA(keras.callbacks.Callback):\n    \n    def __init__(self, filepath, swa_epoch):\n        super(SWA, self).__init__()\n        self.filepath = filepath\n        self.swa_epoch = swa_epoch \n    \n    def on_train_begin(self, logs=None):\n        self.nb_epoch = self.params['epochs']\n        print('Stochastic weight averaging selected for last {} epochs.'\n              .format(self.nb_epoch - self.swa_epoch))\n        \n    def on_epoch_end(self, epoch, logs=None):\n        \n        if epoch == self.swa_epoch:\n            self.swa_weights = self.model.get_weights()\n            \n        elif epoch > self.swa_epoch:    \n            for i in range(len(self.swa_weights)):\n                self.swa_weights[i] = (self.swa_weights[i] * \n                    (epoch - self.swa_epoch) + self.model.get_weights()[i])/((epoch - self.swa_epoch)  + 1)\n        else:\n            pass\n        \n    def on_train_end(self, logs=None):\n        self.model.set_weights(self.swa_weights)\n        print('Final model parameters set to stochastic weight average.')\n        self.model.save_weights(self.filepath)\n        print('Final stochastic averaged weights saved to file.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 50\nbatchSize = 12\n\nswa = SWA('Best_JointFC_model.h5',epochs - 5)\nsnapshot = SnapshotCallbackBuilder(nb_epochs=epochs,nb_snapshots=1, init_lr=1e-3)\n\n\nhistory = model.fit(X_train, y_train, epochs = epochs, verbose = 1, validation_split = 0.1,\n                    validation_steps = 200, steps_per_epoch = len(X_train) //  batchSize,\n                    callbacks = snapshot.get_callbacks())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(history.history).to_hdf(\"Model.h5\",key=\"history\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Present lr: {K.get_value(model.optimizer.lr)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, accuracy, _, precision, recall = model.evaluate(X_test, y_test, verbose=0)\nprint(f'Loss: {np.round(loss,4)}\\nAccuracy: {100 * np.round(accuracy,4)}%\\nPrecision: {np.round(precision,4)}\\nRecall: {np.round(recall, 4)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test)\n\npredictions = []\ntestLabels = []\n\nfor pred in y_pred:\n    predictions.append(np.argmax(pred))\n    \nfor label in y_test:\n        testLabels.append(np.where(label == 1)[0][0])\n\n        \nlabels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n        \ncm = confusion_matrix(testLabels, predictions)\n\nfig = plt.figure()\nax = fig.add_subplot(111)\nmatC = ax.matshow(cm)\nfig.colorbar(cax)\n\nax.set_xticklabels([''] + labels)\nax.set_yticklabels([''] + labels)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(precision_score(testLabels, predictions, average='micro'))\nprint(recall_score(testLabels, predictions, labels=[1,2], average='micro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(testLabels, predictions));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}