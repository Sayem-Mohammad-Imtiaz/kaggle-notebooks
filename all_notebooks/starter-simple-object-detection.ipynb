{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Introduction\nVery basic version of custom object detection using pre trained model."},{"metadata":{},"cell_type":"markdown","source":"## Libraries "},{"metadata":{"trusted":true},"cell_type":"code","source":"from bs4 import BeautifulSoup\nimport random\nimport os, csv\nimport numpy as np\nimport tensorflow\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport random \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reproducibility"},{"metadata":{"trusted":true},"cell_type":"code","source":"tensorflow.random.set_seed(120)\nnp.random.seed(122)\nrandom.seed(120)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data- Pre Processing\n* images and annotation (xml) files will be converted into csv format for smoother flow of the model training."},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# from kaggle_datasets import KaggleDatasets\n# GCS_PATH = KaggleDatasets().get_gcs_path()\n\nimport cv2\na=cv2.imread('../input/currency-symbol-datasets/datasets/datasets/franc/franc10.jpg',0)\nprint(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"datasets_directory = \"../input/simple-object-detection/datasets\"\nannotations_directory=\"../input/simple-object-detection/datasets/annotations/\"\nformat='.jpg'\nN = []      \nfor r, d, f in os.walk(datasets_directory, topdown=False):\n    N.append(f)   \nK=np.arange(len(N[0]))\nrandom.shuffle(K)\nfor i in K:  \n    annotation_file=annotations_directory+N[0][i]\n    ds = BeautifulSoup(open(annotation_file).read(), \"html.parser\")\n    # Iterating each object elements\n    for o in ds.find_all(\"object\"):\n        class_label = o.find(\"name\").string\n        x_min = max(0, int(float(o.find(\"xmin\").string)))\n        y_min = max(0, int(float(o.find(\"ymin\").string)))\n        x_max = min(int(ds.find(\"width\").string), int(float(o.find(\"xmax\").string)))\n        y_max = min(int(ds.find(\"height\").string), int(float(o.find(\"ymax\").string)))\n        # controlling errors\n        if x_min >= x_max or y_min >= y_max:\n            continue\n        elif x_max <= x_min or y_max <= y_min:\n            continue\n        line = [N[1][i], str(x_min), str(y_min), str(x_max), str(y_max), str(class_label)]\n        with open(\"datasets.csv\", 'a', newline='') as f:\n                csv.writer(f).writerow(line)\nprint(\"datasets.csv has been created...\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Reading/Processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('datasets.csv',header = None,names=[\"image_tag\", \"left\", \"top\", \"right\",\"bottom\",'a'])\ndf=df.drop(['a'], axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalise locations (output coordinates)\ndf[\"left\"]=df[\"left\"]/224\ndf[\"top\"]=df[\"top\"]/224\ndf[\"right\"]=df[\"right\"]/224\ndf[\"bottom\"]=df[\"bottom\"]/224\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train and test split\nrt=0.2\nix=int((1-rt)*len(df))\ndf1 = df.iloc[:ix,:] \ndf2 = df.iloc[ix+1:,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(rescale=1./255)\ntrain_g = datagen.flow_from_dataframe(\n    df1, directory='/kaggle/input/datasets/images/',\n    x_col=\"image_tag\",y_col=[\"left\", \"top\", \"right\",\"bottom\"],\n    target_size=(224, 224),batch_size=5, \n    class_mode=\"raw\",subset=\"training\")\nvalid_g = datagen.flow_from_dataframe(\n    df2, directory='/kaggle/input/datasets/images/',\n    x_col=\"image_tag\",y_col=[\"left\", \"top\", \"right\",\"bottom\"],\n    target_size=(224, 224),batch_size=5, \n    class_mode=\"raw\",subset=\"training\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Setup"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model Setup\nmodel = tf.keras.models.Sequential()\nmodel.add(tf.keras.applications.InceptionV3(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3)))\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(64, activation=\"relu\"))\nmodel.add(tf.keras.layers.Dense(4, activation=\"relu\"))\nmodel.summary()\nmodel.compile(tf.keras.optimizers.SGD(learning_rate=0.1),loss='categorical_crossentropy',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training\nmodel.fit(train_g, steps_per_epoch=17, validation_data=valid_g, validation_steps=4, epochs=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\nThe star dectection datasets is created for study purpose. it can be developed further. \nThanks."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}