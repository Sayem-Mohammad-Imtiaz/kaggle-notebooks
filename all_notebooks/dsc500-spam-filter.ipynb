{"cells":[{"metadata":{},"cell_type":"markdown","source":"#### **Name**: Rio Atmadja\n#### **Date**: 20 April 2020\n#### **Course**: DSC500 \n#### **Description**: Understanding spam filtering, compare the performance between: Naive Bayes, Neural Network, Support Vector Machine, K Nearest Neighbors "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, roc_curve, auc \nimport pandas as pd \nfrom scipy.sparse.csr import csr_matrix \nimport numpy as np\nfrom textblob import TextBlob\nfrom pandas.core.series import Series \n%matplotlib inline\nimport matplotlib.pyplot as plt \nimport seaborn as sns \nimport matplotlib\nplt.rcParams['figure.figsize'] = (10,20)  \nplt.rcParams['font.size'] = 16\nplt.style.use('ggplot')\n \n# Misc\nfrom typing import List, Dict \nimport re \nfrom nltk import pos_tag, word_tokenize","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def spam_engine(clf,text: str) -> str:\n    \"\"\"\n    This function will classify if the given input is a spam or ham.\n    :clf    : given the classifier\n    :text   : \n    :return : a string of classifed text\n    \"\"\"\n    if not clf and text: \n        raise AttributeError(\"Classifier and Text are required to run the engine.\")\n        \n    return list( map(lambda x: 'HAM' if x == 1 else 'SPAM' , mlp.predict( tf_idf.transform([text])).tolist() ) )[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_freq(text: str) -> List:\n    \"\"\"\n    This function will extract the most common word used in a spam email. \n    :text : given the spam text\n    :return : The words that associated with spam message\n    \"\"\"\n    if not text: \n        raise AttributeError('text is a required parameter.')\n        \n    vect = CountVectorizer() \n    word = vect.fit_transform( [text] ).toarray().sum(axis=0)\n    \n    freq: Dict = { pos_tag(word_tokenize(k) )[0]:v[0] for k,v in pd.DataFrame( word.reshape(1, len(word)) , columns=vect.get_feature_names() ).to_dict().items() }     \n    \n    return ' '.join([ word[0] for word in freq if 'NN' in word[-1] ])\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clf_model(clf_funct, X_train_dtm, X_test_dtm, y_train, **kwargs):\n    \"\"\"\n    This is a generic function to classify a given ML model\n    :X_train: given a vector of independent training data \n    :X_test: given a vector of independent test data\n    :y_train: given the training dependent variable data\n    :**kwargs : given the ML required arguments \n    \"\"\"\n \n    return clf_funct(kwargs).fit(X_train_dtm, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_clf_proba(**pred_proba) -> Dict:\n    \"\"\"\n    This function will return the prediction proba\n    :pred_proba: It's a kwargs that contains key: classfier name, value: prediction probabilities\n    \"\"\"\n    return pred_proba","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_accuracy_score(y_pred_class: Series, y_test: Series) -> str: \n    \"\"\"\n    This function will return the prediction accuracy of the given set of prediction class and test vector\n    :y_pred_class : given the prediction class vector\n    :y_test: given the test class vector \n    \"\"\"\n    return f\"{accuracy_score(y_pred_class, y_test) * 100:.3f} %\" ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Data preparation: Encoding issue  \nraw_spam: List[str] = open('../input/sms-spam-collection-dataset/spam.csv','r', encoding='latin').read().split('\\n') \nspam_raw_data: List[tuple] = list( map(lambda spam: (spam.split(',')[0], spam.split(',')[1:]) , raw_spam[1:] ) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spam = pd.DataFrame.from_dict(spam_raw_data)\nspam.columns = ['classfication','text']\nspam.index = np.arange(1,len(spam) + 1 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spam.shape ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spam['text'] = spam['text'].apply(lambda x: re.sub( ',,', '', ' '.join(x)) )\nspam['classfication'] = spam['classfication'].apply(lambda x: re.sub('\\\"','',x) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set the image size and font here\nplt.rcParams['figure.figsize'] = (25,10)  \nplt.rcParams['font.size'] = 14","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spam['classfication'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spam['classfication'].value_counts().plot(kind='bar')\nplt.title(\"Distribution of Spams\") # Lot of ham","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# HAM: 1 , SPAM: 0 \nspam['map'] = np.where(spam['classfication'] == 'ham' , 1 , 0)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train, Test, Split "},{"metadata":{"trusted":true},"cell_type":"code","source":"X = spam['text']\ny = spam['map']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=123)\n# tokenize \ntf_idf = TfidfVectorizer(ngram_range=(1,4), lowercase=True, stop_words='english')\nX_train_dtm = tf_idf.fit_transform(X_train)\nX_test_dtm = tf_idf.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokens: List[str] = tf_idf.get_feature_names() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(10,10) , random_state=123)\nmlp.fit(X_train_dtm,y_train)\nmlp_pred = mlp.predict(X_test_dtm)\nmlp_proba = mlp.predict_proba(X_test_dtm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Accuracy: { round( accuracy_score(mlp_pred, y_test) * 100, 3 ) } \")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spam[spam['map'] == 0 ]['text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# is the word Chance associated with spam or ham \n# Todo: extract word frequency in spam \nspam[ spam['text'].apply(lambda x: True if 'chance' in x.lower() else False) ]['classfication'].value_counts().plot(kind='bar')\nplt.title('DSC500: Sampling the word chane')\nplt.yticks(range(1,30, 5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sampling a text "},{"metadata":{"trusted":true},"cell_type":"code","source":"spam_engine( mlp, 'Choose the right credit card for you - we made it easy' ) \nspam_engine(mlp, 'Last chance: Get 50%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extracting frequencies in spam "},{"metadata":{"trusted":true},"cell_type":"code","source":"extracted_values: List[Dict] = spam[ spam['text'].apply(lambda x: True if 'chance' in x.lower() else False) ]['text'].apply(get_freq).tolist() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vect = CountVectorizer()\n# Spam filter: the following words \nfeature_names: List[str] = pd.DataFrame( {'spam_words': extracted_values}, index=range(1,len(extracted_values) + 1))['spam_words'].tolist()\nvect.fit_transform(feature_names) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Words that are associated with Spam email"},{"metadata":{"trusted":true},"cell_type":"code","source":"spam_words = pd.DataFrame( vect.transform(feature_names).toarray().sum(axis=0).reshape(1,184) , columns=vect.get_feature_names()).transpose() \nspam_words.columns = ['spam_words']\nspam_words.sort_values(by='spam_words',ascending=False,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spam_words.head(50).plot(kind='bar')\nplt.title('DSC500: Words associated with spam')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spam[ spam['text'].apply(lambda x: True if 'chance' in x.lower() else False) ]['text'].apply(get_freq).tolist() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Support Vector Machine "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Support Vector Machine \nsvm_clf = SVC(probability=True) \nsvm_clf.fit(X_train_dtm, y_train)\nsvm_pred = svm_clf.predict(X_test_dtm)\nsvm_proba = svm_clf.predict_proba(X_test_dtm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Naive BAyes "},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_multi = MultinomialNB() \nnb_multi.fit(X_train_dtm, y_train)\nnb_multi_pred = nb_multi.predict(X_test_dtm)\nnb_multi_proba = nb_multi.predict_proba(X_test_dtm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### K-Nearest Neighbor "},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=10) # With 10 Neighbors \nknn.fit(X_train_dtm, y_train)\nknn_pred = knn.predict(X_test_dtm)\nknn_proba = knn.predict_proba(X_test_dtm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_proba: Dict = get_clf_proba(svm=(svm_pred,svm_proba[:,1]) , mlp=(mlp_pred,mlp_proba[:,1])  , knn=(knn_pred,knn_proba[:,1]), nb_multi=(nb_multi_pred,nb_multi_proba[:,1]) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Algorithms Peformance"},{"metadata":{"trusted":true},"cell_type":"code","source":"colors: List[str] = ['red', 'blue', 'green', 'purple']\ncounter: int = 0\n    \nfor clf, data in pred_proba.items(): \n    clf_pred, clf_proba = data \n    fpr, tpr, thresholds = roc_curve(y_test,clf_proba)\n    roc_auc = auc(fpr,tpr)\n    plt.plot(fpr, tpr, colors[counter], label=f\"[+] Model: {clf}\\n[+] AUC: {round(roc_auc, 4)} \\n[+]Prediction Accuracy: {get_accuracy_score(clf_pred,y_test)}\")\n    counter += 1\n\nplt.title(\"DSC500: Spam filter classfier performance\")\nplt.xlim([-0.005,1.0])\nplt.ylim([0.0,1.0])\nplt.xlabel(\"False Postive Rate\")\nplt.ylabel(\"True Positve Rate\")\nplt.legend(loc=\"upper right\")\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}