{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, KFold\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier\nfrom sklearn.metrics import roc_auc_score, accuracy_score, roc_curve, confusion_matrix\n\nfrom imblearn.over_sampling import SMOTE\n\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nimport lightgbm as lgb\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Data analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,12), dpi= 60)\nplt.title('Distribution of Outcome variable')\nplt.pie(data['Outcome'].value_counts(), labels = ['healthy','diabetic'], colors = ['gold', 'lightcoral'], autopct='%1.1f%%', shadow=True, startangle=140)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in data.columns:\n    print(i, data[i][data[i] == 0].count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12, 8))\nax = sns.boxplot(data = data, orient = 'h', palette = 'Set2')\nplt.title('Boxplot overview dataset')\nplt.xlabel('values')\nplt.xlim(-3, 300)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12, 8))\nsns.heatmap(data.corr(), annot = True)\nplt.title('Correlation matrix')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Data cleaning and feature engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"def median_feature(feature):\n    temp = data[data[feature] > 0]\n    med_cat = temp.groupby('Outcome')[feature].median().reset_index()\n    return med_cat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preparing_feature(feature, median_data):\n    data.loc[(data['Outcome'] == 0) & (data[feature] == 0), feature] = median_data[median_data['Outcome'] == 0][feature].median()\n    data.loc[(data['Outcome'] == 1) & (data[feature] == 0), feature] = median_data[median_data['Outcome'] == 1][feature].median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def kdeplot(feature, xlabel, title):\n    plt.figure(figsize = (12, 8))\n    ax = sns.kdeplot(data[feature][(data['Outcome'] == 0) & \n                             (data[feature].notnull())], color = 'darkturquoise', shade = True)\n    ax = sns.kdeplot(data[feature][(data['Outcome'] == 1) & \n                             (data[feature].notnull())], color = 'lightcoral', shade= True)\n    plt.xlabel(xlabel)\n    plt.ylabel('frequency')\n    plt.title(title)\n    ax.grid()\n    ax.legend(['healthy','diabetic'])\nkdeplot('Glucose', 'concentration', 'Glucose')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"median_feature_glucose = median_feature('Glucose')\nmedian_feature_glucose","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preparing_feature('Glucose', median_feature_glucose)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kdeplot('Insulin', 'mu U/ml', 'Insulin')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"median_feature_insulin = median_feature('Insulin')\nmedian_feature_insulin","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Insulin'] = data['Insulin'].astype('float')\npreparing_feature('Insulin', median_feature_insulin)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kdeplot('BloodPressure', 'mm Hg', 'BloodPressure')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"median_feature_bpressure = median_feature('BloodPressure')\nmedian_feature_bpressure","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['BloodPressure'] = data['BloodPressure'].astype('float')\npreparing_feature('BloodPressure', median_feature_bpressure)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kdeplot('SkinThickness', 'mm', 'SkinThickness')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"median_feature_skinthickness = median_feature('SkinThickness')\nmedian_feature_skinthickness","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preparing_feature('SkinThickness', median_feature_skinthickness)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kdeplot('BMI', 'weight in kg/(height in m)^2', 'BMI')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"median_feature_bmi = median_feature('BMI')\nmedian_feature_bmi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preparing_feature('BMI', median_feature_bmi)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in data.columns:\n    print(i, data[i][data[i] == 0].count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kdeplot('Age', 'years', 'Age')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kdeplot('DiabetesPedigreeFunction', 'diabetes pedigree function', 'DiabetesPedigreeFunction')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kdeplot('Pregnancies', 'number of times pregnant', 'Pregnancies')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Preprocessing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.drop(['Outcome'], axis = 1)\ny = data['Outcome']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 12345)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric = []\nfor i in X_train.columns:\n        numeric += [i]\nscaler = StandardScaler()\nscaler.fit(X_train[numeric])\nX_train[numeric] = scaler.transform(X_train[numeric])\nX_test[numeric] = scaler.transform(X_test[numeric])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Create and fit models"},{"metadata":{"trusted":true},"cell_type":"code","source":"def confusion_m(model, title):\n    cm = confusion_matrix(y_test, model.predict(X_test))\n    f, ax = plt.subplots(figsize = (8, 6))\n    sns.heatmap(cm, annot = True, linewidths = 0.5, cmap = 'Greens', fmt = '.0f', ax = ax)\n    plt.xlabel('y_predicted')\n    plt.ylabel('y_true')\n    plt.title(title)\n    plt.show()\n\ndef feature_importance(model, title):\n    dataframe = pd.DataFrame(model, X_train.columns).reset_index()\n    dataframe = dataframe.rename(columns = {'index':'features', 0:'coefficients'})\n    dataframe = dataframe.sort_values(by = 'coefficients', ascending = False)\n    plt.figure(figsize=(13,10), dpi= 60)\n    ax = sns.barplot(x = 'coefficients', y = 'features', data = dataframe ,palette = 'viridis')\n    plt.title(title, fontsize = 20)\n    plt.grid()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(random_state = 12345)\nparameters_lr = {'C': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 3, 5, 7, 10, 15, 20, 25, 30, 50], \n                 'penalty':['l1', 'l2', 'elasticnet', 'none'],\n                 'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n                 'class_weight': [1, 3, 10],\n                 'max_iter': [200, 500, 800, 1000, 2000]}\nsearch_lr = RandomizedSearchCV(lr, parameters_lr, cv=5, scoring = 'accuracy', n_jobs = -1, random_state = 12345)\nsearch_lr.fit(X_train, y_train)\nbest_lr = search_lr.best_estimator_\npredict_lr = best_lr.predict(X_test)\nauc_lr = cross_val_score(best_lr, X_test, y_test, scoring = 'roc_auc', cv = 10, n_jobs = -1)\nacc_lr = cross_val_score(best_lr, X_test, y_test, scoring = 'accuracy', cv = 10, n_jobs = -1)\nprint('AUC-ROC for Logistic Regression on test dataset:', sum(auc_lr)/len(auc_lr))\nprint('Accuracy for Logistic Regression on test dataset:', sum(acc_lr)/len(acc_lr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importance(best_lr.coef_[0], 'Feature importance for Logistic Regression')\nconfusion_m(best_lr, 'Confusion matrix for Logistic Regression')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(random_state = 12345)\nparameters_rf = {'n_estimators': range(1, 1800, 25), \n                 'criterion': ['gini', 'entropy'], \n                 'max_depth':range(1, 100), \n                 'min_samples_split': range(1, 12), \n                 'min_samples_leaf': range(1, 12), \n                 'max_features':['auto', 'log2', 'sqrt', 'None']}\nsearch_rf = RandomizedSearchCV(rf, parameters_rf, cv=5, scoring = 'accuracy', n_jobs = -1, random_state = 12345)\n\nsearch_rf.fit(X_train, y_train)\nbest_rf = search_rf.best_estimator_\npredict_rf = best_rf.predict(X_test)\nauc_rf = cross_val_score(best_rf, X_test, y_test, scoring = 'roc_auc', cv = 10, n_jobs = -1)\nacc_rf = cross_val_score(best_rf, X_test, y_test, scoring = 'accuracy', cv = 10, n_jobs = -1) \nprint('AUC-ROC for Random Forest on test dataset:', sum(auc_rf)/len(auc_rf))\nprint('Accuracy for Random Forest on test dataset:', sum(acc_rf)/len(acc_rf))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importance(best_rf.feature_importances_, 'Feature importance for Random Forest')\nconfusion_m(best_rf, 'Confusion matrix for Random Forest')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBClassifier(random_state = 12345, eval_metric='auc')\nparameters_xgb = {'eta': [0.01, 0.05, 0.1, 0.001, 0.005, 0.04, 0.2, 0.0001],  \n                  'min_child_weight':range(1, 5), \n                  'max_depth':range(1, 6), \n                  'learning_rate': [0.01, 0.05, 0.1, 0.001, 0.005, 0.04, 0.2], \n                  'n_estimators':range(0, 2001, 50)}\nsearch_xgb = RandomizedSearchCV(xgb, parameters_xgb, cv = 5, scoring = 'accuracy', n_jobs = -1, random_state = 12345)\nsearch_xgb.fit(X_train, y_train)\nbest_xgb = search_xgb.best_estimator_\npredict_xgb = best_xgb.predict(X_test)\nauc_xgb = cross_val_score(best_xgb, X_test, y_test, scoring = 'roc_auc', cv = 10, n_jobs = -1)\nacc_xgb = cross_val_score(best_xgb, X_test, y_test, scoring = 'accuracy', cv = 10, n_jobs = -1)\nprint('AUC-ROC for XGBoost on test dataset:', sum(auc_xgb)/len(auc_xgb))\nprint('Accuracy for XGBoost on test dataset:', sum(acc_xgb)/len(acc_xgb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importance(best_xgb.feature_importances_, 'Feature importance for XGBoost')\nconfusion_m(best_xgb, 'Confusion matrix for XGBoost')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cb = CatBoostClassifier(random_state = 12345, iterations = 300, eval_metric='Accuracy', verbose = 100)\nparameters_cb = {'depth': range(6, 11),\n                 'learning_rate': [0.001, 0.01, 0.05, 0.1, 0.0001]}\nsearch_cb = RandomizedSearchCV(cb, parameters_cb, cv = 5, scoring = 'accuracy', n_jobs = -1, random_state = 12345)\nsearch_cb.fit(X_train, y_train, verbose = 100)\nbest_cb = search_cb.best_estimator_\npredict_cb = best_cb.predict(X_test)\nauc_cb = cross_val_score(best_cb, X_test, y_test, scoring = 'roc_auc', cv = 10, n_jobs = -1)\nacc_cb = cross_val_score(best_cb, X_test, y_test, scoring = 'accuracy', cv = 10, n_jobs = -1)\nprint('AUC-ROC for CatBoost on test dataset:', sum(auc_cb)/len(auc_cb))\nprint('Accuracy for CatBoost on test dataset:', sum(acc_cb)/len(acc_cb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importance(best_cb.feature_importances_, 'Feature importance for CatBoost')\nconfusion_m(best_cb, 'Confusion matrix for CatBoost')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vc = VotingClassifier(estimators=[('lr', best_lr), ('xgb', best_xgb), ('rf', best_rf), ('cb', best_cb)], voting='soft')\nvc.fit(X_train, y_train)\npredict_vc = vc.predict(X_test)\nauc_vc = cross_val_score(vc, X_test, y_test, scoring = 'roc_auc', cv = 10, n_jobs = -1)\nacc_vc = cross_val_score(vc, X_test, y_test, scoring = 'accuracy', cv = 10, n_jobs = -1)\nprint('AUC-ROC for ensemble models on test dataset:', sum(auc_vc)/len(auc_vc))\nprint('Accuracy for ensemble models on test dataset:', sum(acc_vc)/len(acc_vc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_m(vc, 'Confusion matrix for VotingClassifier')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Result"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = ['logistic_regression', 'random_forest',\n          'xgboost', 'catboost', 'voting']\ndict_values = {'auc_roc': [auc_lr.mean(), auc_rf.mean(),\n                           auc_xgb.mean(), auc_cb.mean(), auc_vc.mean()],\n              'accuracy': [acc_lr.mean(), acc_rf.mean(),\n                            acc_xgb.mean(), acc_cb.mean(), acc_vc.mean()]}\ndf_score = pd.DataFrame(dict_values, index = models, columns = ['auc_roc', 'accuracy'])\ndf_score","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}