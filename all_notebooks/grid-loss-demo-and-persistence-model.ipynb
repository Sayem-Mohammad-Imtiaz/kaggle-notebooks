{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Grid loss demonstration and Persistence model\n\n\nThis notebook will give a demo for how to use the dataset. The pupose of this notebook is to provide the persistence model for predicting the grid loss.\n\n**Persistence model:**\n\nPersistence model is a well used baseline time series perdiction. It assumes that time series data does not change rapidly from day to day. Under this assumption, the persistence models 'predicts' that the values in the future will be a repitition of the last observed values. In this project, persistence model assumes that the grid loss for today will be same as the grid loss last week, the same day. Hence, in the model implementation, training is not needed. For prediction, it just returns the last week's measured grid loss values.\n\nAs you will notice, Persistence model is not the best model. Feel free to explore other features and beat its performance with your models."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport datetime as dt # date time\nimport matplotlib.pyplot as plt # for plotting\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For this demonstration, we used the test.csv file from the dataset. Persistence model was tested on this whole file in this demo, but feel free to play around the start date, duration and end date. We predicted grid loss for grid 1 here."},{"metadata":{"trusted":true},"cell_type":"code","source":"## Add dates and grid number you are interested in\n\nstart_date = dt.datetime(2019,12,1)\nend_date = dt.datetime(2020,5,31)\ngrid_nr = 1\ngrid_col = f'grid{grid_nr}-loss'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Load the test dataset. Training dataset is not needed here as Persistence model just returns the grid loss values from the week before, hence no training is needed.\n\ntest_data = pd.read_csv('../input/grid-loss-time-series-dataset/test.csv', index_col=0)\nx_test = test_data[grid_col]\ndisplay(x_test.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Persistence model was defined below. To use the model in the similar fashion as other sklearn models, we used the same prototype for our model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining the Persistence model, in line with other sklearn models\n\nclass PersistenceModel:\n    def __init__(self):\n        pass\n    def train(self, x_train, y_train):\n        # No training needed\n        pass\n    def predict(self, x_test):\n        # returns the values shifted back by 7 days (i.e. 24*7 hourly values)\n        return x_test.shift(24*7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Other helful functions\n\n# Calculating the model performance. MAE, RMSE and MAPE are calculated.\ndef calculate_error(pred, target):\n    target = target.loc[pred.index[0]: pred.index[-1]]\n    metrics = {\n        \"mae\": np.mean(np.abs(pred - target)), # Mean absolute error\n        \"rmse\": np.sqrt(np.mean((pred - target) ** 2)), # Root mean squared error\n        \"mape\": 100 * np.sum(np.abs(pred - target)) / np.sum(target)} # Mean absolute percentage error\n    return metrics\n\n# Visualizing the target and predictions\ndef plot_predictions(pred, target):\n    target.plot(figsize=(30,10), label='target', linewidth=2)\n    pred.plot(label='prediction', linewidth=2)\n    plt.title('Persistence model performance', fontsize=20)\n    plt.xlabel('Date and time', fontsize=18)\n    plt.ylabel('Grid loss', fontsize=18)\n    plt.xticks(fontsize=14)\n    plt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initializing the model\nmodel = PersistenceModel() \n\n# Returns the last week's values\ny_test = model.predict(x_test)   \n\n# Check model's performance\nerror_metrics = calculate_error(x_test, y_test) \nprint(f'Model performance for predicting loss for grid {grid_nr} is: {error_metrics}')\n\n# Visualize the performance\nplot_predictions(y_test, x_test)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}