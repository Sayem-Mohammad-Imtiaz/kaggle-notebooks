{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introdução"},{"metadata":{},"cell_type":"markdown","source":"<div style=\"text-align: justify\"> O dataset contém características importantes para determinar um bom vinho, constituído por 1.599 observações e suas respectivas classificações sensoriais e psicoquímicas. Por questões de privacidade nenhum tipo de uva foi discriminada, assim como rótulos e preços. Temos disponíveis 12 variáveis distintas, sendo que 11 são características sensoriais/psicoquímicas e 1 com o score final do produto (escala de 0 - 10). </div>"},{"metadata":{},"cell_type":"markdown","source":"Sumário de variáveis:\n\n    1 - fixed acidity\n    2 - volatile acidity\n    3 - citric acid\n    4 - residual sugar\n    5 - chlorides\n    6 - free sulfur dioxide\n    7 - total sulfur dioxide\n    8 - density\n    9 - pH\n    10 - sulphates\n    11 - alcohol\n    12 - quality (score between 0 and 10)"},{"metadata":{},"cell_type":"markdown","source":"<div style=\"text-align: justify\"> O objetivo é encontrar uma relação entre os componentes dos vinhos e suas respectivas notas, habilitando o comprador da importadora a ter uma pré-seleção com base no score atribuído. Entende-se como 'bom' vinho um score igual ou maior do que 6.\n\nO dataset foi encontrado no repositório de machine learning da UCI: https://archive.ics.uci.edu/ml/datasets/wine+quality\n\nCitação: P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009. </div>"},{"metadata":{},"cell_type":"markdown","source":"# Bibliotecas"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pydot\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nfrom subprocess import call\nfrom scipy.stats import zscore\nfrom collections import Counter\nfrom sklearn import preprocessing\nfrom IPython.display import Image\nfrom sklearn.tree import export_graphviz\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom imblearn.over_sampling import RandomOverSampler\nfrom sklearn.metrics import cohen_kappa_score\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\ndataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['quality'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Divisão das classes em duas"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['good quality'] = [1 if x >= 6 else 0 for x in dataset['quality']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['good quality'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Matriz de correlação"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,12))\nsns.heatmap(data=dataset.corr(),annot=True, cmap=\"rocket\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Box plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.plot(kind='box',subplots=True,layout=(5,3),grid=True,figsize=(12,12))\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Remoção dos outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_entries = dataset[(np.abs(zscore(dataset)) < 3).all(axis=1)]\nfiltered_entries","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train_test_split"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dataset.iloc[:,0:-2]\nY = dataset.iloc[:,-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_treino, X_teste, Y_treino, Y_teste = train_test_split(X,Y,\n                                        test_size=0.3,stratify=Y)\n\nprint('Quant de amostras de treino\\n', Y_treino.value_counts())\nprint('Quant de amostras de teste\\n', Y_teste.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Normalizar dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = preprocessing.MinMaxScaler().fit(X_treino)\nX_treino_normalizado = scaler.transform(X_treino)\nX_teste_normalizado = scaler.transform(X_teste)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Classifier"},{"metadata":{},"cell_type":"markdown","source":"<div style=\"text-align: justify\"> O funcionamento desse algoritmo se dá pela criação de muitas árvores de decisão, de maneira aleatória, formando o que podemos enxergar como uma floresta, onde cada árvore será utilizada na escolha do resultado final. </div>\n<div style=\"text-align: justify\"> As Árvores de Decisão, ou Decision Trees, estabelecem regras para tomada de decisão. O algoritmo criará uma estrutura similar a um fluxograma, com “nós” onde uma condição é verificada, e se atendida o fluxo segue por um ramo, caso contrário, por outro, sempre levando ao próximo nó, até a finalização da árvore. Com os dados de treino, o algoritmo busca as melhores condições, e onde inserir cada uma dentro do fluxo. </div>"},{"metadata":{},"cell_type":"markdown","source":"    n_estimators - número de árvores\n    max_depth - número máximo de profundidade da árvore\n    min_samples_split - o número mínimo de amostras necessárias para dividir um nó interno\n    random_state - controla a aleatoriedade da inicialização das amostras usadas ao construir árvores"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=100, max_depth = 4, min_samples_split = 0.1, random_state = 6)\nrf.fit(X_treino_normalizado, Y_treino)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(rf.estimators_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"estimator = rf.estimators_[5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"export_graphviz(estimator, \n                out_file='tree.dot', \n                feature_names = X_treino.columns,\n                rounded = True, proportion = False, \n                precision = 2, filled = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n\nImage(filename = 'tree.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bar plot com importância das variáveis"},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_importances = pd.Series(rf.feature_importances_, index=X.columns)\nfeat_importances.nlargest(25).plot(kind='barh',figsize=(8,8))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predições e cálculo da taxa de erro"},{"metadata":{"trusted":true},"cell_type":"code","source":"valores_preditos_teste = rf.predict(X_teste_normalizado)\nvalores_preditos_treinamento = rf.predict(X_treino_normalizado)\n\nacuracia_teste = accuracy_score(Y_teste,\n                                valores_preditos_teste)\n\nacuracia_treinamento = accuracy_score(Y_treino,\n                                      valores_preditos_treinamento)\n\nkappa_teste = cohen_kappa_score(Y_teste,\n                                      valores_preditos_teste)\n\nkappa_treinamento = cohen_kappa_score(Y_treino,\n                                      valores_preditos_treinamento)\n\nmatriz_confusao_teste = confusion_matrix(Y_teste,\n                                         valores_preditos_teste)\n\nprint('Acuracia treino = ', acuracia_treinamento)\nprint('Acuracia teste = ', acuracia_teste)\nprint('Kappa treino = ', kappa_treinamento)\nprint('Kappa teste = ', kappa_teste)\nprint(matriz_confusao_teste)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Procurando os melhores estimadores"},{"metadata":{},"cell_type":"markdown","source":"    bootstrap - quando falso, todo o conjunto de dados é usado para construir cada árvore."},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {\"max_depth\" : np.linspace(10,100,10),\"min_samples_leaf\":[1,2,4],'min_samples_split':[2,5,10],'bootstrap':[True,False]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"empty = RandomForestClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Grid = GridSearchCV(empty,parameters,refit=True).fit(X_treino_normalizado, Y_treino)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Grid.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Grid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RFC = RandomForestClassifier(bootstrap = True, max_depth = 70.0, min_samples_leaf = 1, min_samples_split = 5).fit(X_treino_normalizado, Y_treino)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valores_preditos_teste = RFC.predict(X_teste_normalizado)\nvalores_preditos_treinamento = RFC.predict(X_treino_normalizado)\n\nacuracia_teste = accuracy_score(Y_teste,\n                                valores_preditos_teste)\n\nacuracia_treinamento = accuracy_score(Y_treino,\n                                      valores_preditos_treinamento)\n\nkappa_teste = cohen_kappa_score(Y_teste,\n                                      valores_preditos_teste)\n\nkappa_treinamento = cohen_kappa_score(Y_treino,\n                                      valores_preditos_treinamento)\n\nmatriz_confusao_teste = confusion_matrix(Y_teste,\n                                         valores_preditos_teste)\n\nprint('Acuracia treino = ', acuracia_treinamento)\nprint('Acuracia teste = ', acuracia_teste)\nprint('Kappa treino = ', kappa_treinamento)\nprint('Kappa teste = ', kappa_teste)\nprint(matriz_confusao_teste)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusões e Considerações"},{"metadata":{},"cell_type":"markdown","source":"<div style=\"text-align: justify\"> O dataset não possui nenhum null value;\nPor outro lado, diversos outliers foram encontrados entre as variáveis, principalmente nas variáveis 'açucar resídual' e 'cloreto'; </div>"},{"metadata":{},"cell_type":"markdown","source":"    'Acidez fixa': não é capaz de predizer a qualidade, uma vez que a variação entre diferentes notas foi parecida;\n    'Acidez volátil': indica correlação entre indicador de acidez e nota. Quanto maior nota menor a acidez;\n    'Acidez cítrica': não indica maior ou melhor qualidade, porém as notas mais altas (7 e 8) apontam maior equilíbrio entre as distribuições;\n    'Açucar resídual': variação equilibrada mas com diversos outliers (especialmente com as notas intermediárias como 5 e 6);\n    'Cloreto': variação equilibrada com diversos outliers (especialmente com as notas intermediárias como 5 e 6);\n    'PH': notas mais altas (acima de 6) apresentaram limites inferiores menores do que as demais notas;\n    'Sulfato': notas mais altas apresentaram maior índice de sulfato;\n    'Álcool': notas mais altas apresentaram maior volume de álcool."},{"metadata":{},"cell_type":"markdown","source":"    \n<div style=\"text-align: justify\"> Ao analisar a importância das características para prever a qualidade, nos gráficos demostrou que o álcool, sulfatos, dióxido de enxofre total, densidade e acidez volátil têm um papel um pouco mais importante na previsão da classificação de qualidade do que as outras características. O método de ajuste dos parâmetros do estimador foram otimizados por uma pesquisa em grade com validação cruzada em uma grade de parâmetros, que foi a utilização do GridSearch no Random Forest que resultou no aumento da capacidade de classificação em quase 5 p.p. de acurácia no conjunto de teste e no kappa houve também um aumento de quase 9 p.p, mas infelizmente gerou Overfitting nos dados. </div>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}