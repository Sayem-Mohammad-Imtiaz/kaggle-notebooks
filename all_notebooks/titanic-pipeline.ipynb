{"cells":[{"metadata":{"_uuid":"0b52b42f-75cb-464c-9f96-79036b1089b6","_cell_guid":"30c86df0-c6fb-499d-abdc-5a6bfe3c1e99","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b0641f2e-6941-4c5a-8135-74c7ce64f2fa","_cell_guid":"be509dbf-8ed4-436f-9a06-3d78c610d5e9","trusted":true},"cell_type":"code","source":"%matplotlib inline\n\n# Start Python Imports\nimport math, time, random, datetime\n\n# Data Manipulation\nimport numpy as np\nimport pandas as pd\n\n# Visualization \nimport matplotlib.pyplot as plt\nimport missingno\nimport seaborn as sns\nplt.style.use('seaborn-whitegrid')\n\n# Preprocessing\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import mean_absolute_error \n\n\n# Machine learning\nimport catboost\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection, tree, preprocessing, metrics, linear_model\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom catboost import CatBoostClassifier, Pool, cv\n\n# Let's be rebels and ignore warnings for now\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5beab065-8512-4c11-8a25-0a4dcd9c79ed","_cell_guid":"82ef7eda-c8c2-452e-b1c9-6626282ffb8d","trusted":true},"cell_type":"code","source":"import pandas as pd\ngender_submission = pd.read_csv(\"../input/titanic/gender_submission.csv\")\nTitanic_testset = pd.read_csv(\"../input/titanic/test.csv\")\nTitanic_train  = pd.read_csv(\"../input/titanic/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"842a1982-c868-4ab9-9bfc-1596509eab9a","_cell_guid":"c975880d-3d4c-4402-b07d-a12088bd9eea","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"316e963f-1d0e-498b-8d87-1e90e2c038f0","_cell_guid":"5a846b42-af93-4895-b42b-885d1c89f575","trusted":true},"cell_type":"code","source":"print('Cheacking for zero values', Titanic_train.isnull().sum())\nprint('-'*50)\nprint('Checking for nanvalues', Titanic_train.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"695b1e55-5ec7-4631-994f-5733f548ab29","_cell_guid":"339b3d78-26bb-4c18-813b-1e299b05d8fa","trusted":true},"cell_type":"code","source":"Titanic_train.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1572abd-f442-485b-a8b3-015b5017cb64","_cell_guid":"eddcea04-bbd8-4e18-b685-f63556266799","trusted":true},"cell_type":"code","source":"Feature = ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n       'Ticket', 'Fare', 'Cabin', 'Embarked']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3d214493-f5ed-4a46-b5ae-47ed7bb5cebd","_cell_guid":"31f28e93-04f7-4180-8bdf-de78ae9f0737","trusted":true},"cell_type":"code","source":"#removing nan values and defining feature and target prediction \ny = Titanic_train.Survived  \nX = Titanic_train[Feature]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"78b03445-05c2-459c-8048-529ca5fff292","_cell_guid":"e5dd35fd-023c-49ee-9f8f-fa6b9c9905bd","trusted":true},"cell_type":"code","source":"#split the data into validation and traning \nX_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06318c56-0a14-4c90-a594-fa73e8a6b7b2","_cell_guid":"139bfd66-e1ea-4417-bb98-3fd119a52c01","trusted":true},"cell_type":"code","source":"#creating a list with all the categorical data with relatively low cardinality\ncategorical_data = [cate for cate in X_train_full if\n                    X_train_full[cate].nunique() < 10 and \n                    X_train_full[cate].dtype == \"object\"]\ncategorical_data","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c5ddf32f-9627-4799-b7d6-774158ac6d8d","_cell_guid":"9be15ac8-1604-46b0-aff7-bf838c76fa24","trusted":true},"cell_type":"code","source":"#We want to find the numerical data before creating a pipline and use simpleimputer and one-hot encoding \nnumerical_data = [num for num in X_train_full if X_train_full[num].dtype in ['int64', 'float64']]\nnumerical_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_cols = categorical_data + numerical_data\nX_train = X_train_full[my_cols].copy()\nX_valid = X_valid_full[my_cols].copy()\nX_test = Titanic_testset[my_cols].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X_train) == len(y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe88cdb5-7544-4ec4-8779-aee872f38633","_cell_guid":"ddde8642-cff7-4c0f-a856-9bf61361f984","trusted":true},"cell_type":"code","source":"# We will now use the pipline to get both preprocessed \n\nnumerical_transformer = SimpleImputer(strategy = 'constant');\n\n\ncategorical_transformer = Pipeline(steps = [('imputer', SimpleImputer(strategy = 'most_frequent')),\n                                             ('onehot', OneHotEncoder (handle_unknown = 'ignore'))\n                                            ]);\n\npreprocessor = ColumnTransformer (transformers = [('num',numerical_transformer, numerical_data), \n                                                 ('cat',categorical_transformer, categorical_data)\n                                                ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocessor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rep_cycle = [num for num in range(50, 450, 50)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#optimizing model RandomForestRegressor\ndef RFRscore(esti_rep): \n    my_model_1 = RandomForestRegressor(n_estimators=esti_rep, random_state = 0)\n    clf = Pipeline(steps=[('preprocessor', preprocessor), \n                        ('model',my_model_1)])\n    clf.fit(X_train, y_train)  \n    predictions_1 = clf.predict(X_valid) \n    mae_1 = mean_absolute_error(predictions_1, y_valid) \n    return mae_1\n\n# Using 50, 100, 150, 200, 250, 300, 350, 400 in n_estimators\nRFR_mae = {}\nfor reps in rep_cycle: \n    RFR_mae[reps] = RFRscore(reps) \nRFR_mae","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#optimizing model XGBoost \n\ndef XGBscore(esti_rep):\n    my_model_2 = XGBRegressor(n_estimators=esti_rep, learning_rate = 0.01)\n    clf = Pipeline(steps=[('preprocessor', preprocessor), \n                        ('model',my_model_2)])\n    clf.fit(X_train, y_train)  \n    predictions_2 = clf.predict(X_valid) \n    mae_2 = mean_absolute_error(predictions_2, y_valid) \n    return mae_2\n\n# Using 50, 100, 150, 200, 250, 300, 350, 400 in n_estimators\nXGB_mae = {}\nfor reps in rep_cycle: \n    XGB_mae[reps] = XGBscore(reps) \nXGB_mae","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6df5fb5d-eb7a-42a6-bf0a-235a4e33964b","_cell_guid":"9cd20d1c-9156-4c48-81aa-32a45a94586a","trusted":true},"cell_type":"code","source":"# We will now move on to defining our models\nmodel_1 = RandomForestRegressor (n_estimators = min(RFR_mae, key=RFR_mae.get), random_state=0)\nmodel_2 = XGBRegressor(n_estimators = min(XGB_mae, key=XGB_mae.get),learning_rate=0.01)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"758e37d6-c9dd-4340-955f-fc4a53cff1b7","_cell_guid":"e7126ed1-cfe6-435a-9629-20e21b0b6982","trusted":true},"cell_type":"code","source":"#Bundle processing \nBundle = Pipeline(steps=[('preprocessor', preprocessor), \n                        ('model', model_2)])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9603e8e0-07c3-48c8-9f0e-fba83a949269","_cell_guid":"e9086ba7-aab2-458f-be4e-337e5f4591ef","trusted":true},"cell_type":"code","source":"#we will now use the prepocessed to to fit the model \n\nBundle.fit(X_train, y_train);\n\n#our prediction will be \n\npreds = Bundle.predict(X_valid)\n\n# Mean absolute error \nmae = mean_absolute_error(preds, y_valid)\nmae","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b9ad937-199a-4b23-9d4a-72cc54ddc293","_cell_guid":"dc02cde9-71f6-431c-ab8c-4c9bfa2d303d","trusted":true},"cell_type":"code","source":"#Use your trained model to generate predictions with the test data\npreds_test = Bundle.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ec90a3c-6ad2-402d-811c-7e75b215d8ac","_cell_guid":"8c7aae08-47f7-42bd-aa9d-29b245a205ed","trusted":true},"cell_type":"code","source":"print(f'Model test accuracy: {Bundle.score(X_valid, y_valid)*100:.3f}%')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c0b73d7e-817d-41ce-a039-124d3190370b","_cell_guid":"93e99e08-1ae2-40ac-a760-3ced0825541f","trusted":true},"cell_type":"code","source":"#save the data to prediction file\n\noutput = pd.DataFrame({'PassengerId': gender_submission.PassengerId, 'Survived': preds_test})\noutput.Survived = output.Survived.astype(int)\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}