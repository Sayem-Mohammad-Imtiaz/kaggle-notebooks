{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nimport tensorflow as tf\nimport csv\nimport random\nimport numpy as np\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import regularizers","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/bengali-news-dataset/train.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/bengali-news-dataset/valid.csv')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fix random seed for reproducibility\nnp.random.seed(7)\ntrain = train.drop_duplicates().reset_index(drop=True)\ntest = test.drop_duplicates().reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.label.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.label = train.label.replace('entertainment', 1)\ntrain.label = train.label.replace('national', 2)\ntrain.label = train.label.replace('sports', 3)\ntrain.label = train.label.replace('kolkata', 4)\ntrain.label = train.label.replace('state', 5)\ntrain.label = train.label.replace('international', 6)\ntrain.label = train.label.replace('sport', 7)\ntrain.label = train.label.replace('nation', 8)\ntrain.label = train.label.replace('world', 9)\ntrain.label = train.label.replace('travel', 10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.label.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.label.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.label = test.label.replace('entertainment', 1)\ntest.label = test.label.replace('national', 2)\ntest.label = test.label.replace('sports', 3)\ntest.label = test.label.replace('kolkata', 4)\ntest.label = test.label.replace('state', 5)\ntest.label = test.label.replace('international', 6)\ntest.label = test.label.replace('sport', 7)\ntest.label = test.label.replace('nation', 8)\ntest.label = test.label.replace('world', 9)\ntest.label = test.label.replace('travel', 10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.label.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.append(test)\ndf = train\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom keras.layers import SpatialDropout1D\nfrom keras.utils import to_categorical\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.model_selection import GridSearchCV\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers.embeddings import Embedding\nfrom keras.preprocessing import sequence\nfrom keras.callbacks import EarlyStopping\nfrom sklearn.feature_selection import RFE\nfrom keras.layers import Conv1D\nfrom keras.layers import MaxPooling1D\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The maximum number of words to be used. (most frequent)\nMAX_NB_WORDS = 50000\n# Max number of words in each complaint.\nMAX_SEQUENCE_LENGTH = 250\n# This is fixed.\nEMBEDDING_DIM = 100\ntokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~।', lower=False)\ntokenizer.fit_on_texts(df.article.values)\nword_index = tokenizer.word_index\nvocab_size = len(word_index)\nprint('Found %s unique tokens.' % vocab_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = tokenizer.texts_to_sequences(df.article.values)\nX = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\nprint('Shape of data tensor:', X.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = pd.get_dummies(df.label).values\nprint('Shape of label tensor:', Y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features, test_features, train_labels, test_labels = train_test_split(X, Y, test_size=.10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Note this is the 100 dimension version of GloVe from Stanford\n# It was unzipped and hosted on a  site to make this notebook easier\n!wget --no-check-certificate \\\n    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/glove.6B.100d.txt \\\n    -O /tmp/glove.6B.100d.txt\nembeddings_index = {};\nwith open('/tmp/glove.6B.100d.txt') as f:\n    for line in f:\n        values = line.split();\n        word = values[0];\n        coefs = np.asarray(values[1:], dtype='float32');\n        embeddings_index[word] = coefs;\n\nembeddings_matrix = np.zeros((vocab_size+1, EMBEDDING_DIM));\nfor word, i in word_index.items():\n    embedding_vector = embeddings_index.get(word);\n    if embedding_vector is not None:\n        embeddings_matrix[i] = embedding_vector;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(embeddings_matrix))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Embedding(vocab_size+1, EMBEDDING_DIM, input_length=X.shape[1], weights=[embeddings_matrix]))\n# experiment with combining different types, such as convolutions and LSTMs\nmodel.add(tf.keras.layers.Dropout(0.2))\nmodel.add(tf.keras.layers.Conv1D(100, 5, activation='relu'))\nmodel.add(tf.keras.layers.MaxPooling1D(pool_size=4))\nmodel.add(tf.keras.layers.LSTM(100))\nmodel.add(tf.keras.layers.Dense(10, activation='softmax'))\n    \nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy']) \nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"\nmodel = Sequential()\nmodel.add(Embedding(vocab_size+1, EMBEDDING_DIM, input_length=X.shape[1], weights=[embeddings_matrix], trainable=False))\nmodel.add(Dropout(0.2))\nmodel.add(Conv1D(100, 5, activation='sigmoid'))\nmodel.add(MaxPooling1D(pool_size=4))\nmodel.add(LSTM(100))\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nprint(model.summary())"},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 50\nbatch_size = 16\n\nhistory = model.fit(train_features, train_labels, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)], verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accr = model.evaluate(test_features,test_labels)\nprint('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nplt.title('Loss')\nplt.plot(history.history['loss'], label='train')\nplt.plot(history.history['val_loss'], label='test')\nplt.legend()\nplt.show()\nplt.title('Accuracy')\nplt.plot(history.history['accuracy'], label='train')\nplt.plot(history.history['val_accuracy'], label='test')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights('bengali_news_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news = [\"\"\"‘বন্ধুত্ব’ করিয়ে দেওয়ার টোপ দিয়ে টাকা হাতানোর অভিযোগে ১৬ জনকে গ্রেফতার করল কলকাতা পুলিশের সাইবার ক্রাইম থানা। ধৃতদের মধ্যে ন’জন পুরুষ এবং সাতজন মহিলা। তাদের মঙ্গলবার ব্যাঙ্কশাল আদালতে তোলা হলে বিচারক ১৫ মে পর্যন্ত পুলিশি হেফাজতের নির্দেশ দিয়েছেন।\\\n    পুলিশ জানিয়েছে, অভিযুক্তেরা বিভিন্ন সংবাদপত্রে ‘এসকর্ট সার্ভিসে’র বিজ্ঞাপন দিত। মহিলাদের সঙ্গে ‘বন্ধুত্ব’ করে লোভনীয় উপার্জনের হাতছানি থাকত সেইসব বিজ্ঞাপনে। এই কাজের জন্য গাড়ি করে নিয়ে যাওয়া এবং বাড়িতে পৌঁছে দেওয়ার ব্যবস্থাও আছে বলে লেখা থাকত সেখানে। যোগাযোগের জন্য দু’টি মোবাইল নম্বরও দেওয়া থাকত। ওই নম্বরে যোগাযোগ করলে ব্যাঙ্ক অ্যাকাউন্টে একাধিকবার বিভিন্ন খাতে টাকা জমা দিতে বলা হতো।\n    অ্যাকাউন্টে টাকা পৌঁছে গেলেই সাইবার ক্রাইম থানার পুলিশ আধিকারিক পরিচয় দিয়ে প্রতারণাচক্রের এক ব্যক্তি ফোন করত সংশ্লিষ্ট আবেদনকারীকে। ফোনে গ্রেফতারির হুমকির পাশাপাশি, ২০ হাজার টাকা দাবি করা হতো বলে অভিযোগ। \\\n    এই প্রতারণাচক্রের খপ্পরে পড়া মুচিপাড়া এলাকার এক বাসিন্দা এপ্রিল মাসে পুলিশের কাছে অভিযোগ দায়ের করেছিলেন। অভিযোগের ভিত্তিতে তদন্ত করতে গিয়ে কসবার রাজডাঙায় একটি ফ্ল্যাটের সন্ধান মেলে। সোমবার রাতে সেখানে হানা দিয়ে অভিযুক্তদের গ্রেফতার করা হয়। ধৃতদের কাছ থেকে ৫৩টি মোবাইল ফোন, ৭৫টি সিম কার্ড, দু’টি কর্ডলেস ফোন, একাধিক রাবার স্ট্যাম্প এবং একটি গাড়ি বাজেয়াপ্ত করেছে পুলিশ।  \n       \"\"\"]\nseq = tokenizer.texts_to_sequences(news)\npadded = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH)\npred = model.predict(padded)\nlabels = ['entertainment', 'national', 'sports', 'kolkata', 'state','international', 'sport', 'nation', 'world', 'travel']\nlabel = pred, labels[np.argmax(pred)]\nprint(\"News Label Is: \")\nprint(label[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}