{"cells":[{"metadata":{"collapsed":true,"_uuid":"22723fcb1b8d92fdd6cbff760e64764aa0c5a0a1"},"cell_type":"markdown","source":"# 1. Introduction\n"},{"metadata":{"_uuid":"e0aa35b1d6b8590ad3726b74fa27018c3a89fd43"},"cell_type":"markdown","source":"In this work, I'm going to predict the house pricing in U.S. I'm going to provide multiple solutions for this project by trying different algorithms in order to get better result. This is supervised approch, we will start from Linear regression and go to more advaced ways for instance Random Forest. This work depnds on House Sales in King County, USA. This dataset is provided by kaggle.com | https://www.kaggle.com/harlfoxem/housesalesprediction/data\n"},{"metadata":{"_uuid":"4052e13a6928a8653ac408b705cd745a22d7aa80"},"cell_type":"markdown","source":"# 2. Dependencies¶\n"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"409561efd02d6aff29bbb199bbdc59684ae5c6b2"},"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.ensemble import ExtraTreesRegressor,GradientBoostingRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import validation_curve\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import cross_val_score\n","execution_count":1,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0fcd1f0ce3d7344069af6469967b3667ce1c507","_kg_hide-input":true},"cell_type":"code","source":"DOWNLOAD_ROOT = \"../input/kc_house_data.csv\"\n\ndef create_dataframe(data_path):\n    df = pd.read_csv(data_path)\n    return df","execution_count":22,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a34429068c90833f830d4ee0f8068fcdc8d090d5","scrolled":true},"cell_type":"code","source":"housing = create_dataframe(DOWNLOAD_ROOT)\nhousing.head()","execution_count":23,"outputs":[]},{"metadata":{"_uuid":"0446b8dc408e7c9e3a9fd5b34d33529c849320ea"},"cell_type":"markdown","source":"# 3. Data exploratory¶\n"},{"metadata":{"trusted":true,"_uuid":"fd233e8e6d796191b6939b0b5abe7252fed7ec4c"},"cell_type":"code","source":"housing.info()\n","execution_count":24,"outputs":[]},{"metadata":{"_uuid":"da74cc07a1213a313da84370d15ae83907165b5d"},"cell_type":"markdown","source":"as we can see the data contains 21 columns such as date, price, floors ...etc.\n\n"},{"metadata":{"_uuid":"be7afb83151021e710bb6c900a21d024e5dc2b1b"},"cell_type":"markdown","source":"lets see if we have any missing value or null\n\n"},{"metadata":{"trusted":true,"_uuid":"de8e6ac2718d36aeafa47b7f0d15f843bc5c56a8"},"cell_type":"code","source":"print(housing.isnull().any())\n","execution_count":25,"outputs":[]},{"metadata":{"_uuid":"16ed323bc33c956190f0fd059d924ec9a9ab0c0e"},"cell_type":"markdown","source":"It seems the data is almost clean no missing values\n\n"},{"metadata":{"trusted":true,"_uuid":"79a97fb40cdeca8ab1e61754cef3224908f685f6"},"cell_type":"code","source":"with sns.plotting_context(\"notebook\",font_scale=2.5):\n    g = sns.pairplot(housing[['sqft_lot','sqft_above','price','sqft_living','bedrooms']], \n                 hue='bedrooms', palette='tab20',size=6)\ng.set(xticklabels=[])","execution_count":26,"outputs":[]},{"metadata":{"_uuid":"b7865ca9b82b7f1685f62e45ccf8b3976e6818c2"},"cell_type":"markdown","source":"Seaborn is a Python visualization library based on matplotlib. It provides a high-level interface for drawing attractive statistical graphics(official). As we see we got some linear visulas, so I will try to use some linear model and see what I can get"},{"metadata":{"trusted":true,"_uuid":"3863590d9cbfb857634dcd19d6c117c5f19b3de4"},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nhousing.hist(bins=10, figsize=(20,15))\nplt.show()","execution_count":27,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27608935554a9c5a24544c689a932e381d450bd2"},"cell_type":"code","source":"import seaborn as sns\ncorr = housing.corr()\nsns.heatmap(corr, \n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)","execution_count":28,"outputs":[]},{"metadata":{"_uuid":"6e33007fea25f00300072d69d89d587a37e08e84"},"cell_type":"markdown","source":"As we know the correlation coefficient ranges from –1 to 1, so here we can observe that there is strong postive correlation between price and soqft_lot , between price and grade and between batheroom and soft_living. However, we can see that strong negative correlation between floors and condition. When coefficients close to zero mean that there is no linear correlation such as condition and zipcode."},{"metadata":{"trusted":true,"_uuid":"66614846ec121991ec69f4e433ba5b0862f691c3"},"cell_type":"code","source":"housing.plot(kind=\"scatter\", x=\"long\", y=\"lat\",alpha=0.1)\n","execution_count":29,"outputs":[]},{"metadata":{"_uuid":"27c73ff57423692817e539b4cd1d698525ac7841"},"cell_type":"markdown","source":"# 6. Prepare the data"},{"metadata":{"_uuid":"28652345a5ae06404e98ace53ce2f458abc7a7c4"},"cell_type":"markdown","source":"Now I'm going to split the data into train_set and test_set. I'm going to give the ratio 0.2, meaning that 80% for train_set and 20% for test_set, I will keep the test_set aside in order to test our model, but before that , lets try to scale the data as it is proofed that some algorithms perform well on scaled data. In addition, I will keep copy of data non scaled in order to try it with algorithms which don't perform well on scaled data\n"},{"metadata":{"trusted":true,"_uuid":"bfb1307e6fcd4924b4731bf75e4d57b24c77a787"},"cell_type":"code","source":"#before scaling the data I'm going to deop price col since it is a label then droping date and id since does't make any\nhousing_scaled = housing.drop('price', axis=1)  # drop labels for training set\nhousing_scaled = housing_scaled.drop('date', axis=1)  # drop date  for training set\nhousing_scaled = housing_scaled.drop('id', axis=1)  # drop id  for training set\n\n#extract the labels\nhousing_labels = housing['price'].copy()\n#scale the data with the label\nscaler = preprocessing.StandardScaler().fit(housing_scaled)\nnew_df = scaler.transform(housing_scaled)\nhousing_scaled = pd.DataFrame(data=new_df, index=list(range(len(new_df))), columns=housing_scaled.columns)","execution_count":32,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"868e1c81af4f8b635de036b3bd16763ac923f5c3"},"cell_type":"code","source":"housing_scaled.head()\n\n","execution_count":33,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1c87a67bea8fde8ba029890b3c180f83bc0b2088"},"cell_type":"code","source":"np.random.seed(0) \n#split the data with raito 0.2\nX_train, X_test, y_train, y_test = train_test_split(housing_scaled.values, housing_labels.values, test_size=0.2)\n","execution_count":35,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc514ca4ae13092920fc2f7b47461b6fb0b8aed5"},"cell_type":"code","source":"print (X_train.shape)\nprint (y_train.shape)\nprint (X_test.shape)\nprint (y_test.shape)","execution_count":37,"outputs":[]},{"metadata":{"_uuid":"021effa65931a4fdf8f8ac9616a7e0a98eb764f6"},"cell_type":"markdown","source":"# 7.Select the model and Evaluation¶"},{"metadata":{"_uuid":"ab930fc599c1d289cbc3927aadc9f2794ec1b5e7"},"cell_type":"markdown","source":"# 7.1 linear regression with Ridge regularizer:¶"},{"metadata":{"trusted":true,"_uuid":"d1f61ce6b01485d68a8fa8d682ccb55240dc979f"},"cell_type":"code","source":"from sklearn.linear_model import Ridge\nridge_reg=Ridge(alpha=1,solver=\"cholesky\")\nridge_reg.fit(X_train,y_train)\n\n","execution_count":38,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c669d52810c278da2d0aa74a134232ec6a5da93c"},"cell_type":"code","source":"ridge_reg.score(X_test, y_test)\n\n","execution_count":39,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9765b9f2cf642307a31daf1b91139944455c88de"},"cell_type":"code","source":"ridge_reg.score(X_train, y_train)\n\n","execution_count":40,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f081a582ffd4c9daac601a8ad1438ce81ecb475"},"cell_type":"code","source":"y_pred=ridge_reg.predict(X_test)\nr2_score(y_test, y_pred)\n\n","execution_count":41,"outputs":[]},{"metadata":{"_uuid":"b4cbc4f7af87a49988e927300a3ff806cfdb72f6"},"cell_type":"markdown","source":"# 7.2 KNeighbors¶"},{"metadata":{"trusted":true,"_uuid":"440f14d72fb413a8993d504733d89273b167db7f"},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\nknn_rg = KNeighborsRegressor(n_neighbors=3)\nknn_rg.fit(X_train, y_train)","execution_count":42,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"530f672c235de14565f14d06ac731b0d6f5c47e3"},"cell_type":"code","source":"knn_rg.score(X_test, y_test)\n\n","execution_count":43,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"749053ce801f51c12fa0e42d992841a73dc28877"},"cell_type":"code","source":"knn_rg.score(X_train, y_train)","execution_count":44,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dffd0c81e3f8585ea1bd6179c98b644ae8581b2c"},"cell_type":"code","source":"y_pred=knn_rg.predict(X_test)\nr2_score(y_test, y_pred)\n\n","execution_count":45,"outputs":[]},{"metadata":{"_uuid":"8e1b2a597cd077a6b1b2a09b5e662a9ad025b009"},"cell_type":"markdown","source":"# 7.3 Trainig with SGD¶"},{"metadata":{"trusted":true,"_uuid":"58717f854b6593ee9fe3b2483576b03d901cb636"},"cell_type":"code","source":"from sklearn.linear_model import SGDRegressor\n#trying SGD with penalty l2\nsgd_reg=SGDRegressor(max_iter=500,penalty='l2',eta0=0.1)\nsgd_reg.fit(X_train,y_train.ravel())\n\n","execution_count":46,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bbe41aa5a4669ad5bc27a386555a03b57b143615"},"cell_type":"code","source":"sgd_reg.score(X_test, y_test)\n\n","execution_count":47,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c682b788b062b22151929beaa92f23ef89033c53"},"cell_type":"code","source":"sgd_reg.score(X_train, y_train)\n\n","execution_count":48,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"58f17b2a56e8a3f21cf1dfff1a89048cb3a5faef"},"cell_type":"code","source":"y_pred=sgd_reg.predict(X_test)\nr2_score(y_test, y_pred)\n\n","execution_count":49,"outputs":[]},{"metadata":{"_uuid":"155bbf1aa44a3b8b580ab8ae003153f2fc9a7121"},"cell_type":"markdown","source":"# 7.4 RandomForestRegressor:¶"},{"metadata":{"trusted":true,"_uuid":"2f01e4346f1ba2c88599c97f582bf1318fa5b94e"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nforest_reg_clf = RandomForestRegressor(random_state=0)\nforest_reg_clf.fit(X_train,y_train)\n\n","execution_count":50,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9686e1c5d5e3dfec604656dda0b0c0ed392ee430"},"cell_type":"code","source":"forest_reg_clf.score(X_test, y_test)\n\n","execution_count":51,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0bcee86b2ea76b16167fcd00e09a95b309258d7"},"cell_type":"code","source":"forest_reg_clf.score(X_train, y_train)\n\n","execution_count":52,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69aee7f8ac6d08c072d024fa3e00fa236ad79f0e"},"cell_type":"code","source":"y_pred=forest_reg_clf.predict(X_test)\nr2_score(y_test, y_pred)\n\n","execution_count":53,"outputs":[]},{"metadata":{"_uuid":"b0dabec80420abfba6efdc27cedf34fbe172a52f"},"cell_type":"markdown","source":"# 7.5 RandomForestRegressor with GridSearchCV¶"},{"metadata":{"trusted":true,"_uuid":"4e6d2c369af5ed8491f4c042476fcbddf3cb5e63"},"cell_type":"code","source":"param_grid=[\n{'n_estimators':[3,10,30,40,50],\t'max_features':[10,14,18]},\n{'n_estimators':[3,10],'max_features':[14,18]}]\nforest_reg=RandomForestRegressor(random_state=0,n_jobs=-1)\nrnd_grid_search=GridSearchCV(forest_reg,param_grid,cv=10)\nrnd_grid_search.fit(X_train,y_train)\n\n","execution_count":54,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b7eb686937d2bb812c45a5869b1923dba7df2f0"},"cell_type":"code","source":"rnd_grid_search.cv_results_['mean_test_score']\n\n","execution_count":55,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0a09487abac664a00b1f9cecf7a66db65dd49fd"},"cell_type":"code","source":"rnd_grid_search.cv_results_['mean_train_score']\n\n","execution_count":56,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2912569f31a01ed813381a494f252de96fb32a4b"},"cell_type":"code","source":"rnd_grid_search.score(X_test, y_test)\n\n","execution_count":57,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"72c187d713e357ec145f19231900f328622b691c"},"cell_type":"code","source":"rnd_grid_search.score(X_train, y_train)\n\n","execution_count":58,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57cbf06c6886c3d042dcff5dec569b39e63a50f8"},"cell_type":"code","source":"y_pred=rnd_grid_search.predict(X_test)\nr2_score(y_test, y_pred)\n\n","execution_count":59,"outputs":[]},{"metadata":{"_uuid":"3159dc12566a54e5d291864bfabc7f93af3873d6"},"cell_type":"markdown","source":"# 7.6 GradientBoostingRegressor:¶"},{"metadata":{"_uuid":"2d0e320adf0f7e43f8814ce55e9eb20db7813539"},"cell_type":"markdown","source":"trains a GBRT ensemble with 120 trees, then measures the validation error at each stage of training to find the optimal number of trees, and finally trains another GBRT ensemble using the optimal number of trees\n"},{"metadata":{"trusted":true,"_uuid":"8449b1c760822bb6e73cf91ec99bc1a60cc1bdd1"},"cell_type":"code","source":"gbrt=GradientBoostingRegressor(max_depth=3,\tn_estimators=120)\ngbrt.fit(X_train,y_train)\nerrors=[mean_squared_error(y_test,y_pred)\nfor y_pred in gbrt.staged_predict(X_test)]\nbst_n_estimators=np.argmin(errors)\nparam_grid=[\n{'n_estimators':[bst_n_estimators],'max_features':[2,4,6,8],'max_depth':[1,2,3],'learning_rate':[0.1,0.2,0.5],'random_state':[0]}]\n\ngbrt_best=GradientBoostingRegressor()\ngbrt_grid_search=GridSearchCV(gbrt_best,param_grid,cv=5)\n\ngbrt_grid_search.fit(X_train,y_train)\n\n","execution_count":60,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc1d48fdf028cdd1ea4e1b34c805b6303b9b5ff7"},"cell_type":"code","source":"gbrt_grid_search.cv_results_['mean_test_score']\n\n","execution_count":61,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c3280c1a2f6020f00bf0db44133b507699c2f02"},"cell_type":"code","source":"gbrt_grid_search.cv_results_['mean_train_score']\n\n","execution_count":62,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5d49d6b3abe4b102af2a4eb7afa6e554ef080d1"},"cell_type":"code","source":"gbrt_grid_search.score(X_test, y_test)\n\n","execution_count":63,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d38e091ca235f5c41be0914603e1911c45013530"},"cell_type":"code","source":"gbrt_grid_search.score(X_train, y_train)\n\n","execution_count":64,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0ae6693611dede7922eefa2427d5ef550e91655"},"cell_type":"code","source":"y_pred=gbrt_grid_search.predict(X_test)\nr2_score(y_test, y_pred)\n\n","execution_count":65,"outputs":[]},{"metadata":{"_uuid":"28c78ae7214dedf1b0bdfb1a53f6348eca3c0907"},"cell_type":"markdown","source":"# 7.7 Extra Trees Regressor¶"},{"metadata":{"_uuid":"20ba6611c55d7ef270cb354946fd8387401ef543"},"cell_type":"markdown","source":"Extra tree trades more bias for a lower variance. It also makes Extra-Trees much faster to train than regular Random Forests since finding the best possible threshold for each feature at every node is one of the most time-consuming tasks of growing a tree\n"},{"metadata":{"trusted":true,"_uuid":"143cf10204d439a77496fb34b73bea803ae075d8"},"cell_type":"code","source":"param_grid=[\n{'n_estimators':[3,10,30,40,50],'max_features':[2,4,6,8]},\n{'n_estimators':[3,10],'max_features':[2,3,4]}]\nforest_reg_extra=ExtraTreesRegressor()\nrnd_grid_search_extra=GridSearchCV(forest_reg_extra,param_grid,cv=10)\nrnd_grid_search_extra.fit(X_train,y_train)\n\n","execution_count":66,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9bf35c46f259ce65d59544b55321b3254ad6e219"},"cell_type":"code","source":"rnd_grid_search_extra.cv_results_['mean_test_score']\n\n","execution_count":67,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3b060d438b953d761064efd46e062c2d4e64803"},"cell_type":"code","source":"rnd_grid_search_extra.cv_results_['mean_train_score']\n\n","execution_count":68,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36f7bef3592e04d1df6189c489291126117d4a01"},"cell_type":"code","source":"rnd_grid_search_extra.score(X_test, y_test)\n\n","execution_count":69,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"106acac4795f45e5f37994468473053972087a8c"},"cell_type":"code","source":"rnd_grid_search_extra.score(X_train, y_train)\n\n","execution_count":70,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"473525b233a2835202d16196eb4d683ec5552996"},"cell_type":"code","source":"y_pred=rnd_grid_search_extra.predict(X_test)\nr2_score(y_test, y_pred)\n\n","execution_count":71,"outputs":[]},{"metadata":{"_uuid":"f559ab3113e9739b7e6450f358677ee01580b1c6"},"cell_type":"markdown","source":"# 8.Discussion¶"},{"metadata":{"_uuid":"5b9c45fbdc10409feb30c86eca24a45533c01e7b"},"cell_type":"markdown","source":"# 8.1 linear regression with Ridge regularizer:¶"},{"metadata":{"_uuid":"b7eb5100f99db797225993f34fb5bee4ebdf6003"},"cell_type":"markdown","source":"First of all, the first model trained is linear regression with ridge regularization, but as we have seen we got very bad accuracy about 69% lets try to pot the actual value and predicted value to see what is happing "},{"metadata":{"trusted":true,"_uuid":"8909e9d3ece92e29d6e63a2c1705eba0a7b3130c"},"cell_type":"code","source":"# Visualising the results\nhousing_predictions_ridge_reg=ridge_reg.predict(X_test)\nplt.plot(y_test, color = 'red', label = 'house Price')\nplt.plot(housing_predictions_ridge_reg, color = 'blue', label = 'Predicted house Price')\nplt.title(' house Price Prediction')\n\nplt.legend()\nplt.show()\n\n","execution_count":72,"outputs":[]},{"metadata":{"_uuid":"d53c250ae31859992bc78c5079e66759a1a07457"},"cell_type":"markdown","source":"ok as we can see the model is not predicting very well because the model is too simple,lets try to plot residual(The difference between the observed value of the dependent variable (y) and the predicted value (ŷ) is called the residual)\n"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6a373d2ed959764be8ae9a8628204d6daedbb2d6"},"cell_type":"code","source":"housing_predictions=ridge_reg.predict(X_test)\n\n","execution_count":73,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9a10113eb17a46b382bb21cf441e6533c458a38"},"cell_type":"code","source":"# housing_predictions=ridge_reg.predict(X_test)\nhousing_predictions_train=ridge_reg.predict(X_train)\nplt.scatter(housing_predictions_train, housing_predictions_train - y_train, c = \"blue\", marker = \"s\", label = \"Training data\")\nplt.scatter(housing_predictions, housing_predictions - y_test, c = \"lightgreen\", marker = \"s\", label = \"Validation data\")\nplt.title(\"Linear regression\")\nplt.xlabel(\"Predicted values\")\nplt.ylabel(\"Residuals\")\nplt.legend(loc = \"upper left\")\nplt.hlines(y = 0, xmin = 11.5, xmax = 15.5, color = \"red\")\nplt.show()\n\n","execution_count":74,"outputs":[]},{"metadata":{"_uuid":"2425e2dbcad902ce700fb8a0a294f868978f4244"},"cell_type":"markdown","source":"The residual plot shows a fairly random pattern,This random pattern indicates that a linear model provides a decent fit to the data. As we see here not extacly random that means our data not pure linear\n"},{"metadata":{"_uuid":"07e7f944aeab682176d466ab388971bbb74cdec9"},"cell_type":"markdown","source":"# 8.2 KNeighbors¶"},{"metadata":{"_uuid":"9cad78a3efd55fe5529ed6986edb68db9d92e452"},"cell_type":"markdown","source":"The second model is KNN,here we got accuracy about 78%\n"},{"metadata":{"trusted":true,"_uuid":"c8885fff6005691dad68590e5ce142efc7f80e43"},"cell_type":"code","source":"# Visualising the results\nhousing_predictions_knn_rg=knn_rg.predict(X_test)\nplt.plot(y_test, color = 'red', label = 'house Price')\nplt.plot(housing_predictions_knn_rg, color = 'blue', label = 'Predicted house Price')\nplt.title(' house Price Prediction')\n\nplt.legend()\nplt.show()\n\n","execution_count":75,"outputs":[]},{"metadata":{"_uuid":"53c07cf541b38db2694417d8ad8defa1cf345f3d"},"cell_type":"markdown","source":"Well it is better than linear regression, but still this model not predicting very well. For example the prices which as above 5 milion but KNN predict them as 2.5 million\n"},{"metadata":{"_uuid":"696a08b53d8adb6ac61f856f9b3ed9dea5764e92"},"cell_type":"markdown","source":"# 8.3 GradientBoostingRegressor"},{"metadata":{"_uuid":"50d31dc6a88cf929c4b3d950eda98a1276dd55c0"},"cell_type":"markdown","source":"As mentioned, I trained a GBRT ensemble with 120 trees, then measures the validation error at each stage of training to find the optimal number of trees, and finally trains another GBRT ensemble using the optimal number of trees\n"},{"metadata":{"trusted":true,"_uuid":"ff3b7acf8eeffb28900fea9cd3bd5fb831deab57"},"cell_type":"code","source":"gbrt_grid_search.best_estimator_\n\n","execution_count":76,"outputs":[]},{"metadata":{"_uuid":"be011225bfb8a13f7bd0887bae9a67bacff108ea"},"cell_type":"markdown","source":"# 8.4 RandomForestRegressor¶"},{"metadata":{"_uuid":"87a20f65a71ddf10b5744cd2fa4f335a057a0616"},"cell_type":"markdown","source":"Finally, It seems that Random Forest Model predict very well without overfitting. Because this model consist of ensemble meaning that it contains many decision trees which make it very powerfull.Lets try to plot the actual values and predicted values\n"},{"metadata":{"trusted":true,"_uuid":"cee91efd63ea2acf4eb924bc87a8fc5cd73a17ac"},"cell_type":"code","source":"# Visualising the results\nhousing_predictions_forest_reg_clf=forest_reg_clf.predict(X_test)\nplt.plot(y_test, color = 'red', label = 'house Price')\nplt.plot(housing_predictions_forest_reg_clf, color = 'blue', label = 'Predicted house Price')\nplt.title(' house Price Prediction')\n\nplt.legend()\nplt.show()\n\n","execution_count":77,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef5ef477d3894a1fe0de042a94c63fd640589a9d"},"cell_type":"code","source":"#plotting a scatter plot between the real price  values and predict price  values\n\nplt.scatter(housing_predictions_forest_reg_clf, y_test, c='red', alpha=0.5)\nplt.show()\n\n","execution_count":78,"outputs":[]},{"metadata":{"_uuid":"131751ecb0420beb2b07f1e76e492349af8ce72a"},"cell_type":"markdown","source":"For better evaluation and in order to avoid any overfitting, I have tried Random Forest with Cross Validation and Grid Search\n"},{"metadata":{"trusted":true,"_uuid":"3ea5444af9b989f8f3bf0f5f1154da0507f9462f"},"cell_type":"code","source":"# Visualising the results\nhousing_predictions_rnd_grid_search=rnd_grid_search.predict(X_test)\nplt.plot(y_test, color = 'red', label = 'house Price')\nplt.plot(housing_predictions_rnd_grid_search, color = 'blue', label = 'Predicted house Price')\nplt.title(' house Price Prediction')\n\nplt.legend()\nplt.show()\n\n","execution_count":79,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"605351f3b947f1009b4c75cc37fd8059b7ef8b53"},"cell_type":"code","source":"#plotting a scatter plot between the real price  values and predict price  values\n\nplt.scatter(housing_predictions_rnd_grid_search, y_test, c='red', alpha=0.5)\nplt.show()\n\n","execution_count":80,"outputs":[]},{"metadata":{"_uuid":"7d5949a9f1b56e082499760270ba195dff4236c6"},"cell_type":"markdown","source":"Ok, it seems the pervious model is overfitting, here we can see the best hyperparametes\n"},{"metadata":{"trusted":true,"_uuid":"35b36d75fef7259f49a128fdbf3596e0433a9f6c"},"cell_type":"code","source":"rnd_grid_search.best_estimator_\n\n","execution_count":81,"outputs":[]},{"metadata":{"_uuid":"35f4f662af46592808bb1288519e2db4ae213741"},"cell_type":"markdown","source":"# 9. Conclusion\n\n\n\n\n\n\nIn this work, I tried multiple algorithms such as linear regression with Ridge regularizer and I got performance around 69% which is poor result. Moreover, I tried KNN algorithm, the performance increased to 77%. However. In RandomForestRegressor with best hyperparameters and cross validation, I achieved good improvment when I got accuracy about 89%.\n"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"097cb0dad0ae808c06d0b53c188b9ae5f3fadba7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}