{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/amazonearphonesreviews/AllProductReviews.csv\")\nprint(df.shape)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df[\"ReviewStar\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use the gensim library to prepare data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from gensim.parsing.preprocessing import preprocess_string, strip_punctuation, strip_short\nfrom gensim.parsing.preprocessing import strip_multiple_whitespaces, strip_numeric, remove_stopwords\n#import spacy\n\n#nlp = spacy.load(\"en_core_web_sm\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews = df[\"ReviewBody\"].values.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CUSTOM_FILTERS = [lambda x: x.lower(), strip_punctuation,\n                  strip_numeric]\n\ntexts = [preprocess_string(review, CUSTOM_FILTERS) for review in reviews]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load the glove model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import gensim.downloader as api\nglove = api.load('glove-wiki-gigaword-300')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For each review, for each token, get the word vector, then compute the average and append to list X.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = []\n\nfor text in texts:\n    vecs = []\n    for word in text:\n        try:\n            vecs.append(glove[word])\n        except:\n            continue\n    X.append(np.mean(vecs, axis = 0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Each average word vector has dimension 300.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X[0].shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some reviews have 0 words after processing. Fill-in these reviews with zeros.","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"missing_indices = []\n\nfor i in range(len(X)):\n    if X[i].shape != (300,):\n        missing_indices.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(missing_indices))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx in missing_indices:\n    X[idx] = np.zeros(shape = (300,))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To boost performance, use predictions from Vader as features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nnltk.download('vader_lexicon')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.sentiment.vader import SentimentIntensityAnalyzer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sia = SentimentIntensityAnalyzer()\nss = sia.polarity_scores(reviews[0])\nprint(ss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(X)):\n    ss = sia.polarity_scores(reviews[i])\n    ss = list(ss.values())\n    X[i] = np.concatenate((X[i], np.array(ss)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 5 classes to predict.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make a train-validation split.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_validation, y_train, y_validation = train_test_split(X, y, random_state = 34, stratify = y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.array(X).shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use RepeatedStratifiedKFold to estimate model performance on the training set.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\n\npipelines = []\npipelines.append(('Logistic Regression', Pipeline([('imp', SimpleImputer()),\n                                                   ('sc', StandardScaler()),\n                                                   ('LR', SGDClassifier(loss = \"log\"))] )))\npipelines.append(('Support Vector Machine', Pipeline([('imp', SimpleImputer()), \n                                                      ('sc', StandardScaler()),\n                                                      ('SV', SGDClassifier())] )))\npipelines.append(('Naive Bayes', Pipeline([('imp', SimpleImputer()), \n                                           ('sc', StandardScaler()),\n                                           ('NB', GaussianNB())] )))\npipelines.append(('Decision Tree', Pipeline([('imp', SimpleImputer()), \n                                             ('sc', StandardScaler()),\n                                             ('Tree', DecisionTreeClassifier())] )))\n\nresults = []\nnames = []\n\nfor name, model in pipelines:\n    kfold = RepeatedStratifiedKFold(n_splits = 3, random_state = 34)\n    cvresults = cross_val_score(model, X_train, y_train, cv = kfold, scoring = \"accuracy\")\n    results.append(cvresults)\n    names.append(name)\n    msg =\"%s: %f (%f)\" % (name, cvresults.mean(), cvresults.std())\n    print(msg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nplt.boxplot(results, labels = names)\nplt.xticks(rotation = 'vertical')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\npipelines = []\npipelines.append(('Support Vector Machine', Pipeline([('imp', SimpleImputer()),\n                                                   ('sc', StandardScaler()),\n                                                   ('SVM', SVC())] )))\npipelines.append(('Random Forest', Pipeline([('imp', SimpleImputer()), \n                                                      ('sc', StandardScaler()),\n                                                      ('RF', RandomForestClassifier())] )))\npipelines.append(('KNN', Pipeline([('imp', SimpleImputer()), \n                                           ('sc', StandardScaler()),\n                                           ('KNN', KNeighborsClassifier())] )))\n\nresults = []\nnames = []\n\nfor name, model in pipelines:\n    kfold = RepeatedStratifiedKFold(n_splits = 3, random_state = 34)\n    cvresults = cross_val_score(model, X_train, y_train, cv = kfold, scoring = \"accuracy\")\n    results.append(cvresults)\n    names.append(name)\n    msg =\"%s: %f (%f)\" % (name, cvresults.mean(), cvresults.std())\n    print(msg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nplt.boxplot(results, labels = names)\nplt.xticks(rotation = 'vertical')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tune the Support Vector Machine model using a randomized search.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Pipeline([('imp', SimpleImputer()),\n                                                   ('sc', StandardScaler()),\n                                                   ('SVM', SVC())] )\nmodel.get_params()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import uniform\n\nparams = {'SVM__C' : uniform(1e-3, 2),\n          'SVM__gamma' : uniform(1e-6, 1)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\nrandom_search = RandomizedSearchCV(model, params, n_iter = 70, cv = 5, random_state = 6)\nrandom_search.fit(X_train, y_train)\n\nprint(\"Best Score: \", random_search.best_score_)\nprint(\"Best Parameters: \", random_search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The default hyperparamters were better than those found in a randomized search.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Fit the model to the training data then estimate performance on the validation set.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ny_pred = model.predict(X_validation)\n\nprint(classification_report(y_validation, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nprint(confusion_matrix(y_validation, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Able to predict 1 and 5 star reviews, but struggle with 2, 3, and 4 star reviews. The model failed to predict a single 2 star review.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}