{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Library imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix, f1_score, accuracy_score\n\nimport warnings\nwarnings.simplefilter(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load the dataset and verify the dataload"},{"metadata":{"trusted":true},"cell_type":"code","source":"strokedf = pd.read_csv(\"../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv\")\n\n# Check the initial rows\nstrokedf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets check the datastructure\nstrokedf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for missing values\n\nstrokedf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Missing value treatment for 'bmi' attribute\n\nThe approach is to substitue mean of the bmi by the target variable - stroke"},{"metadata":{"trusted":true},"cell_type":"code","source":"strokedf['bmi'] = strokedf['bmi'].fillna(strokedf.groupby('stroke')['bmi'].transform('mean'))\n\n# Check whether imputations are done\nstrokedf.isna().sum()\n\n# Another alternate approach\n\n# strokedf[\"bmi\"] = strokedf.groupby(\"stroke\").transform(lambda x: x.fillna(x.mean()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore the target variable\n\nsns.countplot(strokedf['stroke'])\n\nstrokedf['stroke'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### exploration  - gender, hypertension and heart_disease attributes"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Gender by the target variable\")\nprint(strokedf.groupby('stroke')['gender'].value_counts())\nprint(\"\\n\")\nprint(\"hypertension by the target variable\")\nprint(strokedf.groupby('stroke')['hypertension'].value_counts())\nprint(\"\\n\")\nprint(\"heart_disease by the target variable\")\nprint(strokedf.groupby('stroke')['heart_disease'].value_counts())\n\n\n# Doing the visualizations\n\nfig, (ax1, ax2, ax3) = plt.subplots(1,3,figsize=(16,6))\nsns.countplot(x='gender', hue='stroke', data=strokedf, ax=ax1);\nsns.countplot(x='hypertension', hue='stroke', data=strokedf, ax=ax2);\nax2.set_ylabel(\"\")\nsns.countplot(x='heart_disease', hue='stroke', data=strokedf, ax=ax3);\nax3.set_ylabel(\"\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### exploration Age attribute"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore Age attribute\n\nprint(strokedf.groupby('stroke')['age'].mean())\n\n# Explore Age variable with respect to the stroke attribute\nsns.catplot(x=\"stroke\", y=\"age\", kind=\"box\", data=strokedf);\n\ng = sns.FacetGrid(data=strokedf, col='stroke', height=5)\ng.map(sns.distplot, 'age')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore gender and age with respect to stroke and establish any conclusion\n\nsns.catplot(x=\"gender\", y=\"age\", hue='stroke', kind=\"box\", data=strokedf);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### exploration - ever_married, work_type, Residence_type, smoking_status attributes"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"ever_married by the target variable\")\nprint(strokedf.groupby('stroke')['ever_married'].value_counts())\nprint(\"\\n\")\nprint(\"work_type by the target variable\")\nprint(strokedf.groupby('stroke')['work_type'].value_counts())\nprint(\"\\n\")\nprint(\"Residence_type by the target variable\")\nprint(strokedf.groupby('stroke')['Residence_type'].value_counts())\nprint(\"\\n\")\nprint(\"smoking_status by the target variable\")\nprint(strokedf.groupby('stroke')['smoking_status'].value_counts())\n\n\n# Doing the visualizations\n\nfig, (ax1, ax2, ax3, ax4) = plt.subplots(1,4,figsize=(20,6))\nsns.countplot(x='ever_married', hue='stroke', data=strokedf, ax=ax1);\nsns.countplot(x='work_type', hue='stroke', data=strokedf, ax=ax2);\nax2.set_ylabel(\"\")\nsns.countplot(x='Residence_type', hue='stroke', data=strokedf, ax=ax3);\nax3.set_ylabel(\"\")\nsns.countplot(x='smoking_status', hue='stroke', data=strokedf, ax=ax4);\nax4.set_ylabel(\"\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### exploration avg_glucose level"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Explore avg_glucose_level variable with respect to the stroke attribute\n\nprint(strokedf.groupby('stroke')['avg_glucose_level'].mean())\n\nsns.catplot(x=\"stroke\", y=\"avg_glucose_level\", kind=\"box\", data=strokedf);\n\ng = sns.FacetGrid(data=strokedf, col='stroke', height=5)\ng.map(sns.distplot, 'avg_glucose_level')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### exploration bmi attribute"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Explore bmi variable with respect to the stroke attribute\n\nprint(strokedf.groupby('stroke')['bmi'].mean())\n\nsns.catplot(x=\"stroke\", y=\"bmi\", kind=\"box\", data=strokedf);\n\ng = sns.FacetGrid(data=strokedf, col='stroke', height=5)\ng.map(sns.distplot, 'bmi')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modelling - Random Forest"},{"metadata":{},"cell_type":"markdown","source":"### Peform Label Encoder Transformations"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize the label encoder\nlabel_encoder = LabelEncoder() \n\n# Encode labels \nstrokedf['gender'] = label_encoder.fit_transform(strokedf['gender'])\nstrokedf['ever_married'] = label_encoder.fit_transform(strokedf['ever_married'])\nstrokedf['work_type'] = label_encoder.fit_transform(strokedf['work_type'])\nstrokedf['Residence_type'] = label_encoder.fit_transform(strokedf['Residence_type'])\nstrokedf['smoking_status'] = label_encoder.fit_transform(strokedf['smoking_status'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Perform Train , Test Split of the data\n\nSince proportion of the stroke data is less, we will perform a stratified sampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = strokedf.drop('stroke', axis=1)\ntarget = strokedf['stroke']\n\nfeatures_train, features_test, target_train, target_test = train_test_split(features, \n                                                                            target, \n                                                                            test_size=0.3, random_state=101,\n                                                                           stratify = target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Building the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the Random Forest model\nfrom sklearn.ensemble import RandomForestClassifier\n\n# we will build the random forest classifier both using entropy and gini index\nrfc = RandomForestClassifier(n_estimators=100, criterion='entropy')\nrfc.fit(features_train, target_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predictions and Evaluations"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = rfc.predict(features_test)\n\nprint(\"Confusion Matrix - Random Forest Using Gini Index\\n\")\nprint(confusion_matrix(target_test,predictions))\nprint(\"\\n\")\nprint(\"Classification Report \\n\")\nprint(classification_report(target_test,predictions))\nprint(\"\\n\")\nprint(\"Accuracy Score \\n\")\nprint(accuracy_score(target_test, predictions))\nprint(\"\\n\")\nprint(\"F1 Score \\n\")\nprint(f1_score(target_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}