{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nimport warnings\n\nimport os\n\n#Visulization Libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n#importing Machine Learning parameters and classifiers \nimport scipy.stats as stats\nfrom scipy.stats import zscore\n\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_curve,accuracy_score,confusion_matrix,recall_score,precision_score,f1_score, auc\n\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n#Ensemble classifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\nfrom sklearn.ensemble import VotingClassifier","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/bankfullcsv/bank-full.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = [col for col in df.columns]\ncol_with_unknown_value = []\nfor col in cols:\n    if 'unknown' in df[col].values:\n        col_with_unknown_value.append(col)\n        \nprint(\"Columns with Unknown Values -\",col_with_unknown_value)       \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Unknown values count : \\n\")\nfor col in col_with_unknown_value:\n    print(col,\" : \",df[df[col].str.contains('unknown')][col].count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Other values count in attributes having unknown values -\\n\")\nfor col in col_with_unknown_value:\n    print(\"===\",col,\"===\")\n    print(df.groupby(df[col])[col].count(),\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df.columns:\n  print(i,\" :-\")\n  print(df[i].unique())\n  print('==='*25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.apply(lambda x: len(x.unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df.describe()\n#df.describe().transpose()\ndf.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### numerical \nnumerical_cols = list(df.select_dtypes(exclude=['object']))\nnumerical_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[numerical_cols].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### categorical\ncategory_cols = list(df.select_dtypes(include=['object']))\ncategory_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target='Target'\nnon_features=[target]\ncat_features=[col for col in df.select_dtypes('object').columns if col not in non_features]\nnum_features=[col for col in df.select_dtypes(np.number).columns if col not in non_features]\n\nprint(\"Categorical Features :\\n\",cat_features,\"\\n\")\nprint(\"Numerical Features :\\n\",num_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[cat_features].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sns.pairplot(df)\n#plt.show()\n\ng = sns.pairplot(df )\ng.set(xticklabels=[])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\nfor i,col in enumerate(category_cols,start=1):\n    plt.subplot(4,3,i);\n    sns.barplot(df[col].value_counts().values, df[col].value_counts().index)\n    plt.title(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(1,2, figsize=(16,8))\n\ncolors = [\"#FA5858\", \"#64FE2E\"]\nlabels =\"Did not Open Term Suscriptions\", \"Opened Term Suscriptions\"\n\nplt.suptitle('Information on Term Suscriptions', fontsize=20)\n\ndf[\"Target\"].value_counts().plot.pie(explode=[0,0.25], autopct='%1.2f%%', ax=ax[0], shadow=True, colors=colors, \n                                             labels=labels, fontsize=12, startangle=25)\n\n\n# ax[0].set_title('State of Loan', fontsize=16)\nax[0].set_ylabel('% of Condition of Loans', fontsize=14)\n\n# sns.countplot('loan_condition', data=df, ax=ax[1], palette=colors)\n# ax[1].set_title('Condition of Loans', fontsize=20)\n# ax[1].set_xticklabels(['Good', 'Bad'], rotation='horizontal')\npalette = [\"#64FE2E\", \"#FA5858\"]\n\nsns.barplot(x=\"education\", y=\"balance\", hue=\"Target\", data=df, palette=palette, estimator=lambda x: len(x) / len(df) * 100)\nax[1].set(ylabel=\"(%)\")\nax[1].set_xticklabels(df[\"education\"].unique(), rotation=0, rotation_mode=\"anchor\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('seaborn-whitegrid')\n\ndf.hist(bins=20, figsize=(15,10), color='red')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nfor i,col in enumerate(num_features,start=1):\n    plt.subplot(3,3,i);\n    sns.boxplot(y=df[col],x=df[target]);\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df.education.replace('unknown',df.education.mode()[0],inplace=True)\n\ndf.loc[(df['age']>60) & (df['job']=='unknown'), 'job'] = 'retired'\n\ndf.loc[(df['education']=='unknown') & (df['job']=='management'), 'education'] = 'tertiary'\ndf.loc[(df['education']=='unknown') & (df['job']=='services'), 'education'] = 'secondary'\ndf.loc[(df['education']=='unknown') & (df['job']=='housemaid'), 'education'] = 'primary'\n\ndf.loc[(df['job'] == 'unknown') & (df['education']=='basic.4y'), 'job'] = 'blue-collar'\ndf.loc[(df['job'] == 'unknown') & (df['education']=='basic.6y'), 'job'] = 'blue-collar'\ndf.loc[(df['job'] == 'unknown') & (df['education']=='basic.9y'), 'job'] = 'blue-collar'\ndf.loc[(df['job']=='unknown') & (df['education']=='professional.course'), 'job'] = 'technician'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['job'] = df.job.replace('unknown',df.job.mode()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['education'] = df.education.replace('unknown',df.education.mode()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Other values count in attributes having unknown values -\\n\")\nfor col in col_with_unknown_value:\n    print(\"===\",col,\"===\")\n    print(df.groupby(df[col])[col].count(),\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(13,10))\n\nmask = np.zeros_like(df.corr())\nmask[np.triu_indices_from(mask, 1)] = True\n\nsns.heatmap(df.corr(), annot=True,mask=mask, cmap='viridis',linewidths=0.5,ax=ax, fmt='.3f')\n\nrotx = ax.set_xticklabels(ax.get_xticklabels(), rotation=30)\nroty = ax.set_yticklabels(ax.get_yticklabels(), rotation=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[num_features].plot(kind='box',subplots=True, layout=(4,4), fontsize=10, figsize=(16,16));\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nwithOutliers = ['age', 'balance', 'duration', 'campaign','pdays','previous']\n\nIQR=df[withOutliers].describe().T['75%']-df[withOutliers].describe().T['25%']\n\nLW,UW = df[withOutliers].describe().T['25%']-(IQR*1.5),df[withOutliers].describe().T['75%']+(IQR*1.5)\n\n\nfor i in withOutliers:\n    df[i][df[i]>UW[i]]=UW[i];\n    df[i][df[i]<LW[i]]=LW[i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[withOutliers].plot(kind='box',subplots=True, layout=(4,4), fontsize=8, figsize=(14,14));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('seaborn-whitegrid')\n\ndf.hist(bins=20, figsize=(15,10), color='red')\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['duration'] = df['duration'].apply(lambda n:n/60).round(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"duration_campaign = sns.scatterplot(x='duration', y='campaign',data = df,\n                     hue = 'Target')\n\nplt.axis([0,65,0,65])\nplt.ylabel('Number of Calls')\nplt.xlabel('Duration of Calls (Minutes)')\nplt.title('The Relationship between the Number and Duration of Calls')\n# Annotation\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Rows count having call duration less than 10 Sec -\\t',df[df.duration < 10/60]['duration'].count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop rows where call duration was less than 10 seconds\n#dropped 342 rows\ndf = df.drop(df[df.duration < 10/60].index, axis = 0, inplace = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#putting age into bins\ndf.loc[df[\"age\"] < 30,  'age'] = 20\ndf.loc[(df[\"age\"] >= 30) & (df[\"age\"] <= 39), 'age'] = 30\ndf.loc[(df[\"age\"] >= 40) & (df[\"age\"] <= 49), 'age'] = 40\ndf.loc[(df[\"age\"] >= 50) & (df[\"age\"] <= 59), 'age'] = 50\ndf.loc[df[\"age\"] >= 60, 'age'] = 60","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelenc = LabelEncoder()\ndf[category_cols] = df[category_cols].apply(LabelEncoder().fit_transform)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()['Target'][:].plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Target Attribute distribution \\n\")\nprint(df.Target.value_counts(),\"\\n\")\n\nfig,ax= plt.subplots()\nfig.set_size_inches(20,5)\nsns.countplot(x= \"Target\",data=df,ax= ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"per_subs=round((df[df['Target'] == 1]['Target'].value_counts()[1]/df.Target.count())*100, 2)\n\nprint(\"% of clients subscribed for Term Deposite -\\t\",per_subs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(['Target','contact','poutcome'],1)\ny = df['Target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.3, random_state=0)\n\nprint(X_train.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\n#Initialising Logistic Regression\nlr_clf=LogisticRegression()\n\n#Fitting on data\nlr_clf.fit(X_train, y_train)\n\n#Scoring the model on train data\nprint(\"Training Accuracy :\\t \", lr_clf.score(X_train, y_train))\n\n#Scoring the model on test_data\nprint(\"Testing Accuracy :\\t  \",  lr_clf.score(X_test, y_test))\n\ny_pred = lr_clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.confusion_matrix(y_pred, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\n\nclass_label = [\"Positive\", \"Negative\"]\ndf_cm = pd.DataFrame(cm, index = class_label, columns = class_label)\nsns.heatmap(df_cm, annot = True, fmt = \"d\")\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Classification Report\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predictProb = lr_clf.predict_proba(X_train)\n\nfpr, tpr, thresholds = roc_curve(y_train, y_predictProb[::,1])\n\nroc_auc = auc(fpr, tpr)\n\nprint(\"auc :-\",roc_auc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\n\n#Initialising Random Forest model\n#knn_clf = KNeighborsClassifier(n_neighbors=5 , weights = 'distance' )\nknn_clf = KNeighborsClassifier()\n\n#create a dictionary of all values we want to test for n_neighbors\nparams_knn = {'n_neighbors': np.arange(1, 25)}\n\n#use gridsearch to test all values for n_neighbors\nknn_gs = GridSearchCV(knn_clf, params_knn, cv=5)\n\n#Fitting on data\nknn_gs.fit(X_train, y_train)\n\n#Scoring the model on train data\nprint(\"Training Accuracy :\\t \", knn_gs.score(X_train, y_train))\n\n#Scoring the model on test_data\nprint(\"Testing Accuracy :\\t  \",  knn_gs.score(X_test, y_test))\n\n#y_pred = knn_clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#save best model\nknn_best = knn_gs.best_estimator_\n#check best n_neigbors value\nprint(knn_gs.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion matrix\nknn_cm=metrics.confusion_matrix(y_test, knn_gs.predict(X_test))\nknn_cm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion Matrix\nknn_cm=metrics.confusion_matrix(y_test, knn_gs.predict(X_test))\n\nclass_label = [\"Positive\", \"Negative\"]\ndf_cm = pd.DataFrame(knn_cm, index = class_label, columns = class_label)\nsns.heatmap(df_cm, annot = True, fmt = \"d\")\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Classification Report\nprint(classification_report(y_test, knn_gs.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predictProb = knn_gs.predict_proba(X_test)\nfpr, tpr, thresholds = roc_curve(y_test, y_predictProb[::,1])\nroc_auc = auc(fpr, tpr)\nprint(\"auc :-\",roc_auc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = DecisionTreeClassifier()\nknn = KNeighborsClassifier()\nlr = LogisticRegression()\n\ndt.fit(X_train,y_train)\nknn.fit(X_train,y_train)\nlr.fit(X_train,y_train)\n\ndt_score=dt.score(X_test,y_test)\nknn_score=knn.score(X_test,y_test)\nlr_score=lr.score(X_test,y_test)\n\nprint(\"Accuracy Score of Decision Tree -\\t\",dt_score )\nprint(\"Accuracy Score of KNN  -\\t\",knn_score )\nprint(\"Accuracy Score of Logistic Regression -\\t\",lr_score )\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nkfold = model_selection.KFold(n_splits=10, random_state=7)\n#create a new random forest classifier\n#rf = RandomForestClassifier()\n\nmodel = RandomForestClassifier(n_estimators=100, max_features=3)\n#create a dictionary of all values we want to test for n_estimators\nparams_rf = {'n_estimators': [50, 100, 200]}\n\n#use gridsearch to test all values for n_estimators\nrf_gs = GridSearchCV(rf, params_rf, cv=5)\n\n#fit model to training data\n#rf_gs.fit(X_train, y_train)\n#rf_score=rf_gs.score(X_test,y_test)\n\nresults = model_selection.cross_val_score(model, X, y, cv=kfold)\n\nrf_score=results.mean()\n\n\nprint(\"Accuracy Score of Random Classifier -\\t\",rf_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_gs.fit(X_train, y_train)\ny_pred=rf_gs.predict(X_test)\n# Classification Report\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predictProb = rf_gs.predict_proba(X_test)\nfpr, tpr, thresholds = roc_curve(y_test, y_predictProb[::,1])\nroc_auc = auc(fpr, tpr)\nprint(\"auc :-\",roc_auc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\n#model1 = LogisticRegression(random_state=1)\n#model2 = DecisionTreeClassifier(random_state=1)\n#model3 = LogisticRegression()\n#model = VotingClassifier(estimators=[('lr', model1), ('dt', model2),('knn', model3)], voting='hard')\n\nmodel = VotingClassifier(estimators=[('lr', LogisticRegression(random_state=1)), ('dt', DecisionTreeClassifier(random_state=1)),('knn', KNeighborsClassifier())], voting='hard')\nmodel.fit(X_train,y_train)\nvt_score=model.score(X_test,y_test)\n\nprint('Accuracy score of Voting Classifier -\\t',vt_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=model.predict(X_test)\n# Classification Report\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kfold = model_selection.KFold(n_splits=10, random_state=7)\ncart = DecisionTreeClassifier()\n\nmodel = BaggingClassifier(base_estimator=cart, n_estimators=100, random_state=7)\n\n#model.fit(X_train,y_train)\n#bg_clf=model.score(X_test,y_test)\n#print('Accuracy score of Bagging Decision Tree Classifier -\\t', bg_clf)\n\n\nresults = model_selection.cross_val_score(model, X, y, cv=kfold)\nbg_score=results.mean()\n\nprint('Accuracy score of Bagging Decision Tree Classifier -\\t', bg_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train,y_train)\ny_pred=model.predict(X_test)\n# Classification Report\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predictProb = model.predict_proba(X_test)\nfpr, tpr, thresholds = roc_curve(y_test, y_predictProb[::,1])\nroc_auc = auc(fpr, tpr)\nprint(\"auc :-\",roc_auc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\nkfold = model_selection.KFold(n_splits=10, random_state=7)\n\nmodel = AdaBoostClassifier(n_estimators=30, random_state=7)\n\n#model.fit(X_train,y_train)\n#ab_clf=model.score(X_test,y_test)\n#print('Accuracy score of Adaboost Classifier -\\t', ab_clf)\n\nresults = model_selection.cross_val_score(model, X, y, cv=kfold)\nab_score=results.mean()\n\nprint('Accuracy score of Adaboost Classifier -\\t', ab_score)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train,y_train)\ny_pred=model.predict(X_test)\n# Classification Report\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predictProb = model.predict_proba(X_test)\nfpr, tpr, thresholds = roc_curve(y_test, y_predictProb[::,1])\nroc_auc = auc(fpr, tpr)\nprint(\"auc :-\",roc_auc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\ngb_clf = GradientBoostingClassifier(n_estimators = 50, learning_rate = 0.1, random_state=22)\ngbcl = gb_clf.fit(X_train, y_train)\n\npred_GB =gb_clf.predict(X_test)\ngb_score = accuracy_score(y_test, pred_GB)\n\nprint('Accuracy score of GradientBoost Classifier -\\t', gb_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}