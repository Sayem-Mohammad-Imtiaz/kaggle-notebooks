{"cells":[{"metadata":{},"cell_type":"markdown","source":"<div class=\"dataset-header-v2__top-image-container\">\n    <img src=\"https://storage.googleapis.com/kaggle-datasets-images/312305/633246/752964d08f6001573444649668b0b011/dataset-cover.jpg?t=2019-08-22-03-58-44\" class=\"Header_CoverImg-sc-1431b7d ibFJYv\">\n</div>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom numpy import asarray\nfrom pandas import read_csv\nfrom pandas import DataFrame\nfrom pandas import concat\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Conv1D\nfrom tensorflow.keras.layers import MaxPooling1D, Dense\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 12, 6","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"dataset\" style=\"color:#a97828; background:#4dc5ea;\"> \n    <center>Dataset\n        <a class=\"anchor-link\" href=\"#dataset\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/predict-chargeback-frauds-payment/df.csv', index_col=0)\ndf = shuffle(df)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize(df):\n    return (df - df.mean()) / df.std()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[['Card Number', 'Date', 'Amount', 'CBK',]]\n\ncard_numbers_to_idx = { v:k for k,v in enumerate(np.unique(df['Card Number'].values))}\ndf['Card Number'].replace(card_numbers_to_idx, inplace=True)\ndf['Card Number'] = normalize(df['Card Number'])\n\ndf['Date'] = pd.to_datetime(df['Date']).astype(int)\ndf['Date'] = normalize(df['Date'])\n\ndf['Amount'] = normalize(df['Amount'])\n\ndf.replace({'No': 0, 'Yes': 1}, inplace=True)\ndata = df.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n    n_vars = 1 if type(data) is list else data.shape[1]\n    df = DataFrame(data)\n    cols = list()\n    # input sequence (t-n, ... t-1)\n    for i in range(n_in, 0, -1):\n        cols.append(df.shift(i))\n    # forecast sequence (t, t+1, ... t+n)\n    for i in range(0, n_out):\n        cols.append(df.shift(-i))\n    # put it all together\n    agg = concat(cols, axis=1)\n    # drop rows with NaN values\n    if dropnan:\n        agg.dropna(inplace=True)\n    return agg.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = series_to_supervised(data, n_in=6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"models\" style=\"color:#a97828; background:#4dc5ea;\"> \n    <center>Models\n        <a class=\"anchor-link\" href=\"#models\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"class RandomForest():\n    def __init__(self):\n        self.n_estimators = 500\n        self.model = RandomForestRegressor(n_estimators=self.n_estimators)\n        \n    def train(self, train):\n        train = asarray(train)\n        X_train, y_train = train[:, :-1], train[:, -1]\n        self.model.set_params(n_estimators=self.n_estimators)\n        self.model.fit(X_train, y_train)\n        self.n_estimators += 500\n    \n    def predict(self, test):\n        yhat = self.model.predict([test])\n        return yhat[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Xgboost():\n    def __init__(self):\n        self.n_estimators = 500\n        self.model = XGBRegressor(objective='reg:squarederror',\n                                  n_estimators=500)\n        \n    def train(self, train):\n        train = asarray(train)\n        X_train, y_train = train[:, :-1], train[:, -1]\n        self.model.set_params(n_estimators=self.n_estimators)\n        self.model.fit(X_train, y_train)\n        self.n_estimators += 500\n        \n    def predict(self, test):\n        y_hat = self.model.predict(asarray([test]))\n        return y_hat[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CNN():\n    def __init__(self):\n        self.n_in, self.n_out = 27, 1\n        self.model = Sequential()\n        self.model.add(Conv1D(filters=64, kernel_size=2, activation='relu'))\n        self.model.add(MaxPooling1D(pool_size=2))\n        self.model.add(Flatten())\n        self.model.add(Dense(50, activation='relu'))\n        self.model.add(Dense(self.n_out))\n        self.model.compile(optimizer='adam', loss='mse')\n        \n    def train(self, train):\n        train = asarray(train)\n    \n        X_train, y_train = train[:, :-1], train[:, -1]\n\n        n_features = X_train.shape[1]\n        X_train = X_train.reshape(len(X_train), self.n_in, 1)\n        \n        self.model.fit(X_train, y_train, epochs=500, verbose=0)\n        \n    def predict(self, test):\n        y_hat = self.model.predict(test.reshape(1, len(test), 1))\n        return y_hat[0][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_forest = RandomForest()\nxgboost = Xgboost()\ncnn = CNN()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_models():\n    models = []\n    models.append(('random_forest', random_forest))\n    models.append(('xgboost', xgboost))\n    models.append(('cnn', cnn))\n    return models","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"training\" style=\"color:#a97828; background:#4dc5ea;\"> \n    <center>Training\n        <a class=\"anchor-link\" href=\"#training\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_test_split(data, n_test):\n    return data[:-n_test, :], data[-n_test:, :]\n\ndef training(data, n_test, n_models):\n    preds = [list() for a in range(n_models)]\n    train, test = train_test_split(data, n_test)\n\n    history = [x for x in train]\n    for i in range(len(test)):\n        X_test, y_test = test[i, :-1], test[i, -1]\n        models = get_models()\n        for j, (name, model) in enumerate(models):\n            model.train(history)\n            y_hat = model.predict(X_test)\n            preds[j].append(y_hat)\n            if(i % 2 == 0):\n                print('i:{:3d}, Model:{:13s}, Expected:{:.1f}, Predicted:{:.1f}'\n                      .format(i, name, y_test, y_hat))\n            \n        history.append(test[i])\n    \n    errors = [list() for a in range(n_models)]\n    for i, error in enumerate(errors):\n        errors[i] = mean_absolute_error(test[:, -1], preds[i])\n    return errors, test[:, -1], preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 20\nmae, y, y_hat = training(data, epochs, 3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"analysis\" style=\"color:#a97828; background:#4dc5ea;\"> \n    <center>Analysis\n        <a class=\"anchor-link\" href=\"#analysis\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Random Forest MAE: %.3f' % mae[0])\nprint('XGBoost MAE: %.3f' % mae[1])\nprint('CNN MAE: %.3f' % mae[2])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 5))\naxes[0].set_title(\"Random Forest\")\naxes[0].plot(y, label='Expected')\naxes[0].plot(y_hat[0], label='Predicted')\naxes[0].legend()\naxes[1].set_title(\"XGBoost\")\naxes[1].plot(y, label='Expected')\naxes[1].plot(y_hat[1], label='Predicted')\naxes[1].legend()\naxes[2].set_title(\"CNN\")\naxes[2].plot(y, label='Expected')\naxes[2].plot(y_hat[2], label='Predicted')\naxes[2].legend()\n#fig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 id=\"predict\" style=\"color:#a97828; background:#4dc5ea;\"> \n    <center>Predict\n        <a class=\"anchor-link\" href=\"#predict\" target=\"_self\">¶</a>\n    </center>\n</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(models, data, nr_valid):\n    train, test = train_test_split(data, nr_valid)\n    for i in range(len(test)):\n        X_test, y_test = test[i, :-1], test[i, -1]\n        for j, (name, model) in enumerate(models):\n            pred = model.predict(X_test)\n            pred = 1 if pred > 0.5 else 0\n            print('{:1d}) Model Name:{:15s}, Predicted:{:1.3f} - Expected:{:1.3f}'\n                     .format(i+1, name, pred, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_valid = df.iloc[:12].copy()\nvalid_data = series_to_supervised(df_valid.values, n_in=6)\ndf_valid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = get_models()\npredict(models, valid_data, 6)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}