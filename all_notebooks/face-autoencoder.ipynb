{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport tensorflow as tf\nfrom tensorflow.keras import layers, losses\nfrom tensorflow.keras.models import Model\nimport random","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"data_dir = '../input/celeba-dataset/'\ndf_partition = pd.read_csv(f'{data_dir}list_eval_partition.csv')\nimg_dir = f'{data_dir}img_align_celeba/img_align_celeba/'\ntrain_paths = [img_dir + i for i in df_partition[df_partition['partition'] == 0]['image_id']]\nval_paths = [img_dir + i for i in df_partition[df_partition['partition'] == 1]['image_id']]\ntest_paths = [img_dir + i for i in df_partition[df_partition['partition'] == 2]['image_id']]\nprint(f'Train: {len(train_paths)}')\nprint(f'Val: {len(val_paths)}')\nprint(f'Test: {len(test_paths)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_image(path, max_dim=None, gray=False):\n    img = Image.open(path)\n    if max_dim:\n        img.thumbnail((max_dim, max_dim))\n    if gray:\n        img = img.convert('L')\n    return np.array(img)\n\n\ndef normalize(img):\n    img = img / 255\n    return img\n\n\ndef denormalize(img):\n    img = img * 255\n    return img\n\n\ndef show(img, gray=False):\n    plt.axis('off')\n    if gray:\n        plt.imshow(img, cmap='gray')\n    else:\n        plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_dim = 88\ngray = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im = load_image(train_paths[100000], max_dim=max_dim, gray=gray)\nimage_shape = im.shape\nprint(f'Shape: {image_shape}')\nshow(im, gray)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = np.array([load_image(path, max_dim=max_dim, gray=gray)\n                         for path in train_paths[: 2 ** 14]])\ntrain_images = normalize(train_images)\ntrain_images.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images = np.array([load_image(path, max_dim=max_dim, gray=gray)\n                         for path in test_paths[: 2 ** 11]])\ntest_images = normalize(test_images)\ntest_images.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The Autoencoder","metadata":{}},{"cell_type":"code","source":"class Autoencoder(Model):\n    def __init__(self, encoded_dim):\n        super(Autoencoder, self).__init__()\n        self.encoded_dim = encoded_dim   \n        self.encoder = tf.keras.Sequential([\n            layers.Flatten(),\n            layers.Dense(encoded_dim, activation='relu')\n        ])\n        self.decoder = tf.keras.Sequential([\n            layers.Dense(np.prod(image_shape), activation='sigmoid'),\n            layers.Reshape(image_shape)\n        ])\n\n    def call(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n\n# Change the parameter to change the number of encoded dimensions\n# autoencoder = Autoencoder(64)\nautoencoder = Autoencoder(np.prod(image_shape) // 8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"autoencoder.fit(train_images, train_images,\n                epochs=10,\n                shuffle=True,\n                validation_data=(test_images, test_images))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_imgs = autoencoder.encoder(test_images).numpy()\ndecoded_imgs = autoencoder.decoder(encoded_imgs).numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n = 10\nrand = random.randint(0, len(test_images) - n)\n\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    # display original\n    ax = plt.subplot(2, n, i + 1)\n    plt.imshow(test_images[i + rand])\n    plt.title('original')\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # display reconstruction\n    ax = plt.subplot(2, n, i + 1 + n)\n    plt.imshow(decoded_imgs[i + rand])\n    plt.title('reconstructed')\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}