{"cells":[{"metadata":{"_uuid":"37b4fae3654b9789db11eefe67d5fb4db946ec8c"},"cell_type":"markdown","source":"# The BeeImage Dataset - Simplified: Inference\nThis kernel is just an inference engine for a model I trained on a simplified version of the BeeImage data set.  You can run this kernel to see the evaluation results of the model, for each of the validate and test subsets.  The results are excellent: better than 99.5% accuracy.\n\nThe results shown below might be a little startling: 100% accuracy for both the test and validation subsets.  We all know that's not possible, so there must be an explanation.  I propose that the reason the accuracy is impossibly high is because my test subset is too small; it contains only 500 images.  Still, given that the model guesses correctly for 100% of 500 instances, therefore the true accuracy must be at least 99.5%.\n\nThe model was trained in colab because it's so much faster.  That training kernel is named Honeybee Health Classifier - Simplified, and is posted to this same dataset.  It is based on Chollet's VGG16 pretrained model.  It takes too long to run on kaggle, and kept timing out after nine hours.\n\nIn this simplified dataset, the missing queens were removed, and the two varrao categories were collapsed into a single category.  To run it, you will also need my \"honeybees - simplified\" and \"model-cache\" datasets.\n"},{"metadata":{"id":"honpaUwhuVh3","colab_type":"text","_uuid":"613ea1918b2824fcb972bb0c87e1f70c505f30c5"},"cell_type":"markdown","source":"## Dataset"},{"metadata":{"id":"9DUUUAywuM9U","colab_type":"text","_uuid":"33da0ddca384f083c43d011bfd7d51ea8b0dee1c"},"cell_type":"markdown","source":"The credit for collecting and preparing the honeybee dataset goes to Jenny Yang from Kaggle: https://www.kaggle.com/jenny18/honey-bee-annotated-images/.\n"},{"metadata":{"id":"zJZvpoXAhTSL","colab_type":"code","colab":{},"trusted":false,"_uuid":"4adfc667a63495cc5a0a42ef897014e14be2629d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"kkO8qSPKCPRJ","colab_type":"code","outputId":"2793e147-9923-4f50-ac36-cdc25232765b","colab":{"base_uri":"https://localhost:8080/","height":35},"trusted":true,"_uuid":"bdfb52402fe94530c3b14b1be6de7497fea0148c"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random, datetime, os, shutil, math\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import models\nimport os\n\nimage_size = (150, 150)\n\nmodel_filename = \"../input/modelcache/hbhc-simple-val_loss-20190206-6-acc100.h5\"\ncsv_filename = \"../input/modelcache/hbhc-simple-val_loss-20190206-6-acc100.csv\"\n#images in:\ninput_dir = '../input/honeybees-simplified/bees-simple/bees/'\ntrain_dir = input_dir + \"train\"\nvalidate_dir = input_dir + \"validate\"\ntest_dir = input_dir + \"test\"\n\nlog_filename = \"hbhc_infer_log.txt\"\nlog_file = open(log_filename, \"a\")\n\n# timestamp and then write the msg to both the console and the log file:\ndef logprint(msg):\n  msg_str = \"[\"+str(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))+\"] \"+str(msg)\n  print(msg_str)\n  log_file = open(log_filename, \"a\")\n  log_file.write(msg_str+\"\\n\")\n  log_file.close()\n\nlogprint(\"Reopened log file \"+log_filename)\n\n#display a sample of bee photos in an auto-sized grid:\ndef show_bees(bzz):\n  numbees = len(bzz)\n  if numbees == 0:\n    return None\n  rows = int(math.sqrt(numbees))\n  cols = (numbees+1)//rows\n  f, axs = plt.subplots(rows, cols)\n  fig = 0\n  for b in bzz:\n    img = image.load_img(b)\n    row = fig // cols\n    col = fig % cols\n    axs[row, col].imshow(img)\n    fig += 1\n  plt.show()\n  \n#show some sample images:\ndir_name = os.path.join(test_dir,\"category0\")\nall_images = [os.path.join(dir_name, fname) for fname in os.listdir(dir_name)]\nshow_bees(all_images[:6])","execution_count":null,"outputs":[]},{"metadata":{"id":"G6z5judGaRnE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":761},"outputId":"1bde6e69-d5d9-4d28-e307-147aaee10a16","trusted":true,"_uuid":"b0d0947d8f8987cc23c3e269d3b297c5c1fb59e3"},"cell_type":"code","source":"# This is the graph of the training run which generated this model:'\ndf_hist = pd.read_csv(csv_filename)\nax = df_hist.plot(x='epoch',y=['acc','val_acc'])\nax = df_hist.plot(x='epoch',y=['loss','val_loss'])","execution_count":null,"outputs":[]},{"metadata":{"id":"lNlxKWmlaLlW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"67f11150-d827-4d8a-ff65-5e1597a6f6a6","trusted":true,"_uuid":"03a966f1d497fc692ab316a96927442be77f0b01"},"cell_type":"code","source":"# evaluate each of the train, validate and test subsets:\nmodel = models.load_model(model_filename)\n\nlogprint(\"evaluating the test subset\")\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_flow = test_datagen.flow_from_directory(\n        test_dir,\n        target_size=image_size,\n        batch_size=20,\n        class_mode='categorical')\ntest_loss, test_acc = model.evaluate_generator(test_flow, steps=40)\nlogprint('test acc:'+str(test_acc))\n\nlogprint(\"evaluating the validation subset\")\nvalidate_datagen = ImageDataGenerator(rescale=1./255)\nvalidate_flow = validate_datagen.flow_from_directory(\n        validate_dir,\n        target_size=image_size,\n        batch_size=20,\n        class_mode='categorical')\nvalidate_loss, validate_acc = model.evaluate_generator(validate_flow, steps=40)\nlogprint('validate acc:'+str(validate_acc))\n","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"Honey Bee Health Classifier - Simplified Inference","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":1}