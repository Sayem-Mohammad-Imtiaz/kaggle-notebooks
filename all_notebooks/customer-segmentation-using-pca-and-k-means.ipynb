{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Following code is for Customer Segmentation  using food delivery data. In the code you will find the following:**\n\n* EDA and Feature Creation\n* PCA for dimensionality reduction\n* Elbow method to select optimal cluster","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import silhouette_score\nfrom sklearn import preprocessing\nfrom scipy.spatial import ConvexHull\nimport datetime\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-07T11:54:48.338703Z","iopub.execute_input":"2021-06-07T11:54:48.339253Z","iopub.status.idle":"2021-06-07T11:54:48.350915Z","shell.execute_reply.started":"2021-06-07T11:54:48.33922Z","shell.execute_reply":"2021-06-07T11:54:48.349984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf = pd.read_csv(r'/kaggle/input/customer-order-data/SampleAssessment.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T11:54:48.72546Z","iopub.execute_input":"2021-06-07T11:54:48.725856Z","iopub.status.idle":"2021-06-07T11:54:48.764775Z","shell.execute_reply.started":"2021-06-07T11:54:48.72582Z","shell.execute_reply":"2021-06-07T11:54:48.763667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2021-06-07T11:54:49.012732Z","iopub.execute_input":"2021-06-07T11:54:49.013096Z","iopub.status.idle":"2021-06-07T11:54:49.019621Z","shell.execute_reply.started":"2021-06-07T11:54:49.013049Z","shell.execute_reply":"2021-06-07T11:54:49.018805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**EDA**","metadata":{}},{"cell_type":"code","source":"## num of customers\nprint ('Number of Customers:',df.customer_id.nunique())","metadata":{"execution":{"iopub.status.busy":"2021-06-07T11:54:49.732439Z","iopub.execute_input":"2021-06-07T11:54:49.732946Z","iopub.status.idle":"2021-06-07T11:54:49.738968Z","shell.execute_reply.started":"2021-06-07T11:54:49.732914Z","shell.execute_reply":"2021-06-07T11:54:49.738178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()\n#Observations: \n# Amount in last 7 days,Amount in last 4 weeks have missing values (as min=0), \n# Avg_DistanceFromResturant is negative in few cases","metadata":{"execution":{"iopub.status.busy":"2021-06-07T11:54:50.177899Z","iopub.execute_input":"2021-06-07T11:54:50.178401Z","iopub.status.idle":"2021-06-07T11:54:50.219418Z","shell.execute_reply.started":"2021-06-07T11:54:50.17837Z","shell.execute_reply":"2021-06-07T11:54:50.218691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes\n# convert dates to date format","metadata":{"execution":{"iopub.status.busy":"2021-06-07T11:54:50.648921Z","iopub.execute_input":"2021-06-07T11:54:50.649451Z","iopub.status.idle":"2021-06-07T11:54:50.656281Z","shell.execute_reply.started":"2021-06-07T11:54:50.649412Z","shell.execute_reply":"2021-06-07T11:54:50.655458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# format date\ndf['First_Order_Time'] = pd.to_datetime(df['First Time'])\ndf['Recent_Order_Time'] = pd.to_datetime(df['Recent Time'])\n\ndf['First_Order_Time'] = df['First_Order_Time'].dt.strftime('%m/%d/%Y')\ndf['Recent_Order_Time'] = df['Recent_Order_Time'].dt.strftime('%m/%d/%Y')\n\ndf['First_Order_Time'] = pd.to_datetime(df['First_Order_Time'])\ndf['Recent_Order_Time'] = pd.to_datetime(df['Recent_Order_Time'])","metadata":{"execution":{"iopub.status.busy":"2021-06-07T11:54:51.064672Z","iopub.execute_input":"2021-06-07T11:54:51.065201Z","iopub.status.idle":"2021-06-07T11:54:53.175188Z","shell.execute_reply.started":"2021-06-07T11:54:51.065169Z","shell.execute_reply":"2021-06-07T11:54:53.174337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T11:54:53.176443Z","iopub.execute_input":"2021-06-07T11:54:53.176884Z","iopub.status.idle":"2021-06-07T11:54:53.196123Z","shell.execute_reply.started":"2021-06-07T11:54:53.176854Z","shell.execute_reply":"2021-06-07T11:54:53.195138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Feature Creation**","metadata":{}},{"cell_type":"code","source":"# drop redundant columns\ndf.drop(['First Time','Recent Time'], axis = 1, inplace=True)\n\n# assume current date to be just the next day after latest transaction\ndf['current_date'] = max(df['Recent_Order_Time'])+ datetime.timedelta(days=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T11:54:53.197227Z","iopub.execute_input":"2021-06-07T11:54:53.197491Z","iopub.status.idle":"2021-06-07T11:54:53.222619Z","shell.execute_reply.started":"2021-06-07T11:54:53.197467Z","shell.execute_reply":"2021-06-07T11:54:53.221334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extract num_days_since_last_order, num_days_since_first_order\ndf['num_days_since_last_order'] = df['current_date'] - df['Recent_Order_Time']\ndf['num_days_since_first_order'] = df['current_date'] - df['First_Order_Time']","metadata":{"execution":{"iopub.status.busy":"2021-06-07T11:54:53.435105Z","iopub.execute_input":"2021-06-07T11:54:53.435615Z","iopub.status.idle":"2021-06-07T11:54:53.442744Z","shell.execute_reply.started":"2021-06-07T11:54:53.435583Z","shell.execute_reply":"2021-06-07T11:54:53.441819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n## rename columns\n\ndf.columns = ['customer_id', 'num_of_Orders', 'num_of_Orders_in_last_7_days',\n       'num_of_Orders_in_last_4_weeks', 'Amount', 'Amount_in_last_7_days',\n       'Amount_in_last_4_weeks', 'Avg_DistanceFromResturant',\n       'Avg_DeliveryTime', 'First_Order_Time', 'Recent_Order_Time',\n       'current_date', 'num_days_since_last_order',\n       'num_days_since_first_order']","metadata":{"execution":{"iopub.status.busy":"2021-06-07T11:54:53.851051Z","iopub.execute_input":"2021-06-07T11:54:53.851424Z","iopub.status.idle":"2021-06-07T11:54:53.857252Z","shell.execute_reply.started":"2021-06-07T11:54:53.851391Z","shell.execute_reply":"2021-06-07T11:54:53.855672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T11:54:54.444168Z","iopub.execute_input":"2021-06-07T11:54:54.444803Z","iopub.status.idle":"2021-06-07T11:54:54.464682Z","shell.execute_reply.started":"2021-06-07T11:54:54.444749Z","shell.execute_reply":"2021-06-07T11:54:54.463856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check for cases where order value is null for last 7 days and 4 Weeks\nnull_orders_in_last_7_days = df[df.num_of_Orders_in_last_7_days.isna()]\nnull_orders_in_last_4_weeks = df[df.num_of_Orders_in_last_4_weeks.isna()]\n\nprint (null_orders_in_last_7_days.num_days_since_last_order.min())\nprint (null_orders_in_last_4_weeks.num_days_since_last_order.min())\n# it means it these are actually null not missing  so replace them by 0\n\ndf.num_of_Orders_in_last_7_days.fillna(0, inplace = True)\ndf.num_of_Orders_in_last_4_weeks.fillna(0, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T11:54:55.247564Z","iopub.execute_input":"2021-06-07T11:54:55.248136Z","iopub.status.idle":"2021-06-07T11:54:55.261001Z","shell.execute_reply.started":"2021-06-07T11:54:55.248087Z","shell.execute_reply":"2021-06-07T11:54:55.259909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# replace neagtive values with 0\ndf['Avg_DistanceFromResturant'] = np.where(df['Avg_DistanceFromResturant']<0, 0,df['Avg_DistanceFromResturant'])","metadata":{"execution":{"iopub.status.busy":"2021-06-07T11:54:56.20819Z","iopub.execute_input":"2021-06-07T11:54:56.208551Z","iopub.status.idle":"2021-06-07T11:54:56.216866Z","shell.execute_reply.started":"2021-06-07T11:54:56.208517Z","shell.execute_reply":"2021-06-07T11:54:56.215653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T11:54:58.166086Z","iopub.execute_input":"2021-06-07T11:54:58.166479Z","iopub.status.idle":"2021-06-07T11:54:58.219576Z","shell.execute_reply.started":"2021-06-07T11:54:58.166445Z","shell.execute_reply":"2021-06-07T11:54:58.218809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# avg of one order for a customer\ndf['AOV'] = round(df['Amount']/df['num_of_Orders'],0)\n\n# avg of one order for a customer in last 7 days\ndf['AOV_last_7_days'] = np.where(df['num_of_Orders_in_last_7_days']==0, 0,\n                                 round(df['Amount_in_last_7_days']/df['num_of_Orders_in_last_7_days'],0))\n\n# avg of one order for a customer in last 4 weeks\ndf['AOV_last_4_weeks'] = np.where(df['num_of_Orders_in_last_4_weeks']==0, 0,\n                                  round(df['Amount_in_last_4_weeks']/df['num_of_Orders_in_last_4_weeks'],0))","metadata":{"execution":{"iopub.status.busy":"2021-06-07T11:54:59.451558Z","iopub.execute_input":"2021-06-07T11:54:59.45211Z","iopub.status.idle":"2021-06-07T11:54:59.463617Z","shell.execute_reply.started":"2021-06-07T11:54:59.452075Z","shell.execute_reply":"2021-06-07T11:54:59.462763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# % of users transacted in last 7 days\nprint ('% of users transacted in last 7 days:',df[df['num_of_Orders_in_last_7_days']!=0].shape[0]/df.shape[0])\n\n# % of users transacted in last 4 weeks \nprint ('% of users transacted in last 4 weeks:',df[df['num_of_Orders_in_last_4_weeks']!=0].shape[0]/df.shape[0])","metadata":{"execution":{"iopub.status.busy":"2021-06-07T11:54:59.828846Z","iopub.execute_input":"2021-06-07T11:54:59.82935Z","iopub.status.idle":"2021-06-07T11:54:59.840632Z","shell.execute_reply.started":"2021-06-07T11:54:59.829317Z","shell.execute_reply":"2021-06-07T11:54:59.839536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# filtering for only relevant columns\ndf_mod = df[['customer_id','num_of_Orders', 'AOV','AOV_last_7_days','AOV_last_4_weeks', 'Avg_DistanceFromResturant', 'Avg_DeliveryTime', 'num_days_since_last_order', 'num_days_since_first_order']]\n\n# extract days\ndf_mod['num_days_since_last_order'] = df_mod['num_days_since_last_order'].dt.days\ndf_mod['num_days_since_last_order'] = df_mod['num_days_since_last_order'].astype(int)\n\ndf_mod['num_days_since_first_order'] = df_mod['num_days_since_first_order'].dt.days\ndf_mod['num_days_since_first_order'] = df_mod['num_days_since_first_order'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T11:55:00.300837Z","iopub.execute_input":"2021-06-07T11:55:00.301221Z","iopub.status.idle":"2021-06-07T11:55:00.31182Z","shell.execute_reply.started":"2021-06-07T11:55:00.301187Z","shell.execute_reply":"2021-06-07T11:55:00.310729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**PCA and K-means Clustering**","metadata":{}},{"cell_type":"code","source":"# l2-normalize  \nX_normalized = preprocessing.normalize(df_mod[df_mod.columns[1:]], norm='l2')","metadata":{"execution":{"iopub.status.busy":"2021-06-07T11:55:02.084348Z","iopub.execute_input":"2021-06-07T11:55:02.084721Z","iopub.status.idle":"2021-06-07T11:55:02.094003Z","shell.execute_reply.started":"2021-06-07T11:55:02.084677Z","shell.execute_reply":"2021-06-07T11:55:02.092899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(7):\n    pca = PCA(n_components=i)\n    pca_result = pca.fit_transform(X_normalized)\n    print (i,\"explained variance : \",sum(pca.explained_variance_.round(2)), \"|\",\"explained variance ratio : \",sum(pca.explained_variance_ratio_.round(2)))\n    print ('')","metadata":{"execution":{"iopub.status.busy":"2021-06-07T11:55:45.73719Z","iopub.execute_input":"2021-06-07T11:55:45.737547Z","iopub.status.idle":"2021-06-07T11:55:45.908909Z","shell.execute_reply.started":"2021-06-07T11:55:45.737516Z","shell.execute_reply":"2021-06-07T11:55:45.907652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca = PCA(n_components = 4)\npca_result = pca.fit_transform(X_normalized)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T11:55:53.368496Z","iopub.execute_input":"2021-06-07T11:55:53.368863Z","iopub.status.idle":"2021-06-07T11:55:53.398981Z","shell.execute_reply.started":"2021-06-07T11:55:53.368825Z","shell.execute_reply":"2021-06-07T11:55:53.397636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"distortions = []\nsilhouette_avg_list = []\nlabels_temp = [2,3,4,5]\nfor k in labels_temp:\n    kmeanModel = KMeans(n_clusters=k,random_state=100)\n    kmeanModel.fit(pca_result)\n    cluster_labels = kmeanModel.fit_predict(pca_result)\n    silhouette_avg = silhouette_score(pca_result, cluster_labels)\n    print(\"For n_clusters =\", k,\n          \"The average silhouette_score is :\", silhouette_avg)\n    distortions.append(kmeanModel.inertia_)\n    silhouette_avg_list.append(silhouette_avg)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T11:55:56.806115Z","iopub.execute_input":"2021-06-07T11:55:56.806449Z","iopub.status.idle":"2021-06-07T11:56:14.489624Z","shell.execute_reply.started":"2021-06-07T11:55:56.806421Z","shell.execute_reply":"2021-06-07T11:56:14.488559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting elbow curve for optimal k value (inertia vs no. of clusters)\nplt.plot(labels_temp, distortions)\nplt.xlabel('number of clusters(k)')\nplt.ylabel('Distortions')\nplt.title('The Elbow Method showing the optimal k')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T11:56:14.491163Z","iopub.execute_input":"2021-06-07T11:56:14.491472Z","iopub.status.idle":"2021-06-07T11:56:14.644525Z","shell.execute_reply.started":"2021-06-07T11:56:14.491442Z","shell.execute_reply":"2021-06-07T11:56:14.64359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''Make Clusters'''\n\ncluster_size = 4\nk = int(cluster_size)\nkmeans = KMeans(n_clusters=k, random_state=100).fit(pca_result)\ncluster_labels = list(kmeans.predict(pca_result))","metadata":{"execution":{"iopub.status.busy":"2021-06-07T11:56:59.656078Z","iopub.execute_input":"2021-06-07T11:56:59.656442Z","iopub.status.idle":"2021-06-07T11:57:00.946759Z","shell.execute_reply.started":"2021-06-07T11:56:59.656413Z","shell.execute_reply":"2021-06-07T11:57:00.945801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (\"cluster distribution\")\nprojected = pca.fit_transform(X_normalized.data)\nprojected = pd.concat([pd.DataFrame(projected),pd.DataFrame(cluster_labels).rename(columns ={0:'Labels'})],axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T11:57:00.948292Z","iopub.execute_input":"2021-06-07T11:57:00.948601Z","iopub.status.idle":"2021-06-07T11:57:01.050141Z","shell.execute_reply.started":"2021-06-07T11:57:00.948572Z","shell.execute_reply":"2021-06-07T11:57:01.047671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, figsize=(20,10))\ncolors = ['#DF2020', '#81DF20', '#2095DF','#ffff99']\n# plot data\nplt.scatter(projected[0].values, projected[1].values, c=list(kmeans.labels_), alpha = 0.6, s=10)\n# plot centers\ncentroids = kmeans.cluster_centers_\ncen_x = [i[0] for i in centroids] \ncen_y = [i[1] for i in centroids]\n\nplt.scatter(cen_x, cen_y, marker='^', c=colors, s=70)\n# draw enclosure\nfor i in projected['Labels'].unique():\n    points = projected[projected.Labels == i][[0,1]].values\n    # get convex hull\n    hull = ConvexHull(points)\n    # get x and y coordinates\n    # repeat last point to close the polygon\n    x_hull = np.append(points[hull.vertices,0],\n                       points[hull.vertices,0][0])\n    y_hull = np.append(points[hull.vertices,1],\n                       points[hull.vertices,1][0])\n    # plot shape\n    plt.fill(x_hull, y_hull, alpha=0.3, c=colors[i])\n    \n# plt.xlim(0,200)\n# plt.ylim(0,200)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T11:58:10.55174Z","iopub.execute_input":"2021-06-07T11:58:10.552064Z","iopub.status.idle":"2021-06-07T11:58:10.947883Z","shell.execute_reply.started":"2021-06-07T11:58:10.552038Z","shell.execute_reply":"2021-06-07T11:58:10.94681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}