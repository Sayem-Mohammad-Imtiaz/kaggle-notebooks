{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, BatchNormalization\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.models import Model\nfrom keras.models import load_model\nfrom keras.datasets import cifar10\n\nfrom keras.metrics import AUC\n\n\n\nsns.set(style='white', context='notebook', palette='deep')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_mnist():\n\n    train = pd.read_csv(\"/kaggle/input/mnist-in-csv/mnist_train.csv\")\n    test = pd.read_csv(\"/kaggle/input/mnist-in-csv/mnist_test.csv\")\n\n    Y_train = train[\"label\"]\n    Y_test = test[\"label\"]\n\n\n    # Drop 'label' column\n    X_train = train.drop(labels = [\"label\"],axis = 1) \n    X_test = test.drop(labels = [\"label\"],axis = 1) \n\n\n    # free some space\n    train = None\n    test = None\n\n    X_train = X_train / 255.0\n    X_test = X_test / 255.0\n\n\n\n    X_train = X_train.values.reshape(-1,28,28,1)\n    X_test = X_test.values.reshape(-1,28,28,1)\n\n\n    Y_train = to_categorical(Y_train, num_classes = 10)\n    Y_test = to_categorical(Y_test, num_classes = 10)\n\n    # Set the random seed\n    random_seed = 2\n\n    \n    return X_train , X_test, Y_train , Y_test\n\n\ndef get_cifar10():\n    (x_train,y_train),(x_test,y_test) = cifar10.load_data()\n    x_train = x_train / 255.0\n    x_test = x_test / 255.0\n\n    y_train = to_categorical(y_train, num_classes = 10)\n    y_test = to_categorical(y_test, num_classes = 10)\n    \n    return x_train, x_test, y_train, y_test\n\n\ndef get_fashion_mnist():\n    train = pd.read_csv(\"/kaggle/input/fashionmnist/fashion-mnist_train.csv\")\n    test = pd.read_csv(\"/kaggle/input/fashionmnist/fashion-mnist_test.csv\")\n\n    Y_train = train[\"label\"]\n    Y_test = test[\"label\"]\n\n\n    # Drop 'label' column\n    X_train = train.drop(labels = [\"label\"],axis = 1) \n    X_test = test.drop(labels = [\"label\"],axis = 1) \n\n\n    # free some space\n    train = None\n    test = None\n\n    X_train = X_train / 255.0\n    X_test = X_test / 255.0\n\n\n    X_train = X_train.values.reshape(-1,28,28,1)\n    X_test = X_test.values.reshape(-1,28,28,1)\n\n\n    Y_train = to_categorical(Y_train, num_classes = 10)\n    Y_test = to_categorical(Y_test, num_classes = 10)\n\n    # Set the random seed\n    random_seed = 2\n\n    \n    return X_train, X_test, Y_train, Y_test\n\n\ndef get_simple_model(shape):\n    # Set the CNN model \n    model = Sequential()\n\n    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                     activation ='relu', input_shape = shape))\n    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                     activation ='relu'))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(0.25))\n\n\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                     activation ='relu'))\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                     activation ='relu'))\n    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n    model.add(Dropout(0.25))\n\n\n    model.add(Flatten())\n    model.add(Dense(256, activation = \"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(10, activation = \"softmax\"))\n    \n    # Compile the model\n    model.compile(optimizer = \"adam\" , loss = \"categorical_crossentropy\", metrics=[\"accuracy\",AUC()])\n    \n    return model\n\ndef get_vgg16_model(shape):\n    \n    model = Sequential()\n\n    model.add(Conv2D(32, 3, activation='relu', padding='same', input_shape=shape))\n    model.add(Conv2D(64, 3, activation='relu', padding='same'))\n    model.add(MaxPool2D(2, 2))\n    model.add(BatchNormalization())\n\n    model.add(Conv2D(128, 3, activation='relu', padding='same'))\n    model.add(Conv2D(128, 3, activation='relu', padding='same'))\n    model.add(MaxPool2D(2, 2))\n    model.add(BatchNormalization())\n\n    model.add(Conv2D(256, 3, activation='relu', padding='same'))\n    model.add(Conv2D(256, 3, activation='relu', padding='same'))\n    model.add(Conv2D(256, 3, activation='relu', padding='same'))\n    model.add(MaxPool2D(2, 2))\n    model.add(BatchNormalization())\n\n    model.add(Conv2D(512, 3, activation='relu', padding='same'))\n    model.add(Conv2D(512, 3, activation='relu', padding='same'))\n    model.add(Conv2D(512, 3, activation='relu', padding='same'))\n    model.add(MaxPool2D(2, 1)) # default stride is 2\n    model.add(BatchNormalization())\n\n    model.add(Conv2D(512, 3, activation='relu', padding='same'))\n    model.add(Conv2D(512, 3, activation='relu', padding='same'))\n    model.add(Conv2D(512, 3, activation='relu', padding='same'))\n    model.add(MaxPool2D(2, 1)) # default stride is 2\n    model.add(BatchNormalization())\n\n    model.add(Flatten())\n    model.add(Dense(4096, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(4096, activation='relu'))\n    model.add(Dropout(0.5))\n\n    model.add(Dense(10, activation='softmax'))\n    \n    # Compile the model\n    model.compile(optimizer = \"adam\" , loss = \"categorical_crossentropy\", metrics=[\"accuracy\",AUC()])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Normal training and saving models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"datasets = [\"mnist\",\"cifar10\",\"fashion_mnist\"]\nmodels = [\"simple\", \"vgg16\"]\nfor dataset in datasets:\n    X_train, X_test, Y_train, Y_test = eval(f'get_{dataset}()')\n    for model_name in models:\n        print(dataset + \" \"+ model_name)\n        model = eval(f'get_{model_name}_model({X_train.shape[1:]})')\n        history = model.fit(X_train,Y_train, batch_size=128,\n                                      epochs = 10, validation_data = (X_test, Y_test),\n                                      verbose = 1)\n        model.save(f'./{model_name}_{dataset}.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now, Transfer part","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def transfer(archi, dataset, stoping_layer):\n    model = load_model(f\"/kaggle/input/transfer-models/{archi}_{dataset}.h5\")\n    model = Model(model.input, model.layers[-stoping_layer].output)\n    for layer in model.layers:\n        layer.trainable = False\n        \n    # add the FC part\n    x = Flatten()(model.output)\n    x = Dense(50,activation=\"relu\")(x)\n    x = Dense(10,activation=\"softmax\")(x)\n    model = Model(model.input, x)\n    model.compile(optimizer = \"adam\" , loss = \"categorical_crossentropy\",  metrics=[\"accuracy\",AUC()])\n    return model\n\ndef plot_history(history, history2, stop, archi):\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.plot(history2.history['accuracy'])\n    plt.plot(history2.history['val_accuracy'])\n    plt.title(f'accuracy {archi} - stoping at layer {stop} from the bottom')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train_mnist', 'test_mnist', 'train_cifar10', 'test_cifar10'], loc='upper left')\n    plt.show()\n    \n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.plot(history2.history['loss'])\n    plt.plot(history2.history['val_loss'])\n    plt.title(f'{archi} loss trained on {dataset} - stoping at layer {stop} from the bottom')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train_mnist', 'test_mnist', 'train_cifar10', 'test_cifar10'], loc='upper left')\n    plt.show()\n    print()\n    \ndef pad_dataset(train, test):\n    train = np.pad(X_train, [(0, 0),(0, 4),(0, 4),(0, 0)], mode='constant', constant_values=0)\n    test = np.pad(test, [(0, 0),(0, 4),(0, 4),(0, 0)], mode='constant', constant_values=0)\n    train = np.stack((train,) * 3, axis=-1).reshape(train.shape[0], train.shape[1], train.shape[2], 3)\n    test = np.stack((test,) * 3, axis=-1).reshape(test.shape[0], test.shape[1], test.shape[2], 3)\n    return train,test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg_stoping_layers = [7, 12, 17, 22, 26]\nsimple_stoping_layers = [6, 10]\narchis = [\"vgg16\", \"simple\"]\ndatasets = [\"mnist\",\"cifar10\"]\nX_train, X_test, Y_train, Y_test = get_fashion_mnist()\nnp.save(f'./y_test.npy', Y_test)\nfor archi in archis:\n    stoping_points = vgg_stoping_layers if archi == \"vgg16\" else simple_stoping_layers\n    for stop in stoping_points:\n        X_train, X_test, Y_train, Y_test = get_fashion_mnist()\n        histories = []\n        for dataset in datasets:\n            if dataset == \"cifar10\":\n                X_train, X_test = pad_dataset(X_train, X_test)\n            transfer_model = transfer(archi,dataset,stop)\n            print(dataset + \" \"+ archi)\n            history = transfer_model.fit(X_train,Y_train, batch_size=128,\n                                              epochs = 10, validation_data = (X_test, Y_test),\n                                              verbose = 0)\n            histories.append(history)\n            preds = transfer_model.predict(X_test)\n            np.save(f'./{dataset}_{archi}_{stop}.npy', preds)\n        plot_history(histories[0],histories[1], stop , archi)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}