{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"color:SteelBlue; font-size:200%; line-height:1.5\">Определение возраста человека по его фотографии</h1>"},{"metadata":{},"cell_type":"markdown","source":"**Задача:** Построить модель, которая по фотографии определит приблизительный возраст человека.\n\n**Цель:** Определять возраст покупателей в прикассовой зоне, чтобы делать рекомендации товаров и контролировать продажу алкоголя несовершеннолетним."},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"color:SteelBlue; font-size:200%; line-height:1.5\">1. Загрузка данных, исследовательский анализ</h1>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom PIL import Image\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n\nfrom tensorflow.keras.applications.resnet import ResNet50\nfrom tensorflow.keras import Sequential, regularizers, callbacks, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator \nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_train(path):\n    train_datagen = ImageDataGenerator(\n        rescale=1/255.,\n        validation_split = 0.25,\n        horizontal_flip = True\n    )\n    labels = pd.read_csv(path + 'labels.csv')\n    train_flow = train_datagen.flow_from_dataframe(\n        labels, \n        directory = path + 'final_files/final_files/',\n        x_col=\"file_name\",\n        y_col=\"real_age\",\n        target_size=(224, 224),\n        batch_size=32,\n        class_mode='raw',\n        subset='training',\n        seed=12345)\n\n    return train_flow\n\ndef load_test(path):\n    test_datagen = ImageDataGenerator(\n        validation_split=0.25,\n        rescale=1./255\n        )\n\n    labels = pd.read_csv(path + 'labels.csv')\n    test_flow = test_datagen.flow_from_dataframe(\n        labels, \n        directory = path + 'final_files/final_files/',\n        x_col=\"file_name\",\n        y_col=\"real_age\",\n        target_size=(224, 224),\n        batch_size=100,\n        class_mode='raw',\n        subset='validation',\n        seed=12345)\n\n    return test_flow","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '/kaggle/input/appa-real-face-cropped/'\ntrain_flow = load_train(path)\ntest_flow = load_test(path)\nlabels = pd.read_csv(path + 'labels.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(labels.head()) \ndisplay(labels.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Размер выборки:', labels.shape)\nprint('пропущенных значений:')\nprint(labels.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Размер фотографий в наборе данных:"},{"metadata":{"trusted":true},"cell_type":"code","source":"im_size_x, im_size_y = np.array([]), np.array([])\nfor i in range(len(labels)):\n    im = Image.open(path + 'final_files/final_files/' + labels.iloc[i, 0])\n    im_size_x = np.append(im_size_x, im.size[0])\n    im_size_y = np.append(im_size_y, im.size[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Неквадратных изображений:', np.sum( (im_size_x - im_size_y) != 0) )\nnot_rect = \\\n    ((abs(im_size_x/im_size_y) > 1.1) \n     + \n     (abs(im_size_x/im_size_y) < 0.9))\n\nprint( 'Изображения с разницей ширины и высоты более 10%:', np.sum(not_rect))\nprint( 'Доля таких изображений', np.sum(not_rect) / len(labels) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В основном набор данных представлен квдратными изображениями. Но небольшая доля изображений будет растянута или сжата на более чем 10% при предобработке (resizing) данных в keras."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(ncols=2, nrows=1, figsize=(16,4))\nax1, ax2 = axs.flatten()\nax1.hist(im_size_x, bins=100)\nax1.set_xlabel('x, px')\nax2.set_xlabel('x, px')\nsns.boxplot(im_size_x, whis = [5,95])\nplt.suptitle('Размеры изображений в выборке, px')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Минимальный размер изображений по x:', im_size_x.min())\nprint('Средний размер изображений по x:', im_size_x.mean().round(0))\nprint('Медианный размер изображений по x:', np.median(im_size_x))\nprint('Максимальный размер изображений по x:', np.max(im_size_x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Series(im_size_x).describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Размеры изображений в выборке имеют существенный разброс. 75% изображений больше 220 px по оси x. Нужно выполнять resize. Причём, растягивать большое количество изображений, наверное, нежелательно, т.к. на растянутых изображениях изначально группы пикселей несут меньше информации, чем на сжатых. Если использовать размер 224x224, растянутыми более чем в два раза окажутся:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print( round( 100*np.sum(im_size_x < 112) / len(labels), 1) , '% изображений')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(ncols=2, nrows=1, figsize=(16,4))\nax1, ax2 = axs.flatten()\nax1.hist(labels.real_age, bins=50)\nax1.set_xlabel('возраст, лет')\nsns.boxplot(labels.real_age, whis = [5,95])\nax2.set_xlabel('возраст, лет')\nplt.suptitle('Возраст людей в выборке, лет')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels.real_age.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Люди в выборке по возрасту распределены неравномерно. Но, на мой взгляд, выборка в целом соответствует людям, посещающим магазины. Однако виден провал в \"тинейджерском интервале\" и с контролем продажи алкоголя подросткам могут быть проблемы:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Людей старше 13 и младше 18 лет в выборке:', sum ((labels.real_age > 13).values * (labels.real_age < 18).values))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Этого мало для хорошего обучения, на мой взгляд."},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y = next(train_flow)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"big_img_index = np.argsort(im_size_x)[-1]\nsmall_img_index = np.argsort(im_size_x)[0]\nimg_big = Image.open(path + 'final_files/final_files/' + labels.iloc[big_img_index, 0])\nimg_small = Image.open(path + 'final_files/final_files/' + labels.iloc[small_img_index, 0])\nplt.imshow(img_big)\nplt.title('Самое большое и самое маленькое фото:')\nplt.show()\nplt.imshow(img_small)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# выводим 12 изображений\nfig = plt.figure(figsize=(10,10))\nfor i in range(12):\n    fig.add_subplot(3, 4, i+1)\n    plt.imshow(X[i])\n    # для компактности удаляем оси и прижимаем изображения друг к другу\n    plt.title( 'Age: ' + str(y[i]) )\n    plt.xticks([])\n    plt.yticks([])\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"color:SteelBlue; font-size:200%; line-height:1.5\">Выводы по исследовательскому анализу</h1>"},{"metadata":{},"cell_type":"markdown","source":"В наборе данных 7591 изображений лиц, с разбросом по размерам, часть фото - неквадратные. Выборка по возрасту в целом соответствует людям, посещающим магазины, однако несбалансирована. Есть провал в \"тинейджерском интервале\" и с контролем продажи алкоголя подросткам могут быть проблемы."},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"color:SteelBlue; font-size:200%; line-height:1.5\">2. Обучение модели</h1>"},{"metadata":{},"cell_type":"markdown","source":"Обучение модели с архитектурой, построенной на базе [статьи 1](https://github.com/emredogan7/age-estimation-by-CNN/blob/master/doc/report.pdf) и [статьи 2](https://talhassner.github.io/home/publication/2015_CVPR)."},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(input_shape):\n    model = Sequential()\n    optimizer = Adam(lr=0.001)\n    # 224x224x3 ->\n    model.add(Conv2D(filters=96, input_shape=input_shape, kernel_size=(7, 7), \n                     padding='valid', activation='relu'))\n    model.add(MaxPooling2D(pool_size=(3, 3)))\n    model.add(BatchNormalization(momentum=0.9))\n\n    model.add(Conv2D(filters=256, kernel_size=(5, 5), \n                     padding='valid', activation='relu'))\n    model.add(MaxPooling2D(pool_size=(3, 3)))\n    model.add(BatchNormalization(momentum=0.9))\n\n    model.add(Conv2D(filters=384, kernel_size=(3, 3), \n                     padding='valid', activation='relu'))\n    model.add(MaxPooling2D(pool_size=(3, 3)))\n\n    model.add(Flatten())\n\n    model.add(Dropout(0.2))\n\n    model.add(Dense(units=512, activation='relu'))\n    model.add(Dropout(0.2))\n\n    model.add(Dense(units=256, activation='relu'))\n    model.add(Dropout(0.2))\n\n    model.add(Dense(units=64, activation='relu'))\n    model.add(Dropout(0.2))\n\n    model.add(Dense(units=16, activation='relu'))\n    model.add(Dropout(0.2))\n\n    model.add(Dense(units=1, activity_regularizer = regularizers.l2(0.01), activation='relu'))\n\n    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mae'])\n\n    return model\n\n\ndef train_model(model, train_flow, test_flow, batch_size=None, epochs=10,\n                steps_per_epoch=None, validation_steps=None, callbacks_list = None):\n\n    if steps_per_epoch is None:\n        steps_per_epoch = len(train_flow)\n    if validation_steps is None:\n        validation_steps = len(test_flow)\n\n    model.fit(train_flow,\n              validation_data=test_flow,\n              steps_per_epoch=steps_per_epoch,\n              validation_steps=validation_steps, \n              epochs=epochs,\n              callbacks = callbacks_list,\n              verbose=2,\n              shuffle=True)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"model = create_model((224, 224, 3))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks_list = [\n    callbacks.ModelCheckpoint(\n        filepath='cv_arbf_model_{epoch}.h5',\n        # Путь по которому нужно сохранить модель\n        # Два параметра ниже означают, что мы перезапишем\n        # текущий чекпоинт в том и только в том случае, когда\n        # улучшится значение `val_loss`.\n        save_best_only=True,\n        monitor='val_loss',\n        verbose=1)\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = train_model(model, train_flow, train_flow, epochs=50, steps_per_epoch=None, validation_steps=None, callbacks_list = callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.load_model('./cv_arbf_model_45.h5')\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"На своей модели получилось достичь качества на тестовой выборке MAE = 5.8542, но нестабильно. Модель недоучилась, для стабильного качества нужно больше эпох."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}