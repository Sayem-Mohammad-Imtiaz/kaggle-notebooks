{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\nThis notebook contains code used to build a deep learning model on Keras to predict Sign Language from the MNIST dataset"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importing Modules\nimport numpy as np\nimport pandas as pd\n\n# Keras modules\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\nfrom keras.utils import to_categorical\n\n# Train test split\nfrom sklearn.model_selection import train_test_split\n\n# Display and plotting\nfrom IPython.display import Image\nimport plotly_express as px\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\ninit_notebook_mode(connected=True)\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sign Language\nAn image describing the classification task"},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(filename = \"../input/american_sign_language.PNG\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading train and test sets\ntrain = pd.read_csv(\"../input/sign_mnist_train.csv\")\ntest = pd.read_csv(\"../input/sign_mnist_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train:\")\nprint(train.head())\nprint(\"\\nTest:\")\nprint(test.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at training data info\nprint(train.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing & Visualizing Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking distribution of data\nlabel_dist = pd.DataFrame(train['label'].value_counts()).reset_index()\nlabel_dist.columns = ['Label','Count']\npx.bar(label_dist,x = \"Label\", color = \"Label\", y = \"Count\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Good, we shouldn't have data for J (label 9) and Z (label 25). They involve movement."},{"metadata":{},"cell_type":"markdown","source":"# Setting up Train and Test Sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining X and Ys\nX_train = train.iloc[:,1:].copy()\nY_train = train.iloc[:,0].copy()\n\nX_test = test.iloc[:,1:].copy()\nY_test = test.iloc[:,0].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting training model into train and validation sets for deep learning model\nX_train, X_val, Y_train, Y_val = train_test_split(X_train,Y_train, test_size = 0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rescaling data to fall between 0 and 1\nX_train = X_train/255\nX_val = X_val/255\nX_test = X_test/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting to Numpy array and Reshaping X_train and test data\nX_train = np.array(X_train).reshape(X_train.shape[0],28,28,1)\nX_val = np.array(X_val).reshape(X_val.shape[0],28,28,1)\nX_test = np.array(X_test).reshape(X_test.shape[0],28,28,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Categorizing Ys\nY_train = to_categorical(Y_train)\nY_val = to_categorical(Y_val)\nY_test = to_categorical(Y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building Keras Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Building Keras model\nmodel = Sequential()\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = 2))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = 2))\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = 2))\nmodel.add(Flatten())\nmodel.add(Dense(units = 25, activation = 'softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compiling model\nmodel.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy',metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training the Model\nHere, we train the model and evaluate the ideal number of epochs before overfitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X_train,Y_train, validation_data = (X_val, Y_val),epochs = 10, batch_size = 64)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizing Validation Loss/Accuracy Over Epochs"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.DataFrame(history.history).reset_index()\ndata.columns = ['Epoch', \"Validation_Loss\",\"Validation_Accuracy\",\"Loss\",\"Accuracy\"]\ntrace1 = go.Scatter(\n    x = (data['Epoch'] + 1).values,\n    y = data['Loss'].values,\n    name = \"Loss\",\n    mode = \"lines+markers\"\n)\ntrace2 = go.Scatter(\n    x = (data['Epoch'] + 1).values,\n    y = data['Validation_Loss'].values,\n    name = \"Validation_Loss\",\n    mode = \"lines+markers\"\n)\ntrace3 = go.Scatter(\n    x = (data['Epoch'] + 1).values,\n    y = data['Validation_Accuracy'].values,\n    name = \"Validation_Accuracy\",\n    mode = \"lines+markers\"\n)\ntrace4 = go.Scatter(\n    x = (data['Epoch'] + 1).values,\n    y = data['Accuracy'].values,\n    name = \"Accuracy\",\n    mode = \"lines+markers\"\n)\nfig1 =[trace1,trace2]\nfig2 = [trace3,trace4]\niplot(fig1)\niplot(fig2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems like the model only really needs about 4 epochs"},{"metadata":{},"cell_type":"markdown","source":"# Final Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Final Model\nmodel = Sequential()\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = 2))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = 2))\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = 2))\nmodel.add(Flatten())\nmodel.add(Dense(units = 25, activation = 'softmax'))\nmodel.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy',metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train,Y_train, validation_data = (X_val, Y_val),epochs = 4, batch_size = 64)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluating Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model evaluation\nmodel.evaluate(X_test,Y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not a bad result!"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}