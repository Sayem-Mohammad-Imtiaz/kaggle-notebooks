{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1>¿Influyen la cantidad de reviews en la calificación de un libro?</h1>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Sin duda alguna, el crecimiento exponencial del conocimiento humano fue causado por la capacidad de transmitir ideas a través del tiempo. Gracias a la palabra escrita, la humanidad no solo ha sido capaz de transmitir conocimiento, sino creó una herramienta que permití a las personas vivir experiencias ajenas de formas inimaginables para quién no ha leído una buena novela o cuento. No se requiere ser bibliómano para poder recomendar un libro, alegando que es \"una joya\" de la literatura. Todos nos hemos vueltos profetas y evangelizadores de algún buen libro. Pero si el gusto es relativo, ¿podrá ser que a alguien no le guste el mismo libro que a mí me inspiro a ser mejor persona? Claro que sí, es muy probable que al menos a una persona no le guste. Sin embargo, no quiere decir que el hecho de que no lo considere una \"joya de la literatura\", la otra persona lo odié, como todo en la vida, es bueno tener matices.\n\nLa escala de 5 estrellas es conocida por todo el mundo, dónde se entiende en acuerdo social que 0 es un rotundo \"no lo recomiendo\" cerca del \"si quieres un consejo, no lo leas\"; 3 se puede entender como un \"bueno, pero no el mejor\"; mientras que 5, la calificicación de la excelencia. Brindándole a la gente estos matices, podemos obtener más información, así como nuevas preguntas, dónde la más importante podría ser: ¿Mientras más gente lea un libro, más difícil será alcanzar las 5 estrellas?","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Con el Dataset de esta página, se plantea hacer un estudio estadístico sobre la relación que tiene el promedio de calificación que posee un libro, usando la escala de rating de 5 estrellas ('average_rating') y el número de reseñas que ha recibido el mismo ('text_reviews_coun'), considerando el número de reseñas como personas que han leído el libro.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h1>Read Data</h1>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Como primer paso para acceder a la información Desde un punto inicial se poceden a importar las librerías del set básico para analizar un DataFrame con Pandas así como las bibliotecas para el uso de gráficas y arreglos.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.stats\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"books = pd.read_csv('../input/bookscsv/books.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"books.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"books.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Al observar el encabezado de la tabla, se puede apreciar que existe una columna de \"sobra\". El hecho de que lleve de nombre \"Unnamed: 12\" indica que esta columna es el resultado de que una o más filas contengan una coma de más. Considerando la naturaleza de los datos, se puede deducir que el error es más probable de aparecer en el título del libro, o en los autores. Dadas estas suposiciones, se buscará analizar las filas que muestren estos errores, para poder identificar corroborar que si sólo es en una columna o en dos.\n\nPara ello, se diseña una función que busque estos \"errores\"; si los encuentra, imprime la fila, pero en caso de que tenga un error de índice por no contener información, los pasará de largo y seguirá.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_verifier(file):\n    with open(books, mode=\"r\", encoding='utf-8', newline='') as csv_file:\n        csv_reader = csv.reader(csv_file)\n        \n        header = next(csv_reader)\n        count = 0\n        for row in csv_reader:\n            try:\n                last_row = row[12]\n                if last_row == '':\n                    last_row = row[13]\n                print(f'{row}')\n                print(f'LENs. title: {len(row[1])} authors: {len(row[2])} sup_extra: {len(row[3])} sup_rating: {len(row[4])}\\n')\n             \n            except IndexError:\n\n                pass\n        \n        csv_file.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Con la función diseñada (y probada en script), se procede a la importación de csv y os para que el Kernel no lo señale como un objeto tipo DataFrame y lo maneje con un file y string.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv, os\n\nbooks = '../input/goodreadsbooks/books.csv'\ndata_verifier(books)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Gracias a esta función, podemos determinar que el error se encuentra en la columna de autores. Si bien, las longitudes sobresalen en el segundo error, al leer la información detalladamente podemos observar que el error sucede por una coma extra en autores. Ya que se realizará un estudio sobre la relación entre el rating y las reviews, podemos precindir de toda información que no sea estos dos valores y el título.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h1>Carga de la información y análisis de la información</h1>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h2>Delimitación de la información necesaria</h2>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Haciendo un análisis superficial, solo se requerirá la información del rating (float), reviews (int) y los libros resultantes de estos análisis. En el caso del rating y las reviews, podemos notar que un parámetro siempre solicitado es el valor máximo. Por lo que al momento de cargar la información, podemos aprovechar para obtenerlo dentro del mismo ciclo. Si el lector desea agregar más información, a continuación se deja el chunk de la función load_and_max para su edición.\n\nSe hace la aclaración que la importación de 'csv' y 'os' es solo de apoyo didáctico, ya que basta con la importación que se hizo previamente.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv, os\n\ndef load_and_max(file, column_to_find):\n    with open(books, mode=\"r\", encoding='utf-8', newline='') as csv_file:\n        csv_reader = csv.reader(csv_file)\n        \n        header = next(csv_reader)\n        column_array = []\n        max_value = 0\n\n        for row in csv_reader:\n            try:\n                last_row = row[12]\n                if last_row == '':\n                    last_row = row[13]\n\n                if column_to_find == 'average_rating': column_data = float(row[4])\n                elif column_to_find == 'num_pages': column_data = int(row[8])\n                elif column_to_find == 'ratings_count': column_data = int(row[9])\n                elif column_to_find == 'text_reviews_count': column_data = int(row[10])\n                else:\n                    column_array = 'Data not Found. Check input'\n                    max_value = 0\n                    return column_array, max_value\n            except IndexError:\n                if column_to_find == 'average_rating': column_data = float(row[3])\n                elif column_to_find == 'num_pages': column_data =  int(row[7])\n                elif column_to_find == 'ratings_count': column_data = int(row[8])\n                elif column_to_find == 'text_reviews_count': column_data = int(row[9])\n                else:\n                    column_array = 'Data not Found. Check input'\n                    max_value = 0\n                    return column_array, max_value\n\n            column_array.append(column_data)\n            if column_data > max_value:\n                max_value = column_data\n\n    csv_file.close()\n\n    return column_array, max_value","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cómo es posible de observar, la función previa solo fue diseñada para reducir tiempos de ejecución, ya que de esta forma se ahorran dos ciclos O(n) cada uno para la obtención de los valores máximos de los arrays. en caso de que se requiera algún otro dato de la columna, se podría usar la función que se encuentra a continuación, considerando que:\n\n1. Solo carga un array a la vez.\n1. No obtiene valores máximos.\n1. Se garantiza su desempeño exclusivamente para este caso con este csv. Para otro tipo de csv's su utilidad y eficiencia no está garantizada.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_array(file, column_to_find):\n\n    with open(books, mode=\"r\", encoding='utf-8', newline='') as csv_file:\n        csv_reader = csv.reader(csv_file)\n        header = next(csv_reader)\n        column_array = []\n\n        for row in csv_reader:\n            try:\n                last_row = row[12]\n                if last_row == '':\n                    last_row = row[13]\n                #Ordered followinf the fild\n                #First Strings\n                if column_to_find == 'title': column_data = row[1]\n                elif column_to_find == 'authors': column_data = row[2] + ',' + row[3]\n                #Float\n                elif column_to_find == 'average_rating': column_data = float(row[4])\n                #Strings hided as Int\n                elif column_to_find == 'isbn': column_data = row[5]\n                elif column_to_find == 'isbn13': column_data = row[6]\n                #String AF\n                elif column_to_find == 'language_code': column_data = row[7]\n                elif column_to_find == '  num_pages': column_data = int(row[8])\n                elif column_to_find == 'ratings_count': column_data = int(row[9])\n                elif column_to_find == 'text_reviews_count': column_data = int(row[10])\n                #Reason you import Datetime\n                elif column_to_find == 'publication_date': column_data = datetime.strptime(row[11], '%m/%d/%Y')\n                #String\n                elif column_to_find == 'publisher': column_data = row[12]\n                else:\n                    column_data = 'Data not Found. Check input'\n                    \n                    return column_array\n\n                    \n            except IndexError:\n                #Ordered followinf the fild\n                #First Strings\n                if column_to_find == 'title': column_data = row[1]\n                elif column_to_find == 'authors': column_data = row[2]\n                #Float\n                elif column_to_find == 'average_rating': column_data = float(row[3])\n                #Strings hided as Int\n                elif column_to_find == 'isbn': column_data = row[4]\n                elif column_to_find == 'isbn13': column_data = row[5]\n                #String AF\n                elif column_to_find == 'language_code': column_data = row[6]\n                elif column_to_find == 'num_pages': column_data =  int(row[7])\n                elif column_to_find == 'ratings_count': column_data = int(row[8])\n                elif column_to_find == 'text_reviews_count': column_data = int(row[9])\n                #Reason you import Datetime\n                elif column_to_find == 'publication_date': column_data = datetime.strptime(row[10], '%m/%d/%Y')\n                #String\n                elif column_to_find == 'publisher': column_data = row[11]\n                else:\n                    column_data = 'Data not Found. Check input'\n                    \n                    return column_array\n\n            column_array.append(column_data)\n        \n\n    csv_file.close()\n\n    return column_array","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ejecutando por partes el código, se procede a analizarlo su ejecución como partes de un script simple de python, obteniendo la ubicación de nuestro archivo y extrayendo la información relevante.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"books = '../input/goodreadsbooks/books.csv'\n\ntitles = load_array(books, 'title')\nrating, max_rating = load_and_max(books, 'average_rating')\nreviews, max_reviews = load_and_max(books, 'text_reviews_count')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para tener noción de que no se omitió ningún dato, se solicita su tamaño ya que, si tuvieran una diferencia por un solo dato, se corre el riesgo de obtener un error de índice en futuros análisis. De igual forma, se garantiza que los datos faltantes que puedan existir, son por error en el archivo y no por la carga, reduciendo la posibilidad de un re-trabajo","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Información disponible: Titulos: {len(titles)}, rating: {len(rating)}, reviews: {len(reviews)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Al tener el mismo tamaño, procedemos a hacer el análisis con ayuda de Pandas.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"books_dict = {'rating': rating,\n             'reviews': reviews,\n             'titles': titles}\n\nbooks_df = pd.DataFrame(books_dict, columns=['rating','reviews','titles'])\nbooks_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Análisis del Rating</h3>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Antes de realizar conjenturas sobre su calentamiento, encontrando un soporte visual en un histograma, se puede apreciar de forma rápida la tendencia que tiene la serie del rating, permitiéndo decidir cuál es la vía más eficiente para el análisis. Asignando 10 bins, se entiende que el gráfico x muestra la distribución del rating en saltos de 0.5 en la calificación; 100, 0.05; y 500, 0.01 (todas las posibles calificaciones)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y = books_df['rating']\n\nfig, ax = plt.subplots()\nax.hist(y, bins = 500)\nax.set_xlabel('rating')\nax.set_ylabel('Frecuencia')\n\nplt.axvline(np.mean(y)-np.std(y), c = 'k', linestyle = ':', label = '-1 desv. std.')\nplt.axvline(np.mean(y), c = 'r', linestyle = '-', label = 'Promedio')\nplt.axvline(np.mean(y)+np.std(y), c = 'k', linestyle = ':', label = '+1 desv. std.')\nax.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = books_df['rating']\n\nfig, ax = plt.subplots()\nax.hist(y, bins = 100)\nax.set_xlabel('rating')\nax.set_ylabel('Frecuencia')\n\nplt.axvline(np.mean(y)-np.std(y), c = 'k', linestyle = ':', label = '-1 desv. std.')\nplt.axvline(np.mean(y), c = 'r', linestyle = '-', label = 'Promedio')\nplt.axvline(np.mean(y)+np.std(y), c = 'k', linestyle = ':', label = '+1 desv. std.')\nax.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = books_df['rating']\n\nfig, ax = plt.subplots()\nax.hist(y, bins = 10)\nax.set_xlabel('rating')\nax.set_ylabel('Frecuencia')\n\nplt.axvline(np.mean(y)-np.std(y), c = 'k', linestyle = ':', label = '-1 desv. std.')\nplt.axvline(np.mean(y), c = 'r', linestyle = '-', label = 'Promedio')\nplt.axvline(np.mean(y)+np.std(y), c = 'k', linestyle = ':', label = '+1 desv. std.')\nax.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para el caso del rating se puede observar una clara tendencia a la derecha, indicando que resulta más fácil encontrar un valor cercano a las 4 estrellas, pero que, al obtenerlo, decrece de forma más drástica. El hecho de encontrar pocos casos de calificaciones menores a 3.5 podría indicar que la gente tiende a reseñar los libros que les ha parecido decentes, pero resulta raro que alguién realice una reseña de algún libro que no le gustó. A simple vista, se aprecia que es muy raro encontrar una calificación mayor a 4.5 estrellas, pero que sí existen libros con 5 estrellas (\"excelente\").","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Con esa información, se procede a analizar cuales son los libros con mayor calificación (5 estrellas)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def match_case_condition(array, value):\n    match_one_condition = []\n    for element_ub in range(len(array)):\n        if array[element_ub] == value:\n            match_one_condition.append(element_ub)\n\n    return match_one_condition","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"maxium_books = match_case_condition(rating,5)\n\nverified_rate = []\nfor ub in maxium_books:\n    verified_rate.append(rating[ub])\n\nn_reviews_of_titles = []\nfor ub in maxium_books:\n    n_reviews_of_titles.append(reviews[ub])    \n    \nbest_rated_titles = []\nfor ub in maxium_books:\n    best_rated_titles.append(titles[ub])\n    \nbest_rated_books_dict = {'rating': verified_rate,\n             'reviews': n_reviews_of_titles,\n             'titles': best_rated_titles}\n\nbest_rated_books_df = pd.DataFrame(best_rated_books_dict, columns=['rating','reviews','titles'])\nbest_rated_books_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Con este análisis, podemos afirmar que es falsa la idea de que los libros mejor calificados son los que tienen el mayor número de lectores. Este análisis inclusive puede poner en mesa la idea de que un libro con 5 estrellas ha sido poco evaluado por sus lectores.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h2>Considerando Rating y Reviews</h2>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"A diferencia de las estrellas, los reviews tienen la característica de poder tener un comportamiento exponencial, por lo que clasificarlos por grupos carecería de sentido. Para ello se muestran las siguientes gráficas, dónde la primera muestra una clasificación en 10 categorías y la siguiente de 100, usando sus valores cómo parámetro clasificador.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y = books_df['reviews']\nfig, ax = plt.subplots()\nax.hist(y, bins = 10)\nax.set_xlabel('reviews')\nax.set_ylabel('Frecuencia')\n\nplt.axvline(np.mean(y)-np.std(y), c = 'k', linestyle = ':', label = '-1 desv. std.')\nplt.axvline(np.mean(y), c = 'r', linestyle = '-', label = 'Promedio')\nplt.axvline(np.mean(y)+np.std(y), c = 'k', linestyle = ':', label = '+1 desv. std.')\nax.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = books_df['reviews']\nfig, ax = plt.subplots()\nax.hist(y, bins = 100)\nax.set_xlabel('reviews')\nax.set_ylabel('Frecuencia')\n\nplt.axvline(np.mean(y)-np.std(y), c = 'k', linestyle = ':', label = '-1 desv. std.')\nplt.axvline(np.mean(y), c = 'r', linestyle = '-', label = 'Promedio')\nplt.axvline(np.mean(y)+np.std(y), c = 'k', linestyle = ':', label = '+1 desv. std.')\nax.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aparte de mostrar la casi inexistencia de valores altos, se puede deducir que un libro no popular tendrá escasas receñas; y el caso contrario con los libros populares, al poseer muchas receñas. Gracias a la noción otorgada por los resultados con el gráfico, podríamos obtener los libros que tengan como mínimo 1,000 reviews. Con esto, se reducen las iteraciones para encontrar un Top en el que los libros con mayor reviews tengan buena calificación. Esta función, de igual forma, podría ser útil para encontrar todos los libros con la calificación de nuestro interés.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def merge_sort(array):\n    if len(array) > 1:\n        middle = len(array) // 2\n        left = array[:middle]\n        right = array[middle:]\n\n        merge_sort(left)\n        merge_sort(right)\n        \n        \"\"\"SubArrays Iterators\"\"\"\n        i = 0\n        j = 0\n        \"\"\"MainArray Iterator\"\"\"\n        k = 0\n\n        while i < len(left) and j < len(right):\n            if left[i] < right[j]:\n                array[k] = left[i]\n                i += 1\n            else:\n                array[k] = right[j]\n                j += 1\n            \n            k += 1\n\n        while i < len(left):\n            array[k] = left[i]\n            i += 1\n            k += 1\n\n        while j < len(right):\n            array[k] = right[j]\n            j += 1\n            k += 1\n\n    return array\n\ndef binary_search(array, start, end, search_value):\n    if start > end:\n        return end\n    \n    middle = (start + end) // 2\n\n    if array[middle] == search_value:\n        return middle\n    elif array[middle] < search_value:\n        return binary_search(array, middle + 1, end, search_value)\n    else:\n        return binary_search(array, start, middle - 1, search_value)\n\n    \ndef top_condisioned(array, start_value):\n    helper_array = sorted_set(array.copy())\n    helpers_end = len(helper_array) - 1\n    ubication =  binary_search(helper_array, 0, helpers_end, start_value)\n    \n    top_condisioned = []\n    for i in range(ubication, helpers_end):\n        top_condisioned.append(helper_array[i])\n\n    return top_condisioned\n\ndef counted_array(elements_to_count, original_array):\n    count_array = []\n    for value in range(len(elements_to_count)):\n        count_array.append(original_array.count(elements_to_count[value]))\n    \n    return count_array\n\ndef sorted_set(array):\n    reduced_set = set(array)\n    reduced_array = []\n    for element in reduced_set:\n        reduced_array.append(element)\n    reduced_array = merge_sort(reduced_array)\n\n    return reduced_array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"topc_reviews = top_condisioned(reviews, 1000)\nprint(f'Cantidad de libros con más de 1,000 reviews: {len(topc_reviews)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Debido al valor alto, comparado con el número de calificaciones de 5 estrellas, de más de 1,000 receñas, y recordando lo escasos que son los libros con calificaciones mayores a 4.5, podemos buscar los libros que hagan match con estas dos ideas. Primero obteniendo el arreglo con calificaciones mayores a 4.5","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"topc_rating = top_condisioned(rating, 4.5)\nprint(f'Cantidad de calificaciones disponibles y obtenidas, que sean mayores o igual a 4.5 = {len(topc_rating)}; las cuales son: \\n{topc_rating}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def match_cases(array1, wanted_array1, array2, wanted_array2):\n    \"\"\"Notice de diference: the original data has to be of the samen lenght,\n    BUT the match cases can differ. This means that I can have 3 match cases\n    on one side and 50 in the other, and it won't make any trouble\"\"\"\n    if len(array1)==len(array2):\n        match_cases = []\n\n        #Creating Support dictionaries\n        wanted_cases_1 = {}\n        for data in range(len(wanted_array1)):\n            wanted_cases_1[wanted_array1[data]] = 1\n        \n        wanted_cases_2 = {}\n        for data in range(len(wanted_array2)):\n            wanted_cases_2[wanted_array2[data]] = 1\n        \n        for ub in range(len(array1)):\n            val1 = array1[ub]\n            val2 = array2[ub]\n            if val1 in wanted_cases_1 and val2 in wanted_array2:\n                match_cases.append(ub)\n            \n        return match_cases\n\n    else: return 'Arrays must have the samen lenght'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Con la función diseñada, procedemos a insertar los arreglos originales, acompañados de los sets en los que se encuentran los valores permitidos. Cabe resaltar que esta función solo encuentra la ubicación de los valores donde nuestros universos y condiciones se encuentran, más no otorga el libro resultante, ya que no se introduce este dato en la función.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"match_cases = match_cases(rating, topc_rating, reviews, topc_reviews)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Estos casos, denominados \"mejor evaluados\" (bv), se almacenarán un DataFrame distinto, para analizar de forma más fácil su output.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bv_rate = []\nfor ub in match_cases:\n    bv_rate.append(rating[ub])\n\nbv_reviews = []\nfor ub in match_cases:\n    bv_reviews.append(reviews[ub])    \n    \nbv_titles = []\nfor ub in match_cases:\n    bv_titles.append(titles[ub])\n    \nbv_books_dict = {'rating': bv_rate,\n             'reviews': bv_reviews,\n             'titles': bv_titles}\n\nbv_books_df = pd.DataFrame(bv_books_dict, columns=['rating','reviews','titles'])\nbv_books_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ordenando los valores según la columna de reviews, podremos obtener el libro con mayor número de reviews y que tenga una calificación mayor a 4.5. Considerándolo por ende, uno de los mejores libros calificados en este Data Set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bv_books_df.sort_values(by = 'reviews', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Caso contrario. Solo considerar Reviews</h3>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Los siguientes chuncks fueron diseñados para obtener el \"top\" deseado de una serie de elementos numéricos, permitiendo la observación de una tabla dónde solo se consideran los 7 libros con más reviews. Este número fue escogido por la cantidad de coincidencias obtenidas para el DataFrame anterior.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def topx(array, top_size):\n    \"\"\"Considerations.\n    1) Array is ORDERED from minor to major.\n    2) You can insert Arrays with duplicated values.\n    3) You won't insert Sets.\"\"\"\n\n    sorted_and_reduced_array = sorted_set(array.copy())\n    position = len(sorted_and_reduced_array) - 1\n    \n    topx = []\n    value = sorted_and_reduced_array[position]\n    topx.append(value)\n\n    position -= 1\n    max_value = value\n    value = sorted_and_reduced_array[position]\n\n    top_values = 1 \n\n    while top_values < top_size and position >= 0 :\n        if value != max_value:\n            topx.append(sorted_and_reduced_array[position])\n            max_value = value\n            top_values += 1\n        position -= 1\n        value = sorted_and_reduced_array[position]\n\n    return topx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top7_reviews = topx(reviews, 7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def match_top_cases(array1, wanted_array1):\n        match_cases = []\n\n        #Creating Support dictionaries\n        wanted_cases_1 = {}\n        for data in range(len(wanted_array1)):\n            wanted_cases_1[wanted_array1[data]] = 1\n        \n        for ub in range(len(array1)):\n            val1 = array1[ub]\n            if val1 in wanted_cases_1:\n                match_cases.append(ub)\n            \n        return match_cases","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ub_top7r = match_top_cases(reviews, top7_reviews)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def array_matches(match_array, array1, array2, array3):\n    \n    match_array1 = []\n    for ub in match_array:\n        match_array1.append(array1[ub])\n\n    match_array2 = []\n    for ub in match_array:\n        match_array2.append(array2[ub])    \n\n    match_array3 = []\n    for ub in match_array:\n        match_array3.append(array3[ub])\n    \n    return match_array1,match_array2,match_array3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t7rev_rating, t7rev_reviews, t7rev_titles = array_matches(ub_top7r, rating, reviews, titles)\n    \ntop7_books_dict = {'rating': t7rev_rating,\n             'reviews': t7rev_reviews,\n             'titles': t7rev_titles}\n\ntop7_books_df = pd.DataFrame(top7_books_dict, columns=['rating','reviews','titles'])\ntop7_books_df.sort_values(by = 'reviews', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Con esta tabla de resultado, es posible apreciar que el hecho, de que un libro posea un alto número de receñas, no es garantía de una buena calificación, o que sea altamente recomendado.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h2>Comportamiento rating vs reviews</h2>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Debido a los resultados anteriores, se decide implementar un gráfico de puntos \"rating vs reviews\". Este gráfico podrá servir para explicar mejor lo que sucede si solo se consideran el número de receñas.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"books_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = books_df.plot(kind=\"scatter\", x='rating', y='reviews', c='green')\n\nx = books_df['rating']\nplt.axvline(np.mean(x)-np.std(x), c = 'k', linestyle = ':', label = '-1 desv. std.')\nplt.axvline(np.mean(x), c = 'r', linestyle = '-', label = 'Promedio')\nplt.axvline(np.mean(x)+np.std(x), c = 'k', linestyle = ':', label = '+1 desv. std.')\n\ny = books_df['reviews']\nplt.axhline(np.mean(y)-np.std(y), c = 'c', linestyle = ':', label = 'Y: -1 desv. std.')\nplt.axhline(np.mean(y), c = 'b', linestyle = '-', label = 'Promedio y')\nplt.axhline(np.mean(y)+np.std(y), c = 'c', linestyle = ':', label = 'Y: +1 desv. std.')\n\nfig.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Este gráfico presenta una condensación de los puntos entre una calificación de 3.5 y 4.5 y menores a 20,000 reviews. Para el caso de libros mayores a 4.5 podemos observar que no existe un repunte ni libros que traspasen dicho rango, pero sí que los puntos con mayor número de reviews se encuentran igual en dicho rango.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h1>Conclusiones</h1>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<ol>\n<li>Un libro tenga una calificación de 5 estrellas no es garantía de que a mucha gente le haya parecido un libro excelente</li>\n<li>Que un libro haya sido leído por mucha gente, no garantiza que a todos les haya parecido un libro excelente</li>\n<li>Siempre hay que considerar todas las variables disponibles y relevantes de un Data Set</li>\n<li>Conforme más condiciones agreguemos a nuestros análisis, nuestras deducciones pueden ser más precisas y objetivas</li>\n</ol>","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}