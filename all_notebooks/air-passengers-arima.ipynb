{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#load libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.stattools import acf, pacf\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nprint(\"Setup Complete\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/air-passengers/AirPassengers.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print the first 5 and last 5 rows of the data\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get the summary of the data\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that our data has only 2 columns i.e Month column and #Passengers column. We have a total of 144 entries and our data does not contain missing values. The Month column is object datatype so it will be imposible to use the model on the data. We will change the object type to datetime."},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Parse strings to datetime type\ndf['Month'] = pd.to_datetime(df['Month'], infer_datetime_format = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfin = df.set_index('Month',inplace=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfin","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfin.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Month column has been successfully changed to datetime and set as the index."},{"metadata":{},"cell_type":"markdown","source":"# Data Visualization\nWe will plot a graph to see how the data is distributed through time."},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot graph\nplt.xlabel(\"Date\")\nplt.ylabel(\"Number of Air Passengers\")\nplt.plot(dfin)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Just by looking at the plot, we can see that there is an increase in the number of air passengers form the year 1950 to 1960. Therefore, the data is not stationary.\n"},{"metadata":{},"cell_type":"markdown","source":"# Stationarity\nWe will use Dickey-Fuller test to check for stationarity"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Determining rolling statistics\nrolmean = dfin.rolling(window=12).mean()\nrolstd = dfin.rolling(window=12).std()\nprint(rolmean, rolstd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_stationarity(timeseries):\n    \n    #Determine rolling statistics\n    movingaverage = timeseries.rolling(window=12).mean()\n    movingstd = timeseries.rolling(window=12).std()\n    \n    #Plot rolling statistics\n    plt.plot(timeseries, color='blue', label='Original')\n    plt.plot(movingaverage, color='red', label='Rolling Mean')\n    plt.plot(movingstd, color='green', label='Rolling Std')\n    plt.legend(loc='best')\n    plt.title('Rolling Mean & Standard Deviation')\n    plt.show(block=False)\n    \n    #Perform Dickeyâ€“Fuller test:\n    print('Dickey Fuller Test Results:')\n    adftest = adfuller(timeseries['#Passengers'], autolag='AIC')\n    adfresult = pd.Series(adftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in adftest[4].items():\n        adfresult['Critical Value (%s)'%key] = value\n    print(adfresult)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_stationarity(dfin)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plot shows our original data in blue, the Rolling Mean in red and the Rolling Std in green. The Rolling Mean has a clearly upward trend whereas the Rolling Standard Deviation has a slightly upward trend. We could also say the rolling Standard Deviation is slightly constant. "},{"metadata":{},"cell_type":"markdown","source":"The p-value is low, although larger than the Test Statistic, so we can reject the null hypothesis of stationarity to say that our data is not stationary."},{"metadata":{},"cell_type":"markdown","source":"# Transformations\nWe will adjust our data to achieve simpler forecasting. We do this to simplify the patterns in the historical data by removing known sources of variation and try try to make the pattern constant across the timeseries. This will lead to a more accurate forecast."},{"metadata":{},"cell_type":"markdown","source":"To achieve Stationarity, we will transform our data through the log transformation. We do this to remove the trend component."},{"metadata":{"trusted":true},"cell_type":"code","source":"dfin_log = np.log(dfin)\nplt.plot(dfin_log)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The value of y has been changed to log values but the value of x remains the same.\n\nNow we will calculate the rolling statistics  with the same window of 12. "},{"metadata":{"trusted":true},"cell_type":"code","source":"rolmean_log = dfin_log.rolling(window=12).mean()\nrolstd_log = dfin_log.rolling(window=12).std()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(dfin_log, color='blue', label='Original')\nplt.plot(rolmean_log, color='red', label='Rolling Mean')\nplt.plot(rolstd_log, color='green', label='Rolling Std')\nplt.legend(loc='best')\nplt.title('Rolling Mean & Standard Deviation (Log Scale)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The time series as well as the rolling mean have a trend component. We will subtract the rolling mean scale from the time series in order to remove the trend component."},{"metadata":{"trusted":true},"cell_type":"code","source":"newdfin = dfin_log - rolmean_log\nnewdfin\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will remove the NaN values. "},{"metadata":{"trusted":true},"cell_type":"code","source":"newdfin.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newdfin","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_stationarity(newdfin)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Subtracting the rolling mean scale from the time series removed the trend component. We can see that the data is now stationary. The p-value has been reduced from 0.99 to 0.022, and the test statistic value is almost similar to the critical values."},{"metadata":{"trusted":true},"cell_type":"code","source":"#time shift transformation\ndfin_log_diff = dfin_log - dfin_log.shift()\nplt.plot(dfin_log_diff)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfin_log_diff","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove the Nan values\ndfin_log_diff.dropna(inplace=True)\nplt.plot(dfin_log_diff)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfin_log_diff","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_stationarity(dfin_log_diff)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above plot appears to be the best series. The rolling mean and the rolling standard deviation are fairly constant.\n\nThe Dickey-Fuller test however has a p-value of 0.07 which is higher than the previous 0.02. Test Statistic value is not as close to the critical values as well.\n\nWe will now break down the 3 components of the log scale series namely: \n* trend\n* seasonality\n* residuals\n\nWe will use a system libary function. Once separated, we can ignore trend & seasonality and check on the nature of the residuals."},{"metadata":{"trusted":true},"cell_type":"code","source":"decomposition = seasonal_decompose(dfin_log)\n\ntrend = decomposition.trend\nseasonal = decomposition.seasonal\nresidual = decomposition.resid\n\nplt.subplot(411)\nplt.plot(dfin_log, label='Original')\nplt.legend(loc='best')\n\nplt.subplot(412)\nplt.plot(trend, label='Trend')\nplt.legend(loc='best')\n\nplt.subplot(413)\nplt.plot(seasonal,label='Seasonality')\nplt.legend(loc='best')\n\nplt.subplot(414)\nplt.plot(residual, label='Residuals')\nplt.legend(loc='best')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfin_decompose = residual\ndfin_decompose.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rollingmean_decompose = dfin_decompose.rolling(window=12).mean()\nrollingstd_decompose = dfin_decompose.rolling(window=12).std()\n\nplt.plot(dfin_decompose, color='blue', label='Original')\nplt.plot(rollingmean_decompose, color='red', label='Rolling Mean')\nplt.plot(rollingstd_decompose, color='green', label='Rolling Std')\nplt.legend(loc='best')\nplt.title('Rolling Mean & Standard Deviation')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ACF and PACF"},{"metadata":{"trusted":true},"cell_type":"code","source":"lag_acf = acf(dfin_log_diff, nlags=20)\nlag_pacf = pacf(dfin_log_diff, nlags=20, method='ols')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting ACF:\nplt.subplot(121)\nplt.plot(lag_acf)\nplt.axhline(y=0, linestyle='--', color='red')\nplt.axhline(y=-1.96/np.sqrt(len(dfin_log_diff)), linestyle='--', color='red')\nplt.axhline(y=1.96/np.sqrt(len(dfin_log_diff)), linestyle='--', color='red')\nplt.title('Autocorrelation Function')            \n\n#Plotting PACF\nplt.subplot(122)\nplt.plot(lag_pacf)\nplt.axhline(y=0, linestyle='--', color='red')\nplt.axhline(y=-1.96/np.sqrt(len(dfin_log_diff)), linestyle='--', color='red')\nplt.axhline(y=1.96/np.sqrt(len(dfin_log_diff)), linestyle='--', color='red')\nplt.title('Partial Autocorrelation Function')\n            \nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The ACF graph shows the curve touching y=0.0 line at x=2. Thus, from theory, Q = 2. The PACF graph shows the curve touching y=0.0 line at x=2. Thus, from theory, P = 2\n\nARIMA is AR + I + MA. Before implementing ARIMA model, let us check the results of the individual AR & MA model. These models will give a value of RSS. Lower the RSS values indicates a better model.\n"},{"metadata":{},"cell_type":"markdown","source":"# AR Model\nMaking order = (2,1,0)"},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = ARIMA(dfin_log, order=(2,1,0))\nresults_AR = model1.fit(disp=-1)\nplt.plot(dfin_log_diff)\nplt.plot(results_AR.fittedvalues, color='red')\nplt.title('RSS: %.4f'%sum((results_AR.fittedvalues - dfin_log_diff['#Passengers'])**2))\nprint('AR model')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MA Model\nMaking order = (0,1,2)"},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = ARIMA(dfin_log, order=(0,1,2))\nresults_MA = model2.fit(disp=-1)\nplt.plot(dfin_log_diff)\nplt.plot(results_MA.fittedvalues, color='red')\nplt.title('RSS: %.4f'%sum((results_MA.fittedvalues - dfin_log_diff['#Passengers'])**2))\nprint('MA model')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ARIMA Model\nMaking order = (2,1,2)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ARIMA(dfin_log, order=(2,1,2))\nresults_ARIMA = model.fit(disp=-1)\nplt.plot(dfin_log_diff)\nplt.plot(results_ARIMA.fittedvalues, color='red')\nplt.title('RSS: %.4f'%sum((results_ARIMA.fittedvalues - dfin_log_diff['#Passengers'])**2))\nprint('ARIMA model')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**RSS values**\n* AR Model = 1.5023\n* MA Model = 1.4721\n* ARIMA Model = 1.0292\n\nARIMA Model is better than the individual AR and MA Models.\n\nWe will move on to generate the predictions but we need to reconvert the predictions back to original form first before we do prediction plots. This is because we built our model on log transformed data."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prediction and reverse transformation\npredictions_ARIMA_diff = pd.Series(results_ARIMA.fittedvalues, copy=True)\npredictions_ARIMA_diff.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_ARIMA_diff_csum = predictions_ARIMA_diff.cumsum()\npredictions_ARIMA_diff_csum.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_ARIMA_log = pd.Series(dfin_log['#Passengers'].iloc[0], index=dfin_log.index)\npredictions_ARIMA_log = predictions_ARIMA_log.add(predictions_ARIMA_diff_csum, fill_value=0)\npredictions_ARIMA_log.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#inverse of log is exp\npredictions_ARIMA = np.exp(predictions_ARIMA_log)\nplt.plot(dfin)\nplt.plot(predictions_ARIMA)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above plot, we can see that our predicted forecasts are very close to the real time series values. It also indicates a fairly accurate model."},{"metadata":{"trusted":true},"cell_type":"code","source":"dfin_log.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\nWe have 144 (existing data of 12 yrs in months) data points. Now, we want to forecast for additional 10 yrs (10x12 months=120 data points).\n\n144+120 = 264 records/data points\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"results_ARIMA.plot_predict(1,264)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}