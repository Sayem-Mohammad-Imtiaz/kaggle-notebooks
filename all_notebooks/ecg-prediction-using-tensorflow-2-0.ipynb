{"cells":[{"metadata":{},"cell_type":"markdown","source":"Refer to the 'ArXiv 1805.00794'","execution_count":null},{"metadata":{"id":"8zTff37Sj6d8","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, add, ReLU\nfrom tensorflow.keras import Model\nimport matplotlib\nimport matplotlib.pyplot as plt\n\n\ntrain_data = pd.read_csv(\"../input/heartbeat/mitbih_train.csv\", header=None)\ntest_data = pd.read_csv(\"../input/heartbeat/mitbih_test.csv\", header=None)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Processing Pandas dataframe to Numpy array","execution_count":null},{"metadata":{"id":"4iJHRIxKAOWr","executionInfo":{"status":"ok","timestamp":1599711319341,"user_tz":-540,"elapsed":933,"user":{"displayName":"이영빈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiyMS_urIE9fyP18C6LdxPtU72DWEGFgeoaK0_H=s64","userId":"10706824793418709913"}},"outputId":"b22fe589-2d02-4be2-fede-c14b4b67d472","trusted":true},"cell_type":"code","source":"train_information = train_data.iloc[:, :-1].to_numpy()\ntrain_label = train_data.iloc[:, -1].to_numpy()\n\ntest_information = test_data.iloc[:, :-1].to_numpy()\ntest_label = test_data.iloc[:, -1].to_numpy()\n\nprint(test_label)","execution_count":null,"outputs":[]},{"metadata":{"id":"9ra4wGnZ_R99"},"cell_type":"markdown","source":"**Add Gaussian noise to the dataset** It prevents dataset from overfitting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gaussian_flag = 0\n\ndef add_gaussian_noise(signal):\n    noise=np.random.normal(0,0.05,187)\n    return (signal+noise)\n\ntempo=train_information[20]\nprint(train_label[0])\nbruiter=add_gaussian_noise(tempo)\n\nplt.subplot(2,1,1)\nplt.plot(tempo)\n\nplt.subplot(2,1,2)\nplt.plot(bruiter)\n\nplt.show()\n\ntrain_information = add_gaussian_noise(train_information)\ngaussian_flag = not gaussian_flag","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Add a channel for convolutional layer","execution_count":null},{"metadata":{"id":"3rI94-LaiVlp","executionInfo":{"status":"ok","timestamp":1599711332144,"user_tz":-540,"elapsed":666,"user":{"displayName":"이영빈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiyMS_urIE9fyP18C6LdxPtU72DWEGFgeoaK0_H=s64","userId":"10706824793418709913"}},"outputId":"0010f0c2-aef5-4079-a748-a0f49a3b1fd8","trusted":true},"cell_type":"code","source":"train_information = train_information[..., tf.newaxis]\ntest_information = test_information[..., tf.newaxis]\n\nprint(train_information.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Batch the dataset to enhance performance","execution_count":null},{"metadata":{"id":"IDnD0ZS6AoE_","trusted":true},"cell_type":"code","source":"BATCH_SIZE = 64\n\ntrain_ds = tf.data.Dataset.from_tensor_slices(\n    (train_information, train_label)).shuffle(10000).batch(BATCH_SIZE )\ntest_ds = tf.data.Dataset.from_tensor_slices(\n    (test_information, test_label)).batch(BATCH_SIZE )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Construct the model by using Keras subclass API. This model is from the paper 'ArXiv 1805.00794'","execution_count":null},{"metadata":{"id":"p6n7PgbIXLy9","trusted":true},"cell_type":"code","source":"class MyModel(Model):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        self.conv_in = Conv1D(32, input_shape=(None, 187, 1), kernel_size=(5), strides=1,\n                              padding='same', activation='relu')\n        self.conv_relu = Conv1D(32, kernel_size=(5), strides=1,\n                           padding='same', activation='relu')\n        self.conv_raw = Conv1D(32, kernel_size=(5), strides=1,\n                              padding='same')\n        self.maxpool = MaxPooling1D(pool_size=5, strides=2)\n        self.flatten = Flatten()\n        self.relu = ReLU()\n        self.dense = Dense(32, activation='relu')\n        self.dense_out = Dense(5, activation='softmax')\n\n    def routine(self, x):\n        input_param = x\n        x = self.conv_relu(x)\n        x = self.conv_raw(x)\n        x = add([input_param, x])\n        x = self.relu(x)\n        return self.maxpool(x)\n\n    def call(self, x):\n        x = self.conv_in(x)\n        for _ in range(5):\n            x = self.routine(x)\n\n        x = self.flatten(x)\n\n        x = self.dense(x)\n        return self.dense_out(x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Set Loss function & Optimizer and training & test sequence.","execution_count":null},{"metadata":{"id":"iHkY9QQCXMR1","trusted":true},"cell_type":"code","source":"model = MyModel()\n\n# Loss Func. SCC\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n\n# Opimizer Adam\noptimizer = tf.keras.optimizers.Adam()\n\ntrain_loss = tf.keras.metrics.Mean(name='train_loss')\ntrain_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n\ntest_loss = tf.keras.metrics.Mean(name='test_loss')\ntest_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n\n\n@tf.function\ndef train_step(images, labels):\n    with tf.GradientTape() as tape:\n        predictions = model(images)\n        loss = loss_object(labels, predictions)\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n    train_loss(loss)\n    train_accuracy(labels, predictions)\n\n\n@tf.function\ndef test_step(images, labels):\n    predictions = model(images)\n    t_loss = loss_object(labels, predictions)\n\n    test_loss(t_loss)\n    test_accuracy(labels, predictions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's get it started.","execution_count":null},{"metadata":{"id":"DkWm0YxLYKBL","executionInfo":{"status":"ok","timestamp":1599710783037,"user_tz":-540,"elapsed":447078,"user":{"displayName":"이영빈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiyMS_urIE9fyP18C6LdxPtU72DWEGFgeoaK0_H=s64","userId":"10706824793418709913"}},"outputId":"b3929669-a303-4863-a2d1-7af85dfe0c82","trusted":true},"cell_type":"code","source":"EPOCHS = 75\n\ntrain_loss_results = []\ntrain_accuracy_results = []\n\ntest_loss_results = []\ntest_accuracy_results = []\n\n\nfor epoch in range(EPOCHS):\n    for images, labels in train_ds:\n        train_step(images, labels)\n\n    for test_images, test_labels in test_ds:\n        test_step(test_images, test_labels)\n\n    train_loss_results.append(train_loss.result())\n    train_accuracy_results.append(train_accuracy.result())\n\n    test_loss_results.append(test_loss.result())\n    test_accuracy_results.append(test_accuracy.result())\n\n    template = 'EPOCH: {}, LOSS: {}, ACCURACY: {}, TEST LOSS: {}, TEST ACCURACY: {}'\n    if (epoch + 1) % 5 == 0:\n        print(template.format(epoch + 1,\n                              train_loss.result(),\n                              train_accuracy.result() * 100,\n                              test_loss.result(),\n                              test_accuracy.result() * 100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visual results.","execution_count":null},{"metadata":{"id":"Gw3zedjnaOT7","executionInfo":{"status":"ok","timestamp":1599711684195,"user_tz":-540,"elapsed":1536,"user":{"displayName":"이영빈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiyMS_urIE9fyP18C6LdxPtU72DWEGFgeoaK0_H=s64","userId":"10706824793418709913"}},"outputId":"16d9baef-23cd-4efd-8f12-64a174852023","trusted":true},"cell_type":"code","source":"COLOR = 'white'\nmatplotlib.rcParams['text.color'] = COLOR\nmatplotlib.rcParams['axes.labelcolor'] = COLOR\nmatplotlib.rcParams['xtick.color'] = COLOR\nmatplotlib.rcParams['ytick.color'] = COLOR\n\nfig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\nfig.suptitle('Training Results', fontsize=20)\n\naxes[0].set_ylabel(\"Loss\", fontsize=14)\naxes[0].plot(train_loss_results)\naxes[0].grid()\n\naxes[1].set_xlabel(\"Epoch\", fontsize=14)\naxes[1].set_ylabel(\"Accuracy\", fontsize=14)\naxes[1].plot(train_accuracy_results)\naxes[1].grid()\n\n\nfig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\nfig.suptitle('Test Results', fontsize=20)\n\naxes[0].set_ylabel(\"Loss\", fontsize=14)\naxes[0].plot(test_loss_results)\naxes[0].grid()\n\naxes[1].set_xlabel(\"Epoch\", fontsize=14)\naxes[1].set_ylabel(\"Accuracy\", fontsize=14)\naxes[1].plot(test_accuracy_results)\naxes[1].grid()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"aGNYPh5cuGmR","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}