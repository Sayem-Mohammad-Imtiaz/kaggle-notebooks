{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Support Vector Machines - Nonlinear Classification\n### with GridSearch"},{"metadata":{},"cell_type":"markdown","source":"### All needed imports for this notebook"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\npd.options.display.max_colwidth = 80\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OrdinalEncoder\n\nfrom sklearn.svm import SVC # SVM model with kernels\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Fetching Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = '/kaggle/input/car-evaluation-data-set/car_evaluation.csv'\n\nheader_list = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class value']\n\ncars = pd.read_csv(data, names=header_list, index_col=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exploring Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"cars.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cars.info(), cars.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### **Destribution frequency of values in each variable.** Judging by the output, *stratified sampling* is not needed since all data instances seem to be evenly good splitted"},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in cars.columns:\n    print(cars[column].value_counts(), '\\n') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### I had an idea that number of doors can somehow correlate with luggage capacity, but seems that *lug_boot* value does not depended on that"},{"metadata":{"trusted":true},"cell_type":"code","source":"a = cars.loc[cars['doors'] == '2', ['lug_boot']]\nb = cars.loc[cars['doors'] == '3', ['lug_boot']]\nc = cars.loc[cars['doors'] == '4', ['lug_boot']]\nd = cars.loc[cars['doors'] == '5more', ['lug_boot']]\n\nprint(a['lug_boot'].value_counts(), '\\n\\n', b['lug_boot'].value_counts(), '\\n\\n', \n      c['lug_boot'].value_counts(), '\\n\\n', d['lug_boot'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Feature and Target vectors"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = cars.drop(['class value'], axis=1)\ny = cars['class value']\n\nX, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Encoding\n#### There are a limited number of possible values, each of which represents a category, which means that all the variables in dataset are of ordinal categorical data type. Most Machine Learning algorithms prefer to work with numbers, so let’s convert these categories from text to numbers. For this, we can use Scikit-Learn’s OrdinalEncoder class:"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_encode = []\ncolumns_encode.append(header_list)\ncolumns_encode","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_encoder = OrdinalEncoder()\n\nX_train = ordinal_encoder.fit_transform(X_train, columns_encode)\nX_test = ordinal_encoder.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train, y_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Using GridSearch to find the best hyperparameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = [{'kernel': ['poly'], 'C' : [3, 5, 7, 9, 10]},\n             {'kernel' : ['rbf'], 'C' : [3, 5, 7, 9, 10], 'gamma' : [2, 4, 6, 8]}]\n\nsvm = SVC()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search = GridSearchCV(svm, param_grid, return_train_score=True)\n\ngrid_search.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Estimated best hyperparameters for SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### GridSearcg estimated the best model to be with polynomial kernel of ninth degree"},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_y_pred = grid_search.predict(X_test)\n\naccuracy_score(y_test, svm_y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_y_pred_train = grid_search.predict(X_train)\n\naccuracy_score(y_train, svm_y_pred_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Accuracy of training test is a little bit higher, but it's clearly not overfit, so I guess tthe model did very good"},{"metadata":{},"cell_type":"markdown","source":"#### Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, svm_y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, svm_y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}