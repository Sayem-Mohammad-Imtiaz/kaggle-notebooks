{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, PolynomialFeatures\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import mean_absolute_error, r2_score\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:37:51.692984Z","iopub.execute_input":"2021-06-09T01:37:51.693785Z","iopub.status.idle":"2021-06-09T01:37:52.803345Z","shell.execute_reply.started":"2021-06-09T01:37:51.693675Z","shell.execute_reply":"2021-06-09T01:37:52.802371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the data\npath='../input/regression/Ames_Housing_Sales.csv'\nhousing_data=pd.read_csv(path)\nhousing_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:38:24.794884Z","iopub.execute_input":"2021-06-09T01:38:24.795276Z","iopub.status.idle":"2021-06-09T01:38:24.904859Z","shell.execute_reply.started":"2021-06-09T01:38:24.795241Z","shell.execute_reply":"2021-06-09T01:38:24.903612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#view the basic info of the data\nhousing_data.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:38:28.597658Z","iopub.execute_input":"2021-06-09T01:38:28.598002Z","iopub.status.idle":"2021-06-09T01:38:28.631532Z","shell.execute_reply.started":"2021-06-09T01:38:28.597972Z","shell.execute_reply":"2021-06-09T01:38:28.630316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get the idea about the outliers and whether it needs scalling or not\nhousing_data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:38:35.529753Z","iopub.execute_input":"2021-06-09T01:38:35.530151Z","iopub.status.idle":"2021-06-09T01:38:35.811051Z","shell.execute_reply.started":"2021-06-09T01:38:35.530116Z","shell.execute_reply":"2021-06-09T01:38:35.809874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask = housing_data.dtypes == np.object","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:38:36.040099Z","iopub.execute_input":"2021-06-09T01:38:36.040642Z","iopub.status.idle":"2021-06-09T01:38:36.045072Z","shell.execute_reply.started":"2021-06-09T01:38:36.040605Z","shell.execute_reply":"2021-06-09T01:38:36.044279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#separate categorical and numerical columns\ncategorical_col = housing_data.dtypes[mask].index\nnumerical_col = housing_data.dtypes[~mask].index","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:38:36.072046Z","iopub.execute_input":"2021-06-09T01:38:36.072519Z","iopub.status.idle":"2021-06-09T01:38:36.077155Z","shell.execute_reply.started":"2021-06-09T01:38:36.072489Z","shell.execute_reply":"2021-06-09T01:38:36.076501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a copy fo data (good practice this way you don't loose original data)\nhousing_data_copy=housing_data.copy()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:38:36.106203Z","iopub.execute_input":"2021-06-09T01:38:36.10672Z","iopub.status.idle":"2021-06-09T01:38:36.111181Z","shell.execute_reply.started":"2021-06-09T01:38:36.106675Z","shell.execute_reply":"2021-06-09T01:38:36.110121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def scatterplot(data,x,y):\n    \"\"\"\n        function takes \n        data : Dataframe\n        x : x-axis\n        y : y_axis\n        \n        Returns\n        ScatterPlot between x and y\n    \"\"\"\n    sns.scatterplot(data=housing_data_copy,x=x,y=y)\n    plt.title(\"Plot Between \"+x+\" And Sales Price\")\n    return plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:38:36.136756Z","iopub.execute_input":"2021-06-09T01:38:36.137095Z","iopub.status.idle":"2021-06-09T01:38:36.142523Z","shell.execute_reply.started":"2021-06-09T01:38:36.137064Z","shell.execute_reply":"2021-06-09T01:38:36.141642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in numerical_col:\n    scatterplot(housing_data_copy,col,'SalePrice')","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:38:36.176801Z","iopub.execute_input":"2021-06-09T01:38:36.177197Z","iopub.status.idle":"2021-06-09T01:38:43.017977Z","shell.execute_reply.started":"2021-06-09T01:38:36.17716Z","shell.execute_reply":"2021-06-09T01:38:43.016689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Analysis For Numerical columns\n    - 1stFlrSF\n        - It is so much in Linear relation with the SalePrice.\n        - As the value increase the SalePrize also increased.\n    - 1ndFlrSF\n        - It is in polynomial relation with the SalePrice.\n        - As the value increse the SalePrize increased Rapidly.\n    - 3SsnPorch\n        - Most of the Data are zero.\n        - Data which are not zero, Is too much scatter.\n        - No underlying pattern.\n        - Choose to Drop the Column.\n    - BedroomAbvGr\n        - Houses having BedroomAbvGr in between 1-4 have more SalesPrice.\n        - Houses having more or less BedroomAbvGr are less SalesPrice.\n    - BsmtFinSF1\n        - Some values are zero still have significant high SalePrice.\n        - Non-Zero Values have a rising pattern as the BsmtFinSF1 increases.\n    - BsmtFinSF2\n        - Most values are zero and still have a lot higher SalePrice.\n        - Non-Zero Values are mid-ranged SalePrice, where as zero values houses are but priced more and less.\n        - SalePrice is not dependent on BsmtFinSF2.\n        - Choose to drop the column.\n    - BsmtFullBath\n        - Houses having no or 1 BsmtFullBath are priced more than the rest.\n        - It indicate having more BsmtFullBath doesn't necessarily mean to have a higher price.\n    - BsmtHalfBath\n        - Having 0 BsmtHalfBath have more SalePrice.\n        - Values having anything more then 0 offer less maximum SalePrice but the minimum SalePrice of the house is incresed significantly.\n    - BsmtUnfSF\n        - Although the Data seems to be scattered, but examaning closely we can find that it is having polynomial relationship with SalePrice.\n        - At first the values are constant as doesn't shows any deviation, later as the values keep increasing the SalePrice tends to increase.\n    - EnclosedPorch\n        - Most of the houses have no EnclosedPorch still they have a high SalePrice.\n        - While those houses having a fireplace shows no change in SalePrice.\n        - Choose to drop the column.\n    - Fireplaces\n        - Clearly visible as the number of fireplace increases the SalePrice of the house increase.\n        - However the after a certain point it Started being constant and then started decreasing.\n    - FullBath\n        - It can be seen that the variable have a polynomial relationship with SalePrice.\n        - As the values increase the SalePrice increases.\n    - GarageArea\n        - We can see there is gradual increase in SalePrice as the values increase.\n        - And for extreme high values they decrease.\n    - GarageCars\n        - It can be seen that the variable have a polynomial relationship with SalePrice.\n        - Minimum price of SalePrice of the houses increase with increase in values.\n    - GarageYrBlt\n        - Newly built are more prefered by the consumers and are more valuable than other.\n        - And have more SalePrice values thean the older ones.\n    - GrLivArea\n        - It can be seen that the variable have a polynomial relationship with SalePrice.\n        - SalePrice is in increaing pattern with the value.\n    - HalfBath\n        - Having 1 HalfBath have more SalePrice.\n        - As number of Halfbath increases minimum SalePrice of the house also increases.\n    - KitchenAbvGr\n        - Haivng 1 KitchenAbvGr tends to have higher SalePrice.\n        - However as number of KitchenAbvGr increases minimum SalePrice of the house also increases.\n    - LotArea\n        - Haivng a decent LotArea offers a high SalePrice.\n        - Having too large or too short lot area offers low SalePrice.\n    - LotFrontage\n        - Data is concentrated to one point.\n        - It doesn't affect the SalePrice much.\n        - Choose to drop the column.\n    - LowQualFinSF\n        - Most of the data points are zero.\n        - non-zero data points doesn't have any underlying pattern.\n        - Choose to drop the column.\n    - MSSubClass\n        - The data points have too much uncertainity.\n        - For low value of MSSubClass SalePrice if too low and started increasing, then falls down and started increasing again aftere some time.\n        - the reason can be that it is not contributing towards the SalePrice of the houses.\n        - Choose to drop the column.\n    - MasVnrArea\n        - Although the data points are zero.\n        - but we can observe that the SalePrice is in increasing order with respect to MasVnrArea.\n    - MiscVal\n        - Many values are zero still the manage to get a higher SalePrice.\n        - Clearly mean that this feature is not contributing towards the SalePrice.\n        - Choose to drop the column.\n    - MoSold\n        - We can se the graph is constant for each case.\n        - We cant interpret any pattern from the visulization.\n        - Choose to drop the column\n    - OpenPorchSF\n        - Most of the values are zero.\n        - for non zero values as the price increases the minimum SalePrice also increases.\n    - OverallCond\n        - The better the condition of the house the higher SalePrice it will be.\n        - Also the minimum SalePrice of the house is also increased.\n    - OverallQual\n        - The Quality of house increases it increase teh SalePrice to a large extent.\n        - It can be an important feature in the dataset\n    - PoolArea\n        - 98% of the values are zero and still have high SalePrice.\n        - This is clear it is not an important predictor.\n    - ScreenPorch\n        - Most values are zero.\n        - For Non-zero values as the value of ScreenPorch increase minimum SalePrice of the house also increases.\n    - TotRmsAbvGrd\n        - It can be seen that the variable have a polynomial relationship with SalePrice.\n        - Also the minimum SalePrice of the house is also increased.\n    - TotalBsmtSF\n        - Increase in TotalBsmtSF will result in increase in SalePrice.\n        - It is due to the polynomial relationship exist between them.\n    - WoodDeckSF\n        - Having WoodDeckSF will definitely increase the SalePrice \n        - Also the minimum SalePrice of the house is also increased.\n    - YearBuilt\n        - Latest bulit houses are tend to sell at higher SalePrice.\n        - Also there are high number of new built houses.\n    - YearRemodAdd\n        - Houses with range in 1980 to 2000 are tend to have high minimum SalePrice.\n        - while other for others we can see the increasing pattern in SalePrice\n    - YrSold\n        - We can observe that it is constant throughout.\n        - Conclusively we can say it doesn't contribute in SalePrice.","metadata":{}},{"cell_type":"code","source":"#drop unwanted column\ncolumns_to_drop=['3SsnPorch','BsmtFinSF2','EnclosedPorch','LotFrontage','LowQualFinSF','MSSubClass','MiscVal','MoSold','SalePrice']","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:38:43.019838Z","iopub.execute_input":"2021-06-09T01:38:43.020166Z","iopub.status.idle":"2021-06-09T01:38:43.025701Z","shell.execute_reply.started":"2021-06-09T01:38:43.020132Z","shell.execute_reply":"2021-06-09T01:38:43.024657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#redefine numerical column\nnumerical_col = list((set(numerical_col)-set(columns_to_drop)))","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:38:43.028367Z","iopub.execute_input":"2021-06-09T01:38:43.028822Z","iopub.status.idle":"2021-06-09T01:38:43.037577Z","shell.execute_reply.started":"2021-06-09T01:38:43.028784Z","shell.execute_reply":"2021-06-09T01:38:43.036543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def countplot(data,x):\n    \"\"\"\n        function takes \n        data : Dataframe\n        x : x-axis\n               \n        Returns\n        Countplot of x\n    \"\"\"\n    sns.countplot(data=housing_data_copy,x=x)\n    plt.title('Countplot for '+x)\n    plt.xticks(rotation=90)\n    \ndef boxplot(data,x,y):\n    \"\"\"\n        function takes \n        data : Dataframe\n        x : x-axis\n        y : y_axis\n        \n        Returns\n        Boxplot between x and y\n    \"\"\"\n    sns.boxplot(data=housing_data_copy,x=x,y=y)\n    plt.title('Boxplot for '+x)\n    plt.xticks(rotation=90)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:38:43.039173Z","iopub.execute_input":"2021-06-09T01:38:43.039541Z","iopub.status.idle":"2021-06-09T01:38:43.051074Z","shell.execute_reply.started":"2021-06-09T01:38:43.039507Z","shell.execute_reply":"2021-06-09T01:38:43.050268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#group the data of categorical columns\n#if any category has less than 100 observations it will combine it under the name Others\n\nfor col in categorical_col:\n    grouped = housing_data_copy.groupby(col)[col].count()\n    for value in grouped.index:\n        if grouped[value]<100:\n            housing_data_copy[col].replace(value,'Others',inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:38:43.052378Z","iopub.execute_input":"2021-06-09T01:38:43.052672Z","iopub.status.idle":"2021-06-09T01:38:43.187762Z","shell.execute_reply.started":"2021-06-09T01:38:43.05264Z","shell.execute_reply":"2021-06-09T01:38:43.186765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in categorical_col:\n    plt.figure(figsize=(13,6))\n    plt.subplot(1,2,1)\n    boxplot(housing_data_copy,col,'SalePrice')\n    plt.subplot(1,2,2)\n    countplot(housing_data_copy,col)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:38:43.189127Z","iopub.execute_input":"2021-06-09T01:38:43.189399Z","iopub.status.idle":"2021-06-09T01:38:56.108338Z","shell.execute_reply.started":"2021-06-09T01:38:43.189373Z","shell.execute_reply":"2021-06-09T01:38:56.107134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now we drop the columns we don't require\ncolumns_to_drop.extend(['BsmtFinType2','Condition2','Electrical','Fence','Functional','MiscFeature','PavedDrive','Street','Utilities','Exterior2nd','Exterior1st','CentralAir','Heating'])","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:38:56.110117Z","iopub.execute_input":"2021-06-09T01:38:56.11056Z","iopub.status.idle":"2021-06-09T01:38:56.116445Z","shell.execute_reply.started":"2021-06-09T01:38:56.110513Z","shell.execute_reply":"2021-06-09T01:38:56.115527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#redefine numerical column\ncategorical_col=list(set(categorical_col)-set(columns_to_drop))","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:38:56.119132Z","iopub.execute_input":"2021-06-09T01:38:56.119445Z","iopub.status.idle":"2021-06-09T01:38:56.128448Z","shell.execute_reply.started":"2021-06-09T01:38:56.119413Z","shell.execute_reply":"2021-06-09T01:38:56.127739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now for Categorical column we should separate out the column for label Encoding and One-Hot Encoding. Because we want to work differently on both.\ncolumn_for_label_encoding=['BsmtCond','BsmtExposure','BsmtQual','Condition1','ExterCond','ExterQual','FireplaceQu','GarageQual','HeatingQC','KitchenQual','GarageCond']\ncolumn_for_hot_encoding=list(set(categorical_col)-set(column_for_label_encoding))","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:38:56.130099Z","iopub.execute_input":"2021-06-09T01:38:56.130375Z","iopub.status.idle":"2021-06-09T01:38:56.140872Z","shell.execute_reply.started":"2021-06-09T01:38:56.130339Z","shell.execute_reply":"2021-06-09T01:38:56.139961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dataframe to store out model results\nScores=pd.DataFrame(columns=['Model','Polynomial_degree','Alpha_value','Train_score(MAE)','Test_score(MAE)','R2_score(test_data)'])","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:38:56.142046Z","iopub.execute_input":"2021-06-09T01:38:56.142503Z","iopub.status.idle":"2021-06-09T01:38:56.156043Z","shell.execute_reply.started":"2021-06-09T01:38:56.142458Z","shell.execute_reply":"2021-06-09T01:38:56.154807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":"# use to labal data if they are in series ('Good',  'Bad', 'Worst)\noe=OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=10)\n\n# use to hot encode the categorical data \nohe=OneHotEncoder(handle_unknown='ignore')\n\n# It is used to scale the numerical data \nss=StandardScaler()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:38:56.157522Z","iopub.execute_input":"2021-06-09T01:38:56.157858Z","iopub.status.idle":"2021-06-09T01:38:56.169515Z","shell.execute_reply.started":"2021-06-09T01:38:56.157826Z","shell.execute_reply":"2021-06-09T01:38:56.168368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Column Transformer will help use to word differently on different columns within a dataframe\ntransformer = ColumnTransformer(transformers=[('num',ss,numerical_col),\n                                           ('ordinal',oe,column_for_label_encoding),\n                                           ('hotencode',ohe,column_for_hot_encoding)])","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:38:56.170881Z","iopub.execute_input":"2021-06-09T01:38:56.171458Z","iopub.status.idle":"2021-06-09T01:38:56.185357Z","shell.execute_reply.started":"2021-06-09T01:38:56.17141Z","shell.execute_reply":"2021-06-09T01:38:56.184336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  Model Creation","metadata":{}},{"cell_type":"code","source":"# It will create folds with in our data frame so we can use them to Validate our model performance over all the present data\nfolds=KFold(n_splits=3,shuffle=True,random_state=10)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:38:56.186569Z","iopub.execute_input":"2021-06-09T01:38:56.187164Z","iopub.status.idle":"2021-06-09T01:38:56.196085Z","shell.execute_reply.started":"2021-06-09T01:38:56.187119Z","shell.execute_reply":"2021-06-09T01:38:56.195418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_column=categorical_col+numerical_col","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:38:56.197455Z","iopub.execute_input":"2021-06-09T01:38:56.198025Z","iopub.status.idle":"2021-06-09T01:38:56.207672Z","shell.execute_reply.started":"2021-06-09T01:38:56.197983Z","shell.execute_reply":"2021-06-09T01:38:56.206688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Seprate out our Features and target variable\nX=housing_data_copy[total_column]\ny=housing_data_copy.SalePrice","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:38:56.208886Z","iopub.execute_input":"2021-06-09T01:38:56.209452Z","iopub.status.idle":"2021-06-09T01:38:56.221662Z","shell.execute_reply.started":"2021-06-09T01:38:56.209408Z","shell.execute_reply":"2021-06-09T01:38:56.220644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###  Linear Regression","metadata":{}},{"cell_type":"code","source":"for deg in [1,2,3]:\n    #adding polynomial expression to data\n    pf=PolynomialFeatures(degree=deg)\n\n    #model creation\n    LR=LinearRegression()\n\n    #creation of preprocessor  and pipeline\n    preprocessor=Pipeline(steps=[('transform',transformer),\n                                 ('polynomial',pf)])\n    model_pipeline=Pipeline(steps=[('preprocess',preprocessor),\n                              ('model',LR)])\n\n    #to collect prediction scores\n    train_score=[]\n    test_score=[]\n    r2_scores=[]\n\n    #iterating over various folds\n    for train_index,test_index in folds.split(X):\n        #train and test data split\n        train_X, train_y = X.iloc[train_index], y.iloc[train_index]\n        test_X, test_y = X.iloc[test_index], y.iloc[test_index]\n\n        #fit data to model\n        model_pipeline.fit(train_X,train_y)\n\n        #train and test prediction\n        pred_test=model_pipeline.predict(test_X)\n        pred_train=model_pipeline.predict(train_X)\n\n        #appending the prediction score in terms of MEAN ABSOLUTE ERROR\n        train_score.append(mean_absolute_error(train_y,pred_train))\n        test_score.append(mean_absolute_error(test_y,pred_test))\n        r2_scores.append(r2_score(test_y,pred_test))\n        \n    Scores=Scores.append(\n        {'Model':'Linear_regression',\n         'Polynomial_degree':deg,\n         'Alpha_value':np.nan,\n         'Train_score(MAE)': np.mean(train_score),\n         'Test_score(MAE)': np.mean(test_score),\n         'R2_score(test_data)': np.mean(r2_scores)},\n        ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:38:56.224069Z","iopub.execute_input":"2021-06-09T01:38:56.224384Z","iopub.status.idle":"2021-06-09T01:41:51.684131Z","shell.execute_reply.started":"2021-06-09T01:38:56.224355Z","shell.execute_reply":"2021-06-09T01:41:51.682592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#alpha values for Lasso and Ridge regression models\nalphas=[10,0.1,0.001,1e-5,1e-9]","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:41:51.685978Z","iopub.execute_input":"2021-06-09T01:41:51.686573Z","iopub.status.idle":"2021-06-09T01:41:51.691077Z","shell.execute_reply.started":"2021-06-09T01:41:51.686526Z","shell.execute_reply":"2021-06-09T01:41:51.690141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lasso Regression","metadata":{}},{"cell_type":"code","source":"for alpha_val in alphas:\n    for deg in [1,2]:\n        pf=PolynomialFeatures(degree=deg)\n        lasso=Lasso(alpha=alpha_val,max_iter=100000,)\n        preprocessor=Pipeline(steps=[('transform',transformer),\n                                     ('polynomial',pf)])\n        model_pipeline=Pipeline(steps=[('preprocess',preprocessor),\n                                       ('linear_model',lasso)])\n\n        #to collect prediction scores\n        train_score=[]\n        test_score=[]\n        r2_scores=[]\n        #iterating over various folds\n        for train_index,test_index in folds.split(X):\n            #train and test data split\n            train_X, train_y = X.iloc[train_index], y.iloc[train_index]\n            test_X, test_y = X.iloc[test_index], y.iloc[test_index]\n            \n            #fit data to model\n            model_pipeline.fit(train_X,train_y)\n            \n            #train and test prediction\n            pred_test=model_pipeline.predict(test_X)\n            pred_train=model_pipeline.predict(train_X)\n            \n            #appending the prediction score in terms of MEAN ABSOLUTE ERROR\n            train_score.append(mean_absolute_error(train_y,pred_train))\n            test_score.append(mean_absolute_error(test_y,pred_test))\n            r2_scores.append(r2_score(test_y,pred_test))\n\n        Scores=Scores.append(\n            {'Model':'Lasso',\n             'Polynomial_degree':deg,\n             'Alpha_value':alpha_val,\n             'Train_score(MAE)': np.mean(train_score),\n             'Test_score(MAE)': np.mean(test_score)},\n            ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:41:51.692662Z","iopub.execute_input":"2021-06-09T01:41:51.693279Z","iopub.status.idle":"2021-06-09T01:53:19.289129Z","shell.execute_reply.started":"2021-06-09T01:41:51.693185Z","shell.execute_reply":"2021-06-09T01:53:19.288019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ridge Regression","metadata":{}},{"cell_type":"code","source":"for alpha_val in alphas:\n    for deg in [1,2,3]:\n        #adding polynomial expression to data\n        pf=PolynomialFeatures(degree=deg)\n        \n        #model creation\n        ridge=Ridge(alpha=alpha_val)\n        \n        #creation of preprocessor  and pipeline\n        preprocessor=Pipeline(steps=[('transform',transformer),\n                                     ('polynomial',pf)])\n        model_pipeline=Pipeline(steps=[('preprocess',preprocessor),\n                                  ('model',ridge)])\n        \n        #to collect prediction scores\n        train_score = []\n        test_score = []\n        r2_scores = []\n        \n        #iterating over various folds\n        for train_index,test_index in folds.split(X):\n            #train and test data split\n            train_X, train_y = X.iloc[train_index], y.iloc[train_index]\n            test_X, test_y = X.iloc[test_index], y.iloc[test_index]\n            \n            #fit data to model\n            model_pipeline.fit(train_X,train_y)\n            \n            #train and test prediction\n            pred_test=model_pipeline.predict(test_X)\n            pred_train=model_pipeline.predict(train_X)\n            \n            #appending the prediction score in terms of MEAN ABSOLUTE ERROR\n            train_score.append(mean_absolute_error(train_y,pred_train))\n            test_score.append(mean_absolute_error(test_y,pred_test))\n            r2_scores.append(r2_score(test_y,pred_test))\n\n        Scores=Scores.append(\n            {'Model':'Ridge',\n             'Polynomial_degree':deg,\n             'Alpha_value':alpha_val,\n             'Train_score(MAE)': np.mean(train_score),\n             'Test_score(MAE)': np.mean(test_score),\n             'R2_score(test_data)': np.mean(r2_scores)},\n            ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:53:19.290806Z","iopub.execute_input":"2021-06-09T01:53:19.291664Z","iopub.status.idle":"2021-06-09T01:55:12.815785Z","shell.execute_reply.started":"2021-06-09T01:53:19.291603Z","shell.execute_reply":"2021-06-09T01:55:12.8145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Accuracy","metadata":{}},{"cell_type":"code","source":"#viewing the scores of models performance and sorting it in assending order in order to get perfect model\nScores.sort_values(by=['R2_score(test_data)', 'Test_score(MAE)', 'Train_score(MAE)'], ascending=[False,True,True])","metadata":{"execution":{"iopub.status.busy":"2021-06-09T01:55:12.81777Z","iopub.execute_input":"2021-06-09T01:55:12.818215Z","iopub.status.idle":"2021-06-09T01:55:12.861248Z","shell.execute_reply.started":"2021-06-09T01:55:12.818168Z","shell.execute_reply":"2021-06-09T01:55:12.860203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we can see Ridge model with alpha 10 and polynomial degree 1 is performing best.","metadata":{}},{"cell_type":"markdown","source":"So by this we can choose the model with params which fits out model in best way.","metadata":{}}]}