{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this notebook, the main goal is to organize raw data and collect useful information from other sources:\n1. Raw data of CU-BEM is merged as one and compressed to save memory use.\n2. Obtain weather data from NOAA dataset on Kaggle (ref: https://www.kaggle.com/tanatiem/eda-bangkok-weather)\n3. Get holiday information from the website (https://www.timeanddate.com/holidays/)","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport datetime\n\nfrom bq_helper import BigQueryHelper\n\nfrom sklearn.preprocessing import LabelEncoder\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import dates as md\nimport plotly.graph_objs as go\nimport plotly\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport cufflinks as cf\ncf.set_config_file(offline=True)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Merge and Compress raw data of CU-BEMS","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"path_rawdata = '/kaggle/input/cubems-smart-building-energy-and-iaq-data/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_csv = []\n\nfor file in os.listdir(path_rawdata):\n    if file.endswith(\".csv\"):\n        list_csv.append(os.path.join(path_rawdata, file))\n        \nlist_csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_merged = pd.DataFrame({'Date': pd.date_range('2018-07-01', '2020-01-01', freq='min', closed='left')}).set_index('Date')\n\nfor path_csv in list_csv:\n    csv_file_name = path_csv.split('/')[-1]\n    print(csv_file_name)\n    df_temp = pd.read_csv(path_csv)\n    df_temp = df_temp.set_index('Date')\n    df_temp = df_temp.dropna(how='all')\n    df_temp.index = pd.to_datetime(df_temp.index)\n\n\n    str_floor = pd.Series(csv_file_name).str.split('2018|2019|.csv',expand=True).replace('', np.nan).dropna(axis=1).iloc[0,0]\n    df_temp.columns = str_floor + '_' + df_temp.columns\n    \n    df_merged.loc[df_temp.index, df_temp.columns] = df_temp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_merged.iloc[:, :5].resample('H').mean().iplot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_merged.sort_index(axis=0).sort_index(axis=1).to_pickle('df_merged.pickle.gz', compression='gzip')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Get daily weather data from NOAA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input parameters\nstation_name = 'BANGKOK METROPOLIS'\nyears = range(2018, 2020)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"helper = BigQueryHelper('bigquery-public-data', 'noaa_gsod')\n\nsql = '''\nSELECT\n  year, mo, da, temp, min, max, prcp\nFROM\n    `bigquery-public-data.noaa_gsod.gsod{}` a\n    INNER JOIN `bigquery-public-data.noaa_gsod.stations` b ON a.stn = b.usaf\nWHERE\n  country = 'TH' AND name = '{}'\n'''\n\n# Query weather data for each year\ndatasets = [ helper.query_to_pandas(sql.format(i, station_name)) for i in years ]\n\n# print out each year's data shape\nprint('\\n'.join([ '{}: {}'.format(x[0],x[1].shape) for x in zip(years, datasets)]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Concatenate datasets\nweather = pd.concat(datasets)\n\n# Handling missing values based on Table Schema description\nweather['temp'] = weather['temp'].replace({ 9999.9 : np.nan })\nweather['min'] = weather['min'].replace({ 9999.9 : np.nan })\nweather['max'] = weather['max'].replace({ 9999.9 : np.nan })\nweather['prcp'] = weather['prcp'].replace( { 99.99 : 0 })\n\nweather","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data processing\n\n# Setting date index\nweather['date'] = weather.apply(lambda x: \n                                datetime.datetime(int(x.year), int(x.mo), int(x.da)), \n                                axis=1)\nweather = weather.set_index('date')\n\n# Convert temperature values from farenheit to celcius\ndef f_to_c(temp_f):\n    temp_c = (temp_f - 32) * 5/9\n    return round(temp_c, 2)\n\nfor col in ['temp','min','max']:\n    weather[col] = weather[col].apply(f_to_c)\n\n# Convert precipitation from inches to milimeters\ndef inch_to_mm(x):\n    return round(x * 25.4)\n\nweather['prcp'] = weather['prcp'].apply(inch_to_mm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_date = '{}0101'.format(years[0])\nend_date = weather.index.max().strftime('%Y%m%d')\n\n# Re-index to see if there are any days with missing data\nweather = weather.reindex(pd.date_range(start_date, end_date))\n\n# check if there is missing values occured from re-indexing\nmissing = weather[weather.isnull().any(axis=1)].index\n# printing missing index\nmissing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Interpolate numerical variables for the missing days\nweather = weather.interpolate()\n\n# Re-setting year, month, day fields\nweather['year'] = weather.index.year\nweather['mo'] = weather.index.month\nweather['da'] = weather.index.day\n\n# Verify interpolated data\nweather.loc[missing].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = weather[['temp','min','max','prcp']]\ndata.columns = ['Avg Temp', 'Min Temp', 'Max Temp', 'Precip']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.iplot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.to_pickle('df_weather.pickle.gz', compression='gzip')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Get holiday information","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_holiday_2018 = pd.read_html('https://www.timeanddate.com/holidays/thailand/2018')[0]\ndf_holiday_2018.columns = df_holiday_2018.columns.get_level_values(0)\ndf_holiday_2018 = df_holiday_2018.dropna(how='all')\ndf_holiday_2018 = df_holiday_2018[['Date', 'Name', 'Type']]\ndf_holiday_2018['Date'] = '2018 ' + df_holiday_2018['Date']\ndf_holiday_2018['Date'] = pd.to_datetime(df_holiday_2018['Date'])\n\ndf_holiday_2019 = pd.read_html('https://www.timeanddate.com/holidays/thailand/2019')[0]\ndf_holiday_2019.columns = df_holiday_2019.columns.get_level_values(0)\ndf_holiday_2019 = df_holiday_2019.dropna(how='all')\ndf_holiday_2019 = df_holiday_2019[['Date', 'Name', 'Type']]\ndf_holiday_2019['Date'] = '2019 ' + df_holiday_2019['Date']\ndf_holiday_2019['Date'] = pd.to_datetime(df_holiday_2019['Date'])\n\ndf_holiday = pd.concat([df_holiday_2018, df_holiday_2019], axis=0, ignore_index=True)\ndf_holiday = df_holiday.drop_duplicates(subset=['Date'])\ndf_holiday = df_holiday.set_index('Date').asfreq('D')\ndf_holiday.loc[df_holiday.index.weekday>=5, 'Name'] = 'weekend'\ndf_holiday.loc[df_holiday.index.weekday>=5, 'Type'] = 'weekend'\ndf_holiday.columns = 'holiday_' + df_holiday.columns\n\ndf_holiday = df_holiday.reset_index()\ndf_holiday = df_holiday.rename(columns={'Date':'date'}) \n\ndf_holiday","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_holiday_encode = df_holiday.copy()\ndf_holiday_encode[['holiday_Name', 'holiday_Type']] = df_holiday_encode[['holiday_Name', 'holiday_Type']].astype('str').apply(LabelEncoder().fit_transform)\ndf_holiday_encode","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_holiday_encode.set_index('date')['holiday_Type'].iplot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.to_pickle('df_holiday.pickle.gz', compression='gzip')\ndata.to_pickle('df_holiday_encode.pickle.gz', compression='gzip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}