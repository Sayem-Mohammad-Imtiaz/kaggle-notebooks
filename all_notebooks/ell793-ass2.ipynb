{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.datasets import mnist\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.preprocessing import OneHotEncoder\n#df=pd.read_csv('../input/mnist-in-csv/mnist_train.csv')\n#df_test=pd.read_csv('../input/mnist-in-csv/mnist_train.csv')\n#X_test=df.iloc[:, 1:].values\n#Y_test=df.iloc[:, 0].values\n#X=df.iloc[:, 1:].values\n#Y=df.iloc[:, 0].values\n(X, Y), (X_test, Y_test) = mnist.load_data()\n#print(X.shape)\n#print(X_test.shape)\nprint(np.max(X[0, :, :]))\nplt.imshow(X[0, :, :])\nplt.show()\nplt.imshow(X[5, :, :])\nplt.show()\nplt.imshow(X[15, :, :])\nplt.show()\nplt.imshow(X[20, :, :])\nplt.show()\nX=X.reshape((X.shape[0], 28*28))/255\nX_test=X_test.reshape((X_test.shape[0], 28*28))/255\nohe = OneHotEncoder()\nY = ohe.fit_transform(Y.reshape(-1, 1)).toarray()\nY_test= ohe.fit_transform(Y_test.reshape(-1, 1)).toarray()\nprint(Y.shape)\nprint(Y_test.shape)\nmodel=Sequential()\nmodel.add(Dense(500, input_dim=784, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()\nhistory=model.fit(X, Y, validation_data=(X_test, Y_test), epochs=250, batch_size=5000)\n#history=model.fit(X, Y, validation_data =(X_test,Y_test), epochs=250, batch_size=64)\nplt.plot(history.history['loss']) \nplt.plot(history.history['val_loss']) \nplt.title('Model loss') \nplt.ylabel('Loss') \nplt.xlabel('Epoch') \nplt.legend(['Train', 'Test'], loc='upper left') \nplt.show()\n#print(history.keys())\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#l2 regularization\nmodel=Sequential()\nmodel.add(Dense(500, input_dim=784, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)))\nmodel.add(Dense(500, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)))\nmodel.add(Dense(10, activation='softmax', kernel_regularizer=keras.regularizers.l2(0.01)))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()\nhistory=model.fit(X, Y, validation_data=(X_test, Y_test), epochs=250, batch_size=5000)\nplt.plot(history.history['loss']) \nplt.plot(history.history['val_loss']) \nplt.title('Model loss') \nplt.ylabel('Loss') \nplt.xlabel('Epoch') \nplt.legend(['Train', 'Test'], loc='upper left') \nplt.show()\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropout\nmodel=Sequential()\nmodel.add(Flatten(input_shape=(28, 28)))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(500, input_dim=784, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()\nhistory=model.fit(X, Y, validation_data=(X_test, Y_test), epochs=250, batch_size=5000)\nplt.plot(history.history['loss']) \nplt.plot(history.history['val_loss']) \nplt.title('Model loss') \nplt.ylabel('Loss') \nplt.xlabel('Epoch') \nplt.legend(['Train', 'Test'], loc='upper left') \nplt.show()\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#EarlyStop\nearly_stopping = EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=30)\nmodel=Sequential()\nmodel.add(Flatten(input_shape=(28, 28)))\nmodel.add(Dense(500, input_dim=784, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()\nhistory=model.fit(X, Y, validation_data=(X_test, Y_test), epochs=250, batch_size=5000, callbacks=[early_stopping])\nplt.plot(history.history['loss']) \nplt.plot(history.history['val_loss']) \nplt.title('Model loss') \nplt.ylabel('Loss') \nplt.xlabel('Epoch') \nplt.legend(['Train', 'Test'], loc='upper left') \nplt.show()\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}