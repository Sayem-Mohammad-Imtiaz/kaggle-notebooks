{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Why Use TFRecords?\n- to use TPUs more efficiently\n- seperate data preparation from model crafting\n- prepare data once then focus on optimizing training workflow"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\n\n# geospatial libraries\nimport geopandas as gpd\nimport rasterio as rs\nfrom rasterio import features as feat\nfrom rasterio.plot import show\n\n# polygon creation\nfrom shapely.geometry import Point, Polygon\n\n# plotting\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading split\n- read more on image tiling of this dataset [here](https://www.kaggle.com/sandhiwangiyana/sn6-splitting-image-tiles/)\n- you can't create a validation split by choosing random image_id since most tiles are overlaping -> data leak\n- the best way is to choose an area in the map and grab some tiles that have minimum overlaping with other tiles\n- in my notebook above, I split the region into 10 area and group tiles that are >50% inside each area. Some data leak might happen but we should also consider that some portion of the image is the `no-data` region (black part)"},{"metadata":{"trusted":true},"cell_type":"code","source":"SPLIT_SET = np.load('../input/spacenet-6-image-splits/SN6_10_splits.npy', allow_pickle=True)\nprint(f'num of splits: {len(SPLIT_SET)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TFRecords\n- a tfrecord file contains some examples. examples are data features and additional labels that we want to integrate\n- in this notebook, for every example we'll integrate the optical PS-RGB image, annotation mask, image id and total number of building\n- the raster and mask will be stored as BytesList, therefore we need to encode both image as strings"},{"metadata":{"trusted":true},"cell_type":"code","source":"# global params\nROOT_DIR = '../input/spacenet-6-multisensor-allweather-mapping/AOI_11_Rotterdam/'\nMODE = 'PS-RGB'\nIMAGE_SIZE = (768,768)\nIMAGE_CH = 3\n\nSAR_CH = [1,4,3]  # choose which SAR channel to extract, here I take HH,VV,VH","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_image_path(image_id):\n    return f'{ROOT_DIR}{MODE}/SN6_Train_AOI_11_Rotterdam_{MODE}_{image_id}.tif'\n\ndef norm(plane):\n    \"\"\"make sure if max val exceeds given 92.88, it won't result in value >255\n    and making it become 0 when converted to uint8 bcz of overflow\n    \n    used only for sar images since their values are floats\n    \n    Parameters:\n    -----------\n    plane: numpy array of any size and dimension\n    \"\"\"\n    max_val = plane.max() if plane.max()>92.88 else 92.88\n    plane = plane / max_val * 255\n    return plane.astype(np.uint8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load binary mask\n- 1: buildings, 0: background\n- annotations are obtained from respective geojson files"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_binary_mask(image_id, raster):\n    # get geojson file for a given tile\n    geo_path = f'{ROOT_DIR}geojson_buildings/SN6_Train_AOI_11_Rotterdam_Buildings_{image_id}.geojson'\n    gdf = gpd.read_file(geo_path)\n    num_buildings = gdf.shape[0]\n    \n    # handle error when no buildings are present in a tile\n    if num_buildings==0:\n        mask = np.zeros(IMAGE_SIZE)\n    else:\n        # create binary mask, convert to uint8, resize\n        mask = feat.geometry_mask(\n            gdf.geometry,\n            out_shape=(raster.height, raster.width), # original wxh (900,900)\n            transform=raster.transform,\n            invert=True  # makes pixel buildings == 1\n        )\n\n    return mask, num_buildings","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load image with mask\n- both image and mask are encoded with png\n- you could use jpeg to get smaller file size for image but note it only supports 3 channel\n- you can add any preprocessing in this stage, but during training (using TPU), you can only do preprocessing with numpy or tensorflow"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_mask_string(mask):\n    # encode mask to png\n    mask = mask.astype(np.uint8)\n    mask = np.expand_dims(mask, axis=2)  # result: (w,h,1)\n    mask = tf.image.resize(mask, size=IMAGE_SIZE, method='nearest')\n    return tf.io.encode_png(mask)\n\ndef get_image_mask(image_id):\n    \"\"\"Takes an image id, ex: '20190822065725_20190822065959_tile_7283'\n\n    returns:\n        image (string), mask (string), num_building\n    \"\"\"\n    # read image with rasterio\n    raster = rs.open(get_image_path(image_id))\n\n    # grab binary mask\n    mask, num_building = get_binary_mask(image_id, raster)\n    mask = get_mask_string(mask)\n\n    # convert to np array, change to uint8 (encoding doesn't support float), encode to jpeg\n    if MODE == 'SAR-Intensity':\n        # read desired channels and size, then normalize\n        image = norm(raster.read(indexes=SAR_CH, out_shape=IMAGE_SIZE))\n\n    # if non sar image, convert to uint8 when reading\n    else:\n        image = raster.read(out_dtype='uint8', out_shape=IMAGE_SIZE) \n\n    img = rs.plot.reshape_as_image(image)  # fix dimension order, res (w,h,ch)\n    img = tf.io.encode_png(img)\n\n    return img, mask, num_building","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preview image-mask"},{"metadata":{"trusted":true},"cell_type":"code","source":"image, mask, num_building = get_image_mask('20190822065725_20190822065959_tile_7283')\n\nf,(ax1,ax2) = plt.subplots(1,2,figsize=(10,5))\nax1.imshow(tf.io.decode_png(image))\nax2.imshow(tf.io.decode_png(mask))\nax2.set_title(f'buildings: {num_building}')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create TFRecord"},{"metadata":{"trusted":true},"cell_type":"code","source":"# TFRecord data type\ndef _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy() # BytesList won't unpack a string from an EagerTensor. intended for the image data\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _int64_feature(value):\n    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_tfrecord():\n    print(f'using {IMAGE_SIZE[0]}x{IMAGE_SIZE[0]} resolution on {MODE} images')\n\n    # create tfrecords for each split\n    for n, image_ids in enumerate(SPLIT_SET):\n        print(f'writing split {n+1} of {len(SPLIT_SET)}')\n        fn = f'{MODE}{n+1}-{len(image_ids)}.tfrec'\n\n        with tf.io.TFRecordWriter(fn) as writer:\n            for k,image_id in enumerate(image_ids):\n                image_str, mask_str, num_building = get_image_mask(image_id)\n\n                feature = {\n                    'image': _bytes_feature(image_str),\n                    'mask': _bytes_feature(mask_str),\n                    'file_name': _bytes_feature(tf.compat.as_bytes(image_id)),\n                    'building': _int64_feature([num_building]),  # single value needs to be arrayed\n                }\n                \n                # write tfrecords\n                example = tf.train.Example(features=tf.train.Features(feature=feature))\n                writer.write(example.SerializeToString())\n                \n                # report each 50th image\n                if k%50==0:\n                    print(k)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create tf records for optical RGB\nMODE = 'PS-RGB'\ncreate_tfrecord()\n\n# create tf records for SAR\nMODE = 'SAR-Intensity'\ncreate_tfrecord()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load TFRecord\nHere's how you load and preview data from TFRecord"},{"metadata":{"trusted":true},"cell_type":"code","source":"tfrec_format = {\n    'image': tf.io.FixedLenFeature([], tf.string),\n    'mask': tf.io.FixedLenFeature([], tf.string),\n    'file_name': tf.io.FixedLenFeature([], tf.string),\n    'building': tf.io.FixedLenFeature([], tf.int64),\n}\n\ndef parse_example(feature):\n    features = tf.io.parse_single_example(feature, tfrec_format)\n    \n    # decode image and mask\n    image = tf.image.decode_png(features['image'])\n    mask = tf.image.decode_png(features['mask'])\n    \n    data = {}  # dict with file name and building count\n    data['file_name'] = tf.cast(features['file_name'], tf.string)\n    data['num_building'] = tf.cast(features['building'], tf.int32)\n\n    return image, mask, data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames = tf.io.gfile.glob('./*.tfrec')\n\n# load 1 file as TF Dataset\ndataset = tf.data.TFRecordDataset(filenames[0])\n\n# take 1 example and parse\nfor example in dataset.take(1):\n    image, mask, data = parse_example(example)\n    \n    # plot example\n    f,(ax1,ax2) = plt.subplots(1,2,figsize=(10,5))\n    ax1.imshow(image)\n    ax1.set_title(data['file_name'].numpy())\n    ax2.imshow(mask)\n    ax2.set_title(f'buildings: {data[\"num_building\"]}')\n    plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}