{"cells":[{"metadata":{"_uuid":"4a1c505a-af19-4114-9013-4d0cd725fc6e","_cell_guid":"0c5341ac-2f8d-46bb-8749-fa8804155603","trusted":true},"cell_type":"code","source":"from datetime import datetime\ntime_format = \"%d%b%Y %H:%M\"\ndatetime.now().strftime(time_format)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Package"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Adapted to be run for US dataset case numbers with mitigation measures\n# Note: AKNOWLEDGMENT taking the model of COVID-19 data with SIR model from Lisphilar Kaggle\n# AKNOWLEDGE OTHER PEOPLE'S WORK TO AVOID INTELLECTUAL PLAGIARISM\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nfrom collections import defaultdict\nfrom datetime import timedelta\nfrom dateutil.relativedelta import relativedelta\nimport os\nfrom pprint import pprint\nimport warnings\nfrom fbprophet import Prophet\nfrom fbprophet.plot import add_changepoints_to_plot\nimport pystan.misc # in model.fit(): AttributeError: module 'pystan' has no attribute 'misc'\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport matplotlib\nfrom matplotlib.ticker import ScalarFormatter\n%matplotlib inline\nimport numpy as np\nimport optuna\noptuna.logging.disable_default_handler()\nimport pandas as pd\nimport dask.dataframe as dd\npd.plotting.register_matplotlib_converters()\nimport seaborn as sns\nfrom scipy.integrate import solve_ivp","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"np.random.seed(2019)\nos.environ[\"PYTHONHASHSEED\"] = \"2019\"","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.style.use(\"seaborn-ticks\")\nplt.rcParams[\"xtick.direction\"] = \"in\"\nplt.rcParams[\"ytick.direction\"] = \"in\"\nplt.rcParams[\"font.size\"] = 11.0\nplt.rcParams[\"figure.figsize\"] = (9, 6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"pd.set_option(\"display.max_colwidth\", 1000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataset"},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk(\"/kaggle/input\"):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Total population"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"population_raw = pd.read_csv(\n    \"/kaggle/input/covid19-global-forecasting-locations-population/locations_population.csv\"\n)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"population_raw.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"pd.DataFrame(population_raw.isnull().sum()).T","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df = population_raw.copy()\ndf = df.rename({\"Province.State\": \"Province\", \"Country.Region\": \"Country\"}, axis=1)\ncols = [\"Country\", \"Province\", \"Population\"]\ndf = df.loc[:, cols].fillna(\"-\")\ndf.loc[df[\"Country\"] == df[\"Province\"], \"Province\"] = \"-\"\n# Add total records\n_total_df = df.loc[df[\"Province\"] != \"-\", :].groupby(\"Country\").sum()\n_total_df = _total_df.reset_index().assign(Province=\"-\")\ndf = pd.concat([df, _total_df], axis=0, sort=True)\ndf = df.drop_duplicates(subset=[\"Country\", \"Province\"], keep=\"first\")\n# Global\nglobal_value = df.loc[df[\"Province\"] == \"-\", \"Population\"].sum()\ndf = df.append(pd.Series([\"Global\", \"-\", global_value], index=cols), ignore_index=True)\n# Sorting\ndf = df.sort_values(\"Population\", ascending=False).reset_index(drop=True)\ndf = df.loc[:, cols]\npopulation_df = df.copy()\npopulation_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df = population_df.loc[population_df[\"Province\"] == \"-\", :]\npopulation_dict = df.set_index(\"Country\").to_dict()[\"Population\"]\npopulation_dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Population pyramid"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"pyramid_csv_list = list()\nfor dirname, _, filenames in os.walk(\"/kaggle/input/population-pyramid-2019/\"):\n    for filename in filenames:\n        name = os.path.join(dirname, filename)\n        df = pd.read_csv(name)\n        df[\"Country\"], df[\"Year\"], _ = filename.replace(\".\", \"-\").split(\"-\")\n        pyramid_csv_list.append(df)\npyramid_raw = pd.concat(pyramid_csv_list, sort=True)\npyramid_raw.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"pyramid_raw[\"Country\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df = pyramid_raw.copy()\ndf[\"Country\"] = df[\"Country\"].replace(\n    {\n        \"United States of America\": \"US\",\n        \"United Kingdom\": \"UK\",\n    }\n)\n# Global (WORLD)\n_male = [\n    349432556, 342927576, 331497486, 316642222, 308286775, 306059387, 309236984,\n    276447037, 249389688, 241232876, 222609691, 192215395, 157180267, 128939392,\n    87185982, 54754941, 33648953, 15756942, 5327866, 1077791, 124144\n]\n_female = [\n    328509234, 321511867, 309769906, 295553758, 289100903, 288632766, 296293748,\n    268371754, 244399176, 238133281, 223162982, 195633743, 164961323, 140704320,\n    101491347, 69026831, 48281201, 26429329, 11352182, 3055845, 449279\n]\n_df = pd.DataFrame(\n    {\n        \"Age\": df[\"Age\"].unique(),\n        \"Country\": \"Global\",\n        \"F\": _female,\n        \"M\": _male,\n        \"Year\": 2019\n    }\n)\ndf = pd.concat([df, _df], axis=0, ignore_index=True, sort=True)\n# Sweden\n_male = [\n    307116,\n    304759,\n    296771,\n    270840,\n    291723,\n    376952,\n    343311,\n    315086,\n    312017,\n    336452,\n    342117,\n    306949,\n    279609,\n    265511,\n    273061,\n    195029,\n    113166,\n    61775,\n    26170,\n    6768,\n    415\n]\n_female = [\n    290553,\n    288817,\n    280944,\n    257677,\n    274760,\n    361526,\n    330153,\n    300752,\n    301288,\n    327453,\n    331458,\n    300084,\n    280009,\n    272149,\n    286879,\n    212480,\n    143654,\n    97633,\n    52624,\n    18130,\n    1771\n]\n_df = pd.DataFrame(\n    {\n        \"Age\": df[\"Age\"].unique(),\n        \"Country\": \"Sweden\",\n        \"F\": _female,\n        \"M\": _male,\n        \"Year\": 2019\n    }\n)\ndf = pd.concat([df, _df], axis=0, ignore_index=True, sort=True)\n# Philippines\n_male = [\n    5534962,\n    5820604,\n    5538414,\n    5383822,\n    5149849,\n    4710777,\n    4061897,\n    3581091,\n    3237426,\n    2832825,\n    2482953,\n    2015857,\n    1556935,\n    1082875,\n    668107,\n    364200,\n    199400,\n    73508,\n    17327,\n    3035,\n    208\n]\n_female = [\n    5240508,\n    5541514,\n    5273495,\n    5029137,\n    4896316,\n    4589506,\n    3982681,\n    3544279,\n    3191565,\n    2825286,\n    2521463,\n    2112380,\n    1714689,\n    1285782,\n    895866,\n    567282,\n    360751,\n    155294,\n    57969,\n    13376,\n    1411\n]\n_df = pd.DataFrame(\n    {\n        \"Age\": df[\"Age\"].unique(),\n        \"Country\": \"Philippines\",\n        \"F\": _female,\n        \"M\": _male,\n        \"Year\": 2019\n    }\n)\ndf = pd.concat([df, _df], axis=0, ignore_index=True, sort=True)\n# Arrange\ndf[\"Population\"] = df[\"F\"] + df[\"M\"]\ndf = df.pivot_table(\n    index=\"Age\", columns=[\"Country\"], values=\"Population\", aggfunc=\"last\"\n)\ndf = df.astype(np.int64).reset_index().rename({\"Age\": \"Age_bin\"}, axis=1)\nseries = df[\"Age_bin\"].str.replace(\"+\", \"-122\")\ndf[[\"Age_first\", \"Age_last\"]] = series.str.split(\"-\", expand=True).astype(np.int64)\ndf = df.drop(\"Age_bin\", axis=1)\nseries = df[\"Age_last\"]\ndf = df.apply(lambda x: x[:-2] / (x[-1] - x[-2] + 1), axis=1)\ndf[\"Age\"] = series\ndf = pd.merge(df, pd.DataFrame({\"Age\": np.arange(0, 123, 1)}), on=\"Age\", how=\"right\", sort=True)\ndf = df.fillna(method=\"bfill\").astype(np.int64)\ndf = df.set_index(\"Age\")\npyramid_df = df.copy()\npyramid_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The number of days go out (template data)\n**As a comment of this notebook, @marcoferrante estimated the number of days persons of each age group usually go out. Thank you for your kind cooperation!!**"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# @marcoferrante estimation\n_period_of_life_list = [\n    \"nursery\", \"nursery school\", \"elementary school\", \"middle school\",\n    \"high school\", \"university/work\", \"work\", \"work\", \"work\", \"work\",\n    \"retired\", \"retired\", \"retired\"\n]\ndf = pd.DataFrame(\n    {\n        \"Age_first\": [0, 3, 6, 11, 14, 19, 26, 36, 46, 56, 66, 76, 86],\n        \"Age_last\": [2, 5, 10, 13, 18, 25, 35, 45, 55, 65, 75, 85, 95],\n        \"Period_of_life\": _period_of_life_list,\n        \"Days\": [3, 5, 6, 6, 7, 7, 6, 5, 5, 5, 4, 3, 2]\n    }\n)\n# Adjustment by author\ndf[\"Types\"] = df[\"Period_of_life\"].replace(\n    {\n        \"nursery\": \"school\",\n        \"nursery school\": \"school\",\n        \"elementary school\": \"school\",\n        \"middle school\": \"school\",\n        \"high school\": \"school\",\n        \"university/work\": \"school/work\"\n    }\n)\ndf[\"School\"] = df[[\"Types\", \"Days\"]].apply(lambda x: x[1] if \"school\" in x[0] else 0, axis=1)\ndf[\"Office\"] = df[[\"Types\", \"Days\"]].apply(lambda x: x[1] if \"work\" in x[0] else 0, axis=1)\ndf[\"Others\"] = df[\"Days\"] - df[[\"School\", \"Office\"]].sum(axis=1)\ndf.loc[df[\"Others\"] < 0, \"Others\"] = 0\ndf.loc[df.index[1:5], \"School\"] -= 1\ndf.loc[df.index[1:5], \"Others\"] += 1\ndf.loc[df.index[5], [\"School\", \"Office\", \"Others\"]] = [3, 3, 1]\ndf[[\"School\", \"Office\", \"Others\"]] = df[[\"Days\", \"School\", \"Office\", \"Others\"]].apply(\n    lambda x: x[1:] / sum(x[1:]) * x[0], axis=1\n).astype(np.int64)\ndf.loc[df.index[6:10], \"Others\"] += 1\ndf = df.drop([\"Days\", \"Types\"], axis=1)\n# Show dataset\n_out_df = df.copy()\n_out_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For each country, population pyramid data will be combined to the table. The columns with countriy names are the portion of the total population."},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df = pyramid_df.cumsum()\ncountries = df.columns[:]\ndf = pd.merge(_out_df, df, left_on=\"Age_last\", right_on=\"Age\", how=\"left\")\n_first = df.loc[df.index[0], countries]\ndf[countries] = df[countries].diff()\ndf.loc[df.index[0], countries] = _first\ndf[countries] = df[countries].apply(lambda x: x / x.sum(), axis=0)\nout_df = df.copy()\nout_df","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def go_out(country, out_df=out_df):\n    \"\"\"\n    Return the estimated number of days people usually go out.\n    @country <str>: coutry name\n    @out_df <pd.DataFrame>: template dataframe\n    \"\"\"\n    df = out_df.copy()\n    try:\n        series = df[country]\n    except KeyError:\n        raise KeyError(f\"Population pyramid data of {country} is not defined!\")\n    df = df.iloc[:, :6]\n    df[\"Portion\"] = series\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"go_out(\"Global\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c3ebe4cf-2cd1-4d69-9882-8d2cc490e1ea","_cell_guid":"8c2f4e86-2ce9-4aa4-8352-348523a88b51","trusted":true},"cell_type":"markdown","source":"## Functions\nHere, we define the functions to use repeatedly in this notebook."},{"metadata":{"_uuid":"e619de8a-4351-4f6a-97f1-2a07dfc8df8c","_cell_guid":"9aa77813-b9cc-46a4-a77f-88c1b5eb220e","trusted":true},"cell_type":"markdown","source":"### Plotting"},{"metadata":{"_uuid":"102b157f-f1f0-4430-91ba-0660f388c945","_cell_guid":"5b76a2ac-df0d-4c4c-85c6-38c8b147ef93","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def line_plot(df, title, xlabel=None, ylabel=\"Cases\", h=None, v=None,\n              xlim=(None, None), ylim=(0, None), math_scale=True, y_logscale=False, y_integer=False):\n    \"\"\"\n    Show chlonological change of the data.\n    \"\"\"\n    ax = df.plot()\n    if math_scale:\n        ax.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n        ax.ticklabel_format(style=\"sci\",  axis=\"y\",scilimits=(0, 0))\n    if y_logscale:\n        ax.set_yscale(\"log\")\n    if y_integer:\n        fmt = matplotlib.ticker.ScalarFormatter(useOffset=False)\n        fmt.set_scientific(False)\n        ax.yaxis.set_major_formatter(fmt)\n    ax.set_title(title)\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    ax.set_xlim(*xlim)\n    ax.set_ylim(*ylim)\n    ax.legend(bbox_to_anchor=(1.02, 0), loc=\"lower left\", borderaxespad=0)\n    if h is not None:\n        ax.axhline(y=h, color=\"black\", linestyle=\"--\")\n    if v is not None:\n        if not isinstance(v, list):\n            v = [v]\n        for value in v:\n            ax.axvline(x=value, color=\"black\", linestyle=\"--\")\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Trend analysis"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def select_area(ncov_df, group=\"Date\", places=None, areas=None, excluded_places=None,\n                start_date=None, end_date=None, date_format=\"%d%b%Y\"):\n    \"\"\"\n    Select the records of the places.\n    @ncov_df <pd.DataFrame>: the clean data\n    @group <str or None>: group-by the group, or not perform (None)\n    @area or @places:\n        if ncov_df has Country and Province column,\n            @places <list[tuple(<str/None>, <str/None>)]: the list of places\n                - if the list is None, all data will be used\n                - (str, str): both of country and province are specified\n                - (str, None): only country is specified\n                - (None, str) or (None, None): Error\n        if ncov_df has Area column,\n            @areas <list[str]>: the list of area names\n                - if the list is None, all data will be used\n                - eg. Japan\n                - eg. US/California\n    @excluded_places <list[tuple(<str/None>, <str/None>)]: the list of excluded places\n        - if the list is None, all data in the \"places\" will be used\n        - (str, str): both of country and province are specified\n        - (str, None): only country is specified\n        - (None, str) or (None, None): Error\n    @start_date <str>: the start date or None\n    @end_date <str>: the start date or None\n    @date_format <str>: format of @start_date and @end_date\n    @return <pd.DataFrame>: index and columns are as same as @ncov_df\n    \"\"\"\n    # Select the target records\n    df = ncov_df.copy()\n    if (places is not None) or (excluded_places is not None):\n        c_series = df[\"Country\"]\n        p_series = df[\"Province\"]\n        if places is not None:\n            df = pd.DataFrame(columns=ncov_df.columns)\n            for (c, p) in places:\n                if c is None:\n                    raise Exception(\"places: Country must be specified!\")\n                if p is None:\n                    new_df = ncov_df.loc[c_series == c, :]\n                else:\n                    new_df = ncov_df.loc[(c_series == c) & (p_series == p), :]\n                df = pd.concat([df, new_df], axis=0)\n        if excluded_places is not None:\n            for (c, p) in excluded_places:\n                if c is None:\n                    raise Exception(\"excluded_places: Country must be specified!\")\n                if p is None:\n                    df = df.loc[c_series != c, :]\n                else:\n                    c_df = df.loc[(c_series == c) & (p_series != p), :]\n                    other_df = df.loc[c_series != c, :]\n                    df = pd.concat([c_df, other_df], axis=0)\n    if areas is not None:\n        df = df.loc[df[\"Area\"].isin(areas), :]\n    if group is not None:\n        df = df.groupby(group).sum().reset_index()\n    # Range of date\n    if start_date is not None:\n        df = df.loc[df[\"Date\"] >= datetime.strptime(start_date, date_format), :]\n    if end_date is not None:\n        df = df.loc[df[\"Date\"] <= datetime.strptime(end_date, date_format), :]\n    # Only use the records with Confirmed > 0\n    try:\n        df = df.loc[df[\"Confirmed\"] > 0, :]\n    except KeyError:\n        pass\n    # Aleart empty\n    if df.empty:\n        raise Exception(\"The output dataframe is empty!\")\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def show_trend(ncov_df, name=None, variable=\"Confirmed\", n_changepoints=2, **kwargs):\n    \"\"\"\n    Show trend of log10(@variable) using fbprophet package.\n    @ncov_df <pd.DataFrame>: the clean data\n    @variable <str>: variable name to analyse\n        - if Confirmed, use Infected + Recovered + Deaths\n    @n_changepoints <int>: max number of change points\n    @kwargs: keword arguments of select_area()\n    \"\"\"\n    # Data arrangement\n    df = select_area(ncov_df, **kwargs)\n    df = df.loc[:, [\"Date\", variable]]\n    df.columns = [\"ds\", \"y\"]\n    # Log10(x)\n    warnings.resetwarnings()\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        df[\"y\"] = np.log10(df[\"y\"]).replace([np.inf, -np.inf], 0)\n    # fbprophet\n    model = Prophet(growth=\"linear\", daily_seasonality=False, n_changepoints=n_changepoints)\n    model.fit(df)\n    future = model.make_future_dataframe(periods=0)\n    forecast = model.predict(future)\n    # Create figure\n    fig = model.plot(forecast)\n    _ = add_changepoints_to_plot(fig.gca(), model, forecast)\n    if name is None:\n        try:\n            name = f\"{kwargs['places'][0][0]}: \"\n        except Exception:\n            name = str()\n    else:\n        name = f\"{name}: \"\n    plt.title(f\"{name}log10({variable}) over time and chainge points\")\n    plt.ylabel(f\"log10(the number of cases)\")\n    plt.xlabel(\"\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f5acaa2-fff5-45ba-b371-daafda9ce78c","_cell_guid":"7eb3a21d-006c-43bd-ba1d-82fb46cec274","trusted":true},"cell_type":"markdown","source":"### Dataset arrangement"},{"metadata":{"_uuid":"ae73742e-4671-40d8-bd9f-b172e5894660","_cell_guid":"673e50af-45d8-4a5a-897d-88e88cb03cd8","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def create_target_df(ncov_df, total_population,\n                     confirmed=\"Confirmed\", recovered=\"Recovered\", fatal=\"Deaths\", **kwargs):\n    \"\"\"\n    Select the records of the places, calculate the number of susceptible people,\n     and calculate the elapsed time [day] from the start date of the target dataframe.\n    @ncov_df <pd.DataFrame>: the clean data\n    @total_population <int>: total population in the places\n    column names in @ncov_df:\n        @confirmed <str>: column name of the number of confirmed cases\n        @recovered <str>: column name of the number of recovered cases\n        @fatal <str>: column name of the number of fatal cases\n    @kwargs: keword arguments of select_area()\n    @return <tuple(2 objects)>:\n        - 1. first_date <pd.Timestamp>: the first date of the selected records\n        - 2. target_df <pd.DataFrame>:\n            - column T: elapsed time [min] from the start date of the dataset\n            - column Susceptible: the number of patients who are in the palces but not infected/recovered/died\n            - column Infected: the number of infected cases\n            - column Recovered: the number of recovered cases\n            - column Deaths: the number of death cases\n    \"\"\"\n    # Select the target records\n    df = select_area(ncov_df, **kwargs)\n    first_date = df.loc[df.index[0], \"Date\"]\n    # column T\n    df[\"T\"] = ((df[\"Date\"] - first_date).dt.total_seconds() / 60).astype(int)\n    # coluns except T\n    cols = [confirmed, recovered, fatal]\n    if not set(cols).issubset(set(df.columns)):\n        raise KeyError(f\"ncov_df must have {', '.join(cols)} column!\")\n    df[\"Susceptible\"] = total_population - df[confirmed]\n    df[\"Infected\"] = df[confirmed] - df[recovered] - df[fatal]\n    df[\"Recovered\"] = df[recovered]\n    df[\"Fatal\"] = df.loc[:, fatal]\n    response_variables = [\"Susceptible\", \"Infected\", \"Recovered\", \"Fatal\"]\n    # Return\n    target_df = df.loc[:, [\"T\", *response_variables]]\n    return (first_date, target_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9f164794-196a-4755-9d8f-083370aab0a3","_cell_guid":"5102c179-986a-40a7-91a2-711e3c9215fe","trusted":true},"cell_type":"markdown","source":"### Numerical simulation\nWe will perform numerical analysis to solve the ODE using scipy.integrate.solve_ivp function."},{"metadata":{"_uuid":"6007f8a5-764f-4e7e-95b3-ba8796f66402","_cell_guid":"95bcd2ad-14bb-42d1-8db0-d6dfda502f69","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def simulation(model, initials, step_n, **params):\n    \"\"\"\n    Solve ODE of the model.\n    @model <ModelBase>: the model\n    @initials <tuple[float]>: the initial values\n    @step_n <int>: the number of steps\n    @params: the paramerters of the model\n    \"\"\"\n    tstart, dt, tend = 0, 1, step_n\n    sol = solve_ivp(\n        fun=model(**params),\n        t_span=[tstart, tend],\n        y0=np.array(initials, dtype=np.float64),\n        t_eval=np.arange(tstart, tend + dt, dt),\n        dense_output=False  # True\n    )\n    t_df = pd.Series(data=sol[\"t\"], name=\"t\")\n    y_df = pd.DataFrame(data=sol[\"y\"].T.copy(), columns=model.VARIABLES)\n    sim_df = pd.concat([t_df, y_df], axis=1)\n    return sim_df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3922e417-890c-431a-a8bf-507662ce70e8","_cell_guid":"decfa29f-ccbe-4cad-9574-5ff0e771aae7","trusted":true},"cell_type":"markdown","source":"### Description of math model"},{"metadata":{"_uuid":"02915ddd-c0fd-4544-9e47-0a7b4f249cc2","_cell_guid":"eed8b0f8-1e0e-4c8c-8f87-02467bae6912","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class ModelBase(object):\n    NAME = \"Model\"\n    VARIABLES = [\"x\"]\n    PRIORITIES = np.array([1])\n    QUANTILE_RANGE = [0.3, 0.7]\n    MONOTONIC = [\"x\"]\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        \"\"\"\n        Define parameters without tau. This function should be overwritten.\n        @train_df_divided <pd.DataFrame>:\n            - column: t and non-dimensional variables\n        @q_range <list[float, float]>: quantile rage of the parameters calculated by the data\n        @return <dict[name]=(min, max):\n            @min <float>: min value\n            @max <float>: max value\n        \"\"\"\n        param_dict = dict()\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        \"\"\"\n        Calculate the variables of the model.\n        This function should be overwritten.\n        @df <pd.DataFrame>\n        @return <pd.DataFrame>\n        \"\"\"\n        return df\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        \"\"\"\n        Calculate measurable variables using the variables of the model.\n        This function should be overwritten.\n        @df <pd.DataFrame>\n        @return <pd.DataFrame>\n        \"\"\"\n        return df\n\n    @classmethod\n    def create_dataset(cls, ncov_df, total_population, **kwargs):\n        \"\"\"\n        Create dataset with the model-specific varibles.\n        The variables will be divided by total population.\n        The column names (not include T) will be lower letters.\n        **kwargs: See the function named create_target_df()\n        @return <tuple(objects)>:\n            - start_date <pd.Timestamp>\n            - initials <tuple(float)>: the initial values\n            - Tend <int>: the last value of T\n            - df <pd.DataFrame>: the dataset\n        \"\"\"\n        start_date, target_df = create_target_df(ncov_df, total_population, **kwargs)\n        df = cls.calc_variables(target_df).set_index(\"T\") / total_population\n        df.columns = [n.lower() for n in df.columns]\n        initials = df.iloc[0, :].values\n        df = df.reset_index()\n        Tend = df.iloc[-1, 0]\n        return (start_date, initials, Tend, df)\n\n    def calc_r0(self):\n        \"\"\"\n        Calculate R0. This function should be overwritten.\n        \"\"\"\n        return None\n\n    def calc_days_dict(self, tau):\n        \"\"\"\n        Calculate 1/beta [day] etc.\n        This function should be overwritten.\n        @param tau <int>: tau value [hour]\n        \"\"\"\n        return dict()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1bc607ad-3e75-445b-9c90-d88d84783237","_cell_guid":"52b04482-dbfb-4f59-a148-0d696eccfc3a","trusted":true},"cell_type":"markdown","source":"#### SIR model"},{"metadata":{"_uuid":"f4437e32-5ceb-4bd3-9efe-95b84dbcefc8","_cell_guid":"eada8314-baf7-49b0-8d26-d788c45f4cfb","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class SIR(ModelBase):\n    NAME = \"SIR\"\n    VARIABLES = [\"x\", \"y\", \"z\"]\n    PRIORITIES = np.array([1, 1, 1])\n    MONOTONIC = [\"z\"]\n\n    def __init__(self, rho, sigma):\n        super().__init__()\n        self.rho = rho\n        self.sigma = sigma\n\n    def __call__(self, t, X):\n        # x, y, z = [X[i] for i in range(len(self.VARIABLES))]\n        # dxdt = - self.rho * x * y\n        # dydt = self.rho * x * y - self.sigma * y\n        # dzdt = self.sigma * y\n        dxdt = - self.rho * X[0] * X[1]\n        dydt = self.rho * X[0] * X[1] - self.sigma * X[1]\n        dzdt = self.sigma * X[1]\n        return np.array([dxdt, dydt, dzdt])\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        param_dict = super().param_dict()\n        q_range = super().QUANTILE_RANGE[:] if q_range is None else q_range\n        if train_df_divided is not None:\n            df = train_df_divided.copy()\n            # rho = - (dx/dt) / x / y\n            rho_series = 0 - df[\"x\"].diff() / df[\"t\"].diff() / df[\"x\"] / df[\"y\"]\n            param_dict[\"rho\"] = rho_series.quantile(q_range)\n            # sigma = (dz/dt) / y\n            sigma_series = df[\"z\"].diff() / df[\"t\"].diff() / df[\"y\"]\n            param_dict[\"sigma\"] = sigma_series.quantile(q_range)\n            return param_dict\n        param_dict[\"rho\"] = (0, 1)\n        param_dict[\"sigma\"] = (0, 1)\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        df[\"X\"] = df[\"Susceptible\"]\n        df[\"Y\"] = df[\"Infected\"]\n        df[\"Z\"] = df[\"Recovered\"] + df[\"Fatal\"]\n        return df.loc[:, [\"T\", \"X\", \"Y\", \"Z\"]]\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        df[\"Susceptible\"] = df[\"X\"]\n        df[\"Infected\"] = df[\"Y\"]\n        df[\"Recovered/Deaths\"] = df[\"Z\"]\n        return df\n\n    def calc_r0(self):\n        if self.sigma == 0:\n            return np.nan\n        r0 = self.rho / self.sigma\n        return round(r0, 2)\n\n    def calc_days_dict(self, tau):\n        _dict = dict()\n        _dict[\"1/beta [day]\"] = int(tau / 24 / 60 / self.rho)\n        _dict[\"1/gamma [day]\"] = int(tau / 24 / 60 / self.sigma)\n        return _dict","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da7442b6-fa0b-4bf2-bb2d-70625b5b944f","_cell_guid":"945c3774-cf7c-40c8-b63f-d852df420781","trusted":true},"cell_type":"markdown","source":"#### SIR-D model"},{"metadata":{"_uuid":"66a9f00d-1639-4fef-b66e-9fe8adb3f7dc","_cell_guid":"4bbd4ca2-bf18-440a-8fef-a81f8694957f","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class SIRD(ModelBase):\n    NAME = \"SIR-D\"\n    VARIABLES = [\"x\", \"y\", \"z\", \"w\"]\n    PRIORITIES = np.array([1, 10, 10, 2])\n    MONOTONIC = [\"z\", \"w\"]\n\n    def __init__(self, kappa, rho, sigma):\n        super().__init__()\n        self.kappa = kappa\n        self.rho = rho\n        self.sigma = sigma\n\n    def __call__(self, t, X):\n        # x, y, z, w = [X[i] for i in range(len(self.VARIABLES))]\n        # dxdt = - self.rho * x * y\n        # dydt = self.rho * x * y - (self.sigma + self.kappa) * y\n        # dzdt = self.sigma * y\n        # dwdt = self.kappa * y\n        dxdt = - self.rho * X[0] * X[1]\n        dydt = self.rho * X[0] * X[1] - (self.sigma + self.kappa) * X[1]\n        dzdt = self.sigma * X[1]\n        dwdt = self.kappa * X[1]\n        return np.array([dxdt, dydt, dzdt, dwdt])\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        param_dict = super().param_dict()\n        q_range = super().QUANTILE_RANGE[:] if q_range is None else q_range\n        if train_df_divided is not None:\n            df = train_df_divided.copy()\n            # kappa = (dw/dt) / y\n            kappa_series = df[\"w\"].diff() / df[\"t\"].diff() / df[\"y\"]\n            param_dict[\"kappa\"] = kappa_series.quantile(q_range)\n            # rho = - (dx/dt) / x / y\n            rho_series = 0 - df[\"x\"].diff() / df[\"t\"].diff() / df[\"x\"] / df[\"y\"]\n            param_dict[\"rho\"] = rho_series.quantile(q_range)\n            # sigma = (dz/dt) / y\n            sigma_series = df[\"z\"].diff() / df[\"t\"].diff() / df[\"y\"]\n            param_dict[\"sigma\"] = sigma_series.quantile(q_range)\n            return param_dict\n        param_dict[\"kappa\"] = (0, 1)\n        param_dict[\"rho\"] = (0, 1)\n        param_dict[\"sigma\"] = (0, 1)\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        df[\"X\"] = df[\"Susceptible\"]\n        df[\"Y\"] = df[\"Infected\"]\n        df[\"Z\"] = df[\"Recovered\"]\n        df[\"W\"] = df[\"Fatal\"]\n        return df.loc[:, [\"T\", \"X\", \"Y\", \"Z\", \"W\"]]\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        df[\"Susceptible\"] = df[\"X\"]\n        df[\"Infected\"] = df[\"Y\"]\n        df[\"Recovered\"] = df[\"Z\"]\n        df[\"Deaths\"] = df[\"W\"]\n        return df\n\n    def calc_r0(self):\n        try:\n            r0 = self.rho / (self.sigma + self.kappa)\n        except ZeroDivisionError:\n            return np.nan\n        return round(r0, 2)\n\n\n    def calc_days_dict(self, tau):\n        _dict = dict()\n        if self.kappa == 0:\n            _dict[\"1/alpha2 [day]\"] = 0\n        else:\n            _dict[\"1/alpha2 [day]\"] = int(tau / 24 / 60 / self.kappa)\n        _dict[\"1/beta [day]\"] = int(tau / 24 / 60 / self.rho)\n        if self.sigma == 0:\n            _dict[\"1/gamma [day]\"] = 0\n        else:\n            _dict[\"1/gamma [day]\"] = int(tau / 24 / 60 / self.sigma)\n        return _dict","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c178ee57-8983-4f55-84dd-71997fec53ce","_cell_guid":"1e115ae8-7e81-4055-896d-95889d3c973e","trusted":true},"cell_type":"markdown","source":"#### SIR-F model"},{"metadata":{"_uuid":"04c1a590-1767-4ab1-b7de-d58d8ca69841","_cell_guid":"b4fc216a-fe30-4316-90e1-2034c5abff38","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class SIRF(ModelBase):\n    NAME = \"SIR-F\"\n    VARIABLES = [\"x\", \"y\", \"z\", \"w\"]\n    PRIORITIES = np.array([1, 10, 10, 2])\n    MONOTONIC = [\"z\", \"w\"]\n\n    def __init__(self, theta, kappa, rho, sigma):\n        super().__init__()\n        self.theta = theta\n        self.kappa = kappa\n        self.rho = rho\n        self.sigma = sigma\n\n    def __call__(self, t, X):\n        # x, y, z, w = [X[i] for i in range(len(self.VARIABLES))]\n        # dxdt = - self.rho * x * y\n        # dydt = self.rho * (1 - self.theta) * x * y - (self.sigma + self.kappa) * y\n        # dzdt = self.sigma * y\n        # dwdt = self.rho * self.theta * x * y + self.kappa * y\n        dxdt = - self.rho * X[0] * X[1]\n        dydt = self.rho * (1 - self.theta) * X[0] * X[1] - (self.sigma + self.kappa) * X[1]\n        dzdt = self.sigma * X[1]\n        dwdt = self.rho * self.theta * X[0] * X[1] + self.kappa * X[1]\n        return np.array([dxdt, dydt, dzdt, dwdt])\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        param_dict = super().param_dict()\n        q_range = super().QUANTILE_RANGE[:] if q_range is None else q_range\n        param_dict[\"theta\"] = (0, 1)\n        param_dict[\"kappa\"] = (0, 1)\n        if train_df_divided is not None:\n            df = train_df_divided.copy()\n            # rho = - (dx/dt) / x / y\n            rho_series = 0 - df[\"x\"].diff() / df[\"t\"].diff() / df[\"x\"] / df[\"y\"]\n            param_dict[\"rho\"] = rho_series.quantile(q_range)\n            # sigma = (dz/dt) / y\n            sigma_series = df[\"z\"].diff() / df[\"t\"].diff() / df[\"y\"]\n            param_dict[\"sigma\"] = sigma_series.quantile(q_range)\n            return param_dict\n        param_dict[\"rho\"] = (0, 1)\n        param_dict[\"sigma\"] = (0, 1)\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        df[\"X\"] = df[\"Susceptible\"]\n        df[\"Y\"] = df[\"Infected\"]\n        df[\"Z\"] = df[\"Recovered\"]\n        df[\"W\"] = df[\"Fatal\"]\n        return df.loc[:, [\"T\", \"X\", \"Y\", \"Z\", \"W\"]]\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        df[\"Susceptible\"] = df[\"X\"]\n        df[\"Infected\"] = df[\"Y\"]\n        df[\"Recovered\"] = df[\"Z\"]\n        df[\"Fatal\"] = df[\"W\"]\n        return df\n\n    def calc_r0(self):\n        try:\n            r0 = self.rho * (1 - self.theta) / (self.sigma + self.kappa)\n        except ZeroDivisionError:\n            return np.nan\n        return round(r0, 2)\n\n    def calc_days_dict(self, tau):\n        _dict = dict()\n        _dict[\"alpha1 [-]\"] = round(self.theta, 3)\n        if self.kappa == 0:\n            _dict[\"1/alpha2 [day]\"] = 0\n        else:\n            _dict[\"1/alpha2 [day]\"] = int(tau / 24 / 60 / self.kappa)\n        _dict[\"1/beta [day]\"] = int(tau / 24 / 60 / self.rho)\n        if self.sigma == 0:\n            _dict[\"1/gamma [day]\"] = 0\n        else:\n            _dict[\"1/gamma [day]\"] = int(tau / 24 / 60 / self.sigma)\n        return _dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### SEWIR-F model"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class SEWIRF(ModelBase):\n    NAME = \"SEWIR-F\"\n    VARIABLES = [\"x1\", \"x2\", \"x3\", \"y\", \"z\", \"w\"]\n    PRIORITIES = np.array([0, 0, 0, 10, 10, 2])\n    MONOTONIC = [\"z\", \"w\"]\n\n    def __init__(self, theta, kappa, rho1, rho2, rho3, sigma):\n        super().__init__()\n        self.theta = theta\n        self.kappa = kappa\n        self.rho1 = rho1\n        self.rho2 = rho2\n        self.rho3 = rho3\n        self.sigma = sigma\n\n    def __call__(self, t, X):\n        # x1, x2, x3, y, z, w = [X[i] for i in range(len(self.VARIABLES))]\n        # dx1dt = - self.rho1 * x1 * (x3 + y)\n        # dx2dt = self.rho1 * x1 * (x3 + y) - self.rho2 * x2\n        # dx3dt = self.rho2 * x2 - self.rho3 * x3\n        # dydt = self.rho3 * (1 - self.theta) * x3 - (self.sigma + self.kappa) * y\n        # dzdt = self.sigma * y\n        # dwdt = self.rho3 * self.theta * x3 + self.kappa * y\n        dx1dt = - self.rho1 * X[0] * (X[2] + X[3])\n        dx2dt = self.rho1 * X[0] * (X[2] + X[3]) - self.rho2 * X[1]\n        dx3dt = self.rho2 * X[1] - self.rho3 * X[2]\n        dydt = self.rho3 * (1 - self.theta) * X[2] - (self.sigma + self.kappa) * X[3]\n        dzdt = self.sigma * X[3]\n        dwdt = self.rho3 * self.theta * X[2] + self.kappa * X[3]\n        return np.array([dx1dt, dx2dt, dx3dt, dydt, dzdt, dwdt])\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        param_dict = super().param_dict()\n        q_range = super().QUANTILE_RANGE[:] if q_range is None else q_range\n        param_dict[\"theta\"] = (0, 1)\n        param_dict[\"kappa\"] = (0, 1)\n        param_dict[\"rho1\"] = (0, 1)\n        param_dict[\"rho2\"] = (0, 1)\n        param_dict[\"rho3\"] = (0, 1)\n        if train_df_divided is not None:\n            df = train_df_divided.copy()\n            # sigma = (dz/dt) / y\n            sigma_series = df[\"z\"].diff() / df[\"t\"].diff() / df[\"y\"]\n            param_dict[\"sigma\"] = sigma_series.quantile(q_range)\n            return param_dict\n        param_dict[\"sigma\"] = (0, 1)\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        df[\"X1\"] = df[\"Susceptible\"]\n        df[\"X2\"] = 0\n        df[\"X3\"] = 0\n        df[\"Y\"] = df[\"Infected\"]\n        df[\"Z\"] = df[\"Recovered\"]\n        df[\"W\"] = df[\"Fatal\"]\n        return df.loc[:, [\"T\", \"X1\", \"X2\", \"X3\", \"Y\", \"Z\", \"W\"]]\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        df[\"Susceptible\"] = df[\"X1\"]\n        df[\"Infected\"] = df[\"Y\"]\n        df[\"Recovered\"] = df[\"Z\"]\n        df[\"Fatal\"] = df[\"W\"]\n        df[\"Exposed\"] = df[\"X2\"]\n        df[\"Waiting\"] = df[\"X3\"]\n        return df\n\n    def calc_r0(self):\n        try:\n            r0 = self.rho1 * (1 - self.theta) / (self.sigma + self.kappa)\n        except ZeroDivisionError:\n            return np.nan\n        return round(r0, 2)\n\n    def calc_days_dict(self, tau):\n        _dict = dict()\n        _dict[\"alpha1 [-]\"] = round(self.theta, 3)\n        if self.kappa == 0:\n            _dict[\"1/alpha2 [day]\"] = 0\n        else:\n            _dict[\"1/alpha2 [day]\"] = int(tau / 24 / 60 / self.kappa)\n        _dict[\"1/beta1 [day]\"] = int(tau / 24 / 60 / self.rho1)\n        _dict[\"1/beta2 [day]\"] = int(tau / 24 / 60 / self.rho2)\n        _dict[\"1/beta3 [day]\"] = int(tau / 24 / 60 / self.rho3)\n        if self.sigma == 0:\n            _dict[\"1/gamma [day]\"] = 0\n        else:\n            _dict[\"1/gamma [day]\"] = int(tau / 24 / 60 / self.sigma)\n        return _dict","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c713d3b8-105c-4cb0-82ed-dc1f54011715","_cell_guid":"acd82be6-702c-46fb-8b36-bf8b9afe9be4","trusted":true},"cell_type":"markdown","source":"#### SIR-FV model"},{"metadata":{"_uuid":"2a3978f2-82e3-4945-a981-4a6372e1bb20","_cell_guid":"25dec87e-96eb-4198-832e-6babe9381e4c","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class SIRFV(ModelBase):\n    NAME = \"SIR-FV\"\n    VARIABLES = [\"x\", \"y\", \"z\", \"w\"]\n    PRIORITIES = np.array([1, 10, 10, 2])\n    MONOTONIC = [\"z\", \"w\"]\n\n    def __init__(self, theta, kappa, rho, sigma, omega=None, n=None, v_per_day=None):\n        \"\"\"\n        (n and v_per_day) or omega must be applied.\n        @n <float or int>: total population\n        @v_par_day <float or int>: vacctinated persons per day\n        \"\"\"\n        super().__init__()\n        self.theta = theta\n        self.kappa = kappa\n        self.rho = rho\n        self.sigma = sigma\n        if omega is None:\n            try:\n                self.omega = float(v_per_day) / float(n)\n            except TypeError:\n                s = \"Neither (n and va_per_day) nor omega must be applied!\"\n                raise TypeError(s)\n        else:\n            self.omega = float(omega)\n\n    def __call__(self, t, X):\n        # x, y, z, w = [X[i] for i in range(len(self.VARIABLES))]\n        # x with vacctination\n        dxdt = - self.rho * X[0] * X[1] - self.omega\n        dxdt = 0 - X[0] if X[0] + dxdt < 0 else dxdt\n        # y, z, w\n        dydt = self.rho * (1 - self.theta) * X[0] * X[1] - (self.sigma + self.kappa) * X[1]\n        dzdt = self.sigma * X[1]\n        dwdt = self.rho * self.theta * X[0] * X[1] + self.kappa * X[1]\n        return np.array([dxdt, dydt, dzdt, dwdt])\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        param_dict = super().param_dict()\n        q_range = super().QUANTILE_RANGE[:] if q_range is None else q_range\n        param_dict[\"theta\"] = (0, 1)\n        param_dict[\"kappa\"] = (0, 1)\n        param_dict[\"omega\"] = (0, 1)\n        if train_df_divided is not None:\n            df = train_df_divided.copy()\n            # rho = - (dx/dt) / x / y\n            rho_series = 0 - df[\"x\"].diff() / df[\"t\"].diff() / df[\"x\"] / df[\"y\"]\n            param_dict[\"rho\"] = rho_series.quantile(q_range)\n            # sigma = (dz/dt) / y\n            sigma_series = df[\"z\"].diff() / df[\"t\"].diff() / df[\"y\"]\n            param_dict[\"sigma\"] = sigma_series.quantile(q_range)\n            return param_dict\n        param_dict[\"rho\"] = (0, 1)\n        param_dict[\"sigma\"] = (0, 1)\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        df[\"X\"] = df[\"Susceptible\"]\n        df[\"Y\"] = df[\"Infected\"]\n        df[\"Z\"] = df[\"Recovered\"]\n        df[\"W\"] = df[\"Fatal\"]\n        return df.loc[:, [\"T\", \"X\", \"Y\", \"Z\", \"W\"]]\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        df[\"Susceptible\"] = df[\"X\"]\n        df[\"Infected\"] = df[\"Y\"]\n        df[\"Recovered\"] = df[\"Z\"]\n        df[\"Fatal\"] = df[\"W\"]\n        df[\"Immuned\"] = 1 - df[[\"X\", \"Y\", \"Z\", \"W\"]].sum(axis=1)\n        return df\n\n    def calc_r0(self):\n        try:\n            r0 = self.rho * (1 - self.theta) / (self.sigma + self.kappa)\n        except ZeroDivisionError:\n            return np.nan\n        return round(r0, 2)\n\n    def calc_days_dict(self, tau):\n        _dict = dict()\n        _dict[\"alpha1 [-]\"] = round(self.theta, 3)\n        if self.kappa == 0:\n            _dict[\"1/alpha2 [day]\"] = 0\n        else:\n            _dict[\"1/alpha2 [day]\"] = int(tau / 24 / 60 / self.kappa)\n        _dict[\"1/beta [day]\"] = int(tau / 24 / 60 / self.rho)\n        if self.sigma == 0:\n            _dict[\"1/gamma [day]\"] = 0\n        else:\n            _dict[\"1/gamma [day]\"] = int(tau / 24 / 60 / self.sigma)\n        return _dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Parameter Estimation using Optuna"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"class Estimator(object):\n    def __init__(self, model, ncov_df, total_population, name=None, places=None, areas=None,\n                 excluded_places=None, start_date=None, end_date=None, date_format=\"%d%b%Y\", **params):\n        \"\"\"\n        Set training data.\n        @model <ModelBase>: the model\n        @name <str>: name of the area\n        @params: fixed parameter of the model\n        @the other params: See the function named create_target_df()\n        \"\"\"\n        # Fixed parameters\n        self.fixed_param_dict = params.copy()\n        if None in params.values():\n            self.fixed_param_dict = {\n                k: v for (k, v) in params.items() if v is not None\n            }\n        # Register the dataset arranged for the model\n        dataset = model.create_dataset(\n            ncov_df, total_population, places=places, areas=areas,\n            excluded_places=excluded_places,\n            start_date=start_date, end_date=end_date, date_format=date_format\n        )\n        self.start_time, self.initials, self.Tend, self.train_df = dataset\n        self.total_population = total_population\n        self.name = name\n        self.model = model\n        self.param_dict = dict()\n        self.study = None\n        self.optimize_df = None\n\n    def run(self, n_trials=500):\n        \"\"\"\n        Try estimation (optimization of parameters and tau).\n        @n_trials <int>: the number of trials\n        \"\"\"\n        if self.study is None:\n            self.study = optuna.create_study(direction=\"minimize\")\n        self.study.optimize(\n            lambda x: self.objective(x),\n            n_trials=n_trials,\n            n_jobs=-1\n        )\n        param_dict = self.study.best_params.copy()\n        param_dict.update(self.fixed_param_dict)\n        param_dict[\"R0\"] = self.calc_r0()\n        param_dict[\"score\"] = self.score()\n        param_dict.update(self.calc_days_dict())\n        self.param_dict = param_dict.copy()\n        return param_dict\n\n    def history_df(self):\n        \"\"\"\n        Return the hsitory of optimization.\n        @return <pd.DataFrame>\n        \"\"\"\n        optimize_df = self.study.trials_dataframe()\n        optimize_df[\"time[s]\"] = optimize_df[\"datetime_complete\"] - \\\n            optimize_df[\"datetime_start\"]\n        optimize_df[\"time[s]\"] = optimize_df[\"time[s]\"].dt.total_seconds()\n        self.optimize_df = optimize_df.drop(\n            [\"datetime_complete\", \"datetime_start\", \"system_attrs__number\"], axis=1)\n        return self.optimize_df.sort_values(\"value\", ascending=True)\n\n    def history_graph(self):\n        \"\"\"\n        Show the history of parameter search using pair-plot.\n        \"\"\"\n        if self.optimize_df is None:\n            self.history_df()\n        df = self.optimize_df.copy()\n        sns.pairplot(df.loc[:, df.columns.str.startswith(\n            \"params_\")], diag_kind=\"kde\", markers=\"+\")\n        plt.show()\n\n    def objective(self, trial):\n        # Time\n        try:\n            tau = self.fixed_param_dict[\"tau\"]\n        except KeyError:\n            tau = trial.suggest_int(\"tau\", 1, 1440)\n        train_df_divided = self.train_df.copy()\n        train_df_divided[\"t\"] = (train_df_divided[\"T\"] / tau).astype(np.int64)\n        # Parameters\n        param_dict = self.model.param_dict(train_df_divided)\n        p_dict = {\"tau\": None}\n        p_dict.update(\n            {\n                k: trial.suggest_uniform(k, *v)\n                for (k, v) in param_dict.items()\n            }\n        )\n        p_dict.update(self.fixed_param_dict)\n        p_dict.pop(\"tau\")\n        # Simulation\n        t_end = train_df_divided.loc[train_df_divided.index[-1], \"t\"]\n        sim_df = simulation(self.model, self.initials, step_n=t_end, **p_dict)\n        return self.error_f(train_df_divided, sim_df)\n\n    def error_f(self, train_df_divided, sim_df):\n        \"\"\"\n        We need to minimize the difference of the observed values and estimated values.\n        This function calculate the difference of the estimated value and obsereved value.\n        \"\"\"\n        n = self.total_population\n        df = pd.merge(train_df_divided, sim_df, on=\"t\", suffixes=(\"_observed\", \"_estimated\"))\n        diffs = [\n            # Weighted Average: the recent data is more important\n            p * np.average(\n                abs(df[f\"{v}_observed\"] - df[f\"{v}_estimated\"]) / (df[f\"{v}_observed\"] * n + 1),\n                weights=df[\"t\"]\n            )\n            for (p, v) in zip(self.model.PRIORITIES, self.model.VARIABLES)\n        ]\n        return sum(diffs) * n\n\n    def compare_df(self):\n        \"\"\"\n        Show the taining data and simulated data in one dataframe.\n\n        \"\"\"\n        est_dict = self.study.best_params.copy()\n        est_dict.update(self.fixed_param_dict)\n        tau = est_dict[\"tau\"]\n        est_dict.pop(\"tau\")\n        observed_df = self.train_df.drop(\"T\", axis=1)\n        observed_df[\"t\"] = (self.train_df[\"T\"] / tau).astype(int)\n        t_end = observed_df.loc[observed_df.index[-1], \"t\"]\n        sim_df = simulation(self.model, self.initials, step_n=t_end, **est_dict)\n        df = pd.merge(observed_df, sim_df, on=\"t\", suffixes=(\"_observed\", \"_estimated\"))\n        df = df.set_index(\"t\")\n        return df\n\n    def compare_graph(self):\n        \"\"\"\n        Compare obsereved and estimated values in graphs.\n        \"\"\"\n        df = self.compare_df()\n        use_variables = [\n            v for (i, (p, v)) in enumerate(zip(self.model.PRIORITIES, self.model.VARIABLES))\n            if p != 0 and i != 0\n        ]\n        val_len = len(use_variables) + 1\n        fig, axes = plt.subplots(\n            ncols=1, nrows=val_len, figsize=(9, 6 * val_len / 2))\n        for (ax, v) in zip(axes.ravel()[1:], use_variables):\n            df[[f\"{v}_observed\", f\"{v}_estimated\"]].plot.line(\n                ax=ax, ylim=(0, None), sharex=True,\n                title=f\"{self.model.NAME}: Comparison of observed/estimated {v}(t)\"\n            )\n            ax.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n            ax.ticklabel_format(style=\"sci\",  axis=\"y\", scilimits=(0, 0))\n            ax.legend(bbox_to_anchor=(1.02, 0),\n                      loc=\"lower left\", borderaxespad=0)\n        for v in use_variables:\n            df[f\"{v}_diff\"] = df[f\"{v}_observed\"] - df[f\"{v}_estimated\"]\n            df[f\"{v}_diff\"].plot.line(\n                ax=axes.ravel()[0], sharex=True,\n                title=f\"{self.model.NAME}: observed - estimated\"\n            )\n        axes.ravel()[0].axhline(y=0, color=\"black\", linestyle=\"--\")\n        axes.ravel()[0].yaxis.set_major_formatter(\n            ScalarFormatter(useMathText=True))\n        axes.ravel()[0].ticklabel_format(\n            style=\"sci\",  axis=\"y\", scilimits=(0, 0))\n        axes.ravel()[0].legend(bbox_to_anchor=(1.02, 0),\n                               loc=\"lower left\", borderaxespad=0)\n        fig.tight_layout()\n        fig.show()\n\n    def calc_r0(self):\n        \"\"\"\n        Calculate R0.\n        \"\"\"\n        est_dict = self.study.best_params.copy()\n        est_dict.update(self.fixed_param_dict)\n        est_dict.pop(\"tau\")\n        model_instance = self.model(**est_dict)\n        return model_instance.calc_r0()\n\n    def calc_days_dict(self):\n        \"\"\"\n        Calculate 1/beta etc.\n        \"\"\"\n        est_dict = self.study.best_params.copy()\n        est_dict.update(self.fixed_param_dict)\n        tau = est_dict[\"tau\"]\n        est_dict.pop(\"tau\")\n        model_instance = self.model(**est_dict)\n        return model_instance.calc_days_dict(tau)\n\n    def predict_df(self, step_n):\n        \"\"\"\n        Predict the values in the future.\n        @step_n <int>: the number of steps\n        @return <pd.DataFrame>: predicted data for measurable variables.\n        \"\"\"\n        est_dict = self.study.best_params.copy()\n        est_dict.update(self.fixed_param_dict)\n        tau = est_dict[\"tau\"]\n        est_dict.pop(\"tau\")\n        df = simulation(self.model, self.initials, step_n=step_n, **est_dict)\n        df[\"Time\"] = (\n            df[\"t\"] * tau).apply(lambda x: timedelta(minutes=x)) + self.start_time\n        df = df.set_index(\"Time\").drop(\"t\", axis=1)\n        df = (df * self.total_population).astype(np.int64)\n        upper_cols = [n.upper() for n in df.columns]\n        df.columns = upper_cols\n        df = self.model.calc_variables_reverse(df).drop(upper_cols, axis=1)\n        return df\n\n    def predict_graph(self, step_n, name=None, excluded_cols=None):\n        \"\"\"\n        Predict the values in the future and create a figure.\n        @step_n <int>: the number of steps\n        @name <str>: name of the area\n        @excluded_cols <list[str]>: the excluded columns in the figure\n        \"\"\"\n        if self.name is not None:\n            name = self.name\n        else:\n            name = str() if name is None else name\n        df = self.predict_df(step_n=step_n)\n        if excluded_cols is not None:\n            df = df.drop(excluded_cols, axis=1)\n        r0 = self.param_dict[\"R0\"]\n        title = f\"Prediction in {name} with {self.model.NAME} model: R0 = {r0}\"\n        today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)\n        line_plot(df, title, v=today, h=self.total_population)\n\n    def rmsle(self, compare_df):\n        \"\"\"\n        Return the value of RMSLE.\n        @param compare_df <pd.DataFrame>\n        \"\"\"\n        df = compare_df.set_index(\"t\") * self.total_population\n        score = 0\n        for (priority, v) in zip(self.model.PRIORITIES, self.model.VARIABLES):\n            if priority == 0:\n                continue\n            observed, estimated = df[f\"{v}_observed\"], df[f\"{v}_estimated\"]\n            diff = (np.log(observed + 1) - np.log(estimated + 1))\n            score += (diff ** 2).sum()\n        rmsle = np.sqrt(score / len(df))\n        return rmsle\n\n    def score(self):\n        \"\"\"\n        Return the value of RMSLE.\n        \"\"\"\n        rmsle = self.rmsle(self.compare_df().reset_index(\"t\"))\n        return rmsle\n\n    def info(self):\n        \"\"\"\n        Return Estimater information.\n        @return <tupple[object]>:\n            - <ModelBase>: model\n            - <dict[str]=str>: name, total_population, start_time, tau\n            - <dict[str]=float>: values of parameters of model\n        \"\"\"\n        param_dict = self.study.best_params.copy()\n        param_dict.update(self.fixed_param_dict)\n        info_dict = {\n            \"name\": self.name,\n            \"total_population\": self.total_population,\n            \"start_time\": self.start_time,\n            \"tau\": param_dict[\"tau\"],\n            \"initials\": self.initials\n        }\n        param_dict.pop(\"tau\")\n        return (self.model, info_dict, param_dict)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6456fea-dbb4-429f-bddd-f2f28adb2850","_cell_guid":"b3dc178b-d383-4d93-be08-d7ae4b1641c8","trusted":true},"cell_type":"markdown","source":"### Prediction of the data using some models"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class Predicter(object):\n    \"\"\"\n    Predict the future using models.\n    \"\"\"\n    def __init__(self, name, total_population, start_time, tau, initials, date_format=\"%d%b%Y\"):\n        \"\"\"\n        @name <str>: place name\n        @total_population <int>: total population\n        @start_time <datatime>: the start time\n        @tau <int>: tau value (time step)\n        @initials <list/tupple/np.array[float]>: initial values of the first model\n        @date_format <str>: date format to display in figures\n        \"\"\"\n        self.name = name\n        self.total_population = total_population\n        self.start_time = start_time.replace(hour=0, minute=0, second=0, microsecond=0)\n        self.tau = tau\n        self.date_format = date_format\n        # Un-fixed\n        self.last_time = start_time\n        self.axvlines = list()\n        self.initials = initials\n        self.df = pd.DataFrame()\n        self.title_list = list()\n        self.reverse_f = lambda x: x\n        self.model_names = list()\n\n    def add(self, model, end_day_n=None, count_from_last=False, vline=True, **param_dict):\n        \"\"\"\n        @model <ModelBase>: the epidemic model\n        @end_day_n <int/None>: day number of the end date (0, 1, 2,...), or None (now)\n            - if @count_from_last <bool> is True, start point will be the last date registered to Predicter\n        @vline <bool>: if True, vertical line will be shown at the end date\n        @**param_dict <dict>: keyword arguments of the model\n        \"\"\"\n        # Validate day number, and calculate step number\n        vline_yesterday = False\n        if end_day_n == 0:\n            end_day_n = 1\n            vline_yesterday = True\n        if end_day_n is None:\n            end_time = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)\n        else:\n            if count_from_last:\n                end_time = self.last_time + timedelta(days=end_day_n)\n            else:\n                end_time = self.start_time + timedelta(days=end_day_n)\n        if end_time <= self.last_time:\n            raise Exception(f\"Model on {end_time.strftime(self.date_format)} has been registered!\")\n        step_n = int((end_time - self.last_time).total_seconds() / 60 / self.tau) + 1\n        self.last_time = end_time.replace(hour=0, minute=0, second=0, microsecond=0)\n        # Perform simulation\n        new_df = simulation(model, self.initials, step_n=step_n, **param_dict)\n        new_df[\"t\"] = new_df[\"t\"] + len(self.df)\n        self.df = pd.concat([self.df, new_df.iloc[1:, :]], axis=0).fillna(0)\n        self.initials = new_df.set_index(\"t\").iloc[-1, :]\n        # For title\n        self.model_names.append(model.NAME)\n        if vline:\n            vline_date = end_time.replace(hour=0, minute=0, second=0, microsecond=0)\n            if vline_yesterday:\n                vline_date -= timedelta(days=1)\n            self.axvlines.append(vline_date)\n            r0 = model(**param_dict).calc_r0()\n            if len(self.axvlines) == 1:\n                self.title_list.append(f\"{model.NAME}(R0={r0}, -{vline_date.strftime(self.date_format)})\")\n            else:\n                if model.NAME == self.model_names[-1]:\n                    self.title_list.append(f\"({r0}, -{vline_date.strftime(self.date_format)})\")\n                else:\n                    self.title_list.append(f\"{model.NAME}({r0}, -{end_time.strftime(self.date_format)})\")\n        # Update reverse function (X, Y,.. to Susceptible, Infected,...)\n        self.reverse_f = model.calc_variables_reverse\n        return self\n\n    def restore_df(self, min_infected=1):\n        \"\"\"\n        Return the dimentional simulated data.\n        @min_infected <int>: if Infected < min_infected, the records will not be used\n        @return <pd.DataFrame>\n        \"\"\"\n        df = self.df.copy()\n        df[\"Time\"] = self.start_time + df[\"t\"].apply(lambda x: timedelta(minutes=x * self.tau))\n        df = df.drop(\"t\", axis=1).set_index(\"Time\") * self.total_population\n        df = df.astype(np.int64)\n        upper_cols = [n.upper() for n in df.columns]\n        df.columns = upper_cols\n        df = self.reverse_f(df).drop(upper_cols, axis=1)\n        df = df.loc[df[\"Infected\"] >= min_infected, :]\n        return df\n\n    def restore_graph(self, drop_cols=None, min_infected=1, **kwargs):\n        \"\"\"\n        Show the dimentional simulate data as a figure.\n        @drop_cols <list[str]>: the columns not to be shown\n        @min_infected <int>: if Infected < min_infected, the records will not be used\n        @kwargs: keyword arguments of line_plot() function\n        \"\"\"\n        df = self.restore_df(min_infected=min_infected)\n        if drop_cols is not None:\n            df = df.drop(drop_cols, axis=1)\n        today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)\n        axvlines = [today, *self.axvlines] if len(self.axvlines) == 1 else self.axvlines[:]\n        line_plot(\n            df,\n            title=f\"{self.name}: {', '.join(self.title_list)}\",\n            v=axvlines[:-1],\n            h=self.total_population,\n            **kwargs\n        )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Scenario analysis"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"class Scenario(object):\n    \"\"\"\n    Class for scenario analysis.\n    \"\"\"\n    SUFFIX_DICT = defaultdict(lambda: \"th\")\n    SUFFIX_DICT.update({1: \"st\", 2: \"nd\", 3: \"rd\"})\n\n    def __init__(self, ncov_df, name, date_format=\"%d%b%Y\", **kwargs):\n        \"\"\"\n        @ncov_df <pd.DataFrame>: the cleaned data\n        @name <str>: name of the country/area\n        @date_format <str>: string format of date\n        @kwargs: keyword arguments of select_area() function\n        \"\"\"\n        record_df = select_area(ncov_df, **kwargs)\n        record_df = record_df.set_index(\"Date\").resample(\"D\").last()\n        record_df = record_df.interpolate(method=\"linear\")\n        record_df = record_df.loc[:, [\"Confirmed\", \"Infected\", \"Deaths\", \"Recovered\"]]\n        self.record_df = record_df.reset_index()\n        self.name = name\n        self.date_format = date_format\n        self.phase_dict = dict()\n        self.estimator_dict = dict()\n        self.param_df = pd.DataFrame()\n        self.future_phase_dict = dict()\n        self.future_param_dict = dict()\n        self.phases_without_vline = list()\n        self.last_model = ModelBase\n\n    def show_record(self):\n        \"\"\"\n        Show the records.\n        \"\"\"\n        line_plot(\n            self.record_df.drop(\"Confirmed\", axis=1).set_index(\"Date\"),\n            f\"{self.name}: Cases over time\",\n            y_integer=True\n        )\n        return self.record_df\n\n    def growth_factor(self, days_to_predict=0, until_stopping=False, show_figure=True):\n        \"\"\"\n        Return growth factor group and the history of growth factor values.\n        @days_to_predict <int>: how many days to predict\n        @until_stopping <bool>:\n            if True and days_to_predict > 0,\n            calculate growth factor values until the group will shift stopping\n            after the last observation date\n        @show_figure <bool>: if True, show line plot of cases over time\n        \"\"\"\n        # Calculate growth factor\n        if days_to_predict <= 0:\n            # Value\n            records = self.record_df.set_index(\"Date\")[\"Confirmed\"]\n            growth = records.diff() / records.diff().shift(freq=\"D\")\n        else:\n            records = self.predict(days=days_to_predict, show_figure=False)\n            records = records[\"Confirmed\"].fillna(\"ffill\")\n            growth = records.diff() / records.diff().shift()\n        growth = growth.replace(np.inf, np.nan).fillna(1.0)\n        growth = growth.rolling(7).mean()[6:-1].round(2)\n        # Group\n        if days_to_predict > 0 and until_stopping:\n            last_observe_date = self.record_df[\"Date\"].max().round(\"D\")\n            df = pd.DataFrame(\n                {\"Date\": growth.index.round(\"D\"), \"Value\": growth}\n            )\n            df = df.set_index(\"Date\").resample(\"D\").last().reset_index()\n            df = df.loc[df[\"Date\"] > (last_observe_date - timedelta(days=8)), :]\n            date_df = df.loc[(df[\"Value\"] < 1).rolling(7).sum() >= 7, \"Date\"]\n            try:\n                calc_date = date_df.reset_index(drop=True)[0]\n            except IndexError:\n                calc_date = df[\"Date\"].max()\n            group = \"Stopping\"\n            growth = df.loc[df[\"Date\"] <= calc_date, :]\n            more_n = (growth[\"Value\"] > 1)[::-1].cumprod().sum()\n            less_n = (growth[\"Value\"] < 1)[::-1].cumprod().sum()\n            growth = growth.set_index(\"Date\")\n            date_str = calc_date.strftime(\"%d%b%Y\")\n            fig_title = f\"{self.name}: Growth factor over time with prediction until {date_str}\"\n        else:\n            more_n = (growth > 1)[::-1].cumprod().sum()\n            less_n = (growth < 1)[::-1].cumprod().sum()\n            calc_date = growth.index[-1]\n            group = \"Outbreaking\" if more_n >= 7 else \"Stopping\" if less_n >= 7 else \"Crossroad\"\n            fig_title = f\"{self.name}: Growth Factor over time\"\n        group_df = pd.DataFrame(\n            {\n                \"Date\": calc_date,\n                \"Group\": group,\n                \"GF > 1 [straight days]\": more_n,\n                \"GF < 1 [straight days]\": less_n\n            },\n            index=[self.name]\n        )\n        # Growth factor over time\n        if show_figure:\n            growth.plot(title=fig_title, legend=False)\n            plt.axhline(1.0, color=\"black\", linestyle=\"--\")\n            plt.xlabel(None)\n            today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)\n            plt.axvline(today, color=\"black\", linestyle=\"--\")\n            plt.show()\n        return group_df\n        \n    def trend(self, variables=[\"Confirmed\", \"Deaths\", \"Recovered\"], **kwargs):\n        \"\"\"\n        Perform trend analysis.\n        @variables <list[str]>: list of variables\n        @kwargs: keyword arguments of show_trend() function\n        \"\"\"\n        if \"variable\" in kwargs.keys():\n            raise KeyError(\"Please use variables argument rather than variable arugument.\")\n        for val in variables:\n            show_trend(self.record_df, name=self.name, variable=val, **kwargs)\n        return None\n\n    def set_phase(self, start_dates, population):\n        \"\"\"\n        Set phase for hyperparameter estimation.\n        @start_dates <list[str]>: list of start dates of the phases\n        @population <int or list[int]>: total population or list of total population\n        \"\"\"\n        end_dates = [\n            (datetime.strptime(s, self.date_format) - timedelta(days=1)).strftime(self.date_format)\n            for s in start_dates[1:]\n        ]\n        end_dates.append(None)\n        if isinstance(population, int):\n            population_values = [population for _ in range(len(start_dates))]\n        elif len(population) == len(start_dates):\n            population_values = population[:]\n        else:\n            raise Exception(\"start_date and population must have the same length!\")\n        self.phase_dict = {\n            self._num2str(n): {\"start_date\": s, \"end_date\": e, \"population\": p}\n            for (n, (s, e, p)) in enumerate(zip(start_dates, end_dates, population_values), 1)\n        }\n        self.estimator_dict = dict()\n        return pd.DataFrame.from_dict(self.phase_dict, orient=\"index\").fillna(\"-\")\n\n    def estimate(self, model, n_trials=100, same_tau=True):\n        \"\"\"\n        Perform hyperparameter estimation.\n        @model <ModelBase>: math model\n        @n_trials <int>: the number of trials\n        @same_tau <bool>:\n            whether apply the tau value of first phase to the following phases or not.\n        \"\"\"\n        if not self.phase_dict:\n            raise Exception(\"Please use Scenario.set_phase() at first.\")\n        tau = None\n        est_start_time = datetime.now()\n        for num in self.phase_dict.keys():\n            print(f\"Hyperparameter estimation of {num} phase.\")\n            target_dict = self.phase_dict[num]\n            while True:\n                # Create estimator\n                est_start_time_class = datetime.now()\n                self.estimator_dict[num] = Estimator(\n                    model, self.record_df, target_dict[\"population\"],\n                    name=self.name,\n                    start_date=target_dict[\"start_date\"],\n                    end_date=target_dict[\"end_date\"],\n                    date_format=self.date_format,\n                    tau=tau\n                )\n                print(\"\\tEstimator was created.\")\n                # Run trials\n                while True:\n                    print(f\"\\t\\t{n_trials} trials\", end=\" \")\n                    est_start_time_run = datetime.now()\n                    with warnings.catch_warnings():\n                        warnings.simplefilter(\"ignore\")\n                        _ = self.estimator_dict[num].run(n_trials=n_trials)\n                    minutes, seconds = divmod(int((datetime.now() - est_start_time_run).total_seconds()), 60)\n                    print(f\"finished in {minutes} min {seconds} sec.\")\n                    # Check if estimated in (observed * 0.8, observed * 1.2)\n                    compare_df = self.estimator_dict[num].compare_df()\n                    targets = [\n                        (compare_df[f\"{val}_estimated\"], compare_df[f\"{val}_observed\"])\n                        for val in model.MONOTONIC\n                    ]\n                    max_ok = [obs.max() * 0.8 <= est.max() <= obs.max() * 1.2 for (est, obs) in targets]\n                    monotonic_ok = [target[0].is_monotonic for target in targets]\n                    elapsed = (datetime.now() - est_start_time_class).total_seconds()\n                    if all(max_ok) or not all(monotonic_ok) or elapsed > 60 * 3:\n                        break\n                if all(monotonic_ok) and all(max_ok):\n                    print(\"\\tSuccessfully estimated.\")\n                    break\n                vals = [val for (val, ok) in zip(model.MONOTONIC, monotonic_ok) if not ok]\n                try:\n                    print(f\"\\tEstimator will be replaced because estimated {vals[0]} is non-monotonic.\")\n                except IndexError:\n                    print(f\"\\tEstimator will be replaced because it is incapable of improvement.\")\n                    break\n            tau = self.estimator_dict[num].param_dict[\"tau\"]\n        minutes, seconds = divmod(int((datetime.now() - est_start_time).total_seconds()), 60)\n        print(f\"Total: {minutes} min {seconds} sec.\")\n        self.show_parameters()\n        self.last_model = model\n\n    def accuracy_graph(self, phase_n=1):\n        \"\"\"\n        Show observed - estimated graph.\n        @phase_n <int>: phase number\n        \"\"\"\n        phase_numbers = self.estimator_dict.keys()\n        phase = self._num2str(phase_n)\n        if phase not in phase_numbers:\n            raise KeyError(f\"phase_n must be in {list(phase_numbers)[0]} - {list(phase_numbers)[-1]}\")\n        self.estimator_dict[phase].compare_graph()\n\n    def _num2str(self, num):\n        \"\"\"\n        Convert numbers to 1st, 2nd etc.\n        @num <int>: number\n        @return <str>\n        \"\"\"\n        q, mod = divmod(num, 10)\n        suffix = \"th\" if q == 1 else self.SUFFIX_DICT[mod]\n        return f\"{num}{suffix}\"\n\n    def show_parameters(self):\n        \"\"\"\n        Show the parameter values.\n        @retunr <pd.DataFrame>\n        \"\"\"\n        # Phase information\n        phase_dict = self.phase_dict.copy()\n        phase_dict.update(self.future_phase_dict)\n        df1 = pd.DataFrame.from_dict(phase_dict, orient=\"index\")\n        # Parameter information\n        _dict = {\n            k: estimator.param_dict\n            for (k, estimator) in self.estimator_dict.items()\n        }\n        _future_dict = {\n            k: {\n                \"tau\": _dict[\"1st\"][\"tau\"],\n                **param_dict,\n                \"R0\": self.last_model(**param_dict).calc_r0(),\n                \"score\": None,\n                **self.last_model(**param_dict).calc_days_dict(_dict[\"1st\"][\"tau\"])\n            }\n            for (k, param_dict) in self.future_param_dict.items()\n        }\n        _dict.update(_future_dict)\n        df2 = pd.DataFrame.from_dict(_dict, orient=\"index\")\n        # Rename R0 to Rt\n        df2 = df2.rename({\"R0\": \"Rt\"}, axis=1)\n        self.param_df = pd.concat([df1, df2], axis=1).fillna(\"-\")\n        return self.param_df\n\n    def param(self, phase, param_name):\n        \"\"\"\n        Return parameter value.\n        @phase <str>: phase name, like 1st, 2nd..., or last\n        @param_name <str>: name of parameter, like rho\n        \"\"\"\n        if phase == \"last\":\n            phase = list(self.phase_dict.items())[-1][0]\n        try:\n            estimator = self.estimator_dict[phase]\n        except KeyError:\n            raise KeyError(\"Please revise phase name (NOT iinclude future params). e.g. 1st, 2nd,... or last\")\n        try:\n            param_name = \"R0\" if param_name == \"Rt\" else param_name\n            return estimator.param_dict[param_name]\n        except KeyError:\n            raise KeyError(\"Please revise parameter name. e.g. rho, gamma, R0 or R0\")\n\n    def param_history(self, targets=None, box_plot=True, **kwargs):\n        \"\"\"\n        Show the ratio to 1st parameters as a figure (bar plot).\n        @targets <list[str] or str>: parameters to show (including Rt etc.)\n        @box_plot <bool>: if True, box plot. if False, line plot.\n        @kwargs: keword arguments of pd.DataFrame.plot or line_plot()\n        \"\"\"\n        _ = self.show_parameters()\n        targets = self.param_df.columns if targets is None else targets\n        targets = [targets] if isinstance(targets, str) else targets\n        if \"R0\" in targets:\n            targets = [t.replace(\"R0\", \"Rt\") for t in targets]\n        df = self.param_df.loc[:, targets]\n        df.index = self.param_df[[\"start_date\", \"end_date\"]].apply(\n            lambda x: f\"{x[0]}-{x[1].replace('-', 'today')}\",\n            axis=1\n        )\n        df = df / df.iloc[0]\n        if box_plot:\n            df.plot.bar(title=\"Ratio to 1st parameters\", **kwargs)\n            plt.xticks(rotation=0)\n            plt.show()\n        else:\n            _df = df.reset_index(drop=True)\n            _df.index = _df.index + 1\n            line_plot(\n                _df, title=\"Ratio to 1st parameters\",\n                xlabel=\"Phase\", ylabel=str(), math_scale=False,\n                **kwargs\n            )\n\n    def compare_estimated_numbers(self, phases=None):\n        \"\"\"\n        Compare the number of confimred cases estimated with the parameters and show graph.\n        @variable <str>: variable to compare\n        @phases <list[str]>: phase to show (if None, all)\n        \"\"\"\n        phases = list(self.phase_dict.keys()) if phases is None else phases\n        # Observed\n        df = pd.DataFrame(self.record_df.set_index(\"Date\")[\"Confirmed\"])\n        # Estimated\n        for (num, estimator) in self.estimator_dict.items():\n            model, info_dict, param_dict = estimator.info()\n            day_n = int((datetime.today() - info_dict[\"start_time\"]).total_seconds() / 60 / 60 / 24 + 1)\n            predicter = Predicter(**info_dict)\n            predicter.add(model, end_day_n=day_n, **param_dict)\n            # Calculate the number of confirmed cases\n            new_df = predicter.restore_df().drop(\"Susceptible\", axis=1).sum(axis=1)\n            new_df = new_df.resample(\"D\").last()\n            df = pd.concat([df, new_df], axis=1)\n        # Show graph\n        df = df.fillna(0).astype(np.int64)\n        df.columns = [\"Observed\"] + [f\"{phase}_param\" for phase in self.phase_dict.keys()]\n        df = df.loc[self.phase_dict[\"1st\"][\"start_date\"]: self.record_df[\"Date\"].max(), :]\n        for col in df.columns[1:]:\n            if col[:col.find(\"_\")] not in phases:\n                continue\n            line_plot(\n                df.replace(0, np.nan)[[\"Observed\", col]],\n                f\"Confirmed cases over time: Actual and predicted with {col}\",\n                y_integer=True\n            )\n\n    def clear_future_param(self):\n        \"\"\"\n        Clear the future parameters.\n        \"\"\"\n        self.future_param_dict = dict()\n        self.future_phase_dict = dict()\n        last_phase = list(self.phase_dict.items())[-1][0]\n        self.phase_dict[last_phase][\"end_date\"] = None\n        return self\n\n    def add_future_param(self, start_date, vline=True, **kwargs):\n        \"\"\"\n        Add parameters of the future.\n        @start_date <str>: the start date of the phase\n        @vline <bool>: if True, add vertical line in the figure of predicted number of cases\n        @kwargs: keword argument of parameters to change\n        \"\"\"\n        yesterday_of_start = (pd.to_datetime(start_date) - timedelta(days=1)).strftime(self.date_format)\n        # Last phase registered\n        phase_dict = self.phase_dict.copy()\n        phase_dict.update(self.future_phase_dict)\n        last_phase = list(phase_dict.items())[-1][0]\n        # Set the end date of the last phase\n        if self.future_phase_dict:\n            self.future_phase_dict[last_phase][\"end_date\"] = yesterday_of_start\n        else:\n            self.phase_dict[last_phase][\"end_date\"] = yesterday_of_start\n        # Set the new phase\n        try:\n            param_dict = self.estimator_dict[last_phase].info()[2]\n            population = self.phase_dict[last_phase][\"population\"]\n        except KeyError:\n            param_dict = self.future_param_dict[last_phase].copy()\n            population = self.future_phase_dict[last_phase][\"population\"]\n        param_dict.update(**kwargs)\n        new_phase = self._num2str(len(phase_dict) + 1)\n        self.future_param_dict[new_phase] = param_dict\n        self.future_phase_dict[new_phase] = {\n            \"start_date\": start_date,\n            \"end_date\": None,\n            \"population\": population\n        }\n        if not vline:\n            self.phases_without_vline.append(new_phase)\n        return pd.DataFrame.from_dict(self.future_param_dict, orient=\"index\")\n\n    def add_future_param_gradually(self, start_date, end_date, param, first, last):\n        \"\"\"\n        Set the future parameters. The value will be gradually (log-scale) changed.\n        @start_date <str>: the start date of change\n        @end_date <str>: the end date of change\n        @param <str>: parameter name\n        @first <float>: parameter value of the start date\n        @last <float>: parameter value of the end date\n        \"\"\"\n        dates = pd.date_range(start=start_date, end=end_date, freq=\"D\")\n        values = np.logspace(\n            start=np.log10(first), stop=np.log10(last), num=len(dates), base=10.0\n        )\n        for (d, v) in zip(dates, values):\n            vline = True if d in dates[-2:] else False\n            self.add_future_param(d.strftime(self.date_format), vline=vline, **{param: v})\n        return pd.DataFrame.from_dict(self.future_param_dict, orient=\"index\")\n\n    def predict(self, days=1000, min_infected=1, show_figure=True):\n        \"\"\"\n        Predict the future.\n        @days <int or None>: how many days to predict from the last records date\n        @min_infected <int>: if Infected < min_infected, the records will not be used\n        @show_figure <bool>: if True, show line plot of cases over time\n        \"\"\"\n        if not isinstance(days, int):\n            raise TypeError(\"days must be integer!\")\n        # Create parameter dictionary\n        predict_param_dict = {\n            phase: self.estimator_dict[phase].info()[2]\n            for (phase, _) in self.phase_dict.items()\n        }\n        predict_param_dict.update(self.future_param_dict)\n        # Define phases\n        model, info_dict, _ = self.estimator_dict[\"1st\"].info()\n        predicter = Predicter(**info_dict)\n        phase_dict = self.phase_dict.copy()\n        phase_dict.update(self.future_phase_dict)\n        # Simulation with Predicter\n        for (phase, date_dict) in phase_dict.items():\n            start = pd.to_datetime(date_dict[\"start_date\"])\n            end = pd.to_datetime(date_dict[\"end_date\"])\n            if end is None:\n                day_n = days\n            elif start == end:\n                day_n = 0\n            else:\n                day_n = int((end - start).total_seconds() / 60 / 60 / 24) + 1\n            param_dict = predict_param_dict[phase].copy()\n            vline = False if phase in self.phases_without_vline else True\n            predicter.add(model, end_day_n=day_n, count_from_last=True, vline=vline, **param_dict)\n        # Restore\n        df = predicter.restore_df(min_infected=min_infected)\n        try:\n            df[\"Confirmed\"] = df[\"Infected\"] + df[\"Recovered\"] + df[\"Fatal\"]\n        except KeyError:\n            pass\n        # Graph: If max(other variables) < min(Susceptible), not show Susceptible\n        if show_figure:\n            without_s = df.drop(\"Susceptible\", axis=1).sum(axis=1).max()\n            drop_cols = [\"Susceptible\"] if without_s < df[\"Susceptible\"].min() else None\n            predicter.restore_graph(drop_cols=drop_cols, min_infected=min_infected, y_integer=True)\n        return df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"980b4b4e-b055-4c2a-b06f-823e90a42421","_cell_guid":"6347198d-b95f-495b-9d50-f55e917c77e9","trusted":true},"cell_type":"markdown","source":"## Raw data: the number of cases"},{"metadata":{"_uuid":"bc109822-1f6c-48ac-baaa-13698ef4155e","_cell_guid":"b0ede625-76d1-4c24-b85d-6b949c4c98f1","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"raw = pd.read_csv(\"/kaggle/input/novel-corona-virus-2019-dataset/covid_19_data.csv\")\nraw.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73225ddf-46f9-4d8b-bee9-4a5652ecc9fd","_cell_guid":"cde46880-86b1-4177-9c1a-dc3b34e51935","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"raw.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"958fa8de-84d8-4b89-aa22-4a14838ee235","_cell_guid":"fb0a8feb-e0f1-49a3-bc6e-902305e0e4b3","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"raw.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef52159f-5ad3-4258-ab84-d37a194bbb27","_cell_guid":"4f00def7-9acd-49a8-ae1f-a005873d49ae","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"pd.DataFrame(raw.isnull().sum()).T","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f95e36db-f400-4b53-86ec-e15e19d4559e","_cell_guid":"550da578-5c47-45d5-bdf2-80187a491fd0","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"\", \".join(raw[\"Country/Region\"].unique().tolist())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"962463b8-db0f-4f2d-b7cd-ea3ccbce8fb7","_cell_guid":"6b5046c3-897d-438e-b483-ae940da47e72","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"pprint(raw.loc[raw[\"Country/Region\"] == \"Others\", \"Province/State\"].unique().tolist(), compact=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b860d14-e603-420a-a655-de2cae2a082e","_cell_guid":"bafa861d-2610-44dd-bd21-2996ccea0d58","trusted":true},"cell_type":"markdown","source":"## Data Cleening: the number of cases\nNote: \"Infected\" = \"Confirmed\" - \"Deaths\" - \"Recovered\""},{"metadata":{"_uuid":"41f0be0f-f8dc-42f7-8773-65dc60f893e5","_cell_guid":"605752b1-4a5c-421c-82a7-d8ae766d893f","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data_cols = [\"Infected\", \"Deaths\", \"Recovered\"]\ndata_cols_all = [\"Confirmed\", \"Infected\", \"Deaths\", \"Recovered\"]\nrate_cols = [\"Fatal per Confirmed\", \"Recovered per Confirmed\", \"Fatal per (Fatal or Recovered)\"]\nvariable_dict = {\"Susceptible\": \"S\", \"Infected\": \"I\", \"Recovered\": \"R\", \"Deaths\": \"D\"}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2988a829-895b-401a-82ae-97d8026b271e","_cell_guid":"d6846623-7a01-4c27-8efc-61ce58d2553c","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df = raw.rename({\"ObservationDate\": \"Date\", \"Province/State\": \"Province\"}, axis=1)\ndf[\"Date\"] = pd.to_datetime(df[\"Date\"])\ndf[\"Country\"] = df[\"Country/Region\"].replace(\n    {\n        \"Mainland China\": \"China\",\n        \"Hong Kong SAR\": \"Hong Kong\",\n        \"Taipei and environs\": \"Taiwan\",\n        \"Iran (Islamic Republic of)\": \"Iran\",\n        \"Republic of Korea\": \"South Korea\",\n        \"Republic of Ireland\": \"Ireland\",\n        \"Macao SAR\": \"Macau\",\n        \"Russian Federation\": \"Russia\",\n        \"Republic of Moldova\": \"Moldova\",\n        \"Taiwan*\": \"Taiwan\",\n        \"Cruise Ship\": \"Others\",\n        \"United Kingdom\": \"UK\",\n        \"Viet Nam\": \"Vietnam\",\n        \"Czechia\": \"Czech Republic\",\n        \"St. Martin\": \"Saint Martin\",\n        \"Cote d'Ivoire\": \"Ivory Coast\",\n        \"('St. Martin',)\": \"Saint Martin\",\n        \"Congo (Kinshasa)\": \"Congo\",\n    }\n)\ndf[\"Province\"] = df[\"Province\"].fillna(\"-\").replace(\n    {\n        \"Cruise Ship\": \"Diamond Princess\",\n        \"Diamond Princess cruise ship\": \"Diamond Princess\"\n    }\n)\ndf.loc[df[\"Country\"] == \"Diamond Princess\", [\"Country\", \"Province\"]] = [\"Others\", \"Diamond Princess\"]\ndf[\"Infected\"] = df[\"Confirmed\"] - df[\"Deaths\"] - df[\"Recovered\"]\ndf[data_cols_all] = df[data_cols_all].astype(np.int64)\nncov_df_ungrouped = df.loc[:, [\"Date\", \"Country\", \"Province\", *data_cols_all]]\nncov_df_ungrouped.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10e610b6-923a-40b3-955f-e9e5b5bc33a6","_cell_guid":"74d4ce99-e727-4183-b946-88b89a535356","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"ncov_df_ungrouped.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de5f92d7-6dbb-4fe6-bdec-1f9a724b77a6","_cell_guid":"efb366ae-124b-467d-90ed-60a8280391c5","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"ncov_df_ungrouped.describe(include=\"all\").fillna(\"-\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"faa20bbf-b953-4cb7-af45-beab12cf7c0a","_cell_guid":"58b41156-5c89-47a7-a0dc-ceedc742a9c7","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"pd.DataFrame(ncov_df_ungrouped.isnull().sum()).T","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"513c542b-99ec-4a83-b073-7c70cda0340b","_cell_guid":"e36b6608-3109-4811-ae88-c22d1b47d1a9","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"\", \".join(ncov_df_ungrouped[\"Country\"].unique().tolist())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f8a797b1-fee9-4fd1-8859-9a74cd992bbe","_cell_guid":"8e4e6d71-d916-4a64-95a9-69d4fe2eb02c","trusted":true},"cell_type":"markdown","source":"## Visualize total data"},{"metadata":{"_uuid":"44072383-352b-4501-b174-f0ebfef3f95a","_cell_guid":"73d5e052-ebff-4f90-88fb-709637cfb2c4","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"total_df = ncov_df_ungrouped.groupby(\"Date\").sum()\ntotal_df[rate_cols[0]] = total_df[\"Deaths\"] / total_df[data_cols].sum(axis=1)\ntotal_df[rate_cols[1]] = total_df[\"Recovered\"] / total_df[data_cols].sum(axis=1)\ntotal_df[rate_cols[2]] = total_df[\"Deaths\"] / (total_df[\"Deaths\"] + total_df[\"Recovered\"])\ntotal_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9c5d84b3-2cd6-42c3-a740-cd84d2c0a52c","_cell_guid":"9fd5240a-1d2b-48ba-8e3d-5e6723af0e8f","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"f\"{(total_df.index.max() - total_df.index.min()).days} days have passed from the date of the first record.\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12f82256-a349-49b8-9e17-5ac5bd74f5ae","_cell_guid":"2256ddcb-f67f-4c0a-ba93-6768433fc144","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"line_plot(total_df[data_cols], \"Total number of cases over time\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cace33e4-be48-438a-93ca-d2635ea23189","_cell_guid":"acd0eff2-af43-4859-bb62-af9c7ca10809","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"line_plot(total_df[rate_cols], \"Global rate over time\", ylabel=\"\", math_scale=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79935285-74b5-49f7-a46d-bc191a9d38f2","_cell_guid":"a2318e23-9cf4-495b-8bbf-bcf893898e77","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"total_df[rate_cols].plot.kde()\nplt.title(\"Kernel density estimation of the rates\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"37364cc6-0190-49f7-a554-92b67db8d100","_cell_guid":"bd16187a-99ec-4ec8-8aaf-016fd2b53fd8","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"total_df[rate_cols].describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data cleaning: Linelist (COVID19_open_line_list.csv)"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"linelist_open_raw = pd.read_csv(\"/kaggle/input/novel-corona-virus-2019-dataset/COVID19_open_line_list.csv\")\nlinelist_open_raw.info()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df = linelist_open_raw.loc[:, ~linelist_open_raw.columns.str.startswith(\"Unnamed:\")]\ndf = df.dropna(axis=0, how=\"all\")\ndf = df.drop(\n    [\n        # Unnecessary in this notebook\n        \"ID\", \"wuhan(0)_not_wuhan(1)\", \"admin3\", \"admin2\", \"admin1\", \"country_new\", \"admin_id\",\n        \"data_moderator_initials\", \"source\", \"location\", \"lives_in_Wuhan\", \"notes_for_discussion\",\n        \"sequence_available\", \"reported_market_exposure\",\n        # Maybe useful, but un-used\n        \"city\", \"latitude\", \"longitude\", \"geo_resolution\", \"additional_information\",\n        \"travel_history_dates\", \"travel_history_location\", \n    ],\n    axis=1\n)\n# Personal\nage = linelist_open_raw[\"age\"].str.split(\"-\", expand=True)\nage[0] = pd.to_numeric(age[0], errors=\"coerce\")\nage[1] = pd.to_numeric(age[1], errors=\"coerce\")\ndf[\"Age\"] = age.mean(axis=1)\ndf[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].median()).astype(np.int64)\ndf[\"Sex\"] = df[\"sex\"].fillna(\"-\").str.replace(\"4000\", \"-\").str.capitalize()\n# Place\ndf[\"Country\"] = df[\"country\"].fillna(\"-\")\ndf[\"Province\"] = df[\"province\"].fillna(\"-\")\n# Onset Date\nseries = df[\"date_onset_symptoms\"].str.replace(\"end of December 2019\", \"31.12.2019\").replace(\"-25.02.2020\", \"25.02.2020\")\nseries = series.replace(\"20.02.220\", \"20.02.2020\").replace(\"none\", np.NaN).replace(\"10.01.2020 - 22.01.2020\", np.NaN)\ndf[\"Onset_date\"] = pd.to_datetime(series)\n# Hospitalized date\nseries = df[\"date_admission_hospital\"].replace(\"18.01.2020 - 23.01.2020\", np.NaN)\ndf[\"Hospitalized_date\"] = pd.to_datetime(series)\n# Confirmed date\nseries = df[\"date_confirmation\"].replace(\"25.02.2020-26.02.2020\", np.NaN)\ndf[\"Confirmed_date\"] = pd.to_datetime(series)\n# Symptoms/events\ndf[\"Symptoms\"] = df[\"symptoms\"].fillna(\"-\").str.lower()\n# Underlying disease\ndf[\"Underlying_disease\"] = df[[\"chronic_disease_binary\", \"chronic_disease\"]].apply(\n    lambda x: \"No\" if x[0] == 0 else x[1] if x[1] is not np.NaN else \"-\",\n    axis=1\n).str.strip(\";\").str.replace(\"; \", \",\").str.replace(\", \", \",\")\n# Outcome\ndf[\"Outcome\"] = df[\"outcome\"].replace(\n    {\n        \"discharge\": \"discharged\", \"Discharged\": \"discharged\", \"death\": \"died\",\n        \"critical condition, intubated as of 14.02.2020\": \"severe\",\n        \"treated in an intensive care unit (14.02.2020)\": \"severe\", \"05.02.2020\": \"-\",\n        \"Symptoms only improved with cough. Currently hospitalized for follow-up.\": \"stable\"\n    }\n).fillna(\"-\")\nseries = df[\"date_death_or_discharge\"].replace(\"discharge\", np.NaN)\ndf[\"Closed_date\"] = pd.to_datetime(series)\n# Show\nuse_cols = [\n    \"Age\", \"Sex\", \"Country\", \"Province\", \"Onset_date\", \"Hospitalized_date\", \"Confirmed_date\", \n    \"Symptoms\", \"Underlying_disease\", \"Outcome\", \"Closed_date\"\n]\nopen_linelist_df = df.loc[:, use_cols]\nopen_linelist_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data cleaning: Linelist (COVID19_line_list_data.csv)\nLinelist in clinical trials is a list of many case reports.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"linelist_raw = pd.read_csv(\"/kaggle/input/novel-corona-virus-2019-dataset/COVID19_line_list_data.csv\")\nlinelist_raw.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linelist_raw.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = linelist_raw.loc[:, ~linelist_raw.columns.str.startswith(\"Unnamed:\")]\ndf = df.drop([\"id\", \"case_in_country\", \"summary\", \"source\", \"link\"], axis=1)\n# Date\ncase_date_dict = {\n    \"reporting date\": \"Confirmed_date\",\n    \"exposure_start\": \"Exposed_date\",\n    \"exposure_end\": \"Quarantined_date\",\n    \"hosp_visit_date\": \"Hospitalized_date\",\n    \"symptom_onset\": \"Onset_date\",\n    \"death\": \"Deaths_date\",\n    \"recovered\": \"Recovered_date\"    \n}\ndf[\"death\"] = df[\"death\"].replace({\"0\": \"\", \"1\": \"\"})\ndf[\"recovered\"] = df[\"recovered\"].replace({\"0\": \"\", \"1\": \"\", \"12/30/1899\": \"12/30/2019\"})\nfor (col, _) in case_date_dict.items():\n    df[col] = pd.to_datetime(df[col])\ndf = df.rename(case_date_dict, axis=1)\n# Location\ndf[\"Country\"] = df[\"country\"].fillna(\"-\")\ndf[\"Province\"] = df[\"location\"].fillna(\"-\")\ndf[\"Province\"] = df[[\"Country\", \"Province\"]].apply(lambda x: \"-\" if x[0] == x[1] else x[1], axis=1)\n# Personal\ndf[\"Gender\"] = df[\"gender\"].fillna(\"-\").str.capitalize()\ndf[\"Age\"] = df[\"age\"].fillna(df[\"age\"].median()).astype(np.int64) ## Fill in NA with median\ndf[\"From_Wuhan\"] = df[\"from Wuhan\"]\ndf[\"To_Wuhan\"] = df[\"visiting Wuhan\"]\n# Medical\ndf[\"Events\"] = df[\"symptom\"].fillna(\"-\")\n# Order of columns\nlinelist_df = df.loc[\n    :,\n    [\n        \"Country\", \"Province\",\n        \"Exposed_date\", \"Onset_date\", \"Hospitalized_date\", \"Confirmed_date\", \"Quarantined_date\", \"Deaths_date\", \"Recovered_date\",\n        \"Events\",\n        \"Gender\", \"Age\", \"From_Wuhan\", \"To_Wuhan\"\n    ]\n]\nlinelist_df.tail()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linelist_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linelist_df.describe(include=\"all\").fillna(\"-\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"period_df = select_area(linelist_df, group=None)\nperiod_df = period_df.loc[:, [\"Exposed_date\", \"Onset_date\", \"Confirmed_date\"]]\nperiod_df[\"Latent [min]\"] = (period_df[\"Onset_date\"] - period_df[\"Exposed_date\"]).dt.total_seconds() / 60\nperiod_df[\"Waiting [min]\"] = (period_df[\"Confirmed_date\"] - period_df[\"Onset_date\"]).dt.total_seconds() / 60\nperiod_df[\"Latent [day]\"] = period_df[\"Latent [min]\"] / 60 / 24\nperiod_df[\"Waiting [day]\"] = period_df[\"Waiting [min]\"] / 60 / 24\nperiod_df[\"Latent + Waiting [day]\"] = period_df[\"Latent [day]\"] + period_df[\"Waiting [day]\"]\nperiod_df.dropna(axis=0).tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = [\"Latent [day]\", \"Waiting [day]\", \"Latent + Waiting [day]\"]\nperiod_df[cols].plot.kde()\nplt.title(\"Kernel density estimation of latent period and waiting time for confirmation [day]\")\nplt.show()\nperiod_df[cols].describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Grouping by growth factor\nThe number of confirmed cases is increasing in many countries, but there are two of countries. In a first-type country, growth factor is larger than 1 and the number of cases is rapidly increasing. In a second-type country, growth factor is less than 1."},{"metadata":{},"cell_type":"markdown","source":"## Calculate growth factor\nWhere $C$ is the number of confirmed cases,  \n$$\\mathrm{Growth\\ Factor} = \\cfrac{\\Delta \\mathrm{C}_{n}}{\\Delta \\mathrm{C}_{n-1}}$$"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df = ncov_df_ungrouped.pivot_table(\n    index=\"Date\", columns=\"Country\", values=\"Confirmed\", aggfunc=\"sum\"\n).fillna(method=\"ffill\").fillna(0)\n# Growth factor: (delta Number_n) / (delta Number_n)\ndf = df.diff() / df.diff().shift(freq=\"D\")\ndf = df.replace(np.inf, np.nan).fillna(1.0)\n# Rolling mean (window: 7 days)\ndf = df.rolling(7).mean()\ndf = df.iloc[6:-1, :]\n# round: 0.01\ngrowth_value_df = df.round(2)\ngrowth_value_df.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Grouping countires based on growth factor\n* Outbreaking: growth factor $>$ 1 for the last 7 days\n* Stopping: growth factor $<$ 1 for the last 7 days\n* At a crossroad: the others"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df = growth_value_df.copy()\ndf = df.iloc[-7:, :].T\nday_cols = df.columns.strftime(\"%d%b%Y\")\ndf.columns = day_cols\nlast_date = day_cols[-1]\n# Grouping\nmore_col, less_col = \"GF > 1 [straight days]\", \"GF < 1 [straight days]\"\ndf[more_col] = (growth_value_df > 1).iloc[::-1].cumprod().sum(axis=0)\ndf[less_col] = (growth_value_df < 1).iloc[::-1].cumprod().sum(axis=0)\ndf[\"Group\"] = df[[more_col, less_col]].apply(\n    lambda x: \"Outbreaking\" if x[0] >= 7 else \"Stopping\" if x[1] >= 7 else \"Crossroad\",\n    axis=1\n)\n# Sorting\ndf = df.loc[:, [\"Group\", more_col, less_col, *day_cols]]\ndf[\"rank1\"] = df[more_col] * df[last_date]\ndf[\"rank2\"] = df[less_col] * df[last_date]\ndf = df.sort_values([\"Group\", \"rank1\", \"rank2\"], ascending=False)\ndf = df.drop([\"rank1\", \"rank2\"], axis=1)\ngrowth_df = df.copy()\ngrowth_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.merge(ncov_df_ungrouped, growth_df[\"Group\"].reset_index(), on=\"Country\")\nncov_df = df.loc[:, [\"Date\", \"Group\", *ncov_df_ungrouped.columns[1:]]]\nncov_df.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Group 1: Outbreaking, growth factor $>$ 1 for the last 7 days"},{"metadata":{"trusted":true},"cell_type":"code","source":"pprint(growth_df.loc[growth_df[\"Group\"] == \"Outbreaking\", :].index.tolist(), compact=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"growth_df.loc[growth_df[\"Group\"] == \"Outbreaking\", :].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df = ncov_df.loc[ncov_df[\"Group\"] == \"Outbreaking\", [\"Date\", *data_cols]].groupby(\"Date\").sum()\nline_plot(df, \"Group 1 (Outbreaking): Cases over time\", y_integer=True)\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Group 2: Stopping, growth factor $<$ 1 for the last 7 days"},{"metadata":{"trusted":true},"cell_type":"code","source":"pprint(growth_df.loc[growth_df[\"Group\"] == \"Stopping\", :].index.tolist(), compact=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"growth_df.loc[growth_df[\"Group\"] == \"Stopping\", :].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df = ncov_df.loc[ncov_df[\"Group\"] == \"Stopping\", [\"Date\", *data_cols]].groupby(\"Date\").sum()\nline_plot(df, \"Group 2 (Stopping): Cases over time\", y_integer=True)\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Group 3: At a crossroad, the others"},{"metadata":{"trusted":true},"cell_type":"code","source":"pprint(growth_df.loc[growth_df[\"Group\"] == \"Crossroad\", :].index.tolist(), compact=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"growth_df.loc[growth_df[\"Group\"] == \"Crossroad\", :].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df = ncov_df.loc[ncov_df[\"Group\"] == \"Crossroad\", [\"Date\", *data_cols]].groupby(\"Date\").sum()\nline_plot(df, \"Group 3 (At a crossroad): Cases over time\", y_integer=True)\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Trend analysis\nUsing fbprophet package, we will find changing points of log10(comfirmed/deaths/recovered).  \nWe will use the data in the most cirical country where the number of days with growth factor $>$ 1 is the longest."},{"metadata":{},"cell_type":"markdown","source":"## Most critical country"},{"metadata":{"trusted":true},"cell_type":"code","source":"critical_country = growth_df.loc[growth_df[\"Group\"] == \"Outbreaking\", :].index[0]\ncritical_country","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"critical_df = ncov_df.loc[ncov_df[\"Country\"] == critical_country, [\"Date\", *data_cols]].groupby(\"Date\").sum()\ncritical_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"line_plot(critical_df, f\"{critical_country}: Cases over time\", y_integer=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Trend of log10(Confirmed)"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"show_trend(ncov_df, variable=\"Confirmed\", places=[(critical_country, None)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The slope was change at 09Mar2020.**\n<!--**No slope change points were found for the number of confirmed cases.**-->\n<!--**The incline of the number of confirmed cases slightly grow large on 01Mar2020. I will keep a watchful eye on the trend.**-->"},{"metadata":{},"cell_type":"markdown","source":"## Trend of log10(Deaths)"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"show_trend(ncov_df, variable=\"Deaths\", places=[(critical_country, None)], start_date=\"09Mar2020\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**No slope change points were found for the number of fatal cases from 09Mar2020.**\n<!--**Slope of the number of fatal cases was changed on 15Mar2020.**-->"},{"metadata":{},"cell_type":"markdown","source":"## Trend of log10(Recovered)"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"show_trend(ncov_df, variable=\"Recovered\", places=[(critical_country, None)], start_date=\"09Mar2020\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Slope change point was found on 18Mar2020.**\n<!--**No slope change points were found for the number of recovered cases from 09Mar2020.**<-->"},{"metadata":{},"cell_type":"markdown","source":"**Records after 18Mar2020 will be used for improvement of math model.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"critical_country_start = \"23Mar2020\"\ncritical_country = \"US\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SIR to SIR-F\nIn this section, we will create a mathematical model derived from SIR model."},{"metadata":{"_uuid":"df2ad5db-4dbb-4533-ba9e-d335befe57eb","_cell_guid":"cfcd204a-5677-479e-9362-94c15761a4ac","trusted":true},"cell_type":"markdown","source":"## Prediction with SIR model\nTo understand the trend of infection, we will use mathematical epidemic model. Let's start discussion using a basic model named SIR."},{"metadata":{"_uuid":"12135786-c9e9-49f9-a911-0bc18ee5f596","_cell_guid":"0f8c4e04-c768-4933-b547-92588965dbea","trusted":true},"cell_type":"markdown","source":"### What is SIR model?\nSIR model is a simple mathematical model to understand outbreak of infectious diseases.  \n[The SIR epidemic model - Learning Scientific Programming with Python](https://scipython.com/book/chapter-8-scipy/additional-examples/the-sir-epidemic-model/)\n\n * S: Susceptible (=All - Confirmed)\n * I: Infected (=Confirmed - Recovered - Deaths)\n * R: Recovered or fatal (=Recovered + Deaths)\n \nNote: THIS IS NOT THE GENERAL MODEL!  \nThough R in SIR model is \"Recovered and have immunity\", I defined \"R as Recovered or fatal\". This is because mortality rate cannot be ignored in the real COVID-19 data.\n\nModel:  \nS + I $\\overset{\\beta}{\\longrightarrow}$ 2I  \nI $\\overset{\\gamma}{\\longrightarrow}$ R\n\n$\\beta$: Effective contact rate [1/min]  \n$\\gamma$: Recovery(+Mortality) rate [1/min]  \n\nOrdinary Differential Equation (ODE):   \n$\\frac{\\mathrm{d}S}{\\mathrm{d}T}= - N^{-1}\\beta S I$  \n$\\frac{\\mathrm{d}I}{\\mathrm{d}T}= N^{-1}\\beta S I - \\gamma I$  \n$\\frac{\\mathrm{d}R}{\\mathrm{d}T}= \\gamma I$  \n\nWhere $N=S+I+R$ is the total population, $T$ is the elapsed time from the start date."},{"metadata":{"_uuid":"769f133b-0a3a-4779-a15b-f199a2a3a411","_cell_guid":"58bc8d44-4df3-49fb-85c0-d01a804accc1","trusted":true},"cell_type":"markdown","source":"### Non-dimensional SIR model\nTo simplify the model, we will remove the units of the variables from ODE.\n\nSet $(S, I, R) = N \\times (x, y, z)$ and $(T, \\beta, \\gamma) = (\\tau t, \\tau^{-1} \\rho, \\tau^{-1} \\sigma)$.  \n\nThis results in the ODE  \n$\\frac{\\mathrm{d}x}{\\mathrm{d}t}= - \\rho x y$  \n$\\frac{\\mathrm{d}y}{\\mathrm{d}t}= \\rho x y - \\sigma y$  \n$\\frac{\\mathrm{d}z}{\\mathrm{d}t}= \\sigma y$  \n\nWhere $N$ is the total population and $\\tau$ is a coefficient ([min], is an integer to simplify).  \n\nThe range of variables and parameters:  \n$0 < (x, y, z, \\rho, \\sigma) < 1$  \n$1\\leq \\tau \\leq 1440$  \n\nBasic reproduction number, Non-dimentional parameter, is defined as  \n$R_0 = \\rho \\sigma^{-1} = \\beta \\gamma^{-1}$  \n\nEstimated Mean Values of $R_0$:  \n$R_0$ means \"the average number of secondary infections caused by an infected host\" ([Infection Modeling — Part 1](https://towardsdatascience.com/infection-modeling-part-1-87e74645568a)).  \n(Secondary data: [Van den Driessche, P., & Watmough, J. (2002).](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6002118))  \n2.06: Zika in South America, 2015-2016  \n1.51: Ebola in Guinea, 2014  \n1.33: H1N1 influenza in South Africa, 2009  \n3.5 : SARS in 2002-2003  \n1.68: H2N2 influenza in US, 1957  \n3.8 : Fall wave of 1918 Spanish influenza in Genova  \n1.5 : Spring wave of 1918 Spanish influenza in Genova  \n\nWhen $x=\\frac{1}{R_0}$, $\\frac{\\mathrm{d}y}{\\mathrm{d}t}=0$. This means that the max value of confirmed ($=y+z$) is $1-\\frac{1}{R_0}$."},{"metadata":{"_uuid":"5944df9d-9a62-47a4-b5ad-78934aead04b","_cell_guid":"b52b5d34-5e57-4107-987e-625f818de903","trusted":true},"cell_type":"code","source":"train_dataset = SIR.create_dataset(\n    ncov_df, population_dict[critical_country], excluded_places=[(critical_country, None)],\n    start_date=critical_country_start\n)\ntrain_start_date, train_initials, train_Tend, train_df = train_dataset\npprint([train_start_date.strftime(\"%d%b%Y\"), train_initials, train_Tend])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c18c2dd7-b7a7-46ad-b5e7-bc23988843e1","_cell_guid":"1bf56cbc-5386-4e51-a3e2-2d1d3885eb0f","trusted":true},"cell_type":"code","source":"train_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"548ebcec-8e51-454c-90c7-a4872487bdbc","_cell_guid":"1a6dd31a-d462-47cf-a177-fd742f53d93e","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"line_plot(\n    train_df.set_index(\"T\").drop(\"x\", axis=1),\n    \"Training data: y(T), z(T)\", math_scale=False, ylabel=\"\"\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9c541959-9c0e-4c02-9e70-389226457469","_cell_guid":"e3c1fb34-fe2d-4a34-9e60-ec7f45df8970","trusted":true},"cell_type":"markdown","source":"**Note: We cannot convert $T$ to $t$ because $\\tau$ has not been determined yet.**"},{"metadata":{"_uuid":"e64fc4d7-785a-46e5-95e4-c0d98ab7406a","_cell_guid":"ed7f7e66-b59e-48ec-a72b-a709c3ac9ba8","trusted":true},"cell_type":"markdown","source":"### Example of non-dimensional SIR model\nFor example, set $R_0 = 2.5, \\rho=0.2$."},{"metadata":{"_uuid":"dc79d91a-c375-425a-abdf-f076b9a9e85f","_cell_guid":"9b9b266d-cbbf-40e7-a3a4-6dacc93a4d15","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"eg_r0, eg_rho = (2.5, 0.2)\neg_sigma = eg_rho / eg_r0\n(eg_rho, eg_sigma)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"121b3dd1-c224-4326-bede-80b33cebd9d1","_cell_guid":"ee3ee9aa-4f12-4da7-b020-c2b957dfeee9","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"%%time\neg_df = simulation(SIR, train_initials, step_n=200, rho=eg_rho, sigma=eg_sigma)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"eg_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f122114e-f47d-4333-9ffd-6a4a688583fe","_cell_guid":"b5412f17-29a7-43a2-ac5b-e013db3047cf","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"line_plot(\n    eg_df.set_index(\"t\"),\n    title=r\"SIR: $R_0$={0} ($\\rho$={1}, $\\sigma$={2})\".format(eg_r0, eg_rho, eg_sigma),\n    ylabel=\"\",\n    h=1\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c8b29187-d69a-4ca8-b85f-40e9403cbcad","_cell_guid":"57f7a183-3f1e-408a-b080-5913bdcb5d29","trusted":true},"cell_type":"markdown","source":"### Test of hyperparameter optimization using example data\nTo test the hyperparameter optimization functions defeined in this notebook, we will estimate the SIR model parameters using the example data and example $\\tau=1440$ [min] and total population 1,000,000."},{"metadata":{"_uuid":"0b4e853a-35fc-42e5-a8d4-2ad05cc85278","_cell_guid":"2e03f933-96e9-4507-ba3d-8719278eb04e","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# Set the example conditions\neg_tau = 1440\neg_start_date = ncov_df[\"Date\"].min()\neg_total_population = 1000000\n# Create dataset in the format of ncov_df\neg_ori_df = pd.DataFrame(\n    {\n        \"Date\": (eg_df[\"t\"] * eg_tau).apply(lambda x: timedelta(minutes=x)) + eg_start_date,\n        \"Country\": \"Example\",\n        \"Province\": \"Example\"\n    }\n)\neg_ori_df[\"Infected\"] = (eg_df[\"y\"] * eg_total_population).astype(np.int64)\neg_ori_df[\"Deaths\"] = (eg_df[\"z\"] * eg_total_population * 0.02).astype(np.int64)\neg_ori_df[\"Recovered\"] = (eg_df[\"z\"] * eg_total_population * 0.98).astype(np.int64)\neg_ori_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb75b073-f877-478f-b882-23656efaeedd","_cell_guid":"4fa0ca3e-1826-4b5f-9dc9-a115904662a4","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# line_plot(eg_ori_df.set_index(\"Date\")[data_cols], \"Example data\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f7d9ae2b-fc89-45c6-aa8c-7343e6f7cbcb","_cell_guid":"3491e47b-9205-4c4f-9bf4-37fb1c181fb4","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# %%time\n# eg_sir_estimator = Estimator(SIR, eg_ori_df, eg_total_population, places=[(\"Example\", \"Example\")])\n# eg_sir_dict = eg_sir_estimator.run()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7299c718-bd29-4315-a4c7-40123130c6ad","_cell_guid":"9637dfc3-c893-42a4-970f-8dd00a45a479","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# eg_sir_estimator.compare_graph()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2319409-ff8c-41e3-a6e9-381dc88e4b6d","_cell_guid":"334627c9-18e5-420a-8b5f-07907a7336a9","trusted":true,"_kg_hide-output":false,"_kg_hide-input":true},"cell_type":"code","source":"\"\"\"\neg_dict = {\n    \"Condition\": {\n        \"tau\": eg_tau, \"rho\": eg_rho, \"sigma\": eg_sigma,\n        \"R0\": eg_r0, \"score\": 0, **SIR(rho=eg_rho, sigma=eg_sigma).calc_days_dict(eg_tau)\n    },\n    \"Estimation\": eg_sir_dict\n}\ndf = pd.DataFrame.from_dict(eg_dict, orient=\"index\")\ndf\n\"\"\"\nNone","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"abc5f4a0-5674-4678-938b-79db83e4f4f5","_cell_guid":"6ad03ba6-eaba-41ea-b816-17962a58bd54","trusted":true},"cell_type":"markdown","source":"## Prediction with SIR-D model\nBecause we can measure the number of fatal cases and recovered cases separately, we can use two variables (\"Recovered\" and \"Deaths\") instead of \"Recovered + Deaths\" in the mathematical model."},{"metadata":{"_uuid":"ac79b973-cdd3-4beb-825d-c29f987f6cd1","_cell_guid":"54813702-3d5a-4aeb-89dc-b7b5014fb9fb","trusted":true},"cell_type":"markdown","source":"### What is SIR-D model?\n* S: Susceptible\n* I: Infected\n* R: Recovered\n* D: Fatal\n\nModel:  \nS + I $\\overset{\\beta}{\\longrightarrow}$ 2I  \nI $\\overset{\\gamma}{\\longrightarrow}$ R  \nI $\\overset{\\alpha}{\\longrightarrow}$ D  \n\n$\\alpha$: Mortality rate [1/min]  \n$\\beta$: Effective contact rate [1/min]  \n$\\gamma$: Recovery rate [1/min]  \n\nOrdinary Differential Equation (ODE):   \n$\\frac{\\mathrm{d}S}{\\mathrm{d}T}= - N^{-1}\\beta S I$  \n$\\frac{\\mathrm{d}I}{\\mathrm{d}T}= N^{-1}\\beta S I - (\\gamma + \\alpha) I$  \n$\\frac{\\mathrm{d}R}{\\mathrm{d}T}= \\gamma I$  \n$\\frac{\\mathrm{d}D}{\\mathrm{d}T}= \\alpha I$  \n\nWhere $N=S+I+R+D$ is the total population, $T$ is the elapsed time from the start date."},{"metadata":{"_uuid":"20008d93-6fef-4053-af91-aef177eed421","_cell_guid":"b3cbf5d5-c269-4695-8835-46ed417d9c48","trusted":true},"cell_type":"markdown","source":"### Non-dimensional SIR-D model\nSet $(S, I, R, D) = N \\times (x, y, z, w)$ and $(T, \\alpha, \\beta, \\gamma) = (\\tau t, \\tau^{-1} \\kappa, \\tau^{-1} \\rho, \\tau^{-1} \\sigma)$.  \nThis results in the ODE  \n$\\frac{\\mathrm{d}x}{\\mathrm{d}t}= - \\rho x y$  \n$\\frac{\\mathrm{d}y}{\\mathrm{d}t}= \\rho x y - (\\sigma + \\kappa) y$  \n$\\frac{\\mathrm{d}z}{\\mathrm{d}t}= \\sigma y$  \n$\\frac{\\mathrm{d}w}{\\mathrm{d}t}= \\kappa y$  \n\nWhere $N$ is the total population and $\\tau$ is a coefficient ([min], is an integer to simplify).  \n\nThe range of variables and parameters:  \n$0 < (x, y, z, w, \\kappa, \\rho, \\sigma) < 1$  \n$1\\leq \\tau \\leq 1440$\n\nReproduction number can be defined as  \n$R_0 = \\rho (\\sigma + \\kappa)^{-1} = \\beta (\\gamma + \\alpha)^{-1}$"},{"metadata":{"_uuid":"b17a61ed-d8da-43ba-b028-1949760dc0ca","_cell_guid":"c19b122a-84fb-4757-834e-bb72002cdfb3","trusted":true},"cell_type":"markdown","source":"## Prediction with SIR-F model\nSome cases are reported as fatal cases before clinical diagnosis of COVID-19. To consider this issue, \"S + I $\\to$ Fatal + I\" will be added to the model."},{"metadata":{"_uuid":"3f40d0e2-7fb1-4082-8308-e27d37efc943","_cell_guid":"0a2eafd9-5355-4953-af46-025e6554fa59","trusted":true},"cell_type":"markdown","source":"### What is SIR-F model?\n* S: Susceptible\n* S$^\\ast$: Confirmed and un-categorized\n* I: Confirmed and categorized as I\n* R: Recovered\n* F: Fatal with confirmation\n\nMeasurable variables:  \nConfirmed = $I+R+F$  \nRecovered = $R$  \nDeaths = $F$  \n\nModel:  \nS $\\overset{\\beta \\mathrm{I}}{\\longrightarrow}$ S$^\\ast$ $\\overset{\\alpha_1}{\\longrightarrow}$ F  \nS $\\overset{\\beta \\mathrm{I}}{\\longrightarrow}$ S$^\\ast$ $\\overset{1 - \\alpha_1}{\\longrightarrow}$ I  \nI $\\overset{\\gamma}{\\longrightarrow}$ R  \nI $\\overset{\\alpha_2}{\\longrightarrow}$ F  \n\n$\\alpha_1$: Mortality rate of S$^\\ast$ cases [-]  \n$\\alpha_2$: Mortality rate of I cases [1/min]  \n$\\beta$: Effective contact rate [1/min]  \n$\\gamma$: Recovery rate [1/min]  \n\nOrdinary Differential Equation (ODE):   \n$\\frac{\\mathrm{d}S}{\\mathrm{d}T}= - N^{-1}\\beta S I$  \n$\\frac{\\mathrm{d}I}{\\mathrm{d}T}= N^{-1}(1 - \\alpha_1) \\beta S I - (\\gamma + \\alpha_2) I$  \n$\\frac{\\mathrm{d}R}{\\mathrm{d}T}= \\gamma I$  \n$\\frac{\\mathrm{d}F}{\\mathrm{d}T}= N^{-1}\\alpha_1 \\beta S I + \\alpha_2 I$  \n\nWhere $N=S+I+R+F$ is the total population, $T$ is the elapsed time from the start date."},{"metadata":{"_uuid":"1a5a19e0-d71a-409b-902e-707d2afe8249","_cell_guid":"fa88a43d-671a-4109-8d60-8b2cacebed68","trusted":true},"cell_type":"markdown","source":"### Non-dimensional SIR-F model\nSet $(S, I, R, F) = N \\times (x, y, z, w)$ and $(T, \\alpha_1, \\alpha_2, \\beta, \\gamma) = (\\tau t, \\theta, \\tau^{-1} \\kappa, \\tau^{-1} \\rho, \\tau^{-1} \\sigma)$.  \nThis results in the ODE  \n$\\frac{\\mathrm{d}x}{\\mathrm{d}t}= - \\rho x y$  \n$\\frac{\\mathrm{d}y}{\\mathrm{d}t}= \\rho (1-\\theta) x y - (\\sigma + \\kappa) y$  \n$\\frac{\\mathrm{d}z}{\\mathrm{d}t}= \\sigma y$  \n$\\frac{\\mathrm{d}w}{\\mathrm{d}t}= \\rho \\theta x y + \\kappa y$  \n\nWhere $N$ is the total population and $\\tau$ is a coefficient ([min], is an integer to simplify).  \n\nThe range of variables and parameters:  \n$0 < (x, y, z, w, \\theta, \\kappa, \\rho, \\sigma) < 1$  \n$1 \\leq \\tau \\leq 1440$  \n\nReproduction number can be defined as  \n$R_0 = \\rho (1 - \\theta) (\\sigma + \\kappa)^{-1} = \\beta (1 - \\alpha_1) (\\gamma + \\alpha_2)^{-1}$"},{"metadata":{"_uuid":"3312c5a7-3ce0-41f1-bc8b-67da61091c70","_cell_guid":"9ad0cd56-fc56-495c-8e4e-698931fd756f","trusted":true},"cell_type":"markdown","source":"### Hyperparameter optimization\nUsing Optuna package, ($\\theta, \\kappa, \\rho, \\sigma, \\tau$) will be estimated by model fitting."},{"metadata":{"_uuid":"177c29e4-93fa-4fae-864a-77a952f818ad","_cell_guid":"9e90ff6d-2612-4fa1-bc3d-0dae73843f44","trusted":true},"cell_type":"code","source":"%%time\nsirf_estimator = Estimator(\n    SIRF, ncov_df, population_dict[critical_country],\n    name=critical_country, places=[(critical_country, None)],\n    start_date=critical_country_start\n)\nsirf_dict = sirf_estimator.run(300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"sirf_estimator.history_df().head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b11aeb29-afd0-4378-8574-d5124b821ea0","_cell_guid":"75abc8cf-b898-4d9f-b30c-e8e403626447","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"sirf_estimator.history_graph()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"375cb268-d100-4c5b-8f7a-fa3aeb9f319e","_cell_guid":"13b5989d-1ea6-4dae-812e-e5b0ce735c5f","trusted":true},"cell_type":"code","source":"pd.DataFrame.from_dict({\"SIR-F\": sirf_dict}, orient=\"index\").fillna(\"-\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a15a081-716a-4638-907a-60330536b1ef","_cell_guid":"eb91e6c8-7df1-4c50-8765-05f5375f4099","trusted":true},"cell_type":"code","source":"sirf_estimator.compare_graph()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"82cac758-9303-43f5-bd76-5113010cbd12","_cell_guid":"1de174a0-fbaf-4951-bd78-d7071b5ceda4","trusted":true},"cell_type":"code","source":"sirf_estimator.predict_graph(step_n=600)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df = sirf_estimator.predict_df(300)\ndf.loc[datetime.today():, [\"Infected\", \"Recovered\", \"Fatal\"]].head(14).style.background_gradient(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SIR-F with exposed/waiting cases\nThe number of exposed cases in latent period (E) and wating cases for confirmation (W) are un-measurable variables, but key variables as well as S, I, R, F. If E and W are large, outbreak will occur in the near future. Let's replace S $\\overset{\\beta \\mathrm{I}}{\\longrightarrow}$ S$^\\ast$ with S $\\overset{\\beta_1 \\mathrm{(W+I)}}{\\longrightarrow}$ E $\\overset{\\beta_2}{\\longrightarrow}$ W $\\overset{\\beta_3}{\\longrightarrow}$ S$^\\ast$ because W also has infectivity.\n\nNote:  \nW and some rules were added to explain COVID-19 dataset, but this is like-SEIR model.  \nTo study general SEIR-model, please refer to PDF material in [Introduction to SEIR model Models](http://indico.ictp.it/event/7960/session/3/contribution/19/material/slides/)."},{"metadata":{},"cell_type":"markdown","source":"## What is SEWIR-F model?\n* S: Susceptible\n* <u>E: Exposed and in latent period (without infectivity)</u>\n* <u>W: Waiting cases for confirmation (with infectivity)</u>\n* S$^\\ast$: Confirmed and un-categorized\n* I: Confirmed and categorized as I\n* R: Recovered\n* F: Fatal with confirmation\n\nMeasurable variables:  \nTotal population - Confirmed = $S+E+W+S^\\ast$  \nConfirmed = $I+R+F$  \nRecovered = $R$  \nDeaths = $F$  \n\nModel:  \nS $\\overset{\\beta_1 \\mathrm{(W+I)}}{\\longrightarrow}$ E $\\overset{\\beta_2}{\\longrightarrow}$ W $\\overset{\\beta_3}{\\longrightarrow}$ S$^\\ast$ $\\overset{\\alpha_1}{\\longrightarrow}$ F  \nS $\\overset{\\beta_1 \\mathrm{(W+I)}}{\\longrightarrow}$ E $\\overset{\\beta_2}{\\longrightarrow}$ W $\\overset{\\beta_3}{\\longrightarrow}$ S$^\\ast$ $\\overset{1 - \\alpha_1}{\\longrightarrow}$ I  \nI $\\overset{\\gamma}{\\longrightarrow}$ R  \nI $\\overset{\\alpha_2}{\\longrightarrow}$ F  \n\n$\\alpha_1$: Mortality rate of S$^\\ast$ cases [-]  \n$\\alpha_2$: Mortality rate of I cases [1/min]  \n$\\beta_1$: <u>Exposure rate (the number of encounter with the virus in a minute)</u> [1/min]  \n$\\beta_2$: <u>Inverse of latent period</u> [1/min]  \n$\\beta_3$: <u>Inverse of waiting time for confirmation</u> [1/min]  \n$\\gamma$: Recovery rate [1/min]  \n\nOrdinary Differential Equation (ODE):   \n$\\frac{\\mathrm{d}S}{\\mathrm{d}T}= - N^{-1}\\beta_1 S (W + I)$  \n$\\frac{\\mathrm{d}E}{\\mathrm{d}T}= N^{-1}\\beta_1 S (W + I) - \\beta_2 E$  \n$\\frac{\\mathrm{d}W}{\\mathrm{d}T}= \\beta_2 E - \\beta_3 W$  \n$\\frac{\\mathrm{d}I}{\\mathrm{d}T}= (1 - \\alpha_1)\\beta_3 W - (\\gamma + \\alpha_2) I$  \n$\\frac{\\mathrm{d}R}{\\mathrm{d}T}= \\gamma I$  \n$\\frac{\\mathrm{d}F}{\\mathrm{d}T}= N^{-1}\\alpha_1 \\beta_3 W + \\alpha_2 I$  \n\nWhere $N=S+E+W+I+R+F$ is the total population, $T$ is the elapsed time from the start date."},{"metadata":{},"cell_type":"markdown","source":"## Non-dimensional SEWIR-F model\nSet $(S, E, W, I, R, F) = N \\times (x_1, x_2, x_3, y, z, w)$, $(T, \\alpha_1) = (\\tau t, \\theta)$ and $(\\alpha_2, \\beta_i, \\gamma) = \\tau^{-1} \\times (\\kappa, \\rho_i, \\sigma)$.  \nThis results in the ODE  \n$\\frac{\\mathrm{d}x_1}{\\mathrm{d}t}= - \\rho_1 x_1 (x_3 + y)$  \n$\\frac{\\mathrm{d}x_2}{\\mathrm{d}t}= \\rho_1 x_1 (x_3 + y) - \\rho_2 x_2$  \n$\\frac{\\mathrm{d}x_3}{\\mathrm{d}t}= \\rho_2 x_2 - \\rho_3 x_3$  \n$\\frac{\\mathrm{d}y}{\\mathrm{d}t}= (1-\\theta) \\rho_3 x_3 - (\\sigma + \\kappa) y$  \n$\\frac{\\mathrm{d}z}{\\mathrm{d}t}= \\sigma y$  \n$\\frac{\\mathrm{d}w}{\\mathrm{d}t}= \\theta \\rho_3 x_3 + \\kappa y$  \n\nWhere $N$ is the total population and $\\tau$ is a coefficient ([min], is an integer to simplify).  \n\nThe range of variables and parameters:  \n$0 < (x_i, y, z, w, \\theta, \\kappa, \\rho_i, \\sigma) < 1$  \n$1 \\leq \\tau \\leq 1440$  \n\nReproduction number can be defined as  \n$R_0 = \\rho_1 (1-\\theta) (\\sigma + \\kappa)^{-1}$"},{"metadata":{},"cell_type":"markdown","source":"## Calculate $\\rho_2$ and $\\rho_3$\nTo estimate $\\rho_2 = \\tau \\beta_2$ and $\\rho_3 = \\tau \\beta_3$, we first calculate median value of latent period $\\overline{L_{E}}$ and waiting time for confirmation $\\overline{L_{W}}$ using linelist. We assume that patients start to have infectivity from onset dates. This means latent period is equal to incubation period.\n\n$\\beta_2$: Inverse of latent period [1/min]  \n$\\beta_3$: Inverse of waiting time for confirmation [1/min]"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"period_df = select_area(linelist_df, group=None)\nperiod_df = period_df.loc[:, [\"Exposed_date\", \"Onset_date\", \"Confirmed_date\"]]\nperiod_df[\"Latent [min]\"] = (period_df[\"Onset_date\"] - period_df[\"Exposed_date\"]).dt.total_seconds() / 60\nperiod_df[\"Waiting [min]\"] = (period_df[\"Confirmed_date\"] - period_df[\"Onset_date\"]).dt.total_seconds() / 60\nperiod_df[\"Latent [day]\"] = period_df[\"Latent [min]\"] / 60 / 24\nperiod_df[\"Waiting [day]\"] = period_df[\"Waiting [min]\"] / 60 / 24\nperiod_df[\"Latent + Waiting [day]\"] = period_df[\"Latent [day]\"] + period_df[\"Waiting [day]\"]\nperiod_df.dropna(axis=0).tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"cols = [\"Latent [day]\", \"Waiting [day]\", \"Latent + Waiting [day]\"]\nperiod_df[cols].plot.kde()\nplt.title(\"Kernel density estimation of latent period and waiting time for confirmation [day]\")\nplt.show()\nperiod_df[cols].describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"latent_period = period_df[\"Latent [min]\"].median()\nwaiting_time = period_df[\"Waiting [min]\"].median()\nlatent_waiting_day = period_df[\"Latent + Waiting [day]\"].median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tau = sirf_estimator.info()[1][\"tau\"]\nrho2, rho3 = tau / latent_period, tau / waiting_time\n(rho2, rho3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Estimate $\\rho_1$\nWe will estimate $\\rho_1$ and the other parameters by hyperparameter estimation of SEWIR-F model."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nsewirf_estimator = Estimator(\n    SEWIRF, ncov_df, population_dict[critical_country],\n    name=critical_country, excluded_places=[(critical_country, None)],\n    start_date=critical_country_start,\n    tau=tau, rho2=rho2, rho3=rho3\n)\nsewirf_dict = sewirf_estimator.run()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sewirf_estimator.compare_graph()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame.from_dict({\"SIR-F\": sirf_dict, \"SEWIR-F\": sewirf_dict}, orient=\"index\").fillna(\"-\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction with SEWIR-F model"},{"metadata":{"trusted":true},"cell_type":"code","source":"first_model, info_dict, param_dict = sewirf_estimator.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicter = Predicter(**info_dict)\npredicter.add(SEWIRF, end_day_n=None, vline=False, **param_dict)\npredicter.add(SEWIRF, end_day_n=7, count_from_last=True, **param_dict)\npredicter.restore_graph(drop_cols=[\"Susceptible\"])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"df = predicter.restore_df()\ndf.loc[datetime.today():, [\"Exposed\", \"Waiting\", \"Infected\", \"Recovered\", \"Fatal\"]].style.background_gradient(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"predicter = Predicter(**info_dict)\npredicter.add(SEWIRF, end_day_n=200, count_from_last=False, **param_dict)\npredicter.restore_graph(drop_cols=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Factors of model parameters\nTo figure out what to do for minimizing the damage, we will perform scenario analysis in the next section. In this section, we will define the control factors of the SIR-F parameters."},{"metadata":{},"cell_type":"markdown","source":"## Control factors of effective contact rate $\\beta_1$\nPlease reconsider S $\\overset{\\beta_1 \\mathrm{(W+I)}}{\\longrightarrow}$ E formula. Susceptible persons may contact with waiting/confirmed patients, and susceptible persons will be infected with COVID-19. The formura can be replaced with  \nS$_\\mathrm{q}$ $\\overset{g_{s}}{\\Longleftrightarrow}$ S$_{\\mathrm{g}}$ $\\overset{f_1}{\\longrightarrow}$ E$^\\ast$ $\\overset{e^{-h_2}}{\\longrightarrow}$ E  \nW$_\\mathrm{q}$ $\\overset{g_w}{\\Longleftrightarrow}$ W$_{\\mathrm{g}}$  \nI$_\\mathrm{q}$ $\\overset{g_i}{\\Longleftrightarrow}$ I$_{\\mathrm{g}}$  \nI$_\\mathrm{q}$ $\\overset{q}{\\longrightarrow}$ I$_{\\hat{\\mathrm{q}}}$  \nE$^\\ast$ $\\overset{1-e^{-h_2}}{\\longrightarrow}$ R$^\\ast$"},{"metadata":{},"cell_type":"markdown","source":"$\\Longleftrightarrow$ (as substitute for $\\longrightarrow$ with $\\longleftarrow$) means that right side can be return to the left side.  \nS$_\\mathrm{q}$: Susceptible persons with self-quaranting <!--Susceptible in the strict sense-->  \nS$_\\mathrm{g}$: Susceptible persons with family members or friends etc.  \nW$_\\mathrm{q}$: Waiting patients with self-quaranting  \nW$_\\mathrm{g}$: Waiting patients with family members or friends etc.  \nI$_\\mathrm{q}$: Confimered and un-recovered patients with self-quaranting  \nI$_\\mathrm{g}$: Confimered and un-recovered patients with family members or friends etc.  \nI$_\\hat{\\mathrm{q}}$: Confimered and un-recovered patients who was hospitalized  \nE$^\\ast$: Just after being exposed to the virus  \nR$^\\ast$: Being exposed to the virus, fighted with the virus, recovered and immuned without confirmation  "},{"metadata":{},"cell_type":"markdown","source":"$f_1 = v(W_{\\mathrm{g}} + I_{\\mathrm{g}})(1-m)^2(1-w_e)^{w_n}e^{-h_1}sc$ [-] "},{"metadata":{},"cell_type":"markdown","source":"Control factors:  \n$g_s$: The number of days in <u>a week</u> susceptible persons go out [day]  \n$g_w$: The number of days in <u>a week</u> waiting but un-quarantined persons go out [day]  \n$g_i$: The number of days in <u>a week</u> currently infected (confirmed) but un-quarantined persons go out [day]  \n$q$: Quarantine rate of currently infected (confirmed) patients [-]  \n$v$: Probability of virus existance in a droplet [-]  \n$m$: Rate of persons wearing masks effectively (depends logistically on supply of masks) [-]  \n$w_e$: Virus reduction effect of washing hands [-]  \n$w_n$: The number of times people washes their hands before touching their own faces after go out [-]  \n$h_1$: Health condition (active rate of cellular immunity factors) of susceptible and contacted persons [-]  \n$h_2$: Health condition (active rate of humoral immunity factors) of susceptible and contacted persons [-]  \n$c$: The number of contacts between susceptible persons and patients while on the go in a minute (depends on population density) [1/min]  \n$\\delta$:The product of unknown real factors [-]  \n\nThe parameter in the math model:  \n$\\beta_1 = \\cfrac{1}{49}[g_s \\{g_w + g_i (1-q) \\} v (1-m)^2 (1-w_e)^{w_n} e^{-(h_{1}+h_{2})} c \\delta]$ [1/min]"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Value of beta before actions are taken\nbeta1_before = param_dict[\"rho1\"] / info_dict[\"tau\"]\nbeta1_before","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### $g_s$ value before actions are taken\n$g_s$: The number of days in <u>a week</u>, susceptible persons go out [day]  "},{"metadata":{},"cell_type":"markdown","source":"We can calculate weighted average of days with age composion of population."},{"metadata":{"trusted":true},"cell_type":"code","source":"ec_out_df = go_out(critical_country)\nec_out_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs_before = (ec_out_df[[\"School\", \"Office\", \"Others\"]].sum(axis=1) * ec_out_df[\"Portion\"]).sum()\ngs_before","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### $g_s$ value AFTER actions are taken\nIf all schools and offices will be closed, $g_s$ can be reduced. People will go out one day for other reasons instead of going to school/office."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = ec_out_df.copy()\ndf[\"School\"] = 0\ndf[\"Office\"] = 0\ndf.loc[df.index[1:9], \"Others\"] += 1\ngs_after = (df[[\"School\", \"Office\", \"Others\"]].sum(axis=1) * df[\"Portion\"]).sum()\ngs_after","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Impact of actions on $\\beta_1$\nActions to take since today:  \nAll schools and offices will be closed.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"beta1_after = beta1_before * (gs_after / gs_before)\nbeta1_after / beta1_before","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict the future: with actions since today\nThere is a delay between the time point of starting actions and that of appearing the effect. Because I is the main variable, the length of delay can be estimated as sum of latent period and waiting time for confirmation. This value [day] was calculated in \"The number of exposed cases and waiting cases\" section."},{"metadata":{"trusted":true},"cell_type":"code","source":"latent_waiting_day","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"first_model, info_dict, param_dict = sewirf_estimator.info()\ninfo_dict[\"name\"] = critical_country\nchanged_param_dict = param_dict.copy()\nchanged_param_dict[\"rho1\"] = param_dict[\"rho1\"] * beta1_after / beta1_before\ndf = pd.DataFrame.from_dict(\n    {\"No actions\": param_dict, \"With actions\": changed_param_dict},\n    orient=\"index\"\n)\ndf = df.loc[:, [\"rho1\", \"rho2\", \"rho3\", \"theta\", \"kappa\", \"sigma\"]]\ndf[\"R0\"] = df.apply(lambda x: first_model(**x.to_dict()).calc_r0(), axis=1)\ndf[\"tau\"] = info_dict[\"tau\"]\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicter = Predicter(**info_dict)\npredicter.add(SEWIRF, end_day_n=None, count_from_last=False, vline=False, **param_dict)\npredicter.add(SEWIRF, end_day_n=latent_waiting_day, count_from_last=True, **param_dict)\npredicter.add(SEWIRF, end_day_n=30, count_from_last=True, **changed_param_dict)\npredicter.restore_graph(drop_cols=[\"Susceptible\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicter = Predicter(**info_dict)\npredicter.add(SEWIRF, end_day_n=None, count_from_last=False, vline=False, **param_dict)\npredicter.add(SEWIRF, end_day_n=latent_waiting_day, count_from_last=True, **param_dict)\npredicter.add(SEWIRF, end_day_n=400, count_from_last=False, **changed_param_dict)\npredicter.restore_graph(drop_cols=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The actions result in:  \nTotal number of confirmed cases was decreased.  \nPeak point of infected cases was delayed.   \nWe need to fight with the virus for longer period."},{"metadata":{},"cell_type":"markdown","source":"## Control factors of recovery rate $\\gamma$ and mortality rate $\\alpha_2$\nHere, let's reconsider I $\\overset{\\gamma}{\\longrightarrow}$ R and I $\\overset{\\alpha_2}{\\longrightarrow}$ F.  \nBecause balance of immunity (+effect of treatments) and virulence determines whether patients can recover or not, the formulas can be replaced with  \n\nI $\\overset{\\bar{h}}{\\longrightarrow}$ I$^\\star$ $\\overset{\\bar{s}}{\\longrightarrow}$ F$^\\star$ $\\overset{L^{-1}}{\\longrightarrow}$ F  \nI $\\overset{f_2}{\\longrightarrow}$ R$^\\star$ $\\overset{l^{-1}}{\\longrightarrow}$ R  \n\nI$^\\star$: Confirmed cases whose immune systems did not overcome virus multiplication, and <u>without</u> severe events  \nF$^\\star$: Confirmed cases whose immune systems did not overcome virus multiplication, and <u>with</u> severe events  \nR$^\\star$: Confirmed cases whose immune systems overcame virus multiplication or comfirmed cases whose severe events can be stopped"},{"metadata":{},"cell_type":"markdown","source":"Where $f_2 = 1 - \\bar{h}\\ \\bar{s}$  \n\n$\\bar{h}$: Rate of I whose immune systems does NOT overcame virus multiplication [-]  \n$\\bar{s}$: Rate of I$^\\star$ who have severe events, including respiratory failure  [-]  \n$L_i$: Inverse of F$^\\star$'s mortality rate for people $i$ years old [min]  \n$l_i$: Inverse of R$^\\star$'s mortality rate for people $i$ years old [min]  \n$P_i$: The number of people $i$ years old [-]  \n$N$: Total population  \n\n\\begin{align*}\n& \\alpha_2 = \\cfrac{\\bar{h}\\ \\bar{s}}{N} \\sum_{n=0}^{\\infty}\\cfrac{P_{i}}{L_i} \\\\\n    & \\gamma = \\cfrac{1 - \\bar{h}\\ \\bar{s}}{N} \\sum_{n=0}^{\\infty}\\cfrac{P_{i}}{l_i} \\\\\n\\end{align*}"},{"metadata":{},"cell_type":"markdown","source":"## $\\bar{h}$ and $\\bar{s}$ value before actions are taken\nWe assume that $\\bar{h}=0.5$ and $\\bar{s}=0.5$. **(Yes, we need remove this assumtions later!)**  \n**(Using population distribution data and case reports, $\\bar{h}\\ \\bar{s}$ and $1 - \\bar{h}\\ \\bar{s}$ can be calculated.)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"gamma_before = param_dict[\"sigma\"] / info_dict[\"tau\"]\nalpha2_before = param_dict[\"kappa\"] / info_dict[\"tau\"]\n(gamma_before, alpha2_before)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"h_bar_before, s_bar_before = 0.5, 0.5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## $\\bar{h}$ and $\\bar{s}$ value AFTER actions are taken\nAssumtions of new medicines:  \n\"Protease inhibitor\" inhibits virus multiplication. This will reduce $\\bar{h}$"},{"metadata":{"trusted":true},"cell_type":"code","source":"h_bar_after = 0.25\ns_bar_after = s_bar_before","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Impact on $\\gamma$ and $\\alpha_2$\nActions to take:  \nNew Protein inhibitor medicine was introduced."},{"metadata":{"trusted":true},"cell_type":"code","source":"gamma_after = gamma_before * (1 - h_bar_after * s_bar_after) / (1 - h_bar_before * s_bar_before)\ngamma_after","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha2_after = alpha2_before * (h_bar_after * s_bar_after) / (h_bar_before * s_bar_before)\nalpha2_after","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict the future: with actions from the next month"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"first_model, info_dict, param_dict = sewirf_estimator.info()\ninfo_dict[\"name\"] = critical_country\nchanged_param_dict = param_dict.copy()\nchanged_param_dict[\"sigma\"] = param_dict[\"sigma\"] * gamma_after / gamma_before\nchanged_param_dict[\"kappa\"] = param_dict[\"kappa\"] * alpha2_after / alpha2_before\ndf = pd.DataFrame.from_dict(\n    {\"No actions\": param_dict, \"With actions\": changed_param_dict},\n    orient=\"index\"\n)\ndf = df.loc[:, [\"rho1\", \"rho2\", \"rho3\", \"theta\", \"kappa\", \"sigma\"]]\ndf[\"R0\"] = df.apply(lambda x: first_model(**x.to_dict()).calc_r0(), axis=1)\ndf[\"tau\"] = info_dict[\"tau\"]\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicter = Predicter(**info_dict)\npredicter.add(SEWIRF, end_day_n=None, count_from_last=False, vline=False, **param_dict)\npredicter.add(SEWIRF, end_day_n=30, count_from_last=True, **param_dict)\npredicter.add(SEWIRF, end_day_n=30, count_from_last=True, **changed_param_dict)\npredicter.restore_graph(drop_cols=[\"Susceptible\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicter = Predicter(**info_dict)\npredicter.add(SEWIRF, end_day_n=None, count_from_last=False, vline=False, **param_dict)\npredicter.add(SEWIRF, end_day_n=30, count_from_last=True, **param_dict)\npredicter.add(SEWIRF, end_day_n=500, count_from_last=False, **changed_param_dict)\npredicter.restore_graph(drop_cols=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The actions result in:  \nTotal numbers of confirmed/deaths cases were decreased."},{"metadata":{},"cell_type":"markdown","source":"# Scenario in USA\nIn this section, we will perform scenario analysis using the records of Canada."},{"metadata":{"trusted":true},"cell_type":"code","source":"us_scenario = Scenario(ncov_df, name=\"US\", places=[(\"US\", None)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_scenario.show_record().tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_scenario.growth_factor()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Trend analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"us_scenario.trend(variables=[\"Confirmed\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We will use the records from 23Feb2020.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"us_scenario.trend(start_date=\"01Mar2020\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**There are three phases in US.**\n* From 01Mar2020 to 19Mar2020\n* From 20Mar2020 to 31Mar2020\n* From 01Apr2020 to today"},{"metadata":{"trusted":true},"cell_type":"code","source":"us_scenario.set_phase(\n    start_dates=[\"01Mar2020\",\"22Mar2020\",\"01Apr2020\"],\n    population=population_dict[\"US\"]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Estimate SIR-F parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"us_scenario.estimate(SIRF)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1st phase"},{"metadata":{"trusted":true},"cell_type":"code","source":"us_scenario.accuracy_graph(phase_n=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2nd phase\n$\\tau$ of 2nd phase is the same as that of 1st phase."},{"metadata":{"trusted":true},"cell_type":"code","source":"us_scenario.accuracy_graph(phase_n=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3rd phase\n$\\tau$ of 3rd phase is the same as that of 1st phase."},{"metadata":{"trusted":true},"cell_type":"code","source":"us_scenario.accuracy_graph(phase_n=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compare predicted number of confirmed cases"},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"us_scenario.compare_estimated_numbers()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compare parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"us_scenario.param_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_scenario.param_history([\"rho\", \"sigma\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Non-dimensional effective contact rate $\\rho$ seems to be reduced.**"},{"metadata":{},"cell_type":"markdown","source":"## Why $\\rho$ was reduced?"},{"metadata":{"trusted":true},"cell_type":"code","source":"us_scenario.param_df[[\"start_date\", \"end_date\", \"rho\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**It seems that (quaranitine of person contacted with positive patients), school closure and lockdown reduced $\\rho$ value.**"},{"metadata":{},"cell_type":"markdown","source":"## Effect of school closure/lockdown\n\nAcording to first report of [COVID-19 Mobility Monitoring project](https://covid19mm.github.io/in-progress/2020/03/13/first-report-assessment.html) on 13Mar2020, the government of Italy declared a national lockdown on 09Mar2020 and all peole are asked to remain home. This resulted in average reduction of potential encounters of 19% during week 3 (from 07Mar2020 to 10Mar2020)."},{"metadata":{},"cell_type":"markdown","source":"**Here, we will predict the effect of school closure (started before 04Mar2020), lockdown on 13Mar2020 with assumtion that the effect will be shown from the start date of 3rd phase.**"},{"metadata":{},"cell_type":"markdown","source":"### Real factors of $\\beta_1$\n\nThe parameter in the math model:  \n$\\rho_1 = \\tau \\beta_1$  \n$\\beta_1 = \\cfrac{1}{49}[g_s \\{g_w + g_i (1-q) \\} v (1-m)^2 (1-w_e)^{w_n} e^{-(h_{1}+h_{2})} c \\delta]$ [1/min]\n\nControl factors:  \n$g_s$: The number of days in <u>a week</u> susceptible persons go out [day]  \n$g_w$: The number of days in <u>a week</u> waiting but un-quarantined persons go out [day]  \n$g_i$: The number of days in <u>a week</u> currently infected (confirmed) but un-quarantined persons go out [day]  \n$q$: Quarantine rate of currently infected (confirmed) patients [-]  \n$v$: Probability of virus existance in a droplet [-]  \n$m$: Rate of persons wearing masks effectively (depends logistically on supply of masks) [-]  \n$w_e$: Virus reduction effect of washing hands [-]  \n$w_n$: The number of times people washes their hands before touching their own faces after go out [-]  \n$h_1$: Health condition (active rate of cellular immunity factors) of susceptible and contacted persons [-]  \n$h_2$: Health condition (active rate of humoral immunity factors) of susceptible and contacted persons [-]  \n$c$: The number of contacts between susceptible persons and patients while on the go in a minute (depends on population density) [1/min]  \n$\\delta$:The product of unknown real factors [-]  "},{"metadata":{},"cell_type":"markdown","source":"### Value of control factors of $\\beta_1$ before/after the national lockdown\nA national lockdown will effect on $g_s$ and $c$."},{"metadata":{},"cell_type":"markdown","source":"Acccoring the report, we assume average reduction of potential encounters of 19%."},{"metadata":{"trusted":true},"cell_type":"code","source":"c_before, c_after = 1.0, 0.81","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### $g_s$ before the lockdown\nWe will estimate average number peple go out using @marcoferrante estimation table and population pyramid data.\nIt is necessary to replace the population pyramid data for Italy because the situation is different from the average data."},{"metadata":{"trusted":true},"cell_type":"code","source":"us_out_df = go_out(\"US\")\nus_out_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs_before = (us_out_df[[\"School\", \"Office\", \"Others\"]].sum(axis=1) * us_out_df[\"Portion\"]).sum()\ngs_before","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Estimation of $g_s$ after school closure/lockdown\nHere, we estimate the $g_s$ after school closure/lockdown with the assumption that only $g_s$ and $c$ was changed.   \n\nBecause\n$$\\cfrac{\\rho_{\\mathrm{after}}}{gs_{\\mathrm{after}}\\times c_{\\mathrm{after}}} = \\cfrac{\\rho_{\\mathrm{before}}}{gs_{\\mathrm{before}}\\times c_{\\mathrm{before}}}$$\n\n$gs_{\\mathrm{after}}$ is"},{"metadata":{"trusted":true},"cell_type":"code","source":"rho_before = us_scenario.param(\"1st\", \"rho\")\nrho_after = us_scenario.param(\"3rd\", \"rho\")\ngs_after = rho_after / rho_before / c_after * gs_before * c_before\nprint(f\"{round(gs_after, 1)} days in a week susceptible people go out.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's apply this value to the go_out table!  \nWe assume that workers go to their office one day in a week."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = us_out_df.copy()\ndf[\"School\"] = 0\ndf.loc[df[\"Office\"] > 0, \"Office\"] = 1\nsum_so = (df[[\"School\", \"Office\"]].sum(axis=1) * df[\"Portion\"]).sum()\ndf.loc[df[\"Others\"] > 0, \"Others\"] = round(gs_after - sum_so, 1)\nus_out_after_df = df.copy()\nus_out_after_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the $g_s$ value calculated with the table."},{"metadata":{"trusted":true},"cell_type":"code","source":"gs_after = (us_out_after_df[[\"School\", \"Office\", \"Others\"]].sum(axis=1) * us_out_after_df[\"Portion\"]).sum()\nround(gs_after, 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict the future with 3rd parameters"},{"metadata":{},"cell_type":"markdown","source":"In a week,"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"us_scenario.predict(days=38).tail(7).style.background_gradient(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In 30 days,"},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"us_scenario.predict(days=120).tail(7).style.background_gradient(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the long-term,"},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = us_scenario.predict(days=1000, min_infected=1)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}