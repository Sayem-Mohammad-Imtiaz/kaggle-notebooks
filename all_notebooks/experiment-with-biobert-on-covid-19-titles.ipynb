{"cells":[{"metadata":{},"cell_type":"markdown","source":"### BioBERT Sentence Embedding to return COVID-19 articles based on query - An Experiment"},{"metadata":{},"cell_type":"markdown","source":"In this experimental notebook, we tried a general method that search articles from covid-19 datasets that closely corresponds to the user's query.\n\nGiven a user's query, we will compute the cosine similarity between the query and each article's title. In order to do so, we need vectors that represent the query and the titles themselves. \n\nWe do so by generating sentence embeddings using BioBERT. Specifically, we take the average of the token embeddings for each sentence. We tested our function with queries coming from \"Sample Submission Task\" of the challenge. The queries of the task are:\n\n<ul>\n    <li>Are there geographic variations in the rate of COVID-19 spread?</li>\n    <li>Are there geographic variations in the mortality rate of COVID-19?</li>\n    <li>Is there any evidence to suggest geographic based virus mutation?</li>\n</ul>\n\nBefore running all the cells below, we will need to download the biobert model from https://github.com/dmis-lab/biobert. Here, we will be using BioBERT-Base v1.1 (+ PubMed 1M) and we will save the models in a folder called \"biobertv11pubmedckptcopy\".\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os, json\nimport numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To call biobert_embedding, we need to change directory (there is a more elegant way, but sorry for this)\n\nos.chdir('../input/biobertcustom/')\nfrom biobert_embedding import BertSim\n\n# Let us call the BioBERT Sentence Embedding (BertSim) here, and set it to predict mode\n\nbs = BertSim()\nbs.set_predict()\n\n# Now let us change back to the data directory\n\nos.chdir('../CORD-19-research-challenge/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A function to collect the titles from the given input path folder\n\ndef collectTitle(input_path): \n    '''\n        Return all the article's title from the input_path folder\n    '''\n    all_title = []\n    jsonlist     = os.listdir(input_path)\n    for jsonname in jsonlist: \n        jsonfile = input_path + jsonname\n        with open(jsonfile) as f:\n            jsondata = json.load(f)\n            all_title.append((jsondata['metadata']['title'], input_path.split('/')[-2] + '/' + jsonname))\n    return all_title","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This may take some time, please be patient and do not close this notebook :(\n\nalltitles = []\n\nbiorxiv_pdf = collectTitle('biorxiv_medrxiv/biorxiv_medrxiv/pdf_json/')\ncommuse_pdf = collectTitle('comm_use_subset/comm_use_subset/pdf_json/')\ncommuse_pmc = collectTitle('comm_use_subset/comm_use_subset/pmc_json/')\nnoncommuse_pdf = collectTitle('noncomm_use_subset/noncomm_use_subset/pdf_json/')\nnoncommuse_pmc = collectTitle('noncomm_use_subset/noncomm_use_subset/pmc_json/')\ncustomlics_pdf = collectTitle('custom_license/custom_license/pdf_json/')\ncustomlics_pmc = collectTitle('custom_license/custom_license/pmc_json/')\n\nalltitles.extend(biorxiv_pdf)\nalltitles.extend(commuse_pdf)\nalltitles.extend(commuse_pmc)\nalltitles.extend(noncommuse_pdf)\nalltitles.extend(noncommuse_pmc)\nalltitles.extend(customlics_pdf)\nalltitles.extend(customlics_pmc)\n\nalltitles = pd.DataFrame(alltitles)\nalltitles.columns = ['sentence', 'nameoffile']\nalltitles = alltitles[['nameoffile', 'sentence']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clean_text function to remove certain words from the title\n\ndef clean_text(temp):\n    temp = temp.lower()\n    if any('title'in word for word in temp.split(' ')[:4]):\n        temp=temp.replace('title: ','').replace('title page ','').replace('title (provisional) ','')\n        temp=temp.replace('title 1 ','').replace('title 4 ','').replace('title page: 1 ', '')\n        temp=temp.replace('â€¢ title ','').replace('subject areas title ','').replace('title -','')\n        temp=temp.replace('watching brief title ','').replace('title ','').replace('title','')\n    return temp\n\n# Return the cleaned titles\n\nalltitles['sentence'] = alltitles['sentence'].apply(lambda x: clean_text(x))\nalltitles = alltitles.loc[(alltitles['sentence'] != '') & ~pd.isna(alltitles['sentence'])]\nalltitles = alltitles.reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get all the title's embeddings\n\ntitle_embeddings =  bs.bert_sentences_embedding(list(alltitles['sentence'].values))\nalltitles['sentence_embedding'] = title_embeddings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cos_sim(a,b):\n    '''\n        Return the cosine similarity between vector a and vector b\n    '''\n    if a is not None and b is not None:\n        return  np.dot(a, b)/(np.linalg.norm(a) * np.linalg.norm(b))\n    else:\n        return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Next let us prepare the queries embedding\n\nquery0 = \"are there geographic variations in the rate of covid-19 spread?\"\nquery1 = \"are there geographic variations in the mortality rate of covid-19?\"\nquery2 = \"is there any evidence to suggest geographic based virus mutation?\"\nq_e0 = bs.bert_sentences_embedding([query0])[0]\nq_e1 = bs.bert_sentences_embedding([query1])[0]\nq_e2 = bs.bert_sentences_embedding([query2])[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finally, let us check their similarities\n\nalltitles['similarity_0'] = alltitles.apply(lambda x: cos_sim(x['sentence_embedding'],q_e0),axis=1)\nalltitles['similarity_1'] = alltitles.apply(lambda x: cos_sim(x['sentence_embedding'],q_e1),axis=1)\nalltitles['similarity_2'] = alltitles.apply(lambda x: cos_sim(x['sentence_embedding'],q_e2),axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Top 50 articles that answers to query: <b> Are there geographic variations in the rate of COVID-19 spread? </b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"list(alltitles.sort_values(['similarity_0'], ascending = False)['sentence'].reset_index(drop = True).loc[0:49].values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Top 50 articles that answers to query: <b> Are there geographic variations in the mortality rate of COVID-19? </b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"list(alltitles.sort_values(['similarity_1'], ascending = False)['sentence'].reset_index(drop = True).loc[0:49].values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Top 50 articles that answers to query: **Is there any evidence to suggest geographic based virus mutation?**"},{"metadata":{"trusted":true},"cell_type":"code","source":"list(alltitles.sort_values(['similarity_2'], ascending = False)['sentence'].reset_index(drop = True).loc[0:49].values)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}