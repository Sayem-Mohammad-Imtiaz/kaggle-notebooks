{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import re\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \n#import turicreate as tc\n\ndf = pd.read_csv(\"../input/Train_psolI3n.csv\")\ndf1 = pd.DataFrame(df)\nprint(df1.isnull().sum())\ndf1 = df1.dropna()\nprint(df1.head())\ndf3 = pd.read_csv(\"../input/Test_09JmpYa.csv\")\ndf2 = pd.DataFrame(df3)\n#print(df1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15a7062924f108517d41de8bcc88fd454399a82d"},"cell_type":"code","source":"df1 = pd.DataFrame(df)\nprint(df1.axes)\ndf1 =df1.dropna()\nprint(df1.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7163a193d0517567e54001f30b2e784d671357ee"},"cell_type":"code","source":"import numpy as np\n\nignored = len(df1[df1['Email_Status']==0])\nread  = len(df1[df1['Email_Status']==1])\nacknowledge = len(df1[df1['Email_Status']==2])\n\nprint(\"IGNORED:\",ignored)\nprint(\"READ:\",read)\nprint(\"Acknowledge:\",acknowledge)\n\nlabels = ['IGNORED','READ','ACKNOWLEDGE']\nli = [ignored,read,acknowledge]\n\nindex = np.arange(len(labels))\n\nplt.bar(index,li)\nplt.xlabel('Mail-Tracking',fontsize =12)\nplt.ylabel('Count',fontsize =12)\nplt.xticks(index,labels,fontsize=12,rotation=40)\nplt.show()\n\nprint(df1.head())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f31fd9301a90b5391cc546429605b14ee79dee00"},"cell_type":"code","source":"import seaborn as sc\n\nX2 = df1.iloc[:,1:7]\nY2 = df1.iloc[:,-1]\n\ncorrmat  = df1.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(6,6))\n\ng= sc.heatmap(df1[top_corr_features].corr(),annot = True,cmap =\"RdYlGn\")\n\nX_val = df1.iloc[:,1:7]\nY_val = df1.iloc[:,-1]\nY_val = Y_val.astype('int')\n\n#X_train,X_test,Y_train,Y_test = train_test_split(X_val,Y_val,test_size=0.35,random_state = 32)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9eaa1ab1003285a42770247cde01605b796b5e7"},"cell_type":"code","source":"y_col = df1.Email_Status\nprint(y_col.shape)\ndf1.corr()\ndf1.nunique()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96a8924b304d8e043c76f391a3d5453a863a0032"},"cell_type":"code","source":"df1.describe()\ndf1.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dcdd0ed8bdf84ba73a5047881269a5836748cc3e"},"cell_type":"code","source":"df2 = pd.DataFrame(df3)\nprint(df2.index)\n#to_drop = df1()\ndf2.drop(['Customer_Location','Email_Campaign_Type','Time_Email_sent_Category'],1,inplace=True)\ndf2.head()\ndf2.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d229abac61ed6d707d558e32ed0770417bf8f3e0"},"cell_type":"code","source":"df1.Email_Type.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1c5312e3c8a8d248cb150538bab5da6a5907edb"},"cell_type":"code","source":"df1.groupby('Email_Type').agg(['nunique'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1fdcfbe29ed47845cb5029cede739fe9b03e0260"},"cell_type":"code","source":"df1.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9ff3f287df82ab71dedc50291f61120f1fcbb4d"},"cell_type":"code","source":"df1.groupby('Email_Type')['Email_Source_Type'].agg(['size','count','mean'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aafc5e80ebc4a1a00726713d6a70589237dfb3d8"},"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\n\n\nnumeric_features = ['Subject_Hotness_Score','Total_Past_Communications','Word_Count','Total_Links','Total_Images']\ncategory_features = ['Email_Type','Email_Source_Type']\n\nnumeric_transformer = Pipeline(steps=[('imputer',SimpleImputer(fill_value='N/A')),('scaler',StandardScaler())])\ncategory_transformer = Pipeline(steps=[('imputer',SimpleImputer(fill_value='missing')),('onehot',OneHotEncoder(handle_unknown='ignore'))])\n\n\npreprocess = ColumnTransformer(transformers=[('num',numeric_transformer,numeric_features),('cat',category_transformer,category_features)])\n\nclf = Pipeline(steps=[('preprocessor',preprocess),('classifier',LogisticRegression(solver='lbfgs'))])\n\nX_train,X_test,Y_train,Y_test = train_test_split(df1,y_col,test_size=0.3,random_state=75)\n\nclf.fit(X_train,Y_train)\nprint(\"Score:\",clf.score(X_test,Y_test))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c181ab1f921c1d46617951a1d8f69a3c2bab7e5"},"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\n\n\nnumeric_features = ['Subject_Hotness_Score','Total_Past_Communications','Word_Count','Total_Links','Total_Images']\ncategory_features = ['Email_Type','Email_Source_Type']\n\nnumeric_transformer = Pipeline(steps=[('imputer',SimpleImputer(fill_value='N/A')),('scaler',StandardScaler())])\ncategory_transformer = Pipeline(steps=[('imputer',SimpleImputer(fill_value='missing')),('onehot',OneHotEncoder(handle_unknown='ignore'))])\n\n\npreprocess = ColumnTransformer(transformers=[('num',numeric_transformer,numeric_features),('cat',category_transformer,category_features)])\n\nclf = Pipeline(steps=[('preprocessor',preprocess),('classifier',LogisticRegression(solver='lbfgs'))])\n\nfrom xgboost import XGBClassifier\n\ngbm = XGBClassifier(max_depth=3,n_estimator=300,learning_rate=0.05).fit(preprocess.fit_transform(df1),y_col)\n\nimport eli5\n\neli5.show_weights(gbm,top=7)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d54cc4439e4736220382f372b291289404f96d9"},"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\n\n\nnumeric_features = ['Subject_Hotness_Score','Total_Past_Communications','Word_Count','Total_Links','Total_Images']\ncategory_features = ['Email_Type','Email_Source_Type']\n\nnumeric_transformer = Pipeline(steps=[('imputer',SimpleImputer(fill_value='N/A')),('scaler',StandardScaler())])\ncategory_transformer = Pipeline(steps=[('imputer',SimpleImputer(fill_value='missing')),('onehot',OneHotEncoder(handle_unknown='ignore'))])\n\n\npreprocess = ColumnTransformer(transformers=[('num',numeric_transformer,numeric_features),('cat',category_transformer,category_features)])\n\nclf = Pipeline(steps=[('preprocessor',preprocess),('classifier',LogisticRegression(solver='lbfgs'))])\n\nfrom xgboost import XGBClassifier\n\ngbm = XGBClassifier(max_depth=3,n_estimator=300,learning_rate=0.1).fit(preprocess.fit_transform(df1),y_col)\nclf.fit(X_train,Y_train)\nprint(clf.score(X_test,Y_test))\nimport eli5\n\neli5.show_weights(gbm,top=7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"314bd1d168f8a5aebdd6b2185d95fca61274cf35"},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\n\nprint(cross_val_score(gbm,preprocess.fit_transform(df1),y_col,cv=3))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c33628e530f33e19e6d4381579d3f850e9e590a"},"cell_type":"code","source":"df1.columns\nfeatures = ['Email_Type','Subject_Hotness_Score','Email_Source_Type','Total_Past_Communications','Word_Count','Total_Links','Total_Images']\nnumeric_features = ['Subject_Hotness_Score','Total_Past_Communications','Word_Count','Total_Links','Total_Images']\ncategory_features = ['Email_Type','Email_Source_Type']\n\ntrain_test_concat = pd.concat([df1[features],df2[features]])\ntrain_test_concat.info()\ntrain_test_concat.shape\ntrain_test_concat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24d387744489e9b5666a37eccbd124772665eeca"},"cell_type":"code","source":"import psutil\nimport os\n\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaler.fit(train_test_concat[numeric_features])\nprint(u'memoryï¼š{}gb'.format(psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024 / 1024)) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5982e23d8d40d95d5e664c44df8fd30cd9822ad5"},"cell_type":"code","source":"trained_scaled = df1[['Subject_Hotness_Score','Total_Past_Communications','Word_Count','Total_Links','Total_Images']].copy()\ntrained_scaled = scaler.transform(trained_scaled)\ntrained_scaled = pd.DataFrame(trained_scaled,columns = ['Subject_Hotness_Score','Total_Past_Communications','Word_Count','Total_Links','Total_Images'])\ntrained_scaled = pd.concat([trained_scaled,df1[['Email_Type','Email_Source_Type']]],axis=1)\nprint(trained_scaled.info())\nprint(trained_scaled.shape)\ntrained_scaled.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74c0000b80bb79553258bf529adec2ab59844915"},"cell_type":"code","source":"test_scaled = df2[['Subject_Hotness_Score','Total_Past_Communications','Word_Count','Total_Links','Total_Images']].copy()\ntest_scaled = scaler.transform(test_scaled)\ntest_scaled = pd.DataFrame(test_scaled,columns =['Subject_Hotness_Score','Total_Past_Communications','Word_Count','Total_Links','Total_Images'])\ntest_scaled = pd.concat([test_scaled,df2[['Email_Type','Email_Source_Type']]],axis=1)\nprint(test_scaled.info())\nprint(test_scaled.shape)\ntest_scaled.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7650bdb0cfba4dfe089581ab128d8b348ff9701"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\nX_val = df.iloc[:,1:7]\nX_train2,Y_train2,X_test2,Y_test2 = train_test_split(X_val,y_col,test_size=0.3,random_state=33)\nscaler = MinMaxScaler()\nX_scale = scaler.fit_transform(df1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"294a05bda076e6dae2148c3e3811e4367d23e070"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\n\n\nparam_grid = {\n    'n_estimators':[900,1500],\n    'max_depth':range(1,5,2),\n    'max_features': ('log2','sqrt'),\n    'class_weight':[{1:w} for w in [1,1.5]]\n}\n\nGridr= GridSearchCV(RandomForestClassifier(random_state=96),param_grid)\nGridr.fit(data_with_impute,y_col)\n\nprint(\"Best Parameter:\",str(Gridr.best_params_))\n\nrfo = RandomForestClassifier(random_state=96,**Gridr.best_params_)\nrfo.fit(data_with_impute,y_col)\n\nrfcl_fea = pd.DataFrame(rfo.feature_importance_)\nprint(rfcl_fea)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e580acf15f42a781054da62be90b71942d565d5b"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\nX_train2,Y_train2,X_test2,Y_test2 = train_test_split(data_with_impute,y_col,test_size=0.3,random_state=33)\nscaler = MinMaxScaler()\nX_scale = scaler.fit_transform(data_with_impute)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}