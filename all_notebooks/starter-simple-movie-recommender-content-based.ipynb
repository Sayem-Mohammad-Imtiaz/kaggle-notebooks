{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"We can use the available sparse matrices to make a Movie Recommendation system, based on content-based filtering, with ease. Let's move on step by step.","metadata":{}},{"cell_type":"markdown","source":"## Importing Libraries and Datasets","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.metrics.pairwise import linear_kernel #to generate the similarity matrices\nimport scipy.sparse #to process/handle the sparse matrices\nimport warnings #to ignore the warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"../input/\" directory\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:42:19.106858Z","iopub.execute_input":"2021-06-07T14:42:19.107337Z","iopub.status.idle":"2021-06-07T14:42:20.167195Z","shell.execute_reply.started":"2021-06-07T14:42:19.107236Z","shell.execute_reply":"2021-06-07T14:42:20.166249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's consider **Genre: *Action***, **Genre: *Animation*** and **Genre: *Comedy*** as examples. Also the one with all the movies for experimentation.","metadata":{}},{"cell_type":"code","source":"#importing the datasets\naction_df = pd.read_csv(\"/kaggle/input/imdb-movies-dataset/datasets/action_df.csv\")\nanimation_df = pd.read_csv(\"/kaggle/input/imdb-movies-dataset/datasets/animation_df.csv\")\ncomedy_df = pd.read_csv(\"/kaggle/input/imdb-movies-dataset/datasets/comedy_df.csv\")\nallMovies_df = pd.read_csv(\"/kaggle/input/imdb-movies-dataset/datasets/all_df.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:51:33.499233Z","iopub.execute_input":"2021-06-07T14:51:33.499614Z","iopub.status.idle":"2021-06-07T14:51:35.762829Z","shell.execute_reply.started":"2021-06-07T14:51:33.499584Z","shell.execute_reply":"2021-06-07T14:51:35.761922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"action_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:46:50.676442Z","iopub.execute_input":"2021-06-07T14:46:50.676825Z","iopub.status.idle":"2021-06-07T14:46:50.725488Z","shell.execute_reply.started":"2021-06-07T14:46:50.676793Z","shell.execute_reply":"2021-06-07T14:46:50.724349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"animation_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:47:35.875644Z","iopub.execute_input":"2021-06-07T14:47:35.876026Z","iopub.status.idle":"2021-06-07T14:47:35.896846Z","shell.execute_reply.started":"2021-06-07T14:47:35.875994Z","shell.execute_reply":"2021-06-07T14:47:35.89566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comedy_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:47:45.731176Z","iopub.execute_input":"2021-06-07T14:47:45.731559Z","iopub.status.idle":"2021-06-07T14:47:45.788002Z","shell.execute_reply.started":"2021-06-07T14:47:45.731523Z","shell.execute_reply":"2021-06-07T14:47:45.786913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see the datasets are quite clean, considering for using content-based filtering. \n<br>\nThe Comedy dataset is quite huge, compared to Animation and Action Dataset, with a total of 25200 movies. Let's see the information about the allMovies dataset","metadata":{}},{"cell_type":"code","source":"allMovies_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:52:52.129147Z","iopub.execute_input":"2021-06-07T14:52:52.129537Z","iopub.status.idle":"2021-06-07T14:52:52.261359Z","shell.execute_reply.started":"2021-06-07T14:52:52.129494Z","shell.execute_reply":"2021-06-07T14:52:52.260468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"74889 movies, with much less null values.","metadata":{}},{"cell_type":"markdown","source":"## Applying Content-Based Filtering","metadata":{}},{"cell_type":"markdown","source":"Since we already have sparse matrices which have been collected after applying Tf-idf on each dataset, with specifications (analyzer='word', ngram_range=(1,3), stopwords='english'), we can directly import these .npz files and proceed with generating the similarity matrix.\n\n<br>\nAccording to me, using the technique TF-IDF (term frequency – inverse document frequency) to find out ‘How important is a word in it’s corresponding document’ is much more efficient. The product of term frequency and inverse document frequency for each word acts up as a score of it’s importance.\n\n**Term Frequency** tells us the probability of a word occurring in a document (i.e. number of times the word occur/total number of words in a document).\n<br>\n**Inverse Document Frequency** of a word in a given document corpus(dataset) is the logarithmic ratio of the total number of documents to the number of documents int which the word occurs. In our case, the description of each podcast is a document and the collection of all the descriptions is the document corpus.","metadata":{}},{"cell_type":"markdown","source":"Loading the .npz files *(sparse matrices)* for **Genres: *Action, Animation*** and ***Comedy***. ","metadata":{}},{"cell_type":"code","source":"action_sm = scipy.sparse.load_npz(\"/kaggle/input/imdb-movies-dataset/sparse_matrices/action_sm.npz\")\nanimation_sm = scipy.sparse.load_npz(\"/kaggle/input/imdb-movies-dataset/sparse_matrices/animation_sm.npz\")\ncomedy_sm = scipy.sparse.load_npz(\"/kaggle/input/imdb-movies-dataset/sparse_matrices/comedy_sm.npz\")","metadata":{"execution":{"iopub.status.busy":"2021-06-07T15:05:20.369641Z","iopub.execute_input":"2021-06-07T15:05:20.370071Z","iopub.status.idle":"2021-06-07T15:05:20.926567Z","shell.execute_reply.started":"2021-06-07T15:05:20.370014Z","shell.execute_reply":"2021-06-07T15:05:20.925579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we can calculate the similarity between the podcasts on the basis of their tf-idf scores or values( received as a sparse matrix) using an appropriate kernel method, such that the words with closer scores tend to have a similar type of value and this value changes(either increases or decreases) as the difference between the tf-idf scores increases or decreases. These values will be stored in a separate dataframe, this would be our Recommender DataFrame.\n\nHere, we use the Linear Kernel, which is based on the cosine-similarity of the elements. For the linear_kernel method, closer the value is to 1, for given 2 data-points, more similar are the data-points.\n\nThe liner_kernel function returns a ***numpy.ndarray*** which has similarity scores of each movie, compared with every other movie in the dataframe.","metadata":{}},{"cell_type":"markdown","source":"Claculating the similarity matrices of the above sparse matrices.","metadata":{}},{"cell_type":"code","source":"action_simmat = linear_kernel(action_sm, action_sm)\nanimation_simmat = linear_kernel(animation_sm, animation_sm)\ncomedy_simmat = linear_kernel(comedy_sm, comedy_sm)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T15:27:42.689859Z","iopub.execute_input":"2021-06-07T15:27:42.690354Z","iopub.status.idle":"2021-06-07T15:27:58.682858Z","shell.execute_reply.started":"2021-06-07T15:27:42.690317Z","shell.execute_reply":"2021-06-07T15:27:58.681708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Defining a generic function for getting the top 10 recommendations.**","metadata":{}},{"cell_type":"code","source":"def give_recommendations(df, sim_mat, mov_name):\n    movie = df[df.original_title == mov_name].index[0]\n    index_recomm = sim_mat[movie].argsort(axis=0)[-11:-1]\n    \n    print(\"Original Description: \",df.description[movie],\"\\n\")\n\n    for i in np.flipud(index_recomm):\n        print(\"Score: \",sim_mat[movie][i],\"\\t Title: \",df.original_title[i])\n        print(\"IMDb Title ID: \",df.imdb_title_id[i])\n        print(df.description[i],\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-06-07T15:23:29.989352Z","iopub.execute_input":"2021-06-07T15:23:29.989722Z","iopub.status.idle":"2021-06-07T15:23:29.997401Z","shell.execute_reply.started":"2021-06-07T15:23:29.989692Z","shell.execute_reply":"2021-06-07T15:23:29.996417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, let's see the recommendations.","metadata":{}},{"cell_type":"code","source":"give_recommendations(action_df, action_simmat, 'Singham') #let's try with an Indian Movie: Singham","metadata":{"execution":{"iopub.status.busy":"2021-06-07T15:23:32.348836Z","iopub.execute_input":"2021-06-07T15:23:32.349197Z","iopub.status.idle":"2021-06-07T15:23:32.361996Z","shell.execute_reply.started":"2021-06-07T15:23:32.349168Z","shell.execute_reply":"2021-06-07T15:23:32.360744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Well, the recommendations look good...considering the plot of the movie.","metadata":{}},{"cell_type":"markdown","source":"Now, let's try out for Animation.","metadata":{}},{"cell_type":"code","source":"give_recommendations(animation_df, animation_simmat, 'Frozen') #Everyone knows about Frozen, right!","metadata":{"execution":{"iopub.status.busy":"2021-06-07T15:23:37.558868Z","iopub.execute_input":"2021-06-07T15:23:37.559264Z","iopub.status.idle":"2021-06-07T15:23:37.569395Z","shell.execute_reply.started":"2021-06-07T15:23:37.559232Z","shell.execute_reply":"2021-06-07T15:23:37.568301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"give_recommendations(comedy_df, comedy_simmat, 'Phir Hera Pheri') #The classic, the source of all memes.","metadata":{"execution":{"iopub.status.busy":"2021-06-07T15:29:52.119015Z","iopub.execute_input":"2021-06-07T15:29:52.119441Z","iopub.status.idle":"2021-06-07T15:29:52.13581Z","shell.execute_reply.started":"2021-06-07T15:29:52.11939Z","shell.execute_reply":"2021-06-07T15:29:52.134781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, most people would doubt the credibility of the recommender, as it hasn't predicted ***Hera Pheri*** here. Well guys, remember the plot?","metadata":{}},{"cell_type":"code","source":"hera_pheri = comedy_df[(comedy_df.original_title == 'Hera Pheri') & (comedy_df.year == '2000')]\nhera_pheri = hera_pheri.reset_index()\nprint(\"Plot of Hera Pheri(2000) : \", hera_pheri['description'][0])","metadata":{"execution":{"iopub.status.busy":"2021-06-07T15:47:26.799086Z","iopub.execute_input":"2021-06-07T15:47:26.799605Z","iopub.status.idle":"2021-06-07T15:47:26.815176Z","shell.execute_reply.started":"2021-06-07T15:47:26.799571Z","shell.execute_reply":"2021-06-07T15:47:26.814222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since the story is quite different and *content-based filtering* is completely dependant upon the description/ plot, therefore we don't get Hera Pheri as our recommendation.","metadata":{}},{"cell_type":"markdown","source":"**Great!**\n\nSo here's the way to implement these datasets using content-based filtering for getting genre-wise recommendations. I hoped you liked it, *Please upvote if you did :)*\n\n\nLooking forward to your awesome implementations.","metadata":{}},{"cell_type":"markdown","source":"## *Thank you !* ","metadata":{}}]}