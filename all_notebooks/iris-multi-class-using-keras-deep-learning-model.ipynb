{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Multi Class Classification Problem using IRIS Flowers Dataset \n\nThis is a multi class classification problem which has got more than 2 values to be predicted. \n\nIris Dataset contains four features (length and width of sepals and petals) of 50 samples of **three** species of Iris (Iris setosa, Iris virginica and Iris versicolor). \n\nWe will use keras Deep Learning to predict the outcome \n\n#### Libraries needed for run this mode","metadata":{}},{"cell_type":"code","source":"import pandas\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.utils import np_utils\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import Pipeline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-27T10:41:18.004428Z","iopub.execute_input":"2021-07-27T10:41:18.00497Z","iopub.status.idle":"2021-07-27T10:41:18.011875Z","shell.execute_reply.started":"2021-07-27T10:41:18.004921Z","shell.execute_reply":"2021-07-27T10:41:18.010983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loading the data from IRIS Data set in a dataframe.  \n### Split the data into X ( Input Variable ) & Y ( Output Varaible ). ","metadata":{}},{"cell_type":"code","source":"df = pandas.read_csv(\"../input/iris-dataset/iris.data.csv\", header=None)\ndset = df.values\nX = dset[:,0:4].astype(float)\nY = dset[:,4]","metadata":{"execution":{"iopub.status.busy":"2021-07-27T10:41:18.013185Z","iopub.execute_input":"2021-07-27T10:41:18.013645Z","iopub.status.idle":"2021-07-27T10:41:18.034348Z","shell.execute_reply.started":"2021-07-27T10:41:18.013607Z","shell.execute_reply":"2021-07-27T10:41:18.033486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### View the shape and size of the data ","metadata":{}},{"cell_type":"code","source":"df.shape, df.size","metadata":{"execution":{"iopub.status.busy":"2021-07-27T10:41:18.036539Z","iopub.execute_input":"2021-07-27T10:41:18.037379Z","iopub.status.idle":"2021-07-27T10:41:18.044224Z","shell.execute_reply.started":"2021-07-27T10:41:18.037336Z","shell.execute_reply":"2021-07-27T10:41:18.04325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### View the data ","metadata":{}},{"cell_type":"code","source":"df.tail()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T10:41:18.046133Z","iopub.execute_input":"2021-07-27T10:41:18.046821Z","iopub.status.idle":"2021-07-27T10:41:18.067512Z","shell.execute_reply.started":"2021-07-27T10:41:18.046764Z","shell.execute_reply":"2021-07-27T10:41:18.066094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Unique values in the target variable ","metadata":{}},{"cell_type":"code","source":"df[4].unique()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T10:41:18.06916Z","iopub.execute_input":"2021-07-27T10:41:18.06947Z","iopub.status.idle":"2021-07-27T10:41:18.085439Z","shell.execute_reply.started":"2021-07-27T10:41:18.06944Z","shell.execute_reply":"2021-07-27T10:41:18.084142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The output variable as you can see contains String values (Categorrical). There are 3 variables\n### We will do a one hot encoding\n\n### encode class values as integers","metadata":{}},{"cell_type":"code","source":"encoder = LabelEncoder()\nencoder.fit(Y)\nencoded_Y = encoder.transform(Y)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T10:41:18.087286Z","iopub.execute_input":"2021-07-27T10:41:18.087768Z","iopub.status.idle":"2021-07-27T10:41:18.096599Z","shell.execute_reply.started":"2021-07-27T10:41:18.087725Z","shell.execute_reply":"2021-07-27T10:41:18.095879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(encoded_Y)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T10:41:18.098291Z","iopub.execute_input":"2021-07-27T10:41:18.098985Z","iopub.status.idle":"2021-07-27T10:41:18.113294Z","shell.execute_reply.started":"2021-07-27T10:41:18.098941Z","shell.execute_reply":"2021-07-27T10:41:18.111515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Convert integers to dummy variables (i.e. one hot encoded)","metadata":{}},{"cell_type":"code","source":"dummy_y = np_utils.to_categorical(encoded_Y)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T10:41:18.117985Z","iopub.execute_input":"2021-07-27T10:41:18.118365Z","iopub.status.idle":"2021-07-27T10:41:18.126166Z","shell.execute_reply.started":"2021-07-27T10:41:18.118332Z","shell.execute_reply":"2021-07-27T10:41:18.124908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dummy_y)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T10:41:18.141051Z","iopub.execute_input":"2021-07-27T10:41:18.141442Z","iopub.status.idle":"2021-07-27T10:41:18.153645Z","shell.execute_reply.started":"2021-07-27T10:41:18.141411Z","shell.execute_reply":"2021-07-27T10:41:18.152744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data is fully ready and we will now define the neural network models \n\n#### - KerasClassifier class in Keras can be used as an Estimator in scikit-learn. The KerasClassifier takes the name of a function as an argument. This function must return the constructed neural network model, ready for training.\n\n#### - Below is a function that will create a baseline neural network for the iris classification problem. It creates a simple fully connected network with 1 hidden layer that contains 16 neurons.\n\n#### - Hidden layer uses a rectifier activation function which is a good practice. Because we used a one-hot encoding for our iris dataset, the output layer must create 3 output values, one for each class. The output value with the largest value will be taken as the class predicted by the model.\n\n#### - Network topology of this basic one-layer neural network is as follows:-\n4 inputs ------> 8 hidden nodes -------> 3 outputs \n\n#### -  “softmax” activation It is often used as the last activation function of a neural network to normalize the output of a network to a probability distribution over predicted output classes. — Wikipedia[link] Very good link on how softmax works https://towardsdatascience.com/softmax-activation-function-how-it-actually-works-d292d335bd78\n\n#### - \"Adam\" is an adaptive learning rate optimizer algorithn “categorical_crossentropy” is an logarithmic loss function more on this https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c\n\n#### - We can also pass arguments in the construction of the KerasClassifier class that will be passed on to the fit() function internally used to train the neural network. Here, we pass the number of epochs as 200 and batch size as 5 to use when training the model. Debugging is also turned off when training by setting verbose to 0.\n\n","metadata":{}},{"cell_type":"code","source":"# define baseline model\ndef baseline_model():\n# create model\n    model = Sequential()\n    model.add(Dense(16, input_dim=4, activation='relu')) # Hidden Layer \n    model.add(Dense(3, activation='softmax')) # Output Layer\n# Compile model\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model\nestimator = KerasClassifier(build_fn=baseline_model, epochs=150, batch_size=5, verbose=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T10:41:18.155545Z","iopub.execute_input":"2021-07-27T10:41:18.155904Z","iopub.status.idle":"2021-07-27T10:41:18.16534Z","shell.execute_reply.started":"2021-07-27T10:41:18.155867Z","shell.execute_reply":"2021-07-27T10:41:18.1644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We can now evaluate the neural network model on our training data.\n\n#### The scikit-learn has excellent capability to evaluate models using a suite of techniques. The gold standard for evaluating machine learning models is k-fold cross validation.\n\n#### First we can define the model evaluation procedure. Here, we set the number of folds to be 10 (an excellent default) and to shuffle the data before partitioning it.\n\n#### Finally evaluate our model (estimator) on our dataset (X and dummy_y) using a 10-fold cross-validation procedure (kfold).","metadata":{}},{"cell_type":"code","source":"kfold = KFold(n_splits=10, shuffle=True)\nresults = cross_val_score(estimator, X, dummy_y, cv=kfold)\nprint(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))","metadata":{"execution":{"iopub.status.busy":"2021-07-27T10:41:18.167202Z","iopub.execute_input":"2021-07-27T10:41:18.167614Z","iopub.status.idle":"2021-07-27T10:41:57.984784Z","shell.execute_reply.started":"2021-07-27T10:41:18.167583Z","shell.execute_reply":"2021-07-27T10:41:57.983631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Performance of the model on unseen data, this is in the known top results available for this problem.\n\n#### Big thanks to Jason Brownlee for inspiring all of us by very easy understandable hands on examples https://machinelearningmastery.com/about/","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}