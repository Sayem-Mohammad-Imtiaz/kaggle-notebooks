{"cells":[{"metadata":{},"cell_type":"markdown","source":"After reviewing a few of the other onion-or-not kernels, I figured I'd try a character based approach. Instead of cleaning the text and tokenizing each word, I tried tokenizing each character, then fed the integer sequences to a CNN to see what results I got. I consistently achieved over 80% accuracy, which is not bad for such a simple approach."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import *\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\nfrom sklearn.model_selection import train_test_split\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/onion-or-not/OnionOrNot.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here we tokenize each character (rather than each word).\ntokenize = Tokenizer(char_level=True)\ntokenize.fit_on_texts(df.text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pad_sequences(tokenize.texts_to_sequences(df.text), maxlen=250, padding=\"post\")\nY = df.label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel = Sequential([\n                   Embedding(len(tokenize.word_index) + 1, 64),\n                   Conv1D(64, 5, activation=\"relu\"),\n                   Conv1D(64, 5, activation=\"relu\"),\n                   GlobalMaxPooling1D(),\n                   Dense(64, activation=\"relu\"),\n                   Dropout(.25),\n                   Dense(16, activation=\"relu\"),\n                   Dropout(.25),\n                   Dense(2, activation=\"softmax\"),\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split data into training and test sets\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.1, random_state=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x_train, y_train, validation_data=([x_test, y_test]), epochs=5, verbose=1)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}