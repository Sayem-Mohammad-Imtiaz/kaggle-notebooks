{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom pandas_profiling import ProfileReport\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import dates as md\nimport seaborn as sns\nimport plotly.graph_objs as go\nimport plotly\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport cufflinks as cf\ncf.set_config_file(offline=True)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport lightgbm as lgb\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_absolute_error\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport statsmodels.tsa.api as smt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_meta = pd.read_csv('/kaggle/input/building-data-genome-project-v1/meta_open.csv')\ndf_meta","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_meta[df_meta['newweatherfilename']=='weather2.csv']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_powerMeter = pd.read_csv('/kaggle/input/building-data-genome-project-v1/temp_open_utc_complete.csv', index_col='timestamp', parse_dates=True)\ndf_powerMeter.index = df_powerMeter.index.tz_localize(None)\ndf_powerMeter = df_powerMeter/df_meta.set_index('uid').loc[df_powerMeter.columns, 'sqm']\ndf_powerMeter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_bldg_site2 = df_meta.loc[df_meta['newweatherfilename']=='weather2.csv', 'uid'].to_list()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_powerMeter_site2 =  df_powerMeter[list_bldg_site2].dropna(how='all')\ndf_powerMeter_site2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_weather2 = pd.read_csv('/kaggle/input/building-data-genome-project-v1/weather2.csv', index_col='timestamp', parse_dates=True)\ndf_weather2 = df_weather2.select_dtypes(['int', 'float'])\n\nfor col in df_weather2.columns:\n    df_weather2.loc[df_weather2[col]<-100, col] = np.nan\n\ndf_weather2 = df_weather2.reset_index().drop_duplicates(subset=['timestamp'])\n\ndf_weather2 = df_weather2.set_index('timestamp').resample('1H').mean()\n#df_weather2 = df_weather2.interpolate('cubicspline')\n\ndf_weather2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_weather2.iplot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_weather2['TemperatureC_movingAvg_3hr'] = df_weather2['TemperatureC'].rolling(3).mean()\ndf_weather2['TemperatureC_movingAvg_6hr'] = df_weather2['TemperatureC'].rolling(6).mean()\ndf_weather2['TemperatureC_movingAvg_12hr'] = df_weather2['TemperatureC'].rolling(12).mean()\ndf_weather2['TemperatureC_movingAvg_24hr'] = df_weather2['TemperatureC'].rolling(24).mean()\ndf_weather2.loc[:, df_weather2.columns.str.contains('TemperatureC')].iplot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_schedule2 = pd.read_csv('/kaggle/input/building-data-genome-project-v1/schedule2.csv', header=None)\ndf_schedule2 = df_schedule2.rename(columns={0:'date',1:'date_type'})\ndf_schedule2['date'] = pd.to_datetime(df_schedule2['date'])\ndf_schedule2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_schedule2_encode = df_schedule2.copy()\ndf_schedule2_encode['date_type'] = LabelEncoder().fit_transform(df_schedule2_encode['date_type'])\ndf_schedule2_encode","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_schedule2_encode.set_index('date').iplot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_holiday = pd.read_html('https://www.timeanddate.com/holidays/us/2015')[0]\ndf_holiday.columns = df_holiday.columns.get_level_values(0)\ndf_holiday = df_holiday.loc[df_holiday['Date'].str.len()<100]\ndf_holiday = df_holiday[['Date', 'Name', 'Type']]\ndf_holiday['Date'] = '2015 ' + df_holiday['Date']\ndf_holiday['Date'] = pd.to_datetime(df_holiday['Date'])\ndf_holiday = df_holiday.rename(columns={'Date':'date'})\n\ndf_holiday = df_holiday.drop_duplicates(subset=['date'])\ndf_holiday = df_holiday.set_index('date').asfreq('D')\n\ndf_holiday.loc[df_holiday.index.weekday>=5, 'Name'] = 'weekend'\ndf_holiday.loc[df_holiday.index.weekday>=5, 'Type'] = 'weekend'\n\ndf_holiday.columns = 'holiday_' + df_holiday.columns\n\ndf_holiday","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_holiday_encode = df_holiday.copy()\ndf_holiday_encode[['holiday_Name', 'holiday_Type']] = df_holiday_encode[['holiday_Name', 'holiday_Type']].astype('str').apply(LabelEncoder().fit_transform)\ndf_holiday_encode","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_holiday_encode.iplot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Regression model"},{"metadata":{},"cell_type":"markdown","source":"## Model 1: Only timestamp features"},{"metadata":{"trusted":true},"cell_type":"code","source":"name_meter = 'Office_Caleb'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare data for modeling\ndf_temp = df_powerMeter_site2[[name_meter]].copy()\ndf_temp = df_temp.dropna()\n\n# Add timestamp features\ndf_temp['weekday'] = df_temp.index.weekday\ndf_temp['hour'] = df_temp.index.hour\ndf_temp['date'] = df_temp.index.date\n\ndf_temp = df_temp.rename(columns={name_meter: 'load_meas'})\n\ndf_temp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Weekly profiles of building energy\ndf_plot = df_temp.copy()\ndf_plot['date'] = pd.to_datetime(df_plot.index.date)\ndf_plot.pivot_table(columns=['weekday','hour'], index='date', values='load_meas').T.plot(figsize=(15,5),color='black',alpha=0.1,legend=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata = df_temp.loc[df_temp.index.month.isin([1,2,3,5,6,7,9,10,11])].copy()\ntestdata = df_temp.loc[df_temp.index.month.isin([4,8,12])].copy()\n\ntrain_labels = traindata['load_meas']\ntest_labels = testdata['load_meas']\n\ntrain_features = traindata.drop(['load_meas', 'date'], axis=1)\ntest_features = testdata.drop(['load_meas', 'date'], axis=1)\n\nLGB_model = lgb.LGBMRegressor()\nLGB_model.fit(train_features, train_labels)\n\ntestdata['load_pred'] = LGB_model.predict(test_features)\ndf_temp.loc[testdata.index, 'load_pred'] = testdata['load_pred']\n\n# Calculate the absolute errors\nerrors = abs(testdata['load_pred'] - test_labels)\n\nRSQUARED = r2_score(testdata.dropna()['load_meas'], testdata.dropna()['load_pred'])\n\nprint(\"R SQUARED: \"+str(round(RSQUARED,3)))\ntestdata[['load_meas', 'load_pred']].iplot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 2: Timestamp features + Weather"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare data for modeling\ndf_temp = df_powerMeter_site2[[name_meter]].copy()\ndf_temp = df_temp.dropna()\n\n# Add timestamp features\ndf_temp['weekday'] = df_temp.index.weekday\ndf_temp['hour'] = df_temp.index.hour\ndf_temp['date'] = df_temp.index.date\n\n# Add weather features\ndf_temp = df_temp.rename(columns={name_meter: 'load_meas'})\ndf_temp = df_temp.merge(df_weather2.loc[:, df_weather2.columns.str.contains('TemperatureC')], left_index=True, right_index=True)\n\ndf_temp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scatter plot for energy consumptions and outdoor temperature\nplt.figure(figsize=(10,10))\ndf_plot = df_temp.copy()\ndf_plot = df_plot.resample('D').mean()\ndf_plot['weekday/weekend'] = 'weekday'\ndf_plot.loc[df_plot['weekday']>4, 'weekday/weekend'] ='weekend'\n\nax = sns.relplot(x=\"TemperatureC\", y=\"load_meas\", col=\"weekday/weekend\",\n                 kind=\"scatter\", data=df_plot, alpha=0.8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata = df_temp.loc[df_temp.index.month.isin([1,2,3,5,6,7,9,10,11])].dropna().copy()\ntestdata = df_temp.loc[df_temp.index.month.isin([4,8,12])].copy()\n\ntrain_labels = traindata['load_meas']\ntest_labels = testdata['load_meas']\n\ntrain_features = traindata.drop(['load_meas', 'date'], axis=1)\ntest_features = testdata.drop(['load_meas', 'date'], axis=1)\n\nLGB_model = lgb.LGBMRegressor()\nLGB_model.fit(train_features, train_labels)\n\ntestdata['load_pred'] = LGB_model.predict(test_features)\ndf_temp.loc[testdata.index, 'load_pred'] = testdata['load_pred']\n\n# Calculate the absolute errors\nerrors = abs(testdata['load_pred'] - test_labels)\n\nRSQUARED = r2_score(testdata.dropna()['load_meas'], testdata.dropna()['load_pred'])\n\nprint(\"R SQUARED: \"+str(round(RSQUARED,3)))\ntestdata[['load_meas', 'load_pred']].iplot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 3: Timestamp features + Weather + Holidays"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare data for modeling\ndf_temp = df_powerMeter_site2[[name_meter]].copy()\ndf_temp = df_temp.dropna()\n\n# Add timestamp features\ndf_temp['weekday'] = df_temp.index.weekday\ndf_temp['hour'] = df_temp.index.hour\ndf_temp['date'] = pd.to_datetime(df_temp.index.date)\n\n# Add weather features\ndf_temp = df_temp.rename(columns={name_meter: 'load_meas'})\ndf_temp = df_temp.merge(df_weather2.loc[:, df_weather2.columns.str.contains('TemperatureC')], left_index=True, right_index=True)\n\n# Add holiday features\nidx_df = df_temp.index.copy()\ndf_temp = df_temp.merge(df_holiday_encode[['holiday_Type']].reset_index(), on='date')\ndf_temp.index = idx_df\n\ndf_temp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata = df_temp.loc[df_temp.index.month.isin([1,2,3,5,6,7,9,10,11])].dropna().copy()\ntestdata = df_temp.loc[df_temp.index.month.isin([4,8,12])].copy()\n\ntrain_labels = traindata['load_meas']\ntest_labels = testdata['load_meas']\n\ntrain_features = traindata.drop(['load_meas', 'date'], axis=1)\ntest_features = testdata.drop(['load_meas', 'date'], axis=1)\n\nLGB_model = lgb.LGBMRegressor()\nLGB_model.fit(train_features, train_labels)\n\ntestdata['load_pred'] = LGB_model.predict(test_features)\ndf_temp.loc[testdata.index, 'load_pred'] = testdata['load_pred']\n\n# Calculate the absolute errors\nerrors = abs(testdata['load_pred'] - test_labels)\n\nRSQUARED = r2_score(testdata.dropna()['load_meas'], testdata.dropna()['load_pred'])\n\nprint(\"R SQUARED: \"+str(round(RSQUARED,3)))\ntestdata[['load_meas', 'load_pred']].iplot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 4: Timestamp features + Weather + Schedule"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare data for modeling\ndf_temp = df_powerMeter_site2[[name_meter]].copy()\ndf_temp = df_temp.dropna()\n\n# Add timestamp features\ndf_temp['weekday'] = df_temp.index.weekday\ndf_temp['hour'] = df_temp.index.hour\ndf_temp['date'] = pd.to_datetime(df_temp.index.date)\n\n# Add weather features\ndf_temp = df_temp.rename(columns={name_meter: 'load_meas'})\ndf_temp = df_temp.merge(df_weather2.loc[:, df_weather2.columns.str.contains('TemperatureC')], left_index=True, right_index=True)\n\n# Add schedule features\nidx_df = df_temp.index.copy()\ndf_temp = df_temp.merge(df_schedule2_encode, on='date')\ndf_temp.index = idx_df\n\ndf_temp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata = df_temp.loc[df_temp.index.month.isin([1,2,3,5,6,7,9,10,11])].dropna().copy()\ntestdata = df_temp.loc[df_temp.index.month.isin([4,8,12])].copy()\n\ntrain_labels = traindata['load_meas']\ntest_labels = testdata['load_meas']\n\ntrain_features = traindata.drop(['load_meas', 'date'], axis=1)\ntest_features = testdata.drop(['load_meas', 'date'], axis=1)\n\nLGB_model = lgb.LGBMRegressor()\nLGB_model.fit(train_features, train_labels)\n\ntestdata['load_pred'] = LGB_model.predict(test_features)\ndf_temp.loc[testdata.index, 'load_pred'] = testdata['load_pred']\n\n# Calculate the absolute errors\nerrors = abs(testdata['load_pred'] - test_labels)\n\nRSQUARED = r2_score(testdata.dropna()['load_meas'], testdata.dropna()['load_pred'])\n\nprint(\"R SQUARED: \"+str(round(RSQUARED,3)))\ntestdata[['load_meas', 'load_pred']].iplot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 5: Timestamp features + Weather + Schedule + Lag feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare data for modeling\ndf_temp = df_powerMeter_site2[[name_meter]].copy()\ndf_temp = df_temp.dropna()\n\n# Add timestamp features\ndf_temp['weekday'] = df_temp.index.weekday\ndf_temp['hour'] = df_temp.index.hour\ndf_temp['date'] = pd.to_datetime(df_temp.index.date)\n\n# Add weather features\ndf_temp = df_temp.rename(columns={name_meter: 'load_meas'})\ndf_temp = df_temp.merge(df_weather2.loc[:, df_weather2.columns.str.contains('TemperatureC')], left_index=True, right_index=True)\n\n# Add holiday features\nidx_df = df_temp.index.copy()\ndf_temp = df_temp.merge(df_schedule2_encode, on='date')\ndf_temp.index = idx_df\n\n# Add lag features\ndf_temp['load_shift_24hrs'] = df_temp['load_meas'].shift(24)\n\ndf_temp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,8))\n\nax1 = fig.add_subplot(211)\nfig = sm.graphics.tsa.plot_acf(df_temp['load_meas'], lags=24*7, ax=ax1)\nax1.xaxis.set_ticks_position('bottom')\nfig.tight_layout();\n\nax2 = fig.add_subplot(212)\nfig = sm.graphics.tsa.plot_pacf(df_temp['load_meas'], lags=24*7, ax=ax2)\nax2.xaxis.set_ticks_position('bottom')\nfig.tight_layout();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata = df_temp.loc[df_temp.index.month.isin([1,2,3,5,6,7,9,10,11])].dropna().copy()\ntestdata = df_temp.loc[df_temp.index.month.isin([4,8,12])].copy()\n\ntrain_labels = traindata['load_meas']\ntest_labels = testdata['load_meas']\n\ntrain_features = traindata.drop(['load_meas', 'date'], axis=1)\ntest_features = testdata.drop(['load_meas', 'date'], axis=1)\n\nLGB_model = lgb.LGBMRegressor()\nLGB_model.fit(train_features, train_labels)\n\ntestdata['load_pred'] = LGB_model.predict(test_features)\ndf_temp.loc[testdata.index, 'load_pred'] = testdata['load_pred']\n\n# Calculate the absolute errors\nerrors = abs(testdata['load_pred'] - test_labels)\n\nRSQUARED = r2_score(testdata.dropna()['load_meas'], testdata.dropna()['load_pred'])\n\nprint(\"R SQUARED: \"+str(round(RSQUARED,3)))\ntestdata[['load_meas', 'load_pred']].iplot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building 88 energy models (Timestamp features + Weather + Schedule + Lag feature)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_powerMeter_unnormalized = pd.read_csv('/kaggle/input/building-data-genome-project-v1/temp_open_utc_complete.csv', index_col='timestamp', parse_dates=True)\ndf_powerMeter_unnormalized.index = df_powerMeter.index.tz_localize(None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_model_prediction = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name_meter in list_bldg_site2:\n    print(name_meter)\n\n    # Prepare data for modeling\n    df_temp = df_powerMeter_unnormalized[[name_meter]].copy()\n    df_temp = df_temp.dropna()\n\n    # Add timestamp features\n    df_temp['weekday'] = df_temp.index.weekday\n    df_temp['hour'] = df_temp.index.hour\n    df_temp['date'] = pd.to_datetime(df_temp.index.date)\n\n    # Add weather features\n    df_temp = df_temp.rename(columns={name_meter: 'load_meas'})\n    df_temp = df_temp.merge(df_weather2.loc[:, df_weather2.columns.str.contains('TemperatureC')], left_index=True, right_index=True)\n\n    # Add holiday features\n    idx_df = df_temp.index.copy()\n    df_temp = df_temp.merge(df_schedule2_encode, on='date')\n    df_temp.index = idx_df\n\n    # Add lag features\n    df_temp['load_shift_24hrs'] = df_temp['load_meas'].shift(24)\n\n    # Split data for train and test\n    traindata = df_temp.loc[df_temp.index.month.isin([1,2,3,5,6,7,9,10,11])].dropna().copy()\n    testdata = df_temp.loc[df_temp.index.month.isin([4,8,12])].copy()\n\n    train_labels = traindata['load_meas']\n    test_labels = testdata['load_meas']\n\n    train_features = traindata.drop(['load_meas', 'date'], axis=1)\n    test_features = testdata.drop(['load_meas', 'date'], axis=1)\n\n    LGB_model = lgb.LGBMRegressor()\n    LGB_model.fit(train_features, train_labels)\n\n    testdata['load_pred'] = LGB_model.predict(test_features)\n    df_temp.loc[testdata.index, 'load_pred'] = testdata['load_pred']\n\n    # Calculate the absolute errors\n    errors = abs(testdata['load_pred'] - test_labels)\n\n    RSQUARED = r2_score(testdata.dropna()['load_meas'], testdata.dropna()['load_pred'])\n    MAPE = errors/test_labels\n    MAPE = MAPE.loc[MAPE!=np.inf]\n    MAPE = MAPE.loc[MAPE!=-np.inf]\n    MAPE = MAPE.dropna().mean()*100\n\n    print(\"R SQUARED: \"+str(round(RSQUARED,3)))\n    print(\"MAPE: \"+str(round(MAPE,1))+'%')\n    testdata[['load_meas', 'load_pred']].reset_index(drop=True).plot(figsize=(15,3), title=name_meter);plt.show()\n\n    testdata['uid'] = name_meter\n    testdata['RSQUARED'] = RSQUARED\n    testdata['MAPE'] = MAPE\n\n    df_model_prediction = pd.concat([df_model_prediction, testdata[['load_meas', 'load_pred', 'uid','RSQUARED','MAPE']].reset_index()], ignore_index=True, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_model_prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_model_prediction.to_pickle('df_model_prediction.pickle.gz', compression='gzip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}