{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **一个完整的模型**"},{"metadata":{},"cell_type":"markdown","source":"以Titanic为例，建立一个完整的机器学习模型。模型的建立流程包括：\n* 软件包和数据加载\n* EDA\n  * 数据检查\n  * 处理缺失数据\n  * 无关信息和冗余信息\n  * 非数值数据处理\n* 数据可视化\n* 特征值工程\n* 机器学习模型\n\n"},{"metadata":{},"cell_type":"markdown","source":"# **软件包和数据加载**"},{"metadata":{},"cell_type":"markdown","source":"加载软件包和数据。"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# data visualization\nimport seaborn as sns\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nfrom matplotlib import style\n\n# ML algorithms;\n# Algorithms\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.naive_bayes import GaussianNB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get train/test data\n# Notice that train and test have same columns EXCEPT survial;\ntitanic_train = pd.read_csv('/kaggle/input/titanic-machine-learning-from-disaster/train.csv')\ntitanic_test = pd.read_csv('/kaggle/input/titanic-machine-learning-from-disaster/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **数据检查**"},{"metadata":{},"cell_type":"markdown","source":"检查数据的基本信息和统计信息。"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"titanic_train.head(10)\ntitanic_test.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Size of train data\ntitanic_train.shape\n\n# Summary of numeric features; the count will tell if there are missing values;\ntitanic_train.describe()\n\n# Info;\ntitanic_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **处理缺失数据**"},{"metadata":{},"cell_type":"markdown","source":"以下是一个检查 DataFrame 的数据缺失的函数，用以检查训练数据和测试数据的缺失情况。可以看到，'Age', 'Cabin', 'Fare' 都有数据缺失。"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to check the missing percent of a DatFrame;\ndef check_missing_data(df):\n    total = df.isnull().sum().sort_values(ascending = False)\n    percent = round(df.isnull().sum().sort_values(ascending = False) * 100 /len(df),2)\n    return pd.concat([total, percent], axis=1, keys=['Total','Percent'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets check train and test data;\ncheck_missing_data(titanic_train)\ncheck_missing_data(titanic_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"一个简单的处理缺失数据的方式，就是用0和1填补 'Cabin'的缺失数据。因为Cabin本身的字符没有意义，所以在 Cabin缺失的位置填0，并且用1替代Cabin的原有非空字符。"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Missing data: Cabin has high rate of missing data; insted of deleting the column,\n# I will give 1 if Cabin is not null; otherwise 0;\ntitanic_train['Cabin']=np.where(titanic_train['Cabin'].isnull(),0,1)\ntitanic_test['Cabin']=np.where(titanic_test['Cabin'].isnull(),0,1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"对于 'Age', 'Fare', 用对应列的平均值填补缺失的数据。而对于 'Embarked'，用相应列中出现最多的字符来代替缺失的值，这通过 dataframe 的函数 data['Embarked'].mode() 来实现。"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combine train and test data, fill the missing values;\ndataset = [titanic_train, titanic_test]\n\n# def missing_data(x):\nfor data in dataset:\n    #complete missing age with median\n    data['Age'].fillna(data['Age'].mean(), inplace = True)\n\n    #complete missing Embarked with Mode\n    data['Embarked'].fillna(data['Embarked'].mode()[0], inplace = True)\n\n        #complete missing Fare with median\n    data['Fare'].fillna(data['Fare'].mean(), inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"缺失数据经过处理以后，再次确认titanic_train已没有缺失数据，并检查 titanic_train 的最初几行。"},{"metadata":{"trusted":true},"cell_type":"code","source":"check_missing_data(titanic_train)\ncheck_missing_data(titanic_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **无关信息和冗余信息**"},{"metadata":{},"cell_type":"markdown","source":"在之后的练习中，我们将利用训练数据中的信息预测测设数据中的生存状况（即 Survived）。而根据经验，我们相信 'Name', 'Ticket'的信息对生存没有影响。因此将这两列从数据中删除。"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Delete the irrelavent columns: Name, Ticket (which is ticket code)\ndrop_column = ['Name','Ticket']\ntitanic_train.drop(drop_column, axis= 1, inplace = True)\ntitanic_test.drop(drop_column,axis = 1,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **非数值变量的处理**"},{"metadata":{},"cell_type":"markdown","source":"数据中的'Sex'仍然是字符串类型，我们需要将其转化为数值变量。以下的代码中，我们将 'male'用0取代， 'female'用1取代。"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data = [titanic_train, titanic_test]\n\n# Convert ‘Sex’ feature into numeric.\ngenders = {\"male\": 0, \"female\": 1}\n\nfor dataset in all_data:\n    dataset['Sex'] = dataset['Sex'].map(genders)\ntitanic_train['Sex'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **数据可视化**"},{"metadata":{},"cell_type":"markdown","source":"\nSeaborn library 是一个流行作图工具。这里以它为例作图，直观地分析数据中的每个特征值和目标（survived）关系。\n\n以下的图形包括：\n*     Survived vs. non-survied\n*     Cabin vs. survived\n*     Sex vs. survived\n*     Pclass vs. survived\n*     Parch vs. survived\n*     SibSp vs. survived"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function of drawing graph;\ndef draw(graph):\n    for p in graph.patches:\n        height = p.get_height()\n        graph.text(p.get_x()+p.get_width()/2., height + 5,height ,ha= \"center\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Draw survided vs. non-survived;\nsns.set(style=\"darkgrid\")\nplt.figure(figsize = (8, 5))\ngraph= sns.countplot(x='Survived', hue=\"Survived\", data=titanic_train)\ndraw(graph)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cabin and survived;\nsns.set(style=\"darkgrid\")\nplt.figure(figsize = (8, 5))\ngraph  = sns.countplot(x =\"Cabin\", hue =\"Survived\", data = titanic_train)\ndraw(graph)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sex and survied;\nplt.figure(figsize = (8, 5))\ngraph  = sns.countplot(x =\"Sex\", hue =\"Survived\", data = titanic_train)\ndraw(graph)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pclass and survied\nplt.figure(figsize = (8, 5))\ngraph  = sns.countplot(x =\"Pclass\", hue =\"Survived\", data = titanic_train)\ndraw(graph)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Embarked and survied\nplt.figure(figsize = (8, 5))\ngraph  = sns.countplot(x =\"Embarked\", hue =\"Survived\", data = titanic_train)\ndraw(graph)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"从'Embarked' 的图中可以看到，'Embarked' 对 'Survived' 没有太大影响，我们认为这一列是不重要的信息，将这一列从数据中删除。"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We think embaked is not important, so drop it;\ndrop_column = ['Embarked']\ntitanic_train.drop(drop_column, axis=1, inplace = True)\ntitanic_test.drop(drop_column,axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Parch vs survied\nplt.figure(figsize = (8, 5))\ngraph  = sns.countplot(x =\"Parch\", hue =\"Survived\", data = titanic_train)\ndraw(graph)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SibSp vs survied\nplt.figure(figsize = (8, 5))\ngraph  = sns.countplot(x =\"SibSp\", hue =\"Survived\", data = titanic_train)\ndraw(graph)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **特征值工程**"},{"metadata":{},"cell_type":"markdown","source":"根据日常经验，我们猜测 SibSp 和 Parch 的组合，也就是家庭成员，可能会提供额外的有用信息。首先作图提供直观的信息。"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combine SibSp and Parch as new feature; \n# Combne train test first;\nall_data=[titanic_train,titanic_test]\n\nfor dataset in all_data:\n    dataset['Family'] = dataset['SibSp'] + dataset['Parch'] + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Family vs survied\nplt.figure(figsize = (8, 5))\ngraph  = sns.countplot(x =\"Family\", hue =\"Survived\", data = titanic_train)\ndraw(graph)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"将年龄分段，取代原来的连续的年龄值。"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create bins of ages and check ages vs survived;\n# Notice that different bins can be used;\n# Add new column in all_data;\nfor dataset in all_data:\n    dataset['Age_cat'] = pd.cut(dataset['Age'], bins=[0,12,20,40,120], labels=['Children','Teenage','Adult','Elder'])\n    \nplt.figure(figsize = (8, 5))\nsns.barplot(x='Age_cat', y='Survived', data=titanic_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (8, 5))\nag = sns.countplot(x='Age_cat', hue='Survived', data=titanic_train)\ndraw(ag)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"将票价分段，取代原来连续的票价。"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check fare vs survived;\n# Create categorical of fare to plot fare vs Pclass first;\nfor dataset in all_data:\n    dataset['Fare_cat'] = pd.cut(dataset['Fare'], bins=[0,10,50,100,550], labels=['Low_fare','median_fare','Average_fare','high_fare'])\nplt.figure(figsize = (8, 5))\nag = sns.countplot(x='Pclass', hue='Fare_cat', data=titanic_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fare vs survived;\nsns.barplot(x='Fare_cat', y='Survived', data=titanic_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"根据以上的年龄分段图形，我们决定用下面的年龄分段方法。"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use bin to convert ages to bins;\nfor dataset in all_data:\n    dataset['Age'] = dataset['Age'].astype(int)\n    dataset.loc[ dataset['Age'] <= 15, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 15) & (dataset['Age'] <= 20), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 20) & (dataset['Age'] <= 26), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 26) & (dataset['Age'] <= 28), 'Age'] = 3\n    dataset.loc[(dataset['Age'] > 28) & (dataset['Age'] <= 35), 'Age'] = 4\n    dataset.loc[(dataset['Age'] > 35) & (dataset['Age'] <= 45), 'Age'] = 5\n    dataset.loc[ dataset['Age'] > 45, 'Age'] = 6\ntitanic_train['Age'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"综合以上关于特征值的分析，以下的特征值被认为是不重要的，因此从数据中删除。"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove features that are not sued, combined, etc\nfor dataset in all_data:\n    drop_column = ['Age_cat','Fare','SibSp','Parch','Fare_cat','PassengerId']\n    dataset.drop(drop_column, axis=1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"查看保留下来的特征值。"},{"metadata":{"trusted":true},"cell_type":"code","source":"titanic_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **特征值相关性**"},{"metadata":{},"cell_type":"markdown","source":"特征值的相关性有助于分析数据中是否存在冗余信息。从相关系数矩阵中，我们没有发现冗余信息。"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation;\ncorr=titanic_train.corr()#['Survived']\n\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nplt.subplots(figsize = (12,8))\nsns.heatmap(corr, \n            annot=True,\n            mask = mask,\n            cmap = 'RdBu',\n            linewidths=.9, \n            linecolor='white',\n            vmax = 0.3,\n            fmt='.2f',\n            center = 0,\n            square=True)\nplt.title(\"Correlations Matrix\", y = 1,fontsize = 20, pad = 20);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **机器预测模型**"},{"metadata":{},"cell_type":"markdown","source":"在运行机器学习模型之前，首先需要将训练数据中的特征值和标签分离：训练数据中的列'Survived'是标签，其他列都是特征值。将特征值存于X-train，标签存于y_train。\n\n选择测试数据。值得注意的是在测试数据中没有标签列'Survived'，其他列和训练数据相同。模型的目的是要预测测试数据的标签"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Re-organize the data; keep the columns with useful features;\ninput_cols = ['Pclass',\"Sex\",\"Age\",\"Cabin\",\"Family\"]\noutput_cols = [\"Survived\"]\nX_train = titanic_train[input_cols]\ny_train = titanic_train[output_cols]\n\nX_test = titanic_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"通常，调用scikit 的机器学习模型包括以下标准步骤：\n\n* 建立模型架构，并设定所用的参数\n* 使用模型架构拟合训练数据，得到最终的模型\n* 使用模型预测测试数据的标签，并计算性能指标\n\n下面的例子中，对同样的训练和测试数据调用不同的模型。"},{"metadata":{},"cell_type":"markdown","source":"1. Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic regression;\n\nmodel = LogisticRegression()\nmodel.fit(X_train,y_train)\ny_pred_lr=model.predict(X_test)\nmodel.score(X_train,y_train)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"对以上的 Logistic Regression 模型使用5折交叉验证，并显示每一次验证的结果。"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.model_selection import cross_val_score\n-cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. K-Nearest Neighbor"},{"metadata":{"trusted":true},"cell_type":"code","source":"# KNN\nmodel = KNeighborsClassifier(n_neighbors = 3) \nmodel.fit(X_train, y_train)  \ny_pred_knn = model .predict(X_test)  \nmodel.score(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. Gaussian Naive Bayesian"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gaussian naive bayesian\nfrom sklearn.naive_bayes import GaussianNB\nmodel= GaussianNB()\nmodel.fit(X_train,y_train)\ny_pred_gnb=model.predict(X_test) \nmodel.score(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4. Support Vector Machines"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Linear SVM\nmodel  = LinearSVC()\nmodel.fit(X_train, y_train)\n\ny_pred_svc = model.predict(X_test)\nmodel.score(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5. Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random forest\nmodel  = RandomForestClassifier(n_estimators=100)\nmodel.fit(X_train, y_train)\n\ny_pred_rf = model.predict(X_test)\nmodel.score(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"6. Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision tree\nmodel = DecisionTreeClassifier() \nmodel.fit(X_train, y_train)\ny_pred_dt = model.predict(X_test) \nmodel.score(X_train,y_train)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}