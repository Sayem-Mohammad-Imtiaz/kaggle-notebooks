{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Classification\nIn this project, you will use a [dataset from Kaggle](https://www.kaggle.com/andrewmvd/heart-failure-clinical-data) to predict the survival of patients with heart failure from serum creatinine and ejection fraction, and other factors such as age, anemia, diabetes, and so on.\n\nCardiovascular diseases (CVDs) are the number 1 cause of death globally, taking an estimated 17.9 million lives each year, which accounts for 31% of all deaths worldwide. Heart failure is a common event caused by CVDs, and this dataset contains 12 features that can be used to predict mortality by heart failure.\n\nMost cardiovascular diseases can be prevented by addressing behavioral risk factors such as tobacco use, unhealthy diet and obesity, physical inactivity, and harmful alcohol use using population-wide strategies.\n\nPeople with cardiovascular disease or who are at high cardiovascular risk (due to the presence of one or more risk factors such as hypertension, diabetes, hyperlipidemia, or already established disease) need early detection and management wherein a machine learning model can be of great help."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os\n\nfrom collections import Counter\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, InputLayer\nfrom tensorflow.keras.utils import to_categorical\n\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import classification_report\n\nimport numpy as np\n\nfrom matplotlib import pyplot as plt\n\nfrom collections import Counter","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading the data\nUsing `pandas.read_csv()`, load the data from **heart_failure.csv** to a pandas DataFrame object. Assign the resulting DataFrame to a variable called `data`."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use the `DataFrame.info()` method to print all the columns and their types of the DataFrame instance data."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Print the distribution of the `DEATH_EVENT` column in the data DataFrame class using `collections.Counter`. This is the column you will need to predict."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Counter(data['DEATH_EVENT']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Extract the label column `DEATH_EVENT` from the data DataFrame and assign the result to a variable called `y`."},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data['DEATH_EVENT']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Extract the features columns `['age','anaemia','creatinine_phosphokinase','diabetes','ejection_fraction','high_blood_pressure','platelets','serum_creatinine','serum_sodium','sex','smoking','time']` from the DataFrame instance data and assign the result to a variable called `x`."},{"metadata":{"trusted":true},"cell_type":"code","source":"x = data.iloc[:, :-1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data preprocessing\nUse the `pandas.get_dummies()` function to convert the categorical features in the DataFrame instance `x` to one-hot encoding vectors and assign the result back to variable  `x`."},{"metadata":{"trusted":true},"cell_type":"code","source":"x = pd.get_dummies(x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use the `sklearn.model_selection.train_test_split()` method to split the data into training features, test features, training labels, and test labels, respectively. To the `test_size` parameter assign the percentage of data you wish to put in the test data, and use any value for the  `random_state` parameter. Store the results of the function to `X_train`, `X_test`, `Y_train`, `Y_test` variables, making sure you use this order."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state= 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Initialize a `ColumnTransformer` object by using `StandardScaler` to scale the numeric features in the dataset: `['age','creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine','serum_sodium','time']`. Assign the resulting object to a variable called `ct`."},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_columns = x.columns\nct = ColumnTransformer([(\"only numeric\", StandardScaler(), numerical_columns)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use the `ColumnTransformer.fit_transform()` function to train the scaler instance `ct` on the training data `X_train` and assign the result back to `X_train`. Do the same for `x_test`"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = ct.fit_transform(x_train)\nx_test = ct.fit_transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prepare labels for classification\nInitialize an instance of `LabelEncoder` and assign it to a variable called `le`."},{"metadata":{"trusted":true},"cell_type":"code","source":"le =LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using the `LabelEncoder.fit_transform()` function, fit the encoder instance `le` to the training labels `Y_train`, while at the same time converting the training labels according to the trained encoder.\n\nUsing the `LabelEncoder.transform()` function, encode the test labels `Y_test` using the trained encoder `le`."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = le.fit_transform(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = le.transform(y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using the `tensorflow.keras.utils.to_categorical()` function, transform the encoded training labels `Y_train` into a binary vector and assign the result back to `Y_train`. Do the same for y_test"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = to_categorical(y_train)\ny_test = to_categorical(y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Design the model\nInitialize a `tensorflow.keras.models.Sequential` model instance called `model`."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create an input layer instance of `tensorflow.keras.layers.InputLayer` and add it to the model instance model using the `Model.add()` function.\n\nCreate a hidden layer instance of `tensorflow.keras.layers.Dense` with `relu` activation function and 12 hidden neurons, and add it to the model instance `model`.\n\nCreate an output layer instance of `tensorflow.keras.layers.Dense` with a `softmax` activation function (because of classification) with the number of neurons corresponding to the number of classes in the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"shape = x_train.shape\n\nmodel.add(InputLayer(input_shape = shape))\nmodel.add(Dense(64, activation = 'relu'))\nmodel.add(Dense(2, activation = 'softmax'))\n\nmodel.build()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using the `Model.compile()` function, compile the model instance model using the `categorical_crossentropy` loss, `adam` optimizer and `accuracy` as metrics."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train and evaluate the model\nUsing the `Model.fit()` function, fit the model instance model to the training data `X_train` and training labels `Y_train`. Set the number of `epochs` to  `100` and the `batch_size` parameter to `16`."},{"metadata":{"trusted":true},"cell_type":"code","source":"history1 = model.fit(x_train, y_train, epochs=200, batch_size=16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.interpolate import make_interp_spline\nloss = history1.history['loss']\naccuracy = history1.history['accuracy']\n\nfig, (ax1, ax2) = plt.subplots(1, 2,  figsize=(15,5))\n\n#loss plot\nax1.plot(loss, c = 'orange')\nax1.set_xlabel('# epochs')\nax1.set_ylabel('loss')\n\n#accuracy plot\nax2.plot(accuracy)\nax2.set_xlabel('# epochs')\nax2.set_ylabel('accuracy')\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using the `Model.evaluate()` function, evaluate the trained model instance model on the test data `X_test` and test labels `Y_test`. Assign the result to a variable called `loss` (representing the final loss value) and a variable called `acc` (representing the accuracy metrics), respectively."},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, acc = model.evaluate(x_test, y_test, verbose =0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use the `Model.predict()` to get the predictions for the test data `X_test` with the trained model instance model. Assign the result to a variable called `y_estimate`."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_estimate = model.predict(x_test)\ny_estimate = np.argmax(y_estimate, axis=1)\ny_true = np.argmax(y_test, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Print additional metrics, such as `F1-score`, using the `sklearn.metrics.classification_report()` function by providing it with `y_true` and `y_estimate` vectors as input parameters."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_true, y_estimate))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}