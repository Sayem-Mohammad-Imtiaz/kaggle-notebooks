{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Predicting Drug/Paitent fit with Naive Bayes.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.naive_bayes import ComplementNB, MultinomialNB, GaussianNB, CategoricalNB\nfrom sklearn.metrics import f1_score, precision_score, recall_score\nfrom sklearn.model_selection import cross_validate","metadata":{"execution":{"iopub.status.busy":"2021-07-05T20:26:46.776548Z","iopub.execute_input":"2021-07-05T20:26:46.776993Z","iopub.status.idle":"2021-07-05T20:26:47.977264Z","shell.execute_reply.started":"2021-07-05T20:26:46.776898Z","shell.execute_reply":"2021-07-05T20:26:47.976169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import data from ETL pipeline...\nx_train = pd.read_csv('../input/drug-classification-etl/Fact_imb_train_features.csv', index_col = 0, squeeze = True)\ny_train = pd.read_csv('../input/drug-classification-etl/Fact_imb_train_labels.csv', index_col = 0, squeeze = True)\n\nx_test = pd.read_csv('../input/drug-classification-etl/Fact_imb_test_features.csv', index_col = 0, squeeze = True)\ny_test = pd.read_csv('../input/drug-classification-etl/Fact_imb_test_labels.csv', index_col = 0, squeeze = True)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T20:26:47.979067Z","iopub.execute_input":"2021-07-05T20:26:47.97938Z","iopub.status.idle":"2021-07-05T20:26:48.034602Z","shell.execute_reply.started":"2021-07-05T20:26:47.979347Z","shell.execute_reply":"2021-07-05T20:26:48.033548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_baseline_model(train, labels, model):\n    mdl = model()\n    mdl.fit(train, labels)\n    \n    return mdl\n\n# Get a baseline for modeling.\n\n# ComplementNB\ncmp_bl_mdl = train_baseline_model(x_train, y_train, ComplementNB)\nprint(f'ComplementNB = {cmp_bl_mdl.score(x_test,y_test)}') # 68%\n\n# MultinomialNB\nmul_bl_md2 = train_baseline_model(x_train, y_train, MultinomialNB)\nprint(f'MultinomialNB = {mul_bl_md2.score(x_test,y_test)}') # 65%\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-05T20:26:48.036888Z","iopub.execute_input":"2021-07-05T20:26:48.037328Z","iopub.status.idle":"2021-07-05T20:26:48.060472Z","shell.execute_reply.started":"2021-07-05T20:26:48.03728Z","shell.execute_reply":"2021-07-05T20:26:48.059288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Resampling\n\n*** This work was moved to the ETL ***\n\nThe classes are very imbalanced. This will lead to overfitting on the majority class if we tried to model this data as is. To combat this, we employ a technique to resample the classes. We will try NearMiss in order to avoid the consiquences of significant data loss.\n\n*** Balanced Facts are found in the ETL output. ***","metadata":{"execution":{"iopub.status.busy":"2021-07-04T20:14:46.495961Z","iopub.execute_input":"2021-07-04T20:14:46.496351Z","iopub.status.idle":"2021-07-04T20:14:46.506589Z","shell.execute_reply.started":"2021-07-04T20:14:46.49632Z","shell.execute_reply":"2021-07-04T20:14:46.504995Z"}}},{"cell_type":"code","source":"# read in the balanced Facts.\n\nx_train_resampled = pd.read_csv('../input/drug-classification-etl/Fact_resampled_train_features.csv', index_col = 0, squeeze = True)\ny_train_resampled = pd.read_csv('../input/drug-classification-etl/Fact_resampled_train_labels.csv', index_col = 0, squeeze = True)","metadata":{"execution":{"iopub.status.busy":"2021-07-05T20:26:48.062033Z","iopub.execute_input":"2021-07-05T20:26:48.062301Z","iopub.status.idle":"2021-07-05T20:26:48.0849Z","shell.execute_reply.started":"2021-07-05T20:26:48.062274Z","shell.execute_reply":"2021-07-05T20:26:48.08391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"re_comp_md = train_baseline_model(x_train_resampled, y_train_resampled, ComplementNB)\nprint(f'ComplementNB = {re_comp_md.score(x_test,y_test)}')\n\nre_mul_md = train_baseline_model(x_train_resampled, y_train_resampled, MultinomialNB)\nprint(f'MultinomialNB = {re_mul_md.score(x_test,y_test)}')\n\nGau_md = train_baseline_model(x_train_resampled, y_train_resampled, GaussianNB)\nprint(f'GaussianNB = {Gau_md.score(x_test,y_test)}')","metadata":{"execution":{"iopub.status.busy":"2021-07-05T20:26:48.086064Z","iopub.execute_input":"2021-07-05T20:26:48.086509Z","iopub.status.idle":"2021-07-05T20:26:48.10638Z","shell.execute_reply.started":"2021-07-05T20:26:48.086478Z","shell.execute_reply":"2021-07-05T20:26:48.105579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The accuracy of the Complement NB model dropped slightly, while the Multinomial model rose.GaussianNB is highest at 89%. Still the accuracy is not great for any of the Naive Bayes models. Lets run K-Fold crossvalidation to ensure the model is not overfitting.","metadata":{}},{"cell_type":"code","source":"def cross_val(model, x_train, y_train, folds=10):\n    scoring = {'acc': 'accuracy',\n           'prec_micro': 'precision_micro',\n           'rec_micro': 'recall_micro'}\n    scores = cross_validate(model, x_train, y_train, scoring=scoring,\n                         cv=folds, return_train_score=True)\n    return scores","metadata":{"execution":{"iopub.status.busy":"2021-07-05T20:26:48.10744Z","iopub.execute_input":"2021-07-05T20:26:48.107816Z","iopub.status.idle":"2021-07-05T20:26:48.112399Z","shell.execute_reply.started":"2021-07-05T20:26:48.107788Z","shell.execute_reply":"2021-07-05T20:26:48.11127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gas_cv_res = cross_val(Gau_md, x_test, y_test, 4)\n\ndisplay(gas_cv_res['test_acc'].mean())\ndisplay(gas_cv_res['test_prec_micro'].mean())\ndisplay(gas_cv_res['test_rec_micro'].mean())","metadata":{"execution":{"iopub.status.busy":"2021-07-05T20:26:48.113833Z","iopub.execute_input":"2021-07-05T20:26:48.114411Z","iopub.status.idle":"2021-07-05T20:26:48.192321Z","shell.execute_reply.started":"2021-07-05T20:26:48.114367Z","shell.execute_reply":"2021-07-05T20:26:48.191229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gau_preds = Gau_md.predict(x_test)\n\ndisplay(f1_score(y_test, gau_preds, average='micro'))\n\ndisplay(precision_score(y_test, gau_preds, average='micro'))\n\ndisplay(recall_score(y_test, gau_preds, average='micro'))","metadata":{"execution":{"iopub.status.busy":"2021-07-05T20:26:48.193741Z","iopub.execute_input":"2021-07-05T20:26:48.194065Z","iopub.status.idle":"2021-07-05T20:26:48.208998Z","shell.execute_reply.started":"2021-07-05T20:26:48.194035Z","shell.execute_reply":"2021-07-05T20:26:48.208107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusions:\n\nNaive Bayes is not the best model for this data. Out of all of the Naieve Bayes models, Gaussian Naive Bayes performs the best with a F1 of 89%. It is important to remember that the imbalance in the data set must be accounted for... I believe that this work will serve as a decent baseline for the rest of the modeling. ","metadata":{"execution":{"iopub.status.busy":"2021-07-05T00:09:47.899602Z","iopub.execute_input":"2021-07-05T00:09:47.900033Z","iopub.status.idle":"2021-07-05T00:09:47.905604Z","shell.execute_reply.started":"2021-07-05T00:09:47.899998Z","shell.execute_reply":"2021-07-05T00:09:47.904799Z"}}}]}