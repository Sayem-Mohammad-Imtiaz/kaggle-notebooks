{"cells":[{"metadata":{"_uuid":"6f48c282806bc5daa7d48d439b3d25ea4533e83f"},"cell_type":"markdown","source":"**INTRODUCTION**\n\nIn th's project, we'll try to understand and exercise the RNN (Recurrent Neural Network). I decided to use 'International Airline Passengers' dataset for this workout. You'll see:\n* Data Loading and Reading\n* Data Preprocessing (Scaling, Train-Test Datas Split, Reshaping)\n* RNN with Keras\n* Predictions and Visualizations\n* Conclusion\n\nin this project."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport math\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#Firstly, read data from csv file.\ndataset = pd.read_csv('../input/international-airline-passengers.csv',skipfooter=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d6727fcfbd0223353178d25a53039b9780219693"},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f9c2d97b0cf0854827bed2ae69f8d545716f3fb"},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"431318752555cffc802a6fd5c2558f8d4cee98eb"},"cell_type":"code","source":"dataset.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6dc24c5abb46a2739b82f3034c54cf9e06de074a"},"cell_type":"code","source":"dataset.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4d9608b83dbcb9275b6509d3f8adfef7d7ebe9f"},"cell_type":"code","source":"# We only use Number of Passengers in this project. Therefore, we create a new data named as 'data' and\n# assign to just passenger number to this new smaller data.\ndata = dataset.iloc[:,1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"804e12e22d2d3e41658ab70c58f8bed69ae8a286"},"cell_type":"code","source":"# Let's take a look our new data.\nplt.plot(data)\nplt.xlabel(\"Time\")\nplt.ylabel(\"Number of Passengers\")\nplt.title(\"International Airline Passengers\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e618309c0cde865e35399120f983d7dbe0749bd"},"cell_type":"code","source":"# Let's look at the shape of data.\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a231f57e3e3cb5b554b2cdd3e2180463f5de29f"},"cell_type":"code","source":"# As you can see; shape of data is (142,). We should reshape it.\ndata =data.reshape(-1,1)\ndata.astype(\"float32\")\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05d0115942d3982b914986145cac0fefca791314"},"cell_type":"code","source":"# After reshaping, we should scale all of datas between 0 and 1.\nfrom sklearn.preprocessing import MinMaxScaler #import scling library\nscaler = MinMaxScaler(feature_range=(0,1))\ndata_scaled = scaler.fit_transform(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2691456caa4e0985bd32301b5551ead4da3199d1"},"cell_type":"code","source":"# Let's check our data!\ndata_scaled\n# As you can see, we scaled our values!","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"697cc0174158f7e60046210d6e99908087f4fc04"},"cell_type":"markdown","source":"**and now time to train-test datas split!**"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"bc277a4fc760e7c2643008966fafef3b21597cf7"},"cell_type":"code","source":"train_data_size = int(len(data_scaled)*0.50)\ntest_data_size = len(data_scaled) - train_data_size\nprint(\"Train data size is {}\".format(train_data_size))\nprint(\"Test data size is {}\".format(test_data_size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bddd31b53f1dc388eb3f54b59dec2d268781c92f"},"cell_type":"code","source":"train = data_scaled[0:train_data_size,:]\ntest = data_scaled[train_data_size:len(data_scaled),:]\n# Let's check number of train and test datas again\nprint(\"Train data size is {}\".format(len(train)))\nprint(\"Test data size is {}\".format(len(test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f51a2f1cb9410d1ca4c5aa85293a61cafb88129a"},"cell_type":"code","source":"x_train = []\ny_train = []\ntime_steps=10\nfor i in range(len(train)-time_steps-1):\n    a = train[i:(i+time_steps),0]\n    x_train.append(a)\n    y_train.append(train[i + time_steps,0])\ntrainX = np.array(x_train)\ntrainY = np.array(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"791a3eb1c99cd166d6a0e15024c5ccaa23f95d86"},"cell_type":"code","source":"trainX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4b35c3df05fb1ee0fb768dbe7536efb58b3c348"},"cell_type":"code","source":"x_test = []\ny_test = []\nfor i in range(len(test)-time_steps-1):\n    a = test[i:(i+time_steps),0]\n    x_test.append(a)\n    y_test.append(test[i + time_steps,0])\ntestX = np.array(x_test)\ntestY = np.array(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3556dab8fc3822257e048d9e0aba5f871794456"},"cell_type":"code","source":"testX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"109aef500d9a27eccbabb46fbbb9d01e3b57e4eb"},"cell_type":"code","source":"# Let's reshape trainX and testX\ntrainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1],1))\ntestX = np.reshape(testX, (testX.shape[0],testX.shape[1],1))\n# Print and check shapes\nprint(\"Shape of trainX is {}\".format(trainX.shape))\nprint(\"Shape of testX is {}\".format(testX.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d7cb2e86a3ba8e59772209cc4f1cbddf806f5d61"},"cell_type":"markdown","source":"**Time to RNN with Keras!!**"},{"metadata":{"trusted":true,"_uuid":"79349f51d46ae4ca643f601b0a0d15945ad62dba"},"cell_type":"code","source":"# Firstly, define libraries\nfrom keras.layers import Dense, SimpleRNN, Dropout\nfrom keras.metrics import mean_squared_error\nfrom keras.models import Sequential","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f499d4fd2065ce5d4b75f719b3ef264f58292c8c"},"cell_type":"code","source":"# Initializing RNN\nmodel = Sequential()\n# Add the first layer and Dropout regularization\nmodel.add(SimpleRNN(units=100,activation='tanh',return_sequences=True, \n                    input_shape=(trainX.shape[1],1)))\nmodel.add(Dropout(0.20))\n# Second layer and Dropout regularization\nmodel.add(SimpleRNN(units = 100, activation='tanh',return_sequences=True))\nmodel.add(Dropout(0.20))\n# Third layer and Dropout regularization\nmodel.add(SimpleRNN(units = 70, activation='tanh', return_sequences= True))\nmodel.add(Dropout(0.20))\n# Fourth layer and Dropout regularization\nmodel.add(SimpleRNN(units = 50))\nmodel.add(Dropout(0.20))\n# Add final or output layer\nmodel.add(Dense(units=1))\n\n# Compile our RNN model\nmodel.compile(optimizer = 'adam', loss = 'mean_squared_error')\n# Fitting the RNN to the training set\nmodel.fit(trainX, trainY, epochs = 200, batch_size=32)\n# Remember; epochs, batch_size etc. are just some of hyper parameters. \n# You can change these parameters whatever you want","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5fe1ecd75236569707c794aa842c39ab651399bd"},"cell_type":"markdown","source":"**And the final mission: Predictions and Visualization!**"},{"metadata":{"trusted":true,"_uuid":"eff6ebb5e0f3448f7ec35cb9580e8d3c36097637"},"cell_type":"code","source":"trainPrediction = model.predict(trainX)\ntestPrediction = model.predict(testX)\n\n# Remember, we scaled datas between 0 and 1 but now we're at the end of the project.\n# So we should inverse transform datas.\n\ntrainPrediction = scaler.inverse_transform(trainPrediction)\ntrainY = scaler.inverse_transform([trainY])\ntestPrediction = scaler.inverse_transform(testPrediction)\ntestY = scaler.inverse_transform([testY])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"669287f9bbe6e408757bc4d3dc316c39bb4586ac"},"cell_type":"markdown","source":"Let's look at our RMSE (Root Mean Squared Error)"},{"metadata":{"trusted":true,"_uuid":"78d4b4283867c47c1c9b575f86c7df67afa9f5ba"},"cell_type":"code","source":"# There is some problem in there but I didn't know what is it.\n# I googled it and helps with DATAI Team found the problem :)\n# Convert tensor to numpy. Otherwise we could not sqrt values.\nimport tensorflow as tf\nsess = tf.Session()\nwith sess.as_default():\n    trainScore = math.sqrt(mean_squared_error(trainY[0], trainPrediction[:,0]).eval())\n    testScore = math.sqrt(mean_squared_error(testY[0], testPrediction[:,0]).eval())\nprint(\"Train Score is %.2lf RMSE\"%(trainScore))\nprint(\"Test Score is %.2lf RMSE\"%(testScore))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ed29b6ab9830e9a7d6dff9519aa85afae4d68cd"},"cell_type":"code","source":"trainPredictPlot = np.empty_like(dataset)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[time_steps:len(trainPrediction)+time_steps, :] = trainPrediction\n\ntestPredictPlot = np.empty_like(dataset)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(trainPrediction)+(time_steps*2)+1:len(dataset)-1, :] = testPrediction\n\nplt.plot(scaler.inverse_transform(data_scaled),label = 'True Values', color='blue')\nplt.plot(trainPredictPlot,label='Train Prediction', color='red')\nplt.plot(testPredictPlot,label = 'Test Prediction', color='green')\nplt.xlabel(\"Time\")\nplt.ylabel(\"Number of Passengers\")\nplt.title(\"International Airline Passengers\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a702dd80211864a938e723856c501e9922c0612"},"cell_type":"markdown","source":"**CONCLUSION**\n\nWe tried to workout on RNN with Keras library. Our predictions are not perfect but that seems enough for now :) I learned a lot of things from this project myself and I hope you did it too. Your examinations and comments are so important to me. Please, check it out and feel relax to comment me. "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}