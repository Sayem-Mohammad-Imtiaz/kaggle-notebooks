{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport json\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-04T17:10:30.028103Z","iopub.execute_input":"2021-07-04T17:10:30.028476Z","iopub.status.idle":"2021-07-04T17:10:30.039835Z","shell.execute_reply.started":"2021-07-04T17:10:30.028444Z","shell.execute_reply":"2021-07-04T17:10:30.038622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Outline\n\n1. **Load data**\n2. **Data Preprocessing**\n3. **Correlation for features**\n4. **Consider NaN**\n5. **ML model**\n6. **Conclusion**","metadata":{}},{"cell_type":"markdown","source":"## 1. Load data","metadata":{}},{"cell_type":"markdown","source":"**Setting class**","metadata":{}},{"cell_type":"code","source":"class LongTermStrategy:\n    def __init__(self, url, etfname):\n        self.url = url\n        self.etfname = etfname\n        \n    def get_ticker_list(self):\n        df = self.get_stats()\n        list_ticker = sorted(list(set(df['Ticker'].to_list())))\n\n        return list_ticker\n\n    def get_price_data(self, etf_list=[], OnlyRecent=False):\n        self.etf_list = etf_list\n        url_price = self.url+'/data_origin/FS_'+self.etfname+'_Value.json'\n        combined_price = pd.read_json(url_price)\n        df_price = pd.DataFrame({'Recent_price': []})\n\n        if OnlyRecent == True:\n            for symbol in self.etf_list:\n                temp_df = combined_price[combined_price.Ticker.str.contains(symbol)].copy()\n                res = temp_df.loc[temp_df.index[-1], 'Adj Close']\n                df_price.loc[symbol, 'Recent_price'] =res\n            return df_price\n        else:\n            df_price = combined_price.copy()\n            return df_price\n        \n        \n    def get_stats(self, preprocessing = False):\n        url_stats = self.url+'/data_origin/FS_'+self.etfname+'_stats.json'\n        df = pd.read_json(url_stats)\n        if preprocessing == True:\n            df_per = self.get_PER() # PER\n            df_psr = self.get_PSR() # Price/Sales\n            df_pbr = self.get_PBR() # Price/Book\n            df_peg = self.get_PEG() # Price/Earning growth\n            df_forper = self.get_FORPER() # Forward PER\n            df_cap = self.get_CAP() # Market Cap\n\n            # Concat mulit dataframe\n            df = pd.concat([df_per, df_psr, df_pbr, df_peg, df_forper, df_cap], axis=1)\n            \n        return df\n\n    def get_addstats(self, preprocessing = False):\n        url_addstats = self.url+'/data_origin/FS_'+self.etfname+'_addstats.json'\n        df = pd.read_json(url_addstats)\n        if preprocessing == True:\n            df_beta = self.get_Beta()\n            df_divr = self.get_DivRate() # Annual diviend rate\n            df_roe = self.get_ROE() # ROE\n            df_roa = self.get_ROA() # ROA\n            df_pm = self.get_PM() # Profit Margin\n            df_cash = self.get_Cash() # Total Cash\n            df_debt = self.get_Debt() # Total Debt\n            \n            # Concat mulit dataframe\n            df = pd.concat([df_beta, df_divr, df_roe, df_roa, df_pm, df_cash, df_debt], axis=1)\n\n        return df\n\n    def get_balsheets(self, preprocessing = False):\n        url_balsheets = self.url+'/data_origin/FS_'+self.etfname+'_balsheets.json'\n        df = pd.read_json(url_balsheets)\n        if preprocessing == True:\n            df_ta = self.get_TA() # Total Assets\n\n            df = pd.concat([df_ta], axis=1)\n\n        return df\n    \n    def get_income(self, preprocessing = False):\n        url_income = self.url+'/data_origin/FS_'+self.etfname+'_income.json'\n        df = pd.read_json(url_income)\n        if preprocessing == True:\n            df_tr = self.get_TR() # Total revenue\n\n            df = pd.concat([df_tr], axis=1)\n\n        return df\n\n    def get_flow(self, preprocessing = False):\n        url_flow = self.url+'/data_origin/FS_'+self.etfname+'_flow.json'\n        df = pd.read_json(url_flow)\n        if preprocessing == True:\n            df_div = self.get_DIV() # Dividends paid across companies\n            df_iss = self.get_ISS() # Issuance information\n\n            df = pd.concat([df_div, df_iss], axis=1)\n\n        return df\n\n ###################################################################################################\n    ## For stats\n    def get_stats_element(self, etf_list =['AAPL']):\n        df_stats = self.get_stats()\n        self.etf_list = etf_list\n        temp_df = df_stats[df_stats.Ticker == etf_list[0]].copy()\n        list_df = temp_df['Attribute'].to_list()\n        df = pd.DataFrame(columns=list_df, index = self.etf_list)\n        for ticker in self.etf_list:\n            temp_df = df_stats[df_stats.Ticker == ticker].copy()\n            list_df = temp_df['Attribute'].to_list()\n            for att in list_df:\n                temp_df_stats = df_stats[df_stats.Attribute == att].copy()\n                temp_df_stats = temp_df_stats.set_index('Ticker')\n                df.loc[ticker, att] = temp_df_stats.loc[ticker, 'Recent']\n\n        return df\n    \n    def get_addstats_element(self, etf_list =['AAPL']):\n        df_stats = self.get_addstats()\n        self.etf_list = etf_list\n        temp_df = df_stats[df_stats.Ticker == etf_list[0]].copy()\n        list_df = temp_df['Attribute'].to_list()\n        df = pd.DataFrame(columns=list_df, index = self.etf_list)\n        for ticker in self.etf_list:\n            temp_df = df_stats[df_stats.Ticker == ticker].copy()\n            list_df = temp_df['Attribute'].to_list()\n            for att in list_df:\n                temp_df_stats = df_stats[df_stats.Attribute == att].copy()\n                temp_df_stats = temp_df_stats.set_index('Ticker')\n                df.loc[ticker, att] = temp_df_stats.loc[ticker, 'Value']\n\n        return df\n   \n    def get_balsheets_element(self, etf_list =['AAPL']):\n        df_stats = self.get_balsheets()\n        self.etf_list = etf_list\n        temp_df = df_stats[df_stats.Ticker == etf_list[0]].copy()\n        list_df = temp_df['Breakdown'].to_list()\n        df = pd.DataFrame(columns=list_df, index = self.etf_list)\n        for ticker in self.etf_list:\n            temp_df = df_stats[df_stats.Ticker == ticker].copy()\n            list_df = temp_df['Breakdown'].to_list()\n            for att in list_df:\n                temp_df_stats = df_stats[df_stats.Breakdown == att].copy()\n                temp_df_stats = temp_df_stats.set_index('Ticker')\n                df.loc[ticker, att] = temp_df_stats.loc[ticker, 'Recent']\n\n        return df.astype(float)\n    \n    def get_income_element(self, etf_list =['AAPL']):\n        df_stats = self.get_income()\n        self.etf_list = etf_list\n        temp_df = df_stats[df_stats.Ticker == etf_list[0]].copy()\n        list_df = temp_df['Breakdown'].to_list()\n        df = pd.DataFrame(columns=list_df, index = self.etf_list)\n        for ticker in self.etf_list:\n            temp_df = df_stats[df_stats.Ticker == ticker].copy()\n            list_df = temp_df['Breakdown'].to_list()\n            for att in list_df:\n                temp_df_stats = df_stats[df_stats.Breakdown == att].copy()\n                temp_df_stats = temp_df_stats.set_index('Ticker')\n                df.loc[ticker, att] = temp_df_stats.loc[ticker, 'Recent']\n\n        return df.astype(float)\n    \n    \n    def get_flow_element(self, etf_list =['AAPL']):\n        df_stats = self.get_flow()\n        self.etf_list = etf_list\n        temp_df = df_stats[df_stats.Ticker == etf_list[0]].copy()\n        list_df = temp_df['Breakdown'].to_list()\n        df = pd.DataFrame(columns=list_df, index = self.etf_list)\n        for ticker in self.etf_list:\n            temp_df = df_stats[df_stats.Ticker == ticker].copy()\n            list_df = temp_df['Breakdown'].to_list()\n            for att in list_df:\n                temp_df_stats = df_stats[df_stats.Breakdown == att].copy()\n                temp_df_stats = temp_df_stats.set_index('Ticker')\n                df.loc[ticker, att] = temp_df_stats.loc[ticker, 'Recent']\n\n        return df.astype(float)\n\n###################################################################################################\n\n    def get_PER(self):\n        df = self.get_stats()\n        df_per = df[df.Attribute.str.contains('Trailing P/E')].copy()\n        df_per['PER'] = df_per.loc[:, 'Recent']\n        df_per = df_per.drop(['Attribute', 'Recent'], axis=1)\n        df_per = df_per.set_index('Ticker')\n        df_per = df_per.fillna(value=np.nan)\n        df_temp = pd.DataFrame()\n        for col in df_per.columns:\n            df_temp[col] = pd.to_numeric(df_per[col], errors='coerce')\n            \n        return df_temp.astype(float)\n\n    def get_PSR(self):\n        df = self.get_stats()\n        df_psr = df[df.Attribute.str.contains('Price/Sales')].copy()\n        df_psr['PSR'] = df_psr.loc[:, 'Recent']\n        df_psr = df_psr.drop(['Attribute', 'Recent'], axis=1)\n        df_psr = df_psr.set_index('Ticker')\n        df_psr = df_psr.fillna(value=np.nan)\n        df_temp = pd.DataFrame()\n        for col in df_psr.columns:\n            df_temp[col] = pd.to_numeric(df_psr[col], errors='coerce')\n\n        return df_temp.astype(float)\n\n    def get_PBR(self):\n        df = self.get_stats()\n        df_pbr = df[df.Attribute.str.contains('Price/Book')].copy()\n        df_pbr['PBR'] = df_pbr.loc[:, 'Recent']\n        df_pbr = df_pbr.drop(['Attribute', 'Recent'], axis=1)\n        df_pbr = df_pbr.set_index('Ticker')\n\n        return df_pbr.astype(float)\n\n    def get_PEG(self):\n        df = self.get_stats()\n        df_peg = df[df.Attribute.str.contains('PEG')].copy()\n        df_peg['PEG'] = df_peg.loc[:, 'Recent']\n        df_peg = df_peg.drop(['Attribute', 'Recent'], axis=1)\n        df_peg = df_peg.set_index('Ticker')\n\n        return df_peg.astype(float)\n\n    def get_FORPER(self):\n        df = self.get_stats()\n        df_forper = df[df.Attribute.str.contains('Forward P/E')].copy()\n        df_forper['forPER'] = df_forper.loc[:, 'Recent']\n        df_forper = df_forper.drop(['Attribute', 'Recent'], axis=1)\n        df_forper = df_forper.set_index('Ticker')\n        df_temp = pd.DataFrame()\n        for col in df_forper.columns:\n            df_temp[col] = pd.to_numeric(df_forper[col], errors='coerce')\n\n        return df_temp\n    def get_CAP(self):\n        df = self.get_stats()\n        df_cap = df[df.Attribute.str.contains('Cap')].copy()\n        df_cap['marketCap'] = df_cap.loc[:, 'Recent']\n        df_cap = df_cap.drop(['Attribute', 'Recent'], axis=1)\n        df_cap = df_cap.set_index('Ticker')\n        df_cap = df_cap.fillna(value=np.nan)\n        for ticker in df_cap.index:\n            value = df_cap.loc[ticker, 'marketCap']\n            if type(value) == str:\n                value = float(value.replace('.','').replace('T','0000000000').replace('B','0000000'). replace('M','0000').replace('k','0'))\n            df_cap.loc[ticker, 'marketCap'] = value\n\n        return df_cap.astype(float)\n    \n#############################################################\n    \n\n    def get_Beta(self):\n        df = self.get_addstats()\n        df_beta = df[df.Attribute.str.contains('Beta')].copy()\n        df_beta['Beta'] = df_beta.loc[:, 'Value']\n        df_beta = df_beta.drop(['Attribute', 'Value'], axis=1)\n        df_beta = df_beta.set_index('Ticker')\n\n        return df_beta.astype(float)\n    \n    def get_DivRate(self):\n        df = self.get_addstats()\n        df_divr = df[df.Attribute.str.contains('Trailing Annual Dividend Rate')].copy()\n        df_divr['AnnualDividendRate']= df_divr.loc[:, 'Value']\n        df_divr = df_divr.drop(['Attribute', 'Value'], axis=1)\n        df_divr = df_divr.set_index('Ticker')\n\n        return df_divr.astype(float)\n\n    def get_ROE(self):\n        df = self.get_addstats()\n        df_roe = df[df.Attribute.str.contains('Return on Equity')].copy()\n        df_roe['ROE(%)'] = df_roe.loc[:, 'Value']\n        df_roe = df_roe.drop(['Attribute', 'Value'], axis=1)\n        df_roe = df_roe.set_index('Ticker')\n        df_roe = df_roe.fillna(value=np.nan)\n        for ticker in df_roe.index:\n            value = df_roe.loc[ticker, 'ROE(%)']\n            if type(value) == str:\n                value = float(value[:-1].replace(',',''))\n            df_roe.loc[ticker, 'ROE(%)'] = value\n\n        return df_roe.astype(float)\n\n    def get_ROA(self):\n        df = self.get_addstats()\n        df_roa = df[df.Attribute.str.contains('Return on Assets')].copy()\n        df_roa['ROA(%)'] = df_roa.loc[:, 'Value']\n        df_roa = df_roa.drop(['Attribute', 'Value'], axis=1)\n        df_roa = df_roa.set_index('Ticker')\n        df_roa = df_roa.fillna(value=np.nan)\n        for ticker in df_roa.index:\n            value = df_roa.loc[ticker, 'ROA(%)']\n            if type(value) == str:\n                value = float(value[:-1])\n            df_roa.loc[ticker, 'ROA(%)'] = value\n\n        return df_roa.astype(float)\n\n    def get_PM(self):\n        df = self.get_addstats()\n        df_pm = df[df.Attribute.str.contains('Profit Margin')].copy()\n        df_pm['ProfitMargin(%)'] = df_pm.loc[:, 'Value']\n        df_pm = df_pm.drop(['Attribute', 'Value'], axis=1)\n        df_pm = df_pm.set_index('Ticker')\n        df_pm = df_pm.fillna(value=np.nan)\n        for ticker in df_pm.index:\n            value = df_pm.loc[ticker, 'ProfitMargin(%)']\n            if type(value) == str:\n                value = float(value[:-1])\n            df_pm.loc[ticker, 'ProfitMargin(%)'] = value\n\n        return df_pm.astype(float)\n    \n    def get_Cash(self):\n        df = self.get_addstats()\n        df_cash = df[df.Attribute.str.contains('Total Cash Per Share')].copy()\n        df_cash['TotalCash'] = df_cash.loc[:, 'Value']\n        df_cash = df_cash.drop(['Attribute', 'Value'], axis=1)\n        df_cash = df_cash.set_index('Ticker')\n\n        return df_cash.astype(float)\n\n    def get_Debt(self):\n        df = self.get_addstats()\n        df_debt = df[df.Attribute.str.contains('Total Debt/Equity')].copy()\n        df_debt['TotalDebt'] = df_debt.loc[:, 'Value']\n        df_debt = df_debt.drop(['Attribute', 'Value'], axis=1)\n        df_debt = df_debt.set_index('Ticker')\n\n        return df_debt.astype(float)\n\n##########################################################    \n    def get_TA(self):\n        df = self.get_balsheets()\n        df_ta = df[df.Breakdown == 'totalAssets'].copy()\n        df_ta['TotalAssets'] = df_ta.loc[:, 'Recent']\n        df_ta = df_ta.drop(['Breakdown', 'Recent'], axis=1)\n        df_ta = df_ta.set_index('Ticker')\n\n        return df_ta\n    \n    def get_TR(self):\n        df = self.get_income()\n        df_tr = df[df.Breakdown == 'totalRevenue'].copy()\n        df_tr['TotalRevenue'] = df_tr.loc[:, 'Recent']\n        df_tr = df_tr.drop(['Breakdown', 'Recent'], axis=1)\n        df_tr = df_tr.set_index('Ticker')\n\n        return df_tr\n    \n    def get_DIV(self):\n        df = self.get_flow()\n        df_div = df[df.Breakdown == 'dividendsPaid'].copy()\n        df_div['DividendsPaid'] = df_div.loc[:, 'Recent']\n        df_div = df_div.drop(['Breakdown', 'Recent'], axis=1)\n        df_div = df_div.set_index('Ticker')\n\n        return df_div\n\n    def get_ISS(self):\n        df = self.get_flow()\n        df_iss = df[df.Breakdown == 'issuanceOfStock'].copy()\n        df_iss['Issuance'] = df_iss.loc[:, 'Recent']\n        df_iss = df_iss.drop(['Breakdown', 'Recent'], axis=1)\n        df_iss = df_iss.set_index('Ticker')\n\n        return df_iss\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-04T17:10:30.042389Z","iopub.execute_input":"2021-07-04T17:10:30.042848Z","iopub.status.idle":"2021-07-04T17:10:30.125238Z","shell.execute_reply.started":"2021-07-04T17:10:30.042804Z","shell.execute_reply":"2021-07-04T17:10:30.124219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# var and class\nfilename = 'sp500'\nurl='/kaggle/input/sp-500-stocks-value-with-financial-statement'\n\nstrategy = LongTermStrategy(url, filename)\n\n# Get list of stocks\nsp500_list = strategy.get_ticker_list()\nprint(sp500_list)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-04T17:10:30.126872Z","iopub.execute_input":"2021-07-04T17:10:30.127175Z","iopub.status.idle":"2021-07-04T17:10:30.167664Z","shell.execute_reply.started":"2021-07-04T17:10:30.127146Z","shell.execute_reply":"2021-07-04T17:10:30.166734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**2.1 price as time series**\n\nIt needs much time to large datasets.","metadata":{}},{"cell_type":"code","source":"#df_price = strategy.get_price_data(etf_list=sp500_list, OnlyRecent=True)\n#df_price.head(5)\ndf_price = pd.read_json(url+'/data_origin/FS_sp500_Recent_Value.json')\ndf_price.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:10:30.266662Z","iopub.execute_input":"2021-07-04T17:10:30.267046Z","iopub.status.idle":"2021-07-04T17:10:30.284474Z","shell.execute_reply.started":"2021-07-04T17:10:30.267016Z","shell.execute_reply":"2021-07-04T17:10:30.283506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2.2 fundmantal stats**","metadata":{}},{"cell_type":"code","source":"df_stats = strategy.get_stats(True)\ndf_stats.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:10:30.493904Z","iopub.execute_input":"2021-07-04T17:10:30.494392Z","iopub.status.idle":"2021-07-04T17:10:30.781994Z","shell.execute_reply.started":"2021-07-04T17:10:30.494352Z","shell.execute_reply":"2021-07-04T17:10:30.780719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2.3 Additional stats**","metadata":{}},{"cell_type":"code","source":"df_addstats = strategy.get_addstats(True)\ndf_addstats.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:10:30.783964Z","iopub.execute_input":"2021-07-04T17:10:30.784388Z","iopub.status.idle":"2021-07-04T17:10:31.948956Z","shell.execute_reply.started":"2021-07-04T17:10:30.784344Z","shell.execute_reply":"2021-07-04T17:10:31.947889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2.4 Balance sheets**","metadata":{}},{"cell_type":"code","source":"#df_balsheets = strategy.get_balsheets(True)\ndf_balsheets = strategy.get_balsheets_element(sp500_list)\ndf_balsheets.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:10:31.950783Z","iopub.execute_input":"2021-07-04T17:10:31.951112Z","iopub.status.idle":"2021-07-04T17:11:21.835855Z","shell.execute_reply.started":"2021-07-04T17:10:31.951082Z","shell.execute_reply":"2021-07-04T17:11:21.834656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2.5 Imcome statement**","metadata":{}},{"cell_type":"code","source":"#df_income = strategy.get_income(True)\ndf_income = strategy.get_income_element(sp500_list)\ndf_income.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:11:21.838051Z","iopub.execute_input":"2021-07-04T17:11:21.838519Z","iopub.status.idle":"2021-07-04T17:11:59.311882Z","shell.execute_reply.started":"2021-07-04T17:11:21.838471Z","shell.execute_reply":"2021-07-04T17:11:59.311149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2.6 Cash flow**","metadata":{}},{"cell_type":"code","source":"#df_flow = strategy.get_flow(True)\ndf_flow = strategy.get_flow_element(sp500_list)\ndf_flow.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:11:59.312873Z","iopub.execute_input":"2021-07-04T17:11:59.313254Z","iopub.status.idle":"2021-07-04T17:12:28.352002Z","shell.execute_reply.started":"2021-07-04T17:11:59.313224Z","shell.execute_reply":"2021-07-04T17:12:28.350992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2.7 Merge dataframe**","metadata":{}},{"cell_type":"code","source":"df = pd.concat([df_price, df_stats, df_addstats, df_balsheets, df_income, df_flow], axis=1)\ndf.dropna()\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:12:28.353258Z","iopub.execute_input":"2021-07-04T17:12:28.353576Z","iopub.status.idle":"2021-07-04T17:12:28.400591Z","shell.execute_reply.started":"2021-07-04T17:12:28.35353Z","shell.execute_reply":"2021-07-04T17:12:28.399406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2.8 Check numeric dtype**","metadata":{}},{"cell_type":"code","source":"from pandas.api.types import is_numeric_dtype\nnum_cols = [is_numeric_dtype(dtype) for dtype in df.dtypes]\nprint(num_cols)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:12:28.402319Z","iopub.execute_input":"2021-07-04T17:12:28.402739Z","iopub.status.idle":"2021-07-04T17:12:28.409131Z","shell.execute_reply.started":"2021-07-04T17:12:28.402706Z","shell.execute_reply":"2021-07-04T17:12:28.408339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Correlation for features","metadata":{}},{"cell_type":"markdown","source":"**3.1 Split data and test For correlation**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_df_corr, test_df_corr = train_test_split(df.copy(), test_size=0.2)\ntrain_df_corr.head(5), test_df_corr.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:12:28.411406Z","iopub.execute_input":"2021-07-04T17:12:28.411867Z","iopub.status.idle":"2021-07-04T17:12:28.452824Z","shell.execute_reply.started":"2021-07-04T17:12:28.411822Z","shell.execute_reply":"2021-07-04T17:12:28.451717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3.2 Calculation**","metadata":{}},{"cell_type":"code","source":"corrmat = train_df_corr.corr()\ntop_corr_features = corrmat.index[abs(corrmat['Recent_price'])>0.2]\ntop_corr_features","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:12:28.454502Z","iopub.execute_input":"2021-07-04T17:12:28.454796Z","iopub.status.idle":"2021-07-04T17:12:28.470391Z","shell.execute_reply.started":"2021-07-04T17:12:28.454769Z","shell.execute_reply":"2021-07-04T17:12:28.469677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3.2 Heatmap**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(13,10))\nplt_corr = sns.heatmap(train_df_corr[top_corr_features].corr(), annot=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:12:28.471514Z","iopub.execute_input":"2021-07-04T17:12:28.471956Z","iopub.status.idle":"2021-07-04T17:12:32.867023Z","shell.execute_reply.started":"2021-07-04T17:12:28.471913Z","shell.execute_reply":"2021-07-04T17:12:32.865784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Consider NaN\n\nHow to considef NaN data\n\nWe need how to take the NaN data. First of all, we remove the NaN index and columns over ratio of 0.5.\n\nBefore considering, we have to select ticker for analysis.\n\nIn my case, I select energy sector in S&P500 index.","metadata":{}},{"cell_type":"code","source":"energy_list = ['APA', 'COG', 'COP', 'CVX', 'DVN', 'EOG', 'FANG', 'HAL', 'HES', 'KMI',         'MPC', 'MRO', 'NOV', 'OKE', 'OXY', 'PSX', 'PXD', 'SLB', 'VLO', 'WMB', 'XOM']\nport_list = energy_list","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:12:32.868775Z","iopub.execute_input":"2021-07-04T17:12:32.869164Z","iopub.status.idle":"2021-07-04T17:12:32.875625Z","shell.execute_reply.started":"2021-07-04T17:12:32.869125Z","shell.execute_reply":"2021-07-04T17:12:32.874531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**4.1 Remove index**","metadata":{}},{"cell_type":"code","source":"df_index_null = pd.DataFrame(columns=['TotalNull', 'PercentOfNull'])\nfor ticker in df.index:\n    temp_df = df.loc[ticker,:]\n    count_null = temp_df.isnull().sum()\n    percent_count_null = count_null/len(temp_df)\n    df_index_null.loc[ticker, 'TotalNull'] = count_null\n    df_index_null.loc[ticker, 'PercentOfNull'] = percent_count_null\n    remove_index = df_index_null[df_index_null['PercentOfNull']>0.5].index.tolist()\n    for tic in port_list:\n        if tic in remove_index:\n            remove_index.remove(tic)\ndf = df.drop(remove_index, axis=0)\ndf.info()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:12:32.877379Z","iopub.execute_input":"2021-07-04T17:12:32.877804Z","iopub.status.idle":"2021-07-04T17:12:33.769723Z","shell.execute_reply.started":"2021-07-04T17:12:32.877763Z","shell.execute_reply":"2021-07-04T17:12:33.768704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**4.2 Remove columns**","metadata":{}},{"cell_type":"code","source":"nulltotal = df.isnull().sum().sort_values(ascending=False)\nnullpercent = ( df.isnull().sum() / len(df) ).sort_values(ascending=False)\nnullpoint = pd.concat([nulltotal, nullpercent], axis=1, keys=['Total number of null', 'Percent of null'])\nprint(nullpoint)\n\nremove_cols = nullpercent[nullpercent >= 0.5].keys()\ndf = df.drop(remove_cols, axis=1)\nprint(df.isnull().sum().max())\nnewtotal = df.isnull().sum().sort_values(ascending=False)\nprint(newtotal)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:12:33.771198Z","iopub.execute_input":"2021-07-04T17:12:33.771506Z","iopub.status.idle":"2021-07-04T17:12:33.803462Z","shell.execute_reply.started":"2021-07-04T17:12:33.771473Z","shell.execute_reply":"2021-07-04T17:12:33.802069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# filling the numeric data\nnumeric_missed = newtotal.index\nfor feature in numeric_missed:\n    df[feature] = df[feature].fillna(0)\n\nprint('Re check')\nprint(df.isnull().sum().max())","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:12:33.804899Z","iopub.execute_input":"2021-07-04T17:12:33.805182Z","iopub.status.idle":"2021-07-04T17:12:33.891939Z","shell.execute_reply.started":"2021-07-04T17:12:33.805155Z","shell.execute_reply":"2021-07-04T17:12:33.890868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Feature Engineering\nfrom scipy.stats import norm, skew\nnumeric_feats = df.dtypes[df.dtypes != 'object'].index\nskewed_feats = df[numeric_feats].apply(lambda x: skew(x)).sort_values(ascending=False)\nhigh_skew = skewed_feats[abs(skewed_feats) > 0.5]\nprint(high_skew)\n\n#for feature in high_skew.index:\n#    df[feature] = np.log1p(df[feature]-df[feature].min()+1)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:12:33.893111Z","iopub.execute_input":"2021-07-04T17:12:33.893386Z","iopub.status.idle":"2021-07-04T17:12:33.943227Z","shell.execute_reply.started":"2021-07-04T17:12:33.893359Z","shell.execute_reply":"2021-07-04T17:12:33.942197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. ML model","metadata":{}},{"cell_type":"markdown","source":"**5.1 Split train and test for ML**\n\ntarget column is **Market Cap** and then setting.","metadata":{}},{"cell_type":"code","source":"y_df = df['marketCap']\ndf = df.drop(['Recent_price', 'marketCap'], axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:12:33.944695Z","iopub.execute_input":"2021-07-04T17:12:33.944985Z","iopub.status.idle":"2021-07-04T17:12:33.958423Z","shell.execute_reply.started":"2021-07-04T17:12:33.944956Z","shell.execute_reply":"2021-07-04T17:12:33.957189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_df = y_df.to_frame()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:12:33.959829Z","iopub.execute_input":"2021-07-04T17:12:33.960196Z","iopub.status.idle":"2021-07-04T17:12:33.971808Z","shell.execute_reply.started":"2021-07-04T17:12:33.960162Z","shell.execute_reply":"2021-07-04T17:12:33.970729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test = y_df.loc[y_df.index.intersection(port_list), :]\nx_test = df.loc[df.index.intersection(port_list), :]\ny_train = y_df.drop(port_list, axis=0)\nx_train = df.drop(port_list, axis=0)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:12:33.97314Z","iopub.execute_input":"2021-07-04T17:12:33.973456Z","iopub.status.idle":"2021-07-04T17:12:33.988769Z","shell.execute_reply.started":"2021-07-04T17:12:33.973417Z","shell.execute_reply":"2021-07-04T17:12:33.98761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_index = x_test.index","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:12:33.989984Z","iopub.execute_input":"2021-07-04T17:12:33.99041Z","iopub.status.idle":"2021-07-04T17:12:34.001287Z","shell.execute_reply.started":"2021-07-04T17:12:33.990379Z","shell.execute_reply":"2021-07-04T17:12:34.000207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**5.2 Modeling**","metadata":{}},{"cell_type":"code","source":"import xgboost as XGB\n\nthe_model = XGB.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468,\n                            learning_rate=0.05, max_depth=3,\n                            min_child_weight=1.7817, n_estimators=2200,\n                            reg_alpha=0.4640, reg_lambda=0.8571,\n                            subsample=0.5213, random_state =7, nthread = -1)\n\n# To solve error of features_names\nx_train = x_train.loc[:,~x_train.columns.duplicated()]\nduplicate_columns = x_train.columns[x_train.columns.duplicated()]\nx_test = x_test.loc[:,~x_test.columns.duplicated()]\nduplicate_columns_t = x_test.columns[x_test.columns.duplicated()]\n\nthe_model.fit(x_train, y_train)\n\ny_predict = np.floor(the_model.predict(x_test))\n\nsub = pd.DataFrame()\nsub['Ticker'] = test_index\nsub['MarketCapOfPrediction'] = y_predict\nsub = sub.set_index('Ticker')\nsub = pd.concat([sub, y_test], axis=1)\nsub['Ratio'] = sub.MarketCapOfPrediction / sub.marketCap\nsub = sub.sort_values(by= 'Ratio', ascending=False)\nprint(sub)\n\nfrom sklearn.metrics import mean_squared_error\nacc = mean_squared_error(y_test, y_predict)\nprint('mse: ', acc)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:12:34.002668Z","iopub.execute_input":"2021-07-04T17:12:34.002969Z","iopub.status.idle":"2021-07-04T17:12:36.690221Z","shell.execute_reply.started":"2021-07-04T17:12:34.00294Z","shell.execute_reply":"2021-07-04T17:12:36.688783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Conclusion\n\nWe have to know how much to estimatie market price at that time (2021-07-04).\n\nWe should hanv known several ticker is ** low estimation ** for currunt above result for ratio over 1.\n\nIt is up to the individual to judge how to evaluate this result.\n\n\nIf you want to use this code, I'm very sorry that you should change code and make directory for data  a little bit.\n\nI should appreciate and refer for many blog on google. Thanks a lot.\n\nIf you satisfied this post you should check [Github](https://github.com/hanseopark/Stock/tree/master/Strategy) and please **Star** :)\n","metadata":{}}]}