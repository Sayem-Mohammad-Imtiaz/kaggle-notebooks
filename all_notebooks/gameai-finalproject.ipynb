{"cells":[{"metadata":{},"cell_type":"markdown","source":"여성 의류 리뷰 데이터셋을 이용한 감정 분석"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"데이터셋을 읽어옵니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/womens-ecommerce-clothing-reviews/Womens Clothing E-Commerce Reviews.csv\")\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train_data[~train_data['Review Text'].isnull()]\ntrain_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"리뷰 테이터 중 null값이 있는 요소를 확인합니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data['Review Text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.drop(\"Unnamed: 0\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.drop(\"Clothing ID\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.drop(\"Age\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.drop(\"Title\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.drop(\"Positive Feedback Count\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.drop(\"Division Name\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.drop(\"Department Name\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.drop(\"Class Name\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"필요없는 항목들을 삭제해줍니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Review Text'].nunique(),train_data['Recommended IND'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.drop_duplicates(subset=['Review Text'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('총 샘플의 수 :',len(train_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Recommended IND'].value_counts().plot(kind = 'bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data.groupby('Recommended IND').size().reset_index(name = 'count'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data.isnull().values.any())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ntext = 'do!!! you expect... people~ to~ read~ the FAQ, etc. and actually accept hard~! atheism?@@'\nre.sub(r'[^a-zA-Z ]', '', text) #알파벳과 공백을 제외하고 모두 제거","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Review Text'] = train_data['Review Text'].str.replace(\"[^a-zA-Z ]\",\"\")\n# 글과 공백을 제외하고 모두 제거\ntrain_data[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"리뷰를 토큰화 하기 전에 글과 공백을 제외한 다른 요소들을 제거합니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Review Text'].replace('', np.nan, inplace=True)\nprint(train_data.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.tokenize import TreebankWordTokenizer\ntokenizer=TreebankWordTokenizer()\ntext=train_data['Review Text'][0]\nprint(tokenizer.tokenize(text))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"첫 번째 리뷰를 토큰화하여 확인"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = []\nfor sentence in train_data['Review Text']:\n    temp_X = []\n    tokenizer=TreebankWordTokenizer()\n    temp_X=sentence\n    temp_X=tokenizer.tokenize(temp_X)\n    X_train.append(temp_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train[:3])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"전체 리뷰를 토큰화한 후 앞에 3개만 확인해봅니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\ntokenizer2 = Tokenizer()\ntokenizer2.fit_on_texts(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tokenizer2.word_index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"토큰화된 단어들에 인덱스를 부여합니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold = 3\ntotal_cnt = len(tokenizer2.word_index) # 단어의 수\nrare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\ntotal_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\nrare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n\n# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\nfor key, value in tokenizer2.word_counts.items():\n    total_freq = total_freq + value\n\n    # 단어의 등장 빈도수가 threshold보다 작으면\n    if(value < threshold):\n        rare_cnt = rare_cnt + 1\n        rare_freq = rare_freq + value\n\nprint('단어 집합(vocabulary)의 크기 :',total_cnt)\nprint('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\nprint(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\nprint(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 전체 단어 개수 중 빈도수 2이하인 단어 개수는 제거.\n# 0번 패딩 토큰과 1번 OOV 토큰을 고려하여 +2\nvocab_size = total_cnt - rare_cnt + 2\nprint('단어 집합의 크기 :',vocab_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer2 = Tokenizer(vocab_size, oov_token = 'OOV') \ntokenizer2.fit_on_texts(X_train)\nX_train = tokenizer2.texts_to_sequences(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train[:3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = np.array(train_data['Recommended IND'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 빈 샘플들을 제거\nX_train = np.delete(X_train, drop_train, axis=0)\nprint(len(X_train))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('리뷰의 최대 길이 :',max(len(l) for l in X_train))\nprint('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))\nimport matplotlib.pyplot as plt\nplt.hist([len(s) for s in X_train], bins=50)\nplt.xlabel('length of samples')\nplt.ylabel('number of samples')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def below_threshold_len(max_len, nested_list):\n  cnt = 0\n  for s in nested_list:\n    if(len(s) <= max_len):\n        cnt = cnt + 1\n  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_len = 100\nbelow_threshold_len(max_len, X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.sequence import pad_sequences\nX_train = pad_sequences(X_train, maxlen = max_len)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"리뷰의 길이를 100으로 맞춰 정규화 시켜줍니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 빈 샘플들을 제거\nX_train = np.delete(X_train, drop_train, axis=0)\nprint(len(X_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Embedding, Dense, LSTM\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LSTM"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(vocab_size, 100))\nmodel.add(LSTM(128))\nmodel.add(Dense(1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\nmc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\nhistory = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=60, validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loaded_model = load_model('best_model.h5')\nprint(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_train, y_train)[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sentiment_predict(new_sentence):\n    tokenizer.tokenize(new_sentence) # 토큰화\n    encoded = tokenizer2.texts_to_sequences([new_sentence]) # 정수 인코딩\n    pad_new = pad_sequences(encoded, maxlen = max_len) # 패딩\n    score = float(loaded_model.predict(pad_new)) # 예측\n    if(score > 0.5):\n        print(\"{:.2f}% 확률로 긍정 리뷰입니다.\\n\".format(score * 100))\n    else:\n        print(\"{:.2f}% 확률로 부정 리뷰입니다.\\n\".format((1 - score) * 100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment_predict('i love this dress its soo pretty')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment_predict('Its too dark.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment_predict('Okay but its too big')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment_predict('This Tshirt fits me perfectly')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}