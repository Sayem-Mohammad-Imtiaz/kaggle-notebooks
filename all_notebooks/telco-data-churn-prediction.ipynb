{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"I'll build two classifiers for churn prediction, one is classic machine learning algorithm - Logistic Regression, other is neural network built in keras","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"Import packages","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import scale\nfrom keras import Sequential, Input\nfrom keras.layers import Dense, Dropout\nfrom sklearn.model_selection import GridSearchCV\nfrom keras.wrappers.scikit_learn import KerasClassifier\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clean missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df['TotalCharges']==' ','TotalCharges'] = np.nan\ndf['TotalCharges'] = pd.to_numeric(df['TotalCharges'])\ndf.loc[df['TotalCharges'].isnull(),'TotalCharges'] = df['TotalCharges'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since there are many categorical variables, I'll create new dataset where I'll replace them with dummy variables. Since we don't need customerID in analysis I'll remove that variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dummy = pd.get_dummies(df.drop(columns=['customerID']), prefix=['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService',\n       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n       'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n       'PaymentMethod', 'Churn'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dummy.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In case of Yes/No variables, one dummy variable is enough to represent all the information so I'll remove all dummy variables with sufix \"_No\" ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dummy=df_dummy.drop(columns=[x for x in df_dummy.columns if x[-3:]=='_No'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dummy['Churn_Yes'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 3 numerical variables, I'll scale them before creating a model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dummy['MonthlyCharges'] = scale(df_dummy['MonthlyCharges'])\ndf_dummy['TotalCharges'] = scale(df_dummy['TotalCharges'])\ndf_dummy['tenure'] = scale(df_dummy['tenure'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dummy[['MonthlyCharges','TotalCharges','tenure']].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As a baseline model I'll create Logistic Regression model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = LogisticRegression()\nx_train, x_test, y_train, y_test = train_test_split(df_dummy.drop(columns=['Churn_Yes']), df_dummy['Churn_Yes'], test_size=0.3)\nclf.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = clf.predict(x_test)\nprint(confusion_matrix(y_test, pred))\nprint(classification_report(y_test, pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Resulting accuracy is 80% which is ok, but there is still room for improvement.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Defining a model. Output variable is binary so I use sigmoid activation function in the last layer and binary crossentropy as a loss function. Number of layers and nodes is arbitrarily set, I'll change it if needed","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential(\n    [  \n        Dense(16, activation=\"relu\", input_dim=df_dummy.shape[1]-1),\n        Dense(8, activation=\"relu\"),\n        Dense(1,  activation='sigmoid')\n    ]\n)\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_train, y_train, epochs=20, batch_size=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(x_test)\npred = [1 if x[0]>=0.5 else 0 for x in pred]\nprint(confusion_matrix(y_test, pred))\nprint(classification_report(y_test, pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Overall accuracy didn't improve compared to logistic regression model. I'll try to apply different combinations of hyperparameters in order to improve accuracy","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dropout_rate = [0.0, 0.2,0.4, 0.6, 0.8]\nn_neurons = [(32,16,8), (10,5), (16,8,4)]\nbatch_size = [20, 60, 100]\nepochs = [10, 50, 100]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(dropout_rate, n_neurons):\n    model = Sequential()\n    model.add(Dense(n_neurons[0], activation=\"relu\", input_dim=df_dummy.shape[1]-1))\n    for i in range(1,len(n_neurons)):\n        print(n_neurons[i])\n        model.add(Dense(n_neurons[i], activation=\"relu\"))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(1,  activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reference for this part https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\nmodel = KerasClassifier(build_fn=create_model, verbose=0)\nparam_grid = dict(dropout_rate=dropout_rate, n_neurons=n_neurons, batch_size=batch_size, epochs=epochs)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\ngrid_result = grid.fit(x_train, y_train)\n# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hyperparameter optimization didn't result in increased accuracy. This procedure didn't cover all possible combinations, so there are more options that can be explored.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}