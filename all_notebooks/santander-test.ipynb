{"cells":[{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\ntest = pd.read_csv(\"../input/santander-customer-transaction-prediction-dataset/test.csv\")\ntrain = pd.read_csv(\"../input/santander-customer-transaction-prediction-dataset/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.utils import resample\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\n\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report, confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(columns=['ID_code'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#corr = train2.corr()\n#corr.style.background_gradient(cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train2.boxplot(by='target', figsize=(60,55))\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_redundant_pairs(df):\n    pairs_to_drop = set()\n    cols = df.columns\n    for i in range(0, df.shape[1]):\n        for j in range(0, i+1):\n            pairs_to_drop.add((cols[i], cols[j]))\n    return pairs_to_drop\n\n\ndef get_top_abs_correlations(df, n=5):\n    au_corr = df.corr().abs().unstack()\n    labels_to_drop = get_redundant_pairs(df)\n    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n    return au_corr[0:n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Q1 = train2.quantile(0.25)\nQ3 = train2.quantile(0.75)\nIQR = Q3 - Q1\n#print(IQR)\n\n#train2 = train2[~((train2 < (Q1-1.5 * IQR)) | (train2 > (Q3+1.5 * IQR))).any(axis=1)]\n#train2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_corr = get_top_abs_correlations(train, 180)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Training starts here**"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_features = [indx[1] for indx in top_corr.index if indx[0]=='target']\ncorr_features.insert(0, 'target')\n\nrel_features = [indx[0] for indx in top_corr.index if indx[0]!='target'] + [indx[1] for indx in top_corr.index if indx[0]!='target']\ncorr_features2 = [x for x in corr_features if x not in rel_features]\n\ncorr_features = corr_features[:100] # change number of the features\ntrain2 = train[corr_features]\n\ndf_majority = train2[train2.target==0]\ndf_minority = train2[train2.target==1]\n\ndf_majority_downsampled = resample(df_majority,\n                                   replace=False,\n                                   n_samples=20098,\n                                   random_state=123)\n\n'''\ndf_minority_upsampled = resample(df_minority, \n                                 replace=True,\n                                 n_samples=23000,\n                                 random_state=123)\n'''\n\ndf_downsampled = pd.concat([df_majority_downsampled, df_minority])\n#df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n\ndf_sampled = pd.concat([df_majority_downsampled, df_minority])\ndf_sampled.target.value_counts()\n\n\nscaler = MinMaxScaler()\ntrain_scaled = scaler.fit_transform(df_sampled.values)\nX = train_scaled[:, 1:]\ny = train_scaled[:, 0]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n\ntarget_names = ['Negative', 'Positive']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(5)\nknn.fit(X_train, y_train)\ny_pred_knn = knn.predict(X_test)\n\nprint(\"KNN accuracy score: {:.2f}\".format(accuracy_score(y_test, y_pred_knn)), \"\\n\")\nprint(\"KNN confusion matrix:\\n\", confusion_matrix(y_test, y_pred_knn, labels=[0,1]), \"\\n\")\nprint(classification_report(y_test, y_pred_knn, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg = LogisticRegression(random_state=5, solver=\"sag\")\nlogreg.fit(X_train, y_train)\ny_pred_lr = logreg.predict(X_test)\n\nprint(\"LogReg accuracy score: {:.2f}\".format(logreg.score(X_test, y_test)), \"\\n\")\nprint(\"LogReg confusion matrix:\\n\", confusion_matrix(y_test, y_pred_lr, labels=[0,1]), \"\\n\")\nprint(classification_report(y_test, y_pred_lr, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svclassifier = SVC(kernel='linear')\nsvclassifier.fit(X_train, y_train)\ny_pred_svm = svclassifier.predict(X_test)\n\nprint(\"SVM accuracy score: {:.2f}\".format(accuracy_score(y_test, y_pred_svm)), \"\\n\")\nprint(\"SVM confusion matrix:\\n\", confusion_matrix(y_test, y_pred_svm, labels=[0,1]), \"\\n\")\nprint(classification_report(y_test, y_pred_svm, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nbclassifier = BernoulliNB()\nnbclassifier.fit(X_train, y_train)\ny_pred_nb = nbclassifier.predict(X_test)\n\nprint(\"Naive Bayes accuracy score: {:.2f}\".format(accuracy_score(y_test, y_pred_nb)), \"\\n\")\nprint(\"Naive Bayes confusion matrix:\\n\", confusion_matrix(y_test, y_pred_nb, labels=[0,1]), \"\\n\")\nprint(classification_report(y_test, y_pred_nb, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)\ny_pred_dt = dt.predict(X_test)\n\nprint(\"Decision Tree accuracy score: {:.2f}\".format(accuracy_score(y_test, y_pred_dt)), \"\\n\")\nprint(\"Decision Tree confusion matrix:\\n\", confusion_matrix(y_test, y_pred_dt, labels=[0,1]), \"\\n\")\nprint(classification_report(y_test, y_pred_dt, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_pred_rf = rf.predict(X_test)\n\nprint(\"Random Forest accuracy score: {:.2f}\".format(accuracy_score(y_test, y_pred_rf)), \"\\n\")\nprint(\"Random Forest confusion matrix:\\n\", confusion_matrix(y_test, y_pred_rf, labels=[0,1]), \"\\n\")\nprint(classification_report(y_test, y_pred_rf, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\"n_estimators\":1000, \"max_depth\":6, \"seed\":123, \"tree_method\":\"gpu_hist\", \"predictor\":\"gpu_predictor\", \"n_gpus\":1}\nxg_cl = xgb.XGBClassifier(**params)\nxg_cl.fit(X_train, y_train)\ny_pred_xgb = xg_cl.predict(X_test)\n\naccuracy = float(np.sum(y_pred_xgb==y_test))/y_test.shape[0]\nprint(\"XGBoost accuracy score: {:.2f}\".format(accuracy), \"\\n\")\nprint(\"XGBoost confusion matrix:\\n\", confusion_matrix(y_test, y_pred_xgb, labels=[0,1]), \"\\n\")\nprint(classification_report(y_test, y_pred_xgb, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"KNN accuracy score: {:.2f}\".format(accuracy_score(y_test, y_pred_knn)))\nprint(\"LogReg accuracy score: {:.2f}\".format(accuracy_score(y_test, y_pred_lr)))\nprint(\"SVM accuracy score: {:.2f}\".format(accuracy_score(y_test, y_pred_svm)))\nprint(\"Naive Bayes accuracy score: {:.2f}\".format(accuracy_score(y_test, y_pred_nb)))\nprint(\"Decision Tree accuracy score: {:.2f}\".format(accuracy_score(y_test, y_pred_dt)))\nprint(\"Random Forest accuracy score: {:.2f}\".format(accuracy_score(y_test, y_pred_rf)))\nprint(\"XGBoost accuracy score: {:.2f}\".format(accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_dmatrix = xgb.DMatrix(data=X, label=y)\nparams = {\"objective\":\"binary:logistic\", \"max_depth\":6}\n\ncv_results = xgb.cv(dtrain=dataset_dmatrix, params=params, num_boost_round=10, nfold=3, metrics=\"rmse\", as_pandas=True, seed=123)\nprint(cv_results, \"\\n\")\nprint(1-cv_results[\"test-rmse-mean\"].tail(1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_results = xgb.cv(dtrain=dataset_dmatrix, params=params, num_boost_round=50, nfold=3, metrics=\"auc\", as_pandas=True, seed=123)\nprint(cv_results[\"test-auc-mean\"].tail(1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\"n_estimators\":1000, \"max_depth\":6, \"seed\":123, \"tree_method\":\"gpu_hist\", \"predictor\":\"gpu_predictor\", \"n_gpus\":1}\nxg_cl2 = xgb.XGBClassifier(**params)\nxg_cl2.fit(train.drop(columns='target'), train['target'])\n\nweight_features = xg_cl2.get_booster().get_score(importance_type='weight')\nweight_features = [it[0] for it in sorted(weight_features.items(), key=lambda kv:(kv[1]), reverse=True)]\nweight_features.insert(0, 'target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weight_features = weight_features[:70]\ntrain3 = train[weight_features]\n\ndf_majority = train3[train2.target==0]\ndf_minority = train3[train2.target==1]\n\ndf_majority_downsampled = resample(df_majority,\n                                   replace=False,\n                                   n_samples=20098, #30000\n                                   random_state=123)\n\ndf_downsampled = pd.concat([df_majority_downsampled, df_minority])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Prediction starts here**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train3 = train[corr_features]\n\ndf_majority = train3[train2.target==0]\ndf_minority = train3[train2.target==1]\n\ndf_majority_downsampled = resample(df_majority,\n                                   replace=False,\n                                   n_samples=20098, #30000\n                                   random_state=123)\n\ndf_downsampled = pd.concat([df_majority_downsampled, df_minority])\n\n\nscaler = MinMaxScaler()\ntrain_scaled = scaler.fit_transform(df_downsampled.values)\nX_train = train_scaled[:, 1:]\ny_train = train_scaled[:, 0]\n\ncorr_features2 = [it for it in corr_features if it!='target']\n\nscaler_test = MinMaxScaler()\ntest2 = test.drop(columns='ID_code')\ntest2 = test2[corr_features2]\ntest_scaled = scaler_test.fit_transform(test2.values)\n\nX_test = test_scaled\n\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n\ntarget_names = ['Negative', 'Positive']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import validation_curve\n\nparam_range = np.arange(20, 30, 2)\n\ntrain_scores, test_scores = validation_curve(\n    RandomForestClassifier(),\n    X=X_train,\n    y=y_train,\n    param_name='n_estimators',\n    param_range=param_range,\n    cv=3,\n    scoring=\"accuracy\",\n    n_jobs=-1)\n\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\n\nplt.plot(param_range, train_mean, label=\"Training score\", color=\"black\")\nplt.plot(param_range, test_mean, label=\"Cross-validation score\", color=\"dimgrey\")\n\nplt.fill_between(param_range, train_mean - train_std, train_mean + train_std, color=\"gray\")\nplt.fill_between(param_range, test_mean - test_std, test_mean + test_std, color=\"gainsboro\")\n\nplt.title(\"Validation Curve With Random Forest\")\nplt.xlabel(\"Number Of Trees\")\nplt.ylabel(\"Accuracy Score\")\nplt.tight_layout()\nplt.legend(loc=\"best\")\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_pred_rf = rf.predict(X_test)\n\n#print(\"Random Forest accuracy score: {:.2f}\".format(accuracy_score(y_test, y_pred_rf)), \"\\n\")\n#print(\"Random Forest confusion matrix:\\n\", confusion_matrix(y_test, y_pred_rf, labels=[0,1]), \"\\n\")\n#print(classification_report(y_test, y_pred_rf, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\"n_estimators\":1000, \"max_depth\":6, \"seed\":123, \"tree_method\":\"gpu_hist\", \"predictor\":\"gpu_predictor\", \"n_gpus\":1}\nxg_cl = xgb.XGBClassifier(**params)\nxg_cl.fit(X_train, y_train)\ny_pred_xgb = xg_cl.predict(X_test)\n\n#accuracy = float(np.sum(y_pred_xgb==y_test))/y_test.shape[0]\n#print(\"XGBoost accuracy score: {:.2f}\".format(accuracy), \"\\n\")\n#print(\"XGBoost confusion matrix:\\n\", confusion_matrix(y_test, y_pred_xgb, labels=[0,1]), \"\\n\")\n#print(classification_report(y_test, y_pred_xgb, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logreg = LogisticRegression(random_state=5, solver=\"sag\")\nlogreg.fit(X_train, y_train)\ny_pred_lr = logreg.predict(X_test)\n\n#print(\"LogReg accuracy score: {:.2f}\".format(logreg.score(X_test, y_test)), \"\\n\")\n#print(\"LogReg confusion matrix:\\n\", confusion_matrix(y_test, y_pred_lr, labels=[0,1]), \"\\n\")\n#print(classification_report(y_test, y_pred_lr, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(5)\nknn.fit(X_train, y_train)\ny_pred_knn = knn.predict(X_test)\n\n#print(\"KNN accuracy score: {:.2f}\".format(accuracy_score(y_test, y_pred_knn)), \"\\n\")\n#print(\"KNN confusion matrix:\\n\", confusion_matrix(y_test, y_pred_knn, labels=[0,1]), \"\\n\")\n#print(classification_report(y_test, y_pred_knn, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svclassifier = SVC(kernel='linear')\nsvclassifier.fit(X_train, y_train)\ny_pred_svm = svclassifier.predict(X_test)\n\n#print(\"SVM accuracy score: {:.2f}\".format(accuracy_score(y_test, y_pred_svm)), \"\\n\")\n#print(\"SVM confusion matrix:\\n\", confusion_matrix(y_test, y_pred_svm, labels=[0,1]), \"\\n\")\n#print(classification_report(y_test, y_pred_svm, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nbclassifier = BernoulliNB()\nnbclassifier.fit(X_train, y_train)\ny_pred_nb = nbclassifier.predict(X_test)\n\n#print(\"Naive Bayes accuracy score: {:.2f}\".format(accuracy_score(y_test, y_pred_nb)), \"\\n\")\n#print(\"Naive Bayes confusion matrix:\\n\", confusion_matrix(y_test, y_pred_nb, labels=[0,1]), \"\\n\")\n#print(classification_report(y_test, y_pred_nb, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)\ny_pred_dt = dt.predict(X_test)\n\n#print(\"Decision Tree accuracy score: {:.2f}\".format(accuracy_score(y_test, y_pred_dt)), \"\\n\")\n#print(\"Decision Tree confusion matrix:\\n\", confusion_matrix(y_test, y_pred_dt, labels=[0,1]), \"\\n\")\n#print(classification_report(y_test, y_pred_dt, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_rf = pd.DataFrame({\n        \"ID_code\": test[\"ID_code\"],\n        \"target\": y_pred_rf\n})\nsubmission_xgb = pd.DataFrame({\n        \"ID_code\": test[\"ID_code\"],\n        \"target\": y_pred_xgb\n})\nsubmission_lr = pd.DataFrame({\n        \"ID_code\": test[\"ID_code\"],\n        \"target\": y_pred_lr\n})\nsubmission_knn = pd.DataFrame({\n        \"ID_code\": test[\"ID_code\"],\n        \"target\": y_pred_knn\n})\nsubmission_svm = pd.DataFrame({\n        \"ID_code\": test[\"ID_code\"],\n        \"target\": y_pred_svm\n})\nsubmission_nb = pd.DataFrame({\n        \"ID_code\": test[\"ID_code\"],\n        \"target\": y_pred_nb\n})\nsubmission_dt = pd.DataFrame({\n        \"ID_code\": test[\"ID_code\"],\n        \"target\": y_pred_dt\n})\nsubmission_rf.to_csv('submission_rf.csv', index=False)\nsubmission_xgb.to_csv('submission_xgb.csv', index=False)\nsubmission_lr.to_csv('submission_lr.csv', index=False)\nsubmission_knn.to_csv('submission_knn.csv', index=False)\nsubmission_svm.to_csv('submission_svm.csv', index=False)\nsubmission_nb.to_csv('submission_nb.csv', index=False)\nsubmission_dt.to_csv('submission_dt.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}