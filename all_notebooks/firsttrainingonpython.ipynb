{"nbformat":4,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"mimetype":"text/x-python","pygments_lexer":"ipython3","file_extension":".py","name":"python","codemirror_mode":{"version":3,"name":"ipython"},"version":"3.6.3","nbconvert_exporter":"python"}},"cells":[{"source":"# Описание данных","metadata":{},"cell_type":"markdown"},{"source":"Произведем импорт файла и первоначальное исследование.","metadata":{},"cell_type":"markdown"},{"source":"import pandas as pd\nimport numpy as np\n\n\ndf = pd.read_csv('./UCI_Credit_Card.csv')","metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"df.head()","metadata":{"scrolled":false},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"ID: ID клиента <br>\nLIMIT_BAL: Сумма кредитного лимита <br>\nSEX: Пол (1=М, 2=Ж) <br>\nEDUCATION: (1=Среднее, 2=ПТУ, 3=Высшее, 4=Другое, 5, 6=Неизвестно) <br>\nMARRIAGE: Семейное положение (1=Женат/Замужем, 2=Холост, 3=Другое) <br>\nAGE: Возраст, лет <br>\nPAY_0: Наличие просрочки in September, 2005 (-1=платеж во время, 1=просрочка один месяц, ... 9=просрочка девять месяцев и далее) <br>\n...\n<br>\nPAY_6: Наличие просрочки in April, 2005 (scale same as above) <br>\nBILL_AMT1: Сумма остатка на счете in September, 2005 (NT dollar) <br>\n...\n<br>\nBILL_AMT6: Сумма остатка на счете in April, 2005 (NT dollar) <br>\nPAY_AMT1: Сумма предыдущего платежа in September, 2005 (NT dollar) <br>\n...\n<br>\nPAY_AMT6: Сумма предыдущего платежа in April, 2005 (NT dollar) <br>\n**dflt: Целевая метрика - просроченный платеж (1=yes, 0=no)** <br>","metadata":{},"cell_type":"markdown"},{"source":"df.describe()","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"Видим, что в нашей выборке 30 тыс. строк. Средняя сумма кредитного лимита - 167484 $. Средний возраст клиента - 35 лет. Судя по параметру \"Пол\" несколько больше клиентов женского пола. Образование в основном ближе к среднему специальному. **По целевой метрике - количество дефолтов по отношению ко всему объему данных - около 22%, т.е. видна некоторая \"перекошенность\" классов, что, впрочем, для задач классификации является частым явлением.**\n","metadata":{},"cell_type":"markdown"},{"source":"df[df['dflt'] == 1].head()","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"Отфильтруем данные по целевому показателю - dflt и визуально сравним первые пять строк каждой из выборок","metadata":{},"cell_type":"markdown"},{"source":"df[df['dflt'] == 0].head()","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"Уже из случайной выборки, посмотрев на фичи можно сказать, что видна **корреляция целевого признака с показателем просроченности платежей за предыдущие месяцы (PAY_N).** Клиенты, у которых нет дефолта - либо не пользовались картой в предыдущих месяцах (0), либо платили вовремя (-1). Клиенты с дефолтом практически все допускали просрочку 1-2 месяца. Также можно отметить еще корреляцию с возрастом. Просрочники - более молодые - в основном, до 30.Платящие в срок - почти все старше 30.","metadata":{},"cell_type":"markdown"},{"source":"# Визуальный анализ данных","metadata":{},"cell_type":"markdown"},{"source":"Произведем визуализацию полученных выше предположений про возраст и число просроченных платежей в предыдущих месяцах.","metadata":{},"cell_type":"markdown"},{"source":"%matplotlib inline \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.rcParams['figure.figsize'] = (8, 6)","metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"# Заменим значения в колонке dflt на True/False\n# Предварительно скопируем наш датафрейм в другой, чтобы добавлять различные столбцы и трансформировать без влияния на исходную выборку\nd = {0 : False, 1 : True}\nva = df.copy();\nva['dflt'] = va['dflt'].map(d)","metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"d = {False : 'До 30', True : '30 и старше'}\nva['older_30'] = (va['AGE'] >= 30).astype('bool').map(d)\npd.crosstab(va['dflt'], va['older_30'], margins=True)","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"sns.countplot(x='older_30', hue='dflt', data=va);\nax = plt.axes();\nax.set_title('Доля просрочников в зависимости от возраста',fontweight=\"bold\", size=12);","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"Исходя из построенного графика и кросс-таблице не видно какой то корреляции дефолта с возрастом. Более того, можно сказать, что доля просрочников в рамках рассматриваемых возрастных порогов примерно одинакова - 28-29%.\nПроведем подобное исследование для другой метрики - наличие просроченных платежей в предыдущие периоды.\nДля упрощения дальнейшего анализа преобразуем значения в полях PAY_N - -1 изменим в 0, все что больше 0 - в 1.","metadata":{},"cell_type":"markdown"},{"source":"d = {-2: 0,-1: 0,0: 0, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1}\nva['dflt_past'] = va['PAY_0'].map(d) + va['PAY_2'].map(d) + va['PAY_3'].map(d) + va['PAY_4'].map(d) + va['PAY_5'].map(d) + va['PAY_6'].map(d)\nd = {False : 'Без просрочек', True : 'Были просрочки'}\nva['dflt_past'] = (va['dflt_past'] > 0).astype('bool').map(d)\n\npd.crosstab(va['dflt'], va['dflt_past'], margins=True)","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"sns.countplot(x='dflt_past', hue='dflt', data=va);\nax = plt.axes();\nax.set_title('Доля просрочников в зависимости от статуса предыдущих платежей',fontweight=\"bold\", size=12);","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"Здесь видно, что доля просрочников среди платящих в срок значительно меньше, чем среди тех, кто выходил в просрочку в предыдущие периоды. Таким образом можно сказать, что, исходя из визуальной оценки, данный параметр **значительно влияет на целевую метрику**.","metadata":{},"cell_type":"markdown"},{"source":"Посмотрим корреляцию других показателей друг относительно друга, построив и раскрасив матрицу корреляции.","metadata":{},"cell_type":"markdown"},{"source":"plt.figure(figsize=(25,25))\nax = plt.axes()\ncorr = df.drop(['ID'], axis=1).corr()\nsns.heatmap(corr, vmax=1,vmin=-1, square=True, annot=True, cmap='Spectral',linecolor=\"white\", linewidths=0.01, ax=ax)\nax.set_title('Матрица корреляции признаков',fontweight=\"bold\", size=30)\nplt.show()","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"Матрица подтверждает выдвинутое ранее предположение - на целевой показатель ощутимо влияет только показатель PAY_0..6, все остальные - слабо связаны с ним.","metadata":{},"cell_type":"markdown"},{"source":"# Выбор метрики сравнения моделей","metadata":{},"cell_type":"markdown"},{"source":"Исходную выборку разобьем на две подвыборки - обучающую (train) и отложенную (hold) в соотношении 70% - 30%. Для повышения качества подбора и сравнения гиперпараметров моделей и самих моделей между собой будем использовать на обучающей выборке кросс-валидацию, т.к. объем данных не очень большой и время работы будет приемлемым.\n\nМетрики, которые будут использоваться для сравнения моделей: <br>\n**accuracy** - точность \"попадания\" - доля правильно предсказанных ответов целевой метрики <br>\nПоскольку классы у нас несбалансированы - доля просрочников меньше, кроме того есть явное требование к модели - ошибка типа \"False Negative\" хуже, чем \"False Positive\" (лучше некорректно отнести хорошего клиента к просрочникам и дополнительно его проинформировать, чем не выявить потенциального просрочника), также будем использовать: <br>\n**confuzion_matrix** - матрица ошибок <br>\n**precision** - точность, \n**recall** - полнота <br>\n**AUC-ROC** - коэффициент, вид кривой","metadata":{},"cell_type":"markdown"},{"source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV","metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"# Деревья решений","metadata":{},"cell_type":"markdown"},{"source":"Одним из популярных методов решения задачи классификации является построения дерева решений, с него и начнем.\n\n**Принцип работы дерева решений**\nВ наиболее простом виде это способ представления правил в иерархической, последовательной структуре. Основа такой структуры - ответы \"Да\" или \"Нет\" на ряд вопросов. Ветви (ребра графа) хранят в себе значения атрибутов, от которых зависит целевая функция, на листьях же записывается значение целевой функции. Существуют также и другие узлы - родительские и потомки - по которым происходит разветвление, и можно различить случаи.\nОсновной плюс - хорошая интерпретируемость\n\nДля обучения в библиотеке sklearn.tree используется класс DecisionTreeClassifier. \n<br>Основные параметры: \n    - max_depth - максимальная глубина дерева\n    - max_features - максимальное число признаков, по которым ищется лучшее разбиение в дереве\n    - min_samples_leaf - минимальное число объектов в листе\n\nЗададим x - совокупность фичей, y - целевая метрика","metadata":{},"cell_type":"markdown"},{"source":"# Выделяем матрицу с целевой метрикой\ny = df ['dflt']\n# Убираем из исходной матрицы поле с целевой метрикой\nx = df.drop('dflt', axis = 1)","metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"# Делим на обучающую и тестовую выборку\nfrom sklearn.model_selection import train_test_split, cross_val_score\nx_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.3, random_state = 17); # seed генератора случайных сил","metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"from sklearn.tree import DecisionTreeClassifier","metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"clf_tree = DecisionTreeClassifier() # Для начала выполним с дефолтными параметрами\ncvs = cross_val_score(clf_tree, x_train, y_train, cv=5) # Рассчитываем результат для кроссс-валидации","metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"np.mean(cvs)","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"На кросс-валидации доля верных ответов составляет 72%. При этом настроек не проводилось. Проведем подбор гиперпараметров.","metadata":{},"cell_type":"markdown"},{"source":"**Подбираем max_depth, max_features для дерева**","metadata":{},"cell_type":"markdown"},{"source":"tree_params = {'max_depth': np.arange(1,16), 'max_features' : [0.5, 0.7, 1]} # будем перебирать этот гиперпараметр в указанном диапазоне\ntree_grid = GridSearchCV(clf_tree, tree_params, cv=5, n_jobs=-1) # параллелим на все ядра","metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"%%time\ntree_grid.fit(x_train, y_train) # Обучаем модель","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"tree_grid.best_score_,tree_grid.best_params_","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"tree_grid.best_estimator_","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"С учетом оптимизации показатели улучшились, наиболее оптимальная длина дерева **max_depth = 3, max_features = 0.5**. При этом точность - **82%**.\nСделаем прогноз для отложенной выборки, начальную оценку проведем с помощью выбранной метрики accuracy","metadata":{},"cell_type":"markdown"},{"source":"tree_valid_pred = tree_grid.predict(x_valid)","metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"**Вывод:** для новых данных наша модель на основе дерева решения будет правильно прогнозировать в **82% случаев**.\nЭкспортируем наше дерево для визуального просмотра. Ожидаемо, дерево построилось на метрике, которую мы выявили еще на этапе визуального анализа - **просроченные платежи за предыдущие периоды**. Здесь модель выбрала показатели PAY_0, PAY_2, PAY_3.","metadata":{},"cell_type":"markdown"},{"source":"from sklearn.tree import export_graphviz\nexport_graphviz(tree_grid.best_estimator_, out_file = \"tree_dflt.dot\", feature_names=x.columns, filled=True)","metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"<img src=\"files/tree_dflt.png\">","metadata":{},"cell_type":"markdown"},{"source":"# Метод ближайших соседей","metadata":{"collapsed":true},"cell_type":"markdown"},{"source":"**Описание метода:** <br>\nНа уровне интуиции: посмотри на соседей, какие преобладают, таков и ты. <br>\nФормально: основой является гипотеза компактности (для классификации) - если метрика расстояния между примерами введена достаточно удачно, то схожие примеры гораздо чаще лежат в одном классе, чем в разных. <br>\nОсновной плюс - хорошая интерпретируемость<br>\n\nПри использовании в задачах классификации объект присваивается тому классу, который является наиболее распространенным среди k соседей данного элемента, классы которых уже известны. <br>\n\nДля обучения модели в библиотеке sklearn.neighbors используется класс KNeighborsClassifier<br>\nОсновные гиперпараметры: <br>\n    **n_neighbors** - k - кол-во соседних элементов, которые будем учитывать <br>\n    **weights** - uniform (все веса равны), distance (вес обратно пропорционален расстоянию до тестового примера) <br>\n    **metric** - метрика для расчета расстояния (степени похожести) <br>\n    \nПо умолчанию для расчета расстояния используется метрика аналогичная Еквлидовому расстоянию, которое выражается формулой: <br>\n<center>$d=\\sqrt{(x_B-x_A)^2+(y_B-y_A)^2}$</center>","metadata":{},"cell_type":"markdown"},{"source":"from sklearn.neighbors import KNeighborsClassifier\ncls_knn = KNeighborsClassifier()\nnp.mean(cross_val_score(cls_knn, x_train, y_train, cv=5) )","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"knn_params = {'n_neighbors': list(range(50, 100, 10))} # будем перебирать этот гиперпараметр в указанном диапазоне\nknn_grid = GridSearchCV(cls_knn, knn_params, cv=5, n_jobs=-1) # параллелим на все ядра","metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"%%time\nknn_grid.fit(x_train, y_train) # Обучаем модель","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"knn_grid.best_score_,knn_grid.best_params_","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"knn_grid.best_estimator_","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"knn_valid_pred = knn_grid.predict(x_valid)","metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"**Вывод:** При поиске в довольно большом диапазоне возможных значений k получили, что наилучшую точность модель выдает на k=70, однако даже в этом случае точность модели оказывается ниже дерева решений - **всего 78%**. В связи с этим, дальнейшая \"подстройка\" гиперпараметра с большой вероятностью ничего не даст, поэтому изучение модели прекращаем.","metadata":{},"cell_type":"markdown"},{"source":"# Логистическая регрессия","metadata":{},"cell_type":"markdown"},{"source":"**Описание метода** <br>\nОсновная идея логистической регрессии заключается в том, что пространство исходных значений может быть разделено линейной границей (или гиперплоскостью) на две соответствующие классам области. Эта граница задается в зависимости от имеющихся исходных данных и обучающего алгоритма. Чтобы все работало, точки исходных данных должны разделяться линейной границей на две области. Если точки исходных данных удовлетворяют этому требованию, то их можно назвать линейно разделяемыми.\nОсновной гиперпараметр:\n    **с - коэффициент регуляризации**. Влияет на сложность модели - чем он выше, тем меньше сложность","metadata":{"collapsed":true},"cell_type":"markdown"},{"source":"from sklearn.linear_model import LogisticRegression\nLogisticRegression?","metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"logit = LogisticRegression(random_state=17)\nnp.mean(cross_val_score(logit, x_train, y_train.values.ravel(), cv=5))","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"logit_params = {'C': [0.000001, 0.00001, 0.0001, 0.001 ,0.01, 0.1, 1.0, 10, 100]} # будем перебирать этот гиперпараметр в указанном диапазоне\nlogit_grid = GridSearchCV(logit, logit_params, cv=5, n_jobs=-1) # параллелим на все ядра","metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"%%time\nlogit_grid.fit(x_train, y_train) # Обучаем модель","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"logit_grid.best_score_,logit_grid.best_params_","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"logit_grid.best_estimator_","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"logit_valid_pred = logit_grid.predict(x_valid)","metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"**Вывод:** Результат для метрики accuracy такой же, как и по методу kNN - 78%. Кроме этого, подбор гиперпараметров показал, что коэфициент регуляризации (С) стремится к наименьшему значению, что говорит о стремлении модели к максимальному усложнению.","metadata":{},"cell_type":"markdown"},{"source":"# Случайный лес","metadata":{},"cell_type":"markdown"},{"source":"**Описание метода** <br>\nМетод относится к группе методов, представляющих собой ансамбли моделей. <br>\nИсходная выборка методом бутстрэпа разбивается на N подвыборок, для каждой подвыборки строится решающее дерево. <br>\nПараметры: <br>\n**n_estimators** - число деревьев. Чем больше деревьев, тем лучше качество, но время настройки и работы RF также пропорционально увеличивается. Часто при увеличении n_estimators качество на обучающей выборке повышается, а качество на тесте выходит на ассимптоту. <br>\n**max_features** - число признаков для выбора расщепления. При увеличении параметра увеличивается время построения леса, а деревья становятся более однообразными. <br>\n**min_samples_split** - минимальное число объектов, при котором выполняется расщепление. <br>\n**max_depth** - максимальная глубина деревьев. Чем меньше глубина, тем быстрее строится и работает RF. При увеличении глубины резко возрастает качество на обучении, но и на контроле оно, как правило, увеличивается. Рекомендуется использовать максимальную глубину.","metadata":{},"cell_type":"markdown"},{"source":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=100, random_state=17, n_jobs=-1)\nrf.fit(x_train, y_train)","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"rf_valid_pred = rf.predict(x_valid)","metadata":{"collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"# Вывод. Сравнение моделей по метрикам\n## 1. Accuracy","metadata":{},"cell_type":"markdown"},{"source":"tree_accuracy = accuracy_score(y_valid, tree_valid_pred)\nknn_accuracy = accuracy_score(y_valid, knn_valid_pred)\nlogit_accuracy = accuracy_score(y_valid, logit_valid_pred)\nrf_accuracy = accuracy_score(y_valid, rf_valid_pred)\n\nprint(\"tree_accuracy = \" + str(tree_accuracy))\nprint(\"knn_accuracy = \" + str(knn_accuracy))\nprint(\"logit_accuracy = \" + str(logit_accuracy))\nprint(\"rf_accuracy = \" + str(rf_accuracy))","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"**Вывод:** **дерево решений и случайный лес дают примерно одинаковую наилучшую оценку accuracy ~ 82%**. Метод ближайших соседей и логистическая регрессия - также дают неплохую, но более низкую ~ 78%. <br>\nПричина по которой DT и RF дают одинаковую оценку вероятнее всего в том, что не так много признаков, которые действительно коррелируют с целевой метрикой, а именно - это только признаки PAY_0..6. В частности, поэтому увеличение глубины дерева также не давало какого либо эффекта, эстиматор выбрал оптимальную глубину max_depth = 2.","metadata":{},"cell_type":"markdown"},{"source":"## 2. Confuzion_matrix (матрица ошибок)","metadata":{},"cell_type":"markdown"},{"source":"tree_conf_matrix = confusion_matrix(y_valid, tree_valid_pred);\nknn_conf_matrix = confusion_matrix(y_valid, knn_valid_pred);\nlogit_conf_matrix = confusion_matrix(y_valid, logit_valid_pred);\nrf_conf_matrix = confusion_matrix(y_valid, rf_valid_pred);\n\nhm = sns.heatmap(tree_conf_matrix, annot=True); \nplt.title('Decision tree');","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"sns.heatmap(knn_conf_matrix,  annot=True);\nplt.title('kNN');","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"sns.heatmap(logit_conf_matrix, annot=True);\nplt.title('Logit');","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"sns.heatmap(rf_conf_matrix, annot=True);\nplt.title('Random Forest');","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"**Вывод:** **дерево решений и лес дают наиболее адекватную**, хоть и далекую от идеальной матрицу ошибок. Для логистической регрессии видно, что ни одно из позитивных значений не было правильно предсказано. Т.е. можно сделать вывод, что **для нашей задачи логистическая регрессия не работает совсем**.","metadata":{},"cell_type":"markdown"},{"source":"","metadata":{},"cell_type":"markdown"},{"source":"## 3. Precision, recall (точность, полнота)","metadata":{},"cell_type":"markdown"},{"source":"print(\"tree_classification_report\");\nprint(classification_report(y_valid, tree_valid_pred));\nprint(\"knn_classification_report\");\nprint(classification_report(y_valid, knn_valid_pred));\nprint(\"logit_classification_report\");\nprint(classification_report(y_valid, logit_valid_pred));\nprint(\"rf_classification_report\");\nprint(classification_report(y_valid, rf_valid_pred));","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"**Вывод:** дерево решений и лес дают адекватное значение точности (precision): 0.64 (RF), 0.69 (DT). Однако полнота (recall) низкая - 0.38 и 0.34 соответственно, что говорит о том, что 62% просрочников алгоритм не распознал, что довольно плохо.\nПоскольку у нас есть важная вводная - ошибка типа \"False Negative\" хуже, чем \"False Positive\", то нам больше важна полнота, чем точность, поэтому в данной метрике **лучшим является случайный лес**.","metadata":{},"cell_type":"markdown"},{"source":"## 4. ROC-кривая","metadata":{},"cell_type":"markdown"},{"source":"print(\"tree_roc_auc_score = \" + str(roc_auc_score(y_valid, tree_valid_pred)));\nprint(\"knn_roc_auc_score = \" + str(roc_auc_score(y_valid, knn_valid_pred)));\nprint(\"logit_roc_auc_score = \" + str(roc_auc_score(y_valid, logit_valid_pred)));\nprint(\"rf_roc_auc_score = \" + str(roc_auc_score(y_valid, rf_valid_pred)));","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"y_tree_proba = tree_grid.predict_proba(x_valid)\ny_rf_proba = rf.predict_proba(x_valid)\ny_knn_proba = knn_grid.predict_proba(x_valid)\ny_logit_proba = logit_grid.predict_proba(x_valid)\nfpr_tree, tpr_tree, tresholds_tree = roc_curve(y_valid,y_tree_proba[:,1])\nfpr_rf, tpr_rf, tresholds_rf = roc_curve(y_valid,y_rf_proba[:,1])\nfpr_knn, tpr_knn, tresholds_knn = roc_curve(y_valid,y_knn_proba[:,1])\nfpr_logit, tpr_logit, tresholds_logit = roc_curve(y_valid,y_logit_proba[:,1])\nimport matplotlib.pyplot as plt\nplt.plot(fpr_knn, tpr_knn, label = 'kNN')\nplt.plot(fpr_tree, tpr_tree, label = 'Decision tree')\nplt.plot(fpr_rf, tpr_rf, label = 'Random forest')\nplt.plot(fpr_logit, tpr_logit, label = 'Logit')\nplt.legend();\nplt.title('ROC-кривые');\nplt.show()","metadata":{},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"**Вывод:** **площадь под ROC кривой наибольшая у алгоритма RF (0.658)**, чуть меньше Desicion Tree (0.646). Это в общем то следует из того, что полнота для RF оказалась выше.","metadata":{},"cell_type":"markdown"},{"source":"## 5. Вывод\nВ рамках работы был исследован набор данных по клиентам - владельцам кредитных карт, при этом целевой метрикой являлся выход клиента в просрочку в следующем месяце. \nВвиду низкой коррелированности исходных признаков с целевым признаком показатели моделирования являются достаточно низкими (в основном из-за низкого значения recall для всех моделей), при этом наиболее оптимальными моделями оказались дерево решений и случайный лес - по метрикам они практически одинаковы, однако **случайный лес (RF) дает наибольшую полноту, поэтому для нашего случая он является оптимальным.** <br>\nУдалось добиться следующих показателей: <br>\naccuracy = 0.82 <br>\nprecision = 0.64 <br>\nrecall = 0.38 <br>\nroc_auc_score = 0.68 <br>\nЭтот результат похож на результат (не хуже) других участников Kaggle (во всяком случае при беглом просмотре не удалось найти примеры, где accuracy > 82%).","metadata":{},"cell_type":"markdown"}],"nbformat_minor":1}