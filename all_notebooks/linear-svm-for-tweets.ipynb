{"cells":[{"metadata":{"_cell_guid":"3fb90d46-4cf7-edf1-f149-6fdd49ecabb2","trusted":false},"cell_type":"code","source":"# Before we begin, we supress deprecation warnings resulting from nltk on Kaggle\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f5f1a8d6-2465-1f81-50ca-173e7d15d79c","trusted":false},"cell_type":"code","source":"import pandas as pd\ntweets = pd.read_csv(\"../input/Tweets.csv\")\nlist(tweets.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"56171d3a-313c-a946-fb1e-8c86cc3d1966","trusted":false},"cell_type":"code","source":"tweets.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fbdaecb5-81f1-50c3-4ec7-a34a8262a5cf","trusted":false},"cell_type":"code","source":"sentiment_counts = tweets.airline_sentiment.value_counts()\nnumber_of_tweets = tweets.tweet_id.count()\nprint(sentiment_counts)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e14cfc54-490d-ce20-4031-cd385a6999d0","trusted":false},"cell_type":"code","source":"normalizer(\"Here is text about an airline I like.\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"33e1be47-7c09-948b-101d-380ccaeb4196","trusted":false},"cell_type":"code","source":"pd.set_option('display.max_colwidth', -1) # Setting this so we can see the full content of cells\ntweets['normalized_tweet'] = tweets.text.apply(normalizer)\ntweets[['text','normalized_tweet']].head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5e83d39c-c35d-dc3f-1d24-013810053bc9","trusted":false},"cell_type":"code","source":"from nltk import ngrams\ndef ngrams(input_list):\n    #onegrams = input_list\n    bigrams = [' '.join(t) for t in list(zip(input_list, input_list[1:]))]\n    trigrams = [' '.join(t) for t in list(zip(input_list, input_list[1:], input_list[2:]))]\n    return bigrams+trigrams\ntweets['grams'] = tweets.normalized_tweet.apply(ngrams)\ntweets[['grams']].head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c0b51587-a300-8f90-cd30-f44791540f96"},"cell_type":"markdown","source":"And now some counting."},{"metadata":{"_cell_guid":"3a4c4888-2be9-54d6-9b5b-9b8b336cdfa8","trusted":false},"cell_type":"code","source":"import collections\ndef count_words(input):\n    cnt = collections.Counter()\n    for row in input:\n        for word in row:\n            cnt[word] += 1\n    return cnt","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c0395d2b-61cb-213e-6c38-e476770a9028","trusted":false},"cell_type":"code","source":"tweets[(tweets.airline_sentiment == 'negative')][['grams']].apply(count_words)['grams'].most_common(20)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cdca1e1c-eb02-239f-eb98-dc16e32dbcde"},"cell_type":"markdown","source":"We can already tell there's a pattern here. Sentences like \"cancelled flight\", \"late flight\", \"booking problems\",  \"delayed flight\" stand out clearly. Lets check the positive tweets."},{"metadata":{"_cell_guid":"aa00dfb3-81e0-980b-cfd2-e56454a612c4","trusted":false},"cell_type":"code","source":"tweets[(tweets.airline_sentiment == 'positive')][['grams']].apply(count_words)['grams'].most_common(20)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"13b5d690-eb25-6243-7a40-c06cfa3bf825"},"cell_type":"markdown","source":"## Preparing the data"},{"metadata":{"_cell_guid":"f16bfa38-fb30-aff1-d53a-54d23b6a4322","trusted":false},"cell_type":"code","source":"import numpy as np\nfrom scipy.sparse import hstack\nfrom sklearn.feature_extraction.text import CountVectorizer\ncount_vectorizer = CountVectorizer(ngram_range=(1,2))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3a964c4c-c16e-6592-e68e-3f6ef1197fdc","trusted":false},"cell_type":"code","source":"vectorized_data = count_vectorizer.fit_transform(tweets.text)\nindexed_data = hstack((np.array(range(0,vectorized_data.shape[0]))[:,None], vectorized_data))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"457bdfd2-685d-bbc1-699f-1954108dd1d5","trusted":false},"cell_type":"code","source":"def sentiment2target(sentiment):\n    return {\n        'negative': 0,\n        'neutral': 1,\n        'positive' : 2\n    }[sentiment]\ntargets = tweets.airline_sentiment.apply(sentiment2target)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f215daf3-d2b9-134b-a371-98ef9bc3c4e7"},"cell_type":"markdown","source":"To check performance of our classifier we want to split our data in to train and test."},{"metadata":{"_cell_guid":"c99298bd-84e9-d31e-58d1-00dbbdfa83e1","trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndata_train, data_test, targets_train, targets_test = train_test_split(indexed_data, targets, test_size=0.4, random_state=0)\ndata_train_index = data_train[:,0]\ndata_train = data_train[:,1:]\ndata_test_index = data_test[:,0]\ndata_test = data_test[:,1:]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ed3e70df-a983-fb02-1b47-0499bda60850","trusted":false},"cell_type":"code","source":"from sklearn import svm\nfrom sklearn.multiclass import OneVsRestClassifier\nclf = OneVsRestClassifier(svm.SVC(gamma=0.01, C=100., probability=True, class_weight='balanced', kernel='linear'))\nclf_output = clf.fit(data_train, targets_train)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3f5a37b6-e56f-036b-e44e-9ec4814cd8d7"},"cell_type":"markdown","source":"## Evaluation of results"},{"metadata":{"_cell_guid":"1af23c8b-7c12-63f5-260b-9f34d1285064","trusted":false},"cell_type":"code","source":"clf.score(data_test, targets_test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6f1e98e8-f816-5e9a-f0f9-957798dfa8c1"},"cell_type":"markdown","source":"It's most likely possible to achieve a higher score with more tuning, or a more advanced approach. Lets check on how it does on a couple of sentences."},{"metadata":{"_cell_guid":"c8a2059d-c320-c958-613e-0085c791f128","trusted":false},"cell_type":"code","source":"sentences = count_vectorizer.transform([\n    \"What a great airline, the trip was a pleasure!\",\n    \"My issue was quickly resolved after calling customer support. Thanks!\",\n    \"What the hell! My flight was cancelled again. This sucks!\",\n    \"Service was awful. I'll never fly with you again.\",\n    \"You fuckers lost my luggage. Never again!\",\n    \"I have mixed feelings about airlines. I don't know what I think.\",\n    \"\"\n])\nclf.predict_proba(sentences)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c94ef2e0-bd5d-bfb9-16ac-90459b0d29e0","trusted":false},"cell_type":"code","source":"predictions_on_test_data = clf.predict_proba(data_test)\nindex = np.transpose(np.array([range(0,len(predictions_on_test_data))]))\nindexed_predictions = np.concatenate((predictions_on_test_data, index), axis=1).tolist()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a1346d01-0e5d-8f01-b364-1523c8665203","trusted":false},"cell_type":"code","source":"def marginal(p):\n    top2 = p.argsort()[::-1]\n    return abs(p[top2[0]]-p[top2[1]])\nmargin = sorted(list(map(lambda p : [marginal(np.array(p[0:3])),p[3]], indexed_predictions)), key=lambda p : p[0])\nlist(map(lambda p : tweets.iloc[data_test_index[int(p[1])].toarray()[0][0]].text, margin[0:10]))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fa092618-003a-c2e5-1228-a95aa18337ef","trusted":false},"cell_type":"code","source":"list(map(lambda p : predictions_on_test_data[int(p[1])], margin[0:10]))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c2468ac1-b7fb-889c-50a3-e5d7af0269d5","trusted":false},"cell_type":"code","source":"list(map(lambda p : tweets.iloc[data_test_index[int(p[1])].toarray()[0][0]].text, margin[-10:]))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"80f2aff9-3273-caab-b9a4-959aebc9d69d","trusted":false},"cell_type":"code","source":"list(map(lambda p : predictions_on_test_data[int(p[1])], margin[-10:]))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"48fe3201-eb49-9617-eeb5-fca45beb657f","trusted":false},"cell_type":"code","source":"import matplotlib.pyplot as plt\nmarginal_probs = list(map(lambda p : p[0], margin))\nn, bins, patches = plt.hist(marginal_probs, 25, facecolor='blue', alpha=0.75)\nplt.title('Marginal confidence histogram - All data')\nplt.ylabel('Count')\nplt.xlabel('Marginal confidence')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1709f0eb-febe-0161-f1df-ac9585ff580d","trusted":false},"cell_type":"code","source":"positive_test_data = list(filter(lambda row : row[0]==2, hstack((targets_test[:,None], data_test)).toarray()))\npositive_probs = clf.predict_proba(list(map(lambda r : r[1:], positive_test_data)))\nmarginal_positive_probs = list(map(lambda p : marginal(p), positive_probs))\nn, bins, patches = plt.hist(marginal_positive_probs, 25, facecolor='green', alpha=0.75)\nplt.title('Marginal confidence histogram - Positive data')\nplt.ylabel('Count')\nplt.xlabel('Marginal confidence')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"eea28df4-f4a2-0b9b-2547-173935fe551c","trusted":false},"cell_type":"code","source":"positive_test_data = list(filter(lambda row : row[0]==1, hstack((targets_test[:,None], data_test)).toarray()))\npositive_probs = clf.predict_proba(list(map(lambda r : r[1:], positive_test_data)))\nmarginal_positive_probs = list(map(lambda p : marginal(p), positive_probs))\nn, bins, patches = plt.hist(marginal_positive_probs, 25, facecolor='blue', alpha=0.75)\nplt.title('Marginal confidence histogram - Neutral data')\nplt.ylabel('Count')\nplt.xlabel('Marginal confidence')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"52fda712-b5c7-7bb2-0333-68a888547226","trusted":false},"cell_type":"code","source":"negative_test_data = list(filter(lambda row : row[0]==0, hstack((targets_test[:,None], data_test)).toarray()))\nnegative_probs = clf.predict_proba(list(map(lambda r : r[1:], negative_test_data)))\nmarginal_negative_probs = list(map(lambda p : marginal(p), negative_probs))\nn, bins, patches = plt.hist(marginal_negative_probs, 25, facecolor='red', alpha=0.75)\nplt.title('Marginal confidence histogram - Negative data')\nplt.ylabel('Count')\nplt.xlabel('Marginal confidence')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":4}