{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport csv\nimport librosa\nimport collections\nimport logging\nimport os\nimport pathlib\nimport re\nimport string\nimport sys\nimport time\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport glob\nfrom keras.layers import Dense, Conv2D, Dropout, BatchNormalization, MaxPooling2D, Flatten, Input\nfrom keras import Sequential\nimport kerastuner as kt\nimport tensorflow as tf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def createSpectrogram(path):\n  y, sr = librosa.load(path , duration=2.97)\n  spect = librosa.feature.melspectrogram(y=y, sr=sr)\n  return spect\n\nfilename = '../input/gtzan-dataset-music-genre-classification/Data/genres_original'\ngen_dict = dict()\n\ndata = np.zeros((999, 128, 128)).astype(np.float64)\n# labels = np.empty((1000, 1)).astype(np.int32)\nlabels = []\nlabel_to_num = {k:v for v, k in enumerate(os.listdir(filename))}\nnum_to_label = {v:k for v, k in enumerate(os.listdir(filename))}\n\nfor folder in os.listdir(filename):\n    new = filename + \"/\" + folder + \"/*.wav\"\n    for row, wav_file in enumerate(glob.glob(new)):\n        if wav_file != '../input/gtzan-dataset-music-genre-classification/Data/genres_original/jazz/jazz.00054.wav':\n            spect = createSpectrogram(wav_file)\n            data[row, :, :] = spect\n            labels.append(label_to_num[folder])\n            \nlabels = np.array(labels)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels1 = pd.get_dummies(labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size = 0.2,random_state=42, shuffle = True)\nX_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.5,random_state=42, shuffle = True)\n\n\n\ndef add_dim(arr):\n    shape = arr.shape\n    return np.array([elm.reshape(shape[1], shape[2], 1) for elm in arr])\n\nX_train = add_dim(X_train)\nX_test = add_dim(X_test)\nX_val = add_dim(X_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = X_train.shape[1:]\ndef build_CNN_model(input_shape):\n    model = Sequential([\n    Input(input_shape),\n    Conv2D(8,kernel_size=(3,3),strides=(1,1), activation = 'relu'),\n    MaxPooling2D((2,2)),\n    \n    Conv2D(16,kernel_size=(3,3),strides=(1,1), activation = 'relu'),\n    BatchNormalization(),\n    MaxPooling2D((2,2)),\n\n    Conv2D(32,kernel_size=(3,3),strides=(1,1), activation = 'relu'),\n    MaxPooling2D((2,2)),\n        \n    Conv2D(64,kernel_size=(3,3),strides=(1,1), activation = 'relu'),\n    MaxPooling2D((2,2)),\n\n    Conv2D(128,kernel_size=(3,3),strides=(1,1), activation = 'relu'),\n    MaxPooling2D((2,2)),\n\n    Flatten(),\n    Dropout(rate=0.3),\n    Dense(10, activation='softmax')])\n\n    model.compile(loss='SparseCategoricalCrossentropy',\\\n                  optimizer='rmsprop', metrics=['accuracy'])\n    \n    return model\n\n# tuner = kt.Hyperband(build_CNN_model,\n#                      objective='val_accuracy',\n#                      max_epochs=30,\n                     \n#                      directory='./',\n#                      project_name='pro2')\n# tuner.search(X_train, y_train, epochs=50, validation_data=(X_val, y_val), callbacks=[stop_early])\n\n# Get the optimal hyperparameters\n# best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n\n# Invoking the model and training it\ncnn_model = build_CNN_model(input_shape)\ncnn_model.fit(X_train, y_train, epochs = 150, validation_data = (X_val, y_val), batch_size = 32, \\\n             callbacks = [stop_early])\n\n\n# Evaluating the model\n# cnn_model.evaluate((X_test, y_test), batch_size = 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MFCC = pd.read_csv('../input/gtzan-dataset-music-genre-classification/Data/features_30_sec.csv')\nMFCC_y = MFCC.label\nMFCC_X = MFCC.drop(columns = ['label', 'filename', 'length'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MFCC_y_arr = np.delete(np.array(MFCC_y), 554, 0)\n# MFCC_X_arr = np.delete(np.array(MFCC_X), 554, 0)\ndef add_dim(arr):\n    shape = arr.shape\n    if len(shape) == 3:\n        return np.array([elm.reshape(shape[1], shape[2], 1) for elm in arr])\n    else:\n        return np.array([elm.reshape(shape[1], 1) for elm in arr])\nMFCC_X_arr = add_dim(MFCC_X_arr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MFCC_X_train, MFCC_X_test, MFCC_y_train, MFCC_y_test = train_test_split(MFCC_X, MFCC_y, test_size = 0.2,random_state=42, shuffle = True)\n# MFCC_X_test, MFCC_X_val, MFCC_y_test, MFCC_y_val = train_test_split(MFCC_X_test, MFCC_y_test, test_size = 0.5,random_state=42, shuffle = True)\ndef test_split(X, y):\n    X = np.array(X)\n    y = np.array(y)\n    if len(X.shape) == 2:\n        X_train = np.empty((800, X.shape[1]))\n        X_test = np.empty((100, X.shape[1]))\n        X_val = np.empty((99, X.shape[1]))\n        y_train = np.empty((800, y.shape[1]))\n        y_test = np.empty((100, y.shape[1]))\n        y_val = np.empty((99, y.shape[1]))\n    else:\n        X_train = np.empty((800, X.shape[1], X.shape[2]))\n        X_test = np.empty((100, X.shape[1], X.shape[2]))\n        X_val = np.empty((99, X.shape[1], X.shape[2]))\n        y_train = np.empty((800, y.shape[1]))\n        y_test = np.empty((100, y.shape[1]))\n        y_val = np.empty((99, y.shape[1]))\n    j = 0\n    for i in range(0, 1000, 100):\n        X_train[j*80: j * 80 + 80,:] = X[i: i +80,:]\n        X_test[j*10: j * 10 + 10,:] = X[i + 80: i + 90,:]\n        X_val[j*10: j * 10 + 10,:] = X[i + 90: i +100,:]\n        y_val[j*10: j * 10 + 10,:] = y[i + 90: i + 100,:]\n        y_train[j*80: j * 80 + 80,:] = y[i: i + 80,:]\n        y_test[j*10: j * 10 + 10,:] = y[i + 80: i + 90,:]\n        j+=1\n\n    return X_train, X_test, X_val, y_train, y_test, y_val\n#     return X_train\nMFCC_X_train, MFCC_X_test, MFCC_X_val, MFCC_y_train, MFCC_y_test, MFCC_y_val = test_split(MFCC_X_arr, labels1)\nSpect_X_train, Spect_X_test, Spect_X_val, Spect_y_train, Spect_y_test, Spect_y_val = test_split(data, labels1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Our_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_dim_MFCC(arr):\n    shape = arr.shape\n    return np.array([elm.reshape(shape[1], 1) for elm in arr])\n\nMFCC_X_train = add_dim_MFCC(np.array(MFCC_X_train))\nMFCC_X_test = add_dim_MFCC(np.array(MFCC_X_test))\nMFCC_X_val = add_dim_MFCC(np.array(MFCC_X_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def my_model(MFCC, Sepct):\n    X_sepct_in = Input(MFCC)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_angles(pos, i, d_model):\n  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n  return pos * angle_rates\n\ndef positional_encoding(position, d_model):\n  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n                          np.arange(d_model)[np.newaxis, :],\n                          d_model)\n\n  # apply sin to even indices in the array; 2i\n  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n\n  # apply cos to odd indices in the array; 2i+1\n  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n\n  pos_encoding = angle_rads[np.newaxis, ...]\n\n  return tf.cast(pos_encoding, dtype=tf.float32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def scaled_dot_product_attention(query, key, value, mask):\n  matmul_qk = tf.matmul(query, key, transpose_b=True)\n\n  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n  logits = matmul_qk / tf.math.sqrt(depth)\n\n  # add the mask zero out padding tokens.\n  if mask is not None:\n    logits += (mask * -1e9)\n\n  attention_weights = tf.nn.softmax(logits, axis=-1)\n\n  return tf.matmul(attention_weights, value)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MultiHeadAttention(tf.keras.layers.Layer):\n\n  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n    super(MultiHeadAttention, self).__init__(name=name)\n    self.num_heads = num_heads\n    self.d_model = d_model\n\n    assert d_model % self.num_heads == 0\n\n    self.depth = d_model // self.num_heads\n\n    self.query_dense = tf.keras.layers.Dense(units=d_model)\n    self.key_dense = tf.keras.layers.Dense(units=d_model)\n    self.value_dense = tf.keras.layers.Dense(units=d_model)\n\n    self.dense = tf.keras.layers.Dense(units=d_model)\n\n  def split_heads(self, inputs, batch_size):\n    inputs = tf.reshape(\n        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n\n  def call(self, inputs):\n    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n        'value'], inputs['mask']\n    batch_size = tf.shape(query)[0]\n\n    # linear layers\n    query = self.query_dense(query)\n    key = self.key_dense(key)\n    value = self.value_dense(value)\n\n    # split heads\n    query = self.split_heads(query, batch_size)\n    key = self.split_heads(key, batch_size)\n    value = self.split_heads(value, batch_size)\n\n    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n\n    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n\n    concat_attention = tf.reshape(scaled_attention,\n                                  (batch_size, -1, self.d_model))\n\n    outputs = self.dense(concat_attention)\n\n    return outputs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PositionalEncoding(tf.keras.layers.Layer):\n\n  def __init__(self, position, d_model):\n    super(PositionalEncoding, self).__init__()\n    self.pos_encoding = self.positional_encoding(position, d_model)\n\n  def get_angles(self, position, i, d_model):\n    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n    return position * angles\n\n  def positional_encoding(self, position, d_model):\n    angle_rads = self.get_angles(\n        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n        d_model=d_model)\n    # apply sin to even index in the array\n    sines = tf.math.sin(angle_rads[:, 0::2])\n    # apply cos to odd index in the array\n    cosines = tf.math.cos(angle_rads[:, 1::2])\n\n    pos_encoding = tf.concat([sines, cosines], axis=-1)\n    pos_encoding = pos_encoding[tf.newaxis, ...]\n    return tf.cast(pos_encoding, tf.float32)\n\n  def call(self, inputs):\n    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This allows to the transformer to know where there is real data and where it is padded\ndef create_padding_mask(seq):\n  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n  \n  # add extra dimensions to add the padding\n  # to the attention logits.\n  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encoder_layer(units, d_model, num_heads, dropout,name=\"encoder_layer\"):\n  inputs = tf.keras.Input(shape=(None,d_model ), name=\"inputs\")\n  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n\n  attention = MultiHeadAttention(\n      d_model, num_heads, name=\"attention\")({\n          'query': inputs,\n          'key': inputs,\n          'value': inputs,\n          'mask': padding_mask\n      })\n  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n  attention = tf.keras.layers.LayerNormalization(\n      epsilon=1e-6)(inputs + attention)\n\n  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n  outputs = tf.keras.layers.LayerNormalization(\n      epsilon=1e-6)(attention + outputs)\n\n  return tf.keras.Model(\n      inputs=[inputs, padding_mask], outputs=outputs, name=name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encoder(time_steps,\n            num_layers,\n            units,\n            d_model,\n            num_heads,\n            dropout,\n            projection,\n            name=\"encoder\"):\n  inputs = tf.keras.Input(shape=(None,d_model), name=\"inputs\")\n  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n  \n  if projection=='linear':\n    projection=tf.keras.layers.Dense( d_model,use_bias=True, activation='linear')(inputs)\n    print('linear')\n  \n  else:\n    projection=tf.identity(inputs)\n    print('none')\n   \n  projection *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n  projection = PositionalEncoding(time_steps, d_model)(projection)\n\n  outputs = tf.keras.layers.Dropout(rate=dropout)(projection)\n\n  for i in range(num_layers):\n    outputs = encoder_layer(\n        units=units,\n        d_model=d_model,\n        num_heads=num_heads,\n        dropout=dropout,\n        name=\"encoder_layer_{}\".format(i),\n    )([outputs, padding_mask])\n \n \n  \n\n \n  return tf.keras.Model(\n      inputs=[inputs, padding_mask], outputs=outputs, name=name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transformer(time_steps,\n                num_layers,\n                units,\n                d_model,\n                num_heads,\n                dropout,\n                output_size,\n                projection,\n                name=\"transformer\"):\n  inputs = tf.keras.Input(shape=(None,d_model), name=\"inputs\")\n  \n  \n  enc_padding_mask = tf.keras.layers.Lambda(\n      create_padding_mask, output_shape=(1, 1, None),\n      name='enc_padding_mask')(tf.dtypes.cast(\n          \n    #Like our input has a dimension of length X d_model but the masking is applied to a vector\n    # We get the sum for each row and result is a vector. So, if result is 0 it is because in that position was masked      \n    tf.math.reduce_sum(\n    inputs,\n    axis=2,\n    keepdims=False,\n    name=None\n), tf.int32))\n  \n\n  enc_outputs = encoder(\n      time_steps=time_steps,\n      num_layers=num_layers,\n      units=units,\n      d_model=d_model,\n      num_heads=num_heads,\n      dropout=dropout,\n      projection=projection,\n      name='encoder'\n  )(inputs=[inputs, enc_padding_mask])\n\n  #We reshape for feeding our FC in the next step\n  outputs=tf.reshape(enc_outputs,(-1,time_steps*d_model))\n  \n  #We predict our class\n  outputs = tf.keras.layers.Dense(units=output_size,use_bias=True,activation='softmax', name=\"outputs\")(outputs)\n\n  return tf.keras.Model(inputs=[inputs], outputs=outputs, name='audio_class')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nNUM_LAYERS = 4\nD_MODEL = data.shape[2]\nNUM_HEADS = 4\nUNITS = 2048\nDROPOUT = 0.1\nTIME_STEPS= data.shape[1]\nOUTPUT_SIZE=10\nEPOCHS = 100\nEXPERIMENTS=10\n\n\n\nmodel = transformer(time_steps=TIME_STEPS,\n  num_layers=NUM_LAYERS,\n  units=UNITS,\n  d_model=D_MODEL,\n  num_heads=NUM_HEADS,\n  dropout=DROPOUT,\n  output_size=OUTPUT_SIZE,  \n  projection='linear'  )\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(0.000001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n\nmodel.fit(X_train,y_train, epochs=EPOCHS, validation_data=(X_val, y_val), verbose = 1)\n\n# accuracy.append(max(history.history['val_accuracy']))\n\n# proj_implemented.append(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfile = pd.read_csv(\"../input/features-extracted-52/Features_Exctracted 52.csv\")\nfile = file.drop(['filename'], axis = 1)\ny = file.label\nX = file.drop(columns = ['label'])\nscaler = StandardScaler()\nX = scaler.fit_transform(np.array(X, dtype = float))\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=0, shuffle=True)\n\nlabel_encoder = LabelEncoder()\ntransformed_train_y = label_encoder.fit_transform(train_y)\ntransformed_test_y = label_encoder.transform(test_y)\ntr_y = pd.get_dummies(train_y)\nte_y = pd.get_dummies(test_y)\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}