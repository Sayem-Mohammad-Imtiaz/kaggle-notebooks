{"cells":[{"metadata":{},"cell_type":"markdown","source":"# IRIS DATASET EXPLORATION"},{"metadata":{"trusted":true},"cell_type":"code","source":"{'name':'Álvaro Riobóo de Larriva',\n'start_date':'2021/03/09'}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#--< main modules >--#\nimport numpy as np \nimport pandas as pd \nimport scipy as sp\nimport statsmodels.api as sm\nimport sklearn\n\n#--< visualization >--#\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#--< others >--#\nfrom datetime import datetime\nimport time\nfrom IPython.display import display \nimport pickle\nimport gc\n\nfor i in locals().copy():\n    try:\n        print(\"%s:\"%eval(i).__name__, eval(i).__version__)\n    except:\n        continue","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###----------------< START of 'iris_nb.ipynb'>---------------###","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## 0. LOAD DATASET AND PARAMETERS"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import datasets\niris_dict = datasets.load_iris()\nspecies_coded_dict = {k:v for k,v in enumerate(iris_dict['target_names'])}\n\n# Load iris dataframe.\ndata = pd.DataFrame(iris_dict['data'], columns=['sepal_length','sepal_width','petal_length','petal_width'])\ntarget = pd.DataFrame(iris_dict['target'], columns=['species'])\niris = pd.DataFrame.join(data, target)\n\n# Display info\nprint(iris_dict.keys())\nprint(\"\\nFeature_names:\", iris_dict['feature_names'])\nprint(\"\\nSpecies are coded as:\", species_coded_dict)\nprint(\"\\nNAN values:\\n%a\" %iris.isna().sum())\ndisplay(iris)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. EXPLORATORY DATA ANALYSIS (EDA)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display plain information, types and main stats.\ndescr = iris.describe()\n\niris.info()\ndisplay(descr)\n\nqlabels = ['min','25%','50%','75%','max']\nqvalues = descr.loc[qlabels] # we keep quartile values from df description ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pairplot\nsns.pairplot(iris)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Del anterior gráfico de pares vemos en la diagonal principal que \"sepal_length\" y \"sepal_width\" siguen una distribución t-student (si hubiese más datos sería mas parecida a la distribución normal). En cambio \"petal_length\" y \"petal_width\" parecen seguir una distribución bimodal. Nuestro target \"species\" sigue distribución uniforme, y de hecho vemos el mismo número de valores en todas las categorías. Éste es un dataset muy preparado y con probabilidad se habrán tocado datos a propósito desde el antiguo estudio del que es originario. \n\nTambién vemos un razonable número de casos pertenecientes a cada categoría del target. En los gráficos no diagonales restantes, podemos ver una correlación más o menos clara entre variables, incluso diversos grupos señalados dentro de los datos. Investigaremos ahora esta correlación.\n\nNOTA: No nos pararemos demasiado en verificar si las distribuciones mencionadas anteriormente son correctas en cada variable (diagonal principal). Pero de hacerlo, el procedimiento a seguir sería hacer un test $\\chi^2$ para bondad del ajuste en cada variable.\n\n1. Se hace un histograma de nuestras variables continuas en un cierto número de bins, normalizando al conteo total de valores ([0,1]). \n2. Se crea una variable con la distribución modelo dada la función de probabilidad de esa distribución, y de longitud el número de bines. Nótese que no es una random variable, sino una que sigue perfectamente la distribución.\n3. Se realiza el $\\chi^2$-test para determinar con un cierto grado de confianza $\\alpha$ si las distribuciones son independientes. En este caso $H_0$: expected dist. = observed dist, por lo que el test sólo puede determinar independencia entre las distribuciones, pero no asegura que la hipótesis nula (dependencia) sea correcta. En todo caso, cuanto mayor sea el p-value, más seguros estaremos de que las distribuciones son idénticas."},{"metadata":{"trusted":true},"cell_type":"code","source":"# BOXPLOT\nfig ,ax = plt.subplots(figsize=(20,10))\niris.boxplot(by='species', ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# HISTOGRAMS\nprint(plt.style.available)\nwith plt.style.context('classic'):\n    data.hist(bins=20, figsize=(10,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# HEATMAP (upper triangle)\narray = iris.iloc[:,:-1].corr()\nsns.heatmap(array, mask=np.tril(array), annot=True, fmt=\".2f\", cmap=plt.cm.inferno, square=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Del heatmap puede verse de manera visual como \"petal_length\" y \"petal_width\" están más correladas.\n\nTambién vemos una dependencia de 'sepal_length' con el target, y incluso vemos que 'sepal_width' está anticorrelada a los demás predictores.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# SEPAL & PETAL graphics\nsns.lmplot(x=\"sepal_width\", y=\"sepal_length\", hue=\"species\",data=iris)\nsns.lmplot(x=\"petal_width\", y=\"petal_length\", hue=\"species\",data=iris)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Gráfico sepal length/width: Las características del sépalo diferencian a la setosa, pero no a la versicolor y virginica entre sí.\n- Gráfico petal length/width: La setosa se caracteriza por tener dimensiones menores tanto en longitud como en anchura del pétalo. La versicolor y virginica parecen más diferenciables que en el gŕáfico anterior, aunque hay una cierta región de convivencia.\n\nVeremos si el test t-student y el chi-cuadrado nos pueden arrojar certidumbre sobre las poblaciones."},{"metadata":{"trusted":true},"cell_type":"code","source":"# TEST T-STUDENT: H0-> true diff in means=0 (two-sided test)/ rejectable if p-value<0.05 at 95% confidence.\nfrom scipy.stats import ttest_ind\nprint(species_coded_dict)\n\nsetosa = iris.loc[iris['species']==0]\nversicolor = iris.loc[iris['species']==1]\nvirginica = iris.loc[iris['species']==2]\n\npw_ttest = ttest_ind(versicolor['petal_width'], virginica['petal_width']) \npl_ttest = ttest_ind(versicolor['petal_length'], virginica['petal_length'])\nsw_ttest = ttest_ind(versicolor['sepal_width'], virginica['sepal_width']) \nsl_ttest = ttest_ind(versicolor['sepal_length'], virginica['sepal_length'])\n\nprint('\\nVersicolor vs. Virginica: Ttest')\nprint('petal_width--->{}\\npetal_length--->{}'.format(pw_ttest, pl_ttest))\nprint('sepal_width--->{}\\nsepal_length--->{}'.format(sw_ttest, sl_ttest))\n\n## alternative=greater for 'sepal_width' (versicolor < virginica ?)\nfrom scipy.stats import t\n\nt_crit_95 = t.ppf(df=len(virginica)+len(versicolor)-2, q=0.95) #df=degrees_freedom\nt_crit_99 = t.ppf(df=len(virginica)+len(versicolor)-2, q=0.99)\nprint('t critical at 95% conf:{}'.format(t_crit_95), \n     '\\n(idem for 99%):{}'.format(t_crit_99))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"El valor 'statistic' es lo que se denomina t-value. El signo de t en el test indica si la primera muestra tiende a ser mayor (+) o viceversa(-), en este caso obtenemos lo que ya sabíamos en los gráficos 'width'vs'length' anteriores. El hecho de que el t-value (de nuestros tests) sea mayor en valor absoluto que el t-value-crítico de nuestras muestras para un intervalo de confianza dado, nos indica que podemos rechazar la hipótesis nula y por tanto afirmar que las muestras poseen diferentes medias. Si tenemos que $t_{value} > t_{value-crit}$, podemos rechazar $H_0$, lo cual se dará en el caso de 'one-sided test, less-than' donde $H_0: \\mu_{versicolor} >= \\mu_{virginica} $, y podríamos afirmar la hipótesis alternativa $H_1: \\mu_{versicolor} < \\mu_{virginica}$, esto ocurre para los dos intervalos de confianza definidos (95 y 99\\%) para todas las variables.\n\nComo habíamos observado en los gráficos, los valores de 'sepal_width' y 'sepal_length' eran más difusos. Hemos comprobado con los anteriores tests, que aunque en media 'sepal_width' para las clases virginica y versicolor se parezcan, aún son separables. Aún así, es una muestra difusa de ser un peor predictor."},{"metadata":{"trusted":true},"cell_type":"code","source":"# TEST CHI-SQUARE FOR INDEPENDENCE BETWEEN CATEGORICALS: \n'''\nH0 -> sample dists are the same (table-samples)-> so that distinct categories of a variable doesn't affect the other variable \n -> variables are independent // rejectable if p-value<0.05 at 95% confidence. '''\nfrom scipy.stats import chisquare, chi2, chi2_contingency\nfrom scipy.stats import distributions\n\n# CATEGORICAL MAPPING: We map our dataset into a new one with categorical variables matching each interquartile range.\ndef map_quartile_ranges(x, col):\n    if x<qvalues.loc['25%',col]:\n        catv = 'low'\n    elif x<qvalues.loc['50%',col]:\n        catv = 'low-average'\n    elif x<qvalues.loc['75%',col]:\n        catv = 'high-average'\n    else:\n        catv = 'high'\n    return catv\n\ndata_cat = data.copy()\nfor c in data.columns:\n    data_cat[c] = data[c].map(lambda x: map_quartile_ranges(x, c))\n\ndef chi2contingency_by_LemmaOrCol(lemma, one_col):\n    if lemma:\n        features = data_cat.loc[:,data_cat.columns.str.contains(lemma)] \n        \n    else:\n        features = data_cat.loc[:,:] if not one_col else pd.DataFrame(data_cat.loc[:,one_col]) \n        \n    iris_cat = pd.DataFrame.join(features, iris['species'].astype('object'))\n\n    contable = iris_cat.value_counts().unstack('species').fillna(0)\n    display(contable)\n    res = chi2_contingency(contable)\n    gc.collect()\n    return res\n\nchi2contingency_by_LemmaOrCol(lemma = None, one_col=\"sepal_width\") \n# check lemma = 'sepal','petal','length','width', None\n# check all columns separately for lemma=None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos comprobar si las variables tienen dependencia con el target en una versión categórica del dataset, donde asignamos cuatro clases dependiendo del rango intercuartil en el que caigan [0->0.25,-> 0.5,->0.75,->1.00]. En todas las agrupaciones de columnas que se pueden comprobar con la función 'chi2contingency_by_LemmaOrCol', podemos ver un p-value demasiado bajo ($t<e^{-12}$), por lo cual podemos descartar la hipótesis nula que nos dice que las muestras son iguales y por tanto, nuestras variables categóricas son dependientes. Ésto es así porque hemos clasificado en categorías respecto a los rangos de cada variable, sin tener en cuenta las demás. Es decir, hemos comprobado algo tan obvio como que las tres especies de plantas son distintas entre sí atendiendo a la clasificación relativa de algunas de sus propiedades (como 'sepal_width'). Si hubiese alguna combinación de características categóricas que contribuyese significativamente a separar las especies (dependencia), se vería reflejada en este test al tener un p-value alto en torno a un intervalo de confianza aceptable."},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import chi2_contingency\n\nfor f in data.columns:\n    fig = plt.figure()\n    ax = fig.add_subplot()\n    ctab = pd.crosstab(iris['species'],iris[f])\n    sns.heatmap(ctab, ax=ax)\n    c, p, dof, expected = chi2_contingency(ctab,)\n    print(f,'p_value for test is:%f'%p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"La tabla de contingencia representada en heatmaps puede tener una interpretación menos clara. Se puede decir, que representa qué valores de una variable determinada contribuyen más al valor esperado de esa variable diferenciándola por nuestro target 'species'."},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.formula.api as smf\nimport patsy\n\n\nrhs = \"C(species)\"  # independent, categorical\nlhs = \"sepal_width\" # dependent, numeric\n\nformula = lambda lhs,rhs: lhs + \"~\" + rhs   # formulas are handled by \"patsy\" module (.dmatrices)\n#C(variable, method) wrapper that var as cathegory for patsy.dmatrices || default: method='Treatment'\n\n\n\n# OLS: cannot do \"species~(any)\" or \"(any) + 1 ~ species\". It compares same-shape arrays (ONE-WAY)\n[ print(\"{}:\\n{}\\n\".format(lhs, smf.ols( formula(lhs , rhs) ,data=iris).fit().summary())) for lhs in data.columns]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Un simple OLS para cada variable nos dice cómo de bien ajustaría esta variable, midiendo el $R^2$ del modelo resultante. Por el momento, vemos que \"sepal_width\" es el peor predictor, mientras que los mejores predictores serían la anchura y longitud del pétalo."},{"metadata":{},"cell_type":"markdown","source":"## 2. FINDING CANDIDATE ALGORITHMS"},{"metadata":{},"cell_type":"markdown","source":"Para la búsqueda de algoritmos candidatos, usaremos los siguientes para el problema de clasificación:\n\n- LogisticRegression()\n- KNeighborsClassifier()\n- DecisionTreeClassifier()\n- RandomForestClassifier()\n- SVC()\n- XGBClassifier()\n\nPodemos buscar los hiperparámetros más tarde por la clase **\"GridSearchCV\"**, recomendada para datasets con pocos datos y que comprueba todas las opciones disponibles."},{"metadata":{"trusted":true},"cell_type":"code","source":"#--< scikit-learn imports >--#\nfrom sklearn.metrics import make_scorer, roc_curve, RocCurveDisplay, auc\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, LabelBinarizer, label_binarize\nfrom sklearn.model_selection import train_test_split, GridSearchCV\n\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier, Lasso\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, BaggingClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DATA/TARGET definitions\ndata = iris.drop(\"species\", axis=1)\ntarget = iris[\"species\"].values\n\nlabels = pd.Series([0,1,2])\nn_classes = len(labels)\n\n# SCALERS\nsc = StandardScaler()\ndata_sc = sc.fit_transform(data)\n\n#labenc = LabelBinarizer()\n#target = labenc.fit_transform(target)\n\n# TRAIN/TEST split\nX_train, X_test, y_train, y_test = train_test_split(data_sc, target, \n                                                    test_size=0.3, random_state=1994)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We define a function to evaluate all models in a dictionary.\ndef train_all_models(models_dict, train_now=True):\n    if train_now:\n        for k,m in models_dict.items():\n            start_time = time.time()\n            print('MODEL:%s'%k)\n            m.fit(X_train, y_train)\n            print(\"(model_runtime= %.2f s)\\n\"%(time.time() - start_time))\n    else: \n        print(\"Not training for now\")\n    return models_dict\n\ndef plot_predict_all_models(models_dict, kw_dict={'average':'weighted'}):\n    \"\"\"N=1 example:\n    y_pred = label_binarize(XGBc.predict(X_test), classes=labels)\n    res = roc_auc_score(y_test, y_pred, average=\"macro\", multi_class=\"ovo\")\n    print(res)\"\"\"\n    #lb = lambda arr: label_binarize(arr, classes=labels)\n    for k,m in models_dict.items():\n        y_pred = m.predict(X_test)\n        y_pred_bin = m.predict_proba(X_test) #label_binarize(y_pred, classes=labels)\n        print('MODEL :%s\\n'%k,\n              'AUC = %.3f\\n'%roc_auc_score(y_test, y_pred_bin, \n                                           average=kw_dict['average'], \n                                           multi_class=\"ovo\"),\n              'Acc= %.3f\\n'%accuracy_score(y_test, y_pred ),\n              'Prec= %.3f\\n'%precision_score(y_test, y_pred, \n                                             average=kw_dict['average']), \n              'Rec= %.3f\\n'%recall_score(y_test, y_pred, \n                                         average=kw_dict['average']),\n              'F1= %.3f\\n'%f1_score(y_test,y_pred, \n                                    average=kw_dict['average'])\n             )\n        \n        \n        fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(10,5))\n        axs.set_title(r\"ROC curve || Model: {}\".format(m.__repr__()))\n        axs.set_xlabel(\"FPR\") ; axs.set_ylabel(\"TPR\")\n        \n        \n        for c in range(n_classes):\n            fpr, tpr, thresholds = roc_curve(y_test, y_pred_bin[:,c], pos_label=c) \n            roc_auc = auc(fpr, tpr)\n            axs.plot(fpr, tpr, label=f\"class:{c} || AUC={roc_auc:.3f}\")\n            axs.plot([0,1], [0,1], color=\"navy\", linestyle='--')\n        fig.legend()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## VANILLA MODELS\nLc = LogisticRegression()\nKNc = KNeighborsClassifier()\nDTc = DecisionTreeClassifier()\nRFc = RandomForestClassifier()\nSVc = SVC(probability=True)\nXGBc = XGBClassifier(objective=\"reg:logistic\",\n                     eval_metric=\"rmse\",\n                     use_label_encoder=False)  #objective=\"multi:softmax\", \"reg:logistic\", \"multi:softprob\" // probabilities=Trues ->(W!)\n\nmodels_vanilla = {\"Lc\" : Lc,\n             \"KNc\" : KNc,\n             \"DTc\" : DTc,\n             \"RFc\" : RFc,\n             \"SVc\" : SVc,\n             \"XGBc\" : XGBc}\n\n# TRAIN\nmodels_vanilla = train_all_models(models_vanilla, train_now=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# EVALUATION: VANILLA MODELS\nplot_predict_all_models(models_vanilla, kw_dict={'average':'weighted'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. EVALUATION AND IMPROVEMENTS FOR THOSE ALGORITHMS"},{"metadata":{"trusted":true},"cell_type":"code","source":"%timeit\n## SEARCH FOR PARAMETERS GRIDSEARCHCV: CV MODELS || NOTE: Time + + + ...\nLc_kw = {'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n        'fit_intercept' : [True, False],\n        'solver' : ['newton-cg', 'lbfgs', 'liblinear'],\n        'class_weight' : ['balanced', None],\n        'multi_class': ['multinomial', 'ovr'],}\nLc_cv = GridSearchCV(Lc, Lc_kw, cv=4, ) \n\nKNc_kw = {'n_neighbors' : np.arange(1,7),\n          'weights' : ['uniform', 'distance'],\n          'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n          'leaf_size' : np.arange(10,30),\n          'p' : np.arange(1,3)\n         }\nKNc_cv = GridSearchCV(KNc, KNc_kw, cv=4, ) \n\nDTc_kw = {\"criterion\" : ['gini', 'entropy'],\n          \"splitter\" : [\"best\", \"random\"], \n          \"max_depth\" : [2,3,4,None],\n          \"min_samples_leaf\" : np.arange(1,9), \n          \"min_samples_split\": np.arange(2,5),\n          \"max_features\" : [\"sqrt\", \"log2\", None],\n          \"max_leaf_nodes\":[20, 30, None],\n          \"class_weight\" : ['balanced', None],\n          \"ccp_alpha\" : [0, 1]\n          }\nDTc_cv = GridSearchCV(DTc, DTc_kw, cv=4, ) \n\nRFc_kw = {\"n_estimators\" : [20,40], \n          \"criterion\" : ['gini','entropy'],\n          \"min_samples_leaf\" : np.arange(1, 7, 2), \n          \"min_samples_split\": np.arange(2, 3),\n          \"max_features\" : [\"sqrt\", \"log2\"], \n          \"max_depth\" : [3, 4, None],\n          \"max_features\" : [\"sqrt\", \"log2\"],\n          \"max_leaf_nodes\":[10, None],\n          \"class_weight\" : ['balanced', None],\n         }\nRFc_cv = GridSearchCV(RFc, RFc_kw, cv=3, )  \n\nSVc_kw = {\"kernel\" : [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n          \"degree\": [2, 3, 4, 5],\n          \"gamma\" : [\"scale\", \"auto\"],\n          \"shrinking\" : [True, False],\n          \"C\" : [0.5, 1, 1.5, 2],\n          \"class_weight\" : ['balanced', None],\n         }\nSVc_cv = GridSearchCV(SVc, SVc_kw, cv=3, ) \n\nXGBc_kw = {'n_estimators' : [50, 100],\n    'max_depth' : [2, 3, 4],\n    'learning_rate' : [0.02, 0.05, 0.1],\n    'booster' : ['gbtree','gblinear','dart'],\n    'base_score' : [0.25, 0.5, 0.75, 1]}\n\nXGBc_cv = GridSearchCV(XGBc, XGBc_kw, cv=5 ) \n\nmodels_CV = {\"Lc\" : Lc_cv,\n             \"KNc\" : KNc_cv,\n             \"DTc\" : DTc_cv,\n             \"RFc\" : RFc_cv,\n             \"SVc\" : SVc_cv,\n             \"XGBc\" : XGBc_cv}\n\n# TRAIN\nmodels_CV = train_all_models(models_CV)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## EVALUATION AND PLOTTING: CV MODELS\nplot_predict_all_models(models_CV, kw_dict={'average':'weighted'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%timeit\n### HYPERPARAMETER TUNING: IMPROVED MODELS\nLc_imp = LogisticRegression(**models_CV['Lc'].best_params_) \nKNc_imp = KNeighborsClassifier(**models_CV['KNc'].best_params_)\nDTc_imp = DecisionTreeClassifier(**models_CV['DTc'].best_params_)\nRFc_imp = RandomForestClassifier(**models_CV['RFc'].best_params_)\nSVc_imp = SVC(**models_CV['SVc'].best_params_, probability=True)\nXGBc_imp =XGBClassifier(**models_CV['XGBc'].best_params_,\n                        probability=True,\n                        use_label_encoder=False,\n                        objective=\"reg:logistic\",\n                        eval_metric=\"rmse\")\n\n\nmodels_improved = {\"Lc\" : Lc_imp,\n             \"KNc\" : KNc_imp,\n             \"DTc\" : DTc_imp,\n             \"RFc\" : RFc_imp,\n             \"SVc\" : SVc_imp,\n             \"XGBc\" : XGBc_imp}\n\n# TRAIN\nmodels_improved = train_all_models(models_improved, train_now=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## EVALUATION AND PLOTTING: IMPROVED MODELS\nplot_predict_all_models(models_improved, kw_dict={'average':'weighted'})","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"%timeit\n### BAGGING ENSEMBLE: BAG MODELS\nLc_bag = BaggingClassifier(LogisticRegression(**models_CV['Lc'].best_params_)) \nKNc_bag = BaggingClassifier(KNeighborsClassifier(**models_CV['KNc'].best_params_))\nDTc_bag = BaggingClassifier(DecisionTreeClassifier(**models_CV['DTc'].best_params_))\nRFc_bag = BaggingClassifier(RandomForestClassifier(**models_CV['RFc'].best_params_))\nSVc_bag = BaggingClassifier(SVC(**models_CV['SVc'].best_params_, probability=True))\nXGBc_bag = BaggingClassifier(XGBClassifier(**models_CV['XGBc'].best_params_,\n                                            probability=True,\n                                            use_label_encoder=False,\n                                            objective=\"reg:logistic\",\n                                            eval_metric=\"rmse\"))\n\n\nmodels_bag = {\"Lc\" : Lc_bag,\n             \"KNc\" : KNc_bag,\n             \"DTc\" : DTc_bag,\n             \"RFc\" : RFc_bag,\n             \"SVc\" : SVc_bag,\n             \"XGBc\" : XGBc_bag}\n\n# TRAIN\nmodels_bag = train_all_models(models_bag, train_now=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## EVALUATION AND PLOTTING: BAGGING MODELS\nplot_predict_all_models(models_bag)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%timeit\n# MAIN RESULTS INTO DATAFRAMES\nalgorithms = ['Logistic Regression',\n            'K-Nearest Neighbour Classifier',\n            'Decision Tree Classifier', \n            'Random Forest Classifier',\n            'Support Vector Machine Classifier',\n            'XGBoost Classifier']\n\nvanilla_results = pd.DataFrame( {\"Algorithm\": algorithms,\n                          \"Train_score\":[m.score(X_train,y_train) for m in models_vanilla.values()],\n                          \"Test_score\":[m.score(X_test,y_test) for m in models_vanilla.values()]\n                                }).sort_values('Test_score', ascending=False)\n\nimproved_results = pd.DataFrame({\"Algorithm\": algorithms,\n                          \"Train_score\":[m.score(X_train,y_train) for m in models_improved.values()],\n                          \"Test_score\":[m.score(X_test,y_test) for m in models_improved.values()]\n                                }).sort_values('Test_score', ascending=False)\n\nbag_results = pd.DataFrame({\"Algorithm\": algorithms,\n                          \"Train_score\":[m.score(X_train,y_train) for m in models_bag.values()],\n                          \"Test_score\":[m.score(X_test,y_test) for m in models_bag.values()]\n                               }).sort_values('Test_score', ascending=False)\n\ndisplay(\"VANILLA:\", vanilla_results)\ndisplay(\"IMPROVED:\", improved_results)\ndisplay(\"BAGGING:\", bag_results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# EXPORT CLEANED AND IMPUTED DATASET TO CSV (for production)\niris.to_csv(\"iris.csv\", header=True, index=False)\n\n# EXPORTS TO CSV\nvanilla_results.to_csv(\"iris_vanilla_results.csv\")\nimproved_results.to_csv(\"iris_improved_results.csv\")\nbag_results.to_csv(\"iris_bagging_results.csv\")\n\n# EXPORT TO PICKLE\nimport pickle\n\nmodel_filename = 'iris_svm_bag.pkl'\nwith open(model_filename, \"wb\") as f:\n    pickle.dump(models_bag['SVc'], f)\nwith open(\"iris_lc_imp.pkl\", \"wb\") as f:\n    pickle.dump(models_improved['Lc'], f)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# FEATURE IMPORTANCES\nfeatures = pd.Series(models_bag['RFc'].base_estimator_.fit(X_train,y_train).feature_importances_)\nfeatures.index = features.index.map({i:c for i,c in enumerate(data.columns)})\ndisplay(features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <ins>*CONCLUSIONES*:</ins>\n\n**Variables predictoras o features:** 'sepal_width','sepal_length','petal_width','petal_length' \\\n**Variable objetivo o target:** 'species'\n\n- 1. ANÁLISIS EXPLORATORIO DE DATOS:\n\n    - Hay correlación (bastante mayor en las características del pétalo) entre las variables predictoras y la objetivo, salvo en el caso de 'sepal_width',en la que hay una mínima correlación negativa.\n    \n    - La distribución bimodal en algunos de nuestros histogramas y un scatterplot más detallado en las características del pétalo diferenciando por especies, nos llevan a la conclusión de que la especie setosa posee unas propiedades del pétalo suficientemente características para ser diferenciadas del resto de especies. Se podría quitar el subgrupo setosa de nuestros datos y seguir investigando de manera visual y analítica la separación entre versicolor y virginica. \n    \n    - Las variables 'petal_length' y 'petal_width' (sobre todo la segunda) pueden parecer a simple vista que comparten rangos entre las especies virginica y versicolor, pero un análisis más detallado con el test T-student indica que son separables estadísticamente con una confianza significativa (95%). También este test nos dice que ambas características del pétalo son objetivamente mayores en el caso de la virginica.\n    \n    - Si convertimos a variables categóricas en función de nuestros rangos intercuartiles, no hay una combinación de características que sea dependiente y por tanto predictora de nuestra variable target. Ésto hemos podido comprobarlo con nuestro test $\\chi^2$ de independencia.\n        \n- 2. BUSCANDO ALGORITMOS CANDIDATOS:\n\nDefinimos nuestro target 'species', a continuación hemos dividido en train/test con una fracción del 70% y 30%, respectivamente.\n\nHemos realizado un StandardScaler() que nos redistribuye la muestra como $\\sim N(0,1)$, ésto es suficiente y recomendable puesto que no tenemos demasiados valores extremos en nuestros datos y nuestras variables predictoras poseen una distribución normal.\n\nHemos usado los siguientes y famosos algoritmos de sklearn para problemas de clasificación:\n\n    - LinearClassifier(): Modelo más simple, ajusta los coeficientes por medio de minimizar diferencias cuadráticas.\n    - KNeighborsClassifier(): Modelo sencillo que, una vez se establece k (el número de predictores máximo), nos dará la importancia de predictores en torno a la variable de objetivo de la clasificación.\n    - DecisionTreeClassifier(): Modelo sencillo que penaliza la distancia de nuestros datos en relación a valores de prueba , construye un árbol de decisión y permite realizar clasificación. Permite ver la importancia de predictores.\n    - RandomForestClassifier(): Modelo mejorado basado en árboles de decisión que permite promediar una muestra significativa de ellos, sus resultados, y ver la importancia de predictores.\n    - SVC(): Modelo de máquinas de soporte vectorial ('Support Vector Machines'), que busca hacer la mejor división de nuestros datos mediante hiperplanos que los separen.\n    - XGBClassifier(): Modelo complejo y óptimo ('eXtreme Gradient Boosting') basado en árboles de decisión, optimización del descenso del gradiente y una randomizazión de parámetros optimizada, entre otros.\n    \nDado que nuestro dataset es relativamente pequeño, hemos usado GridSearchCV como algoritmo de búsqueda de hiperparámetros. Éste es mas lento que otros (i.e. RandomizedSearchCV), pero ésto se traduce en una mejora general de los hiperparámetros buscados, dado que prueba todas las combinaciones en los datos.\n\n**NOTA: Hemos evaluado la área debajo de la curva ROC (AUC), la precisión (accuracy) del modelo y otras métricas principales de la tabla de contingencia, también hemos dibujado la curva ROC de los modelos para cada posible clase. En las métricas, hemos optado por hacer una media pesada (\"weighted\") entre los 3 pares de evaluación todos-contra-todos.**\n\n- 3. EVALUACIÓN Y MEJORAS PARA ÉSTOS ALGORITMOS:\n\nUna vez buscados los mejores parámetros para nuestros modelos, hemos evaluado nuestros modelos con éstos, lo que hemos llamado modelos \"improved\".\n\nLuego, hemos usado un método de ensamblado ('BaggingClassifier') para mejorar nuestros modelos mediante el ensamblaje de clasificadores con los mejores parámetros encontrados, lo que hemos llamado modelos \"bagging\".\n\nHemos exportado nuestros modelos a DataFrames y hemos guardado los resultados principales, también, hemos guardado el dataset en formato .csv y el mejor modelo en formato 'pickle' para la fase de producción.\n\nEn nuestros algoritmos principales evaluados en test:\n\nPara modelos \"vanilla\" (default): Gana *Logistic Regression*, con un score de 0.978 en test. \n\nPara modelos \"improved\" (con hiperparámetros mejorados), nos dan como favoritos:\n\n1. Logistic Regression \t0.980952 \t0.977778 \\\n2. K-Nearest Neighbour Classifier \t0.971429 \t0.933333 \\\n3. Support Vector Machine Classifier \t0.961905 \t0.933333 \\\n\nPara modelos \"bagging\" (mejorados con ensamblamiento):\n\n1. Support Vector Machine Classifier \t0.971429 \t0.977778 \\\n2. Logistic Regression \t0.990476 \t0.955556 \\\n3. Random Forest Classifier \t0.961905 \t0.955556 \\\n\nPor tanto, guardaremos el modelo SVM_bagging y el Lc_improved en formato 'pickle' para la fase de producción. También guardamos el dataset original.\n\nSegún nuestro mejor modelo que permite estimar la importancia de los predictores en la variable objetivo (RandomForestClassifier_bagging), irían por orden:\n\n**'petal_width' > 'petal_length' > 'sepal_length' > 'sepal_width'**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"###----------------< END of 'iris_nb.ipynb'>---------------###","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}