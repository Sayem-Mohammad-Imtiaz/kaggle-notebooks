{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Use a 2D convolutional neural net to identify the artist behind a painting"},{"metadata":{},"cell_type":"markdown","source":"The title kind of says it all. This notebook is a 2D convolutional neural net (from scratch) to identify the artist behind a painting. There are over 50 artists with over 8000 paintings, some of them kind of similar in the technique, so this makes the training and identification sort of tricky. \n\nHaving said that, I personally am a big fan of Ernst Ludwig Kirchner, so I was a little bit disappointed not to find him in the list of 'the best artworks of all time' (as you will see later). Here, just for completeness a nice painting of Kirchner (title: Nollendorfplatz): \n\n![](https://upload.wikimedia.org/wikipedia/commons/f/ff/Ernst_Ludwig_Kirchner_-_Nollendorfplatz.jpg)\n\nIn any case enjoy the notebook. Any ideas, suggestions or comments are of course more than welcome and appreciated. Have fun!"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom matplotlib import gridspec\nimport PIL\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define a couple of constants\nIMG_HEIGHT  = 300\nIMG_WIDTH   = 300\nBATCH_SIZE  = 32\nEPOCHS      = 20\nSEED        = 1234\nstrPath     = \"../input/best-artworks-of-all-time/images/images/\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare data"},{"metadata":{},"cell_type":"markdown","source":"Next part is to read the data for further usage. For this, predefined functions of Keras are used. I use 20% for validation. The image sizes are rather large since it increases accuracy later."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  strPath,\n  validation_split = 0.2,\n  subset     = \"training\",\n  seed       = SEED,\n  image_size = (IMG_HEIGHT, IMG_WIDTH),\n  batch_size = BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  strPath,\n  validation_split = 0.2,\n  subset     = \"validation\",\n  seed       = SEED,\n  image_size = (IMG_HEIGHT, IMG_WIDTH),\n  batch_size = BATCH_SIZE)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get ( and print) the name of classes, i.e. the name of the artists."},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the artists names\nclass_names = train_ds.class_names\n\n# define for later\nnum_classes = len(class_names)\n\nprint(class_names)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualise some of the paintings"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14, 14))\nfor images, labels in train_ds.take(1):\n  for i in range(16):\n    ax = plt.subplot(4, 4, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[labels[i]])\n    plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for image_batch, labels_batch in train_ds:\n  print(image_batch.shape)\n  print(labels_batch.shape)\n  break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\n\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nval_ds   = val_ds.cache().prefetch(buffer_size=AUTOTUNE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data augmentation"},{"metadata":{},"cell_type":"raw","source":"For at least some decrease of overfitting I use data augmentation with a couple of provided functionalities, i.e. rotation, zoon, transalation and contrast of the figures. In general one could have used more or something different."},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndata_augmentation = keras.Sequential(\n  [\n    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n    layers.experimental.preprocessing.RandomRotation(0.25),\n    layers.experimental.preprocessing.RandomZoom(0.2), \n    layers.experimental.preprocessing.RandomTranslation(0.3,0.2), \n    layers.experimental.preprocessing.RandomContrast(0.2)\n  ]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualise data augmentation"},{"metadata":{},"cell_type":"markdown","source":"Just make some plots of the results of the daa augmentation based on a random painting."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14, 14))\nfor images, _ in train_ds.take(1):\n  for i in range(16):\n    augmented_images = data_augmentation(images)\n    ax = plt.subplot(4, 4, i + 1)\n    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n    plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{},"cell_type":"markdown","source":"The model is a 2D convolutional neural network from scratch. Here one could probably still spend a little bit of time to improve the final results especially acuracy. One could think of using a more complex architecture or something predefined (e.g. ResNet, GoogLeNet, etc) and then attaching something in the end. "},{"metadata":{"trusted":true},"cell_type":"code","source":"\nCONV = 3\n\nmodel = Sequential([\n  data_augmentation,\n  layers.experimental.preprocessing.Rescaling(1./255),\n  layers.Conv2D(16, CONV, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, CONV, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, CONV, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Dropout(0.2),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes)\n])\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As optimiser, I tried a couple of them, but RMSprop seemed to make the best job in terms of accuracy in the end. The choice for loss and metric seems kind of natural for this type of problem."},{"metadata":{"trusted":true},"cell_type":"code","source":"#define model ingredients \nopti = tf.keras.optimizers.RMSprop(momentum=0.1) \nloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) \nmetr = ['accuracy']\n\n#compile model \nmodel.compile(optimizer = opti, \n              loss = loss, \n              metrics = metr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nhistory = model.fit(\n  train_ds,\n  validation_data = val_ds,\n  epochs          = EPOCHS\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# Check loss and accuracy"},{"metadata":{},"cell_type":"markdown","source":"To check for the accuracy but also of course to check on overfitting, the relevant quantities are plotted vs the number epochs."},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the values\nacc      = history.history['accuracy']\nval_acc  = history.history['val_accuracy']\nloss     = history.history['loss']\nval_loss = history.history['val_loss']\n\n\n# show the results\nepochs_range = range(EPOCHS)\n\n\nplt.rcParams.update({'font.size': 15})\n\nfig = plt.figure(figsize=(12, 14))\ngs = gridspec.GridSpec(2, 1, height_ratios=[1, 1]) \n\nax0 = plt.subplot(gs[0])\nplt.plot(epochs_range, acc, label='Training')\nplt.plot(epochs_range, val_acc, label='Validation')\nplt.legend(loc='lower right')\nplt.title('Accuracy and loss')\nplt.ylabel(\"Accuracy\")\nplt.grid(True)\n\nax1 = plt.subplot(gs[1], sharex = ax0)\nplt.plot(epochs_range, loss, label='Training')\nplt.plot(epochs_range, val_loss, label='Validation')\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epochs\")\nplt.grid(True)\n\nplt.subplots_adjust(hspace=.0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion"},{"metadata":{},"cell_type":"markdown","source":"This is a simple version of a convolutional Neural Net. Results are not that awesome, but somewhat solid considering created from scratch. Overfitting seems to be on the smaller level, so this should be okay. Using pretrained models like ResNet50 could improve the performance, will probably try this later at some point. Any further ideas, suggestions on how to increase the accuracy are of course more than welcome."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}