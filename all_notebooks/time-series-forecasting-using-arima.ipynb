{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# import the libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# imoprt the dataset\ndf = pd.read_csv('../input/sales-of-shampoo/sales-of-shampoo-over-a-three-ye.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"We can see that the Month column is of object datatype, we will convert it into a datetime datatype, and also we will make the month column as a Index.\n\nWe will read the csv file again, and perform what we want while reading it.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/sales-of-shampoo/sales-of-shampoo-over-a-three-ye.csv', parse_dates=True,index_col=[0],squeeze=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we will visaulise our data\ndf.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.plot(style = 'k.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we will try to smooth the data as we can see that our data is varied alot, we will smooth by taking average.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ma = df.rolling(window=10).mean()\ndf_ma","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we performed the rolling operation on the dataset as we needed to smooth the data,in rolling we considered 10 rows in order from 1st to 10th and took the average of it and printed the value of it at 10 the position. The data above the 10 rows will be NaN as it does not have adequate rows to print the average of the 10 rows.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# we will now plot the smoothed dataframe.\ndf_ma.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we will now compare the smoothed data to the original data.\ndf.plot()\ndf_ma.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Now we will create a Naive(baseline) model to get the error of the model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Now we will perform the shifting on the data. It is basically adding a new column to the dataframe by shifting the values of the previous columns.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_naive = pd.concat([df,df.shift(1)],axis=1)\ndf_naive","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"by using shift(1) we just shifted each rows by 1 into another column, we can see that there is null value in the dataset,as we will need to find the error, we will find the error by using mean_squared_error,and it does not input NaN values, so we will drop the NaN values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_naive.dropna(inplace=True)\ndf_naive.columns = ['Actual Data','Shifted Data']\ndf_naive ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that our data is now prepared.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# we will get the mean_sqaured_error\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_1 = mean_squared_error(df_naive['Actual Data'],df_naive['Shifted Data'])\nerror_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_1 = np.sqrt(error_1)\nerror_1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we got the error of our naive model around 109. Now we will create ARIMA model , we need to make sure that the error margin of our model should be less than the error margin of the naive model, then only our model will be said as a good model.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## ARIMA( Auto Regressive Integrated Moving Average)\n\n* Auto Regressive = p value\n* Integrated = d value\n* Moving Average = q value\n\nWe can see that our data is not stationary so we can take the value of d as 1.\n\nWe will find the p and q values with plot_acf and plot_pacf.\n\n#### arima(p,d,q)\n* If want an (AR)autoregressive model we will take the value as arima(2,0,0) any value of p\n* If want an (MV)Moving average model we will take the value as arima(0,0,2) any value of q\n* If want an whole ARIMA model we will take the value as arima(2,1,2) any values for all the three.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# acf and pacf\nfrom statsmodels.graphics.tsaplots import plot_acf,plot_pacf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here we are considering the original dataframe, our original dataframe consisted NaN value in the last row so we dropped it.\ndf.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot_acf will give us the q value(Autocorrelation)\n\nplot_acf(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here We can see that first point has correlation of 1 , so we count from the next value untill the value goes into the critical range. We can see that there are 3 points which are not below the critical range.\nSo we take the value of q = 3.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot_pacf will give us the q value(Partial Autocorrelation)\n\nplot_pacf(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here We can see that first point has correlation of 1 , so we count from the next value untill the value goes into the critical range. We can see that there are 3 points which are not below the critical range.\nSo we take the value of q = 2.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# p = 2\n# d = 1\n# q = 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we will now create our ARIMA model.\nfrom statsmodels.tsa.arima_model import ARIMA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we will now create a training and testing data \ndf_train = df[:26]\ndf_test = df[26:]\ndf_train.shape,df_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ARIMA(df_train, order=(3,1,2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_fit = model.fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_fit.aic","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can try different values of the ARIMA model and try to find the aic value, the model who has the least aic value will be the best model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_forecast = model_fit.forecast(steps=10)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error2 = np.sqrt(mean_squared_error(df_test,model_forecast))\nerror2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From this we can say that our ARIMA model is not forecasting better than our naive model.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### To find which model works best with altering p,d,q values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p_values = range(0,5)\nd_values = range(0,3)\nq_values = range(0,5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for p in p_values:\n    for d in d_values:\n        for q in q_values:\n            order = (p,d,q)\n            train,test = df[0:26], df[26:]\n            predictions = []\n            for i in range(len(test)):\n                try:\n                    model = ARIMA(train, order)\n                    model_fit = model.fit(disp=0)\n                    pred_y = model_fit.forecast()[0]\n                    predictions.append(pred_y)\n                    error = np.sqrt(mean_squared_error(test,predictions))\n                    print('Arima%s RMSE = %.2f'% (order,error))\n                except:\n                    continue","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that no order combination works better in reducing the error for our model than the error of our naive model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}