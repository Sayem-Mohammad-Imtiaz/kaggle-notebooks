{"cells":[{"metadata":{},"cell_type":"markdown","source":"Simple Linear Regression with Gradient Descent and Scikit method"},{"metadata":{},"cell_type":"markdown","source":"1.Gradient Descent\n  importing Libary Functions"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/predictingese/AttendanceMarksSA.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X= data['MSE']\nY=data['ESE']\nsns.scatterplot(X,Y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Gradient Descent"},{"metadata":{"trusted":true},"cell_type":"code","source":"theta0=0\ntheta1=0\nalpha=0.01\ncount =10000\nm=len(X) # m is number of example s i.e number of students here","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Implementing Gradient Descent"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(count): \n    Y_hat = theta1*X + theta0    \n    theta0 = theta0 - (alpha/m)*sum(Y_hat-Y)\n    theta1 = theta1 - (alpha/m)*sum(X*(Y_hat-Y))\n    \nprint(theta0,theta1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting Regression line"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_hat = theta1*X + theta0\n\nplt.scatter(X, Y) \nplt.plot([min(X), max(X)], [min(Y_hat), max(Y_hat)], color='red')  # regression line\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculating Residual standard Error"},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\ndef RSE(y_true, y_predicted):\n   \n    y_true = np.array(y_true)\n    y_predicted = np.array(y_predicted)\n    RSS = np.sum(np.square(y_true - y_predicted))\n\n    rse = math.sqrt(RSS / (len(y_true) - 2))\n    return rse\n\n\nrse= RSE(data['ESE'],Y_hat)\nprint(rse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2.Using Scikit-Learn"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Implementation \nCalculating Residual Standard Error"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.array(data['MSE']).reshape(-1,1)\ny = np.array(data['ESE']).reshape(-1,1)\n \n\nmodel = LinearRegression()\nmodel.fit(x,y)\n\n\nprint(model.coef_)\nprint(model.intercept_)\n\ny_predict = model.predict(x)\nrse = RSE(y,y_predict)\n\nprint(rse)\n\n \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"predicting score"},{"metadata":{"trusted":true},"cell_type":"code","source":"marks = [17]\nresult = model.predict([marks])\nprint(result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"if my marks are 17 in Mid semster Examination,my score for End Semster Examination would be 58"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}