{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn import preprocessing\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data reading"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/prostate-cancer/Prostate_Cancer.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns=df.columns\ncolumns_new=[]\nfor i in columns:\n    columns_new.append(any(df[i].isnull()|df[i].isnull()))\ndf=df.drop(columns[columns_new],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"{'unique patients':len(df.id.unique()), 'records':len(df.id)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.countplot(df.diagnosis_result,label=\"Count\")       # M = 212, B = 357\ndf.diagnosis_result.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.boxplot( palette=\"Set2\", orient=\"h\",data=df[df.diagnosis_result=='B'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.boxplot( palette=\"Set2\", orient=\"h\",data=df[df.diagnosis_result=='M'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train and Test spliting"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test=train_test_split(\n    df.drop(['id','diagnosis_result'], axis=1),\n    df[['diagnosis_result']],\n    test_size=0.3,\n    random_state=41)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Removing outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in X_train.columns:\n    \n    df_train1 = X_train[(y_train.diagnosis_result=='B') & (X_train[column]<np.mean(X_train.loc[y_train.diagnosis_result=='B',column])+3*np.std(X_train.loc[y_train.diagnosis_result=='B',column]))]\n    df_test1 = X_test[(y_test.diagnosis_result=='B') & (X_test[column]<np.mean(X_train.loc[y_train.diagnosis_result=='B',column])+3*np.std(X_train.loc[y_train.diagnosis_result=='B',column]))]\n    \n    label_train1 = y_train[(y_train.diagnosis_result=='B') & (X_train[column]<np.mean(X_train.loc[y_train.diagnosis_result=='B',column])+3*np.std(X_train.loc[y_train.diagnosis_result=='B',column]))]\n    label_test1 = y_test[(y_test.diagnosis_result=='B') & (X_test[column]<np.mean(X_train.loc[y_train.diagnosis_result=='B',column])+3*np.std(X_train.loc[y_train.diagnosis_result=='B',column]))]\n    \n    df_train2 = X_train[(y_train.diagnosis_result=='M') & (X_train[column]<np.mean(X_train.loc[y_train.diagnosis_result=='M',column])+3*np.std(X_train.loc[y_train.diagnosis_result=='M',column]))]\n    df_test2 = X_test[(y_test.diagnosis_result=='M') & (X_test[column]<np.mean(X_train.loc[y_train.diagnosis_result=='M',column])+3*np.std(X_train.loc[y_train.diagnosis_result=='M',column]))]\n    \n    label_train2 = y_train[(y_train.diagnosis_result=='M') & (X_train[column]<np.mean(X_train.loc[y_train.diagnosis_result=='M',column])+3*np.std(X_train.loc[y_train.diagnosis_result=='M',column]))]\n    label_test2 = y_test[(y_test.diagnosis_result=='M') & (X_test[column]<np.mean(X_train.loc[y_train.diagnosis_result=='M',column])+3*np.std(X_train.loc[y_train.diagnosis_result=='M',column]))]    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=pd.concat([df_train1,df_train2])\ny_train=pd.concat([label_train1,label_train2])\n\nX_test=pd.concat([df_test1,df_test2])\ny_test=pd.concat([label_test1,label_test2])\n\nX_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Removing correlated features"},{"metadata":{"trusted":true},"cell_type":"code","source":"corrMatrix = X_train.corr()\nf,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(corrMatrix, annot=True,ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncorrelated_features = set()\nfor i in range(len(corrMatrix .columns)):\n    for j in range(i):\n        if abs(corrMatrix.iloc[i, j]) > 0.7:\n            colname = corrMatrix.columns[i]\n            correlated_features.add(colname)\nprint(correlated_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.drop(labels=correlated_features, axis=1, inplace=True)\nX_test.drop(labels=correlated_features, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrMatrix = X_train.corr()\nf,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(corrMatrix, annot=True,ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Removing features with 0 variance"},{"metadata":{"trusted":true},"cell_type":"code","source":"constant_filter = VarianceThreshold(threshold=0.0)\nconstant_filter.fit(X_train)\nX_train = constant_filter.transform(X_train)\nX_test = constant_filter.transform(X_test)\n\nX_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scaling the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"mm_scaler = preprocessing.StandardScaler()\nX_train = pd.DataFrame(mm_scaler.fit_transform(X_train))\nX_test = pd.DataFrame(mm_scaler.transform(X_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def conf_matrix(matrix,pred):\n    class_names= [0,1]# name  of classes\n    fig, ax = plt.subplots()\n    tick_marks = np.arange(len(class_names))\n    plt.xticks(tick_marks, class_names)\n    plt.yticks(tick_marks, class_names)\n    # create heatmap\n    sns.heatmap(pd.DataFrame(matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n    ax.xaxis.set_label_position(\"top\")\n    plt.tight_layout()\n    plt.title('Confusion matrix', y=1.1)\n    plt.ylabel('Actual label')\n    plt.xlabel('Predicted label')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest Classification\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(class_weight=\"balanced\",n_estimators=200,random_state = 1)\nrf.fit(X_train, y_train.values.ravel())\ny_pred=rf.predict(X_test)\nacc = metrics.accuracy_score(y_pred,y_test.values.ravel())*100\nprint(\"Random Forest Algorithm Accuracy Score : {:.2f}%\".format(acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make class predictions with the model\ny_pred = rf.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_pred,y_test)\nconf_matrix(cnf_matrix,y_test)\n# calculate prediction\nreport = classification_report(y_pred,y_test)\nprint(report)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(X_train, y_train.values.ravel())\n\ny_pred=nb.predict(X_test)\nacc = metrics.accuracy_score(y_pred,y_test.values.ravel())*100\n\nprint(\"Accuracy of Naive Bayes: {:.2f}%\".format(acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make class predictions with the model\ny_pred = nb.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_pred,y_test)\nconf_matrix(cnf_matrix,y_test)\n# calculate prediction\nreport = classification_report(y_pred,y_test)\nprint(report)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Suport Vector Machine"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvm = SVC(random_state = 1)\nsvm.fit(X_train, y_train.values.ravel())\n\ny_pred=svm.predict(X_test)\nacc = metrics.accuracy_score(y_pred,y_test.values.ravel())*100\n\nprint(\"Test Accuracy of SVM Algorithm: {:.2f}%\".format(acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make class predictions with the model\ny_pred = svm.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_pred,y_test)\nconf_matrix(cnf_matrix,y_test)\n# calculate prediction\nreport = classification_report(y_pred,y_test)\nprint(report)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# KNN "},{"metadata":{"trusted":true},"cell_type":"code","source":"# KNN Model\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# try ro find best k value\nscore = []\n\nfor i in range(1,20):\n    knn = KNeighborsClassifier(n_neighbors = i)  # n_neighbors means k\n    knn.fit(X_train, y_train.values.ravel())\n    score.append(knn.score(X_test, y_test.values.ravel()))\n    \nplt.plot(range(1,20), score)\nplt.xticks(np.arange(1,20,1))\nplt.xlabel(\"K neighbors\")\nplt.ylabel(\"Score\")\nplt.show()\n\nacc = max(score)*100\nprint(\"Maximum KNN Score is {:.2f}%\".format(acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors =11)  # n_neighbors means k\nknn.fit(X_train, y_train.values.ravel())   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make class predictions with the model\ny_pred = knn.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_pred,y_test)\nconf_matrix(cnf_matrix,y_test)\n# calculate prediction\nreport = classification_report(y_pred,y_test)\nprint(report)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression(max_iter=50)\nlogreg.fit(X_train, y_train.values.ravel())\ny_pred=logreg.predict(X_test)\nacc = metrics.accuracy_score(y_pred,y_test.values.ravel())*100\nprint(\"Test Accuracy of Logistic Regression Algorithm: {:.2f}%\".format(acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make class predictions with the model\ny_pred = logreg.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_pred,y_test)\nconf_matrix(cnf_matrix,y_test)\n# calculate prediction\nreport = classification_report(y_pred,y_test)\nprint(report)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"# define the keras model\nmodel = Sequential()\nmodel.add(Dense(12, input_dim=X_train.shape[1], activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(8, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n# compile the keras model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n# fit the keras model on the dataset\nmodel.fit(X_train, y_train.replace({'B':0,'M':1}), epochs=100, batch_size=8)\n# evaluate the keras model\n_, accuracy = model.evaluate(X_test, y_test.replace({'B':0,'M':1}))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make class predictions with the model\ny_pred = model.predict_classes(X_test)\ncnf_matrix = metrics.confusion_matrix(y_pred,y_test.replace({'B':0,'M':1}))\nconf_matrix(cnf_matrix,y_test)\n# calculate prediction\nreport = classification_report(y_pred,y_test.replace({'B':0,'M':1}))\nprint(report)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Esemble models"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\n\neclf1 = VotingClassifier(estimators=[('lr', logreg), ('rf', knn)],\n                         voting='hard')\neclf1 = eclf1.fit(X_train, y_train.values.ravel())\nprint(eclf1.predict(X_test))\neclf2 = VotingClassifier(estimators=[('lr', logreg), ('rf', knn)],voting='soft')\neclf2 = eclf2.fit(X_train, y_train.values.ravel())\nprint(eclf2.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## First esemble"},{"metadata":{"trusted":true},"cell_type":"code","source":"# make class predictions with the model\ny_pred = eclf1.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_pred,y_test)\nconf_matrix(cnf_matrix,y_test)\n# calculate prediction\nreport = classification_report(y_pred,y_test)\nprint(report)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Second esemble"},{"metadata":{"trusted":true},"cell_type":"code","source":"# make class predictions with the model\ny_pred = eclf2.predict(X_test)\ncnf_matrix = metrics.confusion_matrix(y_pred,y_test)\nconf_matrix(cnf_matrix,y_test)\n# calculate prediction\nreport = classification_report(y_pred,y_test)\nprint(report)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Recommendation"},{"metadata":{},"cell_type":"markdown","source":"100 data points I consider is a low amount of data to work, anyway it gave a decent result for experimentation, It can have better performance with larger amounts of data."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}