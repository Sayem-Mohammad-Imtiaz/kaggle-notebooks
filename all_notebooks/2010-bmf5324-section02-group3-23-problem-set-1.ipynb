{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Table of Contents\n\n* [1. Pre Chapter: Introduction of Assignments](#section-one)\n* [2. Setup](#section-two)\n    - [2.1 Load Libraries](#subsection-two-one)\n    - [2.2 Define Color Scheme](#subsection-two-two)\n    - [2.3 Import Data](#subsection-two-three)\n    - [2.4 Wrangle Data](#subsection-two-four)\n* [3. COVID19 Situation in Singapore](#section-three)\n    - [3.1 COVID19 General Situation Around The World by Country and Date](#subsection-three-one)\n    - [3.2 COVID19 General Situation Around The World by Explosion Center](#subsection-three-two)\n    - [3.3 COVID19 General Situation in Singapore](#subsection-three-three)\n        - [3.3.1 Singapore Total Test Rate](#subsection-three-three-one)\n        - [3.3.2 Singapore Total Infection Rate](#subsection-three-three-two)\n        - [3.3.3 Singapore Total Serious Case Rate](#subsection-three-three-three)\n        - [3.3.4 Singapore Total Death Rate](#subsection-three-three-four)\n    - [3.4 COVID19 Unusual Numbers and Explaination in Singapore](#subsection-three-four)\n* [4. STI and Recession Hedges Finding](#section-four)\n* [5. Volatility vs Return](#section-five)\n* [6. Conclusion](#section-six)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"section-one\"></a>\n# 1. Pre Chapter: Introduction of Assignments\n\nThe report is designed for NUS Course BMF5324, Analystics and Statistics, to investigate the effect of COVID-19 to Singapore Societies. Besides, some other effect to economy as well as hedges will be examed and conclusion will be drawn at the end of the project. The notbook is served to finish the assignment for the course as well."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"section-two\"></a>\n# 2. Setup\n1. Settings -> Environment -> \"Always use latest environment\"\n2. Settings -> Internet -> \"On\""},{"metadata":{},"cell_type":"markdown","source":"![](http://)<a id=\"subsection-two-one\"></a>\n## 2.1 Load Packages"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# datetime operations\nfrom datetime import timedelta\n\n# for numerical analyiss\nimport numpy as np\n\n# to store and process data in dataframe\nimport pandas as pd\n\n# basic visualization package\nimport matplotlib.pyplot as plt\n\n# advanced ploting\nimport seaborn as sns; sns.set()\n\n# interactive visualization\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\n# for offline ploting, must turn this plotly.offline on\nfrom plotly.offline import plot, iplot, init_notebook_mode\ninit_notebook_mode(connected=True)\n\n# hide warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# to interface with operating system\nimport os\n\n# for trendlines\nimport statsmodels\n\n# ------------------------------------ABOVE THIS LINE ARE PROBLEM SET ONE USAGE----------------------------------------#\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-two-two\"></a>\n## 2.2 Define Color Scheme"},{"metadata":{"trusted":true},"cell_type":"code","source":"# color pallette\n# Hexademical code RRGGBB (True Black #000000, True White #ffffff)\ncnf, dth, rec, act = '#393e46', '#ff2e63', '#21bf73', '#fe9801' \n\n# ------------------------------------ABOVE THIS LINE ARE PROBLEM SET ONE USAGE----------------------------------------#","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-two-three\"></a>\n## 2.3 Import Data\nPlease add Covid 19 data (+Add Data, then search by this URL) from https://www.kaggle.com/imdevskp/corona-virus-report\n\nPlease add Ecofin File from computer (local zip source, located at Hanye's computer at C:\\Users\\user\\Desktop\\NUS\\NUS MFin Course\\Sem 1\\BMF 5324 Statistic and Analytics\\Lecture Notes\\L2), do not need to change anything here as the file is already uploaded\n\nPlease add nber-based-recession-indicators-united-states from add Data-search dataset-copy the string there\n\nImport STI index File from computer (local csv source, located at Hanye's computer at C:\\Users\\user\\Desktop\\NUS\\NUS MFin Course\\Sem 1\\BMF 5324 Statistic and Analytics\\Lecture Notes\\L2)\n\nImport T Bill File from computer, not one year as data not avaiable, so use 10 yrs (local csv source, located at Hanye's computer at C:\\Users\\user\\Desktop\\NUS\\NUS MFin Course\\Sem 1\\BMF 5324 Statistic and Analytics\\Lecture Notes\\L2)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1ST FILE IMPUT (for COVID 19 Situation)\n# list files, this has nothing to do with later codes but just display you the file inside the data\n# In total 6 files: country_wise_latest.csv, day_wise.csv, usa_country_wise, covid19_clean_complete, full_group and woldometer\n# First 5 files from John Hopkins Uni, and becasue we do SG only, we use file except usa_country_wise and woldometer file\n!ls ../input/corona-virus-report\n\n##############################################################################################################################################################\n\n# SECOND FILE INPUT: Ecofin file (for macroeconomy test)\n# Create an empty list\nfiles = []\n\n# Fill the list with the file names of the CSV files in the Kaggle folder\nfor dirname, _, filenames in os.walk('../input/ecofinpbs1'):\n    for filename in filenames:\n        files.append(os.path.join(dirname, filename))\n\n# Sort the file names\nfiles = sorted(files)\n\n# Read the CSV files through list comprehension, which can be broken into three parts\n# 1. OUTPUT EXPRESSION [pd.read_csv(f, na_values=['.'])] --- Note: this turns character '.' values into missing value\n# 2. INPUT SEQUENCE [for f] \n# 3. CONDITION (OPTIONAL) [in files] \nseries = [pd.read_csv(f, na_values=['.']) for f in files]\n\n# Define series name, which becomes the dictionary key\nseries_name = ['btc','cpi','gold','snp','high_yield_bond','inv_grade_bond','moderna',\\\n               'employment','tesla_robinhood','trea_20y_bond','trea_10y_yield','tesla','fed_bs','wti']\n\n# series name = dictionary key, series = dictionary value\nseries_dict = dict(zip(series_name, series))\n\n\n##############################################################################################################################################################\n\n# THIRD FILE INPUT: Ecofin file (for us recession test)\n# Read the dataset CSV to an object\nnber_recession_indicator_month = pd.read_csv('../input/nber-based-recession-indicators-united-states/USRECM.csv')\nnber_recession_indicator_day = pd.read_csv('../input/nber-based-recession-indicators-united-states/USRECD.csv')\n\n\n##############################################################################################################################################################\n\n# FORTH FILE INPUT: STIINDEX (for SG stock return)\n# Read the dataset CSV to an object\nSTI = pd.read_csv('../input/stiidx/STI.csv')\n\n##############################################################################################################################################################\n\n# FIFTH FILE INPUT: STIINDEX (for SG stock return)\n# Read the dataset CSV to an object\ntbill = pd.read_csv('../input/tbill10yr/TBill10Yr.csv')\n\n\n# ------------------------------------ABOVE THIS LINE ARE PROBLEM SET ONE USAGE----------------------------------------#\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-two-four\"></a>\n## 2.4 Wrangle Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# PROBLEMSET1: for corona virus report\n\n# 1st file: Country wise\n# This CSV provides you with general look over the country cases (death etc),not daily, for pie and region general chart\ncountry_wise = pd.read_csv('../input/corona-virus-report/country_wise_latest.csv')\n\n# Replace missing values '' with NAN and then 0\ncountry_wise = country_wise.replace('', np.nan).fillna(0)\ncountry_wise_sg_only = country_wise.loc[country_wise[\"Country/Region\"].isin(['Singapore'])]\n\n\n# Already check only one SG is there, to check simply just un# the following code\n# list_of_country_name = []\n# for i in range (0, 187):\n#     list_of_country_name.append(country_wise.iloc[i, 0])\n# print(list_of_country_name)\n\n# if wanted to see the datastructure of this country wise (control + /, can do all # or un#)\n# country_wise.info()\n\n\n##########################################################################################################################\n# 2nd file: full_group\n# This file contains all information as accumulated, each country, everyday what is the case number and regions\n# Grouped by day, country\nfull_grouped = pd.read_csv('../input/corona-virus-report/full_grouped.csv')\n\n# if want to see datastructure of the full group file (control + /, can do all # or un#)\n# full_grouped.info()\n# full_grouped.head(10)\n\n# Checked, SG, Singpore etc wrong spelling does not appear in this file\n# The way to check it is bascially the same as above, quary a list and find if wrong name such as SG, Singpore etc exist\n# And double check in S start region (slice the list and check if no SG missing)\n\n# Convert Date from Dtype \"Object\" (or String) to Dtype \"Datetime\"\nfull_grouped['Date'] = pd.to_datetime(full_grouped['Date'])\n# full_grouped.info(): to check the info of the changed dataset\n\n# After check it, breakdown to SG only, create another dataframe called \"full_grouped_SG_Only\":\nfull_grouped_SG_Only = full_grouped.loc[full_grouped[\"Country/Region\"].isin(['Singapore'])]\n# full_grouped_SG_Only.head(10): to check the info of the changed dataset\n\n##########################################################################################################################\n# 3rd file: day_wise\n# This file only have information on day wise case growth not the country specific\nday_wise = pd.read_csv('../input/corona-virus-report/day_wise.csv')\nday_wise['Date'] = pd.to_datetime(day_wise['Date'])\n\n# if want to see datastructure of the day_wise file (control + /, can do all # or un#)\n# day_wise.info()\n# day_wise.head(10)\n\n##########################################################################################################################\n# 4th file: worldometer\n# This file only have information on day wise case growth not the country specific\nworldometer = pd.read_csv('../input/corona-virus-report/worldometer_data.csv')\n\n# Add some more statistics to worldmeter file\nworldometer['InfectionRate'] = worldometer['TotalCases']/worldometer['Population']\nworldometer['DeathRate'] = worldometer['TotalDeaths']/worldometer['TotalCases']\nworldometer['SeriousRate'] = worldometer['Serious,Critical']/worldometer['TotalCases']\nworldometer['TestRate'] = worldometer['TotalTests']/worldometer['Population']\n\n# if want to see datastructure of the day_wise file (control + /, can do all # or un#)\n# worldometer.info()\n# worldometer.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PROBLEMSET1: for ecofinpbs1\n\n# 1. S&P \nsnp = series_dict['snp']\nsnp['Date'] = pd.to_datetime(snp['Date'])\nsnp.rename(columns={'Adj Close':'snp'}, inplace=True)\nsnp['snp_return'] = snp['snp'].pct_change()\nsnp['snp_volatility_1m'] = (snp['snp_return'].rolling(20).std())*(20)**(1/2) # Annualize daily standard deviation\nsnp['snp_volatility_1y'] = (snp['snp_return'].rolling(252).std())*(252)**(1/2) # 252 trading days per year\nsnp = snp[['Date','snp','snp_return','snp_volatility_1m','snp_volatility_1y']]\n# Calculate 1-month forward cumulative returns\nsnp['one_month_forward_snp_return'] = snp['snp_return'][::-1].rolling(window=20, min_periods=1).sum()[::-1]\n\n\n# 2. Bitcoin\nbtc = series_dict['btc']\nbtc['Date'] = pd.to_datetime(btc['Date'])\nbtc.rename(columns={'Adj Close':'btc'}, inplace=True)\nbtc['btc_return'] = btc['btc'].pct_change()\nbtc['btc_volatility_1m'] = (btc['btc_return'].rolling(20).std())*(20)**(1/2) \nbtc['btc_volatility_1y'] = (btc['btc_return'].rolling(252).std())*(252)**(1/2) \nbtc = btc[['Date','btc','btc_return','btc_volatility_1m','btc_volatility_1y']]\nbtc['one_month_forward_btc_return'] = btc['btc_return'][::-1].rolling(window=20, min_periods=1).sum()[::-1]\n\n# 3. Gold\ngold = series_dict['gold']\ngold['Date'] = pd.to_datetime(gold['DATE'])\ngold.rename(columns={'GOLDPMGBD228NLBM':'gold'}, inplace=True)\ngold['gold_lag1'] = gold['gold'].shift(1)\ngold['gold_lag2'] = gold['gold'].shift(2)\ngold['gold'] = gold['gold'].fillna(gold['gold_lag1'])\ngold['gold'] = gold['gold'].fillna(gold['gold_lag2'])\ngold[\"gold\"] = gold[\"gold\"].astype('float64')\ngold['gold_return'] = gold['gold'].pct_change()\ngold['gold_volatility_1m'] = (gold['gold_return'].rolling(20).std())*(20)**(1/2) \ngold['gold_volatility_1y'] = (gold['gold_return'].rolling(252).std())*(252)**(1/2) \ngold = gold[['Date','gold','gold_return','gold_volatility_1m','gold_volatility_1y']]\ngold['one_month_forward_gold_return'] = gold['gold_return'][::-1].rolling(window=20, min_periods=1).sum()[::-1]\n\n# 4. High Yield Bond\nhigh_yield_bond = series_dict['high_yield_bond']\nhigh_yield_bond['Date'] = pd.to_datetime(high_yield_bond['Date'])\nhigh_yield_bond.rename(columns={'Adj Close':'high_yield_bond'}, inplace=True)\nhigh_yield_bond['high_yield_bond_return'] = high_yield_bond['high_yield_bond'].pct_change()\nhigh_yield_bond['high_yield_bond_volatility_1m'] = (high_yield_bond['high_yield_bond_return'].rolling(20).std())*(20)**(1/2)\nhigh_yield_bond['high_yield_bond_volatility_1y'] = (high_yield_bond['high_yield_bond_return'].rolling(252).std())*(252)**(1/2)\nhigh_yield_bond = high_yield_bond[['Date','high_yield_bond','high_yield_bond_return','high_yield_bond_volatility_1m','high_yield_bond_volatility_1y']]\nhigh_yield_bond['one_month_forward_high_yield_bond_return'] = high_yield_bond['high_yield_bond_return'][::-1].rolling(window=20, min_periods=1).sum()[::-1]\n\n# 5. Investment Grade Bond\ninv_grade_bond = series_dict['inv_grade_bond']\ninv_grade_bond['Date'] = pd.to_datetime(inv_grade_bond['Date'])\ninv_grade_bond.rename(columns={'Adj Close':'inv_grade_bond'}, inplace=True)\ninv_grade_bond['inv_grade_bond_return'] = inv_grade_bond['inv_grade_bond'].pct_change()\ninv_grade_bond['inv_grade_bond_volatility_1m'] = (inv_grade_bond['inv_grade_bond_return'].rolling(20).std())*(20)**(1/2)\ninv_grade_bond['inv_grade_bond_volatility_1y'] = (inv_grade_bond['inv_grade_bond_return'].rolling(252).std())*(252)**(1/2)\ninv_grade_bond = inv_grade_bond[['Date','inv_grade_bond','inv_grade_bond_return','inv_grade_bond_volatility_1m',\n                                 'inv_grade_bond_volatility_1y']]\ninv_grade_bond['one_month_forward_inv_grade_bond_return'] = inv_grade_bond['inv_grade_bond_return'][::-1].rolling(window=20, min_periods=1).sum()[::-1]\n\n# 6. Crude Oil WTI\nwti = series_dict['wti']\nwti['Date'] = pd.to_datetime(wti['DATE'])\nwti.rename(columns={'WTISPLC':'wti'}, inplace=True)\nwti['wti_return'] = wti['wti'].pct_change()\nwti['wti_volatility_1m'] = wti['wti_return'].rolling(20).std()*(20)**(1/2)\nwti['wti_volatility_1y'] = wti['wti_return'].rolling(252).std()*(252)**(1/2)\nwti = wti[['Date','wti','wti_return','wti_volatility_1m','wti_volatility_1y']]\nwti['one_month_forward_wti_return'] = wti['wti_return'][::-1].rolling(window=20, min_periods=1).sum()[::-1]\n\n#7. Inflation\ncpi = series_dict['cpi']\ncpi['Date'] = pd.to_datetime(cpi['DATE'])\ncpi.rename(columns={'CUUR0000SEHE':'cpi'}, inplace=True)\ncpi = cpi[['Date','cpi']]\n\n#8. Employment\nemployment = series_dict['employment']\nemployment['Date'] = pd.to_datetime(employment['DATE'])\nemployment.rename(columns={'PAYEMS_CHG':'employment'}, inplace=True)\nemployment = employment[['Date','employment']]\n\n#9. US Fed's Balance Sheet\nfed_bs = series_dict['fed_bs']\nfed_bs['Date'] = pd.to_datetime(fed_bs['DATE'])\nfed_bs.rename(columns={'WALCL':'fed_bs'}, inplace=True)\nfed_bs = fed_bs[['Date','fed_bs']]\n\n#10. STI Index\nSTI['Date'] = pd.to_datetime(STI['Date'])\nSTI.rename(columns={' Close':'sti'}, inplace=True) # remember there is a space before \"Close\"\nSTI['sti_return'] = STI['sti'].pct_change()\nSTI['sti_volatility_1m'] = (STI['sti_return'].rolling(20).std())*(20)**(1/2) # Annualize daily standard deviation\nSTI['sti_volatility_1y'] = (STI['sti_return'].rolling(252).std())*(252)**(1/2) # 252 trading days per year\nSTI = STI[['Date','sti','sti_return','sti_volatility_1m','sti_volatility_1y']]\n# Calculate 1-month forward cumulative returns\nSTI['one_month_forward_sti_return'] = STI['sti_return'][::-1].rolling(window=20, min_periods=1).sum()[::-1]\n\n#11. Tbill\ntbill[\"help_drop_na\"] = tbill[\"Close\"]/2 # create nup.nan for future dropping and cleanning\ntbill = tbill.dropna()\ntbill['discount_rate'] = tbill ['Adj Close']/100 + 1\ntbill['1plus_discount_rate'] = tbill ['discount_rate']**5\ntbill['tbill_close_price'] = 100/tbill['1plus_discount_rate']\n# try to change date\ntbill['Date'] = pd.to_datetime(tbill['Date'])\ntbill.rename(columns={'tbill_close_price':'tbill'}, inplace=True)\n# do operation\ntbill['tbill_return'] = tbill['tbill'].pct_change()\ntbill['tbill_volatility_1m'] = (tbill['tbill_return'].rolling(20).std())*(20)**(1/2)\ntbill['tbill_volatility_1y'] = (tbill['tbill_return'].rolling(252).std())*(252)**(1/2)\ntbill = tbill[['Date','tbill','tbill_return','tbill_volatility_1m','tbill_volatility_1y']]\ntbill['one_month_forward_tbill_return'] = tbill['tbill_return'][::-1].rolling(window=20, min_periods=1).sum()[::-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PROBLEMSET1: for nber base recession indicator\n\n# Import datasets with Pandas method read_csv\nnber_recession_indicator_month = pd.read_csv('../input/nber-based-recession-indicators-united-states/USRECM.csv')\nnber_recession_indicator_day = pd.read_csv('../input/nber-based-recession-indicators-united-states/USRECD.csv')\n\n# Convert data types\nnber_recession_indicator_day[\"Date\"] = pd.to_datetime(nber_recession_indicator_day[\"date\"])\nnber_recession_indicator_day[\"recession\"] = nber_recession_indicator_day[\"value\"].astype('bool')\n\n# Subset data columns\nnber_recession_indicator_day = nber_recession_indicator_day[[\"Date\",\"recession\"]]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PROBLEMSET1: merge 2nd and 3rd file together\n# Merge datasets together\nasset_classes = [btc,cpi,gold,high_yield_bond,inv_grade_bond,employment,fed_bs,wti,tbill]\n\nbaseline = pd.merge(snp,nber_recession_indicator_day,how='left',left_on='Date', right_on=\"Date\")\nbaseline = pd.merge(STI,baseline,how='left',left_on='Date', right_on=\"Date\")\n\nfor asset_class in asset_classes:\n    baseline = pd.merge(baseline,asset_class,how='left',left_on='Date', right_on=\"Date\")\n\n# Backfilling missing values,  \nbaseline.loc[baseline.Date >= '2020-03-01', \"recession\"] = 1\nbaseline[\"recession\"] = baseline[\"recession\"].fillna(0).astype(bool)\n\nbaseline.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"section-three\"></a>\n# 3.COVID19 Situation in Singapore "},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-three-one\"></a>\n## 3.1 COVID19 General Situation Around The World by Country and Date"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"#chapter1\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate the global trend of active, recover and death chart\n# Collapse Country, Date observations to Date observations and reindex\nactive_total_trend = full_grouped.groupby('Date')['Recovered', 'Deaths', 'Active'].sum().reset_index()\n\n# Melt the data by the value_vars, bascially keep the date and make status as one column, cases become another column\nactive_total_trend = active_total_trend.melt(id_vars=\"Date\", value_vars=['Recovered', 'Deaths', 'Active'],\n                 var_name='Case', value_name='Count')\n\n# Plot the general chart in the ways that as time goes by, what is the case situation\nfig = px.area(active_total_trend, x=\"Date\", y=\"Count\", color='Case', height=600, width=700,\n             title='Cases over time', color_discrete_sequence = [rec, dth, act])\nfig.update_layout(xaxis_rangeslider_visible=True)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notes: General trend of the infected cases still goes up"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Try to plot the stacked chart over time by confirm case, and try to observe the global trend in another way\n\ndef plot_stacked(col):\n    fig = px.bar(full_grouped, x=\"Date\", y=col, color='Country/Region', \n                 height=600, title=col, color_discrete_sequence = px.colors.cyclical.mygbm)\n    fig.update_layout(showlegend=True)\n    fig.show()\n\nplot_stacked('Confirmed')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-three-two\"></a>\n## 3.2 COVID19 General Situation Around The World by Explosion Center"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Try to look at top ten cases country now\n\ndef plot_hbar(df, col, n, hover_data=[]):\n    fig = px.bar(df.sort_values(col).tail(n), \n                 x=col, y=\"Country/Region\", color='WHO Region',  \n                 text=col, orientation='h', width=700, hover_data=hover_data,\n                 color_discrete_sequence = px.colors.qualitative.Dark2)\n    fig.update_layout(title=col, xaxis_title=\"\", yaxis_title=\"\", \n                      yaxis_categoryorder = 'total ascending',\n                      uniformtext_minsize=8, uniformtext_mode='hide')\n    fig.show()\n\nplot_hbar(country_wise, 'Confirmed', 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notes: As we observed, US has the most cases while India's cases has beem climb up"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Try to create a % wise country case chart, merge helps the percentage calculation\ncountry_wise_perc = pd.merge(full_grouped[['Date', 'Country/Region', 'Confirmed', 'Deaths']], \n                day_wise[['Date', 'Confirmed', 'Deaths']], on='Date')\ncountry_wise_perc['% Confirmed'] = round(country_wise_perc['Confirmed_x']/country_wise_perc['Confirmed_y'], 3)*100\ncountry_wise_perc['% Deaths'] = round(country_wise_perc['Deaths_x']/country_wise_perc['Deaths_y'], 3)*100\n\ndef plot_bar(country_wise_perc, col): # change here as there is no feed in df, writing temp very confusing\n    fig = px.bar(country_wise_perc, x='Date', y=col, color='Country/Region', \n             range_y=(0, 100), title='% of Confirmed Cases from each country', \n             color_discrete_sequence=px.colors.qualitative.Prism)\n    fig.show()\n    \nplot_bar(country_wise_perc, '% Confirmed')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notes:\n\nThe explosion center shows that global epic center is shifted from China to Europe then to the US.\n\nNew explosion center start to growth at Latin America and India"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-three-three\"></a>\n## 3.3 COVID19 General Situation in Singapore"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate Current Screenshot of cases expansion in Singapore\n# Graph out the chart\ncountry_wise_sg_only = country_wise_sg_only.melt(value_vars=['Active', 'Deaths', 'Recovered'])\nfig = px.treemap(country_wise_sg_only, path=[\"variable\"], values=\"value\", height=225)\nfig.data[0].textinfo = 'label+text+value'\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notes: Singapore 90% cases has been recovered"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate the global trend of active, recover and death chart for Singapore\n# Collapse Country, Date observations to Date observations and reindex\n# Similar to world chart, can wtire a function to do this and just call, but notebook not scrip so make it clear, write it out\nactive_singapore_trend = full_grouped_SG_Only.groupby('Date')['Recovered', 'Deaths', 'Active'].sum().reset_index()\n\n# Melt the data by the value_vars, bascially keep the date and make status as one column, cases become another column\nactive_singapore_trend = active_singapore_trend.melt(id_vars=\"Date\", value_vars=['Deaths', 'Active', 'Recovered'],\n                 var_name='Case', value_name='Count')\n\n# Plot the general chart in the ways that as time goes by, what is the case situation\nfig = px.area(active_singapore_trend, x=\"Date\", y=\"Count\", color='Case', height=600, width=700,\n             title='Cases over time', color_discrete_sequence = [rec, dth, act])\nfig.update_layout(xaxis_rangeslider_visible=True)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notes: Observed that speed of COVID is under control now"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-three-three-one\"></a>\n### 3.3.1 Singapore Total Test Rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use world meter to see what are the test rate zone Singapore located\nsg_testrate = worldometer[['Country/Region','WHO Region','TotalCases','TestRate']].dropna().sort_values('TestRate',ascending=False)\n\nsg_testrate.reset_index(inplace=True)\nsg_testrate.drop(['index'], axis=1,inplace=True)\nprint(sg_testrate.loc[sg_testrate['Country/Region'] == 'Singapore'])\n\nfig = px.scatter(sg_testrate,x='Country/Region', y='TestRate',size='TotalCases',color='WHO Region',color_discrete_sequence = px.colors.qualitative.Dark2)\nfig.update_layout(title='Test Rate', xaxis_title=\"\", yaxis_title=\"TestRate\",xaxis_categoryorder = 'total ascending',\n                  uniformtext_minsize=8, uniformtext_mode='hide',xaxis_rangeslider_visible=True)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note: Singapore test rate is ranked at the 9th around the world"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-three-three-two\"></a>\n### 3.3.2 Singapore Total Infection Rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use world meter to see what are the infection rate zone Singapore located\n\nsg_infection_rate = worldometer[['Country/Region','WHO Region','TotalCases','InfectionRate']].dropna().sort_values('InfectionRate',ascending=False)\n\nsg_infection_rate.reset_index(inplace=True)\nsg_infection_rate.drop(['index'], axis=1,inplace=True)\nprint(sg_infection_rate.loc[sg_infection_rate['Country/Region'] == 'Singapore'])\n\nfig = px.scatter(sg_infection_rate,x='Country/Region', y='InfectionRate',size='TotalCases',color='WHO Region',color_discrete_sequence = px.colors.qualitative.Dark2)\nfig.update_layout(title='Infection Rate', xaxis_title=\"\", yaxis_title=\"InfectionRate\",xaxis_categoryorder = 'total ascending',\n                  uniformtext_minsize=8, uniformtext_mode='hide',xaxis_rangeslider_visible=True)\nfig.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note: Singapore inflection rate is ranked at the 14th around the world"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-three-three-three\"></a>\n### 3.3.3 Singapore Total Serious Case Rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use worldometer to see the serious case rate for Singapore\nsg_seriousrate = worldometer[['Country/Region','WHO Region','TotalCases','SeriousRate']].dropna().sort_values('SeriousRate',ascending=False)\n\nsg_seriousrate.reset_index(inplace=True)\nsg_seriousrate.drop(['index'], axis=1,inplace=True)\nprint(sg_seriousrate.loc[sg_seriousrate['Country/Region'] == 'Singapore'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note: Singapore does not report any serious rate numbers"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-three-three-four\"></a>\n### 3.3.4 Singapore Total Death Rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use world meter to see what are the death rate zone Singapore located\n\nsg_death_rate = worldometer[['Country/Region','WHO Region','TotalCases','DeathRate']].dropna().sort_values('DeathRate',ascending=False)\n\nsg_death_rate.reset_index(inplace=True)\nsg_death_rate.drop(['index'], axis=1,inplace=True)\nprint(sg_death_rate.loc[sg_death_rate['Country/Region'] == 'Singapore'])\n\nfig = px.scatter(sg_death_rate,x='Country/Region', y='DeathRate',size='TotalCases',color='WHO Region',color_discrete_sequence = px.colors.qualitative.Dark2)\nfig.update_layout(title='Death Rate', xaxis_title=\"\", yaxis_title=\"DeathRate\",xaxis_categoryorder = 'total ascending',\n                  uniformtext_minsize=8, uniformtext_mode='hide',xaxis_rangeslider_visible=True)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note: Singapore Death Rate is one of the lowest in the world"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"subsection-three-four\"></a>\n## 3.4 COVID19 Unusual Numbers and Explaination in Singapore"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use Boolean indexing to generate a mask which is just a series of boolean values representing whether the column contains the specific element or not\nselected = full_grouped['Country/Region'].str.contains('Singapore')\n\n# Apply this mask to our original DataFrame to filter the required values.\nsingapore = full_grouped[selected]\nsingapore[\"New active\"] = singapore[\"Active\"].diff()\nsingapore[\"New recoverd\"] = singapore[\"Recovered\"].diff()\n\nsingapore_diff_case = singapore.melt(id_vars=\"Date\", value_vars=['New deaths', 'New cases', 'New recovered'],\n                 var_name='Case', value_name='Count')\n\nfig = px.area(singapore_diff_case, x=\"Date\", y=\"Count\", color='Case', height=600, width=1200,\n             title='Cases over time', color_discrete_sequence = [rec, dth, act])\nfig.update_layout(xaxis_rangeslider_visible=True)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Discussion on abnormal figures\nApr 18th, 20th 2020: Mass explosion as worker's camp closed and mass amount of foreign workers start to be tested\n\nSpikey Apr to Jun Period: Nearly every 2-3 days there is one testing trough and peak, we discover that is closely link to number of test done by government on that day (dataset hard to find).\n\nJul 20th onwards spike is due to the re-opening of Singapore, several new cases without symdrone aree detected\n"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"section-four\"></a>\n# 4. STI and Recession Hedges Finding"},{"metadata":{"trusted":true},"cell_type":"code","source":"# basic discription of all return and volatility figures\nbaseline[[\"sti_return\", \"sti_volatility_1y\", \"snp_return\", \"snp_volatility_1y\", \"btc_return\", \"btc_volatility_1y\", \"gold_return\", \"gold_volatility_1y\", \n                  \"high_yield_bond_return\", \"high_yield_bond_volatility_1y\", \"inv_grade_bond_return\", \n                  \"inv_grade_bond_volatility_1y\", \"wti_return\", \"wti_volatility_1y\", \"tbill_return\", \"tbill_volatility_1y\"]].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# All return info no volatility info, then get sharp ratio\nstatestable = baseline[[\"sti_return\", \"snp_return\", \"btc_return\", \"gold_return\", \"high_yield_bond_return\", \"inv_grade_bond_return\", \n                  \"wti_return\", \"tbill_return\"]].describe()\n\nreturn_tbill = statestable.loc[\"mean\",\"tbill_return\"]\nstatestable.loc[\"tbill_return\"] = return_tbill\nstatestable.loc[\"sharp_ratio\"] = (statestable.loc[\"mean\"]-statestable.loc[\"tbill_return\"])/statestable.loc[\"std\"]\nprint(statestable)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note: Bitcoin, WTI and Investment Grade Bond has higher sharp ratios"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_chart(series):\n    fig = px.scatter(baseline[baseline[series].notnull()], x=\"Date\", y=series, color=\"recession\", color_discrete_sequence=['#636EFA', '#FFA15A'], width=1200)\n    fig.update_traces(mode='markers', marker_size=4)\n    fig.update_layout(title=series, xaxis_title=\"\", yaxis_title=\"\")\n    fig.show()\n\nplot_chart(\"sti\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note: no significant relationship between STI and recession (purple)"},{"metadata":{"trusted":true},"cell_type":"code","source":"baseline_corr = baseline[[\"sti_return\", \"sti_volatility_1y\", \"snp_return\", \"snp_volatility_1y\", \"btc_return\", \"btc_volatility_1y\", \"gold_return\", \"gold_volatility_1y\", \n                  \"high_yield_bond_return\", \"high_yield_bond_volatility_1y\", \"inv_grade_bond_return\", \n                  \"inv_grade_bond_volatility_1y\", \"wti_return\", \"wti_volatility_1y\", \"tbill_return\", \"tbill_volatility_1y\"]].dropna().corr()\n\nfig, ax = plt.subplots(figsize=(20,10)) \nsns.heatmap(baseline_corr, annot=True, ax = ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note:\n\nWe can see that S&P is actually the best hedging tool for STI index, WTI and High Yield Bond follows.\n\nThis means STI is more of a hedging tool for the global markets"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Detail exam the correlation between STI and S&P\nsns.jointplot(x = 'sti_return', y = 'snp_return', data = baseline, kind='reg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Detail exam the correlation between STI and wti\nsns.jointplot(x = 'sti_return', y = 'wti_return', data = baseline, kind='reg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Detail exam the correlation between STI and high yield bond\nsns.jointplot(x = 'sti_return', y = 'high_yield_bond_return', data = baseline, kind='reg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"section-five\"></a>\n# 5. Volatility vs Return"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_chart_vol_ret(series):\n    fig = px.scatter(baseline[baseline[series+'_return'].notnull()], x=series + '_volatility_1m', \n                     y='one_month_forward_' + series + '_return', width=800,\n                     trendline = 'ols')\n    fig.update_layout(title=str(series) + ' volatility vs one-month forward return', xaxis_title='', yaxis_title='')\n    fig.show()\n    \ndef plot_chart_vol_ret_by_recession(series):\n    fig = px.scatter(baseline[baseline[series+'_return'].notnull()], x=series + '_volatility_1m', \\\n                     color='recession', y='one_month_forward_' + series + '_return', \n                     color_discrete_sequence=['#636EFA', '#FFA15A'], width=800,\n                     trendline = 'ols')\n    fig.update_layout(title=str(series) + ' volatility vs one-month forward return', xaxis_title='', yaxis_title='')\n    fig.show()\n    \n# Show if STI volatility fortune tells return in general\nplot_chart_vol_ret('sti')\n\n# Show if STI volatility fortune tells return in recession or non-recession period\nplot_chart_vol_ret_by_recession('sti')\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note: The relationship is rather vague"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"section-six\"></a>\n# 6. Conclusion"},{"metadata":{},"cell_type":"markdown","source":"- Global case of COVID 19 still growing\n- Epi-center shifted from China to Asia, Europ, US and now located in Latin America and India\n- Singapore case is well-contained while in Jul we see a small re-spike due to re-opening of Singapore\n- Singapore has very high test and infection rate over population (although most of cases are in domitory), however, death rate of Singapore COVID 19 is almost the lowest around the world\n- STI, as a hedging tool, is used more in economy downturn to prevent huge position in risky asset such as WTI, high yield risk bond and s&p 500, in return, assets mentioned above are the best hedgers for STI\n- However, the volatility of STI does not suggests any future STI return in the future"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}