{"cells":[{"metadata":{"_uuid":"d2b5b08b-a54a-4451-b950-d3850a3a6b17","_cell_guid":"4cc81943-4e67-4ad7-98dd-647484543f4f","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\n\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits import mplot3d","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression,Ridge,Lasso,ElasticNet\nimport statsmodels.api as sm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection\nfrom sklearn.model_selection import KFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFE\nfrom mlxtend.feature_selection import SequentialFeatureSelector as sfs\nfrom sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import accuracy_score as acc\nfrom sklearn.metrics import r2_score\nfrom sklearn import ensemble","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/kc-housesales-data/kc_house_data.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have read our data set"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To print five rows of our data set"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 21597 rows and 21 columns in our data set"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Prints us the number of columns in our data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This explains us about the type of variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This describes the data in a stastical way"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no null values in our data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.bedrooms.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This shows us the count of houses based on bed rooms."},{"metadata":{},"cell_type":"markdown","source":"To represent the above data graphically"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df.bedrooms)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's very clear that the 3 bed room houses are more in our given data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.floors.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To count the houses based on the number of floors."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df.floors)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This shows there are 10673 houses which has only first floor."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.grade.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df.grade)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This shows us the grade of the houses."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df.grade,df.price)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Houses with higher grade has higher price value."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(df.grade,df.price)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The split of data and their reg plot."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df.price)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This shows that our target variable price is right skewed."},{"metadata":{},"cell_type":"markdown","source":"We have to convert our right skewed target variable into normal distribution."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['price'] = df['price'].apply(lambda x : np.log(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df.price)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now our data is normally distributed"},{"metadata":{"trusted":true},"cell_type":"code","source":"continous_columns=['id','price', 'bedrooms', 'bathrooms', 'sqft_living',\n       'sqft_lot', 'waterfront','sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n       'lat', 'long', 'sqft_living15', 'sqft_lot15']\nfor i in continous_columns:\n    print(\"columns name:\",i)\n    sns.distplot(df[i])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have printed the different Histograms of our varibales."},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in continous_columns:\n    print(\"column name:\",i)\n    sns.boxplot(df[i])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Box plot of our variables which clearly shows us the outliers present in it."},{"metadata":{"trusted":true},"cell_type":"code","source":"mod=[]\ndef find_outlier(df_in, col_name):\n    q1 = df_in[col_name].quantile(0.25)\n    q3 = df_in[col_name].quantile(0.75)\n    iqr = q3-q1 #Interquartile range\n    fence_low  = q1-1.5*iqr\n    fence_high = q3+1.5*iqr\n    df_high=df_in.loc[(df_in[col_name] > fence_high)]\n    #df_out = df_in.loc[(df_in[col_name] > fence_low) & (df_in[col_name] < fence_high)]\n    outlier_percentage=(df_high.shape[0]/len(df))*100\n    outlier_percentage=round(outlier_percentage,2)\n    print(outlier_percentage)\n    mod.append((col_name,outlier_percentage))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in continous_columns:\n    find_outlier(df,i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"length=len(continous_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result=[]\nnames=[]\nfor i in range(0,length-1):\n    result.append(mod[i][1])\n    names.append(mod[i][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p=pd.DataFrame(result)\np.rename(columns={0:\"outlier_percentage\"},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p.plot.bar(figsize=(20, 8))\nplt.xticks(np.arange(length),names)\nplt.title(\"percentage of outliers in each column\")\nplt.axhline(5)#axis \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We here by print the Outliers present in our data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['date'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we don't need date column we are droping it."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.cov()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax= plt.subplots()\nfig.set_size_inches(11.7, 8.27)\nsns.heatmap(df.corr(),annot=True,linewidths=0.2,vmax = .9)\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fitting our Base model."},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df['price']\nX=df.drop('price',axis=1)\nxc=sm.add_constant(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.stats as stats\nprint(np.abs(round(stats.norm.isf(q = 0.025),2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lin_reg = LinearRegression()\nmodel = lin_reg.fit(X_train,y_train)\nprint(f'R^2 score for train: {lin_reg.score(X_train, y_train)}')\nprint(f'\\nR^2 score for test: {lin_reg.score(X_test, y_test)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import ttest_1samp\nprint(df.mean(),np.std(df,ddof = 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xc = sm.add_constant(X)\nlin_reg = sm.OLS(y,Xc).fit()\nlin_reg.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our basr mode is fitted with the 0.77 R^2 value."},{"metadata":{"trusted":true},"cell_type":"code","source":"lin_reg = LinearRegression()\nlin_reg.fit(X, y)\n\nprint(f'Coefficients: {lin_reg.coef_}')\nprint(f'\\nIntercept: {lin_reg.intercept_}')\nprint(f'\\nR^2 score: {lin_reg.score(X, y)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2,\n          'learning_rate': 0.01, 'loss': 'ls'}\nmodel = ensemble.GradientBoostingRegressor(**params)\n\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, r2_score\nmodel_score = model.score(X_train,y_train)\n# Have a look at R sq to give an idea of the fit ,\n# Explained variance score: 1 is perfect prediction\nprint('R2 sq: ',model_score)\ny_predicted = model.predict(X_test)\n\n# The mean squared error\nprint(\"Mean squared error: %.2f\"% mean_squared_error(y_test, y_predicted))\n# Explained variance score: 1 is perfect prediction\nprint('Test Variance score: %.2f' % r2_score(y_test, y_predicted))\nprint(\"RMSE:%.2f\"% np.sqrt(mean_squared_error(y_test, y_predicted)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'R^2 score for train: {model.score(X_train, y_train)}')\nprint(f'\\nR^2 score for test: {model.score(X_test, y_test)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_predict\n\nfig, ax = plt.subplots()\nax.scatter(y_test, y_predicted, edgecolors=(0, 0, 0))\nax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\nax.set_xlabel('Actual')\nax.set_ylabel('Predicted')\nax.set_title(\"Actual vs Predicted\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}