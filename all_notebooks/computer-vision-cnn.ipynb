{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd ## Pandas Library (will use to load data,create data frame...etc).\nimport numpy as np ## Numpy Library ( will use to convert data frame to array or creating array etc...).\nimport os ## For connecting to machine to get path for reading/writing files.\nimport matplotlib.image as mpimg ## To load image.\nimport matplotlib.pyplot as plt ## For Visualizaton.\nfrom keras.preprocessing import image ## To load Image and convert it into array.\nfrom tqdm import tqdm ## To print Progress bars.\nfrom sklearn.model_selection import train_test_split ## To split train data into train and validation data.\nfrom keras.utils import to_categorical ## One hot Encoding.\nfrom keras.models import Sequential ## Sequential Model.\nfrom keras.layers import Dense ## Fully connected layer(all inputs connected to all nodes).\nfrom keras.layers import Dropout ## For Regularaization (drops couple of nodes based on integer passed to constructor).\nfrom keras.layers import Flatten ## To convert array  into 1D(one dimesional).\nfrom keras.layers import Conv2D ## Convolution two dimensional layer .\nfrom keras.layers import MaxPool2D ## fecthing important features/ reducing dimensions.\nfrom keras.optimizers import RMSprop # Optimizer.\nfrom keras.preprocessing.image import ImageDataGenerator # Image Augmentation.\nfrom keras.callbacks import ReduceLROnPlateau # Call backs/Early stopping.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Set max how many rows and columns you want to display in jupyter notebook.\npd.options.display.max_columns = 200 \npd.get_option('display.max_rows') \npd.set_option('display.max_rows',None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Images path.\nimage_path ='../input/hp-2020/jh_2020/images/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/hp-2020/jh_2020/train.csv',header='infer',sep=',')\ntest = pd.read_csv('../input/hp-2020/jh_2020/test.csv',header='infer',sep=',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Print dimensions of train and test data.\nprint(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Check first record from train data.\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Check last record from train data.\ntrain.tail(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Check first record from test data.\ntest.head(1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.tail(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Get summary statistics of train data.\ntrain.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Get summary statistics of test data.\ntest.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Method will read list of images in the given path and returns image list.\ndef get_images_list(path):\n    image_list = [] ## Initialize empty list.\n    for img in tqdm(os.listdir(path)): ## Get list of image names from the given path and process each image names.\n        image_list.append(img) ## add image name to image list.\n    return image_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Get image list for the the given path.\nimage_list = get_images_list(image_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Print first image name from image_list.\nimage_list[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Plot sample images based on given image location.\ndef display_sample_images(path):\n    plt.figure(figsize=(20,6)) ## Set Figure Size.\n    for ind,image_name in tqdm(enumerate(os.listdir(path))): ## enumerate() function iterates list and return index,value.\n        img = mpimg.imread(os.path.join(path,image_name)) ## imread() reads the image from the given path and image name.\n        if ind<10: ## Based on this condition it prints only 10 images.\n            plt.subplot(2,5,ind+1) ## Add a subplot to the current figure(2 rows,5 columns and current index).\n            plt.imshow(img) ## Displays image.\n            plt.axis('off') ## Axis values will off.\n            plt.title(ind) ## Setting title name to image.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Display first 10 images.\ndisplay_sample_images(image_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Image Size\nIMG_SIZE = 28","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Load training images from the given path based on image names which are there in train data and convert them into array.\ndef load_train_data(img_path):\n    train_data = [] ## Initialize empty list\n    for img in tqdm(train['image_names']): ## Get list of image names from train data and process each image name.\n        if img in image_list: ## If the image name is present in image list then only we have to read image.\n            path = os.path.join(img_path, img) ## Location of the the image.\n            img = image.load_img(path,                              ## Load image from the given path and\n                                 target_size=(IMG_SIZE,IMG_SIZE,3), ## Keep image size as 28X28X3(height,width,color channels) and\n                                 grayscale=False)                   ## grayscale is false indicates that image is color image.\n            img = image.img_to_array(img) ## Convert image pixels into an array.\n            img = img/255 ## Normalize the train data (CNN converg faster on [0..1] data than on [0..255]).\n            train_data.append(img) ## Add normalized image pixel array to train data.      \n    return np.array(train_data) ## Convert list into an array and returns it.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Get training data for the given image path.\ntrain_data = load_train_data(image_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Display sample train image.\nplt.imshow(train_data[1491], cmap = 'gist_gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Get size of the train_data.\nlen(train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Check image size.\nlen(image_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Load testing images from the given path based on images names which are there in test data and convert them into array.\ndef load_test_data(image_path):\n    test_data = []  ## Initialize empty list\n    for img in tqdm(test['image_names']): ## Get list of image names from test data and process each image name.\n        if img in image_list: ## If the image name is present in image list then only we have to read image.\n            path = os.path.join(image_path, img) ## Location of the the image.\n            img = image.load_img(path,                              ## Load image from the given path and\n                                 target_size=(IMG_SIZE,IMG_SIZE,3), ## Keep image size as 28X28X3(height,width,color channels) and\n                                 grayscale=False)                   ## grayscale is false indicates that image is color image.\n            img = image.img_to_array(img) ## Convert image pixels into an array.\n            img = img/255 ## Normalize the test data (CNN converg faster on [0..1] data than on [0..255]).\n            test_data.append(img) ## Add normalized image pixel array to test data.\n    return np.array(test_data) ## Convert list into an array and returns it.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Get testing data for the given image path.\ntest_data = load_test_data(image_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Display sample test image.\nplt.imshow(test_data[0], cmap = 'gist_gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Do one hot encoding on target/label varible.\ny = train['emergency_or_not'].values ## Fetch label/target values(0/1).\ny = to_categorical(y) ## Converts a class vector (integers) to binary class matrix.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Check sample value of target after doing one hot encoding.\ny[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Check sample record of target after doing one hot encoding.\ny[5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Split the train data into train and validation data.\nX_train, X_test, y_train, y_test = train_test_split(train_data,       ## Features(i/p).\n                                                    y,                ## Traget(0/p).\n                                                    random_state=474, ## It is the seed used by the random number generator.\n                                                    test_size=0.2)    ## % of train and validation division.(80:20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the model structure.\n\n## Instantiate Sequential model.\nmodel = Sequential()\n\n# Convolution layer with feature map size 3X3,32 filters,input shape 28X28X3,Relu Activation function.\nmodel.add(Conv2D(32,  ##  Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n                 kernel_size=(3, 3), ## An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window.Can be a single integer to specify the same value for all spatial dimensions(Feature Map).\n                 padding = 'Same', ## one of \"valid\" or \"same\" (padding is added to the frame of the image to allow for more space for the kernel to cover the image).\n                 activation='relu', ## Activation function.If you don't specify anything, no activation is applied.\n                 input_shape=(28,28,3))) ## Input shapes(28X28X3).\n\n## Convolution layer with feature map size 3X3,64 filters,Relu Activation function.\nmodel.add(Conv2D(64,\n                 kernel_size=(3, 3), \n                 padding = 'Same',\n                 activation='relu'))\n\n## Maxpooling layer with kernal size 2X2,default stride (pool_size).\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\n## Droput 25% Nodes.\nmodel.add(Dropout(0.25))\n\n## Convert array data into one dimensional data.\nmodel.add(Flatten())\n\n## Fully connected layer with 128 output shape,Relu Activation function.\nmodel.add(Dense(128, activation='relu'))\n\n## Dropouts 50% Nodes.\nmodel.add(Dropout(0.5))\n\n## Fully connnected layer with 2 output shape,Softmax activation function.\nmodel.add(Dense(2, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compile the model.\nmodel.compile(loss='categorical_crossentropy',  ## String (name of objective function) or objective function or`Loss` instance.\n              optimizer='Adam',                 ## String (name of optimizer) or optimizer instance.\n              metrics=['accuracy'])             ## List of metrics to be evaluated by the model during training and testing.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the model.\nmodel.fit(X_train,                            ## Input/Training data.\n          y_train,                            ## Labels/Targe/Output data.\n          epochs=30,                          ## Number of epochs to train the model.\n          validation_data=(X_test, y_test))   ## On which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data(Validation  data). ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Get predictions for test data\nprediction = model.predict_classes(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Print first value from predictions\nprediction[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Copy test data into temp\ntemp = test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Add predictions data to temp data frame with 'emergency_or_not' column name\ntemp ['emergency_or_not'] = prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Check first 5 records from temp data\ntemp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Copy 'image_names', 'emergency_or_not' columns data from temp to to_submit\nto_submit = temp[['image_names', 'emergency_or_not']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Check the data value count for 'emergency_or_not' column\nto_submit.emergency_or_not.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Store to_submit data into a csv file with name Keras_Predictions \nto_submit.to_csv('Keras_Predictions.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Set the CNN model.\n## My CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out .\n\n## Instantiate Sequential model.\nmodel = Sequential()\n\n## Convolution layer with feature map size 5X5,32 filters,input shape 28X28X1,Relu Activation function.\nmodel.add(Conv2D(filters = 32, ## Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n                 kernel_size = (5,5), ## An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window.Can be a single integer to specify the same value for 1all spatial dimensions.\n                 padding = 'Same', ## one of `\"valid\"` or `\"same\"`.\n                 activation ='relu',## Activation function.If you don't specify anything, no activation is applied.\n                 input_shape = (28,28,3))) ## input shapes(28X28X3).\n\n## Convolution layer with feature map size 5X5,32 filters,Relu Activation function.\nmodel.add(Conv2D(filters = 32,\n                 kernel_size = (5,5),\n                 padding = 'Same', \n                 activation ='relu'))\n\n## Maxpooling layer with kernal size 2X2,default stride (pool_size).\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\n## Droput 25% Nodes.\nmodel.add(Dropout(0.25))\n\n## Convolution layer with feature map size 3X3,64 filters,Relu Activation function.\nmodel.add(Conv2D(filters = 64,\n                 kernel_size = (3,3),\n                 padding = 'Same', \n                 activation ='relu'))\n\n## Convolution layer with feature map size 3X3,64 filters,Relu Activation function.\nmodel.add(Conv2D(filters = 64,\n                 kernel_size = (3,3),\n                 padding = 'Same', \n                 activation ='relu'))\n\n## Maxpooling layer with kernal size 2X2,Stride 2X2.\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n\n## Droput 25% Nodes.\nmodel.add(Dropout(0.25))\n\n## Convert array data into one dimensional data.\nmodel.add(Flatten())\n\n## Fully connected layer with 256 output shape,Relu Activation function.\nmodel.add(Dense(256, activation = \"relu\"))\n\n## Dropouts 50% Nodes.\nmodel.add(Dropout(0.5))\n\n## Fully connnected layer with 2 output shape,Softmax activation function.\nmodel.add(Dense(2, activation = \"softmax\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Define the RMSprop optimizer with leaning rate 0.001.\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Compile the model\nmodel.compile(optimizer = optimizer ,            ## String (name of optimizer) or optimizer instance.\n              loss = \"categorical_crossentropy\", ## String (name of objective function) or objective function or`Loss` instance. \n              metrics=[\"accuracy\"])              ## List of metrics to be evaluated by the model during training and testing.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', ## Quantity to be monitored.\n                                            patience=3,     ## Number of epochs that produced the monitored quantity with no improvement after which training will be stopped. \n                                            verbose=1,      ## int. 0: quiet, 1: update messages.\n                                            factor=0.5,     ## Factor by which the learning rate will be reduced. new_lr = lr * factor\n                                            min_lr=0.00001) ## Lower bound on the learning rate.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Instantiate Data Augmentation\n\ndatagen = ImageDataGenerator(featurewise_center=False,            ## Set input mean to 0 over the dataset\n                             samplewise_center=False,             ## Set each sample mean to 0\n                             featurewise_std_normalization=False, ## Divide inputs by std of the dataset\n                             samplewise_std_normalization=False,  ## Divide each input by its std\n                             zca_whitening=False,                 ## Apply ZCA whitening\n                             rotation_range=10,                   ## Randomly rotate images in the range (degrees, 0 to 180)\n                             zoom_range = 0.1,                    ## Randomly zoom image \n                             width_shift_range=0.1,               ## Randomly shift images horizontally (fraction of total width)\n                             height_shift_range=0.1,              ## Randomly shift images vertically (fraction of total height)\n                             horizontal_flip=False,               ## Randomly flip images horizontally\n                             vertical_flip=False)                 ## Randomly flip images vertically\n\n## Fit data augmentation model\ndatagen.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 30      ## Number of epochs to train a model\nbatch_size = 86  ## Number of sample to process at a time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Fit the model\nhistory = model.fit_generator(datagen.flow(X_train,                           ## Input data\n                                           y_train,                           ## Labels/ Target/ out put data\n                                           batch_size=batch_size),            ## Batch size (default: 32)\n                              epochs = epochs,                                ## Number of epochs to train the model.\n                              validation_data = (X_test, y_test),             ## On which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data(Validation data).\n                              verbose = 2,                                    ## 0, 1, or 2. Verbosity mode 0 = silent, 1 = progress bar, 2 = one line per epoch.\n                              steps_per_epoch=X_train.shape[0] // batch_size, ## Total number of steps (batches of samples) to yield from `generator` before declaring one epoch finished and starting the next epoch. It should typically be equal to `ceil(num_samples / batch_size)`\n                              callbacks=[learning_rate_reduction])            ## List of callbacks to apply during training.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Plot the loss and accuracy curves for training and validation data\nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Get Predictions for test data\nresults = model.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Copy test data into temp\ntemp = test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Add predictions data to temp data frame with 'emergency_or_not' column name\ntemp ['emergency_or_not'] = results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Copy 'image_names', 'emergency_or_not' columns data from temp to to_submit\nto_submit = temp[['image_names', 'emergency_or_not']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Check the data value count for 'emergency_or_not' column\nto_submit.emergency_or_not.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Store to_submit data into a csv file with name Keras_Predictions_With_DataAugmentation \nto_submit.to_csv('Keras_Predictions_With_DataAugmentation.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}