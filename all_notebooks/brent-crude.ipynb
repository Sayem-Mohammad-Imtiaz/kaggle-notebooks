{"cells":[{"metadata":{},"cell_type":"markdown","source":"We start by importing the libraries we are going to use\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/brent-oil-prices/BrentOilPrices.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Coverting first column to datetime format"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.Date = pd.to_datetime(df.Date)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For this project we are going to make an LSTM model, which needs a window of past historical prices to be trained on, along with a target_size of the number of data points we want to predict in the future. The function below prepares our our training and test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def univariate_data(dataset, start_index, end_index, history_size, target_size):\n  data = []\n  labels = []\n\n  start_index = start_index + history_size\n  if end_index is None:\n    end_index = len(dataset) - target_size\n\n  for i in range(start_index, end_index):\n    indices = range(i-history_size, i)\n    # Reshape data from (history_size,) to (history_size, 1)\n    data.append(np.reshape(dataset[indices], (history_size, 1)))\n    labels.append(dataset[i+target_size])\n  return np.array(data), np.array(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_SPLIT = int(0.8 * df.shape[0]) # selecting 80% as our training data \nuni_data = df.Price\nuni_data\nuni_data.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"uni_data = uni_data.values\nuni_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We normalise our data. Keep in mind that we do this only for the traning set."},{"metadata":{"trusted":true},"cell_type":"code","source":"uni_train_mean = uni_data[:TRAIN_SPLIT].mean()\nuni_train_std = uni_data[:TRAIN_SPLIT].std()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"uni_data = (uni_data-uni_train_mean)/uni_train_std\nuni_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"univariate_past_history = 100\nunivariate_future_target = 0\n\nx_train_uni, y_train_uni = univariate_data(uni_data, 0, TRAIN_SPLIT,\n                                           univariate_past_history,\n                                           univariate_future_target)\nx_val_uni, y_val_uni = univariate_data(uni_data, TRAIN_SPLIT, None,\n                                       univariate_past_history,\n                                       univariate_future_target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_time_steps(length):\n  time_steps = []\n  for i in range(-length, 0, 1):\n    time_steps.append(i)\n  return time_steps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_plot(plot_data, delta, title):\n  labels = ['History', 'True Future', 'Model Prediction']\n  marker = ['.-', 'rx', 'go']\n  time_steps = create_time_steps(plot_data[0].shape[0])\n  if delta:\n    future = delta\n  else:\n    future = 0\n\n  plt.title(title)\n  for i, x in enumerate(plot_data):\n    if i:\n      plt.plot(future, plot_data[i], marker[i], markersize=10,\n               label=labels[i])\n    else:\n      plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n  plt.legend()\n  plt.xlim([time_steps[0], (future+5)*2])\n  plt.xlabel('Time-Step')\n  return plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_plot([x_train_uni[0], y_train_uni[0]], 0, 'Sample Example')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 256\nBUFFER_SIZE = 10000\n\ntrain_univariate = tf.data.Dataset.from_tensor_slices((x_train_uni, y_train_uni))\ntrain_univariate = train_univariate.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n\nval_univariate = tf.data.Dataset.from_tensor_slices((x_val_uni, y_val_uni))\nval_univariate = val_univariate.batch(BATCH_SIZE).repeat()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"simple_lstm_model = tf.keras.models.Sequential([\n    tf.keras.layers.LSTM(8, input_shape=x_train_uni.shape[-2:]),\n    tf.keras.layers.Dense(1)\n])\n\nsimple_lstm_model.compile(optimizer='adam', loss='mae')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are going to use 10 epochs to train our LSTM model along with 100 evaluation steps (instead of the whole training set which is the usual)."},{"metadata":{"trusted":true},"cell_type":"code","source":"EVALUATION_INTERVAL = 100\nEPOCHS = 10\n\nsimple_lstm_model.fit(train_univariate, epochs=EPOCHS,\n                      steps_per_epoch=EVALUATION_INTERVAL,\n                      validation_data=val_univariate, validation_steps=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x, y in val_univariate.take(10):\n  plot = show_plot([x[0].numpy(), y[0].numpy(),\n                    simple_lstm_model.predict(x)[0]], 0, 'Simple LSTM model')\n  plot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}