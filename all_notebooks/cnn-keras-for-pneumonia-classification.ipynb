{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Import packages\nimport pandas as pd \nimport numpy as np \nimport os\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#Directory\nmain_folder = \"../input\"\nsubfolder_input = r'all/All'\ncsv_file = r'GTruth.csv'\n\n# Files\nfiles = [f for f in os.listdir(os.path.join(main_folder, subfolder_input)) if \"csv\" not in f]\ndataframe = pd.read_csv(os.path.join(main_folder, subfolder_input, csv_file))\ndataframe[\"Id\"] = dataframe[\"Id\"].apply(lambda x: str(x) + r\".jpeg\")\ndataframe[\"Ground_Truth\"] = dataframe[\"Ground_Truth\"].apply(lambda x: str(1-x)) # Change the label to 0 = normal, 1 = pneumonia","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize an image\nnrows = 4\nncols = 4\nidx = np.random.randint(0, len(files), nrows*ncols)\nfig, axes = plt.subplots(nrows, ncols, figsize = (10, 10))\nfor ii, ax in zip(idx, axes.flatten()):\n\timg = Image.open(os.path.join(main_folder, subfolder_input, files[ii]))\n\tax.imshow(img)\n\tax.xaxis.set_visible(False)\n\tax.yaxis.set_visible(False)\n\tax.title.set_text(\"Class label: %s\" %dataframe.loc[dataframe[\"Id\"] == files[ii], \"Ground_Truth\"].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display the number of cases for \"normal\" (1) and \"pneumonia\" (1)\ndataframe[\"Ground_Truth\"].value_counts().plot.bar()\n\n\"\"\"\n72% - normal (0), 28% - pneumonia (1)\nThere is an imbalance of classes with about 72% of the samples are normal\nThere is a need to balance out the classes prior to training\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the dataframe into train, val and test set\ntrain_set, test_set = train_test_split(dataframe, test_size = 500)\ntrain_set, val_set  = train_test_split(train_set, test_size = 500)\n\nprint(\" No of training samples: %s \\n\" %len(train_set),\n     \"No of validation samples: %s \\n\" %len(val_set),\n     \"No of test samples: %s\" %len(test_set))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create generator for the images\nbatch_size = 128\nimage_height = 256\nimage_width = 256\nimage_channels = 3\n\n## Train generator\ntrain_datagen = ImageDataGenerator(\n\trescale = 1./255,\n\thorizontal_flip = True,\n\trotation_range = 15,\n\twidth_shift_range = 0.1,\n\theight_shift_range = 0.1\n\t)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n\tdataframe = train_set,\n\tdirectory = os.path.join(main_folder, subfolder_input),\n\tx_col = \"Id\",\n\ty_col = \"Ground_Truth\",\n\tclass_mode = \"binary\",\n\tbatch_size = batch_size,\n\ttarget_size = (image_height, image_width)\n\t)\n\n## Val generator\nval_datagen = ImageDataGenerator(rescale = 1./255)\nval_generator = val_datagen.flow_from_dataframe(\n\tdataframe = val_set,\n\tdirectory = os.path.join(main_folder, subfolder_input),\n\tx_col = \"Id\",\n\ty_col = \"Ground_Truth\",\n\tclass_mode = \"binary\",\n\tbatch_size = batch_size,\n\ttarget_size = (image_height, image_width)\n\t)\n\n## Test generator\ntest_datagen = ImageDataGenerator(rescale = 1./255)\ntest_generator = test_datagen.flow_from_dataframe(\n\tdataframe = test_set,\n\tdirectory = os.path.join(main_folder, subfolder_input),\n\tx_col = \"Id\",\n\ty_col = \"Ground_Truth\",\n\tclass_mode = \"binary\",\n\tbatch_size = batch_size,\n\ttarget_size = (image_height, image_width)\n\t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CNN model hyperparameters\ndropout_rate = 0.25\nfc_units_1 = 1024\nfc_units_2 = 512\noutput_units = 1\n\n# Build CNN model\nmodel = Sequential()\n\n## Convolutional layer\n### Layer 1\nmodel.add(Conv2D(filters = 32, kernel_size = 3, strides = 1, padding = \"same\",\n\tinput_shape = (image_height, image_width, image_channels), data_format = \"channels_last\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D())\nmodel.add(Dropout(rate = dropout_rate))\n\n### Layer 2\nmodel.add(Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D())\nmodel.add(Dropout(rate = dropout_rate))\n\n### Layer 3\nmodel.add(Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = \"same\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D())\nmodel.add(Dropout(rate = dropout_rate))\n\n## Fully connected layer\nmodel.add(Flatten())\n### FC1\nmodel.add(Dense(units = fc_units_2, activation = \"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(rate = dropout_rate))\n\n### Output layer\nmodel.add(Dense(units = output_units, activation = \"sigmoid\"))\n\n## CNN model summary\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate = 0.002\n# Optimizer\noptimizer = Adam(lr = learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compile\nmodel.compile(optimizer = optimizer, loss = \"binary_crossentropy\", metrics = [\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Callbacks\n## Reduce learning rate\nreduce_lr = ReduceLROnPlateau(\n\tmonitor = \"val_acc\",\n\tfactor = 0.5,\n\tpatience = 3,\n\tverbose = 1,\n\tmin_lr = 0.00001\n\t)\n\n## Save model on checkpoint\ncheckpoint = ModelCheckpoint(\n\tfilepath = \"../checkpoint/weights.h5\",\n\tmonitor = \"val_acc\",\n\tverbose = 1,\n\tsave_best_only = True,\n\t)\n\n## Early stop if no improvement\nearly_stop = EarlyStopping(\n\tmonitor = \"val_acc\",\n\tmin_delta = 0.05,\n\tpatience = 2,\n\trestore_best_weights = True\n\t)\n\n## List of callbacks for training\ncallbacks = [reduce_lr, checkpoint, early_stop]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 100\n# Train the model\nhistory = model.fit_generator(\n\tgenerator = train_generator,\n\tsteps_per_epoch = len(train_set)//batch_size,\n\tepochs = epochs,\n\tvalidation_data = val_generator,\n\tvalidation_steps = len(val_set)//batch_size\n\t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualization of training and loss loss and acc\n## Plot the loss\nfig, axes = plt.subplots(2, 1, figsize = (10, 8))\naxes[0].plot(history.history[\"loss\"], label = \"Training Loss\", color = \"b\", marker = \"x\")\naxes[0].plot(history.history[\"val_loss\"], label = \"Validation loss\", color = \"r\", marker = \"v\")\naxes[0].title.set_text(\"Loss chart\")\naxes[0].legend(loc = \"best\")\n\n## Plot the accuracy\naxes[1].plot(history.history[\"acc\"], label = \"Training Acc\", color = \"b\", marker = \"x\")\naxes[1].plot(history.history[\"val_acc\"], label = \"Validation Acc\", color = \"r\", marker = \"v\")\naxes[1].title.set_text(\"Accuracy chart\")\naxes[1].legend(loc = \"best\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Provide prediction on validation and test set\n## Output the probability\nval_pred = model.predict_generator(\n\tgenerator = val_generator,\n\tsteps = len(val_generator)\n\t)\n\ntest_pred = model.predict_generator(\n\tgenerator = test_generator,\n\tsteps = len(test_generator)\n\t)\n\n## Convert from probability to binary (0 or 1)\ncriteria = val_pred > 0.5\nval_pred[criteria] = 1\nval_pred[~criteria] = 0\n\ncriteria = test_pred > 0.5\ntest_pred[criteria] = 1\ntest_pred[~criteria] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the confusion matrix\n## Confusion matrix calculation\ncm_val = confusion_matrix(\n\ty_true = val_set[\"Ground_Truth\"].values.astype(int),\n\ty_pred = val_pred\n\t)\n\ncm_val = pd.DataFrame(\n\tcm_val, \n\tindex = [\"Normal\", \"Pneumonia\"],\n\tcolumns = [\"Normal\", \"Pneumonia\"])\n\ncm_test = confusion_matrix(\n\ty_true = test_set[\"Ground_Truth\"].values.astype(int),\n\ty_pred = test_pred\n\t)\n\ncm_test = pd.DataFrame(\n\tcm_test, \n\tindex = [\"Normal\", \"Pneumonia\"],\n\tcolumns = [\"Normal\", \"Pneumonia\"])\n\n## Visualization\nfig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (10, 4))\nsns.heatmap(data = cm_val, annot = True, ax = ax[0], fmt = \"d\")\nsns.heatmap(data = cm_test, annot = True, ax = ax[1], fmt = \"d\")\nax[0].title.set_text(\"Confusion matrix for validation set\")\nax[1].title.set_text(\"Confusion matrix for test set\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}