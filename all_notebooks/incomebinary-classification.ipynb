{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/income/train.csv')\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sex = {\"Male\": 1, \"Female\": 2 }\n\ndf['gender'] = df['gender'].map(sex)\n\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_features = ['age','fnlwgt','educational-num','gender','capital-gain','capital-loss','hours-per-week','income_>50K']\n\n# Identify Categorical features\ncat_features = ['workclass','education','marital-status', 'occupation', 'relationship', 'race', 'native']\nnumeric_features\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.heatmap(df[numeric_features].corr(),annot=True, fmt = \".2f\", cmap = \"coolwarm\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=df.drop(['income_>50K'],axis=1)\ny=df['income_>50K']\nprint(x.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split \nX_train, X_test, y_train, y_test = train_test_split( x, y, test_size = 0.3, random_state = 0) \nprint(X_train.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=X_train.drop(X_train.columns[[1,3,5,6,7,8,13]],axis=1)\nX_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier  \nclassifier1 = DecisionTreeClassifier(criterion='gini')  \nclassifier1.fit(X_train, y_train) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test=X_test.drop(X_test.columns[[1,3,5,6,7,8,13]],axis=1)\nX_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predtrain = classifier1.predict(X_train) \ny_predtrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predtrainlist=list(y_predtrain)\nTrainCountOfgt50K=y_predtrainlist.count(1)\nTrainCountOflt50K=y_predtrainlist.count(0)\nprint(TrainCountOfgt50K)\nprint(TrainCountOflt50K)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier1.predict(X_test)  \nprint(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predlist=list(y_pred)\nTestCountOfgt50K=y_predlist.count(1)\nTestCountOflt50K=y_predlist.count(0)\nprint(TestCountOfgt50K)\nprint(TestCountOflt50K)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix  \nprint(confusion_matrix(y_test, y_pred))  \nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score #importing accuracy_score function from sklearn.metrics package\nacc = accuracy_score(y_test,y_pred)\nprint(\"Accuracy for this model {} %\".format(acc*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classifier1.feature_importances_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n\nclassifier4 = KNeighborsClassifier(n_neighbors= 7)  \nclassifier4.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_4 = classifier4.predict(X_test)  \nprint(y_pred_4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_3 = accuracy_score(y_test,y_pred_4)\nprint(\"Accuracy  model {} %\".format(acc_3*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix  \nprint(confusion_matrix(y_test, y_pred_3))\nprint(classification_report(y_test, y_pred_3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrclf = RandomForestClassifier(n_estimators=100, max_depth=10,random_state=0)\n\nrclf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ry_pred = rclf.predict(X_test)  \nprint(ry_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix  \nprint(confusion_matrix(y_test, ry_pred))  \nprint(classification_report(y_test, ry_pred)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score #importing accuracy_score function from sklearn.metrics package\nacc = accuracy_score(y_test,ry_pred)\nprint(\"Accuracy for this model {} %\".format(acc*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=x.drop(x.columns[[1,3,5,6,7,8,13]],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\nclf = SVC()\nclf.fit(x, y) \nsvm_pred = clf.predict(X_test)  \nprint(svm_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix  \nprint(confusion_matrix(y_test, svm_pred))  \nprint(classification_report(y_test, svm_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score #importing accuracy_score function from sklearn.metrics package\nacc = accuracy_score(y_test,svm_pred)\nprint(\"Accuracy for this model {} %\".format(acc*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression()\nlr.fit(X_train,y_train)\n\nlr_pred = lr.predict(X_test)\n\nfrom sklearn.metrics import classification_report, confusion_matrix  \nprint(confusion_matrix(y_test, lr_pred))  \nprint(classification_report(y_test, lr_pred))\n\nfrom sklearn.metrics import accuracy_score #importing accuracy_score function from sklearn.metrics package\nacc = accuracy_score(y_test,lr_pred)\nprint(\"Accuracy for this model {} %\".format(acc*100))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}