{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 期末報告\n#### 組員: 廖品瑜、胡筆勝"},{"metadata":{},"cell_type":"markdown","source":"## 1.Dataset簡介\n#### 這個資料集收集了從2007年起澳洲各地天氣站的氣象資料，包含今天是否降雨、降雨量、蒸發量、日照、不同時段的風速與風向、不同時段的溫度以及明天是否降雨...等等不同資料。\n\n#### 網址:https://www.kaggle.com/jsphyg/weather-dataset-rattle-package"},{"metadata":{"trusted":true},"cell_type":"code","source":"# data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n# machine learning\nfrom sklearn import tree\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import metrics\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.問題定義\n#### 根據今天的各種氣象資料，訓練一個模型預測澳洲明天會不會下雨。"},{"metadata":{"trusted":true},"cell_type":"code","source":"#read in\npd_data = pd.read_csv('../input/weatherAUS.csv')\npd_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.資料前處理\n#### 3.1 首先將有缺失的列刪除，避免資料不足難以預測。\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop NAN\npd_data=pd_data.dropna(how='any')\nprint(pd_data.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n#### 3.2 我們認為日期、地點都不是影響明日是否會下雨的因素，因此將'Date','Location'刪除。\n#### 'WindGustDir', 'WindDir9am', 'WindDir3pm'為風向，分由於是以文字表示，難轉換成數字，因此在此先不考慮。\n#### 'RISK_MM'是氣象局給出的明天雨量估計，基本上就是我們要的結果，若將此行加入會overfitting，故刪除。\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop something column\ndrop_columns_list = ['WindGustDir', 'WindDir9am', 'WindDir3pm','Date','Location','RISK_MM']\npd_data = pd_data.drop(drop_columns_list, axis=1)\nprint(pd_data.shape)\npd_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#change yes/no to 1/0\npd_data['RainToday'].replace({'No':0,'Yes':1},inplace=True)\npd_data['RainTomorrow'].replace({'No':0,'Yes':1},inplace=True)\npd_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.3 RainToday原本由Yes/No組成，將其改為Yes=1,No=0\n####    將資料分成訓練Train與測試Test部分，Train占了55000筆，Test有1420筆，並把要得出的結果切出來。"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Task: Split the data into train and test\ntrain_y = pd_data['RainTomorrow'].head(55000)\ntest_y= pd_data['RainTomorrow'].tail(1420)\ntrain_x = pd_data.head(55000).drop(['RainTomorrow'], axis=1)\ntest_x= pd_data.tail(1420).drop(['RainTomorrow'], axis=1)\nprint(train_y.head())\nprint(train_x.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.模型\n\n### 4.1 Decision tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"import graphviz \ndtree=tree.DecisionTreeClassifier(max_depth=3)\ndtree=dtree.fit(train_x,train_y)\ndot_data = tree.export_graphviz(dtree, \n                filled=True, \n                feature_names=list(train_x),\n                class_names=['No rain','rain'],\n                special_characters=True)\ngraph = graphviz.Source(dot_data)  \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"graph","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#不同資料與結果的關聯性\ndtree.feature_importances_\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#把訓練好的模型套用到測試數據\npredict_y = dtree.predict(test_x)\npredict_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#計算訓練數據與測試數據的正確率\nfrom sklearn.metrics import accuracy_score\nacc_log = dtree.score(train_x, train_y)\nprint('training accuracy: %.5f' % acc_log)\nx=accuracy_score(test_y, predict_y)\nprint('test accuracy: %.5f' % x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test\n#測試不同的參數，發現並沒有太大改變\n#for i in range(400,601,5):    \n    \"\"\"dtree=tree.DecisionTreeClassifier(min_samples_split=1000,min_samples_leaf =570)\n    dtree=dtree.fit(train_x,train_y)\n    predict_y = dtree.predict(test_x)\n    x=accuracy_score(test_y, predict_y)\n    print('%d' % i,'test accuracy: %.5f'  %x)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#auc\nfpr, tpr, thresholds = metrics.roc_curve(test_y, predict_y, pos_label=1)\nprint('max_depth=3 auc: %.5f' % metrics.auc(fpr, tpr))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4.1.1 測試不同max_depth的正確率"},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_train_acc=[]   #訓練模型套用到訓練數據的正確率\ntree_test_acc=[]    #訓練模型套用到測試數據的正確率\ntree_depth=[]       #不同的max_depth\n\nfor i in range (2,20):\n    dtree=tree.DecisionTreeClassifier(max_depth=i)\n    dtree=dtree.fit(train_x,train_y)\n    acc_log = dtree.score(train_x, train_y)\n    print('max_depth=%d ' % i,'training accuracy: %.5f' % acc_log)\n    \n    predict_y = dtree.predict(test_x)    \n    X=accuracy_score(test_y, predict_y)\n    print('\\t\\ttest accuracy: %.5f' % X)\n    \n    tree_train_acc.append(acc_log)\n    tree_test_acc.append(X)\n    tree_depth.append(i)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(tree_depth,tree_train_acc,'b', label=\"training accuracy\")\nplt.plot(tree_depth,tree_test_acc,'r', label=\"test accuracy\")\nplt.ylabel('accuracy (%)')\nplt.xlabel('max depth ')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nbest_depth = tree_depth[tree_test_acc.index(max(tree_test_acc))]\nprint (\"max depth: \", best_depth)\nprint (\"best test accuracy: %.5f\"% max(tree_test_acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"從上圖可以看出，訓練數據的正確率隨著max_depth的增加而上升，但是測試數據的正確率不會。max_depth=7時，測試數據的正確率達到最高，約略為0.86479%。所以可以認定max_depth=7時的模型較好，max_depth>7的模型會有overfitting的現象。"},{"metadata":{"trusted":true},"cell_type":"code","source":"#dtree=tree.DecisionTreeClassifier(max_depth=7)\n#dtree=dtree.fit(train_x,train_y)\n#predict_y = dtree.predict(test_x)\n#X=accuracy_score(test_y, predict_y)\n#print('max_depth=7 test accuracy: %.5f' % X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#模型評價 auc\nfpr, tpr, thresholds = metrics.roc_curve(test_y, predict_y, pos_label=1)\nprint('max_depth=7 auc: %.5f' % metrics.auc(fpr, tpr))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"auc>0.5 表示模型預測比隨機猜測準確"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 交叉驗證 cross validation \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nscores = cross_val_score(dtree,train_x,train_y,cv=5,scoring='accuracy')\n\n# 計算平均值與標準差\nprint('average of Cross validation: %.5f'%scores.mean())\nprint('standard deviation of Cross validation: %.5f'%scores.std(ddof=1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4.2 Decision tree結果觀察\n1. 3層的決策樹可以有83.6%的正確率。\n2. 7層的決策樹的預測正確率最高，有86.5%。"},{"metadata":{},"cell_type":"markdown","source":"## 5.不同的模型\n### 5.1 logistic regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"# logistic regression\n\nlogreg = LogisticRegression()\nlogreg = logreg.fit(train_x, train_y)\npredict_y = logreg.predict(test_x)\nacc_log = logreg.score(train_x, train_y)\nprint('training accuracy: %.5f' % acc_log)\n\npredict_y =logreg.predict(test_x)\nX=accuracy_score(test_y, predict_y)\nprint('test accuracy: %.5f' % X)\n\n#auc\nfpr, tpr, thresholds = metrics.roc_curve(test_y, predict_y, pos_label=1)\nprint('auc: %.5f' % metrics.auc(fpr, tpr))\n\n#Cross validation\nscores = cross_val_score(logreg,train_x,train_y,cv=5,scoring='accuracy')\n# 計算Cross validation的平均值與標準差\nprint('average of Cross validation: %.5f'%scores.mean())\nprint('standard deviation of Cross validation: %.5f'%scores.std(ddof=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Support Vector Machines\n#運算時間太長\n'''\nsvc = SVC(gamma='auto',C=0.1,kernel=\"linear\", probability=True)\nsvc.fit(train_x, train_y)\npredict_y= svc.predict(test_x)\nacc_svc = svc.score(train_x, train_y)\nprint('training accuracy: %.5f' % acc_svc)\n\npredict_y =svc.predict(test_x)\nX=accuracy_score(test_y, predict_y)\nprint('test accuracy: %.5f' % X)'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n### 5.2 knn"},{"metadata":{"trusted":true},"cell_type":"code","source":"# knn\n\nknn = KNeighborsClassifier(n_neighbors = 10)\nknn.fit(train_x, train_y)\npredict_y = knn.predict(test_x)\nacc_knn = knn.score(train_x, train_y)\nprint('training accuracy: %.5f' % acc_knn)\n\npredict_y =knn.predict(test_x)\nX=accuracy_score(test_y, predict_y)\nprint('test accuracy: %.5f' % X)\n\n#auc\nfpr, tpr, thresholds = metrics.roc_curve(test_y, predict_y, pos_label=1)\nprint('auc: %.5f' % metrics.auc(fpr, tpr))\n\n#Cross validation\nscores = cross_val_score(knn,train_x,train_y,cv=5,scoring='accuracy')\nprint('average of Cross validation: %.5f'%scores.mean())\nprint('standard deviation of Cross validation: %.5f'%scores.std(ddof=1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.3 Gaussian Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(train_x, train_y)\npredict_y = gaussian.predict(test_x)\nacc_gaussian = gaussian.score(train_x, train_y)\nprint('training accuracy: %.5f' % acc_gaussian)\n\npredict_y =gaussian.predict(test_x)\nX=accuracy_score(test_y, predict_y)\nprint('test accuracy: %.5f' % X)\n\n#auc\nfpr, tpr, thresholds = metrics.roc_curve(test_y, predict_y, pos_label=1)\nprint('auc: %.5f' % metrics.auc(fpr, tpr))\n\n#Cross validation\nscores = cross_val_score(gaussian,train_x,train_y,cv=5,scoring='accuracy')\nprint('average of Cross validation: %.5f'%scores.mean())\nprint('standard deviation of Cross validation: %.5f'%scores.std(ddof=1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6.後續工作\n1. 使用Random forest \n2. 將風向的資料、且將日期轉換成季節，重新加入訓練模型中，確認是否有更好的結果。\n3. 可以將Location重新加入訓練模型，預測各地點明天是否降雨。\n\n(註：「後續工作」是口頭報告時還未完成的工作)\n"},{"metadata":{},"cell_type":"markdown","source":"### 6.1 Random Forest"},{"metadata":{},"cell_type":"markdown","source":"#### 6.1.1 計算n_estimators=1000的情況"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrdf = RandomForestClassifier(bootstrap=True, n_estimators=1000, max_depth=7)\nrdf.fit(train_x, train_y)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_log = rdf.score(train_x, train_y)\nprint('training accuracy: %.5f' % acc_log)\n\npredict_y =rdf.predict(test_x)\nX=accuracy_score(test_y, predict_y)\nprint('test accuracy: %.5f' % X)\n#auc\nfpr, tpr, thresholds = metrics.roc_curve(test_y, predict_y, pos_label=1)\nprint('auc: %.5f' % metrics.auc(fpr, tpr))\n\n#Cross validation\n#運算時間太長\n'''scores = cross_val_score(rdf,train_x,train_y,cv=5,scoring='accuracy')\nprint(scores)\nprint('Cross validation: %.5f'%scores.mean())'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 6.1.2 決定最佳的n_estimators"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Parameters:決定最佳的n_estimators\n#目前只算到n_estimators=256，太大需要時間過長\n\nfrom sklearn import model_selection, metrics\n\ndef scorer(model, X,  train_y):\n    preds = model.predict(X)\n    return metrics.accuracy_score( train_y, preds)\n\nn_estimators = [1,2,4,8,16,32,64,128, 256]  ## try different n_estimators\ncv_results = []\n\nfor estimator in n_estimators:\n    rf = RandomForestClassifier(n_estimators=estimator)\n    acc = model_selection.cross_val_score(rf, train_x,  train_y, cv=5, scoring=scorer)\n    cv_results.append(acc.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"line1= plt.plot(n_estimators, cv_results, 'b', label=\"cross validated accuracy\")\nplt.ylabel('accuracy')\nplt.xlabel('n_estimators')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"從目前的結果可知，在n_estimators=256以內，正確率有上升的趨勢，而且n_estimators越大，上升趨勢越緩。但是因為計算時間的問題，n_estimators>256的情況暫時不計算。"},{"metadata":{"trusted":true},"cell_type":"code","source":"best_n_estimators = n_estimators[cv_results.index(max(cv_results))]\nprint (\"best_n_estimators: \", best_n_estimators)\nprint (\"best accuracy: \", max(cv_results))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 6.1.3 random forest結果觀察\n和使用Decision tree相比，random forest沒有提高正確率。"},{"metadata":{},"cell_type":"markdown","source":"### 6.2 將地點考慮進去\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd_data = pd.read_csv('../input/weatherAUS.csv')\npd_data=pd_data.dropna(how='any')\nprint(pd_data.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_columns_list = ['WindGustDir', 'WindDir9am', 'WindDir3pm','Date','Sunshine','RISK_MM']\npd_data = pd_data.drop(drop_columns_list, axis=1)\nprint(pd_data.shape)\n\npd_data['RainToday'].replace({'No':0,'Yes':1},inplace=True)\npd_data['RainTomorrow'].replace({'No':0,'Yes':1},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"groupbyLocation=pd_data.groupby('Location')\nprint(groupbyLocation.size().sort_values(ascending=False))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 6.2.1 把地點轉為數字"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd_data['Location'] = pd_data['Location'].map( {'Darwin':0,'Perth':1,'Brisbane':2,'MelbourneAirport':3,\n                                                'PerthAirport':4,'SydneyAirport':5,'Watsonia':6,'Mildura':7,\n                                                'MountGambier':8,'NorfolkIsland':9,'Cairns':10,'Townsville':11,\n                                                'WaggaWagga':12,'AliceSprings':13,'Nuriootpa':14,'Hobart':15,\n                                                'Moree':16,'Melbourne':17,'Portland':18,'Woomera':19,\n                                                'Sydney':20,'Sale':21,'CoffsHarbour':22,'Williamtown':23,\n                                                'Canberra':24,'Cobar':25} ).astype(int)\ntrain_y=pd_data['RainTomorrow']\ntrain_x=pd_data.drop(['RainTomorrow'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtree=tree.DecisionTreeClassifier(max_depth=7)\ndtree=dtree.fit(train_x,train_y)\nscores = cross_val_score(dtree,train_x,train_y,cv=5,scoring='accuracy')\nprint(scores)\nprint('average of Cross validation: %.5f'%scores.mean())\nprint('standard deviation of Cross validation: %.5f'%scores.std(ddof=1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 6.2.2 Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Logistic Regression\nlogreg = LogisticRegression()\nlogreg.fit(train_x, train_y)\n\n#Cross validation\nscores = cross_val_score(dtree,train_x,train_y,cv=5,scoring='accuracy')\nprint('Cross validation: %.5f'%scores.mean())\nprint('standard deviation of Cross validation: %.5f'%scores.std(ddof=1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 6.2.3 knn"},{"metadata":{"trusted":true},"cell_type":"code","source":"#knn\nknn = KNeighborsClassifier(n_neighbors = 10)\nknn.fit(train_x, train_y)\n\n#Cross validation\nscores = cross_val_score(knn,train_x,train_y,cv=5,scoring='accuracy')\nprint('Cross validation: %.5f'%scores.mean())\nprint('standard deviation of Cross validation: %.5f'%scores.std(ddof=1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 6.2.4 Gaussian Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Gaussian Naive Bayes\ngaussian = GaussianNB()\ngaussian.fit(train_x, train_y)\n#Cross validation\nscores = cross_val_score(gaussian,train_x,train_y,cv=5,scoring='accuracy')\nprint('Cross validation: %.5f'%scores.mean())\nprint('standard deviation of Cross validation: %.5f'%scores.std(ddof=1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 6.2.5 將地點考慮進去的結果觀察\n正確率並沒有提升。"},{"metadata":{},"cell_type":"markdown","source":"## 7.小結\n\n1.我們嘗試使用各種模型預測，預測準確度都能達到80%以上。\n\n2.各個模型的auc都大於0.7，有些模型可達0.8以上，表示使用這些模型預測「明天是否降雨的正確率」都比亂猜的結果來得好。"},{"metadata":{},"cell_type":"markdown","source":"## 8.心得\n#### 廖品瑜:\n#### 感覺課程時間有點少，希望可以用更多時間在帶程式的部分，雖然原理很重要，但講解過大概後應該可以透過自學來完成；而程式的部分就算不太懂原理也可以上手，但需要更多次練習才能找出問題。這次學到的東西很有趣，電腦可以直接引用函式庫真的太方便了，幾乎不需要了解原理就可以使用。也學到Git跟Kaggle還有Jupyter notebook的用法，以後會更深入學習，希望可以在原本的科系上運用。\n#### 胡筆勝:\n#### 課程內容很有趣也很實用，之前完全沒有接觸過相關的領域，但是在一個禮拜內要了解機器學習以及python的課程內容，我覺得有些許困難。繳交作業時間延後之後，我可以有更多時間時作與思考課程內容。"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}