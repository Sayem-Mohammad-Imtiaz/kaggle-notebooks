{"cells":[{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Práctica 1: Análisis exploratorio de datos, preprocesamiento y validación de modelos de clasificación\n### Minería de datos: Curso 2020-2021\n* José Gabriel Ruiz Gomez\n* Francisco Javier Vicente Martínez\n\nBase de datos Pima"},{"metadata":{},"cell_type":"markdown","source":"# 1. Preliminares"},{"metadata":{},"cell_type":"markdown","source":"Cargamos las librerias necesarias"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Third party\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.tree import DecisionTreeClassifier\n\nimport numpy as np\nimport seaborn as sns\nsns.set()\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\n\n# Local application\nimport miner_a_de_datos_an_lisis_exploratorio_utilidad as utils","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fijamos la semilla para que el experimento sea reproducible:"},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 27912","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Acceso y almacenamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"La base de datos Pima Indians Diabetes contiene 768 entradas que corresponden a mujeres de descendencia india de al menos 21 años de edad. La base de datos las clasifica segun tengan diabetes o no con la variable de clase:\n\n* `Outcome`\n\nÉsta puede tomar el valor 0 o 1. Las variables predictoras para este problema son:\n\n* `Pregnancies`: Representa el numero de veces que quedo embarazada\n* `Glucose`: Concentracion de glucose en plasma a 2 horas de un examen de tolerancia de glucosa\n* `BloodPresure`: Presion arterial diastólica (mm Hg)\n* `SkinThickness`: Grosor de un pliegue de piel del triceps (mm)\n* `Insulin`: Serum de insulina de 2 horas (mu U/ml)\n* `BMI`: Indice de masa corporal\n* `DiabetesPedigreeFunction`: Indice obtenido a partir de familiares que padecen diabetes\n* `Age`: Edad "},{"metadata":{},"cell_type":"markdown","source":"Cargamos los datos de `Pima`: "},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath = \"../input/pima-indians-diabetes-database/diabetes.csv\"\n\nindex = False\ntarget = \"Outcome\"\n\ndata = utils.load_data(filepath, index, target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Se ha especificado la variable clase pero en esta base de datos no hay ninguna variable que sirva de identificador."},{"metadata":{},"cell_type":"markdown","source":"Comprobamos que se han cargado bien los datos, la funcion `head` puede que nos de una muestra sesgada pero mi objetivo es ver simplemente si el objeto data se ha creado correctamente:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dividimos los datos en variables predictoras y resultado."},{"metadata":{"trusted":true},"cell_type":"code","source":"(X, y) = utils.divide_dataset(data, target=\"Outcome\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Comprobamos que se han divido correctamente."},{"metadata":{"trusted":true},"cell_type":"code","source":"X.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para evitar el sobreajuste a los datos vamos a dividirlos en conjunto de entrenamiento y de prueba en un ratio de 70% entrenamiento y 30% de prueba:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = 0.7\n\n(X_train, X_test, y_train, y_test) = train_test_split(X, y,\n                                                      shuffle=True,\n                                                      stratify=y,\n                                                      random_state=seed,\n                                                      train_size=train_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"El conjunto de datos de pima no parece seguir ningun tipo de orden pero he decidido aleatorizarlo (`shuffle=True`) de todas formas."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Volvemos a juntar las variables predictoras con las objetivo para el analisis exploratorio:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = utils.join_dataset(X_train, y_train)\ndata_test = utils.join_dataset(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Análisis exploratorio de los datos"},{"metadata":{},"cell_type":"markdown","source":"### Descripcion del conjunto de datos"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nuestro conjunto de entrenamiento se compone de 537 casos con 9 variables, 8 predictoras 1 objetivo."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.info(memory_usage=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Todas las variables son numericas, excepto la variable objetivo.\nTodas las variables son continuas, aunque el numero de embarazos podriamos considerarla discreta ya que por su naturaleza no va a tener muchos valores distintos."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.cat.categories","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nuestra variable clase tiene dos estados: 0 representa que no tiene diabetes y 1 representa que tiene diabetes."},{"metadata":{},"cell_type":"markdown","source":"### Visualizacion de las variables"},{"metadata":{},"cell_type":"markdown","source":"Ahora que ya conocemos el conjunto de datos debemos analizar la distribucion de las variables. En este caso vamos a analizar las variables mediante metodos univariados, en este caso concreto histogramas, ya que todas nuestras variables predictoras son numericas y un diagrama de barras para nuestra variable objetivo."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_histogram(data_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Todos los atributos parecen distribuciones normales, en el caso de `pregnancies`, `insulin`, `diabetesPedigreeFunction` y `age` son distribuciones asimetricas.\n\nLos atributos `pregnancies`, `glucose`, `bloodPresure`, `BMI`, `DiabetesPedigreeFunction` y `Age` contienen algunos outliers.\n\nVariables como `glucose`, `bloodPresure` y `BMI` tienen unos cuantos valores perdidos, `Skin thickness` tiene muchos valores perdidos.\n\nLos valores perdidos estan representados por un 0, el caso de la variable `Insulin` es un tanto problematico porque los pacientes con diabetes de tipo 1 no producen nada de insulina, esto hace complicado distinguir valores perdidos de valores de insulina 0 reales, con lo cual es posible que no podamos usar esta variable, pero para esta practica voy a tratarlos todos como valores perdidos."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_barplot(data_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"La muestra no esta balanceada hay mas casos en los que `Outcome` es 0."},{"metadata":{},"cell_type":"markdown","source":"A continuacion vamos a hacer un analisis multivariado con una matriz de gráficos. Para ver relaciones entre variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"sp = utils.plot_pairplot(data_train, target=\"Outcome\")\nsp.update_layout(width=1400, height=1400, hovermode='closest')\nsp.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A pesar de no poder verse bien hay un par de variables que tienen cierto poder discriminador combinadas con el resto: `Glucose` y `Pregnancies`. \n\nComo se puede ver, los valores para las dos posibilidades de la variable clase estan muy entremezcados, al no haber una distincion clara entre ambas podemos asumir que el modelo no va a salir demasiado bueno.\n\nOtras variables como `DiabetesPedigreeFunction` o `Insulin` seguramente sea mejor utilizarlas de forma independiente."},{"metadata":{},"cell_type":"markdown","source":"Este grafico al tener tantas variables y estar todos los casos tan apelotonados es poco util, para poder cuantificar la relacion entre las variables voy a utilizar un heatmap de coorelacion: "},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.px.imshow(data_train.corr())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver que `Age` y `Pregnancies` tienen bastante correlacion, ademas tambien `BMI` esta coorelacionado con `skinThickness`, `Glucose` y `BloodPresure`, lo cual es logico.\n\nPor otra parte tambien se puede observar una coorelacion positiva entre `skinThicness` e `Insulin` pero esto puede que se deba a la gran cantidad de valores perdidos (0) que tienen ambas."},{"metadata":{},"cell_type":"markdown","source":"# 4. Preprocesamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"Para poder obtener un modelo que tenga sentido de nuestros datos primero tenemos que abordar dos problemas: la discretizacion y los valores perdidos."},{"metadata":{},"cell_type":"markdown","source":"### Valores perdidos"},{"metadata":{},"cell_type":"markdown","source":"Tenemos el problema de que no podemos simplemente imputar los valores perdidos dentro del pipeline porque los valores perdidos se estan representando con un 0 y hay variables en las que 0 es un valor válido, sin ir mas lejos nuestra variable clase tiene 0 o 1, si sustituimos todos los 0 nos cargamoe el problema y todos los modelos van a estar mal, por lo cual no podemos utilizar por si solo un `SimpleImputer`."},{"metadata":{},"cell_type":"markdown","source":"En lugar de esto lo que vamos a utilizar es otro `estimator` que, en teoria, nos va a permitir aplicar nuestro `simpleImputer` tan solo a determinadas columnas, se trata de un `ColumnTransformer`."},{"metadata":{"trusted":true},"cell_type":"code","source":"simpleImputer = SimpleImputer(missing_values=0, strategy='most_frequent')\ncols = ['Glucose','BloodPressure','SkinThickness','Insulin','BMI']\n\nimputer = ColumnTransformer(\n    [(\"ImpMissing\", simpleImputer, cols)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Hemos utilizado como estrategia para el `SimpleImputer` la moda porque en los datos hay outliers y la media se ve muy afectada por estos, la mediana se ve menos afectada, pero como hay valores tan extremos ceemos que es mejor utilizar la moda en su lugar. La moda, aunque menos, tambien se ve algo afectada por valores extremos.\n\nTambien podriamos haber usado correlacion con otras variables, pero no se ve una correlacion tan fuerte como para que valga la pena usar este método."},{"metadata":{},"cell_type":"markdown","source":"### Discretizacion"},{"metadata":{},"cell_type":"markdown","source":"Vista la distribucion de outcome y la naturaleza de los datos tiene mas sentido discretizar con la estratiegia de las k-medias en 2 intervalos."},{"metadata":{"trusted":true},"cell_type":"code","source":"discretizer = KBinsDiscretizer(n_bins=2, strategy=\"kmeans\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Algoritmos de clasificación"},{"metadata":{},"cell_type":"markdown","source":"Creamos el pipeline para todos estimadores, primero siempre poniendo el transformador que imputa los valores perdidos y luego, en su caso, el transformador para la discretización. "},{"metadata":{},"cell_type":"markdown","source":"### Algoritmo Zero-R"},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_r_model = make_pipeline(imputer, DummyClassifier(strategy=\"most_frequent\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Algoritmo CART"},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_model = make_pipeline(imputer, DecisionTreeClassifier(random_state=seed))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discretize_tree_model = make_pipeline(imputer, discretizer, DecisionTreeClassifier(random_state=seed))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En este caso no he modificado los hiperparametros de los modelos porque el `hiperparameter tunning` no forma parte de esta practica, asi que estan por defecto"},{"metadata":{},"cell_type":"markdown","source":"# 6. Evaluacion de modelos"},{"metadata":{"trusted":true},"cell_type":"code","source":"Algoritmos=[]\nMetricas=[]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Zero-R"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=utils.evaluate(zero_r_model,\n               X_train, X_test,\n               y_train, y_test)\nAlgoritmos.append(\"ZeroR\\t\")\nMetricas.append(utils.confMatMetricas(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No hay mucho que decir del Zero-R, el porcentaje de acierto va a ser siempre exactamente igual a la proporcion de casos de la clase mayoritaria, se pueden utilizar los resultados del Zero-R como baseline, el modelo que se acierte mas o menos lo mismo o menos que un Zero-R no vale la pena."},{"metadata":{},"cell_type":"markdown","source":"### Arbol de clasificación"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=utils.evaluate(tree_model,\n               X_train, X_test,\n               y_train, y_test)\nAlgoritmos.append(\"ArbolClas\")\nMetricas.append(utils.confMatMetricas(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"El arbol de clasificacion sin discretizar no lo ha hecho mucho mejor que el Zero-R, pero por lo menos clasifica algunos \"1\" correctamente"},{"metadata":{},"cell_type":"markdown","source":"### Arbol de clasificación discretizado"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=utils.evaluate(discretize_tree_model,\n               X_train, X_test,\n               y_train, y_test)\nAlgoritmos.append(\"ArbolClasDiscr\")\nMetricas.append(utils.confMatMetricas(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Discretizando hemos conseguido mejorar la precision."},{"metadata":{},"cell_type":"markdown","source":"Respecto a los clasificadores obtenidos, son todos bastante malos, pero en base a los resultados discretizando hemos obtenido bastante mas precision aunque a costa de la tasa de verdaderos positivos, este clasificador podria valer para etiquetar correctamente verdaderos negativos, pero eso lo hace mejor el Zero-R.\n\nDe los 3 clasificadores el mejor para clasificar verdaderos positivos es el arbol sin discretizar, aunque tenga una precision parecida al Zero-R y bastantes falsos positivos, para este tipo de problema, desde el punto de vista de la salud creo que seria mejor etiquetar mal a los negativos que a los positivos."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.f1Tabla(Algoritmos, Metricas)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como se puede ver en la tabla anterior el arbol de clasificacion discretizado tiene mejor precision, pero, tal y como habiamos dicho antes, en nuestro caso el árbol de clasificacion sin discretizar es mejor para nuestro caso ya que tiene bastante mejor recall y en un problema como este en el que se estan prediciendo enfermedades preferimos clasificar bien antes a los positivos que a los negativos. Ademas la F1 score da mejor resultado para el arbol sin discretizar también.\n\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}