{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nimport plotly.express as px\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/students-performance-in-exams/StudentsPerformance.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['average'] = (df['math score']+df['reading score']+df['writing score'])/3\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(dpi=100)\nplt.title('Correlation Analysis')\nsns.heatmap(df.corr(),annot=True,lw=1,linecolor='white',cmap='viridis')\nplt.xticks(rotation=60)\nplt.yticks(rotation = 60)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['average'],hist_kws=dict(edgecolor=\"k\", linewidth=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['math score'],hist_kws=dict(edgecolor=\"k\", linewidth=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['reading score'],hist_kws=dict(edgecolor=\"k\", linewidth=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df['writing score'],hist_kws=dict(edgecolor=\"k\", linewidth=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['parental level of education'].value_counts().head(30).plot(kind='barh', figsize=(10,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['race/ethnicity'].value_counts().head(30).plot(kind='barh', figsize=(10,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['race/ethnicity','gender']).size().unstack().plot(kind='bar',stacked=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new = df[['math score','reading score','writing score']].copy()\n\nmath_df = new['math score'].sum()\nreading_df = new['reading score'].sum()\nwriting_df = new['writing score'].sum()\n\ntotal = [math_df,reading_df,writing_df]\ncolumns = ['Math','Reading','Writing']\n\nfig1, ax1 = plt.subplots()\nax1.pie(total, labels=columns, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['reading score','gender']).size().unstack().plot(kind='bar',stacked=True,figsize=(15,15))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['writing score','gender']).size().unstack().plot(kind='bar',stacked=True,figsize=(15,15))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['math score','gender']).size().unstack().plot(kind='bar',stacked=True,figsize=(15,15))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby([\"test preparation course\"]).mean().plot.bar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby([\"parental level of education\"]).mean().plot.bar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby([\"race/ethnicity\"]).mean().plot.bar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bplot = sns.boxplot( y = 'average' ,x ='parental level of education'  ,data = df)\n_ = plt.setp(bplot.get_xticklabels(), rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=\"parental level of education\", y=\"average\", hue=\"gender\", data=df, palette=\"Set1\")\n#sns.plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(columns=['gender'],axis=1)\nY = df['gender']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing \n   \nlabel_encoder = preprocessing.LabelEncoder() \nY = label_encoder.fit_transform(Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.get_dummies(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# FEATURE SELECTION\n\nplt.rcParams['figure.figsize']=15,6 \nsns.set_style(\"darkgrid\")\n\nfrom sklearn.ensemble import ExtraTreesClassifier\nimport matplotlib.pyplot as plt\nmodel = ExtraTreesClassifier()\nmodel.fit(X,Y)\nprint(model.feature_importances_) \nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(12).plot(kind='barh')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**LOGISTIC REGRESSION**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel = LogisticRegression()\n\n# fit the model with the training data\nmodel.fit(X_train,Y_train)\n\n# coefficeints of the trained model\nprint('Coefficient of model :', model.coef_)\nprint('                             ')\n\n# intercept of the model\nprint('Intercept of model',model.intercept_)\nprint('                             ')\n# predict the target on the test dataset\npredict_test = model.predict(X_test)\nprint('Target on test data',predict_test) \nprint('                             ')\n# Accuracy Score on test dataset\naccuracy_test = accuracy_score(Y_test,predict_test)\nprint('accuracy_score on test dataset : ', accuracy_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DECISION TREE**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = DecisionTreeClassifier(max_depth=6)\n\n# fit the model with the training data\nmodel.fit(X_train,Y_train)\n\n# depth of the decision tree\nprint('Depth of the Decision Tree :', model.get_depth())\nprint('                             ')\n# predict the target on the test dataset\npredict_test = model.predict(X_test)\nprint('Target on test data',predict_test) \nprint('                             ')\n# Accuracy Score on test dataset\naccuracy_test = accuracy_score(Y_test,predict_test)\nprint('accuracy_score on test dataset : ', accuracy_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**RANDOM FOREST**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestClassifier(max_depth=8)\n\n# fit the model with the training data\nmodel.fit(X_train,Y_train)\n\n# predict the target on the test dataset\npredict_test = model.predict(X_test)\nprint('Target on test data',predict_test) \nprint('                             ')\n\n# Accuracy Score on test dataset\naccuracy_test = accuracy_score(Y_test,predict_test)\nprint('accuracy_score on test dataset : ', accuracy_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**GARDIENT BOOSTING**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = GradientBoostingClassifier(n_estimators=100,max_depth=3)\n\n# fit the model with the training data\nmodel.fit(X_train,Y_train)\n\n# predict the target on the test dataset\npredict_test = model.predict(X_test)\nprint('\\nTarget on test data',predict_test) \n\n# Accuracy Score on test dataset\nprint('                                  ')\naccuracy_test = accuracy_score(Y_test,predict_test)\nprint('\\naccuracy_score on test dataset : ', accuracy_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**XGBOOST**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = XGBClassifier(max_depth=5)\n\n# fit the model with the training data\nmodel.fit(X_train,Y_train)\n\n# predict the target on the test dataset\npredict_test = model.predict(X_test)\nprint('\\nTarget on test data',predict_test) \n\n# Accuracy Score on test dataset\naccuracy_test = accuracy_score(Y_test,predict_test)\nprint('                                          ')\nprint('\\naccuracy_score on test dataset : ', accuracy_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SVM**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = SVC(kernel='linear')\n\n# fit the model with the training data\nmodel.fit(X_train,Y_train)\n\n# predict the target on the test dataset\npredict_test = model.predict(X_test)\nprint('Target on test data',predict_test) \n\n# Accuracy Score on test dataset\naccuracy_test = accuracy_score(Y_test,predict_test)\nprint('                            ')\nprint('accuracy_score on test dataset : ', accuracy_test)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}