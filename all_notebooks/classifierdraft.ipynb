{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport os\n\n\nfrom PIL import Image, ImageFilter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import os\n# print(os.listdir(\"../input/celeba-dataset/img_align_celeba/img_align_celeba/\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"##img = Image.open('/input/CelebFaces Attributes (CelebA) Dataset/celeba-dataset/images/img_align_celeba/000391.jpg').convert('L')\nimg = Image.open('/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba/000391.jpg')\n\n\nimgplot = plt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd /kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba/\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_data_1 = pd.read_csv('/kaggle/input/celeba-dataset/list_attr_celeba.csv')\ninput_data_1.head(5)\n### contains all the features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_data_1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_data_2 = pd.read_csv('list_bbox_celeba.csv')\ninput_data_2.head(5)\n### contains the bounding box details","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_data_2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_data_3 = pd.read_csv('list_eval_partition.csv')\ninput_data_3.head(5)\n### Shows the recommended partition 0 - training, 1 - valdation, 2 -","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_data_3.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_data_4 = pd.read_csv('list_landmarks_align_celeba.csv')\ninput_data_4.head(5)\n### face details","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_data_4.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pre-processing\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_data_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_attributes = input_data_1\n#df_attributes.set_index('image_id', inplace = True)\ndf_attributes.replace(to_replace=-1, value=0, inplace=True)\ndf_attributes.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## checking the distribution of male and female\n\nplt.title(\"Male-Female distribution\")\nsns.countplot(y='Male', data=df_attributes, color='b')\nplt.show()\n\n##females are more -- imbalanced dataset\n\n#Male : 1, Female: 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting the data into training, validation and test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_data_3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_partition = input_data_3\n##df_partition.set_index(\"image_id\", inplace=True)\ndf_partition['partition'].value_counts().sort_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Joining male attribute with partition dataset\n\ndf_part_attr = df_partition.join(df_attributes['Male'], how='inner')\ndf_part_attr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Data Augmentation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Generating training,test and validation data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_df(df,df_type):\n    if(df_type is 'train'):\n        df_new = df[(df['partition']==0)]\n    elif(df_type is 'val'):\n        df_new = df[(df['partition']==1)]\n    else:\n        df_new = df[(df['partition']==2)]\n    \n    return df_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = generate_df(df_part_attr,'train')\ndf_val = generate_df(df_part_attr,'val')\ndf_test = generate_df(df_part_attr,'test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.head(5))\nprint()\nprint(df_train.shape)\nprint('--------------------------------------')\nprint(df_val.head(5))\nprint()\nprint(df_val.shape)\nprint('--------------------------------------')\nprint(df_test.head(5))\nprint()\nprint(df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Converting the Image to MNIST format","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1. First image in converted into mode 'L' i.e black and white\n# 2. Image is resized \n# 3. Image is sharpened (smooth pixels)\n# 4.Image is pasted on canvas of size 28x28\n# 5.Convert the image to array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## converting image to black-n-white\ndef convertImagetoMNISTstyle(path_to_image):\n    im = Image.open(path_to_image).convert('L')\n    width = float(im.size[0])\n    height = float(im.size[1])\n    newImage = Image.new('L', (28,28), (255)) #creates white canvas of 28x28 pixels\n  \n    if width > height:\n        nheight = int(round(20.0/width * height), 0)\n        if (nheight == 0):\n            nheight = 1\n      \n        img = im.resize((20,nheight), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)\n        wtop = int(round(((28 - nheight)/2),0))\n        newImage.paste(img, (4,wtop))\n    \n    else:\n        nwidth = int(round((20.0/height*width),0))\n        if (nwidth == 0):\n            nwidth = 1\n      \n        img = im.resize((nwidth,20), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)\n        wleft = int(round(((28 - nwidth)/2),0))\n        newImage.paste(img, (wleft,4))\n\n    tv = list(newImage.getdata())\n  \n    tva = [(255 - x) * 1.0 / 255.0 for x in tv]\n  \n    tva_new = np.asarray(tva).reshape(28,28)\n  ##print(tva)\n    return tva_new\n  \n  #plt.show()\n  #return np_im","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%pwd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### test code\n\nnew_image = convertImagetoMNISTstyle('/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba/000391.jpg')\nnew_image_arr = np.asarray(new_image).reshape(28,28)\nnew_image_arr = new_image_arr.reshape(28,28)\nnew_image_arr.shape\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# taking all samples\ndf_train_new = df_train\ndf_test_new = df_test\ndf_val_new = df_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_val_new.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nlist_train_images = []\nfor x in df_train_new['image_id']:\n    print(x)\n    path = '/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba/'+x\n    list_train_images.append(convertImagetoMNISTstyle(path))\n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Image.open(path_to_image).convert?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Image.open(path_to_image).convert","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}