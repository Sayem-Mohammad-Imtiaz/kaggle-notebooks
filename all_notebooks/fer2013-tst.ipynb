{"cells":[{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"import torch\n\n'''\nimport torch.optim as optim\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom torch.utils import data\nfrom torch import nn\nimport time\nfrom IPython import display\nfrom torch.nn import functional as F\n\n# load and preprocess data\nsource = pd.read_csv(\"../input/facial-expression-recognitionferchallenge/fer2013/fer2013/fer2013.csv\")\nprocessed_data = []\nfor i in range(0, len(source)):\n    item = source.iloc[i, 1]\n    temp1 = [float(j) for j in item.split(\" \")]\n    if not any(temp1):\n        continue\n    temp2 = []\n    for j in range(0, 48):\n        temp2.append(temp1[48*j: 48*j+48])\n    temp3 = [torch.tensor([temp2]), source.iloc[i, 0]]\n    processed_data.append(temp3)\n\nlr, num_epochs, batch_size = 0.001, 100, 64\ntrain_iter = data.DataLoader(processed_data[:int(len(processed_data) * 0.9)], batch_size, shuffle=True)\ntest_iter = data.DataLoader(processed_data[int(len(processed_data) * 0.9):], batch_size, shuffle=False)\n\ntransfer_pattern = [\"angry\", \"disgust\", \"fear\", \"happy\", \"sad\", \"surprise\", \"neutral\"]\n\n\ndef plot(series):\n    plt.title(transfer_pattern[processed_data[series][1]])\n    plt.imshow(processed_data[series][0], cmap=\"gray\")\n    plt.show()\n\n# train\nargmax = lambda x, *args, **kwargs: x.argmax(*args, **kwargs)\nastype = lambda x, *args, **kwargs: x.type(*args, **kwargs)\nreduce_sum = lambda x, *args, **kwargs: x.sum(*args, **kwargs)\nsize = lambda x, *args, **kwargs: x.numel(*args, **kwargs)\n\n\nclass Timer:\n    def __init__(self):\n        self.times = []\n        self.start()\n\n    def start(self):\n        self.tik = time.time()\n\n    def stop(self):\n        self.times.append(time.time() - self.tik)\n        return self.times[-1]\n\n    def sum(self):\n        return sum(self.times)\n\n\nclass Accumulator:\n    def __init__(self, n):\n        self.data = [0.0] * n\n\n    def add(self, *args):\n        self.data = [a + float(b) for a, b in zip(self.data, args)]\n\n    def __getitem__(self, idx):\n        return self.data[idx]\n\n\ndef set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n    axes.set_xlabel(xlabel)\n    axes.set_ylabel(ylabel)\n    axes.set_xscale(xscale)\n    axes.set_yscale(yscale)\n    axes.set_xlim(xlim)\n    axes.set_ylim(ylim)\n    if legend:\n        axes.legend(legend)\n    axes.grid()\n\n\nclass Animator:\n    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n                 ylim=None, xscale='linear', yscale='linear',\n                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n                 figsize=(3.5, 2.5)):\n        if legend is None:\n            legend = []\n        display.set_matplotlib_formats('svg')\n        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n        if nrows * ncols == 1:\n            self.axes = [self.axes, ]\n        self.config_axes = lambda: set_axes(\n            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n        self.X, self.Y, self.fmts = None, None, fmts\n\n    def add(self, x, y):\n        if not hasattr(y, \"__len__\"):\n            y = [y]\n        n = len(y)\n        if not hasattr(x, \"__len__\"):\n            x = [x] * n\n        if not self.X:\n            self.X = [[] for _ in range(n)]\n        if not self.Y:\n            self.Y = [[] for _ in range(n)]\n        for i, (a, b) in enumerate(zip(x, y)):\n            if a is not None and b is not None:\n                self.X[i].append(a)\n                self.Y[i].append(b)\n        self.axes[0].cla()\n        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n            self.axes[0].plot(x, y, fmt)\n        self.config_axes()\n        display.clear_output(wait=True)\n\n\ndef try_gpu(i=0):\n    if torch.cuda.device_count() >= i + 1:\n        return torch.device(f'cuda:{i}')\n    return torch.device('cpu')\n\n\ndef accuracy(y_hat, y):\n    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n        y_hat = argmax(y_hat, axis=1)\n    cmp = astype(y_hat, y.dtype) == y\n    return float(reduce_sum(astype(cmp, y.dtype)))\n\n\ndef evaluate_accuracy_gpu(net, data_iter, device=None):\n    net.eval()\n    if not device:\n        device = next(iter(net.parameters())).device\n    metric = Accumulator(2)\n    for X, y in data_iter:\n        X, y = X.to(device), y.to(device)\n        metric.add(accuracy(net(X), y), size(y))\n    return metric[0] / metric[1]\n\n'''\nclass SAM(torch.optim.Optimizer):\n    def __init__(self, params, base_optimizer, rho=0.05, **kwargs):\n        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n\n        defaults = dict(rho=rho, **kwargs)\n        super(SAM, self).__init__(params, defaults)\n\n        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n        self.param_groups = self.base_optimizer.param_groups\n\n    @torch.no_grad()\n    def first_step(self, zero_grad=False):\n        grad_norm = self._grad_norm()\n        for group in self.param_groups:\n            scale = group[\"rho\"] / (grad_norm + 1e-12)\n\n            for p in group[\"params\"]:\n                if p.grad is None: continue\n                e_w = p.grad * scale\n                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n                self.state[p][\"e_w\"] = e_w\n\n        if zero_grad: self.zero_grad()\n\n    @torch.no_grad()\n    def second_step(self, zero_grad=False):\n        for group in self.param_groups:\n            for p in group[\"params\"]:\n                if p.grad is None: continue\n                p.sub_(self.state[p][\"e_w\"])  # get back to \"w\" from \"w + e(w)\"\n\n        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n\n        if zero_grad: self.zero_grad()\n\n    def step(self, closure=None):\n        raise NotImplementedError(\"SAM doesn't work like the other optimizers, you should first call `first_step` and the `second_step`; see the documentation for more info.\")\n\n    def _grad_norm(self):\n        norm = torch.norm(\n                    torch.stack([\n                        p.grad.norm(p=2)\n                        for group in self.param_groups for p in group[\"params\"]\n                        if p.grad is not None\n                    ]),\n                    p=2\n               )\n        return norm\n\n'''\ndef train_plot(net, train_iter, test_iter, num_epochs, lr, optimizer, scheduler, \n              device=try_gpu()):\n    def init_weights(m):\n        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n            torch.nn.init.xavier_uniform_(m.weight)\n    net.apply(init_weights)\n    print('training on', device)\n    net.to(device)\n    loss = nn.CrossEntropyLoss()\n    animator = Animator(xlabel='epoch', xlim=[0, num_epochs],\n                            legend=['loss', 'train acc', 'test acc'])\n    timer = Timer()\n    for epoch in range(num_epochs):\n        metric = Accumulator(3)\n        scheduler.step()\n        for i, (X, y) in enumerate(train_iter):\n            timer.start()\n            net.train()\n            #optimizer.zero_grad()\n            X, y = X.to(device), y.to(device)\n            y_hat = net(X)\n            l = F.cross_entropy(net(X), y)\n            l.backward()\n            optimizer.first_step(zero_grad=True)\n            F.cross_entropy(net(X), y).backward()\n            optimizer.second_step(zero_grad=True)\n            \n            with torch.no_grad():\n                metric.add(l * X.shape[0], accuracy(y_hat, y), X.shape[0])\n            timer.stop()\n            train_loss = metric[0]/metric[2]\n            train_acc = metric[1]/metric[2]\n\n            if (i + 1) % 50 == 0:\n                animator.add(epoch + i / len(train_iter),\n                             (train_loss, train_acc, None))\n        test_acc = evaluate_accuracy_gpu(net, test_iter)\n        animator.add(epoch+1, (None, None, test_acc))\n        print(\"Epoch: {}/{}, train accuray: {}, test accuracy: {}\".format(epoch, num_epochs, train_acc, test_acc))\n    print(f'loss {train_loss:.3f}, train acc {train_acc:.3f}, '\n          f'test acc {test_acc:.3f}')\n    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n          f'on {str(device)}')\n\n    \nclass Mish(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n    def forward(self, x):\n        return x * torch.tanh(F.softplus(x))\n'''\n    \n# construct net\n'''\nstage1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=3, padding=1), Mish(), nn.BatchNorm2d(64),\n                       nn.Conv2d(64, 64, kernel_size=3, padding=1), Mish(), nn.BatchNorm2d(64),\n                       nn.Conv2d(64, 64, kernel_size=3, padding=1), Mish(), nn.BatchNorm2d(64),\n                       nn.MaxPool2d(kernel_size=2), nn.Dropout(p=0.25))\n\nstage2 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=3, padding=1), Mish(), nn.BatchNorm2d(128),\n                       nn.Conv2d(128, 128, kernel_size=3, padding=1), Mish(), nn.BatchNorm2d(128),\n                       nn.Conv2d(128, 128, kernel_size=3, padding=1), Mish(), nn.BatchNorm2d(128),\n                       nn.MaxPool2d(kernel_size=2), nn.Dropout(p=0.25))\n\nstage3 = nn.Sequential(nn.Conv2d(128, 128, kernel_size=3, padding=1), Mish(), nn.BatchNorm2d(128),\n                       nn.Conv2d(128, 128, kernel_size=3, padding=1), Mish(), nn.BatchNorm2d(128),\n                       nn.Conv2d(128, 128, kernel_size=3, padding=1), Mish(), nn.BatchNorm2d(128),\n                       nn.MaxPool2d(kernel_size=2), nn.Dropout(p=0.25))\n\nstage4 = nn.Sequential(nn.Conv2d(128, 128, kernel_size=3, padding=1), Mish(), nn.BatchNorm2d(128),\n                       nn.Conv2d(128, 128, kernel_size=3, padding=1), Mish(), nn.BatchNorm2d(128),\n                       nn.Conv2d(128, 128, kernel_size=3, padding=1), Mish(), nn.BatchNorm2d(128),\n                       nn.MaxPool2d(kernel_size=2), nn.Dropout(p=0.25))\n\nstage5 = nn.Sequential(nn.Conv2d(128, 256, kernel_size=3, padding=1), Mish(), nn.BatchNorm2d(256),\n                       nn.Conv2d(256, 256, kernel_size=3, padding=1), Mish(), nn.BatchNorm2d(256),\n                       nn.Conv2d(256, 256, kernel_size=3, padding=1), Mish(), nn.BatchNorm2d(256),\n                       nn.MaxPool2d(kernel_size=2), nn.Dropout(p=0.25))\n\nnet = nn.Sequential(stage1, stage2, stage3, stage4, stage5, nn.Flatten(), nn.Linear(256, 7))\n'''\n\n'''\nimport torchvision.models as md\nnet = md.wide_resnet101_2()\nnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nnet.fc = nn.Linear(2048, 7)\n'''\n\n'''\nX = torch.rand(size=(1, 1, 32, 32))\nfor layer in net:\n    X = layer(X)\n    print(layer.__class__.__name__,'output shape:\\t', X.shape)\n'''\n\n'''\nbase_optimizer = optim.SGD\noptimizer = SAM(net.parameters(), base_optimizer, lr=0.1, momentum=0.9)\nscheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[20, 32], gamma=0.1)\n\ntrain_plot(net, train_iter, test_iter, num_epochs, lr, optimizer, scheduler)\nplt.savefig(\"Result.jpg\")\nplt.show()\ntorch.save(net.state_dict(), \"Net.param\")\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nimport numpy as np\nimport torchvision.models as models\nimport torch.utils.data as data\nfrom torchvision import transforms\nimport cv2\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport pandas as pd\nimport os ,torch\nimport torch.nn as nn\n\n    \nclass RafDataSet(data.Dataset):\n    def __init__(self, dt, lb):\n        self.data = dt\n        self.label = lb\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        image = self.data[idx][0]\n        label = self.label[idx]\n        \n        return image, label, idx\n\n'''\nclass Res18Feature(nn.Module):\n    def __init__(self, pretrained = True, num_classes = 7, drop_rate = 0):\n        super(Res18Feature, self).__init__()\n        self.drop_rate = drop_rate\n        \n        #resnet  = models.resnet18(pretrained)\n        #resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n        #self.features = nn.Sequential(*list(resnet.children())[:-1]) # after avgpool 512x1\n        #fc_in_dim = list(resnet.children())[-1].in_features # original fc layer's in dimention 512\n        \n        \n        #vgg19_bn\n        \n        resnet = models.vgg13_bn(pretrained)\n        resnet.features[0] = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        #self.features = nn.Sequential(*list(resnet.children())[:-1], *list(resnet.classifier[:-1]))\n        self.features = nn.Sequential(*list(resnet.children())[:-1])\n        self.nxt = resnet.classifier[:-1]\n        \n        fc_in_dim = resnet.classifier[-1].in_features\n        \n        \n    \n        self.fc = nn.Linear(fc_in_dim, num_classes) # new fc layer 512x7\n        self.alpha = nn.Sequential(nn.Linear(fc_in_dim, 1),nn.Sigmoid())\n        \n        \n\n    def forward(self, x):\n        x = self.features(x)\n        \n        #x = self.nxt(x)\n        \n        if self.drop_rate > 0:\n            x =  nn.Dropout(self.drop_rate)(x)\n        x = x.view(x.size(0), -1)\n        x = self.nxt(x)\n        \n        attention_weights = self.alpha(x)\n        out = attention_weights * self.fc(x)\n        return attention_weights, out\n'''\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n    def __init__(self, in_channels, out_channels, stride):\n        super(BasicBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_channels)\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride = stride, padding=1)\n        self.relu1 = nn.ReLU()\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride = stride, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.relu2 = nn.ReLU()\n        self.skip = (in_channels==out_channels)\n\n    def forward(self, x):\n        identity = x\n        out = self.bn1(x)\n        out = self.relu1(out)\n        out = self.conv1(out)\n        out = self.bn2(out)\n        out = self.relu2(out)\n        out = self.conv2(out)\n        if self.skip :\n            out += identity\n\n        return out\n\nclass Res18Feature(nn.Module):\n    def __init__(self, pretrained=False, num_classes=7, drop_rate=0):\n        super(Res18Feature, self).__init__()\n        self.drop_rate = drop_rate\n        self.convin = nn.Conv2d(1, 64, kernel_size=5, stride=2, padding=2)\n        self.bnin = nn.BatchNorm2d(64, track_running_stats=True)\n        self.relu = nn.ReLU()\n        self.stack1 = BasicBlock(64,64,1)\n        self.stack2 = BasicBlock(64,128,1)\n        self.stack3 = BasicBlock(128,256,1)\n        #self.stack4 = BasicBlock(256,512,1)\n        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n        self.alpha = nn.Sequential(nn.Linear(256, 1), nn.Sigmoid())\n        self.fc = nn.Linear(256,7)\n\n    def forward(self, x):\n        x = self.convin(x)\n        x = self.bnin(x)\n        x = self.relu(x)\n\n        x = self.stack1(x)\n        x = self.stack2(x)\n        x = self.stack3(x)\n        #x = self.stack4(x)\n\n        x = self.avgpool(x)\n        if self.drop_rate > 0:\n            x = nn.Dropout(self.drop_rate)(x)\n        x = x.view(x.size(0),-1)\n\n        attention_weights = self.alpha(x)\n        x = attention_weights * self.fc(x)\n\n        return attention_weights, x\n        \ndef run_training():\n\n    imagenet_pretrained = False\n    res18 = Res18Feature(pretrained = imagenet_pretrained, drop_rate = 0.2) \n    \n    source = pd.read_csv(\"../input/facial-expression-recognitionferchallenge/fer2013/fer2013/fer2013.csv\")\n    trans = transforms.Compose([transforms.ToPILImage(), transforms.Resize(128), transforms.ToTensor()])\n    processed_data = []\n    for i in range(0, len(source)):\n        item = source.iloc[i, 1]\n        temp1 = np.array([int(j) for j in item.split(\" \")])\n        temp2 = np.reshape(temp1, (48,48))\n\n        temp3 = [trans(np.uint8(temp2)) * 255, source.iloc[i, 0]]\n        processed_data.append(temp3)\n\n    lb = np.array(source.iloc[:,0]).reshape(-1)\n    lr, num_epochs, batch_size = 0.001, 100, 64\n    train_loader = data.DataLoader(RafDataSet(processed_data[:int(len(processed_data) * 0.9)], lb), batch_size, shuffle=True)\n    val_loader = data.DataLoader(RafDataSet(processed_data[int(len(processed_data) * 0.9):], lb[int(len(processed_data) * 0.9):]), batch_size, shuffle=False)\n    \n    params = res18.parameters()\n    \n    \n    optimizer = torch.optim.SGD(params, 0.05,\n                                    momentum=0.8,\n                                    weight_decay = 1e-4)\n    \n    \n    #base_optimizer = torch.optim.SGD\n    #optimizer = SAM(params, base_optimizer, lr=0.1, momentum=0.9, weight_decay = 1e-4)\n\n    \n    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.9)\n    res18 = res18.cuda()\n    criterion = torch.nn.CrossEntropyLoss()\n    \n    margin_1 = 0.07\n    margin_2 = 0.2\n    beta = 0.7\n    \n    print(next(iter(train_loader)))\n    \n    \n    for i in range(1, 50 + 1):\n        running_loss = 0.0\n        correct_sum = 0\n        iter_cnt = 0\n        res18.train()\n        for batch_i, (imgs, targets, indexes) in enumerate(train_loader):\n            batch_sz = imgs.size(0) \n            iter_cnt += 1\n            tops = int(batch_sz* beta)\n            optimizer.zero_grad()\n            imgs = imgs.cuda()\n            targets = targets.cuda()\n            \n            #add for SAM\n            \n            #_, ot = res18(imgs)\n            #criterion(ot, targets).backward()\n            #optimizer.first_step(zero_grad=True)\n            \n            \n            attention_weights, outputs = res18(imgs)\n            \n            # Rank Regularization\n            _, top_idx = torch.topk(attention_weights.squeeze(), tops)\n            _, down_idx = torch.topk(attention_weights.squeeze(), batch_sz - tops, largest = False)\n\n            high_group = attention_weights[top_idx]\n            low_group = attention_weights[down_idx]\n            high_mean = torch.mean(high_group)\n            low_mean = torch.mean(low_group)\n            diff  = low_mean - high_mean + margin_1\n\n            if diff > 0:\n                RR_loss = diff\n            else:\n                RR_loss = 0.0\n            \n            \n            loss = criterion(outputs, targets) + RR_loss \n            loss.backward()\n            #add for SAM\n            optimizer.step()\n            #optimizer.second_step(zero_grad=True)\n            \n            running_loss += loss\n            _, predicts = torch.max(outputs, 1)\n            correct_num = torch.eq(predicts, targets).sum()\n            correct_sum += correct_num\n\n            # Relabel samples\n            if i >= 12:\n                sm = torch.softmax(outputs, dim = 1)\n                Pmax, predicted_labels = torch.max(sm, 1) # predictions\n                Pgt = torch.gather(sm, 1, targets.view(-1,1)).squeeze() # retrieve predicted probabilities of targets\n                true_or_false = Pmax - Pgt > margin_2\n                update_idx = true_or_false.nonzero().squeeze() # get samples' index in this mini-batch where (Pmax - Pgt > margin_2)\n                label_idx = indexes[update_idx] # get samples' index in train_loader\n                relabels = predicted_labels[update_idx] # predictions where (Pmax - Pgt > margin_2)\n                train_loader.dataset.label[label_idx.cpu().numpy()] = relabels.cpu().numpy() # relabel samples in train_loader\n                \n        scheduler.step()\n        acc = correct_sum.float() / float(len(processed_data)*0.9)\n        running_loss = running_loss/iter_cnt\n        print('[Epoch %d] Training accuracy: %.4f. Loss: %.3f' % (i, acc, running_loss))\n        \n        with torch.no_grad():\n            running_loss = 0.0\n            iter_cnt = 0\n            bingo_cnt = 0\n            sample_cnt = 0\n            res18.eval()\n            for batch_i, (imgs, targets, _) in enumerate(val_loader):\n                _, outputs = res18(imgs.cuda())\n                targets = targets.cuda()\n                loss = criterion(outputs, targets)\n                running_loss += loss\n                iter_cnt+=1\n                _, predicts = torch.max(outputs, 1)\n                correct_num  = torch.eq(predicts,targets)\n                bingo_cnt += correct_num.sum().cpu()\n                sample_cnt += outputs.size(0)\n                \n            running_loss = running_loss/iter_cnt   \n            acc = bingo_cnt.float()/float(sample_cnt)\n            acc = np.around(acc.numpy(),4)\n            print(\"[Epoch %d] Validation accuracy:%.4f. Loss:%.3f\" % (i, acc, running_loss))\n           \n            if acc > 0.7 :\n                torch.save({'iter': i,\n                            'model_state_dict': res18.state_dict(),\n                             'optimizer_state_dict': optimizer.state_dict(),},\n                            os.path.join('models', \"epoch\"+str(i)+\"_acc\"+str(acc)+\".pth\"))\n                print('Model saved.')\n    \n     \n            \n               \nrun_training()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}